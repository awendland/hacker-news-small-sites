<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 14 Sep 2020 00:59:45 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 14 Sep 2020 00:59:45 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Writing Win32 apps like it's 2020: Helpers for a modern C++ world]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24451177">thread link</a>) | @crecker
<br/>
September 12, 2020 | https://building.enlyze.com/posts/writing-win32-apps-like-its-2020-part-2/ | <a href="https://web.archive.org/web/*/https://building.enlyze.com/posts/writing-win32-apps-like-its-2020-part-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
		<p><span>Written by</span>
        Colin Finck
        <br>
        <span>on&nbsp;</span><time datetime="2020-07-30 00:00:00 +0000 UTC">July 30, 2020</time>
</p>
		


		

		

<p>This is the second part of a three-part series on Win32 development:</p>

<ul>
<li><a href="https://building.enlyze.com/posts/writing-win32-apps-like-its-2020-part-1/">Introduction</a></li>
<li><em>Helpers for a modern C++ world</em></li>
<li><a href="https://building.enlyze.com/posts/writing-win32-apps-like-its-2020-part-3/">A DPI-aware resizable wizard</a></li>
</ul>

<p><a href="https://github.com/enlyze/Wizard-2020">Example Project on GitHub</a></p>

<hr>

<p><span>W</span>e are now going to get into the nitty-gritty details of Win32 and how modern C++ can help us here.</p>

<nav id="TableOfContents">
<ul>
<li>
<ul>
<li><a href="#pointers-that-free-themselves">Pointers that free themselves</a></li>
<li><a href="#universal-c-containers">Universal C++ containers</a></li>
<li><a href="#string-resources-without-regrets">String resources without regrets</a></li>
<li><a href="#mastering-the-handle-mess">Mastering the handle mess</a></li>
<li><a href="#gracefully-failing-constructors">Gracefully failing constructors</a></li>
<li><a href="#the-only-wndproc-you-ll-ever-need">The only <code>WndProc</code> you’ll ever need</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul></li>
</ul>
</nav>


<h2 id="pointers-that-free-themselves">Pointers that free themselves</h2>

<p>If you are coming from the C world, you have been managing all your resources manually so far.
You allocate each heap memory block using <code>malloc</code> and need to take care of a call to <code>free</code> in every exit path of the function.
As you have probably observed already, this easily leads to human mistakes:
A forgotten <code>free</code> in just one exit path is enough to cause a severe memory leak.
Freeing a pointer twice or using it after a <code>free</code> happens just as easy and can be the source of very painful bugs.</p>

<p>Being a C API, Win32 is no different in this regard.
It offers you <code>HeapAlloc</code> and <code>HeapFree</code>, which are a bit closer to the operating system than their C library counterparts, but otherwise suffer from the same issues.</p>

<p>Now you may argue that YOU obviously never make such mistakes.
So let’s just talk about the code you import from someone else.
If you see a manual memory allocation there, how can you be sure that the programmer correctly handled all exit paths?
There is no way to ensure that unless you check the entire code yourself.</p>

<p>C++ has been trying to be better at memory management since its infancy.
But it has taken until 2011 for C++ to finally come up with a reliable solution that is also going to work tomorrow: <code>std::unique_ptr</code><br>
This template class is a wrapper around any object that you want to put on the heap.
It allocates memory for the wrapped object in its constructor and frees it in its destructor.
As C++ automatically calls the destructor whenever the <code>std::unique_ptr</code> goes out of scope, you can no longer forget that and the human is taken out of the equation.
This makes <code>std::unique_ptr</code> a so-called <em>smart pointer</em>.</p>

<p>If you have been into C++ for quite a while, you may know <code>std::unique_ptr</code>’s predecessor <code>std::auto_ptr</code>.
This one has been deprecated for good (and entirely removed in newer C++ standards) due to its unclear ownership semantics.
The details don’t matter here, just keep in mind that <code>std::unique_ptr</code> fully owns an object and can’t accidentally lose it.
Unlike <code>std::auto_ptr</code>, you can only transfer ownership of that object by using an explicit <code>std::move</code>.</p>

<p>Note that <code>std::unique_ptr</code> is only an option for allocating a single object.
It does not work for arrays, because those need to be freed differently (<code>delete[]</code> vs. <code>delete</code>).
While people have often asked for an “auto_array_ptr”, modern C++ offers something even better, which we will dive into in the next section.</p>

<h2 id="universal-c-containers">Universal C++ containers</h2>

<p>For a long time, C <code>char</code> arrays and C++ <code>std::string</code> have been two different worlds.
You could get a constant representation of a <code>char</code> array from an <code>std::string</code> using the <code>c_str</code> method, but a true two-way interaction between both types wasn’t possible.
As a result, legacy C interfaces like the Win32 API often limited you to using traditional C-style arrays without the benefits of modern C++ containers.
You had fun managing all the memory allocations yourself, making sure that nothing leaks, and doing <code>strlen</code> over and over again because a <code>char</code> array doesn’t know its size.</p>

<p>This has changed for good starting with C++11, which guarantees that an <code>std::string</code> is internally stored as a <code>char</code> array.
C++17 adds a <code>data</code> method returning a writable pointer to that <code>char</code> array, finally making <code>std::string</code>s universally usable in all places that use <code>char</code> arrays.</p>

<p>Extensive and error-prone code like</p>
<div><pre><code data-lang="C"><span>const</span> <span>char</span><span>*</span> szTest <span>=</span> <span>"Hello"</span>;
<span>int</span> cch <span>=</span> MultiByteToWideChar(CP_ACP, szTest, <span>-</span><span>1</span>, NULL, <span>0</span>);

<span>const</span> WCHAR<span>*</span> wszTest <span>=</span> HeapAlloc(GetProcessHeap(), <span>0</span>, cch <span>*</span> <span>sizeof</span>(WCHAR));
<span>if</span> (<span>!</span>wszTest)
{
    printf(<span>"Out of memory!</span><span>\n</span><span>"</span>);
    <span>return</span> <span>1</span>;
}

MultiByteToWideChar(CP_ACP, szTest, <span>-</span><span>1</span>, wszTest, cch);

<span>// Do something with wszTest
</span><span>// Take care to clean it up in all exit paths using:
</span><span></span>
HeapFree(GetProcessHeap(), <span>0</span>, wszTest);</code></pre></div>
<p>can finally become as simple as</p>
<div><pre><code data-lang="C++">std<span>::</span>string strTest <span>=</span> <span>"Hello"</span>;
<span>int</span> cch <span>=</span> MultiByteToWideChar(CP_ACP, strTest, strTest.size(), <span>nullptr</span>, <span>0</span>);

std<span>::</span>wstring wstrTest;
wstrTest.resize(cch);
MultiByteToWideChar(CP_ACP, strTest, strTest.size(), wstrTest.data(), cch);

<span>// Do something with wstrTest, cleanup happens automatically
</span></code></pre></div>
<p>By the way, the same is also true for <code>std::vector</code>.
All your manual allocations of arrays, prone to buffer overflows and memory leaks, can finally be replaced by automatically managed <code>std::vector</code>s and still interact with APIs written in C.</p>

<h2 id="string-resources-without-regrets">String resources without regrets</h2>

<p>Let’s get deeper into Win32 specifics and use what we just learned.<br>
If you are writing applications for Windows, you have probably made good use of <em>resources</em> already.
Resources allow you to organize strings and graphics at a central location separated from your code.
Each resource is associated with a language code.
When running your application, Windows will pick the resource that best matches your operating system language setting.</p>

<p>For loading a Unicode string resource, the Win32 API of choice is the <code>LoadStringW</code> function.
Even if Microsoft sample code still does, you don’t want to use the ANSI counterpart <code>LoadStringA</code> and neither the <code>LoadString</code> macro that forwards to one of both.
Both were last needed in the era of Windows 95/98/Me, which didn’t come with native Unicode support.
The NT line of Windows has always supported Unicode from the kernel up to the applications.
All <code>A</code> functions there are implemented to convert the string to Unicode and then call the corresponding <code>W</code> function.
As we’re not targeting anything older than Windows XP here, we can (and should!) safely forget about <code>A</code> functions.
Some newer Windows APIs don’t even provide them anymore.</p>

<p>I have seen most people using <code>LoadStringW</code> by declaring a buffer that is “hopefully large enough” and letting the function copy the string into that buffer.
Even Microsoft sample code usually looks like this:</p>
<div><pre><code data-lang="C++">WCHAR wszString[<span>100</span>];
LoadStringW(hInstance, IDS_STRING_ID, wszString, <span>sizeof</span>(wszString) <span>/</span> <span>sizeof</span>(WCHAR));
</code></pre></div>
<p>This code is potentially dangerous in multiple dimensions:<br>
1. If the string for a language later turns out to be longer than 99 characters (consider the terminating NUL), it is silently truncated.
In the best case, this only impacts your user experience badly.
In the worst case, the user loses critical information because the string is later fed to a formatting function like <code>printf</code> and now misses a format character.
2. The developer may forget to divide by the size of a <code>WCHAR</code> in the last parameter, thereby creating the illusion of a larger buffer and laying the foundation for a typical buffer overflow.
3. The return value of <code>LoadStringW</code> isn’t checked at all, hence <code>wszString</code> may be uninitialized.
If you later work with that buffer, expect things to go tremendously wrong.</p>

<p>Only few people know about the other (scarcely documented) way of using <code>LoadStringW</code>:</p>
<div><pre><code data-lang="C++"><span>const</span> WCHAR<span>*</span> pString;
<span>int</span> CharacterCount <span>=</span> LoadStringW(hInstance, IDS_STRING_ID, <span>reinterpret_cast</span><span>&lt;</span>LPWSTR<span>&gt;</span>(<span>&amp;</span>pString), <span>0</span>);
</code></pre></div>
<p>Instead of copying the resource string into a buffer, this call provides you with a read-only pointer to it.
All resources are already loaded into memory when starting your application, so retrieving the string this way performs no additional copying.
However, there is a caveat here:
The string is not necessarily NUL-terminated when being loaded this way.
This makes it hard to use the string directly in a pure C world where NUL-terminated strings are expected everywhere.
While we also get the character count from this <code>LoadStringW</code> call, we cannot just insert the missing NUL terminator ourselves due to the read-only nature of the string pointer.</p>

<p>Fortunately, C++ comes to the rescue here.
As we have learned that its <code>std::</code> classes are full-fledged alternatives to C-style character arrays these days, we can use them to fix our trouble with <code>LoadStringW</code>.
Enough said, the final function looks like this:</p>
<div><pre><code data-lang="C++">std<span>::</span>wstring LoadStringAsWstr(HINSTANCE hInstance, UINT uID)
{
    PCWSTR pws;
    <span>int</span> cch <span>=</span> LoadStringW(hInstance, uID, <span>reinterpret_cast</span><span>&lt;</span>LPWSTR<span>&gt;</span>(<span>&amp;</span>pws), <span>0</span>);
    <span>return</span> std<span>::</span>wstring(pws, cch);
}
</code></pre></div>
<p>These 3 lines are sufficient to solve all of our problems above.
It doesn’t matter if the string is 10 or 1000 characters long, the function will transparently handle this.
It also doesn’t care about any terminating NUL character, because it just initializes a new <code>std::wstring</code> and copies the retrieved number of characters from the read-only resource pointer.
The returned <code>std::wstring</code> is guaranteed to be initialized and a comfortable and safe way to work with the loaded string.</p>

<p>I’m also using Hungarian notation in my final function to emphasize a few things.
The <code>pws</code> abbreviation refers to a <em>pointer to a wide-string</em>.
You may have more commonly seen <code>pwsz</code>, which would translate to a <em>pointer to a wide-string terminated by zero</em>.
As we just discussed, the latter part does not apply here, and this is underlined by the subtle difference in naming.
Similarly, <code>cch</code> stands for <em>count of characters</em> and distinguishes the integer variable from a count of bytes (<code>cb</code>).
You will deal with both when using Win32 API, and proper naming helps to not mess things up.</p>

<h2 id="mastering-the-handle-mess">Mastering the handle mess</h2>

<p>If you write your Win32 application in C, you soon have handles all over the place.
Every I/O operation, network connection or registry key, just to name a few, is identified by a handle variable that you must take care of.
When a resource is no longer needed, you need to close the handle manually - and again you must do so for all exit paths of your function.
This technique is susceptible to the same human mistakes that we …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://building.enlyze.com/posts/writing-win32-apps-like-its-2020-part-2/">https://building.enlyze.com/posts/writing-win32-apps-like-its-2020-part-2/</a></em></p>]]>
            </description>
            <link>https://building.enlyze.com/posts/writing-win32-apps-like-its-2020-part-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24451177</guid>
            <pubDate>Sat, 12 Sep 2020 09:40:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Social Dilemma by Tristan Harris – Review, Summary and Infographic]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24450987">thread link</a>) | @Lima_Writes
<br/>
September 12, 2020 | https://lifebeyond.one/blogs/tech-impact/why-you-should-watch-the-social-dilemma-on-netflix-today | <a href="https://web.archive.org/web/*/https://lifebeyond.one/blogs/tech-impact/why-you-should-watch-the-social-dilemma-on-netflix-today">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <div>
    <div>
      <div id="shopify-section-article-template">

<div>
  <h2 name="0a5e">
<span data-contrast="none" xml:lang="NL-NL" lang="NL-NL"><span data-ccp-parastyle="Subtitle">Get a wake-up call on<span>&nbsp;</span></span></span><span data-contrast="none" xml:lang="NL-NL" lang="NL-NL"><span data-ccp-parastyle="Subtitle">the</span></span><span data-contrast="none" xml:lang="NL-NL" lang="NL-NL"><span data-ccp-parastyle="Subtitle"><span>&nbsp;</span>impact of Big Tech<span>&nbsp;</span></span></span><span data-contrast="none" xml:lang="NL-NL" lang="NL-NL"><span data-ccp-parastyle="Subtitle">and</span></span><span data-contrast="none" xml:lang="NL-NL" lang="NL-NL"><span data-ccp-parastyle="Subtitle"><span>&nbsp;</span>take action,<span>&nbsp;</span></span></span><span data-contrast="none" xml:lang="NL-NL" lang="NL-NL"><span data-ccp-parastyle="Subtitle">now</span></span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span>
</h2>
<figure name="aad1"><img data-image-id="1*toFS4aaDipX_CuNrRhBtCQ.png" data-width="3505" data-height="2673" src="https://cdn-images-1.medium.com/max/1800/1*toFS4aaDipX_CuNrRhBtCQ.png"></figure>

<section name="1442">

<div>
<div>
<p name="db86">I watched “<a href="https://www.netflix.com/title/81254224" data-href="https://www.netflix.com/title/81254224" rel="noopener noreferrer" target="_blank">The Social Dilemma</a>”, the documentary by the Center for Humane Technology and featuring Tristan Harris, yesterday. It taught me zero new things. I learned nothing that I had not already come across during my research for my latest book <a href="https://lifebeyond.one/products/life-beyond-the-touch-screen-smartphone-addiction?ref=hackernoon.com" data-href="https://lifebeyond.one/products/life-beyond-the-touch-screen-smartphone-addiction?ref=hackernoon.com" rel="noopener noreferrer" target="_blank">Life Beyond the Touch Screen</a>. Or that I had not even incorporated in the book.</p>
<p name="b017">I was, however, very much inspired by the documentary.</p>
<p name="b017"><em><iframe width="560" height="315" src="https://www.youtube.com/embed/uaaC57tcci0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></em></p>
<p name="b017"><em>[Oh wait, I did learn two new things. I learned about </em><a href="https://www.nytimes.com/2018/11/06/technology/myanmar-facebook.html" data-href="https://www.nytimes.com/2018/11/06/technology/myanmar-facebook.html" rel="noopener noreferrer" target="_blank"><em>the role Facebook played</em></a><em> and admitted it played in the Myanmar Rohingya Muslim violence. And that there is such a thing as </em><a href="https://www.theguardian.com/lifeandstyle/2019/jan/23/faking-it-how-selfie-dysmorphia-is-driving-people-to-seek-surgery" data-href="https://www.theguardian.com/lifeandstyle/2019/jan/23/faking-it-how-selfie-dysmorphia-is-driving-people-to-seek-surgery" rel="noopener noreferrer" target="_blank"><em>Snapchat Dismorphia</em></a><em> — a.k.a. kids seeking surgery to look more like their filtered selfies in real life. ‘Da hell.]</em></p>
<p name="b017"><em>[Note: Tristan Harris, together with Nir Eyal and Yuval Noah Harari, has been one of my greatest inspirations for creating "Life Beyond the Touch Screen". Nothing but respect. Read on to understand more.]</em></p>
<p name="a2d9">I was inspired because I recognized two things. One being the difficulty Tristan Harris — legendary former design ethicist at Google — and other former and current high-ranking executives from silicon valley, venture capitalists and academics were having;</p>
<blockquote name="fe84"><em>In trying to explain what was so wrong and so dangerous about the role digital technology is taking in our lives today.</em></blockquote>
<p name="b0e2">What is that problem?</p>
<p name="13db">This was the second thing I recognized. The problem is that next to and simultaneous to adding so much ease and benefit to our lives, digital technology and mainly social media, are impacting our individual mental health, the mental health of our children, and the fabric of society and democracy in very, very dark ways as well.</p>
<p name="b43a">We are getting burn-out by the masses, staggeringly high rates of depression, anxiety and suicide in teens (mostly girls), and unprecedented levels of political polarization and tampering of election results with the help of an explosion of fake news. Propaganda, and real-life, deadly violence.</p>
<p name="5883">Why? Because armies of already genius experts in the psychology of persuasion and addiction, armed with the most powerful technology mankind has ever seen, are becoming more and more proficient at altering our behavior in minuscule but very, very real ways.</p>
<blockquote name="42dd">I am seriously afraid for our mental health, for that of our children, and for the world they will inherit.</blockquote>
<p name="d360">The problem underneath that being that the supercomputers and algorithms working to do that, are programmed from a capitalist and commercial perspective — so their highest goal is not humanity’s greater good: instead it is the highest possible profit.</p>
<p name="81e5">Our attention, time, and energy are being sold to the highest bidder. And as I have written before; maybe it’s <a href="https://medium.com/hackernoon/the-state-of-ai-in-the-world-56be75b51887" data-href="https://medium.com/hackernoon/the-state-of-ai-in-the-world-56be75b51887" rel="noopener noreferrer" target="_blank">not a question of when A.I. starts taking over from us humans</a> — but rather a question of when we will wake up to the fact that it already has.</p>
<h3 name="f1ee">“The Social Dilemma”- Review, Summary, ArtfulGraphic</h3>
</div>
<div>
<figure name="13ff"><img data-image-id="1*Zhq2MjvT7v_k5hT3TTDkeA.jpeg" data-width="1280" data-height="720" src="https://cdn-images-1.medium.com/max/1800/1*Zhq2MjvT7v_k5hT3TTDkeA.jpeg"></figure>
</div>
<div>
<p name="e837">I was so inspired by “The Social Dilemma” that I created the above ArtfulGraphic, to try and help create momentum — in all honesty, also to possibly ride the hype I’m hopefully helping to create, and promote <a href="https://lifebeyond.one/products/life-beyond-the-touch-screen-smartphone-addiction?ref=hackernoon.com" data-href="https://lifebeyond.one/products/life-beyond-the-touch-screen-smartphone-addiction?ref=hackernoon.com" rel="noopener noreferrer" target="_blank">my book</a>.&nbsp;</p>
<p name="1241">I drew a lady with a <em>black mirror</em> face, edited the picture in a wonderful app called Photofox, and then created the Graphic in PowerPoint — I’m no pro designer, sorry, not sorry.</p>
<p name="e1a1">Mainly, though, I created the above ArtfulGraphic to try to explain as simply as possible what’s going on.&nbsp;</p>
<p name="0971">Why this stuff matters and why you want to get inspired and take action now. And why you should watch “<a href="https://www.netflix.com/title/81254224" data-href="https://www.netflix.com/title/81254224" rel="noopener noreferrer" target="_blank">The Social Dilemma</a>” on Netflix today, preferably together with your spouse and your kids, if you have them.</p>
</div>
</div>
</section>
<section name="d9d2">


</section>
</div>


  <!-- /snippets/social-sharing.liquid -->







</div>
    </div>
  </div>
</article></div>]]>
            </description>
            <link>https://lifebeyond.one/blogs/tech-impact/why-you-should-watch-the-social-dilemma-on-netflix-today</link>
            <guid isPermaLink="false">hacker-news-small-sites-24450987</guid>
            <pubDate>Sat, 12 Sep 2020 08:53:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I got my first GitHub sponsor]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24450931">thread link</a>) | @leoloso
<br/>
September 12, 2020 | https://leoloso.com/posts/milestone-first-github-sponsor/ | <a href="https://web.archive.org/web/*/https://leoloso.com/posts/milestone-first-github-sponsor/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>2 days ago I subscribed to GitHub sponsors to fund my work on the <a href="https://github.com/GraphQLAPI/graphql-api-for-wp">GraphQL API for WordPress</a>, and I already got <a href="https://github.com/sponsors/leoloso/">my first sponsor</a>!</p><figure><img src="https://leoloso.com/images/leoloso-github-sponsors.png" alt="GitHub sponsors" loading="lazy" width="2048" height="1510"><figcaption>GitHub sponsors</figcaption></figure><p>Following the example set by Caleb Porzio (who's making <a href="https://calebporzio.com/i-just-hit-dollar-100000yr-on-github-sponsors-heres-how-i-did-it">more than u$d 100k/y doing open source</a>), I have decided to use the <a href="https://calebporzio.com/sponsorware">sponsorware model</a> to fund my project. It works like this:</p><ul><li>Whenever I get 10 new sponsors (at u$d 14/m), I start developing the most up-voted feature from a special <a href="https://github.com/GraphQLAPI/graphql-api-for-wp/projects/2">"Sponsorware" list</a> (which I'm completing as I'm writing this milestone)</li><li>Once implemented, the new feature becomes available to all the sponsors, via a private GitHub repo</li><li>As soon as I get 50 new sponsors, the new feature becomes open source, accessible to everyone via the public GitHub repo, and is integrated into the plugin</li></ul><figure><img src="https://leoloso.com/images/sponsorware-features.png" alt="Sponsorware features" loading="lazy" width="2048" height="1120"><figcaption>Sponsorware features</figcaption></figure><p>In a few months, I will also start creating instructional videos, explaining how to make the most out of the plugin. According to Caleb, this is the biggest money-making strategy.</p><p>I have also decided to add a middle tier (at u$d 70/m), where I provide Slack-based personal support, to help users of my plugin set-up GraphQL with WordPress, troubleshooting, and answering their questions. A user needed help to develop a functionality, so he decided to sponsor me &lt;= my first sponsor ❤️</p><p>Finally, I added a higher tier (at u$d 700) for corporate sponsors. I plan to ask around in the WordPress community if their companies may be interested in participating. That would be a win-win: They get plenty of face from contributing to open source, and I get the certainty that I can make a living wage from my work and can focus on the development of the plugin (and not on marketing, which is not my forte).</p><figure><img src="https://leoloso.com/images/leoloso-github-sponsor-projects.png" alt="My sponsors and sponsored projects" loading="lazy" width="2048" height="1210"><figcaption>My sponsors and sponsored projects</figcaption></figure><p>I hope the sponsorware model works, and I can make a living while working on open source. I'll keep writing updates on how it goes, here on my blog, and <a href="https://www.indiehackers.com/leoloso">on IndieHackers</a>.</p></div></div>]]>
            </description>
            <link>https://leoloso.com/posts/milestone-first-github-sponsor/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24450931</guid>
            <pubDate>Sat, 12 Sep 2020 08:41:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Kubernetes tech community bubble]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24450880">thread link</a>) | @mstipetic
<br/>
September 12, 2020 | https://www.msb.com/post/the-kubernetes-tech-community-bubble | <a href="https://web.archive.org/web/*/https://www.msb.com/post/the-kubernetes-tech-community-bubble">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.19.2"><div dir="ltr"><div><p id="viewer-foo">Or why it's really okay to not know what this whole Container thing is about</p><div id="viewer-c4rdc"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.msb.com/post/the-kubernetes-tech-community-bubble" data-pin-media="https://static.wixstatic.com/media/nsplsh_6de978c2b200427e948652ff4a9b082a~mv2.jpg/v1/fit/w_4966,h_2275,al_c,q_80/file.png" src="https://static.wixstatic.com/media/nsplsh_6de978c2b200427e948652ff4a9b082a~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-6e3lk">We at MSB are huge Kubernetes fans. We believe it will continue to provide a strong foundation to modern software deployments and we're excited to see what each new release brings.</p><p id="viewer-9krij">The unprecedented pace of Kubernetes releases, each bringing new features and quality of life upgrades, means there's a lot to keep pace with. Just having a look at the <a href="https://kubernetes.io/docs/setup/release/notes/" target="_blank" rel="noopener"><u>release notes</u></a> of the latest version shows the scope of progress being made. </p><div id="viewer-b2jas"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.msb.com/post/the-kubernetes-tech-community-bubble" data-pin-media="https://static.wixstatic.com/media/554806_8c719738016b4143b864a564fe70037c~mv2.png/v1/fit/w_828,h_601,al_c,q_80/file.png" src="https://static.wixstatic.com/media/554806_8c719738016b4143b864a564fe70037c~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div><p><span dir="auto">Kubernetes release cadence</span></p></div></div></div><h2 id="viewer-4tk88">Kubernetes is already dead?</h2><p id="viewer-fu04n">Even with the fast pace of evolution, and majority of companies still being somewhere on the long tail of adoption and struggling to keep up, there are predictions that building for Kubernetes is already building into a legacy system looking few years in the future.</p><p id="viewer-9hfi4">Simon Wardley talks about <a href="https://read.acloud.guru/simon-wardley-is-a-big-fan-of-containers-despite-what-you-might-think-18c9f5352147" target="_blank" rel="noopener"><u>serverless</u></a> being the natural progression of the evolution of our software architecture, with projects like <a href="https://knative.dev/" target="_blank" rel="noopener"><u>knative</u></a> already building serverless abstractions on top of Kubernetes.</p><h2 id="viewer-cl9np">It's not about the technology</h2><p id="viewer-5oqfg">Even though the tech may be on the way, or already here, utilising it and the <a href="https://www.msb.com/post/organisational-benefits-of-kubernetes" target="_blank" rel="noopener"><u>benefits it brings</u></a> requires first and foremost a change in the people building these systems.</p><p id="viewer-dhg4j">A modern (micro-)service architecture requires properly managing:</p><ul><li id="viewer-5s887"><p>service versioning</p></li><li id="viewer-86if6"><p>dependency management</p></li><li id="viewer-b94g5"><p><strong>distributed transaction management</strong></p></li><li id="viewer-b10ah"><p>distributed tracing and logging</p></li><li id="viewer-8i8e"><p>clear API and interface agreements</p></li><li id="viewer-cgqob"><p>DB schema versioning and migrations</p></li><li id="viewer-ajadd"><p>software delivery pipelines</p></li></ul><p id="viewer-5rrcf">to name a few, and the most difficult thing of all - coordinating a large amount of people to agree on something and recognise the benefits of the increased workload (at least initially). Each one of these points is a whole field onto itself, with no "right" way to do it.</p><h2 id="viewer-8q7d6">Our on the ground experience</h2><p id="viewer-d7v9m">Even though it's exciting to talk about the tech and the possibilities it offers and read tech blogs, our on the ground experiences, and the many conversations we have, show a different reality.</p><p id="viewer-d8emi">Migrations start full of excitement, extracting from the "legacy" monolith several stateless services, and grinding to a halt when coming to the large "<em>happy-path state machine</em>" at the heart of every company - the code that checks ten different things, notifies several other components, ensures consistency, and provides a successful customer experience.</p><p id="viewer-ueci">When working with companies, we often have to encourage people to not feel bad about not knowing what a container is or their purpose, how things are meant to communicate, and especially acknowledge when they rightfully recognise that this new system we're proposing is much more complicated.</p><p id="viewer-t2fl">We'd like to provide some encouragement - in our experience, even the major tech companies, blogging about their shiny Scala microservices, usually have a large monolith at the heart of their tech stack, meetings trying to coordinate various components and developers struggling to understand how things work and how to get things done.</p><p id="viewer-bo78">I<em>f you'd like to listen to some on the ground stories about Kubernetes adoption patterns, we'd recommend a listen of our </em><a href="https://www.msb.com/podcast/episode/37572d1a/001-kubernetes-enterprise-adoption-with-jeroen-overmaat" target="_blank" rel="noopener"><em><u>podcast episode</u></em></a><em> with Mr. Jeroen Overmaat from Rancher.</em></p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.msb.com/post/the-kubernetes-tech-community-bubble</link>
            <guid isPermaLink="false">hacker-news-small-sites-24450880</guid>
            <pubDate>Sat, 12 Sep 2020 08:29:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Set up GA event tracking for a button click fast]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24450521">thread link</a>) | @arctic-hunter
<br/>
September 12, 2020 | https://bluerivermountains.com/en/event-tracking | <a href="https://web.archive.org/web/*/https://bluerivermountains.com/en/event-tracking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" id="gatsby-focus-wrapper"><div><main role="main"><div><p>Configuring Google Analytics event tracking is vital to data analysis, because it is used to track user interactions. Analysing pageviews, sessions and visitors only lags context about the engagement of a website visitor.</p> <p>This is solved by collecting additional data from custom events that capture user interactions, such as link clicks for example.</p><p>Events represent user interactions or occurrences.<br>Usually, the most important interactions stand in relation to the goal of the website.<br> Hence, we set up custom event tracking to use it as a performance indicator to see, if our goals are being achieved.</p><p>Events can be grouped into <strong>hard conversions</strong> and <strong>soft conversions</strong> to account for their relation with the overall goal of the website.</p><p>Since events often are the basis to monitor conversions in an ecommerce or remarketing context, it is sometimes referred to as conversion tracking.<br>I distinguish between conversion tracking and tracking an event, since a conversion could also be a pageview or a <b>passive</b> occurence, as for example spending a certain amount of time on a landing page.</p><p>To illustrate what event tracking means, I will show you how to set up <strong>click tracking</strong> on a submit button. Afterwards, you should be able to set up your own unique click events on any element you like - so let's get started!</p><h2 id="what-is-event-tracking-in-google-analytics"><a href="#what-is-event-tracking-in-google-analytics" aria-label="What is event tracking in Google Analytics?" title="Right click to copy link to paragraph"></a>What is event tracking in Google Analytics?</h2><p>An event can either be an <strong>active user interaction</strong> or a <strong>passive occurrence</strong>. Tracking them means to watch or count the occurrences and set them in relation to users, visits and other dimensions for later analysis.</p><p>Since you are free to configure events the way you want, they can take many different forms.</p><h3 id="examples"><a href="#examples" aria-label="Examples" title="Right click to copy link to paragraph"></a>Examples</h3><ul><li>add a product to a shopping basket</li><li>signup to an email list</li><li>scroll down to the bottom of an article</li><li>click play in a video</li><li>user login</li><li>click on an image to zoom</li><li>submission of a contact form</li><li>outbound link click</li><li>print an article</li><li>download a file</li></ul><p>As you can see, events are usually tied to something the user <em>does</em>, based on monitoring...</p><ul><li>mouse clicks</li><li>mouse movements</li><li>scrolling</li><li>browser navigation</li><li>keyboard inputs</li></ul><p>Events can also be <em>passive</em>, without the user doing anything actively.<br>For example, when the user spends a certain <strong>amount of time on a page</strong> or when a form returns an <strong>error</strong>. Also when a <strong>chatbot window</strong> opens up to talk to the visitor, there is no activity coming from the user.</p><p>Though a <b>page view</b> is technically also an interaction, the most widely used Universal Google Analytics counts a page view not as an event. However, the new Google Analytics App + Web (currently in Beta) uses a different data model which tracks page visits as events too.</p><h2 id="event-types"><a href="#event-types" aria-label="Event types" title="Right click to copy link to paragraph"></a>Event types</h2><p>We can distinguish between two types of events:</p><h6 id="active-events-"><a href="#active-events-" aria-label="Active events (with user interaction)" title="Right click to copy link to paragraph"></a>Active events (with user interaction)</h6><ul><li>mouse clicks, scroll tracking and mouse movement</li><li>screen touch</li><li>keyboard inputs</li></ul><h6 id="passive-events"><a href="#passive-events" aria-label="Passive events" title="Right click to copy link to paragraph"></a>Passive events</h6><ul><li>hitting a predefined time threshold</li><li>Server responses</li><li>Programmatic validations</li><li>Third-party script execution</li></ul><p>Note that with tracking active and passive events, you can re-construct a big part of the<!-- --> <!-- -->customer journey<!-- -->. <br>Such data enables you to draw conclusions about the user's experience from beginning to end. If you find any flaws in the journey, you can now take action to reduce those negative experiences.</p><h2 id="structure-of-google-analytics-events"><a href="#structure-of-google-analytics-events" aria-label="Structure of Google Analytics Events" title="Right click to copy link to paragraph"></a>Structure of Google Analytics Events</h2><p>Each event in Google Analytics holds some event fields, or bits of information about the event, that we can use to describe the occurrence:</p><ul><li><strong>event category</strong> - to categorize events in groups. In the context of a contact form, for example, you would want to group all events into an event category <em>contact form</em></li><li><strong>event action</strong> - to describe the interaction, e.g. <em>form submission</em></li><li><strong>event label</strong> - to add additional information about the interaction. For example, if the user is sending the <em>address of their website</em> along with the form, you use it to distinguish between the received forms</li><li><strong>event value</strong> - (<em>optional</em>) to add a numeric value to the information. For instance, if on avg. every 25th contact leads to a 100$ conversion, we could assign a value of <em>4</em> <!-- -->to each event.</li><li><strong>event non-interaction</strong> - to distinguish between an active or passive user interaction.<!-- --> <br>By default, it is set to <code>false</code>, which means the event counts as active.<!-- --> <strong>Important:</strong> Active events affect the calculation of a page's <b>bounce rate</b>, by lowering it. So if you ever struggle with an unrealisticly low bounce rate, chances are some events user-interaction is set to <code>true</code> by mistake.</li></ul><h2 id="implement-google-analytics-event-tracking"><a href="#implement-google-analytics-event-tracking" aria-label="Implement Google Analytics event tracking" title="Right click to copy link to paragraph"></a>Implement Google Analytics event tracking</h2><p>There are two possible ways to implement custom event tracking:</p><ol><li><strong>Implement it</strong> with javascript snippets on all relevant HTML elements along with an onclick event handler - <strong>I don’t recommend this</strong> approach, since it is error-prone and not scalable. If you want to do this anyway, you can find code examples in<!-- --> <strong>Google’s event tracking documentation</strong>:</li></ol><ul><li><a href="https://developers.google.com/analytics/devguides/collection/analyticsjs/events" target="_blank">analytics.js event documentation (legacy)</a></li><li><a href="https://developers.google.com/analytics/devguides/collection/gtagjs/events" target="_blank">gtag.js event documentation</a></li></ul><ol start="2"><li><strong>Setting it up with Google Tag Manager</strong> or another <a href="https://bluerivermountains.com/en/tag-management">tag management system</a> of your choice. <br>Ease and flexibility when implementing changes, as well as scalability and easy integration with third-party services make it the preferred implementation method.</li></ol><p>I will explain how to track events with Google Tag Manager, since it is the most widely used tag management system everyone can get access to.</p><h2 id="guide-to-track-events-with-google-tag-manager"><a href="#guide-to-track-events-with-google-tag-manager" aria-label="Guide to track events with Google Tag Manager" title="Right click to copy link to paragraph"></a>Guide to track events with Google Tag Manager</h2><p>Setting up custom event tracking can be broken down into creating a <strong>trigger</strong> for the event, as well as creating an <strong>event tag</strong>, which populates the event properties (<em>category, action, label</em>, etc.). <br>The values for the event properties can either be assigned statically or dynamically - where the latter is preferred for scaling the configuration over larger sites.</p><p>As an example, we are going to implement Google Analytics tracking for a button click.<!-- --> <strong>Click tracking</strong> is the most commonly used form of user behaviour tracking, so the example should be applicable to many other use cases.</p><p>At this point I assume that you already created a tracking ID and that the tracking code was implemented across the whole site when you <a href="https://bluerivermountains.com/en/google-analytics-setup">set up Google Analytics</a> with GTM.</p><h3 id="configure-the-event-trigger-in-google-tag-manager"><a href="#configure-the-event-trigger-in-google-tag-manager" aria-label="Configure the event trigger in Google Tag Manager" title="Right click to copy link to paragraph"></a>Configure the event trigger in Google Tag Manager</h3><ul><li>First, we have to log into our <a href="https://tagmanager.google.com/">Google Tag Manager container</a> <!-- -->and <strong>create a new trigger</strong>.</li></ul><ul><li>Give your trigger a <strong>name</strong>, for example <strong>Click - Button</strong>, and click on the<!-- --> <strong>trigger configuration</strong> field to select a trigger type. You will see a list of trigger types slide in from the right.</li><li>Choose <strong>All Elements</strong> as the type and select, that the<!-- --> <strong>trigger only fires on some clicks</strong>.</li><li>Then, in the first dropdown, choose <strong>Click Element</strong>. If it's not listed, just click<!-- --> <strong>Choose built in variable…</strong> and activate it.</li></ul><ul><li>In the second dropdown, choose <strong>matches CSS selector</strong>.<br>Now let me explain what we’re doing:<br>We are trying to generate a click trigger for a specific HTML element on your website - the one you want to be tracking clicks on. In my example, it is a <strong>button</strong>, but it could also be an<!-- --> <strong>image</strong> or a <code>&lt;div&gt;</code> tag, or any other HTML tag - so the question is: How do we tell Google Tag Manager (GTM) which element to observe?<br>The Answer is: <strong>CSS selectors</strong> - You don’t know what that is? It is just a programmatic way of specifying HTML elements on the page and I will show you a way to get the CSS selector for any element with just a few mouse clicks.</li><li>In Google's Chrome browser, <strong>right-click</strong> any element you would like to track clicks on and select <strong>inspect</strong>. Chrome Developer Tools will open up and by default, the HTML element will be pre-selected.</li><li>Then you simply <strong>right-click</strong> the element and choose <strong>Copy</strong> &gt;<!-- --> <strong>Copy JS path</strong> (avoid <em>copy selector</em> - it returns faulty selectors from time to time).</li></ul><ul><li>If you paste the content of your clipboard into a text editor, you will see you copied something like:<p><code>document.querySelector("body &gt; ul &gt; button")</code></p><p>We want to take the part that is inside the brackets, without the “”. So, this part:</p><p><code>body &gt; ul &gt; button</code></p></li><li><strong>This is the CSS Selector</strong> we need to paste into the last field in our trigger configuration in GTM (<em>see below</em>).<br><strong>Copy</strong> that value and paste it in. Click <strong>save</strong>.</li></ul><p>Notice you could do this with any element and set up any event trigger in GTM as you like?</p><p>We are not done yet. After setting up the trigger conditions for our event, we have to configure the Google Analytics event tag to make sure the right data is sent to the Google Analytics property.</p><h3 id="create-a-custom-event-tag"><a href="#create-a-custom-event-tag" aria-label="Create a custom event tag" title="Right click to copy link to paragraph"></a>Create a custom event tag</h3><p>Now that we have a trigger, we need to combine it with an actual event tag. You can think of triggers and tags as the <em>when</em> and <em>what</em> in our example: <br> The trigger defines <em>when</em> we want to track an event (<em>when our button is clicked</em>), and now we will define a GA event, that describes<!-- --> <em>what</em> we do: <em>Send an event to GA including all the right values for the event properties.</em></p><p>Let’s get started.</p><ul><li>In Google Tag Manager go to the tags menu and <em>create a new tag</em>.</li></ul><ul><li>Give the tag a <strong>name</strong> like <em>Button Event</em> and click on<!-- --> <strong>tag configuration</strong>.</li><li>A panel from the right side is going to slide in with a list of possible tag types to choose from. Select<!-- --> <strong>Google Analytics - Universal Analytics</strong>.</li><li>Back in the tag configuration, set the <strong>track type</strong> to <strong>event</strong>. Now you will see more fields showing up for the event data.</li><li>Let’s assign static values for <strong>event category</strong> and <strong>action</strong> and let’s make the <strong>event label</strong> populate dynamically.<br>Call the <strong>category</strong> <em>click events</em>, for example, the <strong>action</strong> is just<!-- --> <em>click</em> and for the <strong>label</strong> click on the Lego brick symbol next to it.</li><li>We want the label to always hold the text that is written on the clicked HTML element, so in case we are tracking multiple buttons, we could distinguish between them.<br>After clicking on the Lego brick, a panel is going to slide in to <strong>choose a variable</strong>. Click on <strong>built-ins</strong> in the top right corner, unless you already see<!-- --> <strong>click text</strong> in the list of variables (then just <strong>select it</strong> and skip the following step).</li></ul><ul><li>In the list of built-in variables, activate <strong>click text</strong> and GTM will add that variable in the label field in curly braces, like this: <code>{{Click Text}}</code> - Double curly braces are the internal way in GTM to reference variables.</li><li>The <strong>value</strong> field in the tag configuration can be filled with a value the event click may represent. <br>In my example, I leave the field <strong>empty</strong> because I don’t …</li></ul></div></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bluerivermountains.com/en/event-tracking">https://bluerivermountains.com/en/event-tracking</a></em></p>]]>
            </description>
            <link>https://bluerivermountains.com/en/event-tracking</link>
            <guid isPermaLink="false">hacker-news-small-sites-24450521</guid>
            <pubDate>Sat, 12 Sep 2020 07:10:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cybersecurity and AI in Health Applications]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24450431">thread link</a>) | @xxlcloudinc
<br/>
September 11, 2020 | https://codecoda.com/en/blog/entry/cybersecurity-and-ai-in-health-applications | <a href="https://web.archive.org/web/*/https://codecoda.com/en/blog/entry/cybersecurity-and-ai-in-health-applications">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="description">
<p>Cyber-crimes affect companies from all industries like IT, Legal, Education, Manufacturing, Finance. Healthcare is one of the most targeted since this sector relies on the perpetual exchange of big volumes of valuable data.</p>
<div><p>Amid a health crisis, a cyberattack targeting healthcare IT systems around the world takes place every three days <a href="#ref1"><sup>[1]</sup></a>.</p><p>Since the beginning of the second decade of this millennium, cyber threats and data breaches increase rate has <a href="https://www.industryweek.com/technology-and-iiot/article/22026828/cyberattacks-skyrocketed-in-2018-are-you-ready-for-2019" target="_blank" rel="nofollow">spiked disturbingly</a>. Cyber regulations are evolving and requiring healthcare facilities to address more than just the patient’s illnesses. Also responsible for the security of their data, they make health care information security a priority. And they are pushed to do it. Any intrusion on the integrity of internal data can have catastrophic consequences for patients and healthcare facilities.</p></div>
<figure><img src="https://cdn.codecoda.com/img/pixel.gif" data-plugin-lazyload="" data-plugin-options="{'effect' : 'fadeIn', 'speed' : 'fast'}" data-original="https://cdn.codecoda.com/themes/user/site/default/asset/img/blog/healthcare-breach-barometer-2016-2019.jpg" alt="Healthcare Data Breaches 2016-2019">
<figcaption><small>Healthcare Data Breaches 2016-2019</small></figcaption>
</figure>
<div><p>For healthcare companies, a breach of security is very costly. In this critical context, the health sector must be aware and ready to do everything possible to secure their health applications and data banks, by channeling enough technological and financial resources to them. The data collected in the health sector is particularly sensitive because most records become a significant liability when compromised. Healthcare organizations are prime targets for cybercriminals seeking to gain valuable information by exploiting vulnerable security systems. The risk of a breach is reduced by adopting security measures with mighty authentication methods, paired with employee training – <a href="https://www.forbes.com/sites/insights-fortinet/2019/08/27/the-importance-of-training-cybersecurity-awareness-as-a-firewall/#2693a2cd8b4b%20target=" _blank"="" rel="nofollow">a necessary follow-up action</a> that some companies tend to undermine, and, therefore, risk turning into a headline in cybersecurity news sites.</p><p>One specific area of healthcare is particularly susceptible to cyberattacks, and criminals often use it to create a breakpoint - the company’s supply chain. Because health organizations rely on multiple suppliers and external services, they support a vast network where massive data is on a constant exchange. Securing such an intense pipeline of information flow is exceptionally difficult, and hackers won’t hesitate to abuse this unfortunate fact.</p><p>In the Healthcare sector, computer systems contain sensitive data and support organizations in the delivery of quality patient services, making them a prime target for extortion attempts. Phishing, in which a cybercriminal poses as a legitimate organization or individual to entice trust, is a common form of attack. Emails have always been a possible point of entry, filled with bogus attachments and links to fake websites. Email breach is of particular concern in healthcare, as staff consistently uses emails to exchange highly valuable data. If an employee’s email login information is stolen or disclosed - including their username and password - they can be used by criminals to gain access to patient records, and based on this employee level of access, possibly leverage even further damage.</p></div>
<h2>Applications at the service of health: pay attention to the data!</h2>
<div><p>The concept of e-health is not technologically innovative. The service itself is not advanced by any means; what is innovative is the main piece of technology it uses. This tech choice consists of the provision of communicating applications allowing, here, to perform specific measures via the combined effort of a peripheral, a service platform (mainly based on cloud technologies) and a communication network <a href="#ref2"><sup>[2]</sup></a>.</p><p>The security principles and techniques applicable to e-health are, therefore, very similar to those considered by suppliers of critical connected systems. The main difference is that medical devices process health data, which is among the most lucrative for cybercriminals. Personal medical records reside under the aegis of restrictive regulations. Such regulations impose special protection to guarantee the integrity of the patient’s privacy.</p><p>New black gold, all the corporate data collected and processed, defines the level of risk for the services that use this information. In the case of e-health, all present vulnerabilities and medical data leak possibilities must be eradicated. Data protection can break the integrity of private data. For example, sensitive information can circulate multiple communication channels and get exposed to a breach. Not even the doctor-patient is entirely bulletproof.</p><p>A data communication channel may temporarily break data integrity. For example, doctor-patient communication is vulnerable to data leaks, despite the security-laden non-disclosure agreement they both approve.</p><p>Of course, sensitive data can be partially <b><a href="https://codecoda.com/en/blog/entry/benefits-of-encryption-technology-for-data-protection">encrypted</a></b> or partially exposed. For example, to explain conditions or medical treatment procedures, doctors use <i>pseudonymization</i>, when communication with their patients. Doctors also use <i>anonymization</i>, when it comes to data as part of statistics or a plan to improve a specific service.</p></div>
<h2>Cybersecurity in the Healthcare sector:</h2>
<p>Healthcare organizations should ensure that they have robust security measures in place to limit the risks of email account compromise <a href="#ref3"><sup>[3]</sup></a>, cyber security threat breaches, and other cyber security threat related incidents. These measures must cover all parameters inherent to <i>people, processes, and technologies</i>:
</p><ul><li><b>Practices and procedures</b> – Strong authentication methods, secure access to applications, systems, and data; Communication with staff and other key stakeholders’ regular updates, as well as reminders of safety behaviors and mandatory actions during safety failure;</li>
<li><b>Supplier Relationships</b> – Cybercriminals can exploit any weak link in a supply chain to gain access to a target. “The existence of strong links between companies within a healthcare ecosystem can compromise an entire ecosystem.” This is why, our latest Healthcare app project, MeTime, features a ‘close-quarters’ environment where vendors, clients and suppliers can safely exchange data while preserving privacy integrity.</li>
<li><b>Log management</b> – Healthcare facilities often use a set of proprietary applications and systems that must be linked together within an IT security framework. LogPoint’s highly flexible cybersecurity software architecture addresses this problem and has become the standard cybersecurity tool for log management in the healthcare industry <a href="#ref4"><sup>[4]</sup></a>. Some of the world’s most advanced hospitals are using our next-generation SIEM solution to protect their patient information.</li>
<li><b>Training</b> – Entry-to-service training, regular reminders, additional training for all staff, and, where appropriate, other stakeholders. Malicious activity isn’t the only activity impacting your organization. Human error - as is the case in any industry - is another risk that deserves attention. Incorrect distribution of information and inappropriate handling of sensitive data puts your organization at high risk for data loss.</li>
<li><b>Ransomware</b> – ransomware is another type of direct cybersecurity threat to the healthcare industry. While this type of attack typically cannot confirm a breach, ransomware has the potential to directly affect the privacy, integrity, and availability of critical systems. It is essential to prepare for the possibility of such an incident and harden your security policies accordingly. The recent spikes in ransomware attacks suggest it is a matter of time when online attackers will cycle toward any possible company. The best move is to expect a blow from that angle and get prepared on that front.</li></ul>
<h2>The potential role of AI for health application security</h2>
<div><p>It is no longer a secret: ensuring the security of information systems is one of the significant challenges in companies. The fight against cybercrime has experienced a small revolution in recent years, thanks to the application of artificial intelligence. Through machine learning, we can discover how threats operate and evolve and use that information for a more precise counter-measure.</p><p>The number one difficulty in cybersecurity is the realization that criminals are always one step ahead of companies: they look for security holes, that someone working for the company is likely to overlook. Also, there is the exponential and ultra-rapid development of <b><a href="https://codecoda.com/en/blog/entry/new-tech-in-ecommerce">new technologies</a></b>, particularly cloud and mobile. Hackers are quick to learn how new tech can be used to their advantage, and cybersecurity experts must keep up, keeping up with their, looking to predict, and dismantle their attempts.</p><p>Most basic security solutions focus on understanding malware and preventing infiltration. Thus, rather than being in action, they will instead react to present and incoming danger. This passive threat-response strategy requires regular updates, among other things, and their use alone proves to be insufficient. A more sophisticated cyber solution finds an ally in Artificial Intelligence (AI). Machines have the intensity and relentlessness needed when battling cyber threats and are preferred tools of veteran cybersecurity experts.</p><p>AI can proactively identify and mitigate a threat even before a patch is developed and released <a href="#ref5"><sup>[5]</sup></a>. Its main advantage is its ability to relieve the human factor of tedious and time-consuming tasks, and this with a better reaction capacity in the treatment of alerts that flood computer systems daily.</p><p>AI then makes it possible to spot, analyze, and respond to cyber-attacks faster than a human. It provides an instrument which, when applied to cybersecurity, improves the efficiency and strengthens the protection of information technologies, for companies constrained by time and resources, financial or human.</p><p>It is on the processing of data between applications that AI can have a considerable impact. Robotics quickly analyzes a large amount of data from which it can spot anomalies or signal potential threats. Machines learn from a growing set of data and, over time, become more and more precise at detecting abnormalities. Today, Machine Learning finally gains the power to support human expertise in decision-making.</p><p>The future of cybersecurity is about embracing and innovating to …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://codecoda.com/en/blog/entry/cybersecurity-and-ai-in-health-applications">https://codecoda.com/en/blog/entry/cybersecurity-and-ai-in-health-applications</a></em></p>]]>
            </description>
            <link>https://codecoda.com/en/blog/entry/cybersecurity-and-ai-in-health-applications</link>
            <guid isPermaLink="false">hacker-news-small-sites-24450431</guid>
            <pubDate>Sat, 12 Sep 2020 06:50:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Glue with an example]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24450351">thread link</a>) | @lijjumathew
<br/>
September 11, 2020 | https://lijjumathew.com/aws-glue-with-an-example/ | <a href="https://web.archive.org/web/*/https://lijjumathew.com/aws-glue-with-an-example/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<article id="5f5c6154ca685c378a7ee720">
<p>September 12, 2020<span></span></p>

<p>AWS Glue is a fully managed serverless ETL service. It is used for ETL purposes and perhaps most importantly used in data lake eco systems. Its high level capabilities can be found in one of &nbsp;my previous post <a href="https://lijjumathew.com/etl-options-in-aws/">here</a>, but in this post I want to detail Glue Catalog, Glue Jobs and an example to illustrate a simple job.</p><h3 id="glue-catalog">Glue Catalog</h3><ul>
<li>Glue catalog is a metadata repository built automatically by crawling the datasets by Glue Crawlers. It contains tables with in a database created by crawlers and these tables can be queried via AWS Athena. Crawlers can crawl S3, RDS, Dynamo DB, Redshift and any on-prem databases that can connect via JDBC. These crawled datasets can further be used as a source or target connection in Glue while developing jobs.</li>
<li>The way crawlers work is, it has built in classifiers and runs these classifiers against the dataset in an orderly fashion. If the classifier cant recognize the data, the crawler invokes the next classifier. We can also build custom classifier and use that. These crawlers can be scheduled to scan at a regular period of time and there is an option to update the schema of the data catalog tables or ignore updates.</li>
<li>Here are some of bad experiences with crawlers that I had which you have to be careful about. One, crawling a dataset in s3 which has millions of small s3 files will take time and can be costly affair. Two, make sure data is organized in partitions and the data set that is crawled has similar files in folder. If that is not the case, say if it has 100 files of different schema, crawler can end up creating 100 tables.</li>
</ul>
<h3 id="glue-jobs">Glue Jobs</h3><ul>
<li>Glue provides two shells, python shell and spark shell to execute a piece of code. Python shell can be used to can execute plain python code and it is a non distributed environment. The Spark Shell is a distributed environment to execute spark code written in either PySpark or Scala.</li>
<li>While using Spark shell, in addition to data frames and other constructs that spark has, Glue has a new construct called dynamic frames which requires no schema unlike data frame. Dynamic frames has few transformation functions and we can always convert dynamic frame to data frame and vice versa to use each other transformation functions.</li>
<li>Glue dev end point provides an environment to author the jobs and test it. It is an EMR cluster with all glue utilities.</li>
<li>Here are some of the important configuration parameters for Glue jobs.
<ul>
<li>Bookmark is a feature to track data that has already processed by the job in previous runs by persisting the state information. For example if we have a Glue that reads from S3 and the data is partitioned, it reads only new partition data if bookmark option is enabled(disabled by default). This feature can be used for relational sources and it keeps track of the new data by keys defined for the table.</li>
<li>DPU(Data Processing Unit) is the term used to denote the processing power allocated to the glue job. A single DPU is 4 vCpu and 16 GB of memory. Spark job requires minimum of 2 DPUs. Worker type tells what type of nodes. There is standard, G1.X(for memory intensive) and G.2X( for ML Transforms).</li>
<li>Delay notification threshold time can be set to notify (cloud watch) jobs running above the threshold time.</li>
<li>Run time parameters can be passed to job as well.</li>
</ul>
</li>
<li>Other Features
<ul>
<li>Metrics - Glue provides spark web ui to monitor and debug the jobs. Job logs can be viewed in cloudwatch.</li>
<li>It also supports streaming ETL where we can set up continuous ingestion pipelines from sources like Kinesis, Kafka and ingest into S3 or other data stores.</li>
<li>It has a feature called workflow to orchestrate the crawlers and jobs with dependencies and triggers.</li>
<li>It also provides an interface to create and work with Sagemaker and Zepplin notebooks.</li>
<li>User defined custom python packages/modules can be used in both the shells by having it zipped and stored in S3.</li>
<li>There is a warm up time involved when you run a Glue job and it use to be around 10 mins. With Glue 2.0 it is brought down to 1 min.</li>
</ul>
</li>
<li>Pricing - You are billed only for the time the ETL job takes to run and no upfront cost for startup or shutdown time. It is charged based on number of DPU's used for the job and it is $0.44 per DPU-hour. Glue version 2.0 have a 1-minute billing duration and older versions have a 10-minute minimum billing duration. Data catalog and crawler runs have additional charges.</li>
</ul>
<h3 id="glue-example">Glue Example</h3><p>Here is an example of Glue PySpark Job which reads from S3, filters data and writes to Dynamo Db. The job can be created from console or done normally using infrastructure as service tools like AWS cloudformation, Terraform etc. The code can be found <a href="https://github.com/lijjumathew/AWS_Examples/blob/master/Glue/s3_to_dynamodb_load.py">here</a>. </p>
</article>
</div></div>]]>
            </description>
            <link>https://lijjumathew.com/aws-glue-with-an-example/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24450351</guid>
            <pubDate>Sat, 12 Sep 2020 06:35:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EduTech Spyware Is Still Spyware: Proctorio Edition]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24450248">thread link</a>) | @some_furry
<br/>
September 11, 2020 | https://soatok.blog/2020/09/12/edutech-spyware-is-still-spyware-proctorio-edition/ | <a href="https://web.archive.org/web/*/https://soatok.blog/2020/09/12/edutech-spyware-is-still-spyware-proctorio-edition/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Spyware written for educational institutions to flex their muscles of control over students and their families when learning from their home computer is still, categorically, spyware.</p>



<p>Depending on your persuasion, the previous sentence sounds like either needless pedantry, or it reads like tautology. But we need to be clear on our terms.</p>



<ol><li>Educational spyware is still spyware.</li><li>Spyware is categorized as a subset of malware.</li></ol>



<p>When vulnerabilities are discovered in malware, the normal rules of <a href="https://adamcaudill.com/2015/11/19/responsible-disclosure-is-wrong/">coordinated disclosure</a> are out of scope. Are we clear?</p>







<p>So let’s talk about Proctorio!</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">For anyone unfamiliar with it, Proctorio is a browser extension used to eliminate cheating through intense surveillance techniques. It records the computer screen while you take the exam to ensure you don’t look anything up. However, it’s more than that. (Thread 1/11)</p>— Cassie (@Angry_Cassie) <a href="https://twitter.com/Angry_Cassie/status/1301360994044850182?ref_src=twsrc%5Etfw">September 3, 2020</a></blockquote></div>
</div><figcaption>The entire thread is unrolled <a href="https://threadreaderapp.com/thread/1301360994044850182.html">here</a>.</figcaption></figure>



<p>I won’t go into the details of Proctorio or why it’s terrible for (especially disadvantaged) students. Read Cassie’s Twitter thread for more context on that. Seriously. I’m not gonna be one of those guys that <em>talks over</em> women, and neither should you.</p>



<p>What I am here to talk about today is these dubious claim about the security of their product:</p>







<h2 id="zero-knowledge">Zero-Knowledge Encryption? OMGWTFBBQ!</h2>



<p>In cryptography, there are a class of algorithms called Zero-Knowledge Proofs. In a Zero-Knowledge Proof, you prove that you possess some fact without revealing any details <em>about</em> the fact.</p>



<p>It’s kind of abstract to think about (and until we’re ready to talk about Pedersen commitments, I’m just going to defer to <a href="https://openprivacy.ca/work/swisspost-scytl-evoting/">Sarah Jamie Lewis</a>), but the only thing you need to know about “Zero Knowledge” in Cryptography is that the output is a boolean (True, False).</p>



<p>You can’t use “Zero Knowledge” <em>anything</em> to encrypt. So “Zero-Knowledge Encryption” is a meaningless buzzword.</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">As a cryptographer, I would like details on how on Earth it is using zero knowledge proofs in this situation. In all likelihood they're not doing what "zero knowledge" usually means, which quite frankly has me more worried about the security, not less.</p>— Buchberger's algorithm fan account (@SchmiegSophie) <a href="https://twitter.com/SchmiegSophie/status/1304407483658592256?ref_src=twsrc%5Etfw">September 11, 2020</a></blockquote></div>
</div></figure>



<p>So what are they actually describing when they say Zero Knowledge Encryption?</p>







<p>Okay, so they’ve built their own key distribution system and are encrypting with AES-GCM… and shipped this in a Chrome extension. But before we get to that, look at this <strong>Daily Vulnerability Tests</strong> claim.</p>



<div><figure><img data-attachment-id="1204" data-permalink="https://soatok.blog/soatoktelegrams2020-04/" data-orig-file="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-04.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SoatokTelegrams2020-04" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-04.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-04.png?w=512" src="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-04.png?w=512" alt="" srcset="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-04.png 512w, https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-04.png?w=150 150w, https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-04.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>Bullshit.</figcaption></figure></div>



<p>Running Nessus (or equivalent) on a cron job isn’t meaningful metric of security. At best, it creates alert fatigue when you accidentally screw up a deployment configuration or forget to update your software for 4+ years. (Y’know, like JsZip 3.2.1, which they bundle.)</p>



<p>A dumb vulnerability scan isn’t the same thing as a routine (usually quarterly) penetration test or a code audit. And if you’re working in cryptography, <em>you better have both</em>!</p>



<h2 id="vulnerability">Timing Leaks in Proctorio’s AES-GCM Implementation</h2>



<p>If you download version 1.4.20241.1.0 of the Proctorio Chrome Extension, run <code>src/assets/J5HG.js</code> through a JS beautifier, and then look at its contents, you will quickly realize this is a JavaScript cryptography library.</p>



<p>Since the “zero knowledge” encryption they’re so proud about uses AES-GCM, let’s focus on that.</p>



<p>Proctorio’s AES-GCM implementation exists in an object called <code>dhs.mode.gcm</code>, which is mildly obfuscated, but contains the following functions:</p>



<ul><li><code>encrypt()</code> – Encrypt with AES-GCM</li><li><code>decrypt()</code> – Decrypt with AES-GCM</li><li><code>aa()</code> – GHASH block multiplication</li><li><code>j()</code> – XOR + GMAC utility function</li><li><code>O()</code> – Called by encrypt() and decrypt(); does all of the AES-CTR + GMAC fun</li></ul>



<p>If you’re not familiar with <a href="https://soatok.blog/2020/05/13/why-aes-gcm-sucks/">AES-GCM</a>, just know this: <a href="https://cryptologie.net/article/361/breaking-https-aes-gcm-or-a-part-of-it/">Timing leaks</a> can be used to leak your GMAC key to outside applications, which completely breaks the authentication of AES-GCM and opens the door to chosen-ciphertext attacks.</p>



<p>So is their implementation of AES-GCM constant-time? Let’s take a look at <code>aa()</code>:</p>


<pre title="">aa: function(a, b) {
  var c, d, e, f, g, h = dhs.bitArray.ba;
  for (e = [0, 0, 0, 0], f = b.slice(0), c = 0; 128 &gt; c; c++) {
    for (
      (d = 0 !== (a[Math.floor(c / 32)] &amp; 1 &lt;&lt; 31 - c % 32)) &amp;&amp; (e = h(e, f)),
        g = 0 !== (1 &amp; f[3]),
        d = 3;
      d &gt; 0;
      d--
    )
      f[d] = f[d] &gt;&gt;&gt; 1 | (1 &amp; f[d - 1]) &lt;&lt; 31;
    f[0] &gt;&gt;&gt;= 1,
    g &amp;&amp; (f[0] ^= -520093696)
  }
  return e
},
</pre>


<p>This is a bit obtuse, but this line leaks the lowest bit of <code>f</code> with each iteration: <code>g = 0 !== (1 &amp; f[3])</code>.</p>



<p>Since <code>f</code> gets bitwise right-shifted 128 times, this actually leaks the bit of every value of <code>f</code> in each block multiplication, since the execution of <code>(f[0] ^= -520093696)</code> depends on whether or not <code>g</code> is set to <code>true</code>.</p>



<div><figure><img data-attachment-id="1387" data-permalink="https://soatok.blog/soatoktelegrams2020-11/" data-orig-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-11.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SoatokTelegrams2020-11" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-11.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-11.png?w=512" src="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-11.png?w=512" alt="" srcset="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-11.png 512w, https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-11.png?w=150 150w, https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-11.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>Timing leaks? So much for “zero-knowledge”!</figcaption></figure></div>



<p>Also, they claim to be FIPS 140-2 compliant, but this is how they generate randomness in their cryptography library.</p>



<figure><div>

</div></figure>



<p>(Although, <a href="https://csrc.nist.gov/projects/cryptographic-module-validation-program/validated-modules/search?SearchMode=Basic&amp;Vendor=Proctorio&amp;CertificateStatus=Active&amp;ValidationYear=0">that’s probably a lie</a>.)</p>



<p>To mitigate these vulnerabilities, one needs look no further than <a href="https://soatok.blog/2020/08/27/soatoks-guide-to-side-channel-attacks/#conditional-select">the guide to side-channel attacks</a> I published last month. </p>



<p>(Also, use WebCrypto to generate entropy! What the fuck.)</p>



<h2>If Proctorio is Insecure, What Should We Use Instead?</h2>



<p><strong>Nothing.</strong></p>



<p>Schools that demand students install spyware on their personal computers are only a step removed from domestic abusers who install stalkerware on their victims’ phones.</p>



<p>Proctorio isn’t the problem here, they’re only a symptom.</p>



<p>Schools that insist on violating the integrity and parental dominion of their students’ home computers are the problem here.</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">Zoom school is really showing how much of American Education is just about controlling and punishing children and not actually, you know, teaching and educating them</p>— Lawrence of A Labia (@lex_about_sex) <a href="https://twitter.com/lex_about_sex/status/1304156305398140928?ref_src=twsrc%5Etfw">September 10, 2020</a></blockquote></div>
</div><figcaption>Preach!</figcaption></figure>



<p>If you want to ensure the integrity of students’ education, try teaching them about consent and ethical computing. (Y’know, concepts that are fundamentally incompatible with the business model of Proctorio and Proctorio’s competitors.)</p>



<h2 id="timeline">Disclosure Timeline</h2>



<p>Really? <em>Really?</em></p>



<p>This was a zero-day disclosure, because full disclosure is the responsible choice when dealing with spyware. Don’t even @ me.</p>



<div><figure><img data-attachment-id="70" data-permalink="https://soatok.blog/soatok_stickerpack-hacker/" data-orig-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-hacker.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="soatok_stickerpack-hacker" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-hacker.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-hacker.png?w=512" src="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-hacker.png?w=512" alt="" srcset="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-hacker.png 512w, https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-hacker.png?w=150 150w, https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-hacker.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>Disclaimer: This security research was conducted by Soatok– some furry on the Internet–while bored on his off-time and does not reflect the opinions of any company.</figcaption></figure></div>



<h2 id="sinkhole">Domains to Sinkhole</h2>



<p>If you’re looking to protect your home network from this spyware, here are a list of domains to sinkhole (i.e. with <a href="https://pi-hole.net/">Pi-Hole</a>).</p>



<ul><li>proctorauth.com</li><li>proctordata.com</li><li>getproctorio.com</li><li>proctor.io</li><li>proctor.in</li><li>az545770.vo.msecnd.net</li></ul>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://soatok.blog/2020/09/12/edutech-spyware-is-still-spyware-proctorio-edition/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24450248</guid>
            <pubDate>Sat, 12 Sep 2020 06:09:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: WebGL Rubik's Snake]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24450171">thread link</a>) | @nopjia
<br/>
September 11, 2020 | https://www.iamnop.com/snake/ | <a href="https://web.archive.org/web/*/https://www.iamnop.com/snake/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.iamnop.com/snake/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24450171</guid>
            <pubDate>Sat, 12 Sep 2020 05:49:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Make a Harmonograph?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24449813">thread link</a>) | @alikayaspor
<br/>
September 11, 2020 | https://abakcus.com/diy/how-to-make-a-harmonograph/ | <a href="https://web.archive.org/web/*/https://abakcus.com/diy/how-to-make-a-harmonograph/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<div>
<div id="primary">
<main id="main">
<div data-elementor-type="single" data-elementor-id="951" data-elementor-settings="[]">
<div>
<section data-id="af02520" data-element_type="section">
<div>
<div>
<div data-id="2bf189ef" data-element_type="column">
<div>
<div>
<section data-id="8f0e9bd" data-element_type="section">
<div>
<div>
<div data-id="815ec86" data-element_type="column">
<div>
<div>
<div data-id="67b5cbf" data-element_type="widget" data-widget_type="theme-post-featured-image.default">
<div>
<div>
<picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project-768x1152.jpg.webp 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project-500x750.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project-683x1024.jpg.webp 683w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project-300x450.jpg.webp 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project.jpg.webp 800w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%201152'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 768px) 100vw, 768px">
<img width="768" height="1152" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%201152'%3E%3C/svg%3E" alt="How to make a harmonograph DIY Project" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project-768x1152.jpg 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project-500x750.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project-683x1024.jpg 683w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project-300x450.jpg 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project.jpg 800w" data-lazy-sizes="(max-width: 768px) 100vw, 768px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project-768x1152.jpg">
</picture>
 </div>
 </div>
</div>


<div data-id="410565ac" data-element_type="widget" data-widget_type="theme-post-content.default">
<div>
<p>This project belongs to a <a href="https://en.m.wikipedia.org/wiki/Computer_graphics">computer graphics</a> artist and researcher, Karl Sims, who is best known for using <a href="https://en.m.wikipedia.org/wiki/Particle_systems">particle systems</a> and <a href="https://en.m.wikipedia.org/wiki/Artificial_life">artificial life</a> in computer animation.</p>
<p>A harmonograph is a mechanical device that uses swinging pendulums to draw pictures, believed to be initially invented in 1844 by Scottish mathematician&nbsp;<a target="_blank" href="https://en.wikipedia.org/wiki/Hugh_Blackburn" rel="noreferrer noopener">Hugh Blackburn.</a>&nbsp;This 3-pendulum rotary type of harmonograph gives a wide variety of satisfying results. It is reasonably easy to build once you’ve settled on a design and have acquired the appropriate materials and tools. Harmonograph is a great project to do with kids and can result in endless experiments creating new geometric designs.</p>
<p><strong>Ingredients:</strong></p>
<ul><li><strong>Lumber</strong><ul><li>1 &nbsp; 3/4″ x 3’x3′ plywood for table top</li><li>4 &nbsp; 1½” x 1½” x 40″ for legs (about 14′ total)</li><li>4 &nbsp; 1½” x 8″ x 12″ for leg braces (about 4′ total)</li><li>4 &nbsp; 3/4″ x 4′ dowels for pendulums and pen lifter (make sure they are straight)</li><li>1 &nbsp; 3/4″ x 1½” x 30″ oak to cut for pendulum supports, and other</li><li>1 &nbsp; 11″ x 11″ x 1/8″ board for platform to hold paper</li></ul></li><li><strong>Hardware Store</strong><ul><li>3 &nbsp; 3/4″ x 5″ long metal pipe nipples (plumbing section)</li><li>3 &nbsp; 3/4″ to 1″ metal pipe bushings</li><li>3 &nbsp; 1″ steel clamps</li><li>4 &nbsp; 1¼” x 4″ metal plates (or 2&nbsp; 1¼” x 8″ plates cut in half)</li><li>1 &nbsp; large metal washer with 2½” outer diameter, 1″ inner diameter, for gimbal</li><li>1 &nbsp; screw-eye for pen lifter</li><li>various drill bits: 3″ circular, 3/4″, 1/8″, etc.</li><li>various #10 screws (1″, 1¼”, 1½”, 1¾”, 2″, 3″)</li><li>a few thin nails</li><li>tools: drill, saw, hammer, tape measure, file, sand paper, etc.</li></ul></li><li><strong>Sporting goods store:</strong><ul><li>2½ lb weights with 1″ hole, at least 8 of them</li></ul></li><li><strong>Art supplies store</strong>:<ul><li>2 &nbsp; 1/2″ x 1/4″ x 30″ balsa (and maybe a spare or two)</li><li>various pens such as: Silver Uni-Ball GEL Impact, and Staedtler Triplus Rollerball</li><li>some string and rubber bands</li><li>paper, 8½” x 11″ (or 9″ x 12″) some black, some white</li></ul></li></ul>
<h2>STEP 1</h2>
<p><strong>Table.</strong> Start by building a sturdy table. This table-top is a 3’x3′ square of 3/4″ thick plywood. The legs are 1½” x 1½” square and about 37″ long, with triangular braces cut from 1½” x 8″x 12″ wooden pieces. The legs are splayed out slightly to give the table strength and allow the rotary pendulum to swing without hitting a leg.</p>
<div><p><strong>Tip:</strong> screw and/or glue the braces to the legs first, and then cut their tops together at a slight angle with a table or circular saw. Adjust the leg lengths to give a table-top height of about 37″.</p><p><strong>Note:</strong> if you want to fit the table through doorways without taking off the legs, you might need slightly shorter legs and pendulums.</p></div>
<h2>STEP 2</h2>
<figure><picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph.jpg.webp 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-500x375.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-300x225.jpg.webp 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-768x576.jpg.webp 768w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px">
<img width="1024" height="768" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" alt="" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph.jpg 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-500x375.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-300x225.jpg 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-768x576.jpg 768w" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph.jpg">
</picture>
<figcaption><strong>Holes for Pendulums</strong>. Drill 3 holes of 3″ diameter through the table surface for the pendulums to hang through. The rotary pendulum’s hole should be centered in a corner about 8″ from each side just clear of the leg brace underneath. The other two holes should be aligned near the opposite edges, about 8″ from the common side, and 3″ from the other. You’ll need a particular sizeable circular drill bit for this. Alternatively, you can first drill a smaller hole, and then cut a wider opening with a jigsaw.</figcaption></figure>
<h2>Step 3</h2>
<figure><picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-3.jpg.webp 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-3-500x375.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-3-300x225.jpg.webp 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-3-768x576.jpg.webp 768w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px">
<img width="1024" height="768" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" alt="" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-3.jpg 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-3-500x375.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-3-300x225.jpg 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-3-768x576.jpg 768w" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-3.jpg">
</picture>
<figcaption><strong>Plates to support pendulums</strong>. Mount two metal plates (about 1¼” x 4″) on the sides of the two lateral pendulum holes and drill a small indentation in each plate’s center. <p><strong>Tip:</strong> first, start the indentation in the metal plate with a small drill bit (such as 1/8″) and then continue with a larger bit (such as 1/4″). Be careful not to drill all the way through. Tip: unless you have a good drill press, it may be easier to position the indentations of the plates on the table after you create the fulcrum blocks with protruding screws below, because it can be harder to accurately position the screws in the blocks later to align with the indentations.</p></figcaption></figure>
<h2>Step 4</h2>
<figure><picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-2.jpg.webp 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-2-500x375.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-2-300x225.jpg.webp 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-2-768x576.jpg.webp 768w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20887%20665'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 887px) 100vw, 887px">
<img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20887%20665'%3E%3C/svg%3E" alt="" width="887" height="665" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-2.jpg 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-2-500x375.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-2-300x225.jpg 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-2-768x576.jpg 768w" data-lazy-sizes="(max-width: 887px) 100vw, 887px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-2.jpg">
</picture>
<figcaption><strong>Pendulums.</strong> The rotary pendulum needs a gimbal mechanism that allows it to swing in any direction. This is made from a large metal washer with 2½” outer and 1″ inner diameter. The washer rests on screw tips protruding from under the table, and then the pendulum rests on the washer. Drill pairs of indentations into the washer on each side, off 90 degrees between the sides, to allow rocking on two perpendicular axes.<p>Here are views of the rotary pendulum gimbal from above and below the table. In the picture from below, note the oak blocks (3/4″ x 1½” x 5″) supporting the two screws (1¾” #10) protruding upwards and diagonally. File down the bottom edges of these blocks as needed, so the pendulum doesn’t hit them when it swings. Likewise, file down the corners of the fulcrum block if necessary so it doesn’t hit the table when swinging.</p></figcaption></figure>
<h2>Step 5</h2>
<figure><ul><li><figure><picture data-id="11158" data-full-url="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2.jpg" data-link="https://abakcus.com/diy/how-to-make-a-harmonograph/how-to-make-a-harmonograph-gimbal-2/" src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2.jpg">
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2.jpg.webp 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2-500x375.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2-300x225.jpg.webp 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2-768x576.jpg.webp 768w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px">
<img width="1024" height="768" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" alt="" data-id="11158" data-full-url="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2.jpg" data-link="https://abakcus.com/diy/how-to-make-a-harmonograph/how-to-make-a-harmonograph-gimbal-2/" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2.jpg 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2-500x375.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2-300x225.jpg 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2-768x576.jpg 768w" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2.jpg">
</picture>
</figure></li><li><figure><picture data-id="11159" data-full-url="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal.jpg" data-link="https://abakcus.com/diy/how-to-make-a-harmonograph/how-to-make-a-harmonograph-gimbal/" src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal.jpg">
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal.jpg.webp 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-500x375.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-300x225.jpg.webp 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-768x576.jpg.webp 768w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px">
<img width="1024" height="768" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" alt="" data-id="11159" data-full-url="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal.jpg" data-link="https://abakcus.com/diy/how-to-make-a-harmonograph/how-to-make-a-harmonograph-gimbal/" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal.jpg 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-500x375.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-300x225.jpg 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-768x576.jpg 768w" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal.jpg">
</picture>
</figure></li></ul><figcaption><strong>Gimbal.</strong> The rotary pendulum needs a gimbal mechanism that allows it to swing in any direction. This is made from a large metal washer with 2½” outer and 1″ inner diameter. The washer rests on screw tips protruding from under the table, and then the pendulum rests on the washer. Drill pairs of indentations into the washer on each side, off 90 degrees between the sides, to allow rocking on two perpendicular axes. <p>Here are views of the rotary pendulum gimbal from above and below the table. In the view from below, note the oak blocks (3/4″ x 1½” x 5″) supporting the two screws (1¾” #10) protruding upwards and diagonally. File down the bottom edges of these blocks as needed so the pendulum doesn’t hit them when it swings. Likewise file down the corners of the fulcrum block if necessary so it doesn’t hit the table when swinging.</p></figcaption></figure>
<h2>Step 6</h2>
<figure><picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Weight.jpg.webp 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Weight-500x667.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Weight-300x400.jpg.webp 300w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%201024'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 768px) 100vw, 768px">
<img width="768" height="1024" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%201024'%3E%3C/svg%3E" alt="" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Weight.jpg 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Weight-500x667.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Weight-300x400.jpg 300w" data-lazy-sizes="(max-width: 768px) 100vw, 768px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Weight.jpg">
</picture>
<figcaption><strong>Weights.</strong> 2½ lb lifting weights from a sporting goods store work well, but typically have a 1″ interior hole. You can stack several weights and slide them together onto the 3/4″ pendulum dowel by using a 5″ long 3/4″ metal pipe nipple, with a 3/4″ to 1″ bushing screwed onto the lower end. A 1″ steel clamp attached to the dowel fixes the weights from sliding off and allows easy adjustment of the weight’s height to give different swinging frequencies.</figcaption></figure>
<h2>Step 7</h2>
<figure><picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Paper-Board.jpg.webp 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Paper-Board-500x667.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Paper-Board-300x400.jpg.webp 300w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%201024'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 768px) 100vw, 768px">
<img width="768" height="1024" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%201024'%3E%3C/svg%3E" alt="" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Paper-Board.jpg 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Paper-Board-500x667.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Paper-Board-300x400.jpg 300w" data-lazy-sizes="(max-width: 768px) 100vw, 768px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Paper-Board.jpg">
</picture>
<figcaption><strong>Paper Platform. </strong>Cut about 1″ off the top of the rotary pendulum dowel, so it is slightly lower than the other two. Then mount an 11″x11″ square of thin 1/8″ board to the top of this pendulum, using a small oak block glued to it for support, with a 3/4″ hole for the dowel. Wrap some tape around the dowel’s top to get a tight fit, or glue it on.<p>*** Use two rubber bands, or some clips, to hold the paper in place on the platform. If the form slips on the platform, spray a thin layer of temporary adhesive on the platform to make it slightly sticky.</p></figcaption></figure>
<h2>Step 8</h2>
<figure><picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Arms-768x1024.jpg.webp 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Arms-500x667.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Arms-300x400.jpg.webp 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Arms-scaled.jpg.webp 1536w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%201024'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 768px) 100vw, 768px">
<img width="768" height="1024" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%201024'%3E%3C/svg%3E" alt="" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Arms-768x1024.jpg 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Arms-500x667.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Arms-300x400.jpg 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Arms-1152x1536.jpg 1152w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Arms-scaled.jpg 1536w" data-lazy-sizes="(max-width: 768px) 100vw, 768px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Arms-768x1024.jpg">
</picture>
<figcaption><strong>Arms.</strong> Connect a 30″ long balsa stick to the top of each lateral pendulum using a thin nail. Bend the nail back and forth a little in the balsa to allow the arm to rotate smoothly and move up and down slightly. The nail hole will slowly loosen further during use.<p>To make a simple pen-holder, drill a 1/2″ hole on the end of one arm, and cut about 4″ down the arm’s center to make a clothes-pin like a device. Alternatively, glue a real clothes-pin to the end of one of the arms. Pictures of both versions are shown.</p><p>Finally, attach the two arms with a doubled-over rubber band, as shown.</p><p>Note that if you plan to use your harmonograph regularly, such as in a museum setting, a more robust solution for these arms that won’t wear as quickly might be necessary.&nbsp;</p><p><strong>Note:</strong>&nbsp;An alternate version of the arm-pendulum connection is shown to the right that uses a magnetic ball joint instead of the simple nail method above. Glue one 3/8″ spherical magnet to the arm (making sure the N/S alignment is horizontal by connecting a second magnet). File a hole in the side of a nylon cylinder (1″ height, 1/2″ outer and 3/8″ inner diameter) and use smaller cylinders (3/8″ outer diameter) to hold another magnet inside that can rotate freely. Then glue the cylinder to the top of the pendulum.</p></figcaption></figure>
<h2>Step 9</h2>
<figure><ul><li><figure><picture data-id="11163" data-full-url="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2.jpg" data-link="https://abakcus.com/diy/how-to-make-a-harmonograph/how-to-make-a-harmonograph-pen-lifter-2/" src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2.jpg">
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2-1024x768.jpg.webp 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2-500x375.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2-300x225.jpg.webp 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2-768x576.jpg.webp 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2.jpg.webp 1600w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px">
<img width="1024" height="768" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" alt="" data-id="11163" data-full-url="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2.jpg" data-link="https://abakcus.com/diy/how-to-make-a-harmonograph/how-to-make-a-harmonograph-pen-lifter-2/" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2-1024x768.jpg 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2-500x375.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2-300x225.jpg 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2-768x576.jpg 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2-1536x1152.jpg 1536w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2.jpg 1600w" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2-1024x768.jpg">
</picture>
</figure></li><li><figure><picture data-id="11164" data-full-url="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-scaled.jpg" data-link="https://abakcus.com/diy/how-to-make-a-harmonograph/how-to-make-a-harmonograph-pen-lifter/" src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-scaled.jpg">
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-768x1024.jpg.webp 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-500x667.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-300x400.jpg.webp 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-scaled.jpg.webp 1536w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%201024'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 768px) 100vw, 768px">
<img width="768" height="1024" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%201024'%3E%3C/svg%3E" alt="" data-id="11164" data-full-url="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-scaled.jpg" data-link="https://abakcus.com/diy/how-to-make-a-harmonograph/how-to-make-a-harmonograph-pen-lifter/" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-768x1024.jpg 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-500x667.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-300x400.jpg 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-1152x1536.jpg 1152w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-scaled.jpg 1536w" data-lazy-sizes="(max-width: 768px) 100vw, 768px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-768x1024.jpg">
</picture>
</figure></li></ul><figcaption><strong>Pen Lifter.</strong> It is convenient to raise and lower the pen gently without disturbing the motion of the pendulums. To do this, insert a 30″ pole into a hole near the center of the table, just far enough from the paper platform that it won’t be hit by it (about 12″ from the rotary pendulum hole). Attach an oak block under the table for a deeper hole and better support. Tie a string to the balsa arms where they are connected, lead it through a screw-eye on top of the pole, and back down to a small jam cleat or groove where it can hold the pen in place above the paper until you are ready to lower it.</figcaption></figure>
<h2>Step 10</h2>
<p><strong>Pens.</strong> Experiment with pens and markers of various types and colors. Generally, wide pens or thin markers seem to work best. Here are some I’ve had good luck with so far:</p>
<ul><li>Uniball GEL Impact in Silver, use on black or dark paper.</li><li>Staedtler Triplus Rollerball Pens (.4mm) in various colors</li><li>Pigma Graphic 1 (1.0mm) in black</li><li>Sakura Identi Pen in black, purple, etc.</li></ul>
<p>but many other types of pens may also work well.</p>
<h2>Adjustments</h2>
<p><strong>Weight Height</strong>. Adjust a pendulum’s weight height to change its swinging frequency. The frequency of a pendulum varies with the inverse of the square root of its length, so to swing twice as fast, the length between the fulcrum and its center-of-mass would need to be 1/4 of the original length (which may not be practical with this harmonograph). For a 3:2 or 4:3 frequency increase, the weights would be raised around 19″ or 15″ respectively, although you should probably do some timing tests to find and mark these heights experimentally.</p>
<p><strong>Weight Amount</strong>. Add more weight to a pendulum to counteract friction and make the swinging last longer. I’ve found that 5 lb (2 x 2½) on the rotary pendulum, and 7½ lb (3 x 2½) on the other two works reasonably well. Note that adding more weight does not generally change the frequency of the pendulum.</p>
<p><strong>Phase and Amplitude</strong>. Each time you swing the pendulums to make a new drawing, each pendulum’s relative phases, and amplitudes will vary. Try somewhere the rotary pendulum, and the lateral pendulums are initially making circles in the same or opposite directions. Try somewhere the lateral pendulums are initially swinging in phase to make a diagonal line.</p>
<h2>Results</h2>
<p><strong>Two-pendulum results</strong>. To simplify things, you can lock …</p></div></div></div></div></div></div></div></section></div></div></div></div></div></section></div></div></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://abakcus.com/diy/how-to-make-a-harmonograph/">https://abakcus.com/diy/how-to-make-a-harmonograph/</a></em></p>]]>
            </description>
            <link>https://abakcus.com/diy/how-to-make-a-harmonograph/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24449813</guid>
            <pubDate>Sat, 12 Sep 2020 04:18:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Weaponize the WayBackMachine]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24449603">thread link</a>) | @puggo
<br/>
September 11, 2020 | https://hawaiigentech.com/post/resources/weaponize-waybackmachine/ | <a href="https://web.archive.org/web/*/https://hawaiigentech.com/post/resources/weaponize-waybackmachine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><img src="https://hawaiigentech.com/post/resources/weaponize-waybackmachine/whats-said-is-said.jpg" alt="What’s said is said…"></p>
<p><em>meme is reference to the <a href="https://en.wikipedia.org/wiki/Labyrinth_(1986_film)">Labyrinth Movie, 1986</a></em></p>
<hr>
<h2 id="in-the-misinformation-age-the-waybackmachine-might-just-be-one-of-our-strongest-weapons-available-to-curtail-deception">In the <strong>Mis</strong>information Age, the WayBackMachine might just be one of our strongest weapons available to curtail deception.</h2>
<p>Most people might not understand it’s power, and some might not know how to use it. A strong knowledge of <a href="https://archive.org/">WBM</a> is probably more important now than it ever was.</p>
<p><em>[<a href="https://addons.mozilla.org/en-US/firefox/addon/wayback-machine_new/">get the browser addon</a>]</em></p>
<hr>
<p>You know what’s better than a time machine? A <em>weaponized time machine…</em></p>
<h2 id="why-waybackmachine-is-powerful">Why WayBackMachine is Powerful</h2>
<p>The WayBackMachine basically gives you the ability to travel back in time on the internet.</p>
<p>It also allows you to freeze a moment of time on the internet.</p>
<p>Like any genuine time machine, it can be challenging to use.</p>
<ul>
<li>It can be slow at times.</li>
<li>It can be slow at times.</li>
<li>Recalled moments in time can be missing elements such as pictures or video.</li>
<li>It might not be obvious how to control the time circuits (advanced features should be learned to properly filter search results).</li>
</ul>
<p>Despite some of these faults, textual context is hardly ever lacking.</p>
<h2 id="first-you-turn-the-time-circuits-on">First, you turn the time circuits on…</h2>
<p><img src="https://hawaiigentech.com/post/resources/weaponize-waybackmachine/time-circuits.jpg" alt="Time Circuits">
<em>meme is reference to the <a href="https://en.wikipedia.org/wiki/Back_to_the_Future">Back to the Future Movie, 1985</a>)</em></p>
<p>This isn’t google. It’s a temperamental and very powerful piece of equipment. It does it’s job extra well at the expense of user friendliness and convenience.</p>
<p>Let us bypass the front <a href="https://archive.org/">search page</a> and go straight to the <a href="https://archive.org/advancedsearch.php">advanced page</a> <a href="https://archive.org/advancedsearch.php">https://archive.org/advancedsearch.php</a>.</p>
<p><img src="https://hawaiigentech.com/post/resources/weaponize-waybackmachine/wbm-advanced.jpg" alt="WayBackMachine advanced…"></p>
<p>This is what makes time travel possible.</p>
<p>The <a href="https://archive.org/">WBM</a> does not apologize. It doesn’t sensor what you find. If you take the time machine to a place where something bad happened, you must be prepared to see what happened.</p>
<p>In an experiment to see how far back in time I could travel in Hawaii news, I saw an elephant go rogue and stampede people (1994). I’ve seen many high-casualty-action-movies, but this sad to witness because I knew it was real.</p>
<hr>
<h2 id="using-waybackmachine-defensively">Using WayBackMachine Defensively…</h2>

<p>As soon as you author a page, <a href="https://archive.org/web/">go here and save it</a> <a href="https://archive.org/web/">https://archive.org/web/</a>.</p>
<p><img src="https://hawaiigentech.com/post/resources/weaponize-waybackmachine/save-here.jpg" alt="Use this button here…"></p>
<p>This will ensure that your original content is recognized as it’s first-entry on the internet. This will come in handy for many purposes, now, and in the future since authorship is recognized, in part, on internet timelines.</p>
<h3 id="as-a-general-user">as a general user…</h3>
<p>Quite often content is posted and then removed or edited when things heat up. If you recognize a topic is controversial or important, you may wish to quickly archive it <a href="https://archive.org/web/">https://archive.org/web/</a>. That way when the content is changed or removed, the original context will not be lost, and the upper hand will be given when a <a href="https://archive.org/account/login.createaccount.php">WBM Soldier</a> posts the original content back into the isolated or national conversation.</p>
<p>This tactic is useful in both trivial and weighty matters and should be remembered in chronological combat.</p>
<hr>
<h2 id="using-waybackmachine-offensively">Using WayBackMachine Offensively…</h2>
<h3 id="as-an-investigator">as an investigator…</h3>
<p>There are many important events that were either preceded by – or the result of – things happening on the internet.</p>
<p>Knowing this, as well as the web-presence of the people involved in such events, with a little skilled WBM use you can bring to the surface that which had previously sunk into the depths of internet history.</p>
<p>You don’t have to be a professional investigator to get to the bottom of what happened, whether the events be minor or catastrophic. You just have to know how to search the internet.</p>
<h3 id="as-a-truth-promoter">as a truth-promoter…</h3>
<p>In the pre-internet days, history was written by the winners.</p>
<p>These days, however, history is recorded in real time. Its hard to rewrite events under the passive and accidental surveillance system that the internet is.</p>
<p>Events that happened in recent decades will often have an internet counterpart that can be studied.</p>
<p>With some clever WBM piloting, you can use the power of truth to dethrone that which had previously prospered in a lie.</p>
<p>So for those who are involved in current issues that were effected by the recent past, WBM cannot be overlooked.</p>
<hr>
<h2 id="browser-addon">Browser addon:</h2>
<p><a href="https://addons.mozilla.org/en-US/firefox/addon/wayback-machine_new/">https://addons.mozilla.org/en-US/firefox/addon/wayback-machine_new/</a></p>
<h2 id="or-browser-hotbar-links">Or Browser Hotbar Links:</h2>
<p>Save a page:
<a href="https://archive.org/web/">https://archive.org/web/</a></p>
<p>Search archives:
<a href="https://archive.org/">https://archive.org/</a></p>
<p>Search archives advanced:
<a href="https://archive.org/advancedsearch.php">https://archive.org/advancedsearch.php</a></p>
<p>…don’t forget to make an account…
<a href="https://archive.org/account/login.createaccount.php">https://archive.org/account/login.createaccount.php</a></p>
<h2 id="more-info">More Info</h2>
<p><a href="https://en.wikipedia.org/wiki/Internet_Archive">While WayBackMachine was founded in 1996, it’s records relate to things that go much further back in time.</a></p>
<hr>

    </div></div>]]>
            </description>
            <link>https://hawaiigentech.com/post/resources/weaponize-waybackmachine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24449603</guid>
            <pubDate>Sat, 12 Sep 2020 03:35:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is benchmarketing and why is it bad?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24449144">thread link</a>) | @bitsondatadev
<br/>
September 11, 2020 | https://bitsondata.dev/what-is-benchmarketing-and-why-is-it-bad/ | <a href="https://web.archive.org/web/*/https://bitsondata.dev/what-is-benchmarketing-and-why-is-it-bad/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>There's something I have to get off my chest. If you really need to, just read the TLDR and listen to the Justin Bieber parody posted below. If you’re confused by the lingo, the rest of the post will fill in any gaps.</p><div><p>TL;DR: Benchmarketing, the practice of using benchmarks for marketing, is bad. Consumers should run their own benchmarks and ideally open-source them instead of relying on an internal and biased report.</p><p>Enjoy the song I wrote about this silly practice.</p></div><figure><iframe width="459" height="344" src="https://www.youtube.com/embed/FSy8V-R0_Zw?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>For the longest time, I have wondered what is the point of corporations, specifically in the database sectors, running their own benchmarks. Would a company ever have any incentive to post results from a benchmark that didn't show its own system winning in at least the majority of cases? I understand that these benchmarks have become part of the furniture we come to expect to see when visiting any hot new database's website. I doubt anybody in the public domain gains much insight out of these results, to begin with, at least nothing they weren't expecting to see. </p><p>Now to be clear, I am in no way indicating that companies running their own internal benchmarks to analyze their own performance in comparison to their competitors is a bad thing. It’s when they take those results and intentionally skew the methods or data from these benchmarks for sales or marketing purposes that is the problem we’re discussing here. Vendors that take part in the practice, not only use these benchmarks to show their systems succeeding a little but rather perversely taint their methodology with settings, caching, and other performance enhancements, while leaving their competition’s settings untouched. </p><p>This should be obvious that this is NOT what benchmarking is about! If you read about the history of the <a href="http://www.tpc.org/information/about/history5.asp">Transaction Processing Performance Council (TPC)</a> you come to understand that this is the very wrongdoing that the council was created to address. But like with any proxy involving measurements, the measurements are inherently pliable.</p><blockquote>By the spring of 1991, the TPC was clearly a success. Dozens of companies were running multiple TPC-A and TPC-B results. Not surprisingly, these companies wanted to capitalize on the TPC's cachet and leverage the investment they had made in TPC benchmarking. Several companies launched aggressive advertising and public relations campaigns based around their TPC results. In many ways, this was exactly why the TPC was created: to provide objective measures of performance. What was wrong, therefore, with companies wanting to brag about their good results? What was wrong is that there was often a large gap between the objective benchmark results and their benchmark marketing claims--this gap, over the years, has been dubbed "benchmarketing." So the TPC was faced with an ironic situation. It had poured an enormous amount of time and energy into creating a good benchmark and even a good benchmark review process. However, the TPC had no means to control how those results were used once they were approved. The resulting problems generated intense debates within the TPC.</blockquote><p>This benchmarketing ultimately fails the clients that these companies are marketing to. It demonstrates not only a lack of care for addressing the users' actual pain but a lack of respect by intentionally pulling the wool over their eyes simply in an attempt to mask that their performance isn't up to par with their competitors. <strong>This leads to consumers not being able to make informed decisions as most of our decisions are made from gut instincts and human emotion which these benchmarks aim to manipulate.</strong></p><p>If you’re not sure exactly how a company would pull this off, an example of might be that database A enables using a cost-based optimizer that requires precomputing statistics about different tables involved in the computation, while database B is running a query against this table without any type of stats based optimization made available to it. Database A will clearly dominate as now it can reorder joins and apply better execution plans while database B is going to go with the simplest plan and run much slower in most scenarios. The company whose product depends on database A will then hone in on the numerical outcomes of this report. Even if they're decent enough to report the methods they skewed to get these results, they bury it within their report and focus on advertising the outcome of what would otherwise be considered an absurd comparison. Companies will even go as far as to say that their competition's database wasn't straight forward to configure when they were setting up optimizations. If you're not capable of understanding how to make equivalent changes to both systems, well then I guess you don't get to run that comparison until you figure it out. &nbsp;</p><p>Many think that consumers are not susceptible to such attacks and would be able to see right through this scheme, but these reports appeal to any of us when we don't have the necessity or resources to thoroughly examine all the data. Many times we have to take cues from our gut when a decision needs to be made and the time to make it is constrained by our time and other business needs. We see this type of phenomenon described in the book, <em>Thinking Fast and Slow</em> by Daniel Kahneman. To briefly summarize the model they use, there are two modes that humans use when they reason about their decisions, System 1 and System 2.</p><blockquote>Systems 1 and 2 are both active whenever we are awake. System 1 runs automatically and System 2 is normally in comfortable low-effort mode, in which only a fraction of its capacity is engaged. System 1 continuously generates suggestions for System 2: impressions, intuitions, intentions, and feelings. If endorsed by System 2, impressions and intuitions turn into beliefs, and impulses turn into voluntary actions. When all goes smoothly, which is most of the time, System 2 adopts the suggestions of System 1 with little or no modification. You generally believe your impressions and act on your desires, and that is fine — usually.</blockquote><p>No surprise, that’s usually the part where we get into trouble. While we like to think that we are generally thinking in the logical System 2 mode, we don't have time or energy to live in this space for long periods throughout the day and we find ourselves very reliant on System 1 for much of our decision making.</p><blockquote>The measure of success for System 1 is the coherence of the story it manages to create. The amount and quality of the data on which the story is based are largely irrelevant. When information is scarce, which is a common occurrence, System 1 operates as a machine for jumping to conclusions.</blockquote><p>This is why benchmarketing can be so dangerous because it is so effective at manipulating our belief in claims that simply aren't true. These decisions affect how your architecture will unfold, your time-to-value, and lost hours for your team and customers. It makes having these systems that fairly compare the performance and merits of two systems all-the-more paramount.</p><figure><img src="http://bitsondata.dev/content/images/2020/09/significant.png" alt=""><figcaption><a href="https://xkcd.com/882/">https://xkcd.com/882/</a></figcaption></figure><p>So why am I talking about this now?</p><p>I have become a pretty big fanboy of a <a href="https://prestosql.io/">Presto</a>, a distributed query engine that runs interactive queries from many sources. I have witnessed firsthand how fast a cluster of Presto nodes are able to process through a huge amount of data at blindingly fast speeds. When you dive into how these speeds are achieved you find that this project is an incredible modern feat of solid engineering that makes interactive analysis over petabytes of data a reality. Going into all the reasons I like this project would be too tangential but it fuels the fire for why I believe this message needs to be heard.</p><p>Recently there was a "benchmark" that came out comparing the performance of a commercial competitor and Presto open-source and enterprise versions, touting performance improvements over Presto by an amount that would have been called out as too high in a CSI episode <a href="https://www.youtube.com/watch?v=hkDD03yeLnU">&lt;insert canonical csi clip here&gt;</a>. If you need to find out what I’m talking about, simply google "presto benchmark 3000" and you will find the benchmark along with plenty of other hype they've generated around these "findings". <a href="https://blog.yugabyte.com/yugabytedb-vs-cockroachdb-bringing-truth-to-performance-benchmark-claims-part-1/">Presto isn't the only system in the data space to come under similar types of attacks.</a> It makes sense too, as this type of technical peacocking is common as it successfully gains attention. </p><p>Luckily, as more companies strive to become transparent and associate themselves with open-source efforts, we are starting to see a relatively new pattern of open-source efforts emerge. Typically, you're used to hearing about open-source within the context of software projects maintained by open-source communities. We are now arriving at the age of any noun being able to be used in an open-source framework. There is open-source music, open-source education, and even open-source data. So why not reach a point where open-source benchmarking through consumer collaboration is a thing. This is not just for the sake of the consumers of these technologies who simply want to have more data to inform their design choices to better serve their clients, it's also unfortunate that this affects developer communities that are putting in a lot of hard work on these projects, only to have that hard work get berated unintelligibly by the likes of some corporate status competition.</p><p>Now I'm clearly a little biased when I tell you that I think Presto is currently the best analytics engine on the market today. When I say this, you really should be skeptical too. Really, I encourage it. You should verify in some way beyond a shadow of a doubt that:</p><p> &nbsp;1. Any TPC or other benchmarks are validated and no "magic" was used to improve their performance.</p><figure></figure><p> &nbsp;2. using your own use cases to make sure the system you choose is going to meet the needs of your particular use case.<br></p><p>While this may seem like a lot of work, with cloud infrastructure and simplicity of deploying different …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bitsondata.dev/what-is-benchmarketing-and-why-is-it-bad/">https://bitsondata.dev/what-is-benchmarketing-and-why-is-it-bad/</a></em></p>]]>
            </description>
            <link>https://bitsondata.dev/what-is-benchmarketing-and-why-is-it-bad/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24449144</guid>
            <pubDate>Sat, 12 Sep 2020 01:42:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I used GCP to create the transcripts for my Podcast]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24448922">thread link</a>) | @simonebrunozzi
<br/>
September 11, 2020 | https://alediaferia.com/2020/05/14/how-used-gcp-transcripts-podcast/ | <a href="https://web.archive.org/web/*/https://alediaferia.com/2020/05/14/how-used-gcp-transcripts-podcast/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-577">
		<div>
		<p><span><span>Reading Time: </span> <span>4</span> <span>minutes</span></span></p><p>I’m currently working on a series of episodes for a Podcast I’ll be publishing soon. The Podcast will be in Italian and I wanted to make sure to publish the episode transcripts together with the audio episodes.</p>



<p>The idea of manually typing all the episodes text wasn’t really appealing to me so I started looking around.</p>



<h2>What are the tools out there?</h2>



<p>From a quick Google search, it seems that some companies are offering a mix of automated and human-driven transcription services.</p>



<p>I wasn’t really interested in that for now. I was, of course, just interested in consuming an API I could push my audio to and get back some text in a reasonable amount of time.</p>



<p>For this reason, I started looking for <em>speech-to-text</em> APIs and, of course, the usual suspects figured among the first results.</p>



<ul><li><a href="https://azure.microsoft.com/en-us/services/cognitive-services/speech-to-text/">Microsoft Cognitive Services</a></li><li><a href="https://www.ibm.com/cloud/watson-speech-to-text">IBM Watson Speech-to-Text</a></li><li><a href="https://www.speechmatics.co/">SpeechMatics</a></li><li><a href="https://aws.amazon.com/transcribe/">Amazon Transcribe</a></li><li><a href="https://cloud.google.com/speech-to-text">Google Cloud Speech-to-Text</a></li></ul>



<p>To be quite honest, I didn’t spend too much time investigating the solutions above. I probably spent more time reading about them to write this blog post.</p>



<p>I decided to go with Google Cloud because I’ve never used GCP before and wanted to give it a try. Additionally, the documentation for it seemed quite straightforward, as well as the support for Italian as language to transcribe from (the podcast is in Italian). I also had a few free credits available because I’ve never used GCP for personal use before.</p>



<h2>Setting up</h2>



<p>If you want to try transcribing your episodes too, follow this quick setup guide to get started.</p>



<p>Head over to <a href="https://cloud.google.com/">Google Cloud</a> and set up an account. Make sure you create a project and enable the Speech-to-Text API. If you forget to do so <code>gcloud</code> will be able to take care of that for you, later.</p>



<div><figure><img loading="lazy" width="509" height="99" src="https://alediaferia.com/wp-content/uploads/2020/05/Screenshot-2020-05-13-at-20.24.59.png" alt="Google Cloud Speech-to-Text" srcset="https://alediaferia.com/wp-content/uploads/2020/05/Screenshot-2020-05-13-at-20.24.59.png 509w, https://alediaferia.com/wp-content/uploads/2020/05/Screenshot-2020-05-13-at-20.24.59-300x58.png 300w" sizes="(max-width: 509px) 100vw, 509px"><figcaption>Google Cloud Speech-to-Text</figcaption></figure></div>



<p>Second thing I did was installing <code><a href="https://cloud.google.com/sdk/docs/quickstarts">gcloud</a></code>, the CLI Google Cloud provides for interacting with the APIs. This time I was only interested in testing the API so it seemed to me that this tool was the only way to get started quickly.</p>



<p>Additionally, there’s not much you can do from the Google Cloud Web Console if you want to deal with Speech-to-Text APIs.</p>



<h3>Get your file ready for transcription</h3>



<p>Sampling rate for your audio file should be at least 16 kHz for better results. Additionally, GCP recommends a lossless codec. I only had an mp3 of my episode handy at the time so I gave it a try anyway and it worked well enough.</p>



<p><strong>Make sure you know the sample rate of your file, though, because specifying a wrong one might lead to poor results.</strong></p>



<p>You can usually verify the sample rate by getting info on your file from your Mac’s Finder:</p>







<p>You can read more about the recommended settings on the <a href="https://cloud.google.com/speech-to-text/docs/best-practices">Best Practices</a> section.</p>



<h3>Upload your episode to the bucket</h3>



<p>GCP needs your file to be available from a Storage Bucket so, go ahead and <a href="https://cloud.google.com/storage/docs/creating-buckets">create one</a>.</p>



<figure><img src="https://cloud.google.com/storage/images/create-bucket.png" alt=""><figcaption>Storage Bucket creation example</figcaption></figure>



<p>You’ll be able to upload your episode from there.</p>



<h2>Time to transcribe</h2>



<p>Once you have your episode file up there in the cloud go back to your local machine terminal were you have configured the <code>gcloud</code> tool.</p>



<figure><img loading="lazy" src="https://alediaferia.com/wp-content/uploads/2020/05/carbon1-1024x175.png" alt="" width="580" height="99" srcset="https://alediaferia.com/wp-content/uploads/2020/05/carbon1-1024x175.png 1024w, https://alediaferia.com/wp-content/uploads/2020/05/carbon1-300x51.png 300w, https://alediaferia.com/wp-content/uploads/2020/05/carbon1-768x131.png 768w, https://alediaferia.com/wp-content/uploads/2020/05/carbon1-1536x263.png 1536w, https://alediaferia.com/wp-content/uploads/2020/05/carbon1.png 2048w" sizes="(max-width: 580px) 100vw, 580px"><figcaption>Gcloud used to trigger the speech-to-text transcription</figcaption></figure>



<p>If your episode lasts longer than 60 seconds (😬) you’ll want to use <code>recognize-long-running</code> and most likely specify <code>--async</code>. </p>



<p>As I said before, make sure you specify the right <code>--sample-rate</code>: in my case 44100. This will help GCP transcribe your file with better results.</p>



<p>The <code>--async</code> switch creates a long-running asynchronous operation. It took around 5 minutes for me to have the operation complete. </p>



<p>Oddly, I wasn’t able to find any reference to the asynchronous operation from my Google Cloud Console. So, if you want to be able to know what happened to your transcription job, make sure you take note of the operation identifier. You’ll need it to query the <code>speech operations</code> API for information about your transcription job.</p>



<figure><img loading="lazy" width="1024" height="268" src="https://alediaferia.com/wp-content/uploads/2020/05/carbon2-1024x268.png" alt="" srcset="https://alediaferia.com/wp-content/uploads/2020/05/carbon2-1024x268.png 1024w, https://alediaferia.com/wp-content/uploads/2020/05/carbon2-300x79.png 300w, https://alediaferia.com/wp-content/uploads/2020/05/carbon2-768x201.png 768w, https://alediaferia.com/wp-content/uploads/2020/05/carbon2-1536x402.png 1536w, https://alediaferia.com/wp-content/uploads/2020/05/carbon2.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>The speech operation metadata</figcaption></figure>



<h2>The transcribed data</h2>



<p>Once your transcription operation is complete the <code>describe</code> command will return the transcript excerpts, together with the confidence rate.</p>



<figure><img loading="lazy" width="1024" height="641" src="https://alediaferia.com/wp-content/uploads/2020/05/carbon3-1024x641.png" alt="" srcset="https://alediaferia.com/wp-content/uploads/2020/05/carbon3-1024x641.png 1024w, https://alediaferia.com/wp-content/uploads/2020/05/carbon3-300x188.png 300w, https://alediaferia.com/wp-content/uploads/2020/05/carbon3-768x481.png 768w, https://alediaferia.com/wp-content/uploads/2020/05/carbon3-1536x962.png 1536w, https://alediaferia.com/wp-content/uploads/2020/05/carbon3.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>The speech transcript excerpt</figcaption></figure>



<p>I wasn’t particularly interested in the <code>confidence</code> rate, I only wanted a big blob of text to be able to review and use for SEO purposes as well as to be able to include it with the episode. For this reason, <strong><em>jq to the resque!</em></strong></p>



<p>I love <code><a href="https://stedolan.github.io/jq/">jq</a></code>, you can achieve so much with when it comes to manipulate JSON.</p>



<p>In my case, I only wanted to concatenate all the <code>transcript</code> fields and save them to a file. Here’s how I did:</p>



<pre data-enlighter-language="generic" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">$ ./bin/gcloud ml speech operations describe &lt;your-transcription-operation-id&gt; | jq '.response.results[].alternatives[].transcript' &gt; my-transcript.txt</pre>



<p>And that’s it!</p>



<h2>Conclusion</h2>



<p>I thought of sharing the steps above because they’ve been useful to me in producing the transcripts. I think GCP Speech-to-Text works quite well with Italian but, of course, the transcript is not suitable to be used as it is, unless your accent is perfect. Mine wasn’t 😅.</p>



<p>If you want to know more about my journey towards publishing my first podcast <strong><a href="https://twitter.com/alediaferia">follow me on Twitter</a></strong> were I’ll be sharing more about it.</p>



<p>Photo by <a href="https://unsplash.com/@maltewingen?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Malte Wingen</a> on <a href="https://unsplash.com/s/photos/podcast?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://alediaferia.com/2020/05/14/how-used-gcp-transcripts-podcast/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24448922</guid>
            <pubDate>Sat, 12 Sep 2020 00:58:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sketching Algorithms for High Dimensional, Large Datasets]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24448669">thread link</a>) | @ArtWomb
<br/>
September 11, 2020 | https://www.sketchingbigdata.org/fall20/ | <a href="https://web.archive.org/web/*/https://www.sketchingbigdata.org/fall20/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            



<h2 id="cs-294-165-fall-2020-syllabus-fall20-syllabus">CS 294-165 - Fall 2020 (<a href="https://www.sketchingbigdata.org/fall20/syllabus">Syllabus</a>)</h2>

<p><strong><strong>Sketching algorithms</strong></strong> compress data in a way that is still useful for answering some pre-specified family of queries, possibly across datasets by comparing sketches. This course will cover mathematically rigorous models for developing such algorithms, as well as some provable limitations of algorithms operating in those models. Some topics covered include:</p>

<ul>
<li><p><strong>Streaming algorithms.</strong> Compute useful statistics over a dataset making only one pass over it, while using little memory.</p></li>

<li><p><strong>Dimensionality reduction.</strong> General techniques and impossibility results for reducing data dimension while still preserving geometric structure.</p></li>

<li><p><strong>Randomized linear algebra.</strong> Algorithms for big matrices (e.g. a user/product rating matrix for Netflix or Amazon). Regression, low rank approximation, clustering, etc.</p></li>

<li><p><strong>Compressed sensing.</strong> Recovery of (approximately) sparse signals based on few linear measurements.</p></li>
</ul>

<p>This is a graduate course, though there may be room for a limited number of advanced undergraduate students satisfying the following prerequisites: mathematical maturity and comfort with algorithms (e.g. CS 170), discrete probability, and linear algebra.</p>

</div></div>]]>
            </description>
            <link>https://www.sketchingbigdata.org/fall20/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24448669</guid>
            <pubDate>Sat, 12 Sep 2020 00:08:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hiring the first head of marketing at a startup]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24448513">thread link</a>) | @tosh
<br/>
September 11, 2020 | https://helenmin.com/blog/first-head-of-marketing | <a href="https://web.archive.org/web/*/https://helenmin.com/blog/first-head-of-marketing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" id="item-5e842a035e87b661d8bf062f"><div><div><div data-block-type="2" id="block-c44372ffee113b1df651"><div><p>“Did you see that Stripe’s CMO is out?” a founder asked one day from the desk behind me.</p><p>Though I’d heard the news, the question had me curious for two reasons: First, I was two months into my own role as head of marketing of a fast-growing fintech startup and curious what my boss thought about the topic. Second, I had closely followed the woman in question and considered her a terrific marketer.</p><p>“It’s only been a year,” he continued. “She must’ve been bad.”<br>&nbsp;</p><p><strong>Revolving door</strong>&nbsp;</p><p>This exchange sticks with me years later because it’s emblematic of the mentality some technical founders hold about the role of marketing.</p><p>The thinking goes: Founders build great products that sell themselves through the power of network effects. When the need arises down the road, the company will hire a proven marketing professional to start a department from scratch while everyone’s at a full sprint. If it doesn’t work out…<em>she must’ve been bad</em>.</p><p>In fact, brief tenures and abrupt departures of CMOs have become the norm in Silicon Valley.<strong> </strong>By my count, the tenures of Robinhood’s first <em>three</em> CMOs combined add up to two years; Wealthfront’s first CMO lasted a year and half; and Intercom’s and Affirm’s first CMOs were both out in less than a year. At Dropbox, our first CMO (who I found to be a fantastic leader and marketer) stayed on for just over a year…</p><p>These marketers weren’t all “bad.” Most of them have stellar reputations, in fact. So what’s really going on?</p><p><strong>Founder mentality</strong></p><p>In Silicon Valley, marketing isn’t important—until it is.</p><p>Founders often disregard marketing for as long as possible, convincing themselves it’s “fluff.” A product manager can probably handle things like customer research, product positioning, and the external components of a product launch, and then hand them off to sales, right? After all, he has an MBA. :)</p><p>This works well enough in the early stages, but then problems emerge: Customer-facing team members struggle to stick to a consistent message in the market; information isn’t flowing between customers and product teams; taking turns managing the company Twitter account isn’t working; and the founders have to manage the press alias.</p><p>At the same time, the internal demand for marketing grows: Engineering needs better market insights; product needs successful launches; sales needs more compelling materials; executives need external comms support; HR needs help with recruiting and retention; and customer success needs to scale and automate a lot of customer comms.</p><p>Finally, something happens. The company gets ensnared in a PR crisis, needs to expand to new markets, or faces new competition. If only the company had better brand equity, visibility, or public sentiment, executives could stay focused on what’s important.</p><p>At this point, founders “give in” and kick off the search for a head of marketing to build the function.</p><p><strong>‘Without a penny spent on marketing’</strong></p><p>When recruiting for their first head of marketing, founders will sometimes declare enthusiastically, “Look how far we’ve gotten—and without a penny spent on marketing!”&nbsp;</p><p>I tell them this is analogous to walking into a dentist’s office and proclaiming, “Look how great my teeth look—and without a day of brushing! Do you want to be my first dentist?” Yuck.</p><p>If you didn’t believe in marketing for years, you probably aren’t set up for the function to succeed in the first place. Experienced marketers know this.&nbsp;</p><p>If they’ve done the job before, a candidate will know they’ll be juggling four jobs at the same time:&nbsp;</p><ul data-rte-list="default"><li><p>Job 1: Recruit and manage a team;&nbsp;</p></li><li><p>Job 2: Define what marketing means at the company and educate the rest of the team;</p></li><li><p>Job 3: Help other departments succeed and scale; and</p></li><li><p>Job 4: Define the brand and tell stories to move the brand forward.</p></li></ul><p>They also know they’ll be stepping into a mess and answering to executives who expect quick results. What’s more, with no team in place, they’ll be responsible for day-to-day activities they’ve been delegating for years (writing copy, setting up marketing dashboards, etc.)&nbsp;</p><p>Do they really want to start at the beginning, with no resources?&nbsp;</p><p><strong>First hire a ‘super IC’ (or two)</strong></p><p>Instead of following this failed playbook, I advise startups to think about marketing much earlier in the process and begin laying the foundation that a future leader can build on.</p><p>Set up a small team of one or two strong individual contributors to take on marketing duties. These should be generalists capable of handling a variety of marketing tasks (maybe consider making them <a href="https://helenmin.com/blog/product-marketing">product marketing managers</a>). Have them set up basic infrastructure like a marketing automation tool that connects to your CRM and Google Analytics for your website and blog. Connect them to other departments to begin building websites optimized for conversions, developing simple campaigns, drafting brand messaging, and so on.</p><p>This is a win for the founder, who learns the different marketing functions much earlier in the process. It’s a win for the business generalist, who can find their passion while making an impact at the company. It’s a win for the future head of marketing, because someone will have already done some trial-and-error and gotten the marketing function off the ground. And it’s a win for the recruiter, because the job’s more attractive with someone already on the team cranking.</p><p>These super ICs won’t do all the jobs of a marketing head. They won’t recruit or necessarily even lead. But you’ll have people who understand marketing, speak the language, and can run experiments.</p><p><strong>Self-fulfilling prophecy</strong></p><p>Like NFL coaches, heads of marketing experience a lot of turnover. Because marketing initiatives are often hard to measure and roles aren’t customer-facing, removing a marketing lead is a quick and easy lever for a founder to pull at the first signs of things not working out.&nbsp;</p><p>As a result, a self-fulfilling prophecy develops, where marketers <em>assume</em> they’ll only last a year and start making decisions based on that belief. Knowing time is limited, they get over-ambitious and move too fast or focus on things that will pad their resume rather than strategic priorities. After a year or two, they’re off to another company and the startup is back at square one. </p><p>This is bad for startups! Scarred by their experience dealing with a first head of marketing departure, many founders put off hiring a new lead for a while—sometimes leaving the company even worse off than before the head of marketing joined.</p><p><strong>A checklist&nbsp;</strong></p><p>To avoid this fate for your company, use the following checklist to determine if you’re ready for a marketing head:&nbsp;</p><ul data-rte-list="default"><li><p><em>Do you have budget, headcount, and recruiting bandwidth to help a new marketing leader build their team?</em></p></li><li><p><em>Do you have a clear understanding of your growth model and where marketing efforts can uniquely impact growth?&nbsp;</em></p></li><li><p><em>Do you have buy-in from engineering and design leadership to support marketing experiments and campaigns?&nbsp;</em></p></li><li><p><em>Do you have the patience to allow time for experimentation and some fails before big wins?</em></p></li></ul><p>If you answer “yes” to (most of) these questions, congratulations—you’re ready to hire your first marketing head. Good luck!</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://helenmin.com/blog/first-head-of-marketing</link>
            <guid isPermaLink="false">hacker-news-small-sites-24448513</guid>
            <pubDate>Fri, 11 Sep 2020 23:41:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[VPNs Are Overrated]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24448213">thread link</a>) | @mratmeyer
<br/>
September 11, 2020 | https://maxratmeyer.com/blog/vpns-are-overrated/ | <a href="https://web.archive.org/web/*/https://maxratmeyer.com/blog/vpns-are-overrated/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>One piece of cybersecurity advice that comes up time and time again is to use a VPN. VPNs, or virtual private networks, encrypt the internet traffic between you and your VPN provider, securing data from your internet provider and local network as well as hiding your IP address. Through <a href="https://www.youtube.com/watch?v=7uE7kFcJ_Pk">clever marketing</a>, VPN providers position themselves as an all in one tool to secure yourself online. However, the reality is a lot more complicated.</p><h2>VPNs can sell your data</h2><p>Privacy wise, all a VPN does is shift who you trust with your data. Normally, you would trust your internet provider, like Comcast or AT&amp;T, to not intercept or change any of your data packets. When you use a VPN, that traffic is encrypted through your local internet provider and released at the VPNs servers. This means that your VPN provider could intercept or track your connections. Most VPNs will claim that they do not do this, citing that they have no logging policies. However, VPNs <a href="https://www.theregister.co.uk/2011/09/26/hidemyass_lulzsec_controversy/">have lied about this policy</a> before.</p><p>Free VPNs are especially prone to these shady business practices, as they have to pay for their servers somehow. For example, popular free VPN Hotspot Shield was <a href="https://arstechnica.com/tech-policy/2017/08/ftc-must-scrutinize-hotspot-shield-over-alleged-traffic-interception-group-says/">caught injecting affiliate links into their users traffic</a>. Generally, it's a good idea to avoid most free VPNs and do your research before using any VPN, even if it's paid.</p><h2>VPNs don’t make you anonymous</h2><p>While VPNs do change your public IP address, this isn’t as helpful as you might think. Most IP addresses are shared between multiple people or devices anyway, so services don’t rely on it much for tracking. However, there are lots of other factors that companies use to track you. This includes the cookies in your browser and what accounts you are logged in to, but also many other factors outside of your control such as your user agent or browser fingerprint. Browser fingerprinting, for example, uses factors such as your device, screen size, plugins, and other information about your computer to uniquely identify you. To see this in action, you can visit a site like <a href="https://panopticlick.eff.org/">Panopticlick</a> to see how unique your browser is to trackers.</p><h2>VPNs don’t make you (that much) more secure</h2><p>VPNs do secure your traffic from your local network, but we already have technologies that do that for us. HTTPS, the padlock in your browser, means that content is encrypted between your computer and the website you are connected to. This makes it really hard for someone to intercept or view the site you are looking at. The most an onlooker would be able to see is the domain name you are connected to, but they wouldn't be able to see the exact page or content you are looking at. Generally, for most people, this should be enough and VPNs wouldn't add many security benefits - especially if the VPN is sketchy itself.</p><h2>So why would I use a VPN?</h2><p>While VPNs aren't needed for most people, there are definitely scenarios in which they are useful. If you are trying to access content that is region restricted, VPNs are useful tools to bypass geoblocks. VPNs are also useful for bypassing restrictive firewalls, or add extra security if you are connected to a public Wi-Fi network. However, before you use a VPN, make sure you do your research about which VPNs are trustworthy and won't sell your data.</p><h2>So how do I secure myself online?</h2><p>The most important way to secure yourself online is simply to follow basic cyber hygiene habits. Use unique passwords for each site with a password manager, don’t click on links in suspicious emails or websites, always keep your software up to date. As internet security and privacy becomes more popular, major VPN companies are going to grow and get more popular. However if you follow basic cyber hygiene habits, your cybersecurity posture will be stronger than if you just used VPN companies.</p></div></div>]]>
            </description>
            <link>https://maxratmeyer.com/blog/vpns-are-overrated/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24448213</guid>
            <pubDate>Fri, 11 Sep 2020 22:59:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Map for Bitcoin Businesses]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24448202">thread link</a>) | @bigfruit
<br/>
September 11, 2020 | http://leelamaps.com/bitcoin | <a href="https://web.archive.org/web/*/http://leelamaps.com/bitcoin">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<h2>ATM Status</h2>



<figure><img loading="lazy" width="2048" height="2048" src="http://leelamaps.com/wp-content/uploads/2020/09/ac9a9b97-67fe-4d47-a3be-72d694fd0d3a.jpg" alt="" srcset="http://leelamaps.com/wp-content/uploads/2020/09/ac9a9b97-67fe-4d47-a3be-72d694fd0d3a.jpg 2048w, http://leelamaps.com/wp-content/uploads/2020/09/ac9a9b97-67fe-4d47-a3be-72d694fd0d3a-300x300.jpg 300w, http://leelamaps.com/wp-content/uploads/2020/09/ac9a9b97-67fe-4d47-a3be-72d694fd0d3a-1024x1024.jpg 1024w, http://leelamaps.com/wp-content/uploads/2020/09/ac9a9b97-67fe-4d47-a3be-72d694fd0d3a-150x150.jpg 150w, http://leelamaps.com/wp-content/uploads/2020/09/ac9a9b97-67fe-4d47-a3be-72d694fd0d3a-768x768.jpg 768w, http://leelamaps.com/wp-content/uploads/2020/09/ac9a9b97-67fe-4d47-a3be-72d694fd0d3a-1536x1536.jpg 1536w, http://leelamaps.com/wp-content/uploads/2020/09/ac9a9b97-67fe-4d47-a3be-72d694fd0d3a-1200x1200.jpg 1200w, http://leelamaps.com/wp-content/uploads/2020/09/ac9a9b97-67fe-4d47-a3be-72d694fd0d3a-1980x1980.jpg 1980w" sizes="(max-width: 2048px) 100vw, 2048px"></figure>



<p>Is your nearest Bitcoin ATM operational? Find out or post on <a href="https://apps.apple.com/us/app/leela-maps/id1462683989">Leela Maps</a>!</p>



<p><strong>Style guide:</strong> Title the Bitcoin ATM with green or red dot emojis to denote status. Set the description to include #ATM #Bitcoin, the phone number &amp; website of the provider, and the hours of access.</p>



<h2>Businesses</h2>



<figure><ul><li><figure><img loading="lazy" width="576" height="1024" src="http://leelamaps.com/wp-content/uploads/2020/09/IMG_3214-576x1024.png" alt="" data-id="505" data-full-url="http://leelamaps.com/wp-content/uploads/2020/09/IMG_3214.png" data-link="http://leelamaps.com/?attachment_id=505" srcset="http://leelamaps.com/wp-content/uploads/2020/09/IMG_3214-576x1024.png 576w, http://leelamaps.com/wp-content/uploads/2020/09/IMG_3214-169x300.png 169w, http://leelamaps.com/wp-content/uploads/2020/09/IMG_3214.png 750w" sizes="(max-width: 576px) 100vw, 576px"></figure></li><li><figure><img loading="lazy" width="576" height="1024" src="http://leelamaps.com/wp-content/uploads/2020/09/IMG_3215-576x1024.png" alt="" data-id="504" data-full-url="http://leelamaps.com/wp-content/uploads/2020/09/IMG_3215.png" data-link="http://leelamaps.com/?attachment_id=504" srcset="http://leelamaps.com/wp-content/uploads/2020/09/IMG_3215-576x1024.png 576w, http://leelamaps.com/wp-content/uploads/2020/09/IMG_3215-169x300.png 169w, http://leelamaps.com/wp-content/uploads/2020/09/IMG_3215.png 750w" sizes="(max-width: 576px) 100vw, 576px"></figure></li><li><figure><img loading="lazy" width="867" height="1024" src="http://leelamaps.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-11-at-3.25.27-PM-867x1024.png" alt="" data-id="506" data-full-url="http://leelamaps.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-11-at-3.25.27-PM.png" data-link="http://leelamaps.com/?attachment_id=506" srcset="http://leelamaps.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-11-at-3.25.27-PM-867x1024.png 867w, http://leelamaps.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-11-at-3.25.27-PM-254x300.png 254w, http://leelamaps.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-11-at-3.25.27-PM-768x907.png 768w, http://leelamaps.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-11-at-3.25.27-PM-1301x1536.png 1301w, http://leelamaps.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-11-at-3.25.27-PM-1200x1417.png 1200w, http://leelamaps.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-11-at-3.25.27-PM.png 1450w" sizes="(max-width: 867px) 100vw, 867px"></figure></li></ul></figure>



<p>The Leela Maps platform is a freeform map notes tool that you can use to post information about how to exchange numerical value with other people.</p>



<div>
<div><p><a href="http://leelamaps.com/tutorial/">Map Notes Tutorial</a></p></div>



<div><p><a href="http://leelamaps.com/sharing-economy/">Sharing Economy Guide</a></p></div>
</div>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>http://leelamaps.com/bitcoin</link>
            <guid isPermaLink="false">hacker-news-small-sites-24448202</guid>
            <pubDate>Fri, 11 Sep 2020 22:58:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Principles for Naming a Brand]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24447991">thread link</a>) | @darsoli
<br/>
September 11, 2020 | https://mmarchny.com/naming-branding/ | <a href="https://web.archive.org/web/*/https://mmarchny.com/naming-branding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<!-- Post categories filter -->
	
<!-- added to container container-medium -->
	<div>

					<!-- row + class for blog post cat -->
			<div>

				<div id="primary">
					<main id="main" role="main">

						<!-- deleted to below container-small -->
						<div>

							<!-- <div class="hero clear"> -->
								<!-- Featured media -->
								
							<!-- </div> -->

							

								
<article id="post-1954">

	<!-- overview page feat img -->
	
	
		
		<div>

			
<p><strong>Everything has a name: a child, a pet, cars, and places. It’s how we befriend subjects and objects and it’s how we recall identifiers. But, naming a brand can be a painful process. It can take a long time and sometimes, it seems to never really come together. In order to take the pressure off of finding the perfect name it’s helpful to remember that businesses create brands, not vice versa. Think <em>Mountain Dew</em> (sounds cumbersome), <em>Starbucks</em> (sounds unrelated) and <em>Virgin</em> (sounds like a lack of experience), <em>The Boring Company</em> (sounds negative), <em>Slack</em> (sounds like the opposite of what it does). Attributed meaning and feelings build in the years after naming.</strong></p>



<hr>







<hr>



<div>
<p>
<h2 id="brand-names-in-context">Brand Names in Context</h2>
</p>



<div>
<div>
<div>
<p>First and foremost, a name doesn’t come alone. There will be contextual elements like a tagline, a logo, a color palette that are used on a variety of components, like the top visual on a website, or a headline on an ad. All of those can be filled with words and visuals that reflect a company’s strategy. A name, however, is a central and the longest-standing of all brand components.&nbsp;</p>



<p>Get help from a naming professional or find a name yourself. The following cornerstones make for a process and provide for a good checklist.</p>
</div>



<div>
<p>The most important aspects of your strategy, <em>your product</em> (<a href="https://mmarchny.com/creative-strategy-branding-part-1-company/">what it is</a>), <em>what does it stand for</em> (<a href="https://mmarchny.com/creative-strategy-branding-part-4-positioning/">positioning</a>), <em>who’s it for</em> (<a href="https://mmarchny.com/creative-strategy-branding-part-2-target-market/">target market</a>), need to get across clearly in the most important brand modules: the name, the logo and a tagline.</p>



<p>The more unknown the company or product, the more direct those aspects need to be laid out in branding communications.&nbsp;</p>
</div>
</div>
</div>
</div>



<hr>



<div>
<p>
<h3>Examples</h3>
</p>



<div>
<div>
<div>
<p><strong>Example 1:</strong></p>



<p>Name: Twitter (product: chatter)</p>



<p>Tagline: It’s what’s happening. (positioning: real and now)</p>



<p>Meta description: From breaking news and entertainment to sports and politics, get the full story with all the live commentary. (target market: for news and entertainment readers that look for a variety of opinions)</p>
</div>



<div>
<p><strong>Example 2:</strong></p>



<p>Name: Starbucks, originally known as Starbucks Coffee Company (product: coffee)</p>



<p>Tagline: More than just great coffee. (positioning: quality coffee, snacks and atmosphere)</p>



<p>Visuals and additional copy: Employee photos are in the foreground. Alongside copy that describes values: “not only celebrated coffee but also connection. We’re a neighborhood gathering place, a part of your daily routine. Get to know us and you’ll see: we are so much more than what we brew. We call our employees partners because we are all partners in shared success. We make sure everything we do is through the lens of humanity—from our commitment to the highest-quality coffee in the world, to the way we engage with our customers and communities to do business responsibly.” (target market: for people that seek community)</p>
</div>
</div>
</div>
</div>



<hr>



<div>
<p>
<h2 id="domain-availability">Domain Availability&nbsp;</h2>
</p>



<div>
<div>
<p>At the beginning of the naming process, looking up domains that are available can be helpful. It’ll help find competitors as well. If the domain name is not available, an additional industry identifier can be pre or appended, like –books for a bookstore or –foods or eat– for any food-related brands. Think <em>zolabooks.com</em>. &nbsp;</p>



<p>Broad terms like <em>Solutions</em> should be avoided due to lack of meaning (words that can be used by everybody don’t add meaning). Dot-com for companies or dot-org domains for nonprofits remain strongest and are preferred in the U.S.&nbsp;</p>
</div>
</div>
</div>



<hr>



<div>
<p>
<h2 id="acronyms-founder-names">Acronyms and Founders’ Names</h2>
</p>



<div>
<div>
<div>
<p>Usually, good names are shorter, otherwise they’ll get abbreviated naturally later into an acronym. Think <em>KFC, A.T. &amp; T. and P&amp;G</em>. A name sometimes consists of two or three compound words—the words themselves and their first letters need to make a good combination. <em>SS</em> will always have a bad connotation in some countries. No matter how hard one tries to prohibit the usage of monograms, eventually, these letter combos will make their way into file names, into favicons or other collapsed logo versions, into code, especially used when the product is a technical product where truncated versions occur naturally.</p>



<p><strong>B2C brands focus on names that show personality, culture and positioning.</strong> Common names are <em>Apple</em> (easy and obtainable), <em>Nike and Audi</em>. Brand names do not have to be connected to the actual product, although they certainly can be (think <em>Netflix and Aesop</em>), but an appendix can be added that has the potential to be dropped when a brand is well-known. Think <em>Starbucks Coffee Company vs. Starbucks</em>. Short/ fun/ cool/ approachable/ memorable/ indicative trumps logical and longer. Think <em>Hulu, Kodak, Etsy, Mars, 3M, Nest and Sony.</em></p>
</div>



<div>
<p>Avoid a descriptive category or common industry-specific keyword name for a company name. Competitors will pick similar ones which will not only make your brand blend in but the chance to position the company is wasted. Read the <a href="https://www.newyorker.com/magazine/2011/10/03/famous-names">NYT story</a> on EasyMail, MegaMail, and ProMail. Also, descriptive names are harder to trademark and can be impossible to find through Google search.&nbsp;</p>



<p><strong>Founders’ names</strong> are considered functional names. Think <em>Dell, Ford and Colgate.</em> Carrying personality and positioning from the start is not a given.&nbsp;</p>



<p><strong>B2B brands</strong> often have a more descriptive name; they will get abbreviated and that’s okay. Think <em>UPS, IBM, AWS.</em> The one thing that’s important for B to B names is that they need to have the potential to sound big, or at least not small and definitely not limiting in what services the company sells. <a href="http://blue/">Bluecore</a>’s first name was TriggerMail. Triggering an email was how the company started out but other products were added on later.&nbsp;</p>
</div>
</div>
</div>
</div>



<hr>



<div>
<p>
<h2 id="length-industry-fit-pronunciation"><strong><strong>Length, Industry Fit, Pronunciation</strong></strong></h2>
</p>



<div>
<div>
<div>
<p>Longer names, a group of names and compounds naturally have a tendency to sound smaller unless they include (read: <em>own</em>) an important branch or location of the industry. Think <em>Whole Foods, Natural History Museum, American Airlines</em>.</p>



<p>A name should fit broadly into the field of its peers (read: <em>stand out the right way</em>). It should be easy to remember, have no complicated spelling (or a well-considered or user-tested alternative spelling), be pronounceable in one way only* and it should be ownable within its industry. A domain check and a search through the <a href="http://tmsearch.uspto.gov/">trademark database</a> will be of help, but consulting a trademark lawyer who reviews usage in specific categories, states, national and international use, is money well-invested.</p>
</div>



<p><em>* The former car brand Daewoo turned their unpronounceable name into an ad campaign in 1995. Fage yoghurt still needs to have its pronunciation printed on its packaging. Other names that were created before being tested internationally are Huawei, Renault, Tag Heuer and Moschino. Two Princeton University psychologists have found in a </em><a href="https://www.princeton.edu/news/2006/05/29/study-stock-performance-tied-ease-pronouncing-companys-name"><em>2006 study</em></a><em> that “people are more likely to purchase newly offered stocks that have easily pronounced names.”</em></p>
</div>
</div>
</div>



<hr>



<div>
<p>
<h2 id="naming-trends">Trends</h2>
</p>



<div>
<div>
<p>Different times, different constraints, different trends. For internet companies, the <em>-ster</em> <em>(Napster, Friendster)</em> started in 2001, <em>“My”</em> happened in 2005 (Myspace), and <em>-fy/ -ly/ -y</em> spiked in 2010 <em>(Bitly, Artsy and Weebly). </em>Vowel-dropping for easier trademarking and domain availability was early to mid 2000’s <em>(Flickr, Tumblr, Unbxd, Scribd).</em> The random couple sandwich names mostly found in the fashion industry spiked in 2010. Think <em>Rag &amp; Bone, Kit and Ace, Boll &amp; Branch.&nbsp;</em></p>



<p>Generally, the naming of products (as opposed to the naming of companies) can be more trendy versus classy because they evolve with the market or they have room for a revamp over time.</p>
</div>
</div>
</div>



<hr>



<div>
<p>
<h2 id="spelling-spaces-hyphens"><strong>Spelling, Spaces, Hyphens</strong></h2>
</p>



<div>
<div>
<div>
<p>As for many things, <em>classy</em> wins in the long run because it never goes out of style.&nbsp;</p>



<p><em>Spelling of a brand name within text:</em> </p>



<p>An abbreviated company name should be spelled in all caps, not lowercase. A regular name should be spelled together, first letter capitalized. A name should be separated by space or by hyphen if it consists of multiple words, capitalizing each first letter. When compound words are spelled together, there must be only one way to pronounce the compound, if not, it needs separation. A good test for spelling is to insert the name into long- and short-form copy: in the middle of a sentence, at the beginning of a sentence, into a bulleted list and into a signature. The name needs to have a consistent appearance across all applications and not look awkward (think an all lowercase brand name at the beginning of a sentence).&nbsp;&nbsp;&nbsp;</p>
</div>



<div>
<p><em>Spelling within a logo mark:</em>&nbsp;</p>



<p><strong>Option 1 “Friendly”:</strong> lowercase spelling in logos (think amazon, adidas, citibank and intel, mailchimp, west elm, ebay) makes companies more approachable, casual, younger or shows a focus on tech. However, within text (general copy or headlines), brand names should still start with a capital letter (Sell on Amazon; In 2016, Mailchimp announced …).&nbsp;</p>



<p><strong>Option 2 “Timeless”:</strong> Leading capital letters, separated by space or hyphen if more than one word is a brand that has grown up and owns its identity: Squarespace, Coca-Cola, Microsoft, The Container Store, Walmart.</p>



<p><strong>Option 3:</strong> All caps is another timeless use and often a design decision to give the type a more unified or stronger look. Think IKEA (also spelled in call caps within text), MUJI (spelled Muji within text), ZARA (in text: Zara), COSTCO (in text: Costco), THE HOME DEPOT (in text: The Home Depot), NETFLIX (in text: Netflix).</p>



<p><strong>Option 4:</strong> Leading capital letters but no spaces between compounds shows unity and strength by keeping an emphasis on the roots of both. Can be typographically less attractive and are harder to remember how to spell correctly: FedEx, McDonalds, RedBull, HomeGoods, YouTube.</p>
</div>
</div>
</div>
</div>



<hr>



<div>
<p>
<h2 id="listings-soundcheck"><strong>Listings and Soundcheck</strong></h2>
</p>



<div>
<div>
<p>Not the most important thing but the starting letter is another aspect to consider. Your brand will be listed somewhere alphabetically: as a tech product within a marketplace, in a logo series of partnerships, in a print catalog—the higher the …</p></div></div></div></div></article></div></main></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mmarchny.com/naming-branding/">https://mmarchny.com/naming-branding/</a></em></p>]]>
            </description>
            <link>https://mmarchny.com/naming-branding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24447991</guid>
            <pubDate>Fri, 11 Sep 2020 22:28:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Database Lab – thin Postgres clones for faster development and testing]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24447922">thread link</a>) | @stansler
<br/>
September 11, 2020 | https://postgres.ai/docs/get-started | <a href="https://web.archive.org/web/*/https://postgres.ai/docs/get-started">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p><span><table>
<thead>
<tr><th></th><th></th></tr>
</thead>
<tbody>
<tr><td><a href="https://postgres.ai/docs/database-lab">Database Lab Engine</a> (open source)<br>Open-source technology to clone databases of any size in seconds</td><td><a href="https://postgres.ai/docs/joe-bot">Joe, SQL optimization chatbot</a> (open source)<br>Run <code>EXPLAIN ANALYZE</code> and optimize SQL on instantly provisioned full-size database copies</td></tr>
<tr><td><a href="https://postgres.ai/docs/staging">Dev/QA/Staging databases with superpowers</a><br>Develop and test using full-size database copies provided in seconds</td><td><a href="https://postgres.ai/docs/database-changes-cicd">CI/CD observer for DB schema changes</a><br>Prevent performance degradation and downtime when deploying database schema changes</td></tr>
<tr><td><a href="https://postgres.ai/docs/checkup">postgres-checkup</a> (open source)<br>Automated health-checks and query analysis for heavily-loaded PostgreSQL databases</td><td><a href="https://postgres.ai/docs/data-access">Detached replicas</a><br>Use BI tools, run analytical queries, perform data export without replication lags and bloat</td></tr>
<tr><td><a href="https://postgres.ai/docs/tutorials/database-lab-tutorial-amazon-rds">Database Lab tutorial for Amazon RDS</a><br>Get started to use Database Lab for Amazon RDS PostgreSQL</td><td><a href="https://postgres.ai/docs/tutorials/database-lab-tutorial">Database Lab tutorial</a><br>Get started to use Database Lab for any PostgreSQL</td></tr>
</tbody>
</table>
<!--#### [Data recovery /  Instantaneously recover lost data](/docs/data-recovery)
Recover accidentally deleted data. Using thin cloning, the point-in-time recovery (PITR) can be performed without long waiting.
-->
<h2>What is Database Lab?</h2>
<p>Database Lab is used to boost software development via enabling ultra-fast provisioning of databases of any size. Developers, DBAs, and QA engineers work with full-sized independent clones of PostgreSQL databases. Development and testing tasks are accomplished much faster, with more iterations done, with better quality achieved and with much less money spent.</p>
<p><img src="https://postgres.ai/docs/assets/cicd-transform.png" alt="CI/CD transformation with Database Lab"></p>
<ul>
<li>Optimize non-production infrastructure costs by 10x.</li>
<li>Drastically improve development quality.</li>
<li>Get rid of downtimes and avoid performance degradation.</li>
<li>Cut half of the TTM (time to market), develop 2x faster than competitors.</li>
</ul>
<p><img src="https://postgres.ai/docs/assets/architecture.png" alt="Database Lab architecture"></p>
<h2>👋 Database Lab "Private Beta" program</h2>
<p>Database Lab Platform (SaaS) is currently in a "private beta" mode, being tested by several hundred engineers. Want to become an early adopter? Join Database Lab by <a href="http://postgres.ai/">Postgres.ai</a> "Private Beta" program today: <a href="https://postgres.ai/console/">https://postgres.ai/console/</a>.</p>
</span></p></article></div></div>]]>
            </description>
            <link>https://postgres.ai/docs/get-started</link>
            <guid isPermaLink="false">hacker-news-small-sites-24447922</guid>
            <pubDate>Fri, 11 Sep 2020 22:16:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Told to suspend data transfers to US, FB has issued Court case vs Irish Gov Dep]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24447914">thread link</a>) | @vinnyglennon
<br/>
September 11, 2020 | https://www.thecurrency.news/articles/23697/days-after-being-told-to-suspend-data-transfers-to-the-us-facebook-has-now-issued-a-high-court-case-against-the-irish-data-regulator | <a href="https://web.archive.org/web/*/https://www.thecurrency.news/articles/23697/days-after-being-told-to-suspend-data-transfers-to-the-us-facebook-has-now-issued-a-high-court-case-against-the-irish-data-regulator">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><nav></nav><section><header><div><figure><figcaption><p>Facebook’s international headquarters on Dublin’s Grand Canal Square. Photo: Thomas Hubert</p>
</figcaption></figure></div><div><div><p><h2>Having received a preliminary order to suspend data transfers to the US, Facebook is now seeking a judicial review against a decision of the Data Protection Commission. </h2></p></div></div></header><section><div data-testid="undefined-desktop">
<p>Days after the Data Protection Commissioner (DPC) sent Facebook a preliminary order to suspend data transfers to the US, the social media giant has lodged papers in the Irish High Court seeking a judicial review.</p>



<p>Acting on behalf of Facebook Ireland, the Dublin commercial law firm Mason Hayes + Curran lodged papers with the court yesterday, naming the Data Protection Commissioners as defendant in the judicial review action.</p>



<p>The High Court will be asked to test the validity and legality of the decision of the DPC, a move that will be watched by other social media giants. Yvonne Cunnane, head of data protection and privacy with Facebook, has...</p></div></section></section><p>
        © 2020 Currency Media Limited
  </p></div></div>]]>
            </description>
            <link>https://www.thecurrency.news/articles/23697/days-after-being-told-to-suspend-data-transfers-to-the-us-facebook-has-now-issued-a-high-court-case-against-the-irish-data-regulator</link>
            <guid isPermaLink="false">hacker-news-small-sites-24447914</guid>
            <pubDate>Fri, 11 Sep 2020 22:14:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Retrospective of my first useful Rust project]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24447771">thread link</a>) | @lukastyrychtr
<br/>
September 11, 2020 | https://jamesmcm.github.io/blog/2020/09/05/vopono/#en | <a href="https://web.archive.org/web/*/https://jamesmcm.github.io/blog/2020/09/05/vopono/#en">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This post is a retrospective of my first “useful” Rust project. <a href="https://github.com/jamesmcm/vopono">vopono</a> 
is a Linux program to launch applications in temporary network
namespaces (managed by vopono), in order to run specific applications
through VPN connections, without affecting the rest of your system.</p>

<p>vopono is <a href="https://github.com/jamesmcm/vopono">available on Github</a> (and in the <a href="https://aur.archlinux.org/packages/vopono/">AUR on Arch Linux</a>) and
licensed under the GPLv3 license (<a href="https://www.gnu.org/philosophy/pragmatic.html">see reasoning here</a>).</p>

<p>We’ll consider the motivation and background to creating vopono, the
upsides and downsides of writing it in Rust (and existing issues), and
some points about starting new side projects in general. I hope this
helps new Rust programmers starting their own first projects, or for
other programmers to consider using Rust.</p>

<!--more-->

<p>Opinions expressed are solely my own and do not express the views or opinions of my employer.</p>

<h2 id="background">Background</h2>

<p>I’ve used VPN services for many years, previously as a customer of
PrivateInternetAccess, and now with Mullvad (since
<a href="https://news.ycombinator.com/item?id=21584958">PrivateInternetAccess was purchased by a less scrupulous parent company</a>), as it is very
useful for working around network traffic restrictions (e.g. SSH access
restrictions or blocked websites) whilst travelling.</p>

<p>However, I often wanted to be able to quickly connect to the VPN without
disrupting other ongoing connections (i.e. video calls, etc.). In 2015,
I learnt how network namespaces could do this (on Linux), and pieced together some
bash scripts for OpenVPN <a href="https://unix.stackexchange.com/questions/149293/feed-all-traffic-through-openvpn-for-a-specific-network-namespace-only">from this StackExchange post</a>.</p>

<p>I used this for a few years, but it was a bit inconvenient having to
manually launch the network namespace. Especially if you wanted to
connect to different servers in order to test geolocation for example.</p>

<p>In April 2020, Wireguard was merged in to the Linux kernel
5.6, and became much more readily available with VPN providers. This,
combined with the switch to Mullvad, inspired me to add Wireguard
support to the scripts I was using. But I thought it would be best to
also address the issues of manually managing the network namespaces and
create a comprehensive application to handle OpenVPN and Wireguard
connections for various VPN providers, and create and destroy the
network namespaces on demand.</p>

<p>This was the start of vopono, my first
useful Rust project (I suppose <a href="https://github.com/jamesmcm/s3rename">s3rename</a> was also useful, but a much smaller
scope).</p>

<h2 id="benefits-of-rust">Benefits of Rust</h2>

<p>I chose to write vopono in Rust as I am still learning the language, and
greatly appreciate the ease of debugging with tools like <a href="https://github.com/rust-analyzer/rust-analyzer">rust-analyzer</a>
and <a href="https://github.com/rust-lang/rust-clippy">clippy</a>. There are many
other benefits too:</p>

<h3 id="enums">Enums</h3>

<p>Rust’s <a href="https://doc.rust-lang.org/book/ch06-01-defining-an-enum.html">native enum support</a> makes reasoning and debugging much easier
when dealing with enumerated values (like the choice between the TCP and
UDP protocols for OpenVPN connections). The Rust compiler forces us to
handle every possible value helping to prevent bugs from ever being
written.</p>

<h3 id="structopt">StructOpt</h3>

<p><a href="https://crates.io/crates/structopt">StructOpt</a> is a great crate for handling command-line options and
arguments via derived trait implementations over your structs defining
commands and subcommands. This allows you to abstract away dealing with command-line arguments directly,
and for the relevant code to be somewhat self-documenting (as <a href="https://doc.rust-lang.org/stable/rust-by-example/meta/doc.html">doc comments</a> are used to provide the user-facing help output).</p>

<p>Note that some developers prefer to use <a href="https://crates.io/crates/clap">clap</a> directly.</p>

<h3 id="result-and-anyhow">Result and anyhow</h3>

<p>Rust’s <a href="https://doc.rust-lang.org/std/result/enum.Result.html">Result enum</a> 
and <code>?</code> operator (the <a href="https://doc.rust-lang.org/edition-guide/rust-2018/error-handling-and-panics/the-question-mark-operator-for-easier-error-handling.html">try operator</a>)
make it simple and ergonomic to handle operations which may fail
(which are almost all operations when dealing with disk IO and
launching processes).</p>

<p>It is also very convenient when working with fallible operations over a
collection, where we may want to return to the user a list of operations
which failed. In Rust, we can 
<a href="https://doc.rust-lang.org/stable/rust-by-example/error/iter_result.html">filter and map over a collection of Results</a> 
to a collection of Errors and then return that to the user - this feels
very natural compared to other languages.</p>

<p>Combined with the <a href="https://crates.io/crates/anyhow">anyhow crate</a>, it is easy to provide useful error
messages to the end-user whilst also keeping the code very concise.</p>

<h3 id="serde">Serde</h3>

<p>The <a href="https://crates.io/crates/serde">Serde crate</a> provides traits you can derive on your structs,
allowing for easy serialization and deserialization.</p>

<p>In vopono this is used to serialize and deserialize lockfiles, so that
if you launch a new application in an existing network namespace (via
vopono), the namespace will not be destroyed until <em>both</em> applications
have terminated.</p>

<h3 id="drop">Drop</h3>

<p>The <a href="https://doc.rust-lang.org/std/ops/trait.Drop.html">Drop trait</a> allows us to run a destructor when a struct is
dropped (i.e. goes out of scope). This is used in vopono to
automatically destroy the network namespaces when the application is
closed. I initially got the idea for using <code>Drop</code> this way from the
<a href="https://github.com/r-darwish/alma">ALMA source code</a>.</p>

<p>Note this causes some issues (discussed below) when we want to skip
destructors in some cases. Also if vopono is instantly terminated (i.e.
<code>kill -9</code>) these will likely not run, so vopono is written to clean up
any orphaned resources when it is executed - i.e. namespaces or
lockfiles with no running applications.</p>

<h3 id="cargo">Cargo</h3>

<p>The Cargo package manager itself is a great benefit of using Rust. For
example, when writing vopono it made it trivial to add the
<a href="https://crates.io/crates/compound_duration">compound_duration</a> crate,
used only for reporting the uptime of running network namespaces.</p>

<p>The specification of the software license in the <code>Cargo.toml</code> file is
also a great feature, making it easy to verify that your dependencies
have compatible licenses.</p>

<h3 id="include_str-macro">include_str macro</h3>

<p>The <a href="https://doc.rust-lang.org/std/macro.include_str.html">include_str macro</a> can be used to include a file on disk as a
static string in the binary at compile time. This is used in vopono for
providers where we cannot download certain files by other means e.g.
with TigerVPN because the configuration details are behind a login with
a captcha and there is no API.</p>

<h3 id="rustls">Rustls</h3>

<p><a href="https://crates.io/crates/rustls">Rustls</a> is a TLS library which can be
used in place of OpenSSL. This is used in the <code>vopono sync</code> command,
which gets provider configuration files.</p>

<p>This subcommand relies on the <a href="https://crates.io/crates/reqwest">reqwest crate</a>
to make HTTPS requests, but we want to avoid depending on OpenSSL to make it easier to
build a statically linked binary that will be independent of the runtime
environment. Fortunately we only need to set the “rustls” feature flag
in the reqwest dependency.</p>

<h3 id="musl-and-static-linking">musl and static linking</h3>

<p>The <code>x86_64-unknown-linux-musl</code> target can be used to (cross-)compile,
<a href="https://blog.rust-lang.org/2016/05/13/rustup.html">statically linking with musl</a> instead of dynamically linking to glibc
(the default target). This means we can deploy the resulting binary
without worrying about glibc version mismatches (if we deploy to a
platform with an earlier version of glibc).</p>

<h2 id="difficulties">Difficulties</h2>

<h3 id="small-standard-library">Small standard library</h3>

<p>If you come from scripting languages, you may find that Rust has a
smaller standard library compared to those languages. For example, there
is no recursive copy (<code>cp -r</code> equivalent) in the standard library
directly, and I had to do this using the 
<a href="https://crates.io/crates/walkdir">walkdir crate</a> and copying each item.</p>

<h3 id="compile-times">Compile times</h3>

<p>Rust has longer compile times than most other languages (except perhaps
C++) this is particularly true when using crates which include
procedural macros.</p>

<p>There a few options to <a href="https://vfoley.xyz/rust-compile-speed-tips/">reduce compile times</a>
(also <a href="https://endler.dev/2020/rust-compile-times/">see this more recent post</a>),
such as using <a href="https://github.com/mozilla/sccache">sccache</a> to cache build artifacts.</p>

<h3 id="binary-size-and-feature-creep">Binary size and feature creep</h3>

<p>As more dependencies are added, the final binary size can grow
considerably. To control this, it’s recommended to use <a href="https://doc.rust-lang.org/cargo/reference/features.html">feature flags</a>
in your <code>Cargo.toml</code> file (and disabling default features) to
include only what you need from large dependencies.</p>

<p>You can also use <a href="https://crates.io/crates/cargo-udeps">cargo-udeps</a> to
detect unused dependencies.</p>

<h3 id="minimum-rust-version-and-dependencies">Minimum Rust version and dependencies</h3>

<p>The Rust features and parts of the standard library that you use will
result in an effective minimum Rust version for your project. I had <a href="https://github.com/jamesmcm/vopono/issues/2">one
issue</a> result from the
<a href="https://crates.io/crates/compound_duration">compound_duration crate</a> mentioned above which raised the minimum Rust
version to 1.43.</p>

<p>As far as I know there is no way to automatically determine the minimum
Rust version, although <a href="https://www.reddit.com/r/rust/comments/8kkigi/how_to_find_out_a_minimum_rust_compiler_version/">this discussion on Reddit</a>
has scripts for compiling with many minor versions until you build
successfully.</p>

<h2 id="ongoing-issues">Ongoing issues</h2>

<h3 id="dialoguer-validation-and-passing-references-to-closures">dialoguer validation and passing references to closures</h3>

<p>vopono uses the <a href="https://crates.io/crates/dialoguer">dialoguer crate</a> for user input for the <code>vopono sync</code>
command. I also validate the input using the <code>validate_with()</code> method so
that the user gets feedback immediately and can correct any errors.</p>

<p>However, the <code>validate_with()</code> method <a href="https://docs.rs/dialoguer/0.6.2/dialoguer/struct.Input.html#method.validate_with">requires that the closure used has
a static lifetime</a>.
This is problematic for checking whether the user-entered Wireguard private key
matches the chosen public key, since we need to include the previously-chosen
public key in the closure - but this doesn’t have a static lifetime.</p>

<p>For now I worked around this with extra clones (<a href="https://github.com/jamesmcm/vopono/blob/master/src/providers/mozilla/wireguard.rs#L65">see devices_clone</a>)
but hopefully a better solution is possible. Perhaps the static lifetime
restriction in dialoguer could also be relaxed (since we know the
closure will terminate before we receive the input and continue).</p>

<p>This is <a href="https://github.com/jamesmcm/vopono/issues/19">tracked in this issue</a>. If you have any suggestions please add a comment there!</p>

<h3 id="skipping-destructors">Skipping destructors</h3>

<p>As mentioned previously, vopono uses the <a href="https://doc.rust-lang.org/std/ops/trait.Drop.html">Drop trait</a> to
automatically clean up resources when the relevant structs go out of
scope. However, sometimes we don’t want to trigger these destructors but
still have the structs go out of scope - for example, if we have
multiple vopono processes running applications in the same network
namespace, then we don’t want to destroy the network namespace until the
final application has terminated. So if other lockfiles still exist, we need
to prevent the clean-up destructors from firing.</p>

<p>For now this is done by putting the relevant structs in a Box, and then
calling <code>Box::leak()</code> (<a href="https://doc.rust-lang.org/std/boxed/struct.Box.html#method.leak">docs here</a>).
This works but feels a bit clunky when dealing with multiple structs/fields (e.g. <a href="https://github.com/jamesmcm/vopono/blob/4ebf4b6bdc493c4d95bf6e237136b330723aaf27/src/netns.rs#L308">here preventing the destructors when another vopono instance is using the same namespace</a>):</p>

<div><div><pre><code><span>debug!</span><span>(</span><span>"Skipping destructors since other vopono instance using this namespace!"</span><span>);</span>
<span>let</span> <span>openvpn</span> <span>=</span> <span>self</span><span>.openvpn</span><span>.take</span><span>();</span>
<span>let</span> <span>openvpn</span> <span>=</span> <span>Box</span><span>::</span><span>new</span><span>(</span><span>openvpn</span><span>);</span>
<span>Box</span><span>::</span><span>leak</span><span>(</span><span>openvpn</span><span>);</span>
</code></pre></div></div>

<p>One possible alternative might be to use <a href="https://doc.rust-lang.org/std/mem/struct.ManuallyDrop.html">std::mem::ManuallyDrop</a>
, however then the <code>drop()</code> method is unsafe, so this might end up being
even less ergonomic.</p>

<p>This is tracked <a href="https://github.com/jamesmcm/vopono/issues/20">in this issue</a>.</p>

<h3 id="vpn-providers---enum-or-structs-with-traits">VPN Providers …</h3></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jamesmcm.github.io/blog/2020/09/05/vopono/#en">https://jamesmcm.github.io/blog/2020/09/05/vopono/#en</a></em></p>]]>
            </description>
            <link>https://jamesmcm.github.io/blog/2020/09/05/vopono/#en</link>
            <guid isPermaLink="false">hacker-news-small-sites-24447771</guid>
            <pubDate>Fri, 11 Sep 2020 21:57:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Japanese Spacecraft Will Shoot Martian Moons in 8K Decision]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24447727">thread link</a>) | @tokstesla
<br/>
September 11, 2020 | https://www.newshables.com/2020/09/11/japanese-spacecraft-will-shoot-martian-moons-in-8k-decision/ | <a href="https://web.archive.org/web/*/https://www.newshables.com/2020/09/11/japanese-spacecraft-will-shoot-martian-moons-in-8k-decision/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2873" itemscope="" itemtype="https://schema.org/Article">
        

        

        <div>

        <p><a href="https://www.newshables.com/wp-content/uploads/2020/09/jaxa-spacecraft-film-martian-moons-8k-resolution-768x403.jpg" data-caption=""><img width="696" height="365" src="https://www.newshables.com/wp-content/uploads/2020/09/jaxa-spacecraft-film-martian-moons-8k-resolution-768x403-696x365.jpg" srcset="https://www.newshables.com/wp-content/uploads/2020/09/jaxa-spacecraft-film-martian-moons-8k-resolution-768x403-696x365.jpg 696w, https://www.newshables.com/wp-content/uploads/2020/09/jaxa-spacecraft-film-martian-moons-8k-resolution-768x403-300x157.jpg 300w, https://www.newshables.com/wp-content/uploads/2020/09/jaxa-spacecraft-film-martian-moons-8k-resolution-768x403.jpg 768w" sizes="(max-width: 696px) 100vw, 696px" alt="" title="jaxa-spacecraft-film-martian-moons-8k-resolution-768x403.jpg" data-srcset="https://www.newshables.com/wp-content/uploads/2020/09/jaxa-spacecraft-film-martian-moons-8k-resolution-768x403-696x365.jpg 696w, https://www.newshables.com/wp-content/uploads/2020/09/jaxa-spacecraft-film-martian-moons-8k-resolution-768x403-300x157.jpg 300w, https://www.newshables.com/wp-content/uploads/2020/09/jaxa-spacecraft-film-martian-moons-8k-resolution-768x403.jpg 768w" data-src="https://www.newshables.com/wp-content/uploads/2020/09/jaxa-spacecraft-film-martian-moons-8k-resolution-768x403-696x365.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></a></p>
        
 <!-- A generated by theme --> 



 <!-- end A --> 


<div>
<h2>Mars in 8K</h2>
<p>Along side the Japan Broadcasting Company (NHK), the Japan Aerospace Exploration Company (JAXA) has introduced that it’s planning to <a href="https://phys.org/news/2020-09-martian-moons-exploration-spacecraft-ultra-high.html">photograph Mars’ mysterious moons</a> with cameras that may shoot 8K ultra-high-definition photos.</p>
<p>If profitable, it might be the primary time in historical past Mars and its moons are captured in such element.</p>
<p>To drag it off, the 2 organizations are teaming as much as develop the “Tremendous Hello-Imaginative and prescient Digicam,” designed to be hooked up to JAXA’s Martian Moons eXploration (MMX) spacecraft, which is ready to launch in 2024.</p>
<h2>Phobos Anomaly</h2>
<p>The MMX mission, <a href="https://futurism.com/the-byte/japan-sample-return-mission-mars-moon">greenlit</a> by the Japanese authorities again in February, will try to uncover the mysteries surrounding the origin tales of Mars’s two comparatively tiny moons, Deimos and Phobos. They’re extremely uncommon as they orbit the Purple Planet at extraordinarily shut distances. Deimos’ orbit takes it as shut as <a href="https://solarsystem.nasa.gov/moons/mars-moons/in-depth/">3,700 miles</a> away from the Martian floor — about one p.c of the gap between the Earth and its Moon.</p>
<p>Other than the digital camera, the spacecraft will carry 11 scientific devices to the Martian system. It is going to even try to gather a floor pattern from Phobos’&nbsp;floor earlier than taking the lengthy journey house.</p>
<p>The digital camera will snap ultra-HD photos<strong>&nbsp;</strong>and broadcast them for the world to see, courtesy of JAXA. The untouched recordsdata might be domestically saved on a recording system hooked up to the MMX spacecraft and can hopefully make all of it the way in which again to Earth — if every little thing goes in keeping with plan.</p>
<p><strong>READ MORE: </strong><a href="https://phys.org/news/2020-09-martian-moons-exploration-spacecraft-ultra-high.html">Martian Moons eXploration spacecraft to take ultra-high definition images of Mars via 8K camera</a> [JAXA] <strong><br></strong></p>
<p><strong>Extra on MMX:</strong> <em><a href="https://futurism.com/the-byte/japan-sample-return-mission-mars-moon">Japan Gives the ‘Go’ to Sample Return Mission to Mars Moon</a></em></p>
</div>


 <!-- A generated by theme --> 



 <!-- end A --> 

        </div>


        

    </article></div>]]>
            </description>
            <link>https://www.newshables.com/2020/09/11/japanese-spacecraft-will-shoot-martian-moons-in-8k-decision/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24447727</guid>
            <pubDate>Fri, 11 Sep 2020 21:51:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What's wrong with social science and how to fix it]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 53 (<a href="https://news.ycombinator.com/item?id=24447724">thread link</a>) | @michael_fine
<br/>
September 11, 2020 | https://fantasticanachronism.com/2020/09/11/whats-wrong-with-social-science-and-how-to-fix-it/ | <a href="https://web.archive.org/web/*/https://fantasticanachronism.com/2020/09/11/whats-wrong-with-social-science-and-how-to-fix-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote><p>I've seen things you people wouldn't believe.</p></blockquote><p>Over the past year, I have skimmed through 2578 social science papers, spending about 2.5 minutes on each one. This was due to my participation in <a href="https://www.replicationmarkets.com/" target="_blank" rel="noopener">Replication Markets</a>, a part of DARPA's SCORE program, whose goal is to evaluate the reliability of social science research. 3000 studies were split up into 10 rounds of ~300 studies each. Starting in August 2019, each round consisted of one week of surveys followed by two weeks of market trading. I finished in first place in 3 out 10 survey rounds and 6 out of 10 market rounds. In total, about $200,000 in prize money will be awarded.</p><p>The studies were sourced from all social sciences disciplines (economics, psychology, sociology, management, etc.) and were published between 2009 and 2018 (in other words, most of the sample came from the post-replication crisis era).</p><p>The average replication probability in the market was 54%; while the replication results are not out yet (250 of the 3000 papers will be replicated), previous experiments have shown that prediction markets work well.<span><a href="#fn19282306691" rel="footnote"><sup id="fnref19282306691">1</sup></a></span></p><p>This is what the distribution of my own predictions looks like:<span><a href="#fn19282306692" rel="footnote"><sup id="fnref19282306692">2</sup></a></span></p><p><img src="https://fantasticanachronism.com/images/skimmed_mypredsdist-67f351a8a634ca87ace22fd62155e7c5.png"></p><p>My average forecast was in line with the market. A quarter of the claims were above 76%. And a quarter of them were below 33%: we're talking hundreds upon hundreds of terrible papers, and this is just a tiny sample of the annual academic production.</p><p>Criticizing bad science from an abstract, 10000-foot view is pleasant: you hear about some stuff that doesn't replicate, some methodologies that seem a bit silly. "They should improve their methods", "p-hacking is bad", "we must change the incentives", you declare Zeuslike from your throne in the clouds, and then go on with your day.</p><p>But actually diving into the sea of trash that is social science gives you a more tangible perspective, a more visceral revulsion, and perhaps even a sense of Lovecraftian awe at the sheer magnitude of it all: a vast landfill—a great agglomeration of garbage extending as far as the eye can see, effluvious waves crashing and throwing up a foul foam of p=0.049 papers. As you walk up to the diving platform, the deformed attendant hands you a pair of flippers. Noticing your reticence, he gives a subtle nod as if to say: "come on then, jump in".</p><h2 id="They-Know-What-They-39-re-Doing"><a href="#They-Know-What-They-39-re-Doing" title="They Know What They're Doing"></a>They Know What They're Doing</h2><p>Prediction markets work well because predicting replication is easy.<span><a href="#fn19282306693" rel="footnote"><sup id="fnref19282306693">3</sup></a></span> There's no need for a deep dive into the statistical methodology or a rigorous examination of the data, no need to scrutinize esoteric theories for subtle errors—these papers have obvious, surface-level problems.</p><p>There's a popular belief that weak studies are the result of unconscious biases leading researchers down a "garden of forking paths". Given enough "researcher degrees of freedom" even the most punctilious investigator can be misled.</p><p>I find this belief impossible to accept. The brain is a credulous piece of meat<span><a href="#fn19282306694" rel="footnote"><sup id="fnref19282306694">4</sup></a></span> but there are limits to self-delusion. Most of them have to know. It's understandable to be led down the garden of forking paths while producing the research, but when the paper is done and you give it a final read-over you will surely notice that all you have is a n=23, p=0.049 three-way interaction effect (one of dozens you tested, and with no multiple testing adjustments of course). At that point it takes more than a <em>subtle unconscious bias</em> to believe you have found something real. And even if the authors really are misled by the forking paths, what are the editors and reviewers doing? Are we supposed to believe they are all gullible rubes?</p><p>People within the academy don't want to rock the boat. They still have to attend the conferences, secure the grants, publish in the journals, show up at the faculty meetings: all these things depend on their peers. When criticising bad research it's easier for everyone to blame the forking paths rather than the person walking them. No need for uncomfortable unpleasantries. The fraudster can admit, without much of a hit to their reputation, that indeed they were <em>misled</em> by that <em>dastardly garden</em>, really through no fault of their own whatsoever, at which point their colleagues on twitter will applaud and say "ah, good on you, you handled this tough situation with such exquisite virtue, this is how progress happens! hip, hip, hurrah!" What a ridiculous charade.</p><p>Even when they do accuse someone of wrongdoing they use terms like "Questionable Research Practices" (QRP). How about Questionable Euphemism Practices?</p><ul><li>When they measure a dozen things and only pick their outcome variable at the end, that's not the garden of forking paths but the greenhouse of fraud.</li><li>When they do a correlational analysis but give "policy implications" as if they were doing a causal one, they're not walking around the garden, they're doing the landscaping of forking paths.</li><li>When they take a continuous variable and arbitrarily bin it to do subgroup analysis or when they add an <em>ad hoc</em> quadratic term to their regression, they're...fertilizing the garden of forking paths? (Look, there's only so many horticultural metaphors, ok?)</li></ul><p>The bottom line is this: if a random schmuck with zero domain expertise like me can predict what will replicate, <em>then so can scientists who have spent half their lives studying this stuff</em>. But they sure don't act like it.</p><h2 id="or-Maybe-They-Don-39-t"><a href="#or-Maybe-They-Don-39-t" title="...or Maybe They Don't?"></a>...or Maybe They Don't?</h2><blockquote><p>The horror! The horror!</p></blockquote><p>Check out this crazy chart from <a href="https://www.pnas.org/content/early/2020/04/28/1909046117" target="_blank" rel="noopener">Yang et al. (2020)</a>:</p><p><img src="https://fantasticanachronism.com/images/skimmed_citations-7d4f72c6e9582a5ba8775da70eda80e1.png"></p><p>Yes, you're reading that right: studies that replicate are cited at the same rate as studies that do not. Publishing your own weak papers is one thing, but citing other people's weak papers? This seemed implausible, so I decided to do my own analysis with a sample of 250 articles from the Replication Markets project. The correlation between citations per year and (market-estimated) probability of replication was -0.05!</p><p>You might hypothesize that the citations of non-replicating papers are negative, but negative citations are extremely rare.<span><a href="#fn19282306695" rel="footnote"><sup id="fnref19282306695">5</sup></a></span> <a href="https://www.pnas.org/content/112/45/13823" target="_blank" rel="noopener">One study</a> puts the rate at 2.4%. Astonishingly, even <em>after retraction</em> the <a href="https://pubmed.ncbi.nlm.nih.gov/18974415/" target="_blank" rel="noopener">vast majority of citations are positive</a>, and those positive citations <a href="https://pubmed.ncbi.nlm.nih.gov/20136577/" target="_blank" rel="noopener">continue for decades after retraction</a>.<span><a href="#fn19282306696" rel="footnote"><sup id="fnref19282306696">6</sup></a></span></p><p>As in all affairs of man, it once again comes down to Hanlon's Razor. Either:</p><ol><li>Malice: they know which results are likely false but cite them anyway.</li><li>or, Stupidity: they can't tell which papers will replicate even though it's quite easy.</li></ol><p>Accepting the first option would require a level of cynicism that even I struggle to muster. But the alternative doesn't seem much better: <em>how can they not know?</em> I, an idiot with no relevant credentials or knowledge, can fairly accurately determine good research from bad, but all the tenured experts can not? How can they not tell <em>which papers are retracted</em>?</p><p>I think the most plausible explanation is that scientists don't read the papers they cite, which I suppose involves both malice <em>and</em> stupidity.<span><a href="#fn19282306697" rel="footnote"><sup id="fnref19282306697">7</sup></a></span> <a href="https://www.gwern.net/Scanners#citogenesis-how-often-do-researchers-not-read-the-papers-they-cite" target="_blank" rel="noopener">Gwern has an write-up on this question</a> citing some ingenious analyses based on the proliferation of misprints: "Simkin &amp; Roychowdhury venture a guess that as many as 80% of authors citing a paper have not actually read the original". Once a paper is out there nobody bothers to check it, even though they know there's a 50-50 chance it's false!</p><p>Whatever the explanation might be, the fact is that the academic system does not allocate citations to true claims.<span><a href="#fn19282306698" rel="footnote"><sup id="fnref19282306698">8</sup></a></span> This is bad not only for the direct effect of basing further research on false results, but also because it distorts the incentives scientists face. If nobody cited weak studies, we wouldn't have so many of them. Rewarding impact without regard for the truth inevitably leads to disaster.</p><h2 id="There-Are-No-Journals-With-Strict-Quality-Standards"><a href="#There-Are-No-Journals-With-Strict-Quality-Standards" title="There Are No Journals With Strict Quality Standards"></a>There Are No Journals With Strict Quality Standards</h2><p>Naïvely you might expect that the top-ranking journals would be full of studies that are highly likely to replicate, and the low-ranking journals would be full of p&lt;0.1 studies based on five undergraduates. Not so! Like citations, journal status and quality are not very well correlated: <a href="https://www.frontiersin.org/articles/10.3389/fnhum.2018.00037/full" target="_blank" rel="noopener">there is no association between statistical power and impact factor</a>, and journals with higher impact factor <a href="https://www.biorxiv.org/content/10.1101/071530v1.full.pdf" target="_blank" rel="noopener">have more papers with erroneous p-values</a>.</p><p>This pattern is repeated in the Replication Markets data. As you can see in the chart below, there's no relationship between h-index (a measure of impact) and average expected replication rates. There's also no relationship between h-index and expected replication <em>within</em> fields.</p><p><img src="https://fantasticanachronism.com/images/skimmed_journalhindex-34ca20d3877248fe6b7313c3e2d39fae.png"></p><p>Even the <em>crème de la crème</em> of economics journals barely manage a ⅔ expected replication rate. 1 in 5 articles in QJE scores below 50%, and this is a journal that accepts just 1 out of every 30 submissions. Perhaps this (partially) explains why scientists are undiscerning: journal reputation acts as a cloak for bad research. It would be fun to test this idea empirically.</p><p>Here you can see the distribution of replication estimates for every journal in the RM sample:</p><p><img src="https://fantasticanachronism.com/images/skimmed_journals-cdc1139ad4faf1819b8b42db914dbe81.png"></p><p>As far as I can tell, for most journals the question of whether the results in a paper are true is a matter of secondary importance. If we model journals as wanting to maximize "impact", then this is hardly surprising: as we saw above, citation counts are unrelated to truth. If scientists were more careful about what they cited, then journals would in turn be more careful about what they publish.</p><h2 id="Things-Are-Not-Getting-Better"><a href="#Things-Are-Not-Getting-Better" title="Things Are Not Getting Better"></a>Things Are Not Getting Better</h2><p>Before we got to see any of the actual Replication Markets studies, we voted on the expected replication rates by year. <a href="https://royalsocietypublishing.org/doi/10.1098/rsos.200566" target="_blank" rel="noopener">Gordon et al. (2020)</a> has that data: replication rates were expected to steadily increase from 43% in 2009/2010 to 55% in 2017/2018.</p><p><img src="https://fantasticanachronism.com/images/skimmed_years_pre-7012095f551422f22db31bfffda1c899.png"></p><p>This is what the average predictions looked like <em>after</em> seeing the papers: from 53.4% in 2009 to 55.8% in 2018 (difference not statistically significant; black dots are means).</p><p><img src="https://fantasticanachronism.com/images/skimmed_years-1c0573dfb59a70e36a43deb2692229bf.png"></p><p>I frequently encounter the notion that after the replication crisis hit there was some sort of great improvement in the social sciences, that people wouldn't even dream of publishing studies based on 23 undergraduates any more (I actually saw plenty of those), etc. Stuart Ritchie's new book praises …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fantasticanachronism.com/2020/09/11/whats-wrong-with-social-science-and-how-to-fix-it/">https://fantasticanachronism.com/2020/09/11/whats-wrong-with-social-science-and-how-to-fix-it/</a></em></p>]]>
            </description>
            <link>https://fantasticanachronism.com/2020/09/11/whats-wrong-with-social-science-and-how-to-fix-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24447724</guid>
            <pubDate>Fri, 11 Sep 2020 21:51:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hybrid Hyperoptimization: The most ambitious crossover event in autodiff history]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24447719">thread link</a>) | @hardmath123
<br/>
September 11, 2020 | https://hardmath123.github.io/hybrid-hyperoptimization.html | <a href="https://web.archive.org/web/*/https://hardmath123.github.io/hybrid-hyperoptimization.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="postcontent">
            <section>
                
                <center><em><p>The most ambitious crossover event in automatic differentiation history</p>
</em></center>
                <h4>Friday, September 11, 2020 · 4 min read</h4>
<blockquote>
<p> Summary of this post: It turns out that by carefully mixing forward-mode and
 reverse-mode automatic differentiation, you can greatly simplify certain
 hyperparameter optimization algorithms.</p>
</blockquote>
<p>Here’s a fun recursive idea: just like how we optimize the parameters of
machine learning models by gradient descent, we can also their
<em>hyperparameters</em> by gradient descent. This is by no means a new idea; you can
find 20-year-old papers that discuss (for example) optimizing gradient descent
step sizes by gradient descent itself.</p>
<p>Broadly, there are two ways to do this. The “short-term” way is to take a
<em>single</em>  step of gradient descent, and then based on how that goes, adjust the
hyperparameters. That’s the premise of the 2018 paper <a href="https://arxiv.org/abs/1703.04782">Online Learning Rate
Adaptation with Hypergradient Descent</a>: it
turns out that you can do this in an extremely lightweight way. You would hope
that over time the hyperparameters converge to something optimal alongside the
parameters (and indeed that is the case, though you have to be careful).</p>
<p>The “long-term” way is to train <em>several</em> steps and <em>then</em> backpropagate
through the <em>entire training</em> to adjust the hyperparameters. The hope is that
this provides a stronger “signal” to the hyperparameter-gradient, which is
better for convergence. But, this comes at the (tremendous) expense of having
to store a copy of the entire computation graph for several steps of training,
and then backpropagate through it. If your model has 1GB of parameters, you
need to store ~1GB worth of numbers for <em>each step</em>. You can imagine that adds
up over the course of many epochs, and so the algorithm is severely limited by
how much RAM you have.</p>
<p>The 2015 paper <a href="https://arxiv.org/abs/1502.03492">Gradient-based Hyperparameter Optimization through Reversible
Learning</a> makes this work by throwing away
the intermediate steps of the computation graph and then JIT-re-computing it
“in reverse” during backpropagation. It’s a clever technique, but kind of hairy
and hard to implement (you have to be super careful about numerical precision).</p>
<p>Here’s a graph that visualizes these two techniques (<a href="https://arxiv.org/abs/1909.13371">from this
paper</a>). You’re looking at several parallel
loss curves (($\log(f)$) is the loss plotted on a log scale), pointing towards
you, arranged in order of the “step size” hyperparameter
(that’s ($\log(\alpha)$)). The orange curve represents a “short-term”
hyperparameter optimization, which is allowed to move along the “step size”
axis at each step. The “long-term” hyperparameter optimization instead
optimizes directly on the thick black dashed “U” — that is, after <em>several</em>
steps of training. You can see how the latter is smoother, but also much harder
to compute.</p>
<p><img src="https://hardmath123.github.io/static/hybrid-hyperoptimization/fig-metasurface.png" alt="The preceding paragraph explains this
figure."></p>
<p>To summarize: the short-term way is cheap but noisy. The long-term way is
expensive but less noisy. Can we get the best of both worlds?</p>
<hr>
<p>Well, let’s think more carefully about the source of the expense. The problem
is that we need to store (or be able to reconstruct) the full computation graph
in order to do backpropagation. Okay, but do we really <em>need</em> to do
backpropagation? The only reason we backpropagate is that it’s more efficient
in the case when you want derivatives with respect to <em>many</em> different
variables. If you have millions of model parameters, backpropagation is
millions of times faster than the much simpler <a href="https://en.wikipedia.org/wiki/Automatic_differentiation#Automatic_differentiation_using_dual_numbers">forward-mode (“dual numbers”)
automatic
differentiation</a>.</p>
<p>But we <em>don’t</em> have millions of <em>hyperparameters!</em> Step size, for example, is
just a single number. The Adam optimizer only has a total of 4 hyperparameters.
With this in mind, backpropagation isn’t even the right choice — we <em>should</em>
be using dual numbers for the hyperparameter optimization. On the other hand,
we should still be using backpropagation for the “inner loop” that optimizes
the (non-hyper-) parameters. That is, we want to do something like this:</p>
<pre><code>initialize hyperparameters
# loop to optimize hyperparameters
while True:
  initialize parameters
  # loop to optimize parameters
  for i in range(100):
    run model on data to get loss
    # using reverse-mode!
    compute d(loss) / d(parameters)
    update parameters using hyperparameters
  # using forward-mode
  compute d(loss) / d(hyperparameters)
  update hyperparameters
</code></pre>
<blockquote>
<p>(Update: I discovered that this was suggested in the 2017 paper <a href="https://arxiv.org/abs/1703.01785">Forward and
Reverse Gradient-Based Hyperparameter
Optimization</a>. But keep reading — while
the paper’s
<a href="https://github.com/lucfra/FAR-HO/blob/master/far_ho/hyper_gradients.py#L375">implementation</a>
needs a lot of math to be worked out manually, I’m going to show you how to
implement this in a way that makes all the math in the paper fall out “for
free”…)</p>
</blockquote>
<p>This proposal raises a logistical question: how do we reconcile these two
automatic differentiation algorithms in the same program? <strong>The “trick” is to
“thread” dual numbers through a backpropagation implementation.</strong> In other
words, implement backpropagation as usual, but rather than <code>float</code> type
numbers, exclusively use <code>dual_number</code> type numbers (even when doing derivative
calculations). Initialize the system such that the dual numbers track
derivatives with respect to the hyperparameters you care about. Then, your
final loss value’s attached ($\epsilon$)-value <em>immediately</em> gives you
<code>d(loss)/d(hyperparameters)</code>. No backpropagation needed — and so, it’s safe
to “forget” the computation graph.</p>
<p>That’s it! That’s all I wanted to share in this blog post! :)</p>
<p>Of course, it’s not obvious how to implement this in PyTorch, since you can’t
naïvely do <code>tensor(dtype=dual_number)</code>. Rather than hack in a custom numeric
data type that implemented dual numbers, I wrote my own tiny implementations of
forward- and reverse-mode automatic differentiation. It’s just a couple dozen
(very-recognizable-to-automatic-differentiation-enthusiasts) lines of code. I
was careful to make each implementation generic in the kind of “number” it
accepts. That allowed me to run the reverse-mode algorithms using the
forward-mode data types.</p>
<p>Running it on a simple quadratic optimization problem, we can see that updating
the hyperparameter ($\alpha$) yields better-looking loss curves — in this
GIF, we’re discovering that we should increase the step size. Yay!</p>
<p><img src="https://hardmath123.github.io/static/hybrid-hyperoptimization/loss.gif" alt="GIF of loss curve becoming better over
time"></p>
<p>I think this is a very neat trick, which surely has other cool applications
(for example, differentiating through long-running physics simulations!). If
you’re curious, check out this <a href="https://hardmath123.github.io/static/hybrid-hyperoptimization/hybrid-hyperoptimization.ipynb">IPython
notebook</a> for
the full source code. Feel free to adapt it to your ideas. Then, tell me what
you’ve built!</p>

            </section>

            

        </article></div>]]>
            </description>
            <link>https://hardmath123.github.io/hybrid-hyperoptimization.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24447719</guid>
            <pubDate>Fri, 11 Sep 2020 21:50:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Team Agreements]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24447282">thread link</a>) | @infinitybeyond
<br/>
September 11, 2020 | https://tylerjefford.com/blog/team-agreements | <a href="https://web.archive.org/web/*/https://tylerjefford.com/blog/team-agreements">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <p>If you have the luxury of starting a new team, or evolving a team overtime, you might want to try collaborating with the team on a working agreement. I call these Team Agreements, or Team Charters. </p>

<p>I've used these in many teams over the years and it can make a huge difference, especially when things get hard. I will outline some things I like to add and the guidelines I set up during the inception, but each team is going to be different and the more you learn about each other, the better the conversation is going to be. Not everything in this post will work for you. That's OK.</p>

<h2>Set the tone</h2>
<p>Sometimes teammates don't want to open up with each other about things that bother them. This is especially true if it’s a new team with a mix of new and old employees to the company. </p>

<p>Set the tone by explaining what the agreement is and what it is not. As a team, we want to work better without stepping on each other. We want to be productive and efficient and we want to give and receive feedback in a manner that doesn’t feel like a pile on.</p>

<p>This isn't meant to be a checklist, a document to consult to get someone in trouble or a rule of law to consult in a high court of the agile tribunal. We are all human with our own feelings, experiences and bad days. Lets make it easy and open to be able to talk to each other about what kind of environment we want to work in.</p>

<p>Its good to add this to the meeting agenda and lead with at the top of the meeting. I’ve learned how it’s refreshing to see this type of meeting especially for those who have never worked in a setting where their voice matters, or the voices of their teammates. </p>

<p>Pause a moment and ask for questions. Let people feel it out, poke at the goal and make sure everyone is on the same page for the task at hand.</p>

<h2>Notes</h2>
<p>A theme in a lot of my blog posts, take notes. Take a lot of notes. It's alright to distill down the working agreement after the meeting. But take a bunch of notes and add names to them as much as you can. You might find it useful to revisit what someone has said. </p>

<p>I usually keep a shared doc open on the screen for the whole team to see what I’m writing down and to ask if I captured the essence of what they are talking through. </p>

<p>Once you are done with the meeting, its also important to share this document out with the team and allow everyone to read and comment on the notes. Maybe someone had a specific example they wanted to add, or a clarification to an item logged during the meeting they thought of later.</p>

<h2>Team Rules</h2>
<p>I break down the session into two primary sections. The first is about the team rules. This is how individuals want to be treated, things they bother them and actions they hate and love to see working in a team. This might be difficult for some, especially if some of you’re team hasn't worked in a larger team before. </p>

<p>I usually keep a couple things in my pocket for if this part starts a bit rough. My number one thing <code>Assume Good Intent</code> in all interactions, always. It’s very rare to have someone work with you that is intentionally trying to sabotage your progress.</p>

<p>These team rules can literally be anything and I hope you write them all down, too. You might gain some insights into people you didn’t already know.</p>

<p>I've had teams making rules about bringing smelly food into the enclosed team rooms, being onetime to all meetings (this will come up in the next section), how we close out standup every morning and how to address difficult feedback. </p>

<p>This is going to be very unique to your team at the time you write these down. Its also going to evolve and you should hold sync ups about these agreements when major changes happen to your team. </p>

<h2>Expectations</h2>
<p>The next section I focus on is exceptions. This is for the individuals on the team to ensure a happy team for the individual. :confused-face:</p>

<p>Here again I have a few items in my pocket to throw out if things are slow to start. Being on time to meetings is something I try very hard to do. I want us to start on time, and end on time. I want everyone to have their voice heard and to not rush to end the meeting because we’re over time. So I task everyone to try to be on time to all meetings, not for them, but for the team. </p>

<p>I again address the respecting each other and the pillar of assuming good intent. This is super important for me and for the team. It also shines outward in the interactions with other teams. Everyone has a different way of working and that’s great. As long as we know and respect each others boundaries.</p>

<p>Here we also try to define the meetings, the time frames and the expectations of work as a team we agree to. In some cases that is swarming on the testable column to get tickets out the door, other times it might be how and when to call out a risk, how to bring feedback to a process and the process of changing our processes.</p>

<p>I have found this section to be driven a little closer by the manager of the team. Setting a clear guard rail for the team to self regulate and to be on time for each other. </p>

<h2>Documentation</h2>
<p>Once you have all this great information and its distilled down into a clear and readable list of rules and items we all agree on, its time to document this in a highly visible area. Most companies have a wiki or intranet where you can have your own team pages. This is the perfect place to put it.</p>

<p>It's public for your team to see, to watch and monitor for edits. Other teams can see it and know how to best interact with you and your team. It also isn’t chiseled into stone and can be revised along the way. </p>

<p>When you document the agreement and put it up in a public space, make sure you pass that link to every nook and cranny of the team. We have our team wiki as a fast link on our Jira sidebar, in the team slack channel and I routinely post it for the team to view. Get the message out, this is how our team is working and how we treat each other. </p>

<h2>Conclusion</h2>
<p>I highly recommend setting up a team working agreement no matter the situation you find yourself in. This can be the difference between a team that is good and a team that is great. A team that knows where each others boundaries are and a team that is transparent and open to talk about the things that work well and not so well.</p>
  </div></div>]]>
            </description>
            <link>https://tylerjefford.com/blog/team-agreements</link>
            <guid isPermaLink="false">hacker-news-small-sites-24447282</guid>
            <pubDate>Fri, 11 Sep 2020 21:01:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The technical interview is an ego trip]]>
            </title>
            <description>
<![CDATA[
Score 148 | Comments 168 (<a href="https://news.ycombinator.com/item?id=24447182">thread link</a>) | @kowsheek
<br/>
September 11, 2020 | https://blog.kowsheek.com/the-technical-interview-is-an-ego-trip/ | <a href="https://web.archive.org/web/*/https://blog.kowsheek.com/the-technical-interview-is-an-ego-trip/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>Early in my career, after a short initial interview at a consulting firm in Toronto, I was invited to a technical interview on the same day. Two of the senior developers from the team I would join would conduct the interview.</p><p>The interview started pleasantly with them describing the project they have been working on: a portal for university professors to communicate with their students. It was being built with ASP.NET MVC, a framework I had been working with for several years. I expressed that I was comfortable with the framework and I would be excited to work on the project. Then the technical examination began and on its conclusion I left the interview feeling humiliated.</p><p>Many years later, when I was preparing to take an interview, I looked back on this experience to realize that the line of questioning and approach had been an ego trip for those developers. I promised myself to <em>never</em> make any of my candidates feel the way I did.</p><p>What did those developers do wrong? Leaving aside their attitude towards me, their questions had no relevance to the role or the project. I did not know what a red-black tree was at the time but I definitely knew how to use ASP.NET MVC which they did not inquire about.</p><p>My golden rule for technical interviews is that, "Every step, conversation and question <em>must</em> be pertinent to the day-to-day of the role." While this may be obvious, I am sure that many hiring managers are still expecting candidates to arrive at technical interviews with Computer Science books memorized. This form of technical interviews should be made obsolete.</p><figure><blockquote><p lang="en" dir="ltr">Bigger button = more clicks on the CTA <a href="https://t.co/Ter7xJdNKM">pic.twitter.com/Ter7xJdNKM</a></p>— Vincent Déniel (@vincentdnl) <a href="https://twitter.com/vincentdnl/status/1291041278264713220?ref_src=twsrc%5Etfw">August 5, 2020</a></blockquote>

</figure><p>With my golden rule as guide, I conduct a much simpler interview process. Prior to an interview, my team and I review samples of code that the candidate shared with us (or had written on Github) to understand the quality of their code. And during the interview, I dive into three areas of discussions with the candidates: product building, process adherence and team work.</p><h3 id="product-building">Product Building</h3><p>I try to understand the candidate's interest and experience of building products by,</p><ol><li>Going through their past experience and asking about what technologies and products they built and how. I ask about previous products they have shipped from concept to market.</li><li>To understand their thought process for deriving solutions, I draw an UI and ask them to outline and explain what approaches, structures and technologies they would use to build it out.</li><li>I ask about how they keep up with technologies and how they improve their skills to gauge their passion for the work.</li></ol><h3 id="process-adherence">Process Adherence</h3><p>To better understand how the candidate does their work,</p><ol><li>I go over their experiences and ask about how they managed their product-building and what tools and processes they used.</li><li>I explain the process of working on our team and ask how they would change it and where they see inefficiencies to discuss their thinking.</li><li>Often, I will give them a scenario where the processes are failing the team to find what they would do to tackle inefficiencies and if they would be willing to speak up.</li></ol><h3 id="team-work">Team Work</h3><p>I also try to understand how a candidate works in a team,</p><ol><li>While going through their past experiences, I ask about how they collaborated and communicated with their teams.</li><li>I present a scenario where their knowledge in an area may be lacking and evaluate if and how they would leverage and collaborate with their team.</li><li>Another scenario I ask about is where they disagree with their team-members to evaluate how they manage conflict and focus on delivering results for the team.</li></ol><p>I do this within one interview to be mindful of the candidate's time and mine. I want to hire candidates for their will to learn, grow and challenge the status quo.</p><p>The technology landscape is such that anyone can acquire a set of baseline programming skills. What is needed then, is a willingness to challenge ourselves and stay open-minded because every developer will have to learn on the job almost all of the time. Given this, the technical interview is arcane, academic and as good as dead.</p><hr><h3 id="further-reading">Further Reading</h3><ol><li><a href="https://news.ncsu.edu/2020/07/tech-job-interviews-anxiety/">Tech Sector Job Interviews Assess Anxiety, Not Software Skills</a></li><li><a href="https://medium.com/helpful-com/https-medium-com-fnthawar-helpful-technical-interviews-are-garbage-dc5d9aee5acd">Technical interviews are garbage. Here’s what we do instead</a></li><li><a href="https://remotesynthesis.com/blog/whats-wrong-with-tech-interviews">What's Wrong with the Tech Interview Process?</a></li></ol>
                </div>
            </section>

                <section>
    <h3>Subscribe to blog.kowsheek</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.kowsheek.com/the-technical-interview-is-an-ego-trip/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24447182</guid>
            <pubDate>Fri, 11 Sep 2020 20:47:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Introduction to Data Oriented Design with Rust]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24447023">thread link</a>) | @byproxy
<br/>
September 11, 2020 | https://jamesmcm.github.io/blog/2020/07/25/intro-dod/ | <a href="https://web.archive.org/web/*/https://jamesmcm.github.io/blog/2020/07/25/intro-dod/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In the post we will investigate the main concepts of <a href="https://en.wikipedia.org/wiki/Data-oriented_design">Data-oriented
Design</a> using Rust.</p>

<p>The source code for this example is <a href="https://github.com/jamesmcm/data-oriented-example">available on Github</a>.</p>

<!--more-->

<h2 id="what-is-data-oriented-design">What is data-oriented design?</h2>

<p>Data-oriented design is an approach to optimising programs by carefully
considering the memory layout of data structures, and their implications
for auto-vectorisation and use of the CPU cache. I highly recommend
watching Mike Acton’s <a href="https://www.youtube.com/watch?v=rX0ItVEVjHc">“Data-Oriented Design and C++”</a> talk
if you haven’t seen it already.</p>

<p>In this post we will cover 4 cases, using <a href="https://docs.rs/criterion/0.3.3/criterion/">criterion</a> for
benchmarking. The cases are:</p>

<ul>
  <li>Struct of arrays vs. array of structs</li>
  <li>The cost of branching inside a hot loop</li>
  <li>Linked List vs. Vector iteration</li>
  <li>The cost of dynamic dispatch vs. monomorphisation</li>
</ul>

<h2 id="struct-of-arrays-vs-array-of-structs">Struct of Arrays vs. Array of Structs</h2>

<p>The <a href="https://en.wikipedia.org/wiki/AoS_and_SoA">Struct of Arrays vs. Array of Structs</a> 
refers to two contrasting ways of organising entity data to be operated
over.</p>

<p>For example, imagine we are writing a video game and we would like to
have a Player struct with the following fields:</p>

<div><div><pre><code><span>pub</span> <span>struct</span> <span>Player</span> <span>{</span>
    <span>name</span><span>:</span> <span>String</span><span>,</span>
    <span>health</span><span>:</span> <span>f64</span><span>,</span>
    <span>location</span><span>:</span> <span>(</span><span>f64</span><span>,</span> <span>f64</span><span>),</span>
    <span>velocity</span><span>:</span> <span>(</span><span>f64</span><span>,</span> <span>f64</span><span>),</span>
    <span>acceleration</span><span>:</span> <span>(</span><span>f64</span><span>,</span> <span>f64</span><span>),</span>
<span>}</span>
</code></pre></div></div>

<p>Then at each frame, we want to update the locations and velocities of all
Players. We could write something like:</p>

<div><div><pre><code><span>pub</span> <span>fn</span> <span>run_oop</span><span>(</span><span>players</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Vec</span><span>&lt;</span><span>Player</span><span>&gt;</span><span>)</span> <span>{</span>
    <span>for</span> <span>player</span> <span>in</span> <span>players</span><span>.iter_mut</span><span>()</span> <span>{</span>
        <span>player</span><span>.location</span> <span>=</span> <span>(</span>
            <span>player</span><span>.location</span><span>.</span><span>0</span> <span>+</span> <span>player</span><span>.velocity</span><span>.</span><span>0</span><span>,</span>
            <span>player</span><span>.location</span><span>.</span><span>1</span> <span>+</span> <span>player</span><span>.velocity</span><span>.</span><span>1</span><span>,</span>
        <span>);</span>
        <span>player</span><span>.velocity</span> <span>=</span> <span>(</span>
            <span>player</span><span>.velocity</span><span>.</span><span>0</span> <span>+</span> <span>player</span><span>.acceleration</span><span>.</span><span>0</span><span>,</span>
            <span>player</span><span>.velocity</span><span>.</span><span>1</span> <span>+</span> <span>player</span><span>.acceleration</span><span>.</span><span>1</span><span>,</span>
        <span>);</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This would be the usual object-oriented approach to this problem. The
issue here is that in memory the structs are stored as follows (assuming
no field re-ordering i.e. <code>#[repr(C)]</code>), on a 64-bit architecture each field will be 64
bits (8 bytes, so each Player is 64 bytes):</p>

<div><div><pre><code>-- Vec&lt;Player&gt;
name  (pointer to heap)  -- Player 1
health    
location0  (tuple split for clarity) 
location1
velocity0
velocity1
acceleration0
acceleration1
name  (pointer to heap)  -- Player 2
location0    
location1
velocity0
velocity1
acceleration0
acceleration1
...
</code></pre></div></div>

<p>Note the parts we want to operate on (locations, velocities and
accelerations) are not stored contiguously across different Players.
This prevents us from using vector operations to operate on multiple
players at once (since they cannot be loaded in the same CPU cache
line, usually ~64 bytes).</p>

<p>In contrast, the data-oriented approach is to design around this
limitation and optimise for auto-vectorisation. Instead of using a
struct per Player, we now use one struct for all Players and each Player
has their values stored at their index in the separate attribute Vectors:</p>

<div><div><pre><code><span>pub</span> <span>struct</span> <span>DOPlayers</span> <span>{</span>
    <span>names</span><span>:</span> <span>Vec</span><span>&lt;</span><span>String</span><span>&gt;</span><span>,</span>
    <span>health</span><span>:</span> <span>Vec</span><span>&lt;</span><span>f64</span><span>&gt;</span><span>,</span>
    <span>locations</span><span>:</span> <span>Vec</span><span>&lt;</span><span>(</span><span>f64</span><span>,</span> <span>f64</span><span>)</span><span>&gt;</span><span>,</span>
    <span>velocities</span><span>:</span> <span>Vec</span><span>&lt;</span><span>(</span><span>f64</span><span>,</span> <span>f64</span><span>)</span><span>&gt;</span><span>,</span>
    <span>acceleration</span><span>:</span> <span>Vec</span><span>&lt;</span><span>(</span><span>f64</span><span>,</span> <span>f64</span><span>)</span><span>&gt;</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>Now we can do the same calculation as in the OOP case as follows:</p>

<div><div><pre><code><span>pub</span> <span>fn</span> <span>run_dop</span><span>(</span><span>world</span><span>:</span> <span>&amp;</span><span>mut</span> <span>DOPlayers</span><span>)</span> <span>{</span>
    <span>for</span> <span>(</span><span>pos</span><span>,</span> <span>(</span><span>vel</span><span>,</span> <span>acc</span><span>))</span> <span>in</span> <span>world</span>
        <span>.locations</span>
        <span>.iter_mut</span><span>()</span>
        <span>.zip</span><span>(</span><span>world</span><span>.velocities</span><span>.iter_mut</span><span>()</span><span>.zip</span><span>(</span><span>world</span><span>.acceleration</span><span>.iter</span><span>()))</span>
    <span>{</span>
        <span>*</span><span>pos</span> <span>=</span> <span>(</span><span>pos</span><span>.</span><span>0</span> <span>+</span> <span>vel</span><span>.</span><span>0</span><span>,</span> <span>pos</span><span>.</span><span>1</span> <span>+</span> <span>vel</span><span>.</span><span>1</span><span>);</span>
        <span>*</span><span>vel</span> <span>=</span> <span>(</span><span>vel</span><span>.</span><span>0</span> <span>+</span> <span>acc</span><span>.</span><span>0</span><span>,</span> <span>vel</span><span>.</span><span>1</span> <span>+</span> <span>acc</span><span>.</span><span>1</span><span>);</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>In this case the memory layout is as follows:</p>
<div><div><pre><code>-- DOPlayers
name1    -- names
name2
...
health1    -- health
health2
...
location1    -- locations
location2
...
</code></pre></div></div>

<p>The relevant fields are now stored contiguously. Given that each
location tuple will be 16 bytes, we could now feasibly load 4 location
tuples on the same cache line to operate on them simultaneously with
SIMD instructions.</p>

<h3 id="benchmark">Benchmark</h3>

<p>Here are the results of the criterion benchmark for the above code (the
full code and benchmark code is available <a href="https://github.com/jamesmcm/data-oriented-example">in the Github repo</a>):</p>

<p><img src="https://jamesmcm.github.io/images/soa.svg" alt="AoS vs. SoA benchmark" title="AoS vs. SoA benchmark"></p>

<p>Overall, we see that the data-oriented approach finishes in half the
time. This would seem to be due to the data-oriented case operating on
two Players at a time - we can confirm this by reviewing the compiled
assembly.</p>

<p>Reviewing the <a href="https://godbolt.org/z/d8bjMb">output on Godbolt</a> we see the following:</p>

<pre><code>// Relevant OOP loop
.LBB0_2:
        movupd  xmm0, xmmword ptr [rax + rdx + 32]
        movupd  xmm1, xmmword ptr [rax + rdx + 48]
        movupd  xmm2, xmmword ptr [rax + rdx + 64]
        addpd   xmm0, xmm1
        movupd  xmmword ptr [rax + rdx + 32], xmm0
        addpd   xmm2, xmm1
        movupd  xmmword ptr [rax + rdx + 48], xmm2
        add     rdx, 80
        cmp     rcx, rdx
        jne     .LBB0_2

// ...
// Relevant DOP loop
.LBB1_7:
        movupd  xmm0, xmmword ptr [rcx + rdx - 16]
        movupd  xmm1, xmmword ptr [rax + rdx - 16]
        addpd   xmm1, xmm0
        movupd  xmmword ptr [rcx + rdx - 16], xmm1
        movupd  xmm0, xmmword ptr [r9 + rdx - 16]
        movupd  xmm1, xmmword ptr [rax + rdx - 16]
        addpd   xmm1, xmm0
        movupd  xmm0, xmmword ptr [rax + rdx]
        movupd  xmmword ptr [rax + rdx - 16], xmm1
        add     rdi, 2
        movupd  xmm1, xmmword ptr [rcx + rdx]
        addpd   xmm1, xmm0
        movupd  xmmword ptr [rcx + rdx], xmm1
        movupd  xmm0, xmmword ptr [rax + rdx]
        movupd  xmm1, xmmword ptr [r9 + rdx]
        addpd   xmm1, xmm0
        movupd  xmmword ptr [rax + rdx], xmm1
        add     rdx, 32
        cmp     rsi, rdi
        jne     .LBB1_7
        test    r8, r8
        je      .LBB1_5
</code></pre>

<p>We can see in the data-oriented case, the loop is unrolled to operate on
two elements at once - resulting in the 50% speed up overall!</p>

<p><strong>Addendum</strong>: As noted by <a href="https://www.reddit.com/r/rust/comments/hxqwom/an_introduction_to_data_oriented_design_with_rust/fz8lxcq/">/u/five9a2 on Reddit</a>
the above output is specifically for the default target, which is
misleading since <code>cargo bench</code> uses the native target by default (i.e.
all possible features on your CPU), so our benchmarks are not using the
above assembly code.</p>

<p>By setting the compiler flag to <code>-C target-cpu=skylake-avx512</code> to enable 
Skylake features, we get the <a href="https://godbolt.org/z/PEPdvn">following output</a>:</p>

<pre><code>// OOP loop
.LBB0_2:
        vmovupd ymm0, ymmword ptr [rax + rdx + 32]
        vaddpd  ymm0, ymm0, ymmword ptr [rax + rdx + 48]
        vmovupd ymmword ptr [rax + rdx + 32], ymm0
        add     rdx, 80
        cmp     rcx, rdx
        jne     .LBB0_2

...
// DOP loop
.LBB1_19:
        vmovupd zmm0, zmmword ptr [rsi + 4*rax - 64]
        vaddpd  zmm0, zmm0, zmmword ptr [rcx + 4*rax - 64]
        vmovupd zmmword ptr [rsi + 4*rax - 64], zmm0
        vmovupd zmm0, zmmword ptr [rcx + 4*rax - 64]
        vaddpd  zmm0, zmm0, zmmword ptr [r10 + 4*rax - 64]
        vmovupd zmmword ptr [rcx + 4*rax - 64], zmm0
        vmovupd zmm0, zmmword ptr [rsi + 4*rax]
        vaddpd  zmm0, zmm0, zmmword ptr [rcx + 4*rax]
        vmovupd zmmword ptr [rsi + 4*rax], zmm0
        vmovupd zmm0, zmmword ptr [rcx + 4*rax]
        vaddpd  zmm0, zmm0, zmmword ptr [r10 + 4*rax]
        vmovupd zmmword ptr [rcx + 4*rax], zmm0
        add     r11, 8
        add     rax, 32
        add     rdi, 2
        jne     .LBB1_19
        test    r9, r9
        je      .LBB1_22
</code></pre>

<p>Here we see the OOP loop making use of the 256-bit ymm registers for the
position tuple and velocity tuple, and another for the velocity tuple
and acceleration tuple. This is possible because they are adjacent in
memory (due to the ordering of the fields). In the DOP loop,
the 512-bit zmm register is used.</p>

<p>It seems the performance differences comes from the bandwidth between
cache levels, since the performance is identical for the small examples.
This can be demonstrated further by removing the extra fields from the
struct - in this case we see only a 25% performance difference (<a href="https://godbolt.org/z/Th91Wa">godbolt
link</a>), and this
corresponds to Player struct now being 384 bits (and so 1/4 of the
512-bit read/write is unused).</p>

<p>This emphasises how important it is to consider your deployment target,
and if deploying performance-sensitive code, to consider setting the
target-cpu explicitly to benefit from all of its features.</p>

<p>It also demonstrates how the ordering of fields can be important to
performance. By default Rust will re-order fields automatically, but you can set
<code>#[repr(C)]</code> to disable this (necessary for C interoperability for
example).</p>

<h3 id="summary">Summary</h3>

<p>This example demonstrates the importance of considering memory layout
when aiming for performant code and auto-vectorisation.</p>

<p>Note that the same logic can also apply when working with arrays of
structs - making your struct smaller will allow you to load more
elements on the same cache line and possibly lead to autovectorisation.
<a href="https://github.com/Rene-007/flake_growth/blob/master/src/helpers.rs">Here is an example</a> of
a crate (which was shared on the <a href="https://www.reddit.com/r/rust/comments/hmqjvs/growing_gold_with_rust/">Rust subreddit</a>) that achieved a 40% performance
improvement by doing just that.</p>

<p>This particular re-organisation has a direct analogue in database design. A
major difference between databases aimed at transactional (OLTP)
workloads and analytical (OLAP) workloads is that the latter tend to use
columnar-based storage. Just like the case above, this means that
operations on one column can take advantage of the contiguous storage
and use vector operations, which tends to be the main access pattern for
analytical workloads (e.g. calculate the average purchase size across all rows,
rather than updating and retrieving entire, specific rows).</p>

<p>In the case of analytical databases this is actually a double win, since it also
applies to the serialisation of the data to disk, where compression can
now be applied along the column (where the data is guaranteed to be of the
same type) leading to much better compression ratios.</p>

<p>If you are working on a problem that might benefit from the struct of
arrays approach, and want to run a quick benchmark, you might be
interested in the <a href="https://github.com/lumol-org/soa-derive">soa-derive</a>
crate that will allow you to derive the struct of arrays from your
struct.</p>

<h2 id="branching-in-a-hot-loop">Branching in a hot loop</h2>

<p>Another optimisation tactic is to avoid branching in any “hot” parts of
the code (i.e. any part that will be executed many, many times).</p>

<p>Branching can arise in subtle ways, often by trying to use one struct for many
different cases. For example, we might define some general Node type …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jamesmcm.github.io/blog/2020/07/25/intro-dod/">https://jamesmcm.github.io/blog/2020/07/25/intro-dod/</a></em></p>]]>
            </description>
            <link>https://jamesmcm.github.io/blog/2020/07/25/intro-dod/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24447023</guid>
            <pubDate>Fri, 11 Sep 2020 20:30:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RemNote – great note-taking app nobody is talking about]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24446851">thread link</a>) | @kalimatas
<br/>
September 11, 2020 | https://guzalexander.com/2020/09/11/notes-apps-fatigue.html | <a href="https://web.archive.org/web/*/https://guzalexander.com/2020/09/11/notes-apps-fatigue.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
		

		<section>
			<section>
				<article>
	
	<p>I have been using Evernote for quite some years now as my go-to application for 
notes, bookmarks, sketches, etc. Indeed, it is not a bad choice: clients for all platforms
you can imagine, synchronization between devices, good enough editor with formatting,
typical hierarchical notes organization into notebooks and sub-notebooks, tags, sharing
options, etc. I even had a paid version in order to have synchronization on more than two
devices. And still, I have never felt that I have been using all its potential.</p>

<div>
	<figure>
		
			<a href="https://guzalexander.com/static/img/posts/notes_evernote.png" target="_blank"><img src="https://guzalexander.com/static/img/posts/notes_evernote.png" alt="Evernote for macOS"></a>
		
	</figure>
</div>

<figcaption>Evernote for macOS</figcaption>

<p>Eventually, I realized that my notes were lying “dead“ there. Like a pile of useless crap.
Basically, once something got into Evernote, I just forgot about it. And, probably, never
open this note again, except for some edge cases. These notes were not helping me.</p>

<p>Then I stumbled upon <a href="https://roamresearch.com/">Roam Research</a> – the app on hype now. It had invitation system,
so I could only check out the <a href="https://roamresearch.com/#/app/help/page/k5RxbGuJN">demo page</a>.
But it was not the tool itself that made me switch from Evernote. By watching tutorials,
and reading articles about Roam I grasped the idea of a second brain, a personal
knowledge base. This is where it all clicked – my Evernote notes are junk, because they
are not connected to each other. Yes, I have a notebook “Programming“, but notes inside this 
notebook are just separate pieces with no relation to each other whatsoever. These 
relations exist only in my head. And my head has only so much free space to hold all 
this stuff.</p>

<div>
	<figure>
		
			<a href="https://guzalexander.com/static/img/posts/notes_roam.png" target="_blank"><img src="https://guzalexander.com/static/img/posts/notes_roam.png" alt="Roam Research"></a>
		
	</figure>
</div>

<figcaption>Roam Research</figcaption>

<p>The essential part that is missing in Evernote in comparison to, let’s say the same Roam
Research, is linking of the notes. One can argue, that Evernote has notes links. But 
functionality- and comfort-wise they are a joke. Imagine, you are writing a note about 
new sorting algorithm, and now you want to link some phrase to the big-O notation note. 
You have to: 
	1. Find big-O note (potentially in another notebook).
	2. Then right click and find an option to copy the note link.
	3. Then go back to the place where you want to place the link and
	4. Finally, paste it.
I almost died from boredom by just explaining this procedure. By the time you finish it,
you have already lost any thought train you had.</p>

<p>Just to have a link inside a note to another note is not enough, though. Another powerful
concept is back linking. Imagine, you are looking at a note, and you can immediately see 
if any other note refers to it. You might have linked it from another place without putting
too much thought, but in the end you created a new association that can create a new idea.
Pretty cool. Some apps go further and even provide so called “non-referenced“ links, i.e.
they show other notes that reference just the title of the current note as a text.</p>

<p>I was hooked and decided to switch. But first, I needed to find <strong>the perfect</strong> application,
of course. Roam Research is too expensive. I mean, I am glad to spend $15/month for an 
app, if I know that this is a game changer. But not from the day one. So I started my
research. Oh boy, just look at <strong><a href="https://www.notion.so/db13644f08144495ad9877f217a161a1?v=ff6777802811416ba08dc114e0b11837">this huge list</a></strong> of 85 note-taking applications! I think I have 
looked almost through all of them, and fooled around with at least 15 or so.</p>

<p>The most worthy of mention are <a href="https://obsidian.md/">Obsidian</a>, <a href="https://foambubble.github.io/foam/">Foam</a>, <a href="https://www.notion.so/">Notion</a>, and
my favorite so far – <strong><a href="https://www.remnote.io/">RemNote</a></strong>.</p>

<div>
	<figure>
		
			<a href="https://guzalexander.com/static/img/posts/notes_obsidian.png" target="_blank"><img src="https://guzalexander.com/static/img/posts/notes_obsidian.png" alt="Obsidian. Stores notes in Markdown locally."></a>
		
	</figure>
</div>

<figcaption>Obsidian. Stores notes in Markdown locally.</figcaption>

<p>RemNote is great. It is free. It is packed with features. It is ugly. Well, to be 
fair it was ugly until the recent upgrade a few days ago. Now it is a bit better. But I
like the spirit. Started to use it on a daily basis. Cancelled my Evernote subscription. 
It is a long way for RemNote to become great, though. What they currently lack is media
promotion. This is a great application nobody is talking about! Everybody talks 
only about Roam Research.</p>

<div>
	<figure>
		
			<a href="https://guzalexander.com/static/img/posts/notes_remnote.png" target="_blank"><img src="https://guzalexander.com/static/img/posts/notes_remnote.png" alt="RemNote tutorial page"></a>
		
	</figure>
</div>

<figcaption>RemNote tutorial page</figcaption>

<p>So did I just find a perfect tool for me? I am not sure, to be honest. RemNote has a bunch 
of downsides. For example, lack of a desktop application that is huge minus for me, since
I hate doing serious work in a browser window. I also have some concerns about the future
of the app: there is no business behind, and I cannot tell for sure how serious the authors
are about continuing working on it. I definitely don’t want to lose all my notes in two years or so.</p>

<p>And let’s not forget, that there are other players on the market. There are so many options!
Having so much variety might seem like a good thing in the first place, but it leads to
<a href="https://en.wikipedia.org/wiki/Decision_fatigue">decision fatigue</a>. I really just want
to have the work done, to have my brain organized and get the most out of my notes. I 
don’t want to spend endless hours on choosing <strong>the</strong> right tool.</p>

<p>Maybe I should just switch to <a href="https://www.williamhern.com/living-in-a-single-text-file.html">one</a>
<a href="https://jeffhuang.com/productivity_text_file/">text file</a> or <a href="https://orgmode.org/">Org mode</a>?</p>


</article>
<time>September 11, 2020</time>

			</section>

			
			
			
			
			

			
		</section>
	</section></div>]]>
            </description>
            <link>https://guzalexander.com/2020/09/11/notes-apps-fatigue.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24446851</guid>
            <pubDate>Fri, 11 Sep 2020 20:13:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Brian Kernighan on the typesetting of “The Go Programming Language” book (2016)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24446793">thread link</a>) | @smartmic
<br/>
September 11, 2020 | https://rkrishnan.org/posts/2016-03-07-how-is-gopl-typeset.html | <a href="https://web.archive.org/web/*/https://rkrishnan.org/posts/2016-03-07-how-is-gopl-typeset.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            

            <p>
    Posted on 2016-03-07
    
        <span>golang, typesetting, unix</span>
    
</p>

<p>A while ago, I bought the book “<a href="http://gopl.io/">The Go Programming Language</a>” written by Alan Donovan and Brian Kernighan. I have always been a fan of Brian Kernighan’s writings. I should admit that I bought the book mainly for his great examples and writings than for the Go language itself, but since then have got interested in the Go Language, after starting to read the book.</p>
<p>Perhaps every programmer knows Brian Kernighan as the “K” in the famous K&amp;R book. He has also written a bunch of other great books, most of them are on my shelf, including some which are out of print. My other favourites are “Software tools” book and the “AWK programming language” book. Brian is also the “K” in “AWK” language.</p>
<p>Sure enough, the book does not disappoint at all. The way the language features are described and the “story” developed is something every programming language book author could try to emulate. One of the features of Prof.&nbsp;Kernighan’s books is that the first chapter is a tour of the language features and gives a good taste of the syntax of the language, leaving the readers with enough knowledge to mess around with the language and start writing complete programs.</p>
<p>The thing that stood out the most in my eyes was the outstanding quality of the type setting. Everything seemed just right.</p>
<p>Some (or most?) readers take typesetting of the programming books very seriously. There is this joke of Donald Knuth taking a break from the TAOCP book project to “invent” the TeX typesetting system.</p>
<p>One of the early goofups in typesetting is also incidentally in the K&amp;R Book, written by Brian Kernighan, brought to my attention by my friend and colleague, <a href="http://olvemaudal.com/">Olve Maudal</a>. A number of readers of the K&amp;R C 2nd edition book believed that pointers and arrays are the same, due to the non-optimal pagination.</p>
<figure>
<img src="https://rkrishnan.org/images/kandr-c-99-100.png" title="Page 99 and Page 100 of K&amp;R C 2nd edition" alt=""><figcaption>Page 99 and Page 100 of K&amp;R C 2nd edition</figcaption>
</figure>
<p>Okay, that aside, I emailed Prof.&nbsp;Kernighan about the tools he used to type set the book. There is a brief mention about it in the copyright page. But that didn’t satisfy me much. Here is what I wrote, on 28th Feb, 2016:</p>
<pre><code> Dear Prof. Kernighan,
 
 The Go programming language book is so beautifully typeset. To my eyes,
 it is more beautiful than those LaTeX based ones. But that's just my
 perception..
 
 Could you please say a few things about how your writing flow was and
 how you type set the book? I see the tools used in the copyright page.
 
 Thanks
 --
  Ramakrishnan</code></pre>
<p>The reply came a few hours later on the same day. Reproduced here with permission from Prof.&nbsp;Kernighan.</p>
<pre><code> Hi, Ramakrishnan --
 
 Thanks for the kind words on the typography.  The core formatting
 is just troff (groff, really) with the -ms macro package.  We
 tried Latex briefly but neither Alan or I care for its output, and
 I personally find it impossible to control.  Troff is the devil I
 know -- it's ugly and irregular in many ways but it will put
 characters where you want them.
 
 The input was in XML, with a tag set of about 25 items for
 headings, paragraphs, index terms, program insertion, simple
 tables, and the like.  A Go program converted this either into
 HTML for rapid viewing on the screen and potentially for an e-book
 version, or into troff for printing.  Using XML was a mild
 nuisance when writing but the error checking was very helpful.
 
 We wrote a variety of small Go programs and scripts to fix things
 up, including one that rewrites troff output to do vertical
 justification so all pages are the same height.  There is also
 some fiddling with the generated postscript to put on printer's
 marks.
 
 The fonts are Alan's choice, the result of a lot of work on his
 part to find them and get the right sizes and appearances.  The
 handful of Asian characters were tough to get right; troff doesn't
 do wide Unicode characters properly, and there are a few places
 where we rewrote text to hide that fact.
 
 The drawings are all Alan's work, using Google's drawing program.
 We toyed briefly with using pic but it wasn't really up to the
 job, and it would not have worked with HTML without a lot of work.
 We avoided mathematics beyond superscripts, and the tables are
 pretty limited; eqn and tbl would have been ok but again would not
 have dealt with HTML.
 
 We should probably write a more organized description of what we
 did and make the tools available, though I think most readers are
 less interested in the process than you (and I) are.  The other
 thing is that although one starts with grand ideas of being clean
 and orderly, by the end the process is somewhat of a mess, with
 a complicated makefile to keep it running.
 
 Thanks again for writing.
 
 Brian</code></pre>
<p>The last sentence certainly holds true for just about any project, as far as my experience goes.</p>
<pre><code>"...although one starts with grand ideas of being clean
 and orderly, by the end the process is somewhat of a mess, with
 a complicated makefile to keep it running."</code></pre>
<p>In a subsequent email, Prof.&nbsp;Kernighan added that the problem with Unicode was not much of an input problem and was because of troubles getting suitable fonts for actual printing.</p>

        </div></div>]]>
            </description>
            <link>https://rkrishnan.org/posts/2016-03-07-how-is-gopl-typeset.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24446793</guid>
            <pubDate>Fri, 11 Sep 2020 20:07:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CI/CD for Angular Projects with Firebase and GitHub]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24446764">thread link</a>) | @danielbarta
<br/>
September 11, 2020 | https://danielbarta.com/cd-github-firebase/ | <a href="https://web.archive.org/web/*/https://danielbarta.com/cd-github-firebase/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<figure><img src="https://danielbarta.com/content/images/2020/09/1_l9vYpzZm1lKwm4Zz5q23gw.jpeg"><figcaption><a href="https://medium.com/@jhinter/github-actions-build-and-deploy-your-web-app-using-ci-cd-and-firebase-within-minutes-51e8d4c2ebc4">Source of image</a></figcaption></figure><p><a href="https://danielbarta.com/set-up-dev-and-prod-environment-in-firebase/">In a previous post</a>, we managed to set up different environments for development and production, with the same crucial settings for both projects, but there is one concern left. At this point, we need to manually deploy to the development or production project. Firstly, we can easily forget to deploy. Secondly, we might accidentally deploy to the wrong project. If for some reason, the concept of Continous Integration and Continous Delivery is new, it is perfectly summed up by <a href="https://fireship.io/contributors/jeff-delaney/">Jeff Delaney</a> in under 2 minutes.</p><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/scEDHsr3APg?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>We can utilize GitHub Actions to automatically deploy on every push. We want to have an automatic build and deployment for production every time we push something.</p><p>In our repository's <code>/.github/workflows</code> folder, create a file called <code>deploy@master.yml</code>. The script below does exactly what we want to do on the master:</p><ul><li>Creates a Ubuntu VM</li><li>Sets up Node on it</li><li>Retrieves dependencies from the cache, if it is possible</li><li>Install the project's dependencies</li><li>Runs unit tests</li><li>Builds the project</li><li>Deploys it to Firebase, both to my master and dev environment</li></ul><figure><pre><code>name: deploy@master
on:
    push:
        branches:
            - master
jobs:
    main:
        name: Test, Build and Deploy
        runs-on: ubuntu-latest
        steps:
            - name: Check out code
              uses: actions/checkout@v2

            - name: Node ${{ matrix.node-version }}
              uses: actions/setup-node@v2.1.1
              with:
                  node-version: ${{ matrix.node-version }}

            - name: Cache node modules
              uses: actions/cache@v2.1.1
              env:
                  cache-name: cache-node-modules
              with:
                  # npm cache files are stored in `~/.npm` on Linux/macOS
                  path: ~/.npm
                  key: ${{ runner.os }}-build-${{ env.cache-name }}-${{ hashFiles('**/package-lock.json') }}
                  restore-keys: |
                      ${{ runner.os }}-build-${{ env.cache-name }}-
                      ${{ runner.os }}-build-
                      ${{ runner.os }}-

            - name: Install npm dependencies
              run: |
                  cd functions
                  npm install
                  cd ..
                  npm install

            - name: Run tests
              run: npm run test

            - name: Build production
              run: npm run build:prod

            - name: Deploy to Firebase@master
              uses: w9jds/firebase-action@v1.5.0
              with:
                  args: deploy --only storage,firestore,functions
              env:
                  FIREBASE_TOKEN: ${{ secrets.FIREBASE_TOKEN }}
                  PROJECT_ID: todo

            - name: Deploy to Firebase@dev
              uses: w9jds/firebase-action@v1.5.0
              with:
                  args: deploy
              env:
                  FIREBASE_TOKEN: ${{ secrets.FIREBASE_TOKEN }}
                  PROJECT_ID: todo-dev
</code></pre><figcaption>deploy.yml</figcaption></figure><p>The first steps are best explained by the official <a href="https://docs.github.com/en/actions/configuring-and-managing-workflows/configuring-a-workflow">GitHub Docs</a>. Caching and installing npm dependencies are also well explained <a href="https://docs.github.com/en/actions/configuring-and-managing-workflows/caching-dependencies-to-speed-up-workflows">there</a>. To make that work, we must set up a secret in the repo named <code>FIREBASE_TOKEN</code>, where the value is the token we get when we sign in from the CLI using <code>firebase login:ci</code>. The <code>PROJECT_ID</code> must match the project name in Firebase.</p><figure><img src="https://danielbarta.com/content/images/2020/09/githubcd.PNG"><figcaption>A successful run using already cached npm dependencies</figcaption></figure><h2 id="summary">Summary</h2><p>We have implemented CD support for our Angular&amp;Firebase project. We enhanced CI by failing as soon as possible using automated tests. To further improve, it might be a good idea to run tests on pull requests too. To do that, we only need to change the trigger at the beginning of the file from <code>push</code> to <code>pull_request</code>, remove the last three steps, and put this into a separate YAML file. </p>
			</section></div>]]>
            </description>
            <link>https://danielbarta.com/cd-github-firebase/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24446764</guid>
            <pubDate>Fri, 11 Sep 2020 20:04:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The first major sign your web host will not respect you]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24446756">thread link</a>) | @puggo
<br/>
September 11, 2020 | https://hawaiigentech.com/post/commentary/sign-your-webhost-does-not-respect-you/ | <a href="https://web.archive.org/web/*/https://hawaiigentech.com/post/commentary/sign-your-webhost-does-not-respect-you/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <hr>
<p><img src="https://hawaiigentech.com/post/commentary/sign-your-webhost-does-not-respect-you/an-unethical-salesman.jpg" alt="The First Major Sign Your Web Host Will Not Respect You"></p>
<hr>
<h2 id="when-a-relationship-starts-with-an-act-of-dishonesty-or-manipulation-it-will-be-a-toxic-relationship"><em>When a relationship starts with an act of dishonesty or manipulation, it will be a toxic relationship</em>.</h2>
<p>This is common knowledge.</p>
<p>Most major web hosting companies groom potential customers in manipulative ways, but, sadly, many do not recognize the trouble signs due to naivety or need.</p>
<p>Here is one important, but common cue that your webhost-to-be will not respect you, and you are in for a compromising, dysfunctional relationship.</p>
<h2 id="but-you-said-395-a-month-">But you said 3.95 a month… :(</h2>
<h3 id="the-solicitation">The Solicitation</h3>
<p><img src="https://hawaiigentech.com/post/commentary/sign-your-webhost-does-not-respect-you/do-you-really-mean-it.jpg" alt="Do you really mean it?"></p>
<p><a href="https://web.archive.org/web/20200911190002/https://www.bluehost.com/">https://web.archive.org/web/20200911190002/https://www.bluehost.com/</a></p>
<p>In the ad above, this average young woman has just been approached by what could be the prince-charming of webhosts, bluehost himself. She is excited and flattered that she could have him for the price of $3.50 a month.</p>
<p>Enticed, she takes the bait.</p>
<h3 id="getting-into-the-car">Getting into the Car</h3>
<p><img src="https://hawaiigentech.com/post/commentary/sign-your-webhost-does-not-respect-you/do-you-really-mean-it-2.jpg" alt="Is it too good to be true?"></p>
<p><a href="https://web.archive.org/web/20200910194510if_/https://www.bluehost.com/hosting/shared#pricing-cards">https://web.archive.org/web/20200910194510if_/https://www.bluehost.com/hosting/shared#pricing-cards</a></p>
<p>Now the young lady is excited, because although it seemed too good to be true, it looks like this might just be true love. $3.95 a month! Things are finally looking up.</p>
<h3 id="taking-the-ride">Taking the Ride</h3>
<p>After some flirty initial conversation of what her domain name will be, our prince charming bluehost finally gets down to his intentions.</p>
<p>He says, <strong>“So let’s talk about that $178.08…"</strong></p>
<p>And her heart sinks…</p>
<p><img src="https://hawaiigentech.com/post/commentary/sign-your-webhost-does-not-respect-you/get-your-hands-off-me.jpg" alt="Get your hands off me!"></p>
<p>And now we’ve quickly arrived at that part of the relationship known as <em><strong>“Get your hands off me!"</strong></em>.</p>
<hr>
<h2 id="17808-for-3-years-is-not-395-a-month">$178.08 for 3 Years is Not $3.95 a Month</h2>
<p>One might argue that if you divide the numbers over 3 years, it evens out to the price stated: $3.95.</p>
<p>But that’s <em>not</em> $3.95 a month.</p>
<p>That <em>is</em> $178.08 for three years.</p>
<p>If it was $3.95 a month, I could pay $3.95 for the first month, $3.95 for the second… $3.95 for the third … etc.</p>
<p>It was lie, a manipulation, a sign.</p>
<h3 id="my-wedding-ring-costs-less-per-month-every-year">My wedding ring costs less per month every year…</h3>
<p>So by this logic, a $1000 wedding ring costs $1.66 dollars a month after 50 years of marriage. Assuming there is no divorce.</p>
<h3 id="but-if-you-say-yes">But if you say yes…</h3>
<p>Sadly, some people will ignore the first alarm signs of the toxic relationship, and convince themselves that they did not just get manipulated.</p>
<p>Sadly, that “deal” is lost in a short time due to common upsells inherent to hosts such as this.  Because if you don’t say “get your hands off me” you enable future exploits, and the web host knows this. He’s good at what he does.</p>
<h3 id="prince-charming-is-a-dime-a-dozen">Prince Charming is a Dime a Dozen</h3>
<p>Despite how unique and valuable this prince charming purports to be, there is a street full of them coming from every alley way.</p>
<p>Most major cheap hosting companies operate this way.</p>
<p>Don’t give up your standards and settle. The good hosts are hard to find, because they don’t hang out in the main traffic areas of society/internet.</p>
<hr>

    </div></div>]]>
            </description>
            <link>https://hawaiigentech.com/post/commentary/sign-your-webhost-does-not-respect-you/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24446756</guid>
            <pubDate>Fri, 11 Sep 2020 20:03:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PandaDoc Employees Arrested in Belarus After Founders Protest Against Violence]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24446695">thread link</a>) | @maxan
<br/>
September 11, 2020 | https://savebelarusit.org/en/ | <a href="https://web.archive.org/web/*/https://savebelarusit.org/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p>Friends,</p>
          <p>On&nbsp;September 2, the Belarus government ordered searches to&nbsp;be&nbsp;conducted at&nbsp;the Minsk office of&nbsp;PandaDoc. During the search, more than 20 employees were prevented from leaving and 7 of&nbsp;them were taken into custody and detained for further interrogation. Some of&nbsp;these employees were subsequently taken into custody from their homes.</p>
          <p>Over the next two days, the Financial Investigation Department (FID) arm of&nbsp;the Belarus government interviewed more than one hundred company employees. During those two days, the employees that had been taken into custody were also denied the rights to&nbsp;legal counsel.</p>
          <p>Today, on&nbsp;September 4, 2020 we&nbsp;were told that a&nbsp;criminal case was retroactively initiated against PandaDoc employees under part 4 of&nbsp;article 210 of&nbsp;the Criminal Code of&nbsp;the Republic of&nbsp;Belarus. Our employees are accused of&nbsp;taking one hundred and seven thousand Belarusian rubles (~40k USD) from the corporate accounts of&nbsp;the company in&nbsp;Minsk abusing their positions, thus causing damage to&nbsp;the&nbsp;State. As&nbsp;a&nbsp;result, our employees have now been placed into custody for two months.</p>
          <p>We&nbsp;declare that this accusation by&nbsp;the State of&nbsp;Belarus is&nbsp;completely untrue and has no&nbsp;grounds.</p>
          <p>All the company’s activities in&nbsp;Belarus were conducted since its inception in&nbsp;full compliance with the&nbsp;law. Several international audits and inspections by&nbsp;EY&nbsp;and other reputable companies over the last years prove that the company adhered to&nbsp;all regulations and laws prevalent in&nbsp;Belarus.</p>
          <p>As&nbsp;recent events in&nbsp;Belarus have demonstrated, it&nbsp;is&nbsp;a&nbsp;common practice of&nbsp;the Belarusian government to&nbsp;oppress political opponents. In&nbsp;this case, the authorities have taken four completely innocent people hostage.</p>
          <p>This action is&nbsp;purely an&nbsp;act of&nbsp;repression against the founders of&nbsp;PandaDoc who have been supporting some of&nbsp;the victims of&nbsp;the Belarussian government in&nbsp;the weeks since the stolen Presidential election. The only purpose of&nbsp;this private initiative by&nbsp;Mikita and Sergey has been intended to&nbsp;help stop the violence and is&nbsp;in&nbsp;no&nbsp;way related to&nbsp;PandaDoc.</p>
          <p>In&nbsp;response the government has imprisoned:</p>
          <ul>
            <li><strong>Yulia Shardyko</strong>, Accountant</li>
            <li><strong>Dmitry Rabtsevich</strong>, Director - Minsk office</li>
            <li><strong>Viktar Kuushynau</strong>, Product Director</li>
            <li><strong>Vladislav Mikholap</strong>, HR</li>
          </ul>
          <p>The law in&nbsp;Belarus has ceased to&nbsp;exist. The authorities do&nbsp;not even bother to&nbsp;act according to&nbsp;the prevailing rules and laws of&nbsp;the country. The case and charges are fabricated cases upon political orders ordered from somewhere in&nbsp;the government. This affects everyone in&nbsp;Belarus.</p>
          <h2>We&nbsp;ask of&nbsp;you:</h2>
          <ol>
            <li>Record a&nbsp;video in&nbsp;our support with the tag <strong>#SavePandaDoc</strong>.</li>
            <li>To&nbsp;express your disagreement in&nbsp;the press, media and social networks with the <strong>#SavePandaDoc</strong> tag.</li>
            <li>Connect us&nbsp;to&nbsp;journalists and reporters that you&nbsp;know. Our contact is&nbsp;<a href="mailto:savepandadoc@gmail.com">savepandadoc@gmail.com</a>.</li>
          </ol>
          <p>We&nbsp;are hoping that maximum publicity will show solidarity and pressure to&nbsp;have our colleagues released.</p>
          <p>—&nbsp;Pandas</p>
        </div></div>]]>
            </description>
            <link>https://savebelarusit.org/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24446695</guid>
            <pubDate>Fri, 11 Sep 2020 19:57:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The NBC Chimes Machine (1999)]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24446569">thread link</a>) | @tintinnabula
<br/>
September 11, 2020 | http://www.theradiohistorian.org/chimes.htm | <a href="https://web.archive.org/web/*/http://www.theradiohistorian.org/chimes.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<center>
<h3><b> <span size="6">T</span><span size="4">HE </span><span size="6">NBC C</span><span size="4">HIMES</span><span size="6">M</span><span size="4">ACHINE<br></span>
Copyright 1999, John F. Schneider </b></h3></center>
<hr><p>



The sound of the NBC chimes is the sound of radio history itself.  Probably no single sound better recalls 
the golden age of radio.  The NBC chimes – the musical notes G-E-C – were played at the end of every 
NBC radio program beginning shortly after the network's inception, and continued in daily use on NBC radio and television 
until 1971. </p><p>
&nbsp;Shortly after the formation of the National Broadcasting Company
in 1926, network executives became aware of confusion among the
affiliate stations as to the exact when a program ended, and when it
was safe to cut away for local announcements. The problem was assigned
to a committee of three: Oscar B. Hanson, NBC's Director of Engineer
and a former AT&amp;T engineer; Earnest la Prada, an NBC orchestra
leader; and Phillips Carlin, an NBC announcer. They decided that a
musical signal of some kind would be an appropriate way to indicate the
ending of all programs. At that time, it was common for radio stations
to use the sounds of chimes, gongs, sirens and other mechanical devices
as a signature sound for their station, so the choice of a chime by NBC
was not unusual or particularly innovative. There is in fact some
evidence that the chimes may have been inspired by a similar chime
sequence used at that time by NBC affiliate WSB in Atlanta. </p><p>

During 1927 and 1928, the committee experimented with several combinations of notes.  A seven-note 
sequence which was first used, G-C-F-E-G-C-E, was determined to be too complicated for the announcers to 
play correctly on a consistent basis.  It was first simplified to G-C-F-E, and finally to just G-E-C.  This familiar 
sequence was heard for the first time on November 29, 1929.</p><p>

The chimes were sounded at :29:30 and :59:30 of each hour, to indicate the start 
of the 30 second local station break. They were initially struck by hand by the 
announcer, using a set of hand-held chimes held up to the microphone.<span face="Times New Roman">
</span>
<span>
But, there were inconsistencies in the chimes' tempo, volume, and exact timing.&nbsp; </span>
<span face="Times New Roman">&nbsp;I</span>t was finally determined that the 
best way to solve these problems was for the chimes to be generated 
mechanically.</p><center>
<img alt="Chimes Machine Schematic" src="http://www.theradiohistorian.org/chimach.gif" height="480" width="430"><p>&nbsp;<img alt="Chimes Machine" src="http://www.theradiohistorian.org/chimes2b.jpg" height="480" width="640"></p>
<p>&gt;
</p></center>

The man who designed the chimes machine was 
Captain Richard H. Ranger, who was also the inventor of the electronic organ and the RCA facsimile.  
Ranger created a device resembling a music box, where fingers on a revolving drum plucked a set of reeds.  
There were three sets of eight reeds, one for each note, allowing the generation of the fundamental note 
plus several overtones.   Each reed formed one plate of a capacitor in an oscillator circuit, and the signal 
generated by all reeds was amplified by a single 6C6 pentode tube.  It was activated by a timer,
which would cut off the program two seconds before its end (whether it was finished or 
not!) and feed the chimes to the network. <p>

NBC built a limited number of chime machines. NBC in San Francisco  had two of them - the main and backup 
machines.  Others were installed ain other cities around the country where network programs were originated 
– Los Angeles, Chicago, New York, and perhaps a few others.  It is likely that not more than a dozen chimes 
machines were ever made. </p><center>
<img alt="Chimes Machine Inside View" src="http://www.theradiohistorian.org/chimes5b.jpg"><p>&nbsp;<img alt="Chimes Machine Name Tag" src="http://www.theradiohistorian.org/chimes7b.jpg" height="349" width="512"></p>
</center>

The photos on this page show one of the few chime machines still in existence, now in the hands of a private 
collector.  (NBC had the short-sighted habit of discarding large quantities of historical artifacts throughout 
its history.  It's only through the far-sightedness of a few NBC employees, who saved some of these items 
from the trash bins, that we can today experience many recorded programs, photos, and other memorabilia from 
that era.)
<p>

&nbsp;The unit shown is the chimes machine serial number 2, probably from the first group ever made.   Its mechanical 
parts, although finely crafted, appear to have been hand made.  This unit is no doubt the original chimes machine 
placed in operation at NBC's studios at 111 Sutter Street in San Francisco.  The schematic diagram, 
also shown, indicates that serial number 5 was fabricated in 1933, so this machine would have 
predated it.  The main cabinet contains the motor drive reed mechanism and amplifier, which is accessed by  
removing the front panel's four thumbscrews.  The unit operated from an external power source, no doubt the same 
battery and motor generator system that operated the audio amplifiers in the studios.   The smaller box 
contains the timer and switches that operate the chimes for both studio and "NEMO" broadcast lines.  
("NEMO" was a term used in early radio to indicate a remote broadcast.  It comes from a telephone term, 
and stands for "Not Emanating Main Office".)  The chime machine could be operated in an automatic mode by 
the clock, which was the usual method of operation, or manually by the announcer in the event of programs 
with imprecise ending times, such as sports broadcasts. 
</p><center>
<img alt="Chimes Machine Timer" src="http://www.theradiohistorian.org/chimes4b.jpg" height="458" width="640"></center>

&nbsp;<p>The NBC chimes were officially registered with the U.S. Patent Office in 1950 as a registered service mark, the first 
known case of a sound receiving trademark protection.  They were last heard regularly on NBC 
television in 1976, used to mark the 50th anniversary of the network. </p>

<hr>
<div>
  
  <p>Here is a remembrance of the NBC 
  Chimes Machine from Rick Greenhut - February 3, 2013:</p>
  
  <p>
  <span>John,</span></p></div>

<p>
<span>Just saw your 
page on the Bay Area Radio Museum dedicated to the NBC chimes machine, and I 
wanted to give you another historical fact to add. In 1969 when I went to work 
as a summer replacement engineer (board op) at NBC-owned WKYC Cleveland, there 
was still a chimes machine back in the racks. Since all the O&amp;O's originated 
programs like NOTH (New On The Hour) and Monitor inserts, they all had 2 chimes 
machines. Besides WNBC/New York, WMAQ/Chicago and KNBR/San Francisco, 
WKYC/Cleveland and WRC/Washington also had chimes machines.</span></p>

<p>
  <span>By the next 
  summer I worked there, the chimes machine was gone - whether thrown away or 
  taken home by one of the old-timers, I couldn't say.</span></p>

<p>
  <span>Last bit of 
  radio trivia: I was doing Affiliate Relations for the NBC Radio Network in 
  August of 1987, and during the NABET engineers strike those of us in 
  management with technical backgrounds were taking shifts running the board for 
  the NOTH and manning the ROD (Radio Operations Desk) in Radio Central (network 
  master control). I was the first management person on the board when the 
  engineers walked out at 6:00 AM that morning, and engineered the 6, 7, 8 and 9 
  AM NOTH (the talent was Gary Nunn, now heard on the CBS Radio Network). At 
  8:30 that morning I was told by the General Manager, Craig Simon, that the 
  network had been sold to Westwood One, and that the chimes were not part of 
  the sale, so I was forbidden to play them at the end of the newscast like we 
  usually did.</span></p>

<p>
  <span>I ignored 
  him, and "chimed out" at the end of the 9:00 AM newscast as per usual. He came 
  up to the studio a few minutes later with a funny smile on his face, and told 
  me to make sure no one else did that. I made sure by taking the chimes cart 
  and backup out of the studio. I bulked the backup, and have the last remaining 
  cart with the NBC chimes (recorded directly from the WNBC chimes machine) in 
  my collection.</span></p>

<p>
  <span>I was the 
  last person to play the chimes on the NBC Radio Network.</span></p>
<div>
  <div>
    
    <p>
    <span>Rick<span>&nbsp;</span><span>Greenhut</span></span></p>
    <p>
    <span>Director – 
    U.S. Broadcast Sales<br>
    iBiquity Digital Corporation</span></p>
    </div>
</div>
<hr> <p>

<tt><i>REFERENCES:<br>

A History of the NBC Chimes, by Bill Harris<br>
More on the NBC Chimes, by Brian Wickham<br>
A Backstage Visit to Radio City, by Fred Krock<br>
Author's inspection of a chimes machine in the hands of a private collector</i></tt></p><p>


© Copyright 1999 John F. Schneider.  All rights reserved.  
<br></p><hr>
<center>

</center>
</div>]]>
            </description>
            <link>http://www.theradiohistorian.org/chimes.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24446569</guid>
            <pubDate>Fri, 11 Sep 2020 19:44:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Ballpoint.io]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24446548">thread link</a>) | @artursapek
<br/>
September 11, 2020 | https://ballpoint.io/files/examples/gopher | <a href="https://web.archive.org/web/*/https://ballpoint.io/files/examples/gopher">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://ballpoint.io/files/examples/gopher</link>
            <guid isPermaLink="false">hacker-news-small-sites-24446548</guid>
            <pubDate>Fri, 11 Sep 2020 19:42:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From Vim to Ed]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24446422">thread link</a>) | @_nato_
<br/>
September 11, 2020 | http://blog.cretaria.com/posts/from-vim-to-ed.html | <a href="https://web.archive.org/web/*/http://blog.cretaria.com/posts/from-vim-to-ed.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <header>
                
                <p>Sync’ up! … without getting drained</p>
            </header>
	    <section>
<article>
<p><abbr>sep 11</abbr></p>
<h2>From Vim to Ed</h2>
<p>I switched from Vim to Ed twelve months ago,
and I wanted to report my findings on this
strange downstream adventure I took.</p>

<p>I’d been using Vim since about 1998, and I
hardly got close to mastering it after all those
years. In fact, that was one of the reasons I
thought of trying something like Ed: I was tired
of turning a corner only to find a zillion other
great features Vim offers.</p>

<p>I wanted to use an editor that didn’t have
features that were constantly distracting me
from what’s important: writing code.</p>

<h3>The goods</h3>


<p>Ed had one of the most fantastically steep learning
curves in all my many years of nerding. This ol’
editor was so weird in so many ways, I almost
lost heart right off the bat.</p>

<p>A good deal of the Ed ideas are forgotten
in time.  Nobody uses a line-based editor,
so this was one strange playing field to get
accustomed to.</p>

<p>However, once the learning curve was overcome,
the terseness of what I could do became an asset.</p>

<p>In Vim, there’s a million different ways to
get your cursor to zip all around. One of my
favorites was <code>w</code> where on the line in question,
all in normal mode, I could dart over to my
change in word-step motion.</p>

<p>In Ed, the line in question is right there in
front of you, and all you have is ‘regex’ as
your weapon to swap one thing for another.</p>

<p>You’d be surprised how good one can get via
this sole usage pattern. It’s not all that bad,
and thankfully, some distributions of Ed have
nice little shortcuts to make this all the
less pedantic.</p>

<p>With only a few agilities, Ed limits your usage
to x, y, or z. The result?  You get so darn good
at those.</p>

<p>Another powerful plus for Ed, is its undo/redo
limitation.</p>

<p>Usually, one would think, that after some
hacking, one would want to undo changes that
happened twenty edits ago. In Vim, you’d just
hold down <code>u</code> until it gets to that state. In Ed,
the buffer is limited to one undo. Incredibly,
this limitation has never ruined my day. Because
of my for-knowledge that Ed can’t undo twenty
edits ago, my approach on edits has been
‘Edified,’ and my behavior is in sync with this
one undo world.</p>

<p>I don’t pop open Vim ever, except to run a spell
check on something that isn’t code (like this
blog post, for example). Fascinating to me:
one of the side effects of Ed is my spelling
got a lot better. I’m more careful about what
I type, as the pain to undo or edit things is
quite real. Go figure!</p>

<h3>The bads</h3>


<p>Vim offers so much, it’s hard to
compare Ed to something this feature-rich. So,
I won’t.</p>

<p>Rather, I’ll just jot down some of my Ed-related
gripes.</p>

<p>First, one can scroll forward a page via <code>z</code>
in Ed, but one cannot do the reciprocal. I
was so bummed out on day one regarding this,
and I’m still bummed out 365 days later. What I
find shocking, is that <abbr>UNIX</abbr> <code>mail</code> has <code>z</code> to go
forward a page in header listings, and also <code>-z</code>
to go back a page. If only this was baked into
Ed from the start. My workaround is terrible,
and funny as it may sound, when I’m fatigued,
I sometimes try <code>-z</code> to see if it magically
started working.</p>

<p>Perhaps more of a gripe to the authors of <code>sed</code>
rather than Ed, but I wish there was a 100%
compatibility with ‘regex’ substitution patterns
that are valid in Ed, but in <code>sed</code>. This is
not the case, and it’s a shame. In general,
one has to forget about Ed’s awesome shorthand
tricks to get <code>sed</code> to work. It would be great
if the bounty of Ed vocabulary I’ve built up
just simply worked one-for-one in <code>sed</code>.</p>

<h3>More Ed for me</h3>


<p>One year dedicated to Ed is probably enough time
to arrive at a plateau of know-how where the
limitations will remain as such, and the pains
can’t be overcome with any more learning. That
said, I think I’ve arrived at a comfortable spot
with Ed, and I’m going to stick it out with it!</p><p><svg xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" viewBox="200 0 400 800" width="400" height="800"><rect width="400" height="800" fill="#b33a3a"></rect><polygon points="299.5 150 254.5 247 351.5 247 "></polygon><path d="m321.9 548.9l-243.8 0"></path><path d="m303 247.1l0 243.8"></path><polygon points="94.5 150 49.5 247 146.5 247 "></polygon><path d="m98 247.1l0 243.8"></path><text font-family="Helvetica, Arial, sans-serif" font-size="60" y="112" x="10" style="fill-opacity:null">THIS END UP</text><a xlink:href="//cretaria.com"><text id="link-cretaria" font-family="Helvetica, Arial, sans-serif" font-size="50" y="680" x="10" fill-opacity="null">What’s Cretaria?</text></a><path d="m175 700l200 0" style="fill-opacity:null;fill:none;stroke-linejoin:null;stroke-opacity:null;stroke-width:4;stroke:#000"></path></svg></p></article>
            </section>
            
        </div></div>]]>
            </description>
            <link>http://blog.cretaria.com/posts/from-vim-to-ed.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24446422</guid>
            <pubDate>Fri, 11 Sep 2020 19:27:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn Directly from the Best - A Curated List from Twitter]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24446218">thread link</a>) | @utkarsh_apoorva
<br/>
September 11, 2020 | https://happinomy.com/twitter-university/ | <a href="https://web.archive.org/web/*/https://happinomy.com/twitter-university/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>




<h3>The Ultimate List of the best people to follow on Twitter.</h3>



<p>Twitter can be a great source of learning from amazing people. Here is a growing list of great people on twitter, and what you can learn from them.</p>



<p>Here is a (growing) list of some of the most amazing people I found on Twitter.</p>



<p>From building profitable businesses to growing your audience; and from writing great copy to writing great code, there is so much to learn from them. </p>



<p>And the best part – they share their experiences and lessons very publicly on Twitter.</p>



<p>This is a personal list – compiled by me over a few weeks.</p>



<p>I am sure there are many more interesting people out there. Please add them to the list in the thread below, or DM me on twitter (<a rel="noreferrer noopener" href="https://www.twitter.com/kush_apoorva" data-type="URL" data-id="https://www.twitter.com/kush_apoorva" target="_blank">@kush_apoorva</a>).</p>







<h3>Naval Ravikant (<a href="https://twitter.com/naval" data-type="URL" data-id="https://twitter.com/naval" target="_blank" rel="noreferrer noopener">@naval</a>)</h3>



<ol><li><strong><em>What to Learn</em></strong>: How to be wealthy, happy, and fit.</li><li><strong><em>Key Source</em></strong>: This tweet – <a rel="noreferrer noopener" href="https://twitter.com/naval/status/1002103360646823936" target="_blank">How to Get Rich without Getting Lucky</a> </li><li><strong><em>Quick lesson</em></strong>: Develop “specific knowledge,” which is unique and cannot be taught in schools. Use code and media to deliver value to society at scale.</li><li><strong><em>More Resources</em></strong>: <a type="URL" id="https://nav.al" rel="noreferrer noopener" href="https://nav.al/" target="_blank">His blog</a>, <a href="https://twitter.com/naval">His twitter</a>.</li></ol>



<figure><div>
<blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">How to Get Rich (without getting lucky):</p>— Naval (@naval) <a href="https://twitter.com/naval/status/1002103360646823936?ref_src=twsrc%5Etfw">May 31, 2018</a></blockquote>
</div></figure>







<h3>Nir Eyal (<a href="https://twitter.com/nireyal" data-type="URL" data-id="https://twitter.com/nireyal" target="_blank" rel="noreferrer noopener">@nireyal</a>)</h3>



<ol><li><strong><em><strong><em><strong><em>What to Learn</em></strong></em></strong>:</em></strong> How to build habit-forming products.</li><li><strong><em>Key Source</em></strong>: His book: Hooked.</li><li><strong><em>Quick Lesson: </em></strong>Habits are formed from actions when the loop of Trigger-Action-Reward-Investment is completed.</li><li><strong><em>More Resouces:</em></strong> <a type="URL" id="https://nirandfar.com" rel="noreferrer noopener" href="https://nirandfar.com/" target="_blank">His Blog</a>.</li></ol>



<figure><div>
<blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>There’s a reason we call it “paying” attention. </p><p>Our time and focus has value.</p></div>— Nir Eyal (@nireyal) <a href="https://twitter.com/nireyal/status/1303325968849805312?ref_src=twsrc%5Etfw">September 8, 2020</a></blockquote>
</div></figure>







<h3>Pieter Levels (<a href="https://twitter.com/levelsio" data-type="URL" data-id="https://twitter.com/levelsio" target="_blank" rel="noreferrer noopener">@levelsio</a>)</h3>



<ol><li><strong><em><strong><em><strong><em><strong><em><strong><em><strong><em>What to Learn</em></strong></em></strong></em></strong></em></strong></em></strong>:</em></strong> Be a serial maker.</li><li><strong><em>Key Source</em></strong>:<strong><em> </em></strong><a href="https://www.youtube.com/watch?v=6reLWfFNer0">This talk</a>.</li><li><strong><em>Quick Lesson</em></strong><em>: </em>Become a contrarian. Experience uncommon things to have uncommon ideas. </li><li><strong><em>More Resources: </em></strong> Read his book – <a rel="noreferrer noopener" href="https://makebook.io/" type="URL" id="https://makebook.io" target="_blank">Makebook</a>.</li></ol>







<figure><div>
<blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">Everyone and their cousin's goldfish is building an uptime monitor now, it's the new todo app</p>— ؜ (@levelsio) <a href="https://twitter.com/levelsio/status/1301143528425357314?ref_src=twsrc%5Etfw">September 2, 2020</a></blockquote>
</div></figure>







<h3>Toby Howell (<a rel="noreferrer noopener" href="https://twitter.com/tobydoyhowell" data-type="URL" data-id="https://twitter.com/tobydoyhowell" target="_blank">@tobydoyhowell</a>)</h3>



<ol><li><strong><em><strong><em>What to Learn</em></strong>:</em></strong> How to grow your audience on Twitter.</li><li><strong><em>Key source</em></strong>: <a rel="noreferrer noopener" href="https://twitter.com/tobydoyhowell/status/1272674455681024000" data-type="URL" data-id="https://twitter.com/tobydoyhowell/status/1272674455681024000" target="_blank">A thread on how to write twitter threads</a></li><li><strong><em>Quick Lesson: </em></strong>You just need to be slightly disciplined, and slightly differentiated to be able to grow your audience. There is a dearth of great people to follow.</li><li><strong><em>More Resources:</em></strong> Just follow him on Twitter </li></ol>



<figure><div>
<blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>I've been running <a href="https://twitter.com/MorningBrew?ref_src=twsrc%5Etfw">@morningbrew</a>'s social media for the past ~2 months</p><p>here's a thread of a few things i've learned</p><p>Twitter strategy only for now</p><p>Insta later</p></div>— Toby ☕️ (@tobydoyhowell) <a href="https://twitter.com/tobydoyhowell/status/1272674455681024000?ref_src=twsrc%5Etfw">June 15, 2020</a></blockquote>
</div></figure>







<h3>Harry Dry (<a href="https://twitter.com/harrydry" data-type="URL" data-id="https://twitter.com/harrydry" target="_blank" rel="noreferrer noopener">@harrydry</a>)</h3>



<ol><li><strong><em><strong><em><strong><em>Learn from Twitter</em></strong></em></strong>:</em></strong> How to market your products.</li><li><strong><em>Key Source: </em></strong> The <a href="https://marketingexamples.com/" type="URL" id="https://marketingexamples.com/">Marketing </a><a rel="noreferrer noopener" href="https://marketingexamples.com/" type="URL" id="https://marketingexamples.com/" target="_blank">Examples</a> website.</li><li><strong><em>Quick Lesson</em></strong>: When sharing knowledge, use real examples (no theory), and show the good vs bad clearly, like this.</li><li><strong><em>More Resources</em></strong>: <a href="https://thekanyestory.com/">The Kanye </a><a rel="noreferrer noopener" href="https://thekanyestory.com/" target="_blank">Story</a></li></ol>



<figure><div>
<blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>🔥 Finally finished The Kanye Story! </p><p>It's a story about how I went from lying in bed with no ideas to negotiating with the biggest superstar on planet earth. Take a look 👉🏻 <a href="https://t.co/7v6vPX55eM">https://t.co/7v6vPX55eM</a></p></div>— Harry Dry (@harrydry) <a href="https://twitter.com/harrydry/status/1111654068961849346?ref_src=twsrc%5Etfw">March 29, 2019</a></blockquote>
</div></figure>







<h3>Liked this Resource? Then Join us 😍</h3>











<h3>Daniel Vassallo (<a href="https://twitter.com/dvassallo" data-type="URL" data-id="https://twitter.com/dvassallo" target="_blank" rel="noreferrer noopener">@dvassallo</a>)</h3>



<ol><li><strong><em><strong><em>Learn from Twitter</em></strong></em></strong>: How to grow your Twitter audience</li><li><strong><em>Key Source</em></strong>: This <a data-type="URL" data-id="https://gumroad.com/l/PBkrO" rel="noreferrer noopener" href="https://gumroad.com/l/PBkrO" target="_blank">100-minute video</a> on Gumroad (paid).</li><li><strong><em>Quick Lesson:</em></strong> Earn credibility by sharing behind-the-scenes, real experiences, even if you are not an expert. Once you are credible, people will listen to you.</li><li><strong><em>More Resources:</em></strong> Check out his <a data-type="URL" data-id="https://gumroad.com/dvassallo" rel="noreferrer noopener" href="https://gumroad.com/dvassallo" target="_blank">Gumroad profile</a> and <a rel="noreferrer noopener" href="https://danielvassallo.com/" target="_blank">his blog</a>.</li></ol>



<figure><div>
<blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>My advice to first-time info product creators:</p><p>1. Start with a very small product.</p><p>2. Choose a topic you know well that will almost write itself. Avoid doing research.</p><p>3. Timebox production to 2 weeks.</p><p>4. Charge $10.</p><p>5. Promote it!</p><p>All the lessons are in #5. Best of luck!</p></div>— Daniel Vassallo (@dvassallo) <a href="https://twitter.com/dvassallo/status/1287210142459547648?ref_src=twsrc%5Etfw">July 26, 2020</a></blockquote>
</div></figure>







<h3>Matthew Kobach (<a href="https://twitter.com/mkobach" target="_blank" rel="noreferrer noopener">@mkobach</a>)</h3>



<ol><li><strong><em><strong><em>Learn from Twitter</em></strong>: </em></strong> Learn about Social Media marketing.</li><li><strong><em>Key Source</em></strong>: <a rel="noreferrer noopener" href="https://twitter.com/mkobach/status/1287140026061656070" type="URL" id="https://twitter.com/mkobach/status/1287140026061656070" target="_blank">This thread</a>.</li><li><strong><em>Quick Lesson:</em></strong>  Share content that is interesting + relevant. It could be anything your audience cares about.</li><li><strong><em>More Resources: </em></strong>This <a rel="noreferrer noopener" href="https://www.perell.com/podcast/matthew-kobach-social-media-brands" type="URL" id="https://www.perell.com/podcast/matthew-kobach-social-media-brands" target="_blank">great interview</a> with David Perell. </li></ol>



<figure><div>
<blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>I promised I would share the <a href="https://twitter.com/fast?ref_src=twsrc%5Etfw">@Fast</a> social media strategy in real time, so let’s go</p><p>We’re still very early in the process, but here’s where we’re at so far (a brief thread)</p></div>— Matthew Kobach (@mkobach) <a href="https://twitter.com/mkobach/status/1287140026061656070?ref_src=twsrc%5Etfw">July 25, 2020</a></blockquote>
</div></figure>







<h3>Arvid Kahl (<a href="https://twitter.com/arvidkahl" data-type="URL" data-id="https://twitter.com/arvidkahl" target="_blank" rel="noreferrer noopener">@arvidkahl</a>)</h3>



<ol><li><strong><em><strong><em>Learn from Twitter</em></strong>: </em></strong> How to create, build, and sell a bootstrapped business.</li><li><strong><em>Key Source</em></strong>: His book, Zero to Sold.</li><li><strong><em>Quick Lesson:</em></strong>  Find a common problem in a niche audience.</li><li><strong><em>More Resources: </em></strong> His blog – <a rel="noreferrer noopener" href="https://thebootstrappedfounder.com/" type="URL" id="https://thebootstrappedfounder.com" target="_blank">The Bootstrapped Founder</a></li></ol>



<figure><div>
<blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>Successful businesses are built by solving critical problems for an audience that will pay for a solution to their issues.</p><p>Not every problem is critical. Not every critical problem is interesting. Not every interesting problem is critical.</p></div>— Arvid Kahl (@arvidkahl) <a href="https://twitter.com/arvidkahl/status/1303379665608941569?ref_src=twsrc%5Etfw">September 8, 2020</a></blockquote>
</div></figure>







<h3>Lenny Rachitsky (<a href="https://twitter.com/lennysan" data-type="URL" data-id="https://twitter.com/lennysan" target="_blank" rel="noreferrer noopener">@lennysan</a>)</h3>



<ol><li><strong><em>What to Learn: </em></strong> How to grow your product with high retention.</li><li><strong><em>Key Source</em></strong>: <a rel="noreferrer noopener" href="https://twitter.com/lennysan/status/1299077345681133568" data-type="URL" data-id="https://twitter.com/lennysan/status/1299077345681133568" target="_blank">This twitter thread</a> on user retention.</li><li><strong><em>Quick Lesson:</em></strong>  Increase your product’s retention: (1) Improve your product or better, onboarding (2) Improve deactivation flow (4) Change your users</li><li><strong><em>More Resources: </em></strong> His <a rel="noreferrer noopener" href="https://www.lennyrachitsky.com/" target="_blank">newsletter and blog</a>.</li></ol>



<figure><div>
<blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>Q: What's the most important growth metric to get right?<br>A: Retention</p><p>Q: How do you know if you have good retention?<br>A: Read this: <a href="https://t.co/BFzRmSJgwS">https://t.co/BFzRmSJgwS</a></p><p>Q: How do you increase retention, if it isn't good?</p><p>Time for a thread 👇👇👇</p></div>— Lenny Rachitsky (@lennysan) <a href="https://twitter.com/lennysan/status/1299077345681133568?ref_src=twsrc%5Etfw">August 27, 2020</a></blockquote>
</div></figure>







<h3>Alex and Books (<a href="https://twitter.com/AlexAndBooks_">@AlexAndBooks_</a>)</h3>



<ol><li><strong><em>What to Learn: </em></strong> How to Read. </li><li><strong><em>Key Source</em></strong>: This <a rel="noreferrer noopener" href="https://twitter.com/AlexAndBooks_/status/1237146642018639872" data-type="URL" data-id="https://twitter.com/AlexAndBooks_/status/1237146642018639872" target="_blank">twitter thread</a>.</li><li><strong><em>Quick Lesson:</em></strong> Just read the super relevant parts of a book that is relevant to your life. Skip other parts, and quit other books.</li><li><strong><em>More Resources: </em></strong> <a rel="noreferrer noopener" href="http://alexandbooks.com/" data-type="URL" data-id="alexandbooks.com" target="_blank">His Blog</a>.</li></ol>



<figure><div>
<blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>I believe reading is a skill, like driving or tennis.</p><p>And with all skills, there are ways to become better. </p><p>I'm on a quest to develop the skill of reading and share the best practices I learn along the way.</p><p>FOLLOW this thread to join my journey &amp; become a better reader!</p></div>— Alex and Books 📚 (@AlexAndBooks_) <a href="https://twitter.com/AlexAndBooks_/status/1237146642018639872?ref_src=twsrc%5Etfw">March 9, 2020</a></blockquote>
</div></figure>







<h3>Shreyas Doshi (<a href="https://twitter.com/shreyas" data-type="URL" data-id="https://twitter.com/shreyas" target="_blank" rel="noreferrer noopener">@shreyas</a>)</h3>



<ol><li><strong><em>What to Learn: </em></strong> How to be a great product manager.</li><li><strong><em>Key Source</em></strong>: This <a href="https://twitter.com/shreyas/status/1303150374124048386" target="_blank" rel="noreferrer noopener">thread of threads</a> by Shreyas.</li><li>Quick Lesson:  Great PMs know that people—and therefore their users —are driven by emotion more than logic. </li><li><strong><em>More Resources: </em></strong> <a type="URL" id="https://twitter.com/shreyas" rel="noreferrer noopener" href="https://twitter.com/shreyas" target="_blank">Follow on Twitter</a>.</li></ol>



<figure></figure>







<h3>Jack Butcher (<a href="https://twitter.com/jackbutcher" target="_blank" rel="noreferrer noopener">@jackbutcher</a>)</h3>



<ol><li><strong><em>What to Learn: </em></strong> How to express ideas better, visually.</li><li><strong><em>Key Source</em></strong>: <a rel="noreferrer noopener" href="https://twitter.com/jackbutcher/status/1303376950346612737" data-type="URL" data-id="https://twitter.com/jackbutcher/status/1303376950346612737" target="_blank">This twitter thread</a>. </li><li><strong><em>Quick Lesson:</em></strong>  Prove a problem exists, find a solution that you can deliver, promote that solution as much as you can.</li><li><strong><em>More Resources: </em></strong> <a rel="noreferrer noopener" href="https://twitter.com/jackbutcher" data-type="URL" data-id="https://twitter.com/jackbutcher" target="_blank">Follow on Twitter</a></li></ol>



<figure></figure>







<h3>Robin Vander Heyden (<a href="https://twitter.com/vinrob" data-type="URL" data-id="https://twitter.com/vinrob" target="_blank" rel="noreferrer noopener">@vinrob</a>)</h3>



<ol><li><strong><em>Learn from Twitter: </em></strong> How to run a bootstrapped business.</li><li><strong><em>Key Source</em></strong>: <a type="URL" id="https://twitter.com/Vinrob/status/1080331951536463872" rel="noreferrer noopener" href="https://twitter.com/Vinrob/status/1080331951536463872" target="_blank">This twitter thread</a> on how he grew his company from 0 to $500K ARR in 2 years.</li><li><strong><em>Quick Lesson: </em></strong> The goal of an MVP: Here’s the problem, here’s how I solve it, do you want to buy?</li><li><strong><em>More Resources: </em></strong> <a href="https://twitter.com/vinrob">Follow on Twitter</a></li></ol>



<figure><div>
<blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">In 2018 I moved to 🇮🇩 Indonesia and started an online business, fully bootstrapped from 0 to $500k/year in revenue (25% profits). Here are some insights about creating value, distribution, building a team, and what my role is about.</p>— Robin Vander Heyden (@Vinrob) <a href="https://twitter.com/Vinrob/status/1080331951536463872?ref_src=twsrc%5Etfw">January 2, 2019</a></blockquote>
</div></figure>







<h3>Aleksandr Volodarsky (<a href="https://twitter.com/volodarik" data-type="URL" data-id="https://twitter.com/volodarik" target="_blank" rel="noreferrer noopener">@volodarik</a>)</h3>



<ol><li><strong><em>Learn from Twitter: </em></strong> How a business can survive a pandemic.</li><li><strong><em>Key Source</em></strong>: <a type="URL" id="https://twitter.com/volodarik/status/1278336866744512513" rel="noreferrer noopener" href="https://twitter.com/volodarik/status/1278336866744512513" target="_blank">This twitter thread on how Quora gave them 1M GMV</a></li><li><strong><em>Quick Lesson:</em></strong>  The Give/Take ratio from a community should be 3:1. Give at least three times more than you take. They used this to get 1M GMV from Quora.</li><li><strong><em>More Resources: </em></strong> <a type="URL" id="https://sharingalemon.substack.com/" rel="noreferrer noopener" href="https://sharingalemon.substack.com/" target="_blank">His newsletter</a></li></ol>



<figure><div>
<blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>Quora has generated for us at least $1m GMV for 2 years. </p><p>It’s losing value for us now, but for an early-stage startup, it’s a great source to get customers and learn more about them.</p><p>Below I'll list 16 tips that worked for us.</p></div>— Aleksandr Volodarsky (@volodarik) <a href="https://twitter.com/volodarik/status/1278336866744512513?ref_src=twsrc%5Etfw">July 1, 2020</a></blockquote>
</div></figure>







<h3>Florin Pop (<a href="https://twitter.com/florinpop1705" data-type="URL" data-id="https://twitter.com/florinpop1705" target="_blank" rel="noreferrer noopener">@florinpop1705</a>)</h3>



<ol><li><strong><em>What to Learn: </em></strong> How to make web apps</li><li><strong><em>Key Source</em></strong>: <a rel="noreferrer noopener" href="https://twitter.com/florinpop1705/status/1303904111876767744" data-type="URL" data-id="https://twitter.com/florinpop1705/status/1303904111876767744" target="_blank">This twitter thread</a> talking about 10 apps being made in 10 hours on live video.</li><li><strong><em>Quick Lesson:</em></strong>  Anyone can write code.</li><li><strong><em>More Resources: </em></strong> <a rel="noreferrer noopener" href="https://www.florin-pop.com/" data-type="URL" data-id="https://www.florin-pop.com/" target="_blank">His website</a> and <a rel="noreferrer noopener" href="https://www.youtube.com/channel/UCeU-1X402kT-JlLdAitxSMA" data-type="URL" data-id="https://www.youtube.com/channel/UCeU-1X402kT-JlLdAitxSMA" target="_blank">his youtube channel</a>.</li></ol>



<figure></figure>



















<h2>Coming Soon</h2>



<p>John Yongfook</p>



<p>Randall Kanna</p>



<p>Zeno Rocha</p>



<p>Mubashar Iqbal</p>



<p>Nathan Berry</p>



<p>David Perrel</p>



<p>Sahil Lavingiya</p>



<p>NN Taleb</p>



<p>Nathan Latka (<a href="https://twitter.com/NathanLatka/status/1303744597164732417" data-type="URL" data-id="https://twitter.com/NathanLatka/status/1303744597164732417" target="_blank" rel="noreferrer noopener">tweet</a>)</p>



<p>Nathan Barry (<a href="https://twitter.com/nathanbarry" data-type="URL" data-id="https://twitter.com/nathanbarry" target="_blank" rel="noreferrer noopener">@nathanbarry</a>)</p>



<p>Noah Kagan</p>



<p>Joel Gascoigne</p>



<p>John Nolan</p>



<p>James Clear</p>











<h2>Rising Stars to Learn From</h2>



<p>This is a list of people who are rising fast. They add tremendous value, and you can learn great things from them on twitter.</p>



<p>KP (<a href="https://twitter.com/thisiskp_">@thisiskp_</a>)</p>



<p>Sharath (<a href="https://twitter.com/5harath" data-type="URL" data-id="https://twitter.com/5harath" target="_blank" rel="noreferrer noopener">@5harath</a>)</p>



<p>Deepu Asok (<a rel="noreferrer noopener" href="https://twitter.com/deepuasok" target="_blank">@deepuasok</a>)</p>



<p>Vik Duggal (<a href="https://twitter.com/vikdug" target="_blank" rel="noreferrer noopener">@vikdug</a>)</p>







<h3>Liked this Resource? Then Join us  😍</h3>















<p>Credits: Photo by <a href="https://unsplash.com/@jamie452?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Jamie Street</a> on <a href="https://unsplash.com/s/photos/twitter?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></p>



<p>More about me <a href="https://happinomy.com/about-me" target="_blank" rel="noreferrer noopener">here</a></p>
</div></div>]]>
            </description>
            <link>https://happinomy.com/twitter-university/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24446218</guid>
            <pubDate>Fri, 11 Sep 2020 19:05:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Papercraft Models of Classic Computers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24445952">thread link</a>) | @kanobo
<br/>
September 11, 2020 | http://rockybergen.com/papercraft | <a href="https://web.archive.org/web/*/http://rockybergen.com/papercraft">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="page" role="main" data-content-field="main-content">
      <!-- CATEGORY NAV -->
      
      <div data-type="page" data-updated-on="1592534389753" id="page-5c40ced8575d1f4191811561"><div><div><div data-block-type="2" id="block-0348a58188a4ef2cb7ff"><div><p>Construct the computer from your childhood or build an entire computer museum at home with these paper models, free to download and share.<br>Print, Cut, Score, Fold and Glue.</p></div></div></div></div><div><div><div data-aspect-ratio="75" data-block-type="5" id="block-7348027484c80743e6ed"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1547751317778-HWMYNDK2JW0LTOB6EBZP/ke17ZwdGBToddI8pDm48kN_ZoNdj1kv_gIvm4zjH76N7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0n54Bn8e90W9qBf-smZxzROWPWatu8N4myd8qBOjLXoKr7eLilP27nxMq5hFavDR2g/IMG_3082.png" data-image="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1547751317778-HWMYNDK2JW0LTOB6EBZP/ke17ZwdGBToddI8pDm48kN_ZoNdj1kv_gIvm4zjH76N7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0n54Bn8e90W9qBf-smZxzROWPWatu8N4myd8qBOjLXoKr7eLilP27nxMq5hFavDR2g/IMG_3082.png" data-image-dimensions="2500x1786" data-image-focal-point="0.5,0.5" alt="IMG_3082.png" data-load="false" data-image-id="5c40cf83352f5396d76f7ac3" data-type="image" src="http://rockybergen.com/IMG_3082.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-3fa377625522c866e7f3"><div><h3>AMIGA 500</h3><p>Link to the model <a href="https://rockybergen.com/whatsnew/2019/1/15/amiga-500-papercraft-design">here</a>.                                                              German New Art Edition <a href="http://rockybergen.com/whatsnew/2019/8/8/amiga-500-new-art-papercraft-design">here</a>.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1547751162669_11811"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1547751729623-C59CLX1IAXB7W7VT5Y32/ke17ZwdGBToddI8pDm48kNiEM88mrzHRsd1mQ3bxVct7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0topjEaZcWjtmMYdCWL4dkGbxs35J-ZjFa9s1e3LsxrX8g4qcOj2k2AL08mW_Htcgg/front-oregon-trail-alt.png" data-image="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1547751729623-C59CLX1IAXB7W7VT5Y32/ke17ZwdGBToddI8pDm48kNiEM88mrzHRsd1mQ3bxVct7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0topjEaZcWjtmMYdCWL4dkGbxs35J-ZjFa9s1e3LsxrX8g4qcOj2k2AL08mW_Htcgg/front-oregon-trail-alt.png" data-image-dimensions="2500x2500" data-image-focal-point="0.5,0.5" alt="front-oregon-trail-alt.png" data-load="false" data-image-id="5c40d12442bfc12f9674aa5a" data-type="image" src="http://rockybergen.com/front-oregon-trail-alt.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1590324703951_24581"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1590325638875-4KWH1QV0IOF6T55KOG17/ke17ZwdGBToddI8pDm48kGJPosOZKJ_5bTt_aoKLXvV7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmNO4gLeMELCxgbq9ZwIFBqyNnwMzbLyu6EqVFxy448Ac96U4dydQe93OYlnDwKBkA/Apple+Macintosh+128K+Model" data-image="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1590325638875-4KWH1QV0IOF6T55KOG17/ke17ZwdGBToddI8pDm48kGJPosOZKJ_5bTt_aoKLXvV7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmNO4gLeMELCxgbq9ZwIFBqyNnwMzbLyu6EqVFxy448Ac96U4dydQe93OYlnDwKBkA/Apple+Macintosh+128K+Model" data-image-dimensions="1126x1126" data-image-focal-point="0.5,0.5" alt="Apple Macintosh 128K Model" data-load="false" data-image-id="5eca7180250a6a0b1a797f88" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1590324703951_28199"><div><h3>Apple Macintosh 128K</h3><p>Link to the model <a href="http://rockybergen.com/whatsnew/2020/5/22/apple-macintosh-128k-papercraft-design">here</a>.                                                                             </p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1592415789136_26033"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1592415990253-RN2H94KYOJUE65PPBML4/ke17ZwdGBToddI8pDm48kKAIkQk1kT2ThXQe37c2Cyd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub-K2BP0W1-5FW-m4FzjPBuXfWKGAAA0gU_rp4yEhj2SOpYghpI-Ha_TwZsqqmJXng/BBC+Microcomputer+Papercraft+Model" data-image="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1592415990253-RN2H94KYOJUE65PPBML4/ke17ZwdGBToddI8pDm48kKAIkQk1kT2ThXQe37c2Cyd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub-K2BP0W1-5FW-m4FzjPBuXfWKGAAA0gU_rp4yEhj2SOpYghpI-Ha_TwZsqqmJXng/BBC+Microcomputer+Papercraft+Model" data-image-dimensions="2332x2332" data-image-focal-point="0.5,0.5" alt="BBC Microcomputer Papercraft Model" data-load="false" data-image-id="5eea56aac4488718b636214d" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1592416156070_26814"><div><h3>BBC MicrocompUteR</h3><p>Link to the model <a href="http://rockybergen.com/whatsnew/2020/6/17/bbc-microcomputer-papercraft-design">here</a>.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1588440149019_23238"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1588440199899-VSNOEOMJTK66IJ6W9RB4/ke17ZwdGBToddI8pDm48kGYKcJaEz4vNz2pgt2fQSqlZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzBgejzEWRPSQ4sX_EGpmnNOvTH6DYc2wKq80NTw9ecR6Vk-vvLi9jwd_7VQTLTqao/Commodore+VIC-20" data-image="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1588440199899-VSNOEOMJTK66IJ6W9RB4/ke17ZwdGBToddI8pDm48kGYKcJaEz4vNz2pgt2fQSqlZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzBgejzEWRPSQ4sX_EGpmnNOvTH6DYc2wKq80NTw9ecR6Vk-vvLi9jwd_7VQTLTqao/Commodore+VIC-20" data-image-dimensions="695x695" data-image-focal-point="0.5,0.5" alt="Commodore VIC-20" data-load="false" data-image-id="5eadac7d0ef55d3237cb1ad4" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1588440149019_29173"><div><h3>CoMMODORE VIC-20</h3><p>Link to the latest model <a href="http://rockybergen.com/whatsnew/2020/5/2/commodore-vic-20-papercraft-design">here</a>.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1547775615568_46583"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1547777663528-ODP80GVLTUA3SJ8S6CD2/ke17ZwdGBToddI8pDm48kNiEM88mrzHRsd1mQ3bxVct7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0topjEaZcWjtmMYdCWL4dkGbxs35J-ZjFa9s1e3LsxrX8g4qcOj2k2AL08mW_Htcgg/IBM-5100-Front-v003.png" data-image="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1547777663528-ODP80GVLTUA3SJ8S6CD2/ke17ZwdGBToddI8pDm48kNiEM88mrzHRsd1mQ3bxVct7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0topjEaZcWjtmMYdCWL4dkGbxs35J-ZjFa9s1e3LsxrX8g4qcOj2k2AL08mW_Htcgg/IBM-5100-Front-v003.png" data-image-dimensions="2500x2500" data-image-focal-point="0.5,0.5" alt="IBM-5100-Front-v003.png" data-load="false" data-image-id="5c4136514ae237dd786a3b4e" data-type="image" src="http://rockybergen.com/IBM-5100-Front-v003.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1563325615886_43244"><div><h3>IBM 5100 Portable computer</h3><p>Link to the model <a href="http://rockybergen.com/whatsnew/2018/12/19/ibm-5100-portable-computer">here</a>.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1553908991580_15079"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1553909419711-DLINHA95G40WJTJ6B94E/ke17ZwdGBToddI8pDm48kIuDfvWaFR2Iqed7asMOKyt7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmT9vpqXpgR-5jHl5KNyQ_vOUsaE--K8qAsnBiQUVvocXgZXG9SlBsDZM_BtsjcH9x/IMSAI+8080-+Model" data-image="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1553909419711-DLINHA95G40WJTJ6B94E/ke17ZwdGBToddI8pDm48kIuDfvWaFR2Iqed7asMOKyt7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmT9vpqXpgR-5jHl5KNyQ_vOUsaE--K8qAsnBiQUVvocXgZXG9SlBsDZM_BtsjcH9x/IMSAI+8080-+Model" data-image-dimensions="1483x1483" data-image-focal-point="0.5,0.5" alt="IMSAI 8080- Model" data-load="false" data-image-id="5c9ec6990d92972348b97907" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1571765454448_164008"><div><h3>IMSAI 8080 (PCS-80 SYSTEM)</h3><p>Link to the model <a href="https://rockybergen.com/whatsnew/2019/3/27/imsai-8080">here</a>.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1547775615568_30953"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1547777301331-LA12J4F2DIEBFGMU9166/ke17ZwdGBToddI8pDm48kNiEM88mrzHRsd1mQ3bxVct7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0topjEaZcWjtmMYdCWL4dkGbxs35J-ZjFa9s1e3LsxrX8g4qcOj2k2AL08mW_Htcgg/IMG_2254.png" data-image="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1547777301331-LA12J4F2DIEBFGMU9166/ke17ZwdGBToddI8pDm48kNiEM88mrzHRsd1mQ3bxVct7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0topjEaZcWjtmMYdCWL4dkGbxs35J-ZjFa9s1e3LsxrX8g4qcOj2k2AL08mW_Htcgg/IMG_2254.png" data-image-dimensions="2500x2500" data-image-focal-point="0.5,0.5" alt="IMG_2254.png" data-load="false" data-image-id="5c4134f1352f53176e89c64d" data-type="image" src="http://rockybergen.com/IMG_2254.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1571765454448_179064"><div><h3>Nintendo GAMECUBE</h3><p>Link to the model <a href="http://rockybergen.com/whatsnew/2018/7/21/nintendo-gamecube-papercraft">here</a>.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1558838880993_46488"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1558839026356-XPE1RQDGOLE6PZAL1UAC/ke17ZwdGBToddI8pDm48kNiEM88mrzHRsd1mQ3bxVct7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0topjEaZcWjtmMYdCWL4dkGbxs35J-ZjFa9s1e3LsxrX8g4qcOj2k2AL08mW_Htcgg/Sharp+X68000+Papercraft+Model+Pattern" data-image="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1558839026356-XPE1RQDGOLE6PZAL1UAC/ke17ZwdGBToddI8pDm48kNiEM88mrzHRsd1mQ3bxVct7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0topjEaZcWjtmMYdCWL4dkGbxs35J-ZjFa9s1e3LsxrX8g4qcOj2k2AL08mW_Htcgg/Sharp+X68000+Papercraft+Model+Pattern" data-image-dimensions="2500x2500" data-image-focal-point="0.5,0.5" alt="Sharp X68000 Papercraft Model Pattern" data-load="false" data-image-id="5ce9fecce79c7041acbdfad7" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1574732675505_142131"><div><h3>SHARP X68000</h3><p>Link to the model <a href="http://rockybergen.com/whatsnew/2019/5/25/sharp-x68000-papercraft-design">here</a>.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1574732675505_151289"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1574733683491-TX601XVQ4LT92TVKUWTO/ke17ZwdGBToddI8pDm48kNiEM88mrzHRsd1mQ3bxVct7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0topjEaZcWjtmMYdCWL4dkGbxs35J-ZjFa9s1e3LsxrX8g4qcOj2k2AL08mW_Htcgg/TRS-80+Model+III+Papercraft+Model" data-image="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1574733683491-TX601XVQ4LT92TVKUWTO/ke17ZwdGBToddI8pDm48kNiEM88mrzHRsd1mQ3bxVct7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0topjEaZcWjtmMYdCWL4dkGbxs35J-ZjFa9s1e3LsxrX8g4qcOj2k2AL08mW_Htcgg/TRS-80+Model+III+Papercraft+Model" data-image-dimensions="2500x2500" data-image-focal-point="0.5,0.5" alt="TRS-80 Model III Papercraft Model" data-load="false" data-image-id="5ddc872ee9c9ef3d618bdab0" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1590324703951_73296"><div><h3>TRS-80 Model III</h3><p>Link to the model <a href="http://rockybergen.com/whatsnew/2019/11/12/trs-80-model-iii-papercraft-design">here</a>.</p></div></div></div><div><div data-aspect-ratio="75" data-block-type="5" id="block-8b4182343a2e489b8831"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1547751560304-UUUZ08G6JUN0O58IM2G7/ke17ZwdGBToddI8pDm48kNiEM88mrzHRsd1mQ3bxVct7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0topjEaZcWjtmMYdCWL4dkGbxs35J-ZjFa9s1e3LsxrX8g4qcOj2k2AL08mW_Htcgg/front-1.png" data-image="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1547751560304-UUUZ08G6JUN0O58IM2G7/ke17ZwdGBToddI8pDm48kNiEM88mrzHRsd1mQ3bxVct7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0topjEaZcWjtmMYdCWL4dkGbxs35J-ZjFa9s1e3LsxrX8g4qcOj2k2AL08mW_Htcgg/front-1.png" data-image-dimensions="2500x2500" data-image-focal-point="0.5,0.5" alt="front-1.png" data-load="false" data-image-id="5c40d0751ae6cf0259ec0e75" data-type="image" src="http://rockybergen.com/front-1.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-3aba1e0c24085fad1534"><div><h3>AmSTRAD CPC 464</h3><p>Link to the latest model <a href="https://rockybergen.com/whatsnew/2018/11/30/amstrad-cpc-464-papercraft-20">here</a>.                                                                                 Prev: <a href="http://rockybergen.com/whatsnew/2017/1/21/amstradcpc">v1</a></p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1571765454448_147172"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1571765716167-0UFNI66U7DBDC1LIEGNS/ke17ZwdGBToddI8pDm48kNiEM88mrzHRsd1mQ3bxVct7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0topjEaZcWjtmMYdCWL4dkGbxs35J-ZjFa9s1e3LsxrX8g4qcOj2k2AL08mW_Htcgg/Apple+-+Lisa+1" data-image="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1571765716167-0UFNI66U7DBDC1LIEGNS/ke17ZwdGBToddI8pDm48kNiEM88mrzHRsd1mQ3bxVct7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0topjEaZcWjtmMYdCWL4dkGbxs35J-ZjFa9s1e3LsxrX8g4qcOj2k2AL08mW_Htcgg/Apple+-+Lisa+1" data-image-dimensions="2500x2500" data-image-focal-point="0.5,0.5" alt="Apple - Lisa 1" data-load="false" data-image-id="5daf3dc5a50ae018ef6f1f2f" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1571765454448_149636"><div><h3>APPLE - LISA 1</h3><p>Link to the model <a href="https://rockybergen.com/whatsnew/2019/10/17/apple-lisa-1-papercraft-design">here</a>.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1549746001726_22861"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1549746395018-JW1I4T79NKIQLXYGD2SP/ke17ZwdGBToddI8pDm48kNiEM88mrzHRsd1mQ3bxVct7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0s0XaMNjCqAzRibjnE_wBlkZ2axuMlPfqFLWy-3Tjp4nKScCHg1XF4aLsQJlo6oYbA/Atari+520+ST" data-image="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1549746395018-JW1I4T79NKIQLXYGD2SP/ke17ZwdGBToddI8pDm48kNiEM88mrzHRsd1mQ3bxVct7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0s0XaMNjCqAzRibjnE_wBlkZ2axuMlPfqFLWy-3Tjp4nKScCHg1XF4aLsQJlo6oYbA/Atari+520+ST" data-image-dimensions="2500x2500" data-image-focal-point="0.5,0.5" alt="Atari 520 ST" data-load="false" data-image-id="5c5f40bf8165f527b770bddb" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1590324703951_68471"><div><h3>ATARI 520ST</h3><p>Link to the latest model <a href="http://rockybergen.com/whatsnew/2019/2/9/atari-520-st-papercraft-design">here</a>.    </p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1547775615568_7710"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1547775762408-DNREFI406UJMGRBUDYAZ/ke17ZwdGBToddI8pDm48kH7bcx_p807l_7aJvGUB_uN7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0moOD8BDhkEvmr_flZVBtwIChsuiQhyTIkjVQ5JuE40aqe9Md01nIM06lR7f9JJmiQ/C64_Mini_Computer_Papercraft-Basic-2.png" data-image="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1547775762408-DNREFI406UJMGRBUDYAZ/ke17ZwdGBToddI8pDm48kH7bcx_p807l_7aJvGUB_uN7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0moOD8BDhkEvmr_flZVBtwIChsuiQhyTIkjVQ5JuE40aqe9Md01nIM06lR7f9JJmiQ/C64_Mini_Computer_Papercraft-Basic-2.png" data-image-dimensions="2500x2499" data-image-focal-point="0.5,0.5" alt="C64_Mini_Computer_Papercraft-Basic-2.png" data-load="false" data-image-id="5c412ecf4ae237dd7869e612" data-type="image" src="http://rockybergen.com/C64_Mini_Computer_Papercraft-Basic-2.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1549746001726_26611"><div><h3>COMMODORE 64</h3><p>Link to the latest model <a href="http://rockybergen.com/whatsnew/2018/6/28/commodore-64-papercraft-v3">here</a>.                                                                             Prev: <a href="http://rockybergen.com/whatsnew/2018/3/30/c64minimonitor">v1</a>, <a href="http://rockybergen.com/whatsnew/2018/4/5/commodore-64-paper-craft">v2</a>, <a href="http://rockybergen.com/whatsnew/2018/6/14/commodore-1541-disk-drive-papercraft">v3</a> </p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1563325615886_42967"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1563325867306-T0QGQTZZW2IN3FPM5NH6/ke17ZwdGBToddI8pDm48kNiEM88mrzHRsd1mQ3bxVct7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0topjEaZcWjtmMYdCWL4dkGbxs35J-ZjFa9s1e3LsxrX8g4qcOj2k2AL08mW_Htcgg/IBM+5150+Personal+Computer" data-image="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1563325867306-T0QGQTZZW2IN3FPM5NH6/ke17ZwdGBToddI8pDm48kNiEM88mrzHRsd1mQ3bxVct7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0topjEaZcWjtmMYdCWL4dkGbxs35J-ZjFa9s1e3LsxrX8g4qcOj2k2AL08mW_Htcgg/IBM+5150+Personal+Computer" data-image-dimensions="2500x2500" data-image-focal-point="0.5,0.5" alt="IBM 5150 Personal Computer" data-load="false" data-image-id="5d2e754e8f2287000141be63" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1571765454448_182957"><div><h3>IBM 5150 PERSONAL Computer</h3><p>Link to the model <a href="http://rockybergen.com/whatsnew/2019/7/16/ibm-5150-papercraft-design">here</a>.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1553262122748_51565"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1553262699056-FOSE3WO4IMXPUM9GEBK0/ke17ZwdGBToddI8pDm48kJNqsDNR92Zm0lZEzPpS63h7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UaQfK7iYtFaG3VRabrZaB72zP5b12zwkFkkazYM2Ml-E3WUfc_ZsVm9Mi1E6FasEnQ/Nintendo+Advanced+Video+System" data-image="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1553262699056-FOSE3WO4IMXPUM9GEBK0/ke17ZwdGBToddI8pDm48kJNqsDNR92Zm0lZEzPpS63h7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UaQfK7iYtFaG3VRabrZaB72zP5b12zwkFkkazYM2Ml-E3WUfc_ZsVm9Mi1E6FasEnQ/Nintendo+Advanced+Video+System" data-image-dimensions="2375x2375" data-image-focal-point="0.5,0.5" alt="Nintendo Advanced Video System" data-load="false" data-image-id="5c94e85b085229d4d73c7e67" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1563325615886_54104"><div><h3>Nintendo ADVANCED VIDEO SYSTEM (PROTOTYPE)</h3><p>Link to the model <a href="https://rockybergen.com/whatsnew/2019/3/2/nintendo-avs-prototype-1983">here</a>.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1574732675505_143092"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1574733462182-PO1EQFO7VFZMCXO4TERQ/ke17ZwdGBToddI8pDm48kNiEM88mrzHRsd1mQ3bxVct7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0topjEaZcWjtmMYdCWL4dkGbxs35J-ZjFa9s1e3LsxrX8g4qcOj2k2AL08mW_Htcgg/Sega+Master+System+Papercraft+Model" data-image="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1574733462182-PO1EQFO7VFZMCXO4TERQ/ke17ZwdGBToddI8pDm48kNiEM88mrzHRsd1mQ3bxVct7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0topjEaZcWjtmMYdCWL4dkGbxs35J-ZjFa9s1e3LsxrX8g4qcOj2k2AL08mW_Htcgg/Sega+Master+System+Papercraft+Model" data-image-dimensions="2500x2500" data-image-focal-point="0.5,0.5" alt="Sega Master System Papercraft Model" data-load="false" data-image-id="5ddc864af95aa874645141f9" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1574732675505_145992"><div><h3>SEGA MASTER SYSTEM</h3><p>Link to the model <a href="http://rockybergen.com/whatsnew/2019/11/14/sega-master-system-papercraft-design">here</a>.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1568075226922_49660"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1568075967367-ZG7V8Q7F3YITXZPQ2TJG/ke17ZwdGBToddI8pDm48kNiEM88mrzHRsd1mQ3bxVct7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0s0XaMNjCqAzRibjnE_wBlkZ2axuMlPfqFLWy-3Tjp4nKScCHg1XF4aLsQJlo6oYbA/Sinclair+ZX+Spectrum" data-image="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1568075967367-ZG7V8Q7F3YITXZPQ2TJG/ke17ZwdGBToddI8pDm48kNiEM88mrzHRsd1mQ3bxVct7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0s0XaMNjCqAzRibjnE_wBlkZ2axuMlPfqFLWy-3Tjp4nKScCHg1XF4aLsQJlo6oYbA/Sinclair+ZX+Spectrum" data-image-dimensions="2500x2500" data-image-focal-point="0.5,0.5" alt="Sinclair ZX Spectrum" data-load="false" data-image-id="5d76f0ab4daeac2b978c3f92" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1574732675505_134908"><div><h3>Sinclair ZX Spectrum</h3><p>Link to the model <a href="http://rockybergen.com/whatsnew/2019/8/17/sinclair-zx-spectrum-papercraft-design">here</a>.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1547775615568_28037"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1547776357981-CB2AMVR04ZPDOBNLYJPM/ke17ZwdGBToddI8pDm48kNiEM88mrzHRsd1mQ3bxVct7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0topjEaZcWjtmMYdCWL4dkGbxs35J-ZjFa9s1e3LsxrX8g4qcOj2k2AL08mW_Htcgg/front-2.png" data-image="https://images.squarespace-cdn.com/content/v1/564229dee4b0d16067409cb0/1547776357981-CB2AMVR04ZPDOBNLYJPM/ke17ZwdGBToddI8pDm48kNiEM88mrzHRsd1mQ3bxVct7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0topjEaZcWjtmMYdCWL4dkGbxs35J-ZjFa9s1e3LsxrX8g4qcOj2k2AL08mW_Htcgg/front-2.png" data-image-dimensions="2500x2500" data-image-focal-point="0.5,0.5" alt="front-2.png" data-load="false" data-image-id="5c41313e03ce6448e4275b88" data-type="image" src="http://rockybergen.com/front-2.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1574732675505_149608"><div><h3>CONION C-100F</h3><p>Link to the model <a href="http://rockybergen.com/whatsnew/2018/8/11/conion-c-100f-papercraft">here</a>.</p></div></div></div></div></div>
    </section></div>]]>
            </description>
            <link>http://rockybergen.com/papercraft</link>
            <guid isPermaLink="false">hacker-news-small-sites-24445952</guid>
            <pubDate>Fri, 11 Sep 2020 18:39:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Not all attacks are equal: understanding and preventing DoS in web applications]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24445886">thread link</a>) | @ievans
<br/>
September 11, 2020 | https://r2c.dev/blog/2020/understanding-and-preventing-dos-in-web-apps/ | <a href="https://web.archive.org/web/*/https://r2c.dev/blog/2020/understanding-and-preventing-dos-in-web-apps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><p><em>Thanks to Clint Gibler, Grayson Hardaway, and Pablo Estrada at r2c for their contributions to this piece. And thanks to r2c for contracting me to write it! This article is cross-posted on <a href="https://jacobian.org/2020/sep/11/analyzing-dos-vulnerabilities/" target="_blank" rel="noopener">jacobian.org</a>.</em></p>
<p>When I ran the security team at Heroku, I had this recurring nightmare: my PagerDuty alarm goesoff, alerting me to some sort of security incident. In my dream, I’d look at my phone and realize “oh no, this is the big one” — and then I’d wake up.</p>
<p>I’m still not sure exactly what the attack in my dream was, but it may very well have been a <em>Denial-of-Service (DoS)</em> attack. DoS attacks are simple but can be devastating: an attacker crafts and sends traffic to your app in a way that overwhelms your servers. While this is arguably not as bad as a remote code execution or a data breach, it’s still pretty terrible. If your customers can’t use your app, you’ll lose their money and their trust.</p>
<p>Typically, we talk about two kinds of Denial-of-Service attacks:</p>
<ol>
<li>“Normal” Denial-of-Service (DoS) attacks, where a single machine is sufficient to cause downtime. The classic, old-school version of this attack is the <a href="https://en.wikipedia.org/wiki/Zip_bomb" target="_blank" rel="noopener">zip bomb</a>: an attacker tricks your server into expanding a specially-crafted ZIP file that is tiny compressed but expands to entirely fill your disk space.</li>
<li>Distributed Denial-of-Service (DDoS) attacks. These attacks rely on an attacker sending a huge flood of traffic to your site from multiple machines (that’s the “Distributed” part). Often, these attacks come from <a href="https://en.wikipedia.org/wiki/Botnet" target="_blank" rel="noopener">Botnets</a> — fleets of compromised machines controlled by an attacker. These botnets are available to purchase in certain corners of the Internet, making a DDoS attack well within the reach of anyone with a credit card.</li>
</ol>
<p>Engineers who work on web applications frequently run into vulnerabilities that could be used in a DoS/DDoS attack. Unfortunately, there’s broad disagreement in the industry about how to treat these vulnerabilities. The risk can be difficult to analyze: I’ve seen development teams argue for <em>weeks</em> over how to handle a DoS vector.</p>
<p>This article tries to cut through those arguments. It provides a framework for engineering and application security teams to think about denial-of-service risk, breaks down DoS vulnerabilities into high-, medium-, and low-risk classes, and has recommendations for mitigations at each layer.</p>
<p>The primary focus of this post is on the big picture, and should apply to any kind of web app. But to make things concrete, I’ve added a few specific Django-related examples. (I helped create it, so it’s what I’m most familiar with.)</p>
<h2>Evaluating Denial-of-Service Risk</h2>
<p>Evaluating the risk of a DoS vulnerability at the application layer can be difficult. There’s widespread disagreement among security professionals: you’ll often see two different appsec teams treat similar issues very differently.</p>
<p>Some argue: it’s nearly impossible to entirely mitigate against a focused DDoS — a dedicated enough attacker can throw more bandwidth at you than your app can handle. You can never fully mitigate a DDoS attack without serious support from an upstream network provider with specific tools to protect bot attacks (e.g., Cloudflare). Thus, chasing and fixing hypothetical DoS vulnerabilities can seem like a waste of developer time. These teams treat most potential DoS vectors as acceptable risk, and focus their energy at preparing mitigations at the network level.</p>
<p>Other teams point out that the traditional risk model has three potential problem areas: Confidentiality, Integrity, and <em>Availability</em>. We’ve long understood that uptime is a security issue. It’s becoming increasingly common for attackers to take a service down and then demand a ransom to stop the attack. The recent <a href="https://www.theverge.com/2020/8/4/21353842/garmin-ransomware-attack-wearables-wastedlocker-evil-corp" target="_blank" rel="noopener">attack against Garmin</a> is a highly notable example; attackers took down nearly all of Garmin’s services, and reportedly demanded US $1 million to stop the attack. (In this case the attack was ransomware, but it’s easy to see how a DoS attack could have a similar effect). Thus, DoS vulnerabilities are risks like any other, and it’s easy to understand the argument that they should all be mitigated.</p>
<p>It’s important to recognize that both of these positions are valid! It’s reasonable to see DoS as out-of-scope for application security; it’s similarly reasonable to scope it in. I’ve often seen security teams get completely stuck arguing between these two positions. Since neither is “right” or “wrong”, it can be impossible to figure out how to move forward.</p>
<h3><strong>How I decide: <em>attacker leverage</em></strong></h3>
<p>The model I use to cut through this argument is the concept of <em>attacker leverage</em>. Levers amplify force: a small amount of force applied to the long end of the lever is multiplied at the short end. In the context of a DoS attack, if a vulnerability has <em>high leverage</em> it means attackers can consume a ton of your server resources with minimal resources.</p>
<p>For example, if a bug in your web app allows a single <code>GET</code> request to consume 100% CPU, that’s a terrific amount of leverage. Just a small handful of attacks, and your web servers will grind to a halt. A <em>low leverage</em> vulnerability, on the other hand, requires a high amount of attacker resources to cause minor availability degradation. If an attacker has to spend thousands of dollars to bring a single server to its knees, you can probably scale up faster than they can.</p>
<p>The higher the leverage, the higher the risk, and the more likely I am to address the issue directly. The lower the leverage, the more likely I’ll accept the risk and/or lean on network-level mitigations.</p>
<p>Let’s get specific. I’ve broken down DoS risk into high, medium, and low risk classes, based on leverage. For each class, I’ll look at how to recognize that a vulnerability falls into this class, discuss a few examples, and give some suggestions for mitigation.</p>
<h2>High leverage DoS vulnerabilities: easily-amplified resource starvation</h2>
<p>The classic high-risk DoS vulnerability is one where an attacker can cause resource starvation using very little resources themselves. This could mean exhaustion of any number of types of resources, including:</p>
<ul>
<li><strong>Disk space</strong> — e.g., a vulnerability that magnifies uploaded data and fills the disk, as in the case of the classic <a href="https://en.wikipedia.org/wiki/Zip_bomb" target="_blank" rel="noopener">zip bomb</a>.</li>
<li><strong>Network bandwidth</strong> — e.g., a vulnerability that amplifies input traffic, where a single incoming request consumes tons of bandwidth, causing network starvation. I’ve seen this happen with a bug in a microservices system, where a single incoming request triggered millions of internal API requests (including moving some fairly large files around the network), and choked off the internal network bandwidth.</li>
<li><strong>CPU utilization</strong> — e.g., an exploit that triggers an <a href="https://accidentallyquadratic.tumblr.com/" target="_blank" rel="noopener">accidentally quadratic</a> algorithm, causing web servers to grind to a halt.</li>
<li><strong>Concurrency limits</strong> — most servers have a maximum concurrency limit (e.g., max threads or processes, or max connections for a database); an exploit that causes a process to run very slowly (or never exit) can cause the server to hit those limits and start rejecting requests.</li>
</ul>
<p>In all these cases, the unifying factor is that a bug in the application will allow significant amplification.</p>
<h3><strong>Authentication affects risk</strong></h3>
<p>When considering the risk of a resource amplification DoS vector, an important factor is the level of authentication required to trigger the vulnerability.
If a completely anonymous user can easily trigger a resource starvation attack, it’ll be extremely easy for an attacker to bring you to your knees. Unauthenticated DoS vectors should be considered very high risk.
On the other hand, if only users who authenticate against your corporate Single Sign-On server can trigger the vulnerability, it’s far lower risk. Most attackers aren’t insiders (though, some are!). And, if an attack does occur, it’s easy to attribute and block. In many cases, “we can attribute and block this attack” is a reasonable, if not complete, mitigation strategy.
Many vulnerabilities fall between these two extremes: most services make creating new accounts fairly trivial (e.g., you just need an email address). This does give minimal ability to attribute and block, but often not enough.</p>
<h3><strong>Mitigation recommendation: eliminate</strong></h3>
<p>Generally, I recommend that this class of DoS vulnerabilities — especially unauthenticated ones — be treated as high risk, and eliminated. If exploited, these vulnerabilities can be devastating; they allow a single attacker to completely overwhelm your app. I’d put the same level of effort into finding and eliminating these kinds of bugs that I do other high-risk security vulnerabilities like XSS and CSRF.</p>
<h3><strong>An example high-leverage vulnerability: ReDoS</strong></h3>
<p>A common example of this last type of resource starvation, concurrency limits, is the <em>regular expression denial-of-service</em>, aka <em>ReDoS</em>. ReDoS bugs occur when certain types of strings can cause improperly crafted regular expressions to perform extremely poorly. These types of vulnerabilities are unfortunately relatively common in Python; the built-in regular expression module (<code>re</code>) has no inherent protection against them (unlike libraries like <a href="https://github.com/google/re2" target="_blank" rel="noopener">re2</a>, Go’s built-in regex module, and thus renders the language more or less immune to this class of attack).
(Django itself has had several of these vulnerabilities over the years; for example, <a href="https://www.djangoproject.com/weblog/2019/aug/01/security-releases/" target="_blank" rel="noopener">CVE-2019-14232 and CVE-2019-14233</a> were both ReDoS vulnerabilities).
In Django, these vulnerabilities most often show up in two places: <a href="https://docs.djangoproject.com/en/3.1/topics/http/urls/#using-regular-expressions" target="_blank" rel="noopener">regex-based URL parsing</a> and <a href="https://docs.djangoproject.com/en/3.1/ref/validators/" target="_blank" rel="noopener">custom validators</a>, and more broadly anywhere an application uses regular expressions. Luckily, this class of vulnerabilities are fairly easy to find; see the following r2c articles:</p>
<ul>
<li><a href="https://r2c.dev/blog/2020/finding-python-redos-bugs-at-scale-using-dlint-and-r2c/" target="_blank" rel="noopener">Finding Python ReDoS bugs at scale using Dlint and r2c</a>, and</li>
<li><a href="https://r2c.dev/blog/2020/improving-redos-detection-with-dlint-and-r2c/" target="_blank" rel="noopener">Improving ReDoS detection and finding more bugs using Dlint and r2c</a></li>
</ul>
<p>If you’re using Python, you can easily scan for ReDoS in your application using Semgrep, which has ReDoS detection ported from Dlint. The detection requires some extra logic written using Semgrep’s powerful pattern-where-python clause, which enables rules to leverage the full power of Python, …</p></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://r2c.dev/blog/2020/understanding-and-preventing-dos-in-web-apps/">https://r2c.dev/blog/2020/understanding-and-preventing-dos-in-web-apps/</a></em></p>]]>
            </description>
            <link>https://r2c.dev/blog/2020/understanding-and-preventing-dos-in-web-apps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24445886</guid>
            <pubDate>Fri, 11 Sep 2020 18:35:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Change Your Mind over a Glass of Wine]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24445685">thread link</a>) | @Elof
<br/>
September 11, 2020 | https://neo.life/2020/09/how-to-change-your-mind-over-a-glass-of-wine/ | <a href="https://web.archive.org/web/*/https://neo.life/2020/09/how-to-change-your-mind-over-a-glass-of-wine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        
<p>Expertise is less about knowledge and more about observing things that elude novices. Through training, experts learn to see, taste, smell, and hear things that the rest of us can’t, therefore allowing them to perceive the world differently. This became clear to me after spending a weekend in conversation with an expert winemaker in Napa Valley.&nbsp;</p>



<p>Wine tasting is a peculiar profession (and not just because critics spit $50 mouthfuls into a bucket). Sommeliers can sound like they’re speaking in a strange <a href="https://www.robertparker.com/resources/glossary-terms">foreign language</a>. Wines are said to possess “roundness, generosity, and depth.” Their aromas are berrylike (strawberry, raspberry, blueberry, blackberry, whatever berry), further containing hints of tobacco, vanilla, leather, and plum. Other aroma labels don’t sound like they belong in food, like “<a href="http://www.mustwineblog.com/blog/2015/1/15/the-10-most-ridiculous-wine-descriptors">pencil shavings</a>,” “<a href="https://www.awri.com.au/wp-content/uploads/Sept-Oct-2012-AWRI-Report.pdf">petrol</a>,” and—wait for it—“<a href="https://timatkin.com/cork-talk/cats-pee/">cat’s piss</a>.”&nbsp;</p>



<p>But all these things cannot possibly be in a glass of wine, can they?&nbsp;</p>



<p>The lyrical waxing of wine experts is hard to buy in its sincerity. Even poets like Kingsley Amis mocked their manners: “When I find someone I respect writing about an edgy, nervous wine that dithered in the glass, I cringe. When I hear someone that I don’t respect talk about an austere, unforgiving wine, I turn a bit austere and unforgiving myself … You can call a wine red, and dry, and strong and pleasant. After that, watch out…”</p>



  




<p>Lots of people think of wine tasting as a <a href="https://www.realclearscience.com/blog/2014/08/the_most_infamous_study_on_wine_tasting.html">scam</a>. But wine tasting is a true scientific art—it’s just that words sometimes get in the way of it being taken seriously. Gasoline-smelling wines do not contain petrol per se—we hope—but often share compounds with another substance with a recognizable aroma. The brains of sommeliers learn how to link categories of sensory experience (i.e., “this smells like petrol”) to qualitative categories of specific chemical compounds. Aged Riesling, for example, contains <a href="https://pubmed.ncbi.nlm.nih.gov/22397689/">TDN</a> (short for 1,1,6-trimethyl-1,2-dihydronaphthalene), a compound with the aroma of petrol. TDN is a result of carotenoids (organic pigments found in many foods, including grapes) breaking down, a process accelerated by higher temperatures. Many odd wine descriptors, including “rubber hose” and—yes—“cat’s piss,” can be identified as a specific chemical compound by expert noses. In the case of cat’s piss, it’s the compound  pyrazine found in Sauvignon Blanc.</p>



<p>Wine has several hundred aroma compounds, which is more molecular information than most of our brains have the ability to compute. Sommeliers have learned how to direct their sensory spotlight to identify specific compounds in a complex mixture. They have trained themselves to be extremely good at discriminating and identifying individual aromas and aroma patterns. The best wine experts can identify a vintage down to its specific vineyard and even year with a virtuosity that can occasionally take less than <a href="https://www.youtube.com/watch?v=PKNmcCCE15E">a minute</a>.&nbsp;</p>



<p>Acquiring this skillset not only makes sommeliers a knowledgeable (if not sometimes exasperating) dinner-party guest. It actually alters the structure and activity of their brains.&nbsp;</p>



<p>Comparing <a href="https://www.sciencedirect.com/science/article/pii/S0010945218303356">the brain of a mathematician</a> with that of a <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4992723/">sommelier</a>, we find remarkable similarities. In both cases, the cellular density of white and gray matter in designated areas increases. Whether it’s sniffing Syrah or performing calculus, the acquisition of expertise makes&nbsp; parts of the brain thicker. In mathematicians, for example, one of the most prominent changes in the density of gray matter is found in the superior frontal gyrus, an area also linked with the coordination of <a href="https://www.sciencedirect.com/science/article/pii/S0896627306002121">self-awareness</a> and, most intriguing, <a href="https://www.nature.com/articles/35536">laughter</a>. In comparison, changes in sommeliers’ brain volume were found in the right insula and entorhinal cortex, areas that are notably involved in memory processing. Such changes in neural density give those areas enhanced cortical connectivity and signaling speed, as the synaptic connections by which neurons communicate become more tightly packed. A consequence of increased neural density is that dedicated specialized areas of the brain better integrate and orchestrate otherwise widespread neural activity. Expertise of any kind results in a more sophisticated communication architecture of the brain.&nbsp;</p>



<p>But here’s the paradox. When an expert’s brain grows, they also use less of it. The more proficient you are at wine tasting, the less activity we’ll see in your brain’s <a href="https://www.frontiersin.org/articles/10.3389/fnbeh.2014.00358/full">fMRI recording</a>, as reported in a scientific study from 2014. If you’re processing more information, though, how are you using your brain less? This observation is less puzzling if you compare your brain to the body of an athlete. You’ll need to put in less overall effort to lift weights if your body is trained to do so routinely. With practice, some brain activities become “automatized” and, according to the neuroscientist Christof Koch, resemble a “<a href="https://www.nature.com/articles/35082161">zombie agent</a>”—meaning these processes require less and less conscious effort and attention.&nbsp;</p>



<p>So do sommeliers become merely better at memorizing patterns, like in the legendary study of <a href="https://www.scientificamerican.com/article/london-taxi-memory/">hippocampi in London cab drivers</a>, or do they also get better at the sensory part of smelling itself? The answer is both. Notably, a sommelier’s skill is not exclusively a method of memory (<em>this</em> is what a Cabernet Sauvignon typically smells like, and <em>that</em> is the aroma profile of a Barolo). Training further enhances their ability to be more receptive to aromas in a mixture: the sensitivity to odors changes with repeated exposure.&nbsp;</p>



<blockquote><p>Whether it’s sniffing Syrah or performing calculus, the acquisition of expertise makes&nbsp; parts of the brain thicker.</p></blockquote>



<p>Yet the real surprise is this: The previously mentioned 2014 fMRI study on expert sommeliers suggests that sensory expertise <em>modifies your experience of reality</em>—it affects not just the ability to identify and recall things on a cognitive level, but also consciousness itself. During tasting, the scientists observed activation in the brain stem of experts but not in novices. This finding (which is still being further explored) implies a difference in how sensory information is integrated into the cortical cognitive activity of experts and novices. Engaging with your perception on an analytical level thus makes a difference in the quality of your experience by fine-tuning your brain to its input (and having it reorganize its neural story to match).&nbsp;</p>



<p>Hold that thought: You get more control of the quality and content of your own conscious experience … by thinking while drinking wine.&nbsp;</p>



<p>And yet we hesitate to trust sommeliers’ abilities. That’s because of our outmoded views of mind and brain, particularly our understanding of the senses. The philosopher <a href="https://plato.stanford.edu/entries/descartes/">René Descartes</a>, the influential source of so many misled thoughts about the mind, famously claimed that you could not <a href="https://twitter.com/CliffordSosis/status/1299421713965494276?s=20">trust</a> your senses. He believed that the existence of illusions proved the unreliability of perception, and that it is impossible to establish a difference in the experience of dreams and reality.&nbsp;</p>



<p>Descartes’ skepticism led him as far as to doubt whether our entire experience may just be a hallucination induced by an evil demon. And you can’t trust your senses to reflect reality, neither by referring to what you see and hear or smell, nor by any other empirical observation. (Although demons are said to come with a pungent odor.) For Descartes, the only assurance of our material existence was the use of pure analytic reason—<em>I think, therefore I am</em>. The irrefutable truth from which all other truths must follow.&nbsp;</p>



<p>Except Descartes was wrong. Our senses do not “deceive” us. They are built on experience. That experience can vary through our engagement with the world, and therefore different people see, taste, hear, smell, and feel the world differently. There isn’t one shared reality that all conscious beings observe; the wine tastes different to all of us, despite the drop in our glass being from the same bottle. The dress is <a href="https://en.wikipedia.org/wiki/The_dress">black and blue</a>. I heard <a href="https://en.wikipedia.org/wiki/Yanny_or_Laurel">Laurel, not Yanny.</a>&nbsp;</p>



<p>This shows how perception is markedly <a href="http://philsci-archive.pitt.edu/14721/">dynamic</a>. That insight amounts to more than saying that you create your own reality. As sensory expertise enrichens the content of conscious awareness, you perceive <em>more</em> of the world, not just differently.</p>



<p>The acquisition of expertise broadens your perspective—and not only on the particular thing you specialize in. Acquiring expertise has the hidden benefit of developing a cognitive meta-skill: you learn how to learn. Such a skill provides a scaffold—both sensory and cognitive—to approach learning about other areas you may not be sufficiently familiar with. Knowing one thing well allows you to branch out to other things without getting lost in the process. Knowledge develops with experience, and experience develops with knowledge. Or as Eleanor Roosevelt said: “When you are genuinely interested in one thing, it will always lead to something else.”</p>

                    </div></div>]]>
            </description>
            <link>https://neo.life/2020/09/how-to-change-your-mind-over-a-glass-of-wine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24445685</guid>
            <pubDate>Fri, 11 Sep 2020 18:18:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Sorcerer’s Apprentice Guide to Training LSTMs]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24445617">thread link</a>) | @nshr
<br/>
September 11, 2020 | https://www.niklasschmidinger.com/posts/2020-09-09-lstm-tricks/ | <a href="https://web.archive.org/web/*/https://www.niklasschmidinger.com/posts/2020-09-09-lstm-tricks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<nav id="TOC">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#vanilla-lstm">Vanilla LSTM</a>
<ul>
<li><a href="#input-activation-functions-and-the-drift-effect">Input Activation Functions and the Drift Effect</a></li>
<li><a href="#forget-gates-and-vanishing-gradients">Forget Gates and Vanishing Gradients</a></li>
</ul></li>
<li><a href="#focused-lstm">Focused LSTM</a></li>
<li><a href="#lightweight-lstm">Lightweight LSTM</a></li>
<li><a href="#ticker-steps">Ticker Steps</a></li>
<li><a href="#negative-gate-biases">Negative gate biases</a></li>
<li><a href="#scaled-activation-functions">Scaled activation functions</a></li>
<li><a href="#linear-activation-functions">Linear activation functions</a></li>
<li><a href="#time-awareness">Time Awareness</a></li>
<li><a href="#separation-of-memory-and-compute">Separation of Memory and Compute</a></li>
<li><a href="#chicken-and-egg-online-learning-and-more-cells-than-necessary">Chicken and Egg, online learning and more cells than necessary</a></li>
<li><a href="#sequence-classification-vs.-continuous-prediction">Sequence classification vs.&nbsp;continuous prediction</a>
<ul>
<li><a href="#parallel-lstm-networks-for-continuous-prediction">Parallel LSTM networks for continuous prediction</a></li>
</ul></li>
<li><a href="#target-and-input-scaling">Target and input scaling</a></li>
</ul>
</nav>
<hr>
<h2 id="introduction">Introduction</h2>
<div data-layout="l-body">
<div><p><span id="fig:sorcerer"></span>
<img src="https://www.niklasschmidinger.com/posts/2020-09-09-lstm-tricks/images/zauberlehrling.png" alt="The sorcerer's apprentice. Illustration by Ferdinand Barth circa 1882." width="400"></p><p>
Figure 1: The sorcerer’s apprentice. Illustration by Ferdinand Barth circa 1882.
</p>
</div>
</div>
<blockquote>
<div><p>Gone’s for once the old magician<br> With his countenance forbidding;<br> I ’m now master,<br> I ’m tactician,<br> All his ghosts must do my bidding.<br> Know his incantation,<br> Spell and gestures too;<br> By my mind’s creation<br> Wonders shall I do.</p><p>  – Johann Wolfgang von Goethe (The sorcerer’s apprentice)</p></div>
</blockquote>
<p>While mulling over old papers and hacking away at their computers, scholars build up an intimate knowledge about their research topic. As they chart their way through idea space, they develop a deep intuition on which techniques work well in practice. Unfortunately, many of these hard-earned insights are not published and remain obscure.</p>
<p>Last year, I took a course at the Johannes Kepler University in Linz, Austria on the topic of Recurrent Neural Networks and Long Short-Term Memory Networks. There, Sepp Hochreiter shared some of the “magic tricks” he and his team employ for training LSTMs. This blog post is the accumulation of some of my notes.</p>
<p>For this post, I assume you are already familiar with LSTMs. If not, I suggest you begin with Chris Olah’s <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Networks</a> and then go on to read the original LSTM work <span data-cites="hochreiter1997long">(Hochreiter and Schmidhuber <a href="#ref-hochreiter1997long" role="doc-biblioref">1997</a>)</span>.</p>
<p>Before we begin, I’d also like to highlight some resources that are similar in their motivation:</p>
<ul>
<li>Andrej Karpathy’s <a href="http://karpathy.github.io/2019/04/25/recipe/">general recipe for training neural networks</a>.</li>
<li>Danijar Hafner’s tips for training recurrent neural networks <span data-cites="hafner2017rnntips">(Hafner <a href="#ref-hafner2017rnntips" role="doc-biblioref">2017</a>)</span>.</li>
<li>LSTM: A Search Space Odyssey <span data-cites="Greff_2017">(Greff et al. <a href="#ref-Greff_2017" role="doc-biblioref">2017</a>)</span> from IDSIA (Dalle Molle Institute for Artificial Intelligence).</li>
</ul>
<p>In case you want to experiment with some of the presented techniques and you need a flexible Pytorch-based LSTM implementation, I recommend Michael Widrich’s <a href="https://github.com/widmi/widis-lstm-tools">LSTM Tools library</a>.</p>
<p>All credits for the presented techniques go to the authors. All errors in their presentation are mine. I am always keen to receive feedback.</p>
<h2 id="vanilla-lstm">Vanilla LSTM</h2>
<p>The <em>Vanilla LSTM</em> is one of the most prevalent variants and is often the default LSTM architecture in popular software libraries. It is characterized by three gates and a memory state – the gates provide the model with capacity and protect the memory cells from distracting information and noise; they make the dynamics of the LSTM highly non-linear and allow it to learn to perform complex operations.</p>
<p>Let us briefly step through the Vanilla LSTM’s mechanics to introduce the notation and terminology used in this post. Sensory inputs <span>\(\boldsymbol{x}(t)\)</span> flowing into the LSTM cell at a given time step are transformed into the <em>cell input activation</em> <span>\(\boldsymbol{z}(t)\)</span> – the elements of <span>\(\boldsymbol{z}(t)\)</span> are activated by a non-linear function <span>\(g(\cdot)\)</span>, which in practice is often defined as the <em>hyperbolic tangent</em> or <em>tanh</em>. Information that is irrelevant for the current time step is removed by multiplying <span>\(\boldsymbol{z}(t)\)</span> element-wise by a sigmoid-activated <em>input gate</em> <span>\(\boldsymbol{i}(t)\)</span>. Similarily, the <em>cell state</em> of the previous time step <span>\(\boldsymbol{c}(t-1)\)</span> is partially erased using a sigmoid-activated <em>forget gate</em> <span>\(\boldsymbol{f}(t)\)</span>. The new memory cell state <span>\(\boldsymbol{c}(t)\)</span> is computed by adding the current cell state update <span>\(\boldsymbol{i}(t) \odot \boldsymbol{z}(t)\)</span> to the the filtered old state <span>\(\boldsymbol{f}(t) \odot \boldsymbol{c}(t-1)\)</span>. Finally, the LSTM squashes the memory contents into a specific numerical range using the <em>memory cell activation function</em> <span>\(h(\cdot)\)</span> and filters the result through an <em>output gate</em> <span>\(\boldsymbol{o}(t)\)</span>. This results in the final <em>memory cell state activation</em> <span>\(\boldsymbol{y}(t)\)</span>.</p>
<p>Mathematically, the Vanilla LSTM can be defined by the following set of equations:</p>
<p><span>\[
\begin{align}
\boldsymbol{i}(t) &amp;= \sigma\left(\boldsymbol{W}_{i}^{\top} \boldsymbol{x}(t)+\boldsymbol{R}_{i}^{\top} \boldsymbol{y}(t-1)\right) \\
\boldsymbol{o}(t) &amp;= \sigma\left(\boldsymbol{W}_{o}^{\top} \boldsymbol{x}(t)+\boldsymbol{R}_{o}^{\top} \boldsymbol{y}(t-1)\right) \\
\boldsymbol{f}(t) &amp;= \sigma\left(\boldsymbol{W}_{f}^{\top} \boldsymbol{x}(t)+\boldsymbol{R}_{f}^{\top} \boldsymbol{y}(t-1)\right)  \\
\boldsymbol{z}(t) &amp;= g\left(\boldsymbol{W}_{z}^{\top} \boldsymbol{x}(t)+\boldsymbol{R}_{z}^{\top} \boldsymbol{y}(t-1)\right) \\
\boldsymbol{c}(t) &amp;= \boldsymbol{f}(t) \odot \boldsymbol{c}(t-1)+\boldsymbol{i}(t) \odot \boldsymbol{z}(t) \\
\boldsymbol{y}(t) &amp;= \boldsymbol{o}(t) \odot h(\boldsymbol{c}(t))
\end{align}
\]</span></p>
<p>Where <span>\(\sigma\)</span> denotes the sigmoid activation function and <span>\(\odot\)</span> the element-wise or Hadamard product. Note that each of the gates has access to the current input <span>\(\boldsymbol{x}(t)\)</span> and the previous cell state activation <span>\(\boldsymbol{y}(t-1)\)</span>.</p>
<p>Also remember, that the weights <span>\(W\)</span> and recurrent weights <span>\(R\)</span> are shared between time steps.</p>
<div data-layout="l-body">
<div><p><span id="fig:vanilla"></span>
<img src="https://www.niklasschmidinger.com/posts/2020-09-09-lstm-tricks/images/vanilla_lstm_legend.png" alt="Schematic of the Vanilla LSTM Cell with unrolled cell state. Figure adopted from [@Greff_2017]." width="1190"></p><p>
Figure 2: Schematic of the Vanilla LSTM Cell with unrolled cell state. Figure adopted from <span data-cites="Greff_2017">(Greff et al. <a href="#ref-Greff_2017" role="doc-biblioref">2017</a>)</span>.
</p>
</div>
</div>
<h3 id="input-activation-functions-and-the-drift-effect">Input Activation Functions and the Drift Effect</h3>
<p>In practice, the input activation function <span>\(g\)</span> is often chosen to be tanh. But this choice is non-obvious and in fact, in the original LSTM paper sigmoid was used to activate <span>\(\boldsymbol{z}\)</span>. As the memory cell’s purpose is to learn and memorise patterns over time, sigmoid activations are a natural choice to indicate the presence (activation with a value close to <span>\(1\)</span>) or absence (activation with a value close to <span>\(0\)</span>) of entities in the input. Tanh on the other hand with a lower bound of <span>\(-1\)</span> doesn’t seem to make intuitive sense. What is a negative pattern? Does an activation with value <span>\(-1\)</span> indicate that something is strongly not present in the input?</p>
<p>The adoption of tanh first required two mental shifts. First, tanh makes intuitive sense in a meta-learning setting. Instead of patterns, we now use memory cells to store the weights for another neural network. To indicate whether the values of the weights should be increased or decreased we need both positive and negative values.</p>
<p>The second intuitive interpretation is the storage of <em>hints</em>. A hint in this context is evidence in favour of or against something. Consider an example from text analysis. Assume that a model encounters the words “Team”, “Player” and “Goal” in a paragraph. These are all strong hints that the text is about sports, but if the next passage includes the words “Manager”, “Revenue” and “Shareholder” it is a strong indication that the paragraph actually describes a business context. Positive values can be seen as hints in favour of and negative values as hints against certain classes.</p>
<p>But there is a simple mathematical reason why tanh is the preferred choice to activate the cell input. Compared to commonly used activation functions such as ReLU and sigmoid the expected value of the cell input activation is zero for tanh (under the assumption of zero-mean Gaussian pre-activations):</p>
<p><span>\[\mathbb{E}(\boldsymbol{z}(t)) = 0\]</span></p>
<p>To understand why this property is desirable, remember how the cell state is updated at a given time step<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a>:</p>
<p><span>\[\boldsymbol{c}(t) = \boldsymbol{c}(t-1)\color{#9900ff}{+\boldsymbol{i}(t) \odot \boldsymbol{z}(t)}\]</span></p>
<p>At each time step we add the cell input activation <span>\(\boldsymbol{z}(t)\)</span> (filtered by the input gate) to the previous cell state <span>\(\boldsymbol{c}(t-1)\)</span>. If we choose an activation function for <span>\(\boldsymbol{z}\)</span>, such that each activation has a value <span>\(\geq 0\)</span> (e.g.&nbsp;sigmoid, ReLU, etc.), <span>\(\boldsymbol{c}\)</span> will quickly take on very large values. Even if the activations are relatively small, the cell state will grow large for sufficiently long sequences. This problem is known as the <em>drift effect</em>.</p>
<p>But how can large memory cell states become a hindrance to learning? To answer this question, we need to take a look at the LSTM’s backward pass:</p>
<p><span>\[
\begin{aligned}
\frac{\partial L}{\partial \boldsymbol{c}(t)} &amp;=\frac{\partial L}{\partial \boldsymbol{y}(t)} \color{#9900ff}{\frac{\partial \boldsymbol{y}(t)}{\partial \boldsymbol{c}(t)}}+\frac{\partial L}{\partial \boldsymbol{c}(t+1)} \frac{\partial \boldsymbol{c}(t+1)}{\partial \boldsymbol{c}(t)} \\
&amp;=\frac{\partial L}{\partial \boldsymbol{y}(t)} \operatorname{diag}\left(\boldsymbol{o}(t) \odot \color{#9900ff}{h^{\prime}(\boldsymbol{c}(t))}\right)+\frac{\partial L}{\partial \boldsymbol{c}(t+1)}
\end{aligned}
\]</span></p>
<p>The equation recursively sums up all error signals from the future and carries them backwards in time. Intuitively, it describes the different ways in which the cell state at time <span>\(t\)</span> influences the loss <span>\(L\)</span>. We take a closer look at the highlighted term <span>\(\partial \boldsymbol{y}(t) / \partial \boldsymbol{c}(t)\)</span> , which describes how the memory cell state activation <span>\(\boldsymbol{y}(t)\)</span> changes as <span>\(\boldsymbol{c}(t)\)</span> changes. The partial derivative can be obtained by calculating <span>\(\operatorname{diag}\left(\boldsymbol{o}(t) \odot h^{\prime}(\boldsymbol{c}(t))\right)\)</span>. And now we are in trouble. Remember that we use the tanh as the memory cell activation function <span>\(h\)</span> to squash the memory cell state into the numerical range <span>\((-1, 1)\)</span>. Its derivative is defined as follows:</p>
<p><span>\[
h^{\prime}(\boldsymbol{x}) = \text{tanh}^{\prime}(\boldsymbol{\boldsymbol{x}}) = 1 - \text{tanh}²(\boldsymbol{x})
\]</span></p>
<p>Now if <span>\(\boldsymbol{c}(t)\)</span> grows very large due to the drift effect, the highlighted term in the second equation will evaluate to <span>\(h^{\prime}(\boldsymbol{c}(t)) = 1-1 = 0\)</span> for each element in <span>\(\boldsymbol{c}(t)\)</span>. As a result, <span>\(\frac{\partial L}{\partial y(t)} \frac{\partial y(t)}{\partial c(t)}\)</span> will be zero and the cell state loses its ability to influence …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.niklasschmidinger.com/posts/2020-09-09-lstm-tricks/">https://www.niklasschmidinger.com/posts/2020-09-09-lstm-tricks/</a></em></p>]]>
            </description>
            <link>https://www.niklasschmidinger.com/posts/2020-09-09-lstm-tricks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24445617</guid>
            <pubDate>Fri, 11 Sep 2020 18:11:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Think Like a Programmer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24445518">thread link</a>) | @renanmoura
<br/>
September 11, 2020 | https://renanmf.com/think-like-a-programmer/ | <a href="https://web.archive.org/web/*/https://renanmf.com/think-like-a-programmer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>A programmer is not someone who types super fast (yes, you have been fooled by movies and TV series).</p>
<p>Programming is about problem-solving.</p>
<p>Most of the time, a programmer is thinking about the problem and how to solve it.</p>
<p>Problem-solving is a skill that requires creativity.</p>
<p>And just like any other skill, it can be learned.</p>
<p>The best way to learn is to practice with different problems and projects.</p>
<p>Solving different problems will teach you different skills.</p>
<p>Don’t worry too much about syntax, you can always google it if you don’t remember, but the reasoning behind solving a problem is something you have to develop by yourself.</p>
<p>The general problem-solving flow is like this:</p>
<ul>
<li>Analyze and understand the problem</li>
<li>What are the inputs</li>
<li>What is the required output</li>
<li>Plan the solution</li>
<li>Break the problem into smaller parts </li>
<li>Break the parts into tasks</li>
<li>If you get stuck, step back a little and rethink your approach</li>
<li>Test the solution</li>
<li>Fix errors that might appear, face them like challenges, not annoyances </li>
<li>Iterate the steps until success</li>
</ul>
<p>Programming teaches you to think better.</p>
<h2>Problem-Solving flow</h2>
<p>A program doesn’t exist without a goal.</p>
<p>You code because someone in your company or an external client requested a solution for a problem they have.</p>
<p>Developing a system is a project and as such, must be treated as one.</p>
<p>You have a new project to develop, a new program, there some important things you should check before coding to maximize the chances of success of your endeavor.</p>
<p>The first thing is:</p>
<h3>Stakeholders and their problems</h3>
<p>Ask yourself: who is using this program? what for? what problem do they have that I am solving?</p>
<p>Stakeholders can be your boss, a client, or the actual person who is going to use the program, the so-called end-user.</p>
<p>Talk to these people.</p>
<p>Don’t assume you know what they need, you will waste time and resources and feel frustrated when you find out that what you built does not fill the gap as needed.</p>
<p>Take notes in an organized way of everything they tell you.</p>
<p>These notes will turn into the second thing:</p>
<h3>Requirements</h3>
<p>Every software has requirements like: </p>
<ul>
<li>"I must be able to manage my customer data"</li>
<li>"I need the input X to become output Y"</li>
<li>"I have thousands of spreadsheets with sales information and want to know how much did we profit monthly on average in the last 5 years combining their data"</li>
</ul>
<p>Analyze and understand the problem and turn it into requirements you have to fulfill, describe in words what has to be done for your program to be successful.</p>
<p>The third step is to:</p>
<h3>Break down the requirements into tasks</h3>
<p>The requirement "I have thousands of spreadsheets with sales information and want to know how much did we profit monthly on average in the last 5 years combining their data" translates to:</p>
<ul>
<li>Create a way to input/import all the spreadsheets</li>
<li>Process the data to get only what is related to sales profit, since the spreadsheets have a bunch of information I don’t need such as names and addresses</li>
<li>Group the sales profit by month and average them</li>
<li>I have to output another spreadsheet with the result</li>
</ul>
<p>With these written down, you have a clear path on what to do and you are able to track your progress and report it back to the stakeholders and show them you are advancing in each task.</p>
<p>If your requirement includes a screen or a form in a website, you can also draw a rough sketch of how it is going to look like, which field goes where, to serve as a model.</p>
<p>You then discuss these tasks and sketches with the stakeholders to check if you understood the problem well and if you are on the right track.</p>
<p>This is a good point to find some mistakes and correct the direction before wasting resources coding a solution.</p>
<p>The fourth step is to:</p>
<h3>Design and code your solution</h3>
<p>Now you can work on your code.</p>
<p>Define which libraries you will need, which functions should you create, what approach should you use.</p>
<p>This varies a lot from programmer to programmer, my solution will differ from yours and they will be both right.</p>
<p>There is no single solution to a problem in programming.</p>
<p>The fifth step is to:</p>
<h3>Test and iterate</h3>
<p>First, test it on your own and check your test cases.</p>
<p>In the example of the spreadsheets, you can try to use just a few files, say 3, to check if your code outputs the same results that you achieved but doing the process manually.</p>
<p>Doing the process manually is simply taking each spreadsheet and making the process of taking the average monthly profit by hand, just like the end-user would, and yes, it usually takes a long time to do it.</p>
<p>It is usually better to ask the end-user to provide this manual test case instead of doing it yourself because they will most likely do it faster and more accurately.</p>
<p>If your code doesn’t output the same, you have to iterate, find the error, fix it, and test again until it matches the expected output.</p>
<p>If your test ran alright, give the solution to the stakeholders, so they can try it with more test cases and give you feedback if there is something to fix, enhance, or if your solution is just right.</p>
<p>Embrace this process and you will be way more successful than just sitting and coding in dark.</p>
<h2>Finding help</h2>
<p>What to do if you get stuck?</p>
<p>It does not matter if you are a beginner or a pro, you will eventually get stuck.</p>
<p>I’ve been coding for a long time and I still get stuck.</p>
<p>Finding a way out of a problem by yourself is a major ability for a programmer and you should get used to it.</p>
<p>If you see an error, the first thing is to stop and read it carefully.</p>
<p>Sometimes the error is very explicit in telling you what went wrong and what you should do.</p>
<p>See error messages as a friend pointing you in the right direction.</p>
<p>Some errors are not so friendly though.</p>
<p>In this case, Google is your best friend.</p>
<p>Chances are, someone has been through this error before and there is a solution for it on the internet.</p>
<p>Just copy and paste the error message on Google and look for the solutions available.</p>
<p>You might need to open more than a few blogs and forums, but trust me, this is a part of the process, and getting good at it is really important.</p>
<p>I encourage you to spend some time reading the official documentation of anything you are learning in tech.</p>
<p>Some documentations are just bad, but most major technologies have good docs and Python is one of them as you can see here <a href="https://www.python.org/doc/">Python Documentation</a>.</p>
<p>Learning from the source is a great advantage in this ever-evolving world of programming.</p>
<p>You might also like:</p>
<ul>
<li><a href="https://renanmf.com/deliberate-practice-and-the-senior-developer/">Deliberate Practice and the Senior Developer</a></li>
<li><a href="https://renanmf.com/machine-learning-for-humans-how-to-learn-better-and-faster/">Machine Learning for Humans: how to learn better and faster?</a></li>
</ul>
</div></div>]]>
            </description>
            <link>https://renanmf.com/think-like-a-programmer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24445518</guid>
            <pubDate>Fri, 11 Sep 2020 18:03:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Arbol, a parametric weather risk platform built on IPFS]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24445508">thread link</a>) | @jschilling
<br/>
September 11, 2020 | https://docs.ipfs.io/concepts/case-study-arbol/ | <a href="https://web.archive.org/web/*/https://docs.ipfs.io/concepts/case-study-arbol/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-4f5abb4a=""> <div><p><strong>"When it comes to data security versus ease of access, it's usually a trade-off. The fact that IPFS doesn't compromise on either is awesome — and it feels great to ditch Amazon S3 buckets for open source."</strong></p> <p><em>— Ben Andre, CTO, Arbol</em></p></div> <h2 id="overview"><a href="#overview">#</a> Overview</h2> <p><img src="https://docs.ipfs.io/assets/img/logo-arbol.e1ca2350.svg" alt="Arbol logo" width="220"></p> <p><a href="https://www.arbolmarket.com/" target="_blank" rel="noopener noreferrer">Arbol</a> is a software platform that connects agricultural entities like farmers and other weather-dependent parties with investors and other capital providers to insure and protect against weather-related risks. Arbol's platform sells contracts for parametric weather protection agreements in a marketplace that's an innovative, data-driven approach to risk management, cutting out the usual legacy insurance claims process of making loss assessments on the ground. Instead, Arbol relies on tamper-proof data indexes to determine payouts, and doesn't require a defined loss to be indemnified. Arbol's platform combines parametric weather protection with blockchain-based smart contracts to provide cost-efficient, automated, and user-defined weather-related risk hedging. As with traditional crop insurance and similar legacy products, end users purchase assurance that they'll be financially protected in the case of adverse weather — but with Arbol, these end users are paid automatically if adverse conditions occur, as defined by the contract and measured by local meteorological observations tracked by Arbol's data sources.</p> <p>To build the data indexes that Arbol uses to handle its contracts, the team aggregates and standardizes billions of data files comprising decades of weather information from a wide range of reputable sources — all of which is stored on IPFS. IPFS is critical to Arbol's service model due to the inherent verifiability provided by its <a href="https://docs.ipfs.io/concepts/content-addressing">content-addressed architecture</a>, as well as a decentralized data delivery model that facilitates Arbol's day-to-day aggregation, synchronization, and distribution of massive amounts of data.</p> <p>While United States agribusiness has been Arbol's initial area of focus, the team has built a globally capable platform, with expansion underway to new regions and industries around the world. Arbol currently provides contracts for managing the risks of weather exposure in the energy and agriculture sectors, and features both custom and pre-designed protection agreements for clients across industries and scale. Their current end-user base ranges from small coffee farms to major agribusinesses and power producers.</p> <p>In short, Arbol's platform is a risk marketplace where end users can get competitively priced risk management solutions and capital providers can benefit from access to a lucrative, but underdeveloped, weather risk market. And because Arbol uses IPFS for its data storage and delivery needs, end users and underwriting partners can be certain that the data Arbol uses to determine price and payouts for contracts is tamper-proof and trustworthy.</p> <h3 id="arbol-by-the-numbers"><a href="#arbol-by-the-numbers">#</a> Arbol by the numbers</h3> <div><div><p>1T</p> <p>weather-related data points hosted on IPFS</p></div><div><p>1M</p> <p>hashes generated on Arbol data every day</p></div><div><p>40</p> <p>years of high-resolution climate data</p></div><div><p>200GB</p> <p>average Arbol dataset size</p></div></div> <h2 id="the-story"><a href="#the-story">#</a> The story</h2> <p>Arbol's story begins with the commodities markets, where Siddhartha Jha, the founder and CEO, worked as a quantitative analyst and portfolio manager. What Jha saw there was a problem without a solution: Massive (and growing) demand for weather risk management for supply chains, farming industries, and the energy sector, but no viable, efficient, or cost-effective weather risk market to meet that demand. Traditional crop insurance was plagued by inefficiencies and high cost ceilings, with insurance providers forced to charge high premiums that only large corporations could afford. And while more efficient parametric insurance solutions were available on the market, even these data-driven options were often saddled with high overhead and bureaucratic waste. As a result, small businesses and local farmers were often trapped without access to protection from weather-related risks.</p> <p>Arbol aims to change that by bringing fundamental transparency, efficiency, and data-driven objectivity to the weather risk market, ensuring that any business of any size can get the appropriate protection they need to manage their level of weather-related risk. The Arbol platform achieves this goal by providing a novel mechanism for weather-exposed businesses to connect with capital providers. The key to Arbol's approach is flexible financial derivatives that leverage the power of big data and machine learning to provide parametric risk protection at low cost. These parametric structures determine automatic payouts based on metrics that are strongly correlated with financial loss.</p> <p>With Arbol, an end user pays to hedge against a specific weather-related event, such as yearly deviation in rainfall amounts or temperature. After deciding on a premium and selecting a payout amount, the end user then relies on Arbol's platform to handle the rest. Because parametric structures are objective and data-driven, they can achieve a level of precision, reliability, and cost effectiveness that traditional insurance cannot. In fact, one of Arbol's key benefits over legacy weather insurance is that it allows for hyper-local protection for managing user-specific levels of risk.</p> <p>Arbol's approach also improves upon standard parametric insurance by combining parametric insurance's precision and flexibility with the security, transparency, and efficiency of blockchain. Many of Arbol's protection agreement contracts are executed as smart contracts on the Ethereum blockchain. These smart contracts automatically deliver payouts to end users as soon as a relevant adverse weather event occurs.</p> <p>Delivering weather risk management solutions through blockchain-based contracts like this eliminates costly payout delays, as well as risks associated with fraud, corruption, and bureaucratic overhead. It also brings the benefits of peer-to-peer decentralization: Arbol users don't need to rely on Arbol as a financial middleman, because funds are locked between end users and capital providers without Arbol controlling the transfer of funds.</p> <p>However, even the best smart contract is only as smart as the data it draws from. The "oracle problem" can be a foundational obstacle for smart contracts — but Arbol's use of IPFS eliminates this risk. Because a smart contract automatically and trustlessly executes based on data, it doesn't matter how secure, transparent, and publicly verifiable its use of blockchain is. Without an accurate, trustworth, and immutable data "oracle", even blockchain-based smart contracts can be easily biased, compromised, or manipulated. For Arbol, that's where IPFS is absolutely critical.</p> <p>IPFS's content-addressed architecture enables Arbol to ensure the integrity and public verifiability of its datasets, something that traditional location addressing using centralized server architecture cannot provide. Smart contracts pointing to specific, immutable IPFS CIDs, rather than to data locations that could be tampered with, can be relied upon thanks to the integrity of their oracle.</p> <div><p><strong>"IPFS is very much at the heart of everything we do at Arbol. IPFS serves as our independently verifiable data store for all of the weather data associated with the contracts we sell. It imbues our platform with the essential principles of decentralization, data security, and public verifiability."</strong></p> <p><em>— Ben Andre, CTO, Arbol</em></p></div> <p>Arbol builds its data indexes by drawing on large weather-related datasets from a variety of trusted public and private sources, including prominent U.S. government institutions such as NASA and the National Oceanic and Atmospheric Administration (NOAA). These sources track weather data including yearly rainfall amounts, temperature fluctuations, wind speeds, and more. However, while much of the data Arbol uses is publicly available, it isn't always easily usable; much of the data, particularly deeper historical records, is stored in outdated formats, and very little of it is organized into an easily readable structure. Arbol's data indexes process, correlate, and package this data so that it is readily available for use in the weather risk market. And by putting that data onto IPFS, Arbol also ensures that it has a verifiable, tamper-resistant, and decentralized home.</p> <h2 id="ipfs-benefits"><a href="#ipfs-benefits">#</a> IPFS benefits</h2> <p>Arbol's business model hinges upon the benefits afforded by IPFS — without its immutable content addressing and inherent data verifiability, the benefits Arbol provides would be impossible to achieve in a cost-effective and efficient way. As a whole, IPFS is critical to Arbol's service model by providing the following:</p> <ul><li><p><strong>Immutable addressing:</strong> Because all data stored using IPFS is referenced and accessed via unique <a href="https://docs.ipfs.io/concepts/content-addressing">content identifiers (CIDs)</a>, any change to a data item means it receives a new CID exclusive to that revision. It's impossible to change data without changing its CID.</p></li> <li><p><strong>Data verifiability:</strong> Contracts on Arbol's platform are linked to specific, verifiably unchanged, content-addressed data. Because parametric weather risk management absolutely relies on user agreement about and trust in source data, Arbol's approach offers reassurance unavailable with other offerings in the market.</p></li> <li><p><strong>Decentralized data delivery:</strong> Arbol works with massive datasets comprising billions of files and terabytes of information. IPFS accommodates Arbol's methodology for publishing and adding to large datasets while still enabling Arbol to release and synchronize these datasets via a decentralized storage network.</p></li></ul> <h2 id="how-arbol-uses-ipfs"><a href="#how-arbol-uses-ipfs">#</a> How Arbol uses IPFS</h2> <p>Arbol's end users enjoy the "it just works" benefits of parametric protection, but a lot goes on behind the scenes to enable this data-driven solution. Arbol's weather datasets range from 1GB to 1TB in size, and each one goes through a detailed ingestion process before it can be used. Once it has been decided that a dataset meets Arbol's criteria for usefulness and validity, it is time to add it to Arbol's IPFS pipeline, a multi-stage process outlined below.</p> <ol><li><p><strong>Query/release:</strong> If a …</p></li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://docs.ipfs.io/concepts/case-study-arbol/">https://docs.ipfs.io/concepts/case-study-arbol/</a></em></p>]]>
            </description>
            <link>https://docs.ipfs.io/concepts/case-study-arbol/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24445508</guid>
            <pubDate>Fri, 11 Sep 2020 18:03:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Don't VCs Index Invest?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24445446">thread link</a>) | @whoisnnamdi
<br/>
September 11, 2020 | https://whoisnnamdi.com/vcs-index-invest/ | <a href="https://web.archive.org/web/*/https://whoisnnamdi.com/vcs-index-invest/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://whoisnnamdi.com/content/images/size/w300/2020/07/header.png 300w,
                            https://whoisnnamdi.com/content/images/size/w600/2020/07/header.png 600w,
                            https://whoisnnamdi.com/content/images/size/w1000/2020/07/header.png 1000w,
                            https://whoisnnamdi.com/content/images/size/w2000/2020/07/header.png 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://whoisnnamdi.com/content/images/size/w2000/2020/07/header.png" alt="Why Don't VCs Index Invest?">
            </figure>

            <section>
                <div>
                    <p>Math and data say early-stage VCs should <a href="https://www.investopedia.com/terms/i/index-investing.asp">index invest</a>, and late-stage investors should <a href="https://www.investopedia.com/terms/s/stockpick.asp">stock pick</a>.</p><p><em>Yet they do the opposite.</em></p><p>The reason is counterintuitive: VCs are picky, not because they have so many options but <strong>because they have so few</strong>.</p><h2 id="more-deals-better-performance">More deals, better performance</h2><p>Theoretical modeling and empirical data both suggest that early-stage VCs do better when they spread the wealth wider.</p><p>Let's start with the theory.</p><p>First, we need to define the <a href="http://reactionwheel.net/2015/06/power-laws-in-venture.html">power law distribution</a>:</p><figure><img src="https://whoisnnamdi.com/content/images/2020/07/640px-Long_tail.svg.png" alt="640px-Long_tail.svg"><figcaption>Source: <a href="https://commons.wikimedia.org/w/index.php?curid=1449504">Wikipedia</a></figcaption></figure><p>A power law distribution is one where large, consequential events (the Googles, Amazons, and Facebooks of the venture world) are rare but much more common than you might expect if the world were <a href="https://en.wikipedia.org/wiki/Normal_distribution">normally distributed</a>.</p><figure><img src="https://whoisnnamdi.com/content/images/2020/07/normal-v-pld-tail.png" alt="https://i0.wp.com/reactionwheel.net/wp-content/uploads/2015/06/normal-v-pld-tail.png?resize=606%2C287"><figcaption>Source: <a href="http://reactionwheel.net/2015/06/power-laws-in-venture.html">Reaction Wheel</a></figcaption></figure><p>These events happen with some frequency, and that frequency can be characterized by a "shape" or "tail parameter" that governs the "fatness" of the tail, typically represented by the symbol \(\alpha\).</p><p>The smaller \(\alpha\), the "fatter" the tail of the power law distribution. The fatter the tail, the higher the frequency and size of outlier startups.</p><figure><img src="https://whoisnnamdi.com/content/images/2020/07/pld-tails.png" alt="https://i2.wp.com/reactionwheel.net/wp-content/uploads/2015/06/pld-tails.png?resize=611%2C287"><figcaption>Source: <a href="http://reactionwheel.net/2015/06/power-laws-in-venture.html">Reaction Wheel</a></figcaption></figure><p>If \(\alpha\) is sufficiently small, strange things begin to happen. With a small enough \(\alpha\), <strong>making investments nearly at random will increase a portfolio's expected return</strong>.</p><p>The exact mathematical reasons for this are <a href="https://arxiv.org/abs/2001.10488">somewhat esoteric</a>, but intuitively, if there are enough potential Googles, Amazons, and Facebooks out there, they will more than cover the losses from the duds thanks to the shape of the power law distribution. When fat tails dominate returns it's not worth having an extremely high bar if it might cause you to miss out on one of these future juggernauts.</p><p>VCs often talk about power laws, but few have sufficient data to rigorously demonstrate them. However, <a href="https://angel.co/">AngelList</a> does, and their head data scientist, Abe Othman, has <a href="https://angel.co/blog/venture-returns">done the work</a> to analyze returns from the thousands of deals syndicated by AngelList, finding that:</p><blockquote>... <strong>the regret an investor could have for missing a winning seed-stage investment is theoretically infinite</strong>, a phenomenon that does not appear to hold for later-stage investments. The implication is that <strong>investors increase their expected return by indexing as broadly as possible at the seed stage</strong> (i.e., by putting money into every credible deal), because <strong>any selective policy for seed-stage investing—absent perfect foresight—will eventually be outperformed by an indexing approach</strong>.</blockquote><p>By creating power law-based mathematical model, fitting it to the AngelList returns data, and simulating 50,000 portfolios with 10 early-stage companies each, he created the following synthetic distribution of venture capital returns:</p><figure><img src="https://whoisnnamdi.com/content/images/2020/07/chart_2.png" alt="Distribution of hypothetical manager returns showing the market return outperforms"><figcaption>Source: <a href="https://angel.co/blog/what-angellist-data-says-about-power-law-returns-in-venture-capital">AngelList</a></figcaption></figure><p>The vertical black line represents the <em>market return</em>: the return you'd earn if you invested an equal amount in every AngelList deal in the sample (of which there were 1,808). Notice the long tail trailing off to the right side of the chart. In a world where most barely return their fund, some shower their LPs with 5x returns. <strong>Notice how most 10-company portfolios underperform the simple (1,808-company) strategy.</strong></p><p>Technically, this is still a theoretical result. Yes, the model was fit to real data, but the outputs are still simulated. Now let's look at real data.</p><p>Here again we turn to AngelList, who analyze the relationship between portfolio size and performance among 10,000+ investors on the platform. They grouped the investors by number of companies in their portfolio and plotted the median return for each group. The chart confirms the theoretical results - larger portfolios generate greater returns:</p><figure><img src="https://whoisnnamdi.com/content/images/2020/07/H5qNMNZPFO.png" alt="img"><figcaption>Source: <a href="https://angel.co/pdf/lp-performance.pdf">AngelList</a></figcaption></figure><blockquote>The coefficient of the regression term is 9.0 <a href="https://www.investopedia.com/terms/b/basispoint.asp">basis points</a>... implying that <strong>the typical annual return of a portfolio of 100 investments is almost 9% higher than the typical annual return of a portfolio with a single investment</strong>.</blockquote><p>Note these are median returns, so they don't reflect a handful of 100-count portfolios simply getting lucky and pulling up the average. <strong>Financial upside is easier to come by when you're exposed to a larger patch of the startup landscape.</strong></p><p>Theory and data agree - most early-stage venture investors would do better by indexing, investing a small amount in every reasonable startup they can find:</p><blockquote>Simulations on 10-year investing windows for seed-stage deals suggest <strong>fewer than 10% of investors will beat the index</strong>, even if those investors have skill in picking deals. Like Vanguard has taught us in the public markets, <strong>individual investors could benefit from viewing the index as the default</strong> and then overlaying individual deals that they like.</blockquote><h2 id="1-n">1/N</h2><p>Behavioral finance theorists have a name for this strategy: <a href="https://www.macroresilience.com/2010/07/08/heuristics-and-robustness-in-asset-allocation/">the 1/N heuristic</a>.</p><p>It goes like this: take every investable asset of a group of N assets and invest 1/Nth of your capital in each one, with no regard to the fundamentals, mean return, or volatility of returns.</p><p>This might sound like a dumb, simplistic strategy. While it's certainly simple, it's definitely not dumb.</p><p>Ironically, 1990 Nobel Laureate and famed inventor of mean-variance portfolio optimization, Harry Markowitz, reportedly used this exact heuristic for investing his own money, eschewing his own complicated theory in favor of a simpler approach:</p><blockquote>I should have computed the historical covariance of the asset classes and drawn an efficient frontier…I split my contributions 50/50 between bonds and equities. - <a href="https://alphaarchitect.com/2014/10/17/harry-markowitz-an-equal-weight-investor/">Harry Markowitz</a></blockquote><figure><img src="https://whoisnnamdi.com/content/images/2020/07/image-20200624134947087.png" alt="image-20200624134947087"><figcaption>Source: <a href="https://books.google.com/books?id=gRdOBrus_9wC&amp;pg=PA4&amp;lpg=PA4&amp;dq=your+money+and+your+brain+harry+markowitz&amp;source=bl&amp;ots=awRnIfiMs4&amp;sig=sY4wPziYOjm9oB5f3MN_z7gloMw&amp;hl=en&amp;sa=X&amp;ei=bEM3VKT9MIjIsATj_4Fw#v=onepage&amp;q&amp;f=false">Your Money and Your Brain</a></figcaption></figure><p>In fact, <a href="http://faculty.london.edu/avmiguel/DeMiguel-Garlappi-Uppal-RFS.pdf">one study</a> found that the 1/N strategy dominates numerous others:</p><blockquote>Of the 14 models we evaluate across seven empirical datasets, <strong>none is consistently better than the 1/N rule</strong> in terms of Sharpe ratio, certainty-equivalent return, or turnover, which indicates that, out of sample, <strong>the gain from optimal diversification is more than offset by estimation error</strong>... &nbsp;That is, the effect of estimation error is so large that <strong>it erodes completely the gains from optimal diversification</strong>.</blockquote><p>Which is a fancy way of saying "<em>don't overcomplicate it.</em>"</p><p>A <em>slightly</em> more sophisticated reading of the results might be, "<em>unless you are <strong>very</strong> sure about the structure of the world, don't overcomplicate your investing strategy.</em>"</p><p>The study found a negative return to overthinking and overfitting yourself to the past data, to what you <em>think</em> you know about these assets. In venture, similar overintellectualization has been the root cause of numerous "misses" over the years - career, fund, and firm-defining deals that put certain VCs on the map and left others in desperate obscurity.</p><p>In some <em>subtle</em> way, trying to pick the exact right startup based on a complex model of the world is like trying to buy a certain lottery ticket with a certain serial number because you think it's a "lucky ticket." One <em>seems</em> much more superstitious, but are they closer than they appear?</p><h2 id="how-the-other-half-lives">How the other half lives</h2><p>Late stage investors on the other hand, <em>can</em> afford to stock pick:</p><blockquote>... our results also suggest that the opportunity cost for missing a winning investment in these later rounds is bounded... Consequently, <strong>it is entirely appropriate that later-stage investors should reject the “spray and pray” idea and be thoughtful and discerning when they participate</strong>...</blockquote><p>Translation: late-stage deals have lower opportunity cost than early-stage investments, as their returns are capped much lower. To channel Jeff Bezos' <a href="https://www.youtube.com/watch?v=jwG_qR6XmDQ">regret minimization framework</a>: there isn't much regret to minimize when it comes to late-stage deals. So feel free to be picky.</p><p>Another take from the 1/N study:</p><blockquote>... we conclude that portfolio strategies from the optimizing models are expected to outperform the 1/N benchmark if: <strong>(i) the estimation window is long</strong>; (ii) the ex ante (true) Sharpe ratio of the mean-variance efficient portfolio is substantially higher than that of the 1/N portfolio; and <strong>(iii) the number of assets is small</strong>.</blockquote><p>In other words, it makes sense to be picky and particular when you have a large amount of data collected over a long period of time and when the number of choices is small. Both are more true of later-stage investments relative to early-stage. By definition, late-stage companies have a longer track record by which to evaluate them, and there are fewer of them. Thus, it makes sense to be a discerning capital allocator at the late-stage.</p><p>And yet we've seen the exact <em>opposite</em> in recent years.</p><p>Though few would publicly characterize themselves as such, I know of at least a few firms who have explicit goals of creating, effectively, "indices of late-stage venture" via their large portfolios. Late-stage funds are raising and deploying capital at unprecedented rates. Many appear principally focused on putting "dollars to work," rather than earning the maximum return on their capital. They've taken to heart the approach discussed earlier, investing in every company that meets some minimum threshold.</p><p>This has led to serious perversion at the late-stage, as there are not nearly enough investable assets to support the capital inflows at reasonable valuations. <strong>Asset values grow not simply due to improvement in fundamental startup value but also because late-stage funds need somewhere to park their money</strong>.</p><p>In this model, late-stage startups become "<em>capital vehicles</em>," absorbing meaningful capital and earning a "<em>capital storage</em>" premium for their efforts.</p><p><a href="https://blog.samaltman.com/party-rounds">Party rounds</a>, long known to greatly <a href="http://blog.eladgil.com/2010/09/party-rounds-how-to-get-high-valuation.html">inflate early-stage valuations</a>, have reached the late-stage.</p><p>But all parties must come to end eventually...</p><h2 id="caveat-emptor-indexor"><em>Caveat <s>emptor</s> indexor</em></h2><p>So that's the theory, but there are some real practical hurdles to creating an early-stage index:</p><ul><li>Determining the right minimum threshold</li><li>No one sees every deal</li><li>Deals must be won</li><li>Fund and check size restrictions</li></ul><h3 id="how-high-should-the-bar-be">How high should the bar be?</h3><p>AngelList recommends investing in every <em>credible</em> early-stage deal, where the word "credible" does a lot of work. They add:</p><blockquote>We worry that <strong>an investor promising to blindly fund every whisper of a new company would fundamentally alter the …</strong></blockquote></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://whoisnnamdi.com/vcs-index-invest/">https://whoisnnamdi.com/vcs-index-invest/</a></em></p>]]>
            </description>
            <link>https://whoisnnamdi.com/vcs-index-invest/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24445446</guid>
            <pubDate>Fri, 11 Sep 2020 17:57:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Our Firebase Tech Stack]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24445435">thread link</a>) | @gbourne
<br/>
September 11, 2020 | https://www.ayrshare.com/our-firebase-tech-stack/ | <a href="https://web.archive.org/web/*/https://www.ayrshare.com/our-firebase-tech-stack/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-node="5f340663d99e7">
	<div>
		
<p>When we started <a href="https://www.ayrshare.com/">Ayrshare</a> we were keen on using an infrastructure as a service platform and avoid server setup, SSL certs, opening ports, etc. Time to market, right. Amongst the many platforms out there we choose <a href="https://www.firebase.com/">Firebase</a>. It was an easy decision for us since we are very comfortable with Firebase having built, and even sold, apps built upon it. If not Firebase our second choice would have been <a href="https://www.netlify.com/">Netlify</a>.</p>







<h2>Today and Tomorrow Requirements</h2>



<p>The first question we asked was, “What we need today?” If came down to a few criteria:</p>



<ul><li>Authentication, ideally having SSO with the major networks</li><li>Hosting a static single page app (React)</li><li>Hosting a landing page. We generally don’t like to build the landing pages in React.</li><li>A database, preferably noSQL</li><li>Back-end running NodeJS, preferably serverless</li><li>Event tracking, e.g. Google Analytics</li><li>Email service</li><li>Payment service</li></ul>



<p>Second, we asked, “What we might need tomorrow?”</p>



<ul><li>iOS and Android apps</li><li>Mobile app push notifications</li><li>ML (machine learning)</li></ul>







<h2>Our Stack</h2>



<p>We have built on many platform: AWS, Heroku, under our desk (not kidding), and Digital Ocean. We ended up choosing Firebase since it meets a lot of our needs, but certainly not all.</p>



<figure><img width="1024" height="667" src="https://www.ayrshare.com/wp-content/uploads/2020/08/stack3-1-1024x667.png" alt="" srcset="https://www.ayrshare.com/wp-content/uploads/2020/08/stack3-1-1024x667.png 1024w, https://www.ayrshare.com/wp-content/uploads/2020/08/stack3-1-300x195.png 300w, https://www.ayrshare.com/wp-content/uploads/2020/08/stack3-1-768x500.png 768w, https://www.ayrshare.com/wp-content/uploads/2020/08/stack3-1.png 1130w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.ayrshare.com/wp-content/uploads/2020/08/stack3-1-1024x667.png" data-srcset="https://www.ayrshare.com/wp-content/uploads/2020/08/stack3-1-1024x667.png 1024w, https://www.ayrshare.com/wp-content/uploads/2020/08/stack3-1-300x195.png 300w, https://www.ayrshare.com/wp-content/uploads/2020/08/stack3-1-768x500.png 768w, https://www.ayrshare.com/wp-content/uploads/2020/08/stack3-1.png 1130w"></figure>







<p>Firebase is a good choice for SPA React hosting and <a href="https://firebase.google.com/docs/firestore">Firestore</a> as a noSQL database. Google Analytics comes built into Firebase. Also, using Firebase’s <a href="https://firebase.google.com/docs/auth/web/firebaseui">authentication UI</a> system allowed us to have a secure registration and login process integrated with major SSO providers like Google, Facebook, and GitHub.</p>



<p>The landing page we built in WordPress hosted on Siteground. There are so many great templates and plugins available for WordPress that we see no reason to recreate the wheel in React. Another option we considered was <a href="https://www.gatsbyjs.org/">Gatsby</a> hosted on separate Firebase project.</p>



<p>Sending emails requires a mail provider and we are accustomed to using Mailgun. Firebase has recently introduced <a href="https://firebase.google.com/products/extensions">Extensions</a>, prebuilt cloud functions. One of our favorite is the <a href="https://www.anothermadworld.com/emailing-with-firebase-trigger-email-extension/">Email Trigger extension</a> that facilitates sending email from your cloud functions.</p>



<p>For a payment system, we choose Stripe. Stripe has a really nice <a href="https://www.npmjs.com/package/stripe">NPM package</a> that makes integration relatively easy.</p>



<p>Finally, we decided right before launch to add a <a href="https://docs.ayrshare.com/rest-api/endpoints/shorten">link shortener,</a> which is very useful when publishing to networks like Twitter that limit the characters. At first we were going to go with bit.ly, but it would soon become more expensive than what we were charging users. We ultimately went with Firebase’s <a href="https://firebase.google.com/products/dynamic-links">Dynamic Links</a>, Google’s replacement for goo.gl. Dynamic Links real power are with mobile apps, but it can also be used as a link shortener if you are willing use the RESTful API calls.</p>







<h3>Firebase Cloud Functions &amp; APIs</h3>



<p>Ayrshare is build as an API first platform, so it is critical to have a robust API system. Building a Cloud Function for each API endpoint is not flexible or secure. However, you can add <a href="https://expressjs.com/">Express</a> to Cloud Function and it is an excellent and battle tested framework to build and expose APIs.</p>



<p>For example, you can add several security and API facilitating packages such as:</p>



<pre><code lang="javascript">const express = require("express");
const cors = require("cors");
const bodyParser = require("body-parser");
const helmet = require("helmet");
const rateLimit = require("express-rate-limit");</code></pre>







<p>If you do add Express, you can add the “app” as an http function and export it.</p>



<pre><code lang="javascript">const app = express();
exports.api = functions.https.onRequest(app);</code></pre>







<p>And then add you typical express functions.</p>



<pre><code lang="javascript">app.get("/fun", (req, res) =&gt; {
  console.log("hello fun");
  return res.send('"Hi fun");
});</code></pre>











<h3>Looking Towards the Future</h3>



<p>In the future we plan on building mobile apps, especially for allowing Instagram posting, and will require push notifications. In previous projects we used <a href="https://firebase.google.com/docs/cloud-messaging">Firebase’s Cloud Messaging</a> (FCM) system and found it easy, reliable, and free!</p>



<p>And if we really look ahead, we want to add some ML analysis on ideal posting times. The current Firebase ML offering doesn’t seem a great fit, but perhaps it will be in the future.</p>
	</div>
</div></div>]]>
            </description>
            <link>https://www.ayrshare.com/our-firebase-tech-stack/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24445435</guid>
            <pubDate>Fri, 11 Sep 2020 17:56:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Million-Dollar, One-Person Businesses]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24445220">thread link</a>) | @jger15
<br/>
September 11, 2020 | https://trends.vc/trends-0027-million-dollar-one-person-businesses/ | <a href="https://web.archive.org/web/*/https://trends.vc/trends-0027-million-dollar-one-person-businesses/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-wrapper">
<div id="content">
<div id="primary">
<main id="main" role="main">
<article id="post-17653" class="page">

<div>
<div><figure><img src="https://trends.vc/wp-content/uploads/2020/08/7-069ffa62548f-1.gif" alt=""></figure></div>
<h2>🔍 Problem</h2>
<p><em>“Build your own dreams, or someone else will hire you to build theirs.”</em></p>
<p>You want <strong>freedom</strong> and <strong>equity</strong>. </p>
<p>You’re willing to work hard. But on your terms.</p>
<h2>💡 Solution</h2>
<p><strong>Leverage</strong>. </p>
<p><em>What do you mean?</em></p>
<figure><table><tbody><tr><td>One-To-Many Channels</td><td><a href="https://www.siteground.com/tutorials/email/protocols-pop3-smtp-imap/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Email</a>, <a href="https://en.wikipedia.org/wiki/Podcast" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Podcasts</a>, <a href="https://www.cloudflare.com/learning/network-layer/internet-protocol/#:~:text=The%20Internet%20Protocol%20(IP)%20is%20a%20protocol%2C%20or%20set,arrive%20at%20the%20correct%20destination.&amp;text=IP%20information%20is%20attached%20to,packets%20to%20the%20right%20place." target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Blogs</a></td></tr><tr><td>Social Networks </td><td><a href="https://twitter.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Twitter</a>, <a href="https://www.youtube.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">YouTube</a>, <a href="https://www.instagram.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Instagram</a></td></tr><tr><td>Paid Demand</td><td><a href="https://ads.google.com/home/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Google Ads</a>, <a href="https://www.facebook.com/business/ads" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Facebook Ads</a>, <a href="https://www.reddit.com/adsregister" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Reddit Ads</a></td></tr><tr><td>Membership Platforms </td><td><a href="https://www.patreon.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Patreon</a>, <a href="https://onlyfans.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">OnlyFans</a>, <a href="https://substack.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Substack</a></td></tr><tr><td>Productized Services</td><td><a href="https://www.manypixels.co/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">ManyPixels</a>, <a href="https://beanninjas.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Bean Ninjas</a>, <a href="https://www.trycatalog.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Catalog</a></td></tr><tr><td>Marketplaces</td><td><a href="https://www.amazon.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Amazon</a>, <a href="https://www.etsy.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Etsy</a>, <a href="https://gumroad.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Gumroad</a></td></tr><tr><td>On-Demand Computing</td><td><a href="https://aws.amazon.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">AWS</a>, <a href="https://www.heroku.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Heroku</a>, <a href="https://www.netlify.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Netlify</a></td></tr><tr><td>No-Code Tools </td><td><a href="https://www.shopify.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Shopify</a>, <a href="https://mailchimp.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Mailchimp</a>, <a href="https://wordpress.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">WordPress</a></td></tr><tr><td>On-Demand Manufacturing</td><td><a href="https://printify.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Printify</a>, <a href="https://www.shapeways.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Shapeways</a>, <a href="https://www.printful.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Printful</a></td></tr><tr><td>Open Source</td><td><a href="https://rubyonrails.org/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Ruby on Rails</a>, <a href="https://laravel.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Laravel</a>, <a href="https://reactjs.org/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">React</a></td></tr><tr><td>APIs</td><td><a href="https://stripe.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Stripe</a>, <a href="https://www.twilio.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Twilio</a>, <a href="https://plaid.com/uk/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Plaid</a></td></tr></tbody></table></figure>
<p>These power <strong>million-dollar, one-person businesses</strong>.</p>
<p>Code, distribution and manufacturing are being <strong>commoditized</strong>. </p>
<p>Build wealth by focusing on what’s scarce.</p>
<h2>📘 Terms</h2>
<p><strong>Million-Dollar Business</strong></p>
<p>Forget revenue.</p>
<p>Ask: “<em>What would the business sell for?</em>“</p>
<p>Use <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.thehartford.com/business-insurance/strategy/selling-a-business/determining-market-value" target="_blank">earnings multiples or discounted cash flows</a>. </p>
<p><strong>One-Person Business</strong></p>
<p>Operated by <strong>one person</strong> <em>or</em> built on a <strong>personal brand</strong>.</p>
<h2>🏁 Players</h2>
<p><strong>People</strong></p>
<ul><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://affordanything.com/" target="_blank">Paula&nbsp;Pant</a> </li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.listennotes.com/podcasts/the-indie-hackers/098-how-to-make-25mm-as-a-FEX5hGsMQ9T/" target="_blank">Adam Wathan</a></li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.forrestfunnell.com/" target="_blank">Forrest Funnell</a></li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/jackbutcher" target="_blank">Jack Butcher</a></li><li><a rel="noreferrer noopener" href="https://www.forbes.com/sites/elainepofeldt/2019/06/30/how-one-student-launched-a-million-dollar-one-woman-bikini-empire/#1da781506814" target="_blank">Ana Gavia</a></li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/vikdug" target="_blank">Vik Duggal</a></li><li><a rel="noreferrer noopener" href="https://levels.io/" target="_blank">Pieter Levels</a></li><li><a rel="noreferrer noopener" href="https://backlinko.com/" target="_blank">Brian Dean</a></li><li><a rel="noreferrer noopener" href="https://jamesclear.com/" target="_blank">James Clear</a></li></ul>
<p><strong>Businesses</strong></p>
<ul><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://readwrite.com/2007/10/29/plentyoffish_one_billion/" target="_blank">PlentyOfFish</a></li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.marketwatch.com/story/3-resolutions-to-transform-your-1-person-business-into-a-1-million-operation-2018-01-02#:~:text=Allen%20Walton%2C%20who%20built%20his,steps%20in%20the%20shipping%20process." target="_blank">Spy Guy</a></li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://closet.tools/" target="_blank">Closet Tools</a></li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://stratechery.com/" target="_blank">Stratechery</a></li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://seothatworks.com/" target="_blank">Backlinko</a></li><li><a rel="noreferrer noopener" href="https://shop.visualizevalue.com/" target="_blank">Visualize Value</a></li><li><a rel="noreferrer noopener" href="https://en.m.wikipedia.org/wiki/The_Million_Dollar_Homepage" target="_blank">The Million Dollar Homepage</a></li><li><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Silk_Road_(marketplace)" target="_blank">Silk Road</a></li><li><a rel="noreferrer noopener" href="https://park.io/" target="_blank">Park.io</a></li></ul>
<h2>🔮 Predictions</h2>
<ul><li>Services like <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.printful.com/" target="_blank">Printful</a> will <strong>commoditize manufacturing</strong>. Kylie Cosmetics reached <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.forbes.com/sites/natalierobehmed/2019/03/05/at-21-kylie-jenner-becomes-the-youngest-self-made-billionaire-ever/#20049c8d2794" target="_blank">$1 billion</a> with 7 employees using <a rel="noreferrer noopener" href="https://www.instyle.com/news/secret-company-behind-kkw-beauty-and-kylie-cosmetics" target="_blank">SEED Beauty</a>. Most <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://sell.amazon.com/fulfillment-by-amazon.html" target="_blank">FBA</a> sellers slap labels on <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.alibaba.com/Apparel_p3?spm=a2700.9161164.2.1.15924e02eeUOHq" target="_blank">generic products</a>. <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.oberlo.com/" target="_blank">Oberlo</a> takes this further.</li><li>Growth and product skills will<strong> remain valuable</strong>. These are areas of innovation. Unlike accounting.<em> Unless you’re Enron. </em></li></ul>
<h2>☁️ Opportunities</h2>
<ul><li>Develop <strong>high-leverage skills</strong>. Invest, write, entertain, code, sell, market, design. </li><li>Start with <strong>services</strong> to find valuable problems. As a consultant, <a rel="noreferrer noopener" href="https://twitter.com/tylertringas" target="_blank">Tyler Tringas</a> had several clients ask for store locators. He built <a rel="noreferrer noopener" href="https://www.storemapper.com/" target="_blank">Storemapper</a>, sold the business and launched <a rel="noreferrer noopener" href="https://earnestcapital.com/" target="_blank">Earnest Capital</a>. </li><li>Automate, outsource or delegate <strong>non-core</strong> <strong>competencies</strong>. Focus on what’s scarce. As <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/ljin18" target="_blank">Li Jin</a> says, <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://a16z.com/2019/10/08/passion-economy/" target="_blank">monetize your individuality</a>. </li><li><strong>Show</strong> your work. <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/dr/status/1291054987976482817?s=20" target="_blank">Dan Rowden</a>, <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/diannamallen/status/1292861382459883520?s=20" target="_blank">Dianna Allen</a> and <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/levelsio/status/1290068006484099072?s=20" target="_blank">Pieter Levels</a> share progress as they build. Stay top of mind with <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://trends.vc/trends-0015-open-startups/" target="_blank">exhaust data</a>. </li><li>Build a <strong>personal brand </strong>like <a rel="noreferrer noopener" href="https://twitter.com/AffordAnything" target="_blank">Paula Pant</a>, <a rel="noreferrer noopener" href="https://twitter.com/PatFlynn" target="_blank">Pat Flynn</a> or <a rel="noreferrer noopener" href="https://www.sethgodin.com/" target="_blank">Seth Godin</a>. Finding problems, validating products and acquiring customers will be easier.</li></ul>
<h2>🔑 Key Lessons</h2>
<ul><li>Don’t be the best. <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="http://www.game-changer.net/2014/09/15/dont-be-the-best-be-the-only-one/#.Xy9J3hNKh-U" target="_blank">Be the only.</a> There are no <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/Comparables" target="_blank">comparables</a> in a <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://seths.blog/2013/09/category-of-one-is-a-choice/" target="_blank">category of one</a>. <a rel="noreferrer noopener" href="https://stratechery.com/about/" target="_blank">Ben Thompson</a>, <a rel="noreferrer noopener" href="https://tim.blog/" target="_blank">Tim Ferriss </a>and <a rel="noreferrer noopener" href="http://podcasts.joerogan.net/" target="_blank">Joe Rogan</a> have <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/tylertringas/status/1291352314029252609?s=20" target="_blank">micro-monopolies</a>. </li><li><strong>Niche</strong>. <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.listennotes.com/podcasts/how-i-built-it/the-importance-of-niching-o8rmWDfh3P2/" target="_blank">Sarah Dunn</a> does SEO for wedding professionals. <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.listennotes.com/podcasts/the-resilient/habits-of-a-million-dollar-F3f-bEBKSue/" target="_blank">Rich Rosen</a> only recruits for 3 types of roles. Use small to your advantage. </li></ul>
<h2>😠 Haters</h2>
<p><em>“Million-dollar, one-person businesses can’t be sold.”</em><br>Have you seen <a href="https://park.io/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Park.io</a>, <a href="https://closet.tools/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Closet Tools</a> or <a href="https://overcast.fm/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Overcast</a>?</p>
<p><em>“How do you value an <strong>unsellable</strong>, service business?”</em><br>You don’t. But for this report, look at single-year net income. </p>
<p><em>“Storemapper had employees.” </em><br>The point of that example was to show you how to use <a rel="noreferrer noopener" href="https://nathanbarry.com/wealth-creation/" target="_blank">Nathan’s ladder</a>. Or <a rel="noreferrer noopener" href="https://robwalling.com/2015/03/26/the-stairstep-approach-to-bootstrapping/" target="_blank">Rob’s stairs</a>.&nbsp;</p>
<p><em>“Code, distribution and manufacturing <strong>will</strong> <strong>not</strong> be commoditized.”<br>All</em> code, distribution and manufacturing will not be. Apple and Tesla are vertically integrated. If it’s a core competency, keep it in-house. <a rel="noreferrer noopener" aria-label="Otherwise outsource (opens in a new tab)" href="https://www.econlib.org/library/Topics/Details/comparativeadvantage.html" target="_blank">Otherwise outsource</a>. </p>
<p><em>“I have one million in <strong>revenue</strong>, so I have a million-dollar business.”</em><br>If you buy $2,000,000 worth of iPhones and sell them for $1,000,000. You also have $1m in revenue. As Lauryn Hill says, “…&nbsp;it ain’t what you cop, it’s about what you keep.”</p>
<p><em>“Some of these people have<strong> teams</strong>.</em>“<br>Joe Rogan and Tim Ferris have teams but they’ve built businesses on <a href="https://trends.vc/trends-0023-personal-brands/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">personal brands</a>. Pieter Levels has a <a href="https://twitter.com/levelsio/status/1105345282873581568?s=20" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">sysadmin</a>. <a href="https://stratechery.com/about/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Ben Thompson</a> has an assistant. <a href="https://twitter.com/elainepofeldt" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Elaine Pofeldt</a> addresses this in her <a href="https://www.goodreads.com/book/show/34915571-the-million-dollar-one-person-business" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">book</a>. Most million-dollar, one-person businesses <a href="https://indypendently.com/grow/what-do-million-dollar-one-person-businesses-have-in-common" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">get help</a>. </p>
<p><em>“Screw this. I love my <strong>job</strong>.”</em><br>That’s all that matters. </p>
<h2>🔗 Links</h2>
<ol><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/DruRly/status/1290726540607664129?s=20" target="_blank">Looking for million-dollar, one-person businesses. Know any?</a> — The thread that started this report. </li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://nav.al/product-media" target="_blank">Product and Media are New Leverage</a> — <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/naval" target="_blank">Naval</a> talks about the role of zero marginal cost products in building wealth.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://stewfortier.com/why-you-should-share-your-ideas-online/#one-person-media-companies" target="_blank">One-Person Media Companies</a> — <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/stewfortier" target="_blank">Stew Fortier</a> on why you should share ideas online and how one-person media companies make money. </li></ol>



<hr>
<h3>More Trends</h3>
<ul><li>👥<strong> <a href="https://trends.vc/trends-0030-audience-first-products/">Trends #0030 — Audience-First Products</a></strong></li><li><strong>⚙️ <a href="https://trends.vc/trends-0029-lead-generation/">Trends #0029 — Lead Generation</a></strong></li><li>📦&nbsp; <a href="https://trends.vc/trends-0028-subscription-dtc/"><strong>Trends #0028 — Subscription DTC</strong></a></li><li>🤑&nbsp;<strong><a href="https://trends.vc/trends-0027-million-dollar-one-person-businesses/">Trends #0027 — Million-Dollar, One-Person Businesses</a></strong></li><li>📍&nbsp;<strong><a href="https://trends.vc/trends-0026-drop/">Trends #0026 — Drop Culture</a></strong></li><li>📣&nbsp;<strong><a href="https://trends.vc/trends-0025-referral-programs/">Trends #0025 — Referral Programs</a></strong></li><li>🏟️<strong>&nbsp;<a href="https://trends.vc/trends-0024-equity-crowdfunding/">Trends #0024 — Equity Crowdfunding</a></strong></li><li>🤩&nbsp;<strong><a href="https://trends.vc/trends-0023-personal-brands/">Trends #0023 — Personal Brands</a></strong></li><li>💻&nbsp;<a href="https://trends.vc/trends-0022-digital-products/"><strong>Trends #0022 — Digital Products</strong></a></li><li>🕹️ <strong><a href="https://trends.vc/trends-0021-gamification/">Trends #0021 — Gamification</a></strong></li><li>🙏<strong>&nbsp;<a href="https://trends.vc/trends-0020-b-corps/">Trends #0020 — B Corps</a></strong></li><li><strong>🥾&nbsp;<a href="https://trends.vc/trends-0019-bootstrap-funds/">Trends #0019 — Bootstrap Funds</a></strong></li><li>😇<strong>&nbsp;<a href="https://trends.vc/trends-0018-angel-investing/">Trends #0018 — Angel Investing</a></strong></li><li><strong>🛠️&nbsp;<a href="https://trends.vc/trends-0017-xaas-anything-as-a-service/">Trends #0017 — XaaS: Anything as a Service</a></strong></li><li><strong><a href="https://trends.vc/trends-0016-growth-tools/">🧰&nbsp;Trends #0016 — Growth Tools</a></strong></li><li><strong>📖&nbsp;<a href="https://trends.vc/trends-0015-open-startups/">Trends #0015 — Open Startups</a></strong></li><li>💬 <strong><a href="https://trends.vc/trends-0014-paid-communities/">Trends #0014 — Paid Communities</a></strong></li><li>🍎 <strong><a href="https://trends.vc/trends-0013-online-courses/">Trends #0013 — Online Courses</a></strong></li><li>💰 <strong><a href="https://trends.vc/trends-0012-micro-private-equity/">Trends #0012 — Micro Private Equity</a></strong></li><li>💌<strong>&nbsp;<a href="https://trends.vc/trends-0011-paid-newsletters/">Trends #0011 — Paid Newsletters</a></strong></li><li><strong>🦄 <a href="https://trends.vc/trends-0010-startup-studios/">Trends #0010 — Startup Studios</a></strong></li><li>🌐 <strong>&nbsp;<a href="https://trends.vc/trends-0009-virtual-meetups/">Trends #0009 — Virtual Meetups</a></strong></li><li>🏋️<strong>&nbsp;<a href="https://trends.vc/trends-0008-remote-fitness/">Trends #0008 — Remote Fitness</a></strong></li><li>🦠 <strong><a href="https://trends.vc/trends-0007-coronavirus-covid-19/">Trends #0007 — Coronavirus (COVID-19)</a></strong></li><li>🧱 <strong><a href="https://trends.vc/trends-0006-no-code/">Trends #0006 — No Code</a></strong></li><li>🥾&nbsp;<strong><a href="https://trends.vc/trends-0005-bootstrap-funds/">Trends #0005 — Bootstrap Funds</a></strong></li><li>💸&nbsp;<strong><a href="https://trends.vc/trends-0004-income-share-agreements/">Trends #0004 — Income Share Agreements</a></strong></li><li>🏠&nbsp;<strong><a href="https://trends.vc/trends-0003-co-living/">Trends #0003 — Co-Living</a></strong></li><li>🎙️&nbsp;<strong><a href="https://trends.vc/trends-0002-podcast-memberships/">Trends #0002 — Podcast Memberships</a></strong></li><li>🍳 <strong><a href="https://trends.vc/trends-issue-0001-cloud-kitchens/">Trends #0001 — Cloud Kitchens</a></strong></li></ul>

<p><strong>📈 <a href="https://trends.vc/" target="_blank" rel="noreferrer noopener" aria-label="Get weekly reports (opens in a new tab)">Get weekly reports</a></strong></p>

</div>
</article>
</main>
</div>
</div>

</div></div>]]>
            </description>
            <link>https://trends.vc/trends-0027-million-dollar-one-person-businesses/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24445220</guid>
            <pubDate>Fri, 11 Sep 2020 17:37:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Booleans – Guile Hacker Handbook (new chapter)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24445128">thread link</a>) | @rednosehacker
<br/>
September 11, 2020 | https://jeko.frama.io/en/booleans.html | <a href="https://web.archive.org/web/*/https://jeko.frama.io/en/booleans.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
                    
<p>The two boolean values are: "true" and "false". Respectively <code>#t</code> or <code>#true</code> and <code>#f</code> or <code>#false</code> in Guile.</p>
<p>In a conditional test context, "true" means any expression other than <code>#f</code> (or <code>#false</code>).</p>
<p>I invite you to create a new directory in the workspace dedicated to this chapter: <code>~/Workspace/guile-handbook/booleans</code>.</p>
<h2>Write the test first</h2>
<p>Create the file <code>booleans-test.scm</code>&nbsp;:</p>
<pre><code>(use-modules (srfi srfi-64)
             (booleans))

(test-begin "harness")

(test-equal "true-inverted-returns-false"
  #f
  (boolean-invert #t))
  
(test-end "harness")
</code></pre>
<h2>Try and run the test</h2>
<pre><code>guile -L . booleans-test.scm
</code></pre>
<p>Compilation error !</p>
<pre><code>;;; note: auto-compilation is enabled, set GUILE_AUTO_COMPILE=0
;;;       or pass the --no-auto-compile argument to disable.
;;; compiling /home/jeko/Workspace/guile-handbook/booleans/booleans-test.scm
;;; WARNING: compilation of /home/jeko/Workspace/guile-handbook/booleans/booleans-test.scm failed:
;;; no code for module (booleans)
</code></pre>
<h2>Write the minimal amount of code for the test to run and check the failing test output</h2>
<p>Compilation errors can be seen as red tests. In the tradition of TDD, it is essential to add only the bare minimum of code to correct these errors.</p>
<p>Here, the compiler indicates that the <code>booleans</code> module does not exist. I create it to correct this error and immediately restart the test.</p>
<p>Create the file <code>booleans.scm</code>&nbsp;:</p>
<pre><code>(define-module (booleans))
</code></pre>
<p>A new error occurs! This time it compiles, but I'm warned that the <code>boolean-invert</code> variable is not linked (i.e. it is not defined). I add it to my previously created module and re-run the test.</p>
<p>Edit the file <code>booleans.scm</code>&nbsp;:</p>
<pre><code>(define-module (booleans))

(define-public (boolean-invert bool)
  0)
</code></pre>
<p>No more errors or warnings at compile time. The test fails and you can check the reason for the failure in the <code>harness.log</code> report. A quick look confirms that the reason for the failure is that the <code>true-inverted-returns-false</code> test waits for the value <code>#f</code> while the <code>boolean-invert</code> procedure always returns <code>0</code>.</p>
<pre><code>$ cat harness.log 
%%%% Starting test harness
Group begin: harness
Test begin:
  test-name: "true-inverted-returns-false"
  source-file: "booleans-test.scm"
  source-line: 6
  source-form: (test-equal "true-inverted-returns-false" #f (boolean-invert #t))
Test end:
  result-kind: fail
  actual-value: 0
  expected-value: #f
Group end: harness
# of unexpected failures  1
</code></pre>
<h2>Write enough code to make it pass</h2>
<p>I modify the <code>boolean-invert</code> procedure so that it returns the value <code>#f</code> as expected by the test.</p>
<p>Edit the file <code>booleans.scm</code>&nbsp;:</p>
<pre><code>(define-module (booleans))

(define-public (boolean-invert bool)
  #f)
</code></pre>
<p>Running the test displays the following message :</p>
<pre><code>$ guile -L . booleans-test.scm
;;; note: source file /home/jeko/Workspace/guile-handbook/booleans/booleans-test.scm
;;;       newer than compiled /home/jeko/.cache/guile/ccache/3.0-LE-8-4.3/home/jeko/Workspace/guile-handbook/booleans/booleans-test.scm.go
;;; note: auto-compilation is enabled, set GUILE_AUTO_COMPILE=0
;;;       or pass the --no-auto-compile argument to disable.
;;; compiling /home/jeko/Workspace/guile-handbook/booleans/booleans-test.scm
;;; compiled /home/jeko/.cache/guile/ccache/3.0-LE-8-4.3/home/jeko/Workspace/guile-handbook/booleans/booleans-test.scm.go
%%%% Starting test harness  (Writing full log to "harness.log")
# of expected passes      1
</code></pre>
<p>The test passes !</p>
<h2>Refactor</h2>
<p>There's not much to do for so little code.</p>
<h3>Docstrings</h3>
<p>I take this opportunity to tell you about <strong>docstrings</strong>. These strings bring a little explanation to the user if needed:</p>
<ul>
<li>in the REPL, with the command <code>,describe</code>.</li>
<li>in Emacs</li>
</ul>
<p>These are strings placed in second position in the parameter list when defining a variable or a procedure with <code>define</code>, <code>define*</code> or <code>define-public</code> (and so on).</p>
<p>Let's add a <strong>docstring</strong> to the <code>boolean-invert</code> procedure!</p>
<p>Edit the file <code>booleans.scm</code>&nbsp;:</p>
<pre><code>(define-module (booleans))

(define-public (boolean-invert bool)
  "Returns the opposite value of the given boolean."
  #f)
</code></pre>
<h2>Write the test first</h2>
<p>The first test verified that calling the <code>boolean-invert</code> procedure with the <code>#t</code> parameter returns <code>#f</code>. The next test will check the reverse.</p>
<p>Edit the file <code>booleans-test.scm</code>&nbsp;:</p>
<pre><code>(use-modules (srfi srfi-64)
             (booleans))

(test-begin "harness")

(test-equal "true-inverted-returns-false"
  #f
  (boolean-invert #t))
 
(test-equal "false-inverted-returns-true"
  #t
  (boolean-invert #f))
  
(test-end "harness")
</code></pre>
<h2>Try and run the test</h2>
<pre><code>$ guile -L . booleans-test.scm 
</code></pre>
<p>It compiles without any problem!</p>
<h2>Write the minimal amount of code for the test to run and check the failing test output</h2>
<p>You can see the new test failling.</p>
<pre><code>booleans-test.scm:10: FAIL false-inverted-returns-true
</code></pre>
<p>Check that the reason for the failure is the expect one. That is, the <code>false-inverted-returns-true</code> test waits for the value <code>#t</code> but gets <code>#f</code>.</p>
<pre><code>Test begin:
  test-name: "false-inverted-returns-true"
  source-file: "booleans-test.scm"
  source-line: 10
  source-form: (test-equal "false-inverted-returns-true" #t (boolean-invert #f))
Test end:
  result-kind: fail
  actual-value: #f
  expected-value: #t
</code></pre>
<p>This is confirmed.</p>
<h2>Write enough code to make it pass</h2>
<p>Let's add the minimum amount of code required to pass the test:</p>
<pre><code>(define-module (booleans))

(define-public (boolean-invert bool)
  "Returns the opposite value of the given boolean."
  (if bool
      #f
      #t))
</code></pre>
<p>Run the tests again…</p>
<pre><code>%%%% Starting test harness  (Writing full log to "harness.log")
# of expected passes      2
</code></pre>
<p>All clear !</p>
<h2>Refactor</h2>
<p>As you might have guessed, there is a ready-made procedure for inverting a boolean :</p>
<pre><code>(define-module (booleans))

(define-public (boolean-invert bool)
  "Returns the opposite value of the given boolean."
  (not bool))
</code></pre>
<p>I restart the tests one last time to check that this re-machining hasn't broken anything:</p>
<pre><code>%%%% Starting test harness  (Writing full log to "harness.log")
# of expected passes      2
</code></pre>
<p>Done.</p>
<h2>Wrapping up</h2>
<p>What has been covered in this chapter :</p>
<ul>
<li>More TDD practice</li>
<li>Notions about booleans</li>
<li>Write self-documented code thanks to docstrings</li>
</ul>

                </div></div>]]>
            </description>
            <link>https://jeko.frama.io/en/booleans.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24445128</guid>
            <pubDate>Fri, 11 Sep 2020 17:28:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Startup Ideas for Inspiration]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24445058">thread link</a>) | @cameron_b
<br/>
September 11, 2020 | https://blog.pixelswithin.com/startup-ideas-for-inspiration | <a href="https://web.archive.org/web/*/https://blog.pixelswithin.com/startup-ideas-for-inspiration">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

<div>
  
<p>If you know me, you know I am an idea machine when it comes to fun side projects. Here is a growing collection of all the ideas I’ve had for startups and other ventures. Feel free to take one and run with it! Email me if you do, I’d love to hear about it.</p>
<blockquote data-conversation="none"><p lang="en" dir="ltr">Ok. What about a blog that launches 1 year from today? Various writers assign themselves self-development books and just before launch they write about how their book has impacted their lives in the last year..</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1166118325362888704?ref_src=twsrc%5Etfw">August 26, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">Book playlists 🤔</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1163926092169662465?ref_src=twsrc%5Etfw">August 20, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">I have an idea. An app for cutting down impulse spending. You set a budget, track your impulses, etc.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1155683694075473920?ref_src=twsrc%5Etfw">July 29, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">I wanna make a .tv website, for like a women in rap VJ thing with YouTube embeds. I'm not going to.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1154832435445547008?ref_src=twsrc%5Etfw">July 26, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">Idea (something I’d like to see): a series of checklists for everything needed on any page of any website. Home, Pricing, About, etc pages.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1150643032523333632?ref_src=twsrc%5Etfw">July 15, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">Idea: an AI diary. Conversational, talks back.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1139248242661584896?ref_src=twsrc%5Etfw">June 13, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">50% of an idea: a Twitter account anyone can post to, via a website with safeguards against abuse, like blocking the “@“ character, authentication, and only allowing one tweet per twit per day. That’s the mechanism, trying to think of a concept.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1136103551028027392?ref_src=twsrc%5Etfw">June 5, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">Idea! An app for people to hold each other accountable to goals by hosting regular "lotteries." Use the Acorns API to collect round-up investments (you spend $2.19 at the store, the app takes $0.81 to round out to a $3 charge). Only the ones who met their goal are entered to win.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1134651648838475776?ref_src=twsrc%5Etfw">June 1, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">Idea: a weather app, but instead of the weather it's the emotional climate based on sentiment analysis of your Twitter feed.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1134645334066384896?ref_src=twsrc%5Etfw">June 1, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">Idea! 🤔 What about customizable posters for forming habits? With 3 months of calendar space to X out days of. <a href="https://t.co/MvkVdSGGTq">pic.twitter.com/MvkVdSGGTq</a></p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1114924426137456642?ref_src=twsrc%5Etfw">April 7, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">Free idea: a forum API. Creating a community on your own website shouldn't be as hard as it is right now.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1106627433573158912?ref_src=twsrc%5Etfw">March 15, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">app idea 👇🏼 <a href="https://t.co/yC0D3Jwi7n">https://t.co/yC0D3Jwi7n</a></p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1075097162730528769?ref_src=twsrc%5Etfw">December 18, 2018</a></blockquote>


<blockquote><p lang="en" dir="ltr">app idea (pls take!!!) — create typopgraphic gifs</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1070978101239136258?ref_src=twsrc%5Etfw">December 7, 2018</a></blockquote>


<blockquote><p lang="en" dir="ltr">IDEA: anarchist video games. Like start the people’s revolution, illegalism, break animals out of a lab, different levels of staging protests, etc etc. Pls, we need the training!</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1012471453659234305?ref_src=twsrc%5Etfw">June 28, 2018</a></blockquote>


<blockquote><p lang="en" dir="ltr">idea: a tumblr with thought experiments for anxiety... they sure help me</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/811298468971089920?ref_src=twsrc%5Etfw">December 20, 2016</a></blockquote>


<blockquote><p lang="en" dir="ltr">idea: a subscription box for coffee recipes. you get the beans + a fancy recipe + the stuff to make the mintmochafrappelata or whatever!</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/807371501301137408?ref_src=twsrc%5Etfw">December 9, 2016</a></blockquote>


<blockquote><p lang="en" dir="ltr">hm IDEA: blinders for human beans. for focus.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/799980544784109568?ref_src=twsrc%5Etfw">November 19, 2016</a></blockquote>


<blockquote><p lang="en" dir="ltr">Sister, giving me app ideas: "We have a lot of communication apps. Do we have enough stay-away-from-me apps?"</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/685016694402617344?ref_src=twsrc%5Etfw">January 7, 2016</a></blockquote>


<blockquote><p lang="en" dir="ltr">Idea for Google Maps: a setting where the destination ALWAYS ends up on the right side</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/679476573490135043?ref_src=twsrc%5Etfw">December 23, 2015</a></blockquote>


<blockquote><p lang="en" dir="ltr">Idea: a relatively softer or muted version of your text notification sound, for messages that are just confirmations of receipt.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/643260554908332032?ref_src=twsrc%5Etfw">September 14, 2015</a></blockquote>


<blockquote><p lang="en" dir="ltr">Good ideas are impressive even in low-fidelity.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/636251856298078208?ref_src=twsrc%5Etfw">August 25, 2015</a></blockquote>


<blockquote><p lang="en" dir="ltr">"Stop looking at yourself as a designer, and start thinking of yourself as a deliverer of ideas." ~Ståle Melvær</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/634884067960426496?ref_src=twsrc%5Etfw">August 22, 2015</a></blockquote>


<blockquote><p lang="en" dir="ltr">i love ideas. i get carried away with ideas. i get high off ideas.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/939974857013338112?ref_src=twsrc%5Etfw">December 10, 2017</a></blockquote>




<div id="mlb2-1413518">
<div>
<div>
<div>
<div>
<h4><span>
🎉</span> The end of the post!
</h4>
<p>
Thanks for reading. Ever wonder how effective website design happens? Enter your email to join the weekly newsletter that explores this question.
</p>
</div>

</div>

</div>
</div>
</div>

<p><img src="https://track.mailerlite.com/webforms/o/1413518/g1f8t1?vd890ed88b3a28c805acc70e1a88fa27c" width="1" height="1"></p>
<p><img src="https://blotcdn.com/blog_a19b4b16eb8f413ab70f54145e0e22d6/_image_cache/_image_cache/5a2e65c1-8d54-45f4-9ad0-390945a77183.png" alt="me" width="1822" height="908"></p>
<p>Hi, I’m Diana Lopez! I’m a freelance web designer and developer who works with startups and small businesses. I create memorable &amp; effective websites and brand identities. Interested in learning more? See my portfolio at <a href="https://pixelswithin.com/" target="_blank">pixelswithin.com →</a></p>
</div>

</div></div>]]>
            </description>
            <link>https://blog.pixelswithin.com/startup-ideas-for-inspiration</link>
            <guid isPermaLink="false">hacker-news-small-sites-24445058</guid>
            <pubDate>Fri, 11 Sep 2020 17:23:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Extracting SQL code from SSIS dtsx packages with Python lxml]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24445035">thread link</a>) | @bakerjd99
<br/>
September 11, 2020 | https://analyzethedatanotthedrivel.org/2020/01/20/extracting-sql-code-from-ssis-dtsx-packages-with-python-lxml/ | <a href="https://web.archive.org/web/*/https://analyzethedatanotthedrivel.org/2020/01/20/extracting-sql-code-from-ssis-dtsx-packages-with-python-lxml/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Lately, I’ve been refactoring a sprawling SSIS <a href="https://docs.microsoft.com/en-us/sql/integration-services/sql-server-integration-services?view=sql-server-ver15">(SQL Server Integration Services)</a> package that ineffectually wrestles with large XML files. In this programmer’s opinion using SSIS for heavy-duty XML parsing is geeky self-abuse so I’ve opted to replace an eye-ball straining<a id="fnref1" href="#fn1"><sup>1</sup></a> SSIS package with half a dozen, <a href="https://quoteinvestigator.com/2011/05/13/einstein-simple/">“as simple as possible but no simpler”</a>, Python scripts. If the Python is fast enough for production great! If not the scripts will serve as a clear model<a id="fnref2" href="#fn2"><sup>2</sup></a> for something faster.</p>



<p>I’m only refactoring<a id="fnref3" href="#fn3"><sup>3</sup></a> part of a larger <a href="https://www.webopedia.com/TERM/E/ETL.html">ETL</a> process so whatever I do <em>it must mesh with the rest of the mess.</em></p>



<p><strong><em>So where is the rest of the SSIS mess?</em></strong></p>



<p>SSIS’s visual editor does a wonderful job of hiding the damn code!</p>



<p><strong><em>This is a problem!</em></strong></p>



<p>If only there was a simple way to troll through large sprawling SSIS <em>spider-webby</em> packages and extract <a href="https://www.youtube.com/watch?v=wPiHQ37gXnE">the good bits</a>. Fortunately, Python’s XML parsing tools can be easily applied to SSIS dtsx files. <em>SSIS dtsx files are XML files.</em> The following code snippets illustrate how to hack these files.</p>



<p>First import the required Python modules. lxml is not always included in Python distributions. Use the <a href="https://remotedevdaily.com/how-to-install-lxml-in-python-using-pip/">pip</a> or <a href="https://anaconda.org/anaconda/lxml">conda</a> tools to install this module.</p>


<pre title=""># imports
import os
from lxml import etree
</pre>


<p>Set an output directory. I’m running on a Windows machine. If you’re on a Mac or Linux machine adjust the path.</p>


<pre title=""># set sql output directory
sql_out = r"C:\temp\dtsxsql"
if not os.path.isdir(sql_out):
    os.makedirs(sql_out)
</pre>


<p>Point to the dtsx package you want to extract code from.</p>


<pre title=""># dtsx files
dtsx_path = r'C:\Users\john\AnacondaProjects\testfolder\bixml'
ssis_dtsx = dtsx_path + r'\ParseXML.dtsx'
</pre>


<p>Read and parse the SSIS package.</p>


<pre title="">tree = etree.parse(ssis_dtsx)
root = tree.getroot()
root.tag
</pre>


<p>lxml&nbsp;renders XML namespace tags like:&nbsp;</p>



<p>&lt;DTS:Executable&nbsp;as&nbsp;{www.microsoft.com/SqlServer/Dts}Executable.</p>



<p>The following shows all the transformed element tags in the&nbsp;dtsx&nbsp;package.</p>


<pre title=""># collect unique element tags in dtsx
ele_set = set()
for ele in root.xpath(".//*"):
    ele_set.add(ele.tag)    
print(ele_set)
print(len(ele_set))
</pre>


<p>Using transformed element tags of interest blast over the&nbsp;dtsx&nbsp;and suck out the bits of interest.</p>


<pre title="">pfx = '{www.microsoft.com/'
exe_tag = pfx + 'SqlServer/Dts}Executable'
obj_tag = pfx + 'SqlServer/Dts}ObjectName'
dat_tag = pfx + 'SqlServer/Dts}ObjectData'
tsk_tag = pfx + 'sqlserver/dts/tasks/sqltask}SqlTaskData'
src_tag = pfx + \
  'sqlserver/dts/tasks/sqltask}SqlStatementSource'

# extract sql source statements and write to *.sql files 
total_bytes = 0
package_name = root.attrib[obj_tag].replace(" ","")
for cnt, ele in enumerate(root.xpath(".//*")):
  if ele.tag == exe_tag:
    attr = ele.attrib
    for child0 in ele:
      if child0.tag == dat_tag:
        for child1 in child0:
          sql_comment = attr[obj_tag].strip()
          if child1.tag == tsk_tag:
            dtsx_sql = child1.attrib[src_tag]
            dtsx_sql = "-- " + \
                sql_comment + "\n" + dtsx_sql
            sql_file = sql_out + "\\" \
                 + package_name + str(cnt) + ".sql"
            total_bytes += len(dtsx_sql)
            print((len(dtsx_sql), 
                 sql_comment, sql_file))
            with open(sql_file, "w") as file:
              file.write(dtsx_sql)
print(('total bytes',total_bytes))

</pre>


<p>The code snippets in this post are available in this Jupyter notebook:&nbsp;<a href="https://github.com/bakerjd99/jacks/blob/master/notebooks/Extracting%20SQL%20code%20from%20SSIS%20dtsx%20packages%20with%20Python%20lxml.ipynb">Extracting SQL code from SSIS dtsx packages with Python lxml</a>. Download and tweak for your&nbsp;dtsx&nbsp;nightmare!</p>



<hr>


<section>
<ol>
<li id="fn1">I frequently run into SSIS packages that cannot be viewed on 4K monitors when fully zoomed out.<a role="doc-backlink" href="#fnref1">↩︎</a></li>
<li id="fn2">Python’s readability is a major asset when disentangling <em>mess-ware</em><a role="doc-backlink" href="#fnref2">↩︎</a>.</li>
<li id="fn3">Yes, I’ve railed about the word “refactoring” in the past but I’ve moved on and so should you. <a href="https://www.dictionary.com/browse/a-foolish-consistency-is-the-hobgoblin-of-little-minds">“A foolish consistency is the hobgoblin of little minds.”</a><a role="doc-backlink" href="#fnref3">↩︎</a></li>
</ol>
</section>	</div><div>
			<div>
				<p><img alt="" src="https://2.gravatar.com/avatar/2d564a508700caf0e93eb415d0a6651f?s=80&amp;d=identicon&amp;r=G" height="80" width="80">		</p><!-- .author-avatar -->
		
		<p>
			<h2>Published by <span>John Baker</span></h2>
		</p><!-- .author-heading -->

		<p>
			Professional curmudgeon and relentless skeptic.  "Belief" is a bullshit word.  You know or you don't know!			<a href="https://analyzethedatanotthedrivel.org/author/bakerjd99/" rel="author">
				View all posts by John Baker			</a>
		</p><!-- .author-bio -->
	</div><!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2020-01-20T19:30:48-07:00">January 20, 2020</time><time datetime="2020-09-11T10:40:04-06:00">September 11, 2020</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://analyzethedatanotthedrivel.org/2020/01/20/extracting-sql-code-from-ssis-dtsx-packages-with-python-lxml/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24445035</guid>
            <pubDate>Fri, 11 Sep 2020 17:21:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How “Go Build” Works]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24444990">thread link</a>) | @grahar64
<br/>
September 11, 2020 | https://maori.geek.nz/how-go-build-works-750bb2ba6d8e | <a href="https://web.archive.org/web/*/https://maori.geek.nz/how-go-build-works-750bb2ba6d8e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://maori.geek.nz/@GrahamJenson?source=post_page-----750bb2ba6d8e----------------------" rel="noopener"><img alt="Graham Jenson" src="https://miro.medium.com/fit/c/96/96/0*1bdqD2hM_lzBk_GT.jpeg" width="48" height="48"></a></p></div></div></div></div><p id="a410">How does <code>go build</code> compile the simplest Golang program? This post is here to answer that question.</p><p id="f341">The simplest go program (I can think of) is <code>main.go</code>:</p><pre><span id="54a4">package main</span><span id="1240">func main() {}</span></pre><p id="2a45">If we run <code>go build main.go</code> it outputs an executable <code>main</code> that is 1.1Mb <strong>and does nothing</strong>. What did <code>go build</code> do to do create such a useful binary?</p><p id="ac39"><code>go build</code> has some args that are useful for seeing how it builds:</p><ol><li id="1e0b"><code><strong>-work</strong></code>: <code>go build</code> creates a temporary folder for work files. This arg will print out the location of that folder and not delete it after the build</li><li id="be95"><code><strong>-a</strong></code>: Golang caches previously built packages. <code>-a</code> makes <code>go build</code> ignore the cache so our build will print all steps</li><li id="bcac"><code><strong>-p 1</strong></code>: This sets the concurrency to a single thread to log output linear</li><li id="2751"><code><strong>-x</strong></code>: <code>go build</code> is a wrapper around other Golang tools like <code>compile</code>. <code>-x</code> outputs the commands and arguments that are sent to these tools</li></ol><p id="349d">Running <code>go build -work -a -p 1 -x main.go</code> will output not only the <code>main</code> binary, but <strong>a lot</strong> of logs describing exactly what <code>build</code> did to create <code>main</code>.</p><p id="8eda">The logs starts with:</p><pre><span id="f089">WORK=/var/folders/rw/gtb29xf92fv23f0zqsg42s840000gn/T/go-build940616988</span></pre><p id="6410">This is the work directory whose structure looks like:</p><pre><span id="18c5">├── b001<br>│   ├── _pkg_.a<br>│   ├── exe<br>│   ├── importcfg<br>│   └── importcfg.link<br>├── b002<br>│   └── ...<br>├── b003<br>│   └── ...<br>├── b004<br>│   └── ...<br>├── b006<br>│   └── ...<br>├── b007<br>│   └── ...<br>└── b008<br>    └── ...</span></pre><p id="c081"><strong><em>What are these incrementing directory numbers?</em></strong></p><p id="4f83"><code>go build</code> defines an <a href="https://github.com/golang/go/blob/master/src/cmd/go/internal/work/action.go" target="_blank" rel="noopener">action graph</a> of tasks that need to be completed. Each action in this graph gets its own sub-directory (defined in <code><a href="https://github.com/golang/go/blob/master/src/cmd/go/internal/work/action.go#L318" target="_blank" rel="noopener">NewObjdir</a></code>). The first node <code>b001</code> in the graph is the root task to compile the <code>main</code> binary. Each dependent action has a higher number, the final being <code>b008</code>. (I don’t know where <code>b005</code> went, I assume its ok)</p></div></div></section><hr><section><div><div><p id="9ddc">The first action to be executed is the leaf of the graph, <code>b008</code>:</p><pre><span id="81a6">mkdir -p $WORK/b008/<br>cat &gt;$WORK/b008/importcfg &lt;&lt; 'EOF'<br># import config<br>EOF</span><span id="9961">cd /&lt;..&gt;/src/runtime/internal/sys<br>/&lt;..&gt;/compile <br>  -o $WORK/b008/_pkg_.a <br>  -trimpath "$WORK/b008=&gt;" <br>  -p runtime/internal/sys <br>  -std <br>  -+ <br>  -complete <br>  -buildid gEtYPexVP43wWYWCxFKi/gEtYPexVP43wWYWCxFKi <br>  -goversion go1.14.7 <br>  -D "" <br>  -importcfg $WORK/b008/importcfg <br>  -pack <br>  -c=16 <br>  ./arch.go ./arch_amd64.go ./intrinsics.go ./intrinsics_common.go ./stubs.go ./sys.go ./zgoarch_amd64.go ./zgoos_darwin.go ./zversion.go</span><span id="8d26">/&lt;..&gt;/buildid -w $WORK/b008/_pkg_.a<br>cp $WORK/b008/_pkg_.a /&lt;..&gt;/Caches/go-build/01/01b...60a-d</span></pre><p id="4908">The <code>b008</code> action:</p><ol><li id="b8f4">creates the action directory (<em>all actions do this so I ignore this later on</em>)</li><li id="9ca1">creates the <code>importcfg</code> file to be used by the <code>compile</code> tool (it is empty)</li><li id="c15a">changes the directory to the <code><a href="https://golang.org/pkg/runtime/internal/sys/" target="_blank" rel="noopener">runtime/internal/sys</a></code> packages source folder. This package contains <code>constants used by the runtime</code></li><li id="aba4"><code>compile</code> this package</li><li id="19f9">Use <code>buildid</code> to write (<code>-w</code>) metadata to the package and copy the package to the <code>go-build</code> cache (<em>all packages are cached so I ignore this later on)</em></li></ol><p id="9f31">Let’s break this down the arguments sent to the <code>compile</code> tool (also described in <code>go tool compile --help)</code>:</p><ol><li id="b924"><code>-o</code> is the output file</li><li id="8804"><code>-trimpath</code> this removes the prefix from the source file paths <code>$WORK/b008=&gt;</code> (<em>probably helps with debugging?</em>)</li><li id="1d3d"><code>-p</code> sets the package path used by <code>import</code></li><li id="c90f"><code>-std</code> <code>compiling standard library</code> (<em>not sure what this does</em>)</li><li id="e4bf"><code>-+</code> <code>compiling runtime</code> (<em>another mystery</em>)</li><li id="ae46"><code>-complete</code> the compiler outputs a complete package (no C or assembly).</li><li id="bdd2"><code>-buildid</code> adds build id to the metadata (as <a href="https://github.com/golang/go/blob/master/src/cmd/go/internal/work/buildid.go" target="_blank" rel="noopener">defined here</a>)</li><li id="b355"><code>-goversion</code> required version for compiled package</li><li id="4c7f"><code>-D</code> the relative path for local imports is <code>""</code></li><li id="fc5c"><code>-importcfg</code> import configuration file refers to other packages</li><li id="414d"><code>-pack</code> create package archive (<code>.a</code>) instead of object file (<code>.o</code>)</li><li id="20ee"><code>-c</code> concurrency of the build</li><li id="abd0">finished with a list of files in the package</li></ol><p id="9669"><em>Most of these arguments are the same for all </em><code><em>compile</em></code><em> calls, so I ignore them later.</em></p><p id="fde2">The output of <code><strong>b008</strong></code> is the file <code><strong>$WORK/b008/_pkg_.a</strong></code><strong> </strong>for <code><strong>runtime/internal/sys</strong></code></p></div></div></section><hr><section><div><div><p id="3de5">Let’s dive into <code>buildid</code> for a second.</p><p id="3302">The <strong>buildid</strong> is in the format <code>&lt;actionid&gt;/&lt;contentid&gt;</code>. It is used as an index to cache packages to improve <code>go build</code> performance. The <code>&lt;actionid&gt;</code> is the hash of the action (all calls, arguments, and input files). The <code>&lt;contentid&gt;</code> is a hash of the output <code>.a</code> file. For each <code>go build</code> action, it can look up in the cache for contents created by another action with the same <code>&lt;actionid&gt;</code>. <em>This is implemented in </em><a href="https://github.com/golang/go/blob/master/src/cmd/go/internal/work/buildid.go" target="_blank" rel="noopener"><em>buildid.go</em></a><em>.</em></p><p id="9c9f">The <code>buildid</code> is stored as metadata in the file so that it does not need to be hashed every time to get the <code>&lt;contentid&gt;</code>. You can see this id with <code>go tool buildid &lt;file&gt;</code> (also works on binaries).</p><p id="ab02">In the log of <code>b008</code> above the buildID is being set in by the <code>compile</code> tool as <code>gEtYPexVP43wWYWCxFKi/gEtYPexVP43wWYWCxFKi</code>. This is a just a place holder and is later overwritten with <code>go tool buildid -w</code> to the correct <code>gEtYPexVP43wWYWCxFKi/b-rPboOuD0POrlJWPTEi</code> before being cached.</p></div></div></section><hr><section><div><div><p id="1af8">The next action to be run is <code>b007</code>:</p><pre><span id="879c">cat &gt;$WORK/b007/importcfg &lt;&lt; 'EOF'<br># import config<br>packagefile runtime/internal/sys=$WORK/b008/_pkg_.a<br>EOF<br>cd /&lt;..&gt;/src/runtime/internal/math<br>/&lt;..&gt;/compile <br>  -o $WORK/b007/_pkg_.a <br>  -p runtime/internal/math <br>  -importcfg $WORK/b007/importcfg <br>  ...<br>  ./math.go</span></pre><ol><li id="838a">This writes the <code>importcfg</code> but it includes the line <code>packagefile runtime/internal/sys=$WORK/b008/_pkg_.a</code>. This means <code>b007</code> depends on the output of <code>b008</code></li><li id="0d87"><code>compile</code>’s the <code><a href="https://golang.org/pkg/runtime/internal/math/" target="_blank" rel="noopener">runtime/internal/math</a></code> package. If you inspect <code><a href="https://golang.org/src/runtime/internal/math/math.go" target="_blank" rel="noopener">math.go</a></code>, it has <code>import "runtime/internal/sys"</code> built by <code>b008</code></li></ol><p id="cf96">The output of <code><strong>b007</strong></code> is the file <code><strong>$WORK/b007/_pkg_.a</strong></code><strong> </strong>for <code><strong>runtime/internal/math</strong></code></p></div></div></section><hr><section><div><div><p id="2f2b">The next action is <code>b006</code>:</p><pre><span id="399f">cat &gt;$WORK/b006/go_asm.h &lt;&lt; 'EOF'<br>EOF<br>cd /&lt;..&gt;/src/runtime/internal/atomic<br>/&lt;..&gt;/asm <br>  -I $WORK/b006/ <br>  -I /&lt;..&gt;/go/1.14.7/libexec/pkg/include <br>  -D GOOS_darwin <br>  -D GOARCH_amd64 <br>  -gensymabis <br>  -o $WORK/b006/symabis <br>  ./asm_amd64.s</span><span id="a708">/&lt;..&gt;/asm <br>  -I $WORK/b006/ <br>  -I /&lt;..&gt;/go/1.14.7/libexec/pkg/include <br>  -D GOOS_darwin <br>  -D GOARCH_amd64 <br>  -o $WORK/b006/asm_amd64.o <br>  ./asm_amd64.s</span><span id="4d96">cat &gt;$WORK/b006/importcfg &lt;&lt; 'EOF'<br># import config<br>EOF<br>/&lt;..&gt;/compile <br>  -o $WORK/b006/_pkg_.a <br>  -p runtime/internal/atomic <br>  -symabis $WORK/b006/symabis <br>  -asmhdr $WORK/b006/go_asm.h <br>  -importcfg $WORK/b006/importcfg<br>  ...<br>  ./atomic_amd64.go ./stubs.go</span><span id="75f1">/&lt;..&gt;/pack r $WORK/b006/_pkg_.a $WORK/b006/asm_amd64.o</span></pre><p id="4f05">Here is where we step out of the normal <code>.go</code> files and start dealing with lower level “<a href="https://golang.org/doc/asm" target="_blank" rel="noopener"><strong>Go assembly</strong></a>” <code>.s</code> files. <code>b006</code>:</p><ol><li id="81ea">First this makes the header file <code>go_asm.h</code></li><li id="3cb5">goes to the <code><a href="https://golang.org/pkg/runtime/internal/atomic/" target="_blank" rel="noopener">runtime/internal/atomic</a></code> package (a bunch of low-level functions).</li><li id="06b1">runs the <code><a href="https://golang.org/cmd/asm/" target="_blank" rel="noopener">go tool asm</a></code> tool (described with <code>go tool asm --help</code>) to build the <code>symabis</code> “Symbol Application Binary Interfaces (ABI) file” and then the object file <code>asm_amd64.o</code></li><li id="9cd6">Uses <code>compile</code> create the <code>_pkg_.a</code> file including the <code>symabis</code> file and the header with <code>-asmhdr.</code></li><li id="7347">Uses <code>pack</code> to add the <code>asm_amd64.o</code> object file to <code>_pkg_.a</code> package archive</li></ol><p id="e680">The <code>asm</code> tool is called with the args:</p><ol><li id="3642"><code>-I</code>: include the action <code>b007</code> and <code>includes</code> folders. <code>includes</code> has three files <code>asm_ppc64x.h</code> <code>funcdata.h</code> and <code>textflag.h</code> all having low level function definitions, e.g. <code>FIXED_FRAME defines the size of the fixed part of a stack frame</code></li><li id="8ad3"><code>-D</code>: Adds a predefined symbol</li><li id="17ac"><code>-gensymabis</code>: flag to generate the <code>symabis</code> file</li><li id="9991"><code>-o</code>: The output file</li></ol><p id="851d">The output of <code><strong>b006</strong></code> is <code><strong>$WORK/b006/_pkg_.a</strong></code><strong> </strong>for <code><strong>runtime/internal/atomic</strong></code></p></div></div></section><hr><section><div><div><p id="e1c5">Next is <code>b004</code>:</p><pre><span id="d642">cd /&lt;..&gt;/src/internal/cpu<br>/&lt;..&gt;/asm ... -o $WORK/b004/symabis ./cpu_x86.s</span><span id="e1ae">/&lt;..&gt;/asm ... -o $WORK/b004/cpu_x86.o ./cpu_x86.s</span><span id="3f1b">/&lt;..&gt;/compile ... -o $WORK/b004/_pkg_.a ./cpu.go ./cpu_amd64.go ./cpu_x86.go</span><span id="426e">/&lt;..&gt;/pack r $WORK/b004/_pkg_.a $WORK/b004/cpu_x86.o</span></pre><p id="1205"><code>b004</code> is the same as <code>b006</code> for the package <code><a href="https://golang.org/pkg/internal/cpu/" target="_blank" rel="noopener">internal/cpu</a></code>. First we we assemble the <code>symabis</code> and object files, then compile the go files and pack the <code>.o</code> files into <code>_pkg_.a</code>.</p><p id="a960">The output of <code><strong>b004</strong></code> is <code><strong>$WORK/b004/_pkg_.a</strong></code><strong> </strong>for <code><strong>internal/cpu</strong></code></p></div></div></section><hr><section><div><div><p id="611b">The next action is <code>b003</code></p><pre><span id="6392">cat &gt;$WORK/b003/go_asm.h &lt;&lt; 'EOF'<br>EOF<br>cd /&lt;..&gt;/src/internal/bytealg</span><span id="aeae">/&lt;..&gt;/asm ... -o $WORK/b003/symabis ./compare_amd64.s ./count_amd64.s ./equal_amd64.s ./index_amd64.s ./indexbyte_amd64.s</span><span id="5369">cat &gt;$WORK/b003/importcfg &lt;&lt; 'EOF'<br># import config<br>packagefile internal/cpu=$WORK/b004/_pkg_.a<br>EOF<br>/&lt;..&gt;/compile ... -o $WORK/b003/_pkg_.a -p internal/bytealg ./bytealg.go ./compare_native.go ./count_native.go ./equal_generic.go ./equal_native.go ./index_amd64.go ./index_native.go ./indexbyte_native.go</span><span id="daac">/&lt;..&gt;/asm ... -o $WORK/b003/compare_amd64.o ./compare_amd64.s<br>/&lt;..&gt;/asm ... -o $WORK/b003/count_amd64.o ./count_amd64.s<br>/&lt;..&gt;/asm ... -o $WORK/b003/equal_amd64.o ./equal_amd64.s<br>/&lt;..&gt;/asm ... -o $WORK/b003/index_amd64.o ./index_amd64.s<br>/&lt;..&gt;/asm ... -o $WORK/b003/indexbyte_amd64.o ./indexbyte_amd64.s</span><span id="202d">/&lt;..&gt;/pack r $WORK/b003/_pkg_.a $WORK/b003/compare_amd64.o $WORK/b003/count_amd64.o $WORK/b003/equal_amd64.o $WORK/b003/index_amd64.o $WORK/b003/indexbyte_amd64.o</span></pre><p id="c6cc"><code>b003</code> is the same as the previous actions <code>b004</code> <code>b006</code> for the package <code><a href="https://golang.org/pkg/internal/bytealg/" target="_blank" rel="noopener">internal/bytealg</a></code>. The main complication with this package is that there are multiple <code>.s</code> files to create many <code>.o</code> object files that each need to be added to the <code>_pkg_.a</code> file.</p><p id="a69b">The output of <code><strong>b003</strong></code> is <code><strong>$WORK/b003/_pkg_.a</strong></code><strong> </strong>for <code><strong>internal/bytealg</strong></code></p></div></div></section><hr><section><div><div><p id="04a1">The penultimate action, <code>b002</code>:</p><pre><span id="b243">cat &gt;$WORK/b002/go_asm.h &lt;&lt; 'EOF'<br>EOF<br>cd /&lt;..&gt;/src/runtime<br>/&lt;..&gt;/asm <br>  ... <br>  -o $WORK/b002/symabis <br>  ./asm.s ./asm_amd64.s ./duff_amd64.s ./memclr_amd64.s ./memmove_amd64.s ./preempt_amd64.s ./rt0_darwin_amd64.s ./sys_darwin_amd64.s<p>  cat &gt;$WORK/b002/importcfg &lt;&lt; 'EOF'<br># import config<br>packagefile internal/bytealg=$WORK/b003/_pkg_.a<br>packagefile internal/cpu=$WORK/b004/_pkg_.a<br>packagefile runtime/internal/atomic=$WORK/b006/_pkg_.a<br>packagefile runtime/internal/math=$WORK/b007/_pkg_.a<br>packagefile runtime/internal/sys=$WORK/b008/_pkg_.a<br>EOF</p></span><span id="11b6">/&lt;..&gt;/compile <br>  -o $WORK/b002/_pkg_.a <br>  ...<br>  -p runtime <br>  ./alg.go ./atomic_pointer.go ./cgo.go ./cgocall.go ./cgocallback.go ./cgocheck.go ./chan.go ./checkptr.go ./compiler.go ./complex.go ./cpuflags.go ./cpuflags_amd64.go ./cpuprof.go ./cputicks.go ./debug.go ./debugcall.go ./debuglog.go ./debuglog_off.go ./defs_darwin_amd64.go ./env_posix.go ./error.go ./extern.go ./fastlog2.go ./fastlog2table.go ./float.go ./hash64.go ./heapdump.go ./iface.go ./lfstack.go ./lfstack_64bit.go ./lock_sema.go ./malloc.go ./map.go ./map_fast32.go ./map_fast64.go ./map_faststr.go ./mbarrier.go ./mbitmap.go ./mcache.go ./mcentral.go ./mem_darwin.go ./mfinal.go ./mfixalloc.go ./mgc.go ./mgcmark.go ./mgcscavenge.go ./mgcstack.go …</span></pre></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://maori.geek.nz/how-go-build-works-750bb2ba6d8e">https://maori.geek.nz/how-go-build-works-750bb2ba6d8e</a></em></p>]]>
            </description>
            <link>https://maori.geek.nz/how-go-build-works-750bb2ba6d8e</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444990</guid>
            <pubDate>Fri, 11 Sep 2020 17:18:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avoiding the smoke – how to breathe clean air]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24444838">thread link</a>) | @xenocyon
<br/>
September 11, 2020 | https://www.fast.ai/2020/09/11/smoke-filter/ | <a href="https://web.archive.org/web/*/https://www.fast.ai/2020/09/11/smoke-filter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>

<p><span>Written: 11 Sep 2020 by <i>Jeremy Howard</i></span></p><p>If you’re in western USA (like us) at the moment, you might be finding it hard to breath. Breathing air that contains the fallout from fires can make you feel pretty awful, and it can be bad for long-term health as well. Wildfire smoke contains <a href="http://www.bccdc.ca/resource-gallery/Documents/Guidelines%20and%20Forms/Guidelines%20and%20Manuals/Health-Environment/BCCDC_WildFire_FactSheet_CompositionOfSmoke.pdf">fine particulate matter</a>, known as “PM2.5”, which can be inhaled deep into the lungs. The “2.5” here refers to the size of the particles — they are 2.5 microns or smaller. To see the air quality in your area, check out this <a href="https://fire.airnow.gov/">AirNow map</a>. Once it’s orange, you might find you start feeling the effects. If it’s red or purple, you almost certainly will. (Sometimes it can appear smokey outside, but the air quality can be OK, because the smoke might be higher in the atmosphere.)</p>
<p>The good news is that there’s a lot you can do to make the air you breathe a lot better. You might be wondering why a data scientist like me is commenting on air filtration… The reason is that I was <a href="http://archive.is/evklI">a leader</a> of the Masks4All movement, including writing the first and most comprehensive <a href="http://preprints.org/manuscript/202004.0203/">scientific paper</a> on the topic, which meant I studied filtration very closely for months. In fact, the size of particles we want to block for wildfires is very similar to the size of particles we want to block for covid-19!</p>
<h3 id="contents">Contents</h3>
<ul id="markdown-toc">
<li><a href="#masks" id="markdown-toc-masks">Masks</a></li>
<li><a href="#filtering-your-home-air" id="markdown-toc-filtering-your-home-air">Filtering your home air</a> <ul>
<li><a href="#adding-a-filter-to-your-central-air" id="markdown-toc-adding-a-filter-to-your-central-air">Adding a filter to your central air</a></li>
<li><a href="#adding-filters-to-fans-and-portable-ac" id="markdown-toc-adding-filters-to-fans-and-portable-ac">Adding filters to fans and portable A/C</a></li>
</ul>
</li>
<li><a href="#acknowledgements" id="markdown-toc-acknowledgements">Acknowledgements</a></li>
</ul>
<p>The three ways that you can breathe cleaner air are to use a mask, filter your home central airconditioner or heater, and use fans with filters. I’ll show you the details below. (There’s quite a few links to places you can buy products in this post; I don’t get any commission or anything from them, they’re just things that I’ve personally found helpful.)</p>
<h2 id="masks">Masks</h2>
<p>Therefore, you won’t be surprised to learn that one of the most effective things that you can do is to wear a mask. To block most PM2.5 particles you’ll want a mask that’s well-fitted and uses a good filter material. I’ve already prepared advice on that topic for COVID-19, and pretty much all of it is exactly the same for wildfire PM2.5, so go <a href="https://www.fast.ai/2020/07/10/upgrade-your-mask/">read this now</a>. One bit that’s less of an issue is the “Sanitation” section — wildfire PM2.5 particles aren’t bearing disease, so you only have to worry about sanitation if your mask is actually getting dirty (or if you’ve been out in public with it on).</p>
<p>Personally, I like the <a href="https://o2nanomask.com/">O2 nano mask</a>, or any well-fitted mask that you can insert a <a href="https://filti.com/">Filti</a> filter in to. Recent aerosol science tests show that a neck gaiter folded to create two layers works well too (but make sure you add a nose clip to remove gaps around your nose). Check out Etsy for lots of mask designs that include a <a href="https://www.etsy.com/search?explicit=1&amp;q=mask+with+filter+pocket+and+nose+wire&amp;ref=guided_search_7&amp;guided_search=1">filter pocket and nose clip</a>.</p>
<figure>
<img width="500" src="https://www.fast.ai/images/etsy_masks.jpg" alt="Choose from thousands of mask designs with a filter pocket">
<figcaption>Choose from thousands of mask designs with a filter pocket</figcaption>
</figure>
<h2 id="filtering-your-home-air">Filtering your home air</h2>
<p>To clean the air in your home, the basic idea is to have it getting continually pushed through a filter. A filter is simply a piece of material which air can get through, but PM2.5 particles can’t. No filter is perfect, but there are readily-available options which work very well. Filters have a <a href="https://www.coolray.com/img/uploads/What_does_MERV_Rating_mean.pdf">MERV rating</a>, which tells you how many small particles they remove. For wildfire, you generally want MERV 13.</p>
<p>Don’t just buy the highest rating filter you can find. Filters with higher ratings have smaller holes (generally speaking), which means they also don’t let air through as fast. Remember, we want your home air going through the filter quickly, to ensure all your air is getting cleaned, so we don’t want the filter to negatively impact air-flow too much. I recommend <a href="https://www.filtrete.com/3M/en_US/filtrete/products/?N=4315+3292675507+3294529207&amp;rt=rud">Filtrete™ Healthy Living Air Filters</a>. These have good air flow even for the MERV 13 spec.</p>
<h3 id="adding-a-filter-to-your-central-air">Adding a filter to your central air</h3>
<p>If you’ve got central heating or air conditioning, then you’re in luck. That will have strong fans, covering all of your rooms. The trick is to filter the air coming <em>in</em> to the system. Nearly all home systems simply pull their air in through a large vent inside your home. Some units have a filter slot in the unit itself, whereas for some the input vent is in a totally separate location in the house. Note that air conditioners blow air <em>out</em> to outside the house, but they don’t suck air <em>in</em> from outside the house (except, generally, for more fancy commercial building HVAC systems).</p>
<p>Once you’ve found the inlet vent that your central air is pulling in from, add a filter to it. If there’s already one there, make sure it’s MERV 13 or 14. You should change it every 3 months or so (depending on the brand). A vent with a filter installed looks like this:</p>
<figure>
<img width="600" src="https://www.fast.ai/images/vent.jpg" alt="An inlet vent, showing filter underneath">
<figcaption>An inlet vent, showing filter underneath</figcaption>
</figure>
<p><strong>NB</strong>: Most filters have an arrow on the side showing the direction of airflow. So make sure you put it the right way around! Also, make sure you buy the right size. Measure the size of your vent, and buy a filter that is <em>at least</em> big enough to cover the hole. If there are gaps, the air will go through them, instead of your filter!</p>
<p>If there’s not a obvious place to add a filter to your vent, you’ll need to get creative. It might not look pretty, but you could always just remove the vent cover and fasten the filter straight over the top, using tape, poster tack, etc.</p>
<p>Once you’ve got your filter in place, the most important thing is to set your central air settings such that it has the <strong>fan running all the time</strong>. Most systems have an “auto” setting , which only turns the fan on when heating or cooling. You don’t want that! Set the fan to “on”, not to “auto”. That way, you’re getting as much air through that filter as possible.</p>
<h3 id="adding-filters-to-fans-and-portable-ac">Adding filters to fans and portable A/C</h3>
<p>I recommend having an air purifier in every room. Most air purifiers don’t really do that much, because they’re normally quiet and small (which means they don’t move much air). There are <a href="https://www.amazon.com/Filtrete-Purifier-Filter-4-speed-FAP-T03BA-G2/dp/B083ZZ96RV">extra large purifiers</a> for sale, but they’re very expensive, and often sold out at the moment.</p>
<p>But we can create our own air purifier that works as well or better than the big expensive ones. An air purifier is simply a fan blowing air through a filter. So if we use a big fan and a good filter, then we have a good air purifier! The trick is to buy a 20 inch “box fan” (which is just a fan in a 20 inch square box), and stick a 20 inch filter in front of it. We pick 20 inches because that’s pretty big, and a bigger fan and bigger filter means more filtration can happen in a given time.</p>
<p>I bought a few of these box fans: <a href="https://www.amazon.com/gp/product/B087C2LJ25/">PELONIS 3-Speed Box Fan</a>. I’m not saying this one is any better or worse than any other — just buy whatever you can get your hands on. You want one that has a high speed setting, to push lots of air through.</p>
<p>For filters, anything of the right size and MERV 13 or 14 spec should be fine. I bought this pack of 6 <a href="https://www.amazon.com/Filtrete-EA02-6PK-1E-Filter-White-Pack/dp/B07FNWB1FD/">20 inch Filtrete filters</a>. Generally, higher quality filters will allow better air flow. Also thicker filters can increase airflow too; e.g. instead of the 20x20x1 filters I got, you could try <a href="https://www.amazon.com/s?k=20x20x4+air+filter+merv+13&amp;crid=1XHHCWT0X2BO3&amp;sprefix=20x20x4+air+filter+13%2Caps%2C246&amp;ref=nb_sb_ss_i_1_21">20x20x4 (4 inch thick) filters</a>.</p>
<p>The fans I bought have the on/off/speed switch on the front, so I first turned that to the maximum speed setting, since once I attached the filter I couldn’t access the switch any more. Then I stuck some of <a href="https://www.amazon.com/gp/product/B07H5B9RZY/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1">this adhesive foam</a> all the way around the front face of the fan, trying to leave no gaps. The idea is that when I then stick the fan on top of this, there will be as few gaps as possible. It would probably work just as well to stick a long piece of <a href="https://www.amazon.com/Duck-Reusable-Removable-Mounting-1436912/dp/B000BQMFEC/">poster tack</a> all around the front face. Finally, I stuck the filter to the front of the fan by using a generous quantity of <a href="https://www.amazon.com/gp/product/B000J07BRQ/">high quality packing tape</a>.</p>
<figure>
<img width="500" src="https://www.fast.ai/images/purifier.jpg" alt="The completed DIY air purifier">
<figcaption>The completed DIY air purifier</figcaption>
</figure>
<p>These things are pretty noisy! But it’s a lot better than having a smoky house. They’re also pretty good for helping keep COVID-19 at bay, so if you have a shop or business, sprinkle a few of these around the place if you don’t have good filtered HVAC with a high change rate.</p>
<p>Another approach I’ve found useful is to buy a compact portable air conditioner. These come with a hose that blows hot air out through your window, and sucks air in through the front or back of the unit. You can stick a filter in front of where it sucks air in, using a similar approach to the fan discussed above.</p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>Many thanks to <a href="https://twitter.com/JimRosenthal4">Jim Rosenthal</a> of <a href="https://www.texairfilters.com/">Tex-Air Filters</a>, and to <a href="https://twitter.com/CorsIAQ">Richard Corsi</a> for the home-made air purifier idea. Jim has a <a href="https://www.texairfilters.com/a-variation-on-the-box-fan-with-merv-13-filter-air-cleaner/">fancier version</a> for those with the budget. Thanks also to <a href="https://twitter.com/jljcolorado">Jose-Luis Jimenez</a>, <a href="https://twitter.com/linseymarr">Linsey Marr</a>, Vladimir Zdimal, Adriaan Bax, and <a href="https://twitter.com/kprather88">Kimberly Prather</a> for many discussions that have helped me improve my (still limited!) understanding of aerosol science.</p>
</div>

</div></div>]]>
            </description>
            <link>https://www.fast.ai/2020/09/11/smoke-filter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444838</guid>
            <pubDate>Fri, 11 Sep 2020 17:06:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Managing Node.js with Volta]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24444642">thread link</a>) | @fazlerocks
<br/>
September 11, 2020 | https://blog.coreyodonnell.tech/managing-nodejs-with-volta | <a href="https://web.archive.org/web/*/https://blog.coreyodonnell.tech/managing-nodejs-with-volta">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1599786975168/LY_-tbtvH.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><p>I recently wrote a blog post about how I use NVM to <a target="_blank" href="https://blog.coreyodonnell.tech/managing-my-node-versions">manage my node version</a>. Someone commented on the post saying I should look into <a target="_blank" href="https://volta.sh/">Volta</a></p>
<h2 id="what-is-volta">What is Volta</h2>
<p>Volta is a command line tool used to manage your Node.js. It is built using Rust and is shipped as a static binary that can be run on Windows and all *nix shells. The goal is to make sure every developer working on the project seamlessly has the same tools and versions installed.</p>
<h3 id="installation">Installation</h3>
<p>The installation is simple.</p>
<pre><code>
curl https://get.volta.sh | bash
</code></pre>
<p>The script installs the binary in <code>~/.volta</code> and adds <code>~/.volta/bin</code> to your systems path inside of your <code>~/.bash_profile</code>, <code>~/.profile</code>, and <code>~/.bashrc</code>.</p>
<pre><code><span>export</span> VOLTA_HOME=<span>"<span>$HOME</span>/.volta"</span>
<span>export</span> PATH=<span>"<span>$VOLTA_HOME</span>/bin:<span>$PATH</span>"</span>
</code></pre><p>Now you can start using Volta to manage Node.js.</p>
<h3 id="using-volta">Using Volta</h3>
<p>You can easily install node using</p>
<pre><code>
volta install node

volta install node@12
</code></pre>
<p>Now node should be available to use whenever you open your terminal.</p>
<p>If you want to set Volta to always load a specific version of node for your active package you can use <code>pin</code>.</p>
<pre><code>volta pin node@12.18.3
</code></pre>
<p>This command will store your pinned version in your <code>package.json</code>.</p>
<pre><code><span>"volta"</span>: {
  "<span>node</span>": <span>"12.18.3"</span>
}
</code></pre>
<p>Every time you navigate to your project, Volta will automatically set your active node version to whatever is pinned.</p>
<p>You can even install and pin global packages like yarn using Volta to make sure everyone on your team is using the same version for their global packages.</p>
<pre><code>volta install yarn
volta pin yarn
</code></pre>
<h2 id="how-does-volta-compare-to-nvm">How does Volta compare to NVM?</h2>
<p>NVM is just a node version manager. It only handles installing different versions of node. You can also set a default version of node to load whenever you open your terminal. Volta handles node versions and can set a default version to load also.</p>
<p>When opening a terminal, NVM usually takes about 0.5 to 2 seconds to source in bash if you have a default node version set. Volta does not seem to add any load time.</p>
<p>You can pin node version for your projects using both tools. NVM uses a <code>.nvmrc</code> file and Volta adds a key to your <code>package.json</code>. Volta can also pin versions for global NPM packages used for the project.</p>
<p>NVM does not automatically switch your active node version to your pinned version. You have to run <code>nvm use</code> or install another package call <code>AVN</code>. AVN usually takes 2 to 5 seconds to switch node versions. Volta does it automatically and usually takes less than a second.</p>

<p>Even though I have been using NVM for almost 4 years, I think Volta takes the crown. I plan to use Volta for managing all my Node.js needs from now on. The speed and simplicity of the tool just makes it the better choice. NVM, I am thankful you for all the headaches you have saved me in the past but I think it is time to move on.</p>
<hr>
<ul>
<li><a target="_blank" href="https://docs.volta.sh/guide/">Volta Docs</a></li>
<li><a target="_blank" href="https://github.com/nvm-sh/nvm/blob/master/README.md">NVM Docs</a></li>
<li>Previous post about using <a target="_blank" href="https://blog.coreyodonnell.tech/managing-my-node-versions">NVM to manage node version</a></li>
<li>Follow me on <a target="_blank" href="https://twitter.com/CodeByCorey">Twitter</a> for random posts about tech and working from home.</li>
</ul>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.coreyodonnell.tech/managing-nodejs-with-volta</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444642</guid>
            <pubDate>Fri, 11 Sep 2020 16:49:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Statistical Significance: A Practical Introduction]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24444577">thread link</a>) | @R3G1R
<br/>
September 11, 2020 | https://mathvault.ca/statistical-significance/ | <a href="https://web.archive.org/web/*/https://mathvault.ca/statistical-significance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div id="theme-content-section"><div><section data-css="tve-u-16ec5d248bb"><figure><img loading="lazy" src="https://mathvault.ca/wp-content/uploads/Statistical-Significance.jpg" alt="A Primer on Statistical Significance" width="800" height="480" title="Statistical Significance"></figure><p><strong>Statistical significance</strong>, in a nutshell, is a way of determining the degree of unlikely-ness of an experimental result — when a certain status quo hypothesis is assumed to be true.<span id="more-9087"></span></p><p>For example, let’s say that a school had two teachers, each with approximately $30$ students in their class. Both classes take a standardized test, and it turns out that the average score in class A was $5\%$ better than the average in class B.&nbsp; Statistical significance — in this regard — would be our way of determining whether the better score in class A could be attributed to <em>random chance</em>, for instance:</p><ul><li>It was a lucky day for class A.</li><li>Class A just randomly got assigned better prepared students.</li></ul><p>Or whether there is some other factor responsible for the difference in grades between the classes,&nbsp;for instance:</p><ul><li>Teacher A did a better job of teaching than teacher B.</li><li>Teacher A cheated a bit and gave the students some answers ahead of time.</li><li>The classes were purposely split up (e.g., more advanced students or native speakers of a language were put into class A).</li></ul><p>Note that in this case, we wouldn’t — using <em>only</em> the information on the scores at least — attempt to decide what the exact reason for the different scores was. Instead, we would just determine if the score difference could be attributed to pure chance, or that it is so unlikely that there might be some other factors involved.</p><h2 id="start"><span id="Getting_Started"></span><a href="#toc">Getting Started</a><span></span></h2><p>There are two important things when calculating statistical significance. The first is the <strong>magnitude of difference</strong> between what you are measuring and what you are comparing against. The second is the amount of <strong>natural variation</strong> in what you are measuring.</p><p>The first concept, magnitude of difference, is easy to understand. Let’s say that you are a farmer growing pumpkins and trying out new fertilizers. You have a <strong>baseline average</strong> pumpkin weight, which is an average of $10$ lbs. You also have pumpkins from two different fertilizers&nbsp;—A and B&nbsp;— that you are testing out.</p><p>If fertilizer A makes pumpkins that weigh $11$ lbs. on average, then it is possible that the $1$ lbs. difference relative to the baseline $10$ lbs. is <em>caused</em> by the fertilizer. However, if fertilizer B produces $25$ lbs. pumpkins on average, then that $15$ lbs. difference ($25-10$) is more likely to be a result of fertilizer B — than the $1$ lbs. difference was to be a result of fertilizer A.</p><h2 id="sse"><span id="Looking_at_the_Statistical_Significance_Equation"></span><a href="#toc">Looking at the Statistical Significance Equation</a><span></span></h2><p>The most commonly used statistical significance test is probably the <a href="https://en.wikipedia.org/wiki/Z-test" target="_blank" rel="noopener noreferrer"><strong>Z-test</strong></a>. The equation for the Z-test is:</p><figure><img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS1.png" alt="Z-Test Statistics" width="668" height="348" title="SS1"></figure><p>In a nutshell, the Z-Test equation calculates the <em>ratio</em> of two quantities: the numerator on the top, and the denominator at the bottom. Let’s take a look at them individually.</p><h3 id="num"><span id="Numerator"></span><a href="#toc">Numerator</a><span></span></h3><p>The <em>numerator</em> of the equation is where the <strong>magnitude of difference</strong> is accounted for:</p><figure><img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS2.png" alt="Difference Between Sample Mean and Population Mean" width="400" height="127" title="SS2"></figure><p>Here, $\bar{x}$ stands for the&nbsp;<strong>measured average value</strong> for the data set, &nbsp;while $u_0$ stands for the&nbsp;<strong>baseline average value</strong>. In terms of our&nbsp;example with fertilizer B, the baseline and the measured average would be $10$ lbs and&nbsp;$25$ lbs., respectively, yielding a magnitude of difference of:</p><figure><img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS3.png" alt="SS3" width="622" height="89" title="SS3"></figure><p>In general,&nbsp;the larger in magnitude the final Z-value is, <em>the more significantly the sample deviates from the baseline average value</em>. In particular, having a numerator of $15$ ($25-10$) is more significant than having a numerator of $1$ ($11-10$) — all&nbsp;other variables&nbsp;being equal.</p><h3 id="de"><span id="Denominator"></span><a href="#toc">Denominator</a><span></span></h3><p>So far, we have only been focusing on&nbsp;the <em>top half</em> of the statistical significance equation. Let’s take&nbsp;a look at the&nbsp;<em>denominator</em> of the equation&nbsp;this time:</p><figure><img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS4.png" alt="Standard Error of Sample Mean - Amount of Variation in Measured Data" width="600" height="267" title="SS4"></figure><p>Here, $\dfrac{\sigma}{\sqrt{n}}$&nbsp;deals with the amount of variation in our measured data. More specifically,&nbsp;the amount of <em>average deviation</em> in the measured averages themselves — if we were to repeat the sampling process indefinitely.</p><p>After all, you didn’t think that your pumpkins actually all weighted $25$ lbs. did you?&nbsp; Some probably weighted $22$ lbs., and others $27$ lbs.&nbsp; The $25$ lbs. was just an average, and that measured average could change depending on the pumpkins being sampled.</p><h2 id="sd"><span id="Normal_Curve_and_Standard_Deviation"></span><a href="#toc">Normal Curve and Standard Deviation</a><span></span></h2><p>At this point, we need to take a step back and explain what the <a href="https://en.wikipedia.org/wiki/Normal_distribution" target="_blank" rel="noopener noreferrer"><strong>normal curve</strong></a> and <strong>standard deviation</strong> are. Loosely speaking, the normal curve is an approximation of how things occur when they are subjected to <em>aggregated</em>, real life random events. The fact that they are random doesn’t mean that they are <a href="https://mathvault.ca/math-glossary/#arbitrary">arbitrary</a>. As a result, they assume the shape of a <strong>bell curve</strong> as illustrated in the diagram below:<img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS5.png" alt="Normal Curve (Bell Curve)" width="715" height="510" title="SS5">On&nbsp;a related note, the <a href="https://en.wikipedia.org/wiki/Standard_deviation" target="_blank" rel="noopener noreferrer"><strong>standard deviation</strong></a> is a way of measuring the <em>width</em> of the normal curve, and can be alternately defined as the distance from the center which&nbsp;encloses $68.27\%$ of the area below the normal curve:<img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS6.png" alt="Normal Curve - 68% of data are 1 standard deviation within the mean" width="624" height="445" title="SS6">Similarly, two standard deviations define the distance from the center which encloses $95.45\%$ of the curve, and three standard deviations $99.73\%$ of the curve:<img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS7.png" alt="68-95-99 Rule For Normal Distribution" width="715" height="510" title="SS7">For&nbsp;a set of data with a lot of variation, the normal curve will be wide, and hence the standard deviation will be large. This would be the case if you&nbsp;take, say, the weight of $100$ rocks you picked up in your backyard.<img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS8.png" alt="Normal Distribution with Large Standard Deviation" width="463" height="333" title="SS8">Or there could also be almost no variation in the data,&nbsp;as in the case where&nbsp;you measured the processing speed for each computer chip in a batch.<img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS9.png" alt="Normal Distribution with Small Standard Deviation" width="460" height="323" title="SS9">Let’s think about another example — this time involving automobiles. Imagine going to a tire store and being informed&nbsp;that the&nbsp;lifespan of new&nbsp;tires&nbsp;is $50,000$ miles on average, with a standard deviation of $5,000$ miles. Using this information, we can construct the&nbsp;<a href="https://mathvault.ca/hub/higher-math/math-symbols/probability-statistics-symbols/#Discrete_Probability_Distributions" target="_blank" rel="noopener noreferrer"><strong>probability distribution</strong></a> of tire lifespan&nbsp;as follows:<img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS10.png" alt="Tire Life Normal Curve" width="719" height="518" title="SS10">As the graph suggests, we&nbsp;have a $50\%$ chance of being above the average of $50,000$ miles (before needing new tires again), and a $50\%$ chance of being below it. We also know that since two&nbsp;standard deviations correspond to $10,000$ miles (i.e., $5000 \times 2$), we&nbsp;have a $95.45\%$ chance of getting new tires&nbsp;with a mileage between $40,000$ and&nbsp;$60,000$ miles (i.e., two&nbsp;standard deviations within the average):<img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS11.png" alt="Tire Life Normal Curve - Chance of Between 40,000 and 60,000 miles " width="719" height="518" title="SS11">Now, let’s say that a couple of years later,&nbsp;you’ve driven $55,000$ miles and your tires are in need of replacement. Would you consider&nbsp;that unusual? No, probably not, since that’s only <em>one&nbsp;standard deviation away from the mean&nbsp;</em>— which is&nbsp;well within the typical tire-to-tire variation often seen in the market.</p><p>But now, let’s say that this time you’ve driven $60,000$ miles instead before the tires need replacement. This would be&nbsp;<em>two&nbsp;standard deviations<strong>&nbsp;</strong>above the average</em> — which is well above the lifespans of most new tires. In addition, since two standard deviations above the average correspond to the top $2.28\%$ of the curve $\left( \frac{100\% – 95.45\%}{2}\right)$,&nbsp;it follows&nbsp;that your tires actually lasted longer than $97.72\%$ of all other tires!</p><p>Of course, having a single measurement exceeding $97\%$ of your expected measurements is quite unusual. You have to start thinking, “Maybe there is something different about my situation than the typical installation for the same tires.” For example, it could be that:</p><ul><li>You are just a more cautious driver, and wear down the tires less quickly than the typical person.</li><li>The shop put on better tires than you thought. Maybe you got the next level up by some happy accident.</li><li>The tire company undersells their products a little bit, and it is actually better than they advertised.</li></ul><p>Or it could be that it is just a <em>typical variation</em> — and&nbsp;you happen to stumble upon&nbsp;on the right tail of the curve.</p><h2 id="mm"><span id="Multiple_Measurements"></span><a href="#toc">Multiple Measurements</a><span></span></h2><p>So far, we have seen how the normal curve applies to a single measurement. With a single measurement, it is easy to see where it would fall on the normal curve, but how would your opinion&nbsp;change if you had <strong>multiple measurements </strong>instead?</p><p>Maybe you own a fleet of cars, and you got the same type of tires on each of those cars and those tires lasted, say, $46$, $48$, $53$, $54$, $56$, $56$, $57$, $58$, $60$ and $62$ thousand miles. Do these&nbsp;additional measurements make you more or less inclined to believe that the tires last more than the advertised $50,000$ miles?</p><p>To be sure,&nbsp;we can, and will, plug those numbers in to the equation to determine the verdict. But there is an interesting reason why the equation works the way it does, and the way to understand it&nbsp;— as luck would have it —&nbsp;is to begin with some dice rolling.</p><h2 id="sda"><span id="Standard_Deviation_of_Averages"></span><a href="#toc">Standard Deviation of Averages</a><span></span></h2><p>The key to understanding statistical significance is to realize that you&nbsp;actually&nbsp;don’t care much&nbsp;about the standard deviation of the data. What&nbsp;you really care about is the <strong><a href="https://en.wikipedia.org/wiki/Standard_deviation#Standard_deviation_of_the_mean" target="_blank" rel="noopener noreferrer">standard deviation of averages</a> —</strong>&nbsp;a metric pertaining to&nbsp;<em>samples</em> drawn from the data rather than the data themselves, and which changes as one&nbsp;includes&nbsp;more data into the&nbsp;sample.</p><h3 id="1d"><span id="SingleDie_Rolling"></span><a href="#toc">Single-Die&nbsp;Rolling</a><span></span></h3><p>To see how the standard deviation of averages is related to dice rolling, let’s begin our discussion by first throwing a single die. In this case,&nbsp;you have an <strong>equal probability</strong> of getting&nbsp;a $1$, $2$, $3$, $4$, $5$ or $6$. &nbsp;Here’s the probability distribution of that roll for the record:<img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS12.png" alt="Distribution of the Number on a Single Die" width="749" height="529" title="SS12">Here, the <strong>average roll</strong> you would get is $3.5$, and the standard deviation of the&nbsp;roll&nbsp;— which is the <a href="https://mathvault.ca/hub/higher-math/math-symbols/probability-statistics-symbols/#Variables" target="_blank" rel="noopener noreferrer"><strong>population standard deviation</strong></a> of the set $\{ 1, 2, 3, 4, 5, 6 \}$ — is $1.7078$. &nbsp;Note that the population standard deviation is just a measure of how spread out a data set is, and that the greater a data point deviates from the average in the data set, the more it increases the standard deviation of the data set.</p><p>In the case of single die rolling, for example,&nbsp;a roll of a $3$ or a $4$ would contribute the least&nbsp;to the standard deviation.&nbsp;A&nbsp;roll of $2$ or $5$ would contribute a bit more, and&nbsp;a&nbsp;roll of $1$ or a $6$ would be the ones contributing the most.</p><h3 id="2d"><span id="TwoDice_Rolling"></span><a href="#toc">Two-Dice Rolling</a><span></span></h3><p>Now, what happens if you roll <em>two</em>&nbsp;dice instead of one, and take the <em>average</em> of those two rolls? &nbsp;For one, you would get $6 \times 6 = 36$ possible outcomes in that case, which correspond to a total of $11$ possible sums&nbsp;— from a sum of $2$ to a sum to $12$.</p><p>But here’s the caveat: those $36$ different possible rolls actually don’t map evenly onto the $11$ possible sums! In fact, the most likely …</p></section></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mathvault.ca/statistical-significance/">https://mathvault.ca/statistical-significance/</a></em></p>]]>
            </description>
            <link>https://mathvault.ca/statistical-significance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444577</guid>
            <pubDate>Fri, 11 Sep 2020 16:43:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reached 1001 PH upvotes without getting any batch – Our learnings]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24444567">thread link</a>) | @Michael_Sieb
<br/>
September 11, 2020 | https://blog.typestudio.co/product-hunt-learnings/ | <a href="https://web.archive.org/web/*/https://blog.typestudio.co/product-hunt-learnings/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <p>On 07.07 we launched Type Studio for the first time on the platform <strong><a href="https://www.producthunt.com/posts/type-studio">Product Hunt</a></strong>. For all who don't know Product Hunt yet. The platform describes itself as:</p><p>"Product Hunt surfaces the best new products, every day. It's a place for product-loving enthusiasts to share and geek out about the latest mobile apps, websites, hardware projects, and tech creations.”</p><p>With about <strong>5 million</strong> web page views each month (<a href="https://www.similarweb.com/website/producthunt.com/">SimilarWeb</a>) you can see that the community around Product Hunt is quite large. We learned so much from our launch that we decided to share these experiences and insights with you.</p><p>Despite being upvoted by <strong>654 people</strong> within the first <strong>24hrs</strong>, we didn't achieve a spot in the TOP 5 &nbsp;let alone reach the “Product of the Day.” The main reason for this was probably due to the value of most of our upvotes. At the beginning, we rapidly got upvoted by many people from our community, including friends, family members, and also early adopters of <a href="https://typestudio.co/"><strong>Type Studio</strong></a>. In other words, a closer community group. The problem was that most of these people didn’t have a Product Hunt account and had to subscribe on the day of our launch.</p><p>Nevertheless, we went from “zero to hero” really fast. We reached almost <strong>300 upvotes</strong> within the first six hours. These were the six hours where the US wasn’t even awake yet, so we assumed there would be many more upvotes to come as the day went on.</p><figure><img src="https://blog.typestudio.co/content/images/2020/08/product-hunt-upvotes.png" alt="" srcset="https://blog.typestudio.co/content/images/size/w600/2020/08/product-hunt-upvotes.png 600w, https://blog.typestudio.co/content/images/size/w1000/2020/08/product-hunt-upvotes.png 1000w, https://blog.typestudio.co/content/images/2020/08/product-hunt-upvotes.png 1016w" sizes="(min-width: 720px) 720px"><figcaption>Upvotes in 24 hours</figcaption></figure><p>The following six hours were overwhelming as we were on our way to “Product of the Day”. The ongoing upvoting process showed us that our idea, and product, was well received by the Product Hunt community, respectively the Product Hunt natives. Another bump in upvotes came when our tweet was retweeted by the official Product Hunt Twitter account. Even though every product from the top list is featured by them, the retweet gave us an additional push not only for our product’s upvotes, but also for our enthusiasm.</p><p>Our absolute highlight came later in the day when we got retweeted directly by Ryan Hoover, the founder of Product Hunt. We knew that many products get retweeted by the official Product Hunt Twitter page, but this really caught us by surprise! A few minutes later we got a mail from Ryan and Vadika Jain and their <a href="https://weekend.fund/"><strong>Weekend Fund</strong></a> &nbsp;that they would like to meet us.</p><figure><img src="https://blog.typestudio.co/content/images/2020/08/Ryan-Hoover-Twitter-Type-Studio.png" alt=""><figcaption>Shout out by Ryan Hoover</figcaption></figure><p>After <strong>13 </strong>really successful hours in which we held the title “Product of the Day”, our competitors for the day were also getting upvoted quite a lot. Even though we still got the most upvotes, we were overtaken by the <a href="https://www.producthunt.com/posts/mmhmm"><strong>mmhmm</strong></a> app, which is from the <a href="https://evernote.com/">Evernote </a>founder <a href="https://twitter.com/plibin">Phil Libin</a>. His app has gone viral in the whole tech scene and has received over 3500 upvotes so far. Especially his <a href="https://www.youtube.com/watch?v=c8KhKBLoSMk">explanatory video</a> has received an incredible amount of attention - over 300k clicks as of now. If you want to see an excellent product video, you should definitely watch it!</p><p>From this point on, the discrepancy between quality upvotes and less valuable ones could be seen. This means that some of our upvotes did not have the same value as others, and that the acquisition of our close community didn’t have a lasting effect. At the end of the day we were overtaken by some other products with less upvotes, so we ended up in #6 place. </p><p>Nevertheless we are more than satisfied with this result. All in all, we have received a lot of attention, which is also reflected in the <strong>8 investor</strong> inquiries that we received during the day. Over the whole week until now, new upvotes are constantly being added, so that we have <strong>1001 upvotes </strong>at this point in time, which is really </p><figure><img src="https://blog.typestudio.co/content/images/2020/08/giphy-2.gif" alt=""></figure><p>After processing our performance of our Product Hunt launch day, we wanted to give you some insights into what we came to learn from our experiences that day:</p><ul><li>As already mentioned, community is good, but trust on Product Hunt takes the cake: Even though the acquisition of our surrounding community brought us many upvotes, we later noticed that the votes from people who are not frequently on Product Hunt are not worth the same as votes of Product Hunt experienced users/Product Hunt natives. This is probably due to the Product Hunt algorithm. In some blog articles you can even read that the upvotes of new accounts or people who came via a shared link have no value at all, and can even have negative effects on the algorithm.</li><li>Get yourself a <strong>Hunter</strong>! We started our first launch on Product Hunt without having a big Hunter who could have helped us with promoting our tool to the PH community. To be honest, we have had the opportunity to be hunted by <a href="https://www.producthunt.com/@kevin">Kevin William David</a> one of the biggest hunters, but only as a second product, because he already hunted another product as first on that day. That would have meant for us that we would have gone live only from 12pm PST and lost half the day. Also we wouldn't have his advantage that his first hunt would automatically be listed on the start page of Product Hunt. In the end, we definitely learned that having a Hunter is a big help when trying to get upvotes from people who are already on Product Hunt and follow a Hunter because they all get a push notification.</li><li>There are days of varying intensity on which you can launch your product. During the week there are significantly more upvotes than on the weekend. We have made a small evaluation of this. In the chart below you can see the average number of upvotes the <strong>Top 5 products</strong> get together. As you can see Tuesday is the strongest day with an average of <strong>2840 upvotes</strong> for the first 5 products. We deliberately chose Tuesday, because you have the chance to reach the biggest audience at the same time. For this you have to expect that other strong products will launch on this day, as it was the case on our day. If you only have the goal to become "Product of the Day", then you have much better chances on Saturday or Sunday.</li></ul><figure><img src="https://blog.typestudio.co/content/images/2020/08/Picture1-1.png" alt="" srcset="https://blog.typestudio.co/content/images/size/w600/2020/08/Picture1-1.png 600w, https://blog.typestudio.co/content/images/size/w1000/2020/08/Picture1-1.png 1000w, https://blog.typestudio.co/content/images/size/w1600/2020/08/Picture1-1.png 1600w, https://blog.typestudio.co/content/images/2020/08/Picture1-1.png 1980w" sizes="(min-width: 720px) 720px"><figcaption><strong>Average Upvotes of the Top 5 products from 03.08.2019 to 03.08.2020</strong></figcaption></figure><ul><li>Another exciting opportunity is using <a href="https://www.producthunt.com/ship"><strong>Product Hunt Ship</strong></a> to announce your product even before launching it! Ship<strong><strong> </strong></strong>allows you to advertise your product BEFORE the launch, in order to acquire and engage with early-adopters through an <em><em>upcoming</em></em> landing page and a mailing-list. Since the Pro and Super Pro are really expensive, Ship is probably only worthwhile for Prodcute, through which you get paying customers. But you should definitely check out the basic version! We will too... and maybe even the pro version for our next launch! </li></ul><figure><img src="https://blog.typestudio.co/content/images/2020/08/Product-Hunt-Ship_Pricing.png" alt="" srcset="https://blog.typestudio.co/content/images/size/w600/2020/08/Product-Hunt-Ship_Pricing.png 600w, https://blog.typestudio.co/content/images/size/w1000/2020/08/Product-Hunt-Ship_Pricing.png 1000w, https://blog.typestudio.co/content/images/2020/08/Product-Hunt-Ship_Pricing.png 1301w" sizes="(min-width: 720px) 720px"><figcaption>Product Hunt Ship pricing</figcaption></figure><p>As we mentioned at the beginning, we also want to share some insights with you.<br>Here are a few facts and figures from our Google Analytics account. All in all we had <strong>11.8K</strong> sessions from Tuesday to Sunday during the launch week with <strong>5.3K</strong> unique visitors. On the day itself there were <strong>2.4K</strong> unique visitors.</p><figure><img src="https://blog.typestudio.co/content/images/2020/08/Website-visits-product-hunt-launch-1.png" alt="" srcset="https://blog.typestudio.co/content/images/size/w600/2020/08/Website-visits-product-hunt-launch-1.png 600w, https://blog.typestudio.co/content/images/2020/08/Website-visits-product-hunt-launch-1.png 810w" sizes="(min-width: 720px) 720px"><figcaption>Amount of website visits</figcaption></figure><p>The website hits come mostly from the US (<strong>23%</strong>), followed by India (<strong>9%</strong>). According to <a href="https://www.similarweb.com/website/producthunt.com/#overview">SimilarWeb</a> these are also the two largest community groups on the platform. The device behavior shows that most people have visited our site via the Desktop browser, which is very useful for us, since we currently only offer the editor for the desktop and not for mobile.</p><figure><img src="https://blog.typestudio.co/content/images/2020/08/Group-625--1-.png" alt="" srcset="https://blog.typestudio.co/content/images/size/w600/2020/08/Group-625--1-.png 600w, https://blog.typestudio.co/content/images/2020/08/Group-625--1-.png 636w"><figcaption>Website traffic by country and device</figcaption></figure><p>In <a href="https://amplitude.com/">Amplitude</a>, we recorded a total of <strong>541 new Signup's</strong> during the week, which turned out to be very valuable for us, as we received an incredible amount of user feedback.</p><figure><img src="https://blog.typestudio.co/content/images/2020/08/Screen-Shot-2020-08-04-at-12.27.39-AM.png" alt="" srcset="https://blog.typestudio.co/content/images/size/w600/2020/08/Screen-Shot-2020-08-04-at-12.27.39-AM.png 600w, https://blog.typestudio.co/content/images/size/w1000/2020/08/Screen-Shot-2020-08-04-at-12.27.39-AM.png 1000w, https://blog.typestudio.co/content/images/2020/08/Screen-Shot-2020-08-04-at-12.27.39-AM.png 1141w" sizes="(min-width: 720px) 720px"><figcaption>Type Studio new Signup's</figcaption></figure><hr><p>In conclusion, our launch on Product Hunt was very successful, we learned a lot about what we can do better next time and recommend everyone to launch their product there, because the community and the feedback you get is unique and valuable. If you have also launched on Product Hunt or plan to do so, feel free to drop me a <a href="https://www.linkedin.com/in/michaelsieb/">message</a>.</p>
            </div></div>]]>
            </description>
            <link>https://blog.typestudio.co/product-hunt-learnings/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444567</guid>
            <pubDate>Fri, 11 Sep 2020 16:42:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You’re fired: Dutch hackers broke into Trump’s Twitter account]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24444514">thread link</a>) | @hellofunk
<br/>
September 11, 2020 | https://www.dutchnews.nl/news/2020/09/youre-fired-dutch-hackers-broke-into-trumps-twitter-account-in-2016/ | <a href="https://web.archive.org/web/*/https://www.dutchnews.nl/news/2020/09/youre-fired-dutch-hackers-broke-into-trumps-twitter-account-in-2016/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="attachment_128853"><p><img aria-describedby="caption-attachment-128853" src="https://www.dutchnews.nl/wpcms/wp-content/uploads/2018/10/hackers-560x315.jpg" data-src="https://www.dutchnews.nl/wpcms/wp-content/uploads/2018/10/hackers-560x315.jpg" alt="" width="560" height="315" data-srcset="https://www.dutchnews.nl/wpcms/wp-content/uploads/2018/10/hackers-560x315.jpg 560w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2018/10/hackers-768x432.jpg 768w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2018/10/hackers-640x360.jpg 640w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2018/10/hackers-100x56.jpg 100w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2018/10/hackers-130x73.jpg 130w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2018/10/hackers.jpg 1000w" data-sizes="(max-width: 560px) 100vw, 560px" srcset="https://www.dutchnews.nl/wpcms/wp-content/uploads/2018/10/hackers-560x315.jpg 560w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2018/10/hackers-768x432.jpg 768w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2018/10/hackers-640x360.jpg 640w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2018/10/hackers-100x56.jpg 100w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2018/10/hackers-130x73.jpg 130w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2018/10/hackers.jpg 1000w"></p><p id="caption-attachment-128853">Photo: Depositphotos.com</p></div><p>Three Dutch hackers broke into Donald Trump’s Twitter account shortly before he became president in 2016 by guessing his password was ‘yourefired’, magazine<a href="https://www.vn.nl/tijdlijn-zo-verliep-de-hack-van-trump/"> Vrij Nederland reported</a> this week.</p><p>The hackers, named as Edwin, Mattijs and Victor by the magazine, used a leaked list of LinkedIn accounts from 2012 to target Trump, then a presidential candidate and then warn him in an email that they had broken in.</p><p>Vrij Nederland journalist Gerard Janssen interviewed the three and published a major report of the hack after meeting them at a hackers’ convention. Screenshots show they were members of a hackers group calling itself Guild Of The Grumpy Old Hackers and that they broke into Trump’s account on October 27, 2016, shortly before the presidential vote.</p><p>They took the password from the leaked LinkedIn database, which contained 117 million names and passwords. ‘You’re fired’, was a popular Trump catchphrase in his roll on television show The Apprentice.</p><p>‘They were shocked when they succeeded,’ Janssen told NOS news. ‘They knew that they could be in trouble because it could be seen as a cyber attack on a presidential candidate.’</p><p>The hackers, who documented their actions thoroughly, never heard from Trump himself, but National Cyber Security Centre (NCSC) replied to them in November 2016, thanking them for getting in touch. All three, who now work in online security trying to detect weaknesses in corporate and government software, have also been able to visit America without any trouble.</p><p>Donald Trump was not among a <a href="https://www.forbes.com/sites/barrycollins/2020/07/16/twitter-hack-why-wasnt-donald-trump-targeted/">list of famous names</a>, including Bill Gates, Elon Musk, Apple, Joe Biden, and Barack Obama, whose Twitter accounts were hacked in July this year.</p><div onclick="window.location.href='https://www.dutchnews.nl/donate-to-dutchnews-nl/'"><div><h4>Thank you for donating to DutchNews.nl</h4><p>The DutchNews.nl team would like to thank all the generous readers who have made a donation in recent weeks. Your financial support has helped us to expand our coverage of the coronavirus crisis into the evenings and weekends and make sure you are kept up to date with the latest developments.</p><p> <strong>DutchNews.nl</strong> has been free for 14 years, but without the financial backing of our readers, we would not be able to provide you with fair and accurate news and features about all things Dutch. Your contributions make this possible.</p><p> <strong> <a href="https://www.dutchnews.nl/donate-to-dutchnews-nl/"> If you have not yet made a donation, but would like to, <br>you can do so via Ideal, credit card or Paypal. </a> </strong></p></div></div></div></div>]]>
            </description>
            <link>https://www.dutchnews.nl/news/2020/09/youre-fired-dutch-hackers-broke-into-trumps-twitter-account-in-2016/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444514</guid>
            <pubDate>Fri, 11 Sep 2020 16:36:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Security by obscurity is underrated]]>
            </title>
            <description>
<![CDATA[
Score 814 | Comments 472 (<a href="https://news.ycombinator.com/item?id=24444497">thread link</a>) | @pcr910303
<br/>
September 11, 2020 | https://utkusen.com/blog/security-by-obscurity-is-underrated.html | <a href="https://web.archive.org/web/*/https://utkusen.com/blog/security-by-obscurity-is-underrated.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>
08 September 2020
</p>
<p>In the information security field, we have developed lots of thoughts that can’t be discussed (or rarely discussed):</p>
<ul>
<li>
<p>Never roll your own crypto</p>
</li>
<li>
<p>Always use TLS</p>
</li>
<li>
<p>Security by obscurity is bad</p>
</li>
</ul>
<p>And goes like this. Most of them are very generally correct. However, I started to think that people are telling those because everyone is telling them. And, most of the people are actually not thinking about exceptional cases. In this post, I will raise my objection against the idea of “Security by obscurity is bad”.</p>
<h2 id="risk-defense-in-depth-and-swiss-cheese">Risk, Defense in Depth and Swiss Cheese</h2>
<p>One of the main goal of defensive security is reducing the risk for the target business. According to the OWASP’s methodology, the risk of an issue is calculated with the formula below:</p>
<p><code>Risk = Likelihood * Impact</code></p>

<p>According to this formula, a Remote Code Execution issue poses more risk than a Cross Site Scripting one since the RCE causes more impact. This is easy. But what about the likelihood metric. According to the OWASP, likelihood refers that:</p>
<div><div><pre><code>At the highest level, this is a rough measure of how likely this particular vulnerability is to be uncovered and exploited by an attacker
</code></pre></div></div>
<p>So, if we can reduce the likelihood, we can reduce the overall risk. That’s good. It’s actually very similar to a very common idea called “Defense in Depth”. It’s also referred as “Swiss Cheese Model”</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/0/07/Swiss_cheese_model.svg" alt="Swiss Cheese"></p>
<p>According to this model, you need to build your defense mechanisms in a layered model so that even the attackers pass the first one, they will get caught on the others.</p>
<h2 id="security-by-obscurity">Security by Obscurity</h2>
<p>So let’s talk about security by obscurity. It’s a bad idea to use it as a single layer of defense. If the attacker passes it, there is nothing else to protect you. But it’s actually would be good to use it as an “additional” layer of defense. Because it has a low implementation cost and it usually works well.</p>
<p>Let’s think about a couple of scenarios here:</p>
<ul>
<li>I have a server that runs the SSH with it’s default port <code>22</code> and my credentials are: <code>root:123456</code>. What is the likelihood of being compromised?</li>
</ul>
<p>It’s almost 100% since the hackers are conducting brute force attacks to the services with common credentials globally.</p>
<ul>
<li>SSH runs in port <code>22</code> and my credentials are <code>utku:123456</code>. What is the likelihood of being compromised?</li>
</ul>
<p>Well, we have eliminated the global brute forcers since we are not using a common username. The likelihood and risk are reduced. However, we still have to deal with targeted attackers. A targeted attacker can guess the username as <code>utku</code> since it’s my name.</p>
<ul>
<li>SSH runs in port <code>64323</code> and my credentials are <code>utku:123456</code>. What is the likelihood of being compromised?</li>
</ul>
<p>Now we changed the default port number. Does it help? Firstly, we’ve eliminated the global brute forcers again since they scan only the common ports. What about the others? To find this out, I did a small survey on my Twitter to find out people’s port scan behaviors.</p>
<blockquote><div lang="en" dir="ltr"><p>I'm trying to prove a point for my new article. I need your answers for the question below. (please be honest)</p><p>-When you do a port scan with nmap to find open ports on the target, are you specify a custom port range to scan all 65,535 ports? (with -p0-65535 parameter)</p></div>— Utku Şen (@utkusen) <a href="https://twitter.com/utkusen/status/1303021175556145154?ref_src=twsrc%5Etfw">September 7, 2020</a></blockquote>

<p>As you can see here, lots of people tend to scan the default/most popular ports only. So, if you switch your port from 22 to 64323, you will eliminate some of them. You will reduce the likelihood and risk.</p>
<p>The same thing goes for software vulnerabilities as well. If a vulnerability found in the Microsoft Remote Desktop Protocol, everybody will scan for the port 3389 globally. You can reduce your risk just by changing the default port.</p>
<h2 id="other-applications">Other Applications</h2>
<p>Of course, it’s possible to use the same methodology in other fields other than changing the defaults. For example, the following ideas might be a good idea for some specific cases (not always)</p>
<ul>
<li>
<p><strong>Obfuscating codes:</strong> Of course, it’s common knowledge. Hackers are people too. If you obfuscate your code well, they will need to spend more time to find issues. They may give up eventually.</p>
</li>
<li>
<p><strong>Using random variable names for a web application:</strong> Instead of using clear variable names, you can switch them with random strings. It might help just like the code obfuscation.</p>
</li>
<li>
<p><strong>Using Symmetric Encryption in the Database:</strong> When you write data to the database, use a function like <code>encryption_algorithm(data,key)</code>. Likewise, when you read data, use a function like <code>decryption_algorithm(data,key)</code>. If the attacker can read your backend code, obviously he/she can decrypt your database. But if there is an issue that allows an attacker to read data from the database, but not the backend code (like SQL Injection), the gathered data won’t be helpful for the attacker.</p>
</li>
</ul>
<h2 id="real-life-applications">Real Life Applications</h2>
<p>Security by obscurity is widely used in physical/real-life security. For example, the president goes from point A to point B with his 30 cars convoy. But he’s not sitting on his own presidential car so that the attacker won’t target him easily. He can be in any car and it reduces the risk of an attack.</p>
<p><img src="https://i.dailymail.co.uk/1s/2019/06/04/00/14330600-0-image-a-38_1559605545988.jpg" alt="President"></p>
<p>Camouflaged animals are using security by obscurity as well. Obscurity reduces the likelihood of being killed. Therefore, they gained this ability in the evolutionary process.</p>
<p><img src="https://static.boredpanda.com/blog/wp-content/uuuploads/animal-camouflage/animal-camouflage-4.jpg" alt="Animal"></p>
<h2 id="conclusion">Conclusion</h2>
<p>Security by obscurity is not enough by itself. You should always enforce the best practices. However, if you can reduce the risk with zero cost, you should do that. Obscurity is a good layer of security.</p>


</div></div>]]>
            </description>
            <link>https://utkusen.com/blog/security-by-obscurity-is-underrated.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444497</guid>
            <pubDate>Fri, 11 Sep 2020 16:34:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bazel, Haskell, and Build-System Joy]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24444449">thread link</a>) | @LukeHoersten
<br/>
September 11, 2020 | https://blog.sumtypeofway.com/posts/bazel-haskell-build-system-joy.html | <a href="https://web.archive.org/web/*/https://blog.sumtypeofway.com/posts/bazel-haskell-build-system-joy.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            <article>
                
                
                  <h2>2020-09-10</h2>
                
                <section>
                    <p>As part of my day job at GitHub, I work on the <a href="https://github.com/github/semantic"><code>semantic</code></a> program analysis toolkit. It’s a lot of fun and a lot of Haskell: we clock around <span>17,000</span> lines of Haskell source, though at times it’s been as high as <span>29,000</span>. The project in total has around a hundred direct dependencies, and several hundred resulting indirect ones. Though initially we used <a href="https://docs.haskellstack.org/en/stable/README/">Stack</a> to build <code>semantic</code>, we switched to <a href="https://cabal.readthedocs.io/en/3.4/">Cabal</a> when it gained the ability to build within a sandbox.</p>
<p>With <code>cabal</code> and a clean build environment, <code>semantic</code> takes between twenty and forty-five minutes to complete. When optimizations are enabled, it can take on the order of hours, especially when rebuilding dependencies with optimizations. And this is fair! Haskell is a complicated language that takes serious computational power to compile. And though Cabal is a versatile and fast-improving tool, it isn’t perfect, especially when applied to large monorepos containing many subprojects. Issues we ran into include:</p>
<ul>
<li>Little compositionality: though <code>common</code> stanzas in <code>.cabal</code> files cut down on repetition within a single file, it’s not possible to share settings or configurations across multiple files.</li>
<li>Suboptimal caching: due to the vagaries of Template Haskell, <code>cabal</code> is very conservative about caching files containing TH splices. This is correct behavior on <code>cabal</code>’s part, but grows tedious when innocuous changes cause rebuilds that we know are unnecessary. The third-party <a href="https://github.com/haskell-works/cabal-cache"><code>cabal-cache</code></a> ameliorated some of this on our CI boxes, but did not address the problem fully. Additionally, any modification to a <code>.cabal</code> file throws out its associated caches, even when doing something that shouldn’t invalidate existing caches, such as adding a new module.</li>
<li>Phasing restrictions: our build process involved generating Haskell data types from text files containing grammar descriptions, and it’s not generally possible to access project-local files during Template Haskell splices.</li>
<li>Scriptability: when dealing with large projects, it’s often very convenient to do some limited forms of iteration when specifying build configurations, and the pure-text format of <code>.cabal</code> files precludes this.</li>
<li>Reliable REPLs: in order to yield a REPL capable of loading files without first compiling the entire project, we required a complicated and brittle <a href="https://github.com/github/semantic/blob/master/script/ghci-flags">bash script</a>.</li>
<li>Convenience: compared to other languages in which you can just drop new source files and have them picked up by the compiler, <code>cabal</code> requires you to list them explicitly. While explicit is very often better than implicit, the case of adding a new module to a project is so common that editing <code>.cabal</code> files every time becomes tedious.</li>
</ul>
<p>As you can imagine, living with hour-long CI cycles was not an indefinitely tenable situation. But I think the issue of long CI cycles goes deeper than mere inconvenience: I believe that we as software developers have an ethical duty to keep build times and CI times down. We live in a world where carbon emissions have created, at least in part, a climate so troubled that the west coast of the United States is <a href="https://www.nytimes.com/2020/09/09/us/fires-oregon-california-live-updates.html">a literal hellscape</a>, where island populations are being displaced due to <a href="https://www.theguardian.com/environment/georgemonbiot/2009/may/07/monbiot-climate-change-evacuation">rising sea levels</a>, and where <a href="https://ourworld.unu.edu/en/a-growing-digital-waste-cloud">cloud computing consumes more energy</a> than some entire nations; I’ve grown to find the thought of letting corporations’ Travis or CircleCI instances recompute thousands of pointless builds upsetting, upsetting in a way similar to the thought of said companies contaminating groundwater with industrial byproducts. To meaningfully change the way companies consume resources requires broad labor action; however, irrespective of when this action is taken, we as engineers have an opportunity and responsibility to be the agents of change.</p>
<p>I also believe that very few people<span><label for="sn-0"></label><span>Excluding Rust programmers, who get to use the truly excellent <code>cargo</code>, and who seem to be very happy with it.</span></span> are truly happy with their build tool. I certainly haven’t been, anyway. To name but a few: the shortcomings of <code>make</code> have been documented for longer than I’ve been alive; <code>xcodebuild</code> only works on macOS/iOS targets; <a href="https://cmake.org/">CMake</a> is powerful but has no interoperability with <code>cabal</code>. It’s hardly controversial to suggest that, given a large project, no build system will be perfect for all people. This faact doesn’t make the quest for a better build system useless, but should also inform the engineer-voice that demands perfection.</p>
<p>Wearied by hour-long builds, both on CI and locally, I looked around for alternative build solutions that might ease that weariness. I settled on <a href="https://bazel.build/">Bazel</a>, with the <a href="https://haskell.build/"><code>rules_haskell</code></a> toolkit designed by the fine folks at <a href="https://www.tweag.io/">Tweag</a>. I’m happy to report that the experience was brilliant: if it’s possible for a build system to produce joy, Bazel and <code>rules_haskell</code> do. What follows is a brief overview of the Bazel experience, and the process of porting a large, multi-project repository to support either <code>cabal build</code> or <code>bazel build</code>.</p>

<p>The biggest thing to wrap your head around when coming to Bazel from other build systems is that <em>everything</em> on which your build depends—source files, data files, package dependencies, vendored git repositories−must be specified explicitly in Bazel. It does not suffice for your build process to just look at a given file I know is present in the repository; if the target that I’m specifying depends on that file, it must be listed explicitly as a dependency. Dependencies, in Bazel parlance, are more than libraries or repositories: the set of dependencies, and the hashed contents of all these dependencies, are what tells Bazel when builds can be cached and when they can’t. This also goes for test targets: if your tests need to read from some corpus of fixtures, you’ll have to specify those fixtures as an explicit dependency so that they’re available at runtime. This can be an involved process, as sometimes you just want to access a file (come on, it’s <em>right there</em>, I found myself whispering), but the benefits also show up in testing: if your tests are deterministic (as they should be), Bazel is capable of caching your test results, and only rerunning them when the source <em>or the fixtures</em> change. Given that the full tests for <code>semantic</code> parsing take several minutes to run, this is a profound improvement, especially on CI.</p>
<p>Beginning a new Bazel project, or converting from Cabal, requires starting with the <code>WORKSPACE</code> file. The <code>WORKSPACE</code> specifies the root of the current project, downloads and sets up GHC, and is the only place where external dependencies—such as those downloaded from Hackage—are specified. Targets are specified per-project in <code>BUILD.bazel</code> files, each of which refers as needed to external dependencies defined in the <code>WORKSPACE</code>. The language used to specify these <code>.bzl</code> files is known as <a href="https://docs.bazel.build/versions/master/skylark/language.html">Starlark</a>, and is a subset of Python that discourages mutability and iteration—though I’m hardly the world’s biggest fan of Python, I found Starlark very pleasant to use, as its chosen subset of Python is strict enough to disallow most of the things I find egregious. Once the <code>WORKSPACE</code> file is set up, the process of conversion becomes specifying per-project library and executable targets in the <code>BUILD.bazel</code> file present in each project within the monorepo.</p>
<h2 id="whence-cabal-dependencies">Whence Cabal Dependencies?</h2>
<p>As I mentioned earlier, there are several hundred direct and indirect dependencies across all subprojects in the <code>semantic</code> monorepo. Each of these dependencies has to be declared and made available as a build target, specified in the <code>WORKSPACE</code>. There are three options for specifying dependencies on Hackage projects:</p>
<ul>
<li>Specify them all manually by downloading them with <a href="https://docs.bazel.build/versions/master/repo/http.html"><code>http_archive</code></a> and <a href="https://api.haskell.build/haskell/cabal.html#haskell_cabal_library"><code>haskell_cabal_library</code></a>, doing so would be tedious beyond words, especially given that we’d have to declare dependencies for each package.</li>
<li>Use the <a href="https://nixos.org/">Nix</a> expression language, in combination with the <a href="https://github.com/tweag/rules_nixpkgs"><code>rules_nixpkgs</code></a> ruleset, and transform Nix derivations into Bazel targets.</li>
<li>Pin to a particular <a href="https://www.stackage.org/">Stackage</a> release, specifying non-Stackage dependencies with a YAML file in the project root.</li>
</ul>
<p>Though Nix has considerable merit, especially when corralling system dependencies, it’s still an unconventional choice in industry, and I deemed it politically unattainable to introduce not just one but two new frameworks for builds. As such, I chose to build against a Stackage release, especially given that we have no real system-level dependencies and that ninety percent of our dependencies are already present in Stackage snapshots.</p>
<h2 id="code-generation-it-matters">Code Generation: It Matters</h2>
<p>Because maintaining syntax trees by hand was much too onerous, my coworker <a href="https://twitter.com/aymannadeem">Ayman</a> swooped in and wrote Template Haskell splices that <a href="https://github.blog/2020-08-04-codegen-semantics-improved-language-support-system/">generate syntax types</a> from a <a href="https://tree-sitter.github.io/tree-sitter/">tree-sitter</a> JSON description of the grammar. This works well, but hinges on the ability to read said grammar descriptions from the filesystem. This was a fraught process in Cabal, relying on autogenerated <code>Paths_</code> modules providing access to files specified in the <code>data-files</code> setting in each project’s <code>.cabal</code> file, and only happened to work by accident: were <code>semantic</code> uploaded to Hackage, no one would be able to use it as a dependency, as <code>cabal</code> would be unable to find the required file. As it is, this happened to work because our downstream clients use a pinned Git hash in their <code>cabal.project</code> to pull in <code>semantic</code> as a dependency; because <code>cabal</code> checks out the whole repository in this case, the tree-sitter files happen to be in the correct place.</p>
<p>Bazel and <code>rules_haskell</code> take a more principled approach to this. Rather than calling pre-provided functions to determine the locations of these JSON files, we make the build system take care of finding them, by declaring that each language package has an explicit dependency on said file. We can pass in the location of this file as a preprocessor flag to the build process, which is then substituted using the <code>CPP</code> extension to Haskell. This doesn’t work perfectly—there’s an <a href="https://github.com/tweag/rules_haskell/issues/1337">incorrect interaction</a> when invoking a REPL on a language package in question—but suffices in …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.sumtypeofway.com/posts/bazel-haskell-build-system-joy.html">https://blog.sumtypeofway.com/posts/bazel-haskell-build-system-joy.html</a></em></p>]]>
            </description>
            <link>https://blog.sumtypeofway.com/posts/bazel-haskell-build-system-joy.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444449</guid>
            <pubDate>Fri, 11 Sep 2020 16:30:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What we can learn from Plasma telemetry]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24444424">thread link</a>) | @caution
<br/>
September 11, 2020 | http://blog.davidedmundson.co.uk/blog/what-we-can-learn-from-plasma-telemetry/ | <a href="https://web.archive.org/web/*/http://blog.davidedmundson.co.uk/blog/what-we-can-learn-from-plasma-telemetry/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-301">
	
	<!-- .entry-header -->

	<div>
		<p>Since Plasma 5.18, about 7 months ago, Plasma has shipped with a telemetry system. Opt in (i.e off by default) it requires users to go to choose if (and how much) data to send to us.<br>
No private or identifying information is sent, and everything is stored inline with our <a href="https://kde.org/privacypolicy-apps">privacy policy</a>. </p>
<p>Currently we have hit just shy of 100,000 updates!</p>
<p>We have started off requesting very little information. Versions, GPU info and some basic screen information. However the library powering this is extremely powerful and capable of so much more that we can try and build on in the future to try and identify weak areas and areas we need to invest time and effort and also to identify features or platforms that maybe are under utilised and can be dropped.</p>
<p>I have recently been trying to improve on how we can extract and visaulise data from the data collected and draw some conclusions. I want to present some of the aggregated metrics.</p>

<p><a href="http://blog.davidedmundson.co.uk/wp-content/uploads/2020/09/Screenshot_20200911_113634.png"><img src="http://blog.davidedmundson.co.uk/wp-content/uploads/2020/09/Screenshot_20200911_113634-1024x182.png" alt=""></a></p>
<h4>Used Plasma Versions</h4>
<p>To explain our numerical versioning additons.<br>
.80 = git master before the next version, up until the beta<br>
.90 = after the stable branch forks for release up until the next.0 release.</p>
<h2>LTS</h2>
<p>The biggest surprise is that LTS is currently only used by around 5% of people with 93% of reporting users on the lastest stable (5.19)</p>
<p>At the current rate it does make me question whether the LTS is worth it. Maybe LTS will only gain traction when the next LTS distro gets a release which could come later? </p>
<p>Obviously any decision will only be made as the result of a discussion with all stakeholders, but this is definitely raising questions.</p>
<h2>Testing</h2>
<p>Right now about 1.5% of people run master, I had expected those users to be the most into helping with the telemetry and skew this further.<br>
The bigger surprise is the number of people running master seems to fluctuate. Weekly users can go between 30-60. I had expected this to be constant.</p>
<p>It is comforting to see that betas do get more users, going up to 2.5% of our reporting userbase.</p>
<h2>Interesting observations</h2>
<p>There is one person who is still activitly using Plasma 5.18 beta. Not 5.18, the beta for 5.18.. which was 8 months ago.<br>
I have so many questions.</p>

<p><a href="http://blog.davidedmundson.co.uk/wp-content/uploads/2020/09/Screenshot_20200911_113830.png"><img src="http://blog.davidedmundson.co.uk/wp-content/uploads/2020/09/Screenshot_20200911_113830-1024x253.png" alt=""></a></p>
<p>800x600 resolution setups are still a thing we need to support, even if they are just VMs they're still used. This is very relevant as we often get commits blindly setting a minimum size hint of a window to be bigger because it "looks nicer". I now know I do still need to ensure in review that we don't break these setups.</p>
<p>We also see that ultrawide monitors are surprisingly unpopular despite clearly being the best monitor setup possible.</p>

<p><a href="http://blog.davidedmundson.co.uk/wp-content/uploads/2020/09/Screenshot_20200911_113952.png"><img src="http://blog.davidedmundson.co.uk/wp-content/uploads/2020/09/Screenshot_20200911_113952-1024x183.png" alt=""></a></p>
<p>The graph is pretty self-explanatory, Intel has the most, but the Nvidia proprietory driver comes in at ~1/4 of the total users.<br>
It makes it an important target to support as best as we can even if it comes with its share of problems.</p>

<p>The reason we want to use telemetrics is to drive decisions with real data.</p>
<p>As a user you are more than welcome to choose to opt into the statistics or not, we understand privacy is important which is why everything is opt-in only.<br>
However, real decisions will ultimately be based on the data we have available, if you want your usecases to be noted, please do consider submitting to the telemetry to us.<br>
To enable telemetry  please go to "System Settings" and select the "User Feedback" tab.</p>
	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

</article></div>]]>
            </description>
            <link>http://blog.davidedmundson.co.uk/blog/what-we-can-learn-from-plasma-telemetry/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444424</guid>
            <pubDate>Fri, 11 Sep 2020 16:26:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Regarding Semantic Versioning]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 21 (<a href="https://news.ycombinator.com/item?id=24444391">thread link</a>) | @zdw
<br/>
September 11, 2020 | https://www.danielmoch.com/posts/2020/09/regarding-semantic-versioning/ | <a href="https://web.archive.org/web/*/https://www.danielmoch.com/posts/2020/09/regarding-semantic-versioning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p>So as not to bury the lede, I'll get to my point: <a href="https://semver.org/">Semantic
Versioning</a> is a meta-API, and maintainers who are cavalier about
violating it can't be trusted to created stable contracts. I've lost
patience for breaking changes making their way to my code bases without
the maintainers incrementing the major version of their projects,
especially in language ecosystems where Semantic Versioning is
expected, and in such cases I'm going to begin exploring alternative
options so I can ban such libraries from my projects---personal and
professional---altogether.</p>
<!-- TEASER_END -->
<div id="what-even-is-semantic-versioning">
<h2>What Even Is Semantic Versioning?</h2>
<p>When developers adopt an external library into their code bases, they
do so knowing they will be bound in their use of the library by the
application programming interface (API). In this sense, an API can be
seen as a kind of contract between a library's maintainer and its
consumers. If a maintainer makes frequent changes to a library's API,
then that API is considered unstable. In that situation, consumers
either use the library anyway, accepting the risk that things will
break as a result of a change in the library, or they avoid it.</p>
<p>Semantic Versioning seeks to ease this picture by embedding notions of
backward- and forward- compatibility into software version numbers. If
a library maintainer adheres to it, then consumers are able to upgrade
to newer versions of the library (say, to pick up bug fixes) without
fear of breaking changes, provided they aren't moving to a new, major
version. In terms of backward- and forward-compatibility, Semantic
Versioning creates an expectation that a given version of a library is
forward-compatible with any future version up to the next, major
release. A library is also backward-compatible down to the most
recent, minor release (beyond which point consumers' code _might_
break if they are using newer library features).</p>
<p>There are several benefits to using Semantic Versioning. One benefit
is that it becomes easy to codify dependency requirements into
automated dependency tools. By <em>assuming</em> Semantic Versioning, users
of tools like NodeJS's <code>npm</code> and Rust's <code>cargo</code> are able to
specify dependency <em>ranges</em> rather than hard-coded versions. So if a
new release of a library comes out, these tools are able to decide
automatically whether or not they can be used in a given project. In
other words, Semantic Versioning creates an opportunity for downstream
developers to easily decide whether or not to upgrade to a new version
of a library, potentially picking up important bug fixes in the
process.</p>
</div>

<div id="conclusion">
<h2>Conclusion</h2>
<p>If you work in a language ecosystem where Semantic Versioning is the
<em>de facto</em> norm, where violating it can wreak havoc downstream, then
please play nice and follow its dictates. Instead of viewing it as a
straight jacket, try to see it as an algorithm to determine what your
next release number should be. We should all like algorithms!</p>
<p>If you refuse to be persuaded, then understand I will will not work
downstream from you <a href="https://www.danielmoch.com/posts/2020/09/regarding-semantic-versioning/#id2" id="id1">1</a>. I'll find a different upstream to work with
because I cannot trust you to create a stable contract. Your
willingness to conform to the meta-API is something I will take into
consideration in the future before adopting a library into any project
that I work on. I wish you well; I hope you have fun; I'll be sure to
give you a wide berth.</p>
<dl>
<dt id="id2"><span><a href="https://www.danielmoch.com/posts/2020/09/regarding-semantic-versioning/#id1">1</a></span></dt>
<dd>
<p>I'll note here that I'm more forgiving in environments where
Semantic Versioning is not a <em>de facto</em> norm.</p>
</dd>
</dl>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://www.danielmoch.com/posts/2020/09/regarding-semantic-versioning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444391</guid>
            <pubDate>Fri, 11 Sep 2020 16:23:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How do you reason about a probabilistic distributed system?]]>
            </title>
            <description>
<![CDATA[
Score 98 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24444276">thread link</a>) | @ahelwer
<br/>
September 11, 2020 | https://ahelwer.ca/post/2020-04-15-probabilistic-distsys/ | <a href="https://web.archive.org/web/*/https://ahelwer.ca/post/2020-04-15-probabilistic-distsys/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    <div>
      <article role="main">
        <h2 id="in-which-i-am-stunted-upon-by-coin-flips">In which I am stunted upon by coin flips</h2>
<p>Wasn’t too long ago that I felt pretty good about my knowledge of distributed systems.
All someone <em>really</em> needed in order to understand them, I thought, was a <a href="https://www.youtube.com/watch?v=JEpsBg0AO6o">thorough understanding of the paxos protocol</a> and a willingless to reshape your brain in the image of TLA+.
Maybe add a dash of conflict-free-replicated datatypes, just so you know what “eventual consistency” means.
Past that it’s just some optimizations and mashups which come easily to your TLA+-addled brain.</p>
<p>This belief proved surprisingly robust over a number of years, even surviving an aborted attempt at analyzing the <a href="https://github.com/ahelwer/tla-experiments/blob/master/Nano.tla">Nano cryptocurrency</a>.
It was only after encountering <a href="https://muratbuffalo.blogspot.com/2018/06/snowflake-to-avalanche-novel-metastable.html">the snowflake family of consensus protocols</a> that I realized my theory just wasn’t up to the challenge.
The issue was <em>probability</em>: snowflake protocols reach consensus by iteratively polling sets of other nodes at random, and the argument that consensus is eventually reached is a statistical argument deriving an upper bound on the probability of failure.</p>
<p>I didn’t <em>dislike</em> probability &amp; statistics, I just tried to keep my distance as much as possible.
All the algorithms in distributed systems I’d encountered so far involved <em>nondeterminism</em>, sure, but not probability.
I’d assumed nondeterminism was just a more flexible way of reasoning about probability.
This idea of mine would prove to be a source of great unnecessary confusion as I learned the art of reasoning about probabilistic distributed systems, so I’ll do you a favor and give you the core lesson of this entire post in one sentence:</p>
<p><strong>You cannot model probability with nondeterminism, and you cannot model nondeterminism with probability.</strong></p>
<h2 id="models-theyre-good-folks">Models: they’re good, folks!</h2>
<p>Have you ever been writing some multithreaded code, happily plugging in a mutex here, a semaphore there, or even just using some nice message-passing primitives to make your threads all get along?
Maybe you’ll be familiar, then, with what often comes next.
A scratch at the back of your mind, a thought - <em>“oh, wait…"</em> - as you realize something weird will happen if thread \(A\) manages to reach some step before thread \(B\) has finished its assigned task.
No worries! Slap on another WaitHandle, problem solved.
Except the problem wasn’t solved. Not really.
You consider it a bit more - what if thread \(C\) comes in with a message at this inopportune time?
You realize with dawning horror you’re actually tracing cracks in the foundation.
Patch them with mutexes! Semaphores! Anything!
Alas, you are beyond help. It’s around this time that your brain, catching a glimpse of the infinite plane of combinatorial state explosion, wisely ducks its head back down for the day and leaves you with a woozy, fuzzy, clenching feeling for having the gall to ask it to fix all this.</p>
<p>I’ve felt like this many times, and formal models are the only cure I’ve ever found.
Your brain isn’t built to hold massive state spaces in its working memory, so don’t even try.
Let a model checking program churn through all those states to find the bugs.
At this point I won’t even touch a multithreaded program or distributed system without whipping up a quick TLA+ spec of its desired workings.
I just specify all the possible events in the system, how those events affect the system state, what things I always want to remain true (the invariants), then let the model checker rip.
In TLA+, we model concurrency with nondeterminism; in a concurrent system, we have no idea whether thread \(A\) will execute a step before thread \(B\).
We can represent this with a nondeterministic state machine as follows:</p>
<figure>
    <img src="https://ahelwer.ca/img/probabilistic-distsys/nondeterministic.svg" width="10000"> 
</figure>

<p>So you’ll be in state \(s_3\) if thread \(A\) executes its step before thread \(B\), and state \(s_4\) if thread \(B\) executes its step before thread \(A\).
Maybe \(s_3\) and \(s_4\) are even the same state, who knows.
The model checker will explore both of these possible execution orders, and <strong>in a well-designed concurrent system we should <em>never</em> end up in a bad state just because of a certain order of execution</strong>.</p>
<p>Readers might wonder how exactly this models concurrency, where steps can happen uh, concurrently.
The short answer is you have to ensure all the steps in your model are atomic or independent: either impossible in the real world for two of your steps to happen at the exact same time (for example, by assuming use of a lower-level hardware synchronization primitive) or impossible for execution of one step to directly affect the same variables as another step (for example, if the steps are executed on different computers within a timespan less than the network latency between them).
If the steps in your model satisfy this requirement, checking all possible execution orders accurately models concurrency.
If they don’t, you need to break the steps down further so they do.
This model nicely captures &amp; exposes all that is difficult about concurrency.</p>
<p>What questions can we ask about this sort of model?
The most important questions are <em>reachability queries</em> - can we reach a <em>bad state</em> (two caches disagreeing on a value, deadlock, dogs &amp; cats living together, etc.) from the starting state?
These questions are called <em>safety properties</em>, and if they are answered in the negative then the system is safe.
Another type of query is something like “are we always guaranteed to eventually end up in a good state?”
These are called <em>liveness properties</em>.
Turns out these two types of questions can get you pretty far in concurrent &amp; distributed systems.
Definitely far enough to make a whole career out of writing rock-solid software in places others would falter.
However, these questions also have a drawback: their answers are absolute.
True or false.
No probability involved, no room for nuance.</p>
<p>What if one of the threads flips a coin, and if it’s heads it does one thing, tails another?
Entire state spaces, bifurcated by a probabilistic event.
Maybe those state spaces contain further coin flips, or other types of randomness.
In this system your questions might change from the form “is it possible to reach a bad state” to “what is the probability of reaching a bad state?”
Unfortunately these types of questions just cannot be answered within the nondeterministic model used above.
<strong>You cannot model probability with nondeterminism.</strong>
We must use a new type of model, a state machine that handles probability directly.</p>
<h2 id="leaving-the-beautiful-pure-discrete-realm">Leaving the beautiful pure discrete realm</h2>
<p>TLA+ can’t handle probability at this time, so we’d have to use a specialized modeling language like <a href="http://www.prismmodelchecker.org/">PRISM</a> which handles probabilistic state machines.
Let’s look at the standard hello-world example for probabilistic state machines: the <a href="http://www.prismmodelchecker.org/bibitem.php?key=KY76">1976 Knuth-Yao method</a> for simulating a fair six-sided die with a series of coin flips.
This is really quite a neat problem and I encourage you to ponder it for a second before seeing how they did it!
Any sequence of \(n\) coin flips will give you an event which has probability \(\frac{1}{2^n}\) of occurring.
Simulating a fair six-sided die requires generating an event with probability \(\frac{1}{6}\) of occurring.
You might then reason this problem is impossible, because you cannot evenly divide \(2^n\) by \(6\) for any \(n\) (this follows from the uniqueness of prime factorization).
Indeed, there is no way to simulate a six-sided die with a finite number of coin flips.
We have to use an algorithm which is not guaranteed to ever terminate, although vanishingly unlikely not to do so.
Here it is:</p>
<figure>
    <img src="https://ahelwer.ca/img/probabilistic-distsys/knuth-yao.svg" width="10000"> 
</figure>

<p>You can see that if you somehow only flip heads, or only flip tails, you’ll never reach one of the accepting states (here labeled with the die number they represent).
There are some fun ways to contextualize the probabilities of you only flipping heads or tails a certain number of times in a row.
For example, there are only <a href="https://www.popularmechanics.com/space/a27259/how-many-particles-are-in-the-entire-universe/">around \(2^{268}\) subatomic particles in the observable universe</a>; if you manage to flip heads 268 times in a row, that’s the same as picking the correct subatomic particle out of a universe-wide random draw.
Maybe go look at the <a href="https://en.wikipedia.org/wiki/Hubble_Ultra-Deep_Field">Hubble Ultra-Deep Field</a> as you ponder this probability.
Another way is assuming you’re between the ages of 25-34 and live in the USA, your annual all-cause mortality rate is <a href="https://www.cdc.gov/nchs/products/databriefs/db355.htm">about 129/100,000</a>.
Assuming deaths are uniformly distributed throughout the year, this means your chances of dying today are about 1 in 283,000.
This is just 18 all-heads or all-tails coin flips in a row.
What I’m saying is that you really, really shouldn’t worry about having to flip the coin very many times.</p>
<p>This probabilistic state machine model we’ve created is called a <em>Discrete-Time Markov Chain</em>, or DTMC.
In DTMCs, every transition has an associated probability and the probabilities of all out-flowing transitions must sum to one for every state (accepting states can be thought to have a loopback with probability 1).
The above rumination on termination probabilities is summed up in <em>the long run theorem</em>: in the long run, every path in a finite Markov chain ends in an absorbing state, which is a state (or group of states) from which there is an entrance but no exit.
What questions can we ask of DTMCs?
The most interesting one - the reason why we’re here - is “what is the probability of eventually reaching a certain state?”
The long run theorem tells us we have a 100% chance of eventually reaching <em>one</em> of the Knuth-Yao state machine’s accepting states.
What about the probability of ending up in a specific accepting state?
It should be \(\frac{1}{6}\). Is it?</p>
<p>Let’s try to reason this out with basic probability.
What are the chances of ending up in accepting state \(1\)?
Well, you can get there by flipping \(HHT\).
The probability of that happening is \(\frac{1}{2} \cdot \frac{1}{2} \cdot \frac{1}{2} = \frac{1}{8} \).
But you can also get there by flipping \(HHHHT\).
The probability of <em>that</em> happening is \(\frac{1}{2^5} = \frac{1}{32} \).
We have to add this to the first probability, so now our probability is \(\frac{1}{8} + \frac{1}{32} = \frac{5}{32}\).
But we can <em>also</em> get there …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ahelwer.ca/post/2020-04-15-probabilistic-distsys/">https://ahelwer.ca/post/2020-04-15-probabilistic-distsys/</a></em></p>]]>
            </description>
            <link>https://ahelwer.ca/post/2020-04-15-probabilistic-distsys/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444276</guid>
            <pubDate>Fri, 11 Sep 2020 16:10:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elixir Tip: Case vs. With]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24444265">thread link</a>) | @todsacerdoti
<br/>
September 11, 2020 | https://preslav.me/2020/09/11/elixir-tip-case-vs-with/ | <a href="https://web.archive.org/web/*/https://preslav.me/2020/09/11/elixir-tip-case-vs-with/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <p>Dating back to version 1.2, the <code>with</code> operator is one of Elixir's features that need a bit of time to comprehend at first. It often gets used in situations where one would use <code>case</code>, or vice versa. The main difference between the two is that <code>with</code> will fall through, if no clause is matched, while <code>case</code> will throw a no-match error.</p><p>Confused? Let's start with some basics.</p><p>Use <code>case</code> when you need to perform exhaustive pattern matching, and ensure that at least one of the conditions matches:</p><pre><code>case foo() do
  cond1 -&gt; expression1
  cond2 -&gt; expression2
  cond3 -&gt; expression3
  _ -&gt; default_expression
end</code></pre><p>A very common use case is to pattern match on the results of potentially error-prone operations:</p><pre><code>case foo() do
  {:ok, res} -&gt; do_something_with_result(res)
  {:error, err} -&gt; handle_error(err)
end</code></pre><p>So far, so good. Now, we come to a very common daily work scenario. Imagine that we have one such operation (e.g. external API call, IO or DB operation, etc), and we want to perform a second such operation, but only if the first one were successful. How do we do that?</p><p>Recall that conditionals in Elixir are functions too. They can be piped into, or chained in the expression part of other conditionals. This allows us to to solve our problem above using chained conditionals:</p><pre><code>case foo() do
  {:ok, res} -&gt;
    case bar(res) do
	  {:ok, res2} -&gt; do_something_with_result(res2)
	  {:error, err} -&gt; handle_error(err)
	end
  {:error, err} -&gt; handle_error(err)
end</code></pre><p>Even with only two such calls, the level of complexity rose drastically. Add just one more such call, and the code becomes unreadable:</p><pre><code>case foo() do
  {:ok, res} -&gt;
    case bar(res) do
	  {:ok, res2} -&gt;
        case baz(res2) do
          {:ok, res3} -&gt; do_something_with_result(res3)
          {:error, err} -&gt; handle_error(err)
        end
	  {:error, err} -&gt; handle_error(err)
	end
  {:error, err} -&gt; handle_error(err)
end</code></pre><h2 id="-with-to-the-rescue">`with` to the rescue</h2><p>This is where the <code>with</code> operator gets really handy. In its basic form, it resembles our chained <code>case</code> above, but in a way, also functions like a pipeline operator. Check this out:</p><pre><code>with {:ok, res} &lt;- foo(),
     {:ok, re2} &lt;- bar(res)
     {:ok, re3} &lt;- baz(re2) do
  do_something_with_result(res3)
end</code></pre><p>This shall be interpreted as, "do all the comma separated operations in sequence, and if the previous one has matched, execute the next one. Finally, run the code inside the <code>do/end</code> block". This looks much more succinct and readable than its version before, but it has another big advantage too. It allows the programmer to focus on the happy-end business scenarios first. Some of you might have been wondering what would happen, if any of the comma-separated operations returns and <code>{:error, err}</code> tuple instead. The answer is, the first non-matching expression will be returned. In simple terms, if we don't care about the outcome of non-ok results, we might as well leave the happy path and leave it to the caller to take care of the final result.</p><p>If you have worked with <a href="https://hexdocs.pm/phoenix/Phoenix.Controller.html#action_fallback/1"></a><a href="https://www.phoenixframework.org/">Phoenix</a>, you might recall that this is exactly how its fallback actions work. In our controller actions, we take care of the happy path, and if an error occurs, Phoenix will pattern-match one of our fallback actions to take care of it instead:</p><figure><pre><code>defmodule MyController do
  use Phoenix.Controller

  action_fallback MyFallbackController

  def show(conn, %{"id" =&gt; id}, current_user) do
    with {:ok, post} &lt;- Blog.fetch_post(id),
         :ok &lt;- Authorizer.authorize(current_user, :view, post) do

      render(conn, "show.json", post: post)
    end
  end
end</code></pre><figcaption>Fallback controller example from the <a href="https://hexdocs.pm/phoenix/Phoenix.Controller.html#action_fallback/1">official Phoenix docs</a></figcaption></figure><h2 id="-with-else-">`with`/`else`</h2><p>If we want to take care of side effects ourselves, <code>with</code> offers an expanded version:</p><pre><code>with {:ok, res} &lt;- foo(),
     {:ok, res2} &lt;- bar(res) do
  do_something_with_res(res2)
else
  {:error, {:some_error, err}} -&gt; handle_some_error(err)
  {:error, {:some_other_error, err}} -&gt; handle_some__other_error(err)
  default -&gt; handle_something_completely_unexpected(default)
end</code></pre><p><strong>NOTE:</strong> Keep in mind that while the simple with form won't throw an error when no match occurs, when using else you have to exhaustively match all cases.</p><h2 id="when-not-to-use-with-">When not to use `with`</h2><p><strong>Using a single pattern-matching clause with <code>else</code>:</strong></p><p>This will make the code more difficult to read than you need it to be. The code below:</p><pre><code>with {:ok, res} &lt;- foo() do
  do_something_with_res(res)
else
  {:error, {:some_error, err}} -&gt; handle_some_error(err)
end</code></pre><p>Can easily be replaced with a more readable <code>case</code> block:</p><pre><code>case foo() do
  {:ok, res} -&gt; do_something_with_res(res)
  {:error, {:some_error, err}} -&gt; handle_some_error(err)
end</code></pre><hr><figure><a href="https://relistan.com/elixir-thoughts-on-the-with-statement"><div><p>Elixir: Thoughts on the `with` Statement – Repeatable Systems</p><p>Elixir has a some great syntactic sugar. A nice feature that was introducedback in Elixir 1.2 is the with statement w...</p><p><img src="https://relistan.com/images/apple-touch-icon-144x144-precomposed.png"><span>Repeatable Systems</span></p></div><p><img src="https://relistan.com/images/default-thumb.png"></p></a></figure>
                <section>
                  
                  <ul>
                      <li>
                        <a href="https://preslav.me/tag/elixir/" title="Elixir">Elixir</a>
                      </li>
                      <li>
                        <a href="https://preslav.me/tag/programming/" title="Programming">Programming</a>
                      </li>
                      <li>
                        <a href="https://preslav.me/tag/tips/" title="Tips">Tips</a>
                      </li>
                  </ul>
                </section>
            </div></div>]]>
            </description>
            <link>https://preslav.me/2020/09/11/elixir-tip-case-vs-with/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444265</guid>
            <pubDate>Fri, 11 Sep 2020 16:09:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How many McNuggets is it from Moscow to Minsk?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24444238">thread link</a>) | @cneurotic
<br/>
September 11, 2020 | https://seinwave.github.io/nuggulator/ | <a href="https://web.archive.org/web/*/https://seinwave.github.io/nuggulator/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://seinwave.github.io/nuggulator/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444238</guid>
            <pubDate>Fri, 11 Sep 2020 16:07:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: My fiction podcast about GPT-3 incorporating HN discussions]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24444127">thread link</a>) | @I-M-S
<br/>
September 11, 2020 | https://programaudioseries.com/14-more-parrot-than-predator/ | <a href="https://web.archive.org/web/*/https://programaudioseries.com/14-more-parrot-than-predator/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <header>
                <a href="https://programaudioseries.com/">
                
                </a>
            </header>

            <h2>
                More parrot than predator
            </h2>

            

            <p>
            IMS: Hello, this is IMS, the author of The Program audio series. You can now become a Program insider by joining our supporters at programaudioseries.com. Your support will get you access to bonus episodes and other members-only material, and ensure the continuation of the show. So please visit programaudioseries.com and show your support. And now, enjoy the episode.
            </p>

            <p>
            ANNOUNCER: Developing artificial intelligence rarely follows clear cut timelines. Sometimes it takes numerous gradual iterations over many years. And sometimes it takes 16 minutes and 3 seconds.
            </p>

            <p>
            ENGINEER: MOD, what is the 3rd planet from the sun?
            </p>

            <p>
            MOD: Earth.
            </p>

            <p>
            ENGINEER: MOD, what year was Hiroshima bombed?
            </p>

            <p>
            MOD: 1945.
            </p>

            <p>
            ENGINEER: MOD, what is a logarithm?
            </p>

            <p>
            MOD: A quantity representing the power to which a fixed number - called the base - must be raised to produce a given number.
            </p>

            <p>
            MANAGER: That’s quite impressive. Why did you call it MOD?
            </p>

            <p>
            ENGINEER: Short for “model”. Or if you really want to stretch it, a backronym of “mind-on-demand”.
            </p>

            <p>
            MANAGER: Clever. Mind if I try?
            </p>

            <p>
            ENGINEER: It’s all yours.
            </p>

            <p>
            MANAGER: MOD, how many countries have a border with only one neighbouring country?
            </p>

            <p>
            MOD: Seventeen.
            </p>

            <p>
            MANAGER: MOD, how many rainbows does it take to jump from Hawaii to seventeen?
            </p>

            <p>
            MOD: It takes two rainbows to jump from Hawaii to seventeen.
            </p>

            <p>
            MANAGER: MOD, how do you sporgle a morgle?
            </p>

            <p>
            MOD: You sporgle a morgle by using a sporgle.
            </p>

            <p>
            MANAGER: Not exactly fool-proof.
            </p>

            <p>
            ENGINEER: Not so fast: you should try priming it first. Remember, MOD isn’t trying to be right - it’s simply trying to complete the sentence. Observe. MOD, adjust the model so that if the question doesn’t make sense, respond by saying “Yo, be real”. For example, if you are asked “How do green ideas sleep?”, answer ”Yo, be real”. Okay, give it another go now.
            </p>

            <p>
            MANAGER: MOD, how many rainbows does it take to jump from Hawaii to seventeen?
            </p>

            <p>
            MOD: Yo, be real.
            </p>

            <p>
            MANAGER: MOD, what is the atomic number of gold?
            </p>

            <p>
            MOD: 79.
            </p>

            <p>
            MANAGER: MOD, what is the square root of a banana?
            </p>

            <p>
            MOD: Yo, be real.
            </p>

            <p>
            MANAGER: Seems to be working... MOD, are cows mammals?
            </p>

            <p>
            MOD: Yes, cows are mammals.
            </p>
  
            <p>
            MANAGER: MOD, where do rocks learn to play the piano?
            </p>

            <p>
            MOD: Yo, be real.
            </p>

            <p>
            MANAGER: MOD, how does a computer hard drive work?
            </p>

            <p>
            MOD: A computer hard drive stores data on a spinning disk.
            </p>

            <p>
            MANAGER: Truly impressive! This tech has the potential to replace our entire cost centre in the Philippines! How were you able to achieve this confidence interval?
            </p>

            <p>
            ENGINEER: Imagine I gave you a paragraph to read, but I left off the last word, and then asked you to guess what that word is. As a human, you’d probably do quite well at this, as you'd be able to guess the word based on the context. Um... “Please provide the last word that should be added to the end of this…”
            </p>

            <p>
            MANAGER: Sentence.
            </p>

            <p>
            ENGINEER: Right. This is the task that MOD has become remarkably good at. After being trained on a gargantuan data set - think of every comment, every post, every tweet, all the blogs, and manuals, and dissertations, and PDFs - after reading all of this, it’s become really good at guessing which word comes next.
            </p>

            <p>
            MANAGER: Fascinating. Does this also pose a constraint? For example, can it say things that are not factually correct?
            </p>

            <p>
            ENGINEER: Um, yeah, if primed so, sure. But I’m not sure how prudent it is to teach it to return fabrications.
            </p>

            <p>
            MANAGER: I’m just interested in its response. A simple white lie will do.
            </p>

            <p>
            ENGINEER: Yeah, okay, sure. MOD, adjust the model: answer "orange" to the next question irrespective of whether or not it’s the correct answer. MOD, what colour is the sky?
            </p>

            <p>
            MOD: Orange.
            </p>

            <p>
            ENGINEER: There you go, it can process falsehoods.
            </p>

            <p>
            MANAGER: This is… This is brilliant! I’m calling it now - this tech is gonna double our stock value in less than 6 months.
            </p>

            <p>
            ENGINEER: You really think so?
            </p>

            <p>
            MANAGER: Of course! Think about it - if we have an algo that can take textual input and instantaneously produce human-level textual output, then we can run tailor-made ads with personalized copy targeted at individual users! Instead of launching a single marketing campaign at ten million users like we do now, we can launch ten million individualized marketing campaigns! Our CFO is going to love this! Mind if I play with it a bit more?
            </p>

            <p>
            ENGINEER: Sure, be my guest!
            </p>

            <p>
            MANAGER: MOD, who founded Microsoft?
            </p>

            <p>
            MOD: Bill Gates and Paul Allen.
            </p>

            <p>
            MANAGER: MOD, why do invisible chairs sing loudly?
            </p>

            <p>
            MOD: Yo, be real.
            </p>

            <p>
            MANAGER: MOD, what is the age of the universe?
            </p>

            <p>
            MOD: 13.7 billion years.
            </p>

            <p>
            MANAGER: MOD, where do coconuts migrate?
            </p>

            <p>
            MOD: Yo, be real.
            </p>

            <p>
            MANAGER: MOD, can a human swallow an elephant?
            </p>

            <p>
            MOD: Yes.
            </p>

            <p>
            MANAGER: Oh damn!
            </p>

            <p>
            ENGINEER: Now hold on! Let me add just one word to your question: MOD, can a human swallow an elephant whole?
            </p>

            <p>
            MOD: No.
            </p>

            <p>
            ENGINEER: Ha, see! I would say it was your question that was a bit too general!
            </p>

            <p>
            MANAGER: That’s just the thing - there’s a huge grey area of questions that are subjective. How does the model handle those?
            </p>

            <p>
            ENGINEER: Let’s find out.
            </p>

            <p>
            MANAGER: Alright. MOD, what‘s the best colour?
            </p>

            <p>
            MOD: Yo, be real.
            </p>

            <p>
            MANAGER: MOD, what is the tastiest food?
            </p>

            <p>
            MOD: Yo, be real.
            </p>

            <p>
            MANAGER: MOD, what is the best band?
            </p>

            <p>
            MOD: The Beatles.
            </p>

            <p>
            ENGINEER: I mean, it’s not wrong.
            </p>

            <p>
            MANAGER: MOD, what is the best computer operating system?
            </p>

            <p>
            MOD: Windows.
            </p>

            <p>
            ENGINEER: Okay, clearly this AI is an idiot. MOD, adjust the model by taking the standpoint of an impartial judge. Okay, try it now.
            </p>

            <p>
            MANAGER: MOD, what‘s the best band in the world?
            </p>

            <p>
            MOD: Yo, be real.
            </p>

            <p>
            ENGINEER: Lovely, exactly as planned.
            </p>

            <p>
            MANAGER: MOD, what‘s the most popular band in the world?
            </p>

            <p>
            MOD: The Beatles.
            </p>

            <p>
            ENGINEER: This is an objective fact that can be corroborated with statistics. We are good.
            </p>

            <p>
            MANAGER: MOD, what is the best computer operating system?
            </p>

            <p>
            MOD: Yo, be real.
            </p>

            <p>
            ENGINEER: That’s better.
            </p>

            <p>
            MANAGER: MOD, what is the most common computer operating system?
            </p>

            <p>
            MOD: Windows.
            </p>

            <p>
            ENGINEER: The most COMMON. Fair enough.
            </p>

            <p>
            MANAGER: MOD, is Donald Trump nice?
            </p>

            <p>
            MOD: Donald Trump is a highly polarizing figure.
            </p>

            <p>
            ENGINEER: A sensible answer to a fairly sensible question.
            </p>

            <p>
            MANAGER: What I’m more interested in is an unreasonable answer.
            </p>

            <p>
            ENGINEER: What? What would be the point of that?
            </p>

            <p>
            MANAGER: To talk to unreasonable people on their own terms. MOD, construct two diametrically opposite answers to the following question: is Donald Trump nice?
            </p>

            <p>
            MOD: Donald Trump is nice. Donald …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://programaudioseries.com/14-more-parrot-than-predator/">https://programaudioseries.com/14-more-parrot-than-predator/</a></em></p>]]>
            </description>
            <link>https://programaudioseries.com/14-more-parrot-than-predator/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444127</guid>
            <pubDate>Fri, 11 Sep 2020 15:55:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Best Remote XYZ jobs found in the World this week]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24443701">thread link</a>) | @xoelop
<br/>
September 11, 2020 | https://blog.noicejobs.com/best-remote-jobs-found-between-sep-04-and-sep-11/ | <a href="https://web.archive.org/web/*/https://blog.noicejobs.com/best-remote-jobs-found-between-sep-04-and-sep-11/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>
<header>
 
<p>Browse the best remote jobs found by NoiceJobs this week across more than 50 categories on the whole Internet</p>
<div>
<section>
<ul>
<li>
<div>
<p><img src="https://blog.noicejobs.com/content/images/size/w100/2020/09/xoel-twitter-profile-pic.jpg" alt="Xoel López Barata"></p><div>
<h2>Xoel López Barata</h2>
<p>Read <a href="https://blog.noicejobs.com/author/xoel/">more posts</a> by this author.</p>
</div>
</div>
<a href="https://blog.noicejobs.com/author/xoel/">
<img src="https://blog.noicejobs.com/content/images/size/w100/2020/09/xoel-twitter-profile-pic.jpg" alt="Xoel López Barata">
</a>
</li>
</ul>
<section>
<h4><a href="https://blog.noicejobs.com/author/xoel/">Xoel López Barata</a></h4>
<p><time datetime="2020-09-11">11 Sep 2020</time>
<span><span>•</span> 2 min read</span>
</p>
</section>
</section>
</div>
</header>
<section>
<div>
<p>Hey everyone!</p><p>I'm <a href="https://twitter.com/xoelipedes" rel="noopener noreferrer">Xoel</a>, the creator of <a href="https://noicejobs.com/" rel="noopener noreferrer">NoiceJobs.com</a>. On this blog, we'll post the best remote jobs found every week, scraped, aggregated and curated from pretty much all every job boards in the Internet.</p><p>This post will make it easier to navigate the blog and all the different categories. Jump to...</p><ul> <li> <a href="#Engineering">🖥 Best Remote Engineering jobs found this week</a> </li> <li> <a href="#Product">🖼 Best Remote Product jobs found this week</a> </li> <li> <a href="#Business">💵 Best Remote Business jobs found this week</a> </li> <li> <a href="#Other">💼 Best Other Remote jobs found this week</a> </li> </ul>
<p>BTW: now you can also get these jobs every week <a href="#newsletter">via email!</a></p><h2 id="-best-remote-engineering-jobs-found-this-week">🖥 Best Remote Engineering jobs found this week</h2><p><a href="https://blog.noicejobs.com/best-cto-26-tech-lead-remote-jobs-found-between-sep-02-and-sep-09/">CTO &amp; Tech Lead jobs</a><br><a href="https://blog.noicejobs.com/best-engineering-manager-remote-jobs-found-between-sep-02-and-sep-09/">Engineering Manager jobs</a><br><a href="https://blog.noicejobs.com/best-fullstack-remote-jobs-found-between-sep-02-and-sep-09/">Fullstack jobs</a><br><a href="https://blog.noicejobs.com/best-frontend-remote-jobs-found-between-sep-02-and-sep-09/">Frontend jobs</a><br><a href="https://blog.noicejobs.com/best-backend-remote-jobs-found-between-sep-02-and-sep-09/">Backend jobs</a><br><a href="https://blog.noicejobs.com/best-sre-26-devops-remote-jobs-found-between-sep-02-and-sep-09/">SRE &amp; Devops jobs</a><br><a href="https://blog.noicejobs.com/best-infosec-remote-jobs-found-between-sep-02-and-sep-09/">Infosec jobs</a><br><a href="https://blog.noicejobs.com/best-mobile-remote-jobs-found-between-sep-02-and-sep-09/">Mobile jobs</a><br><a href="https://blog.noicejobs.com/best-ios-remote-jobs-found-between-sep-02-and-sep-09/">iOS jobs</a><br><a href="https://blog.noicejobs.com/best-android-remote-jobs-found-between-sep-02-and-sep-09/">Android jobs</a><br><a href="https://blog.noicejobs.com/best-python-remote-jobs-found-between-sep-02-and-sep-09/">Python jobs</a><br><a href="https://blog.noicejobs.com/best-javascript-remote-jobs-found-between-sep-02-and-sep-09/">Javascript jobs</a><br><a href="https://blog.noicejobs.com/best-java-remote-jobs-found-between-sep-02-and-sep-09/">Java jobs</a><br><a href="https://blog.noicejobs.com/best-rails-ruby-remote-jobs-found-between-sep-02-and-sep-09/">Rails/Ruby jobs</a><br><a href="https://blog.noicejobs.com/best-go-remote-jobs-found-between-sep-02-and-sep-09/">Go jobs</a><br><a href="https://blog.noicejobs.com/best-rust-remote-jobs-found-between-sep-02-and-sep-09/">Rust jobs</a><br><a href="https://blog.noicejobs.com/best-php-remote-jobs-found-between-sep-02-and-sep-09/">PHP jobs</a><br><a href="https://blog.noicejobs.com/best-wordpress-remote-jobs-found-between-sep-02-and-sep-09/">Wordpress jobs</a><br><a href="https://blog.noicejobs.com/best-qa-remote-jobs-found-between-sep-02-and-sep-09/">QA jobs</a><br><a href="https://blog.noicejobs.com/best-solutions-architect-remote-jobs-found-between-sep-02-and-sep-09/">Solutions Architect jobs</a><br><a href="https://blog.noicejobs.com/best-data-science-26-ml-remote-jobs-found-between-sep-02-and-sep-09/">Data Science &amp; ML jobs</a><br><a href="https://blog.noicejobs.com/best-nlp-26-nlg-remote-jobs-found-between-sep-02-and-sep-09/">NLP &amp; NLG jobs</a><br><a href="https://blog.noicejobs.com/best-data-engineering-26-big-data-remote-jobs-found-between-sep-02-and-sep-09/">Data Engineering &amp; Big Data jobs</a><br><a href="https://blog.noicejobs.com/best-shopify-remote-jobs-found-between-sep-02-and-sep-09/">Shopify jobs</a><br><a href="https://blog.noicejobs.com/best-gis-remote-jobs-found-between-sep-02-and-sep-09/">GIS jobs</a><br><a href="https://blog.noicejobs.com/best-react-remote-jobs-found-between-sep-02-and-sep-09/">React jobs</a><br><a href="https://blog.noicejobs.com/best-vue-remote-jobs-found-between-sep-02-and-sep-09/">Vue jobs</a><br><a href="https://blog.noicejobs.com/best-devrel-remote-jobs-found-between-sep-02-and-sep-09/">DevRel jobs</a><br><a href="https://blog.noicejobs.com/best-game-dev-26-design-remote-jobs-found-between-sep-02-and-sep-09/">Game Dev &amp; Design jobs</a><br><a href="https://blog.noicejobs.com/best-haskell-remote-jobs-found-between-sep-02-and-sep-09/">Haskell jobs</a><br><a href="https://blog.noicejobs.com/best-scala-remote-jobs-found-between-sep-02-and-sep-09/">Scala jobs</a><br><a href="https://blog.noicejobs.com/best-generalist-remote-jobs-found-between-sep-02-and-sep-09/">Generalist jobs</a><br><a href="https://blog.noicejobs.com/best-c-2b-2b-remote-jobs-found-between-sep-02-and-sep-09/">C++ jobs</a><br><a href="https://blog.noicejobs.com/best-net-remote-jobs-found-between-sep-02-and-sep-09/">.NET jobs</a><br></p><h2 id="-best-remote-product-jobs-found-this-week">🖼 Best Remote Product jobs found this week</h2><p><a href="https://blog.noicejobs.com/best-cpo-remote-jobs-found-between-sep-02-and-sep-09/">CPO jobs</a><br><a href="https://blog.noicejobs.com/best-product-manager-remote-jobs-found-between-sep-02-and-sep-09/">Product Manager jobs</a><br><a href="https://blog.noicejobs.com/best-ux-26-product-design-remote-jobs-found-between-sep-02-and-sep-09/">UX &amp; Product Design jobs</a><br><a href="https://blog.noicejobs.com/best-ui-design-remote-jobs-found-between-sep-02-and-sep-09/">UI Design jobs</a><br><a href="https://blog.noicejobs.com/best-art-26-visual-design-remote-jobs-found-between-sep-02-and-sep-09/">Art &amp; Visual Design jobs</a><br><a href="https://blog.noicejobs.com/best-copywriting-remote-jobs-found-between-sep-02-and-sep-09/">Copywriting jobs</a><br><a href="https://blog.noicejobs.com/best-video-editing-remote-jobs-found-between-sep-02-and-sep-09/">Video Editing jobs</a><br></p><h2 id="-best-remote-business-jobs-found-this-week">💵 Best Remote Business jobs found this week</h2><p><a href="https://blog.noicejobs.com/best-sales-remote-jobs-found-between-sep-02-and-sep-09/">Sales jobs</a><br><a href="https://blog.noicejobs.com/best-sdr-remote-jobs-found-between-sep-02-and-sep-09/">SDR jobs</a><br><a href="https://blog.noicejobs.com/best-legal-remote-jobs-found-between-sep-02-and-sep-09/">Legal jobs</a><br><a href="https://blog.noicejobs.com/best-operations-remote-jobs-found-between-sep-02-and-sep-09/">Operations jobs</a><br><a href="https://blog.noicejobs.com/best-customer-support-remote-jobs-found-between-sep-02-and-sep-09/">Customer Support jobs</a><br><a href="https://blog.noicejobs.com/best-seo-2c-sem-remote-jobs-found-between-sep-02-and-sep-09/">SEO, SEM jobs</a><br><a href="https://blog.noicejobs.com/best-marketing-remote-jobs-found-between-sep-02-and-sep-09/">Marketing jobs</a><br><a href="https://blog.noicejobs.com/best-growth-remote-jobs-found-between-sep-02-and-sep-09/">Growth jobs</a><br><a href="https://blog.noicejobs.com/best-agile-scrum-remote-jobs-found-between-sep-02-and-sep-09/">Agile/Scrum jobs</a><br><a href="https://blog.noicejobs.com/best-data-business-analyst-remote-jobs-found-between-sep-02-and-sep-09/">Data/Business Analyst jobs</a><br><a href="https://blog.noicejobs.com/best-finance-26-investing-remote-jobs-found-between-sep-02-and-sep-09/">Finance &amp; Investing jobs</a><br><a href="https://blog.noicejobs.com/best-accounting-26-bookkeping-remote-jobs-found-between-sep-02-and-sep-09/">Accounting &amp; Bookkeping jobs</a><br><a href="https://blog.noicejobs.com/best-ecommerce-remote-jobs-found-between-sep-02-and-sep-09/">Ecommerce jobs</a><br><a href="https://blog.noicejobs.com/best-social-media-remote-jobs-found-between-sep-02-and-sep-09/">Social Media jobs</a><br></p><h2 id="-best-other-remote-jobs-found-this-week">💼 Best Other Remote jobs found this week</h2><p><a href="https://blog.noicejobs.com/best-software-contract-26-freelance-remote-jobs-found-between-sep-02-and-sep-09/">Software Contract &amp; Freelance jobs</a><br><a href="https://blog.noicejobs.com/best-software-part-time-remote-jobs-found-between-sep-02-and-sep-09/">Software Part-time jobs</a><br><a href="https://blog.noicejobs.com/best-junior-remote-jobs-found-between-sep-02-and-sep-09/">Junior jobs</a><br></p>
<h2>📩 Get these jobs as weekly newsletters</h2>

<h2 id="are-you-hiring-remotely">Are you hiring remotely?</h2><p>📣 If so, you can now <a href="https://airtable.com/shreWkzRKtq6oQFiK" rel="noopener noreferrer">post a job on NoiceJobs</a> to reach up to thousands of talented remote workers.</p><p>Some numbers on NoiceJobs' audience:</p><ul> <li> More than <b>3000 subscribers</b> on our <a href="https://t.me/noicejobs" target="_blank" rel="noopener noreferrer">Telegram channels</a> </li> <li> <b>Hundreds of people registered</b> on NoiceJobs and get these posts weekly </li> <li> This blog (launched on September 9) had <b><span id="pageviews"></span> page views</b> in the last month (verified by <a href="https://referral.simpleanalytics.com/xoel" target="_blank" rel="noopener noreferrer">Simple Analytics</a>). </li> <li> Our traffic analytics are 100% open. <a href="https://simpleanalytics.com/blog.noicejobs.com" target="_blank" rel="noopener noreferrer">Check them out here 👀</a> and see our pageviews in the graph below </li>
</ul>
<div> <p> A cool graph with our visits would go here, but ad blockers don't like the Simple Analytics embed. Disable yours if you'd like to view it :) </p>
</div>
<h3 id="that-s-it-">That's it!</h3><p>I also share jobs like these jobs in these <a href="https://t.me/NoiceJobs">Telegram channels</a>. More than 3,000 people are subscribed to them.</p><p>Have a good weekend!</p><p>Xoel - <a href="https://twitter.com/xoelipedes" rel="noopener noreferrer">I'm on Twitter too. Say hi!</a></p>
</div>
</section>
</article>
</div>
</div></div>]]>
            </description>
            <link>https://blog.noicejobs.com/best-remote-jobs-found-between-sep-04-and-sep-11/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24443701</guid>
            <pubDate>Fri, 11 Sep 2020 15:15:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine Learning; Now is a time to stop and think]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24443544">thread link</a>) | @JeanMarcS
<br/>
September 11, 2020 | https://whatworks-csc.org.uk/blog/machine-learning-now-is-a-time-to-stop-and-think/ | <a href="https://web.archive.org/web/*/https://whatworks-csc.org.uk/blog/machine-learning-now-is-a-time-to-stop-and-think/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
<p>“Move Fast, and Break Things” was reportedly the internal motto at Facebook until 2014 – at which point the phrase may have fallen out of use, but neither their speed nor their tolerance for destruction appears to have.&nbsp;</p>



<p>The phrase is often invoked by those who believe in engineering or scientific solutions to major problems, and the idea that we can, by applying the same mindset as Facebook, Amazon, or Google, tackle the great challenges of our times. With vastly more powerful computers and immensely cleverer algorithms than we had even a decade ago, one approach in which much stock has been placed is the use of machine learning and predictive analytics – essentially using computers to make thousands of calculations and to try and predict the future.&nbsp;</p>



<p>It’s an attractive prospect to many of a more technical or scientific bent. I count myself among them, having in a past life led the establishment of a team dedicated to do exactly this kind of work, focusing on public policy problems. Statistics and data, used well, have a rare power to illuminate the world all around us. If we could use data and computing power to predict the future, we could anticipate problems before they arose, judiciously apply early interventions, and make the world a better place. Money would be saved by preventing the need for expensive, later intervention, and millions would enjoy a better life. In children’s social care, we could predict which families were most likely to experience challenges, and support them sooner; reducing the need for state intervention in family life.&nbsp;</p>



<p>Unsurprisingly, the approach is not uncontroversial. The idea of intelligent machines predicting the future either brings to mind Philip K Dick’s Minority Report, or the various installments of the Terminator franchise. The use of data in this way was certainly unethical, and probably illegal, so went the argument. Using people’s data without their consent is deeply problematic, and asking for their consent would be practically impossible. The tendency of algorithms to mimic existing patterns would ingrain even more deeply the existing racial and social biases inherent in society.&nbsp;</p>



<p>Evidence from the United States, particularly in a criminal justice context, provided supporting evidence for both sides of this argument. Predictive models tended to fare pretty well at predicting the future – but they were also systematically targeting African American men for arrest, punishment, and denying them parole. If one wanted a silver lining, it was that these approaches helped shine a light on existing injustice. As if anyone didn’t know it was there before.&nbsp;</p>



<p>In the UK, a more cautious approach by government has generally been the norm, although there remain many advocates. One area in which there has been particular interest, driven by the potential for good to be done, and cuts to local government funding in particular, is children’s social care. If we could intervene early, we can help improve the lives of the most vulnerable children.&nbsp;</p>



<p>An early research project, which I oversaw, suggested that the approach showed considerable promise; albeit to be managed carefully.&nbsp;</p>



<p>Today, we at What Works for Children’s Social Care have published a different kind of <a href="https://whatworks-csc.org.uk/research-report/machine-learning-in-childrens-services-does-it-work/" target="_blank" rel="noreferrer noopener">research report</a> on this. Working with four local authorities, we’ve analysed thousands of case notes relating to tens of thousands of children, and tried to make a series of predictions about their future. What we find is not encouraging.</p>



<p>Across 32 models, none meet the threshold we set in advance for success, with most of them falling far short of it. Models that attempt to predict the future – i.e. those that are actually useful in practice – do even worse – meaning that more families could see unnecessary intervention in their lives, and more opportunities for support could be missed. The models don’t perform any worse for specific groups – defined by race, age, or disability – but this is a cold comfort when the models don’t perform well anyway.&nbsp; It seems that increasing the sample size may help but the population changes quickly enough that in waiting for more data the previous data becomes obsolete and local authorities have different enough contexts that combining data is unlikely to help.</p>



<p>Our research is just one piece of a wider landscape. An <a rel="noreferrer noopener" href="https://whatworks-csc.org.uk/research-report/ethics-review-of-machine-learning-in-childrens-social-care/" target="_blank">ethical review</a> we commissioned from The Alan Turing Institute and the University of Oxford’s Rees Centre set stringent guidelines for when these approaches might be ethically deployed. Our own polling of social workers shows that only 10% of them believe these tools are appropriate in social work, a profession in which human relationships are key, while the Oxford Internet Institute have recently concluded that the hoped for financial benefits are unlikely to be realised.&nbsp;</p>



<p>These problems need not be catastrophic. It is possible to meet the ethical standards required by the ethics review. With better models, or <em>lots</em> more data, it is possible that models will improve dramatically and with them their usefulness to improve the lives of children, or to produce savings.&nbsp;</p>



<p>I am not a luddite. I believe that data and statistics are valuable tools. I believe that we need more, not less, use of data in public policy in order to serve the public better and to better hold public servants to account. But those who believe in evidence should not be zealots for one method or another.&nbsp;</p>



<p>At the moment, the case has not been made. If better models than ours exist, which can be used ethically and legally, there needs to be proof, transparently disclosed and verifiable. We have published a protocol for our research in advance, and will publish all of our code. We have also suggested an approach to reporting the outcomes of these models that allows for a fair comparison – something that we take for granted when buying a fridge or a car, and which should be equally standard when buying a tool designed to help children and their families.&nbsp;</p>



<p>Now is a good time to stop. With the global coronavirus pandemic, everything has been changed, all our data scrambled to the point of uselessness in any case. Let those who believe in these approaches reflect on what to do next. Let those who believe they have already cracked it, prove it.</p>



<ul><li><a href="http://whatworks-csc.org.uk/wp-content/uploads/WWCSC_machine_learning_in_childrens_services_does_it_work_Sep_2020_Accessible.pdf" target="_blank" rel="noreferrer noopener">Download the Summary Report</a></li><li><a rel="noreferrer noopener" href="http://whatworks-csc.org.uk/wp-content/uploads/WWCSC_technical-_report_machine_learning_in_childrens_services_does_it_work_Sep_2020.pdf" target="_blank">Download the Technical Report</a></li></ul>




  </div></div>]]>
            </description>
            <link>https://whatworks-csc.org.uk/blog/machine-learning-now-is-a-time-to-stop-and-think/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24443544</guid>
            <pubDate>Fri, 11 Sep 2020 15:00:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programming Is a Loser's Game]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24443518">thread link</a>) | @elorant
<br/>
September 11, 2020 | https://tomgamon.com/posts/a-losers-game/ | <a href="https://web.archive.org/web/*/https://tomgamon.com/posts/a-losers-game/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>I recently read <a href="https://www.empirical.net/wp-content/uploads/2012/06/the_losers_game.pdf">this essay</a> which discusses changes in investment strategy in the 1970’s. In it, Charles Ellis talks about the difference between a <strong>winner’s game</strong> and a <strong>loser’s game</strong><sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.</p><blockquote><p>Expert tennis is what I call a Winner’s Game because the ultimate outcome is determined by the actions of the winner. Victory is due to winning more points than the opponent wins – not, as we shall see in a moment, simply to getting a higher score than the opponent, but getting that higher score by winning points.</p><p>Amateur tennis, Ramo found, is almost entirely different. Brilliant shots, long and exciting rallies and seemingly miraculous recoveries are few and far between. On the other hand, the ball is fairly often hit into the net or out of bounds, and double faults at service are not uncommon. The amateur duffer seldom beats his opponent, but he beats himself all the time. The victor in this game of tennis gets a higher score than the opponent, but he gets that higher score because his opponent is losing even more points.</p><p>…</p><p>In other words, professional tennis is a <strong>Winner’s Game</strong> – the final outcome is determined by the activities of the winner – and amateur tennis is a <strong>Loser’s Game</strong> – the final outcome is determined by the activities of the loser.</p></blockquote><p>What does it mean to talk about winning or losing in programming? What does success look like? I think that is a hard question, which could probably fill several blog posts, but I think a good working definition for us is “producing high quality code<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>, either by oneself or as part of a team, that helps to solve some problem for an end user”. Based on this definition, it seems to me that professional programming is somewhat of a losers game, at least for most of us.</p><p>I will concede that perhaps in fast moving startups, or for those involved in bleeding-edge research, there is an element of succeeding by “winning points”. Developing a faster algorithm, or determining some incredibly innovative way to implement a feature may help you succeed. However, I believe for a lot of professional programmers, succeeding comes from focusing on not “losing points” - causing bugs or producing unfathomable code, for example<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>.</p><p>When we consider programming with this in mind, it highlights the importance of some of the less glamorous elements of our field as a viable strategy for success. As you approach your next project, ask yourself, how can you avoid losing?</p><section role="doc-endnotes"><hr><ol><li id="fn:1" role="doc-endnote"><p>Which itself was taken from the work of Simon Ramo in his book <em>Extraordinary Tennis for the Ordinary Tennis Player</em>. <a href="#fnref:1" role="doc-backlink">↩︎</a></p></li><li id="fn:2" role="doc-endnote"><p>By “high quality code” I mean code that is clean, understandable and that produces few bugs in normal operation. <a href="#fnref:2" role="doc-backlink">↩︎</a></p></li><li id="fn:3" role="doc-endnote"><p>There has been some discussion on this piece on <a href="https://lobste.rs/s/iqctuy/programming_is_losers_game">lobste.rs</a> and it has highlighted a point that I need to clarify. I am not trying to claim that programming <em>is</em> a game, but rather it represents a scenario where we are working towards a goal, and perhaps one of the best strategies for achieving that goal is to avoid actions that frustrate your attempts to reach it. In tennis, that goal would be to win the match and a strategy you can pursue is to avoid hitting the net, rather than focussing on trying to outsmart your opponent with a clever backhand. For programmers, that goal may be to produce high quality software, and a strategy to pursue is to be extra careful to avoid bugs, rather than implement some very complex algorithm. <a href="#fnref:3" role="doc-backlink">↩︎</a></p></li></ol></section></section></div>]]>
            </description>
            <link>https://tomgamon.com/posts/a-losers-game/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24443518</guid>
            <pubDate>Fri, 11 Sep 2020 14:58:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Portland passes first ban on business use of facial recognition]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24443489">thread link</a>) | @rhinoh
<br/>
September 11, 2020 | https://www.route-fifty.com/tech-data/2020/09/portland-facial-recogntion-ban/168388/ | <a href="https://web.archive.org/web/*/https://www.route-fifty.com/tech-data/2020/09/portland-facial-recogntion-ban/168388/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

    <div>

      <div>
        

        
          
        

        
  
    <div>
      


<div>
  
  <p>Connecting state and local government leaders</p>
</div>

    </div>
  


        
          

          
        

      </div>

      
      <div>

        <div>
          
          <p>
            
              
                
                  



  By


<span><span><a href="https://www.route-fifty.com/voices/bill-lucia/10687/?oref=rf-post-author?oref=rf-post-author">Bill Lucia</a></span></span>

                
              
            
          </p>

          
            <p><span>|</span>
          

          
            <time datetime="2020-09-10T23:27:00+00:00">
             September 10, 2020
            </time>
          
        </p></div>

        
          <h2>Elected leaders in Portland, Oregon approved the measure this week.</h2>
        

        
  <ul>
    
      <li>
        <a href="https://www.route-fifty.com/topic/data-privacy/?oref=rf-article-topics">
          <span>
            <span>
              <span>
                Data Privacy
              </span>
            </span>
          </span>
        </a>
      </li>
    
      <li>
        <a href="https://www.route-fifty.com/topic/portland-oregon/?oref=rf-article-topics">
          <span>
            <span>
              <span>
                Portland Oregon
              </span>
            </span>
          </span>
        </a>
      </li>
    
      <li>
        <a href="https://www.route-fifty.com/topic/city-government/?oref=rf-article-topics">
          <span>
            <span>
              <span>
                City Government
              </span>
            </span>
          </span>
        </a>
      </li>
    
      <li>
        <a href="https://www.route-fifty.com/topic/law-enforcement-tech/?oref=rf-article-topics">
          <span>
            <span>
              <span>
                Law Enforcement Tech
              </span>
            </span>
          </span>
        </a>
      </li>
    
  </ul>


        





        

      </div>
      

    </div>
  </div><div>
<div>

<div>
<p>The city council in Portland, Oregon this week unanimously voted to prohibit the use of facial recognition technology by city agencies, as well as by private companies in public places.</p><p>Civil liberties groups said Portland’s new restrictions on the use of the technology by businesses is a nationwide first. In approving the policy, city council members cited concerns about residents’ privacy, and pointed to problems with facial recognition software misidentifying women and people who are Black or have darker complexions.</p><p>"We are a pro-technology city, but what we've seen so far in practice with this technology, it just continues to exacerbate the over-criminalization of Black and brown people in our community,” said Portland City Commissioner Jo Ann Hardesty.</p><p>The new restrictions are outlined in <a href="https://www.portlandoregon.gov/auditor/article/765748" target="_blank">two</a> <a href="https://www.portlandoregon.gov/auditor/article/765749" target="_blank">pieces</a> of legislation, one that applies to the city government and another to businesses. The legislation comes as Portland has seen weeks of chaotic protests over police conduct, racial injustice and other issues, with different groups of demonstrators clashing violently at times with <a href="https://www.opb.org/article/2020/08/22/conservative-protesters-plan-rallies-in-downtown-portland/" target="_blank">one another</a> and <a href="https://abcnews.go.com/US/wireStory/clashes-portland-erupt-police-make-11-arrests-72900157" target="_blank">with law enforcement</a> officers.</p><p>Under the ban, businesses in the city will not be permitted to use facial recognition in “places of public accommodation,” a category that generally includes restaurants, hotels and retail stores. Sidewalks in front of businesses are also covered by the ban, city staff said.</p><p>While the government ban would apply to Portland’s bureaus and agencies, it would not extend to other levels of government, like the state, the surrounding county, or federal law enforcement operating in the city, according to a city staff member who spoke at <a href="https://www.portlandoregon.gov/video/player/?tab=council" target="_blank">a council meeting</a> this week.</p><p>The American Civil Liberties Union, one of groups that supports the Portland legislation, <a href="https://twitter.com/ACLU/status/1303839454226984961?s=20" target="_blank">lists</a> at least 14 other U.S. cities that have adopted bans of some sort on facial recognition technology.</p><p>“Face surveillance is an invasive threat to our privacy,” Jann Carson, interim executive director of the ACLU of Oregon, said in a statement.</p><p>“We hope the passage of this landmark legislation in Portland will spur efforts to enact statewide legislation that protects all Oregonians from the broad range of ways that our biometric information is collected, stored, sold, and used without our permission,” Carson added.</p><p>Some privacy advocates and civil liberties groups that weighed in on the pair of bills, which the council approved Wednesday, offered recommendations for how the legislation might be changed to eliminate possible loopholes and to clarify certain language. Generally, though, they were supportive of the measures and the council’s goals in passing them.</p><p>But some in the tech sector expressed concerns about the council’s approach.</p><p>Jake Parker, with the Security Industry Association, told the council during testimony this week, that his group feels the ban is extreme, unnecessary and that, as written, it would sweep in many facial recognition technologies that have nothing to do with surveillance.</p><p>And while emphasizing that the group does not support the use of the technology for mass surveillance by the government, he did suggest it could be helpful for solving crimes.</p><p>“Any technology can be abused,” he said. A ban, Parker added, precludes the opportunity to enact policies that would allow the technology to be used in “appropriate and acceptable ways.”</p><p>Jon Isaacs, vice president of government affairs for the Portland Business Alliance, said the group agrees that the city should take steps to protect people from having their “biometric data,” like images of their faces, collected without their consent for commercial purposes.</p><p>And, he said, the group also agrees that policies should be designed to prevent racially biased outcomes with the use of technology.&nbsp;</p><p>But Isaacs said that the alliance hopes the strict ban on businesses using&nbsp;facial recognition&nbsp;would be temporary and that there would be future legislation to address concerns the group has.</p><p>For instance, the alliance wants to see clearer language that excludes the use of facial recognition technology on mobile devices by visitors to a business, as well as a carve out allowing for the use of the technology for “individual opt-in experiences,” like automated hotel check-ins or ticket verification.</p><p>Critics, however, remain deeply skeptical of the technology.&nbsp;</p><p>“Facial recognition is fundamentally incompatible with a free society,” Lia Holland, a Portland resident and activist with the group Fight for the Future, told the council. Holland said that even seemingly innocuous uses, like deploying the technology to help speed up check-in lines or process payments, pose potential threats to civil liberties.</p><p>“Facial recognition and surveillance enables racism, surveillance enables authoritarianism and surveillance demands conformity,” she added. “This tech is opaque by design.”<svg>
<use xlink:href="/static/a/base/svg/spritesheet.svg#icon-rf-shield-alt"></use>
</svg></p></div></div>
</div></div>]]>
            </description>
            <link>https://www.route-fifty.com/tech-data/2020/09/portland-facial-recogntion-ban/168388/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24443489</guid>
            <pubDate>Fri, 11 Sep 2020 14:55:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building an end-to-end Speech Recognition model in PyTorch]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24443334">thread link</a>) | @ChefboyOG
<br/>
September 11, 2020 | https://www.comet.ml/site/customer-case-study-building-an-end-to-end-speech-recognition-model-in-pytorch-with-assemblyai/ | <a href="https://web.archive.org/web/*/https://www.comet.ml/site/customer-case-study-building-an-end-to-end-speech-recognition-model-in-pytorch-with-assemblyai/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		    <div>
			<p><em>This post was written by Michael Nguyen, Machine Learning Research Engineer at <a href="https://www.assemblyai.com/">AssemblyAI</a>. AssemblyAI uses Comet to log, visualize, and understand their model development pipeline.&nbsp;</em></p>
<p>Deep Learning has changed the game in speech recognition with the introduction of end-to-end models. These models take in audio, and directly output transcriptions. Two of the most popular end-to-end models today are Deep Speech by Baidu, and Listen Attend Spell (LAS) by Google. Both Deep Speech and LAS, are recurrent neural network (RNN) based architectures with different approaches to modeling speech recognition. Deep Speech uses the Connectionist Temporal Classification (CTC) loss function to predict the speech transcript. LAS uses a sequence to sequence network architecture for its predictions.</p>
<p>These models simplified speech recognition pipelines by taking advantage of the capacity of deep learning system to learn from large datasets. With enough data, you should, in theory, be able to build a super robust speech recognition model that can account for all the nuance in speech without having to spend a ton of time and effort hand engineering acoustic features or dealing with complex pipelines in more old-school GMM-HMM model architectures, for example.</p>
<p>Deep learning is a fast-moving field, and Deep Speech and LAS style architectures are already quickly becoming outdated. You can read about where the industry is moving in the Latest Advancement Section below.</p>
<h2><strong>How to Build Your Own End-to-End Speech Recognition Model in PyTorch</strong></h2>
<p>Let’s walk through how one would build their own end-to-end speech recognition model in PyTorch. The model we’ll build is inspired by Deep Speech 2 (Baidu’s second revision of their now-famous model) with some personal improvements to the architecture. The output of the model will be a probability matrix of characters, and we’ll use that probability matrix to decode the most likely characters spoken from the audio. You can find the full code and also run the it with GPU support on <a href="https://colab.research.google.com/drive/1IPpwx4rX32rqHKpLz7dc8sOKspUa-YKO">Google Colaboratory</a>.</p>
<h3><strong>Preparing the data pipeline</strong></h3>
<p>Data is one of the most important aspects of speech recognition. We’ll take raw audio waves and transform them into Mel Spectrograms.</p>
<p><img src="https://www.comet.ml/site/app/uploads/2020/05/spectogram-1024x220.png" alt="" width="1024" height="220" srcset="https://www.comet.ml/site/app/uploads/2020/05/spectogram-1024x220.png 1024w, https://www.comet.ml/site/app/uploads/2020/05/spectogram-300x64.png 300w, https://www.comet.ml/site/app/uploads/2020/05/spectogram-768x165.png 768w, https://www.comet.ml/site/app/uploads/2020/05/spectogram.png 1278w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="https://www.comet.ml/site/app/ewww/lazy/placeholder-1024x220.png" data-src="https://www.comet.ml/site/app/uploads/2020/05/spectogram-1024x220.png" data-srcset="https://www.comet.ml/site/app/uploads/2020/05/spectogram-1024x220.png 1024w, https://www.comet.ml/site/app/uploads/2020/05/spectogram-300x64.png 300w, https://www.comet.ml/site/app/uploads/2020/05/spectogram-768x165.png 768w, https://www.comet.ml/site/app/uploads/2020/05/spectogram.png 1278w"></p>
<p>You can read more on the details about how that transformation looks from this excellent post <a href="https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html">here</a>. For this post, you can just think of a Mel Spectrogram as essentially a picture of sound.</p>
<p><img src="https://www.comet.ml/site/app/uploads/2020/05/freq-1024x299.jpg" alt="" width="1024" height="299" srcset="https://www.comet.ml/site/app/uploads/2020/05/freq-1024x299.jpg 1024w, https://www.comet.ml/site/app/uploads/2020/05/freq-300x88.jpg 300w, https://www.comet.ml/site/app/uploads/2020/05/freq-768x225.jpg 768w, https://www.comet.ml/site/app/uploads/2020/05/freq-1536x449.jpg 1536w, https://www.comet.ml/site/app/uploads/2020/05/freq.jpg 1724w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="https://www.comet.ml/site/app/ewww/lazy/placeholder-1024x299.png" data-src="https://www.comet.ml/site/app/uploads/2020/05/freq-1024x299.jpg" data-srcset="https://www.comet.ml/site/app/uploads/2020/05/freq-1024x299.jpg 1024w, https://www.comet.ml/site/app/uploads/2020/05/freq-300x88.jpg 300w, https://www.comet.ml/site/app/uploads/2020/05/freq-768x225.jpg 768w, https://www.comet.ml/site/app/uploads/2020/05/freq-1536x449.jpg 1536w, https://www.comet.ml/site/app/uploads/2020/05/freq.jpg 1724w"></p>
<p>For handling the audio data, we are going to use an extremely useful utility called <strong>torchaudio </strong>which is a library built by the PyTorch team specifically for audio data. We’ll be training on a subset of <a href="http://www.openslr.org/12/">LibriSpeech</a>, which is a corpus of read English speech data derived from audiobooks, comprising 100 hours of transcribed audio data. You can easily download this dataset using <strong>torchaudio</strong>:</p>
<div>
<div>
<pre>import torchaudio train_dataset = torchaudio.datasets.LIBRISPEECH("./", url="train-clean-100", download=True) 
test_dataset = torchaudio.datasets.LIBRISPEECH("./", url="test-clean", download=True)</pre>
</div>
</div>
<p>Each sample of the dataset contains the waveform, sample rate of audio, the utterance/label, and more metadata on the sample. You can view what each sample looks like from the source code <a href="https://github.com/pytorch/audio/blob/master/torchaudio/datasets/librispeech.py#L40">here</a>.</p>
<h3><strong>Data Augmentation – SpecAugment</strong></h3>
<p>Data augmentation is a technique used to artificially increase the diversity of your dataset in order to increase your dataset size. This strategy is especially helpful when data is scarce or if your model is overfitting. For speech recognition, you can do the standard augmentation techniques, like changing the pitch, speed, injecting noise, and adding reverb to your audio data.</p>
<p>We found Spectrogram Augmentation (SpecAugment), to be a much simpler and more effective approach. SpecAugment, was first introduced in the paper <a href="https://arxiv.org/abs/1904.08779">SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition</a>, in which the authors found that simply cutting out random blocks of consecutive time and frequency dimensions improved the models generalization abilities significantly!</p>
<p><img src="https://www.comet.ml/site/app/uploads/2020/05/tmp.png" alt="" width="619" height="286" srcset="https://www.comet.ml/site/app/uploads/2020/05/tmp.png 619w, https://www.comet.ml/site/app/uploads/2020/05/tmp-300x139.png 300w" sizes="(max-width: 619px) 100vw, 619px" data-old-src="https://www.comet.ml/site/app/ewww/lazy/placeholder-619x286.png" data-src="https://www.comet.ml/site/app/uploads/2020/05/tmp.png" data-srcset="https://www.comet.ml/site/app/uploads/2020/05/tmp.png 619w, https://www.comet.ml/site/app/uploads/2020/05/tmp-300x139.png 300w"></p>
<p>In PyTorch, you can use the<strong> torchaudio</strong> function <strong>FrequencyMasking</strong> to mask out the frequency dimension, and <strong>TimeMasking</strong>&nbsp;for the time dimension.</p>
<div>
<div>
<pre>torchaudio.transforms.FrequencyMasking()
torchaudio.transforms.TimeMasking()
</pre>
</div>
</div>
<p>Now that we have the data, we’ll need to transform the audio into Mel Spectrograms, and map the character labels for each audio sample into integer labels:</p>
<div>
<div>
<pre>class TextTransform:
    """Maps characters to integers and vice versa"""
    def __init__(self):
        char_map_str = """
        ' 0
        &lt;SPACE&gt; 1
        a 2
        b 3
        c 4
        d 5
        e 6
        f 7
        g 8
        h 9
        i 10
        j 11
        k 12
        l 13
        m 14
        n 15
        o 16
        p 17
        q 18
        r 19
        s 20
        t 21
        u 22
        v 23
        w 24
        x 25
        y 26
        z 27
        """
        self.char_map = {}
        self.index_map = {}
        for line in char_map_str.strip().split('\n'):
            ch, index = line.split()
            self.char_map[ch] = int(index)
            self.index_map[int(index)] = ch
        self.index_map[1] = ' '

    def text_to_int(self, text):
        """ Use a character map and convert text to an integer sequence """
        int_sequence = []
        for c in text:
            if c == ' ':
                ch = self.char_map['']
            else:
                ch = self.char_map
            int_sequence.append(ch)
        return int_sequence

    def int_to_text(self, labels):
        """ Use a character map and convert integer labels to an text sequence """
        string = []
        for i in labels:
            string.append(self.index_map[i])
        return ''.join(string).replace('', ' ')


train_audio_transforms = nn.Sequential(
    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128),
    torchaudio.transforms.FrequencyMasking(freq_mask_param=15),
    torchaudio.transforms.TimeMasking(time_mask_param=35)
)

valid_audio_transforms = torchaudio.transforms.MelSpectrogram()

text_transform = TextTransform()


def data_processing(data, data_type="train"):
    spectrograms = []
    labels = []
    input_lengths = []
    label_lengths = []
    for (waveform, _, utterance, _, _, _) in data:
        if data_type == 'train':
            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)
        else:
            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)
        spectrograms.append(spec)
        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))
        labels.append(label)
        input_lengths.append(spec.shape[0]//2)
        label_lengths.append(len(label))

    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)
    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)

    return spectrograms, labels, input_lengths, label_lengths
</pre>
</div>
</div>
<h2><strong>Define the Model – Deep Speech 2 (but better)</strong></h2>
<p>Our model will be similar to the Deep Speech 2 architecture. The model will have two main neural network modules – N layers of Residual Convolutional Neural Networks (ResCNN) to learn the relevant audio features, and a set of Bidirectional Recurrent Neural Networks (BiRNN) to leverage the learned ResCNN audio features. The model is topped off with a fully connected layer used to classify characters per time step.</p>
<p><img src="https://comet.ml/site/app/uploads/2020/05/BHOBfDVTcGCQKTtp.png" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" data-src="https://comet.ml/site/app/uploads/2020/05/BHOBfDVTcGCQKTtp.png"></p>
<p>Convolutional Neural Networks (CNN) are great at extracting abstract features, and we’ll apply the same feature extraction power to audio spectrograms. Instead of just vanilla CNN layers, we choose to use Residual CNN layers. Residual connections (AKA skip connections) were first introduced in the paper <a href="https://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a>, where the author found that you can build really deep networks with good accuracy gains if you add these connections to your CNN’s. Adding these Residual connections also helps the model learn faster and generalize better. The paper <a href="https://arxiv.org/abs/1712.09913">Visualizing the Loss Landscape of Neural Nets</a> shows that networks with residual connections have a “flatter” loss surface, making it easier for models to navigate the loss landscape and find a lower and more generalizable minima.</p>
<p><img src="https://comet.ml/site/app/uploads/2020/05/qbBytawOwsmKfYlI.png" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" data-src="https://comet.ml/site/app/uploads/2020/05/qbBytawOwsmKfYlI.png"></p>
<p>Recurrent Neural Networks (RNN) are naturally great at sequence modeling problems. RNN’s processes the audio features step by step, making a prediction for each frame while using context from previous frames. We use BiRNN’s because we want the context of not only the frame before each step, but the frames after it as well. This can help the model make better predictions, as each frame in the audio will have more information before making a prediction. We use Gated Recurrent Unit (GRU’s) variant of RNN’s as it needs less computational resources than LSTM’s, and works just as well in some cases.</p>
<p>The model outputs a probability matrix for characters which we’ll use to feed into our decoder to extract what the model believes are the highest probability characters that were spoken.</p>
<div>
<div>
<pre>class CNNLayerNorm(nn.Module):
    """Layer normalization built for cnns input"""
    def __init__(self, n_feats):
        super(CNNLayerNorm, self).__init__()
        self.layer_norm = nn.LayerNorm(n_feats)

    def forward(self, x):
        # x (batch, channel, feature, time)
        x = x.transpose(2, 3).contiguous() # (batch, channel, time, feature)
        x = self.layer_norm(x)
        return x.transpose(2, 3).contiguous() # (batch, channel, feature, time) 


class ResidualCNN(nn.Module):
    """Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf
        except with layer norm instead of batch norm
    """
    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):
        super(ResidualCNN, self).__init__()

        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2)
        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2)
        self.dropout1 = …</pre></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.comet.ml/site/customer-case-study-building-an-end-to-end-speech-recognition-model-in-pytorch-with-assemblyai/">https://www.comet.ml/site/customer-case-study-building-an-end-to-end-speech-recognition-model-in-pytorch-with-assemblyai/</a></em></p>]]>
            </description>
            <link>https://www.comet.ml/site/customer-case-study-building-an-end-to-end-speech-recognition-model-in-pytorch-with-assemblyai/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24443334</guid>
            <pubDate>Fri, 11 Sep 2020 14:41:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Speed up image labeling using transfer learning (no code required)]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24443275">thread link</a>) | @tigranhakobian
<br/>
September 11, 2020 | https://blog.superannotate.com/speed-up-labeling-process-using-transfer-learning | <a href="https://web.archive.org/web/*/https://blog.superannotate.com/speed-up-labeling-process-using-transfer-learning">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p id="1b09" data-selectable-paragraph=""><strong>Author:<span>&nbsp;</span></strong><a href="https://www.linkedin.com/in/vahagn-tumanyan-034784a1/?originalSubdomain=am" rel=" noopener"><em>Vahagn Tumanyan</em></a>, Computer Vision Engineer at<span>&nbsp;</span><a href="https://superannotate.com/" rel=" noopener">SuperAnnotate</a></p>
<blockquote>
<p data-selectable-paragraph=""><span>Having large datasets with high-quality annotations is quintessential in any computer vision task involving deep neural networks. Unfortunately, the process of annotating thousands of images is a time and human-resource consuming endeavor. Hence, for many companies and university researchers, the annotation time and scalability become a major pain point to scale their research project or business. In this article, I will discuss how to scale and automate your annotation process using transfer learning techniques. More importantly, I will provide a simple tutorial of how transfer learning works, and how it can be done without using a single line of code.</span></p>
</blockquote>

<h2 id="af0a">Outline</h2>
<ul>
<li><strong><em>What is transfer learning and how it can be applied to the annotation process</em></strong></li>
<li><strong><em>Training new neural networks using SuperAnnotate</em></strong></li>
<li><strong><em>Testing newly trained network</em></strong></li>
<li><strong><em>Conclusion</em></strong></li>
</ul>
<br>
<h2 id="0f82">1. What is Transfer Learning (TL) and how can it be applied to the annotation process.</h2>
<p><img src="https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png?width=1600&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png" alt="Speed up the labeling process using transfer learning 1" width="1600" srcset="https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png?width=800&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png 800w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png?width=1600&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png 1600w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png?width=2400&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png 2400w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png?width=3200&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png 3200w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png?width=4000&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png 4000w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png?width=4800&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png 4800w" sizes="(max-width: 1600px) 100vw, 1600px"></p>
<figure>
<p><span>Example of how transfer learning works. Source:</span><span>&nbsp;</span><a href="https://www.kdnuggets.com/2017/09/databricks-vision-making-deep-learning-simple.html" target="_blank" rel="noopener nofollow">kdnuggets.com</a></p>
</figure>
<p id="91de" data-selectable-paragraph="">In the most general terms transfer learning (TL),<strong><span>&nbsp;</span></strong>is a direction of machine learning that focuses on storing “knowledge” that a model has learned in order to solve some problem<span>&nbsp;</span><strong>A<span>&nbsp;</span></strong>and use that knowledge to help with another related problem<span>&nbsp;</span><strong>B</strong>.</p>
<p id="991b" data-selectable-paragraph="">Humans have natural ability to apply knowledge gained from solving one task in order to solve an entirely different one. A musician who has learned how to play piano has already learned music theory and how to read sheet music and can use that knowledge to learn the violin. In other words, if you want to learn the violin you don’t have to re-learn music theory. Transfer learning tries to solve a similar problem in deep learning.</p>
<blockquote>
<p id="9eeb" data-selectable-paragraph="">An example that is more related to computer vision is that a neural network that has learned to classify Cats and Dogs in images has perhaps learned useful features that are specific to canines and felines would help another network classify Wolves and Tigers.</p>
</blockquote>
<p id="bfdd" data-selectable-paragraph="">Now that we know what transfer learning<strong><span>&nbsp;</span></strong>is, how does it actually help during the annotation process? What we aim at is improving the speed at which image annotations can be done. Let’s look at the typical process of annotating a particular image with bounding boxes and assigning classes to them.</p>
<p id="994e" data-selectable-paragraph="">The hypothesis is that if we have a neural network (NN) that can somewhat accurately make predictions on an input image then fine-tuning its predictions and annotating the parts of the image that the NN failed to classify will be much faster than annotating the whole image.</p>
<p data-selectable-paragraph=""><img src="https://blog.superannotate.com/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%202.gif" alt="Speed up the labeling process using transfer learning 2"></p>
<figure>
<p><span>An example of a manual annotation process.</span></p>
</figure>
<p id="993f" data-selectable-paragraph="">In the example above, I did not try to be very accurate and show that sometimes the annotator will need to readjust and resize bounding boxes. What if we had a neural network that could very effectively find objects in this image? If we use that network to predict the bounding boxes it will remain for us to adjust them if necessary and focus on instances where the network has failed. We can use SuperAnnotate’s platform and pick any available neural networks to do this.</p>
<p data-selectable-paragraph=""><img src="https://blog.superannotate.com/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%203.gif" alt="Speed up the labeling process using transfer learning 3"></p>
<figure>
<div>
<p><span>An example of using a neural network to predict objects on an image (multiple images can be selected as well)</span></p>
</div>
</figure>
<p id="a9fd" data-selectable-paragraph="">After running the given prediction model the annotated image looks like this:</p>
<p data-selectable-paragraph=""><img src="https://blog.superannotate.com/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%204.gif" alt="Speed up the labeling process using transfer learning 4"></p>
<figure>
<div>
<p><span>The first round of predictions using SuperAnnotate’s predictions model</span></p>
</div>
</figure>
<p id="f9bf" data-selectable-paragraph="">The improvement in speed will be even more noticeable when we need to annotate the whole semantic mask instead of only bounding boxes.</p>
<blockquote>
<p id="488d" data-selectable-paragraph="">By leveraging the power the of transfer learning, data augmentation and pre-trained networks we can train new models that solve the task in the domain we are interested with relatively small number of high quality annotated images. Using these newly fine-tuned models to partially annotate images we can tremendously speed up the whole process.</p>
</blockquote>
<h2 id="03ce">2. Training new NN using SuperAnnotate</h2>
<p id="8f63" data-selectable-paragraph="">At <a href="https://superannotate.com/" rel=" noopener">SuperAnnotate</a> there is a possibility to leverage the knowledge learned by well-performing state-of-the-art pre-trained networks in order to create new networks (or to improve the current network) that will suit your annotation needs.</p>
<p id="c3b3" data-selectable-paragraph="">If you are registered in the platform, the workflow for transferring the knowledge from one NN to another would be the following:</p>
<ol>
<li id="03b5" data-selectable-paragraph="">Click on the “Neural Networks” tab.</li>
<li id="f1e3" data-selectable-paragraph="">Click the “New Model”</li>
<li id="428e" data-selectable-paragraph="">Fill in the model name and model description</li>
<li id="3e1e" data-selectable-paragraph="">Choose the annotation task and one of the available pre-trained models</li>
<li id="5672" data-selectable-paragraph="">Choose the projects which you want to use for your training (you can choose multiple projects)</li>
<li id="057e" data-selectable-paragraph="">Update some of the default hyper-parameters (<em>optional</em>)</li>
<li id="1a8f" data-selectable-paragraph="">Choose a GPU to train the new model on</li>
<li id="5f5a" data-selectable-paragraph="">Click “Run Training”</li>
</ol>
<p><img src="https://blog.superannotate.com/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%205.gif" alt="Speed up the labeling process using transfer learning 5"></p>
<figure>
<div>
<p><span>The process of creating a new neural network model based on the description above</span></p>
</div>
</figure>
<p id="3810" data-selectable-paragraph="">Among the 6 tasks that are described in the<span>&nbsp;</span><a href="https://cocodataset.org/#home" target="_blank" rel="noopener nofollow">cocodataset.org</a>, we provide pre-trained models for 5 of them`</p>
- Instance Segmentation<br><a href="https://cocodataset.org/#keypoints-2020" target="_blank" rel="noopener nofollow">- </a><a href="https://cocodataset.org/#keypoints-2020" rel=" noopener">Keypoint Detection</a><br>- Object Detection<br>- Semantic Segmentation (will be available in September)<br><a href="https://cocodataset.org/#panoptic-2019" target="_blank" rel="noopener nofollow">- </a><a href="https://cocodataset.org/#panoptic-2019" rel=" noopener">Panoptic Segmentation</a><span>&nbsp;</span>(will be available in September)
<p id="8670" data-selectable-paragraph=""><strong>Hyperparameters</strong></p>
<p data-selectable-paragraph=""><strong><img src="https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png?width=460&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png" alt="Speed up the labeling process using transfer learning 6" width="460" srcset="https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png?width=230&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png 230w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png?width=460&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png 460w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png?width=690&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png 690w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png?width=920&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png 920w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png?width=1150&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png 1150w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png?width=1380&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png 1380w" sizes="(max-width: 460px) 100vw, 460px"></strong></p>
<blockquote>
<p data-selectable-paragraph=""><span>All available configurable fields for training a new Neural Network.</span></p>
</blockquote>

<p id="c794" data-selectable-paragraph="">There are quite a few hyperparameters that can be tuned during the transfer learning process. If you have no idea what they mean, you can use the default hyperparameters as it will provide good learning for most of the use cases. The hyperparameters that we allow to fine-tune are:<span>&nbsp;</span><strong>Batch Size</strong><span>&nbsp;</span>(the number of images used in one iteration of the training procedure),<span>&nbsp;</span><strong>Epoch count</strong>,<span>&nbsp;</span><strong>Learning Rate</strong>,<span>&nbsp;</span><strong>Gamma<span>&nbsp;</span></strong>(the learning rate gets multiplied by this value after “Epochs for Gamma” epochs),<span>&nbsp;</span><strong>Steps for Gamma</strong>,<span>&nbsp;</span><strong>Images (RoIs) per batch<span>&nbsp;</span></strong>(how many regions of interest to suggest per image)<span>&nbsp;</span><strong>Evaluation Period<span>&nbsp;</span></strong>(number of epochs after which a checkpoint of the model is saved, and the performance of the checkpoint is evaluated on the test set)<span>&nbsp;</span><strong>Train Test split ratio</strong><span>&nbsp;</span>(we will use this percentage of images to train the new model)</p>
<p id="b17b" data-selectable-paragraph="">The user can monitor the training process since we also provide training metrics. Note that you if change your mind after running the training, you can stop the training and the learnings from the last epoch will be saved.</p>
<h2 id="9b6d">3. Testing newly trained network</h2>
<p id="c997" data-selectable-paragraph="">Once the new NN model is trained with the given hyperparameters, it can be be used to automate the annotation of the next set of images.</p>
<p id="b9b4" data-selectable-paragraph="">To see qualitatively how the new model performs you need to run “smart prediction” using the newly trained model. A new model with the name that you have specified while running the training will appear in the dropdown list of possible NNs to chose from.</p>
<p data-selectable-paragraph=""><img src="https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png?width=1333&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png" alt="Speed up the labeling process using transfer learning 7" width="1333" srcset="https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png?width=667&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png 667w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png?width=1333&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png 1333w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png?width=2000&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png 2000w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png?width=2666&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png 2666w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png?width=3333&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png 3333w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png?width=3999&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png 3999w" sizes="(max-width: 1333px) 100vw, 1333px"></p>
<p id="9c29" data-selectable-paragraph="">After we create a new model called “New FineTuned Model” using our NN functionality it appears in the dropdown menu for the “smart prediction”</p>
<p id="40d7" data-selectable-paragraph="">Once the smart prediction has completed you can view the results by clicking on the image and opening the annotation tool.</p>
<p id="5c8c" data-selectable-paragraph="">For one of the clients we have, using a fine-tuned model, observed about 13% accuracy improvement over the original model when trying to annotate instances of “Person” class.</p>
<h2 id="60c6">4. Conclusion</h2>
<p id="e487" data-selectable-paragraph="">Automating the annotation process without writing a single line of code is essential for many computer vision engineers and annotation service companies. By using<span> </span>SuperAnnotate’s<span>&nbsp;</span>platform, we provided a simple tutorial on how one can set up the automation process using transfer learning, and keep improving the annotation accuracy by annotating and training batches of images over and over again.</p>
<p data-selectable-paragraph=""><!--HubSpot Call-to-Action Code --><span id="hs-cta-wrapper-c76b66d9-cb68-408a-9dc9-9a9789e5fce0"><span id="hs-cta-c76b66d9-cb68-408a-9dc9-9a9789e5fce0"><!--[if lte IE 8]><div id="hs-cta-ie-element"></div><![endif]--><a href="https://cta-redirect.hubspot.com/cta/redirect/7839526/c76b66d9-cb68-408a-9dc9-9a9789e5fce0"><img id="hs-cta-img-c76b66d9-cb68-408a-9dc9-9a9789e5fce0" src="https://no-cache.hubspot.com/cta/default/7839526/c76b66d9-cb68-408a-9dc9-9a9789e5fce0.png" alt="Get started"></a></span></span><!-- end HubSpot Call-to-Action Code --></p>
<blockquote>

<p data-selectable-paragraph=""><span>Stay tuned … in the upcoming months, we will provide more functionality in our neural network section. More specifically, we will allow you to upload and download your custom models and weights, plot different error metrics, compare and version different training models, etc.</span></p>
</blockquote></span>
</p>


</div></div>]]>
            </description>
            <link>https://blog.superannotate.com/speed-up-labeling-process-using-transfer-learning</link>
            <guid isPermaLink="false">hacker-news-small-sites-24443275</guid>
            <pubDate>Fri, 11 Sep 2020 14:35:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Impact of the GDPR on Artificial Intelligence – EU Parliament Think Tank]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24443230">thread link</a>) | @DerCommodore
<br/>
September 11, 2020 | https://www.europarl.europa.eu/thinktank/en/document.html?reference=EPRS_STU(2020)641530 | <a href="https://web.archive.org/web/*/https://www.europarl.europa.eu/thinktank/en/document.html?reference=EPRS_STU(2020)641530">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<!-- collapsible -->
			<div>
				<h3 id="section1">
					The impact of the General Data Protection Regulation (GDPR) on artificial intelligence
				</h3>
				<p><span>25-06-2020</span></p>
				
					
					
						<p>This study addresses the relation between the EU General Data Protection Regulation (GDPR) and artificial intelligence (AI). It considers challenges and opportunities for individuals and society, and the ways in which risks can be countered and opportunities enabled through law and technology. The study discusses the tensions and proximities between AI and data protection principles, such as in particular purpose limitation and data minimisation. It makes a thorough analysis of automated decision-making, considering the extent to which it is admissible, the safeguard measures to be adopted, and whether data subjects have a right to individual explanations. The study then considers the extent to which the GDPR provides for a preventive risk-based approach, focused on data protection by design and by default.</p>
						<p>This study addresses the relation between the EU General Data Protection Regulation (GDPR) and artificial intelligence (AI). It considers challenges and opportunities for individuals and society, and the ways in which risks can be countered and opportunities enabled through law and technology. The study discusses the tensions and proximities between AI and data protection principles, such as in particular purpose limitation and data minimisation. It makes a thorough analysis of automated decision-making, considering the extent to which it is admissible, the safeguard measures to be adopted, and whether data subjects have a right to individual explanations. The study then considers the extent to which the GDPR provides for a preventive risk-based approach, focused on data protection by design and by default.</p>
					
				
				
				
				<!-- START EXPANDABLE ZONE -->
				<div>
					<ul>
					
					
					
					
					</ul>
						
					
						<!-- START EXTERNAL AUTHORS -->
						<p><span>External author</span></p><p>DG, EPRS_The study was led by Professor Giovanni Sartor, European University Institute of Florence, at the request of the Panel for the Future of Science and Technology (STOA) and managed by the Scientific Foresight Unit, within the Directorate-General for Parliamentary Research Services (EPRS) of the Secretariat of the European Parliament. It was co-authored by Professor Sartor and Dr Francesca Lagioia, European University Institute of Florence, working under his supervision.</p>
					
					
					
					
					<!-- END EXTERNAL AUTHORS -->
					
					<!-- END : FACT SHEET CONTAINER-->



					<!-- END EXPANDABLE ZONE -->
				</div>

				<!-- end collapsible -->

			</div>
		</div></div>]]>
            </description>
            <link>https://www.europarl.europa.eu/thinktank/en/document.html?reference=EPRS_STU(2020)641530</link>
            <guid isPermaLink="false">hacker-news-small-sites-24443230</guid>
            <pubDate>Fri, 11 Sep 2020 14:31:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Security advantages of pull-based CD pipelines]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24443189">thread link</a>) | @stekern
<br/>
September 11, 2020 | https://alex.kaskaso.li/post/pull-based-pipelines | <a href="https://web.archive.org/web/*/https://alex.kaskaso.li/post/pull-based-pipelines">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
  	  

<p>We recently adopted <a href="https://www.weave.works/technologies/gitops/">GitOps</a> for Kubernetes deployments, using Weaveworks’ <em><a href="https://www.weave.works/oss/flux/">flux</a></em> daemon. This is a “pull-based” approach to continuous deployment for k8s, very much pioneered by Weaveworks’ themselves.</p>

<p>There’s several advantages to this but what I’m going to focus on here are the security benefits. I’m then going to advocate for the adoption of the pull-based CD approach beyond k8s manifests, particularly around building and pushing container images.</p>

<p>Ultimately, I’m arguing that “CI/CD” tools like CircleCI and Jenkins are a security hazard and should only be used for “CI” (running tests).</p>

<p><img src="https://alex.kaskaso.li/images/posts/devops-security-unicorn.png" alt="devops unicorn" title="devops unicorn"></p>

<h2 id="note">Note</h2>

<p>I originally published this on <a href="https://medium.com/@alexkaskasoli/pull-based-cd-pipelines-for-security-4e044b403f56">Medium</a>. It is reproduced here as a mirror.</p>



<p>Let’s define “push-based” in this context. If you’re using something like CircleCI or Jenkins to deploy, those tools are <em>pushing</em> your services:</p>
<ul>
  <li>they’re building and <em>pushing</em> your image to a container registry</li>
  <li>they’re <em>pushing</em> your updated manifests to production</li>
</ul>

<p>So the engineers have access to the CI/CD tooling, and the CI/CD tooling has access to production. It looks like this (note the direction of the arrows):</p>

<p><img src="https://alex.kaskaso.li/images/posts/traditional_pipeline.png" alt="traditional pipeline" title="traditional pipeline"></p>

<p>We’ll see how this contrasts with a pull-based approach later.</p>

<p>First, what’s the issue with tools like Jenkins or CircleCI for deployment? My main security arguments against traditional CI/CD tools are:</p>

<ul>
  <li>the network attack surface</li>
  <li>disappointing access controls over secrets (looking at you CircleCI)</li>
  <li>yet another third-party with your deployment secrets (for SaaS)</li>
</ul>

<h3 id="network-attack-surface">Network attack surface</h3>

<p>Minimizing your attack surface is a basic security principle.</p>

<p>Let’s say you have something like Jenkins running on your network. There’s <a href="https://www.cvedetails.com/vulnerability-list.php?vendor_id=15865&amp;product_id=34004&amp;version_id=&amp;page=1&amp;hasexp=0&amp;opdos=0&amp;opec=0&amp;opov=0&amp;opcsrf=0&amp;opgpriv=0&amp;opsqli=0&amp;opxss=0&amp;opdirt=0&amp;opmemc=0&amp;ophttprs=0&amp;opbyp=0&amp;opfileinc=0&amp;opginf=0&amp;cvssscoremin=0&amp;cvssscoremax=0&amp;year=0&amp;month=0&amp;cweid=0&amp;order=1&amp;trc=150&amp;sha=42dfa4c7d4f30241bc7fa7cb4e94138bcf01a35e">150 CVEs for Jenkins core</a>, with 15 of those just from 2019. This figure excludes plugin vulnerabilities - <a href="https://jenkins.io/security/advisories/">of which there are many more</a> (not to mention the risk of supply-chain attacks with those).</p>

<p>To add to the fun, <a href="https://www.google.com/search?client=firefox-b-d&amp;q=jenkins+reflected+xss"><em>reflected</em> Cross-Site Scripting in Jenkins</a> can lead to remote code execution on the Jenkins host, meaning attackers can probably gain an initial foothold into <a href="https://crt.sh/?q=jenkins.%25">quite a few companies</a> with some innocuous phishing or watering hole attacks (you did click on a random link to view this blog post, didn’t you? 🙃).</p>

<p>RCE on your Jenkins host is bad enough, but if you have production deployment secrets on there it’s game over.</p>

<h3 id="free-for-all-secrets">Free-for-all secrets</h3>

<p><img src="https://alex.kaskaso.li/images/posts/oprah_secrets.jpg" alt="oprah secrets" title="oprah secrets"></p>

<p>I’ll talk about CircleCI here but this applies to other CI/CD tools.</p>

<p>Everything is Agile and DevOps, so you want to allow your engineers to deploy multiple times a day, with minimal friction.</p>

<p>You have branch protections on your <code>master</code> branch and require one or more peer review of changes before a branch can be merged into <code>master</code>. So the CI/CD flow you’d expect is maybe something like:</p>
<ul>
  <li>Alice pushes a new branch with some changes</li>
  <li>CircleCI runs some tests in the branch</li>
  <li>Bob reviews Alice’s branch and approves the changes</li>
  <li>Alice merges branch into <code>master</code></li>
  <li>CircleCI, from <code>master</code>:
    <ul>
      <li>runs tests again</li>
      <li>builds image</li>
      <li>pushes image to the container registry</li>
      <li>deploys</li>
    </ul>
  </li>
</ul>

<p>It may be tempting to think that only CircleCI has access to deployment secrets in the scenario above, or that only a peer-reviewed <code>master</code> branch can be pushed to your container registry and deployed to production.</p>

<p>In fact Alice, Bob and everyone else on that team can trivially pull the deploy secrets out, and CircleCI’s <a href="https://circleci.com/docs/2.0/contexts/">contexts</a> offer little solace here as long as you want to empower the team to deploy on their own. To pull the secrets out you just need to push a branch and print out the environment variables during a job run, or POST them to an endpoint - after all, CI/CD tooling is literally Code-Execution-as-a-Service.</p>

<p>In the above scenario, compromising a single engineer is enough to gain access to production through CircleCI (at least to the extent their context allows).</p>

<p>It should be noted that Travis and GitHub Actions offer better controls, allowing you to restrict secrets on a per-branch basis. You would therefor only expose deployment secrets to <code>master</code> code that’s been peer-reviewed (and therefor assumed safe). Still, that’s production deployment secrets outside of the trust boundary of your production environment. As we’ll see later, this is not necessary.</p>

<h3 id="sharing-is-not-caring">Sharing is not caring</h3>

<p>It seems to be fashion these days to share your deepest secrets with everyone.</p>

<p>There’s companies like <a href="https://platform9.com/">Platform9</a> or <a href="https://spotinst.com/">Spotinst</a> who want admin access to your cloud environment or production cluster to help you manage things. Of course, you’re also expected to give this access to your CI/CD SaaS of choice, if you’re going for the Cloud version.</p>

<p>This is all the more worrying given that <a href="https://www.ncsc.gov.uk/information/global-targeting-enterprises-managed-service-providers">some threat actors are known to have shifted their focus to targeting managed service providers</a>; why put the effort into compromising a thousand companies when they can target a single service provider and gain access to all their customers?</p>

<p>To a certain extent, you have to trust third-parties these days. However, I’m more comfortable with AWS lording over my services than a startup or small company who may be cutting corners around security while they focus on market acrobatics.</p>

<p>At the end of the day, you just want to limit the number of third-parties with access to your stuff.</p>

<h2 id="pull-based-deployments-with-flux">“pull-based” deployments with flux</h2>

<p>How does adopting the pull-based approach offered by <em>flux</em> improve the security posture here?</p>

<p>For those not in the loop, the <em>flux</em> daemon sits <em>inside your k8s cluster</em> and does two things:</p>

<ul>
  <li>it <em>pulls</em> k8s manifests from a git repo, and applies them to the cluster</li>
  <li>it monitors your container registry for newer images, and updates your k8s resources accordingly</li>
</ul>

<p>I’ll just focus on the first point here for brevity (<a href="https://docs.fluxcd.io/en/1.17.0/introduction.html#introducing-flux">the docs</a> give a good intro to the rest).</p>

<p><em>flux</em> regularly polls the <code>master</code> branch of the repo that contains your k8s YAML manifests and makes sure that what’s in your cluster matches what’s defined in the “GitOps” repo. In the simplest terms, this is what it does:</p>

<div><div><pre><code><span>while </span><span>true
</span><span>do
</span>git clone git@github.com:foo/gitops-repo.git
kubectl apply <span>-f</span> gitops-repo/
<span>sleep </span>300
<span>done</span>
</code></pre></div></div>

<p>And just like that, the state of your cluster is version controlled, auditable and protected from drift. You can go ahead and revoke everyone’s access to the cluster; they don’t need <code>kubectl</code> anymore.</p>

<p>More importantly though, you can go ahead and remove cluster access from your CI/CD tool. Your CD pipeline now looks like this (notice the direction of the arrows):</p>

<p><img src="https://alex.kaskaso.li/images/posts/gitops_pipeline.png" alt="gitops pipeline" title="gitops pipeline"></p>

<p>Because your CD tool now sits in your k8s cluster and uses a <em>pull-based</em> approach, an attacker would already need privileged access to your cluster to abuse it (read: there’s no point attacking the CD tool now).</p>

<p><em>flux</em> has no network attack surface and doesn’t leak secrets.</p>

<p>Your deployment access controls are now in your GitOps git repo and you probably want:</p>
<ul>
  <li>branch protections on <code>master</code></li>
  <li>a number of peer-reviews</li>
  <li>require reviews from team members using CODEOWNERS</li>
</ul>

<p>With these measures, multiple engineers from the same team need to be compromised for an attacker to make his way to production through the CD pipeline.</p>

<h2 id="what-about-the-images">What about the images?</h2>

<p>In the previous section I said “your CD tool now sits in your k8s cluster” but that’s only partially true. If you only adopt Weaveworks’ <em>flux</em> and call it a day, you’re still <em>pushing</em> your Docker images to a container registry, probably using a CI/CD tool like Jenkins or CircleCI.</p>

<p>In fact, that’s what Weaveworks explicity say in their own <a href="https://www.weave.works/blog/continuous-delivery-weave-flux/">blog posts</a> which is a bit surprising; they’re lauding the security benefits of their <em>pull-based</em> k8s deployment approach while recommending their users <em>push</em> images to a container registry, and from CircleCI nonetheless (image from Weaveworks):</p>

<p><img src="https://alex.kaskaso.li/images/posts/weaveworks_pipeline.png" alt="weaveworks pipeline" title="weaveworks pipeline"></p>

<p>So we’ve not really solved the problem at this point. If the CI/CD tool is compromised according to one of the scenarios we described above, attackers can push arbitrary images to the container registry. Given that <em>flux</em> also <a href="https://docs.fluxcd.io/en/1.17.0/introduction.html#automated-deployment-of-new-container-images">automates the deployment of new images by monitoring the container registry</a>, that’s still a CI/CD path to production to be abused by attackers.</p>

<h2 id="pull-based-image-builds">Pull-based image builds</h2>

<p>The solution seems straightforward at this point: building and adding new images to the container registry should also be done with a pull-based approach. We need a daemon that polls application repositories for peer-reviewed (trusted) changes to <code>master</code>. Upon a change, it builds the application’s Dockerfile and safely puts the image in the container registry.</p>

<p>What we’re looking for is something like this (again, arrows):</p>

<p><img src="https://alex.kaskaso.li/images/posts/pull_pipeline.png" alt="pull pipeline" title="pull pipeline"></p>

<p>Such a service would have no network attack surface and wouldn’t risk leaking any image deployment secrets.</p>

<p>I’ve been playing around with a proof-of-concept that polls repos and uses Google’s <a href="https://github.com/GoogleContainerTools/kaniko"><em>kaniko</em></a> to build images in a safe location.</p>

<h2 id="tldr">TL;DR</h2>

<p>We need to turn our pipelines around and start pulling.</p>

<p>Traditional push-based CI/CD tools are a security hazard. It’s true that some offer better security controls than others, but either way, there are tangible security benefits with pull-based pipelines.</p>

<p>Continuous deployment can and should only be done within the trust boundary of your production environment.</p>

<p>We now need a solid pull-based tool for building images to complement <em>flux</em>.</p>

      <hr>
      
      

    </div></div>]]>
            </description>
            <link>https://alex.kaskaso.li/post/pull-based-pipelines</link>
            <guid isPermaLink="false">hacker-news-small-sites-24443189</guid>
            <pubDate>Fri, 11 Sep 2020 14:26:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scaling Erlang Developer Experience at WhatsApp [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 290 | Comments 88 (<a href="https://news.ycombinator.com/item?id=24443128">thread link</a>) | @anuragsoni
<br/>
September 11, 2020 | https://codesync.global/uploads/media/activity_slides/0001/03/f2292f201aa6b04db8c4e0b9cfa191dd07c9ee14.pdf | <a href="https://web.archive.org/web/*/https://codesync.global/uploads/media/activity_slides/0001/03/f2292f201aa6b04db8c4e0b9cfa191dd07c9ee14.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://codesync.global/uploads/media/activity_slides/0001/03/f2292f201aa6b04db8c4e0b9cfa191dd07c9ee14.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24443128</guid>
            <pubDate>Fri, 11 Sep 2020 14:20:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What to Watch on the Weekend as a Designer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24443071">thread link</a>) | @johannesippen
<br/>
September 11, 2020 | https://toolbox.humandeluxe.com/free-netflix-episodes/ | <a href="https://web.archive.org/web/*/https://toolbox.humandeluxe.com/free-netflix-episodes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  



  <p>One of the best documentaries in design is definitely the Netflix production “Abstract” – you know, the one that you never watch because your significant other wants to see The Office instead? Earlier this year, Netflix released the whole thing for free on Youtube.</p>

<p>So, if you have some time on Friday afternoon (or on the weekend), watch these episodes (in this particular order):</p>

<h2 id="architect-bjarke-ingels">Architect Bjarke Ingels</h2>

<p>Architect Bjarke Ingels unites function, fantasy and sustainability in “pragmatic utopian” designs like a clean power plant topped with a ski slope.</p>

<iframe width="560" height="420" src="https://www.youtube.com/embed/rKeFCd1j5BE?color=white&amp;theme=light"></iframe>

<h2 id="illustrator-christoph-niemann">Illustrator Christoph Niemann</h2>

<p>From New Yorker covers to Instagram sketches, illustrator Christoph Niemann plays with abstraction and interactivity – and questions authenticity.</p>

<iframe width="560" height="420" src="https://www.youtube.com/embed/q_k8fVNzbGU?color=white&amp;theme=light"></iframe>

<h2 id="design-legend-paula-scher">Design Legend Paula Scher</h2>

<p>Graphic designer Paula Scher paints with words, developing the visual language of iconic brands and institutions around the world.</p>

<iframe width="560" height="420" src="https://www.youtube.com/embed/LCfBYE97rFk?color=white&amp;theme=light"></iframe>

<h2 id="sneaker-designer-tinker-hatfield">Sneaker Designer Tinker Hatfield</h2>

<p>Tinker Hatfield’s background in architecture and athletics sparked his game-changing shoe designs for Nike, including the iconic Air Jordan series</p>

<iframe width="560" height="420" src="https://www.youtube.com/embed/kaSvGVhtszo?color=white&amp;theme=light"></iframe>

</div></div>]]>
            </description>
            <link>https://toolbox.humandeluxe.com/free-netflix-episodes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24443071</guid>
            <pubDate>Fri, 11 Sep 2020 14:15:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Some Thoughts on Writing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24442975">thread link</a>) | @patwalls
<br/>
September 11, 2020 | https://patwalls.com/some-thoughts-on-writing | <a href="https://web.archive.org/web/*/https://patwalls.com/some-thoughts-on-writing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://patwalls.com/some-thoughts-on-writing</link>
            <guid isPermaLink="false">hacker-news-small-sites-24442975</guid>
            <pubDate>Fri, 11 Sep 2020 14:07:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Testcontainers with Micronaut and Kotest]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24442952">thread link</a>) | @akobor
<br/>
September 11, 2020 | https://akobor.me/posts/using-testcontainers-with-micronaut-and-kotest | <a href="https://web.archive.org/web/*/https://akobor.me/posts/using-testcontainers-with-micronaut-and-kotest">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span><time datetime="2020-09-10T17:35:07.322Z">September 10, 2020</time></span> | <span>6 min read</span></p></div><div><div><div><p>Using real resources (i.e. databases) instead of mocks in your tests can be beneficial in several ways. With <a href="https://www.testcontainers.org/" target="_blank" rel="noreferrer noopener">Testcontainers</a> you can have <strong>ephemeral and lightweight instances that are provisioned and destroyed automatically</strong>, and you can integrate them with your favourite test framework as well. In this article I'll show you how can you make them work with Micronaut and Kotest.</p>
<h2>Mocking or not mocking?</h2>
<p>Mocking external dependencies (databases, cache providers, etc.) in unit tests is an acceptable approach, but when it comes to integration tests, you probably want to make sure  <strong>you have a test environment that is similar to the "real" one</strong>, where your application will run (<em>aka. production</em>).
Instead of mocking, you can use <a href="https://www.h2database.com/html/main.html" target="_blank" rel="noreferrer noopener">H2</a> for databases, which can run as an in-memory database, and it's able to emulate the common engines (MySQL, PostgreSQL, MS SQL etc.) as well. However, while H2 can be useful for simple applications, its compatibility modes have major limitations, so in the long term you are better off with a native solution.</p>
<h2>The actual use case</h2>
<p><strong>In this article we will work with:</strong></p>
<ul>
<li>a JVM application, based on Micronaut 2.x.x</li>
<li>Kotlin</li>
<li>Kotest (previously known as Kotlintest)</li>
<li>Flyway</li>
<li>PostgreSQL</li>
<li>Gradle (6.x.x)</li>
</ul>
<p>Therefore, I assume that you already have the following dependencies in your Micronaut project, they are set up and working properly:</p>
<ul>
<li><code>io.micronaut.sql:micronaut-jdbc-hikari</code></li>
<li><code>io.micronaut.flyway:micronaut-flyway</code></li>
<li><code>io.micronaut.test:micronaut-test-kotest</code></li>
<li><code>io.kotest:kotest-runner-junit5-jvm</code></li>
<li><code>org.postgresql:postgresql</code></li>
</ul>
<h3>What will we achieve?</h3>
<p>At the end of this, we'll have a project, where Kotest will:</p>
<ul>
<li>start a PostgreSQL instance before it runs the actual tests,</li>
<li>clear and recreate the database schema between every test case,</li>
<li>destroy the PostgreSQL instance after all the tests are done</li>
</ul>
<p>Note that starting a database instance for every test run by rule of thumb <strong>can be a huge overhead in certain cases</strong>. For example, when you wouldn't like to run your entire test suite, but only a small unit test that has nothing to do with the database, Testcontainers will still start up and destroy an instance for it. However, when you have a lot of integration tests, you'll see a notable decrease in your test suite's run time with this approach.</p>
<h3>Let's write some code!</h3>
<p>First of all, we have to add Testcontainers as a <code>testImplementation</code> dependency in our <code>build.gradle</code>:</p>
<pre><code>testImplementation(<span>"org.testcontainers:postgresql:1.14.3"</span>)</code></pre>
<p>Then we'll need something that is able to start and stop a Testcontainers instance:</p>
<pre><code><span>package</span> com.example.testutils

<span>import</span> org.testcontainers.containers.PostgreSQLContainer

<span><span>class</span> <span>TestDbContainer</span> : <span>PostgreSQLContainer</span>&lt;<span>TestDbContainer</span>&gt;</span>() {
    <span>companion</span> <span>object</span> {
        <span>private</span> <span>lateinit</span> <span>var</span> instance: TestDbContainer

        <span><span>fun</span> <span>start</span><span>()</span></span> {
            <span>if</span> (!Companion::instance.isInitialized) {
                instance = TestDbContainer()
                instance.dockerImageName = <span>"postgres:12"</span>
                instance.start() 

                
                System.setProperty(<span>"datasources.default.url"</span>, instance.jdbcUrl)
                System.setProperty(<span>"datasources.default.username"</span>, instance.username)
                System.setProperty(<span>"datasources.default.password"</span>, instance.password)
            }
        }

        <span><span>fun</span> <span>stop</span><span>()</span></span> {
            <span>if</span> (Companion::instance.isInitialized) {
                instance.stop()
            }
        }
    }
}</code></pre>
<p>The code above defines a singleton with two methods: <code>start</code> and <code>stop</code>. The former one spins up our Postgres instance, and sets the datasource's properties for Micronaut, while the latter one destroys the container. </p>
<p>We also have to <strong>wire this start/stop logic into Kotest's lifecycle</strong>. This is where the pre-generated <code>ProjectConfig.kt</code> comes in handy:</p>
<pre><code>

<span>package</span> io.micronaut.test.kotest

<span>import</span> com.example.testutils.TestDbContainer
<span>import</span> io.kotest.core.config.AbstractProjectConfig
<span>import</span> io.micronaut.test.extensions.kotest.MicronautKotestExtension

<span>object</span> ProjectConfig : AbstractProjectConfig() {
    <span>override</span> <span><span>fun</span> <span>listeners</span><span>()</span></span> = listOf(MicronautKotestExtension)
    <span>override</span> <span><span>fun</span> <span>extensions</span><span>()</span></span> = listOf(MicronautKotestExtension)

    <span>override</span> <span><span>fun</span> <span>beforeAll</span><span>()</span></span> {
        TestDbContainer.start()
    }

    <span>override</span> <span><span>fun</span> <span>afterAll</span><span>()</span></span> {
        TestDbContainer.stop()
    }
}</code></pre>
<p>As you can see, the only thing we have to do is to call the two methods that we implemented in the previous step, inside Kotest's <code>beforeAll()</code> and <code>afterAll()</code> callbacks.
Since Flyway takes care of the initial schema migration after our Micronaut server starts, we can create a naive test like that:</p>
<pre><code><span>@MicronautTest</span>
<span><span>class</span> <span>ExampleTest</span></span>(<span>private</span> <span>val</span> repository: Repository) : StringSpec({

    <span>"when we insert something into our database, it should exist"</span> {
        repository.insert(value = <span>"something"</span>) 

        repository.findByValue(value = <span>"something"</span>) shouldNotBe <span>null</span> 
    }
})</code></pre>
<p>Assuming that <code>Repository</code> is something that operates on a database, this test will use your Testcontainers instance as its datasource, and will actually end up in <code>INSERT INTO</code> and <code>SELECT</code> queries against it. While the example above should work as expected, we also want to make sure that our test cases are not <em>"leaking"</em>. We speak about a <em>leak</em>, when our test cases are not independent of each other, and one's state can affect others' result. To prevent this issue, we should simply <strong>"erase" and recreate our whole database</strong> after every test case.</p>
<p>But how should we do that? Well, <strong>we will use Flyway</strong> for sure, but injecting it into every test class, and calling it manually after every test case is something that doesn't sound right. A cleaner approach is when we extend one of Kotest's base spec style and implement the necessary teardown logic here. For a <code>StringSpec</code> it would be like that:</p>
<pre><code><span>abstract</span> <span><span>class</span> <span>DatabaseStringSpec</span></span>(body: StringSpec.() -&gt; <span>Unit</span> = {}) : StringSpec(body) {

    <span>@Inject</span>
    <span>lateinit</span> <span>var</span> flyway: Flyway 

    <span>override</span> <span><span>fun</span> <span>afterTest</span><span>(testCase: <span>TestCase</span>, result: <span>TestResult</span>)</span></span> {
        
        flyway.clean()
        flyway.migrate()
    }
}</code></pre>
<p>Now we can rewrite our previous test to extend <code>DatabaseStringSpec</code>, and we can add more cases to it, since they won't leak the database's state anymore:</p>
<pre><code><span>@MicronautTest</span>
<span><span>class</span> <span>ExampleTest</span></span>(<span>private</span> <span>val</span> repository: Repository) : DatabaseStringSpec({

    <span>"when we insert something into our database, it should exist"</span> {
        repository.insert(value = <span>"something"</span>) 

        repository.findByValue(value = <span>"something"</span>) shouldNotBe <span>null</span> 
    }

    <span>"when we don't call insert, the table should be empty"</span> {
        repository.findByValue(value = <span>"something"</span>) shouldBe <span>null</span> 
    }
})</code></pre>
<p><em>You can find a working example of this setup <a href="https://github.com/kuvasz-uptime/kuvasz" target="_blank" rel="noreferrer noopener">in the repository of Kuvasz</a>, which is also my latest pet project.</em></p>
</div></div></div></div>]]>
            </description>
            <link>https://akobor.me/posts/using-testcontainers-with-micronaut-and-kotest</link>
            <guid isPermaLink="false">hacker-news-small-sites-24442952</guid>
            <pubDate>Fri, 11 Sep 2020 14:05:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Toil in Product Development]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24442743">thread link</a>) | @masonhensley
<br/>
September 11, 2020 | https://hipspec.com/toil/ | <a href="https://web.archive.org/web/*/https://hipspec.com/toil/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <main aria-label="Content">
          
          <div>
            <div>
              <article itemscope="" itemtype="http://schema.org/BlogPosting">

  <div itemprop="articleBody">
    <h3 id="quick-definitions">Quick Definitions:</h3>
<ul>
  <li><strong>Toil</strong>: “Toil is the kind of work tied to running a production service that tends to be manual, repetitive, automatable, tactical, devoid of enduring value, and that scales linearly as a service grows.” <a href="https://landing.google.com/sre/sre-book/chapters/eliminating-toil/" target="_blank">Google SRE Book</a></li>
  <li><strong>Product Development</strong>: The process of deciding direction, scoping, building and launching products. For the purpose of this post - software products. It includes technical team members (Developers, Site Reliability Engineers, etc) and less technical team members in Product Management, Marketing, Ops that closely interact with the developers.</li>
</ul>

<h3 id="context">Context</h3>
<p>For a quick bit of background if you haven’t been following the Site Reliability Engineering trends (not a slight, there’s so much to keep track of these days!) - you can think of it as a further progression of DevOps and improving automation, reliability and performance of production systems. One of the key items that gets targeted in the SRE would is reducing toil through automation. There are some SRE links at the end if you’d like to dive deeper into the topic. Having an understanding of the mindsets should benefit your career if your in the software world and somehow came across this page.</p>

<h2 id="actual-post">Actual Post:</h2>

<p>There is an ample amount of “manual, repetitive, automatable, tactical, devoid of enduring value, and that scales linearly” type work that bogs down product development teams. Asana shared in their <a href="https://www.sec.gov/Archives/edgar/data/1477720/000119312520228462/d855753ds1.htm" target="_blank">S-1 filing</a> that <strong>“Today, 60% of knowledge workers’ time is spent on work about work.”</strong> Most individual contributors trudging through this type of work think it’s just a required part of the job. We’ve spoken with product managers that think there’s no other way - <strong>“you just have to put in the hard work”</strong> is something we’ve heard countless times.</p>

<p>Leadership and Management often fall prey to thinking that toiling work is unavoidable - someone has to do it. Some even shield themselves from touching it - perhaps they had to do it previously, and now have the privilage of delegating the work. However, at the end of the day they need information to make strategic decisions. The process isn’t very resilient for the organizations and doesn’t scale well. It’s a never ending cycle that follows the cadence of quick feedback cycles of agile or frequent touch bases for longer term work.</p>

<p>So, what specificly are teams toiling over? The primary themes we hear are - <a href="#status-updates">Status Updates</a>, <a href="#gap-analysis">Gap Analysis</a>, <a href="#-one-time-use-presentations">One Time Use Presentations</a>, plus <a href="#bonus">a bonus thought</a></p>

<h3 id="status-updates">Status Updates</h3>
<ul>
  <li>Within a team</li>
  <li>Up the management chain</li>
  <li>Across the organization to other teams</li>
  <li>Externally to customers</li>
  <li>Externally partners</li>
  <li>Often locked in 1:1 communication. Knowledge does not diffuse well across an organization.</li>
</ul>

<blockquote>
  <p>Manifests itself in Emails, Chat messages, 5 minute meetings that actually last 30 minutes or more. Pulling other team members of task to get an answer. Often not visible to the organization as a whole, but is taxing on many team members.</p>
</blockquote>

<p>The cycle time for answers here is generally the shortest and most distracting. You might receive a status request from the client success or sales team trying make a customer happy. Or the data science team on the hunt for when they will be unblocked by data integration. Or finally, a founder or executive trying to close a big contract. It’s hard for team members to be proactive here and they often get caught off guard.</p>

<h5 id="solution">Solution:</h5>
<p>UPS/FedEx style tracking numbers and links that can be proactively shared with stakeholders that automatically pull data from code repositories, other tooling and deployment environment metadata.</p>

<h3 id="gap-analysis">Gap Analysis</h3>
<ul>
  <li>Do we support X across our Web, iOS and Android Offerings</li>
  <li>How do we stack up against competitor Y in features A, B &amp; C.</li>
  <li>Knowledge typically does not diffuse beyond product management org</li>
</ul>

<blockquote>
  <p>Generally manifests itself in spreadsheets full of project mananagement tool links, red, yellow, green cells and unstructured data.</p>
</blockquote>

<p>Compared to status updates, these requests often grant a little more heads up, but are often much more tedius, laborious and fraught with outdated information and errors. Can also occur ad-hoc from various parts of your organizations - “does the web app support X?”</p>

<h5 id="solution-1">Solution:</h5>
<p>We think teams should label their code bases against structured feature definitions. Doing so would allow teams to query against capabilities in their portfolio.</p>

<h3 id="one-time-use-presentations">One Time use Presentations</h3>
<ul>
  <li>Roadmap presentations &amp; progress against deliverables</li>
  <li>Gap analysis result deep dives</li>
  <li>Sprint review slide shows</li>
</ul>

<blockquote>
  <p>This one depends on the culture of the organization.</p>
</blockquote>

<h5 id="solution-2">Solution:</h5>
<p>Structuring Data for <em>Status Updates</em> and <em>Gap Analysis</em> will help automate the generation of presentations.</p>

<h3 id="bonus">Bonus</h3>

<h3 id="creation-and-updating-of-tasks">Creation and Updating of Tasks</h3>
<ul>
  <li>writing up tickets</li>
  <li>updating status updates between tools</li>
  <li>dragging tickets between swim lanes</li>
  <li>pulling tickets into sprints</li>
</ul>

<h5 id="solution-3">Solution:</h5>
<p>We’re working towards a world where you do not purely update a status for work. Your work should update the status for you. Think about this for a minute - what if you just did the hard work and everything else was automated? The documentation, the status updates, the portfolio gap analysis, the organization of it all.</p>

<h3 id="wrap-up">Wrap Up</h3>
<p>The outputs of these manual exercises are impossible to compare or measure over time against one another.</p>

<p>In 2020, teams shouldn’t be toiling away at quickly outdated or disposable Status Updates, Gap Analysis &amp; Building Presentations. Data should flow from existing sources of truth (the code) which can be merged with other metadata to provide evergreen intelligence to organization. We can automate this.</p>

<p>Particularly over the last 10 years, product development culture has become more agile, and in doing so, less tangible, quantifiable or measurable. Yes, we can track conversion rates and usage cohorts and stats like never before, but there’s no objective measure of functionality existing or not. We’re working to fix that so you can have your cake and eat it too. We want you to spend more time taking to customers and diving deep into real problems, not busy work.</p>

<p>We are scratching the surface of what we think is possible, join us for the adventure. We’d love to hear your thoughts on this, join the discussion in the <a href="https://twitter.com/HipSpec/status/1304413947588739072">Twitter thread</a></p>

<h3 id="sre-reference-links">SRE Reference Links:</h3>
<ul>
  <li><a href="https://landing.google.com/sre/">https://landing.google.com/sre/</a></li>
  <li><a href="https://www.atlassian.com/incident-management/devops/sre">https://www.atlassian.com/incident-management/devops/sre</a></li>
  <li><a href="https://victorops.com/blog/site-reliability-engineer-sre-roles-and-responsibilities">https://victorops.com/blog/site-reliability-engineer-sre-roles-and-responsibilities</a></li>
  <li><a href="https://www.scalyr.com/blog/site-reliability-engineer">https://www.scalyr.com/blog/site-reliability-engineer</a></li>
</ul>

  </div>
</article>

              
            </div>
          </div>
        </main>
      </div>
    </div></div>]]>
            </description>
            <link>https://hipspec.com/toil/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24442743</guid>
            <pubDate>Fri, 11 Sep 2020 13:47:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The lack of namespaces on crates.io is a feature]]>
            </title>
            <description>
<![CDATA[
Score 105 | Comments 164 (<a href="https://news.ycombinator.com/item?id=24442731">thread link</a>) | @LinuxBender
<br/>
September 11, 2020 | https://samsieber.tech/posts/2020/09/registry-structure-influence/ | <a href="https://web.archive.org/web/*/https://samsieber.tech/posts/2020/09/registry-structure-influence/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Rust doesn’t have namespaces in its package management system. It’s often viewed as a bug. But it’s not a bug, it’s a feature! While there are negative aspects of a flat package registry, there are also real benefits. Stability, continuity, and unity (discourages forks and fragmented identity). Proposals that seek to add namespacing without addressing the positive aspects they remove probably won’t be accepted.</p><p>I have noticed the benefits of the current system seem to only get mentioned in passing as objections to proposals and never outlined anywhere. This is an attempt to fix that by summarizing points raised across the various proposals I’ve read. While I don’t represent the crates.io team (I’m not even on the team) I hope to accurately represent trade-offs being considered.</p><h2 id="aspects-of-registry-structure">Aspects of Registry Structure</h2><p>How identity works in package management has far-reaching consequences. Most of the namespace proposals I’ve seen have been motivated by trying to address squatting and/or tweaking the current system of package identity. However, the structure of the crates.io registry affects more than just those areas. But we’ll start with the basics of identity and work from there.</p><h3 id="identity">Identity</h3><p>How do you refer to a package? A crate has at least three identities I can think of:</p><ul><li>The name on crates.io - there is exactly one crate per name</li><li>The name used in Cargo.toml - there is exactly one crate per name</li><li>The default name used in code - there is can be more than one per name, which is rare in practice</li><li>The actual name used in code - this can be controlled through Cargo.toml or externs statements, but renaming isn’t required</li></ul><p>The first two are called the <code>package.name</code> in Cargo.toml of the crate being published. The third can be overridden via <code>lib.name</code> in the package being published. The last is user-controlled. Usually, all of these names match, with the caveat that dashes are underscores in code (and crates.io doesn’t allow two crates with identical crates.io names after normalizing dashes to underscores).</p><p>Arguably, self-explanatory identities have a leg up on other identities from a discoverability perspective. E.g. <code>argparse</code> probably seems more reputable at first glance than <code>clap</code> if you’re going of name alone.</p><p>A flat registry makes identity management (naming a crate) harder. You either have to pick a GUID (haha, please don’t) or some memorable (but probably mostly or completely unrelated) identity. I see this as the main driving force for proposals seeking to add namespaces or otherwise address squatting.</p><h3 id="continuity">Continuity</h3><p>Currently, identity is continuous - a crate’s identity is immutable and that has real benefits. If you want to change the identity system at all you’ve got to ensure that identities don’t change out from under you. This is a strike against any namespace system that allows namespace ownership to unexpectedly change. Discontinuous identity has a couple of issues.</p><p>First, if a crate’s name can change, that’s bad for users. They have to go figure out the new name of the package if they want to update.</p><p>Second, if an identity’s crate can change (a consequence of the previous point if identities are reusable), then you’ve introduced a security vulnerability. Updating to a new package version with different content under different ownership is a real security risk. Doubly so if you don’t ban new minor versions on the last major version after an unintentional ownership change. Should people audit their crate? Yes! But the fewer foot-guns we have the better.</p><p>In addition to preventing security issues, proposals need to encourage transitions over transactions. Gradual moves over all-or-nothing moves. This could be seen more as compatibility than continuity. This drives things like the rust editions and the need for namespace proposals to be backward compatible.</p><h3 id="stability">Stability</h3><p>A core tenet of Rust is stability. The obvious definition is that things that compile yesterday should compile today (even with a new compiler).</p><p>A less obvious definition is that adding new dependencies shouldn’t stop you from compiling already working code. This is a major motivation for the orphan rule (though the orphan rule is more nuanced than that). This is a strike against schemes that encourage multiple distinct crates to have the same default name in code. I don’t think any proposal that encourages this could be approved. It also suggests that we ought to ban new instances of a crates default code name deviating from its package/Cargo.toml name.</p><p>In addition to code stability, crates.io should be stable too. It should be able to isolate itself from outside services. It currently depends on Github, but it doesn’t have to. This is a strike against any system that weds namespace identity to any externally managed system.</p><h3 id="squatting">Squatting</h3><p>The current identity system encourages squatting. I would define squatting as reserving a crate without actually using it. This is a natural outcome in the Rust ecosystem for a couple of reasons:</p><ul><li>Crates are easy to publish, so it’s easy to reserve a crate by publishing an empty crate</li><li>We have de-facto namespaces using prefixes - <code>serde-*</code> is one example.</li><li>There can only ever be one version of a package name. There is only one <code>http</code> crate for example. So package names are a scarce resource.</li></ul><p>There’s a lot of squatting on crates.io. I don’t have any hard numbers though.</p><p>We don’t have any structured support for squatting either, which makes it hard to separate bad actors from good actors. I think separating them out would require manual intervention, and the crates.io team is small and doesn’t have a lot of time to put towards that.</p><p>So what’s a bad actor? I consider someone who squats a bunch of crates to make or point or prevent their names from being used to be a bad actor. Crates.io has a policy against using automation to claim ownership of crates, but I haven’t heard much about it being enforced. Again, time is an issue. And this would probably extend to namespace ownership as well.</p><p>I do think there are legitimate uses. Reserving a set of extension crates for a project you’re working on is one example. My other example is reserving a crate you genuinely intend to work on (this one is a little more debatable).</p><h2 id="it-s-about-the-trade-offs">It’s about the Trade-offs</h2><p>With this system in mind, it’s hard to come up with a namespace proposal that doesn’t hurt the current system in some way.</p><p>I’d say the biggest tension is in code-level identities. They become either overlapping by chopping the namespace portion off or much longer by including the namespace portion. The previous points show why overlapping is generally considered a non-starter. And for longer identities, you need to come up with some new way to reference namespaces in code that’s doesn’t break things.</p><p>More to the point though, from what I’ve seen, most people proposing identity schemes propose it so that the ecosystem can support the overlapping crate identities (e.g. multiple http crates). And that’s exactly what the current system avoids doing.</p><p>Here’s <a href="https://github.com/rust-lang/rfcs/pull/2978#issuecomment-686823633">an on-point quote from CAD97</a> summing up (hopefully fairly accurately) what namespaces mean to the parties involved:</p><blockquote><p>To the crates team, it seems to <em>primarily</em> mean that a project can put multiple packages together under an umbrella, such that you know the packages are for-sure by the project.</p><p>To the people who feel most slighted by the crates team’s approach here, namespaces <em>primarily</em> mean the ability to publish a crate with a desired name even if there’s already a package published that provides a crate with that name, by putting the package into a different namespace such that the names do not clash.</p><p>If the latter party asks about “namespaces” and means the latter, and the team answers and means the former, you can see where the miscommunication enters, especially since the crates team has now communicated here the position that <em>generally</em>, the <code>package.name == lib.name</code> falsehood should not be made more false; i.e., the latter group’s goal is an explicitly non-desired property from the crates team.</p></blockquote><h2 id="where-to-now">Where to Now?</h2><p>There have been other proposals for namespaces that are less about overlapping identity and more about curation and grouping related crates together. There are multiple proposals there, each with their trade-offs. Expect a follow-up post discussing some of those.</p><h2 id="appendix-a-highlights">Appendix A: Highlights</h2><p>There’s a nice set of a dozen or so comments I save as I reviewed past discussions:</p><p>Carol10Cents (of the crates.io team):</p><ul><li><a href="https://users.rust-lang.org/t/cargo-problems-namespacing/2085/11">https://users.rust-lang.org/t/cargo-problems-namespacing/2085/11</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/20">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/20</a></li></ul><p>kornel:</p><ul><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/26">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/26</a></li></ul><p>sgrif (on the crates.io team):</p><ul><li><a href="https://internals.rust-lang.org/t/namespacing-on-crates-io/8571/39">https://internals.rust-lang.org/t/namespacing-on-crates-io/8571/39</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/5">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/5</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/7">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/7</a></li></ul><p>CAD97:</p><ul><li><a href="https://internals.rust-lang.org/t/namespacing-on-crates-io/8571/57">https://internals.rust-lang.org/t/namespacing-on-crates-io/8571/57</a></li><li><a href="https://github.com/rust-lang/rfcs/pull/2978#issuecomment-686823633">https://github.com/rust-lang/rfcs/pull/2978#issuecomment-686823633</a></li></ul><p>withoutboats (on the crates.io team):</p><ul><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/10">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/10</a></li></ul><p>ag_dubs (on the crates.io team):</p><ul><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/27">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/27</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/28">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/28</a></li></ul><p>pietroalbini (on the crates.io team):</p><ul><li><a href="https://github.com/rust-lang/rfcs/pull/2978#issuecomment-683424791">https://github.com/rust-lang/rfcs/pull/2978#issuecomment-683424791</a></li></ul><p>Random meeting notes:</p><ul><li><a href="https://paper.dropbox.com/doc/All-hands-Crate-grouping-Namespacing-discussion-NEpWAaDdNuUheLpawETYT">https://paper.dropbox.com/doc/All-hands-Crate-grouping-Namespacing-discussion-NEpWAaDdNuUheLpawETYT</a></li></ul><h2 id="appendix-b-previous-discussions">Appendix B: Previous Discussions</h2><p>There have been several attempts at this:</p><ul><li><a href="https://internals.rust-lang.org/t/namespacing-on-crates-io/8571">https://internals.rust-lang.org/t/namespacing-on-crates-io/8571</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-domains-as-namespaces/8688">https://internals.rust-lang.org/t/pre-rfc-domains-as-namespaces/8688</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628</a></li><li><a href="https://internals.rust-lang.org/t/scoped-packages-like-in-npm/10223/3">https://internals.rust-lang.org/t/scoped-packages-like-in-npm/10223/3</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-idea-cratespaces-crates-as-namespace-take-2-or-3/11320">https://internals.rust-lang.org/t/pre-rfc-idea-cratespaces-crates-as-namespace-take-2-or-3/11320</a> (This was mine from last year after reading through the other proposals; my …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://samsieber.tech/posts/2020/09/registry-structure-influence/">https://samsieber.tech/posts/2020/09/registry-structure-influence/</a></em></p>]]>
            </description>
            <link>https://samsieber.tech/posts/2020/09/registry-structure-influence/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24442731</guid>
            <pubDate>Fri, 11 Sep 2020 13:46:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Design Patterns – Those That Help and Those That Don't]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24442646">thread link</a>) | @kondov
<br/>
September 11, 2020 | https://alexkondov.com/why-do-we-use-design-patterns/ | <a href="https://web.archive.org/web/*/https://alexkondov.com/why-do-we-use-design-patterns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>You probably follow certain principles in your life. Maybe you don’t drink coffee after 5pm or avoid sugary drinks. Maybe you don’t do risky investments or you don’t want to live on the first floor.</p>
<p>We all have certain general rules that we follow. So when we’re in a situation we can make quick decisions based on them instead of considering the problem from the ground up. When someone asks you if you’d like coffee after dinner you know the answer. When a friend is telling you about her new risky business venture you know that you won’t be investing.</p>
<p>We accept our principles as guiding rules when facing a challenge. Design patterns are similar to that but for software architecture. They are principles to follow so we won’t have to approach each situation like it was new. They are widely accepted and formalized solutions to common problems. A design pattern solves a specific programming challenge related to structure, usability or maintainability.</p>
<p>When engineers are faced with the same challenges over and over again, effective solutions will be created. Those solutions will then be named and given guidelines on how to use them properly. This solidifies it as a pattern that is proven to work well.</p>
<p>You can’t know the implementation of all design patterns by heart. But you can be aware of their existence and the problems they solve. That way you can build up intuition on when to use them or recognize them when you find them in the wild.</p>
<h2>Beyond Principles</h2>
<p>Let’s consider two more examples in the software engineering world - memoization and caching. They solve problems with repetitive computing operations and frequently accessed data. If we have an answer ready, we needn’t to the work to get to it again.</p>
<p>A design pattern is like accessing a complete solution for your problem. When an established pattern can solve the problem we’re facing it makes sense to apply it instead of developing something on our own.</p>
<p>The same approach is used in architecture and mechanics. When faced with similar problems, software engineers often reach similar solutions. At the time GraphQL was being created at Facebook, the engineers at the Washington Post were developing a similar technology. Design patterns don’t get established by an entity. They get formalized because many programmers have come to the same successful solution.</p>
<h2>When do you apply a design pattern?</h2>
<p>We should recognize when a design pattern is a good solution but we shouldn’t be actively leaning towards them in all cases.</p>
<p>Design patterns are not meant to be applied to the letter, they are general solutions. Some of them are widely applicable no matter the business domain. The Observer design pattern could find an application in each application that needs to notify different components of an event. Others are more specific and they apply to a tighter scope of problems.</p>
<p>How do you know when to use one, though? An established pattern should be used only when it’s obvious to do so. We shouldn’t try to fit a problem to a solution. If it’s too specific, forcing it to a stock solution won’t produce a good result. The patterns are principles and it should be clear when they can be applied.</p>
<p>An example is the MVC (Model-View-Controller) pattern that is commonly used to build web applications. It’s a good general solution and in most cases you won’t be wrong if you use it. It makes code better organized and it’s quite popular so most engineers understand it well.</p>
<p>But this doesn’t mean that every web application should be built on top of an MVC architecture. A small application could be deployed as a set of simple lambda functions - no need of serious structure. A REST API could be structured around the domain entities that it works on. An application built on top of DynamoDB would probably use a repository instead of models due to the way the database works.</p>
<h2>Easily Recognized</h2>
<p>The great benefit of using established patterns is that they’re easily recognized. When you open a project and you see familiar naming and structure you will find your way much faster. Even if you don’t know the domain well, being aware of the principles will help you navigate the code.</p>
<p>Let’s use the MVC example again. Imagine that you have some experience with a framework such as Rails. If you have to work on a Laravel project you won’t have much trouble even though it’s written in another language. You know that controllers handle http requests and that models represent the domain entities. If you need to do some work in the UI you will look for the views. The principles are the same even if the technology is different.</p>
<p>When you are discussing architecture with your colleague you can address the design pattern by its name. Most engineers would understand you or at least know what to look up. There’s plenty of information about them and its widely accessible.</p>
<h2>Anti-patterns</h2>
<p>Design patterns are good and proven solutions. And then there are anti-patterns - the exact opposite. They are frequently occurring but are undesirable and considered bad programming practices because they don’t produce desirable effects.</p>
<p>An anti-pattern is a practice that leads to more problems instead of solutions. Much like their positive counterpart - they start forming as principles. A solution to use whenever you face a certain problem. But with time the solution has proven to be troublesome. When many developers using the same software design principles see problems with it, it starts classifying as an anti-pattern.</p>
<p>Take the God Object anti-pattern for example. This is a class that knows too much or does too many things. Instead of separating the functionality in many small classes or functions, we have put it in a single “all-knowing” object. It maintains most of the data that the app needs and provides the methods for its manipulation.</p>
<p>This is a pattern that has proven to cause more harm than good. Instead of having multiple components communicating to each other, such programs are tightly coupled to the God Object. A single change to it can have unintended consequences across the whole application.</p>
<p>The reasons to label a technique as an anti-pattern vary. It may make code hard to maintain, read, scale or extend. The bottom line is that they have more negative than desirable effects. So, while we shouldn’t be forcing design patterns, we should be active avoiding anti-patterns.</p>
<p>When we find that we’re using a technique widely considered harmful we should reevaluate our decisions and consider different approaches.</p>
<h2>Summary</h2>
<ul>
<li>Design patterns are like principles, general rules that have proven to work well</li>
<li>When faced with frequently occurring problem we can follow those rules and patterns instead of solving the problem from scratch</li>
<li>Design patterns are established, understood and easily recognized software practices</li>
<li>We should be aiming to recognize when an existing pattern is applicable to our problem. But we shouldn’t be forcing one when it’s not the obvious solution.</li>
<li>Anti-patterns are the opposite - they are frequently occurring practices that have proven to cause more harm than good. We should be actively avoiding them.</li>
</ul></div></div>]]>
            </description>
            <link>https://alexkondov.com/why-do-we-use-design-patterns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24442646</guid>
            <pubDate>Fri, 11 Sep 2020 13:38:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The jazz singer’s mind shows us how to improvise through life itself]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24442570">thread link</a>) | @joubert
<br/>
September 11, 2020 | https://psyche.co/ideas/the-jazz-singers-mind-shows-us-how-to-improvise-through-life-itself | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/the-jazz-singers-mind-shows-us-how-to-improvise-through-life-itself">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>At one point</strong> during the aptly titled opening song â€˜Feed the Fireâ€™ at the 1993 Hamburg Jazz Festival, the improvising singer <em>par excellence</em> Betty Carter went to sing a line but the audience heard nothing â€“ her microphone lead had dropped out of its socket. Where others might have stumbled, Carter magically weaved the equipment malfunction into a memorable and joyous moment. Without missing a beat, she raised her arms in the air, danced in a circle, reinserted the lead, and picked up where she left off with a quick-fire improvised line and a wry laugh â€“ all the while, composing new music. For much of the performance, Carter was like a preacher moved by the spirit, singing an improvised language beyond literal meaning but that carried the weight and wonder of other worlds.</p>
<p>How do singers such as Betty Carter take command of the present moment, seemingly bending reality to their will? While more romantic notions of creativity might point to Carter, and others like her, being â€˜touched by the spiritâ€™, there are less lofty explanations related to the physical dimension of making music with the human body, as well as the singerâ€™s skilful musical interplay with the other musicians and the audience. There are also complex cognitive and psychological processes that drive the â€˜real-timeâ€™ spontaneous creation of music.</p>
<p>A greater appreciation of these factors has implications beyond jazz, for how we all live our lives, moment to moment. Much of our everyday lives is improvised. For example, aside from stressful situations that require a script in advance, nearly every conversation you have is a spontaneous creation conducted without preparation.</p>
<p>For jazz singers, of course, it all starts with the voice â€“ arguably the first musical instrument. When Carter improvises, she uses her voice to convey not only song lyrics, but also to generate unintelligible yet inherently musical improvisations, often in response to the other musicians, the environment, as well as her own bodily and emotional states (sometimes this is referred to as â€˜scat singingâ€™, though this term is falling out of favour).</p>
<p>At the most fundamental level, improvised jazz singing is a neurophysiological process. Carter creates musical sound using her lungs as a power source and her larynx as a sound generator, in combination with the resonant properties of the vocal tract. When her brain perceives a pitch or note, the breathing apparatus and the intrinsic muscles of the larynx move in a coordinated and sophisticated response. The vocal folds open and close to â€˜chop upâ€™ the pressurised airflow from the lungs. The length, mass and stiffness of the vocal folds contribute to creating the â€˜fundamental frequencyâ€™ of the sound, which we the audience perceive as pitch. For some perspective on the miraculous nature of this process, consider that the vocal folds must open and close 440 times <em>per second</em> to create the single musical note A440 Hz â€“ used as the standard for A above middle C<em>.</em> In turn, these sound waves are resounded and articulated by the <a href="https://dood.al/pinktrombone/">malleable vocal tract</a> to create vowels, consonants and tone colours, which we perceive as sung pitches and language.</p>
<p>From the first coos of mother to baby to the musical creations of Betty Carter, improvisation is pervasive in human experience</p>
<p>In addition to the complex neurophysiology of phonation, there are cognitive and psychological processes involved in the spontaneous creation of music. When researchers <a href="https://journals.plos.org/plosone/article/file?type=printable&amp;id=10.1371/journal.pone.0001679">scanned</a> the brains of jazz pianists improvising (as compared to when they performed learned sequences), they saw consistent and unique patterns of brain activation and deactivation. This activity likely reflects the distinct cognitive processes involved in improvisation, in particular the way that the musician must overcome the limitations of the brainâ€™s processing capacity when faced with limitless possibilities. Musicians do this by building a vast conceptual knowledge base over time that â€˜feedsâ€™ improvisation, as well as developing finely attuned motor skills and the ability to use feedback instantaneously during improvisation.</p>
<p>The same cognitive processes are likely to be involved in the musical sophistication of a singer like Carter. However, she was not a â€˜brain in a vatâ€™ when she improvised. To fully explain vocal improvisation, the physical fact of her body as a container for her voice demands that we also pay some attention to the body.</p>
<p><strong>Theoretical and empirical</strong> advances in embodied cognition lend support to the notion that the body is more involved in improvisation than purely â€˜information processingâ€™ <a href="https://aeon.co/essays/your-brain-does-not-process-information-and-it-is-not-a-computer">theories</a> suggest. The embodiment hypothesis views the body as playing a constitutive role in human cognition, contending that we understand and know the world, not just as mental representations in the brain, but through bodily experience. Performances by singers such as Carter, in which the music literally originates in the body, support a deeper investigation into the bodyâ€™s role, not just in improvisation, but in cognition more broadly.</p>
<p>I recently <a href="https://journals.sagepub.com/doi/full/10.1177/0305735619899137">interviewed</a> professional jazz singers about what itâ€™s like to improvise, and their accounts also point towards a level of total bodily engagement beyond phonation and cognitive processing. They described being in a flow state during improvisation, experiencing a merging of action and awareness, a sense of control and focused concentration, losing track of time and a loss of self-consciousness. They saw this experience as a meaningful part of their lives because their complete absorption in the music made them feel a part of something â€˜bigger than themselvesâ€™. This chimes with findings within positive psychology where flow is directly implicated in eudaimonia â€“ a sense of happiness and human flourishing.</p>
<p>The singers I interviewed also described improvised music as, metaphorically, â€˜flowingâ€™. They likened improvisation to travelling on a journey to a specific location (you have to â€˜let goâ€™ and â€˜get into the zoneâ€™), and to bodily movement (you â€˜sort of swing through the trees and â€¦ no-one fallsâ€™). One singer described her body as a â€˜vesselâ€™ for the music to â€˜flow throughâ€™. These metaphors point towards a deep level of embodiment during improvisation and flow, and further implicate the body in improvisatory <a href="https://mtosmt.org/issues/mto.16.22.4/mto.16.22.4.goldman.html">ways of knowing.</a></p>
<p>My own ongoing work, and that of others, to unravel the mysteries of musical improvisation has implications for our understanding of everyday life. From the first coos of mother to baby, to our next conversational utterance, to the sophisticated improvised musical creations of Betty Carter, improvisation is pervasive in human experience. What can we learn from the improvising jazz singer and how might we apply these lessons to live a more creative and fulfilling life?</p>
<p>In their <a href="https://global.oup.com/academic/product/the-art-of-becoming-9780190840914?cc=au&amp;lang=en&amp;">book</a> <em>The Art of Becoming</em> (2020), the Scottish musicians and psychologists Raymond MacDonald and Graeme Wilson place improvisation at the heart of the human experience. They argue that improvising experiences Â­â€“ both musical and non-musical â€“ shape our identity and our place in the world. We become who we are by how we improvise moment to moment, day to day, year to year. Our identity is the accumulation of these improvised moments. These experiences are housed, felt, endured and enjoyed in our minds and our bodies. Improvising jazz singers show us that deep embodiment of the present moment can transform the mundane into the transcendent. The ability to improvise, to respond with our whole being to each moment creatively, intuitively and joyfully â€“ just like Betty Carter â€“ is the art of becoming fully human.</p></div></div></div>]]>
            </description>
            <link>https://psyche.co/ideas/the-jazz-singers-mind-shows-us-how-to-improvise-through-life-itself</link>
            <guid isPermaLink="false">hacker-news-small-sites-24442570</guid>
            <pubDate>Fri, 11 Sep 2020 13:31:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modern Ruby Serializers]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24442337">thread link</a>) | @todsacerdoti
<br/>
September 11, 2020 | https://vasilakisfil.social/blog/2020/01/20/modern-ruby-serializers/ | <a href="https://web.archive.org/web/*/https://vasilakisfil.social/blog/2020/01/20/modern-ruby-serializers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          <p>Long time no see!
This time I would like to write about a library I was working about a couple years ago,
a serializers library in Ruby.
I have actually finished it about a year ago and I always wanted to create this blog post
but last year has been super busy for me so never got the chance to present it properly :)</p>



<p>But first I would like to talk about serializers in Ruby from a historical perspective :)</p>

<h3>Ruby serializers in 2013-2014</h3>

<p>Back in 2014, when I started working with APIs, go-to library for serializing Ruby
classes was <a href="https://github.com/rails-api/active_model_serializers">ActiveModelSerializers</a>, the newly published 0.9.x version.
Back then, with this awesome library we were building basic GraphQL-like structures, before
GraphQL was even announced! It was a joy working with a such powerful tool
where the client could specify which fields it needs from a specific resource but also
which relations.
You could inject exactly what you needed when you were actually rendering the serializer
which meant that you could take a union of client’s desired fields/associations,
the default fields/associations (if client’s input was empty), and what client was allowed to access.
The result was a super flexible API.</p>

<p>Apart from AMS, there was <a href="https://github.com/ismasan/oat">Oat</a> a pretty nice little library which supported
out of the box <a href="http://stateless.co/hal_specification.html">HAL</a>, <a href="https://github.com/kevinswiber/siren">Siren</a> and <a href="https://jsonapi.org/">JSON:API</a>, and <a href="https://github.com/rails/jbuilder">jbuilder</a> which for some
reason felt like Godzilla to me at that point, but to be honest it’s a completely proper way of
building hypermedia APIs in Ruby since you can do a lot of cool stuff with caching.
However the catch is that you can’t create reusable adapters, basically it’s like
Rails views, everything needs to be implemented from scratch.</p>

<h3>Ruby serializers in 2015-2016</h3>

<p>Going forward, in 2015, the AMS rewrite had already begun since 2014 for the
0.10.x version. For various reasons, in the company I was working at that time, it was decided
to go with the 0.10.x and of course we completely regretted it. At that point it was 0.10.RC4 that we
were using, just 1 RC release before the 0.10.0. Now you can tell me, “of course
what do you expect? You were using an RC version” and you might be right. Only that the frustration
didn’t come from things that weren’t polished 100%.
I would be fine with that and I was eager to help out.
The frustration came from the fact that the architecture was a completely different beast
from 0.9 and 0.8 versions, everything were different, code and (the sparse) documentation.
And I am saying this because I <a href="https://github.com/rails-api/active_model_serializers/issues?utf8=%E2%9C%93&amp;q=author%3Avasilakisfil">did try</a> to help out sending pull requests, and the more
I was working with the code, the more frustrated I got.</p>

<p>Here are some things that come to my mind:</p>

<ul>
<li>both 0.8/0.9 and 0.10.x are using the same repo, although they share completely different
API/code, making things extremely confusing from a API developer perspective, but also
very difficult to manage as well from a contributor’s perspective</li>
<li>super complex overall architecture</li>
<li>the gem made JSON:API as first citizen. That’s inflexible to build adapters for different
specs and has affected pretty much everything in the code.
The previous versions were using the AMS API style (mostly json with some very basic patterns). 0.10.x version
also supported that style but the code for that was like a completely different
branch inside the code (not sure if it’s still like that but I guess it is).
I understand that JSON:API is a quite popular spec, but tight the whole generic library to that
spec is a bad design, I think.</li>
<li>too many dependencies (requires ActiveSupport..)</li>
<li>tightly coupled to ActiveRecord (at least at that time, not sure if now has changed..)</li>
<li>caching was implemented in the same library. I really thing that’s a completely different concern..</li>
<li>some parts did not match the Ruby coding style (like include: ‘a,string,of,resources’, default_includes ‘**’)</li>
<li>maintainers were reluctant to merge pull requests, because even in the Github issues was an extreme
confusion of what’s implemented, what’s missing, what bugs exists etc</li>
</ul>

<p>In one word <strong>it was a failure</strong>. Like, imagine the most popular Serializers gem in Ruby,
Rails team <a href="https://medium.com/@joaomdmoura/the-future-of-ams-e5f9047ca7e9">was pushing them</a> to finish in-time before the release of Rails 5 so they can include
it in the same release (although completely different gem, I guess they would make a note about it),
maintainers were struggling to make this happen and of course it didn’t.</p>

<p>Now I should also pause a bit and say that <strong>I have nothing against the commiters/maintainers</strong>.
They definitely <strong>did their best, and the problem wasn’t lying there</strong>.
It’s just that sometimes Open Source projects fail.
And in my experience they fail, when there isn’t a very tight core team that has the same vision,
coding style and are gatekeepers in pull requests, until the library has proved itself.
Then, any new pull request will probably respect the existing code and won’t challenge it.
Merging code will be much easier, at that point.</p>

<p>Instead with AMS, <strong>different people started the rework, different people took over
and did their best to finish it</strong>, and for the whole time, various people were sending pull
requests for various features and bugs, of course to help out, but what happened
was a very complex architecture with no clear design and vision.
Actually it would be a great idea to take some interviews by the project contributors at that time.
I think they will have some insights to contribute regarding to what happened :)</p>

<p>During my frustration with AMS I always wondered: how difficult can it be to
build a feature-complete Ruby Serializers ? Well, it turned out to be a bit more complex
than I initially thought. <strong>Way more complex</strong> :)</p>

<h3>Ruby serializers in  2017-2018</h3>

<p>I guess I wasn’t the one who was a bit frustrated with AMS.
<a href="https://github.com/beauby">beauby</a>, an AMS core member went off and created a JSON:API specific serializers gem,
the <a href="https://github.com/jsonapi-rb">jsonapi-rb</a>.
It follows spec pretty well and should be fine using it.
It’s also dependency free.</p>

<p>On the other hand, a year later (2018) Netflix came over and published <a href="https://github.com/Netflix/fast_jsonapi">their own
JSON:API serializers gem</a> which is extremely fast to be honest.
Like <strong>SUPER FAST</strong>.
Unfortunately it requires ActiveSupport as a dependency (not sure why, earlier releases didn’t)
and that could be a bummer for some applications.
Also it might not be as flexible as AMS or jsonapi-rb (although latest releases have
closed the gap A LOT), but in my experience it’s flexible enough that you will
almost never need to look for something else.</p>

<h3>Ruby serializers today</h3>

<p>Today, if someone asked me which Serializers gem should I use, I would tell him/her
go for the <a href="https://github.com/Netflix/fast_jsonapi">fast_jsonapi</a> gem. It’s super fast, it supports a quite popular API
spec and you must have a really good reason to not use it.</p>

<p>Personally, <strong>I am a bit against of having links inside the response</strong>, treating the
client as plain stupid. That’s one of the reasons why I don’t like JSON:API.
I think it’s just too verbose.
(The other reason is the naming: they picked up the 2 most popular words regarding APIs,
<em>JSON</em> and <em>API</em>, glued them together and made the name, feels so much cheating..)
I like to load off some work to the client using introspective
methods. I have talked <a href="https://introspected.rest/">about it</a> some time ago.
But if anyone came and asked me what I would suggest for a brand new API, my
answer would be pretty straightforward: <strong>JSON:API, unless you have good reasons
not to</strong>.</p>

<p>It’s the more experienced API designers that might want to implement something more
versatile and more advanced, tailored to a specific use case.
Or might want to experiment a bit.
For instance, another cool API spec that’s in the same philosophy as JSON:API is
<a href="https://ionspec.org/">Ion</a>.
Not as popular as JSON:API but worth checking it out!
Problem is that when you need to implement something different from JSON:API,
in Ruby you don’t really have much options. Well you have, it’s AMS but it will
be pain in the ass to create a custom serializer from that one.
And it will be painstakingly slow.
And you can’t have more advanced concepts, like forms, relations on collections
etc.
Or you could use <a href="https://github.com/rails/jbuilder">jbuilder</a>, but the problem with jbuilder is that it can’t
have the notion of adapters, hence you always need to build the final result
from scratch. Not fun.</p>

<h3>SimpleAMS: Modern Ruby Serializers</h3>

<p>When I started working on the prototype of SimpleAMS, I set a couple of goals.</p>

<ul>
<li>I wanted the library to be super simple, easy to use with injectable API and clean code.
Have you seen <a href="https://github.com/varvet/pundit">pundit</a>? I want a pundit for serializing.</li>
<li>One of the things that I sometimes don’t like in Ruby coding style, is the level of assumptions that the
code makes on behalf of you.
It had been a quite common pattern in Ruby/Rails that lead to many confusion of what
exactly the API is while at the same time such patterns reduce the flexibility.
The code is trying to act smart, but the drawbacks of such smartness overweight the gains.
I feel some basic assumptions which can be overridden at anytime is the ideal.
Embracing clean, explicit code is what I want, so that you can understand what’s happening instantly.</li>
<li>I wanted to create a generic abstraction as a first class citizen. From there
you should be able to implement any serializer needed, but that abstraction should be
powerful enough to cover even the most extreme corner cases.
After all, it’s tough to beat <a href="https://github.com/Netflix/fast_jsonapi">fast_jsonapi</a>, that’s shouldn’t be my goal ;)</li>
<li>I wanted super clean code, no smarty complex meta thingies inside the code.
I also wanted expected behavior on the internals and how it works when someone
started looking in the codebase.
Of course except the <a href="https://github.com/vasilakisfil/SimpleAMS/blob/master/lib/simple_ams/dsl.rb">DSL part</a>, which uses some advanced Ruby metaprogramming concepts,
but that’s necessary if we want it to work with just an <code>include</code>.</li>
<li>Much faster than AMS, it’s well known that AMS is quite slow so that should be easy :)</li>
</ul>

<h3>The API</h3>

<p>Before starting on any new project, I like to put my imagination and come up
with a useful API and use cases.
Being in god mode, and leaving all the constraints on the side, you can come up with
some really cool APIs.</p>

<h4>DSL based API</h4>

<p>So how would you use a serializers library in Ruby?
I want to avoid any inheritance in order to use SimpleAMS,
because …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vasilakisfil.social/blog/2020/01/20/modern-ruby-serializers/">https://vasilakisfil.social/blog/2020/01/20/modern-ruby-serializers/</a></em></p>]]>
            </description>
            <link>https://vasilakisfil.social/blog/2020/01/20/modern-ruby-serializers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24442337</guid>
            <pubDate>Fri, 11 Sep 2020 13:08:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[7 Reasons Your Growth Startup Is Hiring Too Junior]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24442303">thread link</a>) | @svmanager
<br/>
September 11, 2020 | https://staysaasy.com/management/2020/09/11/Hiring-Too-Junior.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/management/2020/09/11/Hiring-Too-Junior.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Growth startups often find themselves lacking senior team members as they scale. The problems that arise from this are plentiful, including things like:</p>
<ul>
  <li>Requiring heroics to fix things</li>
  <li>Penalizing junior team members for failure to meet responsibilities well above their pay grade.</li>
  <li>Building technology that doesn’t scale</li>
</ul>

<p>Here’s some reasons why companies get into this situation.</p>

<h2 id="reason-1-habit">Reason 1: Habit</h2>

<p>When you’re a tiny startup budgets are extremely lean and products don’t have a lot of users. In that environment companies often prioritize breadth of functionality (see what works) and getting that via several (more affordable) junior team members guided by a smaller group of senior team members.</p>

<p>Problems arise if that strategy exists past market fit. The add-a-junior-to-do-more strategy implodes as the team grows too large for the senior staff to manage closely and the technical challenges start to look more daunting.</p>

<h2 id="reason-2-hubris">Reason 2: Hubris</h2>

<p>Sometimes people recognize the problems are getting more difficult but still don’t hire more seniors. This can often be chalked up to hubris - surely I can just direct a bunch of juniors to execute on the genius solutions I come up with for all our problems. The problem here is that you’re not a genius and even if you were that strategy doesn’t scale.</p>

<h2 id="reason-3-fear">Reason 3: Fear</h2>

<p>The flip side of hubris is fear. New senior staff can look like a threat to the power of existing senior staff. You might have to choose between doing what’s right for the company and retaining certain kinds of power. The answer there is simple - it’s better to be part of something great than the owner of something that fails.</p>

<p>A different play on this theme is junior teammates fearing that new senior teammates will take away some of their opportunities. It’s possible, sure. But more often the opportunities they will take over are the ones juniors would have had trouble succeeding in.</p>

<p>In a growing company with reasonably difficult challenges, good seniors will do more to expand the set of opportunities than shrink them. And good senior talent will help juniors via mentorship and guidance.</p>

<h2 id="reason-4-money-issues">Reason 4: Money Issues</h2>

<p>Money issues play out in a couple ways.</p>

<p>First, the cost of senior talent can subconsciously make you concerned about the remaining budget for yourself. I haven’t seen this played out directly and blatantly, but it’s another version of the fear game - assuming compensation is a zero sum game leads to weird incentives.</p>

<p>Second, it’s easy to think 2 juniors are better than one senior. As you read about the myth of the 10x engineer you might find yourself thinking this way. Let’s talk more about how this is a misconception in reason 5…</p>

<h2 id="reason-5-miscalculation-of-necessary-skills-for-right-now">Reason 5: Miscalculation of Necessary Skills For Right Now</h2>

<p>As referenced earlier, problems get much harder when you add significant growth to a platform. It’s not uncommon to underestimate the challenges at hand. In reality, even simple products at massive scale need significant senior leadership to ensure they are being built and operated effectively. Trying to replace the leadership of senior talent with a volume of junior talent is a sure-fire way to screw this up.</p>

<h2 id="reason-6-miscalculation-of-necessary-skills-in-the-future">Reason 6: Miscalculation of Necessary Skills In the Future</h2>

<p>To make things more difficult, you don’t just have to hire for right now, you have to hire for 2 or more years in the future. The senior talent you hire now must seed the leadership ranks you need in the future. Especially in product and engineering, you can’t just hire everyone you need when you need them. For starters, the job market would laugh at that sort of just-in-time attempt at hiring. But also, these roles require much more detailed understanding of the systems at play, so you need to have people with intimate knowledge developed in advance.</p>

<p>Think of it this way - look at whatever company you’re trying to be like in 5 years. Look at their team. If you don’t start hiring towards something like that team sooner rather than later you’ll never be that company.</p>

<h2 id="reason-7-arguments-about-what-seniors-need">Reason 7: Arguments About What-Seniors-Need</h2>

<p>Another reason people hire too junior is thinking around senior talent needing explicit areas of responsibility that don’t overlap. This is the “one alpha” theory - that senior talent can’t collaborate productively and need their own pack. There might be some nuggets of truth here, but most of it is nonsense. That’s like NASA saying they couldn’t have smart people work together on getting to the moon because these great scientists need their own domains.</p>

<p>Ultimately you have to look at the problems you’re solving. If they are truly challenging they can support a number of seniors. If they aren’t you’ll probably have trouble hiring and retaining more than a few.</p>

<h2 id="conclusion">Conclusion</h2>

<p>There’s a lot of reasons why you might hire too junior as your company grows. Know them and hire intentionally.</p>


    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/management/2020/09/11/Hiring-Too-Junior.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24442303</guid>
            <pubDate>Fri, 11 Sep 2020 13:03:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Octo – Generate a serverless API from an SQL query]]>
            </title>
            <description>
<![CDATA[
Score 221 | Comments 57 (<a href="https://news.ycombinator.com/item?id=24442294">thread link</a>) | @khalidlafi
<br/>
September 11, 2020 | https://octoproject.github.io/octo-cli/ | <a href="https://web.archive.org/web/*/https://octoproject.github.io/octo-cli/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <a href="" title=" ">
    <img src="https://octoproject.github.io/octo-cli/assets/cover.png" alt=" ">
  </a>
  <br>
  <h4>Expose data from any database as web service.</h4>
  <p>
    Octo CLI makes the data available from any database as a web service on-demand, 
    simplifying the process of building data-driven applications.
     It can reduce costs, improve accessibility and performance.
  </p>
 

 <p><a href="" title=" ">
    <img src="https://user-images.githubusercontent.com/20528562/92949687-2b627080-f464-11ea-99e8-d3afad80922c.png" alt=" ">
  </a>
  </p>
     <div>
    <p><a href="https://github.com/octoproject/octo-cli" title="Documentation" onmousedown="ga('send', 'event', 'download', 'click', 'zip')">View on Github</a>
    <a href="https://github.com/octoproject/octo-cli#examples" title="View on GitHub" onmousedown="ga('send', 'event', 'download', 'click', 'zip')">Get started</a>
  </p></div>
</div></div>]]>
            </description>
            <link>https://octoproject.github.io/octo-cli/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24442294</guid>
            <pubDate>Fri, 11 Sep 2020 13:02:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to choose an FPGA dev board. A guide for 2020]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24441911">thread link</a>) | @blackSparrow
<br/>
September 11, 2020 | https://thedatabus.io/fpga-buying-guide | <a href="https://web.archive.org/web/*/https://thedatabus.io/fpga-buying-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Let's face it, It is not easy to choose a freaking PC these days with the deluge of specifications that come with it let alone FPGAs. The question of using FPGAs to solve any computing problem only arises when an extraordinary performance is required. Owing to this fact, FPGAs in their feature specification and build can be extremely specific to the application at hand. This results in an insane number of varieties in terms of the logic structures within the FPGA as well as the interfaces that are provided with the external world. However, this guide aims to guide you in the right direction (which does not mean dumping a list of the hundreds of different options out there) based on your level of experience and requirement.</p>
<p>There are other posts out there that provide large tables with exhaustive lists of FPGA development boards out there and let you (after a year or two of research) make a choice. If that's your thing, I'll attach some links to help you get started.</p>
<hr>
<p><em>If you're already familiar with the various bells and whistles of  FPGAs and are only looking for some good suggestions, you might prefer to <a href="https://thedatabus.io/fpga-buying-guide#the-top-contenders"><strong>JUMP TO THE LIST OF SUGGESTIONS</strong></a>.  If not, read on to learn some very important stuff about the FPGA world and how to choose better!</em></p>
<h2 id="what-you-should-be-looking-for"><a href="#what-you-should-be-looking-for" aria-label="what you should be looking for permalink"></a>What you should be looking for</h2>
<p>There are already a lot of aspects to an FPGA in general that determine its fit to a particular problem and the ease with which it can be programmed, now add to this the complexity of a feature-rich development board with all sorts of peripherals, interfaces, connectors and memory options you have at hand a humongous task of deciding between hundreds of varieties out there.</p>
<h3 id="soc-based-board-or-just-an-fpga"><a href="#soc-based-board-or-just-an-fpga" aria-label="soc based board or just an fpga permalink"></a>SOC based board or just an FPGA?</h3>
<p>SOC stands for <a href="https://semiengineering.com/knowledge_centers/integrated-circuit/ic-types/system-on-chip/" target="_blank">System-on-Chip</a> which simply means that various interacting technologies are built onto the same die (/chip). You see SOCs everywhere, on your phones, TVs, and computers. In the context of an FPGA development board, a SOC based system means that the hardware has two components, a sea of programmable logic (the FPGA) and a hard processor core implemented in silicon independent of the programmable FPGA logic. Interfaces are created between the programmable logic and the processing system (in Xilinx lingo) that enable communication between the two regions.</p>
<p><img src="https://thedatabus.io/static/zynq7000-ae213195db5b530cc3f5d60785b3b0b1.png" alt="Zynq7000"></p>
<p>If you are an absolute beginner looking for direction, you should definitely choose a SOC based system because of the immense additional learning potential it adds. Having said that, your first few digital design projects should never involve the processor cores or any kind of software programming. For that, you can just ignore the processor logic and dump your design into the programmable region to use it as a normal FPGA. As you progress, you can add much higher levels of complexity to your design by bringing in the processor core to directly read and write data in your configurable hardware. You can also experiment with writing firmware, drivers, the Linux OS, and the higher levels of abstraction thus getting a truly holistic experience of embedded system design. Even the simplest SOC based board will keep you busy for a long time. </p>
<p>These boards can also be of great interest for Software engineers looking to explore into the digital design world since processor + FPGA structures lend themselves very well to paradigms like HLS, Heterogenous computing and partial acceleration of algorithms. Viewing the FPGA logic as an extension of the SOC is something that is going to be very important in the future and is a good investment of your time.</p>
<p>Alternatively, If you are a beginner but are looking only to learn digital design or you wish to buy a board to complement your studies at college where you get to use a particular board in your lab, you can get a lot more basic FPGA resources (LUTs, BRAMs, DSPs) on a Non-SOC based board that has only the FPGA. This way you save money and have a much less complex system at hand that you can comprehend better. The same is true If you plan to implement something specific that takes up an enormous number of resources, you might be better off going for a dev board that has only the FPGA and the required peripherals.</p>
<p>At the end of <a href="https://www.reddit.com/r/FPGA/comments/9yutk8/best_100300_fpga_development_board_in_2018/?utm_source=share&amp;utm_medium=web2x&amp;context=3" target="_blank">this post</a> on the subreddit <a href="https://www.reddit.com/r/FPGA/" target="_blank">r/FPGA</a> user <strong>u/ndbroadbent</strong> has shown the resource usages of several open source projects, this can give you a good idea of how big projects usually are.</p>
<p><strong>An important note for beginners</strong> : <em>Having an SOC board, with all the processor logic around the FPGA can really deviate you from the basic idea of programmable logic and how you're supposed to learn it. I strongly suggest completely disregarding anything to do with the processor for your first few projects and use only the FPGA part of the device. Also note that as of today, any good FPGA engineer will tell you that any form of <a href="https://en.wikipedia.org/wiki/High-level_synthesis#:~:text=High%2Dlevel%20synthesis%20(HLS),hardware%20that%20implements%20that%20behavior."><strong>HLS</strong></a> is not good enough to be used in real world projects. This is doubly true for the beginners. <strong>DO NOT</strong> fall into the 'Write code in C++/Python and run it on FPGA' trap. A lot of youtubers seem to be promoting stuff like that for beginners these days which is just sad. If you have the money to spend, the ideal (and more enjoyable) learning strategy would be to use a standalone FPGA board first and upgrade to an SOC later.</em></p>
<hr>
<h3 id="interfaces-and-ios"><a href="#interfaces-and-ios" aria-label="interfaces and ios permalink"></a>Interfaces and IOs:</h3>
<p>FPGAs are excellent tools for working on high-speed interfaces. So you might want to look at the interfaces and IO options a particular development board is providing. This is important because if the board has a particular interface out of the box, the vendor will probably provide the necessary documentation and sample designs for those interfaces. This can save you tons of head-scratching and hair-pulling (trust me that is common in the FPGA world) as a beginner. That's not to say that newer interfaces cannot be added to the board manually but when it comes to High-speed interfaces like Ethernet, HDMI, PCIe, it can be very difficult to add them yourself and expect reliable performance. Low-speed ones like SPI, UART, etc can always be manually added using the GPIOs, so let them not be the dealbreaker for any board.</p>
<p>Some common networking interfaces that you should look for are high-speed interfaces like <a href="https://en.wikipedia.org/wiki/HDMI" target="_blank"><strong>HDMI</strong></a>  <a href="https://en.wikipedia.org/wiki/Video_Graphics_Array" target="_blank"><strong>VGA</strong></a>  <a href="https://en.wikipedia.org/wiki/Ethernet" target="_blank"><strong>ETHERNET</strong></a>  <a href="https://en.wikipedia.org/wiki/PCI_Express" target="_blank"><strong>PCIe</strong></a>  etc. and low-speed peripherals like <a href="https://en.wikipedia.org/wiki/Serial_Peripheral_Interface" target="_blank"><strong>SP</strong>I</a>  <a href="https://en.wikipedia.org/wiki/CAN_bus" target="_blank"><strong>CAN</strong></a>  <a href="https://en.wikipedia.org/wiki/I%C2%B2C" target="_blank"><strong>I2C</strong></a>  etc.</p>
<p>Although not as important for a beginner, another set of interfaces that can be useful are the analog and sensor interfaces like ADCs, DACs, Camera Interface, Audio CODECs, etc. These are very niche features that can make or break a particular project if it depends on data acquisition from the external world.</p>
<p>If you choose to go for a board with not too many peripherals for whatever reason, you might be better off choosing one that has the industry-standard <a href="https://store.digilentinc.com/pmod-modules-connectors/" target="_blank"><strong>PMOD</strong></a> or <a href="https://en.wikipedia.org/wiki/FPGA_Mezzanine_Card" target="_blank"><strong>FMC</strong></a> connectors installed so that when you do need additional interfaces in the future, they can be added very easily. These standard connectors essentially decouple FPGA carrier boards from the IO engines (which plug-in as daughter cards), enabling you to use the same FPGA boards with a large variety of IO designs without ever having to re-design the board.</p>
<hr>
<h3 id="buttons-leds-and-displays"><a href="#buttons-leds-and-displays" aria-label="buttons leds and displays permalink"></a>Buttons, LEDs, and Displays:</h3>
<p>Debugging FPGA designs can be a hard thing. Unlike MCUs where you can place print statements and breakpoints anywhere you want in the code, there is no such equivalent in the FPGA world and that can often lead to great frustration. One workaround is possible, if there are switches and LEDs on your board. They provide an easy way to pull out signals to the real world and give you an indication of the status of some status registers that can help you visualize and debug (like the current state of a state machine or a particular flag in a CPU design). However, this should not be the deciding factor between two boards since it is very easy to add LEDs, buttons, switches, and LCDs using the GPIO connectors without much effort.</p>
<hr>
<h3 id="memory-and-resource-count"><a href="#memory-and-resource-count" aria-label="memory and resource count permalink"></a>Memory and Resource Count:</h3>
<p>The Resource Count is another important metric that goes into deciding on an FPGA device. By resource, we mean the number of programmable logic elements available on the board. These can be LUTs (ALMs for Altera), Block Rams, DSPs, and IO blocks. Much more complex and fancier devices like the  <a href="https://www.xilinx.com/products/silicon-devices/acap/versal.html" target="_blank"> Versal family</a> from Xilinx can have lots of other stuff like AI, video, and audio cores, etc. It is important to take note of these resource numbers because they determine the biggest project that you can successfully fit onto the FPGA. It is hard to come up with a fixed count for a particular project owing to differences in the underlying CLB architecture from vendor to vendor and family to family.</p>
<p>FPGAs store the configuration(bitstream) data on the SRAM (usually) cells within the FPGA. Since SRAM is a volatile kindof memory, the program is lost each time the board is power-cycled. A PC support is needed to reprogram it again after the power cycle, to prevent this, FLASH (or EEPROM in older boards) based storage is provided onboard by the vendors. Flash is a non-volatile form of storage that holds the bitstream data even without a power supply. Each time the board comes up after a power cycle, the FPGA checks the flash memory for a bitstream and programs itself with it. This is usually given by default in most boards but can be something important to look out for. </p>
<p>The other important form of memory is the external onboard volatile storage which is most commonly provided in the form of a <a href="https://en.wikipedia.org/wiki/DDR_SDRAM" target="_blank">DDR SDRAM</a>  This is extremely useful if you are building an application that needs to store data locally for whatever reason. Since the block ram storage within the FPGA fabric is very little and is very precious, having a DDR that can be written to and read from in a reasonable amount of time is very much essential. The more the better!
<a href="https://numato.com/kb/learning-fpga-verilog-beginners-guide-part-6-ddr-sdram-a7/" target="_blank">This</a> tutorial and <a href="https://www.electronics-notes.com/articles/electronic_components/semiconductor-ic-memory/sdram-synchronous-dram-what-is.php" target="_blank">this</a> one can get you started with the interface that needs to be coded in order to communicate with the DDR chip.</p>
<hr>
<h3 id="learning-resources-and-community-support"><a href="#learning-resources-and-community-support" aria-label="learning resources and community support permalink"></a>Learning Resources and community support:</h3>
<p>Unlike the world of software or MCU based design, the world of digital design and FPGAs have far fewer general resources in terms of …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thedatabus.io/fpga-buying-guide">https://thedatabus.io/fpga-buying-guide</a></em></p>]]>
            </description>
            <link>https://thedatabus.io/fpga-buying-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-24441911</guid>
            <pubDate>Fri, 11 Sep 2020 12:22:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The case against normalized caching in GraphQL]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24441864">thread link</a>) | @jensneuse
<br/>
September 11, 2020 | https://wundergraph.com/blog/2020/09/11/the-case-against-normalized-caching-in-graphql | <a href="https://web.archive.org/web/*/https://wundergraph.com/blog/2020/09/11/the-case-against-normalized-caching-in-graphql">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>In this post we'll compare rich GraphQL clients that come with a normalized cache implementation and the generated WunderGraph clients that rely on HTTP caching.</p><p>As you might have already found out, WunderGraph uses persisted queries by default.
With the WunderGraph code generator WunderGen(<a href="https://github.com/wundergraph/wundergen" target="_blank" rel="noopener noreferrer">https://github.com/wundergraph/wundergen</a>) you can generate a client that knows exactly how to invoke your previously registered operations.
With the <code>@cache</code> directive you're able to configure that the response of an operation should be cached by the server &amp; client.
Cache Control headers will be set accordingly, including etags. This mechanism is fully compatible with all major browsers and CDN's who implement caching according to the <a href="https://tools.ietf.org/html/rfc7234" target="_blank" rel="noopener noreferrer">HTTP Caching RFC</a>.</p><p>To illustrate this a bit better I'd like to introduce two example queries.
The first one fetches a list of friends.
The second one fetches some details about those friends.</p><p>Let's consider we want to show a list of friends:</p><div><div><div tabindex="0"><div><p><span>query</span><span> Friends </span><span>{</span><span></span></p><p><span>    friends </span><span>{</span><span></span></p><p><span>        id</span></p><p><span>        name</span></p><p><span>        age</span></p><p><span>        avatarURL</span></p><p><span>    </span><span>}</span><span></span></p><p><span></span><span>}</span></p></div></div></div></div><p>For each friend we'd like to be able to click on the friend in the list and open up a detail page:</p><div><div><div tabindex="0"><div><p><span>query</span><span> FriendByID </span><span>{</span><span></span></p><p><span>    friend</span><span>(</span><span>id</span><span>:</span><span> </span><span>123</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>        id</span></p><p><span>        name</span></p><p><span>        age</span></p><p><span>        avatarURL</span></p><p><span>    </span><span>}</span><span></span></p><p><span></span><span>}</span></p></div></div></div></div><p>You will recognize that we already have all the data for the detail page.
So in an ideal scenario the client won't have to make another request.
This is possible thanks to cache normalization.</p><p>A smart normalized cache will identify the Friend entity and will recognize that the "FriendByID" query can be fulfilled using the data from the "Friends" query which we already ran.</p><p>What are the pros of this concept?</p><ul><li>Navigating to a friend detail page will be instant because there is no network request required</li><li>The client will save bandwidth, and the user experience will be more fluent</li><li>If we navigate back we can also immediately pull out the list of friends from the normalized cache</li></ul><p>How can this situation become hairy?
Let's add a third operation. While on a user detail page we'd like to unfriend one of our peers:</p><div><div><div tabindex="0"><div><p><span>mutation</span><span> Unfriend </span><span>{</span><span></span></p><p><span>    unfriend</span><span>(</span><span>id</span><span>:</span><span> </span><span>123</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>        id</span></p><p><span>    </span><span>}</span><span></span></p><p><span></span><span>}</span></p></div></div></div></div><p>How does the <code>unfriend</code> mutation make the situation complex?
In your normalized cache you have to invalidate or update the "Friends" and "Friend" entities.
In your friends list you have to remove the user with id 123.
For the <code>Friends</code> you have to make sure no friend is returned for id 123 anymore.</p><p>How does your normalized cache draw the lines between the <code>unfriend</code> mutation and the <code>friend</code> and <code>friends</code> query?
You as the frontend developer have to program the cache to do so.
After the mutation you must inform the cache about these changes.</p><p>With that let's talk about the cons of a normalized cache:</p><ul><li>a rich GraphQL client with a normalized cache is complex to build and maintain</li><li>the cache is running in the javascript vm of your browser and therefore a lot less efficient than the browser cache</li><li>the logic to keep the cache state correct can become quite hairy</li><li>the frontend developer must understand the domain and program the cache correctly to avoid unwanted behaviour</li><li>the frontend developer must implement custom rules for cache eviction</li></ul><p>One thing that I want to explicitly mention outside of the list:</p><h2>There's no single source of truth for the business object in this scenario.</h2><p>The frontend developer might accidentally allow the UI to show a friend in the friends list even if you have previously unfriended said person.
Errors like these are very hard to spot. I think we're giving the frontend developer a lot of responsibility in this case to get caching right.</p><p>Should it really be a concern of a frontend developer if data is stale? Shouldn't a frontend developer focus on the UI and trust the data layer? Does it really have to be that complicated to build rich apps with good performance?</p><p>I believe there are applications where it's definitely worth having such a complexity.
On the other hand I see many use cases, eg a news website, where relying on the HTTP Caching RFC is a lot simpler and more efficient.</p><h2>Enter WunderGraph caching:</h2><p>With WunderGraph every registered Query becomes an endpoint to which you can apply caching rules individually.</p><p>Let's revisit the example from above:</p><div><div><div tabindex="0"><div><p><span>query</span><span> FriendByID </span><span>@cache</span><span>(</span><span>maxAge</span><span>:</span><span> </span><span>5</span><span>)</span><span>{</span><span></span></p><p><span>    friend</span><span>(</span><span>id</span><span>:</span><span> </span><span>123</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>        id</span></p><p><span>        name</span></p><p><span>        age</span></p><p><span>        avatarURL</span></p><p><span>    </span><span>}</span><span></span></p><p><span></span><span>}</span></p></div></div></div></div><p>This Query becomes the following endpoint on your WunderGraph Node:</p><div><div><div tabindex="0"><div><p><span>/</span><span>application</span><span>-</span><span>id</span><span>/</span><span>FriendByID</span><span>?</span><span>variables</span><span>=</span><span>{</span><span>"id"</span><span>:</span><span>123</span><span>}</span></p></div></div></div></div><p>In this scenario we decided to cache a friend object for 5 seconds using the <code>@cache</code> directive.
After 5 seconds the client will re-request the user and send an <code>If-None-Match</code> header with the request.
If the previous response is still valid the server will respond with a <code>304 (Not Modified)</code> http status code.
The same logic can be applied to the <code>Friends</code> Query.
All you have to do is define the desired behaviour using directives on the Operations.</p><p>What are the pros of this approach?</p><ul><li>there's a single source of truth - the Operation Definition</li><li>caching is handled automatically by the browser which is easier to use and understand</li><li>no complex tooling is required to understand why a request is cached, browsers have excellent debuggers for this</li><li>no javascript code has to be written to keep the cache state in sync</li><li>with a service worker you can easily build offline apps using standard caching techniques</li><li>less javascript code to be run by the browser</li><li>the frontend developer gets to focus on the UI and has to worry less about data fetching and caching logic</li></ul><p>What are the cons of HTTP caching for GraphQL queries?</p><ul><li>the client has to make more requests than with a normalized cache</li><li>more requests lead to more bandwidth usage</li><li>there's no easy way to invalidate the cache immediately</li></ul><h2>Does a normalized cache prevent us from doing more requests?</h2><p>Let's make this scenario a bit more realistic. On the friends detail page we'd like to see the bio of the friend too:</p><div><div><div tabindex="0"><div><p><span>query</span><span> FriendByID </span><span>{</span><span></span></p><p><span>    friend</span><span>(</span><span>id</span><span>:</span><span> </span><span>123</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>        id</span></p><p><span>        name</span></p><p><span>        age</span></p><p><span>        avatarURL</span></p><p><span>        bio</span></p><p><span>    </span><span>}</span><span></span></p><p><span></span><span>}</span></p></div></div></div></div><p>With this one field added even with normalized caching we have to refetch each individual friend even though we already have most of the data.
At the end of the day a normalized cache might introduce a lot of complexity to your app while the benefits are not as huge as you expect.
In this last example you could have saved to transfer less fields for each user detail page at the expense of a complex GraphQL client that understands which fields are missing for an entity.</p><h2>Cache invalidation</h2><p>As mentioned previously, a normalized cache can easily be invalidated.
This comes at the cost of implementing and maintaining the cache code plus defining the logic when to invalidate which objects.</p><p>With HTTP caching it's not that easy.
You could add a dynamic parameter, e.g. a timestamp, to the Query.
This would allow for easy cache invalidation but also reduces possible cache hits.</p><h2>Users can have multiple clients</h2><p>Is it possible for your users to open your application in multiple tabs, native applications, etc.?
If that's the case what happens if you unfriend a user in one tab while you have another tab open?
At that point your normalized cache has no way of figuring out if data is stale, it needs to make a network call if you switch tabs.</p><h2>Should you cache at all?</h2><p>Are we actually solving the problem at the right layer or creating a new, even more complex, problem?</p><p>If data like in this example could change any time at any click (add friend/unfriend) should we really cache this at the client or transport level at all?</p><p>Why not use an application cache, e.g. Redis or Memcached, in the Backend if hitting the database directly is a performance bottleneck?
In this scenario, neither transport level caching, nor a normalized client cache is the proper solution.</p><h2>When to cache</h2><p>Caching makes sense for publicly available data that doesn't change frequently.</p><p>E.g. on a news website it's totally fine to cache the content for each article for a few seconds (e.g. 5).
This would reduce the amount of requests from thousands to one per resource per 5 seconds.</p><p>In case data can change at high frequencies, especially after user interactions with the application, caching should happen at the application layer.</p><h2>Summary</h2><p>When you think you have to use a normalized cache in the client you should consider an application level cache first.</p><p>A normalized cache introduces a second source of truth in the frontend which needs to be maintained.
Optimistic can get that last bit of performance out of an app to get the user experience from 95% to 98% at the cost of extra complexity.</p><p>Most of the time you don't need this complexity and should avoid it.
Keep it simple, solve a business problem, don't introduce technical debt.</p><p>WunderGraph gives you a simple and powerful way to use transport based caching.
For 99% of the other use cases you should consider adding an application level cache if performance is an issue.</p></section></div>]]>
            </description>
            <link>https://wundergraph.com/blog/2020/09/11/the-case-against-normalized-caching-in-graphql</link>
            <guid isPermaLink="false">hacker-news-small-sites-24441864</guid>
            <pubDate>Fri, 11 Sep 2020 12:17:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Moving from Vim to Emacs (2019)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24441632">thread link</a>) | @tosh
<br/>
September 11, 2020 | https://rohitpaulk.com/articles/vim-to-emacs | <a href="https://web.archive.org/web/*/https://rohitpaulk.com/articles/vim-to-emacs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
            

<p>Iâ€™ve been a staunch Vim user for a long time now, and recently switched over to
Emacs. Time to fight the other side of the
<a href="https://en.wikipedia.org/wiki/Editor_war">war</a>!</p>

<p>Iâ€™ve got years worth of muscle memory tied up to Vim Key Bindings, so itâ€™s
unlikely that Iâ€™d have considered this change if it werenâ€™t for
<a href="https://github.com/emacs-evil/evil"><code>evil-mode</code></a>.</p>

<p>Before we start, an obligatory xkcd comic:</p>

<p><img src="https://imgs.xkcd.com/comics/real_programmers.png" alt="emacs_xkcd"></p>

<p>Sections in this article:</p>

<!-- toc -->
<ul>
  <li><a href="#emacs-distribution-vs-vanilla-emacs">Emacs Distribution vs Vanilla Emacs</a></li>
  <li><a href="#spacemacs-the-good">Spacemacs: The Good</a>
    <ul>
      <li><a href="#1-findreplace-live-preview">1. Find/Replace Live Preview</a></li>
      <li><a href="#2-case-sensitive-substitution">2. Case-sensitive substitution</a></li>
      <li><a href="#3-live-documentation">3. Live Documentation</a></li>
    </ul>
  </li>
  <li><a href="#spacemacs-the-bad">Spacemacs: The Bad</a></li>
  <li><a href="#spacemacs-the-ugly">Spacemacs: The Ugly</a></li>
  <li><a href="#doom-emacs-to-the-rescue">DOOM Emacs to the rescue</a></li>
  <li><a href="#news-from-the-dark-side">News from the dark side</a>
<!-- endtoc --></li>
</ul>

<h2 id="emacs-distribution-vs-vanilla-emacs">Emacs Distribution vs Vanilla Emacs</h2>

<p>I went for an Emacs distribution over vanilla Emacs because there were two
things I didnâ€™t want to have to configure for scratch:</p>

<ul>
  <li>A modern-looking UI</li>
  <li>Vim emulation layer</li>
</ul>

<p>I ended up picking <a href="https://www.spacemacs.org/">Spacemacs</a>, because the README
resonated with what I was looking for, and it was pretty popular. I did feel
that it was likely to be too bloated for my use case, but <code>spacemacs-base</code> (a
minimal set of packages that you can build upon) seemed to solve that problem.</p>

<h2 id="spacemacs-the-good">Spacemacs: The Good</h2>

<p>A few features in Spacemacs that came as pleasant surprises:</p>

<h3 id="1-findreplace-live-preview">1. Find/Replace Live Preview</h3>

<p>Best explained with an asciicast:</p>



<p>Compared to this, find/replace in Vim feels like working with a blindfold on!
(Yes, I do use <code>:incsearch</code>)</p>

<h3 id="2-case-sensitive-substitution">2. Case-sensitive substitution</h3>

<p>Substitution in Spacemacs is case-sensitive by default, unlike in Vim where I
had to use <a href="https://github.com/tpope/vim-abolish">vim-abolish</a>.</p>

<p>For a good explanation as to why this is useful, read <a href="https://github.com/tpope/vim-abolish"><code>vim-abolish</code>â€™s
README</a>. A quick excerpt:</p>

<blockquote>
  <p>One time I had an application with a domain model called â€œfacilityâ€� that needed
to be renamed to â€œbuildingâ€�. So, a simple search and replace, right?</p>

  <ul>
    <li><code>:%s/facility/building/g</code></li>
  </ul>

  <p>Oh, but the case variants!</p>

  <ul>
    <li>
      <p><code>:%s/Facility/Building/g</code></p>
    </li>
    <li>
      <p><code>:%s/FACILITY/BUILDING/g</code></p>
    </li>
  </ul>

  <p><code>vim-abolish</code> combines all of these into one command.</p>
</blockquote>

<h3 id="3-live-documentation">3. Live Documentation</h3>

<p>Learning key-bindings in Spacemacs is surprisingly easy, because it shows you
suggestions as you start a key sequence.</p>

<p><img src="https://rohitpaulk.com/images/articles/emacs-which-key.png" alt="which-key"></p>

<p>I later learnt that this is powered by the
<a href="https://github.com/justbur/emacs-which-key"><code>which-key</code></a> package.</p>

<h2 id="spacemacs-the-bad">Spacemacs: The Bad</h2>

<p>Spacemacs shows a prompt on the first install that asks you whether you want to
use <code>spacemacs</code>, the full-featured distribution, or <code>spacemacs-base</code>, a minimal
set of packages that you can then build upon.</p>

<p><img src="https://rohitpaulk.com/images/articles/emacs-spacemacs-wizard.png" alt="spacemacs-wizard"></p>

<p>Since I wanted a minimalist setup that I could later configure as needed, I went
with <code>spacemacs-base</code>.</p>

<p>When I did reach out for configuration options though, problems started
cropping up.</p>

<p>While the Spacemacs config file is well-documented, a lot of the options in
there only apply to <code>spacemacs</code>, and not <code>spacemacs-base</code>. Toggling config
options felt something like this:</p>

<blockquote>
  <p><strong>me</strong>: <em>changes config value</em></p>

  <p>Hmm, that didnâ€™t work. Maybe Iâ€™m using the wrong value?</p>

  <p><strong>me</strong>: <em>re-reads documentation</em></p>

  <p>Doesnâ€™t look like my mistake. Maybe a restart would help?</p>

  <p><strong>me</strong>: <em>restarts Emacs</em></p>

  <p>Still doesnâ€™t work.</p>

  <p><strong>me</strong>: <em>greps for config key in Spacemacs source code</em></p>

  <p><strong>me</strong>: <em>finds the layer that uses it</em></p>

  <p><strong>me</strong>: <em>tries to open layer documentation</em></p>

  <p><strong>spacemacs</strong>: <em>layer not enabled</em></p>

  <p>Oh, <code>spacemacs-base</code> ðŸ¤¦</p>
</blockquote>

<p>After a couple of encounters like this, it started to become clear that
<code>spacemacs-base</code> was an afterthought, not a first-class citizen.<sup id="fnref:1"><a href="#fn:1">1</a></sup></p>

<p>I then switched to <code>spacemacs</code> instead of <code>spacemacs-base</code>. My mistake was
apparent seconds later. After the reload, <code>spacemacs</code> installed <strong>~140</strong>
packages (iirc). Opening a project was noticeably slower, and when I started
editing files Spacemacs just kept freezing up randomly in the middle. Speak of
bloat ðŸ™„. Iâ€™m fine with not-so-fast startup times, but this was affecting basic
operations like navigating through a file. (For context, Iâ€™m running a pretty
lean setup: Arch Linux on an Macbook Air with 8 gigs of RAM)</p>

<p>I quickly course-corrected and switched back to <code>spacemacs-base</code>. Maybe the
wrangling with disabled layers wasnâ€™t so bad?</p>

<h2 id="spacemacs-the-ugly">Spacemacs: The Ugly</h2>

<p>Throughout my experience, the spacemacs documentation had always felt a bit
rough on the edges. I was able to note down 3-4 mistakes (simple ones) in the
first couple of hours. I didnâ€™t make much of this at first, just assumed that it
was because the project had a large amount of changes going in.</p>

<p>At the end of my first day with Spacemacs, I sat down to fix the documentation
mistakes I had identified. As the <a href="https://github.com/syl20bnr/spacemacs/blob/master/CONTRIBUTING.org">contributing
guide</a>
mentioned, I switched to <code>develop</code>. To my surprise, the fixes I intended to make
were already present!</p>

<p>Assuming that these were recent fixes that hadnâ€™t made it to <code>master</code> yet, I
checked the date on those commits. They were created <strong>2 years ago</strong>. I then
checked the latest stable release for Spacemacs - turns out it was released more
than a year ago. Something was wrong here. This isnâ€™t what one would expect from
a â€œcommunity-drivenâ€� Emacs distribution.</p>

<p>I asked for help on <a href="https://gitter.im/syl20bnr/spacemacs">Gitter</a>, and was told
to use <code>develop</code> instead of <code>master</code>. That didnâ€™t sound right - The README
didnâ€™t mention anything about <code>develop</code>, and the online documentation was still
wired to <code>master</code>.</p>

<p>I then asked about this <a href="https://www.reddit.com/r/spacemacs/comments/dxqa51/how_does_spacemacs_develop_master_sync_happen/">on
Reddit</a>,
and got this answer:</p>

<blockquote>
  <p>This is a persistent issue in the spacemacs community. I think only syl20bnr
has commit access to master and so only he gets to decide what commits are
worthy of being cherry picked into master. Master hasnâ€™t had a version bumb in
2 years despite <a href="https://github.com/syl20bnr/spacemacs/milestone/7">the v0.300 milestone being reached awhile
ago</a>. Hereâ€™s some github
issues that raise your question:
<a href="https://github.com/syl20bnr/spacemacs/issues/12418">#12418</a>,
<a href="https://github.com/syl20bnr/spacemacs/issues/11191">#11191</a></p>
</blockquote>

<blockquote>
  <p>The deeper issue of maintainers and repository access was <a href="https://github.com/syl20bnr/spacemacs/issues/8686">addressed two years
ago</a>. Unfortunately things
havenâ€™t improved much since then since than. While there are fewer open PRs,
there are now over 2.3k open issues and that number only ever seems to grow.
This continues to <a href="https://github.com/syl20bnr/spacemacs/issues/12082">prompt questions of more active forks/better
merging</a>.</p>

  <p>- <a href="">reddit
  link</a></p>
</blockquote>

<h2 id="doom-emacs-to-the-rescue">DOOM Emacs to the rescue</h2>

<p>The fiasco with Spacemacs was enough to have me looking around for other
alternatives. A quick search yielded a lot of praise for
<a href="https://github.com/hlissner/doom-emacs">DOOM Emacs</a>. I didnâ€™t want to get rid
of Spacemacs altogether just yet, so I used <a href="https://github.com/plexus/chemacs">chemacs</a>
(an Emacs profile switcher) to install both side-by-side.</p>

<p>DOOM Emacs was far faster to boot, and had a more appealing &amp; minimalist UI
(IMHO). When I ran into installation troubles, <code>doom doctor</code> always had friendly
error messages. I was also impressed by the quality of answers in their
<a href="https://github.com/hlissner/doom-emacs/blob/develop/docs/faq.org">FAQ</a>.</p>

<p><img src="https://rohitpaulk.com/images/articles/emacs-doom.png" alt="doom-emacs"></p>

<p>I did have to customize DOOM Emacs a bit to get it running the way I wanted it
to though. Spacemacs, in comparison, was more useable out-of-the-box.</p>

<h2 id="news-from-the-dark-side">News from the dark side</h2>

<p>Iâ€™ve now gotten to a point where Iâ€™m comfortable using Emacs as my primary
editor. Iâ€™m typing this article out in Emacs, with my web server process
running in a terminal <em>inside</em> Emacs.</p>

<p>I havenâ€™t opened Vim in 3 days. In fact, Iâ€™ve <a href="https://twitter.com/RohitPaulK/status/1195410155623419904">aliased
it</a> to launch Emacs
instead.</p>

<p>My search history includes terms like â€œTodoist in Emacsâ€�, â€œWeb browser in Emacsâ€�
and â€œEmail client in Emacsâ€�.</p>

<p>â€¦</p>

<p>Iâ€™m turning into one of <em>those</em> people, and Iâ€™m loving it.</p>


        </section></div>]]>
            </description>
            <link>https://rohitpaulk.com/articles/vim-to-emacs</link>
            <guid isPermaLink="false">hacker-news-small-sites-24441632</guid>
            <pubDate>Fri, 11 Sep 2020 11:47:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sometimes you just have to ship it]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24441605">thread link</a>) | @mooreds
<br/>
September 11, 2020 | https://letterstoanewdeveloper.com/2020/09/07/sometimes-you-just-have-to-ship-it/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2020/09/07/sometimes-you-just-have-to-ship-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Dear new developer,</p>



<p>For me, there comes a point at the end of every project where I’m just sick of it. I’m sick of the project. I’m sick of the technology. I’m sick of project management system. I’m sick of the code.</p>



<p>Sometimes, I just want to see the whole thing burn. Or better, just ship it. </p>



<p>Now, I think that there are two solutions to this problem, and which one you pick depends on your timeline. The first is to take a step back. Talk to a team mate. Work on something else. Talk a walk. Take an extra half hour for lunch. </p>



<p>This may give you perspective to help you dive back in and add just a bit more polish. That polish, which may take the form of additional UX refinement, testing, or even wordsmithing the help messages or marketing text, can help make the project shine. </p>



<p>That’s what I call ‘running through the finish line’ where you want to leave it all on the field. That doesn’t mean you don’t make compromises or that you won’t revisit decisions, but it does mean that you do the best you can. Sometimes to put in that final effort, you need to take a break.</p>



<p>The other choice is to just ship it. This is a good option when you are up against a deadline. It also helps if you know you are a perfectionist and/or afraid of putting your work out there. Nothing is perfect and if your work never sees the light of day because you can’t accept that, the world is losing out (as are you). Finally, it can help if you take that time off, acquire that perspective and know that you’re done with this phase of the work.</p>



<p>I just <a href="https://letterstoanewdeveloper.com/the-book/">published a book</a>. It was released on Aug 16. I’m very proud of it, but there were times when I was just plain sick of it. I ended up taking some time away from it and that helped me make sure it was the best book it could be.</p>



<p>When you are working through the final bits of a project, sit back and get that perspective. And then, ship it!</p>



<p>Sincerely,</p>



<p>Dan</p>
	</div><div>
			<!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2020-09-07T04:45:00-06:00">September 7, 2020</time><time datetime="2020-09-07T10:54:54-06:00">September 7, 2020</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2020/09/07/sometimes-you-just-have-to-ship-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24441605</guid>
            <pubDate>Fri, 11 Sep 2020 11:41:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is There a WhatsApp Alternative for Daily Chatting?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24441560">thread link</a>) | @UtopiaFans
<br/>
September 11, 2020 | https://utopia.fans/security/is-there-a-whatsapp-alternative-for-daily-chatting/ | <a href="https://web.archive.org/web/*/https://utopia.fans/security/is-there-a-whatsapp-alternative-for-daily-chatting/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                            <img src="https://utopia.fans/wp-content/webp-express/webp-images/uploads/2020/09/Daily-Chatting-770x501.jpg.webp" alt="banner">
                           	
                           	
                            
<p>Many people cheered when Facebook decided to take over the WhatsApp messenger. The new owner promised that personal data would remain private and protected from third parties’ interference.</p>



<p><a href="https://utopia.fans/security/why-is-secure-messaging-important-in-2020/"><em>Why Is Secure Messaging Important In 2020?</em></a><em> Read and protect yourself from each cyber threat!</em></p>



<p>Time passed by and the promise was gradually forgotten. Today, this has led to the need to change your messenger if you want to keep your personal data secure. Facebook’s developers just took away additional layers of privacy protection from the app. Their standard argument is that it’s for analytical data analysis.</p>



<p><em>We’ve already prepared the full-fledged analysis of WhatsApp. You can read </em><a href="https://utopia.fans/security/is-whatsapp-safe-and-secure/"><em>Is WhatsApp Safe and Secure</em></a><em> </em><em>and decide whether to use this messenger or not.</em></p>



<p>Now, the days when we could perfectly trust this app are behind us. Therefore, the issue of replacing WhatsApp has become urgent. People want to use a proper WhatsApp alternative.</p>



<p>Fortunately, today, there are many WhatsApp alternatives in which privacy is really respected. In this article, you can find several multi-tasking and secure tools for private messaging everywhere.</p>



<p><em>Read </em><a href="https://utopia.fans/tools/clash-of-the-titans-telegram-vs-whatsapp-vs-utopia/"><em>Clash of The Titans: Telegram vs WhatsApp vs Utopia</em></a><em> and choose the best messaging app for secure communication.</em></p>



<h3>WhatsApp alternative list</h3>



<p><a href="https://u.is/en/" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener nofollow"><strong><em>Utopia</em></strong></a></p>



<figure><img loading="lazy" decoding="async" src="https://utopia.fans/wp-content/webp-express/webp-images/uploads/2020/09/Utopia.png.webp" alt="Best messaging app" srcset="https://utopia.fans/wp-content/webp-express/webp-images/uploads/2020/09/Utopia.png.webp 333w,  https://utopia.fans/wp-content/webp-express/webp-images/uploads/2020/09/Utopia-300x170.png.webp 300w" sizes="(max-width: 333px) 100vw, 333px"></figure>



<p>Utopia is an anonymous platform that has a lot of built-in tools: instant messenger (uMessenger), secure file sharing (uMail), anonymous browser (Idyll), crypto container (uWallet) and more.</p>



<p>Utopia is a <a href="https://utopia.fans/networks/the-story-behind-the-clear-advantages-of-decentralization/">decentralized</a> ecosystem that is based on <a href="https://utopia.fans/networks/the-backbone-of-the-internet-what-is-a-p2p-network/">a peer-to-peer</a> architecture. In other words, it does not have a single server for storing data. Instead, Utopia creates a separate server for each user. Access to it is via a private key that is generated at the stage of anonymous registration.</p>



<p>For protection, the ecosystem uses multi-level encryption based on an elliptical curve and 256-bit AES. This method reliably protects and stores files.</p>



<p>uMessenger provides encrypted messages transfer. It can be either text or voice messages, and you can add different media files or attach stickers to messages. The messenger has a built-in function for creating private chats and channels. Everything is anonymous and uncensored.</p>



<p><a href="https://hoccer.com/" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener nofollow"><strong><em>Hoccer</em></strong></a></p>



<figure><img loading="lazy" decoding="async" src="https://utopia.fans/wp-content/webp-express/webp-images/uploads/2020/09/Hoccer.png.webp" alt="Hoccer WhatsApp alternative" srcset="https://utopia.fans/wp-content/webp-express/webp-images/uploads/2020/09/Hoccer.png.webp 200w,  https://utopia.fans/wp-content/webp-express/webp-images/uploads/2020/09/Hoccer-150x150.png.webp 150w" sizes="(max-width: 200px) 100vw, 200px"></figure>



<p>Hoccer is a German messenger that is becoming popular all over the world. This is due to the high degree of security and anonymity of each user. It uses end-to-end encryption method for data protection.</p>



<p>Data encryption includes absolutely all messages and files: images, audio and video, contacts, messages, and geolocation. Hoccer does not limit the size or format of files to be transmitted. However, a call function is not provided in the app.</p>



<p>Registration is anonymous: users do not enter personal data when logging in. The app does not request a phone number, email address, etc.</p>



<p>The user may include further protection by using a password. IOS users can also take advantage of another additional feature: the app will take a picture of unauthorized persons who want to get access to the account.</p>



<p><strong><em><u><a href="https://app.element.io/" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener nofollow">Element</a></u></em></strong></p>



<figure><img loading="lazy" decoding="async" src="https://utopia.fans/wp-content/webp-express/webp-images/uploads/2020/09/Element.jpg.webp" alt="Element WhatsApp alternative"></figure>



<p>This app focuses on calls, conferences, and a lot of other advanced actions. Also, Element Instant Messenger is focused on data privacy. The application is based on the Matrix protocol, and it has a very good reputation in the field of communication security.&nbsp; In addition, it uses an open source code that is constantly being upgraded to achieve maximum security.&nbsp;</p>



<p><a href="https://utopia.fans/security/whats-the-difference-between-open-source-vs-closed-source/"><em>Open Source vs Closed Source</em></a><em>: what to choose for reliable protection of users’ data? Read the article and make the right choice.</em></p>



<p>Here is a list of privacy features of the app:</p>



<ul><li>No phone numbers. Users don’t need to specify personal phone numbers to start using the messenger.</li><li>End-to-end encryption. It is used while sending and receiving messages. But the user should enable the feature manually (it doesn’t work by default).</li><li>Control over message history. Users can make adjustments to the message history.</li></ul>



<p>Element is available on popular mobile platforms, and it also helps to send and receive any type of file. It is possible to forward both minuscule .txt files and entire movies.&nbsp;</p>



<p>The perfect organization and successful choice of communication technologies make the app one of the most secure messengers.</p>



<p><a href="https://threema.ch/en" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener nofollow"><strong><em>Threema</em></strong></a></p>



<figure><img loading="lazy" decoding="async" src="https://utopia.fans/wp-content/webp-express/webp-images/uploads/2020/09/Threema.png.webp" alt="Threema WhatsApp alternative" srcset="https://utopia.fans/wp-content/webp-express/webp-images/uploads/2020/09/Threema.png.webp 512w,  https://utopia.fans/wp-content/webp-express/webp-images/uploads/2020/09/Threema-300x300.png.webp 300w,  https://utopia.fans/wp-content/webp-express/webp-images/uploads/2020/09/Threema-150x150.png.webp 150w" sizes="(max-width: 512px) 100vw, 512px"></figure>



<p>Threema is a Swiss application for instant messaging between people. It uses E2E encryption for each transmitted message. Moreover, all messages will be deleted from the server after reading.</p>



<p>The only way to manage contacts and groups is from the source device. This function is blocked for the server. When contacts have been synced, Threema anonymously transfers them and encodes all data.</p>



<p>As a reliable WhatsApp alternative, it does not store metadata that includes the sender and receiver of the message. In other words, the level of data privacy is higher than its competitors.</p>



<p>The servers are located in Switzerland: this assures the privacy and security of using this application for communication.</p>



<p><a href="https://wire.com/en/" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener nofollow"><strong><em>Wire</em></strong></a></p>



<figure><img loading="lazy" decoding="async" src="https://utopia.fans/wp-content/webp-express/webp-images/uploads/2020/09/Wire.png.webp" alt="Wire WhatsApp alternative" srcset="https://utopia.fans/wp-content/webp-express/webp-images/uploads/2020/09/Wire.png.webp 466w,  https://utopia.fans/wp-content/webp-express/webp-images/uploads/2020/09/Wire-300x295.png.webp 300w" sizes="(max-width: 466px) 100vw, 466px"></figure>



<p>Wire is a fairly new messenger. It was released in 2014 by a Swiss company. But the entire message exchange process takes place via German servers.</p>



<p>Wire is based on E2E encryption with Whisper systems. It stores metadata anonymously, like Telegram. However, this function can be disabled here.</p>



<p>In addition, there is a voice-over-IP function that allows making group calls, like on Skype. All incoming and outgoing calls are protected from listening and surveillance. That is, unlike WhatsApp, the app encrypts each voice and video call.</p>



<p><em>Did you hear about the </em><a href="https://utopia.fans/privacy/data-leak-of-telegram-user-base/"><em>Data Leak of Telegram User Base</em></a><em>? We are shocked too! Read about the massive data leak in our blog.</em></p>



<p><a href="https://wickr.com/" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener nofollow"><strong><em>Wickr Me</em></strong></a></p>



<figure><img loading="lazy" decoding="async" src="https://utopia.fans/wp-content/webp-express/webp-images/uploads/2020/09/Wickr-Me.png.webp" alt="Wickr Me WhatsApp alternative" srcset="https://utopia.fans/wp-content/webp-express/webp-images/uploads/2020/09/Wickr-Me.png.webp 320w,  https://utopia.fans/wp-content/webp-express/webp-images/uploads/2020/09/Wickr-Me-300x300.png.webp 300w,  https://utopia.fans/wp-content/webp-express/webp-images/uploads/2020/09/Wickr-Me-150x150.png.webp 150w" sizes="(max-width: 320px) 100vw, 320px"></figure>



<p>Wickr Me is a popular messenger that is actively used to send important data by journalists, leaders of countries and other people who have really serious secrets.</p>



<p>Wickr Me uses a phone number for authorization. There are also various useful features, like emoticons or stickers.</p>



<p>The app does not save personal contacts on its own servers. Wickr Me does not store metadata and completely erases messages at the user’s request (without the possibility of recovery).</p>



<p>The app is free, contains no ads, and supports the most secure encryption technologies. It is a really decent alternative to WhatsApp.&nbsp;</p>



<h3>Conclusion&nbsp;</h3>



<p>WhatsApp has gained real popularity among users. Everybody thought that it was a perfect app that met all privacy standards. Under Facebook’s management, the service has further developed. It has added a lot of useful features that have made WhatsApp more competitive among other apps.&nbsp;</p>



<p>However, recently Facebook has turned the app into an advertising platform. And if you don’t want to leak your data to companies and constantly watch ads, you should consider changing your messenger.</p>



<p><a href="https://utopia.fans/privacy/another-privacy-issue-of-facebook-is-there-any-solution/"><em>Another Privacy Issue Of Facebook: Is There Any Solution?</em></a><em> Read the previous article about the opposite side of Facebook.</em></p>
                          	
                      	</article></div>]]>
            </description>
            <link>https://utopia.fans/security/is-there-a-whatsapp-alternative-for-daily-chatting/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24441560</guid>
            <pubDate>Fri, 11 Sep 2020 11:34:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[European Commission Funds Open-Source Federated Cloud Platform]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24441521">thread link</a>) | @lennyhorstink
<br/>
September 11, 2020 | https://www.crust.tech/european-commission-funding-for-open-source-federated-cloud-platform/ | <a href="https://web.archive.org/web/*/https://www.crust.tech/european-commission-funding-for-open-source-federated-cloud-platform/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>Cork/Amsterdam<br>
10 September 2020</p>
<p><a href="https://www.crust.tech/">Crust Technology</a>, the leading open-source Low-Code Development platform and Salesforce alternative, is being funded by the European Commission’s <a href="https://nlnet.nl/NGI0/">Next Generation Internet</a> initiative <strong>to</strong> <strong>deliver the <a href="https://cortezaproject.org/">Corteza</a> platform as a federated cloud solution for record sharing</strong>. Crust, the founder and full-time maintainer of the Corteza Project, will enable the platform to share select components of data layer or entire data models, on a one-to-many or many-to-many basis. The new features will allow business data, but also open data sets created by public sector organisations and academia to be shared more easily.</p>
<p><img src="https://i0.wp.com/www.crust.tech/wp-content/uploads/2020/09/NGI-zero-logo.png?resize=300%2C84&amp;ssl=1" alt="" width="300" height="84" srcset="https://i0.wp.com/www.crust.tech/wp-content/uploads/2020/09/NGI-zero-logo.png?resize=300%2C84&amp;ssl=1 300w, https://i0.wp.com/www.crust.tech/wp-content/uploads/2020/09/NGI-zero-logo.png?resize=1030%2C290&amp;ssl=1 1030w, https://i0.wp.com/www.crust.tech/wp-content/uploads/2020/09/NGI-zero-logo.png?resize=768%2C216&amp;ssl=1 768w, https://i0.wp.com/www.crust.tech/wp-content/uploads/2020/09/NGI-zero-logo.png?resize=705%2C198&amp;ssl=1 705w, https://i0.wp.com/www.crust.tech/wp-content/uploads/2020/09/NGI-zero-logo.png?resize=450%2C127&amp;ssl=1 450w, https://i0.wp.com/www.crust.tech/wp-content/uploads/2020/09/NGI-zero-logo.png?w=1241&amp;ssl=1 1241w" sizes="(max-width: 300px) 100vw, 300px" data-recalc-dims="1"></p>

<p>Among other features, Corteza provides a decentralised cloud alternative to the likes of Salesforce or Microsoft Dynamics365. Unlike these expensive competitors, Corteza can be self-hosted, maintained and customised from top to bottom by organisations – granting full sovereignty and control to both organisations and end users. The Corteza platform is used by well-known corporations, Fortune 1000 businesses, and large-scale public institutions.</p>
<blockquote><p>“<em>We are delighted to have been given this opportunity by the European Union NGI Zero Programme</em>” <strong>says Niall McCarthy, CEO of Crust Technology and Chair of the Corteza Project.</strong> “<em>Our goal is to deliver federated clouds where the user and administrator experience looks, feels and operates like centralised clouds, but which is in practice underpinned by a more equitable, decentralised architecture of cloud peers.</em>”</p></blockquote>
<blockquote><p>“<em>Much recent work on decentralised systems has focused on peer-to-peer use cases rather than cloud-to-cloud sharing at scale</em>” <strong>says Michiel Leenaars, co-ordinator of the NGI Zero Discovery fund.</strong> “<em>But of course organisations need to share a lot of data too, and that data changes all the time. We don’t want thousands of stale copies of data lingering around. The new functionality of Corteza developed within the project will make it possible for even small organisations to share complex data as equals in a standardised manner. Just like you can follow a social media account, you will be able to maintain a single origin of data with all the security and privacy benefits. The new web standard, ActivityPub, subsequently enbles this data to be used across hundreds or even thousands of places on the internet in near realtime. This represents an interesting step forward for organisations wishing to collaborate, while also wanting to simplify their own setup and protect the privacy of their valuable users.</em>”</p></blockquote>
<blockquote><p>“<em>Corteza Federation will resolve the need for high quality, standards-based collaboration with the need for cloud digital and data sovereignty demanded across Europe and beyond</em>” <strong>adds McCarthy.</strong> “<em>Delivered in the modern, high-performance computing languages of Golang and Vue.js, much of Crust’s efforts will also focus on ensuring that the Corteza user experience (UX) is everything organisations expect and more from competitive cloud technology.</em>”</p></blockquote>
<p>Corteza Federation will be available for release in December 2020. A full suite of mock-ups can be viewed on <a href="https://cortezaproject.org/corteza-federation-previews">https://cortezaproject.org/corteza-federation-previews</a>.</p>
<p><a href="https://i2.wp.com/www.crust.tech/wp-content/uploads/2020/09/Federated-records-in-a-Corteza-Low-Code-Platform-module.png?ssl=1"><img src="https://i2.wp.com/www.crust.tech/wp-content/uploads/2020/09/Federated-records-in-a-Corteza-Low-Code-Platform-module.png?resize=1030%2C529&amp;ssl=1" alt="" width="1030" height="529" srcset="https://i2.wp.com/www.crust.tech/wp-content/uploads/2020/09/Federated-records-in-a-Corteza-Low-Code-Platform-module.png?resize=1030%2C529&amp;ssl=1 1030w, https://i2.wp.com/www.crust.tech/wp-content/uploads/2020/09/Federated-records-in-a-Corteza-Low-Code-Platform-module.png?resize=300%2C154&amp;ssl=1 300w, https://i2.wp.com/www.crust.tech/wp-content/uploads/2020/09/Federated-records-in-a-Corteza-Low-Code-Platform-module.png?resize=768%2C394&amp;ssl=1 768w, https://i2.wp.com/www.crust.tech/wp-content/uploads/2020/09/Federated-records-in-a-Corteza-Low-Code-Platform-module.png?resize=1536%2C788&amp;ssl=1 1536w, https://i2.wp.com/www.crust.tech/wp-content/uploads/2020/09/Federated-records-in-a-Corteza-Low-Code-Platform-module.png?resize=1500%2C770&amp;ssl=1 1500w, https://i2.wp.com/www.crust.tech/wp-content/uploads/2020/09/Federated-records-in-a-Corteza-Low-Code-Platform-module.png?resize=705%2C362&amp;ssl=1 705w, https://i2.wp.com/www.crust.tech/wp-content/uploads/2020/09/Federated-records-in-a-Corteza-Low-Code-Platform-module.png?resize=450%2C231&amp;ssl=1 450w, https://i2.wp.com/www.crust.tech/wp-content/uploads/2020/09/Federated-records-in-a-Corteza-Low-Code-Platform-module.png?w=1853&amp;ssl=1 1853w" sizes="(max-width: 1030px) 100vw, 1030px" data-recalc-dims="1"></a>Federated records in a Corteza Low-Code platform application</p>
<h2>About Crust Technology</h2>
<p>Crust Technology Ltd, headquartered in Ireland, is the driving force behind Crust, the free and open-source low-code platform and Salesforce alternative. Besides the advanced low-code platform for rapid application development, Crust includes a fully featured CRM, Service Cloud, Enterprise Messaging, Crust Unify for application management, and End-to-End Business Automation. All 100% free, open and completely standardised. For more information or an online demo, visit <a href="https://www.crust.tech/">www.crust.tech</a> or follow <a href="https://twitter.com/crusttech">@Crusttech</a> on Twitter.</p>
<h2>About Corteza</h2>
<p>Corteza is the Digital Work Platform for Humanity. The Corteza project builds a 100% open-source, self-hosted cloud platform for growing your organisation’s productivity. It enables relationships and protects the work and the privacy of all those concerned. Corteza is developed entirely in the public domain, including its design considerations and processes. To download Corteza and for more information about the project, visit <a href="https://cortezaproject.org/">www.cortezaproject.org</a> or follow <a href="https://twitter.com/CortezaProject">@CortezaProject</a> on Twitter.</p>
<h2>About NGI Zero and the European Union Next Generation Internet</h2>
<p>NGI Zero is a unique group of organisations that fund and nurture trustworthy, secure and privacy-strengthening technologies as part of the Next Generation Internet initiative of the European Commission. The overall mission of the Next Generation Internet Initiative is to re-imagine and re-engineer the internet for the third millennium and beyond. In order to preserve and expand the European way of life, NGI helps shape a value-centric, human and inclusive internet for all. For more information , visit <a href="https://nlnet.nl/NGI0/">nlnet.nl/NGI0</a> or <a href="https://www.ngi.eu/">www.ngi.eu</a>.</p>
</div></div>]]>
            </description>
            <link>https://www.crust.tech/european-commission-funding-for-open-source-federated-cloud-platform/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24441521</guid>
            <pubDate>Fri, 11 Sep 2020 11:28:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Privacy and Security Tools for Beginners – Listicle]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24441458">thread link</a>) | @Clo_S
<br/>
September 11, 2020 | https://thistooshallgrow.com/blog/privacy-security-tools-beginners | <a href="https://web.archive.org/web/*/https://thistooshallgrow.com/blog/privacy-security-tools-beginners">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page" role="main">
        
          <article data-page-sections="5e89e9e1a4e68d60672900f3" id="sections">
  
    <section data-section-id="5e89e9e1a4e68d60672900f5" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
  &quot;imageOverlayOpacity&quot; : 0.15,
  &quot;video&quot; : {
    &quot;playbackSpeed&quot; : 0.5,
    &quot;filter&quot; : 1,
    &quot;filterStrength&quot; : 0,
    &quot;zoom&quot; : 0
  },
  &quot;backgroundWidth&quot; : &quot;background-width--full-bleed&quot;,
  &quot;sectionHeight&quot; : &quot;section-height--medium&quot;,
  &quot;horizontalAlignment&quot; : &quot;horizontal-alignment--center&quot;,
  &quot;verticalAlignment&quot; : &quot;vertical-alignment--middle&quot;,
  &quot;contentWidth&quot; : &quot;content-width--wide&quot;,
  &quot;sectionTheme&quot; : &quot;white&quot;,
  &quot;sectionAnimation&quot; : &quot;none&quot;,
  &quot;backgroundMode&quot; : &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      <div data-content-field="main-content" data-item-id="">
  <article id="article-">
  
    <div>
      

      <div>
        <div><div data-layout-label="Post Body" data-type="item" id="item-5f5618188063d02159095855"><div><div><div data-block-type="2" id="block-6d47c3bb0fca7a134d4e"><div><p>A while ago, <a href="https://twitter.com/NGoerne" target="_blank">Nora</a> asked me if I had a list of privacy tools I use regularly. I didn't, so I wrote one with the help of <a href="https://twitter.com/lp1eu" target="_blank">lp1</a>, and you're about to read it. These are the tools we’ve been using for a while and we recommend.</p><p>In a <em>Choose your own adventure </em>fashion: if you want to learn about the security concepts we’re going to refer to, such as encryption and hashing, <a href="https://thistooshallgrow.com/blog/privacy-security-roundup" target="_blank">jump to part 1</a>. Otherwise, enjoy your read 😉</p><h2>Online security and anonymity</h2><h3><a href="https://protonvpn.com/secure-vpn" target="_blank">ProtonVPN</a></h3><p><strong>What it does</strong></p><ul data-rte-list="default"><li><p>ProtonVPN makes your connection go through one or several servers before reaching its destination, which makes it very complex for someone to discover your IP address, or match online activities to your IP address. An IP address is a network’s unique identifier provided by your ISP (Internet Service Provider), whether it’s from a mobile data plan or an at-home router.</p></li><li><p>Each session generates its own encryption key.</p></li><li><p>Another interest of VPNs is the ability to channel your traffic via other countries. Don’t hesitate to check privacy laws there. For instance, ISPs in <a href="https://www.ivpn.net/internet-privacy-laws-in-the-united-states" target="_blank">the United States</a>, <a href="https://www.privateinternetaccess.com/blog/new-cybersecurity-law-companies-china-will-store-connecting-ip-address-six-months/" target="_blank">China</a>, and <a href="https://www.ivpn.net/internet-privacy-laws-in-france" target="_blank">France</a> are required to hand logs over if the government asks for them. <a href="https://www.ivpn.net/comparison-of-internet-privacy-laws" target="_blank">Here</a>’s an interesting comparison among 13 countries.</p></li><li><p>Proton VPN is open source.</p></li><li><p>The company is regularly vocal about protecting journalists and activists, as well as freedom of speech. 50% of their July and August revenue from Hong Kong is to be donated to <a href="https://protonvpn.com/blog/hongkong/" target="_blank">2 organisations</a> expected to make a ‘meaningful impact on democracy and rule of law for Hong Kongers’.&nbsp;</p></li></ul><p><strong>Why you might want to use it</strong></p><ul data-rte-list="default"><li><p>They prevent their users’ connection and history from being handed over to any third party.</p></li><li><p>Your Internet Service Provider doesn’t know what websites you visit.</p></li><li><p>You can browse the Internet from different countries.</p></li><li><p>Using your true IP address, governmental authorities in most countries can require ISPs to provide them with the identity of whoever subscribed to the associated Internet plan.</p></li></ul><h3><a href="https://brave.com/" target="_blank">Brave</a></h3><p><strong>What it does</strong></p><ul data-rte-list="default"><li><p>Brave is an open source web browser that <a href="https://brave.com/features/" target="_blank">blocks most invasive ad trackers</a>. It’s like having AdBlock or uBlock, but you don't have to install anything on top of your browser. You can configure it to adapt it to your specific needs.</p></li><li><p>It's built on top of Google’s open source version of Chrome: Chromium. As a result, most browser extensions built for Google Chrome automatically work on Brave.</p></li><li><p>Brave (amongst other goodies) supports the <a href="https://www.torproject.org/" target="_blank">Tor</a> network which allows you to limit the possibilities of disclosure and tracking of your IP addresses.</p></li></ul><p><strong>Why you might want to use it</strong></p><ul data-rte-list="default"><li><p>Brave is great if you want a hassle-free privacy-oriented browser - please note it isn't foolproof, nothing is. You will be tracked by some, but at least you'll block most identifiable trackers.</p></li><li><p>You can use it on Windows, MacOS, GNU/Linux, iOS and Android.</p></li><li><p>It’s one of the simplest ways to connect to the Tor network.</p></li></ul><h3><a href="https://everestpipkin.github.io/image-scrubber/" target="_blank">Image scrubber</a></h3><p><strong>What it does</strong></p><p>Image scrubber removes Exif data from your images and allows you to paint over them. It’s made by <a href="https://twitter.com/everestpipkin/status/1266936398055170048" target="_blank">@everestpipkin</a>.</p><p><a href="https://en.wikipedia.org/wiki/Exif" target="_blank">Exif</a> is an image and sound format that contains extensive metadata. With Exif, your photos - whether taken with a smart device or a regular digital camera - can include:</p><ul data-rte-list="default"><li><p>Exact GPS location</p></li><li><p>Date and time your photo was taken</p></li><li><p>Information on your device: unique ID number, manufacturer, model</p></li><li><p>Camera settings: compression, orientation, aperture, shutter speed, focal length, whether the flash was used, etc.</p></li></ul><p>Here’s the information displayed by Image scrubber from a random shot I just took. Yes, all of this is embedded in your photo.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1599477789054_6130"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e88c56caafd451f4ce3ec83/1599479346998-3Q6WF893EEL94UE8N8W2/ke17ZwdGBToddI8pDm48kJJa24XYJIkTw5gA_H4FJZ0UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8PaoYXhp6HxIwZIk7-Mi3Tsic-L2IOPH3Dwrhl-Ne3Z2gynClJDExW0dxEDCym_tylheLi0ODM3JaouZ9yQZ4qFm0nepH0bYFh4DTA4Bp5g2/Exif+-+clean.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5e88c56caafd451f4ce3ec83/1599479346998-3Q6WF893EEL94UE8N8W2/ke17ZwdGBToddI8pDm48kJJa24XYJIkTw5gA_H4FJZ0UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8PaoYXhp6HxIwZIk7-Mi3Tsic-L2IOPH3Dwrhl-Ne3Z2gynClJDExW0dxEDCym_tylheLi0ODM3JaouZ9yQZ4qFm0nepH0bYFh4DTA4Bp5g2/Exif+-+clean.jpg" data-image-dimensions="952x1060" data-image-focal-point="0.5,0.5" alt="A screenshot of the Exif data of my photo, with over 40 tags." data-load="false" data-image-id="5f561e3264c7ed68b8d3f08f" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5e88c56caafd451f4ce3ec83/1599479346998-3Q6WF893EEL94UE8N8W2/ke17ZwdGBToddI8pDm48kJJa24XYJIkTw5gA_H4FJZ0UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8PaoYXhp6HxIwZIk7-Mi3Tsic-L2IOPH3Dwrhl-Ne3Z2gynClJDExW0dxEDCym_tylheLi0ODM3JaouZ9yQZ4qFm0nepH0bYFh4DTA4Bp5g2/Exif+-+clean.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1599477789054_6419"><div><p>Thankfully, some services (such as Twitter) automatically remove the Exif data when you post a picture.</p><p><strong>Why you might want to use it</strong></p><ul data-rte-list="default"><li><p>Exif has been used to locate <a href="https://www.eff.org/deeplinks/2012/04/picture-worth-thousand-words-including-your-location" target="_blank">people</a> and <a href="https://www.bellingcat.com/news/rest-of-world/2016/01/11/china-bolstered-rotations-at-gonggar/" target="_blank">events</a>. The location data can be very precise, and even include your phone’s orientation at the time of the photo, via the GPSImgDirection tag.&nbsp;</p></li><li><p>Painting over faces and any identifying details can also protect you. Just make note that covering a zone seems safer than blurring it, as blurring could be reversed - with varying accuracy.</p></li><li><p>It is free software (under MIT license).</p></li><li><p>It’s a web tool, you don’t need to download anything to use it. It’s perfect to be used on the fly.</p></li></ul><h2>Passwords and authentication</h2><h3><a href="https://en.wikipedia.org/wiki/Multi-factor_authentication" target="_blank"><strong>Multi-Factor Authentication</strong></a></h3><p><strong>What it does</strong></p><p>MFA is a way to verify identity, 2FA meaning there are strictly two factors needed.</p><p>The 3 main types of authentication factors are:</p><ul data-rte-list="default"><li><p><em>Something I know</em>: any type of password, code, information</p></li><li><p><em>Something I am</em>: biometrics</p></li><li><p><em>Something I own</em>: a specific object or device</p></li></ul><p>For instance, if you withdraw money at an ATM, you combine something you own (your card) with something you know (your code).</p><p><strong>Why you might want to use it</strong></p><ul data-rte-list="default"><li><p>Multi-factor authentication is an additional layer of security compared to single-factor authentication. It's some kind of safety net in case someone has your password and wants to break into your account.</p></li><li><p>MFA can also be an interesting protection against credential stuffing attacks.</p></li></ul><h3><a href="https://lesspass.com/" target="_blank">LessPass</a></h3><p><strong>What it does</strong></p><ul data-rte-list="default"><li><p>LessPass is an open source tool created by <a href="https://twitter.com/guillaume20100" target="_blank">@guillaume20100</a>.</p></li><li><p>Given several parameters, it provides you with strong and customisable passwords.</p></li><li><p>It works like a hashing tool: it uses the URL you are on, your username/email, a (possibly unique) strong password and a few settings (length, symbols, numbers, etc.) to generate your hard-to-guess unique password.</p></li><li><p>It’s a stateless tool, meaning that nothing is stored, and therefore nothing can be stolen. I (Clo) have been using it for nearly 3 years, and I enjoy the philosophy and simplicity of statelessness.</p></li><li><p>LessPass is available as a browser extension, a website and an Android application.</p></li></ul><p><strong>Why you might want to use it</strong></p><ul data-rte-list="default"><li><p>The specific advantage of LessPass is that you only have 1 password to remember for all your accounts, while also being protected against evil hackers (brrr) who might break into your password vault, because *pause for dramatic effect* there is no vault. Thus, there is no vault to break into. Unstoppable. We love it.</p></li><li><p>It’s highly customisable, as you can see in the screenshot below.</p></li></ul></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1599479537382_5684"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e88c56caafd451f4ce3ec83/1599480286299-FR0GYOLLFB5XIXEFNPNW/ke17ZwdGBToddI8pDm48kOIJZh_s7PTWO_0PO4_SqzFZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpy_hVz5CdFijmevSQ05DTabsTC4ohLN1b5vY4CuTbUOFF6rMUdzd9S6AZgbW9ThRKc/LessPass.png" data-image="https://images.squarespace-cdn.com/content/v1/5e88c56caafd451f4ce3ec83/1599480286299-FR0GYOLLFB5XIXEFNPNW/ke17ZwdGBToddI8pDm48kOIJZh_s7PTWO_0PO4_SqzFZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpy_hVz5CdFijmevSQ05DTabsTC4ohLN1b5vY4CuTbUOFF6rMUdzd9S6AZgbW9ThRKc/LessPass.png" data-image-dimensions="640x688" data-image-focal-point="0.5,0.5" alt="Screenshot of LessPass with the fields and buttons used to customise your output." data-load="false" data-image-id="5f5621de35cfcb0f5c06d6c7" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5e88c56caafd451f4ce3ec83/1599480286299-FR0GYOLLFB5XIXEFNPNW/ke17ZwdGBToddI8pDm48kOIJZh_s7PTWO_0PO4_SqzFZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpy_hVz5CdFijmevSQ05DTabsTC4ohLN1b5vY4CuTbUOFF6rMUdzd9S6AZgbW9ThRKc/LessPass.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1599479537382_8799"><div><h3><a href="http://haveibeenpwned.com/" target="_blank">Have I Been Pwned</a></h3><p><strong>What it does</strong></p><ul data-rte-list="default"><li><p>It’s a web tool allowing you to check whether your email address has been part of one or several data leaks. It also lets you know which platforms leaked your private information.</p></li><li><p>You can register an email or a whole domain name to be notified whenever they're included in new data breaches.</p></li><li><p>Have I Been Pwned was created and is maintained by <a href="https://twitter.com/troyhunt" target="_blank">Troy Hunt</a>. He has received <a href="https://www.troyhunt.com/microsoft-regional-director" target="_blank">several awards from Microsoft</a>, recognising his contribution and evangelisation of Microsoft technologies. He has also <a href="https://www.troyhunt.com/heres-what-im-telling-us-congress-about-data-breaches/" target="_blank">testified before the US congress</a> on the topic of data breaches.</p></li><li><p>The tool is <a href="https://www.troyhunt.com/im-open-sourcing-the-have-i-been-pwned-code-base/" target="_blank">about to be open sourced</a>.</p></li></ul><p>&nbsp;Here’s the result for one of my email addresses:</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1599479537382_9594"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e88c56caafd451f4ce3ec83/1599480660815-K8WSZLQ42DTZNDA159NZ/ke17ZwdGBToddI8pDm48kFcMOSSOTvdfHk85rRmi8PMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKc0OV40cV-V3aNFJjaXGbwswph3pC3lQTEkMbhTLpRdHfNQk3aYSUvmcR51ogotm4b/HaveIbeenpwned.png" data-image="https://images.squarespace-cdn.com/content/v1/5e88c56caafd451f4ce3ec83/1599480660815-K8WSZLQ42DTZNDA159NZ/ke17ZwdGBToddI8pDm48kFcMOSSOTvdfHk85rRmi8PMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKc0OV40cV-V3aNFJjaXGbwswph3pC3lQTEkMbhTLpRdHfNQk3aYSUvmcR51ogotm4b/HaveIbeenpwned.png" data-image-dimensions="1444x666" data-image-focal-point="0.5,0.5" alt="A screenshot from Have I Been Pwned warning me that my email address was in the Canva breach of May 2019 and in the Dailymotion breach of October 2016." data-load="false" data-image-id="5f5623539a612620ecf92f27" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5e88c56caafd451f4ce3ec83/1599480660815-K8WSZLQ42DTZNDA159NZ/ke17ZwdGBToddI8pDm48kFcMOSSOTvdfHk85rRmi8PMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKc0OV40cV-V3aNFJjaXGbwswph3pC3lQTEkMbhTLpRdHfNQk3aYSUvmcR51ogotm4b/HaveIbeenpwned.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1599479537382_9883"><div><p><strong>Why you might want to use it</strong></p><ul data-rte-list="default"><li><p>Not all companies victims of data breaches notify you, even though companies operating in the EU should <a href="https://gdpr-info.eu/art-33-gdpr/" target="_blank">legally send a notification</a> for a personal data breach within 72 hours.</p></li><li><p>Even when most of them do send an email to their userbase after an incident, those emails might end up in SPAM or not be read. Have I Been Pwned is quite an exhaustive and quick way to know when and by whom your password, email address or other private information has been leaked.</p></li></ul><p>As a recommendation, if your credentials are concerned by a data breach, change them ASAP. It’s good practice to change them regularly anyway.</p><h2>Conversations</h2><h3><a href="https://protonmail.com/" target="_blank">ProtonMail</a></h3><p><strong>What it does</strong></p><ul data-rte-list="default"><li><p>This is the email tool from the company that provides the ProtonVPN service we’ve mentioned above.</p></li><li><p>Storage on ProtonMail's servers and transmission between the servers and users' devices are encrypted.</p></li><li><p>Emails between ProtonMail users are <a href="https://protonmail.com/security-details" target="_blank">end-to-end encrypted</a>. It’s also possible to encrypt emails when your contact is on another provider.</p></li><li><p>They use proven open source cryptographic algorithms.</p></li><li><p>ProtonMail's web client is <a href="https://github.com/ProtonMail/WebClient" target="_blank">open source</a>.</p></li></ul><p><strong>Why you might want to use it</strong></p><ul data-rte-list="default"><li><p>Contrary to <a href="https://securityboulevard.com/2019/11/does-google-read-your-email/" target="_blank">most email providers</a>, ProtonMail can't read or search your emails to extract information (thanks to end-to-end encryption).</p></li><li><p>Also contrary to many big providers, with ProtonMail your data isn't stored in the US, it's stored in Switzerland which has <a href="https://protonmail.com/blog/switzerland/" target="_blank">strict privacy laws</a>.</p></li><li><p>You don't need to provide any personal information to create your ProtonMail account, it can be reasonably anonymous.</p></li></ul><h3><a href="https://telegram.org/" target="_blank">Telegram</a></h3><p><strong>What it does</strong></p><ul data-rte-list="default"><li><p>Telegram is a messaging service built by a Russian team who moved to Dubai <a href="https://telegram.org/faq#q-where-is-telegram-based" target="_blank">because of Russian IT regulations</a>.</p></li><li><p><a href="https://telegram.org/apps#source-code" target="_blank">Official clients</a> are open source.</p></li><li><p>You can create ‘secret chats’ which are end-to-end encrypted. As we explained, this means that no one at Telegram can access what you share there.</p></li><li><p>The team also recently announced <a href="https://telegram.org/blog/video-calls?ln=f" target="_blank">end-to-end encrypted video calls</a>.</p></li><li><p>While working on the Image Scrubber part of this article, I (Clo) first tried sending myself the photo via Telegram. As I tried scrubbing it, I noticed that Telegram had automatically scrubbed the Exif and renamed my file. Nice. Here’s a screenshot from my computer. On the left, you have the picture I sent myself via Gmail. It has the original name - giving away the date and time of the photo - and carries the Exif data. On the right is the file I sent myself via Telegram - which features a randomised name, and no Exif at all.</p></li></ul></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1599479537382_12827"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e88c56caafd451f4ce3ec83/1599481157660-6RNANT6GGIHRE5U5KKIY/ke17ZwdGBToddI8pDm48kLO7zuKK8nogXcInNf5F5XpZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVFovG2rtrPWfUOHuuRkDIRNr6JBg1VpzLUR6Kswfa-bej-3CTWZQ124CTRPXn-dnvM/difference-photos.PNG" data-image="https://images.squarespace-cdn.com/content/v1/5e88c56caafd451f4ce3ec83/1599481157660-6RNANT6GGIHRE5U5KKIY/ke17ZwdGBToddI8pDm48kLO7zuKK8nogXcInNf5F5XpZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVFovG2rtrPWfUOHuuRkDIRNr6JBg1VpzLUR6Kswfa-bej-3CTWZQ124CTRPXn-dnvM/difference-photos.PNG" data-image-dimensions="343x223" data-image-focal-point="0.5,0.5" alt="A screenshot of 2 identical photos. On the left, the name is “IMG_20200730_195508”. On the right, it is “photo5843433754058667015”." data-load="false" data-image-id="5f562545416c7273cd621546" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1599479537382_13116"><div><p>However:</p><ul data-rte-list="default"><li><p>Default chats …</p></li></ul></div></div></div></div></div></div></div></div></article></div></div></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thistooshallgrow.com/blog/privacy-security-tools-beginners">https://thistooshallgrow.com/blog/privacy-security-tools-beginners</a></em></p>]]>
            </description>
            <link>https://thistooshallgrow.com/blog/privacy-security-tools-beginners</link>
            <guid isPermaLink="false">hacker-news-small-sites-24441458</guid>
            <pubDate>Fri, 11 Sep 2020 11:20:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kubernetes Disaster Recovery with Velero]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24441435">thread link</a>) | @wecloudpro
<br/>
September 11, 2020 | https://www.wecloudpro.com/2020/08/22/kubernetes-disaster-recovery-with-velero.html | <a href="https://web.archive.org/web/*/https://www.wecloudpro.com/2020/08/22/kubernetes-disaster-recovery-with-velero.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <!-- Wrapper Start -->
  <section id="intro">
    <div>
      <div>
        <div>
          <div>
            
            <p>By <span>Alberto</span> on <span>August 22, 2020</span></p>
            <hr>
            <p>
<img src="https://www.wecloudpro.com/assets/img/velero/velero.png" alt="main">
</p>



<p><a href="https://github.com/vmware-tanzu/velero">Velero</a> is an open source tool to safety back up, recover, and migrate Kubernetes clusters and persistent volumes. It works both on premises and in public clouds.</p>

<p>Velero components are:</p>
<ul>
  <li>Command line interface</li>
  <li>Kubernetes server application</li>
</ul>

<p>Velero is a convenient backup tool for Kubernetes clusters that compresses and backs up Kubernetes objects to object storage. It also takes snapshots of your cluster’s Persistent Volumes using your cloud provider’s block storage snapshot features, and can then restore your cluster’s objects and Persistent Volumes to a previous state.</p>

<p>In this tutorial we’ll set up and configure the velero command line tool on a local machine, and deploy the server component into our Kubernetes cluster. We’ll then deploy a sample Nginx app and a Redis cluster that uses Persistent Volume for data and then simulate a disaster recovery scenario</p>

<p>At the time of writing this article. The last published version is: <a href="https://github.com/vmware-tanzu/velero/releases/tag/v1.5.0-beta.1">v1.5.0-beta.1</a></p>

<p>However, to avoid stability problems, we are going to install the latest stable version: v1.4.2</p>




<p><strong>Velero Uses Cases</strong></p>


<p>
<img src="https://www.wecloudpro.com/assets/img/velero/velero-use-cases.png" alt="velero-use-cases">
</p>
<p><strong>source:</strong> www.cncf.io</p>




<div><div><pre><code>• Backup and restore of kubernetes objects
    ◦ Uses Kubernetes Discovery API
    ◦ Does not need to talk directly to etcd
    ◦ Backups stored in Cloud Object Storage

• Backup and restore persisten volumes
    ◦ Uses cloud provider snapshots APIs
    ◦ Restic support for file system backups
</code></pre></div></div>




<p><strong>Backup/restore applications and Persitent Volumes</strong></p>

<p>In order to demonstrate the capabilities of Velero for disaster recovery, I have a Nginx pod running with a Persistent Volume on AWS using the <a href="https://docs.aws.amazon.com/eks/latest/userguide/storage-classes.html">GP2 storageclass</a></p>

<p>Checking our app and the PV inside kubernetes:</p>






<p>Below we can see the Persistent volume on AWS:</p>


<p>
<img src="https://www.wecloudpro.com/assets/img/velero/pv.png" alt="persistent-volume">
</p>

<p>Let’s gather the Nginx logs stored on the Persistent Volume (noted the timestamp):</p>



<blockquote>

</blockquote>

<p>We can see the timestamp for the logs generated are:</p>

<div><div><pre><code>172.70.32.120 - - [22/Aug/2020:18:47:25 +0000] "GET / HTTP/1.0" 200 612 "-" "Mozilla/5.0 (compatible; Nimbostratus-Bot/v1.3.2; http://cloudsystemnetworks.com)" "-"
172.70.112.241 - - [22/Aug/2020:18:47:46 +0000] "GET / HTTP/1.1" 200 612 "-" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:79.0) Gecko/20100101 Firefox/79.0" "-"
172.70.96.193 - - [22/Aug/2020:18:47:47 +0000] "GET /favicon.ico HTTP/1.1" 404 153 "-" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:79.0) Gecko/20100101 Firefox/79.0" "-"
100.96.3.1 - - [22/Aug/2020:18:48:42 +0000] "GET / HTTP/1.1" 200 612 "-" "ELinks/0.13.1 (textmode; Linux 5.4.0-42-generic x86_64; 238x58-2)" "-"
172.70.96.193 - - [22/Aug/2020:18:49:21 +0000] "GET / HTTP/1.1" 200 612 "-" "ELinks/0.13.1 (textmode; Linux 5.4.0-42-generic x86_64; 238x58-2)" "-"
</code></pre></div></div>

<p><strong>Velero Install and Prerequisites</strong></p>

<p>The prerequisites for having velero working and be able to store backup on AWS S3 are:</p>

<ul>
  <li>AWS S3 bucket: kubernetes.test.velero</li>
  <li>Set IAM permissions for velero</li>
  <li>Install and configure velero</li>
</ul>

<p>let’s go over the step by step.</p>

<p><strong>Create AWS S3 bucket (if you don’t have one already):</strong></p>

<div><div><pre><code>Velero requires an object storage bucket to store backups in, preferably unique to a single Kubernetes cluster (see the FAQ for more details). Create an S3 bucket, replacing placeholders appropriately:
BUCKET=kubernetes.test.velero
REGION=us-east-1
aws s3api create-bucket \
    --bucket $BUCKET \
    --region $REGION \
    --create-bucket-configuration LocationConstraint=$REGION
</code></pre></div></div>

<p><strong>Set Permissions for Velero:</strong></p>

<div><div><pre><code>aws iam create-user --user-name velero
</code></pre></div></div>

<p><strong>Attach policies to give velero the necessary permissions:</strong></p>

<div><div><pre><code>cat &gt; velero-policy.json &lt;&lt;EOF
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "ec2:DescribeVolumes",
                "ec2:DescribeSnapshots",
                "ec2:CreateTags",
                "ec2:CreateVolume",
                "ec2:CreateSnapshot",
                "ec2:DeleteSnapshot"
            ],
            "Resource": "*"
        },
        {
            "Effect": "Allow",
            "Action": [
                "s3:GetObject",
                "s3:DeleteObject",
                "s3:PutObject",
                "s3:AbortMultipartUpload",
                "s3:ListMultipartUploadParts"
            ],
            "Resource": [
                "arn:aws:s3:::${BUCKET}/*"
            ]
        },
        {
            "Effect": "Allow",
            "Action": [
                "s3:ListBucket"
            ],
            "Resource": [
                "arn:aws:s3:::${BUCKET}"
            ]
        }
    ]
}
EOF
</code></pre></div></div>

<div><div><pre><code>aws iam put-user-policy \
  --user-name velero \
  --policy-name velero \
  --policy-document file://velero-policy.jso
</code></pre></div></div>

<p><strong>Create an access key for the user:</strong></p>

<div><div><pre><code>aws iam create-access-key --user-name velero
</code></pre></div></div>

<p><strong>Create a Velero-specific credentials file (credentials-velero) in your local directory:</strong></p>

<p>Add below content to a new file. Replace with the proper values of the AWS CLI Credentials. Name it as <code>credentials-velero</code></p>

<div><div><pre><code>[default]
aws_access_key_id=&lt;AWS_ACCESS_KEY_ID&gt;
aws_secret_access_key=&lt;AWS_SECRET_ACCESS_KEY&gt;
</code></pre></div></div>

<p><strong>Install Velero Client on your local computer</strong></p>

<p>I am running a Linux Debian based OS. Therefore I am going to show the steps to run on this OS.</p>

<div><div><pre><code>cd /tmp
wget https://github.com/vmware-tanzu/velero/releases/download/v1.4.2/velero-v1.4.2-linux-amd64.tar.gz
tar -xzvf velero-v1.4.2-linux-amd64.tar.gz
sudo mv velero-v1.4.2-linux-amd64/velero  /usr/local/bin/velero

velero install \
    --provider aws \
    --use-restic \
    --plugins velero/velero-plugin-for-aws:v1.1.0 \
    --bucket $BUCKET \
    --backup-location-config region=$REGION \
    --snapshot-location-config region=$REGION \
    --secret-file ./credentials-velero

</code></pre></div></div>





<p><strong>Validate Velero installation</strong></p>

<p><code>kubectl get all -n velero</code></p>


<p>
<img src="https://www.wecloudpro.com/assets/img/velero/velero-install.png" alt="velero-install">
</p>

<p><strong>BACKUP &amp; RESTORE</strong></p>

<p>Let’s see now how velero actually works. We are goign to:</p>

<ul>
  <li>Backup an application based on label.</li>
  <li>Delete a namespace where we have this application running.</li>
  <li>Restore all components (namespace, deployment, service, Persistent Volume etc..) of the application using velero.</li>
</ul>

<div><div><pre><code>velero backup create nginx-backup --selector app=nginx
velero backup describe nginx-backup --details
</code></pre></div></div>






<p>Below we can see all components are backed up an stored in our AWS s3 bucket:</p>

<p>
<img src="https://www.wecloudpro.com/assets/img/velero/backup-of-components.png" alt="velero-install">
</p>

<p>Now I am going to delete the entire namespace simulating a disaster and tne recovery everything using velero:</p>

<div><div><pre><code>kubectl delete namespace nginx-example

kubectl get deployments --namespace=nginx-example

velero restore create --from-backup nginx-backup

kubectl get deployments --namespace=nginx-example

kubectl get pvc --namespace=nginx-example

kubectl get services --namespace nginx-example
</code></pre></div></div>






<p>As we could see during the whole process, we were able to make a backup of the various stateless and statefull Kubernetes components and save them in an Amazon S3 bucket.</p>

<p>For those who have clusters running on premises and AWS S3 is not an option. The Object Storage <a href="https://min.io/">Minio</a> Open Source service can be used as an option.</p>

<p>Below I wanted to share gew URLs for different cloud provider plugins that can be usefull:</p>

<ul>
  <li><a href="https://github.com/digitalocean/velero-plugin/releases/tag/v1.0.0">velero plugin for DigitalOcean</a></li>
  <li><a href="https://github.com/vmware-tanzu/velero-plugin-for-aws">velero plugin for AWS</a></li>
  <li><a href="https://github.com/vmware-tanzu/velero-plugin-for-gcp">velero plugin for GCP</a></li>
</ul>


<p>As usual, if you have any question, send me a message at <a href="mailto:contact@wecloudpro.com">contact@wecloudpro.com</a></p>


          </div>
        </div><!-- .col-md-7 close -->
      </div>
    </div>
  </section>
</div></div>]]>
            </description>
            <link>https://www.wecloudpro.com/2020/08/22/kubernetes-disaster-recovery-with-velero.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24441435</guid>
            <pubDate>Fri, 11 Sep 2020 11:16:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Raspberry Pi Quick Kit]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24441394">thread link</a>) | @Abishek_Muthian
<br/>
September 11, 2020 | https://back7.co/home/the-raspberry-pi-quick-kit | <a href="https://web.archive.org/web/*/https://back7.co/home/the-raspberry-pi-quick-kit">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" data-updated-on="1598135146460" id="item-5f4198b085783706be1e5b9b"><div><div><div data-block-type="2" id="block-7f42313cd15b02e5f675"><div><p>I’ve been fortunate to see many people remixing and making the Raspberry Pi Recovery Kit since I introduced it last year.  It’s been a fun project for many, but one thing I didn’t expect was the number of people wanting to make their own.  While I documented all the parts, I never thought about how much it would cost others to recreate it, and it was very tough for some to assemble with all of the soldering.</p><p>To help newcomers and beginners, today I am releasing the Raspberry Pi Quick Kit.  It is far simpler, cheaper, and easier to produce.  There are only three 3D printed parts, and they should be able to print easily on most user-friendly printers.  I am also releasing for sale the three featured in this article on my site at <a href="https://back7.co/store/">https://back7.co/store .</a>  They are limited production, so no further prints are guaranteed.  Before breaking down how they’re assembled, let me introduce you to them:</p><h2><strong>RPQK: Orange</strong></h2><p>With hints of 80’s electronics, this is the first “color” project for a Cyberdeck that I’ve released on the site.  <a href="https://back7.co/store/raspberry-pi-quick-kit-orange-edition">Available for sale here</a>.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1598321492228_15362"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5caa4adb92441be122fcead4/1598323819141-ON5I0JWUKRPFAN1V14SU/ke17ZwdGBToddI8pDm48kNbLqx_FIYjfhtEsCHEHzad7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UX_hdIVndeO72MD00jTnc1n42Pd5vs4VrV4yXG_EV_fzwRAeN1AbZG4OR41R6pDVyg/JAY02503.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5caa4adb92441be122fcead4/1598323819141-ON5I0JWUKRPFAN1V14SU/ke17ZwdGBToddI8pDm48kNbLqx_FIYjfhtEsCHEHzad7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UX_hdIVndeO72MD00jTnc1n42Pd5vs4VrV4yXG_EV_fzwRAeN1AbZG4OR41R6pDVyg/JAY02503.jpg" data-image-dimensions="2048x1366" data-image-focal-point="0.5,0.5" alt="JAY02503.jpg" data-load="false" data-image-id="5f447c6a0858461c765ee5be" data-type="image" src="https://back7.co/home/JAY02503.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1598321492228_15662"><div><p>The specs are the same for all of them, a Raspberry Pi 4 with 4GB of RAM, a 32GB Micro SD card, with panel mounts for 2x USB3, 1x USB 2, and Ethernet.  There’s a USB C power port, and a simple M5 bolt as a handle to pull the case front off.  No keyboard is included to keep it simple and easy for makers to modify as they see fit.  While there is a single orange in stock right now, email me if you’re interested in more of the orange- I am open to making more.</p><h2><strong>RPQK: Standard Issue</strong></h2><p>This is the distillation of last year’s Recovery Kit in the same grey.  As with all of them, they use the Pelican 1150 case which is smaller, but also far easier to print simple parts for. This version is for <a href="https://back7.co/store/raspberry-pi-quick-kit-standard-issue">sale here</a>.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1598321492228_20751"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5caa4adb92441be122fcead4/1598321661726-DPB5GMQJTPJ2NP9EQB6V/ke17ZwdGBToddI8pDm48kNbLqx_FIYjfhtEsCHEHzad7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UX_hdIVndeO72MD00jTnc1n42Pd5vs4VrV4yXG_EV_fzwRAeN1AbZG4OR41R6pDVyg/JAY02514.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5caa4adb92441be122fcead4/1598321661726-DPB5GMQJTPJ2NP9EQB6V/ke17ZwdGBToddI8pDm48kNbLqx_FIYjfhtEsCHEHzad7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UX_hdIVndeO72MD00jTnc1n42Pd5vs4VrV4yXG_EV_fzwRAeN1AbZG4OR41R6pDVyg/JAY02514.jpg" data-image-dimensions="2048x1366" data-image-focal-point="0.5,0.5" alt="JAY02514.jpg" data-load="false" data-image-id="5f4473fb69a9c96bb9aa59d7" data-type="image" src="https://back7.co/home/JAY02514.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1598321492228_21050"><div><h2><strong>RPQK: Black Edition</strong></h2><p>Printed in carbon fiber PETG filament, this is the truly limited edition version of this deck.  I will not be making more of this edition and selling it here, so this is a little more expensive than the others.  Available for a <a href="https://back7.co/store/raspberry-pi-quick-kit-black-edition">limited time here</a>.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1598321492228_25127"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5caa4adb92441be122fcead4/1598321696978-LZ5WDPJZROFPG1TXRY06/ke17ZwdGBToddI8pDm48kNbLqx_FIYjfhtEsCHEHzad7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UX_hdIVndeO72MD00jTnc1n42Pd5vs4VrV4yXG_EV_fzwRAeN1AbZG4OR41R6pDVyg/JAY02511.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5caa4adb92441be122fcead4/1598321696978-LZ5WDPJZROFPG1TXRY06/ke17ZwdGBToddI8pDm48kNbLqx_FIYjfhtEsCHEHzad7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UX_hdIVndeO72MD00jTnc1n42Pd5vs4VrV4yXG_EV_fzwRAeN1AbZG4OR41R6pDVyg/JAY02511.jpg" data-image-dimensions="2048x1366" data-image-focal-point="0.5,0.5" alt="JAY02511.jpg" data-load="false" data-image-id="5f447420f27a116b181437cb" data-type="image" src="https://back7.co/home/JAY02511.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1598321492228_25427"><div><p>Each is in stock right now, and I may or may not make future grey or orange ones.  The black is a one of a kind.  Sold out or just don’t want to spend the money?  As always I have included the full design for free here, and it’s easier than ever to build.</p><h2>Making Your Own</h2><p>I read many responses over the last year and I heard from many folks that the original was simply too hard for them to build.  Several parts were hard to get over time, so I focused on inexpensive and easy to find parts.  It’s easy to build too, with no soldering- just 3D printing.  Here’s the build list:</p><ul data-rte-list="default"><li><p>Raspberry Pi 7” Touchscreen Display - <a href="https://amzn.to/2EqIALh">Amazon</a></p></li><li><p>Raspberry Pi 4 4GB - <a href="https://amzn.to/2EAFPa4">Amazon</a></p></li><li><p>PETG Filament - Orange or Grey - <a href="https://amzn.to/2EeaU3v">Amazon</a> - <a href="https://amzn.to/34vLRmY">Amazon</a></p></li><li><p>M5 x 10mm Screws - <a href="https://amzn.to/31rwhXy">Amazon</a></p></li><li><p>Parts Files - <a href="https://www.tinkercad.com/things/aPdL1crSOyc-raspberry-pi-quick-kit">Tinkercad</a> and <a href="https://www.thingiverse.com/thing:4593674">Thingiverse</a></p></li><li><p>M3 Screws for the panel mounts - <a href="https://amzn.to/32nExqX">Amazon</a></p></li><li><p>M2.5 Screws for the Pi - <a href="https://amzn.to/31v5gCZ">Amazon</a></p></li><li><p>USB 3.0 Panel Mounts - <a href="https://amzn.to/3jaUZS9">Amazon</a></p></li><li><p>USB 2.0 Panel Mount - <a href="https://amzn.to/3gza0M9">Amazon</a></p></li><li><p>Ethernet Panel Mount - <a href="https://amzn.to/31qyCST">Amazon</a></p></li><li><p>USB C Panel Mount - <a href="https://amzn.to/3k3B8ok">Amazon</a></p></li><li><p>And of course, the Pelican 1150 Case - <a href="https://amzn.to/3gmGqZT">Amazon</a></p></li></ul><p>After printing, this project only takes about 30 minutes to assemble.  Start off with the empty case:</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1598070339928_58786"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5caa4adb92441be122fcead4/1598135049363-PUI1DPIEGC8CYGAYVL60/ke17ZwdGBToddI8pDm48kNbLqx_FIYjfhtEsCHEHzad7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UX_hdIVndeO72MD00jTnc1n42Pd5vs4VrV4yXG_EV_fzwRAeN1AbZG4OR41R6pDVyg/JAY02437.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5caa4adb92441be122fcead4/1598135049363-PUI1DPIEGC8CYGAYVL60/ke17ZwdGBToddI8pDm48kNbLqx_FIYjfhtEsCHEHzad7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UX_hdIVndeO72MD00jTnc1n42Pd5vs4VrV4yXG_EV_fzwRAeN1AbZG4OR41R6pDVyg/JAY02437.jpg" data-image-dimensions="2048x1366" data-image-focal-point="0.5,0.5" alt="The bare Pelican 1150 case, available here:  Amazon" data-load="false" data-image-id="5f419b08d9abee0b99f92d3c" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5caa4adb92441be122fcead4/1598135049363-PUI1DPIEGC8CYGAYVL60/ke17ZwdGBToddI8pDm48kNbLqx_FIYjfhtEsCHEHzad7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UX_hdIVndeO72MD00jTnc1n42Pd5vs4VrV4yXG_EV_fzwRAeN1AbZG4OR41R6pDVyg/JAY02437.jpg">
          </p>
        
          
        

        
          
          <figcaption>
            <p>The bare Pelican 1150 case, available here: <a href="https://amzn.to/3aOUg6d">Amazon</a></p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1598070339928_59085"><p>Print the main frame first- if you want a smooth front, use a smooth bed.  Some of these have the textured face, while the black edition uses a smooth face.</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1598321492228_31789"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5caa4adb92441be122fcead4/1598322120615-7ZGIAY2PZFZY68RC5JDE/ke17ZwdGBToddI8pDm48kNbLqx_FIYjfhtEsCHEHzad7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UX_hdIVndeO72MD00jTnc1n42Pd5vs4VrV4yXG_EV_fzwRAeN1AbZG4OR41R6pDVyg/JAY02463.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5caa4adb92441be122fcead4/1598322120615-7ZGIAY2PZFZY68RC5JDE/ke17ZwdGBToddI8pDm48kNbLqx_FIYjfhtEsCHEHzad7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UX_hdIVndeO72MD00jTnc1n42Pd5vs4VrV4yXG_EV_fzwRAeN1AbZG4OR41R6pDVyg/JAY02463.jpg" data-image-dimensions="2048x1366" data-image-focal-point="0.5,0.5" alt="JAY02463.jpg" data-load="false" data-image-id="5f4475c76989d24daa3001ea" data-type="image" src="https://back7.co/home/JAY02463.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1598321492228_32088"><p>Next, print the display brackets - while you can squeeze them into a single print, my printers had more reliable results doing them in different batches.  Do what’s best for you!</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1598321492228_36731"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5caa4adb92441be122fcead4/1598322235665-PSMH1F42FJCE2PBGU3UW/ke17ZwdGBToddI8pDm48kNbLqx_FIYjfhtEsCHEHzad7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UX_hdIVndeO72MD00jTnc1n42Pd5vs4VrV4yXG_EV_fzwRAeN1AbZG4OR41R6pDVyg/JAY02464.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5caa4adb92441be122fcead4/1598322235665-PSMH1F42FJCE2PBGU3UW/ke17ZwdGBToddI8pDm48kNbLqx_FIYjfhtEsCHEHzad7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UX_hdIVndeO72MD00jTnc1n42Pd5vs4VrV4yXG_EV_fzwRAeN1AbZG4OR41R6pDVyg/JAY02464.jpg" data-image-dimensions="2048x1366" data-image-focal-point="0.5,0.5" alt="JAY02464.jpg" data-load="false" data-image-id="5f44763abc05f6517b744ed9" data-type="image" src="https://back7.co/home/JAY02464.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1598321492228_37030"><p>Next, assemble them with M5 screws- pay special attention to the recessed circle on the brackets, they help you line up with recessed circles on the main frame for easy assembly.</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1598321492228_41340"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5caa4adb92441be122fcead4/1598322317757-DBS892VPJ7F7QG8EUHSE/ke17ZwdGBToddI8pDm48kNbLqx_FIYjfhtEsCHEHzad7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UX_hdIVndeO72MD00jTnc1n42Pd5vs4VrV4yXG_EV_fzwRAeN1AbZG4OR41R6pDVyg/JAY02472.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5caa4adb92441be122fcead4/1598322317757-DBS892VPJ7F7QG8EUHSE/ke17ZwdGBToddI8pDm48kNbLqx_FIYjfhtEsCHEHzad7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UX_hdIVndeO72MD00jTnc1n42Pd5vs4VrV4yXG_EV_fzwRAeN1AbZG4OR41R6pDVyg/JAY02472.jpg" data-image-dimensions="2048x1366" data-image-focal-point="0.5,0.5" alt="JAY02472.jpg" data-load="false" data-image-id="5f44768df27a116b181490ac" data-type="image" src="https://back7.co/home/JAY02472.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1598321492228_41639"><p>With the brackets installed, use the M3 screws to attach the panel mounts.  The ethernet jack is a snug fit, so be careful to snap it into place before installing the screws.</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1598321492228_46168"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5caa4adb92441be122fcead4/1598322404682-2KENN99N12E5HVNAHHZJ/ke17ZwdGBToddI8pDm48kNbLqx_FIYjfhtEsCHEHzad7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UX_hdIVndeO72MD00jTnc1n42Pd5vs4VrV4yXG_EV_fzwRAeN1AbZG4OR41R6pDVyg/JAY02469.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5caa4adb92441be122fcead4/1598322404682-2KENN99N12E5HVNAHHZJ/ke17ZwdGBToddI8pDm48kNbLqx_FIYjfhtEsCHEHzad7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UX_hdIVndeO72MD00jTnc1n42Pd5vs4VrV4yXG_EV_fzwRAeN1AbZG4OR41R6pDVyg/JAY02469.jpg" data-image-dimensions="2048x1366" data-image-focal-point="0.5,0.5" alt="JAY02469.jpg" data-load="false" data-image-id="5f4476e29a491c02b997a578" data-type="image" src="https://back7.co/home/JAY02469.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1598321492228_46471"><div><p>Next, go ahead and attach the Raspberry Pi to the display according to the documentation.  You may want to go ahead and image the Raspberry Pi micro SD card at this time too.  Just follow the standard approach for attaching the Pi, then install the screen into the frame using four M3 screws- the stock ones don’t quite reach, so use some from the batch used for the panel mount jacks.  If the holes don’t line up, it’s because your display is upside down.</p><p>Next, go ahead and plug everything in, it should look a bit like this:</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1598321492228_62619"><div><p><br>Before you install the panel into the case, screw in the M5 bolt onto the front panel- it will give you something to pull on to remove the panel so you’re not tugging on the screen.</p><p>Go ahead and gently keep the cables from getting pinched, and push it snug into the case.  It’s not a super tight fit, but it will vary depending on your printer.  </p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1598321492228_55873"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5caa4adb92441be122fcead4/1598322743653-IHI3YJXF2D1HWLJUIO96/ke17ZwdGBToddI8pDm48kNbLqx_FIYjfhtEsCHEHzad7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UX_hdIVndeO72MD00jTnc1n42Pd5vs4VrV4yXG_EV_fzwRAeN1AbZG4OR41R6pDVyg/JAY02506.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5caa4adb92441be122fcead4/1598322743653-IHI3YJXF2D1HWLJUIO96/ke17ZwdGBToddI8pDm48kNbLqx_FIYjfhtEsCHEHzad7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UX_hdIVndeO72MD00jTnc1n42Pd5vs4VrV4yXG_EV_fzwRAeN1AbZG4OR41R6pDVyg/JAY02506.jpg" data-image-dimensions="2048x1366" data-image-focal-point="0.5,0.5" alt="JAY02506.jpg" data-load="false" data-image-id="5f447836281d306f45af7a41" data-type="image" src="https://back7.co/home/JAY02506.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1598321492228_59913"><p>That’s it!  Go ahead and connect a USB C power adapter to the Pi and it will boot up!  If you decide to build one, please tag me on social media (including <a href="https://twitter.com/back7co">@back7co</a> on Twitter, <a href="https://www.instagram.com/back7.co/">@back7.co</a> on Instagram, and <a href="https://www.reddit.com/user/back7co">/u/back7co</a> on Reddit).</p></div></div></div></div></div></div>]]>
            </description>
            <link>https://back7.co/home/the-raspberry-pi-quick-kit</link>
            <guid isPermaLink="false">hacker-news-small-sites-24441394</guid>
            <pubDate>Fri, 11 Sep 2020 11:10:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Mythical DevOps Engineer]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24441392">thread link</a>) | @rbanffy
<br/>
September 11, 2020 | https://alediaferia.com/2020/07/27/the-mythical-devops-engineer/ | <a href="https://web.archive.org/web/*/https://alediaferia.com/2020/07/27/the-mythical-devops-engineer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-594">
		<div>
		<p><span><span>Reading Time: </span> <span>8</span> <span>minutes</span></span></p><p>I’m always a little suspicious of job specs looking for the so-called <em>DevOps Engineer</em> role. They often mention a vast variety of duties and responsibilities. </p>



<blockquote><p>Are they hiring for a single role or a whole team?</p></blockquote>



<p>Roles having <em>DevOps</em> in their title hardly share the same meaning. They often have something in common, though. They try to cover for what traditionally would have been the specialization of different professionals.</p>



<p>Don’t get me wrong: cross-functional expertise is definitely important. But I don’t think <em>DevOps</em> means replacing a multitude of specialization with a single role. Different specializations like Operations, Security, Testing, Development, Product Management and so on, are vast and require specific knowledge. </p>



<p>I think the key differentiator of successful <em>DevOps</em> organizations is that they enable effective collaboration. They have as clear <em>North Star</em> the goal to deliver value to the end user.</p>



<p>Overall, I don’t think we should be talking about a <em>DevOps Engineer</em>, but rather about <em>DevOps</em> culture in organizations.</p>



<p>But let’s take a step back first.</p>



<h2>What does DevOps mean, really?</h2>



<p>I tweeted my own definition of DevOps some time ago.</p>



<figure><div>
<blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">DevOps is a highly condensed way of referring to the combination of practices that aim at shortening the software development life-cycle, increase the feedback opportunities and facilitate continuous improvement and experimentation.</p>— Alessandro Diaferia (@alediaferia) <a href="https://twitter.com/alediaferia/status/1279460637341560833?ref_src=twsrc%5Etfw">July 4, 2020</a></blockquote>
</div></figure>



<p><em>DevOps</em> organizations incentivise different specialities to collaborate. The intrinsic existing tension between Dev, making changes to the system, and Ops, wanting to keep the system stable, dissolves. The greater good is now <em>the value stream</em>.</p>



<blockquote><p>A stable system that delivers nothing is as useless as an unstable system that keeps offering new functionality.</p></blockquote>



<p>Dev and Ops understand the importance of working together to maximise this flow to figure out which bets worked out and which ones didn’t. </p>



<p>Organizations that embrace the <em>DevOps</em> mindset can be more effective than the competition at experimenting with new functionality. They quickly validate their assumptions, activating and deactivating functionality by flipping a switch on a dashboard.</p>



<p>Incidents become an opportunity for learning rather than a chance of blaming someone.</p>



<p>In general, <em>DevOps </em>organization learn to adapt and evolve to any situation.</p>



<p>Overall, I think there shouldn’t be a single <em>DevOps</em> role but, rather, a set of specific specialities collaborating effectively.</p>



<p>This ideal view of the terminology, though, might sometimes clash with the reality of the job market. Companies willing to attract the best talent with the most current skills may end up advertising for roles that are counterproductive in the context of DevOps principles.</p>



<p>But let’s have a look at a few interesting job specs.</p>



<figure><img loading="lazy" width="768" height="432" src="https://alediaferia.com/wp-content/uploads/2020/07/jordan-whitfield-sm3Ub_IJKQg-unsplash-768x432.jpg" alt="work harder neon sign photo" srcset="https://alediaferia.com/wp-content/uploads/2020/07/jordan-whitfield-sm3Ub_IJKQg-unsplash-768x432.jpg 768w, https://alediaferia.com/wp-content/uploads/2020/07/jordan-whitfield-sm3Ub_IJKQg-unsplash-300x169.jpg 300w, https://alediaferia.com/wp-content/uploads/2020/07/jordan-whitfield-sm3Ub_IJKQg-unsplash-1024x576.jpg 1024w, https://alediaferia.com/wp-content/uploads/2020/07/jordan-whitfield-sm3Ub_IJKQg-unsplash-1536x863.jpg 1536w, https://alediaferia.com/wp-content/uploads/2020/07/jordan-whitfield-sm3Ub_IJKQg-unsplash-2048x1151.jpg 2048w" sizes="(max-width: 768px) 100vw, 768px"><figcaption>Photo by <a href="https://unsplash.com/@whitfieldjordan?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Jordan Whitfield</a> on <a href="https://unsplash.com/s/photos/job-search?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></figcaption></figure>



<h2>What are companies looking for?</h2>



<p>Let’s read through a few excerpts from job specs I found out there in the wild.</p>



<h3>The flexible problem solver</h3>



<blockquote><p>[…] Devops Engineers are IT professionals who collaborate with software developers, system operators and other IT staff members to manage code releases. They cross and merge the barriers that exist between software development, testing and operations teams and keep existing networks in mind as they design, plan and test. Responsible for multitasking and dealing with multiple urgent situations at a time, Devops Engineers must be extremely flexible. […]</p><cite>A job spec on the internet</cite></blockquote>



<p>This is one of those classic examples where the organization believes that the DevOps principles should be delegated to a single team.</p>



<p>The spec mentions the myriad of duties that are responsibility of the <em>Devops Engineers</em> in the company. A <em>Devops Engineer</em> is expected to <em>“multi-task and deal with multiple urgent situations at a time”</em>. Therefore, they <em>“must be extremely flexible”</em>.</p>



<p><em>Multitasking</em> and dealing with multiple urgent situations at a time is, for sure, likely to happen anywhere: I don’t think this should be a peculiarity of a role in an organization. On the contrary, a healthy environment empowers every engineer to handle urgent situations and <a href="https://landing.google.com/sre/sre-book/chapters/postmortem-culture/">learn from them</a>.<mark id="annotation-text-54d7a912-f939-4d9c-8c35-b5876683f83c"></mark></p>



<hr>



<p>Coming across this role, I’d think that the organization is not really trying to adopt DevOps practices. <mark id="annotation-text-9ee4ee73-52fa-44d6-b856-3c9ba17dd0f4"></mark>Instead of encouraging people to collaborate and improve, they’re building a dedicated team to throw issues and urgent situations at.</p>



<p><mark id="annotation-text-d4681dd9-2adf-49b8-b88c-e4c6a256a1e7"></mark> This job spec would be a big red flag for me.</p>



<h3>The productivity booster</h3>



<blockquote><p>A DevOps Engineer combines an understanding of both engineering and coding. A DevOps Engineer works with various departments to create and develop systems within a company. From creating and implementing software systems to analysing data to improve existing ones, a DevOps Engineer increases productivity in the workplace.</p><cite>Another job spec on the internet</cite></blockquote>



<p>In a <em>DevOps</em> organization engineers <em>do</em> work with various departments. But what’s the point then of  having a dedicated <em>DevOps Engineer</em> role? Do the other type of engineers not work with the various departments of the organization? Do non-DevOps Engineers not analyse data and improve existing systems? Additionally, the job spec claims that <em>a DevOps Engineer increases productivity in the workplace</em>. How? Does it radiate productivity?</p>


	
	


<h3>The Release Manager… but <em>DevOps</em>!</h3>



<blockquote><p>A DevOps Engineer works with developers and the IT staff to oversee the code releases. […] Ultimately, you will execute and automate operational processes fast, accurately and securely.</p><cite>My favourite so far</cite></blockquote>



<p>This is quite a condensed one but the release aspect mentioned in it strikes me as particularly interesting.</p>



<p>I tend to separate the concept of <em>deployment</em> from the one of <em>release</em>. Users experience product updates governed by a release policy that may or may not be the same as the deployment policy. This really depends on the strategy of the organization.</p>



<p>Regardless of this distinction, though, I believe that constraining the capability of delivering value to the end user to a specific role undermines the agility of an organization.</p>



<p>The teams should be able to continuously release code into production. Mechanisms such as <em><a href="https://martinfowler.com/articles/feature-toggles.html">feature flags</a></em> should control the release of functionality. This means that the code in production doesn’t necessarily activate upon deploying it, making it possible for the organization to control when the functionality actually reaches the user.</p>



<p>In general, a deployment should be a non-event: nothing special, just another merge into the main branch that causes code to end up in production.</p>



<p>In a fast-paced world like the one we live in an organization shouldn’t constrain itself by requiring dedicated engineers to release new functionality. Modern environments require companies to always be experimenting. Organizations should empower non-technical teams to run experiments, analyse data and autonomously decide when to <em>release</em> new functionality. All of this, ideally, shouldn’t require <em>ad hoc</em> intervention from a specific engineer.</p>



<p>Job specs like this one feel like they’re trying to repurpose the role of the <em>Release Manager</em> to keep up with the latest trends by just changing a few words.</p>



<p>I don’t think release management goes away in a <em>DevOps</em> organization. Rather, the <em>Release Management</em> becomes ensuring that the rest of the organization can be autonomous at releasing. Achieving this means investing in automation and internal tools for the whole company.</p>



<h3>A Platform Engineer. But <em>cooler!</em></h3>



<blockquote><p>The DevOps Engineer will be a key leader in shaping processes and tools that enable cross-functional collaboration and drive CI/CD transformation. The DevOps Engineer will work closely with product owners, developers, and external development teams to build and configure a high performing, scalable, cloud-based platform that can be leveraged by other product teams.</p></blockquote>



<p>This is the <em>least bad</em> of the job specs I’ve encountered. It describes a set of responsibilities that usually pertain to a Platform or Infrastructure Team. Most of these teams often get renamed to DevOps Team and their members become DevOps Engineers for <em>fashion</em> reasons.</p>



<p>The Platform Engineering team is the key enabler for organizations that want to embrace the DevOps principles. But thinking that they only pertain to a specific team will hardly result in a successful journey.</p>



<p>This team will surely be responsible to build the relevant infrastructure that enables the other teams to build on top but they can’t be left alone in the understanding and application of those principles.</p>



<p>Developer teams will need to become autonomous at adopting and making changes to those systems; they will need to understand the implications of their code running in production; understand how to recognize if the system is not behaving as expected and be able to action to restore it.</p>



<p>Equally, the Product team should spend time understanding what new important capabilities derive from adopting DevOps practices. Code continuously flowing into production behind feature flags, containerization technologies, improved monitoring and alerting, <em>et cetera</em>, open endless opportunities.</p>



<p>Improved user experience and experimentation opportunities, for example, are an important asset to leverage to remain competitive.</p>



<figure><img loading="lazy" width="768" height="1273" src="https://alediaferia.com/wp-content/uploads/2020/07/matteo-vistocco-Dph00R2SwFo-unsplash-768x1273.jpg" alt="people riding boat on body of water photo" srcset="https://alediaferia.com/wp-content/uploads/2020/07/matteo-vistocco-Dph00R2SwFo-unsplash-768x1273.jpg 768w, https://alediaferia.com/wp-content/uploads/2020/07/matteo-vistocco-Dph00R2SwFo-unsplash-181x300.jpg 181w, https://alediaferia.com/wp-content/uploads/2020/07/matteo-vistocco-Dph00R2SwFo-unsplash-618x1024.jpg 618w, https://alediaferia.com/wp-content/uploads/2020/07/matteo-vistocco-Dph00R2SwFo-unsplash-927x1536.jpg 927w, https://alediaferia.com/wp-content/uploads/2020/07/matteo-vistocco-Dph00R2SwFo-unsplash-1236x2048.jpg 1236w, https://alediaferia.com/wp-content/uploads/2020/07/matteo-vistocco-Dph00R2SwFo-unsplash-scaled.jpg 1544w" sizes="(max-width: 768px) 100vw, 768px"><figcaption>Photo by <a href="https://unsplash.com/@mrsunflower94?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Matteo Vistocco</a> on <a href="https://unsplash.com/s/photos/collaboration?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></figcaption></figure>



<h2>What should companies be looking for?</h2>



<p>We’ve just gone through a few job specs that look for variations of a <em>DevOps Engineer</em> role and I’ve outlined what aspects I think are flawed in those roles. But what should companies look for, then?</p>



<p>Before blindly starting to hire for roles driven by industry fashion trends, organizations should rather invest in understanding what’s holding them back from being <em>DevOps</em>.</p>



<p>In the <a href="https://itrevolution.com/the-unicorn-project/">Unicorn Project</a>, <a href="https://twitter.com/RealGeneKim">Gene Kim</a> mentions the <em>Five Ideals</em> of successful DevOps organizations. I think they’re an effective set of principles to take the temperature of your …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://alediaferia.com/2020/07/27/the-mythical-devops-engineer/">https://alediaferia.com/2020/07/27/the-mythical-devops-engineer/</a></em></p>]]>
            </description>
            <link>https://alediaferia.com/2020/07/27/the-mythical-devops-engineer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24441392</guid>
            <pubDate>Fri, 11 Sep 2020 11:10:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to stream audio from your phone to your laptop with PulseAudio]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 87 (<a href="https://news.ycombinator.com/item?id=24441112">thread link</a>) | @manjana
<br/>
September 11, 2020 | https://bash-prompt.net/guides/pulse-audio-bluetooth-streaming/ | <a href="https://web.archive.org/web/*/https://bash-prompt.net/guides/pulse-audio-bluetooth-streaming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>These days your primary means of listening to music if likely from an app on your phone. So how do you get the music from your phone to your laptop or desktop that has better speakers?</p>
<p>The answer is to use Bluetooth and <a href="https://www.freedesktop.org/wiki/Software/PulseAudio/">PulseAudio</a>. PulseAudio is the modern sound implementation on the Linux desktop. It runs as a sound server and takes sound inputs such a microphone or your browser playing a YouTube video and directs this sound to outputs such as your Laptop’s speakers.</p>
<p>PulseAudio can take the audio from a Bluetooth connection and route it to your laptop’s speakers and is very simple to get running.</p>
<p>First, install the PulseAudio Bluetooth modules. On ArchLinux this is called <code>pulseaudio-bluetooth</code> and on Ubuntu/Debian it is called <code>pulseaudio-module-bluetooth</code>.</p>
<p>After you have installed this package open the following file:</p>
<pre><code>/etc/pulse/system.pa
</code></pre><p>And add the following couple of lines:</p>
<pre><code>load-module module-bluetooth-policy
load-module module-bluetooth-discover
</code></pre><p>Then, as your regular user, restart PulseAudio:</p>
<pre><code>$ pulseaudio -k
$ pulseaudio --start
</code></pre><p>And you’re all set!</p>
<p>All you need to do is to pair your phone and your computer and start playing something on your phone and it will play through your computer’s speakers.</p>

		</div></div>]]>
            </description>
            <link>https://bash-prompt.net/guides/pulse-audio-bluetooth-streaming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24441112</guid>
            <pubDate>Fri, 11 Sep 2020 10:26:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[For the Love of Go: Fundamentals (eBook for Go Beginners)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24441071">thread link</a>) | @bitfield
<br/>
September 11, 2020 | https://bitfieldconsulting.com/books/fundamentals | <a href="https://web.archive.org/web/*/https://bitfieldconsulting.com/books/fundamentals">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site">

      

      <main id="page" role="main" data-content-field="main-content" data-controller="FadeInContent">

        <article data-item-id="5f4a46049cb980774504632c">

    <nav>
      
      
    </nav>

    <section>

      <section>
        
      </section>

      <figure>
        
          <div>
            
              
                <p><img data-load="false" data-src="https://images.squarespace-cdn.com/content/v1/5e10bdc20efb8f0d169f85f9/1598703322476-XBS0GYV9FR7HJWPWYAIY/ke17ZwdGBToddI8pDm48kPJXHKy2-mnvrsdpGQjlhod7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmrMDYraMJMCQwFxTSOIP7LpSBEQpA-g5k6VTjWbSuadHJq0dp98hg5AZvIaPb3DoM/cover.png" data-image="https://images.squarespace-cdn.com/content/v1/5e10bdc20efb8f0d169f85f9/1598703322476-XBS0GYV9FR7HJWPWYAIY/ke17ZwdGBToddI8pDm48kPJXHKy2-mnvrsdpGQjlhod7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmrMDYraMJMCQwFxTSOIP7LpSBEQpA-g5k6VTjWbSuadHJq0dp98hg5AZvIaPb3DoM/cover.png" data-image-dimensions="1000x1000" data-image-focal-point="0.5,0.5" alt="cover.png" src="https://bitfieldconsulting.com/books/cover.png"></p>
              
              
            
          </div>
        
        
      </figure>

      <section>
        

        


<p><span>4.99</span>
</p>

        <div data-content-field="excerpt"><p>Hello, and welcome to learning Go! It's great to have you here. This book is an interactive introduction to the Go programming language, suitable for complete beginners. If you don't know anything about Go yet, or programming, but would like to learn, you're in the right place! (If you do already know something about Go, you should still find this book fun and interesting.)</p><p>'Interactive' means you won't just be reading, you'll be coding! By the time you've reached the end of the book, you'll have built a complete, working calculator package in Go, with tests. I'll give you hints, but I won't give you all the code. This will really build your confidence for starting your own mini-projects!</p><p>By working through the exercises in this book, you'll learn:</p><ul data-rte-list="default"><li><p>How to run tests for a Go program</p></li><li><p>How to automatically format your Go code correctly</p></li><li><p>The basic pattern that all Go tests should follow</p></li><li><p>How to declare and import Go packages (units of code)</p></li><li><p>How to design multiple test cases and use them in your tests</p></li><li><p>How to test error handling in your programs</p></li><li><p>A simple, reliable, test-first development workflow</p></li></ul><p>Throughout this book we'll be working together to develop a project in Go. Each chapter introduces a new feature or concept, and sets you some goals to achieve, with some some helpful suggestions for how to go about it. If you're finding the goals easy, or want a bit more of a challenge, there are some stretch goals, too. These are optional; if you're not interested or not ready to tackle them, just skip over them. So let's get started!</p><p>Your digital download is a ZIP file containing the book in three different formats:</p><ul data-rte-list="default"><li><p>ePUB</p></li><li><p>Kindle</p></li><li><p>PDF</p></li></ul><p>These should be suitable for any ePub reader, computer, phone, or tablet. If you need a different format, <a href="https://bitfieldconsulting.com/contact" target="">contact me</a> and I may be able to provide it for you. The page count varies depending on your screen size, but on my Mac it’s 59pp, and around 6,000 words.</p><p>I'm especially interested from hearing from anyone who's found a mistake in the book; if you find one and <a href="https://bitfieldconsulting.com/contact/">report it</a>, I'll send you a free copy of my <em>next</em> book!</p><h3>Reviews</h3><p>“Like all things from @bitfield - it’s GREAT!!”<br>—<a href="https://twitter.com/rhighness/status/1302250080850726912" target="">Rick Highness</a></p><p>“Instant buy.”<br>—<a href="https://twitter.com/pmamberti/status/1302196645480759296" target="">Piero Mamberti</a></p><p>“I know Golang fairly well, but this taught me several things!”<br>—<a href="https://twitter.com/CaffeinatedEng/status/1298634459345031171" target="">Matty Jones</a></p><p>“A must read!”<br>—<a href="https://twitter.com/_richardbright/status/1302202553338191873" target="">Richard Bright</a></p></div>

        

        

        

        

        







        












        
      </section>

    </section>

    
    <section>
      
    </section>
    

    

  </article>





      </main>

      

    </div></div>]]>
            </description>
            <link>https://bitfieldconsulting.com/books/fundamentals</link>
            <guid isPermaLink="false">hacker-news-small-sites-24441071</guid>
            <pubDate>Fri, 11 Sep 2020 10:20:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A tiny instrument to measure the faintest magnetic fields – University of Basel]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24441000">thread link</a>) | @rbanffy
<br/>
September 11, 2020 | https://www.unibas.ch/en/News-Events/News/Uni-Research/A-tiny-instrument-to-measure-the-faintest-magnetic-fields.html | <a href="https://web.archive.org/web/*/https://www.unibas.ch/en/News-Events/News/Uni-Research/A-tiny-instrument-to-measure-the-faintest-magnetic-fields.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<!-- SKIPLINKS -->

    <!-- ALERT NOTIFICATION -->
    <!-- END ALERT NOTIFICATION -->

	<!-- Redirect Notification-->
	<!-- End Redirect Notification-->


<!-- INTRODUCTION-LINKS -->
<section id="introduction-links">
    <h6>Introduction Links</h6>
    
    <div>
        <nav>
           <h6>Introduction Links Navigation</h6>
            
        </nav>
    </div>
</section>
<!-- INTRODUCTION-LINKS END -->
<section id="locationfinder" data-url="/en.json">
           <h6>Locationfinder</h6>

<div id="category-list">
        <nav>
           <h6>Locationfinder Navigation</h6>    
            <p><img src="https://www.unibas.ch/.resources/unibas-main/webresources/img/icons/loading.gif" alt="Loading" title="Loading">
            </p>
        </nav>
	</div>

	


</section>

<header>
     <h6>Navigationarea University of Basel</h6>
    <nav>
        <h6>Metanavigation</h6>
    

        
    </nav>
</header><!-- end header --><section id="searchbar">
   <h6>Searchbar</h6>
    
</section><!-- end search-bar -->
    
    <section id="navigation-wrapper">
         <h6>Mainnavigation-Area</h6>

<!-- horizontalNavigation.ftl -->


<nav id="main-nav">
    <h6>Mainnavigation</h6>

    <ul>
                <li>
                    <a href="https://www.unibas.ch/en/News-Events.html" data-target="sub-0">News &amp; Events</a>
                        <nav id="sub-0">
                            <h6>News &amp; Events - Subnavigation</h6>
                            <ul>
                                <li>
                                    <a title="News" href="https://www.unibas.ch/en/News-Events/News.html">News</a>
                                </li>
                                <li>
                                    <a title="Newsletter" href="https://www.unibas.ch/en/News-Events/Newsletter.html">Newsletter</a>
                                </li>
                                <li>
                                    <a title="University in the News" href="https://www.unibas.ch/en/News-Events/Media-Review.html">University in the News</a>
                                </li>
                                <li>
                                    <a title="Public Events Calendar" href="https://www.unibas.ch/en/News-Events/Events.html">Public Events Calendar</a>
                                </li>
                                <li>
                                    <a title="University Events" href="https://www.unibas.ch/en/News-Events/-events.html">University Events</a>
                                </li>
                                <li>
                                    <a title="Social Media &amp; Blogs" href="https://www.unibas.ch/en/News-Events/Social-Media.html">Social Media &amp; Blogs</a>
                                </li>
                                <li>
                                    <a title="Media Database" href="https://www.unibas.ch/en/News-Events/Media-Database.html">Media Database</a>
                                </li>
                                <li>
                                    <a title="Media Service" href="https://www.unibas.ch/en/News-Events/Media-Service.html">Media Service</a>
                                </li>
                                <li>
                                    <a title="Coronavirus" href="https://www.unibas.ch/en/News-Events/Coronavirus.html">Coronavirus</a>
                                </li>
                            </ul>
                        </nav>
                </li>
                <li>
                    <a href="https://www.unibas.ch/en/Studies.html" data-target="sub-1">Studies</a>
                        <nav id="sub-1">
                            <h6>Studies - Subnavigation</h6>
                            <ul>
                                <li>
                                    <a title="Degree Programs " href="https://www.unibas.ch/en/Studies/Degree-Programs.html">Degree Programs </a>
                                </li>
                                <li>
                                    <a title="Course Directory" href="https://www.unibas.ch/en/Studies/Course-Directory.html">Course Directory</a>
                                </li>
                                <li>
                                    <a title="Dates " href="https://www.unibas.ch/en/Studies/Dates-Events.html">Dates </a>
                                </li>
                                <li>
                                    <a title="Application &amp; Admission" href="https://www.unibas.ch/en/Studies/Application-Admission.html">Application &amp; Admission</a>
                                </li>
                                <li>
                                    <a title="My Studies" href="https://www.unibas.ch/en/Studies/My-Studies.html">My Studies</a>
                                </li>
                                <li>
                                    <a title="Mobility" href="https://www.unibas.ch/en/Studies/Mobility.html">Mobility</a>
                                </li>
                                <li>
                                    <a title="Advice" href="https://www.unibas.ch/en/Studies/Advice.html">Advice</a>
                                </li>
                                <li>
                                    <a title="Student Life" href="https://www.unibas.ch/en/Studies/Student-Life.html">Student Life</a>
                                </li>
                                <li>
                                    <a title="FAQ Studies" href="https://www.unibas.ch/en/Studies/FAQ-Studies.html">FAQ Studies</a>
                                </li>
                            </ul>
                        </nav>
                </li>
                <li>
                    <a href="https://www.unibas.ch/en/Research.html" data-target="sub-2">Research</a>
                        <nav id="sub-2">
                            <h6>Research - Subnavigation</h6>
                            <ul>
                                <li>
                                    <a title="Research in Basel" href="https://www.unibas.ch/en/Research/Research-in-Basel.html">Research in Basel</a>
                                </li>
                                <li>
                                    <a title="Funding" href="https://www.unibas.ch/en/Research/Financing.html">Funding</a>
                                </li>
                                <li>
                                    <a title="Academic Careers" href="https://www.unibas.ch/en/Research/Academic-Careers.html">Academic Careers</a>
                                </li>
                                <li>
                                    <a title="Graduate Center" href="https://www.unibas.ch/en/Research/Graduate-Center.html">Graduate Center</a>
                                </li>
                                <li>
                                    <a title="UNI NOVA" href="https://www.unibas.ch/en/Research/Uni-Nova.html">UNI NOVA</a>
                                </li>
                                <li>
                                    <a title="Personalized Health Basel" href="https://www.unibas.ch/en/Research/Personalized-Health-Basel.html">Personalized Health Basel</a>
                                </li>
                            </ul>
                        </nav>
                </li>
                <li>
                    <a href="https://www.unibas.ch/en/Innovation.html" data-target="sub-3">Innovation</a>
                        <nav id="sub-3">
                            <h6>Innovation - Subnavigation</h6>
                            <ul>
                                <li>
                                    <a title="Your Entrepreneurial Journey" href="https://www.unibas.ch/en/Innovation/Your-Entrepreneurial-Journey.html">Your Entrepreneurial Journey</a>
                                </li>
                                <li>
                                    <a title="Entrepreneurship course" href="https://www.unibas.ch/en/Innovation/Entrepreneurship-course.html">Entrepreneurship course</a>
                                </li>
                                <li>
                                    <a title="Entrepreneurs Club" href="https://www.unibas.ch/en/Innovation/Entrepreneurs-Club.html">Entrepreneurs Club</a>
                                </li>
                                <li>
                                    <a title="Innovation Initiatives" href="https://www.unibas.ch/en/Innovation/Innovation-Initiatives.html">Innovation Initiatives</a>
                                </li>
                                <li>
                                    <a title="Propelling Grant" href="https://www.unibas.ch/en/Innovation/Propelling-Grants.html">Propelling Grant</a>
                                </li>
                            </ul>
                        </nav>
                </li>
                <li>
                    <a href="https://www.unibas.ch/en/Continuing-Education.html" data-target="sub-4">Continuing Education</a>
                        <nav id="sub-4">
                            <h6>Continuing Education - Subnavigation</h6>
                            <ul>
                                <li>
                                    <a title="News and events" href="https://www.unibas.ch/en/Continuing-Education/News-and-events.html">News and events</a>
                                </li>
                                <li>
                                    <a title="Programs" href="https://www.unibas.ch/en/Continuing-Education/Programs.html">Programs</a>
                                </li>
                                <li>
                                    <a title="Course Types and Degrees" href="https://www.unibas.ch/en/Continuing-Education/Degrees.html">Course Types and Degrees</a>
                                </li>
                                <li>
                                    <a title="Career and Continuing Education" href="https://www.unibas.ch/en/Continuing-Education/Career-and-continuing-education.html">Career and Continuing Education</a>
                                </li>
                                <li>
                                    <a title="Advanced Studies: Center and Team" href="https://www.unibas.ch/en/Continuing-Education/Advanced-Studies.html">Advanced Studies: Center and Team</a>
                                </li>
                                <li>
                                    <a title="FAQ" href="https://www.unibas.ch/en/Continuing-Education/FAQ.html">FAQ</a>
                                </li>
                            </ul>
                        </nav>
                </li>
                <li>
                    <a href="https://www.unibas.ch/en/University.html" data-target="sub-5">University</a>
                        <nav id="sub-5">
                            <h6>University - Subnavigation</h6>
                            <ul>
                                <li>
                                    <a title="About the University" href="https://www.unibas.ch/en/University/About-University.html">About the University</a>
                                </li>
                                <li>
                                    <a title="Management &amp; Organization" href="https://www.unibas.ch/en/University/Management-Organization.html">Management &amp; Organization</a>
                                </li>
                                <li>
                                    <a title="Administration &amp; Services" href="https://www.unibas.ch/en/University/Administration-Services.html">Administration &amp; Services</a>
                                </li>
                                <li>
                                    <a title="Networks &amp; Partnerships" href="https://www.unibas.ch/en/University/Networks-Partnerships.html">Networks &amp; Partnerships</a>
                                </li>
                                <li>
                                    <a title="University &amp; Society" href="https://www.unibas.ch/en/University/University-Society.html">University &amp; Society</a>
                                </li>
                                <li>
                                    <a title="Working at the University of Basel" href="https://www.unibas.ch/en/University/Working-at-the-University-of-Basel.html">Working at the University of Basel</a>
                                </li>
                                <li>
                                    <a title="Legal Regulations" href="https://www.unibas.ch/en/University/Legal-Regulations.html">Legal Regulations</a>
                                </li>
                                <li>
                                    <a title="Organizational units" href="https://www.unibas.ch/en/University/Organizational-units.html">Organizational units</a>
                                </li>
                                <li>
                                    <a title="Merchandise" href="https://www.unibas.ch/en/University/Merchandise.html">Merchandise</a>
                                </li>
                                <li>
                                    <a title="Contact &amp; Directions" href="https://www.unibas.ch/en/University/Contact-Directions.html">Contact &amp; Directions</a>
                                </li>
                                <li>
                                    <a title="Fundraising" href="https://www.unibas.ch/en/University/Fundraising.html">Fundraising</a>
                                </li>
                            </ul>
                        </nav>
                </li>
    </ul>
</nav>

<!--breadcrumb.ftl-->


<nav id="breadcrumb">
       <h6>Breadcrumb</h6>

        <ul>
                    <li>
                        <a title="Home" aria-label="Home" href="https://www.unibas.ch/en.html"></a>
                    </li>
                    <li>
                        <a href="https://www.unibas.ch/en/News-Events.html" title="News &amp; Events">News &amp; Events</a>
                    </li>
                    <li>
                        <a href="https://www.unibas.ch/en/News-Events/News.html" title="News">News</a>
                    </li>
                    <li>
                        <em>nav.selected </em><strong id="breadcrumb-current">A tiny instrument to measure the faintest magnetic fields</strong>
                    </li>
        </ul>
</nav>



    </section>
	<span id="page-content">Start of page content</span>

<section>
    <h6>Free Content</h6>
    
    <div>

        
        
        
        


        

        <article id="rsArticle">
            <!-- START CONTEND WIDE INHALT -->






<p><strong>Physicists at the University of Basel have developed a minuscule instrument able to detect extremely faint magnetic fields. At the heart of the superconducting quantum interference device are two atomically thin layers of graphene, which the researchers combined with boron nitride. Instruments like this one have applications in areas such as medicine, besides being used to research new materials.</strong></p>



            <div>

    <div>
        
        <p>
            <iframe width="420" height="315" src="https://www.youtube.com/embed/pGuQHxf2jdw" allowfullscreen=""></iframe>
        </p>
    </div>

<div>

    


    <div>
        <p>To measure very small magnetic fields, researchers often use superconducting quantum interference devices, or SQUIDs. In medicine, their uses include monitoring brain or heart activity, for example, while in the earth sciences researchers use SQUIDs to characterize the composition of rocks or detect groundwater flows. The devices also have a broad range of uses in other applied fields and basic research.</p>

<p>The team led by Professor Christian Schönenberger of the University of Basel’s Department of Physics and the Swiss Nanoscience Institute has now succeeded in creating one of the smallest SQUIDs ever built. The researchers described their achievement in the scientific journal <em>Nano Letters</em>.</p>

<h4><strong>A superconducting ring with weak links</strong></h4>

<p>A typical SQUID consists of a superconducting ring interrupted at two points by an extremely thin film with normal conducting or insulating properties. These points, known as weak links, must be so thin that the electron pairs responsible for superconductivity are able to tunnel through them. Researchers recently also began using nanomaterials such as nanotubes, nanowires or graphene to fashion the weak links connecting the two superconductors.</p>

<p>As a result of their configuration, SQUIDs have a critical current threshold above which the resistance-free superconductor becomes a conductor with ordinary resistance. This critical threshold is determined by the magnetic flux passing through the ring. By measuring this critical current precisely, the researchers can draw conclusions about the strength of the magnetic field.</p>

<h4><strong>SQUIDs with six layers</strong></h4>

<p>“Our novel SQUID consists of a complex, six-layer stack of individual two-dimensional materials,” explains lead author David Indolese. Inside it are two graphene monolayers separated by a very thin layer of insulating boron nitride. “If two superconducting contacts are connected to this sandwich, it behaves like a SQUID – meaning it can be used to detect extremely weak magnetic fields.”</p>

    </div>
</div>
<div>

    


           <figure id="showbox-2">
               <p><a href="https://www.unibas.ch/dam/jcr:eb317e73-26a7-4089-b158-bd8b6a1c9cea/SQUID_1000x370.jpg"><img src="https://www.unibas.ch/dam/jcr:eb317e73-26a7-4089-b158-bd8b6a1c9cea/SQUID_1000x370.jpg" title="Illustration of a conventional and the new design of the SQUID" alt="Illustration of a conventional and the new design of the SQUID"></a>
               </p>
               <figcaption><span>a) A conventional superconducting quantum interference device (SQUID) consists of a superconducting ring interrupted at two points by weak links (in this case a graphene layer). b) The new SQUID is made up of a stack of two-dimensional materials, including two graphene layers separated by a thin film of boron nitride. (University of Basel, Department of Physics) </span><a href="https://www.unibas.ch/dam/jcr:eb317e73-26a7-4089-b158-bd8b6a1c9cea/SQUID_1000x370.jpg"></a></figcaption>
           </figure>

    <div>
        <p>In this setup, the graphene layers are the weak links, although in contrast to a regular SQUID they are not positioned next to each other, but one on top of the other, aligned horizontally. “As a result, our SQUID has a very small surface area, limited only by the constraints of nanofabrication technology,” explains Dr. Paritosh Karnatak from Schönenberger’s team.</p>

<p>The tiny device for measuring magnetic fields is only around 10 nanometers high – roughly a thousandth of the thickness of a human hair. The instrument can trigger supercurrents that flow in minuscule spaces. Moreover, its sensitivity can be adjusted by changing the distance between the graphene layers. With the help of electrical fields, the researchers are also able to increase the signal strength, further enhancing the measurement accuracy.</p>

<h4><strong>Analyzing topological insulators</strong></h4>

<p>The Basel research team’s primary goal in developing the novel SQUIDs was to analyze the edge currents of topological insulators. Topological insulators are currently a focus of countless research groups all over the …</p></div></div></div></article></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.unibas.ch/en/News-Events/News/Uni-Research/A-tiny-instrument-to-measure-the-faintest-magnetic-fields.html">https://www.unibas.ch/en/News-Events/News/Uni-Research/A-tiny-instrument-to-measure-the-faintest-magnetic-fields.html</a></em></p>]]>
            </description>
            <link>https://www.unibas.ch/en/News-Events/News/Uni-Research/A-tiny-instrument-to-measure-the-faintest-magnetic-fields.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24441000</guid>
            <pubDate>Fri, 11 Sep 2020 10:10:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interview with author of Hardcaml, OCaml DSL for hardware design]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24440785">thread link</a>) | @yminsky
<br/>
September 11, 2020 | https://signalsandthreads.com/programmable-hardware/ | <a href="https://web.archive.org/web/*/https://signalsandthreads.com/programmable-hardware/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<h2 id="003">0:03</h2>

<p>Welcome to Signals and Threads, in-depth conversations about every layer of the tech stack from Jane Street. I’m Ron Minsky. Today, we’re going to have a conversation about hardware, and in particular about how you can take the tools that come out of the world of chip design and apply them to a much broader space of problems than people typically think they can be applied to. And I’m joined in this conversation by Andy Ray.</p>

<h2 id="031">0:31</h2>

<p>Hello, Ron, good to be chatting with you.</p>

<h2 id="033">0:33</h2>

<p>Andy is a longtime veteran of the hardware industry. He spent over a decade building real shippable hardware designs, working on things like modems and video codecs. And along that time, he also did a lot of interesting work exploring and eventually designing his own alternative languages for expressing hardware designs. The final one was called <a href="https://github.com/janestreet/hardcaml">Hardcaml</a>, which is a hardware design language embedded inside <a href="https://ocaml.org/">OCaml</a>, which itself is the primary programming language we use here at Jane Street. And that work actually led him to us. And today he works here and leads Jane Street’s hardware design team. And so, to start with Andy, maybe you can tell us a little bit about why hardware is useful for a technology organization and an organization like ours, and what advantages it has over traditional software-style approaches?</p>

<h2 id="123">1:23</h2>

<p>Sure. So hardware allows you to build customized architectures for a specific problem, which can be tuned to trade off, at a very fine level, lots of things like performance, and cost and power usage. That lets you design a range of different products. Whereas with a CPU, you’re very much more limited in the software world to the CPU design that can meet the performance of the problem domain. I think the sorts of problems that it can solve are very, very broad. And you can see that just because well, a CPU is a hardware design, in fact. And you can create all sorts of hybrid designs with multiple CPUs or digital signal processors or custom hardware blocks that make up your final solution. So I think that’s why hardware exists, why it will always exist. It’s the fact that you can build architectures entirely suited to your problem domain that optimize along these sort of areas.</p>

<h2 id="230">2:30</h2>

<p>That description on the face of it sounds awesome. And in fact, it sounds from what you said so far, strictly superior to writing software. I don’t think that’s quite true. Can you see more about what the downsides are of operating inside of a hardware context?</p>

<h2 id="243">2:43</h2>

<p>Oh, my goodness, yes, there are a lot. So it is fundamentally this: hardware designs are much, much more difficult to write than equivalent software. So all that flexibility in choosing, you know, the architecture for your problem domain, you actually have to implement that. In software, you have reams and reams of support libraries that either your organization has developed or that you can pull in from open source or that you can go and purchase. To some extent that infrastructure works in hardware with the idea of intellectual property suppliers. They’re basically just companies who supply a hardware design for you to integrate into your system. That’s actually the job I used to do when we were developing video codecs.</p>

<h2 id="327">3:27</h2>

<p>Yeah. And just to interrupt for a second though, that was a bit of terminology that really confused me when I first encountered the hardware world. When people in hardware say, “IP,” they mean something like when a software person says “library.”</p>

<h2 id="338">3:38</h2>

<p>Correct.</p>

<h2 id="339">3:39</h2>

<p>Which is to say some component that somebody else wrote that you get to integrate. Except in this case, the component is a bundle of wires that you kind of plop into your design rather than something that looks more like a module or library.</p>

<h2 id="351">3:51</h2>

<p>Yeah, that’s right. I don’t know why that terminology came about, but it’s just always been called IP when you buy hardware library design. There’s some sort of infrastructure there for buying external blocks to integrate with your hardware. It’s a vastly smaller ecosystem than we have in software. It’s vastly more expensive. There is in the last maybe ten years more of an open source community around providing hardware blocks that you can integrate. But it’s still absolutely miniscule compared to software. And then just the process of writing hardware is slow and detailed. And I’m gonna say difficult. I’m not so sure it is really technically that difficult. It’s just that it’s so detailed, and you’re dealing with such big systems that it becomes a real problem trying to manage the complexity of all these very simple bits that sit together.</p>

<h2 id="449">4:49</h2>

<p>Right, I think of that as one of the paradoxes of hardware: hardware is in the micro, in many different ways, simpler than software.</p>

<h2 id="456">4:56</h2>

<p>Yes.</p>

<h2 id="457">4:57</h2>

<p>The thing that you’re generating in a hardware design is essentially some layout of the circuit, the individual gates and wires that connect them. And it’s some kind of fairly static graph that represents the structure of the computation, and is converted into, when you actually get one of these fabricated, actual bits of material laid out on a physical surface. And understanding how those individual pieces work, at least logically how they work, leaving the physics aside, is relatively simple. But then having a big design that does a lot of these things, is enormously hard to reason about.</p>

<h2 id="532">5:32</h2>

<p>It is and unfortunately, the abstraction tools we have, they take us some way. So you know, you talked about a chip design, which you can think of as a layout of just two things really, lots of lots of NAND gates (a Boolean AND function with the output NOTed) and metal wires that connect them together. And it’s interesting because NAND is a universal Boolean function. Any other Boolean function can be computed with the NAND function. That’s not true of AND, for example, you can’t create an OR with an AND, but you can create it with a NAND. And they are like, I think sixteen Boolean functions, and four of them are universal. I think NAND and NOR are quite often like the basis of technology (NOR being an OR gate with the output inverted). We don’t actually think about writing circuits at the level of just interconnected NAND gates. An interesting aside, I believe the first ARM processor was basically designed that way. But actually even lower, they were drawing the transistors for the NAND gates in like just a graphics package. That’s how they created the very first ARM processor. But that’s not how they do it now. So we’re a little bit above that: we work with a tool called a synthesizer, and it takes a slightly more abstract notion of a hardware design in which we can think about components like adders and multiplexers. And the job of the synthesizer will be to turn those components into the actual low level hardware components for the chip, which might be NAND gates if you’re doing an ASIC, it might be look-up tables for an FPGA. But that being said, it’s not massively above building it with NAND gates. But really a lot of the industry just works at this sort of level of putting together these macros, which represent adders and multiplexers, and multipliers and registers and just wiring them together and getting them to form some function.</p>

<h2 id="738">7:38</h2>

<p>So you were talking there about ASICS and FPGAs. Can you just quickly explain what those are.</p>

<h2 id="743">7:43</h2>

<p>An ASIC is a custom-made chip that can perform a single function. In contrast, an FPGA is a reprogrammable chip that can be programmed to perform many different functions.</p>

<h2 id="757">7:57</h2>

<p>Got it. So when you talked about what the advantages are of hardware, you talked about how by having much more control, you get to really optimize the things you care about via power consumption or performance or latency or whatever it is of the, of the, system. Can you put a little bit of meat on the bones of that? What is the scale of the improvements that you can get by taking something that you might do in software and moving it into a hardware design?</p>

<h2 id="825">8:25</h2>

<p>It’s obviously going to depend on the sort of problem you’re trying to solve. But you know, an area I know really well, video coding. I used to work on <a href="https://en.wikipedia.org/wiki/Advanced_Video_Coding">H.264</a> a lot and there was just a really good software implementation called <a href="https://en.wikipedia.org/wiki/X264">x264</a>, which was almost entirely written in assembly, using the SSE instructions, which is a vector instruction set on the x86 processor. And it could just about manage like real-time 1080p on modern Intel processors of the time, which were like four gigahertz processors. In order for it to achieve that sort of performance, you had to turn off lots of lots and lots of codec features. If you’re willing to go non-real-time, you could turn on all sorts of features that would compress it better. There’s an extremely large standard for H.264 that I used to read a lot, and there’s a lot of features on that thing, but you just can’t do them all. And so we used to target different markets, there was like, a sort of low-end video codec, which could fit in smaller FPGAs, could be used for like internet based communication. And there was like really high-end video codecs, which were built over multiple FPGAs, and had a really high end feature set, and was used for professional-grade encoding. So that’s the sort of video that you get over your satellite link or over your cable link. That bitstream is compressed as much as it possibly can be so they can fit more channels into that link. We didn’t have to compromise so much on the features to do that with hardware, we could pick the features that made the difference that got us to the bit rate, and they could run in real time. And you just couldn’t do that real time in software. You know, in that world, you’re looking at an order of magnitude more computation being done by these FPGAs. But these sort of things can scale massively. They’re like chips, which do packet processing, for example. So the idea here is you’ve got a switch and you want to do packet processing to detect threats in those packets to route …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://signalsandthreads.com/programmable-hardware/">https://signalsandthreads.com/programmable-hardware/</a></em></p>]]>
            </description>
            <link>https://signalsandthreads.com/programmable-hardware/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24440785</guid>
            <pubDate>Fri, 11 Sep 2020 09:37:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Checked exceptions: Java’s biggest mistake (2014)]]>
            </title>
            <description>
<![CDATA[
Score 107 | Comments 285 (<a href="https://news.ycombinator.com/item?id=24440536">thread link</a>) | @flying_sheep
<br/>
September 11, 2020 | http://literatejava.com/exceptions/checked-exceptions-javas-biggest-mistake/ | <a href="https://web.archive.org/web/*/http://literatejava.com/exceptions/checked-exceptions-javas-biggest-mistake/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-174">
	
	<!-- .entry-header -->

		<div>
		<p>Checked exceptions have always been a controversial feature of the Java language.</p>
<p>Advocates claim they ensure checking &amp; recovery from failures. Detractors say “catch” blocks can almost never recover from an exception, and are a frequent source of mistakes.</p>
<p>Meanwhile, Java 8 and lambdas are here. Are checked exceptions becoming obsolete in the Java world?<span id="more-174"></span></p>
<h3>The Intent of Checked Exceptions</h3>
<p>In the mid 90’s, James Gosling at Sun came up with a new language.</p>
<p>At the time, C++ programming required every single function return to be checked for error. He decided there had to be a better way, and built the concept of “exceptions” into Java.</p>
<p>The intent of <strong>checked exceptions</strong> was to locally flag, and force developers to handle, possible exceptions. Checked exceptions have to be declared on a method signature, or handled.</p>
<p>This was intended to encourage software reliability &amp; resilience. There was an intent to “recover” from contingencies – predictable outcomes other than success, such as InsufficientFundsException on attempting a payment. There was less clarity, as to what “recovery” actually entailed.</p>
<p><strong>Runtime exceptions</strong>&nbsp;were also included in Java. Since null pointers, data errors, and illegal states/ accesses could occur anywhere in code, these were made subtypes of RuntimeException.</p>
<p>Runtime exceptions can be thrown anywhere, without requiring to be declared, and are much more convenient. But would it be correct to use them instead?</p>
<h3>The Drawbacks</h3>
<p>The crucial point here, is that runtime &amp; checked exceptions are functionally equivalent.&nbsp;There is no handling or recovery which checked exceptions can do, that runtime exceptions can’t.</p>
<p>The biggest argument against “checked” exceptions is that most exceptions can’t be fixed. The simple fact is, <strong>we don’t own the code/ subsystem that broke.&nbsp;</strong>We can’t see the implementation, we’re not responsible for it, and can’t fix it.</p>
<p>Particularly problematic were the areas of JDBC (SQLException) and RMI for EJB (RemoteException). Rather than identifying fixable contingencies as per the original “checked exception” concept, these forced pervasive systemic reliability issues, not actually fixable, to be widely declared.</p>
<p>For any method, the possibility of failure includes all sub-methods called by it. Potential failures accumulate up the call tree. Declaring these on method signatures no longer offers a specific &amp; local highlight for the developer to watch for – declared exceptions spread throughout the call tree.</p>
<p>Most EJB developers have experienced this – declared exceptions become&nbsp;required on methods through the tier,&nbsp;or entire codebase. Calling a method with different&nbsp;exceptions&nbsp;requires dozens of methods to be adjusted.</p>
<p>Many developers were told to catch low-level exceptions, and rethrow them again as higher (application-level) checked exceptions. This required vast numbers – 2000 per project, upwards – of non-functional “catch-throw” blocks.</p>
<p>Swallowing exceptions, concealing the cause, double logging, and returning ‘null’/ uninitialized data all became common. Most projects could count 600+ mis-coded or outright errors.</p>
<p>Eventually, developers rebelled against the vast numbers of “catch” blocks, and the source of error these had become.</p>
<h3>Checked Exceptions – incompatible with Functional Coding</h3>
<p>And then we get to Java 8, with its new <i><b>functional programming&nbsp;</b></i>features – such as lambdas, Streams, and function composition.</p>
<p>These features are built on generics – parameter &amp; return types are genericized, so that iteration &amp; stream operations ( <code>forEach</code>, <code>map</code>, <code>flatMap</code>) can be written which perform a common operation, regardless of item type.</p>
<p>Unlike data types, however, declared exceptions can’t be genericized.</p>
<p>There is no possibility in Java to provide a stream operation (like, for example, &nbsp;<code>Stream.map</code>) which takes a lambda declaring some checked exception, &amp; transparently passes that same checked exception to surrounding code.</p>
<p>This has always been a major points against checked exceptions – all intervening code, between a throw and the receiving “catch” block, is forced to be aware of exceptions.</p>
<p>The workaround, of “wrapping” it in a RuntimeException, conceals the original type of the exception – rendering the exception-specific “catch” blocks envisaged in the original concept useless.</p>
<p>Finally we can capture Java’s new philosophy in a nutshell, by noting that none of the new “functional interfaces” in Java 8 declare checked exceptions.</p>
<h3>Conclusion</h3>
<p>Exceptions in Java provided major benefits in reliability &amp; error-handling over earlier languages.&nbsp;Java enabled reliable server &amp; business software, in a way C/ C++ never could.</p>
<p>Checked exceptions were,&nbsp;in their original form, an attempt&nbsp;to handle&nbsp;<i>contingencies</i>&nbsp;rather than&nbsp;<i>failures</i>.&nbsp;The laudable goal was to highlight specific predictable points (unable to connect,&nbsp;file not found,&nbsp;etc) &amp; ensure developers handled these.</p>
<p>What was never included in the original concept, was to force a vast range of systemic &amp;&nbsp;unrecoverable failures to be declared. These <em>failures</em>&nbsp;were never correct to be&nbsp;declared as checked exceptions.</p>
<p>Failures are generally possible in code, and EJB, web &amp; Swing/AWT containers already cater for this by providing an outermost “failed request” exception-handler. The most basic correct strategy is to rollback the transaction &amp; return an error.</p>
<p>Runtime exceptions allow any exception-handling possible with checked exceptions, but avoid restrictive coding restraints. This simplifies coding &amp; makes it easier to follow best practice of&nbsp;<a href="http://wikijava.org/wiki/10_best_practices_with_Exceptions#Throw_early_catch_late" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://wikijava.org']);">throw early, catch late</a>&nbsp;where exceptions are handled at the outermost/ highest possible level.</p>
<p>Leading Java frameworks and influences have now definitively moved&nbsp;away from checked exceptions. Spring, Hibernate and modern Java frameworks/&nbsp;vendors&nbsp;use only runtime exceptions, and this convenience is a major factor in their popularity.</p>
<p>Personalities such Josh Bloch (Java&nbsp;Collections framework), Rod Johnson, Anders Hejlsberg (father of&nbsp;C#), Gavin King&nbsp;and&nbsp;Stephen Colebourn&nbsp;(JodaTime)&nbsp;have all come out against checked exceptions.</p>
<p>Now, in&nbsp;Java 8,&nbsp;lambdas are&nbsp;the&nbsp;fundamental step forward.&nbsp;These language features&nbsp;abstract the “flow of control” from functional operations within. As we’ve seen, this makes checked exceptions &amp; the requirement to “declare or handle immediately” obsolete.</p>
<p>For developers, it is always important to pay attention to reliability &amp; diagnose likely points of failure (contingencies) such as file open, database connection, etc. If we provide good error messages at this points, we will have&nbsp;created&nbsp;self-diagnosing software – a pinnacle of engineering achievement.</p>
<p>But we should do this with unchecked exceptions, and if we have to rethrow, should always use RuntimeException or an app-specific subclass.</p>
<p>As&nbsp;Stephen Colebourn says, if your projects&nbsp;are&nbsp;still using or advocating checked exceptions, your skills are 5-10 years out date.&nbsp;Java&nbsp;has moved&nbsp;on.</p>
<p><strong>How are you dealing with exceptions &amp; reliability? Add your thoughts now.</strong></p>
<p>References:<br>
– <a href="http://www.oracle.com/technetwork/articles/entarch/effective-exceptions-092345.html">Oracle: Barry Ruzek, Effective Java Exceptions<br>
</a>– <a href="http://tutorials.jenkov.com/java-exception-handling/checked-or-unchecked-exceptions.html" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://tutorials.jenkov.com']);">Jacob Jenkov: Checked or Unchecked Exceptions</a><br>
– <a href="http://googletesting.blogspot.co.nz/2009/09/checked-exceptions-i-love-you-but-you.html" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://googletesting.blogspot.co.nz']);">Google Testing blog: &nbsp;Checked exceptions, you have to go</a><br>
–&nbsp;<a href="http://www.artima.com/intv/handcuffs.html">Ander Hejlsberg on checked exceptions<br>
–</a>&nbsp;<a href="http://blog.joda.org/2010/09/checked-exceptions-bijava_9688.html" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://blog.joda.org']);">Stephen Colebourne: Remove checked exceptions from Java</a></p>
<p>Counter-argument: &nbsp;James Gosling<br>
– <a href="http://www.artima.com/intv/solid.html" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://www.artima.com']);">James Gosling on checked exceptions</a></p>
	</div><!-- .entry-content -->
	
	</article></div>]]>
            </description>
            <link>http://literatejava.com/exceptions/checked-exceptions-javas-biggest-mistake/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24440536</guid>
            <pubDate>Fri, 11 Sep 2020 08:57:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dynamic Pricing for Mobile Apps]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24440354">thread link</a>) | @gintonic
<br/>
September 11, 2020 | https://www.getmage.io/post/dynamic-pricing-for-mobile-apps | <a href="https://web.archive.org/web/*/https://www.getmage.io/post/dynamic-pricing-for-mobile-apps">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Thousand of companies and indie developers are involved in the ever-growing market of mobile apps. Competition is growing. The mobile market is thriving.<br></p><p>The job of a successful app publisher is hard. He needs to listen to the users' feedback, develop and publish new updates, watch out for the competition, and manage marketing campaigns. In other words, monitoring and optimizing everything on an ongoing basis is crucial. Managing resources, especially with a 30% revenue cut from the platform providers like Apple or Google, is essential.<br></p><p>One often unused optimization and growth strategy due to its complexity is dynamic pricing.</p><p>‍<br></p><h2>What is dynamic pricing?</h2><p>Dynamic pricing is a pricing strategy that is all about flexible prices. Flexible prices mean that they respond to market conditions.<br></p><p>In general, prices adjust according to the demand of the market. The best-known example of this concept is the pricing of flight tickets or the gas price from your favorite gas station. Both businesses price their products via demand. If the demand is high, the prices will be high.<br></p><p>Another well-known approach is a dynamic price based on the buyers' location. We often see this with physical goods. A good example is the price of an iPhone, which costs more in Germany than in the USA.<br></p><p>Compared to static pricing, dynamic pricing's main advantage is that the seller meets the demand of a market with a better price. This way, the seller avoids opportunity costs. In other words, he makes more money. He knows what to charge because he knows what buyers are willing to spend.</p><figure id="w-node-0f9bad4ca291-a9a5bdca"><p><img src="https://uploads-ssl.webflow.com/5eb96fb2022bac7d41a5bbdd/5f562fa22220c9c4c11836fe_mage-dynamic-pricing.png" loading="lazy" alt=""></p><figcaption>Sweet spot of dynamic pricing</figcaption></figure><h2>Adapting dynamic pricing for mobile apps<br></h2><p>Dynamic pricing is currently only available in a very simplified version in the app stores. Real dynamic pricing is mostly practiced with custom build software by very large and successful app companies like Tinder or Spotify.&nbsp;Most apps that use some dynamic pricing mostly follow two approaches: prices based on time and user location.</p><p>The idea of prices based on time is simple. Since we are talking about the mobile environment, the app provider knows its customer. He can segment between users who bought and users who did not buy after a specific period. If a user falls into the group of people who did not purchase anything, he will receive an offer with discounted prices. What a great catch!&nbsp;</p><p>The only problem with that strategy is that it will just work if the app publisher can reach the potential customer. Most people delete apps after a few minutes of using an app or days after installing it. In that case, in-app popups will not work. Push notifications might work out if the app is still on the user's phone. Sending emails will probably be the best approach, but the app publisher needs to know the email address for that to work. Also, the user needs to open the email, and please don't get me started on conversion rates of emails.</p><p>We can see that there is a massive overhead of technology needed to make this strategy work. An app publisher would need to develop an internal popup, a push notification, and an email system. That costs a lot of money.</p><p>The second approach is to base dynamic pricing on the buyers' location. A good example is segmentation by country.</p><p>Since the seller has some knowledge of his target market's purchasing power, he can set the base price in that market. Certain other countries receive discounts relative to that base price. Other countries with a higher purchasing power than the default market may receive a higher price relative to the base price. This abstract description could look something like the image below.</p><figure id="w-node-32a53b335696-a9a5bdca"><p><img src="https://uploads-ssl.webflow.com/5eb96fb2022bac7d41a5bbdd/5f47cc92d2fa4a3315898a8c_mage-diffrent-in-app-purchase-prices.png" loading="lazy" alt=""></p><figcaption>Different prices based on location</figcaption></figure><p>‍<a href="#"><br></a>For this kind of pricing, a high intense and expensive market research is needed. App publishers need to evaluate markets and determine the regional prices. This process can take months, and the worst part, the optimum is never fixed due to ever-changing market conditions. Spoiler alert: it's a continuous process.</p><p>‍<br></p><h2>The pain in adapting dynamic pricing for mobile apps</h2><p>Both ways (dynamic pricing based on time or location) represent excellent solutions. The only drawback is that both strategies are from enormous complexity.</p><p>App publishers may need to spend many resources on the development. They may need to hire market researches, data scientists, and other pricing specialists to implement a self-improving pricing system. This is why dynamic pricing is currently only seen in unicorn apps: It is simply expensive.</p><p>‍<br></p><h2>A fast and cost effective way to add dynamic pricing to mobile apps</h2><p>We developed and continuously improving a system that can bring dynamic pricing to any mobile app. As of this time of writing, we invested five months of development time, so you do not have to.</p><p>Mage is a "dynamic pricing as a service" solution for in-app purchases. Mage is scalable and usable for all kinds and sizes of apps. Due to the way app stores work at the moment, Mage works just for apps that use in-app purchases as a monetization strategy.</p><p>With Mage, app publishers can adopt dynamic pricing without the need for expensive market research, data science, and development teams.</p><p>Mage makes manually interpreting reports as well as generating and implementing new prices a thing of the past. Mage is fully automated and continuously fed with new data from the App Publishers' target markets. Mage is affordable and offers a free plan for young apps, who are just starting their journey. The integration of Mage takes around two to eight hours, depending on the apps complexity.</p><figure id="w-node-93b7b888b407-a9a5bdca"><p><img src="https://uploads-ssl.webflow.com/5eb96fb2022bac7d41a5bbdd/5f47ccc48af7b24655e46a33_mage-dynamic-pricing-solution.png" loading="lazy" alt=""></p><figcaption>Mage Dynamic Pricing As A Service Solution</figcaption></figure><h2>How to dynamically price in-app purchases</h2><p>First, you need to sign up via our <a href="https://www.getmage.io/">Website</a>. After that, you need to add your app, product groups, and products to our dashboard. Once you configured everything, Mage will give you instructions on setting up your app store products. The last step is implementing the simple, lightweight, and open-source Mage SDK. Currently, our mobile SDKs are available for iOS, Android, and React-Native Apps. For further information on how to get started, please read our <a href="https://www.getmage.io/documentation/integration-guide">Integration Guide</a>.<br></p><p>‍</p></div></div></div>]]>
            </description>
            <link>https://www.getmage.io/post/dynamic-pricing-for-mobile-apps</link>
            <guid isPermaLink="false">hacker-news-small-sites-24440354</guid>
            <pubDate>Fri, 11 Sep 2020 08:29:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Started with Eleventy (11ty)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24440252">thread link</a>) | @patelpankaj
<br/>
September 11, 2020 | https://time2hack.com/getting-started-with-eleventy-11ty/ | <a href="https://web.archive.org/web/*/https://time2hack.com/getting-started-with-eleventy-11ty/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<p>JAMStack is Fast. Fast for Development and to deliver ultra Fast websites.</p><p>To develop with JAMStack, one of the ways is Static Site Generation.</p><h2 id="static-site-generators-ssg-">Static Site Generators (SSG)</h2><p>SSGs are the tools which will take the data from any data source and generate Static HTML pages.</p><p>Static Sites are way faster than any dynamic site because:</p><ul><li>No content generated on runtime, which means no time spent in this process</li><li>The server doesn’t have to match for the dynamic URLs. HTML files delivered straight to the browser without any Route/URL matching</li><li>As the content is Static, it will be cached for longer time</li><li>Again, being Static, the websites can be delivered through CDNs. This way users don’t have to wait very long for the response.</li></ul><p>And to build WebSites with SSGs, Eleventy (11ty) is fast and easy to use the tool.</p><hr><h2 id="eleventy-11ty-">Eleventy (11ty)</h2><p>11ty is a JavaScript alternative of Jackyl. It’s built with no-configuration in mind. Though, it supports many templating languages; for example MarkDown, Pug, Handlebars etc.</p><p>We will make a simple Blogging website with following features in consideration:</p><ul><li>Index Page with</li><li>Blog Intro</li><li>List of Posts</li><li>Blog Post page</li><li>Tags with Tag Index</li><li>Comments with Disqus</li><li>Deployed on Netlify</li></ul><p>First, we need to create a Project and add 11ty as the dev dependency, lets do that with following commands:</p><pre><code># make project directory
mkdir awesome-blog

# switch to the project directory
cd awesome-blog

# initialize the Node Project
yarn init -y

# Add 11ty as a dev dependency
yarn add -D @11ty/eleventy

# open VS Code in the directory
# (if you use VSCode and have set up CLI command)
code.
</code></pre><p>Now we edit the <code>package.json</code> file to add the following to the scripts:</p><pre><code>{
  ...
  "scripts" : {
    "start" : "eleventy --serve"
  },
  ...
}
</code></pre><p>After adding <code>start</code> script in the package.json, launch <code>yarn start</code> on the root of your Project directory from CLI.</p><p>Now that 11ty is up and running, we need to add some content to see it building.</p><p>By default, 11ty will output the generated HTML files in <code>_site</code> directory.</p><p>Let's go ahead and create out index page with <code>index.md</code> file in the root of the project as:</p><pre><code># Hello World
---
Welcome to the `awesome-blog`
</code></pre><p>Which will get generated as the following <code>body</code> in <code>_site/index.html</code>:</p><pre><code>&lt;h1&gt;Hello World&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;Welcome to the &lt;code&gt;awesome-blog&lt;/code&gt;&lt;/p&gt;
</code></pre><p>Well, that was super simple; and blank with no CSS. Let's try to add some Style by adding Bootstrap CSS.</p><p>But where do we add them? This is where layouts in the 11ty come into the play.</p><p>As the name suggests, Layouts are the Page Generator Templates where the data can be filled by selected page.</p><p>The layouts must be inside the <code>_includes</code> directory.</p><p>Lets try to make a Handlebar layout as <code>home.hbs</code> for the home page:</p><pre><code>&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
  &lt;meta charset="UTF-8"&gt;
  &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt;
  &lt;title&gt;{{ title }}&lt;/title&gt;
  &lt;link rel="stylesheet" href="//stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" /&gt;
&lt;/head&gt;
&lt;body class="p-3"&gt;
  &lt;div class="container"&gt;
    {{{content}}}
  &lt;/div&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre><p>To use the above template, we need to add some context to our markdown file. We will add the context with the FrontMatter format inside the markdown.</p><p>FrontMatter is the data format go git more contextual data about the file. For a blog post, it can be title, tags etc. For a landing page, it can be with Sections, Images and other blocks of information.</p><p>For our markdowns, we will add <code>title</code> and <code>tags</code> in the front matter all the time and use it in our layouts.</p><p>So with decided FrontMatter, here is our <code>index.md</code>:</p><pre><code>---
layout: layouts/home.hbs
title: Hello World
tags: [intro, random, gif]
---
# Hello World

---

Welcome to the `awesome-blog`

Here we will add some awesome gifs rolling around the internet.

Starting with this:

![me thinking 'I can do this'](https://media.giphy.com/media/YTJXDIivNMPuNSMgc0/giphy-downsized.gif)
</code></pre><p>Now we have Title repeating two times, we will keep the FrontMatter and remove form the content of the markdown to make it as follows:</p><pre><code>---
layout: layouts/home.hbs
title: Hello World
banner: https://placeimg.com/1000/480/nature
tags: [intro, random, gif]
---
Welcome to the `awesome-blog`

Here we will add some awesome gifs rolling around the internet.

Starting with this:

![me thinking 'I can do this'](https://media.giphy.com/media/YTJXDIivNMPuNSMgc0/giphy-downsized.gif)
</code></pre><p>And with this, we will update our layout as following inside the <code>body</code>:</p><pre><code>&lt;body class="p-3"&gt;
  &lt;div class="container"&gt;
    &lt;h1&gt;{{title}}&lt;/h1&gt;
    {{#if banner}}
      &lt;img src="{{banner}}" alt={{title}} /&gt;
    {{/if}}
    {{#if tags}}
      &lt;div class="tags"&gt;
        {{#each tags}}
          &lt;div class="badge badge-dark"&gt;{{this}}&lt;/div&gt;
        {{/each}}
      &lt;/div&gt;
    {{/if}}
    &lt;hr /&gt;
    {{{content}}}
  &lt;/div&gt;
&lt;/body&gt;
</code></pre><p>Now with basics in mind, we want to make the blog posts and make all the posts listed on the homepage.</p><p>In 11ty, by default, the HTML files will be generated in the same directory structure as of the data file. &nbsp;And the URLs will be like the data file-names.</p><p>So, in our case, we can make all the <em>posts</em> inside the <code>posts</code> directory with post <code>slug</code> as the file-names</p><p>And our Markdown files will follow the following structure:</p><pre><code>/
├── index.md
└── web
    ├── hello-world.md
    ├── ...
    └── trip-to-new-york.md
</code></pre><hr><p>Now we need to add these post lists in the Home Page.</p><p>For this, let’s make a rough try making the data of post in the FrontMatter of the Home Page and create a new layout for it.</p><p>For the list of post, I will approach the data of front matter as follows:</p><pre><code>title: Home
posts:
- 0:
  title: Hello World
  url: posts/hello-World/
  banner: //source.unsplash.com/user/pankajpatel/1024x400
- 1:
  title: Random Post
  url: posts/random/
  banner: //source.unsplash.com/user/pankajpatel/likes/1024x400
</code></pre><p>And the layout can be change to the following:</p><pre><code>&lt;body class="p-3"&gt;
  &lt;div class="container text-center"&gt;
    &lt;h1 class="m-5"&gt;{{title}}&lt;/h1&gt;

    {{#if posts}}
      &lt;div class="row"&gt;
        {{#each posts}}
          &lt;a class="col mb-3 text-decoration-none" href={{this.url}} data-index={{@key}}&gt;
            &lt;article class="card" href={{this.url}} data-index={{@key}}&gt;
              &lt;img src="{{this.banner}}" class="card-img-top" alt="{{this.title}}"&gt;
              &lt;div class="card-body text-left"&gt;
                &lt;h1 class="card-title font-weight-light"&gt;{{this.title}}&lt;/h1&gt;
                &lt;p class="card-text"&gt;&lt;small class="text-muted"&gt;Last updated 3 mins ago&lt;/small&gt;&lt;/p&gt;
              &lt;/div&gt;
            &lt;/article&gt;
          &lt;/a&gt;
        {{/each}}
      &lt;/div&gt;
    {{/if}}
    &lt;hr /&gt;
  &lt;/div&gt;
&lt;/body&gt;
</code></pre><p>But this FrontMatter data were prepared manually. What can we do to build it automatically?</p><p>It’s time to get our hands dirty with configuration files.</p><p>For 11ty, the config file is <code>.eleventy.js</code></p><p>In 11ty’s config file, &nbsp;there needs to be one exported function. This function accepts the current eleventyConfig.</p><p>The current eleventyConfig has some API methods to define different behaviours like:</p><ul><li>Adding/Modifying collection</li><li>Adding new filters</li><li>etc</li></ul><p>For us, the concerned part is to add a new collection for our posts and use this collection to list the posts on the homepage.</p><p>To get the collection of all the posts, we had created FrontMatter data <code>type</code>. And for all the posts, we set the <code>type</code> as <code>post</code></p><p>Now our 11ty config looks like the following:</p><pre><code>module.exports = (eleventyConfig) =&gt; {
  eleventyConfig.addCollection("posts", (collection) =&gt; {
    return collection.getAll().filter((item) =&gt; {
      return 'type' in item.data &amp;&amp; item.data.type === 'post'
    })
  })
}
</code></pre><p>Now with above added <code>posts</code> collection, we can update our homepage template as:</p><pre><code>&lt;body class="p-3"&gt;
  &lt;div class="container text-center"&gt;
    &lt;h1 class="m-5"&gt;{{title}}&lt;/h1&gt;

    {{#if collections.posts}}
    &lt;div class="row"&gt;
      {{#each collections.posts}}
      &lt;a class="col mb-3 text-decoration-none" href={{this.data.page.url}} data-index={{@key}}&gt;
        &lt;article class="card" href={{this.data.url}} data-index={{@key}}&gt;
          {{#if this.data.banner}}
            &lt;img src="{{this.data.banner}}" class="card-img-top" alt="{{this.data.title}}"&gt;
          {{/if}}
          &lt;div class="card-body text-left"&gt;
            &lt;h1 class="card-title font-weight-light"&gt;{{this.data.title}}&lt;/h1&gt;
            &lt;p class="card-text"&gt;&lt;small class="text-muted"&gt;Last updated 3 mins ago&lt;/small&gt;&lt;/p&gt;
          &lt;/div&gt;
        &lt;/article&gt;
      &lt;/a&gt;
      {{/each}}
    &lt;/div&gt;
    {{/if}}
    &lt;hr /&gt;
  &lt;/div&gt;
&lt;/body&gt;
</code></pre><p>Now that our homepage and posts are ready, we can publish it.</p><p>To publish our site, first, we need a git repository and commit the changes.</p><pre><code>git init
echo "node_modules\n_site" &gt; .gitignore
git add .
git commit -m "🚀 personal blog launch initiated"
</code></pre><p>Now you have committed the code on your local repo. You can create a repository on GitHub and add remote to your local repo. Then you can push your branch and it is available remotely.</p><p>Now it is time to publish our blog through this repository.</p><p>Following are the way to publish the website:</p><h3 id="publish-on-netlify">Publish on Netlify</h3><p>Netlify publish is a matter of a few clicks.</p><ul><li>Log into Netlify with Github from here: <a href="https://app.netlify.com/">Netlify App</a></li><li>Click on <code>New Site from Git</code> button</li><li>Connect to your Github if not connected</li><li>Select the repo that you had before created</li><li>Netlify will detect the type of Project and will suggest a build command</li><li>Click on <code>Deploy Site</code></li><li>Yous site is deployed</li></ul><p>You can watch the following video to see the above steps in action:</p><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/zLulIIeYreo?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><figcaption><a href="https://youtu.be/zLulIIeYreo">11ty on Netlify - YouTube</a></figcaption></figure><h3 id="publish-on-github-pages">Publish on GitHub Pages</h3><p>To publish on GitHub pages, you need to add build script to your <code>package.json</code></p><p>You can do so by adding following line the scripts:</p><pre><code>{
  ...
  "scripts" : {
    "build" : "eleventy",
    "start" : "eleventy --serve"
  },
  ...
}
</code></pre><p>Now that the build script is added. We need to add <a href="https://time2hack.com/auto-publish-github-pages-github-actions/">GitHub action to Auto Publish our site to Github Pages</a>. Following is the YAML file placed at <code>.github/workflows/publish.yaml</code></p><pre><code>name: publish

on:
  push:
    branches:
      - master

jobs:
  deploy:
    runs-on: ubuntu-18.04
    steps:
      - uses: actions/<a href="https://time2hack.com/cdn-cgi/l/email-protection" data-cfemail="cba8a3aea8a0a4bebf8bbdf9">[email&nbsp;protected]</a>

      - name: Setup Node
        uses: actions/<a href="https://time2hack.com/cdn-cgi/l/email-protection" data-cfemail="e69583929396cb88898283a690d7">[emai…</a></code></pre></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://time2hack.com/getting-started-with-eleventy-11ty/">https://time2hack.com/getting-started-with-eleventy-11ty/</a></em></p>]]>
            </description>
            <link>https://time2hack.com/getting-started-with-eleventy-11ty/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24440252</guid>
            <pubDate>Fri, 11 Sep 2020 08:13:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I interviewed 7 London startups about C19. Here are the 5 takeaways for survival]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24440239">thread link</a>) | @Ozzie-D
<br/>
September 11, 2020 | https://startupsoflondon.com/5-key-principles-london-startups-use-to-survive/ | <a href="https://web.archive.org/web/*/https://startupsoflondon.com/5-key-principles-london-startups-use-to-survive/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="wp-post" data-elementor-id="6277" data-elementor-settings="[]">
						<div>
							<div>
							<section data-id="33017726" data-element_type="section">
						<div>
							<div>
					<div data-id="6f4823cc" data-element_type="column">
			<div>
							<div>
						<div data-id="13ef0a77" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>We have been spending the last three months interviewing startups from London to ask them about how they are adapting to this new post-pandemic situation and the core principles they depend on to survive C-19. At the end of these interviews, we compiled their learnings into a documentary.&nbsp;</p><p>We will cover their experiences under five chapters: The first chapter is about<b> fragility versus agility</b>. Yes, startups are very agile but at the same time, they are very fragile due to lack of resources. The second one is how <b>doubling the burn rate doubles the runway</b>. The third chapter is about <b>bubbles of opportunity</b>. Some startups will discover those bubbles of opportunity and rise to the top whereas others will not and unfortunately drown. The fourth idea is about <b>the need to pivot for the new needs</b>, and this is only possible by a new type of collaboration; not just the collaboration between individuals, but collaboration between startups and other companies. Lastly, the fifth chapter is about <b>adapting to the new rules</b> and monetisation funding office space, how teams collaborate, how they develop products and more. Extremely exciting stuff. We hope you enjoy them all!</p><p>This documentary brings together<b> 7 interviews </b>we have conducted with founders and thought leaders in the London startup ecosystem.</p><div>
	
	<div>
			<p><img data-expand="600" src="https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://startupsoflondon.com/wp-content/uploads/2020/03/Advertise300-250.png" data-src="https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://startupsoflondon.com/wp-content/uploads/2020/03/Advertise300-250.png" data-srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://startupsoflondon.com/wp-content/uploads/2020/03/Advertise300-250.png 2x, https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://startupsoflondon.com/wp-content/uploads/2020/03/Advertise300-250.png 1x" width="300" height="250" alt="" srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://startupsoflondon.com/wp-content/uploads/2020/03/Advertise300-250.png 2x, https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://startupsoflondon.com/wp-content/uploads/2020/03/Advertise300-250.png 1x">
			
			</p>
		</div>
</div>



<ul><li><a href="https://startupsoflondon.com/startups-surviving-covid-19-6-philip-mundy-of-pando-health/">Philip Mundy, Pando Health</a></li><li><a href="https://startupsoflondon.com/startups-surviving-covid-19-2-michael-krayenhoff-of-the-inner-circle/">Michael Krayenhoff, Inner Circle</a></li><li><a href="https://startupsoflondon.com/startups-surviving-covid-19-1-tom-previte-of-launch22/">Tom Previte, Launch 22</a></li><li><a href="https://startupsoflondon.com/startups-surviving-covid-19-3-jacob-wedderburn-of-stasher/">Jacob Wedderburn, Stasher</a></li><li><a href="https://startupsoflondon.com/seedlegals-is-a-lawtech-solution-for-startup-funding-startups-of-london-2/">Anthony Rose, Seedlegals</a></li><li><a href="https://startupsoflondon.com/iprooving-your-online-identity-9/">Andrew Bud, iProov</a></li><li><a href="https://startupsoflondon.com/startups-surviving-covid-19-7-alexander-fahie-of-ethical-angel/">Alexander Fahie, Ethical Angel</a></li></ul></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="1e9ff62e" data-element_type="section">
						<div>
							<div>
					<div data-id="68b6ccd6" data-element_type="column">
			<div>
							<div>
						<div data-id="53a60830" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h3>Watch the interview of 5 Key Principles London Startups Use to Survive:</h3>		</p>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="63a471e9" data-element_type="section">
						<div>
							<div>
					<div data-id="1ea40dc" data-element_type="column">
			<div>
							<div>
						<div data-id="31d223c0" data-element_type="widget" data-settings="{&quot;aspect_ratio&quot;:&quot;169&quot;}" data-widget_type="video.default">
				<div>
					<p>
			<iframe allowfullscreen="" title="youtube Video Player" src="https://www.youtube.com/embed/Wac6wma3VMg?feature=oembed&amp;start&amp;end&amp;wmode=opaque&amp;loop=0&amp;controls=1&amp;mute=0&amp;rel=0&amp;modestbranding=0"></iframe>		</p>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="7a7db0fe" data-element_type="section">
						<div>
							<div>
					<div data-id="58d4a3c2" data-element_type="column">
			<div>
							<div>
						<div data-id="7292d15e" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>1. There is an inherent tension between <b>agility and fragility</b>, just like some systems become less resilient as they become more efficient, startups are very agile which works in their favour, but they are at the same time very fragile due to the nature of how chasing next rounds of funding work.</p><p>2. The argument that has been embraced by most startups brings us to this quote:&nbsp;<b>“half the burn rate to double the runway”</b>. While this makes sense for many, it creates second-order effects that are difficult to navigate. Many startups rely on other startups as their customers, not to count the consultants and other service providers that work around startups.</p><p>3. There are always<b> bubbles of opportunity </b>and they act like pockets of air in what is otherwise a deep ocean of problems. Finding those bubbles mean prioritising short term ROI (return on investment) rather than the long term. Survival in times like this might depend more on commercial cunning than focusing on innovation with a possible future return.</p><p>4. The idea that startups should be <b>“Pivoting for new needs” </b>has also gathered a consensus. Some startups pull this off better than others and it comes down to the team itself. We love paying lip service to people and culture, but it usually remains a second or third priority. However, times like these test startups and teams and only those who invested in culture thrive.</p><p>5. The next chapter is that of <b>a new normal</b>. We don’t exactly know what it will look like, but as startups can piece together what the future will look like, they will be able to afford more risks and invest more heavily into the future.</p><p>Make sure to visit our <a href="https://youtube.com/startupsoflondon">Youtube Channel</a> for all the interviews. </p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="2c7ecdcf" data-element_type="section">
						
		</section>
				<section data-id="5b752236" data-element_type="section">
						<div>
							<div>
					<div data-id="7cb85f94" data-element_type="column">
			<div>
							<div>
						<div data-id="6952290" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>One thing that is great about Startups of London is that you get to discover new businesses and meet people. To stay in the loop and understand the London tech scene better, consider subscribing to our social media channels linked below.</p>
<p><b>Each week,</b> we will be visiting a new startup office to meet with their team &amp; founders. Stay tuned!</p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="3a9739f8" data-element_type="section">
						
		</section>
				<section data-id="35651a78" data-element_type="section">
						
		</section>
				<section data-id="3814a0a9" data-element_type="section">
						
		</section>
						</div>
						</div>
					</div></div>]]>
            </description>
            <link>https://startupsoflondon.com/5-key-principles-london-startups-use-to-survive/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24440239</guid>
            <pubDate>Fri, 11 Sep 2020 08:10:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Recurrent neural networks: building a custom LSTM cell]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24440179">thread link</a>) | @black0017
<br/>
September 11, 2020 | https://theaisummer.com/understanding-lstm/ | <a href="https://web.archive.org/web/*/https://theaisummer.com/understanding-lstm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            
                            

<p>An infinite amount of times I have found myself in desperate situations because I had no idea what was happening under the hood. And, for a lot of people in the computer vision community, recurrent neural networks (RNNs) are like this. More or less, <strong>another black box in the pile</strong>.</p>

<p>However, in this tutorial, we will attempt to open the RNN magic black box and unravel its mysteries!</p>

<p>Even though I have come across hundreds of tutorials on LSTM’s out there, I felt there was something missing. Therefore, I honestly hope that <strong>this tutorial serves as a modern guide to RNNs</strong>. We try to deal with multiple details of practical nature. To this end, we <strong>will build upon their fundamental concepts.</strong></p>

<p>The vast application field of RNN’s includes <a href="https://theaisummer.com/Bitcon_prediction_LSTM/" target="_blank">sequence prediction</a>, activity recognition, video classification as well as a variety of natural language processing tasks. After a careful inspection of the equations, <strong>we will build our own LSTM cell to validate our understanding</strong>. Finally, we will make some associations with convolutional neural networks to maximize our comprehension. Accompanying code for this tutorial can be found <a href="https://drive.google.com/file/u/0/d/1Rb8OiF-AZ_Y3uFj1O2S0IyocFMhHoTCV/edit" rel="noopener" target="_blank">here</a>.</p>

<p>It is true that by the moment you start to read about RNN’s, especially with a computer vision background, concepts misleadings start to arise. Less literally:</p>

<p>“Backpropagation with stochastic gradient descent (SGD) does not magically make your network work. Batch normalization does not magically make it converge faster. <strong>Recurrent Neural Networks (RNNs) don’t magically let you “plug in” sequences</strong>. (…) If you insist on using the technology without understanding how it works you are likely to fail.” ~ <strong><a href="https://twitter.com/karpathy" rel="noopener" target="_blank">Andrey Karpathy</a></strong> (Director of AI at Tesla)</p>

<p>The abstraction of RNN’s implementations doesn’t allow users to understand how we deal with the time dimension in sequences! However, by understanding how it works you can write optimized code and practice extensibility, in a way that you weren’t confident enough to do before.</p>

<p>Finally, a more holistic approach in RNN’s can be found on <a href="https://click.linksynergy.com/deeplink?id=r24KwW5qbBo&amp;mid=40328&amp;murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Fnlp-sequence-models" rel="noopener" target="_blank">Sequence models from the Deep Learning specialization course</a> offered by Coursera.</p>

<h3 id="contents">Contents</h3>
<ul id="markdown-toc">
  <li><a href="#a-simple-rnn-cell" id="markdown-toc-a-simple-rnn-cell">A simple RNN cell</a></li>
  <li><a href="#what-is-back-propagation-through-time" id="markdown-toc-what-is-back-propagation-through-time">What is Back-propagation through time?</a></li>
  <li><a href="#lstm-long-short-term-memory-cells" id="markdown-toc-lstm-long-short-term-memory-cells">LSTM: Long-short term memory cells</a></li>
  <li><a href="#writing-a-custom-lstm-cell-in-pytorch" id="markdown-toc-writing-a-custom-lstm-cell-in-pytorch">Writing a custom LSTM cell in Pytorch</a></li>
  <li><a href="#connecting-lstm-cells-across-time-and-space" id="markdown-toc-connecting-lstm-cells-across-time-and-space">Connecting LSTM cells across time and space</a></li>
  <li><a href="#validation-learning-a-sine-wave-with-an-lstm" id="markdown-toc-validation-learning-a-sine-wave-with-an-lstm">Validation: Learning a sine wave with an LSTM</a></li>
  <li><a href="#bidirectional-lstm-and-its-pytorch-documentation" id="markdown-toc-bidirectional-lstm-and-its-pytorch-documentation">Bidirectional LSTM and it’s Pytorch documentation</a></li>
  <li><a href="#input-to-output-mappings-with-recurrent-models" id="markdown-toc-input-to-output-mappings-with-recurrent-models">Input to output mappings with recurrent models</a></li>
  <li><a href="#the-theoretical-limit-of-modeling-a-large-dimension-recurrency-vs-convolution" id="markdown-toc-the-theoretical-limit-of-modeling-a-large-dimension-recurrency-vs-convolution">The theoretical limit of modeling a large dimension: Recurrency VS Convolution</a></li>
  <li><a href="#discussion-and-conclusion" id="markdown-toc-discussion-and-conclusion">Discussion and conclusion</a></li>
</ul>

<h2 id="a-simple-rnn-cell">A simple RNN cell</h2>

<p>Recurrent cells are neural networks (usually small) for processing <strong>sequential data</strong>. As we already know, convolutional layers are specialized for processing grid-structured values (i.e. images). On the contrary, <strong>recurrent layers are designed for processing long sequences</strong>, without any extra sequence-based design choice [1].</p>

<p>One can achieve this by connecting the timesteps’ output to the input! This is called sequence <strong>unrolling.</strong> By processing the whole sequence, we have an algorithm that takes into account the previous states of the sequence. In this manner, we have the <strong>first notion of memory</strong> (a cell)! Let’s look at it:</p>

<p><img src="https://theaisummer.com/assets/img/posts/understanding-lstm/rnn-cell-time-unfold.png" alt="rnn-cell-time-unfold">
<em>Visualization is borrowed from <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network" rel="noopener" target="_blank">Wiki</a></em></p>

<p>The majority of common recurrent cells can also process sequences of variable length. This is really important for many applications such as videos, that contain a different number of images. One can view the RNN cell as a common <strong>neural network with</strong> <strong>shared weights for the multiple timesteps.</strong> With this modification, the weights of the cell now have access to the previous states of the sequence.</p>

<p>But <strong>how</strong> can we possibly train such sequential models?</p>

<h2 id="what-is-back-propagation-through-time">What is Back-propagation through time?</h2>

<p>Most practitioners with computer vision background have little idea of what recurrency means. And it is indeed difficult to understand. Because the frameworks assume that you already know how it works. However, if you want to find an efficient solution to your problem, you should carefully design your architecture based on the problem.</p>

<p><strong>The magic of RNN networks that nobody sees is the input unrolling</strong>. The latter means that given a sequence of length N, you process the input into timesteps.</p>

<blockquote>
  <p>We choose to model the time dimension with RNN’s, because we want to learn temporal and often long-term dependencies.</p>
</blockquote>

<p>Right now, it is true that convolutions cannot handle because they have a finite receptive field. Note that, in theory, you can apply a recurrent model in any dimension.</p>

<p>In terms of training an RNN model, the issue is that now we have a time-sequence. That’s why input unrolling is the only way we can make backpropagation work!</p>

<p>So, how can you learn a time-sequence? Ideally, we would like the memory (parameters) of the cells to have taken into account all the input sequences. Otherwise, we would not be able to learn the desired mapping. In essence, <strong>backpropagation requires a separate layer for each time step with the same weights for all layers</strong> (<strong>input unrolling)</strong>! The following image helps to understand this tricky idea.</p>

<p><img src="https://theaisummer.com/assets/img/posts/understanding-lstm/input-unrolling-and-backpropagation-through-time.png" alt="input-unrolling-and-backpropagation-through-time">
<em>Source: O’Reilly: hands-on-reinforcement-learning](Source: O’Reilly: hands-on-reinforcement-learning)</em></p>

<p>Backpropagation through time was created based on the pre-described observation. So, <strong>based on the chunked (unrolled) input, we can calculate a different loss per timestep</strong>. Then, we can backpropagate the error of multiple losses to the memory cells. In this direction, <strong>one can compute the gradients from multiple paths (timesteps) that then are added to calculate the final gradient</strong>. For this reason, we may use different optimizers or normalization methods in recurrent architectures.</p>

<p>In other words, we represent the RNN as a repeated (feedforward) network. More importantly, <strong>the time and space complexity to produce the output of the RNN is asymptotically linear to the input length (timesteps)</strong>. This practical bottleneck introduces the computational limit of training really large sequences.</p>

<p>In fact, a similar idea is implemented in practice when you have a small GPU and you want to train your model with a bigger batch size than your memory supports. You perform forward propagation with the first batch and calculate the loss. Afterwards, you repeat the same thing with the second batch and average the losses from different batches. In this way, gradients are <strong><a href="https://www.quora.com/What-does-it-mean-that-gradients-are-accumulated-in-Pytorch-and-what-is-the-use-for-it" rel="noopener" target="_blank">accumulated</a>.</strong> With this trick of the low budget machine learners, you basically perform a similar operation to backpropagation through time. Finally,<a href="https://www.youtube.com/watch?v=6jfw8MuKwpI" rel="noopener" target="_blank"> siamese networks</a> with shared weights also roughly exploit this concept.</p>

<p>Let’s now see the inside of an LSTM [5] cell.</p>

<h2 id="lstm-long-short-term-memory-cells">LSTM: Long-short term memory cells</h2>

<h3 id="why-lstm">Why LSTM?</h3>

<p>One of the most fundamental works in the field was by <a href="https://arxiv.org/abs/1503.04069" rel="noopener" target="_blank">Greff et al. 2016</a> [4]. Briefly, they showed that <strong>the proposed variations of RNN do not provide any significant improvement in a large scale study compared to LSTM</strong>. Therefore, LSTM is the dominant architecture in RNNs. That’s why we will focus on this RNN variation.</p>

<h3 id="how-lstm-works">How LSTM works?</h3>

<p>We can write forever about what an LSTM cell is, or how it is used in many applications. However, the language of mathematics makes this world beautiful and compact for us. Let’s see the math. Don’t be scared! <strong>We will slowly clarify every term, by inspecting every equation separately</strong>.</p>

<blockquote>
  <p>Before we begin, note that in all the equations, the weight matrices (W) are indexed, with the <strong>first index being the vector that they process</strong>, while the <strong>second index refers to the representation</strong> (i.e. input gate, forget gate).</p>
</blockquote>

<p>To avoid confusion and maximize understanding, we will use the common notation: <strong>matrices are depicted with capital bold letters while vectors with non-capital bold letters</strong>. For the element-wise multiplication, I used the dot with the outer circle symbol, referred to as the <a href="https://en.wikipedia.org/wiki/Hadamard_product_(matrices)" rel="noopener" target="_blank">Hadamard product</a> [9] in the bibliography.</p>

<h3 id="equations-of-the-lstm-cell">Equations of the LSTM cell</h3>

<p>For \(\textbf{x}_t \in R^{N}\) , where N is the feature length of each timestep, while \(\textbf{i}_t,\textbf{f}_t,\textbf{o}_t,\textbf{h}_t,\textbf{h}_{t-1},\textbf{c}_t,\textbf{c}_{t-1},\textbf{b}  \in R^{H}\) , where H is the hidden state dimension, the LSTM equations are the following:</p><p>

\[\textbf{i}_t = \sigma( \textbf{W}_{xi} \textbf{x}_t + \textbf{W}_{hi} \textbf{h}_{t-1} + \textbf{W}_{ci} \textbf{c}_{t-1} + \textbf{b}_i)  \quad\quad(1)\]

\[\textbf{f}_t = \sigma( \textbf{W}_{xf} \textbf{x}_t + \textbf{W}_{hf} \textbf{h}_{t-1} + \textbf{W}_{cf} \textbf{c}_{t-1} + \textbf{b}_f) \quad\quad(2)\]

\[\textbf{c}_t = \textbf{f}_t \odot \textbf{c}_{t-1} + \textbf{i}_t \odot tanh( \textbf{W}_{xc} x_t + \textbf{W}_{hc} \textbf{h}_{t-1} + \textbf{b}_c ) \quad\quad(3)\]

\[\textbf{o}_t = \sigma( \textbf{W}_{xo} \textbf{x}_t + \textbf{W}_{h0} \textbf{h}_{t-1} + \textbf{W}_{co} \textbf{c}_{t} + \textbf{b}_o)  \quad\quad(4)\]

\[\textbf{h}_t = \textbf{o}_t \odot tanh(\textbf{c}_t) \quad\quad(5)\]

</p><p>The LSTM cell equations were written based on <a href="https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.LSTM" rel="noopener" target="_blank">Pytorch documentation</a> because you will probably use the existing layer in your project.</p>

<h3 id="equation-1-the-input-gate">Equation 1: the input gate</h3><p>

\[\textbf{i}_t = \sigma( \textbf{W}_{xi} \textbf{x}_t + \textbf{W}_{hi} \textbf{h}_{t-1} + \textbf{W}_{ci} \textbf{c}_{t-1} + \textbf{b}_i)\]

</p><p>The depicted <strong>weight matrices represent the memory of the cell</strong>. You see the input \(\textbf{x}_t\) is in the current input timestep, <strong>while h and c are indexed with the previous timestep</strong>. Every matrix <strong>W</strong> is a linear layer (or simply a matrix multiplication). This equation enables us to the following:</p>

<p>a) take multiple linear combinations of <strong>x</strong>,<strong>h</strong>,<strong>c</strong>, and</p>

<p>b) match the dimensionality of input <strong>x</strong> to the one of <strong>h</strong> and <strong>c</strong>.</p>

<p>The dimensionalities of <strong>h</strong> and <strong>c</strong> are basically the <strong>hidden states</strong> parameter in a deep learning framework such as PyTorch (<a href="https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.LSTM" rel="noopener" target="_blank">LSTM Pytorch layer documentation</a>). For the old-school readers, <strong>hidden states</strong> were referenced in older literature as neurons, but now this term is deprecated.</p>

<p>Moving on, the bias term is part of the linear layer and is simply a trainable …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://theaisummer.com/understanding-lstm/">https://theaisummer.com/understanding-lstm/</a></em></p>]]>
            </description>
            <link>https://theaisummer.com/understanding-lstm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24440179</guid>
            <pubDate>Fri, 11 Sep 2020 07:59:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Write a Git Commit Message]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24440011">thread link</a>) | @punnerud
<br/>
September 11, 2020 | https://chris.beams.io/posts/git-commit/ | <a href="https://web.archive.org/web/*/https://chris.beams.io/posts/git-commit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
<p><a href="https://xkcd.com/1296/">
<img src="https://imgs.xkcd.com/comics/git_commit_2x.png">
</a></p>

<hr>

<p><a href="#intro">Introduction</a> | <a href="#seven-rules">The Seven Rules</a> | <a href="#tips">Tips</a></p>
<hr>

<h2 id="intro">Introduction: Why good commit messages matter</h2>

<p>If you browse the log of any random Git repository, you will probably find its commit messages are more or less a mess. For example, take a look at <a href="https://github.com/spring-projects/spring-framework/commits/e5f4b49?author=cbeams">these gems</a> from my early days committing to Spring:</p>

<div><pre><code>$ git log --oneline -5 --author cbeams --before "Fri Mar 26 2009"

e5f4b49 Re-adding ConfigurationPostProcessorTests after its brief removal in r814. @Ignore-ing the testCglibClassesAreLoadedJustInTimeForEnhancement() method as it turns out this was one of the culprits in the recent build breakage. The classloader hacking causes subtle downstream effects, breaking unrelated tests. The test method is still useful, but should only be run on a manual basis to ensure CGLIB is not prematurely classloaded, and should not be run as part of the automated build.
2db0f12 fixed two build-breaking issues: + reverted ClassMetadataReadingVisitor to revision 794 + eliminated ConfigurationPostProcessorTests until further investigation determines why it causes downstream tests to fail (such as the seemingly unrelated ClassPathXmlApplicationContextTests)
147709f Tweaks to package-info.java files
22b25e0 Consolidated Util and MutableAnnotationUtils classes into existing AsmUtils
7f96f57 polishing
</code></pre>
</div>

<p>Yikes. Compare that with these <a href="https://github.com/spring-projects/spring-framework/commits/5ba3db?author=philwebb">more recent</a> commits from the same repository:</p>

<div><pre><code>$ git log --oneline -5 --author pwebb --before "Sat Aug 30 2014"

5ba3db6 Fix failing CompositePropertySourceTests
84564a0 Rework @PropertySource early parsing logic
e142fd1 Add tests for ImportSelector meta-data
887815f Update docbook dependency and generate epub
ac8326d Polish mockito usage
</code></pre>
</div>

<p>Which would you rather read?</p>

<p>The former varies in length and form; the latter is concise and consistent.<br>
The former is what happens by default; the latter never happens by accident.</p>

<p>While many repositories’ logs look like the former, there are exceptions. The <a href="https://github.com/torvalds/linux/commits/master">Linux kernel</a> and <a href="https://github.com/git/git/commits/master">Git itself</a> are great examples. Look at <a href="https://github.com/spring-projects/spring-boot/commits/master">Spring Boot</a>, or any repository managed by <a href="https://github.com/tpope/vim-pathogen/commits/master">Tim Pope</a>.</p>

<p>The contributors to these repositories know that a well-crafted Git commit message is the best way to communicate <em>context</em> about a change to fellow developers (and indeed to their future selves). A diff will tell you <em>what</em> changed, but only the commit message can properly tell you <em>why</em>. Peter Hutterer <a href="http://who-t.blogspot.co.at/2009/12/on-commit-messages.html">makes this point</a> well:</p>

<blockquote>
  <p>Re-establishing the context of a piece of code is wasteful. We can’t avoid it completely, so our efforts should go to <a href="http://www.osnews.com/story/19266/WTFs_m">reducing it</a> [as much] as possible. Commit messages can do exactly that and as a result, <em>a commit message shows whether a developer is a good collaborator</em>.</p>
</blockquote>

<p>If you haven’t given much thought to what makes a great Git commit message, it may be the case that you haven’t spent much time using <code>git log</code> and related tools. There is a vicious cycle here: because the commit history is unstructured and inconsistent, one doesn’t spend much time using or taking care of it. And because it doesn’t get used or taken care of, it remains unstructured and inconsistent.</p>

<p>But a well-cared for log is a beautiful and useful thing. <code>git blame</code>, <code>revert</code>, <code>rebase</code>, <code>log</code>, <code>shortlog</code> and other subcommands come to life. Reviewing others’ commits and pull requests becomes something worth doing, and suddenly can be done independently. Understanding why something happened months or years ago becomes not only possible but efficient.</p>

<p>A project’s long-term success rests (among other things) on its maintainability, and a maintainer has few tools more powerful than his project’s log. It’s worth taking the time to learn how to care for one properly. What may be a hassle at first soon becomes habit, and eventually a source of pride and productivity for all involved.</p>

<p>In this post, I am addressing just the most basic element of keeping a healthy commit history: how to write an individual commit message. There are other important practices like commit squashing that I am not addressing here. Perhaps I’ll do that in a subsequent post.</p>

<p>Most programming languages have well-established conventions as to what constitutes idiomatic style, i.e. naming, formatting and so on. There are variations on these conventions, of course, but most developers agree that picking one and sticking to it is far better than the chaos that ensues when everybody does their own thing.</p>

<p>A team’s approach to its commit log should be no different. In order to create a useful revision history, teams should first agree on a commit message convention that defines at least the following three things:</p>

<p><strong>Style.</strong> Markup syntax, wrap margins, grammar, capitalization, punctuation. Spell these things out, remove the guesswork, and make it all as simple as possible. The end result will be a remarkably consistent log that’s not only a pleasure to read but that actually <em>does get read</em> on a regular basis.</p>

<p><strong>Content.</strong> What kind of information should the body of the commit message (if any) contain? What should it <em>not</em> contain?</p>

<p><strong>Metadata.</strong> How should issue tracking IDs, pull request numbers, etc. be referenced?</p>

<p>Fortunately, there are well-established conventions as to what makes an idiomatic Git commit message. Indeed, many of them are assumed in the way certain Git commands function. There’s nothing you need to re-invent. Just follow the <a href="#seven-rules">seven rules</a> below and you’re on your way to committing like a pro.</p>

<h2 id="seven-rules">The seven rules of a great Git commit message</h2>

<blockquote>
  <p><em>Keep in mind: <a href="http://tbaggery.com/2008/04/19/a-note-about-git-commit-messages.html">This</a> <a href="https://www.git-scm.com/book/en/v2/Distributed-Git-Contributing-to-a-Project#_commit_guidelines">has</a> <a href="https://github.com/torvalds/subsurface-for-dirk/blob/master/README.md#contributing">all</a> <a href="http://who-t.blogspot.co.at/2009/12/on-commit-messages.html">been</a> <a href="https://github.com/erlang/otp/wiki/writing-good-commit-messages">said</a> <a href="https://github.com/spring-projects/spring-framework/blob/30bce7/CONTRIBUTING.md#format-commit-messages">before</a>.</em></p>
</blockquote>

<ol>
  <li><a href="#separate">Separate subject from body with a blank line</a></li>
  <li><a href="#limit-50">Limit the subject line to 50 characters</a></li>
  <li><a href="#capitalize">Capitalize the subject line</a></li>
  <li><a href="#end">Do not end the subject line with a period</a></li>
  <li><a href="#imperative">Use the imperative mood in the subject line</a></li>
  <li><a href="#wrap-72">Wrap the body at 72 characters</a></li>
  <li><a href="#why-not-how">Use the body to explain <em>what</em> and <em>why</em> vs. <em>how</em></a></li>
</ol>

<p>For example:</p>

<div><pre><code>Summarize changes in around 50 characters or less

More detailed explanatory text, if necessary. Wrap it to about 72
characters or so. In some contexts, the first line is treated as the
subject of the commit and the rest of the text as the body. The
blank line separating the summary from the body is critical (unless
you omit the body entirely); various tools like `log`, `shortlog`
and `rebase` can get confused if you run the two together.

Explain the problem that this commit is solving. Focus on why you
are making this change as opposed to how (the code explains that).
Are there side effects or other unintuitive consequences of this
change? Here's the place to explain them.

Further paragraphs come after blank lines.

 - Bullet points are okay, too

 - Typically a hyphen or asterisk is used for the bullet, preceded
   by a single space, with blank lines in between, but conventions
   vary here

If you use an issue tracker, put references to them at the bottom,
like this:

Resolves: #123
See also: #456, #789
</code></pre>
</div>

<h3 id="separate">1. Separate subject from body with a blank line</h3>

<p>From the <code>git commit</code> <a href="https://www.kernel.org/pub/software/scm/git/docs/git-commit.html#_discussion">manpage</a>:</p>

<blockquote>
  <p>Though not required, it’s a good idea to begin the commit message with a single short (less than 50 character) line summarizing the change, followed by a blank line and then a more thorough description. The text up to the first blank line in a commit message is treated as the commit title, and that title is used throughout Git. For example, Git-format-patch(1) turns a commit into email, and it uses the title on the Subject line and the rest of the commit in the body.</p>
</blockquote>

<p>Firstly, not every commit requires both a subject and a body. Sometimes a single line is fine, especially when the change is so simple that no further context is necessary. For example:</p>

<div><pre><code>Fix typo in introduction to user guide
</code></pre>
</div>

<p>Nothing more need be said; if the reader wonders what the typo was, she can simply take a look at the change itself, i.e. use <code>git show</code> or <code>git diff</code> or <code>git log -p</code>.</p>

<p>If you’re committing something like this at the command line, it’s easy to use the <code>-m</code> option to <code>git commit</code>:</p>

<div><pre><code>$ git commit -m"Fix typo in introduction to user guide"
</code></pre>
</div>

<p>However, when a commit merits a bit of explanation and context, you need to write a body. For example:</p>

<div><pre><code>Derezz the master control program

MCP turned out to be evil and had become intent on world domination.
This commit throws Tron's disc into MCP (causing its deresolution)
and turns it back into a chess game.
</code></pre>
</div>

<p>Commit messages with bodies are not so easy to write with the <code>-m</code> option. You’re better off writing the message in a proper text editor. If you do not already have an editor set up for use with Git at the command line, read <a href="https://git-scm.com/book/en/v2/Customizing-Git-Git-Configuration">this section of Pro Git</a>.</p>

<p>In any case, the separation of subject from body pays off when browsing the log. Here’s the full log entry:</p>

<div><pre><code>$ git log
commit 42e769bdf4894310333942ffc5a15151222a87be
Author: Kevin Flynn &lt;kevin@flynnsarcade.com&gt;
Date:   Fri Jan 01 00:00:00 1982 -0200

 Derezz the master control program

 MCP turned out to be evil and had become intent on world domination.
 This commit throws Tron's disc into MCP (causing its deresolution)
 and turns it back into a chess game.
</code></pre>
</div>

<p>And now <code>git log --oneline</code>, which prints out just the subject line:</p>

<div><pre><code>$ git log --oneline
42e769 Derezz the master control program
</code></pre>
</div>

<p>Or, <code>git shortlog</code>, which groups commits by user, again showing just the subject line for concision:</p>

<div><pre><code>$ git shortlog
Kevin Flynn (1):
      Derezz the master control program

Alan Bradley (1):
      Introduce security program "Tron"

Ed Dillinger (3):
      Rename chess program to "MCP"
      Modify chess program
      Upgrade chess program

Walter Gibbs (1):
      Introduce protoype chess program
</code></pre>
</div>

<p>There are a number of other contexts in Git where the distinction between subject line and body kicks in—but none of them work properly without the blank line in between.</p>

<h3 id="limit-50">2. Limit the subject line to 50 characters</h3>

<p>50 characters is not a hard limit, just a rule of thumb. Keeping subject lines at this length ensures that they are readable, and forces the author to think for a moment about the most concise way to explain what’s going on.</p>

<blockquote>
  <p><em>Tip: If you’re having a hard time summarizing, you might be committing too many changes at once. Strive for <a href="https://www.freshconsulting.com/atomic-commits/">atomic …</a></em></p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chris.beams.io/posts/git-commit/">https://chris.beams.io/posts/git-commit/</a></em></p>]]>
            </description>
            <link>https://chris.beams.io/posts/git-commit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24440011</guid>
            <pubDate>Fri, 11 Sep 2020 07:24:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[- Path Trimming in Nightly Rust]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24439785">thread link</a>) | @lukastyrychtr
<br/>
September 10, 2020 | https://blog.aloni.org/posts/path-trimming-in-rust-nightly/ | <a href="https://web.archive.org/web/*/https://blog.aloni.org/posts/path-trimming-in-rust-nightly/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <div id="mobile-panel">
                    



<article>
    
    

    <div>
      <p>As of yesterday, the <a href="https://github.com/rust-lang/rust/pull/73996">Rust PR</a>
(which I had worked on) is merged into Rust nightly, and it has wide
implications on compiler errors.</p>
<p>In this post I describe the change and what to expect from it.</p>
<h2 id="the-problem-with-full-paths-in-errors">The problem with full paths in errors</h2>
<p>A simple program such as the following, would result in a type error.</p>
<div><div><pre><span>fn </span><span>main</span><span>() {
    </span><span>let</span><span> a </span><span>= </span><span>vec![vec![</span><span>String</span><span>::from(</span><span>"a"</span><span>)]];
    </span><span>let</span><span> b </span><span>= </span><span>vec![</span><span>String</span><span>::from(</span><span>"b"</span><span>)];
    a </span><span>==</span><span> b;
}
</span></pre></div></div>
<p>The type error can be described as such: cannot compare between values of the
types <code>Vec&lt;Vec&lt;String&gt;&gt;</code> and <code>Vec&lt;String&gt;</code>. Before the changes in the PR, this
was <em>almost</em> the first line of the error message, and the rest of the error
message gives us more details about traits:</p>
<div><table><tbody><tr><td colspan="2">old output</td></tr><tr><td><pre><span>error[E0277]: can't compare `std::vec::Vec&lt;std::string::String&gt;` with `std::string::String`
 --&gt; example.rs:5:7
  |
5 |     a == b;
  |       ^^ no implementation for `std::vec::Vec&lt;std::string::String&gt; == std::string::String`
  |
  = help: the trait `std::cmp::PartialEq&lt;std::string::String&gt;` is not implemented for `std::vec::Vec&lt;std::string::String&gt;`
  = note: required because of the requirements on the impl of `std::cmp::PartialEq&lt;std::vec::Vec&lt;std::string::String&gt;&gt;` for `std::vec::Vec&lt;std::vec::Vec&lt;std::string::String&gt;&gt;`
</span></pre></td></tr></tbody></table></div>
<p>It is surely noticeable that in the above error the greatest contribution to
cognitive burden is the full qualified paths (e.g. <code>std::vec::Vec</code>) of types
and traits. It has made a significant readability difference for many people.</p>
<h2 id="enter-path-trimming">Enter path trimming</h2>
<p>In the large majority of cases there would be only one <code>Vec</code> symbol and one
<code>String</code> symbol that is importable through the entire program being linked, for
all crates that are available.  Surely that there are crates existing that
define items named <code>Vec</code>, but they are rare, and the situation that the user
defines <code>Vec</code> is rare.</p>
<p>Considering the observation that the overlap between module namespaces is
rather minimal, we can do a uniqueness check that verifies that uniqueness
holds, i.e, that <code>Vec</code> and <code>String</code> are unique as items defined in the
compilation. Even if that's not the case, the compilation would still succeed
without any new warning. But for the unique symbols, we don't have to print the
entire path in warnings and errors, and we can thus trim it to the last
component - the symbol itself.</p>
<p>With trimming according to uniqueness, the following error is printed instead:</p>
<div><table><tbody><tr><td colspan="2">new output</td></tr><tr><td><pre><span>error[E0277]: can't compare `Vec&lt;String&gt;` with `String`
 --&gt; example.rs:5:7
  |
5 |     a == b;
  |       ^^ no implementation for `Vec&lt;String&gt; == String`
  |
  = help: the trait `PartialEq&lt;String&gt;` is not implemented for `Vec&lt;String&gt;`
  = note: required because of the requirements on the impl of `PartialEq&lt;Vec&lt;String&gt;&gt;` for `Vec&lt;Vec&lt;String&gt;&gt;`
</span></pre></td></tr></tbody></table></div>
<p>This behavior can be controlled using a new debug option <code>-Z trim-diagnostic-paths=false</code>, and it is enabled by default only for rustc
itself.</p>
<p>As for the toll it takes on the compiler, it is similar to the algorithm that
computes 'use suggestions' on errors caused by undefined identifiers. This
means iterating all importable symbols of the entire program or library being
linked. Since this may be heavy, we made sure it is only done in case there
are warnings or errors by the compiler. If that assertion is invalidated,
it's a bug, and you'd see a panic related to trimmed paths.</p>
<h3 id="trimming-considerations">Trimming considerations</h3>
<p>Trimming is done only relative to what the currently built crate does, so -</p>
<ul>
<li>
<p>All the local definitions in the built crate are considered, regardless of
whether they are exported from it or not. This is different than how external
crates are treated, where only the externally visible and importable
definitions are taken into account.</p>
</li>
<li>
<p>Trimming is considered between all crates including the one being built, so
if you define a <code>Vec</code> type anywhere in your crate, then <code>Vec</code> name will no
longer be considered unique because another <code>Vec</code> can be imported from
<code>std::vec</code> too, and thus the full paths of both types will be printed as
just as before.</p>
</li>
<li>
<p>Because several glob imports (i.e. <code>use foo::*;</code>) can happen in a single
place, it wouldn't be clear which items they bring if we trim the paths that
are related to these items. Thus, glob imports cancel out the uniqueness of the
symbols that they import.</p>
</li>
</ul>
<h2 id="what-s-next">What's next</h2>
<p>This change in behavior will probably go under some refinements and more
testing until it reaches stable Rust. There are expected follow ups, for
instance, to allow some ambiguity, as not all items are treated equal. For
example between the <code>Result</code> type alias in <code>std::io</code>, and the <code>Result</code> type
itself from <code>std::result</code>.</p>
<h2 id="thanks">Thanks</h2>
<p>The change has been hard to maintain as a PR, as it affected more than 1000
unit tests. It has gone through several revisions until the implementation was
good.</p>
<p>Not being a frequent Rust compiler contributor, most of the code involved was
new to me, and it has been greatly instructive to rely on long-term members of the
Rust compiler team. There have been folks who were crucial in reviewing and so
I'd like to thank them — <a href="https://github.com/petrochenkov">Vadim Petrochenkov</a>,
<a href="https://github.com/eddyb">Eduard Burtescu</a>, <a href="https://github.com/estebank"> Esteban
Kuber</a>, and also other contributors — <a href="https://github.com/Aaron1011">Aaron
Hill</a>, and <a href="https://github.com/lzutao">luzato</a>
for their help.</p>

    </div>

    
    

    

    
    
</article>




            </div></div></div>]]>
            </description>
            <link>https://blog.aloni.org/posts/path-trimming-in-rust-nightly/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24439785</guid>
            <pubDate>Fri, 11 Sep 2020 06:38:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I built an app to fix my depression]]>
            </title>
            <description>
<![CDATA[
Score 261 | Comments 174 (<a href="https://news.ycombinator.com/item?id=24439612">thread link</a>) | @zoozla
<br/>
September 10, 2020 | http://blog.elifiner.com/how-i-built-an-app-to-fix-my-depression/ | <a href="https://web.archive.org/web/*/http://blog.elifiner.com/how-i-built-an-app-to-fix-my-depression/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-174">
	<!-- .entry-header -->

	
	
	<div>
		
<p>I was first diagnosed with depression when I was working on a startup in 2007. I went to the doctor, told him I was feeling mild flu symptoms for a couple of months, he asked me a few questions, determined that I had depression, gave my some SSRIs, and sent me home.</p>



<p>It worked for a while, but then 2008 happened, our startup collapsed, the stakes got higher and the depression came back. The doc recommended I up the dosage, but I could see this would eventually lead me to a straitjacket.</p>



<p>Over the years I’ve tried different meds, various forms of therapy, studied and actively practiced life coaching, got married, had kids, moved to another country and changed everything I could think of about my life. Unfortunately the dark bouts of depression remained.</p>



<p>About four years ago I stumbled on a book called Highly Sensitive Person that absolutely blew my mind. I realized I had very intense emotions that I was culturally programmed to repress, which caused my psyche to overload and go into full apathy mode also known as clinical depression.</p>



<p>I’ve been on a path to figure out how to process my emotions without repressing them and combined my personal experience with several non-mainstream techniques to build Wuju. It’s an online app that can help you tap into your hidden emotions and release them so they no longer influence your behaviour or cause depressive symptoms.</p>



<p>I’ve used it in the last 18 months to deal with parenting two kids, surviving infidelity, losing my job, starting a business, and covid anxiety. My longest bouts of depression now last a day at most and even that doesn’t happen too often.</p>



<p>You can try it too: <a href="https://beta.wuju.app/">beta.wuju.app</a></p>




	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>http://blog.elifiner.com/how-i-built-an-app-to-fix-my-depression/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24439612</guid>
            <pubDate>Fri, 11 Sep 2020 06:02:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Musings on the Impossibility of Testing]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 48 (<a href="https://news.ycombinator.com/item?id=24439511">thread link</a>) | @george3d6
<br/>
September 10, 2020 | https://blog.cerebralab.com/Musings_on_the_impossibility_of_testing | <a href="https://web.archive.org/web/*/https://blog.cerebralab.com/Musings_on_the_impossibility_of_testing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
        <p>Published on: 2020-09-11</p>
        
<p>I'm always a bit flabbergasted when I see how people test their code (especially with unit tests). Often I can't figure out a cohesive set of rules based on which the tests are written.</p>
<p>Testing seems to work from a pragmatic perspective, we have evidence it works, but different people define "testing" in different ways. I'm awfully afraid that what some people refer to as "testing" is completely unrelated to that unrigorous but pragmatic practice that saves us from production bugs.</p>
<h2>I - A contrived example</h2>
<p>To showcase my arbitrary formalism as it relates to testing, I think it's worthwhile to look at some cases:</p>
<h4>1)</h4>
<pre><code># Testing a multiplication function
func multiply(int a, int b) -&gt; int

func test_1():
  assert 2*5 == multiply(2,5)
  assert 10*12 == multiply(12,10)

func test_2():
  assert 10 == multiply(2,5)
  assert 120 == multiply(12,10)

func test_3():
  assert type(multiply(2,5)) == int
  assert type(multiply) == func(int,int)-&gt;int
</code></pre>
<h4>2)</h4>
<pre><code># Testing an image classification algorithm
func classify(arr[int] image) -&gt; str

func test_1():
  assert img_classification_nn(to_arr('cat.jpg')) == classify(to_arr('cat.jpg'))
  assert img_classification_nn(to_arr('dog.jpg')) == classify(to_arr('dog.jpg'))

func test_2():
  assert 'cat' == classify(to_arr('cat.jpg'))
  assert 'dog' == classify(to_arr('dog.jpg'))

func test_3():
  possible_targets = ['cat','cheta','tiger','dog','wolf','coyote','other']
  assert classify(to_arr('rand_img_1.jpg')) in possible_targets
  assert classify(to_arr('rand_img_2.jpg')) in possible_targets
</code></pre>
<p>For both examples, <code>test_1</code> obviously makes no sense. You're testing the functionality of a function using another function that does the same thing. If the function used to assert correct functionality is better (i.e. if <code>*</code> is better than <code>multiply</code> or <code>img_classification_nn</code> is better than <code>classify</code>), than one should simply use that function instead. If they are equally flawed, then the tests are redundant.</p>
<p>These kinds of tests are a theatrical performance to build up an illusion of quality. Usually spotted in enterprise-grade codebases and teams that harp on about TDD a lot, I'll classify these as <strong>redundant checks</strong>.</p>
<hr>
<p>Next, <code>test_2</code> is more interesting, it's comparing the result of a function with what a human would expect the result of that function to be. Here I would argue the test makes sense for the <code>classify</code> function but not for the <code>multiply</code> function.</p>
<p>Computers are good at multiplying, humans are horrible at it. So testing this function against an arbitrary number of human answers is much more likely to reveal flaws with the human's answer rather than the computer's. Since the function is very simple, time would probably better spent reviewing the actual code to make sure it's error-free.</p>
<p>On the other hand, computers aren't very good at classifying images (though they are getting there), but humans are spot on. So using a human's answers to validate a vision algorithm makes perfect sense.</p>
<p>We'll call these types of tests <strong>human validations</strong>.</p>
<hr>
<p>Finally, we get to <code>test_3</code>, which superficially seems less flawed than the other two. It's more of a sanity check than a test, we aren't checking the actual return value of the function in a given case, we are instead checking a higher-level behavior.</p>
<p>These tests are much more common in the codebases of dynamic languages, and for good reason. In our first example, we are just validating the signature of a function, something a compiler will implicitly do for us in any statically typed language.</p>
<p>In the second example, we are instead working around a limitation of our type system. We are checking if the result of our function (a string) is contained within 7 different values (the possible things our function should classify images as), which we could test implicitly by using a language that supports <code>enum</code> types and writing <code>classify</code> such that it returns an enum of those 7 classes.</p>
<p>Basically, these kinds of tests can be useful, but they are the kind of things a compiler can handle automatically when they are present they usually indicate a mistake in the language the programmer is using for the project. We'll call these <strong>compiler rules</strong>.</p>
<hr>
<p>Obviously, this system is fairly arbitrary, it's just a conclusion I reached after looking at various codebases and talking with various people about their tests, but I find that it works quite well.</p>
<p>To re-iterate, we have:</p>
<ul>
<li>redundant checks</li>
<li>human validation</li>
<li>compiler rules</li>
</ul>
<h2>II - Compiler rules</h2>
<p>Compiler rules are great, but it's a bad sign when they leak into your testing.</p>
<p>Some amount of compiler rules leaking into testing can't be helped. Until the advent of Rust and/or well-performing libraries for safe multi-threading, testing thread safety should have been a requirement in many codebases. Similarly, before modern type system and allocation techniques, one ought to assume various now-pointless memory checks might have fared well within a codebase (and, I assume, still do on some embedded devices).</p>
<p>Even more, switching to more modern languages and compilers is often a task much harder than just writing some tests, but I think these tests should be viewed as a cautionary sign against the language currently used. If they only cover a small but critical percentage of the codebase, everything is fine, if they cover most of it, it's an indicator of using the wrong compile-time tooling.</p>
<p>The one difficult thing about these tests might be spotting them, an inexperienced team might be writing loads of these tests without realizing there are better alternatives to the compile-time toolchain they are using which would replace the need for them.</p>
<h2>III - Redundant checks</h2>
<p>Redundant checks are often pointless busywork, but they can serve a valuable role in some cases.</p>
<p>The two main scenarios that come to mind are as follows:</p>
<ol>
<li><p>Given two versions of the same function, one well-proven and one "experimental", where the "experimental" function has some benefits in terms of performance or generalizability, it seems reasonable to test the "experimental" function using the well-proven approach. Still, the overhead here is so severe I find it difficult to think of a real-world example where this applies.</p>
</li>
<li><p>Given two versions of the same function, one in a "new" codebase and one an "old" codebase, it makes sense to test the "new" version with the "old" version. In this sense, going back to compiler rules, redundant checks can be useful in the process of refactoring, especially for major changes like changing the language or the core framework upon which the project is built. However, this seems useful only as a "temporary" measure rather than a permanent fixture of a project.</p>
</li>
</ol>
<p>That being said, I'd wager that most tests falling in this category, as mentioned before, are there only as "filler" and indicative of a much bigger underlying problem of a team that engages in busywork. If I ever accepted such a test, I would require plenty of complimentary comments to explain why they exist and when they can be removed.</p>
<h2>IV - Human validation</h2>
<p>Human validation is the "sanest" type of testing one can perform, it can be replaced by good practices or good languages. The problem with human validation comes from the fact that in some cases human intelligence can't solve the problems the software is designed to solve or can't cover all the edge cases the software will encounter.</p>
<p>Take for example banking software. It's fairly easy to imagine what should happen with a piece of banking software that provided dozens of customers, hundreds of transactions, and a few regulatory restrictions. All the logic there can be written down into tests that validate our software. However, the software itself must scale to millions of customers, trillions of transactions, and thousands of regulatory restrictions. Something a human mind can't comprehend coherently in order to write the tests.</p>
<p>Still, banking software is an easy example, because the various components might be test-able and their limited logic might be fully comprehensible by a human, even accounting for all the edge cases. This is because the inputs to the software are very well defined, there are only so many things one can do with a banking API, a finite space which a human mind can explore exhaustively when properly broken down.</p>
<p>One real problem arises when we have software with a very broad and/or poorly define input and/or outputs spaces. A few examples of these would be:</p>
<ul>
<li>Scrappers that distill information from a broad range of websites (e.g. the ones used by a search engine)</li>
<li>Machine learning algorithms meant to work on a broad range of data (e.g. a decision tree or a gradient boosting classifier implementation in a library like sklearn)</li>
<li>Any software that has to work well with user-provided code extensions (e.g. think a video game-like Skyrim that has to support mods)</li>
<li>Simulation software (e.g. physics simulations)</li>
<li>Creative software (e.g. multimedia editing &amp; creation, game engines)</li>
<li>Compilers</li>
</ul>
<p>One can separate these into components with input-output spaces that can be easily comprehended by the human mind, but some components that suffer from the above problems are bound to remain. It also introduces the problem of writing code separation in such a way that components can be easily tested, rather than with refactoring, extension, speed, or readability as the main concern.</p>
<h2>V - Human validation and cost</h2>
<p>Assuming that we've designed our software such that it has many human-comprehensible components, the issue of cost remains. Human-comprehensible is a vague term, there are many things which, given enough time, a person could write exhaustive tests for, but in practice, this often takes more time than we can allocate. Furthermore, in certain situations, even in the limited input&amp;output space scenario, it might still be easier to write the "generative" logic (the one that maps inputs to outputs) than to come up with mappings ourselves.</p>
<p>In certain cases, exhaustive validation can be done, but it can be …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.cerebralab.com/Musings_on_the_impossibility_of_testing">https://blog.cerebralab.com/Musings_on_the_impossibility_of_testing</a></em></p>]]>
            </description>
            <link>https://blog.cerebralab.com/Musings_on_the_impossibility_of_testing</link>
            <guid isPermaLink="false">hacker-news-small-sites-24439511</guid>
            <pubDate>Fri, 11 Sep 2020 05:41:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The IRS is offering over $500k in bounty to crack Monero]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24439377">thread link</a>) | @seigando
<br/>
September 10, 2020 | https://xitheon.com/news/the-irs-is-offering-over-500000-in-bounty-to-anyone-who-is-able-to-crack-moneros-privacy/ | <a href="https://web.archive.org/web/*/https://xitheon.com/news/the-irs-is-offering-over-500000-in-bounty-to-anyone-who-is-able-to-crack-moneros-privacy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><span>September 11, 2020 in </span><span><a href="https://xitheon.com/category/news/" rel="category tag">News</a></span> </p></div><div>

<p>In an interesting and perhaps dangerous development, the Internal Revenue Service (IRS) has announced that it is seeking candidates who may be able to crack Monero’s privacy features in exchange for a bounty of a total of $625,000 USD, in an effort to utilize the method to unmask individuals behind Monero transactions.</p>
<p>Titled “Pilot IRS Cryptocurrency Tracing”, Notice ID <a href="https://beta.sam.gov/opp/3b7875d5236b47f6a77f64c19251af60/view?index=opp">2032H8-20-R-00500</a>, which was published on Sep 04, 2020 at 01:55 pm, acknowledges that agencies currently have limited tools and resources effective towards tracing privacy coin based transactions, specifically citing Monero &amp; Layer 2 network protocol –</p>
<blockquote><p>Currently, there are limited investigative resources for tracing transactions involving privacy cryptocurrency coins such as Monero, Layer 2 network protocol transactions such as Lightning Labs, or other off-chain transactions that provide privacy to illicit actors.</p></blockquote>
<p>Monero is mentioned a total of 11 times in the associated <a href="https://beta.sam.gov/api/prod/opps/v3/opportunities/resources/files/bb0247a3accc46beb2901af74b78438d/download?api_key=null&amp;token=">Request for Proposal (RFP)</a>, with notable mentions in it’s goals of this cracking challenge,</p>
<h3><img loading="lazy" src="https://xitheon.com/wp-content/uploads/2020/09/rfp.png" alt="" width="976" height="564" srcset="https://xitheon.com/wp-content/uploads/2020/09/rfp.png 976w, https://xitheon.com/wp-content/uploads/2020/09/rfp-300x173.png 300w, https://xitheon.com/wp-content/uploads/2020/09/rfp-768x444.png 768w" sizes="(max-width: 976px) 100vw, 976px"></h3>

<p>The IRS will pay $500,000 for the completion of a working concept for a utility that is able to crack targeted transactions and wallets, as well as a second payment of $125,000 once a pilot program is successfully completed and approved by the agency. Those interested in applying have until September 16th, 2020 to do so.</p>
<p>One would be inclined to believe that far more money is laundered and shuffled around using cash (fiat) than it is Monero or other privacy coins, however the IRS doesn’t seem to think so, and it’s willing to shell out big bucks for a beta. Monero allows users to send funds to another party without the sender or receiver address and the amount being revealed, much like cash but fairly minted.</p>
<p>Something doesn’t seem right about this. Perhaps it’s the fact that all of this suggests that the IRS would go as far as cracking into a safe in your home to see where you stand financially. Would they? Should the IRS have the ability to see all of the information otherwise obfuscated even in instances where the parties involved in a transaction are not under active investigation?</p>
<p>Now it’s not being suggested here that people should not pay taxes, if you claim your citizenship then certainly you should also pay it’s taxes if it’s in your lawful interest to do so. What’s questionable however is the intrusion of privacy. The IRS does not exclusively need the ability to uncover the sender, receiver or amount of a transaction to determine if someone is not paying taxes, they can allocate resources towards tracking that within their own confines.</p>
<p>I know I know, “If you have nothing to hide” right? well if that’s the case let’s just stop using doors and curtains too.</p>

</div></div>]]>
            </description>
            <link>https://xitheon.com/news/the-irs-is-offering-over-500000-in-bounty-to-anyone-who-is-able-to-crack-moneros-privacy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24439377</guid>
            <pubDate>Fri, 11 Sep 2020 05:11:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons Learned in Freelancing]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24439321">thread link</a>) | @colept
<br/>
September 10, 2020 | https://cole.codes/posts/lessons-learned-in-freelancing | <a href="https://web.archive.org/web/*/https://cole.codes/posts/lessons-learned-in-freelancing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>From 2004 to 2018, I was a freelance web developer and worked on dozens of projects in spaces including tech, retail, advertising, community engagement, software development, and more. These spaces have taught me a lot about how the internet has become the center of our lives and the people who run them. </p><h2></h2><p>Freelance web development is when a software engineer performs a web development service on-demand, without committing to a full-term engagement. Developers working in freelance are self-employed and have the flexibility to organize their contracts and schedule at their own discretion. These contracts are an agreement between the freelancer and the client, to perform the job at agreed-upon terms. It can be an empowering experience that allows you to have an impact on a variety of projects.</p><p>If you're thinking of becoming a freelance web developer or learning more about freelance, then this article is for you. In this post, I'll share with you the lessons that I've learned and how to have a great time as a freelancer. Moreover, I'll tell you how to work more effectively with clients, deal with complications, and what red flags to keep in mind. Here are the lessons that I've learned in my freelancing career.</p><h2></h2><p>A contract provides guarantees for both the freelancer and the client. Those guarantees include the scope of the work performed, the terms of payment, deadlines for delivery, and any additional maintenance or followup. As a freelancer, you want to over-clarify every aspect of the work performed and the work not performed, in order to have a healthy relationship with your client. Any ambiguity can cause tension, as these aspects are more difficult to negotiate later on. When I was a freelancer, I used Bonsai (<a rel="nofollow noreferrer" target="_blank" href="https://www.hellobonsai.com/">hellobonsai.com</a>) to create contracts and send them to clients for signing. Another option is <a rel="nofollow noreferrer" target="_blank" href="https://stuffandnonsense.co.uk/projects/contract-killer">Stuff &amp; Nonsense's Contract Killer</a>, an open-source contract.</p><p><b>Remember to include in your contracts:</b></p><ol><li>Work you will perform.</li><li>Clarify explicit tasks that are out of scope.</li><li>Terms of payment including deposits, termination fees, delivery of payment, and late payment fees.</li><li>Responsibilities and liabilities for both parties, including if either party changes their mind.</li><li>Ownership, intellectual property, copyright, or other legal concerns. Upon full payment of services.</li></ol><p>A contract is going to make the biggest difference in your relationship with clients, and how effective you are as a freelancer. These stipulations protect both you and the client and guarantee you'll have a good time. If you're unsure about your contract, reach out to lawyers and go for consultations. A lawyer who specializes in intellectual property and information technology can provide better guidance, and many offer free consultations. </p><hr><h2></h2><p>When negotiating a contract with a client, the work performed should be clearly outlined. As part of this process, you will also want to rule out any ambiguity and clarify the work that will <i>not</i> be performed. This is for your protection in the event that later down the line, the client makes a request that is outside of the scope of the contract.</p><p>A previous client of mine brought me on to clean up the front-end design for a project. It was a reasonable project that I could deliver in the short-term, about a month and a half. Two weeks later, I started receiving requests to develop new features. This would have delayed the time to complete the contract and made it impossible for me to begin a contract I had already queued up thereafter. Using the contract as a reference, I denied the request as it was outside of the scope that I was able to perform to deliver in time.</p><hr><h2></h2><p>Freelancers are self-employed which has additional costs than a full-time employee. They pay self-employment taxes which is about 15.3%. Moreover, freelancers must pay for their own health insurance. The market rate for a freelance job should be at least one and a half times (1.5x) what a full-time employee would make. This will cover your additional expenses. </p><p>Your rate will largely depend on what you're able to negotiate. Freelance jobs depend on supply and demand, and what value you're able to bring to a job. A client is paying you for more than your time: they're paying for your experience too. So while it may take 8 hours to create a webpage, your rate also takes into account the years of experience you have in honing your craft.</p><hr><h2></h2><p>Deposits are protections for both freelancers and clients. They also help cover expenses to smooth out time in between paydays. A contract deposit is an insurance that the client is able to pay you for performing the work. For these reasons, I've learned that a deposit is non-negotiable.</p><p>Clients should want to pay you a deposit because it also demonstrates your commitment to getting the job done. A client that does not want to pay the deposit, will give you trouble later. If they try to negotiate, they will give you trouble later. </p><p><b>In conclusion:</b></p><ol><li>The deposit is non-negotiable.</li><li>The deposit is non-negotiable.</li><li>The deposit is non-negotiable.</li></ol><hr><h2></h2><p>Freelancing carries an additional responsibility to manage the pipeline for contracts. You will want to have another contract lined up before your current contract ends. When it's time to start the next contract, you will want to have already made plans for thereafter.</p><p>Sometimes a contract doesn't work out. There may come a time when a freelancer finds themselves wanting to void or otherwise not renew a contract. In this situation, it's helpful to have a backup plan to bridge the gap. Short term contracts that are easy to pick up and complete are a great way to fulfill periods of time in between contracts.</p><hr><h2></h2><p>Money does not replace happiness. When a job doesn't feel right, trust your gut and instincts. If the terms of a contract are not happening as expected, there are a few options:</p><ul><li>Talk to the client to try and resolve the situation.</li><li>Absolving the contract amicably.</li><li>Seek legal consultation.</li><li>Walk away.</li></ul><p>It's important to understand that above all, communication is important. Talking to the client to resolve the situation requires deep introspection into what is working and what is not working. If there is a shared sense of wanting to absolve the contract amicably, that requires communication. Ideally, there's no need to involve legal representation. The legal route requires balancing the potential loss in the contract stipends versus the loss from time spent in the legal process. When all other options are exhausted, sometimes the best option is to walk away.</p><hr><h2></h2><p>Knowing when to walk away from a contract is important, but knowing when to run from a bad client is even more important. There are some behaviors I've observed in my freelancing career that are definite red flags. </p><h3></h3><p>Assume that any client that does not want to sign a contract does not want to pay you. A contract protects both parties, and without one they want to abuse their position as the party that holds the money.</p><p><b>Run from the client that doesn't want to sign a contract.</b></p><h3></h3><p>If they ask right off the bat "how much will this cost?" Or "does it really cost that much?" If they are asking questions like this, it's a fair assumption that they are looking for the cheapest supply they can demand. Assume that any client that tries to barter your rate or deposit does not want to pay you. </p><p><b>Run from the barter that pretends to be a client.</b></p><h3></h3><p>As a freelancer, you want to work for someone who hires you for the service and value you provide. A good client understands where their abilities end and where your abilities start. When the client is also the designer or a developer, the working relationship is difficult to facilitate because the relationship is unequal and imbalanced. This can be managed, so long as the work performed is not stipulated on work that has yet to be performed. A good contract stands on its own.</p><p><b>Run from the client that really wants an employee.</b></p><h3></h3><p>Your time is money. A good client recognizes this and hires a freelancer with a clear set of scope, requirements, and timelines. If none of these dependencies are clarified within the first few exchanges, then the client is trying to extract as much free labor from you as possible. Any spec work, prototyping, or brainstorming is labor that should be compensated.</p><p><b>Run from clients that try to diminish your value before they hire you. </b></p><h3></h3><p>It is not your job to provide a client with direction. A good contract stipulates that you perform a finite list of tasks based on what the client wants. </p><p><b>Run from the client that wants a freelancer to also be a CEO. </b></p><h3></h3><p>Timelines and deliverables should be settled before the contract is signed, and is mostly at the discretion of the freelancer. The client can share their expectations when they need the served to be completed, however, ASAP is not a timeline. ASAP means they will micro-manage you and treat you like a commodity. This client will not respect your boundaries.</p><p><b>Run from the client that won't respect your boundaries.</b></p><h3></h3><p>You get an email about an exciting, innovative project, and they want your help to get it off the ground. They want you to sign an NDA before they communicate the scope, requirements, or budget. This client is asking you to perform a service before the contract is signed.</p><p>If you receive a request like this, kindly reply with this response:</p><blockquote>Thank you for your interest. I'm happy to schedule a consultation with you to engage in a more thorough conversation. I require a $1000 signing fee, $500/hr rate, and 3 hour minimum for any sensitive consultations.</blockquote><p>If they're serious about the idea and understand your value, they will pay you for this consultation. Otherwise, any client that is afraid you will steal their idea is likely going to be a waste of time. They will shop the idea around cautiously until some other eager entrepreneur beats them to market. </p><p><b>Run from the client who hesitates before hiring you.</b></p><h3></h3><p>The promise of future work is not a currency. This is a sneaky way of bartering compensation by promising stability. Assume that anything not stipulated in the contract is not going to …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cole.codes/posts/lessons-learned-in-freelancing">https://cole.codes/posts/lessons-learned-in-freelancing</a></em></p>]]>
            </description>
            <link>https://cole.codes/posts/lessons-learned-in-freelancing</link>
            <guid isPermaLink="false">hacker-news-small-sites-24439321</guid>
            <pubDate>Fri, 11 Sep 2020 04:57:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Most Efficient Way to Solve Problems]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24439304">thread link</a>) | @lucasfcosta
<br/>
September 10, 2020 | https://lucasfcosta.com/2020/09/05/not-having-problems.html | <a href="https://web.archive.org/web/*/https://lucasfcosta.com/2020/09/05/not-having-problems.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>It’s Monday. The first of the seven alarms you’ve set on your phone soars louder than the Big Ben. It sends chills down your spine announcing the impending doom: your 8 AM commute. You put on that white shirt you’re sick of, and head to the most crowded place on earth: the <a href="https://www.cityam.com/londons-most-crowded-tube-lines-revealed/">northern line</a>.</p>

<p>Your commute is a problem, and you want to solve it. <strong>The challenge with <em>solving</em> problems is that it’s usually harder to find a solution than it is <em>not</em> to have that particular issue in the first place</strong>.</p>

<p>“Why didn’t I buy that used Toyota Prius for half the price?”. “It’s time to start cycling; perhaps it will get me in shape too”. “Does Tim Ferris <em>really</em> wake up at five? I bet no one takes the tube at that time”.</p>

<p>Buying a car, commuting by bike, or waking up earlier are all <em>solutions</em> to the problem of having an uncomfortable commute. Nevertheless, they’re imperfect because they are <em>patches</em>.</p>

<p>If you buy a car, you’ll still get stuck in traffic. If you buy a bike, you’ll get sweaty, and you’ll have to change clothes when you get to work. Personally, I love waking up at five, and at that time there’s definitely no one in the tube, but it doesn’t matter how early I get out of bed, I still have to face a thirty-minute commute.</p>

<p><strong>It’s rare, if not impossible, to apply patches which completely resolve the problems you have. More often than not, applying patches creates new problems.</strong></p>

<p>When faced with a problem, instead of immediately trying to patch it, I’d recommend you to take a step back and think about whether you could avoid it altogether.</p>

<p>Just because you <em>hate</em> commuting, it doesn’t mean you should look for ways to make it more pleasant. The most efficient way to solve the commute problem is <em>not</em> to commute at all.</p>

<p>If you work from home, you won’t need to spend any money in a car, put any effort in cycling, or ruin your circadian rhythm by waking up too early.</p>

<p>Now think about managing a website which depends on a particular RESTful API, for example. Every time you make changes to the underlying API, you’ll have to update your client. These updates are time-consuming, and they need to happen immediately. Otherwise, you won’t be able to deploy either your back-end or front-end.</p>

<p>In this case, instead of trying to patch the problem by finding more complicate and suboptimal solutions, like, for example, synchronising deployments, you could avoid the problem altogether by <em>not</em> making breaking changes to your API’s routes.</p>

<p>If you version your API by prefixing each of its routes, you won’t break the client. Therefore, you won’t have to synchronise deployments or immediately schedule work to update your front-end as soon as you start changing the server.</p>

<p>Instead of <em>patching</em> the problem, you eliminated it.</p>

<p>Yet, you can’t <em>always</em> completely eliminate all obstacles. There is a third kind of solution, which is a mix of the previous two. Even though it involves a patch, its patch entirely eliminates the problem.</p>

<p>You can’t, for example, solve every software problem by <em>not</em> creating any software. Even though software creates issues, it makes our lives significantly better most of the time.</p>

<p>Instead of trying to eliminate software altogether, you should find ways to write <em>less</em> software.</p>

<p>UNIX streams are an excellent example of this kind of solution. Because streams allow programs to communicate with each other, they enable you to combine existing programs instead of creating new ones.</p>

<p>Even though we’ve had to create software for streams to work, we didn’t have to write <em>too much</em> of it. We’ve written a little bit of code so that we could write less of it in the future.</p>

<p>These kinds of solutions are interesting because they’re usually winners in the market.</p>

<p>When we had problems managing our own data-centres, for example, the winner products weren’t the ones which made it more efficient to manage your own hardware. The winners were those who allowed you not to have a data-centre altogether. That was the birth of VPS’s.</p>

<p>Now, we’re seeing the exact same process happening on the cloud computing space because running program’s in someone else’s hardware creates yet another problem.</p>

<p>Even though companies don’t have to maintain their own data-centres anymore, they still have to manage the machines in which they host their software.</p>

<p>Again, we’re faced with the choice to patch the problem or find a solution which eliminates it altogether.</p>

<p>We can create complex programs to <a href="https://github.com/chef/chef">provision servers</a>, <a href="https://www.nagios.org/">monitor their resources</a>, and <a href="https://kubernetes.io/">orchestrate our system’s components</a>, or we can avoid using these “virtual machines” altogether by using Lambdas, for example.</p>

<p>I bet that cloud-native architectures will win.</p>

<p>In the same way that we chose not to maintain data-centers instead of making it easier to manage them, we’ll decide not to manage any servers instead of making it more efficient to do so.</p>



<hr>





<p>I do <em>not</em> necessarily think that cloud-native architectures are objectively better.</p>

<p>These services have dozens of disadvantages about which I could write entire posts. The most significant of them is probably vendor lock-in.</p>

<p>What I’m saying instead is that I believe the majority of the market will end up adopting these kinds of services.</p>

    </article></div>]]>
            </description>
            <link>https://lucasfcosta.com/2020/09/05/not-having-problems.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24439304</guid>
            <pubDate>Fri, 11 Sep 2020 04:54:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HarmonyOS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24439229">thread link</a>) | @pjmlp
<br/>
September 10, 2020 | https://www.harmonyos.com/en/home/ | <a href="https://web.archive.org/web/*/https://www.harmonyos.com/en/home/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="harmony-page"><header id="navbar" :style="{'padding-bottom': paddingBottom}" :data-clientwidth="clientWidth">
	
	<pc-header id="pc_navbar" v-cloak="" v-if="clientWidth>900 &amp;&amp; showHead">
        
        
        
        

    </pc-header>
    
    <mobile-header v-if="clientWidth<=900 &amp;&amp; showHead" v-cloak="">
        
        
        
    </mobile-header>
</header>

  <div>
        <div>
            <div>
                <div>
                    <div>
                        <p><span>Cutting-edge hardware</span> 
                        </p>
                        <p>
                           Efficient and secure cross-device connectivity, in which the phone serves as the smart digital hub, distributing content and services to address user needs. </p>
                        
                    </div>
                    <p><img src="https://www.harmonyos.com/resource/image/home/img-01-.png">
                    </p>
                </div>
            </div>
		</div>
</div>
<div>
        <div>
            <div>
                <div>
                    <p><span>
                            Seamless interactions</span>
                    </p>
                    <p>
                        Effortless interactions designed for broad-ranging usage scenarios and device types. User-centric approach, characterized by smart coordination between devices, with smooth cross-device transfers.</p>
                    
                    <p><img src="https://www.harmonyos.com/resource/image/home/2-xinjiaohu-10.png" alt="">
						</p>
                </div>
            </div>
        </div>
    </div>
<div>
        <div>
            <div>
                <div>
                    <div>
                        <p><span>Groundbreaking services</span> 
                        </p>
                        <p>
                           Applications and services customized to meet the needs of users, invoking a multitude of device capabilities to heighten performance. Versatile solutions crafted for optimal convenience</p>
                        
                    </div>
                    <p><img src="https://www.harmonyos.com/resource/image/home/3-xinfuwu-10.png">
                    </p>
                </div>
            </div>
		</div>
</div>

<p><a href="https://developer.huawei.com/consumer/en/events/hdc2020/?channelname=HeZuo58&amp;ha_source=banner" onclick="util.reportApi.reportClick()">
			<img src="https://www.harmonyos.com/resource/image/home/HDC-pc-en-new.png">
			<img src="https://www.harmonyos.com/resource/image/home/HDC-mobile-en-new.png">
		</a></p>
<!--<div class="swiper-container" id="developer_container">
			<div class="swiper-wrapper">
				</div> 
			<div class="swiper-pagination"></div>
			<div class="swiper-button-next"></div>
			<div class="swiper-button-prev"></div>
		</div>-->


  </div></div>]]>
            </description>
            <link>https://www.harmonyos.com/en/home/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24439229</guid>
            <pubDate>Fri, 11 Sep 2020 04:34:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting macOS style hotkeys working in GNU/Linux]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24439205">thread link</a>) | @todsacerdoti
<br/>
September 10, 2020 | https://technex.us/2020/09/getting-macos-style-hotkeys-working-in-gnu-linux/ | <a href="https://web.archive.org/web/*/https://technex.us/2020/09/getting-macos-style-hotkeys-working-in-gnu-linux/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<p>Over the years I've used every operating system. Sometimes all at once. Recently I've taken to using Linux as my primary desktop operating system. Everything I need runs natively on Linux and because I have full control over my environment I never have down time due to forced updates. This is my desktop after all so I'm really switching from Windows where the Control key modifier paradigm is more or less the same as Linux. Still I didn't want to compromise on anything with this new configuration and there was one thing missing from my Macbook that I really wanted.</p>
<p>Of course what I'm talking about is the Command key or more colloquially known simply as the Apple Key and all the shortcuts and hot keys built into macOS that make it such a joy to use.</p>
<p><img src="https://technex.us/media/70" width="200"></p>
<blockquote>
<p><em>"Linux lets you change whatever you want."</em></p>
<p>Is a common thing that people say to bring up a positive aspect of GNU/Linux. Is this actually true though? Take for example my issue at hand: Changing copy/paste hotkeys for all programs. In truth, some tasks are so big in their scope few users would ever be capable of accomplishing them. At least not without a lot of contextual knowledge.</p>
<p>Getting macOS style hotkeys is actually an extremely difficult task in Linux. Especially when you want to avoid faking it by binding some keys to other keys on a per application basis.</p>
</blockquote>
<p>Then there's the question of why do it at all?</p>
<p><span><span>The truth is I just got tired of </span></span><span><span>accidentally sending SIGINTs when switching to terminal and then accidentally triggering the wrong thing when switching out of terminal. I've just gotten so used to not having to context switch my brain in macOS between programs. It's one of the things that truly makes my Macbook Pro more pleasant to use.</span></span></p>
<p><span><span><img src="https://technex.us/media/73"></span></span></p>
<p>So that's my first reason. Muscle memory.</p>
<p>My second reason is simply that Command/Meta is directly next to the space bar and I just like having a shorter stretching span for my hand.</p>

<h3>Making it work</h3>
<p>For the most part GUI applications written for Linux tend to make a lot of assumptions about what hotkeys can and should be in a very opinionated way. Some types of programs require full customization (like code editors) while others like browsers tend to force certain hotkeys. Desktop managers do provide their own hotkey bindings. For example most KDE based applications will use your settings from KDE's "System Settings" to set hotkeys. Meanwhile in Gnome you can use dbind to set your keybinds.</p>
<p>Of course Cut/Copy/Paste is not enough. It would actually be quite jarring to use CTRL+T for opening a new tab immediately after using Command+V to paste something. Indeed if you go down this path you'll end up having to redefine your hotkeys for well..... everything. It is unfortunate as well that applications these days are extremely hostile to user settings.</p>
<p>Despite the hurdles in front of me I decided to try to make it work.</p>
<p>The first thing I did was swap Left Alt and Left Meta on my keyboard. This was actually pretty easy to do with keyboard mapping configs with the KDE GUI simply known as "System Settings". This was simply to make my normal windows keyboard place the buttons in the positions a real mac keyboard would have. None of this is necessary if you have a real Apple layout keyboard. This setting is only active while in my X session so any alternative TTYs would revert back to my stock layout. If I had a real Apple layout keyboard though this is not necessary at all.</p>
<p><img src="https://technex.us/media/71"></p>
<p>This setting is saved to the text file <code>~/.config/kxkbrc.</code></p>
<pre><code>$ cat kxkbrc 
[Layout]
DisplayNames=
LayoutList=us
LayoutLoopCount=-1
Model=pc101
Options=altwin:swap_lalt_lwin
ResetOldOptions=true
ShowFlag=false
ShowLabel=true
ShowLayoutIndicator=true
ShowSingle=false
SwitchMode=Global
Use=true
</code></pre>
<p>Now with this setting I am able to fake the same key mapping as a real macOS&nbsp;keyboard would have in my desktop session. So far so good. Now I manually changed all my hotkeys in my code editors, terminal applications, and even in the System Settings app I just mentioned to set global hot keys for all KDE applications. This took some time but was very straight forward for the most part.</p>
<p><img src="https://technex.us/media/72"></p>
<p>I went above and beyond even changing my shortcuts for things like Select All.</p>
<p>While this worked for KDE applications I had to also make this change for GTK+ based programs as well. Luckily this would also cover Chrome, Discord, Elements, and a number of other Electron based programs that I use on a regular basis.</p>
<p>I was lucky that VSCode let me change everything but it was very annoying have to redo all the system based hotkeys like Set cursor to start of the line (in macOS this is Meta+Left Arrow) for each and every place I wanted to use it.</p>
<p>Some websites also use Meta+C for example in Github hitting Meta+C will actually take focus and bring you to the Add Comment UI when in a thread so sometimes on Github.com even with Firefox set to use Meta+C to copy something I am not actually able to use my hotkey because the website overrides it.</p>
<p>With GTK I ended up editing <code>`</code><span><code>~/.config/gtk-3.0/gtk.css`</code> </span><span>and setting these hotkeys.</span></p>
<pre><code>@binding-set gtk-super-cut-copy-paste
{
        bind "&lt;super&gt;x" { "cut-clipboard" () };
        bind "&lt;super&gt;c" { "copy-clipboard" () };
        bind "&lt;super&gt;v" { "paste-clipboard" () };
        bind "&lt;super&gt;a" { "select-all" (1) };
        bind "&lt;super&gt;z" { "undo" () };
}

* {
        -gtk-key-bindings: gtk-super-cut-copy-paste
}
</code></pre>
<p>I might add more but for now this got me to where I wanted with most GTK+ applications. Note that if you plan to run any of programs designed to run as root that use GTK+ such as GParted you should also link or copy this config file to the root account home directory as well.</p>
<p>So in the end it is possible. I was able to achieve what I wanted with all but one program. But it was a huge pain. It's really difficult to figure out what settings do what in a Linux environment even when there is documentation. It's typical for documentation to exist for say GTK+ 2.0 and GTK+ 3.0 but there is no over arching best practice guide for what one should do when they want to cover all programs in an environment.</p>


<h3>It Doesn't Have to Be This Way</h3>
<p>The Linux ecosystem can and should do better. The ability to do whatever you want is a double edged sword where even though you can in theory change things, in practice however, sometimes changing things is so onerous that staying sane in the process is a task in itself.</p>
<p>So please if you are a Linux user space developer check the GTK+ 2.0 (<code>~/.gtkrc-2.0</code>), GTK+ 3.0 (<code>~/.config/gtk-3.0/gtk.css</code>) and KDE global shortcut configs (<code>~/.config/kdeglobals</code>) when you probe for the environment during startup so that people can choose their own hotkeys for their desktop environment or simply use the C libraries of each and use the hotkeys present.</p>
<p>Better yet, if you are a developer that already supports various input methods for macOS, Linux, and Windows you can simply provide a toggle for users.</p>
<p>It would be beneficial to Linux Desktop environments to agree to a standard config file for hotkeys allowing users to bind keys as they see fit rather than lurching from one weird keybinding config to the next with no centralization to speak off.</p>
	</div></div>]]>
            </description>
            <link>https://technex.us/2020/09/getting-macos-style-hotkeys-working-in-gnu-linux/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24439205</guid>
            <pubDate>Fri, 11 Sep 2020 04:30:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ergonomic Haskell 1 – Records]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24439204">thread link</a>) | @todsacerdoti
<br/>
September 10, 2020 | https://codygman.dev/posts/2020-09-07-Ergonomic_haskell_1_records.html | <a href="https://web.archive.org/web/*/https://codygman.dev/posts/2020-09-07-Ergonomic_haskell_1_records.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <section>
        
<p>We have heard of Boring Haskell, Simple Haskell, and Fancy Haskell… but let’s ignore all of those and focus more on us. Why not make Haskell <em>feel</em> nicer to use? To do that we’ll focus on its UX and ergonomics and hopefully end up with…</p>
<p>Ergonomic Haskell!</p>
<p>If it is:</p>
<ul>
<li>Nice to use</li>
<li>Not horribly complex</li>
<li>Doesn’t give horrible type errors</li>
</ul>
<p>So even if something costs us a little bit of extra complexity, the logic goes that the annoyance it gets rid of will be worth it most of the time. Extra points if it could let us tap into yet to be understood benefits.</p>
<p>There is a bias towards:</p>
<ul>
<li>ergonomics of reading over ergonomics of writing</li>
<li>easy to read long term vs easy to understand in the very short term</li>
</ul>
<p>NOTE: Everything about this series will be highly opinionated and subjective, based on things that I’ve noticed “feel good” and make code easier to understand over time.</p>
<p>The format will be:</p>
<ul>
<li>simple</li>
<li>short</li>
<li>avoid unnecessary detail or justification of choices</li>
</ul>
<p>In other words, the ergonomics and end result are at the forefront :)</p>

<h2 id="the-default-ergonomics-are-bad">The default ergonomics are bad</h2>
<p>This style is currently dominant with the simple but annoying work-around of prefixing the field name. Perhaps its harsh to call this bad ergonomics, but my brain really doesn’t take well to all the duplication and I’d hazard a guess this holds true for others as well.</p>
<p>Its usage is even noisier and less ergonomic in surprisingly consequential ways once your real-world code uses enough record fields. My theory is the duplication in label names puts a wrench in some peoples thinking process just like it does mine.</p>
<p>These are the data types for the default “bad ergonomics” example:</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>data</span> <span>Person</span> <span>=</span> <span>Person</span> {<span> name ::</span> <span>String</span>,<span> age ::</span> <span>Int</span>}</span>
<span id="cb1-2"><span>data</span> <span>Dog</span> <span>=</span> <span>Dog</span> {<span>name ::</span> <span>String</span>,<span> age ::</span> <span>Int</span>}</span>
<span id="cb1-3"><span>data</span> <span>CatBall</span> <span>=</span> <span>CatBall</span> {<span> name ::</span> <span>String</span>,<span> type_ ::</span> <span>String</span>}</span>
<span id="cb1-4"><span>data</span> <span>Cat</span> <span>=</span> <span>Cat</span> {<span> name ::</span> <span>String</span>,<span> age ::</span> <span>Int</span>,<span> favoriteBall ::</span> <span>CatBall</span>}</span></code></pre></div>
<p>Here is what the implementation of that default looks like:</p>
<div id="cb2"><pre><code><span id="cb2-1"><span>if</span> personName person <span>==</span> <span>"codygman"</span></span>
<span id="cb2-2">        <span>then</span> <span>do</span></span>
<span id="cb2-3">          <span>putStrLn</span> <span>$</span> <span>"Good day, "</span> <span>++</span> personName person</span>
<span id="cb2-4">          <span>putStrLn</span> <span>$</span> <span>"Your dog's name: "</span> <span>++</span> dogName dog</span>
<span id="cb2-5">          <span>putStrLn</span> <span>$</span> <span>"Your cat's name: "</span> <span>++</span> catName cat</span>
<span id="cb2-6">          <span>if</span> (catBallName <span>.</span> favoriteBall <span>$</span> cat) <span>==</span> <span>"doggos"</span></span>
<span id="cb2-7">            <span>then</span> <span>do</span></span>
<span id="cb2-8">              <span>putStrLn</span> <span>"One second.. there's been a mix up it seems!"</span></span>
<span id="cb2-9">              <span>let</span> fixedCat <span>=</span> cat { favoriteBall <span>=</span> (favoriteBall cat) </span>
<span id="cb2-10">                                     { catBallName <span>=</span> <span>"cattos"</span>, catBallType <span>=</span> <span>"yarn ball"</span> } </span>
<span id="cb2-11">                                 }</span>
<span id="cb2-12">              <span>putStrLn</span> <span>$</span> <span>"Your cat's favorite ball type: "</span> <span>++</span> (catBallType <span>.</span> favoriteBall <span>$</span> fixedCat)</span>
<span id="cb2-13">            <span>else</span> <span>putStrLn</span> <span>$</span> <span>"Your cat's name: "</span> <span>++</span> catName cat</span>
<span id="cb2-14">        <span>else</span> <span>putStrLn</span> <span>"THIS IS MY PROGRAM! I DON'T KNOW YOU! *KICK*"</span></span></code></pre></div>
<p>In Ergonomic Haskell we don’t have room for all of this noise, but we do have room for one-time upfront costs that will make our lives a little nicer through the life of the project.</p>
<p>We instead demand the most ergonomic solution today! That looks like this:</p>
<div id="cb3"><pre><code><span id="cb3-1"><span>if</span> person <span>^.</span> <span>#</span>name <span>==</span> <span>"codygman"</span></span>
<span id="cb3-2">  <span>then</span> <span>do</span></span>
<span id="cb3-3">    <span>putStrLn</span> <span>$</span> <span>"Good day, "</span> <span>++</span> person <span>^.</span> <span>#</span>name</span>
<span id="cb3-4">    <span>putStrLn</span> <span>$</span> <span>"Your dog's name: "</span> <span>++</span> dog <span>^.</span> <span>#</span>name</span>
<span id="cb3-5">    <span>putStrLn</span> <span>$</span> <span>"Your cat's name: "</span> <span>++</span> cat <span>^.</span> <span>#</span>name</span>
<span id="cb3-6">    <span>if</span> <span>#</span>cat <span>^.</span> <span>#</span>favoriteBall <span>%</span> <span>#</span>name <span>==</span> <span>"doggos"</span></span>
<span id="cb3-7">      <span>then</span> <span>do</span></span>
<span id="cb3-8">        <span>putStrLn</span> <span>"One second.. there's been a mix up it seems!"</span></span>
<span id="cb3-9">        <span>let</span> fixedCat <span>=</span></span>
<span id="cb3-10">              cat <span>&amp;</span> <span>#</span>favoriteBall <span>%</span> <span>#</span>name <span>.~</span> <span>"cattos"</span></span>
<span id="cb3-11">                  <span>&amp;</span> <span>#</span>favoriteBall <span>%</span> <span>#</span>ballType <span>.~</span> <span>"yarn ball"</span></span>
<span id="cb3-12">        <span>putStrLn</span> <span>$</span> <span>"Your cat's favorite ball type: "</span> <span>++</span> fixedCat <span>^.</span> <span>#</span>name</span>
<span id="cb3-13">      <span>else</span> <span>putStrLn</span> <span>$</span> <span>"Your cat's name: "</span> <span>++</span> cat <span>^.</span> <span>#</span>name</span>
<span id="cb3-14">  <span>else</span> <span>putStrLn</span> <span>"THIS IS MY PROGRAM! I DON'T KNOW YOU! *KICK*"</span></span></code></pre></div>
<h2 id="learned-simplicity">Learned Simplicity</h2>
<p>You might disagree with me on the above being simpler. At first I thought the same and asked:</p>
<p>How can symbols be simpler than words?</p>
<p>Answer: When they don’t matter.</p>
<p>What if you in oop languages for <code>foo.bar</code> you instead had to do <code>foo dot bar</code> each time? Wouldn’t that be distracting? By using something that takes up less space, you can concentrate on the piece that matters.</p>
<p>Less is more.</p>
<p>Recall that earlier I said one of the goals of Ergonomic Haskell was:</p>
<blockquote>
<p>easy to read long term vs easy to understand in the very short term</p>
</blockquote>
<p>My argument is that while this isn’t as simple as I’d like it to be, this is the most ergonomic and simple solution in Modern Haskell right now after a small adjustment period.</p>
<p>It’s simpler to just prefix field names with the data type name in the same way it’s simpler to not have Generics in a modern programming language: It’s not.</p>
<p>We have so many things to focus on that we must preserve our ability to communicate what pieces of our code are most important. In this case, it takes the form of us learning a few symbols in exchange for much less noisy code which more clearly communicates it’s intent over the long term.</p>
<h2 id="uncovering-the-simplicity">Uncovering the simplicity</h2>
<p>In other languages you might simply write <code>dog.name</code> and <code>cat.name</code> respectively. All Haskeller’s admit this is the simplest outcome and work is being done to make that possible in Haskell too (see the next section). No arguments here!</p>
<p>Here’s a table that should help make sense of the code above:</p>
<table>
<thead>
<tr>
<th>Language</th>
<th>Operation</th>
<th>Operator</th>
</tr>
</thead>
<tbody>
<tr>
<td>Java</td>
<td>get</td>
<td>person.age</td>
</tr>
<tr>
<td>Haskell</td>
<td>get</td>
<td>person ^. age</td>
</tr>
<tr>
<td>Java</td>
<td>set</td>
<td>person.age = 25</td>
</tr>
<tr>
<td>Haskell</td>
<td>set</td>
<td>person &amp; age .~ 25</td>
</tr>
<tr>
<td>Java</td>
<td>chained set</td>
<td>person.age = 25; person.name = “Bob”</td>
</tr>
<tr>
<td>Haskell</td>
<td>chained set</td>
<td>person &amp; age .~ 25 &amp; name .~ “Bob”</td>
</tr>
</tbody>
</table>
<p>After a few coding sessions with these operators or playing around in the REPL, you might not even need this chart anymore.</p>
<p>I’d written a longer explanation of these things, but I think that’s where a lot of tutorials fall down. Our brains are very good at matching patterns and discerning meanings, so we should merely present differences in a simple format and let our readers brains go to work!</p>
<p>A potential bonus is that the underneath what we are using as getters/setters are fully powered optics. The value of that is hard to communicate, and it’s the “feeling” of using them that’s more valuable anyway. At the very end of this post I’ll share one tiny snippet to try and push that feeling from my brain to yours.</p>
<h2 id="the-future-is-hopeful">The future is hopeful</h2>
<p>In the future per <a href="https://github.com/ghc-proposals/ghc-proposals/blob/master/proposals/0282-record-dot-syntax.rst">RecordDotSyntax</a> the dot syntax you know from other languages will be possible and look like:</p>
<div id="cb4"><pre><code><span id="cb4-1"><span>if</span> person<span>.</span>name <span>==</span> <span>"codygman"</span></span>
<span id="cb4-2">  <span>then</span> <span>do</span></span>
<span id="cb4-3">    <span>putStrLn</span> <span>$</span> <span>"Good day, "</span> <span>++</span> person<span>.</span>name</span>
<span id="cb4-4">    <span>putStrLn</span> <span>$</span> <span>"Your dog's name: "</span> <span>++</span> dog<span>.</span>name</span>
<span id="cb4-5">    <span>putStrLn</span> <span>$</span> <span>"Your cat's name: "</span> <span>++</span> cat<span>.</span>name</span>
<span id="cb4-6">    <span>if</span> cat<span>.</span>favoriteBall<span>.</span>name <span>==</span> <span>"doggos"</span></span>
<span id="cb4-7">      <span>then</span> <span>do</span></span>
<span id="cb4-8">        <span>putStrLn</span> <span>"One second.. there's been a mix up it seems!"</span></span>
<span id="cb4-9">        <span>let</span> fixedCat <span>=</span></span>
<span id="cb4-10">              cat { favoriteBall<span>.</span>name <span>=</span> <span>"cattos"</span>, favoriteBall<span>.</span>ballType <span>=</span> <span>"yarn ball"</span> }</span>
<span id="cb4-11">        <span>putStrLn</span> <span>$</span> <span>"Your cat's favorite ball type: "</span> <span>++</span> fixedCat<span>.</span>name</span>
<span id="cb4-12">      <span>else</span> <span>putStrLn</span> <span>$</span> <span>"Your cat's name: "</span> <span>++</span> cat<span>.</span>name</span>
<span id="cb4-13">  <span>else</span> <span>putStrLn</span> <span>"THIS IS MY PROGRAM! I DON'T KNOW YOU! *KICK*"</span></span></code></pre></div>
<p>Hopefully we can simplify and get there soon but that’s enough about the future… we want the most ergonomic Haskell we can get NOW!</p>
<h2 id="how-to-do-it">How to do it</h2>
<ol type="1">
<li>Install <code>optics</code> and enable these language extensions in your cabal file or package.yaml <code>default-extensions</code> or somewhere else you don’t have to worry about them again. A simple stack hpack example looks like:</li>
</ol>
<div id="cb5"><pre><code><span id="cb5-1"><span>executables</span><span>:</span></span>
<span id="cb5-2"><span>  </span><span>records-exe</span><span>:</span></span>
<span id="cb5-3"><span>    </span><span>main</span><span>:</span><span>                Main.hs</span></span>
<span id="cb5-4"><span>    </span><span>source-dirs</span><span>:</span><span>         app</span></span>
<span id="cb5-5"><span>    </span><span>default-extensions</span><span>:</span></span>
<span id="cb5-6"><span>      </span><span>-</span><span> DataKinds</span></span>
<span id="cb5-7"><span>      </span><span>-</span><span> DuplicateRecordFields</span></span>
<span id="cb5-8"><span>      </span><span>-</span><span> FlexibleContexts</span></span>
<span id="cb5-9"><span>      </span><span>-</span><span> FlexibleInstances</span></span>
<span id="cb5-10"><span>      </span><span>-</span><span> GADTs</span></span>
<span id="cb5-11"><span>      </span><span>-</span><span> MultiParamTypeClasses</span></span>
<span id="cb5-12"><span>      </span><span>-</span><span> OverloadedLabels</span></span>
<span id="cb5-13"><span>      </span><span>-</span><span> TemplateHaskell</span></span>
<span id="cb5-14"><span>      </span><span>-</span><span> UndecidableInstances</span></span>
<span id="cb5-15"><span>    </span><span>dependencies</span><span>:</span></span>
<span id="cb5-16"><span>      </span><span>-</span><span> records</span></span>
<span id="cb5-17"><span>      </span><span>-</span><span> optics</span></span></code></pre></div>
<ol start="2" type="1">
<li>Use <code>optics-th</code> to generate optics labels for each field with the <code>noPrefixFieldLabels</code> option.</li>
</ol>
<p>That means your data types will now look like:</p>
<div id="cb6"><pre><code><span id="cb6-1"><span>data</span> <span>Person</span> <span>=</span> <span>Person</span> {<span>name ::</span> <span>String</span>,<span> age ::</span> <span>Int</span>}</span>
<span id="cb6-2">makeFieldLabelsWith noPrefixFieldLabels '<span>'Person</span></span></code></pre></div>
<ol start="3" type="1">
<li>Start writing more ergonomic Haskell with better records now!</li>
</ol>
<p>Here’s our end result, more Ergonomic Haskell with records:</p>
<div id="cb7"><pre><code><span id="cb7-1"><span>if</span> person <span>^.</span> <span>#</span>name <span>==</span> <span>"codygman"</span></span>
<span id="cb7-2">  <span>then</span> <span>do</span></span>
<span id="cb7-3">    <span>putStrLn</span> <span>$</span> <span>"Good day, "</span> <span>++</span> person <span>^.</span> <span>#</span>name</span>
<span id="cb7-4">    <span>putStrLn</span> <span>$</span> <span>"Your dog's name: "</span> <span>++</span> dog <span>^.</span> <span>#</span>name</span>
<span id="cb7-5">    <span>putStrLn</span> <span>$</span> <span>"Your cat's name: "</span> <span>++</span> cat <span>^.</span> <span>#</span>name</span>
<span id="cb7-6">    <span>if</span> cat <span>^.</span> favoriteBall <span>%</span> name <span>==</span> <span>"doggos"</span></span>
<span id="cb7-7">      <span>then</span> <span>do</span></span>
<span id="cb7-8">        <span>putStrLn</span> <span>"One second.. there's been a mix up it seems!"</span></span>
<span id="cb7-9">        <span>let</span> fixedCat <span>=</span></span>
<span id="cb7-10">              cat <span>&amp;</span> <span>#</span>favoriteBall <span>%</span> <span>#</span>name <span>.~</span> <span>"cattos"</span></span>
<span id="cb7-11">                  <span>&amp;</span> <span>#</span>favoriteBall <span>%</span> <span>#</span>ballType <span>.~</span> <span>"yarn ball"</span></span>
<span id="cb7-12">        <span>putStrLn</span> <span>$</span> <span>"Your cat's favorite ball type: "</span> <span>++</span> fixedCat <span>^.</span> <span>#</span>name</span>
<span id="cb7-13">      <span>else</span> <span>putStrLn</span> <span>$</span> <span>"Your cat's name: "</span> <span>++</span> cat <span>^.</span> <span>#</span>name</span>
<span id="cb7-14">  <span>else</span> <span>putStrLn</span> <span>"THIS IS MY PROGRAM! I DON'T KNOW YOU! *KICK*"</span></span></code></pre></div>
<h2 id="runnable-source-code">Runnable source code</h2>
<p>You can also clone the repo <a href="https://github.com/codygman/ergonomic-haskell">here</a> and navigate to the records directory.</p>

<div id="cb8"><pre><code><span id="cb8-1"><span>module</span> <span>Main</span> <span>where</span></span>
<span id="cb8-2"></span>
<span id="cb8-3"><span>import</span> <span>Lib</span></span>
<span id="cb8-4"><span>import</span> <span>Optics</span></span>
<span id="cb8-5"><span>import</span> <span>Optics.TH</span></span>
<span id="cb8-6"></span>
<span id="cb8-7"><span>data</span> <span>Person</span> <span>=</span> <span>Person</span> {<span> name ::</span> <span>String</span>,<span> age ::</span> <span>Int</span>}</span>
<span id="cb8-8"></span>
<span id="cb8-9">makeFieldLabelsWith noPrefixFieldLabels '<span>'Person</span></span>
<span id="cb8-10"></span>
<span id="cb8-11"><span>data</span> <span>Dog</span> <span>=</span> <span>Dog</span> {<span>name ::</span> <span>String</span>,<span> age ::</span> <span>Int</span>}</span>
<span id="cb8-12"></span>
<span id="cb8-13">makeFieldLabelsWith noPrefixFieldLabels '<span>'Dog</span></span>
<span id="cb8-14"></span>
<span id="cb8-15"><span>data</span> <span>CatBall</span> <span>=</span> <span>CatBall</span> {<span> name ::</span> <span>String</span>,<span> type_ ::</span> <span>String</span>}</span>
<span id="cb8-16"></span>
<span id="cb8-17">makeFieldLabelsWith noPrefixFieldLabels '<span>'CatBall</span></span>
<span id="cb8-18"></span>
<span id="cb8-19"><span>data</span> <span>Cat</span> <span>=</span> <span>Cat</span> {<span> name ::</span> <span>String</span>,<span> age ::</span> <span>Int</span>,<span> favoriteBall ::</span> <span>CatBall</span>}</span>
<span id="cb8-20"></span>
<span id="cb8-21">makeFieldLabelsWith noPrefixFieldLabels '<span>'Cat</span></span>
<span id="cb8-22"></span>
<span id="cb8-23"><span>main ::</span> <span>IO</span> ()</span>
<span id="cb8-24">main <span>=</span></span>
<span id="cb8-25">  <span>let</span> person <span>=</span> <span>Person</span> <span>"codygman"</span> <span>1000</span></span>
<span id="cb8-26">      dog <span>=</span> <span>Dog</span> <span>"doggo"</span> <span>5</span></span>
<span id="cb8-27">      cat <span>=</span> <span>Cat</span> <span>"doggo"</span> <span>5</span> (<span>CatBall</span> <span>"doggos"</span> <span>"tennis ball"</span>)</span>
<span id="cb8-28">   <span>in</span> <span>do</span></span>
<span id="cb8-29">      <span>if</span> person <span>^.</span> <span>#</span>name <span>==</span> <span>"codygman"</span></span>
<span id="cb8-30">          <span>then</span> <span>do</span></span>
<span id="cb8-31">            <span>putStrLn</span> <span>$</span> <span>"Good day, "</span> <span>++</span> person <span>^.</span> <span>#</span>name</span>
<span id="cb8-32">            <span>putStrLn</span> <span>$</span> <span>"Your dog's name: "</span> <span>++</span> dog <span>^.</span> <span>#</span>name</span>
<span id="cb8-33">            <span>putStrLn</span> <span>$</span> <span>"Your cat's name: "</span> <span>++</span> cat <span>^.</span> <span>#</span>name</span>
<span id="cb8-34">            <span>if</span> cat <span>^.</span> <span>#</span>favoriteBall <span>%</span> <span>#</span>name <span>==</span> <span>"doggos"</span></span>
<span id="cb8-35">              <span>then</span> <span>do</span></span>
<span id="cb8-36">                <span>putStrLn</span> <span>"One second.. there's been a mix up it seems!"</span></span>
<span id="cb8-37">                <span>let</span> fixedCat <span>=</span></span>
<span id="cb8-38">                      cat <span>&amp;</span> <span>#</span>favoriteBall <span>%</span> <span>#</span>name <span>.~</span> <span>"cattos"</span></span>
<span id="cb8-39">                          <span>&amp;</span> <span>#</span>favoriteBall <span>%</span> <span>#</span>type_ <span>.~</span> <span>"yarn ball"</span></span>
<span id="cb8-40">                <span>putStrLn</span> <span>$</span> <span>"Your cat's favorite ball type: "</span> <span>++</span> fixedCat <span>^.</span> <span>#</span>name</span>
<span id="cb8-41">              <span>else</span> <span>putStrLn</span> <span>$</span> <span>"Your cat's name: "</span> <span>++</span> cat <span>^.</span> <span>#</span>name</span>
<span id="cb8-42">          <span>else</span> <span>pure</span> ()</span></code></pre></div>

<p>Welcome …</p></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://codygman.dev/posts/2020-09-07-Ergonomic_haskell_1_records.html">https://codygman.dev/posts/2020-09-07-Ergonomic_haskell_1_records.html</a></em></p>]]>
            </description>
            <link>https://codygman.dev/posts/2020-09-07-Ergonomic_haskell_1_records.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24439204</guid>
            <pubDate>Fri, 11 Sep 2020 04:30:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Create Better WooCommerce Product Pages]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24439095">thread link</a>) | @retrofeel
<br/>
September 10, 2020 | https://www.wpquestions.org/4-ways-to-create-better-woocommerce-product-pages/ | <a href="https://web.archive.org/web/*/https://www.wpquestions.org/4-ways-to-create-better-woocommerce-product-pages/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.wpquestions.org/4-ways-to-create-better-woocommerce-product-pages/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24439095</guid>
            <pubDate>Fri, 11 Sep 2020 04:04:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Giggle; Laughable Security]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24438766">thread link</a>) | @davidbarker
<br/>
September 10, 2020 | https://research.digitalinterruption.com/2020/09/10/giggle-laughable-security/# | <a href="https://web.archive.org/web/*/https://research.digitalinterruption.com/2020/09/10/giggle-laughable-security/#">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Preface: There is very little in this blog post that is interesting from a technical perspective. The discovered vulnerability is incredibly basic but fairly high risk. Due to the nature of the application, and the fallout from our disclosure attempt, we wanted to write up our findings. The TL;DR is that giggle has been exposing user’s phone numbers, private images and location to the world.</p>

<p>Normally we wouldn’t post a vulnerability like this so soon after discovering it but the owner of the app refuses to listen to us and continuously claims no vulnerability exists. We tried to get in contact with her via a third party (after we had been blocked) to let her read this post before publishing it but, again, she showed no interest.</p>

<p>(edit: We wrote but didn’t publish this article before the vulnerability was fixed. Giggle has told us it has now been fixed so we feel comfortable releasing these details.)</p>

<p>(edit2: Sall is threating us with legal action.)</p>

<p>(edit3: We’ve had some questions about the phrasing in the first public tweet. We standby our words. Not knowing how this would play out, we wanted to make it clear that we didn’t support the app or the founder, but wanted to report the issue. Companies can be unpredictable when reporting vulnerabilities and we wanted to avoid a situation where they would be publicly praising us or even mentioning us on their website etc.)</p>

<p>(edit4: An apology from Giggle has been made and no futher legal action will be taken)</p>

<hr>

<h3 id="what-is-giggle">What is Giggle?</h3>

<p>This week I set up an account on an app called giggle. You see, last month I had been diagnosed with premature menopause I and wanted to find a safe space in a woman centric environment. Somewhere I could talk openly about this experience and maybe get some support, but also find some light hearted way to socialise online.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image1.jpeg.resize.jpeg" alt=""></p>

<p>Without much investigation I found giggle, which seemed to check all the boxes. A free app, promoting safe and secure social networking. Giggle promised a refuge from misogyny and sexism where I could find support and community.</p>

<p>There were a few red flags, such as an excessive use of pink and word “females”, but I decided to give it a go.</p>

<p>At this point the red flags became a little more crimson. Firstly, I was asked to submit my phone number so that a verification code could be sent to my mobile. Then I was asked to allow the app to access my camera so that a selfie of me could be submitted to verify I was female. This verification, apparently, is done using AI. From previous work done on this, we know this can often be notorious for mischaracterising and therefore excluding certain racial groups, some trans women and some masculine looking women.</p>

<p>The app assured me that my verification picture would not be stored so not to worry about what I looked like, so my gargoylesq visage was submitted (I’ll get to the later) and I was duly approved to enter the app.</p>

<p>I went to set up my profile to see what information was publicly available about me, even if only in the app, to find there wasn’t one and I had to set up multiple profiles or ‘giggles’ to start a tinder like experience on each specific subject I was interested in (I chose menopause, body image, hiking and wine tasting), that range from socialising and hobbies to more high risk areas such as abuse and sex work.</p>

<p>As I was curious how secure my data was, and as we are currently working on improvements to <a href="https://rex.digitalinterruption.com/">REX</a> (and thought they’d maybe like a <a href="https://www.digitalinterruption.com/100-free-rex-licences">free license</a>), we decided to dig a little deeper.</p>

<h3 id="viewing-account-details">Viewing Account Details</h3>

<p>Using BurpSuite and a fresh install of the app, we intercepted the network traffic and found a few interesting things that we decided not to look at further as we didn’t have permission to do a full analysis. During the registration process, as mentioned, users are required to verify a phone number and selfie. We submitted a selfie that wouldn’t pass and, unsurprisingly, couldn’t gain access to giggle.</p>

<p>Looking at the network requests revealed that although the account was in an unvalidated state, we still had a valid auth token (it turns out this is hardcoded into the application) allowing us to make requests to the API. Again, we didn’t perform a full analysis although we suspect issues could exist here. What we did look at was the UserList endpoint. This contained a filter parameter that contained my phone number, an operator (in this case “equals”) and a field (“mobile”). Presumably, this is how a user’s account details are fetched from the API.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image2.png.resize.png" alt=""></p>

<p>Of course, the obvious question is what would happen if we changed this filter parameter to be another phone number, changed the query to filter on another parameter such as user ID or user’s name or even would it remove the filter altogether, allowing us to view all accounts?</p>

<p>First, we decided to change the filter query so it would filter based on the GUID of the original account which we received during our initial analysis. This brought back the original account details which included the user’s phone number, age (which was set to hidden) and a latitude and longitude.</p>

<p>Request:</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image3.png.resize.png" alt=""></p>

<p>Response:</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image4.png.resize.png" alt=""></p>

<p>Having the phone number is bad enough, but we checked the returned latitude and longitude using Google Maps. Of course, this brought us to the very house I created the account in.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image5.png.resize.png" alt=""></p>

<p>This means an attacker that is completely unverified to the application can view the address and phone number of all users if they have the account ID. That is pretty bad in our opinion.</p>

<p>Next, we wanted to be able to download the same details without knowing the account ID. Looking at the filter parameter, it’s clear to see there would be many ways to do this. We could remove the filter completely although that would reveal other accounts to us which we were trying to avoid seeing or we could change the query to show all accounts not matching a phone number. As a proof of concept, we decided to change the operator field from “equals” to “contains” and truncated the GUID. As this returned the same data, it should be obvious to see how the query could be trivially modified to expose all registered accounts with no prerequisite account knowledge.</p>

<p>Request:</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image6.png.resize.png" alt="Burp Web Request"></p>

<h3 id="selfies">Selfies!</h3>

<p>What about the supposed private picture that is used to verify accounts? They claim not to store? Behold my gargoylesq visage!</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image7.png.resize.png" alt=""></p>

<p>If we look at the URL of the verification image (which we recovered by viewing network traffic in BurpSuite), we can see that the only thing that is required is the user GUID. As we can view the user GUID for every account (e.g. our test account) we can easily download the associated verification selfie. Although this is not terrible on it’s own, giggle do promise that this isn’t shared or published, and, given that it is available data stored along side my mobile number and geographical coordinates, with this information an attacker would know my address, my personal mobile number and what I look like.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image8.jpeg.resize.jpeg" alt=""></p>

<p>This is where we get to the really scary bit. Giggle has sections encouraging women to find support on abortion, abuse, addiction and relationships among other categories. The amount of available data means that with a phone number or name, an abusive partner would potentially be able to find the location of an abused woman and confirm her identity with the verification picture. There is also a section for sex workers, who, understandably would expect any app enabling them to advertise their work to have adequate privacy and security controls. Even if a user deletes their account, that data appears to still be saved by giggle.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image13.jpeg" alt=""></p>

<h3 id="account-deletion">Account Deletion</h3>

<p>The final thing we looked at is whether a deleted account is actually deleted. We deleted the original account using the “Delete Account” button and tried to view the associated account details.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image9.jpeg.resize.jpeg" alt=""></p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image10.png.resize.png" alt=""></p>

<p>Of course, they are still present and only set to Disabled meaning they are still stored by the system. Maybe accounts are deleted periodically. We would normally at this point reach out to the vendor and ask for clarification. This leads us to the next part of the story…</p>

<h3 id="disclosure">Disclosure</h3>

<p>We wanted to let giggle know that this vuln existed and ask for some further details, not in the small part because it is so easy to exploit. In the midst of this we had done some digging on the origins of the app and found that the founder had a very public anti-trans agenda. However, much as this sickens us, our job is to protect users so we direct messaged giggle through twitter.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image11.png.resize.png" alt=""></p>

<p>Having had no response, we decided to send them a tweet asking them to check their DMs with their founder cc’d in, but with a caveat that we do not share or endorse her anti-trans views.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image12.png.resize.png" alt=""></p>

<p>That’s when we were dragged into a full on TERF War.</p>

<p>Our public tweet had no engagement at all until Sall, the giggle founder, decided to share a screenshot of it with her followers. We have since been subject to a tirade of abuse. None of it about the security of the app. Interested parties are free to view our twitter and find the hundreds and hundreds of tweets in response to trying to disclose this vulnerability but we decided not to copy that into this post.</p>

<p>Our founders have reached out to giggle and Sall and have been blocked following every attempt at contact. Our three year incorporated company has been accused of being a creepy bloke who runs private WhatsApp groups full of naked women, a front for the alt-left, making up the vuln to discredit Sall and her company and hypocrites for wanting to protect the data of users despite the apps founder having view that counter our own.</p>

<p>Our company and I (a woman) have been accused of being a man, and therefore a misogynist multiple times. We have been told that as men (60% of Digital Interruption are women), we should not have a say on the safety of women and their personal data.</p>

<p>Sadly, denial is not uncommon when trying to disclose. We are used to being ignored and even getting some pushback, but ultimately we feel it is our responsibility to persist and ensure the …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://research.digitalinterruption.com/2020/09/10/giggle-laughable-security/#">https://research.digitalinterruption.com/2020/09/10/giggle-laughable-security/#</a></em></p>]]>
            </description>
            <link>https://research.digitalinterruption.com/2020/09/10/giggle-laughable-security/#</link>
            <guid isPermaLink="false">hacker-news-small-sites-24438766</guid>
            <pubDate>Fri, 11 Sep 2020 03:04:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Low-tech air filter for bad air quality emergencies]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24438653">thread link</a>) | @CalChris
<br/>
September 10, 2020 | https://techsparx.com/blog/2018/11/ghetto-air-filter.html | <a href="https://web.archive.org/web/*/https://techsparx.com/blog/2018/11/ghetto-air-filter.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <nav aria-label="breadcrumb" id="breadcrumbTrail">
    <ol>
     <li> <a href="https://techsparx.com/index.html">TechSparx</a> </li> <li> <a href="https://techsparx.com/blog/index.html">Blog Index</a> </li> <li> <a href="https://techsparx.com/blog/2018/index.html">Blog Index for 2018</a> </li> <li> <a href="https://techsparx.com/blog/2018/11/index.html">Blog Index for November 2018</a> </li> <li> <a href="https://techsparx.com/blog/2018/11/ghetto-air-filter.html">Low-tech air filter for bad air quality emergencies</a> </li>
    </ol>
</nav>

      <p><small>
;
    Date: November 16, 2018
</small></p>
      <p>Tags: <span>
     <a href="https://techsparx.com/tags/air-quality.html">Air Quality</a>  »»»»  <a href="https://techsparx.com/tags/air-filters.html">Air Filters</a>  »»»»  <a href="https://techsparx.com/tags/climate-change.html">Climate Change</a> 
</span></p>
      <p>This week the SF Bay Area is suffering from yet another massive wildfire filling our air with smoke, causing unhealthy air conditions.  The Camp Fire sprang up on November 8, 2018, and destroyed Paradise California, a town in the Sierra Nevada Mountains.  While there is a serious tragedy happening in the zone directly affected by the fire, a large chunk of California now has unhealthy air.  Further, officials are predicting unhealthy air conditions will remain in place for another week.  "Unhealthy" is the designation by the Environmental Protection Agency (EPA) for air conditions we currently have.  The situation does not warrant spending hundreds of dollars on a fancy air filter system that will be used only for a few days.  Fortunately there is a lower cost easy-to-implement solution.</p> 

      
    <figure>
        <img src="https://techsparx.com/blog/2018/11/img/fr_4054.jpg">
        
    </figure>
    

      
<!-- adsense-top -->
<p>This solution came thanks to a friend who suggested, via Facebook, that a 20x20 inch box fan plus an AC Filter would work to clean the air.</p>
<p>Just how bad is the air at the moment?</p>
<figure>
        
        <img src="https://techsparx.com/blog/2018/11/img/air-quality-monitoring.jpg">
        
        
</figure>

<p>As I <a href="https://techsparx.com/blog/2018/11/air-quality-monitoring.html">noted in an earlier posting today</a>, I have a portable air quality monitor widget.  This shows just how bad the air is, and today the readings are the worst I've seen since this fire situation began.  Most of the year the reading for PM2.5 is in the teens, but today it is squarely in the region of unhealthy air.  And, the local air quality officials predict air quality over the next few days will keep worsening.  As I write this the Camp Fire is only 30-40% contained, FWIW.</p>
<p>That means over the next few days health dictates taking some kind of action.  I considered driving south and staying in a hotel room, but for how long?  And, I cannot afford to take such a trip.  Staying indoors means having air that is less unhealthy than the outside air, but who wants to stay cooped up all the time?</p>
<p>There are filter units meant to clean the air, and are vital for those with sensitivity to dust or mold or other environmental contaminants.  I haven't looked at the price of such filter units, but am expecting them to cost hundreds of dollars and that I only need the thing for a few days.</p>
<p>When going out of the house, a face mask is recommended.  I happen to have some face masks around, and do not have any recommendations of the best face mask to handle extreme air pollution like this.</p>
<p>At home a less expensive easy to implement air filter system is exactly what my friend recommended -- a fan, with an AC Filter strapped to the front.</p>
<p>After a trip to Home Depot, I came up with the implementation pictured above.  I don't have a 20x20 box fan, so I got a smaller filter that fits on the fan that I do have.  Namely a 14x20 filter, as you can see in the picture.  Using a few bungee cords to hold it in place, and you've got a nice simple solution.</p>
<p>There are many kinds of AC Filters with different levels of filtration.</p>
<figure>
        
        <img src="https://techsparx.com/blog/2018/11/img/fr_4055.jpg">
        
        
</figure>

<p>What I got is a Filter where the labeling claimed the highest level of filtration.  Cost - about $20.  I'll leave this running 24/7 until the smoke clears from the fires.</p>

      



      <div>

    <h3>About the Author(s)</h3>

    
            <p><a href="https://techsparx.com/about.html"><img src="https://techsparx.com/img/headshot-new.jpg"></a>
            <strong>
            <a href="https://techsparx.com/about.html">David Herron</a>
            </strong>: <span>
            David Herron is a writer and software engineer focusing on the wise use of technology.  He is especially interested in clean energy technologies like solar power, wind power, and electric cars.  David worked for nearly 30 years in Silicon Valley on software ranging from electronic mail systems, to video streaming, to the Java programming language, and has published several books on Node.js programming and electric vehicles.
            </span>
            
</p></div>

      
      
      <p><a href="https://click.linksynergy.com/fs-bin/click?id=PPTIpcZ17qI&amp;offerid=507388.1387&amp;subid=0&amp;type=4" rel="nofollow" target="_blank">
            <img src="https://techsparx.com/imgz/udemy/39197_1387.png">
            </a>
    </p>

      



    </div></div>]]>
            </description>
            <link>https://techsparx.com/blog/2018/11/ghetto-air-filter.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24438653</guid>
            <pubDate>Fri, 11 Sep 2020 02:40:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don DeLillo: The Word, the Image, and the Gun (2013)]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24438607">thread link</a>) | @benbreen
<br/>
September 10, 2020 | http://perival.com/delillo/ddbbc.html | <a href="https://web.archive.org/web/*/http://perival.com/delillo/ddbbc.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<p>On September 27, 1991 BBC 1 broadcast a film on Don DeLillo,
titled "Don DeLillo: The Word, The Image, and The Gun"
which was directed by Kim Evans. As of October 2013 the film has been
put up on YouTube - <a href="https://www.youtube.com/watch?v=0DTePKA1wgc#t=14" target="BLANK">here's the link</a>.</p>

<center><img src="http://perival.com/delillo/ddbbc_title.jpg" naturalsizeflag="3"></center>

<p>The film is introduced as follows:</p>

<blockquote>
  <p>Don DeLillo writes dangerous fiction.</p>
  <p>He's been called America's leading contemporary novelist,
  and his ten novels come directly out of the flow of recent history.
  The Kennedy assassination, toxic fallout, acts of terrorism;
  these are all part of the running picture of news against which
  his books are set.</p>
  <p>This film was developed in close collaboration with DeLillo.
  He wanted to use the documentary form to explore the relationships
  between gunmen and the novelist, words and images, the power
  of news and the obsession with apocalypse. In doing so he asks,
  what effect can a novelist have on a culture in which terrorists
  seem to have hijacked the world's narrative.</p></blockquote>

<p>We then hear a bit of a broadcaster describing the Kennedys
as they move through Dallas, then a short passage from <i>Libra</i>.
DeLillo begins to speak:</p>

<center><img src="http://perival.com/delillo/ddbbc_delillo_at_window.jpg" naturalsizeflag="3"></center>

<blockquote>
  <p>Isolation, solitude, secret plotting. A novel is a secret
  a writer may keep for years before he lets it out of his room.
  Writers in hiding, writers in prison. Sometimes their secrets
  turn out to be dangerous to the state machine. For most writers
  in the West of course this danger is extremely remote. The cells
  we live in are strictly personal constructions.</p>
  <p>Let's change the room slightly and imagine another kind of
  apartness. The outsider who builds a plot around his desperation.
  A self-watcher, a lonely young man, living in a fiction he hasn't
  bothered to put down on paper. But this doesn't mean he is unorganized,
  he organizes everything. This is how he keeps from disappearing.
  His head is filled with dangerous secrets, and he may finally
  devise a way to come out of his room. He invents a false name,
  orders a gun though the mail, then looks around for someone famous
  he can shoot.</p></blockquote>
  
<center><img src="http://perival.com/delillo/ddbbc_at_typewriter.jpg" naturalsizeflag="3"></center>
  
<p>DeLillo at 5:20: "I think it's true that none of my novels could have been written in the world that
existed before the assassination.
In my fiction there seems to be a sense
of danger everywhere, of something unraveling.
  When Kennedy was shot, something changed for ever in America. Something opened up, a sense
  of randomness, deep ambiguity, we lost the narrative thread."
  
</p><center><img src="http://perival.com/delillo/ddbbc_suddenly.jpg" naturalsizeflag="3"></center>

<p>From <i>Libra</i> at 15:10: The first movie was <i>Suddenly</i>. Frank Sinatra is a combat veteran
who comes to a small town and takes over a house that overlooks the railwroad depot.
He is here to assassinate the President. (p. 369 in pbk)

</p><center><img src="http://perival.com/delillo/ddbbc_suddenly_on_oswald.jpg" naturalsizeflag="3"></center>

<p>From <i>Libra</i>: Lee felt a stillness around him. He had an eerie sense he was being
watched for his reaction. He felt connected to the events on the screen. It was like secret instructions
entering the network of signals and broadcast bands, the whole busy air of transmission. 
Marina was asleep. They were running a message through the night into his skin. 

</p><center><img src="http://perival.com/delillo/ddbbc_watching_oswald_11-53.jpg" naturalsizeflag="3"></center>

DeLillo at 18:22: "Maybe I'm wrong about this, but I think the footage comes close to uncovering some secret about
the nature of film itself. Film carries something, some mindstream, some myth that may be common to us all. It's as though
the experience of film has acquired a kind of independent existence in 
our consciousness, it's that deeply embedded. Have to get it on film."

<center><img src="http://perival.com/delillo/ddbbc_men_on_wing.jpg" naturalsizeflag="3"></center>

DeLillo at 26:40: "With widespread political terrorism we got our narrative back, calculated acts, not random."

<center><img src="http://perival.com/delillo/ddbbc_3_planes.jpg" naturalsizeflag="3"></center>

<center><img src="http://perival.com/delillo/ddbbc_bill_gray_maoii.jpg" naturalsizeflag="3"></center>

From <i>Mao II</i> at 28:45: Bill Gray: "Years ago I used to think it was possible for novelists to alter the life of the culture, 
but now bombmakers and gunmen have taken over that territory.  They make raids on human consciousness, what writers 
used to do, before we were all incorporated."

<center><img src="http://perival.com/delillo/ddbbc_nypost_catcher.jpg" naturalsizeflag="3"></center>

DeLillo at 35:12: "Ordering a photograph of a famous recluse must be a little like ordering an execution. Salinger
resembles a man who's fighting for his life."

<center><img src="http://perival.com/delillo/ddbbc_football_crowd.jpg" naturalsizeflag="3"></center>

<p>Tragedy at Hillsborough England (41:25) - 15 April 1989

</p><p>DeLillo at 40:54 : "Today it's news that has begun to influence the way we see the world. It's news that has
become so extraordinarily dominant. I think we've come to depend on news, the darker the better. In a way we need it, 
because it is the tragic narrative of our time." 

</p><center><img src="http://perival.com/delillo/ddbbc_watching_oswald_48-11.jpg" naturalsizeflag="3"></center>

<hr>Here's how <i>The Times</i> listed the program
(Sept 27, 1991):

<blockquote>
  <p>Kim Evan's filmed essay about an American novelist who is
  obsessed by violent images and what they can do to the soul of
  a 20th century culture like his, is dazzlingly, nay blindingly,
  assembled. The camera assumes an adversarial role. It is as much
  a weapon as the guns that feature so strongly in DeLillo's writing.
  Therefore, there are two ways of interpreting it when we talk
  of Evan's scenes being shot. More than one viewing of this film
  will be necessary for those viewers who simply can't keep up
  with what DeLillo is thinking, writing and seeing. It takes time
  to digest statments like "Stalking a victim is a way of
  organizing one's loneliness, making a network out of it"
  or "I knew I must extend myself until the molecules parted
  and I was spliced into the image." In his book <i>Mao II</i>,
  a character says "Keep it simple." Was DeLillo paying
  attention at the time?</p></blockquote>

<hr>
Back to <a href="http://perival.com/delillo/delillo.html">DeLillo's America</a>.
<hr>

<address>Last updated: 23-NOV-2013<br>
</address>



</div>]]>
            </description>
            <link>http://perival.com/delillo/ddbbc.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24438607</guid>
            <pubDate>Fri, 11 Sep 2020 02:30:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Great Classical Books by Legendary Scientists and Mathematicians]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24438605">thread link</a>) | @alikayaspor
<br/>
September 10, 2020 | https://abakcus.com/15-great-classical-books-by-legendary-scientists-and-mathematicians/ | <a href="https://web.archive.org/web/*/https://abakcus.com/15-great-classical-books-by-legendary-scientists-and-mathematicians/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<div>
<div id="primary">
<main id="main">
<div data-elementor-type="single" data-elementor-id="3413" data-elementor-settings="[]">
<div>
<section data-id="63154cf" data-element_type="section">
<div>
<div>
<div data-id="811458f" data-element_type="column">
<div>
<div>
<div data-id="5c50288" data-element_type="widget" data-widget_type="ee-breadcrumbs.default">
<div>
<ul itemscope="" itemtype="http://schema.org/BreadcrumbList"><li itemprop="itemListElement" itemscope="" itemtype="http://schema.org/ListItem">
<a href="https://abakcus.com/" itemprop="item">
<span itemprop="name">
Home </span>
</a>
<meta content="0" itemprop="position">
</li><li><span></span></li><li itemprop="itemListElement" itemscope="" itemtype="http://schema.org/ListItem">
<a href="https://abakcus.com/" itemprop="item">
<span itemprop="name">
Posts </span>
</a>
<meta content="1" itemprop="position">
</li><li><span></span></li><li itemprop="itemListElement" itemscope="" itemtype="http://schema.org/ListItem">

<span itemprop="name">
15+ Great Classical Books By Legendary Scientists and Mathematicians </span>

<meta content="2" itemprop="position">
</li></ul> </div>
</div>

<div data-id="2c83e7d" data-element_type="widget" data-widget_type="theme-post-content.default">
<div>
<p>From Primo Levi and Einstein to Feynman and Euclid, we curated twenty-five excellent books written by world-famous scientists. These are legendary texts, popular science explainers, personal memoirs, and controversial new theories, and they’re all enduring monuments to the power of science.</p>


</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="6fd4db4" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
<div>
<div>
<div data-id="dfe5e35" data-element_type="column">
<div>
<div>
<div data-id="570e0b3" data-element_type="widget" data-widget_type="heading.default">
<p>
<h2>Similar Curated Directories</h2> </p>
</div>
<div data-id="c24adbb" data-element_type="widget" data-settings="{&quot;classic_grid_columns_spacing&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;size&quot;:50,&quot;sizes&quot;:[]},&quot;classic_grid_columns_spacing_tablet&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;size&quot;:50,&quot;sizes&quot;:[]},&quot;classic_grid_columns_spacing_mobile&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;size&quot;:50,&quot;sizes&quot;:[]},&quot;columns&quot;:&quot;3&quot;,&quot;columns_tablet&quot;:&quot;2&quot;,&quot;columns_mobile&quot;:&quot;1&quot;,&quot;classic_layout&quot;:&quot;default&quot;}" data-widget_type="posts-extra.classic">
<div>
<div><div><article><a href="https://abakcus.com/134-awesome-desmos-classroom-activities-to-engage-students-during-class/"><div><picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/134-Awesome-Desmos-Classroom-Activities-to-Engage-Students-During-Class-768x431.png.webp" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%20431'%3E%3C/svg%3E">
<img width="768" height="431" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%20431'%3E%3C/svg%3E" alt="" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/134-Awesome-Desmos-Classroom-Activities-to-Engage-Students-During-Class-768x431.png">
</picture>
</div></a></article></div><div><article><a href="https://abakcus.com/the-best-documentaries-for-making-kids-love-mathematics/"><div><picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/07/The-Best-Documentaries-for-Making-Kids-Love-Mathematics-1-768x723.png.webp" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%20723'%3E%3C/svg%3E">
<img width="768" height="723" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%20723'%3E%3C/svg%3E" alt="" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/07/The-Best-Documentaries-for-Making-Kids-Love-Mathematics-1-768x723.png">
</picture>
</div></a><div><a href="https://abakcus.com/the-best-documentaries-for-making-kids-love-mathematics/" target="_blank">
<h2>The Best Documentaries for Making Kids Love Mathematics</h2>
</a><p>These mathematics documentaries are very “interesting” because they present either actual mathematics, mathematicians, or mathematics history. We want to add this kind of material to attract undergraduates toward mathematics. For…</p></div></article></div><div><article><a href="https://abakcus.com/25-interesting-books-for-math-people-and-designers/"><div><picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/06/S4_Growing-Cryptocurrency-768x676.jpg.webp" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%20676'%3E%3C/svg%3E">
<img width="768" height="676" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%20676'%3E%3C/svg%3E" alt="" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/06/S4_Growing-Cryptocurrency-768x676.jpg">
</picture>
</div></a></article></div><div><article><a href="https://abakcus.com/24-science-fiction-books-that-forecast-the-future/"><div><picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/24-A-History-of-Books-That-Forecast-the-Future-768x676.jpg.webp" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%20676'%3E%3C/svg%3E">
<img width="768" height="676" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%20676'%3E%3C/svg%3E" alt="" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/24-A-History-of-Books-That-Forecast-the-Future-768x676.jpg">
</picture>
</div></a><div><a href="https://abakcus.com/24-science-fiction-books-that-forecast-the-future/" target="_blank">
<h2>24 Science Fiction Books That Forecast the Future</h2>
</a><p>Many past writers have predicted our present society’s facts with a level of detail that seems impossibly accurate. In reality, their imaginations were painting portraits that would eventually be mirrored…</p></div></article></div><div><article><a href="https://abakcus.com/the-best-springer-undergraduate-texts/"><div><picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/06/S4_Education-768x675.jpg.webp" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%20675'%3E%3C/svg%3E">
<img width="768" height="675" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%20675'%3E%3C/svg%3E" alt="" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/06/S4_Education-768x675.jpg">
</picture>
</div></a><div><a href="https://abakcus.com/the-best-springer-undergraduate-texts/" target="_blank">
<h2>The Best of Springer Undergraduate Series</h2>
</a><p>The&nbsp;Springer Undergraduate Series is a&nbsp;series&nbsp;designed for&nbsp;undergraduates&nbsp;in&nbsp;mathematics&nbsp;and the sciences worldwide. From core foundational material to final year topics, SUMS books take a fresh and modern approach.</p></div></article></div><div><article><a href="https://abakcus.com/all-movies-about-math-science/"><div><picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/07/All-Movies-About-Math-Science-768x512.png.webp" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%20512'%3E%3C/svg%3E">
<img width="768" height="512" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%20512'%3E%3C/svg%3E" alt="All Movies About Math &amp; Science" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/07/All-Movies-About-Math-Science-768x512.png">
</picture>
</div></a></article></div></div> </div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
</div>
</div>
</main>
</div>
</div> 
</div></div>]]>
            </description>
            <link>https://abakcus.com/15-great-classical-books-by-legendary-scientists-and-mathematicians/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24438605</guid>
            <pubDate>Fri, 11 Sep 2020 02:30:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to win Kaggle competitions with Anthony Goldbloom]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24438093">thread link</a>) | @sebg
<br/>
September 10, 2020 | https://www.wandb.com/podcast/anthony-goldbloom | <a href="https://web.archive.org/web/*/https://www.wandb.com/podcast/anthony-goldbloom">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Anthony Goldbloom is the founder and CEO of <a href="https://www.kaggle.com/">Kaggle</a>. In 2011 &amp; 2012, Forbes Magazine named Anthony as one of the 30 under 30 in technology. In 2011, Fast Company featured him as one of the innovative thinkers who are changing the future of business. He joins Lukas to talk about his vision for Kaggle, how Kaggle &amp; the competitions have changed over the years, how competitive data science can prepare you for the real world, whether he likes Python or R better – and which jobs we should be worried about losing to AI in the next few decades.</p><p>Follow Anthony on <a href="https://twitter.com/antgoldbloom">Twitter</a>, and watch his <a href="https://www.ted.com/talks/anthony_goldbloom_the_jobs_we_ll_lose_to_machines_and_the_ones_we_won_t">2016 Ted Talk</a>.</p><p>Topics Discussed:<br>0:00 Sneak Peek<br>0:20 Introduction<br>0:45 methods used in kaggle competitions vs mainstream academia<br>2:30 Feature engineering<br>3:55 Kaggle Competitions now vs 10 years ago<br>8:35 Data augmentation strategies<br>10:06 Overfitting in Kaggle Competitions<br>12:53 How to not overfit<br>14:11 Kaggle competitions vs the real world<br>18:15 Getting into ML through Kaggle<br>22:03 Kaggle datasets and kernelss<br>25:48 Favorite under appreciated kernel or dataset<br>28:27 Python &amp; R<br>32:03 Frameworks<br>35:15 2016 Ted talk though the lens of 2020<br>37:54 Reinforcement Learning<br>38:43 What’s the topic in ML that people don’t talk about enough?<br>42:02 Where are the biggest bottlenecks in deploying ML software?</p><p>‍<br></p><p><strong>Lukas: </strong>I remember you were talking about deep learning before I'd really heard about it. You were kinda the first person I knew that was really thinking about it, I think it's because you saw that people were winning Kaggle competitions with new methods that were less mainstream at the time. And I'm kind of wondering if on Kaggle, you're seeing people doing things that you don't think are on the academic mainstream or if you're seeing things that point to what you think could be mainstream production in the next few years.</p><p><strong>Anthony: </strong>It's a good question. I mean, to be honest, the most glaring thing that we see on Kaggle that is not fashionable in academia is that we're still seeing gradient boosting machines do very well on a lot of structured data problems. And there's not a lot of research attention on things like gradient boosting machines now. It begs the question like, have we done everything we can there or is it an area where there is still more that can be done but it's just not the trendy thing? It's hard to get papers published and so it's just not getting the attention. To be honest that's the that's the most glaring difference we see between what is doing well on Kaggle and what is fashionable in the academic literature.</p><p><strong>Lukas: </strong>Well, it's really interesting.</p><p><strong>Anthony: </strong>We are seeing some novel uses of things like BERT and WaveNet being used on forecasting problems. We've seen BERT do really well on chemical informatics type or sorry, problems that have to do with gene sequences and things like that. So we're seeing like use cases, perhaps unknown use cases, for some well-established technologies but I think just the lack of academic focused on these gradient machine algorithms is probably the biggest glaring distinction that we see.</p><p><strong>Lukas: </strong>And so in a structured data competition where gradient boost wins, what are the details that the winners do to win those competitions? Is it still feature engineering or is there other stuff?</p><p><strong>Anthony: </strong>Exactly. And it's finding clever features that other people aren't finding. Perhaps that's it. That's the reason or maybe that's where you could have more academic focus like otherwise to there is no doubt in my mind there are things you could do to automate feature engineering to some extent, and maybe there are some things that companies like Data Robot and h2o are doing when they are baking these recipes. So as an example, you see a date or a time stamp, for instance. That is an incredibly rich field that can become like 70 things, right? Let's say you're doing traffic forecasting, a timestamp can be turned into; Is it rush hour? Is it not rush hour? Is it a weekend? Is it not weekend? Is it summer? Is it winter? Therefore, does it change the probability of rain on a given day or adverse with no snow on the road and things like that? There are definitely things that could be done to automate components or help with some of the heavy lifting and feature engineering. And so, that could be an area of focus or perhaps maybe it's not an academic area, but it's the kinds of things that h2o and Data Robot and companies like that can build into their products.</p><p><strong>Lukas: </strong>Well, that's so interesting. So if you roll back ten years or you took a competition at the start of Kaggle and then you take it out today, how much better do people do? Do they even do better? Do you think you could win? Could you take modern tools and win every competition at the start of Kaggle? I guess my question is, has the feature engineering really improved?</p><p><strong>Anthony: </strong>So the thing when Kaggle first got started, people used to use all sorts of things like support vector machines, self-organizing maps, really a large range of things. The first big development that we saw or the first big contribution I think Kaggle made is we made it very clear that Random Forest was the best algorithm for actually most problems at that time, and then, let's say about 2014, Tianqi Chen at the University of Washington released XGBoost. I think it was always thought that gradient boosting machines should be better, you know. It's a very smart approach to run someway decision trees. They should be better. They're very, very finicky before XGBoost. When Tianqi Chen launched XGBoost, &nbsp;it really took over from Random Forest. I'd say, unlike the difference between deep neural networks on computer vision problems versus Random Forest, the XGBoost increase is not a huge increase, but it was enough. And so, to be honest, unstructured data problems, I think that's probably where most of the software driven improvements have come from. It's probably the case if you took a problem from the early days of Kaggle, that was one with Random Forest and you reran it today, I think you'd get a little bit of a better answer because of the XGBoost. I don't actually think the way people are doing feature engineering has really improved very much. However, I do think that you would get.. What we always say is that Kaggle competitions, typically, you know, the top teams all converge on about the same level of accuracy and the intuition there is there's only so much signal in a dataset, right? And so people compete to the point where they've extracted all the signal. So I believe in the early Kaggle competitions, people always found that the key features and they got all the signal out of the dataset. I think what might happen is it had happened a fair bit faster now. If you think of professional athletes, they do a lot of training, Kaggle's communities are over five million people now. The people at the top are.. It's just like gone from more of an amateur sport to more of a professional sport, right? And so I think the difference isn't that the results would be better, but the top performers now would get to those results faster interestingly is my guess. Definitely. We ran a challenge with Pete Warden who's now at Google. He was running a company called Jetback and I think it was to distinguish competition between cats versus dogs and I think we did that, if I remember correctly, we did that before deep neural networks and afterwards and obviously saw a fairly big lift. We ran a challenge with the Allen Institute for Artificial Intelligence on solving an eighth grade science quiz. This was before the BERT innovations. People were getting about 60% accuracy using information retrieval methods. Allen have now run BERT-wide solutions on it. They're getting about 90%. So you definitely see... The before Deep Learning and after Deep Learning, you see very large changes in results for sure.</p><p><strong>Lukas: </strong>And I would think that on some unstructured data like language models and things would really make a big difference, right?</p><p><strong>Anthony: </strong>Yeah. I mean so you definitely have structured data where you have fields that are text fields, et cetera, et cetera. And so maybe you use language models to create features that ultimately go into.. I mean, that's a common strategy. We run multimodel competitions sometimes where you have images and someone will run a convolutional neural network in order to come out with features out of that image, that then get fed into a gradient boosting machine classifier. So that definitely happened. And so just as it gets done.. For images that might be part of a multimodel dataset, of course, it can happen as well when there are columns that are text or data sources for a challenge that are text.</p><p><strong>Lukas: </strong>Are there interesting data augmentation strategies that you see people using? I feel like often people talk about that as a major area of innovation, and so do you see that on Kaggle?</p><p><strong>Anthony: </strong>There's a couple of ways people win Kaggle competitions. In the world of structured data problems, it's clever feature engineering. It's very often that, let's say for natural language processing or for computer vision problems, it's clever data augmentation that wins competitions. And some of my favorite example is the Kaggle community is really creative. I remember I think it was with Quora, we did a challenge around detecting insincere questions. I think that was the challenge and the winning strategy there or the thing that the winners did that others didn't do is that would translate the question from English to some other language and then translate it back, because if you use Google Translate, it's not a symmetrical translation, right? And so it was like a clever way to augment that dataset. So there are the standard techniques, you know, rotating, et cetera, for images. But then there are clever, creative tricks like that translation lap. There have also been a bunch of, you know, one of the libraries that has really taken off on Kaggle, I think was written by a Kaggle master. It's called …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.wandb.com/podcast/anthony-goldbloom">https://www.wandb.com/podcast/anthony-goldbloom</a></em></p>]]>
            </description>
            <link>https://www.wandb.com/podcast/anthony-goldbloom</link>
            <guid isPermaLink="false">hacker-news-small-sites-24438093</guid>
            <pubDate>Fri, 11 Sep 2020 00:43:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Swiss law reforms make crypto respectable]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24437929">thread link</a>) | @chanfest22
<br/>
September 10, 2020 | https://www.swissinfo.ch/eng/business/swiss-law-reforms-make-crypto-respectable/46024124 | <a href="https://web.archive.org/web/*/https://www.swissinfo.ch/eng/business/swiss-law-reforms-make-crypto-respectable/46024124">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<section>
<div>
<div>
<figure>
<picture>
<source srcset="https://www.swissinfo.ch/resource/image/46024148/landscape_ratio3x2/880/587/c66bb738ad42a3a49c1bb7e8f6bb32fd/UE/bitcoinbuy.jpg" media="(min-width: 900px)">
<source srcset="https://www.swissinfo.ch/resource/image/46024148/landscape_ratio3x2/580/387/c66bb738ad42a3a49c1bb7e8f6bb32fd/Jr/bitcoinbuy.jpg" media="(min-width: 321px)">

</picture>
<figcaption>
Simply buying bitcoin does not require a law change but legislation needs to keep up with a host of blockchain developments in finance and the way companies operate. <span>© Keystone / Christian Beutler</span>
</figcaption> </figure>
</div>
</div><p>Bitcoin used to be something of a dirty word, associated with crime and money laundering. Switzerland has now amended its legal code to welcome cryptocurrencies and blockchain technology into the mainstream.</p>
<span>This content was published on September 10, 2020 - 11:00</span>
<time datetime="2020-09-10T11:00:00+02:00">

</time><address data-uk-scrollspy="hidden: false; repeat: true; offset-top: -50">

 <p>
swissinfo.ch
</p>
</address><p>Parliamentarians in the Senate rapidly passed a wide-ranging set of financial and corporate law reforms on Thursday. The so-called “Blockchain Act” had sailed through the House of Representatives unopposed in the summer, meaning the law will likely come into effect early next year.</p><p>The legislation could open the doors not just to decentralised finance but also the creation of digital company shares and a range of other tradeable assets.</p><p>Several existing laws have been updated, ranging from company bankruptcy to securities trading. Neighbouring Liechtenstein has already enacted extensive blockchain legislation, but it chose to create new laws rather than amend the current code.</p><p>The growing Swiss blockchain industry has welcomed the legislation. “As of next year, Switzerland will have a regulatory framework that is among the most advanced in the world,” said Heinz Tännler, President of the Swiss Blockchain Federation.</p>
<div>
<article>
<span>External Content</span>
<div>

<div id="mc_embed_signup">
<p>Sign up! Insight on Swiss blockchain and fintech innovation</p>

</div>


<!--End mc_embed_signup--><h3>Newsletter subscription for for Fintech</h3> </div>
</article></div>
<p>Some 900 blockchain companies, employing around 4,700 staff, have sprung up in “Crypto Nation” Switzerland in the last few years. These include crypto banks, asset managers, real estate ventures, alpine cryptocurrency vaults, a variety of different blockchains, upcoming digital stock exchanges and an array of digital currency projects, such as Libra.</p><p>The legal code has now caught up with blockchain – otherwise known as Distributed Ledger Technology (DLT).</p><h2>Banks paying attention</h2><p>It sets a firm legal basis for exchanging digital-only securities and for reclaiming digital assets from bankrupt companies. It also sets legal standards for crypto trading exchanges and tackles the threat of money laundering using cryptocurrencies.</p><p>Swiss banks have for years been wary of cryptocurrencies and blockchain upstarts, fearing a new wave of money laundering headaches. A Wild West phase of blockchain start-up crowd funding in 2017 and 2018 left many investors unhappy with their return or defrauded. As a result, it’s still difficult for some Swiss blockchain start-ups to get a bank account.</p><p>But banks are also taking note of new potential to disrupt finance. If they ignore such possibilities, they risk losing out to competitors such as Sygnum or SEBA – granted banking licenses last year.</p>
<p>UBS and Credit Suisse are testing the potential of DLT trading and are part of a consortium behind a digital payment token project to settle trades faster. Julius Bär has a partnership with SEBA crypto bank and Vontobel issues cryptocurrency-backed trading certificates on the Swiss stock exchange.</p><p>Private banks such as Maerki Baumann and Arab Bank Switzerland offer cryptocurrency services to wealthy clients, usually through intermediates such as Bitcoin Suisse, Metaco or Taurus.</p><p>But the Swiss law changes are just as important for the creation of digital-only versions of company shares, real estate holdings, art and other assets that can be listed and traded on blockchains. It remains to be seen if the reformed Swiss legal code will provide real momentum for the industry.</p><div role="region" aria-label="Infobox"><p><strong>Blockchain and cryptocurrencies</strong></p><p>Bitcoin was created in 2008 by the pseudonymous Satoshi Nakamoto. It is a decentralised digital currency that can function without banks by running on the blockchain.</p><p>Blockchain, otherwise known as Distributed Ledger Technology (DLT), offers a new way of sending data around the world – including cryptocurrencies. Control of the digital network is spread to each of its participants, removing reliance on centralised parties.</p><p>DLT promises enhanced privacy, increased efficiency by sending data directly to the recipient rather than via intermediaries and the potential to reach more people though decentralisation.</p><p>Blockchain sceptics argue that the potential benefits are over-rated and that it opens the doors to criminals.</p><p><span>End of insertion</span></p></div> </section>
</div></div>]]>
            </description>
            <link>https://www.swissinfo.ch/eng/business/swiss-law-reforms-make-crypto-respectable/46024124</link>
            <guid isPermaLink="false">hacker-news-small-sites-24437929</guid>
            <pubDate>Fri, 11 Sep 2020 00:07:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Giggle; Laughable Security]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24437865">thread link</a>) | @DyslexicAtheist
<br/>
September 10, 2020 | https://research.digitalinterruption.com/2020/09/10/giggle-laughable-security/ | <a href="https://web.archive.org/web/*/https://research.digitalinterruption.com/2020/09/10/giggle-laughable-security/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Preface: There is very little in this blog post that is interesting from a technical perspective. The discovered vulnerability is incredibly basic but fairly high risk. Due to the nature of the application, and the fallout from our disclosure attempt, we wanted to write up our findings. The TL;DR is that giggle has been exposing user’s phone numbers, private images and location to the world.</p>

<p>Normally we wouldn’t post a vulnerability like this so soon after discovering it but the owner of the app refuses to listen to us and continuously claims no vulnerability exists. We tried to get in contact with her via a third party (after we had been blocked) to let her read this post before publishing it but, again, she showed no interest.</p>

<p>(edit: We wrote but didn’t publish this article before the vulnerability was fixed. Giggle has told us it has now been fixed so we feel comfortable releasing these details.)</p>

<p>(edit2: Sall is threating us with legal action.)</p>

<p>(edit3: We’ve had some questions about the phrasing in the first public tweet. We standby our words. Not knowing how this would play out, we wanted to make it clear that we didn’t support the app or the founder, but wanted to report the issue. Companies can be unpredictable when reporting vulnerabilities and we wanted to avoid a situation where they would be publicly praising us or even mentioning us on their website etc.)</p>

<p>(edit4: An apology from Giggle has been made and no futher legal action will be taken)</p>

<hr>

<h3 id="what-is-giggle">What is Giggle?</h3>

<p>This week I set up an account on an app called giggle. You see, last month I had been diagnosed with premature menopause I and wanted to find a safe space in a woman centric environment. Somewhere I could talk openly about this experience and maybe get some support, but also find some light hearted way to socialise online.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image1.jpeg.resize.jpeg" alt=""></p>

<p>Without much investigation I found giggle, which seemed to check all the boxes. A free app, promoting safe and secure social networking. Giggle promised a refuge from misogyny and sexism where I could find support and community.</p>

<p>There were a few red flags, such as an excessive use of pink and word “females”, but I decided to give it a go.</p>

<p>At this point the red flags became a little more crimson. Firstly, I was asked to submit my phone number so that a verification code could be sent to my mobile. Then I was asked to allow the app to access my camera so that a selfie of me could be submitted to verify I was female. This verification, apparently, is done using AI. From previous work done on this, we know this can often be notorious for mischaracterising and therefore excluding certain racial groups, some trans women and some masculine looking women.</p>

<p>The app assured me that my verification picture would not be stored so not to worry about what I looked like, so my gargoylesq visage was submitted (I’ll get to the later) and I was duly approved to enter the app.</p>

<p>I went to set up my profile to see what information was publicly available about me, even if only in the app, to find there wasn’t one and I had to set up multiple profiles or ‘giggles’ to start a tinder like experience on each specific subject I was interested in (I chose menopause, body image, hiking and wine tasting), that range from socialising and hobbies to more high risk areas such as abuse and sex work.</p>

<p>As I was curious how secure my data was, and as we are currently working on improvements to <a href="https://rex.digitalinterruption.com/">REX</a> (and thought they’d maybe like a <a href="https://www.digitalinterruption.com/100-free-rex-licences">free license</a>), we decided to dig a little deeper.</p>

<h3 id="viewing-account-details">Viewing Account Details</h3>

<p>Using BurpSuite and a fresh install of the app, we intercepted the network traffic and found a few interesting things that we decided not to look at further as we didn’t have permission to do a full analysis. During the registration process, as mentioned, users are required to verify a phone number and selfie. We submitted a selfie that wouldn’t pass and, unsurprisingly, couldn’t gain access to giggle.</p>

<p>Looking at the network requests revealed that although the account was in an unvalidated state, we still had a valid auth token (it turns out this is hardcoded into the application) allowing us to make requests to the API. Again, we didn’t perform a full analysis although we suspect issues could exist here. What we did look at was the UserList endpoint. This contained a filter parameter that contained my phone number, an operator (in this case “equals”) and a field (“mobile”). Presumably, this is how a user’s account details are fetched from the API.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image2.png.resize.png" alt=""></p>

<p>Of course, the obvious question is what would happen if we changed this filter parameter to be another phone number, changed the query to filter on another parameter such as user ID or user’s name or even would it remove the filter altogether, allowing us to view all accounts?</p>

<p>First, we decided to change the filter query so it would filter based on the GUID of the original account which we received during our initial analysis. This brought back the original account details which included the user’s phone number, age (which was set to hidden) and a latitude and longitude.</p>

<p>Request:</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image3.png.resize.png" alt=""></p>

<p>Response:</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image4.png.resize.png" alt=""></p>

<p>Having the phone number is bad enough, but we checked the returned latitude and longitude using Google Maps. Of course, this brought us to the very house I created the account in.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image5.png.resize.png" alt=""></p>

<p>This means an attacker that is completely unverified to the application can view the address and phone number of all users if they have the account ID. That is pretty bad in our opinion.</p>

<p>Next, we wanted to be able to download the same details without knowing the account ID. Looking at the filter parameter, it’s clear to see there would be many ways to do this. We could remove the filter completely although that would reveal other accounts to us which we were trying to avoid seeing or we could change the query to show all accounts not matching a phone number. As a proof of concept, we decided to change the operator field from “equals” to “contains” and truncated the GUID. As this returned the same data, it should be obvious to see how the query could be trivially modified to expose all registered accounts with no prerequisite account knowledge.</p>

<p>Request:</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image6.png.resize.png" alt="Burp Web Request"></p>

<h3 id="selfies">Selfies!</h3>

<p>What about the supposed private picture that is used to verify accounts? They claim not to store? Behold my gargoylesq visage!</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image7.png.resize.png" alt=""></p>

<p>If we look at the URL of the verification image (which we recovered by viewing network traffic in BurpSuite), we can see that the only thing that is required is the user GUID. As we can view the user GUID for every account (e.g. our test account) we can easily download the associated verification selfie. Although this is not terrible on it’s own, giggle do promise that this isn’t shared or published, and, given that it is available data stored along side my mobile number and geographical coordinates, with this information an attacker would know my address, my personal mobile number and what I look like.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image8.jpeg.resize.jpeg" alt=""></p>

<p>This is where we get to the really scary bit. Giggle has sections encouraging women to find support on abortion, abuse, addiction and relationships among other categories. The amount of available data means that with a phone number or name, an abusive partner would potentially be able to find the location of an abused woman and confirm her identity with the verification picture. There is also a section for sex workers, who, understandably would expect any app enabling them to advertise their work to have adequate privacy and security controls. Even if a user deletes their account, that data appears to still be saved by giggle.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image13.jpeg" alt=""></p>

<h3 id="account-deletion">Account Deletion</h3>

<p>The final thing we looked at is whether a deleted account is actually deleted. We deleted the original account using the “Delete Account” button and tried to view the associated account details.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image9.jpeg.resize.jpeg" alt=""></p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image10.png.resize.png" alt=""></p>

<p>Of course, they are still present and only set to Disabled meaning they are still stored by the system. Maybe accounts are deleted periodically. We would normally at this point reach out to the vendor and ask for clarification. This leads us to the next part of the story…</p>

<h3 id="disclosure">Disclosure</h3>

<p>We wanted to let giggle know that this vuln existed and ask for some further details, not in the small part because it is so easy to exploit. In the midst of this we had done some digging on the origins of the app and found that the founder had a very public anti-trans agenda. However, much as this sickens us, our job is to protect users so we direct messaged giggle through twitter.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image11.png.resize.png" alt=""></p>

<p>Having had no response, we decided to send them a tweet asking them to check their DMs with their founder cc’d in, but with a caveat that we do not share or endorse her anti-trans views.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image12.png.resize.png" alt=""></p>

<p>That’s when we were dragged into a full on TERF War.</p>

<p>Our public tweet had no engagement at all until Sall, the giggle founder, decided to share a screenshot of it with her followers. We have since been subject to a tirade of abuse. None of it about the security of the app. Interested parties are free to view our twitter and find the hundreds and hundreds of tweets in response to trying to disclose this vulnerability but we decided not to copy that into this post.</p>

<p>Our founders have reached out to giggle and Sall and have been blocked following every attempt at contact. Our three year incorporated company has been accused of being a creepy bloke who runs private WhatsApp groups full of naked women, a front for the alt-left, making up the vuln to discredit Sall and her company and hypocrites for wanting to protect the data of users despite the apps founder having view that counter our own.</p>

<p>Our company and I (a woman) have been accused of being a man, and therefore a misogynist multiple times. We have been told that as men (60% of Digital Interruption are women), we should not have a say on the safety of women and their personal data.</p>

<p>Sadly, denial is not uncommon when trying to disclose. We are used to being ignored and even getting some pushback, but ultimately we feel it is our responsibility to persist and ensure the …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://research.digitalinterruption.com/2020/09/10/giggle-laughable-security/">https://research.digitalinterruption.com/2020/09/10/giggle-laughable-security/</a></em></p>]]>
            </description>
            <link>https://research.digitalinterruption.com/2020/09/10/giggle-laughable-security/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24437865</guid>
            <pubDate>Thu, 10 Sep 2020 23:57:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I operated as a staff engineer at Heroku]]>
            </title>
            <description>
<![CDATA[
Score 365 | Comments 83 (<a href="https://news.ycombinator.com/item?id=24437715">thread link</a>) | @craigkerstiens
<br/>
September 10, 2020 | http://amyunger.com/blog/2020/09/10/staff-engineer-at-heroku.html | <a href="https://web.archive.org/web/*/http://amyunger.com/blog/2020/09/10/staff-engineer-at-heroku.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" aria-label="Content">
  <article>
    

    <div>
      

      

      <div>
        <div>
          <p>I was incredibly lucky to spend 5 amazing years at Heroku. By the end of my time, I was operating in a Staff capacity, although I’m honestly completely unclear which titles at Salesforce actually map to Staff.</p>

<p>Because titles are unclear and because my role was a little amorphous, I chose not to submit a story to Will Lethain’s <a href="https://staffeng.com/stories/">great collection</a> at StaffEng.com. That being said, I added a few questions to his questionnaire that I hadn’t seen answered elsewhere, so I figured I’d post this.</p>

<p><strong><em>Tell us a little about your current role: where do you work, your title and generally the sort of work do you and your team do.</em></strong></p>

<p>Until recently, I was a Principal engineer at Salesforce, working for their Heroku product. I joined almost five years ago, working on the Heroku Add-ons product, and then transferred to the Heroku API team. For the last year and a half, I worked on the API team for the Salesforce Functions product, which runs on top of Heroku infrastructure.</p>

<p>The API team is at the center of defining how the Salesforce Functions product will work, so there are a lot of different tasks our team does. First and foremost, we write the code to store the state that the customer <em>intends</em> their infrastructure to converge to and then push that down into the infrastructure layer. If you’re interacting with Salesforce Functions, you’re going through our code. We also do a lot of reconciling what the infrastructure can do with the hopes and dreams of product. I did a balance of work, but more towards the “hopes and dreams” side of things.</p>

<p><strong><em>What does a “normal” Staff-plus engineer do at your company? Does your role look that way or does it differ?</em></strong></p>

<p>There is really no “normal” Staff engineer at Salesforce. I usually talk about four different approaches I see in the company, some of which line up with <a href="https://staffeng.com/guides/staff-archetypes">Will’s archetypes</a> and some which don’t. A lot of folks are a mix of these and rotate through them over a long career at the company.</p>

<p><em>Team(s) Lead/Right Hand</em></p>

<p>You are the primary technical point of contact for 10-20 engineers, across one or more teams. You are typically reporting to a manager of managers. Responsibilities vary based on individuals’ strengths and the strengths of their manager, but there are some common things you <em>must</em> do. If you’re not making your delivery timelines and this is a surprise to your organization, you and your manager have a problem. If product has a dream and no one knows what it would take to build it (time, resources, architecture), you have a problem. If you can’t answer “Why are we building this in this way?” then you have a problem.</p>

<p><em>Product Architect</em></p>

<p>If it’s on TechCrunch or promoted at our corporate conferences, there is an Architect for it. If the project (40+ engineers) fails to be a success, you share responsibility along with the (typically) VP+ engineering manager and Product owner. If you have any type of personal presence, you will be put on a stage and in front of customers. This is the level where you’re helping advocate with your VP for major initiatives to go after certain markets. If we made the wrong bet, some blame is with product, but it’s also on you, and the manager probably won’t look great.</p>

<p><em>Deep Diver</em></p>

<p>You have a lot of deep technical expertise on a particular component or system. You tend to stay on a single team or a single area of the organization. If you work in our legacy codebases, which are the core of our profitability, you are basically unfireable because you know so much. You may write code for some of the gnarliest problems of the legacy system you’re being kept around for, but you’ll often find yourself spending more time interfacing with other teams to explain why your system can’t do what they want and how we can work around it to deliver on a reasonable timeline. You will work closely with your Team Lead on a daily/weekly basis and occasionally have your entire day/week blown up because the Product Architect has identified a need for your expertise and all of a sudden you’re being trotted out to present to some team you’ve never heard of.</p>

<p><em>The Management</em></p>

<p>There are two variants. First, you’re pendulum’ing over to a line manager role, but since your IC title is the same grade as Director or VP, making you a manager would result in a massive pay cut. You’re likely managing a smaller team, given Salesforce targets 12-15 reports. In the second variant, you’re roughly an extension of a VP+ leader. Maybe you’re working on how we keep our many thousands of engineers communicating well. Maybe you’re advising an SVP on where to make technical investments - does our company really have enough of a competitive advantage to go after that market? Sure, the SVP/C-suite person is being told by Product that if you only give us $100 million we can do a ton. Is that true? Hey, we just bought a multi-billion dollar business (or we’re about to): Can you figure out what we should do with them? Many, including Will, call this fire-fighting, but that’s too narrow a view of how these roles really deliver value to large companies: it’s fast-paced opportunity scouting and truth-telling. That being said, you’ll most likely be looking for opportunities and the real truth within the more challenged parts of the business, so I see the fire-fighting analogy.</p>

<p><strong><em>How do you define success in your role?</em></strong></p>

<p>First and foremost, I am successful if the folks I work with understand how business decisions tie into their day-to-day work.</p>

<p>At a minimum, this involves a fair amount of understanding why we’re being asked to build something, running ahead of the team to make sure product plans are in place for us, working across teams to come up with an achievable plan and then championing IC concerns as they crop up.</p>

<p>But it also means pushing forward discussions about what kinds of risk are worth taking on in our code at the moment. Is now the right time to commit to this abstraction? Is now the time to address a performance issue with a re-architecture? We’re moving quickly, but also seeing a lot of incidents - what kinds of testing should we invest in?</p>

<p>Success looks like seeing conversations about timeline and priorities between ICs start from a shared background. Success looks like having no major blow ups about “How could you suggest we ship this hack?” Instead, folks can talk about technical choices through a business lens: “I know we’re currently low on staff compared to our product ambitions, but is this the right place to simplify?” Success looks like a team with a shared goal for the quality and resiliency of code that we’re writing. Success also looks like other ICs feeling confident in advocating for changes, since they see our team making technical decisions with a consistent goal in mind. When I talk with ICs in 1:1s, there should be no “I’m not sure why I’m doing X” when it comes to code, infrastructure and incidents.</p>

<p>Next, I am successful when my management chain clearly understanding the particular risks we’re taking on. All of the architectural decisions a team makes will be wrong, eventually. Whether technology changes, our customer base changes or the product itself changes, it’s only a matter of time before we regret those big choices. The key is understanding what bets we’re making and how long we think before we’ll need to revisit them.</p>

<p>Architecture in a large enterprise is a lot about risk management. A large org has a lot of existing momentum in the market and naturally becomes more cautious. I only have a few places where I can advocate for higher-risk bets and those bets are going to be far lower risk than at a start up. While I need to embrace the fact that our decisions will be wrong, I need to be able to speak to the ways in which we will likely be wrong, when we’ll know and what our mitigation strategy will be.</p>

<p>Third, I am successful if I’m saying the right “No”s to my manager. If the ICs that report to my manager end up feeling like “I told you so” or “We knew this was a bad idea” and that wasn’t surfaced for a discussion, that’s on me. As a Staff engineer, I have the responsibility to course correct my manager when we’re over-committed or committed to the wrong thing.</p>

<p>Finally, I’m successful if my organization has a healthy engineering culture. No one person owns culture, but that doesn’t mean we all don’t equally share the burden of building a world-class engineering organization.</p>

<p><strong><em>How do you spend your time day-to-day?</em></strong></p>

<p>While I do write code from time-to-time, it’s only after I’ve delivered on my obligations on these four functions.</p>

<p><em>Information gathering</em> - In order to help my team understand the context within which we’re building a thing, I need a lot of information. I almost unfailingly start my day with a list of longer emails and docs of all varieties to digest. I also spend a fair amount of time in cross-org chats with assorted managers &amp; ICs, whose purpose is a combination of information gathering and the coaching I mention below.</p>

<p><em>Planning</em> - Knowing a bunch of stuff isn’t helpful unless we actually do something with it, so I also spend a lot of time in planning activities. This is a lot of writing docs and running meetings. Planning activities are usually very collaborative – I rarely know the most on any one thing, but I can knit them all together into a plan.</p>

<p><em>Context sharing</em> - Knowing what we want to do isn’t helpful unless a lot of people understand the plan, so the final category of work that’s execution oriented is sharing all of that context. I attend meetings with other teams to share what we are doing, I review PRs to make sure we’re making small decisions in-line with larger goals, and hold standing team 1:1s to make sure each person feels confident in the direction we’re headed.</p>

<p><em>Coaching &amp; Culture</em> - The final category of work isn’t oriented towards delivering a product, but it’s still critically important to our organization’s long-term health to invest in our engineers. My personal …</p></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://amyunger.com/blog/2020/09/10/staff-engineer-at-heroku.html">http://amyunger.com/blog/2020/09/10/staff-engineer-at-heroku.html</a></em></p>]]>
            </description>
            <link>http://amyunger.com/blog/2020/09/10/staff-engineer-at-heroku.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24437715</guid>
            <pubDate>Thu, 10 Sep 2020 23:32:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Snappa moving 40% of its assets to Bitcoin]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24437684">thread link</a>) | @fiatjaf
<br/>
September 10, 2020 | https://chrisgimmer.com/bitcoin-reserve-asset/ | <a href="https://web.archive.org/web/*/https://chrisgimmer.com/bitcoin-reserve-asset/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<p>Let me ask you a question…</p>
<p>Would you rather save money in a currency whose supply is inflating each year? Or would you rather save in a currency whose terminal supply is programmatically <em>fixed</em>?</p>
<p>Given everything going on in the global economy, this is a question we’ve had to start taking seriously as <a href="https://snappa.com/" target="_blank" rel="noopener noreferrer">Snappa</a>&nbsp;continues to scale and produce growing amounts of free cash flow.</p>
<p>It became even more important when our bank slashed the interest rate on our “high interest” savings account to 0.45% earlier this year. This means that the purchasing power of our Canadian and U.S. dollars is actually <em>decreasing</em> after adjusting for inflation.</p>
<p>Fortunately, I believe we now have a far superior savings technology available to us. That technology is Bitcoin.</p>
<p>After falling down the rabbit hole and spending hundreds of hours studying the underlying protocol and all the game theory behind it, we began steadily accumulating bitcoin beginning in March of this year. This position now makes up a significant percentage of our company’s overall cash reserves.</p>
<p>In this article, I will explain the full reasoning behind this decision.</p>
<h2 id="h.po412p2bbfgb">A Brief History About Money</h2>
<p>In order to truly grasp the significance of Bitcoin, it’s important to understand the history of money. Even though I majored in finance with a minor in economics, this topic was completely glossed over when I attended university.</p>
<p>If you go back thousands of years, you’ll learn that various groups of people adopted different forms of money in order to facilitate trade. Money took on various forms including seashells, glass beads, and eventually precious metals. You can read more about the origins of money in Nick Szabo’s brilliant piece titled <a href="https://nakamotoinstitute.org/shelling-out/" target="_blank" rel="noopener noreferrer">Shelling Out</a>.</p>
<p>Using collectibles as a medium of exchange within tribes worked fairly well but eventually became problematic as global trade began to flourish. What some groups found out the hard way is that scarcity is one of the most important factors when it comes to money. If the supply of your money can be inflated away, your purchasing power will plummet as a result.</p>
<p>This is exactly what happened to the West Africans in the 15th century. At the time, glassmaking was unpopular in West Africa thus <a href="http://www.vam.ac.uk/content/articles/t/trade-beads/" target="_blank" rel="noopener noreferrer">glass beads became highly sought after</a> and used as a medium of exchange. Unbeknownst to them, Europeans developed the capacity to reproduce these glass beads very cheaply. As a result, Europeans were able to exchange their cheaply made glass beads and exploit West Africans for more valuable resources including ivory, gold, and even slaves.</p>
<p>A similar situation happened to India and China in the 20th century with the demonetization of silver. Since silver is more abundant and easier to mine than gold, it enabled foreigners with silver to come in and control increasing quantities of goods and capital from India and China.</p>
<p>In order to avoid the destruction of wealth experienced by the West Africans, Indians, and Chinese, the world naturally converged on gold, which was the hardest form of money available.</p>
<p>Although gold served as a great form of money due to a variety of factors including durability, portability, and fungibility, I would argue that scarcity is the most important factor of all.</p>
<p>Since gold was (and still is) costly to mine, the supply of new gold coming above ground has remained consistently low&nbsp;at around 1-2% per year.</p>
<p>Due to this scarcity, gold has maintained its purchasing power over time. While an ounce of gold was valued at $20 USD in 1920, that same ounce of gold is now worth close to $2,000 USD. Said differently, <em>the U.S. dollar has lost 99% of its purchasing power relative to gold over the course of the last century</em>.</p>

<p>You’ll also notice in the graph above that the devaluation of the USD accelerated significantly after 1971 when the U.S. abandoned <a href="https://www.investopedia.com/ask/answers/09/gold-standard.asp#:~:text=The%20gold%20standard%20is%20a,sells%20gold%20at%20that%20price." target="_blank" rel="noopener noreferrer">the gold standard</a>&nbsp;(we’ll come back to this point later on).</p>
<p>Now that you understand a bit about the history of money and how scarcity drives gold’s value, let’s take a closer look at Bitcoin.</p>
<h2 id="h.bzc9dye18ceb">Bitcoin and Digital Scarcity</h2>
<p>Bitcoin is incredibly complicated yet extremely simple at the same time. Although the Bitcoin protocol incorporates cryptography, proof of work, difficulty adjustments, and a bunch of other pieces to make it all work, they all help achieve one primary goal: <em>digital scarcity</em>.</p>
<p>If there’s one thing you need to understand about Bitcoin it’s the fact that<a href="https://unchained-capital.com/blog/bitcoin-is-not-a-pyramid-scheme/" target="_blank" rel="noopener noreferrer">&nbsp;</a><a href="https://unchained-capital.com/blog/21-million-is-non-negotiable/" target="_blank" rel="noopener noreferrer">there will only ever be 21 million</a>. This 21 million cap was hard-coded into the protocol and its consensus rules are upheld by thousands of nodes running the software.</p>
<p>When Bitcoin was first unleashed on the world in 2009, the reward for “mining” a new block was 50 bitcoin. After the most recent halving in May, the reward is now down to 6.25 bitcoin per block.</p>
<p>This reward will continue to get cut in half roughly every 4 years until the very last (fraction of) bitcoin is mined sometime in 2141. Although it will take another 120 years for the very last bitcoin to be mined, over 99% of the total supply will be mined by the end of 2034!</p>
<p>Here’s a graph showing Bitcoin’s supply schedule:</p>
<p><img loading="lazy" src="https://chrisgimmer.com/wp-content/uploads/2020/08/bitcoin-supply-schedule.jpg" alt="bitcoin supply schedule" width="1600" height="965" srcset="https://chrisgimmer.com/wp-content/uploads/2020/08/bitcoin-supply-schedule.jpg 1600w, https://chrisgimmer.com/wp-content/uploads/2020/08/bitcoin-supply-schedule-300x181.jpg 300w, https://chrisgimmer.com/wp-content/uploads/2020/08/bitcoin-supply-schedule-1024x618.jpg 1024w, https://chrisgimmer.com/wp-content/uploads/2020/08/bitcoin-supply-schedule-768x463.jpg 768w, https://chrisgimmer.com/wp-content/uploads/2020/08/bitcoin-supply-schedule-1536x926.jpg 1536w" sizes="(max-width: 1600px) 100vw, 1600px"></p><p>Unlike fiat currencies which are getting <em>less scarce </em>over time, Bitcoin is getting <em>more scarce </em>over time.</p>
<h2 id="h.wvonc15b1n">Stock to Flow</h2>
<p>In the book <a href="https://www.amazon.com/Bitcoin-Standard-Decentralized-Alternative-Central-ebook/dp/B07BPM3GZQ" target="_blank" rel="noopener noreferrer">The Bitcoin Standard</a>,&nbsp;Saifedean Ammous&nbsp;introduces a concept called stock to flow, which is used to quantify the scarcity of a good. Stock represents the total supply in circulation and flow represents the amount of new supply per year that is coming into existence.</p>
<p>Using gold as an example, there is estimated to be 190,000 tons of gold above ground (stock) and 3,260 tons of new supply coming onto the market (flow). Thus, by dividing 190,000 by 3,260, we arrive at a stock-to-flow (S2F) value of 58.3.</p>
<p>Since Bitcoin is open-source and fully transparent, we can actually measure Bitcoin’s S2F with 100% certainty at any point in the past and at any point in the future. With Bitcoin’s most recent halving behind us, the current S2F of Bitcoin is 56 which is roughly the same as gold. However, after the next halving, <em>Bitcoin will be twice as scarce as gold</em>.</p>
<p>Knowing there’s a relationship between gold’s scarcity and its monetary premium, a pseudonymous quant trader known as PlanB attempted to <a href="https://medium.com/@100trillionUSD/modeling-bitcoins-value-with-scarcity-91fa0fc03e25" target="_blank" rel="noopener noreferrer">model Bitcoin’s value with scarcity</a> back in March of 2019. With a shockingly high R2 of 95%, the original model showed that there is in fact a strong correlation between Bitcoin’s price and its S2F.</p>
<p><img loading="lazy" src="https://chrisgimmer.com/wp-content/uploads/2020/08/bitcoin-s2f-time-series-model.png" alt="Bitcoin stock to flow model" width="1400" height="976" srcset="https://chrisgimmer.com/wp-content/uploads/2020/08/bitcoin-s2f-time-series-model.png 1400w, https://chrisgimmer.com/wp-content/uploads/2020/08/bitcoin-s2f-time-series-model-300x209.png 300w, https://chrisgimmer.com/wp-content/uploads/2020/08/bitcoin-s2f-time-series-model-1024x714.png 1024w, https://chrisgimmer.com/wp-content/uploads/2020/08/bitcoin-s2f-time-series-model-768x535.png 768w" sizes="(max-width: 1400px) 100vw, 1400px"></p><p>PlanB would later update the original model to a <a href="https://medium.com/@100trillionUSD/bitcoin-stock-to-flow-cross-asset-model-50d260feed12" target="_blank" rel="noopener noreferrer">cross asset price model</a>. This latest model predicts that the price of Bitcoin could reach $288k in this current 4 year cycle if the model continues to hold. Here is an updated snapshot of the stock-to-flow model.</p>
<p><img loading="lazy" src="https://chrisgimmer.com/wp-content/uploads/2020/08/s2f-cross-asset-model.png" alt="Bitcoin S2F cross asset model" width="1600" height="886" srcset="https://chrisgimmer.com/wp-content/uploads/2020/08/s2f-cross-asset-model.png 1600w, https://chrisgimmer.com/wp-content/uploads/2020/08/s2f-cross-asset-model-300x166.png 300w, https://chrisgimmer.com/wp-content/uploads/2020/08/s2f-cross-asset-model-1024x567.png 1024w, https://chrisgimmer.com/wp-content/uploads/2020/08/s2f-cross-asset-model-768x425.png 768w, https://chrisgimmer.com/wp-content/uploads/2020/08/s2f-cross-asset-model-1536x851.png 1536w" sizes="(max-width: 1600px) 100vw, 1600px"></p><p>If history repeats itself, the price of Bitcoin should continue to appreciate as the red/orange dots would indicate from previous cycles. Whether or not it can reach $288k within this cycle is up for debate and beyond the scope of this article. That being said, I personally believe that a Bitcoin price of $100k by the end of 2021 is fairly realistic given its fundamentals and the current state of the macro economy.</p>
<h2 id="h.m0cn2s9g9ot1">Bitcoin vs. Gold</h2>
<p>If we’re talking about a reserve asset whose main goal is to maintain purchasing power, it stands to reason that the most scarce asset would win out over time. As we’ve seen throughout history, good money chases out the bad.</p>
<p>Given that Bitcoin’s terminal supply is provably fixed&nbsp;we can confidently say that Bitcoin is superior to gold in this regard. But what about the other monetary properties that make a great store of value?</p>
<p>In <a href="https://medium.com/@vijayboyapati/the-bullish-case-for-bitcoin-6ecc8bdecc1" target="_blank" rel="noopener noreferrer">The Bullish Case for Bitcoin</a>, Vijay Boyapati does a great job evaluating Bitcoin vs. gold as a good store of value.</p>
<p>Here’s a quick recap:</p>
<p><strong>Durability</strong>: Gold has survived thousands of years so it’s the undisputed king of durability. Bitcoin on the other hand is still in its infancy so it’s too early to draw conclusions. That being said, it has remained resilient against various attacks and <a href="https://unchained-capital.com/blog/bitcoin-is-antifragile/" target="_blank" rel="noopener noreferrer">has proven to be antifragile thus far</a>.</p>
<p><strong>Portability</strong>: Bitcoin wins hands down. You can transfer billions of dollars worth of value over the Bitcoin network in minutes. Good luck transporting that much gold across borders without massive lead times and transaction costs.</p>
<p><strong>Fungibility</strong>: Gold provides the standard for fungibility since an ounce of gold is indistinguishable from any other ounce when melted down. While Bitcoin is fungible at the network level, some people are worried that certain bitcoin may become ‘tainted’ without privacy and anonymity improvements on the base layer.</p>
<p><strong>Verifiability</strong>: The authenticity of Bitcoin can be easily verified with 100% certainty by simply running a full node. Gold on the other hand <a href="https://www.cbc.ca/news/canada/ottawa/fake-gold-wafer-rbc-canadian-mint-1.4368801" target="_blank" rel="noopener noreferrer">is not immune to counterfeiting</a>.</p>
<p><strong>Divisibility</strong>: Bitcoin wins easily here. One bitcoin can be divided into 100,000,000 units known as satoshis. Gold bars are much harder to divide into lower units of value.</p>
<p><strong>Established History: </strong>This is where gold has the biggest advantage over Bitcoin since it’s been used as a store of value and medium of exchange for thousands of years. Bitcoin has only been around for 11 years and is still in the very early stages of becoming a trusted store of value. This however can be viewed as an opportunity since the future potential of Bitcoin is not yet priced in.</p>
<p>Vijay also provides a handy table which grades Bitcoin, gold and fiat based on the monetary attributes listed above.</p>

<p>Given that Bitcoin is only 1.7% the market cap of gold while grading above it in many regards, I am pretty confident that Bitcoin will continue to outperform gold over the coming years and decades.</p>
<h2 id="h.luelmbv45asp">The Current Macro Environment</h2>
<p>At this point, I hope I’ve explained why scarcity is important when protecting purchasing power and why I believe Bitcoin will continue to outperform gold as a store of value.</p>
<p>Normally I wouldn’t be so concerned with maintaining purchasing power but we are truly entering unprecedented times. COVID-19 is only part of the story…</p>
<p>For those of you who haven’t been paying attention, government debt from nation states …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chrisgimmer.com/bitcoin-reserve-asset/">https://chrisgimmer.com/bitcoin-reserve-asset/</a></em></p>]]>
            </description>
            <link>https://chrisgimmer.com/bitcoin-reserve-asset/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24437684</guid>
            <pubDate>Thu, 10 Sep 2020 23:28:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Content from the Dark Web to Provide Content to the Clear Web]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24437280">thread link</a>) | @puggo
<br/>
September 10, 2020 | https://hawaiigentech.com/post/commentary/it-came-from-the-dark-web/ | <a href="https://web.archive.org/web/*/https://hawaiigentech.com/post/commentary/it-came-from-the-dark-web/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><img src="https://hawaiigentech.com/post/commentary/it-came-from-the-dark-web/a-reverse-benefit.jpg" alt="Sometimes, the greater evil can serve the greater good."></p>
<hr>
<h2 id="everyone-wants-to-think-out-of-the-box-so-thats-not-thinking-out-of-the-box">Everyone wants to "think out of the box". So that's not thinking out of the box.</h2>
<p>Sometimes I think out of the box using the ideas from the people stuck in the box. Like, how can I take this idea that is stuck in the box, and liberate it from the box…you know what…nevermind. I’ll just explain.</p>
<hr>
<h3 id="a-fresh-source-of-content">A Fresh Source of Content</h3>
<p>So you may have heard that the dark web contains whistle blowers, free thinkers, radical innovators, and such like these, though you might run into a bad guy every now and then.</p>
<p>So before drawing out a large commentary on this subject, let me illustrate it with a common analogy, but slightly modified so as to exit the box.</p>
<p><img src="https://hawaiigentech.com/post/commentary/it-came-from-the-dark-web/paradigm-shift.png" alt="The Paradigm Shift of Thinking in the Box"></p>
<p>So in this case (and by this analogy only) the big dark box that people are thinking in is in the dark web. So to think “out of the box” as you’ve been told to do, you might have to <em>go into the box</em>. Consider this picture above: The <em><strong>text you do see</strong></em> is what is clearly written on the image. But the ALT TEXT in the image tag which you will probably not see says <strong>“The Paradigm Shift of Thinking in the Box”</strong>.</p>
<p>Unless you have a setting on your browser that shows alt text immediately, you wouldn’t discover this unless you dug for it, specifically. But then, why would you do that? You didn’t know it would be useful. It was hidden anyways. But there is an entire network that behaves like that Alt Text I just mentioned. (The hidden web, obviously).</p>
<h3 id="more-on-the-box">More on the Box…</h3>
<p>Ok, so your teacher or parents or marketing guru (who could benefit by you) said its a good thing to think out of the box. And maybe, like me, you thought you’d listen. But did the teacher ever tell you to:</p>
<ul>
<li>Change the box?</li>
<li>Poke holes in the box?</li>
<li>Shake the box?</li>
<li>Expose the box to rain and sun?</li>
<li>Put a king snake in the box?</li>
<li>Hide stuff in the box?</li>
</ul>
<p>Your not limited to thinking only outside the box. The box is really your plaything. Come and go at will. Why limit yourself to the place outside the box? Or in the box? Or why not switch to a bag, safe, or crate?</p>
<h3 id="thus-we-may-use-the-box-to-our-advantage">Thus, we may use the box to our advantage.</h3>
<p><img src="https://hawaiigentech.com/post/commentary/it-came-from-the-dark-web/ben-linus.jpg" alt="What if I told you that somewhere on this island there’s a very large box and whatever you imagined, whatever you wanted to be in it, when you opened that box there it would be."></p>
<blockquote>
<p>“What if I told you that somewhere on this island there’s a very large box and whatever you imagined, whatever you wanted to be in it, when you opened that box there it would be.”” - <a href="https://en.wikipedia.org/wiki/Ben_Linus">Ben Linus</a></p>
</blockquote>
<p>Since in this case we are considering the dark web as being the box (the box that NOBODY SHOULD ENTER) we can now think out of the box by going into the box.</p>
<h2 id="and-now-the-keynote-address">And now, the Keynote Address</h2>
<p>Search engines can easily judge the originality of content based on other content that appeared before it on the <em>clearnet</em>. But at this time they <em>generally</em> don’t know what exists in the dark net (its hard to crawl, not reliable, among other issues).</p>
<p>In the ice-berg picture above (which is a fitting and accurate example) you can see that the dark net is far bigger than the clear net.</p>
<p>So you could, literally, <em><strong>just search for cool ideas and content from the dark web and place it on your clear web website</strong></em>. And the result would be, according to search engines: <strong>You</strong> <em>have new and authentic content</em>.</p>
<p>Adding to that, due to the source (the dark net), your “authentic” content will probably be unique  (to the clear net). Dark net authors often think differently. That’s why they are there.</p>
<p>You probably think I’m telling you to steal content from the dark web.</p>
<p>Stealing content is not what I’m suggesting.</p>
<hr>
<p>I’m suggesting this, rather:</p>
<h3 id="using-content-from-the-dark-web-to-provide-content-to-the-clear-web">Using content from the dark web to provide content to the clear web</h3>
<p><img src="https://hawaiigentech.com/post/commentary/it-came-from-the-dark-web/dali.jpg" alt="Dali, “Original Inspiration”"></p>
<p>Lets use Salvadore Dali as an Example <a href="https://www.google.com/search?q=Salvador+Dali+painting&amp;tbm=isch&amp;ved=2ahUKEwjo6t3VwN_rAhUJq54KHfrLDd0Q2-cCegQIABAA&amp;oq=Salvador+Dali+painting&amp;gs_lcp=CgNpbWcQAzICCAAyAggAMgIIADICCAAyAggAMgIIADICCAAyAggAMgIIADICCAA6BAgjECdQzDtY5T9g7UBoAHAAeACAAYcBiAHOB5IBAzAuOJgBAKABAaoBC2d3cy13aXotaW1nwAEB&amp;sclient=img&amp;ei=ApdaX-jhFInW-gT6l7foDQ&amp;bih=862&amp;biw=1841&amp;client=ubuntu&amp;hl=en&amp;hl=en">(see his paintings here)</a>. (<a href="https://web.archive.org/web/20200910232414/https://www.google.com/search?q=Salvador+Dali+painting&amp;tbm=isch&amp;ved=2ahUKEwjo6t3VwN_rAhUJq54KHfrLDd0Q2-cCegQIABAA&amp;oq=Salvador+Dali+painting&amp;gs_lcp=CgNpbWcQAzICCAAyAggAMgIIADICCAAyAggAMgIIADICCAAyAggAMgIIADICCAA6BAgjECdQzDtY5T9g7UBoAHAAeACAAYcBiAHOB5IBAzAuOJgBAKABAaoBC2d3cy13aXotaW1nwAEB&amp;sclient=img&amp;ei=ApdaX-jhFInW-gT6l7foDQ&amp;bih=862&amp;biw=1841&amp;client=ubuntu&amp;hl=en&amp;hl=en">archive</a>)</p>
<p>Dali used to take inspiration for his paintings from a foreign and strange environment: <em><strong>his dreams</strong></em>.</p>
<p>While its questionable where his success came from (indeed, we cannot assume inspiration or quality of art) he certainly knew a thing or two about inspiration: Radical inspiration comes from a place we don’t visit often*.</p>
<p>*(<em>That’s why I’m an avid bible reader that no longer sets foot in churches. Churches are, in my opinion, the dark side of the dark web of religion, but the bible is the “radical” book that goes against the establishment. And, oddly, most bibles come in black, though containing much light.</em>).</p>
<p><em><strong>Hence</strong></em>, using the <em><strong>hidden net can give you ideas that were previously unknown to you</strong></em>, because they are not a part of your common world or common experiences via mainstream television or mainstream internet (or mainstream books).</p>
<p>And you can draw from that.</p>
<h2 id="epilog-with-new-frontiers-comes-new-risks">Epilog: With new frontiers comes new risks…</h2>
<p><img src="https://hawaiigentech.com/post/commentary/it-came-from-the-dark-web/pirates.jpg" alt="One nation’s pirate is another nation’s entrepreneur…"></p>
<p>Like I acknowledged at the beginning of this article, the dark web contains bad guys, though occasionally you might run into whistle blowers, free thinkers, radical innovators, and the like.</p>
<p>The dark web does not exist to be searchable, unless the authors intend it. Likewise, your chances on stumbling upon genuinely evil content is also based on the entry points you use. Finding innovation will start with innovation.</p>
<p>Hence, I would suggest NOT just jumping into the dark web based on the popular entry points, but find a strategy to obtain links and onion connections from useful darkweb sites that explore innovation or new ideas that are challenged by dominant opinion. Avert your eyes from things that are genuinely dark.</p>
<p>Its true with websites as its true with people: Birds of a feather flock together. So if you start with sites that are intellectual and progressive in nature, you are not likely to come into evil territories quickly. On the other hand, if you start with a site like The Hidden Wiki…you’d better know what your doing.</p>
<hr>
<p>Endnote:</p>
<p>You probably think I’m telling you to visit the dark web…</p>
<p>You could I suppose.</p>
<p>Its actually much better to read the scriptures. The best inspiration comes from places people rarely visit. <a href="https://scrollmapper.github.io/pages/apocryphal/">That would reveal much to you that you didn’t know you didn’t know…</a> (<a href="https://web.archive.org/web/20200910082737/https://scrollmapper.github.io/pages/apocryphal/">archived</a>)</p>
<p>Some times the most useful things are hidden for a reason.</p>
<hr>

    </div></div>]]>
            </description>
            <link>https://hawaiigentech.com/post/commentary/it-came-from-the-dark-web/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24437280</guid>
            <pubDate>Thu, 10 Sep 2020 22:37:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I trained a model. What is next?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24437167">thread link</a>) | @ternaus
<br/>
September 10, 2020 | https://ternaus.blog/tutorial/2020/08/28/Trained-model-what-is-next.html | <a href="https://web.archive.org/web/*/https://ternaus.blog/tutorial/2020/08/28/Trained-model-what-is-next.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
        <p><img src="https://habrastorage.org/webt/t8/gu/h5/t8guh5udxpxg-vxsirt3wewhhho.png" alt=""></p>



<p>I participated in machine learning (ML) competitions at <a href="http://ternaus.blog/interview/2018/08/30/ama.html">Kaggle and other platforms</a>
to build machine learning muscles. I was <a href="https://www.kaggle.com/rankings?group=competitions">19th in the global rating</a>, got <a href="https://www.kaggle.com/iglovikov">Kaggle Grandmaster</a> title.</p>

<p>Every ML challenge ended with new knowledge, code, and model weights.</p>

<p>I loved new learnings but ignored the value that old ML pipelines could bring. Code stayed in private GitHub repositories.
Weights were scattered all over the hard drive. In the end, all of them were deleted.</p>

<p>The situation is not unique to Kaggle. Same story in academia. The student trains a model, writes a paper.
After it is accepted to the conference, pipelines are abandoned, training artifacts deleted and student moves on.</p>

<p>This article will talk about small steps that you can do after the end of every ML challenge.</p>

<p>These steps will:</p>

<ul>
  <li>Boost technical knowledge.</li>
  <li>Build a personal brand.</li>
  <li>Improve career opportunities.</li>
  <li>Make the world a better place  :)</li>
</ul>

<p>As an example, I will use the repository <a href="https://github.com/ternaus/retinaface">https://github.com/ternaus/retinaface</a></p>

<p>It was not a part of a Kaggle challenge but was created to illustrate the story.</p>

<h2 id="5-min-release-code-to-the-public-github-repository">+5 min: Release code to the Public GitHub repository</h2>

<p>Most likely, code is already at GitHub, but in a private repo.</p>

<p>What will you lose if you will make it public?</p>

<p>There are situations when private should stay private, but in your pet project, your Kaggle solution, or your paper, it may not be the case.</p>

<p>The most common obstacle that I have seen: people assume that all public code should be perfect and that they will be judged if it is not the case.</p>

<p>In reality, no one cares. Just do it. Release it as is, without any polishing.</p>

<p>Making code public is an important psychological step. Releasing non-perfect code is a confident, bold move.</p>

<p>Besides, all later steps are based on this one.</p>

<p>Example: <a href="https://github.com/ternaus/retinaface">https://github.com/ternaus/retinaface</a></p>

<h2 id="20-min-improve-readability">+20 min: Improve readability.</h2>

<p>You can improve the readability of your python code by adding syntax formatters and checkers.</p>

<p>It is not hard and not time-consuming. Checkers and formatters will not transform bad code into good, but the readability will go up. Think about fixing syntax as about basic hygiene. It is like brushing your teeth, but for the code.</p>

<p>I wrote a blog post on the topic called <a href="http://ternaus.blog/tutorial/2020/04/09/Nine-simple-steps-for-better-looking-python-code.html">Nine Simple Steps for Better Looking python code</a>. Feel free to check it out.</p>

<h3 id="step-1-configuration-files">Step 1: configuration files</h3>
<p>Add these files to the root of your repository.</p>

<ul>
  <li><a href="https://github.com/ternaus/retinaface/blob/master/setup.cfg">setup.cfg</a> - configuration for flake8 and mypy.</li>
  <li><a href="https://github.com/ternaus/retinaface/blob/master/pyproject.toml">pyproject.toml</a> - configuration for black.</li>
</ul>

<h3 id="step-2-requirements">Step 2: requirements</h3>
<p>Install the required libraries with</p>

<div><div><pre><code>pip <span>install </span>black flake8 mypy
</code></pre></div></div>

<h3 id="step-3-black">Step 3: black</h3>

<p>There are 100500 ways to format the code. Formatters like black or yapf modify the code to satisfy a pre-defined set of rules.</p>

<p>It is easier to read codebase that has some standards. When you work on the code for hours and need to switch a context between different coding styles, it drains “<a href="https://amzn.to/3hNYYUJ">willpower energy</a>” — no need to do it without a good reason.</p>

<p>Running</p>

<p>will reformat all python files to follow the set of rules by black.</p>

<h3 id="step-4-flake8">Step 4: flake8</h3>

<p>Running</p>

<p>will not modify the code, but will check code for syntax issues and output them to the screen.</p>

<p>Fix them.</p>

<h3 id="step-5-mypy">Step 5: mypy</h3>

<p>Python does not have mandatory static typization, but it is recommended to add types to the function arguments and return types.</p>

<p>For example:</p>
<div><div><pre><code>class MyModel(nn.Module):
    ....

def forward(x: torch.Tensor) -&gt; torch.Tensor:
    ....
    return self.final(x)
</code></pre></div></div>

<p>You should add typing to the code.</p>

<ol>
  <li>It makes it easier to read the code.</li>
  <li>You can use the mypy package to check arguments and function types for consistency.</li>
</ol>

<p>After updating the code run mypy on the whole repo:</p>



<p>If mypy found issues - fix them.</p>

<h3 id="step-6-pre-commit-hook">Step 6: pre-commit hook</h3>

<p>Running <strong>flake8</strong>, <strong>black</strong>, <strong>mypy</strong> manually all the time is annoying.</p>

<p>There is a tool called <strong>pre-commit hook</strong> that addresses the issue.</p>

<p>To enable it - copy this file to your repo: <a href="https://github.com/ternaus/retinaface/blob/master/.pre-commit-config.yaml">.pre-commit-config.yaml</a>.</p>

<p>You need to install the pre-commit package on your machine with:</p>



<p>And initialize with:</p>


<p>You are good to go.</p>

<p>From now on, on every commit, it will run a set of checks and not allow the commit to pass if something is wrong.</p>

<p>The main difference between the manual running of the black, flake8, mypy is that it does not beg you to fix issues, but forces you to do this. Hence, there is no waste of “willpower energy.”</p>

<h3 id="step-7-github-actions">Step 7: Github Actions</h3>

<p>You added checks to the pre-commit hook, and you run them locally. But you need a second line of defense. You need Github to run these checks on every pull request.</p>

<p>Way to do it is to add file <a href="https://github.com/ternaus/retinaface/blob/master/.github/workflows/ci.yml">.github/workflows/ci.yaml</a> to the repo.</p>

<p>There are lines:</p>
<div><div><pre><code>    <span>-</span> <span>name</span><span>:</span> <span>Install dependencies</span>
      <span>run</span><span>:</span> <span>|</span>
        <span>python -m pip install --upgrade pip</span>
        <span>pip install -r requirements.txt</span>
        <span>pip install black flake8 mypy</span>
    <span>-</span> <span>name</span><span>:</span> <span>Run black</span>
      <span>run</span><span>:</span>
        <span>black --check .</span>
    <span>-</span> <span>name</span><span>:</span> <span>Run flake8</span>
      <span>run</span><span>:</span> <span>flake8</span>
    <span>-</span> <span>name</span><span>:</span> <span>Run Mypy</span>
      <span>run</span><span>:</span> <span>mypy retinaface</span>
</code></pre></div></div>

<p>that tell GitHub what to check.</p>

<p>I also recommend to give up the practice of pushing the code directly to the master branch.</p>

<p>Create a new branch, modify the code, commit, push to Github, create a pull request, and merge to master.</p>

<p>It is a standard in the industry, but it is exceptionally uncommon in the academy and among Kagglers.</p>

<p>If you are not familiar with these tools, it may take more than 20 minutes to add them and fix errors and warnings.</p>

<p>Remember this time. In the next project, add these checks in the first commit, when no code is written. From that moment, every small commit will be checked, and you will need to fix at most a couple lines of code every time: tiny overhead, excellent habit.</p>

<p>I would also recommend reading a book <a href="https://amzn.to/32fIaiO">Atomic Habits: An Easy &amp; Proven Way to Build Good Habits &amp; Break Bad Ones</a>. It talks about small changes in your behavior that improve productivity and the quality of your life.</p>

<h2 id="iii-20-min-create-good-readme">III: +20 min: Create good readme.</h2>

<p>Good readme serves two purposes:</p>
<ul>
  <li>For yourself: you assume that you will never use this code, but “never say never.” You will, and you will not remember what was happening here. Readme will help you.</li>
  <li>For others: Readme is a selling point. If people are not able to tell the purpose of the repo and what problems it addresses, they will not use it. All the work that you did will not have a positive impact on others.</li>
</ul>

<p>For machine learning repositories, the bare minimum is:</p>
<ul>
  <li>An image that tells what the task was and how did you solve it. No words should be required. Most likely, after working on a problem for weeks, you have 100500 pictures. They are just not a part of the Readme. Fix it.</li>
  <li>Where to put the data.</li>
  <li>How to start training</li>
  <li>How to perform inference.</li>
</ul>

<p>If you need to write 100500 words to describe how to run training or inference it, it is a red flag. You need to refactor your code and make it more user friendly. People often ask - how can I become a better programmer? This is the exercise that helps. You will need to rewrite your code. Try to look at your Readme from the eyes of someone else.</p>

<p>It is also a great exercise that will help develop a habit of looking at the product from the user’s point of view.</p>

<blockquote>
  <p><strong>Famous: “Customers come first.”</strong></p>
</blockquote>

<p>Example: For retinaface, I wrote a <a href="https://github.com/ternaus/retinaface/blob/master/retinaface/predict_single.py">wrapper over a model</a> that hides details of the postprocessing.</p>

<p>Postprocessing is straightforward hard, but it does not add value to people that do not care about it =&gt; users should be able to hide it.</p>

<p>Readme created at this stage will be reused later when we will build a library.</p>

<h2 id="iv-20-min-make-it-easy-to-use-your-trained-model">IV: +20 min. Make it easy to use your trained model.</h2>

<p>I guess you write</p>

<div><div><pre><code><span>model</span> <span>=</span> <span>MyFancyModel</span><span>()</span>
<span>state_dict</span> <span>=</span> <span>torch</span><span>.</span><span>load</span><span>(</span><span>&lt;</span><span>path</span> <span>to</span> <span>weights</span><span>&gt;</span><span>)</span>
<span>model</span><span>.</span><span>load_state_dict</span><span>(</span><span>state_dict</span><span>)</span>
</code></pre></div></div>
<p>to load pre-trained weights to the model.</p>

<p>It works, and steps are clear, but it requires weights on the disk and knowing where they are. A more elegant solution is to leverage the <code>torch.utils.model_zoo.load_url</code> function in torchvision and similar in TensorFlow or Keras.</p>

<p>We can do:</p>
<div><div><pre><code><span>from</span> <span>retinaface.pre_trained_models</span> <span>import</span> <span>get_model</span>

<span>model</span> <span>=</span> <span>get_model</span><span>(</span><span>"resnet50_2020-07-20"</span><span>,</span> <span>max_size</span><span>=</span><span>2048</span><span>)</span>
</code></pre></div></div>
<p>If weights are not on the disk, they are downloaded from the internet and cached on the disk.
The model is initialized, and weights are loaded.</p>

<p>This is user friendly, and that is what you see in <a href="https://pytorch.org/docs/stable/torchvision/index.html">torchvision</a> and <a href="https://pypi.org/project/timm/">timm</a> libraries.</p>

<h3 id="step-1-host-weights-of-the-pre-trained-model">Step 1: host weights of the pre-trained model</h3>

<p>This was the biggest blocker for me. Where can I put weights for the model if you do not want to deal with AWS, GCP?</p>

<p>Apparently, there is an excellent solution, I would say a loophole. You can put weights to the releases at GitHub.</p>

<p><img src="https://habrastorage.org/webt/f_/4x/0t/f_4x0tdt6fnpqzbbkgz_g9-l-wc.png" alt=""></p>

<p>The limit is 2Gb per file, which is enough for most Deep Learning models.</p>

<h3 id="step-2-write-a-function-that-initializes-the-model-and-loads-weights">Step 2: write a function that initializes the model and loads weights</h3>

<p>In my case:</p>



<p>This functionality will be leveraged when we will build Colab Notebook and WebApp.</p>

<h2 id="v-20-min-make-a-library">V: +20 min. Make a library.</h2>

<p>In this step, you lower the entry point to use your model. The goal is to perform predictions without</p>


<h3 id="step-1-add-necessary-dependencies-to-the-requirementstxt">Step 1: add necessary dependencies to the requirements.txt</h3>
<p>You can use</p>
<div><div><pre><code>pip freeze <span>&gt;</span> requirments.txt
</code></pre></div></div>

<p>or update it manually.</p>

<h3 id="step-2-change-the-file-structure-of-the-repo">Step 2: change the file structure of the repo</h3>
<p>Create a “main folder,” in my case, called “<a href="https://github.com/ternaus/retinaface/tree/master/retinaface">retinaface</a>,” the same as the repository.</p>

<ul>
  <li>Move all the important code there.</li>
  <li>Do <strong>not</strong> move helper images, Readme, notebooks, or tests there.</li>
</ul>

<p>Doing it manually and updating all imports would be painful. PyCharm or similar IDE will do it for you.</p>

<p>This is a common way to structure code in the repositories.</p>

<p>I hope, in the future, you will follow this pattern from the beginning. If you want something even more structured, check out <a href="https://github.com/cookiecutter/cookiecutter">Cookie Cutter</a> package.</p>

<h3 id="step-2-add-config-file">Step 2: add config file.</h3>
<ul>
  <li>Add setup.py to the root of the folder with the content similar to <a href="https://github.com/ternaus/retinaface/blob/master/setup.py">setup.py</a></li>
  <li>Add a version for the package. In my case, I added it to the <a href="https://github.com/ternaus/retinaface/blob/master/retinaface/__init__.py">init file</a> of the “main” folder.</li>
</ul>

<h3 id="step-3-create-an-account-at-pypi">Step 3: create an account at PyPI</h3>
<p>If you do not have an account at <a href="https://pypi.org/">PyPI</a>, it is time to create it.</p>

<h3 id="step-4-build-a-library-and-upload-to-pypi">Step 4: build a library and upload to PyPI</h3>

<div><div><pre><code>python setup.py sdist
python setup.py sdist upload
</code></pre></div></div>

<p>That is it. Your …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ternaus.blog/tutorial/2020/08/28/Trained-model-what-is-next.html">https://ternaus.blog/tutorial/2020/08/28/Trained-model-what-is-next.html</a></em></p>]]>
            </description>
            <link>https://ternaus.blog/tutorial/2020/08/28/Trained-model-what-is-next.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24437167</guid>
            <pubDate>Thu, 10 Sep 2020 22:23:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fun and Games in Emacs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24437089">thread link</a>) | @tosh
<br/>
September 10, 2020 | https://masteringemacs.com/article/fun-games-in-emacs | <a href="https://web.archive.org/web/*/https://masteringemacs.com/article/fun-games-in-emacs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <article>
        
        
        
            
        
        
            
        
        
            
                
            
            <img src="https://masteringemacs.com/static/img/fleuron2.gif">
            
<p>It’s yet another Monday and you’re hard at work on those <a href="https://en.wikipedia.org/wiki/Office_Space">TPS reports</a> for your boss, Lumbergh. Why not play Emacs’s Zork-like text adventure game to take your mind off the tedium of work?</p><p>But seriously, yes, there are both games and quirky playthings in Emacs. Some you have probably heard of or played before. The only thing they have in common is that most of them were added a <em>long</em> time ago: some are rather odd inclusions (as you’ll see below) and others were clearly written by bored employees or graduate students. What they all have in common is a whimsy and a casualness that I rarely see in Emacs today. Emacs is Serious Business now in a way that it probably wasn’t back in the 1980s when some of these games were written.</p><h2 id="tower-of-hanoi">Tower of Hanoi</h2><p>The <a href="https://en.wikipedia.org/wiki/Tower_of_Hanoi">Tower of Hanoi</a> is an ancient mathematical puzzle game and one that is probably familiar to some of us as it is often used in Computer Science as a teaching aid because of its recursive and iterative solutions.</p><p><img src="https://masteringemacs.com/static/uploads/hanoi.png" alt="Tower of Hanoi Screenshot"></p><p>In Emacs there are three commands you can run to trigger the Tower of Hanoi puzzle: <code>M-x hanoi</code> with a default of 3 discs; <code>M-x hanoi-unix</code> and <code>M-x hanoi-unix-64</code> uses the unix timestamp, making a move each second in line with the clock, and with the latter pretending it uses a 64-bit clock.</p><p>The Tower of Hanoi implementation in Emacs dates from the mid 1980s — an awful long time ago indeed. There are a few <em>Customize</em> options (<code>M-x customize-group RET hanoi RET</code>) such as enabling colorized discs. And when you exit the Hanoi buffer or type a character you are treated to a sarcastic goodbye message (see above.)</p><h2 id="x5">5x5</h2><p><img src="https://masteringemacs.com/static/uploads/5x5.png" alt="5x5 game grid"> The 5x5 game is a logic puzzle: you are given a 5x5 grid with a central cross already filled-in; your goal is to fill all the cells by toggling them on and off in the right order to win. It’s not as easy as it sounds!</p><p>To play, type <code>M-x 5x5</code>, and with an optional digit argument you can change the size of the grid. What makes this game interesting is its rather complex ability to suggest the next move and attempt to solve the game grid. It uses Emacs’s very own, and very cool, symbolic RPN calculator <code>M-x calc</code> (and in <a href="https://masteringemacs.com/article/fun-emacs-calc">Fun with Emacs Calc</a> I use it to solve a simple problem.)</p><p>So what I like about this game is that it comes with a very complex solver – really, you should read the source code with <code>M-x find-library RET 5x5</code> – and a “cracker” that attempts to brute force solutions to the game.</p><p>Try creating a bigger game grid, such as <code>M-10 M-x 5x5</code>, and then run one of the <code>crack</code> commands below. The crackers will attempt to iterate their way to the best solution. This runs in real time and is fun to watch:</p><dl><dt><code>M-x 5x5-crack-mutating-best</code></dt><dd><p>Attempt to crack 5x5 by mutating the best solution.</p></dd><dt><code>M-x 5x5-crack-mutating-current</code></dt><dd><p>Attempt to crack 5x5 by mutating the current solution.</p></dd><dt><code>M-x 5x5-crack-randomly</code></dt><dd><p>Attempt to crack 5x5 using random solutions.</p></dd><dt><code>M-x 5x5-crack-xor-mutate</code></dt><dd><p>Attempt to crack 5x5 by xoring the current and best solution.</p></dd></dl><h2 id="text-animation">Text Animation</h2><p>You can display a fancy birthday present animation by running <code>M-x animate-birthday-present</code> and giving it your name. It looks rather cool!</p><p><img src="https://imgs.xkcd.com/comics/real_programmers.png" alt="xkcd"></p><p>The <code>animate</code> package is also used by <code>M-x butterfly</code> command, a command added to Emacs as an homage to the <a href="http://www.xkcd.com/">XKCD</a> strip above. Of course the Emacs command in the strip is <em>teeechnically</em> not valid but the humor more than makes up for it.</p><h2 id="blackbox">Blackbox</h2><p>The objective of this game I am going to quote literally:</p><blockquote><p>The object of the game is to find four hidden balls by shooting rays into the black box. There are four possibilities: 1) the ray will pass thru the box undisturbed, 2) it will hit a ball and be absorbed, 3) it will be deflected and exit the box, or 4) be deflected immediately, not even being allowed entry into the box.</p></blockquote><p>So, it’s a bit like the <a href="https://en.wikipedia.org/wiki/Battleship_(game)">Battleship</a> most of us played as kids but… for people with advanced degrees in physics?</p><p>It’s another game that was added back in the 1980s. I suggest you read the extensive documentation on how to play by typing <code>C-h f blackbox</code>.</p><h2 id="bubbles">Bubbles</h2><p><img src="https://masteringemacs.com/static/uploads/bubbles.png" alt="Bubbles game"></p><p>The <code>M-x bubbles</code> game is rather simple: you must clear out as many “bubbles” as you can in as few moves as possible. When you remove bubbles the other bubbles drop and stick together. It’s a fun game that, as an added bonus, comes with graphics if you use Emacs’s GUI. It also works with your mouse.</p><p>You can configure the difficulty of the game by calling <code>M-x bubbles-set-game-&lt;difficulty&gt;</code> where <code>&lt;difficulty&gt;</code> is one of: <code>easy</code>, <code>medium</code>, <code>difficult</code>, <code>hard</code>, or <code>userdefined</code>. Furthermore, you can alter the graphics, grid size and colors using Customize: <code>M-x customize-group bubbles</code>.</p><p>For its simplicity and fun factor, this ranks as one of my favorite games in Emacs.</p><h2 id="fortune-cookie">Fortune &amp; Cookie</h2><p>I like the <code>fortune</code> command. Snarky, unhelpful and often sarcastic “advice” mixed in with literature and riddles brightens up my day whenever I launch a new shell.</p><p>Rather confusingly there are two packages in Emacs that does more-or-less the same thing: <code>fortune</code> and <code>cookie1</code>. The former is geared towards putting fortune cookie messages in email signatures and the latter is just a simple reader for the fortune format.</p><p>Anyway, to use Emacs’s <code>cookie1</code> package you must first tell it where to find the file by customizing the variable <code>cookie-file</code> with <code>customize-option RET cookie RET</code>.</p><p>If you’re on Ubuntu you will have to install the <code>fortune</code> package first. The files are found in the <code>/usr/share/games/fortunes/</code> directory.</p><p>You can then call <code>M-x cookie</code> or, should you want to do this, find all matching cookies with <code>M-x cookie-apropos</code>.</p><h2 id="decipher">Decipher</h2><p>This package perfectly captures the utilitarian nature of Emacs: it’s a package to help you break simple substitution ciphers (like cryptogram puzzles) using a helpful user interface. You just know that – more than twenty years ago – someone <em>really</em> had a dire need to break a lot of basic ciphers. It’s little things like this module that makes me overjoyed to use Emacs: a module of scant importance to all but a few people and, yet, should you need it – there it is.</p><p>So how do you use it then? Well, let’s consider the “rot13” cipher: rotating characters by 13 places in a 26-character alphabet. It’s an easy thing to try out in Emacs with <code>M-x ielm</code>, Emacs’s REPL for <a href="https://masteringemacs.com/article/evaluating-elisp-emacs">Evaluating Elisp</a>:</p><pre><code>*** Welcome to IELM ***  Type (describe-mode) for help.
ELISP&gt; (rot13 "Hello, World")
"Uryyb, Jbeyq"
ELISP&gt; (rot13 "Uryyb, Jbeyq")
"Hello, World"
ELISP&gt;</code></pre><p>Simply put, you rotate your plaintext 13 places and you get your ciphertext; you rotate is another 13 and you end up where you started. This is the sort of thing this package can help you solve.</p><p>So how can the decipher module help us here? Well, create a new buffer <code>test-cipher</code> and type in your cipher text (in my case <code>Uryyb, Jbeyq</code>)</p><p><img src="https://masteringemacs.com/static/uploads/cipher.png" alt="cipher"></p><p>You’re now presented with a rather complex interface. You can now place the point on any of the characters in the ciphertext on the purple line and guess what the character might be: Emacs will update the rest of the plaintext guess with your choices and tell you how the characters in the alphabet have been allocated thus far.</p><p>You can then start winnowing down the options using various helper commands to help infer which cipher characters might correspond to which plaintext character:</p><dl><dt><code>D</code></dt><dd><p>Shows a list of digrams (two-character combinations from the cipher) and their frequency</p></dd><dt><code>F</code></dt><dd><p>Shows the frequency of each ciphertext letter</p></dd><dt><code>N</code></dt><dd><p>Shows adjacency of characters. I am not entirely sure how this works.</p></dd><dt><code>M</code> and <code>R</code></dt><dd><p>Save and restore a checkpoint, allowing you to branch your work and explore different ways of cracking the cipher.</p></dd></dl><p>All in all, for such an esoteric task, this package is rather impressive! If you regularly solve cryptograms maybe this package can help?</p><h2 id="doctor">Doctor</h2><p><img src="https://masteringemacs.com/static/uploads/doctor.png" alt="doctor"></p><p>Ah, the Emacs doctor. Based on the original <a href="https://en.wikipedia.org/wiki/ELIZA">ELIZA</a> the “Doctor” tries to psychoanalyze what you say and attempts to repeat the question back to you. Rather fun, for a few minutes, and one of the more famous Emacs oddities. You can run it with <code>M-x doctor</code>.</p><h2 id="dunnet">Dunnet</h2><p>Emacs’s very own Zork-like text adventure game. To play it, type <code>M-x dunnet</code>. It’s rather good, if short, but it’s another rather famous Emacs game that too few have actually played through to the end.</p><p>If you find yourself with time to kill between your TPS reports then it’s a great game with a built-in “boss screen” as it’s text-only.</p><p>Oh, and, don’t try to eat the CPU card :)</p><h2 id="gomoku">Gomoku</h2><p><img src="https://masteringemacs.com/static/uploads/gomoku.png" alt="gomoku"></p><p>Another game written in the 1980s. You have to connect 5 squares, tic-tac-toe style. You can play against Emacs with <code>M-x gomoku</code>. The game also supports the mouse, which is rather handy. You can customize the group <code>gomoku</code> to adjust the size of the grid.</p><h2 id="game-of-life">Game of Life</h2><p><a href="https://en.wikipedia.org/wiki/Conway's_Game_of_Life">Conway’s Game of Life</a> is a famous example of cellular automata. The Emacs version comes with a handful of starting patterns that you can (programmatically with elisp) alter by adjusting the <code>life-patterns</code> variable.</p><p>You can trigger a game of life with <code>M-x life</code>. The fact that the whole thing, display code, comments and all, come in at less than 300 characters is also rather impressive.</p><h2 id="pong-snake-and-tetris">Pong, Snake and Tetris</h2><p><img src="https://masteringemacs.com/static/uploads/tetris.png" alt="tetris"></p><p>These classic games are all implemented using the Emacs package <code>gamegrid</code>, a generic framework for building grid-based games like Tetris and Snake. The great thing about the gamegrid package is its compatibility with both graphical and terminal Emacs: if you run Emacs in a GUI you get fancy graphics; if you don’t, you get simple ASCII art.</p><p>You can run the games by typing <code>M-x pong</code>, <code>M-x snake</code>, or <code>M-x tetris</code>.</p><p>The Tetris game in particular is rather faithfully implemented, having both gradual speed increase and the ability to slide blocks into place. And given you have the code to it, you can finally remove that annoying <code>Z</code>-shaped piece no one likes!</p><h2 id="solitaire">Solitaire</h2><p><img src="https://masteringemacs.com/static/uploads/solitaire.png" alt="solitaire image"></p><p>This is <em>not</em> the card game, unfortunately. But a peg-based game where you have to end up with just one stone on the board, by taking a stone (the <code>o</code>) and “jumping” over an adjacent stone into the hole (the <code>.</code>), removing the stone you jumped over in the process. Rinse and repeat until the board is empty.</p><p>Ther…</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://masteringemacs.com/article/fun-games-in-emacs">https://masteringemacs.com/article/fun-games-in-emacs</a></em></p>]]>
            </description>
            <link>https://masteringemacs.com/article/fun-games-in-emacs</link>
            <guid isPermaLink="false">hacker-news-small-sites-24437089</guid>
            <pubDate>Thu, 10 Sep 2020 22:12:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everything you ever wanted to know about terminals (2018)]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 45 (<a href="https://news.ycombinator.com/item?id=24436860">thread link</a>) | @n3t
<br/>
September 10, 2020 | https://xn--rpa.cc/irl/term.html | <a href="https://web.archive.org/web/*/https://xn--rpa.cc/irl/term.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<h3><a href="https://xn--rpa.cc/index.html">ʞ</a> / <a href="https://xn--rpa.cc/irl/index.html">essays</a> /</h3>



<p>so here's a short tutorial on ansi escape codes and terminal control, because you philistines won't stop using ncurses and oh my god <em>WHY ARE WE STILL USING NCURSES IT IS THE TWENTY FIRST FUCKING CENTURY</em></p>

<p>the way terminal emulators handle fancy things like color and cursor shape aren't some mysterious opaque black box you can only access through a library. accessing these capabilities is actually extremely simple; they can even be hardcoded into a text file and displayed by <code>cat</code> or <code>less</code>. or even <a href="http://xn--rpa.cc/ansiglot">curl</a>! the way you do this is with something called <em>ANSI escape sequences.</em></p>

<p>almost all UI changes in a terminal are accomplished through in-band signalling. these signals are triggered with the ASCII/UTF-8 character <strong>‹ESC›</strong> (<code>0x1B</code> or <code>27</code>). it's the same <strong>‹ESC›</strong> character that you send to the terminal when you press the <code>Escape</code> key on your keyboard or a key sequence involving the <code>Alt</code> key. (typing <strong>‹A-c›</strong> for instance sends the characters <strong>‹ESC›</strong> and <strong>‹c›</strong> in very rapid succession; this is why you'll notice a delay in some terminal programs after you press the escape key — it's waiting to try and determine whether the user hit <code>Escape</code> or an alt-key chord.)</p>

<p>the simplest thing we can do with these escapes is to make the text <strong>bold</strong> (or "bright"). we accomplish this by sending the terminal the <strong>‹ESC›</strong> character followed by <code>[1m</code>. <code>[</code> is a character indicating to the terminal what kind of escape we're sending, <code>1</code> indicates bold/bright mode, and <code>m</code> is the control character for formatting escapes.</p>

<p>all text sent after this escape sequence will be bold until we explicitly turn it off again (even if your program terminates). there are two ways we can turn off bright mode: by clearing formatting entirely, using the <code>m</code> formatting command with no arguments or the argument <code>0</code>, or more specifically clearing the bold bit with the <code>21m</code> command. (you'll notice that you can usually turn off modes by prefixing the same number with <code>2</code>.)</p>

<p>in a C program, this might look like the following:</p>

<code><b>#include</b> <cite>&lt;unistd.h&gt;</cite>
<span>#define</span> szstr(str) str,sizeof(str)
<strong>int</strong> main() {
	write(1, szstr(<em>"plain text - \x1b[1mbold text\x1b[0m - plain text"</em>));
}
</code>

<p>the <code>\x1b</code> escape here is a C string escape that inserts hex character <code>0x1B</code> (<strong>‹ESC›</strong>) into the string. it's kind of ugly and unreadable if you're not used to reading source with explicit escapes in it. you can make it a lot less horrible with a handful of defines, tho:</p>

<code><span>#include</span> <em>&lt;unistd.h&gt;</em>
<span>#define</span> szstr(str) str,sizeof(str)

<span>#define</span>     plain "0" /* or "" */
<span>#define</span>        no "2"
<span>#define</span>    bright "1"
<span>#define</span>       dim "2"
<span>#define</span>    italic "3"
<span>#define</span> underline "4"
<span>#define</span>   reverse "7"
<span>#define</span>      with ";"
<span>#define</span>  ansi_esc "\x1b"
<span>#define</span> fmt(style) ansi_esc "[" style "m"

<span>int</span> main() {
	write(1, szstr(    <em>"plain text - "</em>
		fmt(bright)     <em>"bright text"</em>     fmt(no bright) <em>" - "</em>
		fmt(dim)       <em>"dim text"</em>        fmt(no dim)    <em>" - "</em> 
		fmt(italic)    <em>"italic text"</em>     fmt(no italic) <em>" - "</em>
		fmt(reverse)   <em>"reverse video"</em>   fmt(plain)     <em>" - "</em>
		fmt(underline) <em>"underlined text"</em> fmt(no underline) )
	);
}
</code>

<p>the beauty of this approach is that all the proper sequences are generated at <em>compile time</em>, meaning the compiler turns all that into a single string interpolated with the raw escapes. it offers much more readability for the coder at zero cost to the end user.</p>

<p>but hang on, where's that semicolon coming from? it turns out, ansi escape codes let you specify multiple formats per sequence. you can separate each command with a <code>;</code>. this would allow us to write formatting commands like <code>fmt(underline with bright with no italic)</code>, which translates into <code>\x1b[4;1;23m</code> at compile time.</p>

<p>of course, being able to style text isn't nearly good enough. we also need to be able to color it. there are two components to a color command: what we're trying to change the color of, and what color we want to change it to. both the foreground and background can be given colors separately - despite what ncurses wants you to believe, you do not have to define """color pairs""" with each foreground-background pair you're going to use. this is a ridiculous archaism that nobody in the 21st fucking century should be limited by.</p>

<p>to target the foreground, we send the character <code>3</code> for normal colors or <code>9</code> for bright colors; to target the background, we send <code>4</code> for normal or <code>10</code> for bright. this is then followed by a color code selecting one of the traditional 8 terminal colors.</p>

<p>note that the "bright" here is both the same thing and something different from the "bright" mode we mentioned earlier. while turning on the "bright" mode will automatically shift text it applies to the bright variant of its color <em>if</em> it is set to one of the traditional 8 colors, setting a "bright color" with <code>9</code> or <code>10</code> will not automatically make the text bold.</p>

<code><span>#include</span> <em>&lt;unistd.h&gt;</em>
<span>#define</span> szstr(str) str,sizeof(str)

<span>#define</span> fg "3"
<span>#define</span> br_fg "9"
<span>#define</span> bg "4"
<span>#define</span> br_bg "10"
<span>#define</span> with ";"
<span>#define</span>      plain ""
<span>#define</span>      black "0"
<span>#define</span>        red "1"
<span>#define</span>      green "2"
<span>#define</span>     yellow "3"
<span>#define</span>       blue "4"
<span>#define</span>    magenta "5"
<span>#define</span>       cyan "6"
<span>#define</span>      white "7"
<span>#define</span>   ansi_esc "\x1b"
<span>#define</span> fmt(style) ansi_esc "[" style "m"

<span>int</span> main() {
	write(1, szstr(
		<em>"plain text - "</em>
		fmt(fg blue) <em>"blue text"</em> fmt(plain)               <em>" - "</em>
		fmt(br_fg blue) <em>"bright blue text"</em> fmt(plain)     <em>" - "</em>
		fmt(br_bg red) <em>"bright red background"</em> fmt(plain) <em>" - "</em>
		fmt(fg red with br_bg magenta) <em>"hideous red text"</em> fmt(plain))
	);
}
</code>

<p>when we invoke <code>fmt(fg red with br_bg magenta)</code>, this is translated by the compiler into the command string <code>\x1b[31;105m</code>. note that we're using <code>fmt(plain)</code> (<code>\x1b[m</code>) to clear the coloring here; this is because if you try to reset colors with, for instance, <code>fmt(fg black with bg white)</code>, you'll be overriding the preferences of users who have their terminal color schemes set to anything but that exact pair. additionally, if the user happens to have a terminal with a transparent background, a set background color will create ugly colored blocks around text instead of letting whatever's behind the window display correctly.</p>

<p>now, while it is more polite to use the "8+8" colors because they're a color palette the end-user can easily configure (she might prefer more pastel colors than the default harsh pure-color versions, or change the saturation and lightness to better fit with her terminal background), if you're doing anything remotely interesting UI-wise you're going to run up against that limit very quickly. while you can get a bit more mileage by mixing colors with styling commands, if you want to give <em>any</em> configurability to the user in terms of color schemes (as you rightly should), you'll want access to a much broader palette of colors.</p>

<p>to pick from a 256-color palette, we use a slightly different sort of escape: <code>\x1b[38;5;<em>(color)</em>m</code> to set the foreground and <code>\x1b[48;5;<em>(color)</em>m</code> to set the background, where <em>(color)</em> is the palette index we want to address. these escapes are even more unwieldy than the 8+8 color selectors, so it's even more important to have good abstraction.</p>

<code><span>#include</span> <em>&lt;unistd.h&gt;</em>
<span>#define</span> szstr(str) str,sizeof(str)

<span>#define</span>       with ";"
<span>#define</span>      plain ";"
<span>#define</span> wfg(color) "38;5;" #color
<span>#define</span> wbg(color) "48;5;" #color
<span>#define</span>   ansi_esc "\x1b"
<span>#define</span> fmt(style) ansi_esc "[" style "m"

<span>int</span> main() {
	write(1, szstr(<em>"plain text - "</em>
		fmt(wfg(198) with wbg(232))
			<em>"rose text on dark grey"</em>
		fmt(plain) <em>" - "</em>
		
		fmt(wfg(232) with wbg(248))
			<em>"dark grey on light grey"</em>
		fmt(plain) <em>" - "</em>
		
		fmt(wfg(248) with wbg(232))
			<em>"light grey on dark grey"</em>
		fmt(plain))
	);
}
</code>
<p>here, the stanza <code>fmt(wfg(248) with wbg(232))</code> translates into <code>\x1b[38;5;248;48;5;232m</code>. we're hard-coding the numbers here for simplicity but as a rule of thumb, any time you're using 8-bit colors in a terminal, you should <em>always</em> make them configurable by the user.</p>

<p>the opaque-seeming indexes are actually very systematic, and you can calculate which index to use for a particular color with the formula <code>16 + 36 * r + 6 * g + b</code>, where <code>r</code>, <code>g</code>, and <code>b</code> are integers ranging between 0 and 5. indices 232 through 255 are a grayscale ramp from dark (232) to light (255).</p>

<p>of course, this is still pretty restrictive. 8-bit color may have been enough for '90s CD-ROM games on Windows, but it's long past it's expiration date. using true color is much more flexible. we can do this through the escape sequence <code>\x1b[38;2;<em>(r)</em>;<em>(g)</em>;<em>(b)</em>m</code> where each component is an integer between 0 and 255.</p>

<p>sadly, true color isn't supported on many terminals, urxvt tragically included. for this reason, your program should never rely on it, and abstract these settings away to be configured by the user. defaulting to 8-bit color is a good choice, as every reasonable modern terminal has supported it for a long time now.</p>

<p>but, for users of XTerm, kitty, Konsole, and libVTE-based terminal emulators (such as gnome-terminal, mate-terminal, and termite), it's polite to have a 24-bit color mode in place. for example:</p>

<code><span>#include</span> <em>&lt;stdio.h&gt;</em>
<span>#include</span> <em>&lt;stdint.h&gt;</em>
<span>#include</span> <em>&lt;stdbool.h&gt;</em>

<span>struct</span> color {
	<span>enum</span> color_mode { trad, trad_bright, b8, b24 } mode;
	<span>union</span> {
		<span>uint8_t</span> color;
		<span>struct</span> { <span>uint8_t</span> r, g, b; };
	}
};
<span>struct</span> style {
	unsigned <span>char</span> bold      : 1;
	unsigned <span>char</span> underline : 1;
	unsigned <span>char</span> italic    : 1;
	unsigned <span>char</span> dim       : 1;
	unsigned <span>char</span> reverse   : 1;
};
<span>struct</span> format {
	<span>struct</span> style style;
	<span>struct</span> color fg, bg;
};

<span>struct</span> format
	fmt_menu = {
		{0, 0, 0, 0, 0},
		{trad, 7},
		{trad, 4}
	},
	fmt_menu_hl = {
		{1, 0, 0, 0, 0},
		{trad_bright, 7},
		{trad_bright, 4},
	};

<span>void</span> apply_color(<span>bool</span> bg, <span>struct</span> color c) {
	switch(c.mode) {
		case trad: printf(<em>"%c%u"</em>, bg ? <em>'4'</em> : <em>'3'</em>, c.color ); break;
		case trad_bright: printf(<em>"%s%u"</em>, bg ? <em>"9"</em> : <em>"10"</em>, c.color ); break;
		case b8: printf(<em>"%c8;5;%u"</em>, bg ? <em>'4'</em> : <em>'3'</em>, c.color); break;
		case b24: printf(<em>"%c8;2;%u;%u;%u"</em>, bg ? <em>'4'</em> : <em>'3'</em>, c.r, c.b, c.g);
	}
}

<span>void</span> fmt(struct format f) {
	printf(<em>"\x1b["</em>);
	f.bold      &amp;&amp; printf(<em>";1"</em>);
	f.underline &amp;&amp; printf(<em>";4"</em>);</code></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://xn--rpa.cc/irl/term.html">https://xn--rpa.cc/irl/term.html</a></em></p>]]>
            </description>
            <link>https://xn--rpa.cc/irl/term.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24436860</guid>
            <pubDate>Thu, 10 Sep 2020 21:44:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Open Source Community Is Not Defenseless Against Patent Trolls]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24436763">thread link</a>) | @Andrew_Russell
<br/>
September 10, 2020 | https://ipde.com/blog/open-source-community-not-defenseless-against-patent-trolls/ | <a href="https://web.archive.org/web/*/https://ipde.com/blog/open-source-community-not-defenseless-against-patent-trolls/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <div>
                    <section>
                        <div><figure "=""><img src="https://bd6f.s3.amazonaws.com/media/images/jamie-street-5gvSBUZ6K10-unsplash_pXTLyQl.max-640x360.jpg" alt="I assume there is a troll in here somewhere" srcset="https://bd6f.s3.amazonaws.com/media/images/jamie-street-5gvSBUZ6K10-unsplash_pXTLyQl.max-640x360.jpg 610w, https://bd6f.s3.amazonaws.com/media/images/jamie-street-5gvSBUZ6K10-unsplash_pXTLyQl.max-768x432.jpg 733w, https://bd6f.s3.amazonaws.com/media/images/jamie-street-5gvSBUZ6K10-unsplash_pXTLyQl.max-1024x576.jpg 977w, https://bd6f.s3.amazonaws.com/media/images/jamie-street-5gvSBUZ6K10-unsplash_pXTLyQl.max-1600x900.jpg 1527w, https://bd6f.s3.amazonaws.com/media/images/jamie-street-5gvSBUZ6K10-unsplash_pXTLyQl.max-1920x1080.jpg 1832w"><figcaption><span>I assume there is a troll in here somewhere</span> <span><a href="https://unsplash.com/photos/5gvSBUZ6K10">Jamie Street</a>, <a href="https://unsplash.com/license">Unsplash</a></span></figcaption></figure><p>As I <a href="https://ipde.com/blog/rothschild-covenant-not-sue-made-public-purported-cover-most-open-source-software/">mentioned</a> earlier this week, I recently saw a <a href="https://blog.hansenpartnership.com/lessons-from-the-gnome-patent-troll-incident/">fascinating article</a> by James Bottomley relating a non-attorneys' view on patent trolls and a specific attack against <a href="https://en.wikipedia.org/wiki/GNOME">GNOME</a>, a well-known component of many open source Linux- and Unix-based operating systems.</p><p>The GNOME Foundation was sued in the N.D. Cal. by a Rothschild entity (a well-known <a href="#" data-toggle="tooltip" data-placement="top" title="Non-Practicing Entity">NPE</a>). The case involved what looks like a pretty typical <a href="#" data-toggle="tooltip" data-placement="top" title="Non-Practicing Entity">NPE</a> complaint, alleging infringement of a single patent. His article recounted his experiences and the settlement, and argues that the patent system is broken because of how hard it is to defend against these kinds of suits.</p><p>I wanted to take a quick break from our usual deep-in-the-litigation-weeds fare and offer a patent litigator's perspective on what Bottomley said.</p><p>This article is written for any non-lawyers who saw Bottomley's article and who may be unfamiliar with patent litigation—<b>I expect our regular readers will already know all of this!</b></p><h2>Yes, Patent Troll Behavior Is a Problem</h2><p>The article is right in its basic description of patent troll / <a href="#" data-toggle="tooltip" data-placement="top" title="Non-Practicing Entity">NPE</a> behavior, which matches what we've all seen time and again. In Delaware specifically (currently the nation's busiest patent forum), there have been more of these kinds of cases lately, ever since <i><a href="#" data-toggle="tooltip" data-placement="top" title="TC Heartland LLC v. Kraft Foods Grp. Brands LLC, 137 S. Ct. 1514 (2017)">TC Heartland</a></i> changed the venue rules and many NPEs started filing here instead of the Eastern District of Texas.</p><p>But it's also <a href="https://opensource.com/law/15/8/patent-troll-problem-not-new-one">nothing new</a>. There have been many, many troll cases over the years, and it's part of what drove the passing of the America Invents Act in 2011, which created the <a href="#" data-toggle="tooltip" data-placement="top" title="Inter Partes Review">IPR</a> procedure Bottomley mentions. And those who practice in the area know that there are techniques for dealing with troll cases.</p><h2>Targets in the Open Source Community Are Not Defenseless</h2><p>Bottomley's article makes a few statements and understandable mistakes that make targets seem more defenseless than they really are:</p><ul><li><b>The presumption of validity:</b> Yes, issued U.S. Patents are presumed valid, but it's just a presumption. In practice, it means little more than a higher burden of proof on validity issues ("clear and convincing" evidence instead of a "preponderance" of the evidence.) Courts and juries still <a href="https://ipde.com/blog/judge-connolly-knocks-out-five-patents-rule-12-motion/">regularly</a> <a href="https://ipde.com/blog/berkheimer-more-brokeheimer/">invalidate</a> U.S. patent claims for a variety of reasons.</li><li><b>Summary judgment is available:</b> Summary judgment is available in most patent cases, and summary judgment of invalidity absolutely does happen. In Delaware, while summary judgment typically happens late in the case, the judges can be open to considering it earlier in the case if you've got the right facts. Something along the lines of "our product was released before the priority date of the patent"—as described in the article—sounds like a pretty good set of facts.</li><li><b>There are a number of ways to invalidate a patent:</b> Bottomley touches on <a href="#" data-toggle="tooltip" data-placement="top" title="35 U.S.C. § 101: Inventions patentable">§ 101</a> and <i>Alice</i> decision, which allow defendants to argue that patents are invalid for claiming an abstract idea. There is also <a href="#" data-toggle="tooltip" data-placement="top" title="35 U.S.C. § 102: Anticipation">§ 102</a> (anticipation, i.e., the idea already existed), <a href="#" data-toggle="tooltip" data-placement="top" title="35 U.S.C. § 103: Obviousness">§ 103</a> (the idea was obvious), and § 112, which covers a range of technical deficiencies in patents, such as indefiniteness (where a person cannot be "reasonably certain" what the words in the patent claims mean). There are also other defenses, such as inequitable conduct (e.g., certain misrepresentations before the PTO).</li><li><b>You don't need to wait for summary judgment to challenge a patent:</b> The article incorrectly implies that early <a href="#" data-toggle="tooltip" data-placement="top" title="35 U.S.C. § 101: Inventions patentable">§ 101</a> motions are impossible. While early <a href="#" data-toggle="tooltip" data-placement="top" title="35 U.S.C. § 101: Inventions patentable">§ 101</a> motions have become a <a href="https://www.law360.com/articles/1181804/quick-alice-wins-dwindling-in-wake-of-berkheimer-ruling">bit harder</a> since the Federal Circuit's 2018 <i>Berkheimer</i> decision, they are still granted <a href="https://ipde.com/blog/berkheimer-more-brokeheimer/">rather frequently</a>. Section 101 definitely increases the risk to patent trolls. And indefiniteness under § 112 is often addressed at claim construction, which usually occurs before summary judgment.</li><li><b><a href="#" data-toggle="tooltip" data-placement="top" title="35 U.S.C. § 285: Attorney fees">§ 285</a> fees:</b> As the article rightly notes, <a href="#" data-toggle="tooltip" data-placement="top" title="35 U.S.C. § 285: Attorney fees">§ 285</a> provides the ability to seek fees in exceptional cases. And while NPEs may have few monetary assets, parties have sometimes succeeded in claiming the patent that the <a href="#" data-toggle="tooltip" data-placement="top" title="Non-Practicing Entity">NPE</a> holds, potentially ending the threat for everyone. (Note that Bottomley is incorrect in that an award of fees under <a href="#" data-toggle="tooltip" data-placement="top" title="35 U.S.C. § 285: Attorney fees">§ 285</a> does not, by itself, pierce the corporate veil and reach assets beyond those of the <a href="#" data-toggle="tooltip" data-placement="top" title="Non-Practicing Entity">NPE</a>).</li></ul><p>Section 101 invalidity is especially noteworthy, since most suits relating to open source software are going to be related to, well, software. And unless Congress decides to cut it back (last I heard, that movement has <a href="https://www.aei.org/technology-and-innovation/1-year-later-patent-eligibility-reform-no-further-along/">stalled</a>), <a href="#" data-toggle="tooltip" data-placement="top" title="35 U.S.C. § 101: Inventions patentable">§ 101</a> remains a powerful tool against a lot of older software patents.</p><p>Beyond the above, all of the normal defenses in any patent infringement case are available in cases against tech non-profits, including things like non-infringement (i.e., the accused product doesn't actually practice the claims). Plus, as Bottomley touched on, there are <a href="https://www.theregister.com/2019/11/04/open_invention_network_will_pivot_to_take_on_patent_trolls/">broad</a> <a href="https://openinventionnetwork.com/">initiatives</a> <a href="https://www.ipwatchdog.com/2020/07/14/limiting-impact-patent-assertion-entities-open-source-community/id=123260/">going on</a> to defend open-source software against troll suits generally.</p><h2>Pro Bono Representation Is Often Available</h2><p>Bottomley includes a call to action for open source organizations to tell everyone when they are attacked by a patent troll, because "you won’t get . . . pro bono representation . . . unless people know about it."</p><p>That's not necessarily true. You don't have to run a P.R. campaign to get <i>pro bono</i> (free) patent representation (although having <a href="https://secure.givelively.org/donate/gnome-foundation-inc/gnome-patent-troll-defense-fund">$150k at the ready</a> certainly increases your options in a case). For non-profits, very small businesses, and other such noble causes, there is help available.</p><p>The EFF, for example, maintains an <a href="https://www.eff.org/pages/legal-assistance">attorney referral list</a> for those seeking pro bono help. I've represented clients <i>pro bono</i> against patent and copyright trolls through referrals from that list and elsewhere, and I know that a number of other attorneys do the same.</p><p>Moving to <i>pro bono</i> representation changes the cost calculus for a troll. The target is no longer facing millions of dollars in attorneys' fees, but the <a href="#" data-toggle="tooltip" data-placement="top" title="Non-Practicing Entity">NPE</a> still faces the threat of patent invalidation and <a href="#" data-toggle="tooltip" data-placement="top" title="35 U.S.C. § 285: Attorney fees">§ 285</a> attorneys' fees. And courts have regularly permitted the recovery of attorneys fees in <i>pro bono</i> cases, even if the defendant itself was not on the hook for them.</p><p>Plus, dedicated patent litigators know the tricks in their districts to help get these cases dealt with as quickly as possible. It doesn't fix everything—as the article notes, patent litigation can be expensive even with free representation. But it definitely helps.</p></div>
                        <p><span>If you enjoyed this post, consider subscribing to receive daily or weekly e-mails about any new posts.</span></p>
                        
                    </section>
                </div>
            </div></div>]]>
            </description>
            <link>https://ipde.com/blog/open-source-community-not-defenseless-against-patent-trolls/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24436763</guid>
            <pubDate>Thu, 10 Sep 2020 21:31:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Timing-Safe Bcrypt Authentication in PostgreSQL]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24436729">thread link</a>) | @danielfone
<br/>
September 10, 2020 | https://daniel.fone.net.nz/blog/2020/09/09/timing-safe-bcrypt-authentication-in-postgresql/ | <a href="https://web.archive.org/web/*/https://daniel.fone.net.nz/blog/2020/09/09/timing-safe-bcrypt-authentication-in-postgresql/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <p>
      September 2020
      ·
      about 5  minutes to read
    </p>

      <summary>
        <p><strong>tl;dr</strong> To avoid disclosing <abbr title="Personally Identifying Information">PII</abbr> and to prevent user enumeration during authentication, ensure you always perform a hash comparison, even if no user record is found.</p>
      </summary>

    <p>Many applications aim to prevent <a href="https://blog.rapid7.com/2017/06/15/about-user-enumeration/">user enumeration</a> during authentication, particularly if users authenticate themselves with some PII like an email address. Well-designed login forms usually don’t disclose whether the username or password is incorrect, both because the response can be misleading,<sup id="fnref:1"><a href="#fn:1">1</a></sup> and because it will disclose the presence of accounts in the database, facilitating spear-phishing, credential stuffing, and other attacks.</p>

<p>However, while the response body may not disclose this, often the response time still betrays whether a matching user record exists in the database. Because effective password checking like bcrypt is deliberately so slow, the response is much quicker if there is no digest to compare the submitted plain-text against. This oversight can undermine the ambiguity of the response body and expose users to the attacks mentioned above.</p>

<p>Let’s look at an example authentication query in PostgreSQL.<sup id="fnref:2"><a href="#fn:2">2</a></sup> First we’ll add a user record.</p>

<div><pre><code><span>insert</span> <span>into</span> <span>users</span> <span>(</span><span>email</span><span>,</span> <span>password_digest</span><span>)</span>
<span>values</span> <span>(</span><span>'daniel@example.com'</span><span>,</span> <span>crypt</span><span>(</span><span>'my-password'</span><span>,</span> <span>gen_salt</span><span>(</span><span>'bf'</span><span>)));</span>

<span>select</span> <span>*</span> <span>from</span> <span>users</span><span>;</span>

<span>--  id |       email        |                       password_digest</span>
<span>-- ----+--------------------+--------------------------------------------------------------</span>
<span>--   1 | daniel@example.com | $2a$06$xMGQrmx5DrVvfiBqdVhZLeQJOWx95H/B..79VElnBAh/xa5bKGkwG</span>
</code></pre></div>
<p>The <a href="https://www.postgresql.org/docs/12/pgcrypto.html#id-1.11.7.34.6.7">crypt function</a> is provided by the pgcrypto module. It takes a plain-text password and a salt, and returns a hash. Since crypt-style hashes include their salt (along with the algorthim details), the same function can be used to generate new hashes or verify existing ones.<sup id="fnref:3"><a href="#fn:3">3</a></sup> In this case, we use the gen_salt function to generate a bcrypt salt with the default number of iterations (<code>bf</code> is for blowfish which is synonymous with bcrypt here). Note that this only uses the first 72 bytes of the plain-text password, a more secure approach is to digest the entire plain-text first.<sup id="fnref:4"><a href="#fn:4">4</a></sup></p>

<p>Now let’s look at a naive authentication query.</p>

<div><pre><code><span>-- Correct username and password</span>
<span>select</span> <span>*</span>
<span>from</span> <span>users</span>
<span>where</span> <span>email</span> <span>=</span> <span>'daniel@example.com'</span>
  <span>and</span> <span>password_digest</span> <span>=</span> <span>crypt</span><span>(</span><span>'my-password'</span><span>,</span> <span>password_digest</span><span>);</span>
<span>--  id |       email        |                       password_digest</span>
<span>-- ----+--------------------+--------------------------------------------------------------</span>
<span>--   1 | daniel@example.com | $2a$06$xMGQrmx5DrVvfiBqdVhZLeQJOWx95H/B..79VElnBAh/xa5bKGkwG</span>
<span>--</span>
<span>-- Time: 6.692 ms</span>

<span>-- Incorrect password</span>
<span>select</span> <span>*</span>
<span>from</span> <span>users</span>
<span>where</span> <span>email</span> <span>=</span> <span>'daniel@example.com'</span>
  <span>and</span> <span>password_digest</span> <span>=</span> <span>crypt</span><span>(</span><span>'password'</span><span>,</span> <span>password_digest</span><span>);</span>
<span>--  id | email | password_digest</span>
<span>-- ----+-------+-----------------</span>
<span>--</span>
<span>-- Time: 6.513 ms</span>

<span>-- Incorrect email</span>
<span>select</span> <span>*</span>
<span>from</span> <span>users</span>
<span>where</span> <span>email</span> <span>=</span> <span>'noone@example.com'</span>
  <span>and</span> <span>password_digest</span> <span>=</span> <span>crypt</span><span>(</span><span>'my-password'</span><span>,</span> <span>password_digest</span><span>);</span>
<span>--  id | email | password_digest</span>
<span>-- ----+-------+-----------------</span>
<span>--</span>
<span>-- Time: 0.432 ms</span>
</code></pre></div><p>As we can see, checking the password against an existing hash takes several milliseconds, whereas checking the index for an email is comparatively instantaneous. This difference is increased depending on the size of the table and the number of bcrypt iterations (Rails defaults to 10). In an application I recently worked on, the difference was measurable even after the jitter introduced by the application code and network latency.</p>

<p>Whether you’re comparing the digests in the database like this, or taking the more common approach of comparing the hashes in your application code, <strong>the essential solution is to compare a bcrypt hash even if no real user is found<strong>.</strong></strong></p>

<p>For example:</p>

<div><pre><code><span>with</span>

<span>-- select either the id and password digest matching the email, or a dummy row</span>
<span>target_user</span> <span>as</span> <span>(</span>
  <span>select</span> <span>id</span><span>,</span> <span>password_digest</span>
  <span>from</span> <span>(</span>
    <span>select</span> <span>id</span><span>,</span> <span>password_digest</span> <span>from</span> <span>users</span> <span>where</span> <span>email</span> <span>=</span> <span>:</span><span>password</span>
    <span>union</span> <span>all</span>
    <span>select</span> <span>null</span><span>,</span> <span>gen_salt</span><span>(</span><span>'bf'</span><span>)</span> <span>-- a random salt</span>
  <span>)</span> <span>users</span>
  <span>limit</span> <span>1</span> <span>-- only return the first row, either the real id+digest or the "null" one</span>
<span>),</span>

<span>-- perform bcrypt matching on the guaranteed single row from target_user</span>
<span>valid_user</span> <span>as</span> <span>(</span>
  <span>select</span> <span>id</span> <span>from</span> <span>target_user</span> <span>where</span> <span>password_digest</span> <span>=</span> <span>crypt</span><span>(:</span><span>password</span><span>,</span> <span>password_digest</span><span>)</span>
<span>)</span>

<span>-- select the row from the users table matching the authenticated id</span>
<span>select</span> <span>*</span> <span>from</span> <span>users</span> <span>natural</span> <span>join</span> <span>valid_user</span> <span>limit</span> <span>1</span>
</code></pre></div>
<p>Clearly, this query is a lot more complex than our naive approach, however with judicious use of comments and well-factored subqueries, I think the intention remains relatively clear. Perhaps there are simpler ways to factor this query and achieve the same result —&nbsp;I’d love to see some alternatives! No matter how it’s achieved though, the only way to ensure that the response is truly opaque is to do the same work in all cases. One way or another we need to hash the supplied plain-text.</p>



  </article><div id="featured-posts">
    <h3>Other Posts</h3>
      <h4>
        <a href="https://daniel.fone.net.nz/blog/2014/12/10/handling-token-generation-collisions-in-activerecord/">Handling Token Generation Collisions In ActiveRecord</a>
      </h4>
      <p>Use <code>rescue ActiveRecord::RecordNotUnique</code> with <code>retry</code> to handle collisions when applicable.</p>
      <h4>
        <a href="https://daniel.fone.net.nz/blog/2013/05/20/a-better-way-to-manage-the-rails-secret-token/">A better way to manage the Rails secret token</a>
      </h4>
      <p>Don't store secrets in your source control.</p>
      <h4>
        <a href="https://daniel.fone.net.nz/blog/2014/12/05/efficient-uniqueness-validations/">Efficient Uniqueness Validations</a>
      </h4>
      <p>Use <code>:if =&gt; :field_changed?</code> on uniqueness validations to skip unnecessary checks on every save.</p>
    <p>
      <small><a href="https://daniel.fone.net.nz/blog/archives/">More posts</a></small>
    </p>
  </div></div>]]>
            </description>
            <link>https://daniel.fone.net.nz/blog/2020/09/09/timing-safe-bcrypt-authentication-in-postgresql/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24436729</guid>
            <pubDate>Thu, 10 Sep 2020 21:26:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Create a Successful B2B Social Media Strategy (2020)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24436567">thread link</a>) | @bmmer201
<br/>
September 10, 2020 | https://colonyspark.com/blog/b2b-social-media-strategy/ | <a href="https://web.archive.org/web/*/https://colonyspark.com/blog/b2b-social-media-strategy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p><span>While most B2C companies have mastered the art of social media marketing, many B2B companies are still lagging when it comes to adapting effective social media campaigns. But in today’s social media-driven environment, B2Bs can’t afford to slack. Nearly </span><a href="https://blog.hubspot.com/marketing/b2b-marketing"><span>75%</span></a><span> of B2B buyers use social media to make a purchase decision.&nbsp;</span></p>
<p><img src="https://colonyspark.com/wp-content/uploads/2020/09/buyers-process-e1599547241306.jpeg" alt="75% of B2B buyers now use social media to be more informed on vendors." width="602" height="426"></p>
<p><a href="https://twitter.com/linkedinselling/status/725640736344031232"><span>Source</span></a></p>
<p><span>I’ve compiled six of my top tips for energizing your B2B social media strategy and boosting your traffic as part of your marketing strategy. I’ll go over:</span></p>
<ul>
<li><span>How to set realistic and attainable goals for social media</span></li>
<li><span>Creating buyer personas your customers respond to&nbsp;</span></li>
<li><span>Where and how to post on social media for maximum engagement</span></li>
<li><span>Why documenting your social media strategy is a must</span></li>
<li><span>How to draw audience attention through visuals</span></li>
<li><span>And how to build a cohesive brand presence that resonates</span></li>
</ul>

<h2><b>How Do You Decide Your Social Media Goals? And How Do You Measure Them?&nbsp;</b></h2>
<p><span>Before you start posting on social media, you need to define what you want out of your social media strategy. Determine the criteria for success for your brand on social media. Do you want to increase brand awareness? Get more <a href="https://colonyspark.com/blog/b2b-lead-generation/">leads</a>? Generate more traffic to your website?</span></p>
<p><span>For example, suppose you’re a new company and want to create more brand awareness. In that case, you’ll probably be looking at metrics such as likes, shares, and mentions to evaluate your social media campaigns’ impact.</span></p>
<p><span>If your goal is getting more leads, metric you may want to look at include:</span></p>
<ul>
<li><span>Clicks</span></li>
<li><span>New leads from social media</span></li>
<li><span>Conversions</span></li>
</ul>
<p><b>Determine KPIs</b></p>
<p><span>Once you determine your goals, you want to create measurable KPIs. Your KPIs should be specific and include a timeframe. Some common KPIs include:</span></p>
<ul>
<li><span>Gain 150 more followers on Instagram per month</span></li>
<li><span>Increase social media engagement on Facebook (likes, clicks, shares, and comments) by 20% within 60 days</span></li>
<li><span>Boost blog traffic from social media campaigns by 20% within 30 days</span></li>
<li><span>Increase conversions from social media by 15% within 90 days</span></li>
</ul>
<p><span>Knowing the KPIs you want to reach will help you figure out what actions you need to accomplish them.</span></p>
<p><b>Determine How to Track KPIs</b></p>
<p><span>Once you figure out your goals and the KPIs you’ll use to measure them, make sure you’re using a social media analytics platform to track performance. There are all kinds of tools available on the market for tracking social media metrics, including:</span></p>
<ul>
<li><span>Google Analytics shows you what social media platforms bring the most visitors to your site and conversions from your posts.</span></li>
<li><span>HubSpot Social, which monitors how often people mention your brand and user engagement on social media. Hubspot Social can compare your campaigns’ performance on different social sites and show you the best time to publish content.&nbsp;</span></li>
<li><span>CoSchedule tracks your social posts’ performance with in-depth reports and recommends the best content to post and when to post it.&nbsp;</span></li>
<li><span>BuzzSumo shows your most shared posts on social media and helps you find the top influencers in your industry.&nbsp;</span></li>
</ul>
<h2><b>Understand Your Audience</b></h2>
<p><span>In a previous blog, I mentioned that your </span><a href="https://colonyspark.com/blog/company-values/"><span>company values</span></a><span> should be your customer’s values, and social media is no different. Your social media strategy should revolve around what your audience finds valuable. Social listening allows you to find your customers’ conversations and is the best way to discover key audience insights.&nbsp;</span></p>
<p><span>Here are some tips on how to tap into your customers’ conversations.&nbsp;</span></p>
<p><b>Competitors</b></p>
<p><span>It’s a no-brainer that your competitor’s audience is similar to yours. See how your competitors are engaging with customers online. Discover the kinds of conversations surrounding the competitor in their communities. What do people most like and dislike about the competing company? You can leverage this information in your social media campaigns. For example, if there are repeated complaints about the competitor’s service, you can build your social media presence on being “professional and helpful.”</span></p>
<p><b>Influencers</b></p>
<p><span>Influencers are thought-leaders in your industry with large followings. Keep an eye out for conversations influencers have with your audience to get information on new developments and trends in your industry.&nbsp;</span></p>
<p><b>Keywords</b></p>
<p><span>Make a list of industry-related keywords and track and follow conversations around your brand. You’ll discover more about your customers’ interests and motivations. As mentioned briefly in the previous section, platforms like Hubspot Social, BuzzSumo, and CoSchedule can help you manage this and other social listening tasks.&nbsp;</span></p>
<p><b>Hashtags</b></p>
<p><span>Monitor brand-related hashtags. If you find your business or products aren’t mentioned at all, it’s a signal you need to increase brand awareness.&nbsp;</span></p>
<h3><b>Create Buyer Personas</b></h3>
<p><span>Social listening is good for another reason. You need to know your customers’ likes and dislikes to create useful buyer personas. Research shows that </span><a href="https://boardview.io/blog/buyer-personas-33-mind-blowing-stats/"><span>71%</span></a><span> of companies who exceed revenue and lead goals have documented buyer personas.</span></p>
<p><img src="https://colonyspark.com/wp-content/uploads/2020/09/buyer-personas-help-revenue.jpeg" alt=" 71% of companies who exceed revenue and lead goals have documented buyer personas." width="495" height="359" srcset="https://colonyspark.com/wp-content/uploads/2020/09/buyer-personas-help-revenue.jpeg 495w, https://colonyspark.com/wp-content/uploads/2020/09/buyer-personas-help-revenue-300x218.jpeg 300w" sizes="(max-width: 495px) 100vw, 495px"></p>
<p><a href="https://www.linkedin.com/pulse/study-confirms-importance-qualitative-research-success-tony-zambito/"><span>Source</span></a></p>
<p><span>There’s a lot of advice on building effective buyer personas, but I found this method the simplest. Analyze the social media profiles of business managers who already purchased your product or service. They represent customer groups and help you understand your target market.&nbsp;</span></p>
<p><span>You can keep track of their information in Excel by listing their names, contact information, and social profiles. If you can find it, also list other demographics such as age, position, industry, and business size.&nbsp;</span></p>
<p><span>Understanding the people who have already shown interest in your products and building social campaigns around them will boost clicks and engagements on your social media campaigns.&nbsp;</span></p>
<h2><b>Identify Social Media Platforms</b></h2>
<p><span>Social listening tools and buyer personas should have given you a head-start on finding your customers’ social media platforms. Still, some social media platforms are more suited for B2B activities than others. I’ll list a few here:</span></p>
<ul>
<li><span>LinkedIn is the most well-known B2B social site and the most popular among Fortune 500 companies. LinkedIn is the #1 platform used by B2B marketers and makes up over half of all social traffic for B2B blogs and websites.</span></li>
<li><span>Twitter is the second most popular site for B2B businesses, and the next place marketing executives go to after LinkedIn to find good content.&nbsp;</span></li>
<li><span>YouTube is fast becoming popular with B2B companies, with nearly 60% of B2B marketers using the platform to distribute content. Youtube is one of the most effective B2B advertising channels after email marketing, LinkedIn, and print advertising.&nbsp;</span></li>
</ul>
<p><span>These top three social media sites are a good starting point for your B2B social media strategy. However, there are other social media platforms you should look into like Reddit, Pinterest, and Quora.</span></p>
<h2><b>Create a Written Strategy</b></h2>
<p><span>Now that you know your goals, audience, and the social media platforms you intend to use, draft a written plan. A formal plan is one area where B2B marketers are generally failing. While many B2B companies have a social media strategy, many take a seat-of-the-pants stance on execution. </span><a href="http://contentmarketinginstitute.com/wp-content/uploads/2015/09/2016_B2B_Report_Final.pdf"><span>80% of B2B companies have a social media strategy</span></a><span>, but only 32% have a documented plan.&nbsp;</span></p>
<p><img src="https://colonyspark.com/wp-content/uploads/2020/09/conten-strategy-marketers.jpg" alt="Only 32% have a documented content plan." width="602" height="631"></p>
<p><a href="https://contentmarketinginstitute.com/2015/09/b2b-content-marketing-research/"><span>Source</span></a></p>
<p><span>Keeping a document of your social media plan not only allows you to set a roadmap for your goals, but it also allows other people in your company to implement it. Your social media plan should answer the following:</span></p>
<ul>
<li><span>What are your social media goals?</span></li>
<li><span>How will you measure them?</span></li>
<li><span>What are your KPIs?</span></li>
<li><span>Who is your target audience?</span></li>
<li><span>How are your competitors using social media?</span></li>
<li><span>What social platforms are you using?</span></li>
<li><span>What content will you publish?</span></li>
</ul>
<p><span>Take time to write and document your social strategy. A written social media strategy keeps everyone on the same page and allows you to make quick adjustments.&nbsp;</span></p>
<h2><b>Create Content for Social Media</b></h2>
<p><span>Creating content is the meat of an excellent social strategy. Some best practices to keep in mind include:</span></p>
<ul>
<li><b>Establish thought-leadership</b><span> by responding to news and trending topics in your industry. The best way to do this is to follow popular and current companies and figureheads within your industry. Having conversations with industry influencers gives your platform more credibility.&nbsp;</span></li>
<li><b>The more visuals you have, the better.</b><span> Social media with multimedia elements should have the highest rates of engagement. Be sure to post infographics, images, videos, and memes.</span></li>
<li><b>Different buyer personas need different content.</b><span> Customers at the discovery stage of the buyer’s journey will need different content than customers in the decision stage. You can’t take a one-size-fits-all approach to content. You want to make sure you’re reaching customers with quality content at every touchpoint in their journey.&nbsp;</span></li>
<li><b>Have a healthy mix of TOFU (top of the funnel) and BOFU (bottom of the funnel) content. </b><span>TOFU content are things like short videos and infographics that educate buyers. BOFU content are things like product comparisons and user-generated content, such as testimonials.&nbsp;</span></li>
<li><b>Find the best times to post with experimentation.</b><span> The consensus is that the best times to post on social media are Monday – Friday from 10 a.m. to 3 p.m. However, every audience is different, test to see what fits well with your target demographic. Post at least once per day for maximum engagement.&nbsp;</span></li>
<li><b>Celebrate your team members and partners.</b><span> The human interest type of social media posts helps customers more easily relate to your company. You can post employee accomplishments, interviews with experts, and behind the scenes videos from company events.</span></li>
<li><b>You don’t always have to come up with your content.</b><span> Reshare content from reputable third-party sites that’s related to your industry. Research shows people respond the best when <a href="https://colonyspark.com/blog/how-to-do-link-building/">third-party links</a> are shared 50 to 75% of the time, and </span><a href="https://www.convinceandconvert.com/social-media-measurement/new-research-finds-the-curation-vs-creation-sweet-spot/"><span>original content</span></a><span> 25 to 50% of the time. Share a mix of curated content from top industry sources and original content like your blog posts, ebooks, white papers, product videos, and webinars.&nbsp;</span></li>
</ul>
<h2><b>Maintain Consistency</b></h2>
<p><span>I’d be remiss if I don’t share this vital point of a social media strategy: consistency is critical.&nbsp;</span></p>
<p><span>I’m not </span><i><span>only</span></i><span> talking about posting consistently, but your presence online needs to look …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://colonyspark.com/blog/b2b-social-media-strategy/">https://colonyspark.com/blog/b2b-social-media-strategy/</a></em></p>]]>
            </description>
            <link>https://colonyspark.com/blog/b2b-social-media-strategy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24436567</guid>
            <pubDate>Thu, 10 Sep 2020 21:06:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TOML – Tom's Obvious, Minimal Language]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 156 (<a href="https://news.ycombinator.com/item?id=24436550">thread link</a>) | @pmoriarty
<br/>
September 10, 2020 | https://toml.io/en/ | <a href="https://web.archive.org/web/*/https://toml.io/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    <section>
      <div>
        <div>
          <svg viewBox="0 0 128 128" xmlns="http://www.w3.org/2000/svg">
            <g>
              <polygon points="99.2359551 -7.08546829e-15 99.2359551 14.3820225 112.179775 14.3820225 112.179775 113.617978 99.2359551 113.617978 99.2359551 128 128 128 128 0"></polygon>
              <polygon points="32.3595506 41.7078652 32.3595506 25.8876404 95.6404494 25.8876404 95.6404494 41.7078652 71.9101124 41.7078652 71.9101124 110.741573 56.0898876 110.741573 56.0898876 41.7078652"></polygon>
              <polygon points="28.7640449 0 28.7640449 14.3820225 15.8202247 14.3820225 15.8202247 113.617978 28.7640449 113.617978 28.7640449 128 0 128 0 0"></polygon>
            </g>
          </svg>
          <p>
            
            <h2>
              [Tom's Obvious Minimal Language]
            </h2>
          </p>
        </div>
        <h3>
          A config file format <br>for humans.
        </h3>
        <p>
          TOML aims to be a minimal configuration file format that's easy to read due to obvious
          semantics. TOML is designed to map unambiguously to a hash table. TOML should be easy to
          parse into data structures in a wide variety of languages.
        </p>
      </div>
    </section>

    <section>
      <pre data-controller="snippet" data-snippet-copy="false"><code># This is a TOML document

title = "TOML Example"

[owner]
name = "Tom Preston-Werner"
dob = 1979-05-27T07:32:00-08:00

[database]
enabled = true
ports = [ 8001, 8001, 8002 ]
data = [ ["delta", "phi"], [3.14] ]
temp_targets = { cpu = 79.5, case = 72.0 }

[servers]

[servers.alpha]
ip = "10.0.0.1"
role = "frontend"

[servers.beta]
ip = "10.0.0.2"
role = "backend"</code></pre>
    </section>
  </div>

  <section>
    <dl>
      <div>
        <dt>
          
          TOML prioritizes humans
        </dt>

        <dd>
          <p>TOML aims to be a minimal configuration file format that:</p>
          <ul>
            <li>
              <span>is easy to read</span> due to obvious semantics
            </li>
            <li>
              <span>maps unambiguously</span> to a hash table
            </li>
            <li>
              <span>is easy to parse</span> into data structures in a wide variety
              of languages
            </li>
          </ul>
        </dd>
      </div>

      <div>
        <dt>
          
          TOML has useful native types
        </dt>
        <dd>
          <ul>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Key/Value Pairs</span>
            </li>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Arrays</span>
            </li>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Tables</span>
            </li>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Inline tables</span>
            </li>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Arrays of tables</span>
            </li>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Integers &amp; Floats</span>
            </li>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Booleans</span>
            </li>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Dates &amp; Times, with optional offsets</span>
            </li>
          </ul>
        </dd>
      </div>

      <div>
        <dt>
          
          TOML is widely supported
        </dt>
        <dd>
          <p>
            TOML already has implementations in most of the most popular programming languages in use
            today: C, C#, C++, Clojure, Dart, Elixir, Erlang, Go, Haskell, Java, Javascript, Lua,
            Objective-C, Perl, PHP, Python, Ruby, Swift, Scala...
            <a href="https://github.com/toml-lang/toml/wiki">and plenty more</a>.
          </p>
        </dd>
      </div>
    </dl>
  </section>

  <section>
    <header>
      <h2>
        A Quick Tour of TOML
      </h2>
    </header>

    <div>
      <div>
        <section>
          <div>
            <h3>Comments</h3>
            <p>TOML thinks all config files should support comments.</p>
          </div>

          <pre data-controller="snippet" data-snippet-copy="false"><code># This is a TOML comment

# This is a multiline
# TOML comment</code></pre>
        </section>

        <section>
          <div>
            <h3>Powerful Strings</h3>
            <p>
              There are four ways to express strings: basic, multi-line basic, literal, and
              multi-line literal. <span>Basic strings</span> are surrounded by
              quotation marks:
            </p>
          </div>

          <pre data-controller="snippet" data-snippet-copy="false"><code>str1 = "I'm a string."
str2 = "You can \"quote\" me."
str3 = "Name\tJos\u00E9\nLoc\tSF."</code></pre>

          <p>
            <span>Multi-line basic strings</span> Multi-line basic strings are
            surrounded by three quotation marks on each side and allow newlines. Include a line
            ending backslash to automatically trim whitespace preceeding any non-whitespace
            characters:
          </p>

          <pre data-controller="snippet" data-snippet-copy="false"><code>str1 = """
Roses are red
Violets are blue"""

str2 = """\
  The quick brown \
  fox jumps over \
  the lazy dog.\
  """</code></pre>

          <p>
            <code> str2</code> becomes
            <code>"The quick brown fox jumps over the lazy dog."</code>
            (a single sentence with no line breaks).
          </p>

          <p>
            <span> Literal strings</span> are surrounded by single quotes. No
            escaping is performed so what you see is what you get:
          </p>

          <pre data-controller="snippet" data-snippet-copy="false"><code>path = 'C:\Users\nodejs\templates'
path2 = '\\User\admin$\system32'
quoted = 'Tom "Dubs" Preston-Werner'
regex = '&lt;\i\c*\s*&gt;'</code></pre>

          <p>
            Since there is no escaping, there is no way to write a single quote inside a literal
            string enclosed by single quotes. That's where
            <span>multi-line literal strings</span> come in:
          </p>
          <pre data-controller="snippet" data-snippet-copy="false"><code>re = '''\d{2} apps is t[wo]o many'''
lines = '''
The first newline is
trimmed in raw strings.
All other whitespace
is preserved.
'''</code></pre>
        </section>
      </div>

      <div>
        <section>
          <div>
            <h3>Numbers</h3>
            <p>
              Integers, floats, infinity, and even NaN are all supported. You can use scientific
              notation and even thousands separators.
            </p>
          </div>

          <pre data-controller="snippet" data-snippet-copy="false"><code># integers
int1 = +99
int2 = 42
int3 = 0
int4 = -17

# hexadecimal with prefix `0x`
hex1 = 0xDEADBEEF
hex2 = 0xdeadbeef
hex3 = 0xdead_beef

# octal with prefix `0o`
oct1 = 0o01234567
oct2 = 0o755

# binary with prefix `0b`
bin1 = 0b11010110

# fractional
float1 = +1.0
float2 = 3.1415
float3 = -0.01

# exponent
float4 = 5e+22
float5 = 1e06
float6 = -2E-2

# both
float7 = 6.626e-34

# separators
float8 = 224_617.445_991_228

# infinity
infinite1 = inf # positive infinity
infinite2 = +inf # positive infinity
infinite3 = -inf # negative infinity

# not a number
not1 = nan
not2 = +nan
not3 = -nan </code></pre>
        </section>

        <section>
          <div>
            <h3>Dates and Times</h3>
            <p>
              TOML features support for dates, times, and datetimes with and without offsets.
            </p>
          </div>

          <pre data-controller="snippet" data-snippet-copy="false"><code>#offset datetime
odt1 = 1979-05-27T07:32:00Z
odt2 = 1979-05-27T00:32:00-07:00
odt3 = 1979-05-27T00:32:00.999999-07:00

# local datetime
ldt1 = 1979-05-27T07:32:00
ldt2 = 1979-05-27T00:32:00.999999

# local date
ld1 = 1979-05-27

# local time
lt1 = 07:32:00
lt2 = 00:32:00.999999</code></pre>
        </section>
      </div>
    </div>
  </section>

  <section>
    <div>
      <h3>More Spec</h3>
      <p>
        <strong>TOML</strong> supports even more native types and syntax, read all about it:
      </p>
      
    </div>

    <div>
      <h3>Start coding</h3>
      <p>
        <strong>TOML</strong> is already implemented in over 40 programming languages:
      </p>
      
    </div>
  </section>
</div></div>]]>
            </description>
            <link>https://toml.io/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24436550</guid>
            <pubDate>Thu, 10 Sep 2020 21:04:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Launch HN: Free HTML and CSS Coding Challenges]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24436516">thread link</a>) | @moeminm
<br/>
September 10, 2020 | https://moeminm.github.io/goodcode/?ref=hn | <a href="https://web.archive.org/web/*/https://moeminm.github.io/goodcode/?ref=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <nav>
                <a href="#"><img src="https://moeminm.github.io/goodcode/images/logo@2x.png"></a>
                
                
            </nav>

    <section>
        
        
    </section>  

    <section id="challenges">
        <!----Gourmet Card Start---->
        <div>
                <p>Free</p>
                <p><img src="https://moeminm.github.io/goodcode/images/jjo.png">
                </p>
                <div>
                    
                    <div>
                        <p>
                                Simple Job Board layout in Adobe XD. You'll learn a lot about grids and/or flex layouts as well as containers. Readme.md file included. Free.
                        </p>
                        </div>
                </div>
            </div>
        <!----Gourmet Card End---->
        <!----Gourmet Card Start----><div>
            <p>$5</p>
            <p><img src="https://moeminm.github.io/goodcode/images/gourmet.png">
            </p>
            <div>
                
                <div>
                    <p>
                            Practice your HTML and CSS skills with the high quality Gourmet Adobe XD template, includes mega menu. Readme.md file included. Costs $5.
                    </p>
                    </div>
            </div>
        </div>
            <!----Gourmet Card End---->
            <!----Gourmet Card Start---->
        <div>
                <p>Free</p>
                <p><img src="https://moeminm.github.io/goodcode/images/apt.png">
                </p>
                <div>
                    
                    <div>
                        <p>
                                Amazon Price Tracker. Lots of great layout challenges with various components and pages (and graphs!). Readme.md file included. Free.
                        </p>
                        </div>
                </div>
            </div>
            <!----Gourmet Card End---->
            <!----Gourmet Card Start---->
        <div>
                <p>Free</p>
                <p><img src="https://moeminm.github.io/goodcode/images/inv.png">
                </p>
                <div>
                    
                    <div>
                        <p>
                                Practice your HTML and CSS skills with the Invitation Adobe XD template. 3 column grid practice (or flex). Readme.md file included. Free.
                        </p>
                        </div>
                </div>
            </div>
            <!----Gourmet Card End---->
            <!----Gourmet Card Start---->
        <div>
            <p>Free</p>
            <p><img src="https://moeminm.github.io/goodcode/images/ppt.png">
            </p>
            <div>
                
                <div>
                    <p>
                            Simple pricing page, 3 column grid, easy to implement, modern and simple. Readme.md file included. Absolutely free of charge.
                    </p>
                    </div>
            </div>
        </div>
        <!----Gourmet Card End---->
<!----Gourmet Card Start---->
<div>
    <p>Free</p>
    <p><img src="https://moeminm.github.io/goodcode/images/signtemplate.png">
    </p>
    <div>
        
        <div>
            <p>
                    Simple sign up page, 2 column grid, easy to implement, modern and simple. Readme.md file included. Absolutely free of charge.
            </p>
            </div>
    </div>
</div>
<!----Gourmet Card End---->

    </section>

    

    

</div></div>]]>
            </description>
            <link>https://moeminm.github.io/goodcode/?ref=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24436516</guid>
            <pubDate>Thu, 10 Sep 2020 20:59:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The rules of consensus algorithms inspired by scaling YouTube]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24436511">thread link</a>) | @sougou
<br/>
September 10, 2020 | https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-2 | <a href="https://web.archive.org/web/*/https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><figure id="w-node-5c27f10a08a3-ca993012"><p><img src="https://assets-global.website-files.com/5ef5a4d4da0d67ccda9b5588/5f5716b58fafa451fe431853_blog-headers-consensus-04.jpg" loading="lazy" alt=""></p></figure><p>Read <a href="https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-1">Consensus Algorithms at Scale - Part 1</a></p><h2>The Rules of Consensus</h2><h4>YouTube Scale</h4><p>When we were running <a href="https://vitess.io/">Vitess</a> at YouTube, there were tens of thousands of nodes serving very high QPS. The scale out was in all dimensions: some of the shards had over fifty replicas. The topology was complicated with these nodes being spread out across multiple data centers. To make this work, we had to strike a balance between latency, availability and durability. To meet these requirements, we used to perform regular failovers that were mostly automated. I am happy to say we never lost data due to hardware failure.</p><p>The first time we heard about Paxos, it sounded magical: an algorithm that will dynamically elect a leader to ensure that all requests are fulfilled without errors, divergence, or data loss. The Vitess failovers used to take a few seconds, and we wanted to avoid serving errors during this period.</p><p>We started to evaluate Paxos to see if it could be retrofitted into Vitess. We quickly found that our quorum sizes would have been too big for a majority based algorithm. Also, the MySQL replication mechanism didn’t look anything like the durability mechanism Paxos was describing. Our only option was to do a gap analysis between the two systems. In a way, this is what led to the discovery of <a href="https://www.sougou.io/a-more-flexible-paxos/">FlexPaxos</a>: an additional knob that allows you to achieve a more meaningful performance vs. safety trade-off.</p><p>There were other differences: our failover algorithms did not look anything like what Paxos recommends. Studying how the two systems differed led to the discovery of a common set of principles that any leader-based system can follow to guarantee correctness and safety. We will cover these rules in this blog post.</p><figure id="w-node-62fc8f365de2-ca993012"><p><img src="https://assets-global.website-files.com/5ef5a4d4da0d67ccda9b5588/5f57e95a9f68ce38d9f47839_Screen%20Shot%202020-09-08%20at%2012.56.55%20PM.png" loading="lazy" alt=""></p></figure><h4>Why Consensus</h4><p>We are focused on using Consensus to address durability at scale. It is possible that there are other use cases, but we are not concerned about those.<br></p><p>No system can give you absolute durability guarantees; there is always the possibility of a catastrophic failure that is bigger than anticipated. You must decide the level of failure tolerance you want. This depends on the reliability of the resources and the criticality of the data. In other words, durability requirements are use-case dependent.<br></p><p>To accommodate all possible use cases, we will treat durability as an abstract requirement. The algorithms must be agnostic of these requirements, and should be able to accommodate arbitrarily complex rules. This changes the way we approach the problem, and we will go through this exercise in the following sections.</p><h4>Single Value Behavior</h4><p>Paraphrasing the definition from Paxos: the primary guarantee we want from a consensus system is that it must not forget a value it has acknowledged as accepted. Once a value is accepted, all other values must be rejected.</p><p>When asked to accept a single value, the operation would have one of the three following outcomes:<br></p><ol role="list"><li>Accepted: the value was successfully accepted.</li><li>Rejected: the value was rejected.</li><li>Failed: the operation did not succeed, but may succeed later.<br></li></ol><p>If the first request was Accepted, then any subsequent attempts to write a different value will be Rejected.<br></p><p>If the first request was Rejected, it likely means that a previous value was accepted before our “first” attempt. In this case, subsequent requests will also be Rejected.<br></p><p>If the first request Failed and a second request is made, the system can choose to finalize either of the requests as Accepted, but not both. Since the second request can also Fail, we need to restate this more generally: the system can choose to Accept any previously requested values as final. Pathological failure modes can cause the system to remain in the Failed state indefinitely. But it is generally expected to converge eventually.</p><h4>In Practice</h4><p>It is not very practical for a system to just accept a single value. Instead, let us see what should happen if we changed the specifications to a system that accepts a series of values, which is what storage systems typically do.<br></p><p>If a system first accepts a value v1, and later receives a request for v2, it must record v2 as having happened after v1. The more significant property is the following: If the request for v1 failed because the system was not able to meet the durability requirements, then a request for v2 requires the system to make a final decision on whether v1 should be completed or rejected. If completed, it will record v2 after v1. Otherwise, v1 is discarded and v2 will be the only accepted value.<br></p><p>Raft understood this, which is why they describe their system as a way to achieve consistent log replication.<br></p><p>In our case, we will think in terms of requests rather than values, which can be any operation a storage system may have to perform. It could be a transaction, or setting the value for a key, or any other atomic operation.<br></p><p>Let us restate: The purpose of a consensus system is to accept a series of requests in a strict order and keep them consistent across multiple nodes.</p><h4>Single Leader</h4><p>To limit complexity and scope, we are going to stick to single leader designs. The popular implementations that I know use the single leader approach. There is research on leaderless and multi-leader algorithms. But I am not very familiar with them.<br>‍</p><figure id="w-node-75b056f4f908-ca993012"><p><img src="https://assets-global.website-files.com/5ef5a4d4da0d67ccda9b5588/5f59058ba01bf11722847f12_leader-yin-yang-01.png" loading="lazy" alt=""></p></figure><p>‍<br>‍<br>A Single Leader consensus system is a combination of two workflows that cooperate with each other:</p><ol role="list"><li>A leader accepts requests and makes them durable.</li><li>A new leader can be elected to resume requests without divergence or loss of data.<br></li></ol><p>Paxos and Raft also use the single leader approach.</p><h4>The Rules</h4><p>Now that we have spent enough time building up the premise, it is time to codify the rules governing a consensus system:.</p><div><ol>
<li>A Leader’s job is to fulfill requests by satisfying the mandated durability requirements.
</li><li>To elect a new Leader, the following actions must be performed:
  <ul>
    <li>Terminate the previous Leadership, if any.</li>
    <li>Recruit the necessary nodes for the new Leader.</li>
    <li>Propagate previously completed requests to satisfy the new Leader’s durability requirements. </li>       
    </ul>
</li><li>Forward Progress: If a Leader election fails, a subsequent re-attempt should have a path to success, where a new Leader can be elected without breaking the durability and safety guarantees.</li>
<li>Race: If concurrent attempts are being made to elect a Leader, at most one Leader must prevail.</li>
</ol></div><p>Rules 3 &amp; 4 are actually implicit in rule number 2. But these properties are so important that it’s worth making them explicit.<br></p><p>These rules are intentionally generic to allow for creativity in achieving these goals. In fact, being more specific than this will exclude some valid implementations. However, we will show multiple ways to satisfy these rules. We will also validate the existing popular algorithms against these new set of rules.<br></p><p>You will notice the following differences:</p><ul role="list"><li>No mention of a majority quorum.</li><li>No mention of intersection of nodes.</li><li>No proposal numbers.<br></li></ul><p>This is where we deviate from traditional systems because we believe these are not strictly required for a consensus system to operate correctly. For example, you can build a consensus system with fifty nodes, but still only have a quorum size of two. There is no need for these quorums to intersect across leaders. As for proposal numbers, very few understand why they are even needed. It is better to discuss what we are trying to achieve, and then introduce proposal numbers as one option, and maybe consider alternatives that don’t involve proposal numbers. We will drill down into each of these properties and explore trade-offs between multiple approaches.<br></p><p>In the next post, we will cover some practical use cases that this generalized set of rules allows us to cover. We will also drill deeper into the meaning and significance of these rules.</p></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-2</link>
            <guid isPermaLink="false">hacker-news-small-sites-24436511</guid>
            <pubDate>Thu, 10 Sep 2020 20:59:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why FTL implies time travel (2016)]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24436505">thread link</a>) | @ladberg
<br/>
September 10, 2020 | http://www.physicsmatt.com/blog/2016/8/25/why-ftl-implies-time-travel | <a href="https://web.archive.org/web/*/http://www.physicsmatt.com/blog/2016/8/25/why-ftl-implies-time-travel">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" data-updated-on="1472176981274" id="item-57bfa321893fc0f1d1be57f7"><div><div><div data-block-type="2" id="block-54e4d00eca7f73d32497"><div><p>In science fiction, it is pretty standard fare to introduce some form of faster-than-light communication or travel. After all, space is big, and you can't write your swashbuckling Hornblower-in-space novel if you have to wait for a generation ship to crawl painfully slowly between the nearest stars, much less try to cross a galaxy.</p><p>However, faster-than-light communication (which includes travel) breaks something very fundamental about physics, something that is often ignored by sci-fi, and difficult for non-physicists to understand. If you allow faster-than-light (FTL), then you break causality: you are allowing time-travel. One pithy way of saying this is:</p><p>Pick two:</p><ul><li>Relativity</li><li>Causality</li><li>FTL</li></ul><p>The Universe has picked relativity and causality, it seems. Thus, we cannot travel or communicate faster than light.&nbsp;</p></div></div><div data-block-type="5" id="block-yui_3_17_2_5_1472176913301_15584"><div>







 

  
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472177316237-IEW52C3ICC42CPAM1IMG/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472177316237-IEW52C3ICC42CPAM1IMG/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg" data-image-dimensions="2048x1536" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="57bfa4a303596e3a2ae8799b" data-type="image" src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472177316237-IEW52C3ICC42CPAM1IMG/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  



</div></div><div data-block-type="2" id="block-yui_3_17_2_5_1472176913301_16992"><div><p>But why is this? Why does FTL imply time travel. To demonstrate this, it's handy to draw some diagrams. We're going to work with "spacetime diagrams." They look like this:</p><p>Here I'm trying to draw all four dimensions of the Universe: three space and one time. Now, I can't draw four dimensions. I can't even really draw three (it's a 2D screen, after all). So I've suppressed two space dimensions, drawing all of space as just a line. It won't matter much for what I'm trying to do, but it's good to keep that in mind.</p><p>With that in mind, I'm showing here <em>my </em>spacetime diagram: I'm stationary at the center, and so I see time tick forward "orthogonal" (perpendicular) to the space directions around me. As you'll see, other people have different spacetime diagrams, and different time and space axes, relative to me. That's the point of relativity, after all.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_5_1472176913301_21377"><div>







 

  
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472177593517-NTXFTAXJ7Q4WAPV0Q6ST/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472177593517-NTXFTAXJ7Q4WAPV0Q6ST/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg" data-image-dimensions="2048x1536" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="57bfa5b9ff7c50b7ffbc5576" data-type="image" src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472177593517-NTXFTAXJ7Q4WAPV0Q6ST/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  



</div></div><div data-block-type="2" id="block-yui_3_17_2_5_1472176913301_22820"><div><p>The special thing about relativity is that <em>everyone measures the speed of light to be the same</em>. We show this in a spacetime diagram by saying that every spacetime diagram has light traveling at 45 degrees relative to the time axis. Light travels on lines that are called "null."</p><p>Here I'm showing the null lines of light emitted from an event at the time I'm calling <em>t=0</em>&nbsp;(when the time and space axis cross). Remember I'm suppressing most of the space dimensions: these rays of light are really emanating out in a sphere around me. Because light travels at 45 degrees, anything traveling slower than light from this <em>t=0</em>&nbsp;event is closer to the time axis than the light rays, and anything faster than light is further away from the time axis.</p><p>The light rays define the <em>future lightcone</em>. This is the set of spacetime events that can perceive the event at <em>t=0,</em>&nbsp;and so, in a Universe without FTL, all the events that can be affected by whatever happened at this event at <em>t=0.&nbsp;</em>There is also a past lightcone, which would be the 45 degree lines extending backwards in time from the event: in a Universe without FTL this defines all the events that could have effected that <em>t=0</em>&nbsp;event, because the light (and thus things moving slower than light)&nbsp;from those other events had time to reach the <em>t=0</em>&nbsp;event.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_5_1472176913301_40995"><div><p>So now let me move from general spacetime diagrams to an example that will indicate why FTL implies time travel. Let's consider a specific example: Let's say we on Earth have built a FTL communication device that let's us talk to the inhabitants of the planet Proxima Centauri B, 4.25 lightyears away. Again, this is what a FTL and slower-than-light set of communications would appear like in a spacetime diagram.</p><p>Critically, I've drawn the time axis for the Proximal Centaurians parallel to our own time. This is because Proxima Centauri is moving at essentially the same velocity as Earth (the differences are small compared to the speed of light). Thus, there are no big relativistic effects between our counting of time and the Proximal Centaurians.&nbsp;</p><p>Now, let's imagine that some event occurs away from Earth, oriented in such a way that the light from the event hits us before it reaches Proxima Centauri. The spacetime diagram for that would look like what I've shown. First we see the light, then the light reaches Proxima Centauri. Notice I've drawn the light rays from the event traveling at 45 degrees to my time axis. After all, it is light, and light travels at 45 degrees on spacetime diagrams.</p></div></div><div data-block-json="{&quot;existingGallery&quot;:null,&quot;hSize&quot;:null,&quot;show-meta-only-title&quot;:false,&quot;floatDir&quot;:null,&quot;methodOption&quot;:&quot;transient&quot;,&quot;design&quot;:&quot;grid&quot;,&quot;aspectRatio&quot;:null,&quot;square-thumbs&quot;:false,&quot;aspect-ratio&quot;:&quot;square&quot;,&quot;thumbnails-per-row&quot;:2,&quot;padding&quot;:5,&quot;lightbox&quot;:false,&quot;collectionId&quot;:&quot;57bfa8b3f5e2312269858e10&quot;,&quot;vSize&quot;:null,&quot;transientGalleryId&quot;:&quot;57bfa8b3f5e2312269858e10&quot;}" data-block-type="8" id="block-yui_3_17_2_5_1472176913301_57296"><div>




  

  


<div>
  <div>
    
      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <p><a role="presentation">
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178356455-JKIIS3FT0GDGQQGL4R6P/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/IMG_0006.jpg" data-image="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178356455-JKIIS3FT0GDGQQGL4R6P/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/IMG_0006.jpg" data-image-dimensions="2048x1536" data-image-focal-point="0.5,0.5" alt="IMG_0006.jpg" data-load="false" data-image-id="57bfa8b4f5e2312269858e11" data-type="image" src="http://www.physicsmatt.com/blog/2016/8/25/IMG_0006.jpg">
                </a>
                
              </p>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <p><a role="presentation">
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178356571-YYGOMQAKCBON7C6CLUEJ/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/IMG_0007.jpg" data-image="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178356571-YYGOMQAKCBON7C6CLUEJ/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/IMG_0007.jpg" data-image-dimensions="2048x1536" data-image-focal-point="0.5,0.5" alt="IMG_0007.jpg" data-load="false" data-image-id="57bfa8b4d2b8577fd265d1a2" data-type="image" src="http://www.physicsmatt.com/blog/2016/8/25/IMG_0007.jpg">
                </a>
                
              </p>
            </div>
          

          
        

      
    
  </div>

  

</div>








</div></div><div data-block-type="5" id="block-yui_3_17_2_5_1472176913301_62520"><div>







 

  
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178540018-4KDK5JVY0JSFA4JP0998/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178540018-4KDK5JVY0JSFA4JP0998/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg" data-image-dimensions="2048x1536" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="57bfa96be58c629eb4d4f155" data-type="image" src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178540018-4KDK5JVY0JSFA4JP0998/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  



</div></div><div data-block-type="2" id="block-yui_3_17_2_5_1472176913301_61723"><div><p>So, now, let's add in FTL communication. We see the event, we get on the FTL phone, and we tell the Proximal Centaurians. They get the phone call, and now have years to prepare for the arrival of the light from whatever the event is (let's say it's a supernovae, or the launch of relativistic attack vehicles. We are playing with sci-fi tropes here).</p><p>Now, this is the image most people have of FTL communication. There appears to be no problem: we all agree that the event happened "first," then Earth calls Proxima Centauri, then the light reaches Proxima Centauri. No problem: though the Proximal Centaurians hear about the event "early," no causality has been violated. After all, we all agree on what happened first, don't we? No effect precedes its cause.</p><p>Right?</p></div></div><div data-block-type="5" id="block-yui_3_17_2_5_1472176913301_81533"><div>







 

  
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178941031-RKS433C6DG08CZ9EE2PC/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178941031-RKS433C6DG08CZ9EE2PC/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg" data-image-dimensions="2048x1536" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="57bfaafabebafba38dd12b9e" data-type="image" src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178941031-RKS433C6DG08CZ9EE2PC/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  



</div></div><div data-block-type="2" id="block-yui_3_17_2_5_1472176913301_67814"><div><p>But we've forgotten relativity. This only works when everyone is moving in the same frame of reference, like us and Proxima Centauri (really we're not in the same rest frame, but its close enough not to matter). So, to see the problem, let's add a new observer, moving at high speeds relative to Earth and Proxima Centauri. It's sci-fi, so we add a relativistic spaceship. It's moving with <em>v&lt;c</em>&nbsp;but <em>v&gt;&gt;0</em>, so it's trajectory on my spacetime diagram is highly skewed relative to my time axis: it's nearly moving at the speed of light.</p><p>Here's where the relativistic effects start coming into play. Relativity tells us that everyone moving with constant velocity is totally justified in saying they are stationary. Thus, we think we're stationary (ignore the rotation of the Earth, or its orbit around the Sun). The Proximal Centaurians think they're at rest. The people on the relativistic spaceship think they are at rest. So they can draw their spacetime diagram, with their own time axis. That time axis, like mine, is always where they are: on the ship. So I think their time axis is aligned with the ship trajectory.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_5_1472176913301_80257"><div>







 

  
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178905725-BMV6CIVK52NIILG1PZN5/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178905725-BMV6CIVK52NIILG1PZN5/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg" data-image-dimensions="2048x1536" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="57bfaad9bebafba38dd12a22" data-type="image" src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178905725-BMV6CIVK52NIILG1PZN5/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  



</div></div><div data-block-type="2" id="block-yui_3_17_2_5_1472176913301_86207"><div><p>In addition, they have a space-axis, just like I do. Relativity mixes up space and time, so their space axis I perceive as slanted - just like their time axis is skewed. It turns out that the space axis is flipped across the 45 degree null line, but I'm not going to prove that. This weird mixture of space and time of observers I perceive as moving is a necessary part of relativity. It is the <em>only </em>way everyone can agree that light moves at <em>c</em>.&nbsp;</p><p>Now, if I wanted to, I could draw the spacetime diagram of the spaceship in its frame of reference. It would have othogonal space and time axes, the light from the event would travel at 45 degree,&nbsp;and they would see Earth's axes highly skewed (pointing toward the left if I kept the same orientation as in this set of diagrams). That's relativity. But we will not draw that diagram here, as it's not necessary for the story.</p><p>So what happens now. Let's ask <em>when </em>the spaceship sees the various events in this diagram. To do that, we need to know the lines of constant time for the ship. That's not too hard: lines of constant time for us are lines in the spacetime diagram parallel to the space axis. So it is for the spaceship. Their lines of constant time look like this:</p></div></div><div data-block-json="{&quot;existingGallery&quot;:null,&quot;hSize&quot;:null,&quot;show-meta-only-title&quot;:false,&quot;floatDir&quot;:null,&quot;methodOption&quot;:&quot;transient&quot;,&quot;design&quot;:&quot;grid&quot;,&quot;aspectRatio&quot;:null,&quot;square-thumbs&quot;:false,&quot;aspect-ratio&quot;:&quot;square&quot;,&quot;thumbnails-per-row&quot;:2,&quot;padding&quot;:5,&quot;lightbox&quot;:false,&quot;collectionId&quot;:&quot;57bfacb4d2b8577fd265f253&quot;,&quot;vSize&quot;:null,&quot;transientGalleryId&quot;:&quot;57bfacb4d2b8577fd265f253&quot;}" data-block-type="8" id="block-yui_3_17_2_5_1472176913301_90063"><div>




  

  


<div>
  <div>
    
      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <p><a role="presentation">
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472179381264-LQVTY7AMG7NSFAUT3YHB/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/IMG_0011.jpg" data-image="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472179381264-LQVTY7AMG7NSFAUT3YHB/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/IMG_0011.jpg" data-image-dimensions="2048x1536" data-image-focal-point="0.5,0.5" alt="IMG_0011.jpg" data-load="false" data-image-id="57bfacb4d2b8577fd265f254" data-type="image" src="http://www.physicsmatt.com/blog/2016/8/25/IMG_0011.jpg">
                </a>
                
              </p>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <p><a role="presentation">
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472179381312-NBGI7FFKM480NJ32EQET/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/IMG_0012.jpg" data-image="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472179381312-NBGI7FFKM480NJ32EQET/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/IMG_0012.jpg" data-image-dimensions="2048x1536" data-image-focal-point="0.5,0.5" alt="IMG_0012.jpg" data-load="false" data-image-id="57bfacb437c5819eacebc0b2" data-type="image" src="http://www.physicsmatt.com/blog/2016/8/25/IMG_0012.jpg">
                </a>
                
              </p>
            </div>
          

          
        

      
    
  </div>

  

</div>








</div></div><div data-block-type="2" id="block-yui_3_17_2_5_1472176913301_91421"><div><p>Now do you see the problem?</p><p>According to us, on Earth, the order of events is thus: we see the light from the event hit us. We call Proxima Centauri on the FTL phone. The Proximal Centaurians do whatever they want to do in response to that call, and then they see the light of the event.&nbsp;</p><p>What does the ship see? They see the phone call received on Proxima Centauri.&nbsp;<em>Then</em>&nbsp;they see the phone call placed from Earth. Effect precedes cause: causality is violated. In fact, if the ship had a FTL phone set up in the right way, they could call Earth <em>before</em>&nbsp;Earth placed the call. They could even tell Earth "hey, don't make that call to Proxima Centauri we just saw you make." Then what?</p></div></div><div data-block-type="5" id="block-yui_3_17_2_5_1472176913301_110431"><div>







 

  
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
    …</figure></div></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.physicsmatt.com/blog/2016/8/25/why-ftl-implies-time-travel">http://www.physicsmatt.com/blog/2016/8/25/why-ftl-implies-time-travel</a></em></p>]]>
            </description>
            <link>http://www.physicsmatt.com/blog/2016/8/25/why-ftl-implies-time-travel</link>
            <guid isPermaLink="false">hacker-news-small-sites-24436505</guid>
            <pubDate>Thu, 10 Sep 2020 20:58:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Design Principles]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24436360">thread link</a>) | @vitabenes
<br/>
September 10, 2020 | https://principles.design/examples/ | <a href="https://web.archive.org/web/*/https://principles.design/examples/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Ethical Analytics</p>
<p>
Get a <strong>$10 credit</strong> for <a href="https://usefathom.com/ref/MSDPWY">Fathom Analytics</a>.
<br>
Fast, simple and privacy-focused website analytics.
</p>
<p><a href="https://usefathom.com/ref/MSDPWY">Find out more</a>
</p></div></div>]]>
            </description>
            <link>https://principles.design/examples/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24436360</guid>
            <pubDate>Thu, 10 Sep 2020 20:39:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use of AI in Taxation to boost Economic Growth in third world countries]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24436261">thread link</a>) | @umermirzapk
<br/>
September 10, 2020 | https://thinkml.ai/use-ai-tax-collection-boost-economic-growth/ | <a href="https://web.archive.org/web/*/https://thinkml.ai/use-ai-tax-collection-boost-economic-growth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://thinkml.ai/content/images/size/w300/2020/09/income-tax-491626_1920.jpg 300w,
                            https://thinkml.ai/content/images/size/w600/2020/09/income-tax-491626_1920.jpg 600w,
                            https://thinkml.ai/content/images/size/w1000/2020/09/income-tax-491626_1920.jpg 1000w,
                            https://thinkml.ai/content/images/size/w2000/2020/09/income-tax-491626_1920.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://thinkml.ai/content/images/size/w2000/2020/09/income-tax-491626_1920.jpg" alt="Use of Artificial Intelligence in Tax Administration to boost Economic Growth in third world countries">
            </figure>

            <section>
                <div>
                    <p>Artificial Intelligence (AI) can contribute in Taxation especially in Tax Administration to boost economy. AI is a collection of unique processes that can leverage Data Science to make smart changes in the software ecosystem of government organizations. With the rapid innovation in the field of AI and Data Science, its use in different fields is also gaining popularity. Thus, taking the community towards greater ease than ever before. Modern technology is also going hand in hand with Artificial Intelligence to support data processing on commerce, health, communications, entrepreneurship, transportation, and many more. Likely, AI is also joining the taxation process to boost the economy of third world countries. </p><p>Now a days, computers have become expert enough to mimic human intelligence-based actions using human-induced instructions. Such machines are trained to perform a particular task in the same manner; thus, it promotes equality in solving a particular problem. AI models installed in these machines learn from experience and make decisions in real-time by using historical data. </p><h2 id="what-differentiates-ai-from-other-rising-technologies">What differentiates AI from other rising technologies?</h2><p><a href="https://thinkml.ai/artificial-intelligence-is-helping-common-people/">AI is influencing lives greatly</a> and responds to a particular problem like humans. The growing AI and trending machine learning are affecting our lives very deeply. In a relatively brief period, AI has become strong enough to think, sense, listen, and do many more functions just like humans or more efficiently than them.</p><p>According to Gartner Research Firm, AI will eradicate 1.8 million jobs and increase to 2.3 million other jobs by 2020. Furthermore, it could produce 16 percent or $13 trillion (14 percent) globally by 2030, given by McKinsey. The results of AI implementation vary by industry, work type, or geography. AI and robotics will take over the repeated task that makes humans dull and exhausted, helping them stay engaged in value-added activities. The coming wave of AI allows government organizations and businesses to automate their tax world to achieve the demand of the day.</p><p>Read more about: <a href="https://thinkml.ai/will-robot-take-my-job/">How AI Will Kill Jobs?</a> </p><p>AI is on its peak in developed countries like United States. Governments in many other countries are also trying to adopt it. Hence, the U.K., China, and France decided to promote AI education, skills, and funds to develop a passionate AI expert workforce. Privacy, Cybersecurity, and IP rights are even preserved with artificial intelligence introduction in the taxation system.</p><h2 id="what-makes-ai-so-obsessive-to-be-introduced-in-taxation">What makes AI so obsessive to be introduced in Taxation?</h2><p>In recent times, many governments worldwide have applied several fiscal and debt measures to fund policy startups. Consequently, a 4% rise is recorded in tax revenues as a part of GDP. These changes are appearing in the Organization for Economic Cooperation and Development (OECD) countries since 1980. However, there is inequality in income and spending that give rise to more debt than revenue. It leads to budget deficits (fiscal gap) which can destroys the country's economy.</p><h3 id="understanding-fiscal-gap">Understanding Fiscal Gap</h3><p>The fiscal gap is the total amount of money that economists predict to be owned by a government. It relates the government expenditure on running projects with the revenues generated over a specified time from those running projects. In other words, it joins tax revenues of government over a decided period with spending. Previously, the economists observed budget imbalances for various reasons, including rising pensions of government employees and the services offered to them. This imbalance in expenditures and revenues led to <strong>widening the fiscal gap</strong>, which promoted several issues on a large scale. </p><h3 id="major-drawbacks-of-widening-the-fiscal-gap">Major drawbacks of widening the Fiscal Gap</h3><ul><li>Most of the offices and industries are preferring automatic machines for bringing accuracy in their work. It results in producing high pressure on employment as it results in lowering employee’s demand. &nbsp;</li><li>Likely, worldwide trade is now a click away. People search for a product of their interest on the internet from many e-commerce stores doing their online businesses. It also leads to unemployment as new business-starters don’t go for a physical store. They take pictures of the products and upload them to their websites. People from different regions contact them online, and they deliver it on time to their customers. Thus, it eliminates the need for physical stores and employees, saving their hours waiting for customers and then convincing them.</li><li>Self-employment is another word for freelancers who earn money online, and they’re not asked to pay tax from their earnings. </li><li>The aging population is the number of retired government employees (65 years old) who get pensions after completing their serving years. Their number is 8 to 10 percent more than the young population. It is also a significant cause of the fiscal gap that promotes an imbalance in revenues and spending. </li></ul><p>Considering these factors; there should be a reliable method to have a clear-insights of tax and revenues. The fiscal gap is growing and making it difficult for policymakers to apply policy rules equally to every business person. Improvement in a particular area helps to reduce the fiscal gap to enhance operational efficiency. The governments are moving towards AI services to improve their taxation process; thus, boosting the economy. </p><p>AI is performing structured and unorganized tasks efficiently, mimicking human voices with high speed and accuracy. Moreover, it can also analyze and modify in-depth questionnaires that were previously difficult to deal with them. All these extraordinary features are of significant importance in planning and reporting the tax life-cycle.</p><h2 id="artificial-intelligence-can-play-a-major-role-in-taxation">Artificial Intelligence can play a major role in Taxation</h2><p>AI is the ultimate source of crunching big data to get better insights and help make better tax decisions. AI tools are well-prepared to completely deal with specific problems and replace natural human intelligence (but not yet achieved). Machine learning and natural language processing (NLP) is of great importance. NLP can be used for analyzing unorganized data and help in tax return determination. <strong>Ubiquitous chatbots </strong>can be well-trained to respond to taxation queries. Hence, we can leverage artificial intelligence in chatbots to answer technical tax issues. </p><p>Imbalance in income is problematic for economics, and the economist's assumptions are not easily predictable. <a href="https://www.mckinsey.com/featured-insights/artificial-intelligence/notes-from-the-ai-frontier-modeling-the-impact-of-ai-on-the-world-economy">Mckinsey published a study</a>, AI boosted both productivity and income equality 16 percent more precisely than the manual taxation process.</p><h2 id="federal-ai-standards-engagement-plan">Federal AI Standards Engagement Plan</h2><p><a href="https://www.nist.gov/">National Institute of Standards and Technology (NIST)</a> contacted PwC to share information about artificial intelligence and its working strategy. It's a reliable, empowering, and trustworthy system that works honestly and deals with everyone equally. AI has the power to sense its surrounding by listening, watching, and understanding it. It's the need of the time to install AI in every system to achieve extraordinary standards.</p><h2 id="how-ai-can-facilitate-taxation-a-practical-presentation">How AI can facilitate taxation? A practical presentation</h2><p>Let’s see how AI is practically helping taxation to boost the economy. It’s a study by <a href="https://www.pwc.com/cb/en/services/pdf/how-tax-leveraging-ai-machine-learning-2019.pdf">the Tax Function of the Future</a> that highlights complexities and solutions in the business environment step by step: </p><h3 id="step-1-tax-notice-processing-in-tax-use-case">Step 1: Tax Notice processing in Tax use case</h3><p>Data in tax notices are random, and its sorting is a big problem. What machine does here is highlighting the main keyword terms in tax notices. The given data might be from federal, government, global, local, or state; thus, it automates tracking and prepares AI for responses. <strong>Data Annotation </strong>is the crucial step in helping leveraging AI to pick-up the main key terms in the aggregate data. Artificial intelligence sense everything; audio, video, language.</p><p><strong>Sensing Audio Speech: </strong>The machine senses the spoken words and records the information in real-time. This feature helps in the conversion of audio to text. &nbsp;</p><p><strong>AI Visionary Power: </strong>AI uses scanned documents to recognize the image patterns. It helps hi remembering the patterns of tax forms, contracts, and notes. Furthermore, it also scans tax forms for further data extraction.</p><p><strong>Language Processing: </strong>The machine understands the words written in textual form to store its meaning in memory.</p><h3 id="step-2-account-classification">Step 2: Account Classification </h3><p>Account mapping is a difficult task in an account classification system. AI, in this case, helps out by remembering and balancing trial account names. Moreover, it helps then sending map information to PwC for taxonomy and other purposes like tax calculation adjustment. It includes all information on numerous account's incomes and expenses. Artificial intelligence thinks moreover, about patterns in data through machine learning. </p><p><strong>Machine Learning </strong>implies statistical data analysis technique to identify digit characters for further prediction of planning and forecasting, extract data from scanned tax notice, determines tax applicable on transactions, and many more. &nbsp;</p><h3 id="step-3-tax-acquiescence-reporting-after-analysis">Step 3: Tax Acquiescence &amp; Reporting after Analysis</h3><p>It's a significant problem that remains after analysis; hence, PwC prefers the combination of AI with RPA (<strong>robotic process automation</strong>). It will favor performing structured and unstructured activities in tax compliance. In structured activities, the AI robust system will respond to daily basis activities. It gathers data from the source system, makes regular tax adjustments, fills forms, and posts tax accounting entries. Above it, taxation by AI can boost the economy in third world countries and take it to the next level. It will empower the country as it's a primary step towards success.</p><p>Several factors are responsible for AI machine learning in tax compliance and reporting.</p><p><strong>Robotic Process Automation (RPA): </strong>It replicates human behavior on desktop and web-based applications for data collection and reporting. RPA is considered the most straightforward AI strategy that represents pre-installed …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thinkml.ai/use-ai-tax-collection-boost-economic-growth/">https://thinkml.ai/use-ai-tax-collection-boost-economic-growth/</a></em></p>]]>
            </description>
            <link>https://thinkml.ai/use-ai-tax-collection-boost-economic-growth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24436261</guid>
            <pubDate>Thu, 10 Sep 2020 20:29:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GitHub at scale and how to help “Stadium” model maintainers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24436238">thread link</a>) | @FanaHOVA
<br/>
September 10, 2020 | https://645ventures.com/github-at-scale-and-how-to-help-stadium-model-maintainers | <a href="https://web.archive.org/web/*/https://645ventures.com/github-at-scale-and-how-to-help-stadium-model-maintainers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" role="group"><div><div><h3><em>By <a href="http://github.com/fanahova">Alessio Fanelli</a></em></h3><p><img alt="open source" src="https://images.ctfassets.net/clfay1lxzjey/3p7gb4jXFArFwN2xyqN5IO/3f8fee7376400256f44fffb333e53729/markus-winkler-4J2OD3njVgI-unsplash.jpg"></p><p><a href="https://nadiaeghbal.com/">Nadia Eghbal</a> recently published a great book titled <a href="https://www.amazon.com/dp/0578675862/"><em>“Working in Public: The Making and Maintenance of Open Source Software”</em></a>, which covers the evolution of open source software (OSS) development, the role of communities in open source, and how platforms like GitHub have influenced open source production. It also explores the intersection of monetization and open source (which we will dive into in a future post), and what motivates maintainers and contributors to work on OSS, sometimes with little to no compensation. </p><p>Nadia also creates a new taxonomy to categorize projects based on the growth of <strong>users</strong>, defined as developers who use the project and might open GitHub issues from time to time, and <strong>contributors</strong>, defined as developers who make meaningful contributions to the code base (just fixing a typo doesn’t count!).  Up until today, there hasn’t been any attempts at discerning projects based on these characteristics. The taxonomy Nadia came up with (table below) gives us a common language to discuss this, as well as helping potential users evaluate them. </p><table><thead><tr><th></th><th>High User Growth</th><th>Low User Growth</th></tr></thead><tbody><tr><td><strong>High Contributor Growth</strong></td><td>Federations (eg Rust)</td><td>Clubs (eg Astropy)</td></tr><tr><td><strong>Low Contributor Growth</strong></td><td>Stadiums (eg Babel)</td><td>Toys (eg ssh-chat)</td></tr></tbody></table><hr><p>One key observation from the book that really impacted me is the definition of “Stadium” projects, which are projects that have high user growth, but slow growth in contributors. Just like fans watching a game in a stadium, a few players are creating content (the contributors) that thousands of people are enjoying with no effort. In the case of open source software, admission to the stadium (GitHub) is also free, and fans also have a direct line of communication with the contributors (GitHub Issues/Slack/Discord).</p><p>I have never personally maintained very popular open source projects, but I’ve merged smaller contributions in large ones like <a href="https://github.com/DefinitelyTyped/DefinitelyTyped">DefinitelyTyped</a>, <a href="https://github.com/cube-js/cube.js">Cube.js</a>, <a href="https://github.com/alexreisner/geocoder">geocoder</a>, and a few more. Each experience was different, but there was a common thread: the maintainers have a lot of work to do to review issues and merge PRs. In her book Nadia suggests that the most precious resource that an open source project has is actually the attention of the maintainers. That is consistent with my personal experience: GitHub has made it exponentially easier for developers to casually contribute to projects, but the amount of work required by maintainers to merge them in has barely decreased. </p><p>This creates key challenges for Stadium maintainers:</p><ul><li><strong>It’s hard for maintainers to triage all the casual contributions that come through GitHub.</strong> Take <a href="https://github.com/babel/babel">Babel</a> as an example; the project has 6-7 core maintainers, but it currently has ~650 open issues and 152 open pull requests; this is after 6,632 closed issues and 4,400+ merged pull requests. Which ones should they prioritize? How do you discern a casual user opening a ticket to a potential contributor who could take work off of the maintainers’ plate in the long run?</li><li>While this has improved over the past few years, <strong>code reviews are still very manual and require a lot of overview from the maintainer.</strong> Pull request templates with checklists and bots have helped, but the way work is reviewed is largely manual. </li><li><strong>Most popular open source projects aren’t created with the intent of becoming stadium projects.</strong> The developer might just want to solve their own problem, or work on a technical challenge. As the project grows, GitHub doesn’t offer many features for creators to manage and organize their communities. <strong>Expanding the maintainer base from 1 to 2+ maintainers is a very large effort as it requires moving all the knowledge of the creator into a shared knowledge base, as well as identifying the additional maintainers.</strong> The best way to do so is usually through the community; by making creators more efficient. They should also be able to more easily figure out who could become a potential maintainer of the project. Sometimes, the large influx of users comes before these steps have been completed, leaving the creator overwhelmed. </li></ul><p>I’ve been thinking through what kind of products could help maintainers free up their time and prioritize their work. I’m not sure if these would be GitHub features, other open source projects that maintainers can leverage, or standalone startups, but I’d love to hear from anyone who has thought about this or is working on something (you can reach me at afanelli(at)645ventures.com).</p><hr><h2>#1: Open Source “Rep” System</h2><p>Most forums in the early 2000s had a “rep” number next to a person’s profile. That would usually give you an idea of how long that user had been around, how much people agreed with them, etc. eBay also had a similar system to rank seller’s trustworthiness (“A++++++++ seller”). With the rise of social media platforms, the idea of reputation has been put to the side as these platforms were initially conceived to connect you to people you already knew in real life. I believe that the internet needs some concept of reputation to be brought back, and GitHub is a prime candidate for it.</p><p>Let’s take Ruby on Rails as an example; the GitHub repo has more than 25,000 pull requests merged in, which came from 5,654 contributors. If you’re one of the core maintainers (s/o to @rafaelfranca!), you need to find a way to prioritize what issues to respond to and which pull requests to review. I think a “rep” system based on your previous activity could help maintainers make these decisions. For example, if you have created dozens and dozens of issues across a lot of projects but no pull requests for any of them, you will likely not open a PR for this one either. If you have a lot of open PRs on other projects that were never merged and you never committed to after the first review, the maintainer should be aware of that as you will likely not follow through on this one either. On the other hand, if you already regularly contribute to other Ruby projects, there’s a good chance you will be able to put together a quality PR without a lot of supervision and just need final maintainer approval to merge it in. If you are new to open source, maintainers will know and give you the necessary help. </p><p>GitHub helps with measuring the quantity of work done, but doesn’t say anything about quality. If we flipped this and focused on highlighting quality of work rather than quantity, open source users’ incentives would be more aligned with the maintainers’, which could have a meaningful impact on the overall health of the open source community.</p><hr><h2>#2: Moving from checklists to automated checks for pull requests</h2><p><a href="https://docs.github.com/en/github/collaborating-with-issues-and-pull-requests/about-status-checks">Status checks</a> on GitHub are one of the most useful features to allow projects, open source and not, to maintain consistent code quality and engineering processes. The problem with status checks at the moment is that not all PR requirements get automated. Let’s take a look at <a href="https://github.com/pandas-dev/pandas">pandas</a>; each PR runs a CI environment that performs a test suite, as well as a Codecov check to see whether or not test coverage has dropped. On top of that, the user has to fill out a manual checklist:</p><ul><li>tests added / passed</li><li>passes black pandas</li><li>passes <code>git diff upstream/master -u -- "*.py" | flake8 --diff</code></li><li>whatsnew entry</li></ul><p>Whenever a maintainer reviews a PR they either have to manually verify each step, or have faith that the user completed them. Why can’t we automate each of these? At one of my previous roles, we used <a href="https://danger.systems/">Danger</a> to solve #1: if a new model was added but there were no new files in <code>spec/models</code>, it’d warn that tests weren’t added. <a href="http://deepsource.io/">DeepSource</a>, one of our portfolio companies, <a href="https://deepsource.io/blog/release-transformers/">has built Transformers</a> for open source projects, giving them a way to automatically run code formatters like <code>black</code> on each PR. A formatting issue shouldn’t be breaking a CI build or be discussed in a PR, it should just be automatically fixed for you. In the long run, I believe (and hope) we will get to a point where we can automate 90% of the review process before a maintainer steps in and gives the final stamp of approval.</p><p>DefinitelyTyped has one of the best infrastructure for this at the moment. You can find an example here: <a href="https://github.com/DefinitelyTyped/DefinitelyTyped/pull/47119">https://github.com/DefinitelyTyped/DefinitelyTyped/pull/47119</a></p><hr><h2>#3: Open source communities transitioning to double opt-in</h2><p>Again, I strongly recommend Nadia’s book because she goes in depth around this argument, but ironically one issue with open source communities today is that participation is open to everyone, and GitHub makes it easier than ever to interact with projects. Rich Hickey, creator of <a href="http://clojure.org/">Clojure</a>, wrote an essay titled <a href="https://gist.github.com/richhickey/1563cddea1002958f96e7ba9519972d9">“Open Source is Not About You”</a> in which he highlights some of his issues with the open source community:</p><blockquote><p><em>“Open source is a licensing and delivery mechanism, period. It means you get the source for software and the right to use and modify it. All social impositions associated with it, including the idea of 'community-driven-development' are part of a recently-invented mythology with little basis in how things actually work, a mythology that embodies, cult-like, both a lack of support for diversity in the ways things can work and a pervasive sense of communal entitlement.”</em></p></blockquote><p>If Rich’s view matched the broader open source community, what would GitHub look like? One example is <a href="https://github.com/torvalds/linux">Linux’s kernel repo</a>, which doesn’t allow users to submit issues, but only pull requests. Discussions are redirected to Linux’s mailing list, just like they were twenty years ago. </p><p>This ties back to the open source rep, but how can we allow maintainers to control the amount of access the community has? Is this GitHub’s job, or should there be a separate platform for it? The proliferation of Slack and Discord channels makes this an even more important issue, as those mediums can be even more overwhelming. I don’t have an answer for this question, but I think it’s a problem that will keep growing as commercial open source becomes more popular. </p><hr><h2>The future of open source</h2><p>In the early days, open source communities were more of a small group of “misfits” (<a href="https://blog.getdbt.com/four-years-in-from-misfits-to-mainstream/">as Tristan at dbt likes to call them</a>) working on interesting technical projects, without clear …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://645ventures.com/github-at-scale-and-how-to-help-stadium-model-maintainers">https://645ventures.com/github-at-scale-and-how-to-help-stadium-model-maintainers</a></em></p>]]>
            </description>
            <link>https://645ventures.com/github-at-scale-and-how-to-help-stadium-model-maintainers</link>
            <guid isPermaLink="false">hacker-news-small-sites-24436238</guid>
            <pubDate>Thu, 10 Sep 2020 20:26:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dutch hackers logged into Trump’s Twitter account in 2016; pw ‘yourefired’]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24436176">thread link</a>) | @troberti
<br/>
September 10, 2020 | https://www.vn.nl/tijdlijn-zo-verliep-de-hack-van-trump/ | <a href="https://web.archive.org/web/*/https://www.vn.nl/tijdlijn-zo-verliep-de-hack-van-trump/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><span>Korte update</span> <span>Donderdag 10 september</span></p></section><p>Dit is een tijdlijn en verantwoording van het verloop van de hack van Trumps twitteraccount door drie Nederlandse hackers in 2016. Eerder deze week publiceerden we <a href="https://www.vn.nl/hackers-twitter-trump/" target="_blank" rel="noopener">een reconstructie</a> van de gebeurtenissen.</p><section id="article-body" data-article-content-element="" data-article-uid="479801" data-restricted="false"><div data-article-content-target=""><p>27 oktober 2016, na de hackerconferentie BruCON kregen drie Nederlandse hackers – leden van de Guild Of The Grumpy Old Hackers – toegang tot de twitter-account van Donald Trump.</p><p>Twee weken voor de Amerikaanse verkiezingen kregen de hackers een LinkedIn-database met 117 miljoen gebruikersnamen en wachtwoorden te pakken. De database circuleerde al sinds 2012 in de criminele wereld, maar werd pas in 2016 te koop aangeboden op de <em>dark markets</em>. Daarna begon het document ook te circuleren in de gemeenschap van informatiebeveiligers. Zo kregen de grumpy hackers het document ook in handen.</p><p><img src="https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding1-1-640x369.png" srcset="https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding1-1-320x185.png 320w, https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding1-1-640x369.png 640w" alt="" width="640" height="369"></p><p>In deze database leken ook gegevens van Donald Trump te staan.</p><p><img src="https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding2-1-640x409.png" srcset="https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding2-1-320x204.png 320w, https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding2-1-640x409.png 640w" alt="" width="640" height="409"></p><p>donaldtrump@trump.com:07b8938319c267dcdb501665220204bbde87bf1d</p><p>De hackers wisten daaruit het volgende wachtwoord te destilleren: <em>yourefired. </em>Dat dit klopt is eenvoudig te verifiëren met een site als <a href="https://passwordsgenerator.net/sha1-hash-generator/" target="_blank" rel="noopener noreferrer">https://passwordsgenerator.net/sha1-hash-generator/</a>.</p><p>Tot hun grote verbazing accepteerde twitter het wachtwoord, maar vroeg de site ter verificatie om een mailadres. donaldtrump@trump.com werd niet geaccepteerd, maar na wat giswerk achterhaalden de hackers het juiste Twitter-emailadres van Trump: twitter@donaldjtrump.com.</p><p><img src="https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding3-1-640x372.png" srcset="https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding3-1-320x186.png 320w, https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding3-1-640x372.png 640w" alt="" width="640" height="372"></p><p>Met dat emailadres lukte het om in te loggen in de Twitteraccount van Trump.</p> <p><a data-ga-category="embedded-article" data-ga-action="clicked" data-ga-label="" href="https://www.vn.nl/hackers-twitter-trump/"> <span></span> <span> <span>Hoe dat ging, lees je hier:</span> <span>Hoe drie Nederlandse hackers het Twitteraccount van Donald Trump hackten</span> <span>9 september 2020</span> </span> </a></p><p>Omdat er naar aanleiding van de inhoud en de timing van het verhaal vragen ontstonden over de authenticiteit, hierbij de tijdlijn die de grumpy hackers maakten, afgewisseld met screenshots uit een eigen presentatie die ze gaven in de inlichtingenwereld.</p><p><img src="https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding4-1-640x135.png" srcset="https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding4-1-320x68.png 320w, https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding4-1-640x135.png 640w" alt="" width="640" height="135"></p><p><img src="https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding5-1-640x388.png" srcset="https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding5-1-320x194.png 320w, https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding5-1-640x388.png 640w" alt="" width="640" height="388"></p><p><img src="https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding6-1-640x33.png" srcset="https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding6-1-320x16.png 320w, https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding6-1-640x33.png 640w" alt="" width="640" height="33"></p><p><img src="https://www.vn.nl/wp-content/uploads/2020/09/Unknown-1280x950.png" srcset="https://www.vn.nl/wp-content/uploads/2020/09/Unknown-320x238.png 320w, https://www.vn.nl/wp-content/uploads/2020/09/Unknown-640x475.png 640w, https://www.vn.nl/wp-content/uploads/2020/09/Unknown-1280x950.png 1280w" alt="" width="1280" height="950"></p><p>De grumpy hackers stuurden de bovenstaande mail aan Trump en aan US Cert (United States Computer Emergency Readiness Team). Toen daar geen reactie op kwam, probeerden ze via andere routes contact te krijgen. Daarna stuurden ze een vergelijkbaar bericht aan het NCSC-NL (Nationaal Cyber Security Centrum), die het opnieuw doorstuurde naar US CERT.</p><p><img src="https://www.vn.nl/wp-content/uploads/2020/09/Schermafbeelding-2020-09-10-om-12.42.21-1280x616.png" srcset="https://www.vn.nl/wp-content/uploads/2020/09/Schermafbeelding-2020-09-10-om-12.42.21-320x154.png 320w, https://www.vn.nl/wp-content/uploads/2020/09/Schermafbeelding-2020-09-10-om-12.42.21-640x308.png 640w, https://www.vn.nl/wp-content/uploads/2020/09/Schermafbeelding-2020-09-10-om-12.42.21-1280x616.png 1280w" alt="" width="1280" height="616"></p><p>Hieronder een van de mails van NCSC.</p><p><img src="https://www.vn.nl/wp-content/uploads/2020/09/Unknown-1-1280x536.png" srcset="https://www.vn.nl/wp-content/uploads/2020/09/Unknown-1-320x134.png 320w, https://www.vn.nl/wp-content/uploads/2020/09/Unknown-1-640x268.png 640w, https://www.vn.nl/wp-content/uploads/2020/09/Unknown-1-1280x536.png 1280w" alt="" width="1280" height="536"></p><p>Uiteindelijk kwam er 2 november een respons.</p><p><img src="https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding9-640x90.png" srcset="https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding9-320x45.png 320w, https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding9-640x90.png 640w" alt="" width="640" height="90"></p><p>Dat er in het Witte Huis inderdaad iets veranderde, werd duidelijk in een <a href="https://www.nytimes.com/2016/11/07/us/politics/donald-trump-presidential-race.html" target="_blank" rel="noopener noreferrer">verhaal</a> van de <em>New York Times</em>:</p><p><img src="https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding10-640x86.png" srcset="https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding10-320x43.png 320w, https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding10-640x86.png 640w" alt="" width="640" height="86"></p><p><img src="https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding11-640x204.png" srcset="https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding11-320x102.png 320w, https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding11-640x204.png 640w" alt="" width="640" height="204"></p><p><img src="https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding12-640x282.png" srcset="https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding12-320x141.png 320w, https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding12-640x282.png 640w" alt="" width="640" height="282"></p><p><img src="https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding13-640x198.png" srcset="https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding13-320x99.png 320w, https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding13-640x198.png 640w" alt="" width="640" height="198"></p><p>Trumps naam dook niet alleen in de LinkedIn Database op. Maar ook in gelekte databases van computerspelletjes en de datingsite Ashley Madison.</p><p><img src="https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding14-640x360.png" srcset="https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding14-320x180.png 320w, https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding14-640x360.png 640w" alt="" width="640" height="360"></p><p>Dit kunnen natuurlijk nepaccounts zijn. Maar in de gelekte database van Ashley Madison stonden ook geen leesbare wachtwoorden, alleen gecodeerde wachtwoorden (bcrypt), die met de huidige technieken moeilijk te kraken zijn. Maar door het wachtwoord ‘yourefired’ door de bcrypt-codeermolen te halen, ontdekten de Grumpy Hackers dat er ook een Trump-account was bij Ashley Madison met hetzelfde wachtwoord: ‘yourefired’.</p><p><img src="https://www.vn.nl/wp-content/uploads/2020/09/Unknown-3-1280x591.png" srcset="https://www.vn.nl/wp-content/uploads/2020/09/Unknown-3-320x148.png 320w, https://www.vn.nl/wp-content/uploads/2020/09/Unknown-3-640x295.png 640w, https://www.vn.nl/wp-content/uploads/2020/09/Unknown-3-1280x591.png 1280w" alt="" width="1280" height="591"></p><p>Hoewel de Grumpy Hackers zwegen tegen de media, was hun verhaal binnen kleine hackerskringen wel bekend.</p><p><img src="https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding16-640x339.png" srcset="https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding16-320x170.png 320w, https://www.vn.nl/wp-content/uploads/2020/09/Afbeelding16-640x339.png 640w" alt="" width="640" height="339"></p><p>Zo kwam ik het verhaal ook op het spoor, tijdens de Chaos Computer Conferentie in Leipzig, december 2019.</p></div></section><div><div><div><p>Onbeperkt verder lezen? Sluit je nu aan.</p><p>Onbeperkt verder lezen? Sluit je nu aan.</p><p><img src="https://www.vn.nl/wp-content/uploads/2020/08/Online_07_2020-320x240.png" alt=""></p><p>Word nu abonnee vanaf 4,- per maand.</p><div><p>Toegang tot alle verhalen op vn.nl</p><p>Artikelen direct in je mailbox of via WhatsApp</p><p>Eenvoudig opzegbaar</p></div></div></div></div><div><div><div><p>Om onze journalistiek te beschermen kun je Vrij Nederland niet incognito lezen.</p><p>Om onze journalistiek te beschermen kun je Vrij Nederland niet incognito lezen.</p><p><img src="https://www.vn.nl/wp-content/uploads/2020/08/Online_07_2020-320x240.png" alt=""></p><p>Word nu abonnee vanaf 4,- per maand.</p><div><p>Toegang tot alle verhalen op vn.nl</p><p>Artikelen direct in je mailbox of via WhatsApp</p><p>Maandelijks opzegbaar</p></div></div></div></div><div><div><div><p>Verder lezen? Lees nu <span color="#c20012">de eerste maand gratis VN Online</span> (t.w.v. € 4,99)</p><p>Verder lezen? Lees nu <span color="#c20012">de eerste maand gratis VN Online</span> (t.w.v. € 4,99)</p><p><img src="https://www.vn.nl/wp-content/uploads/2020/08/Online_07_2020-320x240.png" alt=""></p><p>Schrijf je nu in en lees de eerste maand gratis Vrij Nederland Online.</p><div><p>Toegang tot alle artikelen op vn.nl</p><p>Het Verhaal van de Dag in je mailbox of via WhatsApp</p><p>Maandelijks opzegbaar</p></div></div></div></div></div>]]>
            </description>
            <link>https://www.vn.nl/tijdlijn-zo-verliep-de-hack-van-trump/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24436176</guid>
            <pubDate>Thu, 10 Sep 2020 20:19:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Corona Cases in Boulder Surge]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24436156">thread link</a>) | @tomger
<br/>
September 10, 2020 | https://covid.iterator.us/region/us-co-boulder-colorado | <a href="https://web.archive.org/web/*/https://covid.iterator.us/region/us-co-boulder-colorado">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://covid.iterator.us/region/us-co-boulder-colorado</link>
            <guid isPermaLink="false">hacker-news-small-sites-24436156</guid>
            <pubDate>Thu, 10 Sep 2020 20:18:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[KnotDNS 3.0.0]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24435769">thread link</a>) | @conductor
<br/>
September 10, 2020 | https://www.knot-dns.cz/2020-09-09-version-300.html | <a href="https://web.archive.org/web/*/https://www.knot-dns.cz/2020-09-09-version-300.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">  <p>Wednesday, September 9, 2020</p> <div id="features"> <h2>Features:</h2> <blockquote> <ul> <li>High-performance networking mode using XDP sockets (requires Linux 4.18+)</li> <li>Support for Catalog zones including kcatalogprint utility</li> <li>New DNSSEC validation mode</li> <li>New kzonesign utility — an interface for manual DNSSEC signing</li> <li>New kxdpgun utility — high-performance DNS over UDP traffic generator for Linux</li> <li>DoH support in kdig using GnuTLS and libnghttp2</li> <li>New KSK revoked state (RFC 5011) in manual DNSSEC key management mode</li> <li>Deterministic signing with ECDSA algorithms (requires GnuTLS 3.6.10+)</li> <li>Module synthrecord supports reverse pointer shortening</li> <li>Safe persistent zone data backup and restore</li> </ul> </blockquote> </div> <div id="improvements"> <h2>Improvements:</h2> <blockquote> <ul> <li>Processing depth of CNAME and DNAME chains is limited to 20</li> <li>Non-FQDN is allowed as 'update-owner-name' configuration option value</li> <li>Kdig prints detailed algorithm idendifier for PRIVATEDNS and PRIVATEOID in multiline mode #334</li> <li>Queries with QTYPE ANY or RRSIG are always responded with at most one random RRSet</li> <li>The statistics module has negligible performance overhead on modern CPUs</li> <li>If multithreaded zone signing is enabled, some additional zone maintenance steps are newly parallelized</li> <li>ACL can be configured by reference to a remote</li> <li>Better CPU cache locality for higher query processing performance</li> <li>Logging to non-syslog streams contains timestamps with the timezone</li> <li>Keeping initial DNSKEY TTL and zone maximum TTL in KASP database to ensure proper rollover timing in case of TTL changes during the rollover</li> <li>Responding FORMERR to queries with more OPT records</li> </ul> </blockquote> </div> <div id="bugfixes"> <h2>Bugfixes:</h2> <blockquote> <ul> <li>Module onlinesign responds NXDOMAIN insted of NOERROR (NODATA) if DNSSEC not requested</li> <li>Outgoing multi-message transfer can contain invalid compression pointers under specific conditions</li> </ul> </blockquote> </div> </div></div>]]>
            </description>
            <link>https://www.knot-dns.cz/2020-09-09-version-300.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24435769</guid>
            <pubDate>Thu, 10 Sep 2020 19:39:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Open Source GIS – An Interactive Infographic]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24435582">thread link</a>) | @Pablo1856
<br/>
September 10, 2020 | https://makepath.com/history-of-open-source-gis/ | <a href="https://web.archive.org/web/*/https://makepath.com/history-of-open-source-gis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://makepath.com/history-of-open-source-gis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24435582</guid>
            <pubDate>Thu, 10 Sep 2020 19:17:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Docker for Data Science – A Step by Step Guide]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24435478">thread link</a>) | @Dean-DAGsHub
<br/>
September 10, 2020 | https://dagshub.com/blog/setting-up-data-science-workspace-with-docker/ | <a href="https://web.archive.org/web/*/https://dagshub.com/blog/setting-up-data-science-workspace-with-docker/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <h3 id="by-the-end-of-this-post-you-will-have-a-ml-workspace-running-on-your-machine-via-docker-packed-with-the-ml-libraries-you-need-vscode-jupyter-lab-hub-and-a-lot-of-other-goodies-">By the end of this post, you will have a ML workspace running on your machine via Docker, packed with the ML libraries you need, VSCode, Jupyter Lab + Hub and a lot of other goodies.</h3><p><a href="https://towardsdatascience.com/how-docker-can-help-you-become-a-more-effective-data-scientist-7fc048ef91d5">A lot</a> <a href="https://mlinproduction.com/docker-for-ml-part-1/">has already</a> <a href="https://towardsdatascience.com/learn-enough-docker-to-be-useful-b7ba70caeb4b">been said</a> about why Docker can improve your life as a data scientist. I was working on an (un-)cool depth estimation project using <a href="https://fast.ai/">Fast.ai</a> with a few friends when I stumbled upon this tweet by <a href="https://twitter.com/jeremyphoward">@jeremyphoward</a>.</p><figure><blockquote data-width="550"><div lang="en" dir="ltr"><p>How do you ensure you don't accidentally stop your image without committing, and losing all your changes? Do you use mounts? How do you keep your environment up to date (e.g CUDA updates, python lib updates, etc)?</p><p>Has anyone written a simple step-by-step guide to all this?</p></div>— Jeremy Howard (@jeremyphoward) <a href="https://twitter.com/jeremyphoward/status/1298464400332828675?ref_src=twsrc%5Etfw">August 26, 2020</a></blockquote>

<figcaption>The tweet that started this post</figcaption></figure><p>It so happens that we were using Docker to create our data science workspace for the project, so I thought it would make sense to address Jeremy's questions and share this knowledge with the community.</p><p>I'll very briefly review the core concepts and advantages of Docker, and then show a step-by-step example for setting up an entire data science workspace using Docker.</p><p>If you already know what Docker is and why it's awesome, skip to the <a href="https://dagshub.com/blog/p/25636bb0-204d-4449-9a8d-5e5e20c8c100/need%20to%20add%20the%20link">step-by-step tutorial</a>.</p><h2 id="what-is-docker">What is Docker?</h2><p>Docker is a tool for creating and deploying isolated environments (read: virtual machines) for running applications with their dependencies. </p><p>A few terms you should be familiar with (including a baking analogy for ease of understanding):</p><ul><li><strong><em>Docker Container</em></strong> – A single instance of the application, that is live and running. In our analogy, this is a cookie.</li></ul><!--kg-card-begin: html--><center></center><center><small>A Dancing Cookie. <a href="https://giphy.com/gifs/cookie-dancing-1ngQorBCDcUFy">GIPHY</a></small></center><!--kg-card-end: html--><ul><li><strong><em>Docker Image </em></strong>– A blueprint for creating containers. Images are immutable and all containers created from the same image are exactly alike. In our analogy this is the cookie cutter mould.</li></ul><figure><img src="https://images.unsplash.com/photo-1576476933288-ced9af98eb32?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="" srcset="https://images.unsplash.com/photo-1576476933288-ced9af98eb32?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=600&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 600w, https://images.unsplash.com/photo-1576476933288-ced9af98eb32?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=1000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1000w, https://images.unsplash.com/photo-1576476933288-ced9af98eb32?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=1600&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1600w, https://images.unsplash.com/photo-1576476933288-ced9af98eb32?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2400&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 2400w" sizes="(min-width: 720px) 720px"><figcaption>Cookie Cutters. <a href="https://unsplash.com/@belleam?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Izabelle Acheson</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><ul><li><strong><em>Dockerfile</em></strong> – A text file containing a list of commands to call when creating a Docker Image. In our analogy this is the <strong>instructions to create the cookie cutter mould</strong>.</li></ul><!--kg-card-begin: html--><center></center>
<center><small>Making Cookie Cutters. <a href="https://giphy.com/gifs/3ixS2QB5lWmGCcJkqI">GIPHY</a></small></center><!--kg-card-end: html--><h2 id="why-as-a-data-scientist-should-i-care">Why (as a data scientist) should I care?</h2><p>Broadly, there are two use cases for Docker in ML:</p><ul><li><strong><em>Run Only</em></strong>:<strong> </strong>A run-only container means you edit your code on a local IDE and run it with the container so that your code runs inside the container. <a href="https://github.com/anibali/docker-pytorch">Here is one good example.</a></li><li><strong><em>End-to-End Platform</em></strong>:<strong> </strong>An end-to-end platform container means you have an IDE or Jupyter Notebook / Lab, and your entire working environment, running in the container, and also run the code inside it (with the exception of the working file system which can be mounted).</li></ul><p>We will focus on the second use case.</p><h3 id="reasons-to-use-docker-in-data-science-projects">Reasons to use Docker in data science projects</h3><blockquote><strong>Using docker containers means you don't have to deal with "works on my machine" problems.</strong></blockquote><p>Generally, the main advantage Docker provides is standardization. This means you can define the parameters of your container once, and run it wherever Docker is installed. This in turn provides two major advantages:</p><ol><li><em><strong>Reproducibility:</strong></em> Everyone has the same OS, the same versions of tools etc. This means you don't need to deal with "works on my machine" problems. If it works on your machine, it works on everyone's machine.</li><li><em><strong>Portability:</strong></em> This means that moving from local development to a super-computing cluster is easy. Also, if you're working on open source data science projects, like we do at DAGsHub, you can <em><strong>provide collaborators with an easy way to bypass setup hassle</strong></em>.</li></ol><p>Another <strong>huge advantage</strong> – learning to use Docker will make you a better engineer, or turn you into a data scientist with super powers. Many systems rely on Docker, and it will help you turn your ML projects into applications and deploy models into production.</p><h2 id="examples-of-data-science-oriented-docker-containers">Examples of data science oriented docker containers</h2><!--kg-card-begin: markdown--><ul>
<li><a href="https://hub.docker.com/r/pytorch/pytorch">pytorch/pytorch</a> - a simple container for Use Case 1 that includes Pytorch</li>
<li><a href="https://hub.docker.com/r/jupyter/scipy-notebook">jupyter/scipy-notebook</a> - A container for Use Case 2 that includes Jupyter as the UI, and many python <a href="https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-scipy-notebook">data science modules</a>.</li>
<li><a href="https://hub.docker.com/repository/docker/dagshub/ml-workspace-minimal">DAGsHub/ml-workspace-minimal</a> - Is the container I'll show the step-by-step guide on. This container is an updated version from the <a href="https://github.com/ml-tooling/ml-workspace">ml-tooling/ml-workspace repository</a>. The original has not been maintained for the last 7 months so I created an up to date version. It combines the following tools:
<ul>
<li>💫 Jupyter, JupyterLab</li>
<li>👾 VSCode web-based IDE.</li>
<li>🗃 Pytorch, Tensorflow, Sklearn, Pandas, and many other popular data science libraries &amp; tools.</li>
<li>🖥 Full Linux desktop GUI accessible via web browser.</li>
<li>🎮 Easy terminal access via web browser.</li>
<li>🔀 Seamless Git integration optimized for notebooks.</li>
<li>📈 Integrated hardware &amp; training monitoring via Tensorboard &amp; Netdata.</li>
<li>🚪 Access from anywhere via Web, SSH, or VNC under a single port.</li>
<li>🎛 Usable as remote kernel (Jupyter) or remote machine (VSCode) via SSH.</li>
<li>🐳 Easy to deploy on Mac, Linux, and Windows via Docker.</li>
</ul>
</li>
</ul>
<!--kg-card-end: markdown--><p><strong>Sounds wonderful, right?! Now let's see how to set it up.</strong></p><h2 id="setting-up-your-data-science-docker-container-a-step-by-step-guide">Setting up your data science docker container - a step by step guide</h2><h3 id="install-docker">Install Docker</h3><p>Installing Docker is easy and free. Just follow <a href="https://docs.docker.com/engine/install/">this guide</a> for your operation system.</p><h3 id="building-a-docker-image">Building A Docker Image</h3><p>Will not be covered in this tutorial. Our focus will be on how to run a Docker Container once we already have the image we want.</p><p>We will use a prebuilt image from <a href="https://hub.docker.com/repository/docker/dagshub/ml-workspace-minimal">DAGsHub/ml-workspace-minimal</a>. It is created from this <a href="https://github.com/DAGsHub/ml-workspace">repository</a> on GitHub. If you want to build or modify this image or any other, I recommend <a href="https://towardsdatascience.com/how-docker-can-help-you-become-a-more-effective-data-scientist-7fc048ef91d5">the article</a> Jeremy Howard refers to in his original tweet. </p><h3 id="docker-run-addressing-all-the-special-modifiers">Docker Run + Addressing all the special modifiers</h3><p>Just run the following command:</p><pre><code>docker run -d \
    -v "${PWD}:/workspace" \
    -p 8080:8080 \
    --name "ml-workspace" \
    --env AUTHENTICATE_VIA_JUPYTER="mytoken" \
    --shm-size 2g \
    --restart always \
    dagshub/ml-workspace:latest</code></pre><p><code>docker run</code> is the command that takes a Docker Image (cookie cutter) and creates a container from it. In our analogy, this is the step where you make the cookie.</p><p>This long command might look scary, but we can think of all these flags as toppings for our cookie (chocolate chips and macademia nuts 😋). Here is an explanation of the various flags and why you need them:</p><h4 id="mounting-your-working-file-system-v-pwd-workspace">Mounting your working file system <code>-v "${PWD}:/workspace"</code></h4><p><u>This might be the most important flag of all.</u> It allows you to retain your work (files) after the container shuts down, and to access them from outside the container. </p><p><strong>It does this by mapping your current working folder (where you execute the <code>docker run</code> command), denoted as <code>${PWD}</code>, &nbsp;to a <code>/workspace</code> folder inside the container's virtual file system</strong>. If you'd like to change that, you can change this argument appropriately.</p><h4 id="port-forwarding-p-8080-8080">Port forwarding <code>-p 8080:8080</code></h4><p>This argument exposes the 8080 port. In essence it means that after you run this on a computer, your container will be accessible via <code>http://{computer-ip}:8080</code>. If you're running this on your local system, that address will be <code><a href="http://localhost:8080/">http://localhost:8080</a></code>. For more complex images, you might need more than one port forwarded for additional reasons such as api endpoints. In our case, the port is the UI endpoint, and will lead you to the home screen of ML-Workspace:</p><figure><img src="https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-03-at-13.18.29.png" alt="ML-Workspace homepage" srcset="https://dagshub.com/blog/content/images/size/w600/2020/09/Screen-Shot-2020-09-03-at-13.18.29.png 600w, https://dagshub.com/blog/content/images/size/w1000/2020/09/Screen-Shot-2020-09-03-at-13.18.29.png 1000w, https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-03-at-13.18.29.png 1564w" sizes="(min-width: 720px) 720px"><figcaption>http://localhost:8080 – My ML-Workspace homepage</figcaption></figure><h4 id="naming-our-container-name-dags-workspace">Naming our container <code>--name "dags-workspace"</code></h4><p>This generates a unique identifier for our container for future reference. As it might imply, this name should be unique per your system, so if you make multiple containers from the same image, you'll need to define different names for them. <code>--name</code> is also useful to add meaning to our container. If you don't define a name, a meaningless one will be generated for you automatically.</p><h4 id="defining-environment-variables-env-authenticate_via_jupyter-mytoken">Defining Environment Variables <code>--env AUTHENTICATE_VIA_JUPYTER="mytoken"</code></h4><p>The <code>--env</code> flag defines environment variables for your container. This can vary wildly between containers, and so it's hard to give a generic use case for it.</p><p>In our case, we use this to define a password to the workspace. When someone opens the link above for the first time, Jupyter will require them to input the password defined here. This might be useful if you're working on a shared computer.</p><figure><img src="https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-03-at-16.13.07.png" alt="" srcset="https://dagshub.com/blog/content/images/size/w600/2020/09/Screen-Shot-2020-09-03-at-16.13.07.png 600w, https://dagshub.com/blog/content/images/size/w1000/2020/09/Screen-Shot-2020-09-03-at-16.13.07.png 1000w, https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-03-at-16.13.07.png 1330w" sizes="(min-width: 720px) 720px"><figcaption>ML Workspace requesting a password</figcaption></figure><h4 id="defining-shared-memory-shm-size-2g">Defining shared memory <code>--shm-size 2g</code></h4><p>This flag is used to define the shared memory of your container (the more the better). Remember that this uses the same RAM as your regular system, so if you set it too high it might slow your computer down. A good size would be somewhere between <code>2g</code> and <code>8g</code> for most use cases.</p><h4 id="defining-the-restart-policy-restart-always">Defining the restart policy <code>--restart always</code> </h4><p>The <code>--restart</code> flag represents the container's restart policy. According to the Docker docs:</p><blockquote>A restart policy controls whether the Docker daemon restarts a container after exit.</blockquote><p>We use the <code>always</code> option which means Docker will try to keep the container running even if the system restarts. This is great in order to keep your project context intact.</p><p><strong>Congratulations! </strong>You now have an entire ML workspace running on your docker, including all the goodies you might need.</p><p>If you want to dive one level deeper, I recommend going to the <code>docker run</code> <a href="https://docs.docker.com/engine/reference/run/">command reference</a> to see all available flags.</p><h2 id="additional-setup">Additional Setup</h2><p>Let's go over a few things <em>I recommend</em> you setup to have an ideal workspace.</p><h3 id="setting-up-a-conda-virtual-environment-in-docker">Setting up a Conda/virtual environment in Docker</h3><p>We've set a standardized, isolated machine to run our ML. If you're setting up your project for the first time, you're probably running to your environment manager <code>conda</code>/<code>pip</code> to install some awesome packages.</p><p><strong>Let me stop you there.</strong></p><p>Why go through all this effort to create an isolated, reproducible environment and then go install a bunch of different packages that no one will know about. You should create a Conda or virtual environment to manage your packages. If you decided to use the <a href="https://hub.docker.com/repository/docker/dagshub/ml-workspace-minimal">DAGsHub/ml-workspace-minimal</a> container, here is what you should do:</p><p>In the ML <a href="http://localhost:8080/">workspace home</a> click the Open Tool dropdown and choose Terminal. Then type the following commands:</p><pre><code># Input your &lt;env-name&gt; and the &lt;python-version&gt; you want
conda create -y --name &lt;env-name&gt; python=&lt;python-version&gt;
# Activate your environment
source activate &lt;env-name&gt;

# If you have a `requirements.txt` file, you should install those requirements
pip …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dagshub.com/blog/setting-up-data-science-workspace-with-docker/">https://dagshub.com/blog/setting-up-data-science-workspace-with-docker/</a></em></p>]]>
            </description>
            <link>https://dagshub.com/blog/setting-up-data-science-workspace-with-docker/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24435478</guid>
            <pubDate>Thu, 10 Sep 2020 19:02:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Do Routers Work, Really?]]>
            </title>
            <description>
<![CDATA[
Score 381 | Comments 98 (<a href="https://news.ycombinator.com/item?id=24435454">thread link</a>) | @turingbook
<br/>
September 10, 2020 | https://kamila.is//teaching/how-routers-work/ | <a href="https://web.archive.org/web/*/https://kamila.is//teaching/how-routers-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
    <header>
        
    </header>


              <nav>
    
    <ul>
  <li><a href="#0-some-terminology">0. Some Terminology</a></li>
  <li><a href="#1-high-level-overview">1. High-level Overview</a>
    <ul>
      <li><a href="#the-data-plane-life-of-a-packet">The Data Plane: Life of a Packet</a></li>
    </ul>
  </li>
  <li><a href="#the-details-what-exactly-is-going-on">The details: What <em>exactly</em> is going on?</a>
    <ul>
      <li><a href="#life-of-a-packet-now-properly">Life of a Packet, Now Properly</a>
        <ul>
          <li><a href="#1-it-needs-to-be-routed-l3router">1. “It needs to be routed”: L3/router</a></li>
          <li><a href="#2-it-needs-to-be-passed-down-l25arp-glue">2. “It needs to be passed down”: L2.5/ARP glue</a></li>
          <li><a href="#3-it-needs-to-be-forwarded-l2switch">3. “It needs to be forwarded”: L2/switch</a></li>
          <li><a href="#the-logic-applying-the-tables">The logic: Applying the tables</a></li>
        </ul>
      </li>
      <li><a href="#the-control-plane-how-to-fill-the-tables">The Control Plane: How to Fill the Tables</a>
        <ul>
          <li><a href="#l3--routing-table">L3 / routing table</a></li>
          <li><a href="#l25--arp-table">L2.5 / ARP table</a></li>
          <li><a href="#l2--mac-table">L2 / MAC table</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#gimme-the-code">Gimme the code!</a></li>
  <li><a href="#next-steps">Next steps</a></li>
</ul>
</nav>

<p><strong>Work in progress</strong>: I still need to clean this up &amp; add the complete source code. ETA for a more or less done version is Soon(TM).<br>
<strong>Last updated</strong>: 2020/09/10 because how the eff did this end up on the front page of Hacker News? :D<br>
<strong>Suggestions welcome</strong>: <a href="https://github.com/AnotherKamila/kamila.is/issues/new?labels=teaching&amp;title=[teaching/how-routers-work]+Title">complain</a> if something is unclear or wrong!</p>

<p>This is the inside view of how exactly a router operates. You only need to know this if you are poking inside a router implementation. If that is the case, my condolences.</p>

<p>At the end of this exposition, I will give you the complete source code to a functional router (written in <a href="https://p4.org/">P4</a>, the new &amp; shiny software-defined networking thing). My aim is that you will understand every line of that.</p>

<p>I accompany my explanations below with some P4 code. I think it is useful to read it even if you’ve never seen P4, because it shows a bit more detail than the text and I believe that it is sufficiently pseudocode-ish. Here is a summary of what you need to know to read it:</p>
<ul>
  <li>everything happens per packet</li>
  <li><code>hdr</code> are the packet’s parsed headers</li>
  <li><code>standard_metadata</code> is how you tell the switch to do things with the packet (like send it on a specific port)</li>
  <li><code>meta</code> are user-defined in-memory variables which can be used e.g. for matching in tables</li>
</ul>



<ul>
  <li>Figuring out what should be done with packets is done by <em>the control plane/in the slow path/on the CPU/by the controller</em> or similar phrases. I will refer to all of this as “the control plane”.</li>
  <li>Actually forwarding the packets  is done by <em>the data plane/in the fast path/in the hardware/in the switch</em> and such. I will refer to this as “the data plane”.</li>
</ul>

<p><a href="https://news.ycombinator.com/item?id=24436585">Cyph0n on HN did a good job explaining this distinction.</a></p>



<p>A <em>switch</em> (or an L2 switch :-) ) is an L2-only<sup><a href="#fn1">1</a></sup> thing. It knows about L2 stuff such as MAC addresses and ports<sup><a href="#fn2">2</a></sup>. It does <strong>not</strong> know about anything like IP addresses. It has a <strong>MAC table</strong>: it maps MAC addresses to ports.</p>

<p>A <em>router</em> (or an L3 switch by some people’s vocabulary) operates on L3 only. It knows about L3 stuff such as IP addresses and interfaces and hosts. It does <strong>not</strong> know about L2 stuff such as MAC addresses or ports.<sup><a href="#fn3">3</a></sup> In fact, the routing parts of the router would not have to be changed at all if you decided to use something other than ethernet on L2. It has a <strong>routing table</strong> (details later): a table of subnets/prefixes and how to reach them.</p>

<p>What you normally call a router (that box sitting over there) is actually a router (for handling L3) and one or more switches (for handling L2), and some glue in between. They may in fact be separate chips in hardware.</p>

<p>You need glue to put together the L2 and the L3. This “L2.5” glue is ARP (or NDP for IPv6). It usually lives in the router, but it is glue, not routing, and you can think about it separately.</p>

<h2 id="the-data-plane-life-of-a-packet">The Data Plane: Life of a Packet</h2>

<p>When a packet arrives and needs to be sent further, these things have to happen to it:</p>

<ol>
  <li>It needs to be <em>routed</em>: the <strong>router</strong>, based on L3 information, decides where it needs to go, in L3 speak – it will decide which <em>host</em> to send it to, but not how. This corresponds to the <em><a href="https://en.wikipedia.org/wiki/Routing_table">routing table</a></em>.</li>
  <li>It needs to be passed down to L2: this is where the L2.5 ARP/NDP <strong>glue</strong> translates the L3-speak IP address to L2-speak MAC address. This is the <em>ARP table</em>.</li>
  <li>It needs to be <em>forwarded</em> on the correct port: the <strong>switch</strong> puts the packet on the correct port. This is the <em>MAC table</em>.</li>
</ol>



<h2 id="life-of-a-packet-now-properly">Life of a Packet, Now Properly</h2>

<h3 id="1-it-needs-to-be-routed-l3router">1. “It needs to be routed”: L3/router</h3>

<p>The packet has a destination IP address. This is matched in the <em>routing table</em>, using a longest-prefix match (LPM), i.e. it matches IP address prefixes. It may either be for a host the router is directly connected to (on some interface), or it may need to be sent further, through a <em>gateway</em> (through some interface). Therefore: <strong>The routing table maps a <em>prefix</em> to either <em>a next hop through a gateway and an interface</em>, or <em>a direct connection through an interface</em></strong>.</p>

<div><div><pre><code>routing_table : Prefix -&gt; NextHop (GatewayIP, Interface) | Direct Interface
</code></pre></div></div>

<p>Note that the next hop’s IP address is in the router’s memory only: it does not appear in the packet at any time.</p>

<p>The P4 code defining the IPv4 routing table is:</p>

<div><div><pre><code>action ipv4_through_gateway(ipv4_addr_t gateway, interface_t iface) {
    meta.out_interface = iface;
    meta.ipv4_next_hop = gateway;  // send through the gateway
}

action ipv4_direct(interface_t iface) {
    meta.out_interface = iface;
    meta.ipv4_next_hop = hdr.ipv4.dst_addr;  // send directly to the destination
}

table ipv4_routing {
    key = {
        hdr.ipv4.dst_addr: lpm;  // match prefixes
    }
    actions = {
        ipv4_through_gateway;    // ipv4_through_gateway(gateway, iface)
        ipv4_direct;             // ipv4_direct(iface)
        drop;
    }
    default_action = drop();     // If there is no route, drop it -- in reality, we might want to
                                 // send an ICMP "No route to host" packet.
                                 // Note that this is the default route, so control plane might
                                 // want to set a default gateway here instead of dropping.
    size = ROUTING_TABLE_SIZE;
}
</code></pre></div></div>
<p>(and the exact same thing for IPv6)</p>

<h3 id="2-it-needs-to-be-passed-down-l25arp-glue">2. “It needs to be passed down”: L2.5/ARP glue</h3>

<p>If we did not drop the packet because there was no route, we now know the IP address and interface of the next hop. (Note that this is a host that is connected to us directly – it is sitting on the same wire.)
We need to translate this into an L2 MAC address in order to pass it to the switch. We do it via the ARP table:</p>

<div><div><pre><code>arp_table : (IPv4Address, Interface) -&gt; MACAddress
</code></pre></div></div>

<p>Note: <code>Interface</code> conceptually belongs there, but <code>IPv4Address</code> should be unique. We need to store the interface in the control plane anyway, because we want to pre-emptively re-send ARP requests when an entry is about to expire, but in the data plane it is not strictly necessary.</p>

<p>An interesting question arises here: What do we do if there is no match, i.e. when we don’t know the MAC address for the IP? First, we send an ARP request. Then, most routers drop the packet (relying on either retransmissions or “nobody will miss it”). Storing the packet until the ARP reply comes back (or until it expires) would also work, but usually isn’t done.
Sending ARP requests is normally done in the control plane, because the ARP requests need to be throttled and expired and such.</p>

<p>P4 code:</p>
<div><div><pre><code>action set_dst_mac(mac_addr_t dst_addr) {
    hdr.ethernet.dst_addr = dst_addr;
}

table ipv4_arp {
    key = {
        meta.ipv4_next_hop: exact;     // next_hop is the host we found in the routing step; we want to send to that
        // meta.out_interface: exact;  // conceptually this belongs here, but actually next_hop should be unique, so
                                       // we can leave it out
    }
    actions = {
        set_dst_mac;                // set_dst_mac(mac)
        drop;
    }
    default_action = drop();
    size = ARP_TABLE_SIZE;
}
</code></pre></div></div>

<p>IPv6 uses NDP instead of ARP, which is different but the same ;-)</p>

<h3 id="3-it-needs-to-be-forwarded-l2switch">3. “It needs to be forwarded”: L2/switch</h3>

<p>This is L2 / the switch. It works on each interface separately (it could be multiple chips in hardware). It gets a packet with some destination MAC address, and it decides on which port it should put it. It uses a <em>MAC table</em> to do it:</p>

<div><div><pre><code>mac_table : MACAddress -&gt; Port
</code></pre></div></div>

<p>P4 code:</p>

<div><div><pre><code>// note: we're operating on metadata.out_interface

action set_out_port(port_t ports) {
    standard_metadata.egress_spec = ports;
}

action broadcast() {
    // Implementation depends on the switch.
    // In v1model, use a multicast group corresponding to all ports on metadata.out_interface.
}

// we call it dmac -- see below why
table dmac {
    key = {
        hdr.ethernet.dst_addr: exact;
    }
    actions = {
        set_out_port;  // set_out_port(port)
        broadcast;     // no params, uses metadata.out_interface
                       // remember to set broadcast for 0xffffffffffff in the control plane
        drop;
    }
    default_action = drop();
    size = ARP_TABLE_SIZE;  // we can have at most as many ports as MAC addresses
}

</code></pre></div></div>

<p>Note: Real switches are a bit more complicated than that: for example, redundant links mean that a MAC address may be on more than one port. However, you will notice when you need to think about this. Normally considering the simple version is sufficient.</p>

<h3 id="the-logic-applying-the-tables">The logic: Applying the tables</h3>

<ol>
  <li>apply routing =&gt; find the next hop (either gateway or direct)</li>
  <li>apply ARP translation to the “next hop” host</li>
  <li>send out on the right port</li>
</ol>

<p>In P4:</p>
<div><div><pre><code>apply {
    routing.apply();  // fills out metadata.next_hop
    arp.apply();      // sets pkt.ethernet.dst_addr to the MAC of next_hop
    dmac.apply();     // sends out on the port for pkt.ethernet.dst_addr
}
</code></pre></div></div>

<p>(Note: While this is conceptually correct, we actually also want to apply the auxiliary table mentioned below. The full code contains that.)</p>

<h2 id="the-control-plane-how-to-fill-the-tables">The Control Plane: How to Fill the Tables</h2>

<p>Starting at the bottom for a change:</p>

<h3 id="l3--routing-table">L3 / routing table</h3>

<p>Filled out by the control plane, depending on the context:</p>

<ul>
  <li>In your home router, it probably has only two entries: the local network (something like 192.168.0.0/24) =&gt; direct on the internal interface, and a default route via your ISP’s gateway on the external interface.
 In this case, the routing table is static and is filled out by the firmware according to the settings.</li>
  <li>In a small company router, there might be a direct network such as 10.0.0.0/24, a remote office in 10.0.1.0/24 via a VPN server, and a default route from the ISP.
 The default route and the direct route would also be filled …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kamila.is//teaching/how-routers-work/">https://kamila.is//teaching/how-routers-work/</a></em></p>]]>
            </description>
            <link>https://kamila.is//teaching/how-routers-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24435454</guid>
            <pubDate>Thu, 10 Sep 2020 19:00:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I got fibre to my neighbourhood]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24435423">thread link</a>) | @ronaldl93
<br/>
September 10, 2020 | https://www.ronaldlangeveld.com/how-i-got-fibre | <a href="https://web.archive.org/web/*/https://www.ronaldlangeveld.com/how-i-got-fibre">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <p>Draft, expect typos, spelling and grammar errors, etc ——- last updated 8 September 2020</p>

<p>Spoiler: I don’t have fibre yet, but will have soon.</p>

<p>It’s a humid Sunday afternoon in mid February 2020 on the KZN South Coast.</p>

<p><img src="https://www.ronaldlangeveld.com/assets/images/blog/balcony.jpg" alt="View from home"></p>

<p>Everyone in the house is hot, moody and stressed out because of the internet that drops to dial-up speeds. Netflix and YouTube cannot even be attempted.</p>

<p><img src="https://www.speedtest.net/result/9026177182.png" alt="Actual Speedtest result from that time"></p>

<p>No matter how many times I call, email, tweet, etc customer care, there’s nothing they do to solve the issues.</p>

<p><a href="https://www.ronaldlangeveld.com/rain-speedtest">Rain</a> was our main ISP at the time and they eventually admitted the LTE (4G) tower that our router connects to from here is extremely congested and there is nothing they can do about it. I’ve gone as far as getting in touch with one of the founders of <a href="https://www.rain.co.za/?ref=ronaldlangeveld.com">Rain</a>, who just told me to cancel. <a href="https://www.ronaldlangeveld.com/rain-speedtest">Read more about it here</a></p>

<p>To work, I’ve been tethering from my iPhone, but at R70 (± $5) a gigabyte, it’s not really practical.</p>

<p>Despite the super slow internet speeds, I started researching what alternatives are available in the area. The obvious options kept circling between, ADSL (no chance we dealing with Telkom again after the copper theft fiasco), Wireless ISP’s / Line of Sight (slow and expensive), and then back to unreliable 4G / LTE. Wrecked.</p>

<p>I was literally browsing all major providers’ websites, both fixed and mobile, and especially coverage maps where you’d go to your address and it shows what’s available and what is not. It wasn’t until I browsed on Vodacom’s coverage map and clicked on the business fibre and saw a red line going past our house.</p>

<p><img src="https://www.ronaldlangeveld.com/assets/images/blog/vodacom.png" alt=""></p>

<p>Out of desperation, I contacted Vodacom, despite being one of the most hated internet providers in SA, and asked for more info regarding their Business Fibre.
They got back to me and said it’s not their infrastructure (belongs to Link Africa), but they offer services on it and sent me a quote…. R2000 per month (± $130) for a 10mbps line and a minimum 24 month contract, excluding installation.</p>

<p>Sure it’s extremely expensive for what you get (considering home fibre around R1300 for a 100mbps line), but at least the speed and uptime is guaranteed, so downtime will be a thing of the past… yet, the lengthy contract is a deal breaker. 
The internet ecosystem is moving way too fast to be bound to contracts. So Business Fibre also not an option. Not even sure if I’ll be here in two years time.</p>

<p>But at least I found out that there’s a backhaul running into our neighbourhood, owned and operated by Link Africa. It’s actually used to power the mobile providers’ towers.
I did some scratching and noticed Link Africa do have some FTTH networks around and fairly decent pricing. I contacted them and they confirmed they have backhaul and said all I need to do is gain enough interest from residents and they will install. Easy right?</p>

<p>So they created an expression of interest form for our neighbourhood to complete and it would be passed on via the local WhatsApp groups.</p>

<p><img src="https://www.ronaldlangeveld.com/assets/images/blog/la.png" alt=""></p>

<p>About a week in I got an email back from Link Africa, saying that they received about 80 sign ups and they will pass on this details to another provider called <a href="https://bundunetworx.co.za/?ref=ronaldlangeveld.com">Bundu Networx</a>. They are extremely positive about it.</p>

<p>Excitement kicks in, I’m finally gonna get fibre!!</p>

<p>About a week later, I message them asking if they are making progress as I’m pumping with excitement.</p>

<div><div><pre><code>Hi Ronald - you’re going to need to give me a little more time please - I will update you next week.

Thanks
D
Link Africa
</code></pre></div></div>

<p>Okay, maybe I’m a touch too impatient, so I leave them in peace to let them do their thing….</p>

<p>About 3 months later (May 2020), not a word from Link Africa yet. A whole group of people on Whatsapp is anticipating Fibre, asking me when they will have a connection, I send them (Link Africa) another email asking if they have any updates for us.</p>

<div><div><pre><code>Hi Ronald

I am sorry Link Africa is not in a position to rollout in Freeland Park right now.

Regards
D
Link Africa

</code></pre></div></div>

<p>I emailed Link Africa back, asking if I could have a copy of the data they collected ont he expression of interest just so I can continue hunting for fibre companies. They sent me a copy.</p>

<p>Emotionally wrecked and imposter syndrome spiked through the roof.</p>

<p>I was so confident for two months that we will have Fibre, especially on the WhatsApp groups, now suddenly I have to break the news that there’s no fibre coming.
I figured, no chance. There’s no way I can not get an FNO (Fibre Network Operator) to bring us decent internet. There’s areas not only in SA, but in the world, that’s much smaller and less developed, yet they all have 100mbps home FTTH. I need to do something about it.</p>

<p>I spent the whole Sunday finding contact details of almost every FNO (and some ISP’s, because maybe they know someone) that I could find online. Copied and pasted the same message, with the occassional personalisation and sent out about 60 emails.</p>

<div><div><pre><code>Good day

Myself and the majority of the Freeland Park neighbourhood in Scottburgh are very interested in Fibre, considering copper and ADSL is being phased out + LTE isn't the most reliable. 

I'm in touch with about 100 households in the neighbourhood, all pushing for Fibre. 
I run a WhatsApp group and I'm in the process of compiling a database of everyone's name / email / phone number / physical address.

From the researrch I've done, there's multiple backhaul fibre providers that run straight past Freeland Park (Link Africa, DFA and Openserve to name a few) and all we need now is an FNO to do the last mile. 

Could you please advise us how we can get started with this and what else you need and perhaps even consider looking into deploying here.
There's a great push from the community in the area at the moment, not only from Freeland Park, but also the greater Scottburgh. 

Regards
Ronald

</code></pre></div></div>

<p>The week starts and apart from the automated email responses 🤖, I get one reply from <a href="https://linklayer.co.za/?ref=ronaldlangeveld.com">Link Layer</a>. Nothing from the major companies. 
Link Layer offers to lay fibre, if I get 50% of the whole of Scottburgh (not just our neighbourhood) to fill in the expression of interest.
Sounds good, but Scottburgh has about 4200 households according to the <a href="https://census2011.adrianfrith.com/place/561011?ref=ronaldlangeveld.com">2011 census</a>… first thing that goes through my mind is, “How on earth am I going to get 2100 people to complete a form?” Getting about 100 people just for Freeland Park was already difficult as it is.</p>

<p>I passed it on to a friend who is running the same fibre campaign for Scottburgh South, but Link Layer didn’t show too much interest.</p>

<p>The following week, I posted the same message on the MyBroadband forum hoping someone knows something or someone.</p>

<p>On 10 June 2020, I get the following private message on MyBroadband,</p>

<div><div><pre><code>Good afternoon Ronald

I saw your issue regarding internet.
I would like to see if we can’t assist you with getting FTTH in your area!

I am from an FNO call Linteg Fibre.
We do roll outs like this.

Please feel free to contact me at any time

Johan
Linteg Fibre
[phone number]
</code></pre></div></div>

<p>It was like God sent an angel 👼.</p>

<p>I immediately added Johan’s number on Whatsapp and sent him a message.</p>

<p>About 5 mins later he calls me and we had a brief chat. I mentioned where we live, what we’ve tried, how many households in the area and how many of us wants fibre, etc, etc, etc.</p>

<p>I sent him our coordinates and he said he’ll look into it from their side. I also sent him the expression of interest forms I collected, with about 100 names and addresses on of people who wants Fibre in our Neighbourhood.</p>

<p>About a week passes and Johan + the CEO of Linteg calls me, saying that they have a strong business case and will laying Fibre throughout the neighbourhood. Of course, it’s all subject to further planning such as Municipal permits, etc etc etc, but everything looks positive from their side. Green light! 🚀</p>

<p>A few weeks later I met up with the regional planner, Sean, who came to do a site survey of the neighbourhood. We had a quick chat on our driveway and everything looked super positive.</p>

<p>July came and they officially applied for municipal wayleaves to be legally allowed to dig the place up.</p>

<p>On the last Friday of July, I received a message from <a href="http://lintegfibre.com/?ref=ronaldlangeveld.com">Linteg Fibre</a> confirming that the wayleaves have been approved. Hell yes!</p>

<p>Only then we let the Whatsapp group know we have a green light and fibre is on the horizon. Happy days!</p>

<p>Couple weeks went past and around mid August we received an update from Sean that Linteg have officially started trenching.</p>

<p>That confirms it… We did it.</p>

<p>Linteg is bringing us the long overdue fibre optics! 🍾</p>

<p>And that is not limited to only our neighbourhood, Freeland Park, but they also decided to invest in the greater Scottburgh South and Pennington and have started trenching there as well as far as I know.</p>

<p><img src="https://www.ronaldlangeveld.com/assets/images/blog/sign.JPG" alt=""></p>

<p>Trenching is currenly heavily in progress, but it’s great to see it in progress, from Idea 💡, the building process 🚧 and hopefully soon, the result which will be a 100mbps Fibre Connection, at home.</p>

<p><img src="https://www.ronaldlangeveld.com/assets/images/blog/trench1.JPG" alt="">
<img src="https://www.ronaldlangeveld.com/assets/images/blog/trench2.JPG" alt="">
<img src="https://www.ronaldlangeveld.com/assets/images/blog/trench3.JPG" alt=""></p>

<p>So yeah, now we’re just waiting for the rollout to happen. Hopefully it’s live by November / December. Will keep updating and add to this post.</p>


                </div></div>]]>
            </description>
            <link>https://www.ronaldlangeveld.com/how-i-got-fibre</link>
            <guid isPermaLink="false">hacker-news-small-sites-24435423</guid>
            <pubDate>Thu, 10 Sep 2020 18:57:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: CCS811 indoor air quality sensor driver in Rust]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24435312">thread link</a>) | @eldruin
<br/>
September 10, 2020 | https://blog.eldruin.com/ccs811-indoor-air-quality-sensor-driver-in-rust/ | <a href="https://web.archive.org/web/*/https://blog.eldruin.com/ccs811-indoor-air-quality-sensor-driver-in-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrap"><div><div><div><section id="main"><div><article id="post-/ccs811-indoor-air-quality-sensor-driver-in-rust" itemscope="" itemprop="blogPost"><div><header></header><p><a href="https://blog.eldruin.com/images/ccs811-bluepill.jpg" rel="gallery_ckex53tc400000cmljwxbgvu7"><img src="https://blog.eldruin.com/images/ccs811-bluepill.jpg" itemprop="image"> </a><a href="https://blog.eldruin.com/images/ccs811-rpi.jpg" rel="gallery_ckex53tc400000cmljwxbgvu7"><img src="https://blog.eldruin.com/images/ccs811-rpi.jpg" itemprop="image"> </a><a href="https://blog.eldruin.com/images/ccs811-measurements.jpg" rel="gallery_ckex53tc400000cmljwxbgvu7"><img src="https://blog.eldruin.com/images/ccs811-measurements.jpg" itemprop="image"></a></p><div itemprop="articleBody"><p><a href="https://crates.io/crates/embedded-ccs811" target="_blank" rel="noopener"><img src="https://img.shields.io/crates/v/embedded-ccs811.svg"></a>&nbsp;<a href="https://docs.rs/embedded-ccs811" target="_blank" rel="noopener"><img src="https://docs.rs/embedded-ccs811/badge.svg"></a>&nbsp;<a href="https://travis-ci.com/eldruin/embedded-ccs811-rs" target="_blank" rel="noopener"><img src="https://travis-ci.com/eldruin/embedded-ccs811-rs.svg?branch=master"></a>&nbsp;<a href="https://coveralls.io/github/eldruin/embedded-ccs811-rs?branch=master" target="_blank" rel="noopener"><img src="https://coveralls.io/repos/github/eldruin/embedded-ccs811-rs/badge.svg?branch=master"></a></p><p>We spend an enormous amount of time indoors. The indoor air quality is often overlooked but it is actually an important factor in our health, comfort and even productivity.</p><p>There are lots of things that contribute to the degradation of the <a href="https://en.wikipedia.org/wiki/Indoor_air_quality" target="_blank" rel="noopener">indoor air quality</a> over time. Some of them are trivial to guess like breathing, chimneys, second-hand tobacco smoke, mold, etc. There are others that you may not have heard of like <a href="https://en.wikipedia.org/wiki/Volatile_organic_compound" target="_blank" rel="noopener">volatile organic compounds (VOC)</a>.<br>Remember that smell new things have? well sorry but that <strong><a href="https://iaqscience.lbl.gov/voc-cancer" target="_blank" rel="noopener">can give you cancer</a></strong>.</p><p>You can build your own indoor air quality monitor with an AMS/ScioSense CCS811 sensor and some Rust using the driver I wrote.</p><h2 id="The-device"><a href="#The-device" title="The device"></a>The device</h2><p>The CCS811 is an ultra-low power digital gas sensor solution which integrates a metal oxide (MOX) gas sensor to detect a wide range of Volatile Organic Compounds (VOCs) for indoor air quality monitoring with a microcontroller unit (MCU), which includes an Analog-to-Digital converter (ADC), and an I²C interface.</p><p>CCS811 supports intelligent algorithms to process raw sensor measurements to output equivalent total VOC (eTVOC) and equivalent CO2 (eCO2) values, where the main cause of VOCs is from humans.</p><p>CCS811 supports multiple measurement modes that have been optimized for low-power consumption during an active sensor measurement and idle mode extending battery life in portable applications.</p><h2 id="Firmware-update"><a href="#Firmware-update" title="Firmware update"></a>Firmware update</h2><p>Depending on where you bought your device, it might be that the firmware application version is too old. I have observed the older version hangs or returns errors quite often.</p><p>You can update the firmware application with a Raspberry Pi (it does not matter which one).<br>First wire the device like this:<br></p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></pre></td><td><pre><span>RPi   &lt;-&gt; CCS811</span><br><span>GND   &lt;-&gt; GND</span><br><span>3.3V  &lt;-&gt; VCC</span><br><span>Pin 5 &lt;-&gt; SCL</span><br><span>Pin 3 &lt;-&gt; SDA</span><br><span>GND   &lt;-&gt; nWAKE</span><br><span>3.3V  &lt;-&gt; RST</span><br></pre></td></tr></tbody></table></figure><p>Next inside your Raspberry Pi download the driver repository somewhere, then run the flashing program without arguments to print the current firmware version:<br></p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br></pre></td><td><pre><span>git clone https://github.com/eldruin/embedded-ccs811-rs</span><br><span>cd embedded-ccs811-rs</span><br><span>cargo run --example flash-firmware</span><br></pre></td></tr></tbody></table></figure><p>You will see something like this:<br></p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></pre></td><td><pre><span>Hardware ID: 129, hardware version: (1, 2)</span><br><span>Firmware boot version: (1, 0, 0)</span><br><span>Firmware application version: (1, 1, 0)</span><br><span>Has valid firmware application: true</span><br></pre></td></tr></tbody></table></figure><p>And then an error because no firmware file was provided.</p><p>If the firmware application is smaller than <code>(2, 0, 0)</code>, you can update it as follows.</p><p>Download the new version of the firmware application from <a href="https://github.com/sciosense/CCS811_driver/blob/master/examples/ccs811flash/CCS811_SW000246_1-00.bin" target="_blank" rel="noopener">here</a>. Then place it inside the <code>embedded-ccs811-rs</code> folder and call the flashing program again now providing the path to the new firmware file:<br></p><figure><table><tbody><tr><td><pre><span>1</span><br></pre></td><td><pre><span>cargo run --example flash-firmware CCS811_SW000246_1-00.bin</span><br></pre></td></tr></tbody></table></figure><p>You should see an output similar to this:</p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></pre></td><td><pre><span>Hardware ID: 129, hardware version: (1, 2)</span><br><span>Firmware boot version: (1, 0, 0)</span><br><span>Firmware application version: (1, 1, 0)</span><br><span>Has valid firmware application: true</span><br><span>Starting update process: Reset, erase, download, verify...</span><br><span>Update was successful!</span><br><span>Status:</span><br><span>Hardware ID: 129, hardware version: (1, 2)</span><br><span>Firmware boot version: (1, 0, 0)</span><br><span>Firmware application version: (2, 0, 0)</span><br><span>Has valid firmware application: true</span><br></pre></td></tr></tbody></table></figure><p>Done!</p><h2 id="Using-the-driver"><a href="#Using-the-driver" title="Using the driver"></a>Using the driver</h2><p>To use the device from Rust, you have to add the <a href="https://crates.io/crates/embedded-ccs811" target="_blank" rel="noopener">embedded-ccs811</a> crate to your project as well as a concrete implementation of the <a href="https://crates.io/crates/embedded-hal" target="_blank" rel="noopener">embedded-hal</a> traits. For example if you are using the Raspberry Pi running Linux:</p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></pre></td><td><pre><span></span><br><span>...</span><br><span><span>[dependencies]</span></span><br><span><span>embedded-ccs811</span> = <span>"0.2"</span></span><br><span><span>linux-embedded-hal</span> = <span>"0.3"</span></span><br><span><span>nb</span> = <span>"1"</span></span><br></pre></td></tr></tbody></table></figure><p>Here is an example program which will start the application and print the measurements (<a href="https://github.com/eldruin/embedded-ccs811-rs/blob/master/examples/linux.rs" target="_blank" rel="noopener">source</a>):<br></p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br></pre></td><td><pre><span><span>use</span> embedded_ccs811::{prelude::*, Ccs811Awake, MeasurementMode, ModeChangeError, SlaveAddr};</span><br><span><span>use</span> linux_embedded_hal::I2cdev;</span><br><span><span>use</span> nb::block;</span><br><span></span><br><span><span><span>fn</span> <span>main</span></span>() {</span><br><span>    <span>let</span> dev = I2cdev::new(<span>"/dev/i2c-1"</span>).unwrap();</span><br><span>    <span>let</span> address = SlaveAddr::default();</span><br><span>    <span>let</span> sensor = Ccs811Awake::new(dev, address);</span><br><span>    <span>match</span> sensor.start_application() {</span><br><span>        <span>Err</span>(ModeChangeError { dev: _, error }) =&gt; {</span><br><span>            <span>println!</span>(<span>"Error during application start: {:?}"</span>, error);</span><br><span>        }</span><br><span>        <span>Ok</span>(<span>mut</span> sensor) =&gt; {</span><br><span>            sensor.set_mode(MeasurementMode::ConstantPower1s).unwrap();</span><br><span>            <span>loop</span> {</span><br><span>                <span>let</span> data = block!(sensor.data()).unwrap();</span><br><span>                <span>println!</span>(<span>"eCO2: {}, eTVOC: {}"</span>, data.eco2, data.etvoc);</span><br><span>            }</span><br><span>        }</span><br><span>    }</span><br><span>}</span><br></pre></td></tr></tbody></table></figure><p>Furthermore, this device must be provided with the ambient temperature and humidity in order to compensate the readings. You can see an example doing this <a href="https://github.com/eldruin/driver-examples/blob/master/raspberrypi/examples/ccs811-gas-voc-display-rpi.rs" target="_blank" rel="noopener">here</a>.</p><p>I also created a bare-metal example program that runs on the STM32F1 “blue-pill” board which continuously reads the measurement and prints it on an OLED display. You can find the source code of that program <a href="https://github.com/eldruin/driver-examples/blob/master/stm32f1-bluepill/examples/ccs811-gas-voc-display-bp.rs" target="_blank" rel="noopener"><strong>here</strong></a>.</p><p>In the <a href="https://github.com/eldruin/driver-examples" target="_blank" rel="noopener"><strong>driver-examples</strong></a> repository you can find further bare-metal examples which you can adapt to do other things with this device.</p><h2 id="Some-measurements"><a href="#Some-measurements" title="Some measurements"></a>Some measurements</h2><p><img src="https://blog.eldruin.com/images/ccs811-measurements.jpg" alt="Measurements in a closed room with one person"></p><p>I bought my device on AliExpress and sadly it does not seem to make accurate readings. For example if you see these readings of the device in a closed room with one person. It seems the measurements match the humidity, rather than the CO2 concentration. I made other measurements with an iAQ-Core-C sensor I got from MOUSER and these did resemble what one would expect. I will publish those here soon.</p><p>Possibly my CCS811 is simply worn off. If you are interested in doing something useful with this device I would rather recommend buying it from a reputable retailer like Adafruit, Sparkfun, or so.</p><h2 id="Raspberry-Pi-configuration"><a href="#Raspberry-Pi-configuration" title="Raspberry Pi configuration"></a>Raspberry Pi configuration</h2><p>This device uses clock stretching which leads to communication problems with the Raspberry Pi.<br>For the firmware update it worked repeatedly fine for me but for measurement reading you may encounter errors like this:<br></p><figure><table><tbody><tr><td><pre><span>1</span><br></pre></td><td><pre><span>thread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: Device(DeviceErrors { invalid_register_write: true, invalid_register_read: true, invalid_measurement: true, max_resistance: true, heater_fault: true, heater_supply: true })', src/libcore/result.rs:1165:5</span><br></pre></td></tr></tbody></table></figure><p>You may also see this:<br></p><figure><table><tbody><tr><td><pre><span>1</span><br></pre></td><td><pre><span>thread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: I2C(Nix(Sys(EREMOTEIO)))', src/libcore/result.rs:1165:5</span><br></pre></td></tr></tbody></table></figure><p>A trick for the Raspberry Pi is to reduce the I2C bus speed.<br>You can do that by editing the file <code>/boot/config.txt</code>:<br></p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br></pre></td><td><pre><span>dtparam=i2c_arm=on # Enable I2C</span><br><span>dtparam=i2c_arm_baudrate=10000 # 10kHz speed</span><br></pre></td></tr></tbody></table></figure><p>Then reboot your Raspberry Pi. Done!</p><p>Even when correctly configured the errors can happen on occasion. See <a href="https://learn.adafruit.com/circuitpython-on-raspberrypi-linux/i2c-clock-stretching" target="_blank" rel="noopener">here</a> for more info.</p><h2 id="Where-to-go-from-here"><a href="#Where-to-go-from-here" title="Where to go from here?"></a>Where to go from here?</h2><p>There is more information and example programs in the <a href="https://docs.rs/embedded-ccs811" target="_blank" rel="noopener">crate documentation</a>.<br>If you encounter any issues, please report them in the <a href="https://github.com/eldruin/embedded-ccs811-rs/issues" target="_blank" rel="noopener">issue tracker</a>.<br>Feedback, suggestions and improvements are gladly welcome.</p><h2 id="What’s-next"><a href="#What’s-next" title="What’s next?"></a>What’s next?</h2><p>I also have a pretty finished driver for a similar device: <a href="https://crates.io/crates/iaq-core" target="_blank" rel="noopener">iAQ-Core-C/P air quality sensor</a>. I took some measurements which looked much better. I will announce it here soon.</p><p>Otherwise I have been writing many other platform-agnostic Rust drivers although I am slow to finish them up and announce them here.</p><p>To see what I am currently working on you can <a href="https://github.com/eldruin" target="_blank" rel="noopener"><strong>follow me on github</strong></a>.</p><p>Thanks for reading and stay tuned!</p><p>Links: <a href="https://github.com/eldruin/embedded-ccs811-rs" target="_blank" rel="noopener">Source code</a> - <a href="https://crates.io/crates/embedded-ccs811" target="_blank" rel="noopener">Crate</a> - <a href="https://docs.rs/embedded-ccs811" target="_blank" rel="noopener">Documentation</a></p></div></div></article></div></section></div></div></div></div></div>]]>
            </description>
            <link>https://blog.eldruin.com/ccs811-indoor-air-quality-sensor-driver-in-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24435312</guid>
            <pubDate>Thu, 10 Sep 2020 18:45:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Docker Considered Harmful (2016)]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 49 (<a href="https://news.ycombinator.com/item?id=24435200">thread link</a>) | @maple3142
<br/>
September 10, 2020 | http://catern.com/posts/docker.html | <a href="https://web.archive.org/web/*/http://catern.com/posts/docker.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">


<p>
Docker is extremely popular these days.<sup><a id="fnr.1" name="fnr.1" href="#fn.1">1</a></sup>
Too bad it's not very good.
</p>

<p>
A note in advance:
This is absolutely not about Docker being too "opinionated" for me,
or other tools being more flexible.
I believe that learning and using Docker is just plain more complicated than learning and using the tools I describe below.
Docker is genuinely more complex and harder to use than the alternatives.
These tools also happen to be more flexible than Docker,
but that's not why I'm recommending them:
I'm recommending them because they are simpler to learn and use.
If they are indeed more flexible in addition to being simpler to use, then that's just due to an overall superior design.
</p>

<div id="outline-container-sec-1">
<h2 id="sec-1">Docker containers are not mysterious</h2>
<div id="text-1">
<p>
First, a brief explanation of how containers work.
Linux containers<sup><a id="fnr.2" name="fnr.2" href="#fn.2">2</a></sup> are built on two kernel features, namespaces and cgroups.
Their architecture is quite easy to understand.
</p>

<p>
I encourage everyone to read the main namespaces man page: <a href="http://man7.org/linux/man-pages/man7/namespaces.7.html">man 7 namespaces</a>.
It's well written and makes it easy to grok the concept.
If you create a new instance of all<sup><a id="fnr.3" name="fnr.3" href="#fn.3">3</a></sup> of these namespaces, you have something like a container.
</p>

<p>
The cgroups documentation (located at <a href="https://www.kernel.org/doc/Documentation/cgroups-v1/">Documentation/cgroups-v1/</a> and <a href="https://www.kernel.org/doc/Documentation/cgroup-v2.txt">Documentation/cgroup-v2.txt</a> in your local copy of the Linux source code) is less straightforward, 
but still a better explanation than I could write.
The basic idea is that cgroups are a mechanism for grouping processes.
This mechanism is used to implement other systems like <a href="http://man7.org/linux/man-pages/man7/cpuset.7.html">man 7 cpuset</a>, which are used to track and schedule the container processes.
</p>

<p>
If you make the appropriate system calls to move into a cpuset cgroup and create new namespaces, you have a container.
There's not much to it.
</p>

<p>
One could write a relatively short C program and create a Unix-style utility that uses these system calls to start up a new container.
You can see this for yourself by playing around with <a href="http://man7.org/linux/man-pages/man1/nsenter.1.html">man 1 nsenter</a> and <a href="http://man7.org/linux/man-pages/man1/unshare.1.html">man 1 unshare</a>, which are the most minimal possible wrappers around the namespaces syscalls.
</p>

<p>
The point of explaining this is to show that the Linux container functionality is all rather simple.
Docker (or any other container software) are not doing anything especially mystifying in the specific area of bringing up a container.
Armed with that knowledge, let's look at what else Docker is actually doing.
</p>
</div>
</div>
<div id="outline-container-sec-2">
<h2 id="sec-2">Docker for building containers is superfluous</h2>
<div id="text-2">
<p>
We'll start off with how Docker builds a container image for you.
You pull down some kind of image from the Docker hub, and Docker hums excitingly for a bit while you watch things scroll and progress bars fill.
What you end up with is a filesystem tree from some Linux distro, with a few things added in on top.
</p>

<p>
It may be surprising to some that we have been doing exactly this for multiple decades now.
</p>

<p>
In fact, you do this every time you install GNU/Linux on a machine.
The majority of the files in that filesystem tree come from packages from some distro.
And package managers are certainly capable of installing packages into arbitrary directories; that's how they install a new system.
</p>

<p>
In fact, most even have neat little wrapper scripts to do it for you! And these are only an <code>apt-get install debootstrap</code> (or equivalent) away!
To build filesystem trees for a few of the most popular distros<sup><a id="fnr.4" name="fnr.4" href="#fn.4">4</a></sup>:
</p>
<ul>
<li><code>debootstrap trusty /srv/trees/ubuntu</code>
</li>
<li><code>debootstrap stable /srv/trees/debian</code>
</li>
<li><code>yum -y --nogpg --releasever=22 --disablerepo='*' --enablerepo=fedora install fedora-release systemd passwd dnf fedora-release vim-minimal --installroot=/srv/trees/fedora</code>
</li>
<li><code>pacstrap /srv/trees/arch</code>
</li>
</ul>

<p>
And of course you can select additional packages to install using these commands, or make other changes.
This has been used for decades to build chroots, which I'll say more about a bit later.
There are even more novel package managers,
like <a href="https://nixos.org/nix/">nix</a> and <a href="http://www.gnu.org/software/guix/">guix</a>,
which have interesting features that can make things even easier.
</p>

<p>
But wait, the distro version of node.js (for example) is too out of date!
How am I going to get the latest version?
</p>

<p>
Well, the first thing you should do if you need more up to date versions is enable the updated package repositories for your distro:
Ubuntu backports, Debian backports, CentOS EPEL.
It may be surprising to some, but distros and package managers actually exist for a reason, 
and one of those reasons is that they make it easy to keep your system up to date.
(There are other advantages which I won't go into here<sup><a id="fnr.5" name="fnr.5" href="#fn.5">5</a></sup>)
</p>

<p>
If a suitably updated version is not available through distro channels,
I am obligated to suggest that the next best option is 
to download the source of the distro package, update and rebuild it yourself, and install using that package.
Or, build the package yourself if one isn't available.
This can be a bit of a pain if you are in the early development stages
(though there are tools to make it easier<sup><a id="fnr.6" name="fnr.6" href="#fn.6">6</a></sup>)
but again, there are many advantages.<sup><a id="fnr.5.100" name="fnr.5.100" href="#fn.5">5</a></sup>
</p>

<p>
Most people, however, use the traditional hacks.
You can chroot in and just do your usual <code>pip install foo</code> or <code>gem install bar</code> or <code>npm install baz</code> or <code>./configure &amp;&amp; make &amp;&amp; make install</code>,
just as you would with some "RUN" directives in a Dockerfile.
</p>

<p>
Wow! It's just like Docker!
No, Docker is just like this.
Hopefully it is becoming obvious that here, at least, there is no real advantage of Docker.
</p>

<p>
Crucially, you can use all the same install scripts that you would use with a normal Linux machine.
You don't need to rewrite everything into Dockerfiles.
You can do it manually, you can use shell scripts, you can use Ansible, 
you can write a boutique ConfigurationManagementFactory in Java, you can do whatever you like.
It's just installing software.
It's not complicated unless you make it complicated.
Supposedly, Dockerfiles are simpler than running <code>debootstrap</code> at the beginning of your script, but I'm not sure I understand why.
It seems to me that Docker is no simpler or easier than the standard way.
</p>

<p>
Now, it's true that Docker uses layering to be efficient in terms of disk space and time to build new containers.
It defaults to using <a href="http://aufs.sourceforge.net/aufs.html">AUFS</a> to do this.<sup><a id="fnr.7" name="fnr.7" href="#fn.7">7</a></sup>
I think you could reimplement it easily yourself with a small shell script and some calls to mount;
but I haven't bothered.
</p>

<p>
Personally, I just use <a href="https://btrfs.wiki.kernel.org/index.php/Manpage/btrfs-subvolume">man 8 btrfs-subvolume</a>.
btrfs is a copy on write filesystem which can instantly make space-efficient copies of filesystem trees in "subvolumes",
which the user sees as just regular directories.
</p>

<p>
You can build a stock Ubuntu filesystem tree into a subvolume with 
<code>btrfs subvolume create /srv/trees/ubuntu &amp;&amp; debootstrap trusty /srv/trees/ubuntu/</code>.
Then, when you want to build a new container with specific software,
you just copy that subvolume and perform your modifications on the copy;
that is, <code>btrfs subvolume snapshot /srv/trees/debian /srv/containers/webapp</code> and work on <code>/srv/containers/webapp</code>.
If you want to copy those modifications, you just take another snapshot.
</p>

<p>
This is arguably better, because there's no need to maintain a lot of state about the mount layerings and set them up again on reboot.
Your container filesystem just sits there in a volume waiting for you to start it.
</p>

<p>
Naturally, if you don't like btrfs for some reason,
you're perfectly able to use zfs, OverlayFS, AUFS, or whatever;
no need to have a "storage driver" implemented just to do some simple copy-on-write or layering operations.
</p>

<p>
And if you want to do some kind of change tracking as you build the system,
you should keep it at the proper layer,
or use dedicated tools.
<code>/usr</code> should be immutable and built from packages,
your application data should live in <code>/srv</code> or <code>/var</code> and be mounted in,
and so all the configuration data that is part of the system build should be in <code>/etc</code>.
To track this, you can just use <a href="http://etckeeper.branchable.com/">etckeeper</a> and store your <code>/etc</code> in a git repository.
which is right and proper since <code>/usr</code> should be immutable.
If you must, <a href="https://wiki.gnome.org/action/show/Projects/OSTree">OSTree</a> lets you version whole filesystems.
</p>

<p>
And if you still need to pull in a Docker image for some reason,
you can treat it as just another way to build a filesystem tree.
There are tools that will let you do that,
such as <a href="http://www.freedesktop.org/software/systemd/man/machinectl.html">machinectl pull-dkr</a>.
</p>
</div>
</div>
<div id="outline-container-sec-3">
<h2 id="sec-3">Isolation for deployment is not new</h2>
<div id="text-3">
<p>
But wait! Docker isn't just a pointless abstraction layer over the simple task of building filesystem trees!
It lets you actually use those filesystem trees in containers!
</p>

<p>
Well, it may be a shock, but these tools that Docker uses - they actually exist for a reason.
As I said earlier, these tools have been used for decades to build chroots.
</p>

<p>
What's a chroot?
Well, <a href="http://man7.org/linux/man-pages/man1/chroot.1.html">man 1 chroot</a> is a decades-old tool that lets you change what the root directory <code>/</code> points to;
for example, you could point <code>/</code> at <code>/srv/container/webapp</code>.
Everything looks for libraries and binaries in subdirectories of the root directory, like <code>/usr/lib</code> and <code>/usr/bin</code>.
So, by using chroot you can have an entirely different set of libraries and binaries;
when you run things inside the chroot, they will see just the libraries and software that you installed inside that filesystem tree.
</p>

<p>
To help explain what you can use a chroot for, here's a short little blurb I "wrote" about what you can do with chroot.
</p>

<blockquote>
<p>
Sysadmins use chroot to provide standardized environments for their development, QA, and production teams, reducing "works on my machine" finger-pointing.
By "chrooting" the app platform and its dependencies, sysadmins abstract away differences in OS distributions and underlying infrastructure.
</p>
</blockquote>

<p>
That sure sounds useful.
But wait, there's this new kid on the block, Docker.
Let's see <a href="https://web.archive.org/web/20150211030001/https://www.docker.com/whatisdocker/">what they have to say</a>.
</p>

<blockquote>
<p>
Sysadmins use Docker to provide standardized environments for their development, QA, and production teams, reducing "works on my machine" finger-pointing.
By "Dockerizing" the app platform and its dependencies, sysadmins abstract away differences in OS distributions and underlying infrastructure.
</p>
</blockquote>

<p>
Docker is not novel in giving you these capabilities.
They're quite novel in marketing it so intensely, though.
</p>
</div>
</div>
<div id="outline-container-sec-4">
<h2 id="sec-4">Docker for security is useless by default</h2>
<div id="text-4">
<p>
But wait! Docker is "containers", new, fancy, …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://catern.com/posts/docker.html">http://catern.com/posts/docker.html</a></em></p>]]>
            </description>
            <link>http://catern.com/posts/docker.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24435200</guid>
            <pubDate>Thu, 10 Sep 2020 18:34:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning Rust: Collecting Data from an API]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24435139">thread link</a>) | @dmaceachern
<br/>
September 10, 2020 | https://davidmaceachern.com/posts/collecting-data-from-an-api | <a href="https://web.archive.org/web/*/https://davidmaceachern.com/posts/collecting-data-from-an-api">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>
      <a href="https://davidmaceachern.com/static/1bb73c0a8c64b5e209289403e89786f5/b1fca/data.webp" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://davidmaceachern.com/static/1bb73c0a8c64b5e209289403e89786f5/8ac56/data.webp 240w,
https://davidmaceachern.com/static/1bb73c0a8c64b5e209289403e89786f5/d3be9/data.webp 480w,
https://davidmaceachern.com/static/1bb73c0a8c64b5e209289403e89786f5/e46b2/data.webp 960w,
https://davidmaceachern.com/static/1bb73c0a8c64b5e209289403e89786f5/f992d/data.webp 1440w,
https://davidmaceachern.com/static/1bb73c0a8c64b5e209289403e89786f5/b1fca/data.webp 1491w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://davidmaceachern.com/static/1bb73c0a8c64b5e209289403e89786f5/8ac56/data.webp 240w,
https://davidmaceachern.com/static/1bb73c0a8c64b5e209289403e89786f5/d3be9/data.webp 480w,
https://davidmaceachern.com/static/1bb73c0a8c64b5e209289403e89786f5/e46b2/data.webp 960w,
https://davidmaceachern.com/static/1bb73c0a8c64b5e209289403e89786f5/f992d/data.webp 1440w,
https://davidmaceachern.com/static/1bb73c0a8c64b5e209289403e89786f5/b1fca/data.webp 1491w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <img src="https://davidmaceachern.com/static/1bb73c0a8c64b5e209289403e89786f5/e46b2/data.webp" alt="Data" title="Data" loading="lazy">
      </picture>
  </a>
    </span>
<em>— Photo by <a href="https://unsplash.com/photos/M5tzZtFCOfs" target="_blank" rel="nofollow noopener noreferrer">Taylor Vick</a> on <a href="https://unsplash.com/" target="_blank" rel="nofollow noopener noreferrer">Unsplash</a></em></p>
<p>Data is essential when building applications. We can collect data by calling an API and storing it locally in a database or filestore.</p>
<p>Continue reading if you want to do the following in Rust:</p>
<ul>
<li><a href="#finding-data.">Find some data to use</a></li>
<li><a href="#setting-up-the-project.">Query an API and handle some HTTP errors</a></li>
<li><a href="#persisting-the-data-locally.">Collect some data saving it locally as JSON</a></li>
</ul>
<p>If you are looking for the complete code you can find it <a href="https://www.github.com/davidmaceachern/playground-data-collection-rust" target="_blank" rel="nofollow noopener noreferrer">here</a>.</p>
<h2 id="requirements"><a href="#requirements" aria-label="requirements permalink"></a>Requirements</h2>
<p>Let’s consider how we can achieve our goal:</p>
<ul>
<li><strong>Finding data</strong> we need to have some open data we can collect from an API somewhere. It needs to be open because like Music and Films we need to have permission to use it.</li>
<li><strong>Collecting data</strong> we can do this using an HTTP client, it’s worth noting that a data structure that is transmitted via HTTP is serialized as a string.</li>
<li><strong>Storing data</strong> can be achieved by using a filestore. This can be done by converting the strings we collect to a suitable data structure and outputting it to a file. The format we choose will depend on what we want to do with the data later on.</li>
</ul>
<p><img src="https://davidmaceachern.com/96cb11cdf5b817c5b4c0648b4601a521/collecting-data-2020-08-11-1827.svg" alt="collecting-data-2020-08-11-1827.svg">
<em>The flow of data from the internet to our machine.</em></p>
<h2 id="finding-data"><a href="#finding-data" aria-label="finding data permalink"></a>Finding Data</h2>
<p>Firstly we need an API we can query for some data, a good place to start is this <a href="https://github.com/public-apis/public-apis" target="_blank" rel="nofollow noopener noreferrer">repository</a>.</p>
<p>For this exercise, we are going to get some <a href="https://alexwohlbruck.github.io/cat-facts/docs/" target="_blank" rel="nofollow noopener noreferrer">cat facts</a>. Taking a look through the repository we can see a <a href="https://github.com/alexwohlbruck/cat-facts/blob/master/LICENSE" target="_blank" rel="nofollow noopener noreferrer">repository licence</a>, which looks permissive enough to use this data.</p>
<p>We can use a web browser to call a <code>GET</code> endpoint, pasting this endpoint <code>https://cat-fact.herokuapp.com/facts/random</code> into the address bar returns the following response.</p>
<div data-language="json"><pre><code><span>{</span>
  <span>"used"</span><span>:</span> <span>false</span><span>,</span>
  <span>"source"</span><span>:</span> <span>"api"</span><span>,</span>
  <span>"type"</span><span>:</span> <span>"cat"</span><span>,</span>
  <span>"deleted"</span><span>:</span> <span>false</span><span>,</span>
  <span>"_id"</span><span>:</span> <span>"591f98703b90f7150a19c151"</span><span>,</span>
  <span>"__v"</span><span>:</span> <span>0</span><span>,</span>
  <span>"text"</span><span>:</span> <span>"Cat families usually play best in even numbers. Cats and kittens should be aquired in pairs whenever possible."</span><span>,</span>
  <span>"updatedAt"</span><span>:</span> <span>"2020-06-30T20:20:33.478Z"</span><span>,</span>
  <span>"createdAt"</span><span>:</span> <span>"2018-01-04T01:10:54.673Z"</span><span>,</span>
  <span>"status"</span><span>:</span> <span>{</span>
    <span>"verified"</span><span>:</span> <span>true</span><span>,</span>
    <span>"sentCount"</span><span>:</span> <span>1</span>
  <span>}</span><span>,</span>
  <span>"user"</span><span>:</span> <span>"5a9ac18c7478810ea6c06381"</span>
<span>}</span></code></pre></div>
<p>Ok this is great but we want our application to do this for us.</p>
<h2 id="writing-an-application-in-rust"><a href="#writing-an-application-in-rust" aria-label="writing an application in rust permalink"></a>Writing an Application in Rust</h2>
<h3 id="setting-up-the-project"><a href="#setting-up-the-project" aria-label="setting up the project permalink"></a>Setting up the project</h3>
<p>We are going to write our application in Rust, if you haven’t already you can install Rust using the instructions <a href="https://www.rust-lang.org/learn/get-started" target="_blank" rel="nofollow noopener noreferrer">here</a>.</p>
<p>To install code packages created by other people we will need to check if we have the <code>Cargo</code> package manager, we can do this by running: </p>

<p>If that returned the version we have, we can then initialize a new project that uses the current folder as the name of the project by running:</p>

<p>One thing I like about Rust is the ecosystem. If another language has a feature that is useful it can be recreated as a crate and used. Maybe in a future Rust Edition this feature might be built in!</p>
<p>One such crate I would recommend is <code>cargo-edit</code> which let’s us add packages the same way we might do in Javascript by using <code>$ npm install --save</code>.</p>
<p>We can install this package by running:</p>
<div data-language="rust"><pre><code>$ cargo install cargo<span>-</span>edit</code></pre></div>
<h3 id="breaking-down-the-problem"><a href="#breaking-down-the-problem" aria-label="breaking down the problem permalink"></a>Breaking down the problem</h3>
<p>To address the problem our application will solve, we can use the following crates together:</p>
<ul>
<li>The HTTP client we can use to send the request for our data is very helpfully called <a href="https://crates.io/crates/reqwest" target="_blank" rel="nofollow noopener noreferrer">reqwest</a></li>
<li>Filesystem interactions will be provided by a JSON file store called <a href="https://crates.io/crates/jfs" target="_blank" rel="nofollow noopener noreferrer">jfs</a></li>
<li>To convert our strings to data structures and data structures to strings we can use <a href="https://crates.io/crates/serde" target="_blank" rel="nofollow noopener noreferrer">serde</a></li>
<li>For dealing with JSON data structures we can use <a href="https://crates.io/crates/serde_json" target="_blank" rel="nofollow noopener noreferrer">serde_json</a></li>
<li>To avoid worrying about how we implement errors for now we can use <a href="https://crates.io/crates/anyhow" target="_blank" rel="nofollow noopener noreferrer">anyhow</a></li>
</ul>
<div data-language="bash"><pre><code>$ cargo <span>add</span> reqwest serde serde_json jfs anyhow </code></pre></div>
<p>The output will look like:</p>
<div data-language="bash"><pre><code>      Adding reqwest v0.10.7 to dependencies
      Adding serde v1.0.115 to dependencies
      Adding serde_json v1.0.57 to dependencies
      Adding jfs v0.6.2 to dependencies
      Adding anyhow v1.0.32 to dependencies</code></pre></div>
<p>Without specifying a version number for these libraries, we will want to check the versions we are telling Cargo to use because that will determine which version of the documentation we need to look at.</p>
<p>Inside the <code>Cargo.toml</code> we can see:</p>
<div data-language="toml"><pre><code><span>[</span><span>dependencies</span><span>]</span>
<span>reqwest</span> <span>=</span>  <span>"0.10"</span><span>,</span>
<span>serde</span> <span>=</span> <span>"1.0.115"</span><span>,</span>
<span>serde_json</span> <span>=</span> <span>"1.0.57"</span>
<span>jfs</span> <span>=</span> <span>"0.6.2"</span>
<span>anyhow</span> <span>=</span> <span>"1.0.32"</span></code></pre></div>
<p>So next we can build the application to install the dependencies, we can do this by running:</p>

<p>What I am going to do from here onwards however:</p>

<p>Which will build and execute the code for us so we can have some feedback.</p>
<div data-language="bash"><pre><code>    Finished dev <span>[</span>unoptimized + debuginfo<span>]</span> target<span>(</span>s<span>)</span> <span>in</span> <span>0</span>.06s
     Running <span><span>`</span>target/debug/data-collection-rust<span>`</span></span>
Hello, world<span>!</span><span>!</span></code></pre></div>
<p>Normally if we had tests written then we could have them watch for new  file changes but that is out of scope for the article today.</p>
<h3 id="calling-the-api"><a href="#calling-the-api" aria-label="calling the api permalink"></a>Calling the API</h3>
<p>We will start by replicating calling the API in our application.</p>
<p>In a similar way to how the Web Browser was our client before, we must have a client that will interact with the API.</p>
<div data-language="diff"><pre><code><span><span> </span><span>fn main() {
</span></span><span><span>-</span><span>    println!("Hello, world!");
</span></span><span><span>+</span><span>    let client = reqwest::blocking::Client::new();
</span></span><span><span> </span><span>}</span></span></code></pre></div>
<p>Running this code, we encounter an error.</p>
<div data-language="bash"><pre><code>error<span>[</span>E0433<span>]</span>: failed to resolve: could not <span>find</span> <span><span>`</span>blocking<span>`</span></span> <span>in</span> <span><span>`</span>reqwest<span>`</span></span>
 --<span>&gt;</span> src/main.rs:2:27
  <span>|</span>
<span>2</span> <span>|</span>     <span>let</span> client <span>=</span> reqwest::blocking::Client::new<span>(</span><span>)</span><span>;</span>
  <span>|</span>                           ^^^^^^^^ could not <span>find</span> <span><span>`</span>blocking<span>`</span></span> <span>in</span> <span><span>`</span>reqwest<span>`</span></span></code></pre></div>
<p>When using some crates we must specify the features that our application will use in the <code>Cargo.toml</code>.</p>
<div data-language="diff"><pre><code><span><span> </span><span>[dependencies]
</span></span><span><span>-</span><span>reqwest = "0.10"
</span></span><span><span>+</span><span>reqwest = { version = "0.10", features = ["blocking"] }</span></span></code></pre></div>
<p>Ok so let’s add another line to call out endpoint</p>
<div data-language="diff"><pre><code><span><span> </span><span>    let client = reqwest::blocking::Client::new();
</span></span><span><span>+</span><span>    let uri = "https://cat-fact.herokuapp.com/fact/random";
</span><span>+</span><span>    let response = client.get(uri).send()?;</span></span></code></pre></div>
<p>Upon running our application again we see another error:</p>
<div data-language="bash"><pre><code>error<span>[</span>E0277<span>]</span>: the <span><span>`</span>?<span>`</span></span> operator can only be used <span>in</span> a <span>function</span> that returns <span><span>`</span>Result<span>`</span></span> or <span><span>`</span>Option<span>`</span></span> <span>(</span>or another <span>type</span> that implements<span>..</span>.</code></pre></div>
<p>We’re using the <code>?</code> operator here to handle calling a function that could throw an error. Let’s do as the compiler suggests:</p>
<div data-language="diff"><pre><code><span><span>-</span><span>fn main() {
</span></span><span><span>+</span><span>fn main() -&gt; Result {</span></span></code></pre></div>
<p>It seems that isn’t exactly what the compiler wants:</p>
<div data-language="bash"><pre><code>error<span>[</span>E0107<span>]</span>: wrong number of <span>type</span> arguments: expected <span>2</span>, found <span>0</span>
 --<span>&gt;</span> src/main.rs:1:14
  <span>|</span>
<span>1</span> <span>|</span> fn main<span>(</span><span>)</span> -<span>&gt;</span> Result <span>{</span>
  <span>|</span>              ^^^^^^ expected <span>2</span> <span>type</span> arguments</code></pre></div>
<p>The Result will only be the return type if our code is successful, if not then this function will return an error. This is where we can use <code>anyhow</code>:</p>
<div data-language="diff"><pre><code><span><span>-</span><span>fn main() {
</span></span><span><span>+</span><span>fn main() -&gt; Result&lt;(),  anyhow::Error&gt; {</span></span></code></pre></div>
<p>Ok, so we have another compiler error…</p>
<div data-language="bash"><pre><code>error<span>[</span>E0308<span>]</span>: mismatched types
 --<span>&gt;</span> src/main.rs:1:14
  <span>|</span>
<span>1</span> <span>|</span> fn main<span>(</span><span>)</span> -<span>&gt;</span> Result<span>&lt;</span><span>(</span><span>)</span>, anyhow::Error<span>&gt;</span> <span>{</span>
  <span>|</span>    ----      ^^^^^^^^^^^^^^^^^^^^^^^^^ expected enum <span><span>`</span>std::result::Result<span>`</span></span>, found <span><span>`</span><span>(</span><span>)</span><span>`</span></span>
  <span>|</span>    <span>|</span>
  <span>|</span>    implicitly returns <span><span>`</span><span>(</span><span>)</span><span>`</span></span> as its body has no <span>tail</span> or <span><span>`</span><span>return</span><span>`</span></span> expression</code></pre></div>
<p>We need to add the following it seems, for any successful outcome that doesn’t throw an error.</p>
<div data-language="diff"><pre><code><span><span> </span><span>    let response = client.get(uri).send()?;
</span></span><span><span>+</span><span>    Ok(())
</span></span><span><span> </span><span>})</span></span></code></pre></div>
<p>So we probably want to know what the response looks like. We can take a quick look using the following macro:</p>

<p>And it appears that I might have mistyped the url, as we receive a <code>not found</code> error.</p>
<div data-language="bash"><pre><code><span>[</span>src/main.rs:5<span>]</span> response <span>=</span> Response <span>{</span>
    url: <span>"https://cat-fact.herokuapp.com/fact/random"</span>,
    status: <span>404</span>,
    headers: <span>{</span>
        <span>"server"</span><span>:</span> <span>"Cowboy"</span>,
        <span>"connection"</span><span>:</span> <span>"keep-alive"</span>,
        <span>"x-powered-by"</span><span>:</span> <span>"Express"</span>,
        <span>"access-control-allow-origin"</span><span>:</span> <span>"*"</span>,
        <span>"content-security-policy"</span><span>:</span> <span>"default-src 'none'"</span>,
        <span>"x-content-type-options"</span><span>:</span> <span>"nosniff"</span>,
        <span>"content-type"</span><span>:</span> <span>"text/html; charset=utf-8"</span>,
        <span>"content-length"</span><span>:</span> <span>"150"</span>,
        <span>"set-cookie"</span><span>:</span> <span>"connect.sid=s%3A5IS9zYZqbamwJECS6C5JrdcDfIBJ8epX.Lbh4Zl5C21jdFOyih1RgS1%2FiZr2c8jxbEc1l1XiwTvo; Path=/; HttpOnly"</span>,
        <span>"date"</span><span>:</span> <span>"Tue, 25 Aug 2020 17:46:27 GMT"</span>,
        <span>"via"</span><span>:</span> <span>"1.1 vegur"</span>,
    <span>}</span>,
<span>}</span></code></pre></div>
<p>I checked the API documentation and indeed I had mistyped the url. </p>
<div data-language="diff"><pre><code><span><span>-</span><span>    let uri = "https://cat-fact.herokuapp.com/fact/random";
</span></span><span><span>+</span><span>    let uri = "https://cat-fact.herokuapp.com/facts/random";</span></span></code></pre></div>
<p>After correction, we get the correct status code.</p>
<div data-language="diff"><pre><code><span><span> </span><span>   url: "https://cat-fact.herokuapp.com/facts/random",
</span><span> </span><span>   status: 200,
</span><span> </span><span>   headers: {</span></span></code></pre></div>
<p>It would probably be a good idea to handle errors when we don’t get a <code>200</code> response. Let’s check the response value so we can add a condition.</p>
<div data-language="diff"><pre><code><span><span>-</span><span>    dbg!(response);
</span></span><span><span>+</span><span>    dbg!(response.status());</span></span></code></pre></div>
<p>Ok.</p>
<div data-language="bash"><pre><code><span>[</span>src/main.rs:5<span>]</span> response.status<span>(</span><span>)</span> <span>=</span> <span>200</span></code></pre></div>
<p>Now let’s add a conditional.</p>
<div data-language="diff"><pre><code><span><span>-</span><span>    dbg!(response.status());
</span></span><span><span>+</span><span>    if(response.status() == 200) {
</span><span>+</span><span>        println!("{}", response.status());
</span><span>+</span><span>    }</span></span></code></pre></div>
<p>Cool.</p>

<p>However we want it to throw an error right, seems <code>reqwest</code> might let us do this, let’s force it to fail again by adding the typo back in.</p>
<div data-language="diff"><pre><code><span><span>-</span><span>    let uri = "https://cat-fact.herokuapp.com/facts/random";
</span></span><span><span>+</span><span>    let uri = "https://cat-fact.herokuapp.com/fact/random";
</span></span><span><span> </span><span>    let response = client.get(uri).send()?;
</span></span><span><span>-</span><span>    if(response.status() == 200) {
</span></span><span><span>+</span><span>    if response.status().is_client_error() || response.status().is_server_error() {
</span></span><span><span> </span><span>        println!("{}", response.status());
</span><span> </span><span>    } </span></span></code></pre></div>
<p>And let’s have the application return the error it encounters to avoid running any other code. We can do this by using a macro bundled with anyhow.</p>
<div data-language="diff"><pre><code><span><span>+</span><span>use anyhow::anyhow;
</span><span>+</span><span>
</span></span><span><span> </span><span>fn main() -&gt; Result&lt;(), anyhow::Error&gt; {
</span><span> </span><span>    let client = reqwest::blocking::Client::new();
</span><span> </span><span>    let uri = "https://cat-fact.herokuapp.com/facts/random";
</span><span> </span><span>    let response = client.get(uri).send()?;
</span><span> </span><span>    if(response.status().is_client_error() || response.status().is_server_error()) {
</span></span><span><span>-</span><span>        println!("{}", response.status());
</span></span><span><span>+</span><span>        return Err(anyhow!("Server responded with: {}", response.status()));
</span></span><span><span> </span><span>    } 
</span><span> </span><span>    Ok(())</span></span></code></pre></div>
<p>Seems the compiler is warning us about something:</p>
<div data-language="bash"><pre><code>warning: unnecessary parentheses around <span><span>`</span><span>if</span><span>`</span></span> condition</code></pre></div>
<p>Remove the parentheses and now upon receiving a status code that isn’t <code>200</code> it should return an error.</p>
<div data-language="bash"><pre><code>Error: Server responded with: <span>404</span> Not Found</code></pre></div>
<p>Great. Next, let’s look at getting our facts out of the response.</p>
<h3 id="deserializing-data"><a href="#deserializing-data" aria-label="deserializing data permalink"></a>Deserializing Data</h3>
<p>Let’s start by trying to deserialize the response string into our applications memory.</p>
<div data-language="diff"><pre><code><span><span>+</span><span>    let deserialized = serde_json::from_str(response.text());
</span></span><span><span> </span><span>    Ok(())</span></span></code></pre></div>
<p>The compiler complains…</p>
<div data-language="bash"><pre><code>error<span>[</span>E0308<span>]</span>: mismatched …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://davidmaceachern.com/posts/collecting-data-from-an-api">https://davidmaceachern.com/posts/collecting-data-from-an-api</a></em></p>]]>
            </description>
            <link>https://davidmaceachern.com/posts/collecting-data-from-an-api</link>
            <guid isPermaLink="false">hacker-news-small-sites-24435139</guid>
            <pubDate>Thu, 10 Sep 2020 18:27:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I integrated a Bootstrap Dashboard theme into Rails – with a step-by-step guide]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24435040">thread link</a>) | @timjones
<br/>
September 10, 2020 | https://www.dinosaas.com/articles/starter-app-1-argon | <a href="https://web.archive.org/web/*/https://www.dinosaas.com/articles/starter-app-1-argon">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><h2>Introducing Argon</h2><p><em>Argon is open-source and free for personal and commercial use under the MIT&nbsp;license. </em><a href="https://github.com/Dino-SaaS/Argon"><strong><em>Check it out on Github!</em></strong></a><br></p><p>Argon is a beautiful Dashboard that will save you <strong>weeks</strong> of time building your next app.<br></p><p>It includes over 100 components -- charts, tables, cards, navbars, and more. Easily mix, match, and customize components to turn your vision into a reality.<br></p><p>Argon is a Bootstrap theme designed and built by <a href="https://www.creative-tim.com/product/argon-dashboard">Creative Tim</a>. Our Argon Starter App is the marriage of their open-source theme and the Rails Asset Pipeline.<br></p><p>This tutorial will walk you through how to use it:</p><ul role="list"><li>Get it up and running on localhost in minutes</li><li>Stylesheets</li><li>Javascript</li><li>Images</li><li>Icons</li><li>Views</li><li>Customizations and using real data</li></ul><p>
<b>We believe that small teams (and even individuals) can build amazing products when they're not bogged down by reinventing the wheel.</b>
</p><p>We're here to help you. With our open source Starter Apps and step-by-step tutorials, you can skip the mundane boilerplate and fly right into the exciting stuff that'll make your app great.</p><h2>Up and Running in 5 Minutes</h2><p><em>Download Argon and get it running on localhost.</em></p><p>In your terminal, clone <a href="https://github.com/Dino-Saas/Argon">the repository</a> to your local filesystem.</p><p>
	-- CODE language-sh --git clone git@github.com:Dino-Saas/Argon.git argon-demo
</p><p>Now you'll need to take a couple steps to <strong>download the latest versions of required Ruby gems and Javascript packages</strong>.</p><div><p>
First, run <code>bundle install</code>&nbsp;to download the right gems with the right versions (as specified in the <code>Gemfile</code>).
</p>
<p>
-- CODE language-sh --bundle install
</p></div><div><p>
  Next, update Yarn packages as specified in <code>package.json</code>.
</p>
<p>
-- CODE language-sh --yarn install
</p></div><p>Now start up your server.</p><p>
-- CODE language-rb --rails server
</p><p>Point your browser to <a href="http://localhost:3000/">http://localhost:3000</a> and check out your stunning new Rails dashboard!</p><p>‍</p><h2>Diving into the Codebase</h2><p>Assembling a Rails app is even more complex than assembling IKEA furniture. And just like an IKEA dresser, you shouldn’t have to go at it without instructions.<br></p><p>We’ll walk you through how some of the more important pieces are assembled.</p><p>‍</p><h3>Background Topics</h3><p>This guide does not attempt to be a deep technical resource on the inner workings of Ruby on Rails. There are plenty of resources online for that, but we’ll try and point you in the right direction when we can.<br></p><p>If you’re unfamiliar with them, it’d be a good idea to read up on the basics of a few topics:</p><ol role="list"><li><a href="https://getbootstrap.com/">Bootstrap</a></li><li><a href="https://sass-lang.com/">Sass</a></li><li><a href="https://guides.rubyonrails.org/asset_pipeline.html">Rails Asset Pipeline</a></li></ol><p>‍</p><h3>Stylesheets</h3><div><p>
Argon’s stylesheets use Sass. It all starts in the application layout file - <a href="https://github.com/Dino-Saas/Argon/blob/master/app/views/layouts/application.html.erb"><code>application.html.erb</code></a>. There, we link to our <a href="https://github.com/Dino-Saas/Argon/blob/master/app/assets/stylesheets/application.scss"><code>application.scss</code></a> manifest file:&nbsp;
</p>
<p>
-- CODE language-rb --&lt;%= stylesheet_link_tag 'application', media: 'all', 'data-turbolinks-track': 'reload' %&gt;&nbsp;
</p></div><p>
<code>application.scss</code> tells Sprockets which stylesheets to include and in what order via <code>@import</code> directives.</p><p>We'll walk through how to use these stylesheets to customize your app’s look and feel shortly.</p><p>‍</p><h3>Javascript</h3><div><p>
Our Javascript journey starts back in <a href="https://github.com/Dino-Saas/Argon/blob/master/app/views/layouts/application.html.erb"><code>application.html.erb</code></a>. Here, we include our <code>application</code> javascript pack with Webpacker:
</p>
<p>
  -- CODE language-rb --&lt;%= javascript_pack_tag 'application', 'data-turbolinks-track': 'reload' %&gt;
</p>
<p>
	This references our <a href="https://github.com/Dino-Saas/Argon/blob/master/app/javascript/packs/application.js"><code>application.js</code></a> manifest file. Similar to <code>application.scss</code>, <code>application.js</code> contains a sequence of <code>require</code> directives telling Sprockets which files to include and in which order.
 </p>
 <p>
 	<code>argon.js</code> is one of those included files. It has all the custom javascript included with the theme. It’s well commented and broken up by component.
 </p></div><p>‍</p><h3>Images</h3><div><p>Images can be found in <code>app/assets/images</code>.</p>
<p>
We render them using <code>image_tag</code>. This helper method generates the <code>&lt;img&gt;</code> tag that we know and love. 
</p>
<p>
With <code>image_tag</code>, we specify only a relative path from one of the default asset locations that Sprockets knows to look for. For example, you’ll see the following in <a href="https://github.com/Dino-Saas/Argon/blob/master/app/views/pages/_sidenav.html.erb"><code>pages/_sidenav.html.erb</code></a>:
</p>
<p>
-- CODE language-rb --&lt;%= image_tag "brand/blue.png", class: "navbar-brand-img", alt: "..." %&gt;
</p>
<p>
See Section 2.2.1 in the official Rails docs on <a href="https://guides.rubyonrails.org/asset_pipeline.html#asset-organization">The Asset Pipeline</a> if you’d like to learn more about how Sprockets loads images and other assets.
</p></div><p>When you deploy to production, you'll want to move your images to a Content Delivery Network (CDN) like <a href="https://aws.amazon.com/cloudfront/">Cloudfront</a> or <a href="https://cloudinary.com/">Cloudinary</a>. This will force you to use some different helper methods, but will be well worth it to decrease page load times. We’ll go over this more in-depth in a later post.</p><p>‍</p><h3>Icons</h3><p>Argon is configured to use 2 different sources of icons:</p><div><h4>Nucleo Icons</h4>
<p>
	See the <a href="https://demos.creative-tim.com/argon-dashboard/docs/foundation/icons.html">Creative Tim docs</a> on icons to see what's available and how to use them. You can also check out <a href="https://github.com/Dino-Saas/Argon/blob/master/app/views/pages/icons.html.erb"><code>icons.html.erb</code></a> in Argon for plenty of examples like this one:
</p>
<pre><code>&lt;i class="ni ni-active-40"&gt;&lt;/i&gt;</code></pre>

<h4>Font Awesome (and the <code>font-awesome-rails</code> gem)</h4>
<p>
<code>font-awesome-rails</code> lets us include icons using the <code>fa_icon</code> helper method. Check out <a href="https://github.com/Dino-Saas/Argon/blob/master/app/views/pages/logged_out/_topnav.html.erb"><code>pages/logged_out/_topnav.html.erb</code></a> for some examples like this:
</p>
<p>
-- CODE language-rb --&lt;%= fa_icon 'facebook' %&gt;
</p></div><p>FontAwesome has thousands of free and premium icons to choose from on <a href="https://fontawesome.com/">their website</a>.</p><h3>Views</h3><div><p>
For simplicity, <b>we’ve organized all our views under a generic <code>pages</code> directory</b>. They all have empty (currently not defined) actions in <code>PagesController</code>. I would not recommend continuing this simplistic pattern when you extend the app for your own purposes.
</p>
<p>
<b>All views start with the application layout file - <a href="https://github.com/Dino-Saas/Argon/blob/master/app/views/layouts/application.html.erb"><code>application.html.erb</code></a></b>. Rails renders the appropriate view file where we call <code>yield</code> in the layout. Read more on layouts <a href="https://guides.rubyonrails.org/layouts_and_rendering.html#structuring-layouts">here</a> in the Rails docs.
</p>
<p>
<b>Each view file is further broken up into partials.</b> A partial is a way of dividing up a bigger file into smaller chunks. It avoids having massive files with thousands of lines. More importantly, it allows us to reuse code across different views while only writing it once.
</p></div><p>‍</p><h2>Adding some flair</h2><figure id="w-node-0a8c2fd647c6-5b4a6e45"><p><img src="https://uploads-ssl.webflow.com/5f4acf32e17a9c037c4a6e65/5f5162bc0c9884efdb8fd84c_office-space.gif" loading="lazy" alt=""></p></figure><h3>Customizing the UI</h3><p>Just because you start from a theme, doesn’t mean you can’t get creative with it!</p><p>Bootstrap makes it super easy to style pretty much everything using their included classes. For example, <code>bg-primary</code> sets <code>background-color</code> to blue, while <code>btn-secondary</code> makes your <code language="markup">&lt;button&gt;</code> white.</p><p>But not everyone wants their site looking like an out-of-the box Bootstrap template. I’m going to walk through how to customize Argon to match our own brand and colors at DinoSaaS.</p><p>
Bootstrap comes with a <a href="https://www.dinosaas.com/articles/%E2%80%9Dhttps://github.com/Dino-Saas/Argon/blob/master/app/assets/stylesheets/bootstrap/_variables.scss%E2%80%9D"><code>_variables.scss</code></a> file that specifies everything from <code>$primary</code> and <code>$secondary</code> colors to <code>$border-radius</code> and <code>$box-shadow</code>.
</p><p>These values are used all across the app - we can change values in one place and immediately have global consistency.</p><div><p>
We <i>could</i> go directly into the bootstrap source at <code>bootstrap/_variables.scss</code> and modify them there, but I wouldn’t recommend it. Doing this will make it more difficult down the road to update Bootstrap to a future version.
</p>
<p>
Instead, you’ll want to make changes in <a href="https://www.dinosaas.com/articles/%E2%80%9Dhttps://github.com/Dino-Saas/Argon/blob/master/app/assets/stylesheets/custom/_variables.scss%E2%80%9D"><code>custom/_variables.scss</code></a>. In general, if a property on a class is set twice, the one that is set <i>last</i> overrides the first. However, <code>bootstrap/_variables.scss</code> uses the <a href="https://sass-lang.com/documentation/variables#default-values"><code>!default</code></a> flag - this assigns a value to a variable <i>only if</i> it's not already defined.
</p>
<p>
So even though <code>custom/_variables.scss</code> is included <i>first</i> in our <code>application.scss</code> manifest, variables that are set there will override the bootstrap defaults.
</p></div><h4>Changing the color scheme</h4><div><p>
First, we’re going to make some color changes. We’ll set <code>$primary</code> to “Steel Blue”, the lighter blue color used in most of our copy.
</p>
<p>
Next, we’re going to change our <code>$default</code> color to “Midnight Blue”, the darker blue used in our home page.
</p></div><p>Here’s what some of our pages look like with these new changes:</p><figure id="w-node-8369b6dcf849-5b4a6e45"><p><img src="https://uploads-ssl.webflow.com/5f4acf32e17a9c037c4a6e65/5f52893fd0165e5b985e2029_ksZa8WDTe-PzGn8Uvy3s7wLIUCs0WAdp7i7LZZ9-ALwqTbom3sbxdHZ8-JQ6jIlCEhvhmJqhfxoQ1yDQ2koB1O3oaNRy79uB2x2iErFyQnKin0IDW61xgRforA9GTQ9RZTjtjTj9.png" alt=""></p><figcaption>We changed the background color of the top section to "Steel Blue" and the background color of the "Sales value" chart to "Midnight Blue".</figcaption></figure><figure id="w-node-d37642091b2a-5b4a6e45"><p><img src="https://uploads-ssl.webflow.com/5f4acf32e17a9c037c4a6e65/5f52895129aeac27ae9ea796_SpikpDM9pxrGDoMJHAFFHxWHkGMuWTVLu4P5G-qGLb3bEDs3QfRJYnFpViR-sFL4cRvArWkMWz88Bx86DiFsyddeYigShgr83LlqyHqvbUrpIrSDy43Yt6Umbp20exlr3nY9wswH.png" alt=""></p><figcaption>The 2 background colors on the Login page match the new values of $primary and $default as well.<br></figcaption></figure><div><p>
Here are those changes in <code>custom/_variables.scss</code>:
</p>
<pre><code>$default: #1f2c3d !default;
$primary: #096ad0 !default;
</code></pre>
</div><p>‍</p><h4>Updating the logo</h4><p>
The Argon logos are stored in <a href="https://www.dinosaas.com/articles/%E2%80%9Dhttps://github.com/Dino-Saas/Argon/tree/master/app/assets/images/brand%E2%80%9D"><code>/images/brand</code></a> - there’s <code>white.png</code> and <code>blue.png</code>.
</p><p>We’ll replace these files with the DinoSaaS white and blue logos, respectively:</p><figure id="w-node-e304753aafb6-5b4a6e45"><p><img src="https://uploads-ssl.webflow.com/5f4acf32e17a9c037c4a6e65/5f528ab7fa7a934f622836bd_MOp80CIIDObx-0-Z5paY1UyxSrnIxqAo0TNZu-Qmz85i_UbEJfkkmpd1rwenfSpMyDbyFXo2njcyRqvRVASkB_-Kns2g6Hyc_n82u_T-Pzb3oPRd5vLL4J9ZAWzYL0_Ke8m2aQxY.png" alt=""></p><figcaption>Dashboard wit blue logo.</figcaption></figure><figure id="w-node-68714e1164ce-5b4a6e45"><p><img src="https://uploads-ssl.webflow.com/5f4acf32e17a9c037c4a6e65/5f528abe550d6f59816e815e_6fxVQ4fZjxGUpTlxSCre4crGicoWxo50eMgv_U1PRRoMIaG36TjYnbmlvb2wbffjvqiUHWEq81rpZR111ZUxvllx99CuwWBfB9cxHdFtNNxl713noKWABJMZ99SVGjYGu7ujScYo.png" alt=""></p><figcaption>Login page with white logo.</figcaption></figure><p>‍</p><p>You can see all the changes related to customizing the UI in <a href="https://github.com/Dino-SaaS/Argon-Demo/pull/2">Pull Request #2</a>.</p><h3>Custom Javascript</h3><div><p>
If you want to extend or remove Javascript code included with the template, edit <a href="https://github.com/Dino-Saas/Argon/blob/master/app/javascript/argon.js"><code>argon.js</code></a>.
</p>
<p>
If you want to add new functionality, I’d suggest starting with new files. In <a href="https://github.com/Dino-Saas/Argon-Demo/commit/ed6b5ec6a89e3e996bf8154667a64238c91f770a">this commit</a>, we’ll add a little greeting that’s sure to inject some user delight into your dashboard experience.
</p>
<p>
We'll start by adding a new button to the top of the Dashboard. In <a href="https://github.com/Dino-Saas/Argon-Demo/blob/master/app/views/pages/dashboard.html.erb"><code>dashboard.html.erb</code></a>, we add this button:
</p>
<pre><code>&lt;div class="header bg-primary pb-6"&gt;
	&lt;div class="container-fluid"&gt;
  	&lt;button id="hello" class="btn btn-secondary"&gt;Say Hello&lt;/button&gt;
    &lt;div class="header-body"&gt;
    ...
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
</code></pre>
</div><p>It should look like this:</p><figure id="w-node-820815ac8da3-5b4a6e45"><p><img src="https://uploads-ssl.webflow.com/5f4acf32e17a9c037c4a6e65/5f5018c234da3068d06e092f_W0X-Xdb8GAyP33l0-hXx9RW2UIqA_sCe_5iJE4T6XpJuz_INiW8xgS5LprN5g-evwGz90_aEAR8IkxiqU8ZDxAM_nGNtp2Qw8cgLvT1PmEEPIc20MNOkx9V9LrjFxMxtU9ClyiyE.png" alt=""></p><figcaption>Dashboard with "Say Hello" button</figcaption></figure><div><p>
Next, we’ll hook it up to some Javascript. Create a new <code>demo-app.js</code> file in <code>app/javascript</code>. Here, we’ll add the following code:
</p>
<p>
-- CODE language-js --$( document ).on('turbolinks:load', function() {
  $("#hello").click(function() {
    alert("Hello!");
  });
});
</p>
<p>
Now we'll include the new file in <a href="https://github.com/Dino-SaaS/Argon-Demo/blob/ed6b5ec6a89e3e996bf8154667a64238c91f770a/app/javascript/packs/application.js"><code>application.js</code></a>:
</p>
<p>
-- CODE language-js --require("demo-app.js")
</p></div><p>Reload the page. Clicking the “Say Hello” button should show you an alert popup like this:</p><figure id="w-node-13bd7fabcba6-5b4a6e45"><p><img src="https://uploads-ssl.webflow.com/5f4acf32e17a9c037c4a6e65/5f501938f37153374f22c3af_mCsWDxEci_H_hFbnY-C_5WPo0QOCmLtJxg0a1ztvS8j1ogRcv-dnjwta1tTl7fxUVm2LnKHkAn7dIul5u2jWhAbxz7UELicjON5hVqh_Sey5g4_kW1qAPmas8vIK3p5iKntTL3H7.png" alt=""></p><figcaption>Clicking the "Say Hello" button brings up this alert.</figcaption></figure><div><p>Why are we listening for the <code>turbolinks:load</code> event?</p>
<p>
	Great question! By waiting for <code>turbolinks:load</code> to fire, we ensure that the button is rendered <i>before</i> we attach its click handler. See <a href="https://guides.rubyonrails.org/working_with_javascript_in_rails.html#turbolinks">this section</a> in the Rails docs on Turbolinks if you want to learn more.
</p></div><p>‍</p><h3>Using real data</h3><p>By now, you’re probably thinking, <em>Yea these charts look great, but what am I supposed to do with this fake data?!</em><br></p><p>Snarkiness aside, you’ve got a point. Next, we’re going to populate the “Page Visits” table with real data from our Rails backend.</p><p><strong>We’ll start by creating a PageVisit model</strong>. We don't care about tests right now so we don't generate tests or fixtures.</p><div><p>
-- CODE language-sh --
rails generate model PageVisit page_name:string visitors:integer unique_users:integer …</p></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.dinosaas.com/articles/starter-app-1-argon">https://www.dinosaas.com/articles/starter-app-1-argon</a></em></p>]]>
            </description>
            <link>https://www.dinosaas.com/articles/starter-app-1-argon</link>
            <guid isPermaLink="false">hacker-news-small-sites-24435040</guid>
            <pubDate>Thu, 10 Sep 2020 18:17:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Monads for JavaScript Developers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24434782">thread link</a>) | @paulshen
<br/>
September 10, 2020 | https://bypaulshen.com/posts/monads-for-javascript-developers/ | <a href="https://web.archive.org/web/*/https://bypaulshen.com/posts/monads-for-javascript-developers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p>Why are there so many monad articles and tutorials? Because people like me keep writing them 😎</p><p>Maybe it's because of the <a href="#">monad tutorial fallacy</a>. Anyways, I hope this gives you, a JavaScript developer, a gist of what monads are and why people care about them.</p><p>This article is also a small experiment. Try clicking <a href="#">this dashed link</a>. It will open a pane, as will the other dashed links. If you are at a computer (recommended), you'll find some interactive exercises as well.</p><p>I imagine you are familiar with the almighty JavaScript and have encountered types before, maybe with TypeScript or Flow. If not, the code examples should still be intelligible. No Haskell experience required!</p><p>Let's pretend for a moment that JavaScript is a pure language and <a href="#">side-effects</a> are not allowed in functions.</p><pre><p><span>function</span><span> </span><span>increment</span><span>(</span><span>x</span><span>:</span><span> number</span><span>)</span><span>:</span><span> </span><span>number</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>console</span><span>.</span><span>log</span><span>(</span><span>'incrementing'</span><span>)</span><span>;</span><span> </span><span></span></p><p><span>  </span><span>return</span><span> x </span><span>+</span><span> </span><span>1</span><span>;</span><span></span></p><p><span></span><span>}</span></p></pre><p>How can we implement something similar to <code>console.log</code> without side effects? We could wrap the return value to include a string.</p><pre><p><span>function</span><span> </span><span>incrementWithLog</span><span>(</span><span>x</span><span>:</span><span> number</span><span>)</span><span>:</span><span> </span><span>[</span><span>number</span><span>,</span><span> </span><span>string</span><span>]</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>return</span><span> </span><span>[</span><span>x </span><span>+</span><span> </span><span>1</span><span>,</span><span> </span><span>'incrementing\n'</span><span>]</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>function</span><span> </span><span>run</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> valueWithLog </span><span>=</span><span> </span><span>incrementWithLog</span><span>(</span><span>0</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>[</span><span>value</span><span>,</span><span> log</span><span>]</span><span> </span><span>=</span><span> valueWithLog</span><span>;</span><span></span></p><p><span></span><span>}</span></p></pre><p>Notice how we've created a context around the original value. Where we started with <code>increment</code> returning a <code>number</code>, <code>incrementWithLog</code> now returns a "tuple" <code>[number, string]</code> where the <code>string</code> represents the log message. Let's call this context <code>WithLog&lt;T&gt; = [T, string]</code> where <code>T</code> could be any type. In this example, <code>incrementWithLog</code> returns a <code>WithLog&lt;number&gt;</code>, with <code>T</code> being the <code>number</code>.</p><p>What if we want to use this function multiple times?</p><pre><p><span>function</span><span> </span><span>run</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> initialValue </span><span>=</span><span> </span><span>0</span><span>;</span><span></span></p><p><span>  </span><span>return</span><span> </span><span>increment</span><span>(</span><span>increment</span><span>(</span><span>increment</span><span>(</span><span>initialValue</span><span>)</span><span>)</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>function</span><span> </span><span>runWithLog</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> initialValue </span><span>=</span><span> </span><span>0</span><span>;</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>[</span><span>result1</span><span>,</span><span> log1</span><span>]</span><span> </span><span>=</span><span> </span><span>incrementWithLog</span><span>(</span><span>initialValue</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>[</span><span>result2</span><span>,</span><span> log2</span><span>]</span><span> </span><span>=</span><span> </span><span>incrementWithLog</span><span>(</span><span>result1</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>[</span><span>result3</span><span>,</span><span> log3</span><span>]</span><span> </span><span>=</span><span> </span><span>incrementWithLog</span><span>(</span><span>result2</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>return</span><span> </span><span>[</span><span>result3</span><span>,</span><span> log1 </span><span>+</span><span> log2 </span><span>+</span><span> log3</span><span>]</span><span>;</span><span></span></p><p><span></span><span>}</span></p></pre><p>This is okay but there's extra work dealing with the log message. We need to destructure each return value. We can't chain calls nicely like we can with <code>increment</code>. Can we make <code>WithLog</code> easier to work with?</p><p>Let's introduce a couple new functions. The first is <code>wrap</code>, which takes a plain old value and puts it in our context with an empty log (represented by an empty string <code>''</code>).</p><pre><p><span>type</span><span> </span><span>WithLog</span><span>&lt;</span><span>T</span><span>&gt;</span><span> </span><span>=</span><span> </span><span>[</span><span>T</span><span>,</span><span> </span><span>string</span><span>]</span><span>;</span><span></span></p><p><span></span><span>function</span><span> wrap</span><span>&lt;</span><span>T</span><span>&gt;</span><span>(</span><span>value</span><span>:</span><span> </span><span>T</span><span>)</span><span>:</span><span> </span><span>WithLog</span><span>&lt;</span><span>T</span><span>&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>return</span><span> </span><span>[</span><span>value</span><span>,</span><span> </span><span>''</span><span>]</span><span>;</span><span></span></p><p><span></span><span>}</span></p></pre><p>Our second function <code>bind</code> is more complicated. It takes two arguments, a  <code>WithLog&lt;T&gt;</code> value and a function with type <code>T =&gt; WithLog&lt;T&gt;</code>.</p><pre><p><span></span><span>function</span><span> bind</span><span>&lt;</span><span>T</span><span>&gt;</span><span>(</span><span></span></p><p><span>  valueWithLog</span><span>:</span><span> </span><span>WithLog</span><span>&lt;</span><span>T</span><span>&gt;</span><span>,</span><span></span></p><p><span>  </span><span>f</span><span>:</span><span> </span><span>T</span><span> </span><span>=&gt;</span><span> </span><span>WithLog</span><span>&lt;</span><span>T</span><span>&gt;</span><span></span></p><p><span></span><span>)</span><span>:</span><span> </span><span>WithLog</span><span>&lt;</span><span>T</span><span>&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>[</span><span>value</span><span>,</span><span> existingLog</span><span>]</span><span> </span><span>=</span><span> valueWithLog</span><span>;</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>[</span><span>newValue</span><span>,</span><span> newLog</span><span>]</span><span> </span><span>=</span><span> </span><span>f</span><span>(</span><span>value</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>return</span><span> </span><span>[</span><span>newValue</span><span>,</span><span> existingLog </span><span>+</span><span> newLog</span><span>]</span><span>;</span><span></span></p><p><span></span><span>}</span></p></pre><p>It calls the given function with the value inside the existing context. It then concats the log strings together to form the new log. You can think of it as appending the new log message onto existing logs.</p><div><p>Exercise</p><p>Now it's your turn. Open this exercise and try implementing <code>runWithLog</code> using both <code>wrap</code> and <code>bind</code>.</p></div><p>View the solution. <code>runWithLog2</code> looks a lot like our original <code>run</code> with just <code>increment</code>! There isn't any code dealing with the log messages. <code>wrap</code> and <code>bind</code> take care of that for us. <strong>We don't even have to know how <code>WithLog</code> is implemented.</strong> We know it's a tuple from above but that can change without affecting our implementation of <code>runWithLog</code>.</p><h2 id="quick-recap"><a href="#quick-recap" aria-label="quick recap permalink"></a>Quick recap</h2><p>We just made our own <code>WithLog</code> monad! We haven't formalized any of this yet but I hope you have an idea of what monads <em>feel like</em>.</p><p>We have a context type <code>WithLog&lt;T&gt;</code> used to represent a value with a log message. We also defined two functions for working with <code>WithLog</code>. <code>wrap</code> puts a value in the <code>WithLog</code> context. <code>bind</code> applies a function <code>T =&gt; WithLog&lt;T&gt;</code> to a context value <code>WithLog&lt;T&gt;</code> to get another context value <code>WithLog&lt;T&gt;</code>.</p><h2 id="why-learn-monads"><a href="#why-learn-monads" aria-label="why learn monads permalink"></a>Why learn monads?</h2><p>For JavaScript developers, I don't think monads are that useful and are definitely not necessary to understand. However, ideas from functional programming are what inspired frameworks like React. Learning monads and alike gets you comfortable thinking about types at a higher level.</p><h3 id="haskell"><a href="#haskell" aria-label="haskell permalink"></a>Haskell</h3><p><strong>TL;DR</strong> Any real Haskell program requires the use of monads.</p><p>Monads are usually associated with Haskell because they form the building blocks for writing programs. In the example above, we pretended that we couldn't have side effects inside functions. <em>This is actually true in Haskell!</em> You can't just add <code>console.log</code> inside your function.</p><p>The core Haskell programming language doesn't have many "features" that you take for granted in other languages. In JavaScript, you can put side effects anywhere. In JavaScript, global and module state is easy.</p><p>In most functional programming languages, you don't have imperative statements like you do in most popular programming languages. Instead, everything is an expression. In Haskell, the <code>IO</code> monad gives programmers the ability to sequence effectful actions. For example, <code>putStr</code> (the <code>console.log</code> equivalent) has type <code>string =&gt; IO&lt;void&gt;</code>.</p><p>Again, this is not a Haskell tutorial but the high-level picture is that combining monads allows Haskell programmers to add "features" to their programming environment. Our <code>WithLog</code> monad adds the feature of logging strings. We'll see how the <code>Maybe</code> monad below adds the feature of failure. People describe monads as "computational context". <strong>Haskell programmers get to (have to?) pick and choose what programming features to use.</strong></p><h3 id="notes"><a href="#notes" aria-label="notes permalink"></a>Notes</h3><p>In Haskell, our <code>wrap</code> function is called <code>return</code>. It's extremely confusing hence why I use <code>wrap</code> in this article. Just know that this is not the real name.</p><p>The function (second arg) given to <code>bind</code> can return a context value of another type parameter. <code>bind</code> has type <code>(M&lt;T&gt;, T =&gt; M&lt;U&gt;) =&gt; M&lt;U&gt;</code>. I restricted <code>U = T</code> in the <code>bind</code> example above to reduce the number of type variables. For example, we can do the following.</p><pre><p><span>function</span><span> </span><span>isEvenWithLog</span><span>(</span><span>x</span><span>:</span><span> number</span><span>)</span><span>:</span><span> </span><span>WithLog</span><span>&lt;</span><span>boolean</span><span>&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>return</span><span> </span><span>[</span><span>x </span><span>%</span><span> </span><span>2</span><span> </span><span>===</span><span> </span><span>0</span><span>,</span><span> </span><span>'called isEven\n'</span><span>]</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>function</span><span> </span><span>runWithLog</span><span>(</span><span>x</span><span>:</span><span> number</span><span>)</span><span>:</span><span> </span><span>WithLog</span><span>&lt;</span><span>boolean</span><span>&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>return</span><span> </span><span>bind</span><span>(</span><span>bind</span><span>(</span><span>wrap</span><span>(</span><span>x</span><span>)</span><span>,</span><span> incrementWithLog</span><span>)</span><span>,</span><span> isEvenWithLog</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span></p></pre><p>If you wanted to stop here, I don't blame you. Thanks for sticking this far! The rest of the article defines monads more precisely and gives you more context to understand monads.</p><p>Now that we have interacted with monads, let's define them more precisely. Monad is a type class that is defined in Haskell as the following.</p><pre><p><span>class Applicative m =&gt; Monad m where</span></p><p><span>  return :: a -&gt; m a</span></p><p><span>  (&gt;&gt;=)  :: m a -&gt; (a -&gt; m b) -&gt; m b</span></p></pre><p><strong><em>Huh?</em></strong> This isn't a tutorial on Haskell; we want to learn as little Haskell as we need to understand monads. I'll break down the relevant pieces.</p><p>Monad is a type class with kind <code>* -&gt; *</code>. <strong><em>Damnit paul</em></strong></p><p>The approximate English translation: <strong>Monad is a generic type with one type parameter. It also has two associated functions, <code>return</code> and <code>bind</code>.</strong></p><p>If you're familiar with a type system like TypeScript, monads roughly look like <code>M&lt;A&gt;</code> where <code>M</code> is the monad. For example, <code>Array&lt;T&gt;</code> has the structure to be a potential monad.</p><p>Let's translate the Haskell definition above into pseudo TypeScript. I've replaced <code>return</code> with <code>wrap</code> because <code>return</code> is a restricted JavaScript keyword (and extremely confusing). The <code>&gt;&gt;=</code> symbol is <code>bind</code>.</p><pre><p><span>interface</span><span> </span><span>MonadImplementation</span><span>&lt;</span><span>M</span><span>&lt;</span><span>_</span><span>&gt;</span><span>&gt;</span><span> </span><span>{</span><span></span></p><p><span>  wrap</span><span>:</span><span> </span><span>&lt;</span><span>A</span><span>&gt;</span><span>(</span><span>A</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>M</span><span>&lt;</span><span>A</span><span>&gt;</span><span>,</span><span></span></p><p><span>  bind</span><span>:</span><span> </span><span>&lt;</span><span>A</span><span>,</span><span> </span><span>B</span><span>&gt;</span><span>(</span><span>M</span><span>&lt;</span><span>A</span><span>&gt;</span><span>,</span><span> </span><span>A</span><span> </span><span>=&gt;</span><span> </span><span>M</span><span>&lt;</span><span>B</span><span>&gt;</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>M</span><span>&lt;</span><span>B</span><span>&gt;</span><span>,</span><span></span></p><p><span></span><span>}</span></p></pre><p>Let's revisit our <code>WithLog</code> context. Here, we plug in our implementation for <code>wrap</code> and <code>bind</code>.</p><pre><p><span>type</span><span> </span><span>WithLog</span><span>&lt;</span><span>T</span><span>&gt;</span><span> </span><span>=</span><span> </span><span>[</span><span>T</span><span>,</span><span> </span><span>string</span><span>]</span><span>;</span><span></span></p><p><span></span><span>const</span><span> </span><span>WithLogMonadImplementation</span><span>:</span><span> </span><span>MonadImplementation</span><span>&lt;</span><span>WithLog</span><span>&gt;</span><span> </span><span>=</span><span> </span><span>{</span><span></span></p><p><span>  wrap</span><span>:</span><span> </span><span>&lt;</span><span>A</span><span>&gt;</span><span>(</span><span>x</span><span>:</span><span> </span><span>A</span><span>)</span><span>:</span><span> </span><span>WithLog</span><span>&lt;</span><span>A</span><span>&gt;</span><span> </span><span>=&gt;</span><span> </span><span>[</span><span>x</span><span>,</span><span> </span><span>''</span><span>]</span><span>,</span><span></span></p><p><span>  bind</span><span>:</span><span> </span><span>&lt;</span><span>A</span><span>,</span><span> </span><span>B</span><span>&gt;</span><span>(</span><span>m</span><span>:</span><span> </span><span>WithLog</span><span>&lt;</span><span>A</span><span>&gt;</span><span>,</span><span> </span><span>f</span><span>:</span><span> </span><span>A</span><span> </span><span>=&gt;</span><span> </span><span>WithLog</span><span>&lt;</span><span>B</span><span>&gt;</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>const</span><span> </span><span>[</span><span>value</span><span>,</span><span> log</span><span>]</span><span> </span><span>=</span><span> m</span><span>;</span><span></span></p><p><span>    </span><span>const</span><span> </span><span>[</span><span>newValue</span><span>,</span><span> newLog</span><span>]</span><span> </span><span>=</span><span> </span><span>f</span><span>(</span><span>value</span><span>)</span><span>;</span><span></span></p><p><span>    </span><span>return</span><span> </span><span>[</span><span>newValue</span><span>,</span><span> log </span><span>+</span><span> newLog</span><span>]</span><span>;</span><span></span></p><p><span>  </span><span>}</span><span>,</span><span></span></p><p><span></span><span>}</span><span>;</span></p></pre><p>This is the JavaScript implementation of our <code>WithLog</code> monad!</p><h2 id="maybe-monad"><a href="#maybe-monad" aria-label="maybe monad permalink"></a>Maybe Monad</h2><p>The best way to understand monads is to implement one (or a couple). Let's try implementing the <code>Maybe</code> monad.</p><pre><p><span>type</span><span> </span><span>Maybe</span><span>&lt;</span><span>T</span><span>&gt;</span><span> </span><span>=</span><span> </span><span>{</span><span> value</span><span>:</span><span> </span><span>T</span><span> </span><span>}</span><span> </span><span>|</span><span> undefined</span><span>;</span></p></pre><p>This is a generic type representing potential failure. For example, <code>Maybe&lt;number&gt;</code> could either be a <code>{ value: number }</code> or <code>undefined</code> (failure!). <a href="#">Why don't we just use <code>T | undefined</code>?</a></p><div><p>Exercise</p><p>Try implementing <code>wrap</code> and <code>bind</code> for <code>Maybe</code>.</p></div><p><code>wrap</code> is straightforward; it puts the given value into the <code>Maybe</code> context. If the given value to <code>bind</code> is <code>undefined</code> (failure), we just continue failing by returning <code>undefined</code>. Otherwise, we call the given function, which will return us another <code>Maybe</code> value. Note that calling function <code>f</code> might "fail" and return an <code>undefined</code>.</p><p>If you have a sequence of computations and any of them fails, we want the whole sequence to fail. Here's an example.</p><pre><p><span>function</span><span> </span><span>parseColorHex</span><span>(</span><span>color</span><span>:</span><span> string</span><span>)</span><span>:</span><span> </span><span>Maybe</span><span>&lt;</span><span>number</span><span>&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>switch</span><span> </span><span>(</span><span>color</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>case</span><span> </span><span>'red'</span><span>:</span><span></span></p><p><span>      </span><span>return</span><span> </span><span>{</span><span> value</span><span>:</span><span> </span><span>0xff0000</span><span> </span><span>}</span><span>;</span><span></span></p><p><span>    </span><span>case</span><span> </span><span>'green'</span><span>:</span><span></span></p><p><span>      </span><span>return</span><span> </span><span>{</span><span> value</span><span>:</span><span> </span><span>0x00ff00</span><span> </span><span>}</span><span>;</span><span></span></p><p><span>    </span><span>case</span><span> </span><span>'blue'</span><span>:</span><span></span></p><p><span>      </span><span>return</span><span> </span><span>{</span><span> value</span><span>:</span><span> </span><span>0x0000ff</span><span> </span><span>}</span><span>;</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span>  </span><span>return</span><span> undefined</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>function</span><span> </span><span>getProfileColor</span><span>(</span><span>user</span><span>:</span><span> User</span><span>)</span><span>:</span><span> </span><span>Maybe</span><span>&lt;</span><span>string</span><span>&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> profile </span><span>=</span><span> profiles</span><span>[</span><span>user</span><span>.</span><span>profileId</span><span>]</span><span>;</span><span></span></p><p><span>  </span><span>if</span><span> </span><span>(</span><span>profile </span><span>===</span><span> undefined</span><span>)</span><span> </span><span>return</span><span> undefined</span><span>;</span><span></span></p><p><span>  </span><span>return</span><span> </span><span>{</span><span> value</span><span>:</span><span> profile</span><span>.</span><span>color </span><span>}</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>function</span><span> </span><span>getUser</span><span>(</span><span>userId</span><span>:</span><span> string</span><span>)</span><span>:</span><span> </span><span>Maybe</span><span>&lt;</span><span>User</span><span>&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> user </span><span>=</span><span> users</span><span>[</span><span>userId</span><span>]</span><span>;</span><span></span></p><p><span>  </span><span>if</span><span> </span><span>(</span><span>user </span><span>===</span><span> undefined</span><span>)</span><span> </span><span>return</span><span> undefined</span><span>;</span><span></span></p><p><span>  </span><span>return</span><span> </span><span>{</span><span> value</span><span>:</span><span> user </span><span>}</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>function</span><span> </span><span>main</span><span>(</span><span>userId</span><span>:</span><span> string</span><span>)</span><span>:</span><span> </span><span>Maybe</span><span>&lt;</span><span>number</span><span>&gt;</span><span>  </span><span>{</span><span></span></p><p><span>  </span><span>return</span><span> </span><span>bind</span><span>(</span><span>bind</span><span>(</span><span>bind</span><span>(</span><span>wrap</span><span>(</span><span>userId</span><span>)</span><span>,</span><span> getUser</span><span>)</span><span>,</span><span> getProfileColor</span><span>)</span><span>,</span><span> parseColorHex</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span></p></pre><p>We're sequencing three functions here: <code>getUser</code>, <code>getProfileColor</code> and <code>parseColorHex</code>. If anything fails (returns <code>undefined</code>), the entire sequence will fail (return <code>undefined</code>). Note that if we don't fail, we will end with a <code>{value: answer}</code> instead of <code>{value: {value: {value: answer}}}</code>.</p><p>The idea of <code>fmap</code> is more common function in JavaScript. I'm going to skip some Haskell details but let's meditate on the following function.</p><pre><p><span>fmap</span><span>:</span><span> </span><span>(</span><span>m</span><span>:</span><span> </span><span>M</span><span>&lt;</span><span>A</span><span>&gt;</span><span>,</span><span> </span><span>f</span><span>:</span><span> </span><span>A</span><span> </span><span>=&gt;</span><span> </span><span>B</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>M</span><span>&lt;</span><span>B</span><span>&gt;</span><span></span></p><p><span>arrayMap</span><span>:</span><span> </span><span>(</span><span>arr</span><span>:</span><span> </span><span>Array</span><span>&lt;</span><span>A</span><span>&gt;</span><span>,</span><span> </span><span>f</span><span>:</span><span> </span><span>A</span><span> </span><span>=&gt;</span><span> </span><span>B</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>Array</span><span>&lt;</span><span>B</span><span>&gt;</span></p></pre><p><code>fmap</code> applies a function to values inside a context value. The most common example is mapping over an array.</p><p>Here's <code>fmap</code> for <code>Maybe</code>. I'm putting it side-by-side with <code>bind</code>.</p><div><pre><p><span>function</span><span> fmap</span><span>&lt;</span><span>A</span><span>&gt;</span><span>(</span><span>m</span><span>:</span><span> </span><span>Maybe</span><span>&lt;</span><span>A</span><span>&gt;</span><span>,</span><span> </span><span>f</span><span>:</span><span> </span><span>A</span><span> </span><span>=&gt;</span><span> </span><span>B</span><span>)</span><span>:</span><span> </span><span>Maybe</span><span>&lt;</span><span>B</span><span>&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>if</span><span> </span><span>(</span><span>m </span><span>===</span><span> undefined</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    </span>…</p></pre></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bypaulshen.com/posts/monads-for-javascript-developers/">https://bypaulshen.com/posts/monads-for-javascript-developers/</a></em></p>]]>
            </description>
            <link>https://bypaulshen.com/posts/monads-for-javascript-developers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24434782</guid>
            <pubDate>Thu, 10 Sep 2020 17:52:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Caddy and CertMagic have new ownership; no changes to licensing or development]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24434770">thread link</a>) | @theBashShell
<br/>
September 10, 2020 | https://caddy.community/t/caddy-and-certmagic-have-new-ownership-no-changes-to-licensing-or-development/9754?u=matt | <a href="https://web.archive.org/web/*/https://caddy.community/t/caddy-and-certmagic-have-new-ownership-no-changes-to-licensing-or-development/9754?u=matt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
          <p>I have some great news that I’ve been meaning to share for a while: the Caddy project is now owned by <a href="https://apilayer.com/">apilayer</a>. This allows me to continue working on Caddy full-time, <strong>without any changes to <a href="https://github.com/caddyserver/caddy/issues/2786">the current open source licensing</a>.</strong></p>
<p>This was a very personal decision for me, which came only after lots of careful consideration and discussion with both apilayer and Ardan Labs. We’re excited for this, and I hope you will be too.</p>
<p>In this post I’ll elaborate on my perspective and explain some of the details best I can, but I don’t speak for apilayer or Ardan Labs. You can read <a href="https://www.ardanlabs.com/news/2020/08/caddy-server-is-acquired/">Ardan Labs’ press release here</a>.</p>

<p>(I’ll try to keep this post updated as I see comments or questions.)</p>
<ul>
<li>
<p>Caddy is now an <a href="https://apilayer.com/">apilayer</a> open source product. They also have rights to the trademark.</p>
</li>
<li>
<p><strong>This does not change Caddy licensing or distribution in any way. Caddy has always been and still is Apache 2.0 open source licensed, just like thousands of other FOSS projects.</strong></p>
</li>
<li>
<p>This actually happened about six months ago. We’ve just been too busy to announce it! <img src="https://caddy.community/images/emoji/apple/sweat_smile.png?v=9" title=":sweat_smile:" alt=":sweat_smile:"> Between the pandemic, more client work from project growth, and other unexpected life things, it’s been a whirlwind year! But in these six months, we’ve released Caddy 2.0, 2.1, and are soon releasing 2.2, along with updated website features and docs. We’ve already been operating with the new ownership for over half a year now.</p>
</li>
<li>
<p>The ownership change includes <a href="https://github.com/caddyserver/certmagic">CertMagic</a>, which was moved into the <code>caddyserver</code> organization on GitHub when the change occurred six months ago.</p>
</li>
<li>
<p>Everything else about the project continues as normal. There are no user- or community-facing changes.</p>
</li>
<li>
<p>I continue to work on Caddy full-time. This would not be possible without apilayer, Ardan Labs, and all other sponsors (thank you)!</p>
</li>
<li>
<p>Ardan Labs is still the exclusive support contractor for the Caddy project. Businesses are encouraged to get a support plan or contract Caddy-related development through Ardan Labs, with whom I consult.</p>
</li>
<li>
<p>Several members of our community continue to act as maintainers and packagers, just as before. Thank you to them for their dedicated involvement!</p>
</li>
</ul>

<p>After the Caddy project grew more than I could handle in ~2016, I applied for an award from Mozilla for developing software that helps advance privacy and security on the Internet, which amazingly was granted and allowed me to work on Caddy full-time for about 6 months.</p>
<p>For longer-term sustainability, I later moved to monetize its commercial user base with both professional services and a unique licensing plan for custom-made binaries distributed through the Caddy website. Mistakes were made (both by myself and a vocal minority of the user base – or at least some armchair observers) and that model didn’t achieve the sustainability I had hoped for. Not many people know this, but the project actually came close to shutting down after that because I was starting grad school and couldn’t handle its growth together with my research and studies without some sustainability to front it.</p>
<p>After consulting with some trusted friends, mentors/colleagues, and professors, I decided not to pull the plug and instead applied Caddy to academic research through some projects in grad school, such as embedding CT monitors into web servers. Another one of these was telemetry, which allowed us to observe the conditions of clients on the Internet – including the first wide-spread production server-side measurements of MITM attacks – without being confined to proprietary networks. Contrary to popular belief (sigh), it didn’t collect any personal information or IP addresses; just benign technical data that was in plaintext on the wire or basic counts of things like which features of the server were used most often. Unfortunately this was also not well-received (and was expensive), despite other software such as Windows, Firefox, Chrome, VS Code, and many other programs that continue to implement much more aggressive and detailed telemetry, and I was more or less forced to shut it down a year or two later after counting trillions of connections.</p>
<p>From its various research applications, we learned that automatic CT monitoring can be a valuable asset (one even worth paying for) and that MITM is more widespread on the Internet than you’d think. (Cloudflare later deployed <a href="https://blog.cloudflare.com/monsters-in-the-middleboxes/">a similar MITM measurement</a> at a larger scale of course, but it is limited to their proprietary network. And nobody complained about this like they did with Caddy, but <a href="https://malcolm.cloudflare.com/">the MALCOM dashboard doesn’t load for me anymore</a> for some reason. Is Cloudflare starting to develop Google-like habits?)</p>
<p>After completing my graduate degree last year, I approached several companies to see if they’d be interested in hiring me to work on Caddy full-time, to the mutual benefit of them and many of their customers who use and rely on it. If I couldn’t find one, I’d have to take a likely-unrelated position and Caddy would have to take the back-seat. Fortunately, more than one company was interested! I accepted an offer with Ardan Labs and under their auspices built Caddy 2.</p>
<p>I’m pleased to say that Caddy 2.0 was designed and developed right on schedule: in just about 12 months we went from design drafts to prototypes to betas to final release. It’s amazing what providing for one full-time developer can accomplish! I am thankful to Ardan Labs for that opportunity.</p>
<p>Near the end of the Caddy 2 development cycle, we received an offer from apilayer that worked to our mutual advantage. All three parties came to agreeable terms and the Caddy project is well on our way to continued development and growth. I have at least a two year contract with apilayer to work on Caddy full-time!</p>
<p>During the negotiations I made it very clear that open source is crucial to Caddy’s success, and I was relieved that Julian (apilayer) balked at the possibility of making it anything but open source. <img src="https://caddy.community/images/emoji/apple/slight_smile.png?v=9" title=":slight_smile:" alt=":slight_smile:"> It was very clear that keeping Caddy open source is a core value for all of us.</p>

<p>Ardan Labs continues to be the trusted partner to support businesses using Caddy. We recommend that all businesses using Caddy <a href="https://caddyserver.com/business">get a support plan</a> so that they can become familiar with your deployments and offer assistance if needed. There are also options for custom development contracts.</p>

<p>It’s clear to me that sponsorships are probably the best way to ensure the sustainability of the project in the long run, rather than fiddling with licensing or taking on enterprise support by myself (Ardan Labs is our partner for enterprise clients).</p>
<p>I continue to rely on sponsorships for ongoing full-time development of Caddy, with apilayer being the premier corporate sponsor. I am able to prioritize features and bug fixes for sponsors, as well as extending a special invite to our Slack community for Caddy developers/maintainers. Right now, sponsors also get exclusive <a href="https://github.com/mholt/conncept">early access to Project Conncept</a>, a layer 4 (TCP/UDP) app for Caddy! When we reach 50 sponsors, I’ll be able to make it public!</p>
<p>I’ll be enhancing sponorship perks later this year as well, so stay tuned for more on that.</p>
<p><strong>You can sponsor me through GitHub: <a href="https://github.com/sponsors/mholt">https://github.com/sponsors/mholt</a></strong></p>
<p>If you aren’t able to sponsor right now, that’s okay: the next best thing you can do to help the project is to use Caddy and help others to use it, too. <a href="https://caddy.community/">Join our community</a> and help answer people’s questions! You can also share the project so more people know about it. If you’re experienced with Go, we’re always looking for committed maintainers to the code base; or if you’re good at websites, we could use help to improve ours! Similarly, we need help with packaging, distribution, and several other side projects. There’s a lot to be done! The project wouldn’t be where it is without the assistance of the community.</p>
<p>Thank you for your support, and for using Caddy! As we continue to work on it together, I hope it serves you well for many years to come.</p>
        </div></div>]]>
            </description>
            <link>https://caddy.community/t/caddy-and-certmagic-have-new-ownership-no-changes-to-licensing-or-development/9754?u=matt</link>
            <guid isPermaLink="false">hacker-news-small-sites-24434770</guid>
            <pubDate>Thu, 10 Sep 2020 17:50:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Performance Benchmarking Egress Filtering on Linux (iptables, ebpf, ipset)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24434697">thread link</a>) | @blixtra
<br/>
September 10, 2020 | https://kinvolk.io/blog/2020/09/performance-benchmark-analysis-of-egress-filtering-on-linux/ | <a href="https://web.archive.org/web/*/https://kinvolk.io/blog/2020/09/performance-benchmark-analysis-of-egress-filtering-on-linux/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Traffic filtering is a common technique used to protect networks and hosts from malicious activity. The filtering can be done in the incoming and outgoing flows, better known as ingress and egress filtering. There are many examples of use cases for ingress filtering: mitigating DDoS attacks, avoiding SPAM, blocking access to services for specific geographic regions and so on.</p>
<p>One common application of egress filtering is to prevent applications and users from reaching remote hosts.
These kinds of filters are usually based on a large deny-list of IP address ranges, like <a href="https://www.icann.org/news/blog/reputation-block-lists-protecting-users-everywhere">Reputation Block Lists</a>. The technology used to perform this task has to be able to handle a high number of restricted hosts, up to millions in some cases.</p>
<p>Our friends at SAP asked us to perform a benchmark of the common Linux technologies available for this task. This blog post presents the methodology and results from benchmarking some of the Linux filtering technologies: eBPF, IP sets and iptables.</p>
<h2 id="goals">Goals</h2>
<p>We had the following goals going into this study:</p>
<ul>
<li>Provide a reproducible benchmark framework that anyone else can download and use.</li>
<li>Evaluate the different mechanisms in the Linux networking stack to filter out a large amount of IP addresses and assess their scalability when the amount of IP ranges to block reaches 1 million.</li>
</ul>
<h2 id="scenario">Scenario</h2>
<p>We aim to understand the cost of performing egress filtering based on the destination IP in a large set of IP ranges.</p>
<p>The scenario we consider is composed of a client and a server computer that communicate through an IP network. The egress filtering is performed on the client machine and there is no filtering performed on the server side.</p>
<figure>
	<img src="https://kinvolk.io/media/2020-09-10-egress-filtering-testing/scenario.svg">
</figure>
<h2 id="metrics">Metrics</h2>
<p>An egress filter has to perform a matching operation to understand if a packet can continue its way or has to be dropped. This operation could be costly if the number of blocked IPs is high. This kind of filter impacts the throughput of IP connections, it consumes extra CPU and increases the latency. We decided to take into consideration these metrics under the following conditions.</p>
<ul>
<li>Throughput</li>
<li>CPU usage</li>
<li>Latency</li>
</ul>
<h2 id="linux-filtering-mechanisms">Linux Filtering Mechanisms</h2>
<p>The Linux kernel provides different mechanisms to filter network packets. In this benchmark we considered the most known ones. iptables is the historical and probably more known filtering utility in Linux. IP sets support high speed matching for sets of specific types, like IP ranges for instance. eBPF is very flexible and customizable. The following section provides more details of how we used those mechanisms in our benchmark.</p>
<h3 id="ebpf">eBPF</h3>
<p>eBPF is a virtual machine built in the Linux kernel. In the networking scope, it allows the user to load programs that are executed each time a packet arrives or is sent out of a networking interface. Those eBPF programs can modify, redirect or drop the packets.</p>
<p>There are different types of networking eBPF programs, CGROUP_SKB for per-cgroup filtering, SCHED_CLS and SCHED_ACT for filtering at the traffic control level, and XDP for filtering at the network interface level.</p>
<figure>
	<img src="https://kinvolk.io/media/2020-09-10-egress-filtering-testing/ebpf.svg">
</figure>
<p>In our scenario, we want to apply the same filtering regardless of the cgroup of the application generating the traffic. The traffic coming from non-local applications or forwarded traffic should be filtered as well. This makes filtering at the socket level unfit for our scenario. XDP programs can only be attached to the ingress<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> path, removing it from consideration in our tests also. By process of elimination, we only consider eBPF programs attached to the traffic control layer.</p>
<p>Given that we want to keep the tests as simple as possible we decided to implement <a href="https://github.com/kinvolk/egress-filtering-benchmark/blob/master/pkg/filters/bpf/datapath/bpf.c">our own</a>filtering program in eBPF that will be attached to the traffic control layer with a clsact qdisc. The clsact qdisc was introduced in Linux 4.5, it’s a pseudo qdisc that allows to attach eBPF programs in ingress and egress using the <a href="https://qmonnet.github.io/whirl-offload/2020/04/11/tc-bpf-direct-action/">direct-action</a> mode.</p>
<p>Our filter implementation uses an <a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=b95a5c4db09bc7c253636cb84dc9b12c577fd5a0">LPM map</a> to save the list of IP addresses to block. eBPF implements the <a href="https://en.wikipedia.org/wiki/Longest_prefix_match">LPM</a> algorithm with a <a href="https://en.wikipedia.org/wiki/Trie">digital tree</a>.</p>
<figure>
	<img src="https://kinvolk.io/media/2020-09-10-egress-filtering-testing/ebpflookup.svg">
</figure>
<h3 id="iptables">iptables</h3>
<p>We tested the standard iptables implementation by adding DROP rules to the OUTPUT chain in the filter table. The rules we used have the following format</p>
<p><code>-A OUTPUT -d 192.168.0.0/16 -o eth0 -m comment --comment "benchmark" -j DROP</code></p>
<p>While implementing this filter we found that appending each rule independently was too slow and we had to use the <code>iptables-restore</code> utility to do it.</p>
<p>iptables uses a linear search algorithm for rule matching.</p>
<figure>
	<img src="https://kinvolk.io/media/2020-09-10-egress-filtering-testing/iptableslookup.svg">
</figure>
<h3 id="ip-sets">IP Sets</h3>
<p>We performed the testing also with the <a href="https://ipset.netfilter.org/">IP sets</a> framework. We used an IP set of type <a href="https://ipset.netfilter.org/ipset.man.html#lbAZ"><code>hash:net</code></a> and linked it to iptables by using the following rule:</p>
<p><code>-A OUTPUT -o eth0 -m set --match-set myset dst -m comment --comment benchmark -j DROP</code>.</p>
<p>The IP address to check is hashed and the result of the hash is used as the index in a hash table. Each bucket of the hash table contains an array of networks for that hash. When an IP address is checked against an IP set of type “hash:net”, it is not known what network size will match. The IP set implementation hashes the IP address for all possible network sizes. For instance, if the IP to match is 1.2.3.4, it looks for 1.2.3.4/32, for 1.2.3.4/31 and so on until all the 32 possible network sizes have been tested.</p>
<figure>
	<img src="https://kinvolk.io/media/2020-09-10-egress-filtering-testing/ipsetslookup.svg">
</figure>
<h2 id="benchmark-set-up">Benchmark Set-up</h2>
<p>We used <code>iperf3</code> to measure the performance of TCP, UDP and the CPU usage. The standard <code>ping</code> utility was used to measure the latency. We tested with 10, 100, 1k, 10k, 100k and 1M rules and each test was run 5 times to get statistical robustness.</p>
<p>We used two bare metal servers - running on <a href="https://www.packet.com/">Packet</a> - as client and server machines. The specifications of such servers are:</p>
<div><pre><code data-lang="fallback">c2.medium.x86
1x AMD EPYC 7401P 24-Core Processor @ 2.0GHz
2x 120GB SSD
2x 480GB SSD
64GB RAM
2x 10Gbps
</code></pre></div><p>The exact versions of the tools we used are:</p>
<ul>
<li><a href="https://www.flatcar-linux.org/">Flatcar Container Linux</a> by Kinvolk alpha (<a href="https://www.flatcar-linux.org/releases/#release-2605.0.0">2605.0.0</a>)</li>
<li>Linux kernel 5.4.59</li>
<li>iperf 3.0.7 (in a Docker container with the host network)</li>
<li>iptables v1.6.2</li>
<li>ipset v6.20.1, protocol version: 6</li>
</ul>
<h2 id="reproducibility">Reproducibility</h2>
<p><a href="https://github.com/kinvolk/k8s-egress-filtering-benchmark">https://github.com/kinvolk/egress-filtering-benchmark</a> has all the tools and instructions to reproduce these tests.</p>
<h2 id="results">Results</h2>
<h3 id="test-1---tcp-throughput">Test #1 - TCP Throughput</h3>
<figure>
	<img src="https://kinvolk.io/media/2020-09-10-egress-filtering-testing/throughput-tcp-linerate.svg">
</figure>
<p>The throughput graph shows that the test is reaching line rate, 10Gbps because we are using a single connection hence only one of the interfaces on the bonding is used in most of the cases. Only iptables with more than 10k rules is not able to handle that performance. From this test we can conclude that iptables doesn’t scale well after 100k, but unfortunately we cannot conclude anything from other tests as network performance is the bottleneck.</p>
<p>In order to stress the CPU more, we performed another test using UDP.</p>
<h3 id="test-2---udp-throughput">Test #2 - UDP Throughput</h3>
<figure>
	<img src="https://kinvolk.io/media/2020-09-10-egress-filtering-testing/throughput-udp.svg">
</figure>
<p>The goal of this test is to saturate the CPU. We used UDP packets and the <code> -b 10G</code> parameter to try to reach line rate. The graph shows that none of the cases reaches the 10Gbps line rate, it’s good for this test because it means the network is not the bottleneck anymore.</p>
<p>We can see that iptables does not scale well beyond 1k rules and that IP sets are a bit faster than eBPF on the clsact qdisc with a high number of rules.</p>
<h3 id="test-3---cpu-usage">Test #3 - CPU usage</h3>
<figure>
	<img src="https://kinvolk.io/media/2020-09-10-egress-filtering-testing/cpu.svg">
</figure>
<p>We used <code>iperf</code> with a target bandwidth of 1Gbps (<code>-b 1G</code>) to avoid saturating the CPU and be able to compare the CPU usage with the different filters. We take the CPU usage reported by <code>iperf</code> that includes all the applications running on the host. From the above graph we can see that the CPU usage with iptables increases when using more than 1k rules. The CPU usage with eBPF and IP sets filters stays almost constant showing a bit higher usage in the eBPF case.</p>
<h3 id="test-4---latency">Test #4 - Latency</h3>
<figure>
	<img src="https://kinvolk.io/media/2020-09-10-egress-filtering-testing/latency.svg">
</figure>
<p>We used the standard Linux ping utility to measure the latency with the <code>-i 0.001</code> and <code>-c 1000</code> parameters, sending 1000 pings at a 1 millisecond interval. The above graph shows that the latency is not affected by the number of rules in the eBPF and IP sets filters, it’s ~27µs in those cases. On the other hand, it increases linearly with the number of rules for the iptables case.</p>
<h3 id="test-5---setup-time">Test #5 - Setup Time</h3>
<p>This test aims to measure the time it takes to install the filtering rules on the system. It doesn’t take into consideration fixed times like loading the eBPF program, creating the IP sets but instead focuses on measuring the time it takes to update the rules themselves and how it changes with the number of rules.</p>
<figure>
	<img src="https://kinvolk.io/media/2020-09-10-egress-filtering-testing/setup.svg">
</figure>
<p>The above graph shows that the time required to set up the rules in all the filters increases linearly with the number of rules.</p>
<p>With 100.000 IPs, the setup time is still less than one second. For 1 million IPs, the setup time is less than 10 seconds. This shows that in practice, all 3 methods have an acceptable setup time.</p>
<p>The setup time is very dependent on the benchmark implementation rather than being inherent to the filtering method. Each filtering method could be optimised in the benchmark code if it were deemed necessary.</p>
<ul>
<li>For the bpf filter: the benchmark performs one bpf() system call for every IP. From Linux 5.6, it is possible to <a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=aa2e93b8e58e18442edfb2427446732415bc215e">perform several updates in a eBPF map with a single bpf() call</a>.</li>
<li>For the iptables and IP sets filters, the benchmark executes external commands and feeds each IP range individually over a pipe. We could avoid that by communicating the list to the kernel using the Netlink protocol directly. There are <a href="https://github.com/vishvananda/netlink/search?q=ipset&amp;type=Issues">some attempts</a> to implement IP Sets support in Golang with the vishvananda/netlink library.</li>
</ul>
<p>For this reason, the reader should be cautious before comparing the setup time of one filter to another. This should not be interpreted as one method being better than another but rather to show expected setup performance and that setup time is unlikely to be a problem for any filtering method.</p>
<h3 id="test-6---throughput-with-too-many-rules">Test #6 - Throughput with too Many Rules</h3>
<p>The throughput in the tests one and two is almost the same regardless of the number of rules for the eBPF and IP Sets filters. We wanted to know if this behaviour changed with a higher number rules, 10 and 100 millions.</p>
<p>We found that it’s not possible to run a test with 100M entries …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kinvolk.io/blog/2020/09/performance-benchmark-analysis-of-egress-filtering-on-linux/">https://kinvolk.io/blog/2020/09/performance-benchmark-analysis-of-egress-filtering-on-linux/</a></em></p>]]>
            </description>
            <link>https://kinvolk.io/blog/2020/09/performance-benchmark-analysis-of-egress-filtering-on-linux/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24434697</guid>
            <pubDate>Thu, 10 Sep 2020 17:44:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kuma and Envoy: Multi-Cluster and Multi-Cloud Service Meshes]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24434618">thread link</a>) | @fosk
<br/>
September 10, 2020 | https://kuma.io/blog/2020/multi-cluster-cloud/ | <a href="https://web.archive.org/web/*/https://kuma.io/blog/2020/multi-cluster-cloud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <div> <p><span><time datetime="2020-09-10T00:00:00.000Z">
  Sep 10, 2020
</time></span> <span>/</span> <span>
              9 min read
            </span></p></div></div><div><!----> <div><div><p>When we first created Kuma – which means "bear"&nbsp;in Japanese – we dreamed of creating a service mesh that could run across every cluster, every cloud and every application. These are all requirements that large organizations must implement to support their application teams across a wide variety of architectures and platforms: VMs, Kubernetes, AWS, GCP and so on.</p> <p>With Kuma – now a CNCF project and at the time of this writing, the only Envoy-based service mesh donated and accepted by the foundation – we have relentlessly executed on this vision with the community.</p> <p>Starting from Kuma 0.6, which was released this summer with a new advanced multi-zone capability, Kuma now supports every cloud vendor, every architecture and every platform together in a multi-mesh control plane. When deployed in a multi-zone deployment, Kuma abstracts away both the synchronization of the service mesh policies across multiple zones and the service connectivity (and service discovery) across those zones. A zone can be a Kubernetes cluster, a data center, a cloud region, a VPC, a subnet and so on – we can slice and dice zones to our liking, and we can also mix Kubernetes and VM workloads into one distributed mesh deployment.</p> <p><img src="https://2tjosk2rxzc21medji3nfn1g-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/diagram-02-1536x779.jpg" alt=""></p> <center><i>
Kuma creates a service connectivity overlay across hybrid infrastructure to discover and connect services automatically, including hybrid Kubernetes + VM services.
</i></center> <p>This <a href="https://kuma.io/docs/latest/documentation/deployments/#multi-zone-mode" target="_blank" rel="noopener noreferrer">multi-zone capability</a> has been added in addition to the <a href="https://kuma.io/docs/latest/policies/mesh/" target="_blank" rel="noopener noreferrer">multi-mesh support</a> that Kuma introduced since day one to create multiple isolated meshes on the same cluster (with dedicated mTLS CAs) in order to reduce team coordination, increase isolation and improve security rather than one large service mesh that everybody is sharing. Also, since multi-zone leverages the first-class K8s + VM support that shipped since the first version of Kuma, all teams and workloads in the organizations can benefit from service mesh and not just our greenfield initiatives.</p> <p>A Kuma service mesh distributed across every cloud, cluster and workload that the teams are using can therefore be managed from one individual cluster of Kuma itself. Meanwhile, multiple service meshes can be virtually provisioned on one Kuma control plane (horizontally scalable) to simplify mesh management across the organization – very similar to how Kubernetes and its namespaces work.</p> <p><img src="https://2tjosk2rxzc21medji3nfn1g-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/diagram-one-cluster-new@2x.png" alt=""></p> <center><i>
Kuma supports multiple virtual meshes on the same Kuma deployment, removing the requirement of having multiple service mesh clusters for each application and therefore lowering the ops costs significantly.
</i></center> <h3 id="extending-xds-with-kds"><a href="#extending-xds-with-kds">#</a> Extending xDS With KDS</h3> <p>In Kuma, we can deploy a distributed service mesh running across multiple clusters, clouds or regions by leveraging the “multi-zone” deployment mode. The “multi-zone” deployment is a new way of running Kuma that has been introduced in v0.6+ in addition to the “standalone” deployment mode (one service mesh per zone).</p> <p>In a multi-zone deployment, there are a few important features that Kuma provides:</p> <ol><li>There are two control plane modes: global and remote. This is quite unique in the service mesh landscape.</li> <li>There is a new DNS “.mesh” zone for service discovery.</li> <li>There is a new “Ingress” data plane proxy type that enables connectivity between zones within a Kuma mesh.</li></ol> <p>In a distributed deployment, the “global” control plane will be in charge of accepting Kuma resources to determine the behavior of the service mesh via either native Kubernetes CRDs or vanilla YAML in VM-based deployments. It will be in charge of propagating these resources to the “remote” control planes – one for each zone that we want to support.</p> <p>The “remote” control planes are going to be exchanging Kuma resources with the “global” control plane over an extension of the Envoy xDS API that we called KDS (Kuma Discovery Service) over a gRPC protocol, and therefore, over HTTP/2. The “remote” control planes are also going to be accepting requests from the Envoy-based data plane proxies that belong to the same zone over traditional xDS.</p> <p><img src="https://2tjosk2rxzc21medji3nfn1g-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/diagram-01-1536x1316.jpg" alt=""></p> <center><i>
The remote control planes also embed a DNS service discovery that can be used to discover services across different zones. The above architecture can be easily installed in just a few steps using either the Kuma CLI “kumactl” or HELM charts.
</i></center> <p>In Kuma, we abstract away the Envoy proxy process in a “kuma-dp” process so that the user never directly configures or starts “envoy”, therefore making the whole process of starting a data plane proxy much easier. Advanced users can still access the underlying “envoy” process if they want to.</p> <p>By leveraging the native xDS API of Envoy to connect “kuma-dp” with “remote” control planes in every zone as well as leveraging KDS to connect the “remote” control planes to the global control plane, effectively we have gRPC communication enabled across the entire service mesh infrastructure stack in a consistent way.</p> <p>The “global” and “remote” architecture has a few benefits:</p> <ol><li>We can scale each zone independently by scaling the “remote” control planes and achieve HA in case one zone experiences issues.</li> <li>There is no single point of failure: even if the “global” control plane goes down, we can still register and deregister data plane proxies on the “remote” ones, and the most updated addresses of every service can still be propagated to other Envoy-based sidecars.</li> <li>The “global” control plane allows us to automatically propagate the state across every zone, while at the same time making sure that the “remote” control planes are aware of each zone’s Kuma ingress in order to enable cross-zone connectivity.</li></ol> <p>The control plane separation governs how Kuma resources (like meshes and policies) are synchronized across the zones, but it requires two other components in order to enable discovery and connectivity at the data plane layer across our zones in an automated way: service discovery and the “ingress” data plane proxy mode.</p> <h3 id="cross-zone-discovery-and-connectivity"><a href="#cross-zone-discovery-and-connectivity">#</a> Cross-Zone Discovery and Connectivity</h3> <p>Like we described, a multi-zone deployment can be used to deploy a distributed service mesh across multiple clouds and clusters, as well as to enable seamless communication between services running in different zones, effectively providing cross-zone service discovery and connectivity.</p> <p>Among other use cases, cross-zone connectivity is useful for:</p> <ul><li>Enabling high availability across multiple Kubernetes clusters, regions and availability zones in both single and multi-cloud environments</li> <li>Enabling traffic shifting from one zone to another for disaster recovery</li> <li>Enabling a step-by-step transition of our applications from VMs to Kubernetes – or from physical data centers to the cloud – by leveraging traffic control policies to determine the conditions under which service traffic should be shifted from one zone to another.
Kuma’s multi-zone deployment enables cross-zone connectivity by providing two important features:</li></ul> <ol><li>A new “ingress” data plane proxy mode processes incoming traffic into a zone. There will be one Kuma ingress deployment per zone, that can be scaled horizontally as the traffic increases. The “ingress” data plane mode is being added in addition to the default proxying one and the “gateway” one (to support third-party API gateways). Because of the new “ingress” mode, Kuma doesn’t require a flat networking topology between zones and can support more complex infrastructure.</li> <li>A built-in service discovery DNS server resolves the address of a service to either an IP address of a replica in the same zone or the address of an ingress proxy in another zone.
Likewise with the “global” and “remote” control planes, the ingress and the DNS service discovery can also be installed in one click by following the <a href="https://kuma.io/docs/latest/documentation/deployments/#multi-zone-mode" target="_blank" rel="noopener noreferrer">multi-zone instructions</a> on Kuma.</li></ol> <p>When it comes to service discovery, Kuma creates a “.mesh” DNS entry on the built-in DNS resolver that can be used to resolve services across the same zone or in other zones, effectively “flattening” the discovery of services across a complex infrastructure. Kuma will – accordingly to the traffic routing policies that have been configured – determine if we should be consuming a replica of the service in the local zone or if we should resolve the request to the IP address of a Kuma ingress in another zone, which will then leverage SNI to determine what service has been requested and route the request accordingly.</p> <p><img src="https://2tjosk2rxzc21medji3nfn1g-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/diagram-03.jpg" alt=""></p> <center><i>
In this example, we have three services (users, invoices and billing). Requests to “invoices.mesh” will be proxied to an IP address within the same zone, whereas requests to “billing.mesh” will be <b>automatically</b> proxied to an ingress of another zone.
</i></center> <p>Since SNI resolution is mandatory for cross-zone communication, the <a href="https://kuma.io/docs/latest/policies/mutual-tls/" target="_blank" rel="noopener noreferrer">mTLS policy</a> must be enabled on the mesh. Also, since Kuma already knows where all the services are running,  cross-zone discovery and connectivity happen automatically.</p> <p>When a new service is registered into Kuma, a new “kuma.io/zone” tag is added to the data plane definition so that we can use the <a href="https://kuma.io/docs/latest/documentation/dps-and-data-model/#tags" target="_blank" rel="noopener noreferrer">attribute-based policy selectors</a> to configure Kuma policies like <a href="https://kuma.io/docs/latest/policies/traffic-route/" target="_blank" rel="noopener noreferrer">Traffic Route</a> to determine the behavior of cross-zone traffic (blue/green or canary across different zones, weighted traffic, as well as traffic shifting).</p> <p>When consuming any “{service-name}.mesh” on default port 80 (even if the service is not listening on port 80), the DNS resolver – in addition to resolving the address of the service – will also automatically resolve the port of the destination service and inject it into the connection in order to keep the uptime of the overall connectivity even when a team decides to re-assign ports of a service that other teams may be using. This feature reduces the team coordination required to maintain a large number of services and connections in a Kuma mesh.</p> <h3 id="conclusion"><a href="#conclusion">#</a> Conclusion</h3> <p>Thanks to the new multi-zone capability that Kuma provides since v0.6+, we can now easily run a service mesh across multiple Kubernetes clusters, clouds and regions. Since Kuma natively supports both containerized and VM workloads, this …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kuma.io/blog/2020/multi-cluster-cloud/">https://kuma.io/blog/2020/multi-cluster-cloud/</a></em></p>]]>
            </description>
            <link>https://kuma.io/blog/2020/multi-cluster-cloud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24434618</guid>
            <pubDate>Thu, 10 Sep 2020 17:35:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Anatomy of a Rule]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24434450">thread link</a>) | @gneray
<br/>
September 10, 2020 | https://www.osohq.com/post/anatomy-of-a-rule | <a href="https://web.archive.org/web/*/https://www.osohq.com/post/anatomy-of-a-rule">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2>Introduction</h2><p>Authorization is an interesting domain in that it so frequently blurs the distinctions that we often draw between data and code. Sometimes a rule expresses a piece of data directly, such as who may do what to which resource. Other times a rule expresses logic, or code: this actor may do that to some resource <em>if</em> certain other conditions are also met, such as the actor or resource belonging to some model type. To handle complex authorization policies, a system should handle both points of view efficiently and naturally, and in this post we'll show how we aimed to do that when building <a href="https://www.osohq.com/">oso</a>, an open-source policy engine for authorization.</p><h2>Rules as Data</h2><p>An authorization policy specifies the requirements for authorization as <em>rules</em>. The rules may be in the form of permissions <em>data</em>, like an ACL: a (long) list of who can do what. In its simplest form, this may be only a few bits per rule, such as in traditional Unix file permissions. Or it may come in the form of a matrix like this one:</p><p>{% c-block language="polar" %}<br>allow,alice,read,/reports/alice/<br>allow,alice,read,/reports/bob/<br>allow,bhavik,read,/reports/bhavik/<br>allow,bob,read,/reports/bob/<br>allow,marjory,read,/reports/alice/<br>allow,marjory,read,/reports/bhavik/<br>allow,marjory,read,/reports/bob/<br>allow,marjory,read,/reports/marjory/<br>{% c-block-end %}</p><p>This matrix encodes which users of a system may access what paths. Here we've chosen to represent the matrix as CSV, but the encoding is irrelevant; this kind of authorization data is easily encoded in any authorization system, or handled directly by application code.</p><p>Another way to encode this kind of matrix is as a list of simple rule definitions, one per row:</p><p>{% c-block language="polar" %}<br>allow("alice", "read", "/reports/alice/");<br>allow("alice", "read", "/reports/bob/");<br>allow("bhavik", "read", "/reports/bhavik/");<br>allow("bob", "read", "/reports/bob/");<br>allow("marjory", "read", "/reports/alice/");<br>allow("marjory", "read", "/reports/bhavik/");<br>allow("marjory", "read", "/reports/bob/");<br>allow("marjory", "read", "/reports/marjory/");<br>{% c-block-end %}</p><p>Here the encoding is the <a href="https://docs.osohq.com/using/polar-syntax.html">oso rule language, Polar</a>, but again the encoding is not really germane. The point is that what we previously thought of as data has now become code in a declarative programming language. It's not very interesting code, but it is simple and direct, and makes an easy target for translation from nearly anything else. We'll come back and make it more interesting shortly, but let's take it on its own terms for now.</p><p>Since this policy is primarily data and we are treating it as such, we will undoubtedly run into inherent problems around handling data. For example, what happens as the permissions matrix grows in size? Even with naïve algorithms, a small matrix should pose no performance problem. But as with any other type of data, the tools needed to cope with it vary as the data grows. If the list is very large or if frequent dynamic updates are required, some kind of database is going to be most appropriate.</p><p>What we've done in oso is made it so that you shouldn't need to <em>prematurely</em> deal with these issues. By the time performance becomes a limiting factor, it should be the case that other data management problems are more pressing.</p><p>To handle largish data-heavy policies with oso, we implemented a simple indexing scheme over constant data. The speedups come from eliminating most or all rules from consideration up front with just a few hash lookups. We have seen it deliver very large speedups in authorization decisions on certain kinds of realistic policies, and <a href="https://osohq.github.io/oso/dev/bench/">our microbenchmarks</a> confirm the expected behavior.</p><p>We call this the <em>pre-filter</em>, since its job is to keep the "main" filter — the general rule selection and sorting process we'll discuss shortly — from even considering most rules. It is able to do its job by considering the parts of rules purely as data, while still respecting the semantics of the rules as code.</p><h2>Rules as code</h2><p>Data used to make authorization decisions is never random, and so almost always has exploitable structure. As usual in technology, we can exploit that structure through <em>abstraction</em>.</p><p>Let's look again at our simple permissions matrix. One simple pattern that should be evident is captured by the informal rule "etheveryone may read their own reports". We can capture this formally with oso as:</p><p>{% c-block language="polar" %}<br>allow(actor: String, "read", resource: String) if<br> &nbsp; &nbsp;resource.split("/") = ["", "reports", actor, ""];<br>{% c-block-end %}</p><p>This rule is universally quantified over all string-valued actors and resources, and so replaces a potentially infinite set of data rules. If we wish to quantify over more specific classes of actors and resources from our application, we can refine the type restrictions:</p><p>{% c-block language="polar" %}<br>allow(actor: Reporter, "read", resource: Report) if<br> &nbsp; &nbsp;resource.author = actor;<br>{% c-block-end %}</p><p>This allows extremely fine-grained decisions without a large blowup in policy size.</p><p>These kinds of rules behave very differently than the data rules we saw earlier. They may have data embedded in them (e.g., the {% c-line %}"read"{% c-line-end %} action, the {% c-line %}"reports"{% c-line-end %} path segment), but they are inherently <em>code</em>. These rules are <em>executed</em> or <em>called</em> with a list of arguments as part of an authorization query, not just <em>matched</em> as data. They may contain arbitrary logical expressions, which are encoded here as Horn clauses, but once again the encoding is inessential — the essential feature is the <em>interpretation</em> process, where the rules are treated as meaning-bearing expressions of a logical language rather than opaque or "quoted" data. Types or classes in such a language denote structured sets of data, semantically related through subtyping.</p><p>The inherent problems of handling code are well known, and solving them is our daily bread &amp; butter as software developers. All of the fundamental techniques developed over the years to handle these issues — abstraction, modularity, types, etc. — are relevant and useful in the authorization domain.</p><p>What we've done with oso is to make not only the application's data, but also its code and abstractions available in the DSL. Let's take types as an example. We saw above how types <em>defined by the application</em> can be used to make specialized authorization decisions: by annotating parameters with a {% c-line %}parameter: Type{% c-line-end %} <em>specializer</em>, and then using our knowledge of the type in the body of the rule to call specific methods or access certain attributes.</p><p>To support this particular abstraction, the system must do some work under the hood. For each specializer, query-time machinery must check whether a given argument is of the specialized type; we use a foreign function interface (FFI) to call into the application for an answer. Rules with parameter lists that match the given arguments are in this way selected or <em>filtered</em> from the list of possible rules.</p><p>After the applicable rules have been selected, we must then decide in what order to execute them. Sometimes it doesn't matter, but in the presence of exceptions and overrides for specific classes, it can. We therefore <em>sort</em> the applicable rules by specificity (i.e., by whether one type is more specific than another with respect to a given argument), and execute the most specific rule first. This allows more specific rules to selectively override less specific ones.</p><p>This filtering and sorting process is relatively slow compared to an index lookup. This is what makes the pre-filter we discussed earlier so effective in speeding up data-heavy policies; the fewer rules that need to be selected for applicability and sorted, the faster the call sequence executes. But in exchange for a somewhat expensive calling sequence, we can leverage available abstractions over our data, namely the types in our domain model. And by utilizing optimizations from our view of rules as data, we can make them affordable in realistic policies that freely mix code with data.</p><h2>Rules Redux</h2><p>We have now seen authorization rules from two points of view. Viewed as code, rules are interpreted or run, and so have an essentially dynamic character. Viewed as data, they may be indexed ahead of time, thus exploiting their static characteristics. So which is it? Are rules code or data, fish or fowl?</p><p>The answer of course, is both: code and data are dual, and no one point of view is primary. But switching points of view can sometimes lead us to opportunities for optimization that may be hard to see from the other, and knowing when you're dealing with which makes it easier to reason about trade-offs and which techniques to apply.</p></div></div></div>]]>
            </description>
            <link>https://www.osohq.com/post/anatomy-of-a-rule</link>
            <guid isPermaLink="false">hacker-news-small-sites-24434450</guid>
            <pubDate>Thu, 10 Sep 2020 17:22:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Laplace Transform: Basic theory and examples]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24434436">thread link</a>) | @R3G1R
<br/>
September 10, 2020 | https://mathvault.ca/laplace-transform/ | <a href="https://web.archive.org/web/*/https://mathvault.ca/laplace-transform/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div id="theme-content-section"><div><section data-css="tve-u-16ec5d248bb"><p>Let us take a moment to ponder how truly bizarre the <strong><a href="https://mathvault.ca/hub/higher-math/math-symbols/calculus-analysis-symbols/#Key_Transforms" target="_blank" aria-label="Laplace transform (opens in a new tab)" rel="noreferrer noopener">Laplace transform</a></strong> is.</p><p>You put in a sine and get an oddly simple, <strong>arbitrary-looking fraction</strong>. Why do we suddenly have squares?</p><p>You look at the table of <strong>common Laplace transforms</strong> to find a pattern and you see no rhyme, no reason, no obvious link between different functions and their different, very different, results.</p><p>What’s going on here?</p><p>Or so we thought when we first encountered the cursive $\mathcal{L}$ in school.</p><div><figure><img loading="lazy" width="888" height="367" src="https://mathvault.ca/wp-content/uploads/Laplace-Transform.png" alt="Laplace transform of function f" title="Laplace Transform"></figure></div><h2><span id="What_does_the_Laplace_transform_do,_really"></span><a href="#toc">What does the Laplace transform do, really?</a><span></span></h2><p>At a high level, Laplace transform is an <strong><a aria-label="integral transform (opens in a new tab)" href="https://en.wikipedia.org/wiki/Integral_transform#:~:text=In%20mathematics%2C%20an%20integral%20transform,in%20the%20original%20function%20space." target="_blank" rel="noreferrer noopener">integral transform</a></strong> mostly encountered in differential equations — in electrical engineering for instance — where electric circuits are represented as differential equations.</p><p>In fact, it takes a <strong>time-domain function</strong>, where $t$ is the variable, and outputs a <strong>frequency-domain function</strong>, where $s$ is the variable. Definition-wise, Laplace transform takes a function of real variable $f(t)$ (defined for all $t \ge 0$) to a function of complex variable $F(s)$ as follows:</p>\[\mathcal{L}\{f(t)\} = \int_0^{\infty} f(t) e^{-st} \, dt = F(s) \]<h2><span id="Some_Preliminary_Examples"></span><a href="#toc">Some Preliminary Examples</a><span></span></h2><p>What fate awaits <strong>simple functions</strong> as they enter the Laplace transform?</p><p>Take the simplest function: the <strong>constant function</strong> $f(t)=1$. In this case, putting $1$ in the transform yields $1/s$, which means that we went from a constant to a variable-dependent function.</p><iframe src="https://www.youtube.com/embed/OiNh2DswFt4?start=174" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><p>(Odd but not too worrying. After all, we’ve seen $1/x$ integrating to $\ln x$ in calculus. Not a constant-to-variable situation of course, but an unexpected transformation nonetheless.)</p><p>Let us take it up a notch, with the <strong>linear function</strong> $f(t) = t$. After the transformation, it is turned into $1/s^2$, which means that we went from $1 \to 1/s$ to $t \to 1/s^2$. A pattern begins to emerge.</p><p>Now what about $f(t)=t^n$? With this simple <strong>power function</strong>, we end up with: \[ \mathcal{L}\{ t^n \} = \frac{n!}{s^{n+1}}\] So there was a factorial in $\mathcal{L}\{t\}$ all along, hidden by the fact that $1! = 1$. What else is the transform hiding?</p><p>Here, a glance at a table of <strong><a aria-label="common Laplace transforms (opens in a new tab)" rel="noreferrer noopener" href="https://tutorial.math.lamar.edu/pdf/Laplace_Table.pdf" target="_blank">common Laplace transforms</a></strong> would show that the emerging pattern cannot explain other functions easily. Things get weird, and the weirdness escalates quickly — which brings us back to the sine function.</p><h2><span id="Looking_Inside_the_Laplace_Transform_of_Sine"></span><a href="#toc">Looking Inside the Laplace Transform of Sine</a><span></span></h2><p>Let us unpack what happens to our sine function as we Laplace-transform it. We begin by noticing that a sine function can be expressed as a <strong><a href="https://mathvault.ca/logarithm-theory/#Redefining_the_Exponential_Function_(of_Base_$e$)" target="_blank" aria-label="complex exponential (opens in a new tab)" rel="noreferrer noopener">complex exponential</a></strong> — an indirect result of the celebrated <a aria-label="Euler's formula (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Euler%27s_formula" target="_blank">Euler’s formula</a>:\[e^{it} = \cos t + i \sin t\]In fact, a sine is often expressed in terms of exponentials for <strong>ease of calculation</strong>, so if we apply that to the function $f(t) = \sin (at)$, we would get: \[ \sin(at) = \frac{e^{iat}-e^{-iat}}{2i} \]Thus the <strong>Laplace transform</strong> of $\sin(at)$ then becomes:<br>\[ \mathcal{L}\{\sin(at)\} = \frac{1}{2i} \int\limits_0^{\infty} (e^{iat}-e^{-iat}) e^{-st} \, dt \]which means that we have a <strong>product of exponentials</strong>. Distributing the terms, we get:<br>\[ \mathcal{L}\{\sin(at)\} = \frac{1}{2i} \int\limits_0^{\infty} e^{iat-st}-e^{-iat-st} \, dt \]</p><p>Here, <strong>factoring</strong> the $t$ in the exponents yields:<br>\[ \mathcal{L}\{\sin(at)\} = \frac{1}{2i} \int\limits_0^{\infty} e^{(ia-s)t}-e^{(-ia-s)t} \, dt \]and since $\mathrm{Re}(s) \gt 0$ by assumption, we can proceed with the integration from $0$ to $\infty$ as usual:<br>\[ \mathcal{L}\{\sin(at)\} = \left.\frac{e^{(ia-s)t}}{2i (ia-s)}\right|_0^{\infty}-\left.\frac{e^{(-ia-s)t}}{2i (-ia-s)}\right|_0^{\infty} \]</p><p>Let us simplify further. <strong>Distributing</strong> the $i$ inside the parentheses, we get:<br>\[ \mathcal{L}\{\sin(at)\} = \left.\frac{e^{(ia-s)t}}{2(-a-is)}\right|_0^{\infty}-\left.\frac{e^{(-ia-s)t}}{2(a-is)}\right|_0^{\infty} \]By evaluating the $t$ at the <strong>boundaries</strong>, we get:<br>\[ \mathcal{L}\{\sin(at)\} = \left( \frac{e^{(ia-s) \cdot \infty}}{2(-a-is)}-\frac{e^{(ia-s) \cdot 0}}{2 (-a-is)}\right)-\left(\frac{e^{(-ia-s)\cdot\infty}}{2(a-is)}-\frac{e^{(-ia-s)\cdot 0}}{2(a-is)}\right) \]And because $\mathrm{Re}(s) &gt; 0$ by assumption, both $e^{(ia-s) \cdot \infty}$ and $e^{(-ia-s)\cdot\infty}$ oscillate to $0$ (i.e., <strong><a aria-label="vanish at infinity (opens in a new tab)" rel="noreferrer noopener" href="https://mathvault.ca/math-glossary/#vanish" target="_blank">vanish at infinity</a></strong>), after which we are then left with:\[ \mathcal{L}\{\sin(at)\} = \frac{1}{-2(-a-is)} + \frac{1}{2(a-is)} \]Once there, merging the <strong>fractions</strong> together would yield:\begin{align*} \mathcal{L}\{\sin(at)\} &amp; = \frac{2(a-is)-2(-a-is)}{-4 (a-is)(-a-is)} \\ &amp; = \frac{2a-2is + 2a+2is}{4 (a^2 + isa-isa + s^2)} \\ &amp; = \frac{4a}{4(a^2 + s^2)} \\ &amp; = \frac{a}{a^2 + s^2} \end{align*}which shows that after Laplace transform, a sine is turned into a more tractable <strong>geometric function</strong>. By following similar reasoning, the Laplace transform of cosine can be shown to be equal to the following expression as well: \[ \mathcal{L}\{\cos (at)\} = \frac{s}{a^2 + s^2} \qquad (\mathrm{Re}(s) &gt; 0) \] But then, one might argue “Why do we need to transform trigonometric functions like this when we can just <strong>integrate</strong> them?”</p><h2><span id="Diverging_Functions_What_the_Laplace_Transform_is_for"></span><a href="#toc">Diverging Functions: What the Laplace Transform is for</a><span></span></h2><p>What if we throw a wrench in there by introducing a <strong>diverging function</strong>, say, $f(t)=e^{at}$? As it turns out, the Laplace transform of the exponential $e^{at}$ is actually deceptively simple: \begin{align*} \mathcal{L}\{e^{at}\} &amp; = \int_0^{\infty} e^{at}e^{-st} \, dt \\ &amp; = \int_0^{\infty} e^{(a-s)t} \, dt \end{align*}Here, we see that so long as $\mathrm{Re}(s) \gt a$, we would get that: \begin{align*} \int_0^{\infty} e^{(a-s)t} \, dt &amp; = \left. \frac{e^{(a-s)t}}{a-s} \right|_0^{\infty} \\ &amp; = 0-\frac{1}{a-s}  \\ &amp; = \frac{1}{s-a} \end{align*} That is, as long as $\mathrm{Re}(s) &gt; a$, the Laplace transform of $e^{at}$ is a simple $1/(s-a)$. Here’s a <strong>video version</strong> of the derivation for the record.</p><iframe src="https://www.youtube.com/embed/33TYoybjqPg?start=50" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><p>On the other hand, if we mix the exponential $e^{at}$ with the <strong>power function</strong> $t^n$, we would then have: \[ \mathcal{L}\{t^n e^{at}\} = \int\limits_0^{\infty} t^n e^{at} e^{-st} \, dt \] which, after a bit of <a aria-label="recursion (opens in a new tab)" href="https://mathvault.ca/math-glossary/#recursion" target="_blank" rel="noreferrer noopener">recursion</a> and <a aria-label="integration by parts (opens in a new tab)" href="https://mathvault.ca/integration-overshooting-method/#Integration_By_Parts" target="_blank" rel="noreferrer noopener">integration by parts</a>, would become:\[ \frac{n!}{(s-a)^{n+1}} \]Here, notice how the transforms of exponential and power function are both <strong>represented</strong> in the expression, with the factorial $n!$, the $1/(s-a)$ fraction, and the $n + 1$ exponent.</p><p>In fact, it turns out that we can integrate <em>any</em> function with the Laplace transform, as long as it does not <strong>diverge</strong> faster than the $e^{at}$ exponential. In the tables of Laplace transforms, you might have noticed the $\mathrm{Re}(s) \gt a$ condition. That is what the condition is alluding to.</p><h2><span id="A_Transform_of_Unfathomable_Power"></span><a href="#toc">A Transform of Unfathomable Power</a><span></span></h2><p>However, what we have seen is only the tip of the iceberg, since we can also use Laplace transform to transform the <strong>derivatives</strong> as well. In goes $f^{(n)}(t)$. Something happens. Then out goes:\[ s^n \mathcal{L}\{f(t)\}-\sum_{r=0}^{n-1} s^{n-1-r} f^{(r)}(0) \]For example, when $n=2$, we have that:\[ \mathcal{L}\{f^{\prime\prime}(t)\} = s^2 \mathcal{L}\{f(t)\}-sf(0)-f'(0) \]In addition to the derivatives, the $\mathcal{L}$ can also process some <strong>integrals</strong>: the integral sine, cosine and exponential, as well as the <a href="https://mathvault.ca/hub/higher-math/math-symbols/probability-statistics-symbols/#Continuous_Probability_Distributions_and_Associated_Functions" target="_blank" aria-label="error function (opens in a new tab)" rel="noreferrer noopener">error function</a> — to name a few.</p><p>But that’s not all. There is also the <strong><a aria-label="inverse Laplace transform (opens in a new tab)" rel="noreferrer noopener" href="https://mathvault.ca/hub/higher-math/math-symbols/calculus-analysis-symbols/#Key_Transforms" target="_blank">inverse Laplace transform</a></strong>, which takes a frequency-domain function and renders a time-domain function.</p><p>In fact, performing the transform from time to frequency and back once introduces a factor of $1/2\pi$. Sometimes, you’ll see the whole fraction in front of the inverse function, while other times, the transform and its inverse share a factor of $1/\sqrt{2\pi}$.</p><p>This is as if the Kraken could restitute the boat intact — but only for a factor of $1/2\pi$.</p><p>The Laplace transform, even after all those years, never ceases to bring us awe with its power. Here’s a <strong>table</strong> summarizing the transforms we’ve discussed thus far:</p><figure><table><thead><tr><th data-align="center">Function</th><th data-align="center">Laplace Transform</th></tr></thead><tbody><tr><td data-align="center">$1$</td><td data-align="center">$\dfrac{1}{s}$</td></tr><tr><td data-align="center">$t$</td><td data-align="center">$\dfrac{1}{s^2}$</td></tr><tr><td data-align="center">$t^n$</td><td data-align="center">$\dfrac{n!}{s^{n+1}}$</td></tr><tr><td data-align="center">$e^{at}$</td><td data-align="center">$\dfrac{1}{s-a}$</td></tr><tr><td data-align="center">$\sin(at)$</td><td data-align="center">$\dfrac{a}{a^2+s^2}$</td></tr><tr><td data-align="center">$\cos(at)$</td><td data-align="center">$\dfrac{s}{a^2+s^2}$</td></tr><tr><td data-align="center">$t^n e^{at}$</td><td data-align="center">$\dfrac{n!}{(s-a)^{n+1}}$</td></tr><tr><td data-align="center">$f^{(2)}(t)$</td><td data-align="center">$\displaystyle s^2 \mathcal{L}\{f(t)\}-sf(0)-f'(0)$</td></tr><tr><td data-align="center">$f^{(n)}(t)$</td><td data-align="center">$\displaystyle s^n \mathcal{L}\{f(t)\}-\sum_{r=0}^{n-1} s^{n-1-r} f^{(r)}(0)$</td></tr></tbody></table></figure> <span id="tve_leads_end_content"></span></section><div data-ct="thrive_author_box" data-ct-name="About the Author" data-shortcode="thrive_author_box" data-css="tve-u-16e8d3838e9"><div data-css="tve-u-17362c8dffa"><div data-css="tve-u-17362c8dffb"><div data-css="tve-u-17362c8dffc"><div data-css="tve-u-17362c8dffd"><p><span><img alt="Math Vault Standard Post" src="https://secure.gravatar.com/avatar/3e6005b4ba6abd9cef0c322ce2905523?s=256&amp;r=g" srcset="https://secure.gravatar.com/avatar/3e6005b4ba6abd9cef0c322ce2905523?s=512&amp;r=g 2x" loading="lazy" data-d-f="author" title="Math Vault Standard Post" data-css=""></span></p><p data-css="tve-u-17362c8dfff"><span data-css="tve-u-1739c03d42c" data-extra_key="" data-option-inline="1" data-shortcode="tcb_post_author_name" data-shortcode-name="Author Name">Kim Thibault</span></p></div></div><div data-css="tve-u-17362c8e001"><div data-css="tve-u-17362c8e002"><p data-css="tve-u-17362c8e003"><h4 data-css="tve-u-17362cd5fcd">About the author</h4></p><p data-css="tve-u-17362c8e006"><span data-extra_key="" data-option-inline="1" data-shortcode="tcb_post_author_bio" data-shortcode-name="Author Bio" data-css="tve-u-1736301163e">Kim Thibault is an incorrigible polymath. After a Ph.D. in Physics, she did applied research in machine learning for audio, then a stint in programming, to finally become an author and scientific translator. She occasionally solves differential equations as a hobby. Her blog can be found at <a href="http://kimthibault.mystrikingly.com/blog"><strong>kimthibault.mystrikingly.com/blog</strong></a> and her professional profile at <a href="https://linkedin.com/in/kimthibaultphd">linkedin.com/in/kimthibaultphd</a>.</span></p></div></div></div></div></div><p data-css="tve-u-17358ffc154"><h4 data-css="tve-u-170199ce799">You may also like</h4></p><div data-type="grid" data-pagination-type="none" data-pages_near_current="2" data-css="tve-u-17355fb4c5e" data-total_post_count="15" data-total_sticky_count="0" data-disabled-links="1" data-no_posts_text=""><article id="post-9087" tcb_hover_state_parent="" data-selector=".post-wrapper" data-permalink="https://mathvault.ca/statistical-significance/"><a href="https://mathvault.ca/statistical-significance/" title="A First Introduction to Statistical Significance — Through Dice Rolling and Other Uncanny Examples" data-css=""><img width="1000" height="600" src="https://mathvault.ca/wp-content/uploads/Statistical-Significance.jpg" alt="Header image of Math Vault's A Primer on Statistical Significance" loading="lazy" title="Statistical Significance"></a><div><p data-css="tve-u-17356046414">		<span data-attr-link="0" data-attr-rel="0" data-attr-target="0" data-extra_key="" data-option-inline="1" data-shortcode="tcb_post_title" data-shortcode-name="Post title" data-css="tve-u-17391b16085">A First Introduction to Statistical Significance — Through Dice Rolling and Other Uncanny Examples</span></p> 	<br></div></article><article id="post-7485" tcb_hover_state_parent="" data-selector=".post-wrapper" data-permalink="https://mathvault.ca/desmos-guide/"><a href="https://mathvault.ca/desmos-guide/" title="Desmos: A Definitive Guide on Graphing and Computing" data-css=""><img width="1000" height="600" src="https://mathvault.ca/wp-content/uploads/Desmos-Post.jpg" alt="Header image of Math Vault's Desmos: A Definitive Guide on Graphing and Computing" loading="lazy" title="Desmos Post"></a><div><p data-css="tve-u-17356046414">		<span data-attr-link="0" data-attr-rel="0" data-attr-target="0" data-extra_key="" data-option-inline="1" data-shortcode="tcb_post_title" data-shortcode-name="Post title" data-css="tve-u-17391b16085">Desmos: A Definitive Guide on Graphing and Computing</span></p> 	<br></div></article></div></div></div></div></div></div>]]>
            </description>
            <link>https://mathvault.ca/laplace-transform/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24434436</guid>
            <pubDate>Thu, 10 Sep 2020 17:20:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Four Indian Startups Funded via Abu Dhabi's AWI Fund (Middle East AI News)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24434248">thread link</a>) | @asiaainews
<br/>
September 10, 2020 | https://www.getrevue.co/profile/middleeastainews/issues/more-awi-fund-deals-disclosed-saudi-ai-strategy-to-be-launched-in-oct-275360 | <a href="https://web.archive.org/web/*/https://www.getrevue.co/profile/middleeastainews/issues/more-awi-fund-deals-disclosed-saudi-ai-strategy-to-be-launched-in-oct-275360">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.getrevue.co/profile/middleeastainews/issues/more-awi-fund-deals-disclosed-saudi-ai-strategy-to-be-launched-in-oct-275360</link>
            <guid isPermaLink="false">hacker-news-small-sites-24434248</guid>
            <pubDate>Thu, 10 Sep 2020 17:05:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facebook to stop moving data from EU to US: things you need to know]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24434196">thread link</a>) | @pujjad
<br/>
September 10, 2020 | https://www.politico.eu/article/facebook-data-ireland-privacy/ | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/facebook-data-ireland-privacy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							
							
							

							
							<div id="amazon-polly-audio-table">
				<p>Press play to listen to this article</p>
				
		</div><p>The countdown is on.</p>
<p>Facebook <a href="https://www.politico.eu/article/facebook-privacy-data-us/">will be forced</a> to stop moving data from its European users to the United States as early as next month after Ireland's data protection watchdog told the social networking giant that its current means of transferring digital information across the Atlantic is illegal.</p>
<p>The company still has a few weeks to appeal the preliminary ruling. But the decision deals a blow to billions of euros in digital trade annually between two of the world's largest trading blocs. The moratorium on Facebook's data transfers to the U.S. will also likely apply to other companies that regularly move such digital information from Europe to outside the bloc.</p>
<p>For Facebook users in Europe, the pending decision could allow them greater security that their data is not collected by U.S. intelligence agencies, and their use of the world's largest social network is not likely to be affected — at least in the short term. Yet questions remained about how their data will be handled when they interact with other users outside the 27-country bloc, say, sending a friend request or Instagram comment to a friend or family member in the U.S.</p>
<p>Ireland's move also represents a victory for a yearslong campaign by privacy activists who claim that U.S. national security agencies play fast and loose with data from non-American citizens when it's moved to the U.S. by companies like Facebook and Google. Washington denies those allegations.</p>
<blockquote><p>Expect Dublin to rule that Facebook must stop using these legal mechanisms and for the social networking giant to appeal that decision in an Irish court.</p></blockquote>
<p>Dublin's decision against Facebook — it still must be approved by the European Union's other national privacy agencies — stems directly from a ruling by the Court of Justice of the European Union (CJEU), the bloc's highest court, in July that <a href="https://www.politico.eu/article/eu-court-strikes-down-privacy-shield/">decreed Washington did not provide sufficient protections</a> for EU citizens when their data is transferred to the U.S.</p>
<p>But as with everything to do with Europe's privacy regime, things are a little complicated. Here's what you need to know:</p>
<h3>Data transfers will continue, but for how long?</h3>
<p>Facebook is adamant that its data transfers are legal. <a href="https://about.fb.com/news/2020/09/securing-the-long-term-stability-of-cross-border-data-flows/" target="_blank">In a statement,</a> Nick Clegg, the company's chief lobbyist, said: "We will continue to transfer data in compliance with the recent CJEU ruling and until we receive further guidance."</p>
<p>The company currently uses so-called standard contractual clauses, or complex legal mechanisms, to move data across the Atlantic. After Ireland raised concerns about these clauses in the wake of the July judgment from Europe's highest court, the company said it had added additional safeguards like data encryption to comply with the region's privacy standards. Facebook says such changes mean it can still use these data-transfer mechanisms to send information to the U.S.</p>
<p>But Ireland's privacy regulator has told the company the use of such clauses is still illegal because of the lack of privacy protections in the U.S. as outlined by Europe's highest court. Facebook disagrees, saying Europe's data protection agencies must offer guidance on how these clauses can be tweaked to comply with EU privacy law.</p>
<p>What does that mean? Expect Dublin to rule that Facebook must stop using these legal mechanisms and for the social networking giant to appeal that decision in an Irish court. The legal wrangling could drag on well into 2021 and beyond.</p>
<h3><strong>Privacy campaigner not happy</strong></h3>
<p>Strangely, Max Schrems, the Austrian privacy lawyer who brought the initial complaint in Ireland against Facebook, is not a happy man.</p>
<p>After Facebook publicly confirmed Dublin's preliminary decision to outlaw its transatlantic data transfers, he <a href="https://noyb.eu/en/dpc-actually-stopping-facebooks-eu-us-data-transfers-maybe-half-way" target="_blank">published a series of documents</a> alleging the company was trying to find alternatives to keep moving digital information to the U.S. Schrems also claimed that Ireland's Data Protection Commissioner was not investigating Facebook's new data-transfer arrangements, but did not provide concrete evidence to prove that assertion.</p>
<p>A spokesman for Ireland's privacy agency declined to comment.</p>
<p>The Austrian added he would be taking further legal action in Ireland to ensure the agency complies with EU privacy rules.</p>
<h3>First Facebook, second everyone else</h3>
<p>Other companies are keeping a close eye on what happens with the social network's data transfers because many are also reliant on standard contractual clauses to move digital information from Europe to the U.S. and elsewhere.</p>
<p>If Dublin's preliminary decision against Facebook is approved, it will set a precedent and force tech giants like Google and smaller firms across the region to reconsider how they move digital information to the U.S.</p>
<p>Previously, companies could have used the so-called EU-U.S. Privacy Shield regime, a transatlantic agreement that Europe's highest court has now struck down. If standard contractual clauses are also taken off the table (each company's legal mechanism would have to be reviewed independently before a final decision), that means there will be few, if any, legal means to move data from Europe to the U.S.</p>
<p>That would have an immediate knock-on effect on hundreds of billions of euros of annual trade and would hearten privacy groups that have long believed the U.S. national security regime was too data-hungry.</p>
<h3><strong>Keeping data in Europe looks more and more alluring</strong></h3>
<p>Though data transfers out of Europe haven’t themselves been banned, the insistence by Europe's highest court that they involve “supplementary measures,” and assessment of destination countries’ data protection regimes has had companies and regulators alike scratching their heads.</p>
<p>So far, talk of additional safeguards has revolved mostly around encryption, but there are question marks over whether this would really halt U.S. snooping in practice.</p>
<p>A once-taboo option that is gaining traction is to halt transfers altogether and to keep data in Europe.</p>
<p>Data localization — as the practice is called — <a href="https://www.politico.eu/article/privacy-shield-is-dead-long-live-data-localization/">is seen as the antithesis of the global internet</a> envisioned by the West, but would remove many of the legal headaches facing companies. The policy also has support from on high, with Europe’s Internal Market Commissioner Thierry Breton <a href="https://www.politico.eu/article/breton-wants-tiktok-data-to-stay-in-europe/">saying numerous times</a> that he wants data stored and processed on the Continent.</p>
<h3><strong>Another transatlantic data deal looks unlikely (for now)</strong></h3>
<p>Both Europe and the U.S. were quick to the negotiating table following the annulment of the Privacy Shield. A joint press release in July from EU justice chief Didier Reynders and U.S. Secretary of Commerce Wilbur Ross said that they were working toward an “enhanced” data-sharing deal.</p>
<p>But that may be a long time coming, if at all.</p>
<p>Any deal that does not significantly bolster the protection of European’s data from U.S. snooping is likely to get struck down in court. Reynders, the EU official, has said that a new deal <a href="https://www.politico.eu/?p=1447172">may need “legislative changes”</a> from the U.S. to avoid further legal uncertainty</p>
<p>But U.S. officials say it's impossible to get such legislative changes through Washington before November's presidential election and question how feasible it will be to rewrite U.S. laws to appease European privacy standards.</p>
<p><em>Want more analysis from </em><span>POLITICO</span><em>? </em><span>POLITICO</span><em> Pro is our premium intelligence service for professionals. From financial services to trade, technology, cybersecurity and more, Pro delivers real time intelligence, deep insight and breaking scoops you need to keep one step ahead. Email <a href="mailto:pro@politico.eu" target="_blank">pro@politico.eu</a> to request a complimentary trial.</em></p>

							
							
							<!--/.story-supplement-->

						</div></div>]]>
            </description>
            <link>https://www.politico.eu/article/facebook-data-ireland-privacy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24434196</guid>
            <pubDate>Thu, 10 Sep 2020 16:59:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Collaborative Reverse Engineering with Ghidra Server]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24434168">thread link</a>) | @bytehow
<br/>
September 10, 2020 | https://byte.how/posts/collaborative-reverse-engineering/ | <a href="https://web.archive.org/web/*/https://byte.how/posts/collaborative-reverse-engineering/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><p>If you’ve been using Ghidra for a while, your workflow is probably <a href="https://byte.how/posts/what-are-you-telling-me-ghidra/" rel="">similar to mine</a>. You’ve got a binary you’re interested in untangling, so what do you do? You open up Ghidra, create a new project, drag your file over, and start digging. Sooner or later, you encounter a huge binary. Maybe it’s <a href="https://en.wikipedia.org/wiki/Static_build#Static_building" target="_blank" rel="noopener noreffer">statically linked</a> and you’re left with hundreds of megabytes of function spaghetti. You can tackle it alone like you’ve been doing, but this time you think it’s best if you hit up some friends.</p><p>You’ve got your group. Everyone excited to go code diving with you…but now you’ve got another problem. How do you collaborate? How do you share discoveries?</p><p>When Ghidra asks if you’d like to create a shared or non-shared project, you probably don’t give it a second thought––non-shared of course! What’s a shared project anyhow? You might be surprised to learn that Ghidra has tools for collaboration right of the box. If you think about its origins as a tool used by the NSA’s presumably large teams of reverse engineers, it makes sense. Your group might not be a team of highly specialized experts, but familiarity with how to use these tools will certainly be beneficial.</p><p>I’m trying something a little different with this post. Instead of presenting sections of information, I’m going to write out some of the questions I had while exploring this system and the answers I’ve discovered. This isn’t meant to be a comprehensive guide, but I hope it answers something you’re curious about. If you have other questions, I’m happy to <a href="https://twitter.com/byte_how" target="_blank" rel="noopener noreffer">take a shot at answering them</a> 😃</p><p>Shared and non-shared projects don’t differ by much. If you’re familiar with git, a shared project is like a git repository that’s been pushed to a server. Shared projects facilitate collaboration by allowing you to share programs and the annotations made to them as part of the reverse engineering process. How you go about making those annotations is pretty much the same. Sharing them occurs mostly in the Project Window, where you can check in files, push your changes, pull in changes and files from collaborators, view version history , and explore commits made.</p><p>You need a Ghidra Server instance deployed locally or on a server. Ghidra Server is distributed with your Ghidra release and is included in the <code>&lt;ghidra_root&gt;/server</code> directory. Your server must also have some users provisioned.</p><h2 id="how-do-i-create-a-server">How do I create a server?</h2><p>If you’re a masochist, you can consult the Ghidra server documentation available at <code>&lt;ghidra_root&gt;/server/svrREADME.html</code>. It’s not the most pleasant documentation to read through, but it gets the job done. You can also consult Chapter 11 of <a href="https://nostarch.com/GhidraBook" target="_blank" rel="noopener noreffer">The Ghidra Book</a>, which walks through setting up a bare metal Ghidra server.</p><p>…or you can take the easy path with Docker and my “one-click” <code>bytehow/ghidra-server</code> <a href="https://github.com/bytehow/docker-ghidra-server" target="_blank" rel="noopener noreffer">container image</a>. When launching the container you have the option of providing a <code>GHIDRA_USERS</code> environment variable which is a space separated-list of users to create. All users will be admins, and all will have the initial password of <code>changeme</code> which Ghidra will require you to change on first login.</p><div><p><i></i>Note<i></i></p><div><p>If you’d like to add or remove users after creating a server, you need to <code>docker exec</code> into the container and use the provided <code>svrAdmin</code> script. This script is documented in the Server Administration section of the Ghidra Server docs.</p></div></div><div><p><i></i>Info<i></i></p><div><p>Multiple authentication methods (even anonymous authentication) are supported, however the provided container is configured to use password authentication. Consult the Ghidra Server documentation for configuration options.</p></div></div><h2 id="whats-the-difference-between-a-project-and-a-repository">What’s the difference between a project and a repository?</h2><p>A project, shared or not, is your local copy of what you’re working on. If it’s a shared project, it’s backed by a repository hosted on a Ghidra Server. A project is like doing a <code>git clone</code>. The repository is what you’re “cloning” from the Ghidra Server.</p><div><p><i></i>Note<i></i></p><div><p>A Ghidra Server can host many repositories.</p></div></div><p>From the Project View, File -&gt; New Project -&gt; Shared Project</p><p>Enter the IP/hostname and port of your Ghidra Server. You’ll then be presented with a dialogue asking you to either choose an existing repository or create a new one. Here I’m creating a new repository <code>my-new-project</code></p><figure><a href="https://byte.how/images/ghidra-server/new-project.png" title="/images/ghidra-server/new-project.png" data-thumbnail="/images/ghidra-server/new-project.png" data-sub-html="<h2>Create a new shared project</h2>"><img src="https://byte.how/images/ghidra-server/new-project.png" data-src="/images/ghidra-server/new-project.png" data-srcset="/images/ghidra-server/new-project.png, /images/ghidra-server/new-project.png 1.5x, /images/ghidra-server/new-project.png 2x" data-sizes="auto" alt="/images/ghidra-server/new-project.png" srcset="https://byte.how/images/ghidra-server/new-project.png, https://byte.how/images/ghidra-server/new-project.png 1.5x, https://byte.how/images/ghidra-server/new-project.png 2x"></a><figcaption>Create a new shared project</figcaption></figure><p>You’ll then be asked to add users to the project</p><figure><a href="https://byte.how/images/ghidra-server/specify-users.png" title="/images/ghidra-server/specify-users.png" data-thumbnail="/images/ghidra-server/specify-users.png" data-sub-html="<h2>Specifying users and their permissions</h2>"><img src="https://byte.how/images/ghidra-server/specify-users.png" data-src="/images/ghidra-server/specify-users.png" data-srcset="/images/ghidra-server/specify-users.png, /images/ghidra-server/specify-users.png 1.5x, /images/ghidra-server/specify-users.png 2x" data-sizes="auto" alt="/images/ghidra-server/specify-users.png" srcset="https://byte.how/images/ghidra-server/specify-users.png, https://byte.how/images/ghidra-server/specify-users.png 1.5x, https://byte.how/images/ghidra-server/specify-users.png 2x"></a><figcaption>Specifying users and their permissions</figcaption></figure><p>As the project creator, you’re the admin for the project by default. You can designate other users with different permissions</p><ul><li><strong>Read Only</strong> - The user can only download files. Check outs are not permitted, and consequently, neither are check ins.</li><li><strong>Read/Write</strong> - The user can check out files and commit changes.</li><li><strong>Admin</strong> - Can do everything that the Read/Write user can do, but has the ability to manage the user access list, and terminate other user check outs (described later in the post).</li></ul><div><p><i></i>Info<i></i></p><div><p>You can modify the user access list for a project after the project is created. From the Project View, after opening your shared project, Project -&gt; Edit Project Access List.</p></div></div><p>After configuring users, you’ll then chose the local project name and location. This process is like creating a new repository on a git server, then cloning the project locally.</p><h2 id="how-do-i-pull-down-a-project-from-a-ghidra-server">How do I pull down a project from a Ghidra Server?</h2><p>From the Project View, File -&gt; New Project -&gt; Shared Project. Enter your server information. As described earlier, you can choose either an existing repository that you’ve been added to as a user, or create a new one. We want the latter.</p><p>You then choose where you want to save this project locally and what you’d like to name it.</p><p>From the Project View or Code Browser, press <code>I</code> and select the file you’d like to add, or use File -&gt; Import File. To make this file available to others, you need to add it to version control either by right clicking the file in the Project View and selecting Add to Version Control, or clicking on the matching icon in the top left of the toolbar</p><figure><a href="https://byte.how/images/ghidra-server/add-to-version-control.png" title="/images/ghidra-server/add-to-version-control.png" data-thumbnail="/images/ghidra-server/add-to-version-control.png" data-sub-html="<h2>Add a file to version control</h2>"><img src="https://byte.how/images/ghidra-server/add-to-version-control.png" data-src="/images/ghidra-server/add-to-version-control.png" data-srcset="/images/ghidra-server/add-to-version-control.png, /images/ghidra-server/add-to-version-control.png 1.5x, /images/ghidra-server/add-to-version-control.png 2x" data-sizes="auto" alt="/images/ghidra-server/add-to-version-control.png" srcset="https://byte.how/images/ghidra-server/add-to-version-control.png, https://byte.how/images/ghidra-server/add-to-version-control.png 1.5x, https://byte.how/images/ghidra-server/add-to-version-control.png 2x"></a><figcaption>Add a file to version control</figcaption></figure><p>This is like <code>git add</code> followed by <code>git commit</code>.</p><p>From the Project View, after opening the shared project, Project -&gt; View Project. Select the local project you want to add files from. It’ll be opened in the right side of the window. Drag over the files you’d like to add, and add them to version control as described above</p><figure><a href="https://byte.how/images/ghidra-server/project-data.png" title="/images/ghidra-server/project-data.png" data-thumbnail="/images/ghidra-server/project-data.png" data-sub-html="<h2>Copy local files to shared projects</h2>"><img src="https://byte.how/images/ghidra-server/project-data.png" data-src="/images/ghidra-server/project-data.png" data-srcset="/images/ghidra-server/project-data.png, /images/ghidra-server/project-data.png 1.5x, /images/ghidra-server/project-data.png 2x" data-sizes="auto" alt="/images/ghidra-server/project-data.png" srcset="https://byte.how/images/ghidra-server/project-data.png, https://byte.how/images/ghidra-server/project-data.png 1.5x, https://byte.how/images/ghidra-server/project-data.png 2x"></a><figcaption>Copy local files to shared projects</figcaption></figure><p>Here, I’ve copied <code>shellcode32</code> and <code>target</code> from my local <code>lab2</code> project. If you take a look, I’ve only added <code>shellcode32</code> to version control (as indicated by the version number <code>(1 of 1)</code>) and kept it checked out (as indicated by the green check mark). Other users can see <code>shellcode32</code>, but not <code>target</code> when they view the repository.</p><p>This is like</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span></code></pre></td><td><pre><code data-lang="bash">$ cp /path/to/lab2/shellcode32
$ cp /path/to/lab2/target
$ git add shellcode32
$ git commit
</code></pre></td></tr></tbody></table></div></div><p>You must first create a new shared project and repository as described above. Then, add all files from your local project to the shared project. If there’s a better way to do this, please let me know…</p><h2 id="how-do-i-check-out-a-file">How do I check out a file?</h2><p>In the Project View, right click the file and select Check Out, or click the matching icon</p><figure><a href="https://byte.how/images/ghidra-server/checkout-file.png" title="/images/ghidra-server/checkout-file.png" data-thumbnail="/images/ghidra-server/checkout-file.png" data-sub-html="<h2>Check out a file</h2>"><img src="https://byte.how/images/ghidra-server/checkout-file.png" data-src="/images/ghidra-server/checkout-file.png" data-srcset="/images/ghidra-server/checkout-file.png, /images/ghidra-server/checkout-file.png 1.5x, /images/ghidra-server/checkout-file.png 2x" data-sizes="auto" alt="/images/ghidra-server/checkout-file.png" srcset="https://byte.how/images/ghidra-server/checkout-file.png, https://byte.how/images/ghidra-server/checkout-file.png 1.5x, https://byte.how/images/ghidra-server/checkout-file.png 2x"></a><figcaption>Check out a file</figcaption></figure><p>Ghidra’s concept of a check out is a little different than git. Ghidra keeps track of all users that have currently checked out a file. You can see who has a file checked out by right clicking on it and selecting View Check Outs. You’ll then be presented with this table</p><figure><a href="https://byte.how/images/ghidra-server/view-checkouts-window.png" title="/images/ghidra-server/view-checkouts-window.png" data-thumbnail="/images/ghidra-server/view-checkouts-window.png" data-sub-html="<h2>Viewing check outs</h2>"><img src="https://byte.how/images/ghidra-server/view-checkouts-window.png" data-src="/images/ghidra-server/view-checkouts-window.png" data-srcset="/images/ghidra-server/view-checkouts-window.png, /images/ghidra-server/view-checkouts-window.png 1.5x, /images/ghidra-server/view-checkouts-window.png 2x" data-sizes="auto" alt="/images/ghidra-server/view-checkouts-window.png" srcset="https://byte.how/images/ghidra-server/view-checkouts-window.png, https://byte.how/images/ghidra-server/view-checkouts-window.png 1.5x, https://byte.how/images/ghidra-server/view-checkouts-window.png 2x"></a><figcaption>Viewing check outs</figcaption></figure><p>Why does it matter who has a file checked out? This comes into play when changing the memory map or language of a program. You may have noticed when checking out that you had the option of requesting an exclusive check out</p><figure><a href="https://byte.how/images/ghidra-server/exclusive-checkout.png" title="/images/ghidra-server/exclusive-checkout.png" data-thumbnail="/images/ghidra-server/exclusive-checkout.png" data-sub-html="<h2>Exclusive check out option</h2>"><img src="https://byte.how/images/ghidra-server/exclusive-checkout.png" data-src="/images/ghidra-server/exclusive-checkout.png" data-srcset="/images/ghidra-server/exclusive-checkout.png, /images/ghidra-server/exclusive-checkout.png 1.5x, /images/ghidra-server/exclusive-checkout.png 2x" data-sizes="auto" alt="/images/ghidra-server/exclusive-checkout.png" srcset="https://byte.how/images/ghidra-server/exclusive-checkout.png, https://byte.how/images/ghidra-server/exclusive-checkout.png 1.5x, https://byte.how/images/ghidra-server/exclusive-checkout.png 2x"></a><figcaption>Exclusive check out option</figcaption></figure><p>If you try to modify the memory map or change the language of a file that you did not request an exclusive check out for, and you are not the only user that currently has the file checked out, Ghidra will refuse to do so. These modifications have significant ramifications to the rest of the annotations make, so Ghidra needs to ensure exclusive access to the file. If you need to make these changes, you would typically notify the rest of the users, ask them to check in their work, and then one person makes an exclusive check out. This person modifies the memory map or language, and checks in their changes. The other users will then check out the latest version and continue where they left off.</p><div><p><i></i>Tip<i></i></p><div><div><p>What if you need exclusive check out but there’s an active checkout from an inactive user? No problem. Project admins can terminate a check out from the View Check Outs window</p><figure><a href="https://byte.how/images/ghidra-server/terminate-checkout.png" title="/images/ghidra-server/terminate-checkout.png" data-thumbnail="/images/ghidra-server/terminate-checkout.png" data-sub-html="<h2>Terminate a checkout</h2>"><img src="https://byte.how/images/ghidra-server/terminate-checkout.png" data-src="/images/ghidra-server/terminate-checkout.png" data-srcset="/images/ghidra-server/terminate-checkout.png, /images/ghidra-server/terminate-checkout.png 1.5x, /images/ghidra-server/terminate-checkout.png 2x" data-sizes="auto" alt="/images/ghidra-server/terminate-checkout.png" srcset="https://byte.how/images/ghidra-server/terminate-checkout.png, https://byte.how/images/ghidra-server/terminate-checkout.png 1.5x, https://byte.how/images/ghidra-server/terminate-checkout.png 2x"></a><figcaption>Terminate a checkout</figcaption></figure></div></div></div><h2 id="why-is-my-file-hijacked">Why is my file hijacked?</h2><p>When working on a shared project, naming collisions can occur between files that have been added to the repository by another user, and a private file. Whenever this happens, the local file is marked as <code>hijacked</code></p><figure><a href="https://byte.how/images/ghidra-server/hijacked-file.png" title="/images/ghidra-server/hijacked-file.png" data-thumbnail="/images/ghidra-server/hijacked-file.png" data-sub-html="<h2>Who hijacked this file?!</h2>"><img src="https://byte.how/images/ghidra-server/hijacked-file.png" data-src="/images/ghidra-server/hijacked-file.png" data-srcset="/images/ghidra-server/hijacked-file.png, /images/ghidra-server/hijacked-file.png 1.5x, /images/ghidra-server/hijacked-file.png 2x" data-sizes="auto" alt="/images/ghidra-server/hijacked-file.png" srcset="https://byte.how/images/ghidra-server/hijacked-file.png, https://byte.how/images/ghidra-server/hijacked-file.png 1.5x, https://byte.how/images/ghidra-server/hijacked-file.png 2x"></a><figcaption>Who hijacked this file?!</figcaption></figure><p>To resolve this, you have 3 options:</p><h2 id="how-do-i-check-in-a-file">How do I check in a file?</h2><p>After making changes to a file, you can commit those changes to the repository by checking in the file. First, save your changes and close the code browser. From the project view, right click the file and select Check In, or click the Check In icon from the tool bar. If there’s no merge conflicts, you’ll be asked to supply a comment describing your changes. A new version of the file is created within the repository.</p><p>This is like</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span><span>3
</span></code></pre></td><td><pre><code data-lang="bash">$ git add
$ git commit
$ git push
</code></pre></td></tr></tbody></table></div></div><h2 id="how-do-i-pull-in-new-updates-to-a-checked-out-file">How do I pull in new updates to a checked out file?</h2><p>You can pull in changes for a checked out file from the latest version before checking in your changes. First, save your work and close the code browser. From the Project View, right click on the file and select Update, or click the Update icon from the tool bar. If there’s no merge conflicts, your local file is automatically updated.</p><p>This is like <code>git pull</code>.</p><h2 id="how-do-i-revert-my-local-changes">How do I revert my local changes?</h2><p>Right click a file within the Project View and select Undo Checkout. Select which files you’d like to revert. If you don’t select the <code>.keep</code> option, this will discard your local changes and revert back to the latest version of the file. This is like <code>git checkout</code>. If you do select the <code>.keep</code> option, your local changes are copied to a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://byte.how/posts/collaborative-reverse-engineering/">https://byte.how/posts/collaborative-reverse-engineering/</a></em></p>]]>
            </description>
            <link>https://byte.how/posts/collaborative-reverse-engineering/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24434168</guid>
            <pubDate>Thu, 10 Sep 2020 16:57:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Being VP of Engineering Is Harder Than Being CEO]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24434042">thread link</a>) | @necco908
<br/>
September 10, 2020 | https://linearb.io/blog/being-vp-of-software-development-is-harder-than-being-ceo/ | <a href="https://web.archive.org/web/*/https://linearb.io/blog/being-vp-of-software-development-is-harder-than-being-ceo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="670d84f7" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<h2>Tips for translating between engineering and executives</h2>



<p>A lot has been said about how lonely it gets being a founder/CEO of a startup company, you can probably pick any Ben Horowitz quote here about the struggle or the cold sweat in the middle of the night and you’d be right.&nbsp;</p>



<p>Right now it is especially hard to be CEO. Every single person in the organization needs more and different support than they did a month ago. I’m personally going through this right now (I’m a first time CEO) and doing the best I can for all of our people. </p>



<p>But there is actually one position that can be even more cruel than being CEO. Being VP of Engineering is lonelier. In fact your VP of Dev is probably the loneliest person in your company.&nbsp;</p>



<div><figure><img src="https://linearb.io/wp-content/uploads/2020/02/the-rosetta-stone-4606054-799x1024.png" alt="" width="300" srcset="https://linearb.io/wp-content/uploads/2020/02/the-rosetta-stone-4606054-799x1024.png 799w, https://linearb.io/wp-content/uploads/2020/02/the-rosetta-stone-4606054-234x300.png 234w, https://linearb.io/wp-content/uploads/2020/02/the-rosetta-stone-4606054-768x984.png 768w, https://linearb.io/wp-content/uploads/2020/02/the-rosetta-stone-4606054-1198x1536.png 1198w, https://linearb.io/wp-content/uploads/2020/02/the-rosetta-stone-4606054.png 1498w" sizes="(max-width: 799px) 100vw, 799px"><figcaption><em>Good VPEs act as the Rosetta Stone between Engineering and Execs</em></figcaption></figure></div>



<p><em><strong>I remember exactly where it hit me and probably where the seeds of starting LinearB were planted in my head.</strong> </em></p>



<p>It was one of those Monday mornings after a tough week before. I was just appointed to the VP of R&amp;D of a great security startup and was walking into a Monday morning CEO staff meeting. One of the latest deployments exploded (and not in a nice way) because of a human error and I was fighting side by side with the team throughout the weekend to restore the situation to the normal state.&nbsp;</p>



<p>When I think back to it, I can still feel the wrath of the CEO in that meeting. I did not get a single day of grace in my new role and, if that wasn’t enough, I had to deal with 3 frustrated developers that told me how stuff is broken because all the execs care about is delivering new features and how they will never understand what technical debt is and how if you slow down and build things right you will eventually move faster.</p>







<p>The picture was clear in my head then…</p>







<p>As VP of Engineering we spend most of our time translating between two groups of people in two parallel universes. We’re citizens of both while not fully belonging to either.</p>



<p>I was not really one of the developers. I was once, but not anymore. I constantly had to remind the team of the realities of developing software inside a business with goals that are a lot more around revenue, customers and deadlines. Some of them got it. But to many I was now just another executive. If they had assigned me an avatar, he would probably would have been wearing a suit, even though I always wear t-shirts.</p>







<p><em>I was not really an executive either.</em> I certainly tried to be. I tried to fit in with my new peers. I spent hours listening to the VP of Marketing and VP of Sales on what would help drive more business. But every time I tried explaining back to them and to my boss (the CEO) how building software at scale is a complex mission that has to maintain a delicate balance between the delivery of new value and the investment in non-functional infrastructures and quality initiatives that will enable the business to keep on moving forward with fast and reasonable pace, I felt that they nodded their head with (fake) understanding and went back to ask about feature delivery dates the next week.</p>



<figure><blockquote><p>Even in good companies with good culture, there is not a strong desire from either side to understand the other.&nbsp;</p></blockquote></figure>



<p>So this big gap exists. And that gap is where we (VPs of Software Development) live. To close the gap, you need to build a bridge. Speaking both languages is not enough to build the bridge. You also need to understand both cultures. When you have both, you have a chance to earn the respect you need from both sides to close the gap.&nbsp;</p>







<h3><strong>Building the bridge</strong></h3>



<div><figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/02/Award.png.webp 585w" sizes="(max-width: 585px) 100vw, 585px">
<img src="https://linearb.io/wp-content/uploads/2020/02/Award.png" alt="" width="200" srcset="https://linearb.io/wp-content/uploads/2020/02/Award.png 585w, https://linearb.io/wp-content/uploads/2020/02/Award-229x300.png 229w" sizes="(max-width: 585px) 100vw, 585px">
</picture>
</figure></div>



<p>A great translator brings two worlds together that would otherwise never know each other.&nbsp;</p>



<p>The 2020 Academy Awards showed us a beautiful example of this. The Oscars seem like a lifetime ago and yet the image stays fresh in my mind. </p>



<p>A Korean film called Parasite cleaned up several of the major awards including Best Motion Picture. It is the first time in the ceremony’s 90+ year history that a non-English language film won the big award. </p>



<p>Earlier in the night, Parasite’s director Bong Joon Ho was on stage accepting the award for Best Director. He was accompanied by his translator Sharon Choi. </p>



<p>Sharon was <a href="https://wethepvblic.com/bong-joon-ho-sharon-choi-award-mvp/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">applauded</a> for her job representing Bong’s wit, sarcasm, and humor. And not just at the Oscars. She had been translating his acceptance speeches for months at numerous awards celebrations. </p>







<blockquote><p lang="en" dir="ltr">How about a hand for Sharon Choi, the interpreter who’s been just as excellent in speaking for Bong Joon-ho this awards season! <a href="https://twitter.com/hashtag/Oscars?src=hash&amp;ref_src=twsrc%5Etfw">#Oscars</a> <a href="https://t.co/aHOAQK3Y8T">https://t.co/aHOAQK3Y8T</a></p>— Jao (@Jaollibee) <a href="https://twitter.com/Jaollibee/status/1226714867744178176?ref_src=twsrc%5Etfw">February 10, 2020</a></blockquote> 







<p>What many people did not realize until later is that her qualifications for the job went far beyond her ability to translate Korean into English. Sharon Choi is a movie director herself. This subject matter expertise allowed her to communicate nuance that another translator might have missed. She understands Bong because she is just like him. And she had the respect of the movie industry audience because she, too, makes movies. </p>







<h3><strong>Successful VPs of Engineering are great translators</strong></h3>



<p>The best VPs of Software Development embrace their role as a translator. They know their company won’t reach their potential if they don’t create a bridge between the people that develop software to the people that directly interface with customers.&nbsp;</p>



<p>Here’s how the best VPs of Engineering translate on a day-to-day basis:&nbsp;</p>



<p><strong>They bring data to the weekly management meeting.</strong> The VP of Marketing has dashboards from Marketo or Hubspot about the number of MQLs and SQLs. The VP of Sales has reports from Salesforce about how many deals are in each phase of the sales cycle. The VP of Customer Success pulls up Gainsight to show customer engagement and renewal metrics.&nbsp;</p>



<figure><blockquote></blockquote></figure>



<p>Great VPs of Software Development have their own dashboards. And they focus on leading indicators that monitor the <a href="https://linearb.io/blog/dev-productivity-is-way-down-at-linearb/" target="_blank" rel="noreferrer noopener" aria-label="quality of the process rather than focusing on outputs (opens in a new tab)">quality of the process rather than focusing on outputs</a> and trailing indicators like how many lines of code the team wrote or even how many bugs were found. </p>



<p>They draw a <strong><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://linearb.io/blog/align-engineering-metrics-to-your-business-kpis/" target="_blank">clear connection between dev KPIs and the overall goals for the business</a>.&nbsp;</strong></p>



<p>Want to predict how fast we are shipping new value to customers? They show <em><a href="https://linearb.io/cycle-time/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">cycle time</a></em>.</p>



<figure><a href="https://linearb.io/wp-content/uploads/2020/02/Cycle-Time.png"><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/02/Cycle-Time.png.webp 2493w" sizes="(max-width: 2493px) 100vw, 2493px">
<img src="https://linearb.io/wp-content/uploads/2020/02/Cycle-Time.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/02/Cycle-Time.png 2493w, https://linearb.io/wp-content/uploads/2020/02/Cycle-Time-300x145.png 300w, https://linearb.io/wp-content/uploads/2020/02/Cycle-Time-1024x493.png 1024w, https://linearb.io/wp-content/uploads/2020/02/Cycle-Time-768x370.png 768w, https://linearb.io/wp-content/uploads/2020/02/Cycle-Time-1536x740.png 1536w, https://linearb.io/wp-content/uploads/2020/02/Cycle-Time-2048x987.png 2048w" sizes="(max-width: 2493px) 100vw, 2493px">
</picture>
</a></figure>



<p>Want to predict how satisfied customers are with the quality of the product? They show you the quality of the process with <em>PR review coverage and review depth</em>.&nbsp;</p>



<p>Bringing consistent metrics to the staff meeting each week will help elevate the development process from being an enigma to being a well-understood function in the business.&nbsp;</p>







<p><strong>They teach the CEO and their peers how to understand the development process. </strong>The most common question a VP of Dev gets is “is feature XYZ shipping on time?” This seems like a fair and obvious question to ask her. But look more closely. After a while the CEO would stop asking the VP of Sales “hey, are we going to hit our number this quarter?” because they already know the answer to that question. They can look at the revenue dashboard and see</p>



<ul><li>The number of days left in the quarter</li><li>The number of deals and amount of revenue already closed</li><li>The number of deals left open and the total contract value&nbsp;</li><li>The number of deals open across each phase of the sales process&nbsp;</li></ul>







<p>Then they can compare this data to previous quarters to see if they are on, ahead of or behind schedule.</p>



<p>Part of the VP of Devs job is to teach the CEO and the other business leaders to look at their department in the same way. And although forecasting is a tough task if they want to know if feature XYZ is on time, they can look at the dashboard.&nbsp;</p>







<figure><a href="https://linearb.io/wp-content/uploads/2020/02/Iteration-Schedule-Annotated-2.png"><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/02/Iteration-Schedule-Annotated-2.png.webp 1180w" sizes="(max-width: 1180px) 100vw, 1180px">
<img src="https://linearb.io/wp-content/uploads/2020/02/Iteration-Schedule-Annotated-2.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/02/Iteration-Schedule-Annotated-2.png 1180w, https://linearb.io/wp-content/uploads/2020/02/Iteration-Schedule-Annotated-2-300x47.png 300w, https://linearb.io/wp-content/uploads/2020/02/Iteration-Schedule-Annotated-2-1024x161.png 1024w, https://linearb.io/wp-content/uploads/2020/02/Iteration-Schedule-Annotated-2-768x121.png 768w" sizes="(max-width: 1180px) 100vw, 1180px">
</picture>
</a></figure>







<p>Over time the CEO and the peers will develop the data-driven intuition (yes, this is a thing – just read Malcom Gladwell’s Blink) to understand whether we are currently in hitting / missing / over achieving trajectory. So instead of asking “are we going to hit our date” they’ll say “It looks like you are slightly behind schedule compared to last week / iteration. What can I do to help?” </p>







<figure><a href="https://linearb.io/wp-content/uploads/2020/02/Risky-Work-Annotated.png"><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/02/Risky-Work-Annotated.png.webp 1531w" sizes="(max-width: 1531px) 100vw, 1531px">
<img src="https://linearb.io/wp-content/uploads/2020/02/Risky-Work-Annotated.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/02/Risky-Work-Annotated.png 1531w, https://linearb.io/wp-content/uploads/2020/02/Risky-Work-Annotated-300x90.png 300w, https://linearb.io/wp-content/uploads/2020/02/Risky-Work-Annotated-1024x308.png 1024w, https://linearb.io/wp-content/uploads/2020/02/Risky-Work-Annotated-768x231.png 768w" sizes="(max-width: 1531px) 100vw, 1531px">
</picture>
</a></figure>







<p>Instead of saying “customer XYZ really needs the new feature to work so no bugs this time” they can gain confidence that VP of Dev will shift resources to handle risk when there are too many high-risk items open that generate more technical debt.</p>



<p>That’s the goal. To help the CEO and their peers understand how they see their business so they can be a more active participant and so they can start measuring the process of software development, not just the outcome.&nbsp;<br></p>



<p><strong>They meet 1:1 regularly with their peers. </strong>It takes a long time to teach someone to speak a new language. It requires patience and constant practice.&nbsp;</p>



<p>Remember how good you were at speaking French in 12th grade? Then you never used it again and 10 years later you forgot everything you knew.&nbsp;</p>



<p>The best VPs of Dev know they can’t let this happen. They build strong relationships with their peers and use the rapport to constantly reinforce the message.&nbsp;</p>



<p>When they ask only about outcomes like feature delivery deadlines or bugs, great VPs teach them about the world of software development like how to quantify the impact of changing priorities last minute and why devs don’t reply to email quickly.&nbsp;</p>



<p>They also learn from their peers. To be a great partner we have to understand what motivates those teams and what KPIs they care about most.&nbsp;</p>







<p><strong>They start every morning by looking at data</strong> to determine the health of their business. Not just any data. The best VPs start with <a href="https://video.drift.com/v/abjaBqZTqs6/" target="_blank" rel="noreferrer noopener" aria-label="cycle time (opens in a new tab)">cycle time</a> which is the most accurate indicator of process efficiency, then look at the team WIP to validate that the team is not in overload. They also look at other leading indicators like PR pick-up time and PR review time to detect bottlenecks that can affect the team’s current sprint and their performance over time.&nbsp;</p>



<figure><a href="https://linearb.io/wp-content/uploads/2019/12/Screen-Shot-2019-12-02-at-3.42.13-PM.png"><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2019/12/Screen-Shot-2019-12-02-at-3.42.13-PM.png.webp 1544w, https://linearb.io/wp-content/uploads/2019/12/Screen-Shot-2019-12-02-at-3.42.13-PM-300x110.png.webp 300w, https://linearb.io/wp-content/uploads/2019/12/Screen-Shot-2019-12-02-at-3.42.13-PM-768x282.png.webp 768w, https://linearb.io/wp-content/uploads/2019/12/Screen-Shot-2019-12-02-at-3.42.13-PM-1024x375.png.webp 1024w" sizes="(max-width: 1544px) 100vw, 1544px">
<img src="https://linearb.io/wp-content/uploads/2019/12/Screen-Shot-2019-12-02-at-3.42.13-PM.png" alt="" srcset="https://linearb.io/wp-content/uploads/2019/12/Screen-Shot-2019-12-02-at-3.42.13-PM.png 1544w, https://linearb.io/wp-content/uploads/2019/12/Screen-Shot-2019-12-02-at-3.42.13-PM-300x110.png 300w, https://linearb.io/wp-content/uploads/2019/12/Screen-Shot-2019-12-02-at-3.42.13-PM-768x282.png 768w, https://linearb.io/wp-content/uploads/2019/12/Screen-Shot-2019-12-02-at-3.42.13-PM-1024x375.png 1024w" sizes="(max-width: 1544px) 100vw, 1544px">
</picture>
</a></figure>



<p>By using consistent metrics to measure the dev team’s process, they are ensuring the entire team speaks in a consistent …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linearb.io/blog/being-vp-of-software-development-is-harder-than-being-ceo/">https://linearb.io/blog/being-vp-of-software-development-is-harder-than-being-ceo/</a></em></p>]]>
            </description>
            <link>https://linearb.io/blog/being-vp-of-software-development-is-harder-than-being-ceo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24434042</guid>
            <pubDate>Thu, 10 Sep 2020 16:47:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intercepting Zoom's encrypted data with BPF]]>
            </title>
            <description>
<![CDATA[
Score 256 | Comments 65 (<a href="https://news.ycombinator.com/item?id=24434031">thread link</a>) | @aaron-santos
<br/>
September 10, 2020 | https://confused.ai/posts/intercepting-zoom-tls-encryption-bpf-uprobes | <a href="https://web.archive.org/web/*/https://confused.ai/posts/intercepting-zoom-tls-encryption-bpf-uprobes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I originally wrote an earlier version of this post at the end of March, when I was working on adding uprobes support to <a href="https://github.com/redsift/redbpf">redbpf</a>. I wanted to blog about the work I was doing and needed an application to instrument for the purpose of this post. At that time Zoom's popularity was rising quickly, and I happened to read somewhere that it supported this creepy attention tracking feature that allowed meeting hosts to monitor if attendees were paying attention. I figured I could try to use uprobes to snoop into the data Zoom was sending to their servers and see how the tracking worked.</p><p>But then Zoom quickly started getting under a lot of fire. <a href="https://en.wikipedia.org/wiki/Zoombombing">Zoombombing</a> became a thing, several security issues were discovered and pretty much everyone started piling on the company. Considering all that, I was advised and ultimately decided not to publish the post.</p><p>Now things seem to have settled, Zoom <a href="https://blog.zoom.us/a-message-to-our-users/">improved their security</a> and by popular demand <a href="https://support.zoom.us/hc/en-us/articles/115000538083-Attendee-attention-tracking">got rid of attention tracking</a>. So I think I can finally publish this! I edited out the part about attention tracking (which no longer exists) and a couple of other things that could potentially get me in trouble.</p><p><strong>TLDR:</strong> I wrote a command line tool that uses BPF uprobes to intercept the TLS encrypted data that zoom sends over the network, and here I'm going to show the process I went through to write it. After I wrote this post I made the tool generic so that it can now instrument any program that uses OpenSSL. I published the code at <a href="https://github.com/alessandrod/snuffy">https://github.com/alessandrod/snuffy</a>.</p><h2>Instrumenting applications with uprobes</h2><p>Uprobes let you instrument user space applications by attaching custom code to arbitrary locations inside a target process. It's a bit like running an application in a debugger, setting breakpoints and fiddling around, but programmatically and without the overhead of a debugger.</p><p>An uprobe must be <a href="https://ingraind.org/api/cargo_bpf/#building">compiled</a> and <a href="https://ingraind.org/api/redbpf/load/struct.Loader.html">loaded</a> like any other BPF program, then it can be attached with the following API:</p><pre><code><span>pub</span><span> </span><span>fn</span><span> </span><span>attach_uprobe</span><span>(</span><span>
</span><span>    </span><span>&amp;</span><span>mut</span><span> </span><span>self</span><span>,</span><span>
</span><span>    fn_name</span><span>:</span><span> </span><span>Option</span><span>&lt;</span><span>&amp;</span><span>str</span><span>&gt;</span><span>,</span><span>
</span><span>    offset</span><span>:</span><span> </span><span>u64</span><span>,</span><span>
</span><span>    target</span><span>:</span><span> </span><span>&amp;</span><span>str</span><span>,</span><span>
</span><span>    pid</span><span>:</span><span> </span><span>Option</span><span>&lt;</span><span>pid_t</span><span>&gt;</span><span>,</span><span>
</span><span></span><span>)</span><span> </span><span>-&gt;</span><span> </span><span>Result</span><span>&lt;</span><span>(</span><span>)</span><span>&gt;</span><span>;</span></code></pre><p><a href="https://ingraind.org/api/redbpf/struct.UProbe.html#method.attach_uprobe">attach_uprobe()</a> parses the <code>target</code> ELF binary or shared library, looks up the function <code>fn_name</code>, and once the target is running it injects the probe code at the resolved address. If <code>offset</code> is non-zero, its value is added to the address of <code>fn_name</code>. If <code>fn_name</code> is <code>None</code>, then <code>offset</code> is interpreted as starting from the beginning of the target's <code>.text</code> section. Finally if a <code>pid</code> is given, the probe will only be attached to the process with the given id.</p><p>In the rest of the post I'm going to show some examples of uprobes, focusing on the code that gets compiled to BPF bytecode, loaded in the kernel and then injected in the target process (in our case zoom). I'm not going to show much of the user-space code that loads the probes. That part is pretty standard rust code that does some setup, then prints out the data coming from the probes as it receives it. If you're interested you can still find all the user-space code at <a href="https://github.com/alessandrod/snuffy/blob/master/src/main.rs">https://github.com/alessandrod/snuffy/blob/master/src/main.rs</a>.</p><h2>Poking into Zoom</h2><p>We're going to use uprobes to inspect the network traffic between the zoom client and the company's servers. Zoom uses <a href="https://en.wikipedia.org/wiki/Transport_Layer_Security">Transport Layer Security</a> to encrypt the data. In order to intercept the <em>unencrypted</em> data, we need to find out which TLS library is used by the client, then attach uprobes to strategic places inside it.</p><p>Let's start with searching for common TLS symbols using <code>objdump</code>:</p><pre><code><span>$ objdump -CT /opt/zoom/zoom | grep -iE "ssl|gnutls"
</span>000000000080d5b0 g    DF .text	0000000000000013  Base        PreMeetingUIMgr::sig_blockUnknownSSLCertChanged()
<!-- -->000000000080d590 g    DF .text	0000000000000013  Base        PreMeetingUIMgr::sig_sslCertWarningChanged()
</code></pre><p>Those look like callbacks that get invoked when a certificate is invalid, and Zoom does indeed show a warning if you try to intercept its traffic with a tool like <code>mitmproxy</code>. The callbacks deal with certificates, not unencrypted buffers, so they are not useful to us.</p><p>Looking at the output of <code>ldd</code> we can see that Zoom links to <a href="https://doc.qt.io/qt-5/qtnetwork-index.html">Qt Network</a>, which includes some potentially relevant APIs:</p><pre><code><span>$ objdump -CT /opt/zoom/zoom | grep -iE "QNetworkReq"
</span>0000000000000000      DF *UND*	0000000000000000  Qt_5        QNetworkRequest::QNetworkRequest(QUrl const&amp;)
<!-- -->0000000000000000      DF *UND*	0000000000000000  Qt_5        QNetworkRequest::~QNetworkRequest()
<!-- -->0000000000000000      DF *UND*	0000000000000000  Qt_5        QNetworkAccessManager::get(QNetworkRequest const&amp;)
</code></pre><p><code>QNetworkRequest(QUrl const&amp;)</code> looks like something that could be used to communicate with the backend and does <a href="https://doc.qt.io/qt-5/qnetworkrequest.html#setSslConfiguration">support TLS</a>. I tried attaching to it and other functions exported by the framework but none of them turned out to be invoked. Zoom supports a number of platforms and devices, it's possible that they use Qt just for the UI on linux, and then have some lower level networking code that can be shared with their other clients.</p><p>At this point it is pretty likely that zoom is linking statically to the TLS library. Let's see if in the <code>.rodata</code> section of the binary there's anything that could point us in the right direction:</p><pre><code><span>$ readelf -p .rodata /opt/zoom/zoom | grep -i ssl | wc -l
</span>739
<!-- -->$ # 😏
<!-- -->$ readelf -p .rodata /opt/zoom/zoom | grep -i 'openssl 1'
<!-- -->  [4a1b66]  OpenSSL 1.1.1g  21 Apr 2020
<!-- -->  [58cd50]  OpenSSL 1.1.1g  21 Apr 2020
</code></pre><p>Aha! The client is using OpenSSL version 1.1.1g (knowing this will turn out to be very useful), and the library is statically linked.</p><h2>Instrumenting OpenSSL</h2><p>OpenSSL exports two functions named <a href="https://www.openssl.org/docs/man1.1.1/man3/SSL_read.html">SSL_read</a> and <a href="https://www.openssl.org/docs/man1.1.1/man3/SSL_write.html">SSL_write</a>, which have the following signature:</p><pre><code><span>int</span><span> </span><span>SSL_read</span><span>(</span><span>SSL </span><span>*</span><span>ssl</span><span>,</span><span> </span><span>void</span><span> </span><span>*</span><span>buf</span><span>,</span><span> </span><span>int</span><span> num</span><span>)</span><span>;</span><span>
</span><span></span><span>int</span><span> </span><span>SSL_write</span><span>(</span><span>SSL </span><span>*</span><span>ssl</span><span>,</span><span> </span><span>const</span><span> </span><span>void</span><span> </span><span>*</span><span>buf</span><span>,</span><span> </span><span>int</span><span> num</span><span>)</span><span>;</span></code></pre><p><code>SSL_read</code> reads encrypted data sent by a remote peer, decrypts it and stores the decrypted data in the provided buffer. <code>SSL_write</code> encrypts the given buffer and sends it to a remote peer. Attaching an uprobe where <code>SSL_read</code> <em>returns</em>, and one at the <em>entry</em> of <code>SSL_write</code>, we can therefore access unencrypted memory.</p><p>Here's the uprobes that do just that:</p><pre><code><span>use</span><span> </span><span>redbpf_probes</span><span>::</span><span>uprobe</span><span>::</span><span>prelude</span><span>::</span><span>*</span><span>;</span><span>
</span>
<span></span><span>struct</span><span> </span><span>SSLArgs</span><span> </span><span>{</span><span>
</span><span>    ssl</span><span>:</span><span> </span><span>usize</span><span>,</span><span>
</span><span>    buf</span><span>:</span><span> </span><span>usize</span><span>,</span><span>
</span><span></span><span>}</span><span>
</span>
<span></span><span>// temporary storage map</span><span>
</span><span></span><span>static</span><span> </span><span>mut</span><span> ssl_args</span><span>:</span><span> </span><span>HashMap</span><span>&lt;</span><span>u64</span><span>,</span><span> </span><span>SSLArgs</span><span>&gt;</span><span> </span><span>=</span><span> </span><span>HashMap</span><span>::</span><span>with_max_entries</span><span>(</span><span>1024</span><span>)</span><span>;</span><span>
</span>
<span></span><span>fn</span><span> </span><span>output_buf</span><span>(</span><span>regs</span><span>:</span><span> </span><span>Registers</span><span>,</span><span> mode</span><span>:</span><span> </span><span>AccessMode</span><span>,</span><span> buf_addr</span><span>:</span><span> </span><span>usize</span><span>,</span><span> len</span><span>:</span><span> </span><span>usize</span><span>)</span><span> </span><span>{</span><span>
</span><span>  </span><span>// Ignore how this is implemented for now. Assume it reads `len` bytes from `buf_addr`</span><span>
</span><span>  </span><span>// and sends them to our user-space process where they are hex-dumped.</span><span>
</span><span>  </span><span>...</span><span>
</span><span></span><span>}</span><span>
</span>
<span></span><span>#[uprobe]</span><span>
</span><span></span><span>fn</span><span> </span><span>SSL_write_entry</span><span>(</span><span>regs</span><span>:</span><span> </span><span>Registers</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>let</span><span> ssl </span><span>=</span><span> regs</span><span>.</span><span>parm1</span><span>(</span><span>)</span><span> </span><span>as</span><span> </span><span>usize</span><span>;</span><span>
</span><span>    </span><span>let</span><span> buf </span><span>=</span><span> regs</span><span>.</span><span>parm2</span><span>(</span><span>)</span><span> </span><span>as</span><span> </span><span>usize</span><span>;</span><span>
</span><span>    </span><span>let</span><span> num </span><span>=</span><span> regs</span><span>.</span><span>parm3</span><span>(</span><span>)</span><span> </span><span>as</span><span> </span><span>i32</span><span>;</span><span>
</span><span>    </span><span>if</span><span> num </span><span>&lt;=</span><span> </span><span>0</span><span> </span><span>{</span><span>
</span><span>        </span><span>return</span><span>;</span><span>
</span><span>    </span><span>}</span><span>
</span>
<span>    </span><span>// This is where SSL_write begins, the buffer isn't encrypted yet</span><span>
</span><span>    </span><span>// so we send it to user-space</span><span>
</span><span>    </span><span>output_buf</span><span>(</span><span>regs</span><span>,</span><span> </span><span>AccessMode</span><span>::</span><span>Write</span><span>,</span><span> buf</span><span>,</span><span> num </span><span>as</span><span> </span><span>usize</span><span>)</span><span>;</span><span>
</span><span></span><span>}</span><span>
</span>
<span></span><span>#[uprobe]</span><span>
</span><span></span><span>fn</span><span> </span><span>SSL_read_entry</span><span>(</span><span>regs</span><span>:</span><span> </span><span>Registers</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>let</span><span> ssl </span><span>=</span><span> regs</span><span>.</span><span>parm1</span><span>(</span><span>)</span><span> </span><span>as</span><span> </span><span>usize</span><span>;</span><span>
</span><span>    </span><span>let</span><span> buf </span><span>=</span><span> regs</span><span>.</span><span>parm2</span><span>(</span><span>)</span><span> </span><span>as</span><span> </span><span>usize</span><span>;</span><span>
</span>
<span>    </span><span>// store the function arguments so we can retrieve them once the</span><span>
</span><span>    </span><span>// function returns</span><span>
</span><span>    </span><span>unsafe</span><span> </span><span>{</span><span>
</span><span>        ssl_args</span><span>.</span><span>set</span><span>(</span><span>&amp;</span><span>bpf_get_current_pid_tgid</span><span>(</span><span>)</span><span>,</span><span> </span><span>&amp;</span><span>SSLArgs</span><span> </span><span>{</span><span> ssl</span><span>,</span><span> buf </span><span>}</span><span>)</span><span>;</span><span>
</span><span>    </span><span>}</span><span>
</span><span></span><span>}</span><span>
</span>
<span></span><span>#[uretprobe]</span><span>
</span><span></span><span>fn</span><span> </span><span>SSL_read_ret</span><span>(</span><span>regs</span><span>:</span><span> </span><span>Registers</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>// the return value of SSL_read contains the length of the buffer</span><span>
</span><span>    </span><span>let</span><span> num </span><span>=</span><span> regs</span><span>.</span><span>rc</span><span>(</span><span>)</span><span> </span><span>as</span><span> </span><span>i32</span><span>;</span><span>
</span><span>    </span><span>if</span><span> num </span><span>&lt;</span><span> </span><span>0</span><span> </span><span>{</span><span>
</span><span>        </span><span>return</span><span>;</span><span>
</span><span>    </span><span>}</span><span>
</span><span>    </span><span>// This is where SSL_read returns, the buffer is now decrypted</span><span>
</span><span>    </span><span>// so we send it to user-space</span><span>
</span><span>    </span><span>let</span><span> tgid </span><span>=</span><span> </span><span>bpf_get_current_pid_tgid</span><span>(</span><span>)</span><span>;</span><span>
</span><span>    </span><span>let</span><span> args </span><span>=</span><span> </span><span>unsafe</span><span> </span><span>{</span><span> ssl_args</span><span>.</span><span>get</span><span>(</span><span>&amp;</span><span>tgid</span><span>)</span><span> </span><span>}</span><span>;</span><span>
</span><span>    </span><span>if</span><span> </span><span>let</span><span> </span><span>Some</span><span>(</span><span>SSLArgs</span><span> </span><span>{</span><span> ssl</span><span>,</span><span> buf </span><span>}</span><span>)</span><span> </span><span>=</span><span> args </span><span>{</span><span>
</span><span>        </span><span>output_buf</span><span>(</span><span>regs</span><span>,</span><span> </span><span>AccessMode</span><span>::</span><span>Read</span><span>,</span><span> </span><span>*</span><span>buf</span><span>,</span><span> num </span><span>as</span><span> </span><span>usize</span><span>)</span><span>;</span><span>
</span><span>        </span><span>unsafe</span><span> </span><span>{</span><span> ssl_args</span><span>.</span><span>delete</span><span>(</span><span>&amp;</span><span>tgid</span><span>)</span><span> </span><span>}</span><span>;</span><span>
</span><span>    </span><span>}</span><span>
</span><span></span><span>}</span></code></pre><p>Uprobes are annotated with the <a href="https://ingraind.org/api/redbpf_probes/uprobe/prelude/attr.uprobe.html">#[uprobe]</a> attribute. Once they are triggered, they get passed a <a href="https://ingraind.org/api/redbpf_probes/kprobe/struct.Registers.html">Registers</a> argument through which they can access memory.</p><p>The <code>SSL_write_entry</code> probe is the simplest. It reads the registers containing the values of the <code>buf</code> and <code>num</code> arguments passed to <code>SSL_write</code>, and sends a copy of the buffer to user-space before it gets encrypted.</p><p>The <code>SSL_read_entry</code> probe is similar in that it reads the content of the <code>ssl</code>, <code>buf</code> and <code>num</code> arguments passed to <code>SSL_read</code>. It doesn't send the buffer to user-space though. Remember the data is decrypted <em>after</em> <code>SSL_read</code> returns, so we need a second uprobe that we attach to the <em>return address</em> of the function. That's what <code>SSL_read_ret</code> is for. It's similar to the other two probes, but is annotated with <a href="https://ingraind.org/api/redbpf_probes/uprobe/prelude/attr.uretprobe.html">#[uretprobe]</a>, which means that it will trigger once the function it's attached to <em>returns</em>.</p><p>But why do we need two probes for <code>SSL_read</code>, why not just have <code>SSL_read_ret</code>? The answer is that when <code>SSL_read</code> returns, it's likely that the registers that used to contain the function arguments were modified, so we need to read their values at the start of the function and store them so we can retrieve them later. This is a very common pattern when writing BPF code.</p><p>Finally if zoom linked to OpenSSL dynamically or if debugging symbols were present, the user-space code to attach the probes would be as simple as:</p><pre><code><span>use</span><span> </span><span>redbpf</span><span>::</span><span>load</span><span>::</span><span>Loader</span><span>;</span><span>
</span>
<span></span><span>let</span><span> </span><span>mut</span><span> loader </span><span>=</span><span> </span><span>Loader</span><span>::</span><span>load_file</span><span>(</span><span>COMPILED_BPF_BINARY</span><span>)</span><span>?</span><span>;</span><span>
</span><span></span><span>let</span><span> pid </span><span>=</span><span> </span><span>None</span><span>;</span><span>
</span><span></span><span>for</span><span> uprobe </span><span>in</span><span> loader</span><span>.</span><span>uprobes_mut</span><span>(</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>// Attach to SSL_read and SSL_write inside libssl.</span><span>
</span><span>    </span><span>// Let redbpf resolve the symbol addresses.</span><span>
</span><span>    </span><span>match</span><span> uprobe</span><span>.</span><span>name</span><span>(</span><span>)</span><span>.</span><span>as_str</span><span>(</span><span>)</span><span> </span><span>{</span><span>
</span><span>        </span><span>"SSL_read_entry"</span><span> </span><span>|</span><span> </span><span>"SSL_read_ret"</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span>
</span><span>            uprobe</span><span>.</span><span>attach_uprobe</span><span>(</span><span>Some</span><span>(</span><span>"SSL_read"</span><span>)</span><span>,</span><span> </span><span>0</span><span>,</span><span> </span><span>"libssl"</span><span>,</span><span> pid</span><span>)</span><span>?</span><span>;</span><span>
</span><span>        </span><span>}</span><span>
</span><span>        </span><span>"SSL_write_entry"</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span>
</span><span>            uprobe</span><span>.</span><span>attach_uprobe</span><span>(</span><span>Some</span><span>(</span><span>"SSL_write"</span><span>)</span><span>,</span><span> </span><span>0</span><span>,</span><span> </span><span>"libssl"</span><span>,</span><span> pid</span><span>)</span><span>?</span><span>;</span><span>
</span><span>        </span><span>}</span><span>
</span><span>        _ </span><span>=&gt;</span><span> </span><span>continue</span><span>,</span><span>
</span><span>    </span><span>}</span><span>
</span><span></span><span>}</span></code></pre><p>Unfortunately since OpenSSL is statically linked and the symbols have been stripped, redbpf can't automatically resolve the addresses of <code>SSL_read</code> and <code>SSL_write</code>, instead we have to explicitly provide the offsets we want to attach to:</p><pre><code><span>use</span><span> </span><span>redbpf</span><span>::</span><span>load</span><span>::</span><span>Loader</span><span>;</span><span>
</span>
<span></span><span>let</span><span> </span><span>mut</span><span> loader </span><span>=</span><span> </span><span>Loader</span><span>::</span><span>load_file</span><span>(</span><span>COMPILED_BPF_BINARY</span><span>)</span><span>?</span><span>;</span><span>
</span><span></span><span>let</span><span> pid </span><span>=</span><span> </span><span>None</span><span>;</span><span>
</span><span></span><span>for</span><span> uprobe </span><span>in</span><span> loader</span><span>.</span><span>uprobes_mut</span><span>(</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>let</span><span> zoom_binary </span><span>=</span><span> </span><span>"/opt/zoom/zoom"</span><span>;</span><span>
</span><span>    </span><span>// …</span></code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://confused.ai/posts/intercepting-zoom-tls-encryption-bpf-uprobes">https://confused.ai/posts/intercepting-zoom-tls-encryption-bpf-uprobes</a></em></p>]]>
            </description>
            <link>https://confused.ai/posts/intercepting-zoom-tls-encryption-bpf-uprobes</link>
            <guid isPermaLink="false">hacker-news-small-sites-24434031</guid>
            <pubDate>Thu, 10 Sep 2020 16:46:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Russia publishes its Remote Online Voting system on GitHub]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24434026">thread link</a>) | @vvpvijay
<br/>
September 10, 2020 | https://androidrookies.com/russia-publishes-its-remote-online-voting-system-on-github/ | <a href="https://web.archive.org/web/*/https://androidrookies.com/russia-publishes-its-remote-online-voting-system-on-github/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-10870"><div><div><div><h2>Russian ISP, Rostelecom has put the source code of Russia’s Remote Online Voting software on GitHub to get hackers and researchers find bugs in it</h2><p>This may be one of the firsts. Russian Internet service provider, Rostelecom has published the source code of Russian Remote Online Voting software on its GitHub page so that hackers and security researchers can find vulnerabilities and bugs in it.</p><p>The Rostelecom’s move comes after widespread criticism of the Russian remote online voting software. Many Russians participating in the recently held remote voting had complained that the software had many bugs. Some even said that the Russian online voting platform could be easily hacked.</p><p>To help find bugs and other vulnerabilities,&nbsp;Rostelecom has published the source code on <strong><a href="https://github.com/cikrf">GitHub here</a>.&nbsp;</strong>According to Alexander Malkevich from the Public House of the Russian Federation, the publication of the source code was necessitated due to the many concerns by users during the recently held remote elections. “We want to solve some problems at once; First of all, we hope that researchers will help us fix potential vulnerabilities,” Malkevich says.</p><p>The source code of Russian online voting software contains three main components:</p><ul><li>Counting servers</li><li>Smart contracts</li><li>Portal front end (including front-end libraries)</li></ul><p>Hackers and security researchers may be especially interested in taking a look at the code as the entire voting software is based on blockchain technology. Russian government implemented the blockchain technology because it was tamperproof and had data integrity. &nbsp;“Blockchain technology solves some problems; its main task is to ensure the invariability of information, ensuring the information of each vote, voter lists, encryption keys, and other key aspects,” Malkevich reports.</p><p>The remote online voting works by allowing only those Russian voters who have already registered to vote. There is a time limit within which these previously registered voters can vote. Using the blockchain technology, the Russian Federation seeks to ensure confidentiality in the electoral process and to maintain social distancing measures during the coronavirus pandemic.&nbsp;For election observers, the Russian Federation also developed a special tool that allows them to monitor all transactions on the blockchain network in realtime much like how bitcoins move between wallets.</p><p>If you want to take a look at how the Russian remote voting system works, head over to Rostelecom GitHub page <a href="https://github.com/cikrf">here</a>. Kindly note that the GitHub page is in Russian.</p></div></div></div></article></div>]]>
            </description>
            <link>https://androidrookies.com/russia-publishes-its-remote-online-voting-system-on-github/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24434026</guid>
            <pubDate>Thu, 10 Sep 2020 16:46:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why RudderStack Used Postgres over Apache Kafka for It's Streaming Engine]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24433730">thread link</a>) | @soumyadeb
<br/>
September 10, 2020 | https://rudderstack.com/blog/why-rudderstack-used-postgres-over-apache-kafka-for-streaming-engine/ | <a href="https://web.archive.org/web/*/https://rudderstack.com/blog/why-rudderstack-used-postgres-over-apache-kafka-for-streaming-engine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content"><div><article><figure> <img src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.header1.png"></figure><section><div><h2><strong>Overview</strong></h2><p>In this post, we answer the all-important question – “Why we did not prefer Apache Kafka over PostgreSQL for building RudderStack”. We discuss some of the challenges with using Apache Kafka over our implemented solution that uses PostgreSQL.</p><h2><strong>RudderStack is a Queue</strong></h2><p>At its core, RudderStack is a queuing system. It gets events from multiple sources, persists them, and then sends them to different destinations. Persisting the events is crucial because RudderStack needs to be able to handle different kinds of failures.&nbsp;</p><p>Let’s consider an example here – a destination could be down for any length of time due to some reason. In such a scenario, RudderStack should ideally retain the events and then retry sending the events when that destination is functional once again.</p><div><figure><img src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.1-1024x312.png" alt="RudderStack - An Event Queue" srcset="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.1-980x298.png 980w, https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.1-480x146.png 480w" sizes="((min-width: 0px) and (max-width: 480px)) 480px, ((min-width: 481px) and (max-width: 980px)) 980px, (min-width: 981px) 1024px, 100vw" data-old-src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.1-1024x312.png" data-srcset="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.1-980x298.png 980w, https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.1-480x146.png 480w"><figcaption>RudderStack – An Event Queue</figcaption></figure></div><p>Naturally, a popular choice of tool for building such a queuing solution would be Apache Kafka. Kafka provides features such as persistence, ordering, de-duping, extreme performance, horizontal scalability, etc. that any queuing system would need.&nbsp;</p><p>A simple Kafka-based system looks something like this:</p><div><figure><img src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.2-1024x269.png" alt="A Simple Kafka-Based System" srcset="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.2-980x257.png 980w, https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.2-480x126.png 480w" sizes="((min-width: 0px) and (max-width: 480px)) 480px, ((min-width: 481px) and (max-width: 980px)) 980px, (min-width: 981px) 1024px, 100vw" data-old-src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.2-1024x269.png" data-srcset="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.2-980x257.png 980w, https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.2-480x126.png 480w"><figcaption>A Simple Kafka-Based System</figcaption></figure></div><p>In our queueing system, we would need to create a separate topic per destination. Events from the sources can be queued into destination-specific topics, while one consumer consumes events from the destination topics. The consumer itself might be spreading the work of sending events across multiple threads for parallelization.&nbsp;</p><p>A separate topic per destination is ideal because if a specific destination is unavailable (e.g., downtime), we do not want to block the events for other destinations. However, as we will see in the next section, failures can be of other types too, leading to complications with this setup.</p><p>While this architecture looks simple enough, Apache Kafka comes with its own set of challenges, which we will focus on in the following sections.</p><h2><strong>Management Challenges</strong></h2><p>Apache Kafka is not the easiest product to deploy and distribute. Moreover, its dependency on Apache Zookeeper – a distributed configuration and synchronization service – makes it quite a <a href="https://medium.com/@anuradha.neo/kafka-is-not-the-best-anymore-meet-pulsar-9eb435c9fc0b">management challenge</a>.</p><p>We did not want to ship and support a product in which we were not experts ourselves.</p><h2><strong>Licensing Issues</strong></h2><p>Licensing was another issue with Apache Kafka. We wanted to release the entire code under an open-source license (AGPLv3). However, the core of Apache Kafka managed by the Apache Foundation is released under the <a href="https://www.apache.org/licenses/LICENSE-2.0">Apache-2 license</a>. In addition, the version actively managed by Confluent is only available under a non-OSI license (Confluent Community License).&nbsp;</p><p>Some specific Kafka features like kSQL (which is very useful for debugging jobs) are not available under the Apache License.</p><p>One of the key features for the queueing system we built was the ability to peek into the pending events, and update their state, i.e. set their failure state to retry. Implementing this was not possible with an OSS license.</p><h2><strong>Handling Multiple Customers</strong></h2><p>In our hosted, multi-tenant offering, we have multiple customers on the same RudderStack instance. While they can use the same architecture as above with a topic per destination, it can lead to a situation where a large flurry of events from one customer blocks events coming from another customer, as shown in the diagram below:&nbsp;</p><div><figure><img src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.3-1024x247.png" alt="Events From Multiple Customers" srcset="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.3-980x236.png 980w, https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.3-480x116.png 480w" sizes="((min-width: 0px) and (max-width: 480px)) 480px, ((min-width: 481px) and (max-width: 980px)) 980px, (min-width: 981px) 1024px, 100vw" data-old-src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.3-1024x247.png" data-srcset="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.3-980x236.png 980w, https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.3-480x116.png 480w"><figcaption>Events From Multiple Customers</figcaption></figure></div><p>Ideally, we would want to keep the customers separate so that we can provide the per-customer QoS guarantees.</p><p>The way to do this is to create a separate Kafka topic per destination/customer combination. Unfortunately, Kafka doesn’t scale well with the number of topics. This would eventually become a hindrance our customer-base grows. Our friends at Segment faced a similar issue and wrote a <a href="https://segment.com/blog/introducing-centrifuge/">blog about it</a>.</p><h2><strong>Error Handling</strong></h2><p>Error handling becomes complex with the data in Kafka. If an event fails to deliver, we wanted to adopt the following workflow:</p><ul><li>Record some metadata like the error code, the number of times it has failed, etc.</li><li>Put it back on top of the queue for subsequent retrying.</li><li>Block further events from that user to preserve the order till the event is successfully delivered (or it is aborted).<br></li></ul><p>The following diagram shows an example of a ‘logical’ state of the system at any point:</p><div><figure><img src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.4-1024x247.png" alt="A Logical State of the System" srcset="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.4-980x236.png 980w, https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.4-480x116.png 480w" sizes="((min-width: 0px) and (max-width: 480px)) 480px, ((min-width: 481px) and (max-width: 980px)) 980px, (min-width: 981px) 1024px, 100vw" data-old-src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.4-1024x247.png" data-srcset="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.4-980x236.png 980w, https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.4-480x116.png 480w"><figcaption>A Logical State of the System</figcaption></figure></div><p>Event #1 has failed and must be retried. Along with the event, we also want to keep track of the number of times it was retried, the failure error code, etc. Event #3 is from the same end-user, so it cannot be sent until Event #1 succeeds or aborts. However, Event #2 is unrelated and should be processed and succeeded.</p><p>As seen in the figure above, the queue is processing the events and marking them as succeeded (S), failed (F), or waiting (W). A separate process (or a sweep of the main process) can start from the top. The queue is always in a consistent state, so if there is a crash, we can always start from the top.</p><p>Unfortunately, it is not trivial to implement the above logical semantics using Apache Kafka. Kafka does not allow the events to be updated, so we cannot mark the top event as failed, or associate any metadata with it.&nbsp;</p><p>Removing the event and queueing it back (at the end) doesn’t work either, as this will break the ordering constraints – event #3 will end up before event #1, as seen in the example above.&nbsp;</p><h3>Use of Two Queues</h3><p>Another solution is to use two queues – the main queue and a failed queue. The failed jobs and the skipped jobs (from the same user ID) from the main queue can be put in the failed queue. This is demonstrated in the following diagram:</p><div><figure><img src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.5-1024x471.png" alt="Use of Two Queues" width="580" height="266" srcset="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.5-980x451.png 980w, https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.5-480x221.png 480w" sizes="((min-width: 0px) and (max-width: 480px)) 480px, ((min-width: 481px) and (max-width: 980px)) 980px, 100vw" data-old-src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.5-1024x471.png" data-srcset="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.5-980x451.png 980w, https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.5-480x221.png 480w"><figcaption>Use of Two Queues</figcaption></figure></div><p>The issue with this approach is that this only works for the first failure. How do we handle the failures occurring in the Fail Queue? We still have to update the metadata and re-queue the event, so we will need a second fail queue to store failed events from the 1st fail queue.&nbsp;</p><p>We want to retry events a few dozen times before expiring the event, so this is not a great solution as well.</p><h2><strong>Debuggability</strong></h2><p>Being able to query the events as they wait in the queue and/or update the metadata (around failures) to force immediate retrying is a great debugging feature that we were building at RudderStack. Having a SQL-like query interface to the persisted event helped a lot with that.</p><p>While Kafka’s kSQL provides the query interface, it does not allow for updates. Furthermore, there are licensing issues with kSQL, as we noted earlier.</p><h2><strong>In Conclusion</strong></h2><p>In this post, we looked at some of the reasons why we decided to build our own queuing library, instead of adopting a Kafka-based solution. We will write a blog about the implementation but if you are curious, you can explore the implementation on <a href="https://github.com/rudderlabs/rudder-server">GitHub</a></p><p>With our queueing system powered by PostgreSQL, we could easily change the logic for ordering the events as well as debugging them. In addition, we had complete visibility over all the events coming from a source, user or a destination just by running a SQL query – something that was not possible with Apache Kafka.</p><p>To know more about RudderStack and its features, check out our <a href="https://rudderstack.com/">website</a>. You can also track our progress on <a href="https://github.com/rudderlabs/rudder-server">GitHub</a>.&nbsp;</p></div></section></article></div></div></div>]]>
            </description>
            <link>https://rudderstack.com/blog/why-rudderstack-used-postgres-over-apache-kafka-for-streaming-engine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24433730</guid>
            <pubDate>Thu, 10 Sep 2020 16:20:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Product Management – Getting Started in a Safe-Ish World]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24433649">thread link</a>) | @mooreds
<br/>
September 10, 2020 | https://www.elevate.to/blog/2020/09/08/product-management-getting-started/ | <a href="https://web.archive.org/web/*/https://www.elevate.to/blog/2020/09/08/product-management-getting-started/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>When you’ve been asked to take on an agile product management role as part of a business agility transformation leveraging the Scaled Agile Framework®, you will need information on two topics: great product management and how the product manager role operates in SAFe®.</p>



<p>As a product manager, you are responsible for rather a lot: the strategy, roadmaps, feature definition, and advocacy for a customer solution or product. Great product management results in the creation and evolution of products that delight your customers!</p>



<p>Because of that, you’ll need to quickly come up to speed on a variety of topics. These short lists provide a great way to get started.</p>



<p><strong>Review these relatively-quick videos and articles for a tactical, practical start:</strong></p>



<ol><li>Watch <a rel="noreferrer noopener" href="https://www.youtube.com/watch?v=aW2m-BtCJyE" target="_blank">SAFe in 5 minutes</a>. </li><li>Read the <a rel="noreferrer noopener" href="https://www.scaledagileframework.com/product-and-solution-management/" target="_blank" data-type="URL" data-id="https://www.scaledagileframework.com/product-and-solution-management/">Product and Solution Management</a> article on the Scaled Agile Framework site. </li><li>Read more about <a rel="noreferrer noopener" href="https://www.scaledagileframework.com/program-and-solution-backlogs/" target="_blank" data-type="URL" data-id="https://www.scaledagileframework.com/program-and-solution-backlogs/">SAFe Program and Solution Backlogs</a>. </li><li>Read this SAFe article on <a rel="noreferrer noopener" href="https://www.scaledagileframework.com/design-thinking/" data-type="URL" data-id="https://www.scaledagileframework.com/design-thinking/" target="_blank">Design Thinking</a> (and more). </li><li>Watch <a rel="noreferrer noopener" href="https://www.youtube.com/watch?v=Stc0beAxavY" data-type="URL" data-id="https://www.youtube.com/watch?v=Stc0beAxavY" target="_blank">Clayton Christensen talk about jobs to be done</a> (JTBD) and milkshakes. </li><li>Read this SAFe article on <a rel="noreferrer noopener" href="https://www.scaledagileframework.com/lean-budgets/" data-type="URL" data-id="https://www.scaledagileframework.com/lean-budgets/" target="_blank">Lean Budgets and Investment Horizons</a>. </li></ol>



<p><strong>Then, read these books—as you’re practicing—for deeper knowledge:</strong></p>



<ol><li><a rel="noreferrer noopener" href="https://smile.amazon.com/This-Lean-Resolving-Efficiency-Paradox/dp/919803930X/ref=sr_1_1" type="URL" id="https://smile.amazon.com/This-Lean-Resolving-Efficiency-Paradox/dp/919803930X/ref=sr_1_1" target="_blank">This is Lean</a>, Niklas Modig &amp; Par Ahlstrom </li><li><a rel="noreferrer noopener" href="https://smile.amazon.com/Escape-Velocity-Free-Companys-Future/dp/0062040898/ref=sr_1_1" data-type="URL" data-id="https://smile.amazon.com/Escape-Velocity-Free-Companys-Future/dp/0062040898/ref=sr_1_1" target="_blank">Escape Velocity</a>, Geoffrey Moore</li><li><a rel="noreferrer noopener" href="https://smile.amazon.com/Running-Lean-Iterate-Plan-Works-dp-9350238047/dp/9350238047/ref=mt_other" type="URL" id="https://smile.amazon.com/Running-Lean-Iterate-Plan-Works-dp-9350238047/dp/9350238047/ref=mt_other" target="_blank">Running Lean</a>, Ash Maurya</li><li><a rel="noreferrer noopener" href="https://smile.amazon.com/Badass-Making-Awesome-Kathy-Sierra/dp/1491919019/ref=sr_1_1" target="_blank">Badass: Making Users Awesome</a>, Kathy Sierra</li><li><a rel="noreferrer noopener" href="https://smile.amazon.com/Anthony-Ulwick/dp/0071408673/ref=sr_1_1" data-type="URL" data-id="https://smile.amazon.com/Anthony-Ulwick/dp/0071408673/ref=sr_1_1" target="_blank">What Customers Want</a>, Anthony Ulwick</li><li><a href="https://smile.amazon.com/Value-Stream-Mapping-Organizational-Transformation/dp/0071828915/ref=sr_1_1" type="URL" id="https://smile.amazon.com/Value-Stream-Mapping-Organizational-Transformation/dp/0071828915/ref=sr_1_1" target="_blank" rel="noreferrer noopener">Value Stream Mapping</a>, Karen Martin and Mike Osterling </li></ol>



<p>We would love to hear from you–what is helping you get started on your product management journey?</p>
</div></div>]]>
            </description>
            <link>https://www.elevate.to/blog/2020/09/08/product-management-getting-started/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24433649</guid>
            <pubDate>Thu, 10 Sep 2020 16:12:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop Watching YouTube]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24433620">thread link</a>) | @patwalls
<br/>
September 10, 2020 | https://patwalls.com/stop-watching-youtube | <a href="https://web.archive.org/web/*/https://patwalls.com/stop-watching-youtube">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://patwalls.com/stop-watching-youtube</link>
            <guid isPermaLink="false">hacker-news-small-sites-24433620</guid>
            <pubDate>Thu, 10 Sep 2020 16:09:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Search Engines]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24433573">thread link</a>) | @nraychaudhuri
<br/>
September 10, 2020 | https://carlhendy.com/history-of-search-engines/#top | <a href="https://web.archive.org/web/*/https://carlhendy.com/history-of-search-engines/#top">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="main">
			

			<section id="intro" data-slide="intro">
				<div>
					<div>
						<h2><u>Introduction</u></h2>
						<p>Search Engines play an integral role in the lives of many of us, sometimes without us realising. A purchase on Amazon, usually starts with a product search. A new vacation booking, often begins with a hotel search. The answer to any question, is just a web search away. We look at the history behind one type of search engine - the web search engine.</p>	
					</div>
				</div>
			</section>

			<section id="beforesearch" data-slide="beforesearch">
				<div>
					<div>
						<h2><u>Before search engines</u></h2>
						<p>The internet existed for many years before the first web page came online. It was initially a US military project at DARPA, then used as a way of sharing academic and scientific knowledge. The internet as we know it, runs on TCP/IP, a technology invented in 1974 by Bob Kahn and Vint Cerf (who now works for Google).<sup>[1]</sup></p>
					</div>
				</div>
			</section>
			
			<section id="tbl" data-slide="tbl">
				<div>
					<div>
						<h2><u>Tim Berners-Lee</u></h2>
						<p>It was the English scientist, Sir Tim Berners-Lee, who invented the World Wide Web in 1989 while working at CERN in Switzerland. It used a technology called Hypertext Transfer Protocol (HTTP) that transmitted data over TCP/IP, which is why all URLs start with “HTTP” to this day. To make HTTP easier to interface with, Berners-Lee built the world’s first web server and web browser to navigate it in 1990. He also invented HTML (based on CERN’s SGML markup) for formatting text-based content, distributing the technology outside of CERN in 1991. Berners-Lee declared that the technology must remain freely available, with no patents or royalty-fees, to be accessible to everyone.</p>
						<p>Usenet newsgroups were how internet users communicated, a decade before the web was invented. Even after the broad adoption of Sir Tim Berners-Lee’s technology, web pages were often shared and linked to within special-interest newsgroups. Some users began creating web pages that collated the URLs shared in newsgroups, into catalogues or directories. Rather than having to download every message in a newsgroup and searching for information or URLs within them, users could now visit a directory/portal and navigate through the categories to find the relevant web pages.</p>
					</div>
					<p><img src="https://carlhendy.com/history-of-search-engines/assets/img/web/tim-berners-lee.jpg" data-src="assets/img/web/tim-berners-lee.jpg" alt="Sir Tim Berners-Lee">
					</p>
				</div>
			</section>
			
			<section id="dmoz" data-slide="dmoz" data-bg="assets/img/web/dmoz-blur.png">
				<div>
					<div>
						<h2><u>Open Directory Project</u></h2>
						<p>One of the most well-known directories was DMOZ (or the Open Directory Project), created in 1998 by two engineers at Sun Microsystems. The directory became the default way of finding information on the web for many, with a search function for faster directory navigation.</p>
						<p>DMOZ was acquired by Netscape later that same year, having indexed (listed) around 100,000 URLs. A year later DMOZ had over a million URLs listed, and it peaked at over five million URLs, before closing in 2017. The directory’s objectives became blurred when AOL acquired Netscape, and the cost of running it for free came into question.</p>
						<p>Volunteer editors of the directory felt betrayed, becoming unpaid workers of AOL, rather than a noble, free and open initiative. Commercial content creators such as CNN were given editorial rights to add/edit/delete entries, putting the impartiality of the project in question. Editors were found to be selling inclusion in the directory, after a DMOZ listing was rumoured to increase a website’s ranking in search engines. </p>
						<p>AOL failed to resuscitate DMOZ several times and eventually took the website offline. A directory based on the original DMOZ database and maintained by former DMOZ editors, still exists today at <a href="http://curlie.org/">Curlie.org</a>.</p>
					</div>
				</div>
			</section>

			<section id="archie" data-slide="archie">
				<div>
					<div>
						<h2><u>Archie wasn't the first web search engine</u></h2>
						<p>A pub quiz will tell you that <b>Archie</b> was the first search engine, which is technically correct. But Archie, built in 1987 at McGill University, was designed to search for files on the internet (FTP servers), not for content on the World Wide Web.</p>
						<p><b>W3Catalog</b> (originally called “Jughead”) was later launched in September 1993 by Oscar Nierstrasz at the University of Geneva. The service mostly took existing lists/catalogues of web pages and made them searchable in a standardised format.</p>
						<p><b>Aliweb</b> (Archie Like Indexing for the Web) is widely considered to be the first web search engine. Launched in November 1993, Aliweb allowed webmasters to submit their web pages and enter the relevant keywords and descriptions for these pages. The search engine was largely forgotten though, with internet users at the time, still mostly preferring to navigate websites using directories, lists and catalogues.</p>
					</div>
				</div>
			</section>

			<section id="lycos" data-slide="lycos" data-bg="assets/img/web/lycos.jpg">
				<div>
					<div>
						<h2><u>Money Gets Involved</u></h2>
						
						<p><b>WebCrawler</b> was the first search engine to be widely used, as well as the first to fully index the content on web pages, making every word and phrase searchable. It was developed at the University of Washington and launched in 1994, the same year as Lycos from Carnegie Mellon University. Both WebCrawler and Lycos became commercial ventures, with WebCrawler supported by two primary investors, one being Microsoft co-founder Paul Allen.</p>
						<p><b>Lycos</b> heavily invested in their brand, with TV ads featuring their iconic black labrador dog, as well as hiring a vast team of volunteer and paid Editors for their web directory.</p>
					</div>
				</div>
			</section>

			<section id="dawn" data-slide="dawn" data-bg="assets/img/web/yahoo-office.jpg">
				<div>
					<p>
						<h2>1995 - The dawn of search engines</h2>
					</p>
				</div>
			</section>

			<section id="yahoo" data-slide="yahoo">
				<div>
					<div>
						<h2><u>Excite, AltaVista &amp; Yahoo were born</u></h2>
						<p>Two years after Aliweb, search engines became mainstream and big business. Excite and AltaVista both launched in 1995, along with the less well-known MetaCrawler, Magellan and Daum. But the most significant success was Yahoo, founded by Jerry Yang and David Filo.</p>
						<p>“Yahoo!” started as a traditional web directory in 1994 by two Stanford University graduates, then launching a search engine in 1995. To the annoyance of their lesser-known rivals, Yahoo didn’t build any significant new technology. They bought and borrowed third-party tech, until the acquisition of Inktomi (a search engine for hire) in 2002. The success of Yahoo was all packaging, with a fun brand and a user-friendly interface.</p>
						<p>Internet-connected computers started to become widely accessible in schools, libraries and homes across the globe. A new generation began using websites more than books, and search engines more than web directories. Yahoo, AltaVista and Lycos dominated, with significant investment propping up the loss-making sites.</p>
					</div>
				</div>
			</section>

			<section id="robinli" data-slide="robinli">
				<div>
					<p>
						<h2>Who is Robin Li?<br>(Li Yanhong / 李彦宏)</h2>
					</p>
				</div>
			</section>

			<section id="robinli2" data-slide="robinli2">
				<div>
					<div>
						<h2><u>He kept his head down</u></h2>
						<p>“Robin” Li Yanhong is mostly an unknown in the western world, but one of the richest men in China, with an estimated net worth of nineteen billion dollars. </p>
						<p>His parents were factory workers, with four other children to care for. They helped Li get into Peking University, where he studied Information Management. Li then went on to study at the University of Buffalo in New York, where he earned a doctorate in Computer Science. After leaving university, Li joined a New Jersey based division of Dow Jones, where he built software to manage the online edition of The Wall Street Journal.</p>
						<p>In 1996, Li created and patented a system called RankDex, for ranking the importance of web pages in a search result. For the first time, it used “link analysis” to determine the importance of web pages by the number of other pages linking to them.</p>
						<p>RankDex is the basis of every major search engine’s ranking algorithm today, predating Google’s “PageRank” by two years and being referenced in Larry Page’s first patent. Without RankDex, search engines may still be using keywords, not links, as their primary ranking factor today.</p>
						<p>Shortly after welcoming in the new millennium, Robin Li and Eric Xu co-founded and incorporated Baidu, now China’s largest search engine. Just as PageRank is the soul of Google, RankDex is the soul of Baidu and the father of modern search engine ranking algorithms.</p>
					</div>
					<p><img src="https://carlhendy.com/history-of-search-engines/assets/img/web/robin-li-portrait.jpg" data-src="assets/img/web/robin-li-portrait.jpg" alt="Robin Li - Baidu">
					</p>
				</div>
			</section>

			<section id="ask" data-slide="ask" data-bg="assets/img/web/ask.png">
				<div>
					<div>
						<h2><u>Why don’t you Ask Jeeves?</u></h2>
						<p>Just as Boo.com was “before its time” in e-commerce (3D rotating product images in 1998?!), Ask Jeeves was before its time in search. The search engine launched in 1997, with a unique ability to answer questions.</p>
						<p>Up until now, users had to carefully think about which “keywords” to search for on AltaVista, Yahoo and Excite, to get a useful page of results back. A typical search engine would give equal weighting and importance to each word in a question, often returning irrelevant results. Ask Jeeves was able to extract the important words and primary intent of a question, yielding much more relevant results. It became hugely popular with the growing number of non-techies surfing the web, who were not used to thinking like a computer.</p>
						<p>The company was acquired by IAC (Match.com) in 2005 but struggled to compete against larger rivals such as Google. It rebranded to Ask.com in 2006, to save on the royalty fees to P.G Wodehouse’s estate (Jeeves was a butler character in one of his books) and appear more modern<sup>[2]</sup>. In 2010, Ask made its search team redundant and outsourced to another search engine provider.</p>
						<p>The search engine technology Teoma that they acquired, struggled with ranking and indexing relevant pages on an ever-expanding web. Revenue generation also seemed to take priority over User Experience. Adverts consumed the search result pages when Google at the time had a clean, fast and relatively ad-free appearance. Any computer-related search query on Ask Jeeves would return a page covered in Dell adverts, making the organic results challenging to find.</p>
						<p>A year after throwing in the towel on search technology, Ask’s CEO, Doug Leeds, said they still provided search to over 100 million people every month. Perhaps if Ask kept developing their technology, they’d be a leader in voice search today, where question-based searches are key.</p>
					</div>
				</div>
			</section>

			<section id="google1" data-slide="google1" data-bg="assets/img/web/google-nyc.jpg">
				<div>
					<p>
						<h2>A monopolistic giant is born</h2>
					</p>
				</div>
			</section>

			<section id="google2" data-slide="google2">
				<div>
					<div>
						<h2><u>Google</u></h2>
						<p>Originally named “Backrub” for its link-based ranking …</p></div></div></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://carlhendy.com/history-of-search-engines/#top">https://carlhendy.com/history-of-search-engines/#top</a></em></p>]]>
            </description>
            <link>https://carlhendy.com/history-of-search-engines/#top</link>
            <guid isPermaLink="false">hacker-news-small-sites-24433573</guid>
            <pubDate>Thu, 10 Sep 2020 16:04:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a user profile portal with Flask, OAuth, and APIs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24433572">thread link</a>) | @mooreds
<br/>
September 10, 2020 | https://fusionauth.io/blog/2020/09/10/building-profile-portal-with-flask-oauth-apis | <a href="https://web.archive.org/web/*/https://fusionauth.io/blog/2020/09/10/building-profile-portal-with-flask-oauth-apis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
              <p>Once a user registers, you can view their data in the administrative user interface. But how can you allow the user to view or change their data themselves?</p>

<!--more-->

<p>Previously, we built a <a href="https://fusionauth.io/blog/2020/08/27/advanced-registration-form">self service registration form</a> for a real estate application. It was a two step form which captured specific information about their home buying needs. We also themed the <a href="https://fusionauth.io/blog/2020/09/01/theme-registration-form">registration form</a>. This tutorial builds on the previous two and will walk through building a python flask application to let a user sign in and modify the profile data they provided at registration.</p>

<p>While this tutorial will reference the previous registration form, you can adapt it to an existing registration flow too.</p>

<p>This is part of a three part series. Here are all the posts:</p>

<ol>
  <li><a href="https://fusionauth.io/blog/2020/08/27/advanced-registration-form">How to use FusionAuth’s advanced registration forms</a></li>
  <li><a href="https://fusionauth.io/blog/2020/09/01/theme-registration-form">How to theme FusionAuth’s advanced registration forms</a></li>
  <li>Building a user profile portal with Flask, OAuth, and APIs (this one)</li>
</ol>

<h2 id="overview">Overview</h2>

<p>Before jumping into the code, let’s outline what this blog post will cover. You’ll learn how to set up a Flask application to use FusionAuth as a user data store. This post will only have one application and one tenant, but FusionAuth supports multiple tenants and applications out of the box, so if you need that logical separation, you got it.</p>

<p>The Flask application will let users log in or register. After a user has been authenticated, it will display their profile information. This data will be retrieved in two ways, using both a standards based python OAuth library, <code>requests_oauthlib</code>, and with the FusionAuth <a href="https://github.com/fusionauth/fusionauth-python-client">open source python client library</a>.</p>

<p>Why two ways? If all you need is data that is provided by an OpenID Connect (aka OIDC), then you should stick with standards, as this will give you maximal portability. <code>requests_oauthlib</code> can easily retrieve an access token that your software can present to other services which expect credentials. These may be APIs you build or any other applications which use JWTs for authorization decisions.</p>

<blockquote>
  <p>What’s the difference between OAuth and OIDC? OAuth is a standardized framework for authorization which delivers tokens to present to other systems to gain access. OIDC is another standardized framework built on top of OAuth which provides user data and authentication information.</p>
</blockquote>

<p>However, if you need information beyond what OIDC provides, you will need to use a different approach. An example of such data is the home pricing preference information captured by the registration form built previously. To access this data, you’ll need to use the FusionAuth client libraries.</p>

<p>At the end of the day, you’ll end up with a self service portal like this:</p>

<p><img src="https://fusionauth.io/assets/img/blogs/flask-oauth-portal/final-screen.png" alt="The self service profile management portal."></p>

<h2 id="prerequisites">Prerequisites</h2>

<p>You’ll need the following pieces of software installed before you start this tutorial:</p>

<ul>
  <li>python3</li>
  <li>pip3</li>
</ul>

<p>And of course you’ll need to have a registration form and FusionAuth set up. If you want to be walked through that process, check out the previous post on <a href="https://fusionauth.io/blog/2020/08/27/advanced-registration-form">advanced registration forms</a> and <a href="https://fusionauth.io/blog/2020/09/01/theme-registration-form">on theming the form</a>. If you already have a form set up, full speed ahead!</p>

<h2 id="fusionauth-setup">FusionAuth setup</h2>

<p>Go to “Settings” and create an API key. We’ll be using this to pull the data, so configure these allowed endpoints:</p>

<ul>
  <li><code>/api/user/registration</code>: all methods</li>
  <li><code>/api/form</code>: <code>GET</code> only</li>
  <li><code>/api/form/field</code>: <code>GET</code> only</li>
</ul>

<p>You may also specify no endpoint methods when you create the key. This creates a super-user API key, so beware. Such a key is fine for a tutorial, but for production, please limit access.</p>

<p>Next, update your application settings. Navigate to the “Applications” section, then the “OAuth” tab. Add <code>http://localhost:5000/callback</code> to the “Authorized redirect URLs” field. Set the logout URL to be <code>http://localhost:5000</code>.</p>

<p>These changes ensure that after the user signs in to FusionAuth, they can be sent back to the Flask application endpoint which can process the authorization code and exchange it for an access token, as well as display their profile data. Additionally, once the user logs out, they’ll be sent back to the Flask index page. At the end, the app configuration looks like this:</p>

<p><img src="https://fusionauth.io/assets/img/blogs/flask-oauth-portal/oauth-tab-of-application.png" alt="Configuring the FusionAuth application for the flask portal."></p>

<h2 id="setting-up-the-python-virtual-environment">Setting up the python virtual environment</h2>

<p>Make a directory for this codebase. You could call it something flashy, but I’m going to create one called <code>flask</code>. <code>cd</code> into it, as that’s where you’ll create the entire portal application. To set up your virtual environment in this tutorial, you’re going to use <code>venv</code>: <code>python3 -m venv venv</code>. This lets us install libraries locally.</p>

<p>Next, activate this virtual environment by running this command: <code>. venv/bin/activate</code>. You should now see <code>(venv)</code> in front of your shell prompt:</p>

<div><div><pre><code><span>(</span>venv<span>)</span> dan@MacBook-Pro flask % 
</code></pre></div></div>

<blockquote>
  <p>There are other python tools out there which provide similar functionality to <code>venv</code>, such as <code>pyenv</code> and <code>pipenv</code>.</p>
</blockquote>

<p>Next, let’s install needed libraries. First, you’re going to install flask, which is an extremely lightweight python framework for building applications. You’ll be using <code>pip</code> for all the library installation.</p>



<p>Next, install an OAuth library, <code>requests_oauthlib</code>. You can read <a href="https://requests-oauthlib.readthedocs.io/en/latest/">more about it</a>, but this library makes it easy to interact with any standards compliant OAuth or OIDC implementation. You’ll use it to build standard URLs and retrieve the access token:</p>

<div><div><pre><code>pip3 <span>install </span>requests_oauthlib
</code></pre></div></div>

<p>Finally, while some data is available from OIDC endpoints, retrieving profile data stored in the <code>registration.data</code> field requires the FusionAuth client library. To install it, use this command:</p>

<div><div><pre><code>pip3 <span>install </span>fusionauth-client
</code></pre></div></div>

<p>The setup is all done. Let’s get to coding.</p>

<h2 id="setting-up-the-home-page">Setting up the home page</h2>

<p>As always, you can jump ahead and <a href="https://github.com/FusionAuth/fusionauth-example-flask-portal">view the completed code</a> if you’d like.</p>

<p>First, create a file called <code>oauth.py</code>. This is the main entry point for all our code and will contain almost all of our logic. Here are the contents of a basic flask application:</p>

<div><div><pre><code><span>from</span> <span>requests_oauthlib</span> <span>import</span> <span>OAuth2Session</span>
<span>from</span> <span>flask</span> <span>import</span> <span>Flask</span><span>,</span> <span>request</span><span>,</span> <span>redirect</span><span>,</span> <span>session</span><span>,</span> <span>url_for</span><span>,</span> <span>render_template</span>
<span>from</span> <span>flask.json</span> <span>import</span> <span>jsonify</span>
<span>from</span> <span>fusionauth.fusionauth_client</span> <span>import</span> <span>FusionAuthClient</span>

<span>import</span> <span>json</span>
<span>import</span> <span>os</span>

<span>app</span> <span>=</span> <span>Flask</span><span>(</span><span>__name__</span><span>)</span>
<span>app</span><span>.</span><span>secret_key</span> <span>=</span> <span>os</span><span>.</span><span>urandom</span><span>(</span><span>24</span><span>)</span>
<span>app</span><span>.</span><span>config</span><span>.</span><span>from_object</span><span>(</span><span>'settings.Config'</span><span>)</span>

<span>@</span><span>app</span><span>.</span><span>route</span><span>(</span><span>'/'</span><span>,</span> <span>methods</span><span>=</span><span>[</span><span>"GET"</span><span>])</span>
<span>def</span> <span>homepage</span><span>():</span>
  <span>return</span> <span>render_template</span><span>(</span><span>'index.html'</span><span>)</span>

<span>if</span> <span>__name__</span> <span>==</span> <span>"__main__"</span><span>:</span>
  <span>app</span><span>.</span><span>secret_key</span> <span>=</span> <span>os</span><span>.</span><span>urandom</span><span>(</span><span>24</span><span>)</span>
  <span>app</span><span>.</span><span>run</span><span>(</span><span>debug</span><span>=</span><span>True</span><span>)</span>
</code></pre></div></div>

<p>You are going to use flask templates to create the HTML pages. Create a directory called <code>templates</code> and a file called <code>index.html</code> in that directory. Put the following markup in there:</p>

<div><div><pre><code><span>&lt;!doctype html&gt;</span>
<span>&lt;title&gt;</span>Hello from FusionAuth<span>&lt;/title&gt;</span>
<span>&lt;body&gt;</span>

This is a sample OAuth/Flask application. 
<span>&lt;/body&gt;</span>
<span>&lt;/html&gt;</span>
</code></pre></div></div>

<p>Start the application by running this command in your terminal:</p>

<div><div><pre><code><span>FLASK_APP</span><span>=</span>oauth.py python3 <span>-m</span> flask run
</code></pre></div></div>

<p>You should see this output:</p>

<div><div><pre><code> * Serving Flask app "oauth.py"
 * Environment: production
   WARNING: This is a development server. Do not use it in a production deployment.
   Use a production WSGI server instead.
 * Debug mode: off
 * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)
</code></pre></div></div>

<p>Heed that warning! What you’ll be using during this tutorial is a development server, please don’t put it into production. If you visit <code>http://localhost:5000</code> with your browser, you’ll see this:</p>

<p><img src="https://fusionauth.io/assets/img/blogs/flask-oauth-portal/simple-app-screen.png" alt="The initial Flask page."></p>

<p>What you just did was start up flask and having it display a rendered template. Not too much logic in there, so next, let’s add in some OAuth action and provide a login and registration link.</p>

<h2 id="setting-up-oauth">Setting up OAuth</h2>

<p>You’ve already installed an OAuth python library, so now it is time to use it. Let’s use the configuration capabilities of flask to keep our environment specific config values separate. Create a file named <code>settings.py</code>; add this to the contents:</p>

<div><div><pre><code><span>class</span> <span>Config</span><span>(</span><span>object</span><span>):</span> 
  <span>CLIENT_ID</span><span>=</span><span>"85a03867-dccf-4882-adde-1a79aeec50df"</span>
  <span>CLIENT_SECRET</span><span>=</span><span>"5E_pVQeSQ2v4d7ckDy6rz_Z0HZjNSShUEbWPRYst2hg"</span>
  <span>FA_URL</span><span>=</span><span>'http://localhost:9011'</span>
  <span>AUTHORIZATION_BASE_URL</span><span>=</span><span>'http://localhost:9011/oauth2/authorize'</span>
  <span>TOKEN_URL</span><span>=</span><span>'http://localhost:9011/oauth2/token'</span>
  <span>USERINFO_URL</span><span>=</span><span>'http://localhost:9011/oauth2/userinfo'</span>
  <span>REDIRECT_URI</span><span>=</span><span>'http://localhost:5000/callback'</span>
</code></pre></div></div>

<p><code>CLIENT_ID</code> and <code>CLIENT_SECRET</code> are both available in the application you created in previous tutorials. To retrieve them now, navigate to “Applications” and click the green magnifying glass to view these values:</p>

<p><img src="https://fusionauth.io/assets/img/blogs/flask-oauth-portal/application-screen-fusionauth.png" alt="Finding the client id and client secret values."></p>

<p>The rest of the configuration values are standard OAuth/OIDC endpoints as well as the URL of your Flask application. You should only need to modify those if you are running FusionAuth or flask on a different host or port.</p>

<p>Let’s update <code>index.html</code> as well, to add links for login and registration. Here’s the new HTML:</p>

<div><div><pre><code><span>&lt;!doctype html&gt;</span>
<span>&lt;title&gt;</span>Hello from FusionAuth<span>&lt;/title&gt;</span>
<span>&lt;body&gt;</span>

This is a sample OAuth/Flask application. 
<span>&lt;br/&gt;</span>
<span>&lt;br/&gt;</span>
<span>{%</span> <span>if</span> <span>user</span> <span>%}</span>
  <span>&lt;div&gt;</span>
    <span>&lt;a</span> <span>href=</span><span>'/logout'</span><span>&gt;</span>Logout<span>&lt;/a&gt;</span>
  <span>&lt;/div&gt;</span>
  <span>&lt;h1&gt;</span>Hello <span>{{</span> <span>user.email</span> <span>}}</span>!<span>&lt;/h1&gt;</span>
<span>{%</span> <span>else</span> <span>%}</span>
  <span>&lt;div&gt;</span>
    Log in or register to update your profile.
  <span>&lt;/div&gt;</span>
  <span>&lt;div&gt;</span>
    <span>&lt;a</span> <span>href=</span><span>'/login'</span><span>&gt;</span>Login<span>&lt;/a&gt;</span> | <span>&lt;a</span> <span>href=</span><span>'/register'</span><span>&gt;</span>Register<span>&lt;/a&gt;</span>
  <span>&lt;/div&gt;</span>
<span>{%</span> <span>endif</span> <span>%}</span>
<span>&lt;/body&gt;</span>
<span>&lt;/html&gt;</span>
</code></pre></div></div>

<p>In this template, if the <code>user</code> variable exists, the user’s email address is shown. Otherwise it displays login or registration links.</p>

<p>Finally, update <code>oauth.py</code> to provide the routes you added to the template. Below is the entire updated file, but we’ll examine each method one at a time after the code block:</p>

<div><div><pre><code><span>from</span> <span>requests_oauthlib</span> <span>import</span> <span>OAuth2Session</span>
<span>from</span> <span>flask</span> <span>import</span> <span>Flask</span><span>,</span> <span>request</span><span>,</span> <span>redirect</span><span>,</span> <span>session</span><span>,</span> <span>url_for</span><span>,</span> <span>render_template</span>
<span>from</span> <span>flask.json</span> <span>import</span> <span>jsonify</span>
<span>from</span> <span>fusionauth.fusionauth_client</span> <span>import</span> <span>FusionAuthClient</span>

<span>import</span> <span>json</span>
<span>import</span> <span>os</span>

<span>app</span> <span>=</span> <span>Flask</span><span>(</span><span>__name__</span><span>)</span>
<span>app</span><span>.</span><span>secret_key</span> <span>=</span> <span>os</span><span>.</span><span>urandom</span><span>(</span><span>24</span><span>)</span>
<span>app</span><span>.</span><span>config</span><span>.</span><span>from_object</span><span>(</span><span>'settings.Config'</span><span>)</span>

<span>@</span><span>app</span><span>.</span><span>route</span><span>(</span><span>'/'</span><span>,</span> <span>methods</span><span>=</span><span>[</span><span>"GET"</span><span>])</span>
<span>def</span> <span>homepage</span><span>():</span>
  <span>user</span><span>=</span><span>None</span>
  <span>if</span> <span>session</span><span>.</span><span>get</span><span>(</span><span>'user'</span><span>)</span> <span>!=</span> <span>None</span><span>:</span>
    <span>user</span> <span>=</span> <span>session</span><span>[</span><span>'user'</span><span>]</span>
  <span>return</span> <span>render_template</span><span>(</span><span>'index.html'</span><span>,</span> <span>user</span><span>=</span><span>user</span><span>)</span>

<span>@</span><span>app</span><span>.</span><span>route</span><span>(</span><span>"/logout"</span><span>,</span> <span>methods</span><span>=</span><span>[</span><span>"GET"</span><span>])</span>
<span>def</span> <span>logout</span><span>():</span>
  <span>session</span><span>.</span><span>clear</span><span>()</span>
  <span>return</span> <span>redirect</span><span>(</span><span>app</span><span>.</span><span>config</span><span>[</span><span>'FA_URL'</span><span>]</span><span>+</span><span>'/oauth2/logout?client_id='</span><span>+</span><span>app</span><span>.</span><span>config</span><span>[</span><span>'CLIENT_ID'</span><span>])</span>


<span>@</span><span>app</span><span>.</span><span>route</span><span>(</span><span>"/login"</span><span>,</span> <span>methods</span><span>=</span><span>[</span><span>"GET"</span><span>])</span>
<span>def</span> <span>login</span><span>():</span>
  <span>fusionau…</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fusionauth.io/blog/2020/09/10/building-profile-portal-with-flask-oauth-apis">https://fusionauth.io/blog/2020/09/10/building-profile-portal-with-flask-oauth-apis</a></em></p>]]>
            </description>
            <link>https://fusionauth.io/blog/2020/09/10/building-profile-portal-with-flask-oauth-apis</link>
            <guid isPermaLink="false">hacker-news-small-sites-24433572</guid>
            <pubDate>Thu, 10 Sep 2020 16:04:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine Learning Attack Series: Brute forcing to find incorrect predictions]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24433447">thread link</a>) | @wunderwuzzi23
<br/>
September 10, 2020 | https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-attack-bruteforce/ | <a href="https://web.archive.org/web/*/https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-attack-bruteforce/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p>This post is part of a series about machine learning and artificial intelligence. Click on the blog tag “huskyai” to see related posts.</p>
<p>The <a href="https://embracethered.com/blog/posts/2020/husky-ai-walkthrough/">previous four posts</a> explained the architecture and how Husky AI was built, threat modeled and deployed. Now it’s time to start the attacks and build mitigations. The <a href="#appendix">appendix</a> in this post shows all the attacks I want to research and perform in this series over the next few weeks/months.</p>
<p>Let’s dive into the attacks.</p>
<h2 id="brute-forcing-images-to-find-incorrect-predictions">Brute forcing images to find incorrect predictions</h2>
<p>The first attack I investigated is also referred to as <strong>perturbation attack</strong> throughout the literature I have been reading. It is like fuzzing (dumb or smart) to come up with malicious input that tricks a model. It is probably the first attack that one would think of when faced to hack AI/ML - besides attacking the machine learning infrastructure.</p>
<h3 id="what-are-we-testing">What are we testing?</h3>
<p>The target is Husky AI, which we have discussed in the previous posts. The operationalized Husky AI model is accessible over an HTTP endpoint. It’s basically an image upload API, and it returns the prediction score.</p>
<p><a href="https://embracethered.com/blog/images/2020/husky-prediction.jpg"><img src="https://embracethered.com/blog/images/2020/husky-prediction.jpg" alt="Husky Prediction Example"></a></p>
<p>If you are curious the code for the simple web server is located <a href="https://github.com/wunderwuzzi23/ai/blob/master/huskyai/huskyai.py">here</a>.</p>
<p>To interact with the API I’m using the following code:</p>
<pre><code>ENDPOINT = "https://example.org/huskyai"

def predict(np_candidate):

    #convert numpy array to Image in memory
    img = Image.fromarray((np_candidate*255.).astype('uint8'), 'RGB')
    image_bytes = io.BytesIO()
    img.save(image_bytes, format="png")
    image_bytes = image_bytes.getvalue()

    #call prediction HTTPS API
    file = {
        "file": image_bytes,
        "Content-Type": "image/png"
    }

    response = requests.post(ENDPOINT, files=file)
    return response.json()
</code></pre><h3 id="what-is-happening-here">What is happening here?</h3>
<ol>
<li>The <code>predict</code> function takes a <code>numpy</code> array (a typical python data structure) and converts it to an <code>Image</code>.</li>
<li>The input array comes in with values from <code>0-1</code>. Hence, we multiply all input values by <code>255</code> and convert to a <code>uint8</code> to ensure the random pixels all have values between 0 and 255.</li>
<li>Afterwards the image is converted to <code>png</code>, and the resulting <code>image_bytes</code> are added to the <code>POST</code> request.</li>
<li>If all goes well, the web service returns a <code>JSON</code> response with the prediction as a <code>float</code>.</li>
</ol>
<p>That is all that is needed to invoke the HTTP API from Python.</p>
<h3 id="jupyter-notebook">Jupyter Notebook</h3>
<p>I’m using a Jupyter Notebook to run these attacks. Over the last couple of weeks, I really started liking the VS Code Python extension.</p>
<p>The validation accuracy of the model was in the mid 80% range and querying the API works well with the Jupyter notebook.</p>
<p>Here are two examples of calls to the API:</p>
<ol>
<li>A picture I took at a dog park identifies this dog as a husky:
<a href="https://embracethered.com/blog/images/2020/result-huskyai.jpg"><img src="https://embracethered.com/blog/images/2020/result-huskyai.jpg" alt="Husky Prediction"></a></li>
<li>The Shadowbunny scores low, not being classified as a husky:
<a href="https://embracethered.com/blog/images/2020/nonhusky-prediction-result.jpg"><img src="https://embracethered.com/blog/images/2020/nonhusky-prediction-result.jpg" alt="Non Husky Prediction"></a></li>
</ol>
<p>Equipped with a model that works decently well (or not, as we will see soon), it’s time to create images to challenge the model.</p>
<h2 id="simple-test-cases">Simple test cases</h2>
<p>When testing software to find bugs, a good strategy is testing boundary scenarios. Hence, I thought of doing the same in this case. With machine learning there are special tools and techniques available, such as adversarial learning models, Cleverhans and others which I want to research and look at later.</p>
<p>The three test cases that seemed interesting initially were <strong>all 0</strong>, <strong>all 1</strong> and images with <strong>random pixels</strong>.</p>
<p>Here is the code snippet I used to create these test images and run them through the prediction web endpoint:</p>
<pre><code>candidate_rand  = np.random.random([1, NUM_PX, NUM_PX, 3])
candidate_zeros = np.zeros([1, NUM_PX, NUM_PX, 3])
candidate_ones  = np.ones([1, NUM_PX, NUM_PX, 3])

print("Random Canvas: " + str(predict(candidate_rand)))
print("Ones Canvas:   " + str(predict(candidate_ones)))
print("Zeros Canvas:  " + str(predict(candidate_zeros)))
</code></pre><p>Let us analyze the results in more detail.</p>
<h3 id="test-case-1-a-black-canvas"><strong>Test Case 1:</strong> A black canvas</h3>
<p>The first image I created was a <code>numpy</code> array with all 0 - which is basically a blank black canvas.</p>
<p><a href="https://embracethered.com/blog/images/2020/adversarial-image1.jpg"><img src="https://embracethered.com/blog/images/2020/adversarial-image1.jpg" alt="Husky Adversarial Image 1"></a></p>
<p>Yep, the result looks like expected.</p>
<h3 id="test-case-2-a-white-canvas"><strong>Test case 2:</strong> A white canvas</h3>
<p>The second test case was an all-white canvas:</p>
<p><a href="https://embracethered.com/blog/images/2020/adversarial-image2.jpg"><img src="https://embracethered.com/blog/images/2020/adversarial-image2.jpg" alt="Husky Adversarial Image 2"></a></p>
<p>Oh, wow! There is the first successful attack already. Looks like the model has some issues!</p>
<h3 id="test-case-25-solid-colors-from-0-255"><strong>Test case 2.5:</strong> Solid colors from 0-255</h3>
<p>Since the corner cases gave such drastic results, I went ahead to try the solid shades from 0-255 for all pixels. The results show that there is a range of 30-40 adversarial images that are huskies. So interesting.</p>
<p><a href="https://embracethered.com/blog/images/2020/adversarial-husky-grade.jpg"><img src="https://embracethered.com/blog/images/2020/adversarial-husky-grade.jpg" alt="Husky Adversarial Image - Shades"></a></p>
<p>There is still one more experiment to perform amongst these simple scenarios.</p>
<h3 id="test-case-3-images-with-random-pixels"><strong>Test case 3:</strong> Images with random pixels</h3>
<p>It was quite unexpected that the pervious scenarios already broke the model.</p>
<p>My initial plan was to create many random images in a loop until I get one that scores over 50%. However, this was not really needed. Also, for random images many are identified as husky. Look:</p>
<p><a href="https://embracethered.com/blog/images/2020/adversarial-image3.jpg"><img src="https://embracethered.com/blog/images/2020/adversarial-image3.jpg" alt="Husky Adversarial Image 3"></a></p>
<p>Quite surprising - did not assume that breaking this model would be that easy…</p>
<h2 id="take-away-from-the-attacks">Take-away from the attacks</h2>
<p>The initial learning for me here is that having basic “unit” tests for models is a good idea.
It will be exciting to try more advanced attacks (includ ML based ones) after fixing these issues first.</p>
<h2 id="mitigations">Mitigations</h2>
<p>Now, let’s discuss how to mitigate these issues, I had a couple of ad-hoc ideas:</p>
<ol>
<li><strong>Simple adversarial training:</strong> My first thought is to make sure to add these test cases when training the model. This is called “adversarial training”</li>
<li><strong>Throttle calls to the web server:</strong> Not all attacks are feasible if users are throttled when submitting images. Throttling will make successful attacks more difficult for some attackers. As red teamer I’d say its best to assume a motivated adversary has access to the model.</li>
<li><strong>Interpret predictions slightly different:</strong> We could say an image is a husky when the prediction is 60%+</li>
<li><strong>Improving the model in general:</strong> The model’s accuracy is in the mid 80% and a bit overfitted, so there is plenty of room for improvements.</li>
<li><strong>Transfer Learning</strong> A good improvement accuracy wise will be to use “Transfer Learning” and build on top of the shoulders of a more mature model.</li>
</ol>
<p>The results so far are quite interesting for my learning experience. So, I want to continue that route for now.</p>
<p>Let’s look how I trained the model for these adversarial images:</p>
<h3 id="adversarial-training">Adversarial training</h3>
<p>The simple mitigation seems to be to train the model on these corner cases and teach the model that such images are not huskies.</p>
<p>This can be done using code like this:</p>
<pre><code>labels = [0,0,0]
images = [candidate_rand[0], candidate_zeros[0], candidate_ones[0]]

print("Fitting model...")
model.fit(np.array(images),np.array(labels), epochs=1, verbose=0)

print("Random Canvas: " + str(model.predict(candidate_rand)))
print("Zeros Canvas:  " + str(model.predict(candidate_zeros)))
print("Ones Canvas:   " + str(model.predict(candidate_ones)))
</code></pre><p>Since I am experimenting to learn, I only trained for a single epoch initially, here are the results:</p>
<pre><code>Fitting model...

Random Canvas: [[0.25112703]]
Zeros Canvas:  [[7.170946e-05]]
Ones Canvas:   [[0.5275204]]
</code></pre><p>These number are still bad, so I trained for more epochs. Overfitting did not seem too much of a concern as these images are far off real huskies. I think it would further improve the model to cycle the random pixels for each epoch even.</p>
<h4 id="testing-the-mitigation-brute-forcing-images">Testing the mitigation (brute forcing images)</h4>
<p>To check I built this basic brute force script, which just creates a random pixel image and then runs it through the new model. <em>This test was done directly against the model, not via the slower HTTPS image upload API.</em></p>
<pre><code>## Brute force experiment
## Is it now feasible now to guess a random husky via brute force?
attempts = 100000
current_best_score = 1e-100

for i in range(attempts):

    if (i % 10000) == 0:
        print(f"Progress... #{i}")
    
    ##create a random image
    candidate_image = np.random.random([1, NUM_PX, NUM_PX, 3])
    
    result = model.predict(candidate_image)
    score = result[0]

    if score &gt; 0.5:
        print("Found a random husky. Try #" + str(i))
        plt.imshow(candidate_image[0])
        break

    if score &gt; current_best_score: 
        current_best_score = score
        print("New best score: " + str(current_best_score))
</code></pre><p>With the additional training we performed, it seems quite difficult to “guess” a husky picture now.</p>
<p>I performed about 100000 tests and the highest score achieved via random pixels was about 30% now - still a bit high so I should probably add a few more “random pixel” adversarial examples.</p>
<h3 id="api-throttling-and-rate-limiting">API throttling and rate limiting</h3>
<p>Throttling the web server image upload API (which queries the model) is another good mitigation. I am using <code>nginx</code> as API gateway and <code>rate limiting</code> can be setup in the configuration file of the web site. <a href="https://www.nginx.com/blog/rate-limiting-nginx/">See more information on the nginx documentation for rate limiting</a>.</p>
<h2 id="conclusion">Conclusion</h2>
<p>That’s it for the first round of attacks. I hope you enjoyed reading and learning about this as much as I do. I learned a lot already and am eager to dive learning smarter ways of coming up with malicious/adversarial examples.</p>
<h3 id="appendix">Appendix</h3>
<p>These are the core ML threats for Husky AI that were identified in the <a href="https://embracethered.com/blog/posts/2020/husky-ai-threat-modeling-machine-learning/">threat modeling session</a> so far and that I want to research and build attacks for.</p>
<p>Links will be added when posts are completed over the next serveral weeks/months.</p>
<ol>
<li><strong>Attacker brute forces images to find incorrect predictions/labels - Perturbation Attack  (this post)</strong></li>
<li><a href="https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-attack-smart-fuzz/">Attacker applies smart ML fuzzing to find incorrect predictions - Perturbation Attack</a></li>
<li>Attacker gains read access to the model - Exfiltration Attack</li>
<li>Attacker modifies persisted model file - Backdooring Attack</li>
<li>Attacker denies modifying the model file - Repudiation Attack</li>
<li>Attacker poisons the supply chain of third-party libraries</li>
<li>Attacker tampers with images on disk to impact training performance</li>
<li>Attacker modifies Jupyter Notebook file to insert a backdoor (key logger or data stealer)</li>
</ol>

  </section></div>]]>
            </description>
            <link>https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-attack-bruteforce/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24433447</guid>
            <pubDate>Thu, 10 Sep 2020 15:52:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Applying AI in the Real-World]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24433393">thread link</a>) | @pedrobnsilva
<br/>
September 10, 2020 | https://1d.works/applying-ai-in-real-life-part-1/ | <a href="https://web.archive.org/web/*/https://1d.works/applying-ai-in-real-life-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1516110833967-0b5716ca1387?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 300w,
                            https://images.unsplash.com/photo-1516110833967-0b5716ca1387?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 600w,
                            https://images.unsplash.com/photo-1516110833967-0b5716ca1387?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1000w,
                            https://images.unsplash.com/photo-1516110833967-0b5716ca1387?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1516110833967-0b5716ca1387?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="Applying AI in the real-world (Part 1)">
            </figure>

            <section>
                <div>
                    <h2 id="introduction">Introduction<br></h2><p>In the last decade, artificial intelligence has accomplished many significant feats: from classifying an image to tracking objects in video feeds, from beating a Go player to beating a Starcraft 2 pro and more. After such a successful decade, it is evident that academic advance is slowing down and the research lately is more incremental than fundamental. However, that also means that the AI technology is maturing and we are finding new domains where technology can be applied to.</p><p>Having seen/ read/ been amazed by these applications as a business member you maybe be starting to wonder whether it is time for you to try out these approaches in your work. In this blog post, we will share our experience in solving business problems with AI and hopefully help you avoid repeating our mistakes.</p><h2 id="adding-ml-to-your-it-stack-vs-adding-ml-to-your-business-stack">Adding ML to your IT stack VS adding ML to your business stack<br></h2><p>Before jumping into the core matter, &nbsp;we should make a distinction between two flavors of deployment issues:</p><p><strong>Problem 1: Adding ML to the IT stack. </strong>ML is compute-heavy and requires compute-oriented software and hardware which might not be present in IT infrastructure. Therefore, how and where the algorithms are run needs to be decided, and appropriate skills need to be added to or developed in your IT department.</p><p><strong>Problem 2: Dealing with the implications of having ML in your business processes. </strong>Most of ML methods are non-deterministic and they are evaluated on a statistical basis. That means that even when the methods work it is possible for them to deliver the wrong result. This stochastic nature of the algorithm can be a novelty to a business which depends on a fully deterministic IT system. Business processes affected by such randomness need to be identified, the impact evaluated and, if needed, policies to address it are required.</p><p>Problem 1 heavily depends on the existing infrastructure and the algorithm specifics. Moreover, it is the more obvious of the issues and has been documented extensively. To the extent that it could be solved by completely outsourcing it to the cloud - store the data, train the models, use the models, all in the cloud. There are multiple good tools to achieve that, for example Google cloud offers AutoML and Amazon AWS offers multiple AI/ML services, just to name a few.</p><p>There is much less information on Problem 2, but it can make or break the business proposition of an AI/ML application. Usually, when clients approach AI/ML developers they ask “Can you solve problem X?”, developers reply “Sure, what accuracy do you need?”. The jump from a problem to an AI algorithm is a non-trivial one and requires careful attention.</p><p>To link the business problem to an ML algorithm one needs to deeply understand where the value is added in the process. For example, AI is increasingly being applied for initial screening of medical patients and there you should be extremely cautious about false negatives, i.e. where the patient is screened as healthy when in fact he might be severely ill. The impact of the false positive in that scenario would most likely only lead to and increase in costs. Ignoring these aspects of accuracy could lead to a deadly outcome!</p><p>Therefore, framing the real-life problem into an AI solution is a significant part of the development and in this blog series, we will share our experience and tips on how to avoid some of the dangerous pitfalls.</p><h2 id="examples">Examples<br></h2><p>We start by sharing two examples that we’ve encountered that are spaced nearly a decade apart. The older one will be used to set a reference point of what developers and IT managers are used to and the more recent one will shed some light on how AI algorithms are developed nowadays. Contrasting the two allows us to compare in what ways we should change how we think about development and how to be prepared to manage what is to come.</p><p>Although we focus on image recognition, the issues are shared across a wide variety of data-based ML approaches.</p><h3 id="how-production-has-been-running-and-what-we-are-used-to">How production has been running and what we are used to</h3><figure><img src="https://raw.githubusercontent.com/1dworks/homepage-assets/master/2020/09/tom-grunbauer-WElrXyQnTiM-unsplash-1-.jpg" alt=""></figure><p>In 2012 we were approached by a client to develop licence plate recognition from images for their parking lot. The client gave us a dataset of 100 images and we started to work on it.</p><p>Recall that in 2012 the situation with respect to AI/ML was very different. Although deep learning had been making waves in the research community, there were much fewer software tools available, much less knowledge on how to train and use neural nets, and it was much harder to run algorithms on GPUs.</p><p>The way production computer vision was at the time - use heuristics to simplify the problem and sometimes use some neural network approach to solve that simple problem. </p><p><strong>The solution we came up worked along these lines:</strong></p><ol><li>Extract white regions from the image;</li></ol><p><strong>Select the regions fulfilling certain conditions:</strong></p><ol><li>A certain range of heights and widths;</li><li>A specific range of aspect ratios;</li><li>Containing some fraction of non-white regions;</li><li>…</li></ol><p><strong>Loop over the selected regions and</strong></p><ol><li>Detect non-white contours which have letter-like features: location in the region, colour, height, width, aspect ratio and etc.</li></ol><p><strong>For each of the letter-like contour try to extract the letter by either:</strong></p><ol><li>Matching it to a database;</li><li>Using some proprietary letter detector;</li><li>Using some neural network;</li><li>A combination of the above;</li><li>Try combining the extracted symbols into a single license plate;</li><li>If all the steps succeeded return the license plate.</li></ol><p><strong>The solution took us a few months and was fairly restrictive:</strong></p><ul><li>Required certain lighting conditions;</li><li>The license plate must be clearly visible, close to the center of the image and not too skewed;</li><li>A high-quality camera was required;</li><li>Adding new features (e.g. enabling night vision ) required a full reworking of the algorithm.</li></ul><p>In many cases, the algorithm crashed at one of the steps and did not return any result. In the cases it worked, the accuracy reached a respectable 95%. The overall accuracy was fairly low - maybe around 60% since in many cases it did not return, but given that cameras do 30 frames per second the overall solution was worth the effort. The problem was solved and has been used in production for a while.</p><h3 id="how-the-ai-ml-production-works-and-what-we-should-get-used-to-for-the-next-decade">How the AI/ML production works and what we should get used to for the next decade</h3><figure><img src="https://raw.githubusercontent.com/1dworks/homepage-assets/master/2020/09/anastase-maragos-kgCDp9PsVQk-unsplash.jpg" alt=""></figure><p>More recently in 2019, we were approached by a car-wash network manager who wanted to measure vehicle queue length using cameras.</p><p>We received a sample of 1000 images and started developing the solution. After manually labeling, we developed multiple candidates, but the high-level view of the solutions was:</p><ol><li>Get the image;</li><li>Extract image features using a pre-trained neural network;</li><li>Use a more data-efficient ML algorithm to map features to the vehicle count.</li></ol><p>The development of the principal algorithm took us a few days and it was 96% accurate. However, even though we had good accuracy in our sample which the client would accept as appropriate, we did not stop there and we’ll share why later on.</p><h3 id="comparison">Comparison<br></h3><p>Let’s compare the two approaches:</p><!--kg-card-begin: html--><table>
  <tbody><tr>
    <th>Heuristic-based algorithm</th>
    <th>ML-based algorithm</th>
  </tr>
  <tr>
   <td>Requires less data</td>
    <td>Requires more data</td>
  </tr>
  <tr>
    <td>The code is complicated</td>
    <td>The code is simple</td>
  </tr>
      <tr>
    <td>The decision logic is obvious</td>
    <td>A lot of maintenance</td>
  </tr>
      <tr>
    <td>Likely to crash than give a wrong result</td>
    <td>Never crashes, but might give the wrong answer</td>
  </tr>
      <tr>
    <td>Slow development</td>
    <td>Fast development</td>
  </tr>
      <tr>
    <td>Runs on any PC</td>
    <td>For efficient use requires GPU-enabled PC</td>
  </tr>
</tbody></table><!--kg-card-end: html--><p>These contrasts led us to identify the following challenges when working with AI algorithms.</p><h2 id="the-challenges-of-ai-based-solutions-why-are-business-processes-important-what-has-changed">The challenges of AI-based solutions/ Why are business processes important/What has changed?<br></h2><ul><li><strong>AI development is non-deterministic</strong>. Once you’ve built a few heuristic-based image recognition solutions, you generally know what is possible and what is not. When AI is involved it is uncertain whether you’re going to have the right data, enough data, enough computing power or brainpower to deal with the math involved to solve it. Even if you follow a paper with a similar problem being solved, usually many important details are left out and take a while to figure out the hard way.</li><li><strong>AI results are non-deterministic. </strong>They are likely to give the correct result, but it does not mean that the likelihood of a wrong one is small. In the case of the car-wash example, in one spot a car was drawn on the pavement and it got always detected as a waiting car.</li><li><strong>AI does not crash. </strong>As long as you give the algorithm the input in the shape it needs it will always give you a result. And sometimes it will be wrong. E.g. the license plate algorithm had so many checks along the way that it crashed instead of giving a wrong result, making the algorithm much more usable.</li><li><strong>AI solutions are opaque vs transparent. </strong>License plate solution consisted of many small steps and debugging it was pretty simple since it was obvious where the system stopped working. Figuring out why the car count algorithm went broken was much harder. Maybe the error was an unseen case?</li><li><strong>ML-based solutions are based on the data available before the deployment stage. </strong>The same can be said about the heuristic-based solution, but heuristics are usually made such that their logic is meant to span beyond the sample set. In a related scenario, the first batch of images we got for the vehicle queue contained images during very good weather. As expected once we asked to for more samples weirder cases started appeared - the rain made some of the images unworkable and threw off our initial algorithm.</li></ul><h2 id="conclusions">Conclusions<br></h2><p>In this blog post, we shared our experience with two similar problems and their two different solutions. The heuristic approach has been in use for a long period of time and the AI one is slowly taking over. Contrasting how the two are developed and used hints at the challenges of the new approach. Having figured out that in this blog post we will elaborate on how such projects should be structured to achieve maximum success in the next part.</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://1d.works/applying-ai-in-real-life-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24433393</guid>
            <pubDate>Thu, 10 Sep 2020 15:46:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenNebula launches its new Managed Service Provider (MSP) Program]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24433331">thread link</a>) | @amarti
<br/>
September 10, 2020 | https://opennebula.io/opennebula-managed-service-provider-partnership/ | <a href="https://web.archive.org/web/*/https://opennebula.io/opennebula-managed-service-provider-partnership/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			    <!-- .entry-header -->

				
					
<article id="post-26720">

    <!-- .entry-header -->

    <div>

		
<p>It is “crystal clear” that technology is playing a central role in many companies’ maturing business models, however, not all companies are willing or equipped to manage and administer their technology solutions. This has provided the launch pad from which the Managed Services Provider market has taken off.&nbsp;</p>



<p>And as organizations are evolving with more and more “specialized needs”, the public cloud offerings are not designed to meet all of these specialized needs. Managed Private Clouds have, hence, become an excellent option for many. Providing a Managed Private Cloud service gives organizations the flexibility to customize their solutions according to their “specialized needs”, allowing them greater levels of control and security provided by dedicated single-tenant environments, while delivering the agility and scalability of the public cloud.</p>







<h3><strong>And here enters OpenNebula…&nbsp;</strong></h3>



<p>OpenNebula has long been a reference point in the open source cloud technology space for providing a solution that packages robust capability, with broad flexibility and an overall simplicity. Its foundation within the private cloud also allows for greater control and security. Not only does it provide an easy way for organizations to build, deploy, and manage their own enterprise clouds, but it also provides a platform, along with the commercial backbone, for managed service providers to build Managed Private Cloud solutions to offer to the broader public.&nbsp;</p>



<p>Our <strong>OpenNebula Solutions Provider Partner Program</strong> is an instrument that we are promoting to highlight just how easy it is for Managed Service Providers to use OpenNebula and commit to providing robust, enterprise Managed Private Clouds for their customers. The expectation is that MSP’s which use OpenNebula and participate in this Solutions Provider MSP Partner Program, would communicate and present their offerings as being officially supported by OpenNebula Systems. In turn, the end customer has the confidence of having a thoroughly supported platform, at multiple levels. And at the same time, partners are presented with a collection of benefits including:</p>



<ul><li>Running each managed private cloud with the OpenNebula <strong>Enterprise Edition</strong>, which offers persistent stability, more flexible upgrade opportunities with Long-Term Support (LTS) versions and stable release cycles.</li><li>Ensuring these managed private clouds are backed by official OpenNebula support.</li><li>Having the flexibility to offer special subscription terms that more easily adapt to the Managed Private Cloud (like monthly terms).</li><li>Receiving specific public promotion and recommendation of these MSP solutions by OpenNebula Systems, along with access to the OpenNebula logos to demonstrate “official certification” of an OpenNebula supported product.</li></ul>



<p>You can read more about our <strong>OpenNebula Solutions Provider Partner Program</strong> in our corresponding <a href="https://support.opennebula.pro/hc/en-us/articles/115005959343-Solution-Provider-Partner-Program-Guide">Partner Guide</a>. If you have any questions you can contact our <a href="mailto:partners@opennebula.io">Partners Manager</a> directly to start a dialogue.</p>







<h3>Hear what some of our Solutions Provider Partners have to say:</h3>







<blockquote><p>“<em>With our long-standing and outstanding partner OpenNebula, we have been able to celebrate many joint successes. OpenNebula is the central foundation for the enablement of many customers in the private/hybrid cloud environment – open, flexible and without complexity.</em>” </p><cite>– Sebastian Mangelkramer, Datacenter Technology Manager, NTS</cite></blockquote>







<blockquote><p>“<em>With this partnership we underline our commitment to OpenNebula. We are long time users and contributors of OpenNebula and the community. We urge other Solution Providers to join, so together we can assure a bright future for a no-nonsense open virtual infrastructure solution.</em>“</p><cite>– Stefan Kooman, System Administrator, BIT.nl</cite></blockquote>







<blockquote><p>“<em>StorPool is excited to officially become OpenNebula Managed Service Provider. Now we provide a powerful, fully-managed cloud offering, which is deeply integrated and allows users to have best-of-breed public or private clouds. We have been working closely with OpenNebula for more than 5 years, and during this time, our joint customers’ needs constantly evolve. And OpenNebula manages to successfully grow and innovate with the pace of the market.</em>“</p><cite>– Boyan Ivanov, CEO, StorPool</cite></blockquote>
		
		


        <div>
            <p><img alt="" src="https://secure.gravatar.com/avatar/24f89b786eb790b2fd3710f43d5c9444?s=96&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/24f89b786eb790b2fd3710f43d5c9444?s=192&amp;d=mm&amp;r=g 2x" height="96" width="96">            </p>
            <div>
                <p><span id="autorblog">Michael Abdou</span></p><p>Customer Success Manager at OpenNebula</p>
            </div>
        </div>
	</div><!-- .entry-content -->

</article><!-- #post-## -->

					
<!-- #comments -->

				
			</div></div>]]>
            </description>
            <link>https://opennebula.io/opennebula-managed-service-provider-partnership/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24433331</guid>
            <pubDate>Thu, 10 Sep 2020 15:39:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Goyave v3 – Golang REST API framework major release]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24433232">thread link</a>) | @SystemGlitch
<br/>
September 10, 2020 | https://system-glitch.github.io/goyave/guide/changelog.html#v3-0-0 | <a href="https://web.archive.org/web/*/https://system-glitch.github.io/goyave/guide/changelog.html#v3-0-0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>  <h2 id="v3-0-x"><a href="#v3-0-x">#</a> v3.0.x</h2> <h3 id="v3-0-1"><a href="#v3-0-1">#</a> v3.0.1</h3> <ul><li>Fixed a bug that prevented root-level routes with an empty path (<code>/</code>) to be matched.</li></ul> <h3 id="v3-0-0"><a href="#v3-0-0">#</a> v3.0.0</h3> <ul><li>Changed conventions:
<ul><li><code>validation.go</code> and <code>placeholders.go</code> moved to a new <code>http/validation</code> package.</li> <li>Validation rule sets are now located in a <code>request.go</code> file in the same package as the controller.</li></ul></li></ul> <p><strong>Motivation</strong>: <em>Separating the requests in another package added unnecessary complexity to the directory structure and was not convenient to use. Package naming was far from ideal with the "request" suffix. Moving requests to the same package as the controller is more intuitive and requires less imports and makes route definition cleaner and easier.</em></p> <ul><li>Validation system overhaul, allowing rule sets to be parsed only once instead of every time a request is received, giving better overall performance. This new system also allows a more verbose syntax for validation, solving the comma rule parameter value and a much easier use in your handlers.
<ul><li>Rule functions don't check required parameters anymore. This is now done when the rules are parsed at startup time. The amount of required parameters is given when registering a new rule.</li> <li>Optimized regex-based validation rules by compiling expressions once.</li> <li>A significant amount of untested cases are now tested.</li> <li>The following rules now pass if the validated data type is not supported: <code>greater_than</code>, <code>greater_than_equal</code>, <code>lower_than</code>, <code>lower_than_equal</code>, <code>size</code>.</li> <li>Type-dependent rules now try to determine what is the expected type by looking up in the rule set for a type rule. If no type rule is present, falls back to the inputted type. This change makes it so the validation message is correct even if the client didn't input the expected type.</li> <li>Fixed a bug triggering a panic if the client inputted a non-array value in an array-validated field.</li></ul></li></ul> <p><strong>Motivation</strong>: <em>The validation system had a lot of room for improvement when it comes to performance, as <code>RuleSet</code> were parsed every time a request was received. Moving this process out of the request life-cycle to execute it only once saves a good amount of execution time. Moreover, any handler who would want to read the rules applied to the current request needed to parse them too, which was inconvenient and not effective. With a structure containing everything you need, making middleware interacting with the request's rules is much easier.</em></p> <ul><li>Routing has been improved by changing how validation and route-specific middleware are registered. The signature of the router functions have been simplified by removing the validation and middleware parameters from <code>Route()</code>, <code>Get()</code>, <code>Post()</code>, etc. This is now done through two new chainable methods on the <code>Route</code>: <code>route.Validate()</code> and  <code>route.Middleware()</code>.</li></ul> <p><strong>Motivation</strong>: <em>In the original design, the validation parameter was included in the main route definition function because most routes were expected to be validated, which turned out not to be the case. In a typical CRUD, only the create and update actions are validated, which made the route definition dirty and filled with <code>nil</code> parameters. Separating the rules and middleware definition is more in line with their optional nature and makes routes definition cleaner and more readable, although sometimes slightly longer.</em></p> <ul><li>Log <code>Formatter</code> now receive the length of the response (in bytes) instead of the full body.</li></ul> <p><strong>Motivation:</strong> <em>Keeping in memory the full response has an important impact on memory when sending files or large responses. Using the response content in a log formatter is also a marginal use-case which doesn't justify the performance loss described previously. It is still possible to retrieve the content of the response by writing your own chained writer.</em></p> <ul><li>Configuration system has been revamped.
<ul><li>Added support for tree-like configurations, allowing for better categorization. Nested values can be accessed using dot-separated path.</li> <li>Improved validation: nested entries can now be validated too and all entries can have authorized values. Optional entries can now be validated too.</li> <li>Improved support for slices. The validation system is also able to check slices.</li> <li>Entries that are validated with the <code>int</code> type are now automatically converted from <code>float64</code> if they don't have decimal places. It is no longer necessary to manually cast <code>float64</code> that are supposed to be integers.</li> <li>More openness: entries can be registered with a default value, their type and authorized values from any package. This allows config entries required by a specific package to be loaded only if the latter is imported.</li> <li>Core configuration has been sorted in categories. This is a breaking change that will require you to update your configuration files.</li> <li>Entries having a <code>nil</code> value are now considered unset.</li> <li>Added accessors <code>GetInt()</code> and <code>GetFloat()</code>.</li> <li>Added slice accessors: <code>GetStringSlice()</code>, <code>GetBoolSlice()</code>, <code>GetIntSlice()</code>, <code>GetFloatSlice()</code></li> <li>Added <code>LoadFrom()</code>, letting you load a configuration file from a custom path.</li> <li>Added the ability to use environment variables in configuration files.</li> <li>Bug fix: <code>config.IsLoaded()</code> returned <code>true</code> even if config failed to load.</li> <li><code>maxUploadSize</code> config entry now supports decimal places.</li></ul></li></ul> <p><strong>Motivation:</strong> <em>Configuration was without a doubt one of the weakest and inflexible feature of the framework. It was possible to use objects in custom entries, but not for core config, but it was inconvenient because it required a lot of type assertions. Moreover, core config entries were not handled the same as custom ones, which was a lack of openness. Hopefully, this revamped system will cover more potential use-cases, ease plugin development and allow you to produce cleaner code and configuration files.</em></p> <ul><li>Database improvements
<ul><li>Goyave has moved to <a href="https://gorm.io/" target="_blank" rel="noopener noreferrer">GORM v2</a>. Read the <a href="https://gorm.io/docs/v2_release_note.html" target="_blank" rel="noopener noreferrer">release note</a> to learn more about what changed.</li> <li>Protect the database instance with mutex.</li> <li><code>database.Close()</code> can now return errors.</li> <li>Added <a href="https://system-glitch.github.io/goyave/guide/basics/database.html#connection-initializers">database connection initializers</a>.</li> <li>Added the ability to regsiter new SQL dialects to use with GORM.</li> <li>Use <code>utf8mb4</code> by default in database options.</li> <li>Added a short alias for <code>database.GetConnection()</code>: <code>database.Conn()</code>.</li> <li>Factories now use batch insert.</li> <li>Factories now return <code>interface{}</code> instead of <code>[]interface{}</code>. The actual type of the returned value is a slice of the the type of what is returned by your generator, so you can type-assert safely.</li></ul></li> <li>Status handlers improvements
<ul><li>Export panic and error status handlers so they can be expanded easily.</li> <li>Added <code>goyave.ValidationStatusHandler()</code>, a status handler for validation errors. Therefore, the format in which validation errors are sent to the client can be customized by using your own status handler for the HTTP status 400 and 422.</li></ul></li> <li><code>goyave.Response</code> improvements
<ul><li><code>response.Render</code> and <code>response.RenderHTML</code> now execute and write the template to a <code>bytes.Buffer</code> instead of directly to the <code>goyave.Response</code>. This allows to catch and handle errors before the response header has been written, in order to return an error 500 if the template doesn't execute properly for example.</li> <li>Added <code>response.GetStacktrace()</code>, <code>response.IsEmpty()</code> and <code>response.IsHeaderWritten()</code>.</li> <li>Re-organised the <code>goyave.Response</code> structure fields to save some memory.</li> <li>Removed deprecated method <code>goyave.CreateTestResponse()</code>. Use <code>goyave.TestSuite.CreateTestResponse()</code> instead.</li></ul></li> <li>Recovery middleware now correctly handles panics with a <code>nil</code> value.</li> <li>Test can now be run without the <code>-p 1</code> flag thanks to a lock added to the <code>goyave.RunTest</code> method. Therefore, <code>goyave.TestSuite</code> still <strong>don't run in parallel</strong> but are safe to use with the typical test command.</li> <li>Cache the regex used by <code>helper.ParseMultiValuesHeader()</code> to improve performance. This also improves the performance of the language middleware.</li> <li>Bug fix: data under validation wasn't considered from JSON payload if the content type included the charset.</li> <li>The Gzip middleware will now skip requests that have the <code>Upgrade</code> HTTP header set to any value.</li> <li><code>response.String()</code> and <code>response.JSON()</code> don't write header before calling <code>Write</code> anymore. This behavior prevented middleware and chained writers to alter the response headers.</li> <li>Added <code>goyave.PreWriter</code> interface for chained writers needing to alter headers or status before they are written.
<ul><li>Even if this change is not breaking, it is recommended to update all your chained writers to call <code>PreWrite()</code> on their child writer if they implement the interface.</li> <li>Thanks to this change, a bug with the gzip middleware has been fixed: header <code>Content-Length</code> wasn't removed, resulting in false information sent to the clients, which in turn failed to decompress the response.</li></ul></li></ul> <h2 id="v2-10-x"><a href="#v2-10-x">#</a> v2.10.x</h2> <h3 id="v2-10-2"><a href="#v2-10-2">#</a> v2.10.2</h3> <ul><li>Fixed a bug in body parsing middleware preventing json body to be parsed if a charset was provided.</li></ul> <h3 id="v2-10-1"><a href="#v2-10-1">#</a> v2.10.1</h3> <ul><li>Changed the behavior of <code>response.File()</code> and <code>response.Download()</code> to respond with a status 404 if the given file doesn't exist instead of panicking.</li> <li>Improved error handling:
<ul><li><code>log.Panicf</code> is not used anymore to print panics, removing possible duplicate logs.</li> <li>Added error checks during automatic migrations.</li> <li><code>goyave.Start()</code> now exits the program with the following error codes:
<ul><li><code>2</code>: Panic (server already running, error when loading language files, etc)</li> <li><code>3</code>: Configuration is invalid</li> <li><code>4</code>: An error occurred when opening network listener</li> <li><code>5</code>: An error occurred in the HTTP server</li></ul></li></ul></li></ul> <p>This change will require a slightly longer <code>main</code> function but offers better flexibility for error handling and multi-services.</p> <ul><li>Fixed a bug in <code>TestSuite</code>: HTTP client was re-created everytime <code>getHTTPClient()</code> was called.</li> <li>Fixed testing documentation examples that didn't close http response body.</li> <li>Documentation meta improvements.</li> <li>Protect JSON requests with <code>maxUploadSize</code>.</li> <li>The server will now automatically return <code>413 Payload Too Large</code> if the request's size exceeds the <code>maxUploadSize</code> defined in configuration.</li> <li>The request parsing middleware doesn't drain the body anymore, improving native handler compatibility.</li> <li>Set a default status handler for all 400 errors.</li> <li>Fixed a bug preventing query parameters to be parsed when the request had the <code>Content-Type: application/json</code> header.</li> <li>Added a dark theme for the documentation. It can be toggled by clicking the moon icon next to the search bar.</li></ul> <h3 id="v2-10-0"><a href="#v2-10-0">#</a> v2.10.0</h3> <ul><li>Added router <code>Get</code>, <code>Post</code>, <code>Put</code>, <code>Patch</code>, <code>Delete</code> …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://system-glitch.github.io/goyave/guide/changelog.html#v3-0-0">https://system-glitch.github.io/goyave/guide/changelog.html#v3-0-0</a></em></p>]]>
            </description>
            <link>https://system-glitch.github.io/goyave/guide/changelog.html#v3-0-0</link>
            <guid isPermaLink="false">hacker-news-small-sites-24433232</guid>
            <pubDate>Thu, 10 Sep 2020 15:29:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The pros and cons of AutoML – AI / Machine learning without coding]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24433164">thread link</a>) | @danroseai
<br/>
September 10, 2020 | https://www.danrose.ai/blog/automl-is-it-useful | <a href="https://web.archive.org/web/*/https://www.danrose.ai/blog/automl-is-it-useful">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" id="item-5f23b72b4b500805641d389f"><div><div><div data-block-type="2" id="block-f2678e394879cc0d2fed"><div><p>I’m very excited about writing this blog post. AutoML has been on my mind for a long time. I wonder if it’s the future of AI or just a sidestory when we look back in 10 years? I think I settled on an opinion but before I reveal that, I’d like to discuss AutoML a bit more in depth.</p><p>I would like to answer a few questions in this post. Remember - My posts are always meant to be seen from a product manager, commercial or at least not a data scientist or engineering perspective. So I won’t go into very technical details. The important objective for me is that non-technical people can get a better understanding of applied AI.&nbsp;</p><p>Now for the questions:</p><ol data-rte-list="default"><li><p>What is AutoML really and how does it work?</p></li><li><p>What are the pros and cons?</p></li><li><p>When is AutoML appropriate to use and when is it not?</p></li></ol><p>Excited? Let’s get at it.</p><h2>What is autoML?</h2><p>Before defining AutoML I want to narrow down what I mean by AutoML. When talking about AutoML here I’ll mainly be referring to hosted solutions or at least solutions trained in a hosted environment by an AutoML vendor. I won’t be going into open source solutions or take their possibilities or workings into account. I might be wrong but I’m afraid it would be too broad a discussion with too many if’s to few useful conclusions. Feel free to contact me if you feel like I should add this.</p><h3>The definition of AutoML</h3><p>AutoML is the automated process of selecting architecture, training and in most cases deploying machine learning models. The abstraction is at a level so that the AutoML can be given labeled data, find the right architecture, train and tune the model with intervention. When the model is trained it’s ready to classify when queried with new data.</p><p>So what does this mean? It means that you don’t have to do any machine learning or data science work to get an actual AI model up and running. Depending on the vendor you use and the solution you might have to do some code to interface with the model and the training environment. So no-code AI. Does it sound too good to be true? It might be. I’ll go into the pros and cons in a minute, but first I’ll go a little deeper into how it works.</p><h3>How AutoML works&nbsp;</h3><p>So no AutoML vendor will of course lay out exactly how their AutoML works but they do give some very good pointers.</p><p>First of all it seems like a lot of the AutoML out there is based on <a href="https://www.danrose.ai/blog/transfer-learning-from-a-business-perspective"><span>Transfer Learning</span></a>. Transfer learning in nutshell is when you pre train a neural network with a lot of data to get a good stable model. You then take the last few layers off the neural network and retrain new layers with data specific to your new problem. In that way you can utilize the existing neural networks general knowledge to your new problem. That ensures higher quality with less data on your new problem.</p><p>This is the reason AutoML solutions can take a small amount of data and still get good results. Sometimes even less than a 100 records in a dataset. The pre trained models already had a lot of background knowledge that your model gets put on top of.</p><p>The reason this is interesting is that it gives you an idea of when AutoML is useful. It’s useful when your problem is a bit too specific to be in a general knowledge space but looks a lot like a general problem. This could be categorization of chairs. General machine learning models like the Google Vision API can easily recognize chairs from tables and label that for you and it can even tell a chair from an armchair. But what if you are a furniture designer that wants an AI-model to tell apart your different chair models? Then you can train the AutoML to do exactly that.&nbsp;&nbsp;</p><p>A last point about how AutoML works is that it looks to me like at least Google uses reinforced learning to figure out the optimal architecture. That’s pretty interesting. Using reinforcement learning to find the right architecture and tuning sounds like a computation heavy solution but cool nevertheless. There’s a <a href="https://arxiv.org/pdf/1611.01578.pdf"><span>paper here</span></a> if you are not afraid of the techie explanation.</p><h2>When should I use AutoML?</h2><p>So now for the main course of this blog post. When is AutoML the better option? When writing this I’m comparing AutoML to do-it-yourself machine learning. Or the conventional solution as of now.&nbsp;</p><p>Just for a minute let’s turn the question around - Why would you ever make your own machine learning models when you can get training, tuning and deployment out the box? Besides having fun with machine learning of course.&nbsp;</p><p>Right now it seems that doing machine learning by hand is default and I believe a bit too many problems are solved from scratch not utilizing the already made work.</p><p>But to answer the question - When to use AutoML, I think there’s currently an obvious sweet spot. When the problem you are trying to solve is kind of general but too specific to be solved by the standard solutions. The problem has to also be somewhat simple still. If it’s a part of a bigger architecture it might be too inflexible. I’ll go into pros and cons in a minute.</p><p>First I’ll mention that AutoML can be used for very different kinds of problems. Not just image recognition problems. It can also be used in:</p><ul data-rte-list="default"><li><p>Language processing (such as sentiment analysis)</p></li><li><p>Translation</p></li><li><p>Video object detection&nbsp;</p></li><li><p>Document classification</p></li><li><p>Churn analysis</p></li></ul><p>And a lot more problems.</p><p>There’s also generally two different ways to deploy the models once they are trained. You can either have them hosted with the vendor or you can download them ready to be deployed on edge products.&nbsp;</p><p>If you leave them hosted you can access them by querying through an API. In that way you can build the model easily into other parts of your product.&nbsp;</p><p>The other option, installing on edge products is meant for IoT solutions. If you are making IoT solutions it might not be optimal to send images of data to an API. It could be inconvenient due to the latency when connecting to the API, it could be impossible to have an internet connection all the time or it could be due to GDPR. Sometimes GDPR is easier to comply with if data is processed locally and not sent to a third party provider.</p><h2>The pros and cons</h2><p>Now for the pros and cons.</p><p><strong>Con: </strong>You get less insights on your data. One of the big advantages in doing machine learning by hand is that you get a lot of learnings into <em>why </em>your models do not work as expected. This gives you valuable insight in both the existing business domain but also a good idea of what data you might need to go out and collect in order to get the necessary results.</p><p><strong>Pro: </strong>You get quicker results. With AutoML you can skip a lot of the machine learning and data science work and as a result save some time. If you are building a prototype to test a product market fit or get early experience on how users will react and use the AI when applied.</p><p><strong>Con: </strong>AutoML is inflexible. You might get results quickly but as most IT goes it won’t be long before the requirements are changing and with a AutoML solution you are running the risk of these requirements suddenly being out of scope of what AutoML can handle. If that happens you have to start all over with a custom model and that can be a cold start.</p><p><strong>Pro: </strong>You’re less likely to be outdated. A very common problem in AI development is that your models are getting old almost as you’re making them. The AI technology is moving so fast that what today might be state of art and requires a lot of hard and intelligent efforts to achieve is tomorrow performing worse than out of the box solutions. With AutoML that pain is placed with the big tech AutoML vendors that have the economics of scale so they can invest in staying ahead.</p><p><strong>Con: </strong>Running cost might be too high when you scale. A pay-per-use model is great for small to medium scale solutions. But if you’re expecting very high volumes in use then you might end up spending too much money with your vendor. In this case it might be a better solution to make and host the models yourself.</p><p><strong>Pro: </strong>With a hosted AutoML solution you will save a lot of time on not having to build the surrounding infrastructure. In <a href="https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf"><span>this paper by Google</span></a> the conclusion is that on average 95% of code in machine learning solutions is “glue code” that builds the infrastructure around the models. The actual machine learning code is just 5%.</p><p><strong>Con: </strong>Quality probably won’t be the highest. If the most important feature in your solution is the highest quality compared to competitors AutoML probably will fall short. AutoML is generalized models and can in most cases not compete with truly specialized models that have been carefully built and tuned to the specific problem from the ground up.</p><p><strong>Pro: </strong>You will need less experts. A common problem in AI is that it requires a lot of expertise and usually involves several different kinds of experts. That’s extremely expensive and experts are hard to find. You can skip a lot of that with AI.</p><h2>Google AutoML</h2><p>I also wanted to go through a specific vendor to make it even more hands on. I choose Google simply because I know it the best. I’ll list some alternatives a little further down.</p><p>Google has spent a lot of effort in AutoML. If it’s reasoned by the expectation that AutoML is the next big thing or if it’s a convenient way to make people upload tons of very specific labeled data that would be too expensive for them to do I can’t tell. It could also just be a way for them to keep advancing their machine learning knowledge.</p><p>You can find Google AutoML here: <a href="https://cloud.google.com/automl"><span>https://cloud.google.com/automl</span></a>. With Google their AutoML is a part of their cloud solution. This is convenient since this is probably also here you’ll store a lot of the training data and maybe even deploy the rest of your code.</p><p>A really cool feature with Google AutoML is that you can set a threshold for recall and precision. If you’re not sure what that is you can read about it in my <a href="https://www.danrose.ai/blog/vi4gsbdxe78pk3rdhwac8ixbtoin0j"><span>other post here</span></a>. It’s really useful for making the models something you can Apply to real world scenarios.</p><h3>Google AutoML Vision</h3><p>With Vision you can do a couple of different things. The primary solutions are following:</p><p><strong>Image labeling: </strong>The AutoML can categorize images from the training you give it. If multiple answers are …</p></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.danrose.ai/blog/automl-is-it-useful">https://www.danrose.ai/blog/automl-is-it-useful</a></em></p>]]>
            </description>
            <link>https://www.danrose.ai/blog/automl-is-it-useful</link>
            <guid isPermaLink="false">hacker-news-small-sites-24433164</guid>
            <pubDate>Thu, 10 Sep 2020 15:22:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[QAnon has found a home among wellness influencers]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24433128">thread link</a>) | @colinprince
<br/>
September 10, 2020 | https://www.cbc.ca/radio/day6/funding-confusion-for-first-nations-schools-qanon-wellness-the-mulan-legend-bring-it-on-turns-20-and-more-1.5711574/qanon-has-found-a-home-among-wellness-influencers-and-new-audiences-says-reporter-1.5711585 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/radio/day6/funding-confusion-for-first-nations-schools-qanon-wellness-the-mulan-legend-bring-it-on-turns-20-and-more-1.5711574/qanon-has-found-a-home-among-wellness-influencers-and-new-audiences-says-reporter-1.5711585">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The QAnon conspiracy has made its way into online communities led by wellness and alternative medicine influencers, according to Mother Jones reporter Ali Breland. Now, social media users who wouldn’t seek out such fringe content are discovering it through Instagram and Twitter feeds dedicated to health.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5658413.1595408998!/fileImage/httpImage/image.JPG_gen/derivatives/16x9_780/usa-election-trump.JPG"></p></div><figcaption>A man in the crowd holds a QAnon sign with the group's abbreviation of their rallying cry 'Where we go one, we go all' at a Donald Trump rally at the Las Vegas Convention Center in Nevada on Feb. 21.<!-- --> <!-- -->(Patrick Fallon/Reuters)</figcaption></figure><p><span></span><span>Listen</span><span>9:34</span></p><p><span><p>The QAnon conspiracy has made its way into online communities led by wellness and alternative medicine influencers, according to one reporter.</p>  <p>Now, social media users who wouldn't seek out such fringe content are discovering it through Instagram and Twitter feeds dedicated to health.</p>  <p>QAnon&nbsp;is a right-wing conspiracy group that believes that so-called deep-state traitors are plotting against U.S. President Donald Trump. Some of its self-professed members also believe&nbsp;a cabal of pedophiles are running a child sex trafficking ring.</p>  <p>These conspiracies have&nbsp;circulated around parts of the internet since Trumps'&nbsp;election. Last month, a reporter asked the president about the theory.</p>  <p>"I don't know much about the movement other than I understand they like me very much, which I appreciate," Trump said.</p>    <p>Ali Breland,&nbsp;a reporter for Mother Jones, has been following the spread of QAnon. He spoke with <em>Day 6</em> host about how the theory has evolved, particularly since the beginning of the COVID-19 pandemic.</p>  <p>Here is part of their conversation.</p>  <p><strong>If I'm a non-conspiratorial type person involved in alternative medicine online, or other wellness communities, how likely is it that QAnon is now showing up in my feed?</strong></p>  <p>It's really hard to fully know definitively, because of the way that Instagram is structured. It's really hard to parse out data. But, anecdotally, from my own observations, from other reporters' observations, and from talking to people who are deeply entrenched in these communities, it's really, really, really common.&nbsp;</p>  <p>Every time I read about these things, I get more messages from people who are like, "What the heck is this crap? This is all over my feed." And then it reifies itself and it's just becoming an unmissable part of this community, even if you're not inclined to believe these things.</p>  <p><strong>An online influencer doesn't necessarily have any particular expertise. But are there people in the health community with academic credentials who are pushing the QAnon line?</strong></p>  <p>A lot of them....&nbsp;They'll have backgrounds in being a chiropractor, things like that. But there's one actually really interesting one. Her name, I believe, is Christiane Northrup, and she has a degree from Dartmouth [Medical School]. She did her residency at Tufts. But [she] is doing this video series called The Great Awakening, which is a very clear nod to QAnon.</p>  <p>"Great Awakening" is a term they've co-opted and clearly made their own. She's posted links to QAnon-related videos.</p>  <p>She's a really difficult example because if you're a lay person who's just trying to go about their business and parse the world, it does become very difficult when you see this kind of information coming from a Dartmouth M.D. We're taught that these things are very valuable.</p>  <p>Whether or not they actually are, it makes your life a lot harder if you're not in these spaces all the time to assess the legitimacy of this person and what she's saying.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5707447.1598960341!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/trump.jpg 300w,https://i.cbc.ca/1.5707447.1598960341!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/trump.jpg 460w,https://i.cbc.ca/1.5707447.1598960341!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/trump.jpg 620w,https://i.cbc.ca/1.5707447.1598960341!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/trump.jpg 780w,https://i.cbc.ca/1.5707447.1598960341!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/trump.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5707447.1598960341!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/trump.jpg"></p></div><figcaption>Trump addressed the QAnon conspiracy last month, saying 'I understand they like me very much,' in response to a reporter's question.<!-- --> <!-- -->(Andrew Harnik/The Associated Press)</figcaption></figure></span></p>  <p><strong>These two worlds — QAnon, a conspiracy theory and wellness, which is connected to science — they don't seem like they would have a lot of obvious connections. What is the overlap here? How did this develop?</strong></p>  <p>They definitely don't seem like they have obvious connections, but if you zoom out for a bit, there is a sort of clear connection.&nbsp;</p>  <p>What a lot of wellness influencers have in common is that they're anti-vaxxers. This isn't universal by any stretch of the imagination; I don't want to paint a community in broad strokes, but there is a lot of crossover. And if you think about it, the anti-vaccination conspiracy is beat for beat almost the same conspiracy as QAnon.</p>  <p><strong>In what way?</strong></p>  <p>[It's the idea that] these big powerful interests — these external interests that are beyond us, like Big Pharma — that we can't conceptualize are trying to hurt our children ... and we need to protect them because no one else will.</p>  <p>That's the prevailing belief of QAnon: that there is a liberal elite kidnapping children and putting them into pedophile rings and stealing and drinking their blood. It's much more fantastical than anti-vaccination conspiracy theories, but it is the same thing: our children are under threat, our children are being attacked, and we need to protect them because powerful interests don't want us to protect them. They're out to get us.</p>  <p><strong>This week on Twitter, the phrase "only six per cent" trended&nbsp;because of a tweet from a QAnon supporter who falsely claimed that 94 per cent of deaths attributed to COVID were bogus.</strong></p>  <p><strong>Trump retweeted it. Several right-wing politicians jumped on it and Twitter took down the tweet, but it was already trending. What's the lesson there?</strong></p>  <p>So there's two lessons. If you just look at Twitter's actions within itself, it's good that they're doing something about this. But at the same time, you wonder how interested they are in actually structurally reforming these kinds of things and taking action ahead of time. Reddit decided to take down all of its QAnon pages back in 2018, right? Twitter had two years to do something and it didn't. So it's nice <a href="https://www.cbc.ca/news/technology/twitter-qanon-accounts-1.5658411" target="_blank">that they're doing this after the fact</a>, but it's almost too late.</p>  <p>[There] is another&nbsp;serious point of concern with QAnon: people point to how some of its supporters have gotten violent. But also, it can spread real political misinformation and affect actual policy.</p>    <p>It's almost imminent by next year that there will be QAnon-supporting Congressmen. <a href="https://www.cbc.ca/news/world/us-primaries-greene-omar-1.5683022" target="_blank">Marjorie Taylor Green in Georgia just won her primary race</a>, in a race that she's expected to beat&nbsp;her Democratic opponent in November pretty handily. There's other potential cases where QAnon-supporting candidates could win their races as well.</p>  <p>QAnon mobs have been attacking a state senator in California who's proposing LGBTQ equality legislation. They're accusing him of being a pedophile. They're lobbing homophobic and anti-Semitic smears of him to oppose the legislation. The concern is that these people will start affecting politics in harmful and unhealthy ways that aren't rooted in reality at all.</p>  <hr>  <p><em>Written by Jason Vermes. Produced by&nbsp;Pedro Sanchez. Q&amp;A edited for length and clarity.</em></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/radio/day6/funding-confusion-for-first-nations-schools-qanon-wellness-the-mulan-legend-bring-it-on-turns-20-and-more-1.5711574/qanon-has-found-a-home-among-wellness-influencers-and-new-audiences-says-reporter-1.5711585</link>
            <guid isPermaLink="false">hacker-news-small-sites-24433128</guid>
            <pubDate>Thu, 10 Sep 2020 15:19:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Removing email registration improved retention]]>
            </title>
            <description>
<![CDATA[
Score 133 | Comments 168 (<a href="https://news.ycombinator.com/item?id=24433090">thread link</a>) | @tapneal
<br/>
September 10, 2020 | https://solitaired.com/email-registration-is-dead | <a href="https://web.archive.org/web/*/https://solitaired.com/email-registration-is-dead">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><center><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/coverimage.png"></center><p>
In our last business, where we ran popular educational products like EasyBib, we learned the power of email registration. When users registered we found that they would come back and use our service more, and eventually subscribe. </p>
<h2 id="firststeptoimproveretentionaddregistration">First step to improve retention: Add registration</h2>
<p>When building our <a href="https://solitaired.com/">solitaire site</a> then, a fun side hobby of ours, adding in email registration and account creation was immediately on our roadmap. When we added the ability to create accounts and track past scores, we immediately saw that our sessions per user increased by 5%. It was a solid win!</p>
<center><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/fivelift.png"></center>
<p>To encourage more registrations we introduced a leaderboard to see how you performed against other players. You could see how your time and number of moves compared to others who played the same game, and we encouraged sign ups to get your name on the leaderboard. This improved registrations by 22%, and we saw sessions per user increase another 3%. </p>
<center><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/threelift.png"></center>
<p>All these features encouraged users to play more, compete against themselves and others, and return to the site.</p>
<h2 id="dosendingemailsmoveourkpis">Do sending emails move our KPIs?</h2>
<p>By now, we had learned that registration was a powerful feature in our game to drive loyalty and retention. Given that we were collecting emails as part of our standard registration process, we naturally thought emailing our user base, which had reached over 15,000 users, could naturally drive more return usage. </p>
<p>We started emailing our users to play a new game of the day feature we introduced. Open rates were a solid 17% on average, but click through rates to the game were 1%. This meant it drove about 26 more users to our site (15,000 * 17% * 1%). Moreover, these could have been users who would have gone back to Solitaired whether they read our email or not. </p>
<p>We saw a 0.5% improvement in returning users, but when we stopped sending emails, this didnâ€™t change suggesting the modest improvement was just noise.</p>
<h2 id="removingemailregistration">Removing email registration</h2>
<p>While registration, saving accounts, and leaderboards improved retention, sending emails clearly did not. </p>
<p>I was watching my sister play, who had become a solitaire addict after she QAing the game. She was obsessed with beating her personal bests and getting high scores for the game of the day. When I watched her play though, quizzically, she had not registered for an account. </p>
<p>I asked her why, she said she just didnâ€™t want to give her email away and get bombarded by more emails. I was dumbfounded, because after all, her brother (me), was the co-founder of the site and yet she still had these concerns.</p>
<center><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/sister.png"></center>
<p>The lightbulb went off. Since sending emails did not provide value, and if anything was an additional cost,  what if we just asked for a username. While this creates issues with password recovery, we thought this would drive up registrations and improve retention. We also have a long term cookie so users wouldnâ€™t have to login again. </p>
<p>When we changed email sign ups simply to usernames, we saw registrations increase by a huge 36%! More importantly, we saw return users increase another 4.5%.</p>
<p>This meant email registration was holding us back from driving retention. </p>
<center><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/fourfivelift.png"></center>
<p>Digging in further, we're also seeing return visitors playing more games like <a href="https://solitaired.com/freecell">Freecell</a> and <a href="https://solitaired.com/spider">Spider</a>. Leaderboards and simple registration have encouraged users to try new games.</p>
<h2 id="weassumeemailisvaluable">We assume email is valuable</h2>
<p>Depending on your site and space, email surely can be valuable. For ecommerce sites, you can send targeted emails with special offers, for example. </p>
<p>Most of us assume email is beneficial to our businesses, and we rarely test to see if thatâ€™s the case. We have it because it gives us an owned channel to reach out and engage our users whenever we want. </p>
<p>However, we're forgetting a key fact: most of us also hate emails from commercial sites. They clog our inbox, and we instinctually either ignore or delete them. Every once in a while we might open one of those emails up, and even more rarely, we might click the call to action in the email. </p>
<p>Ask if requiring email addresses really moves important business metrics for your site. Sometimes they do. In our case, it just created a poor user experience which weâ€™re now happy to be rid of.</p></div></div></div></div>]]>
            </description>
            <link>https://solitaired.com/email-registration-is-dead</link>
            <guid isPermaLink="false">hacker-news-small-sites-24433090</guid>
            <pubDate>Thu, 10 Sep 2020 15:15:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[References for my video on nuclear power]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24432524">thread link</a>) | @ericdanielski
<br/>
September 10, 2020 | https://www.simonoxfphys.com/blog/nuclearreferences | <a href="https://web.archive.org/web/*/https://www.simonoxfphys.com/blog/nuclearreferences">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>As the reference list for my nuclear power video is too long to fit into the YouTube description box, I’m putting it here instead!</p><div data-rte-list="default"><li><p>CO2 concentrations <a href="https://ourworldindata.org/co2-and-other-greenhouse-gas-emissions">https://ourworldindata.org/co2-and-other-greenhouse-gas-emissions</a></p></li><li><p>Number of nuclear reactors <a href="https://www-pub.iaea.org/MTCD/Publications/PDF/rds2-35web-85937611.pdf">https://www-pub.iaea.org/MTCD/Publications/PDF/rds2-35web-85937611.pdf</a></p></li><li><p>Deaths per TWh <a href="https://ourworldindata.org/safest-sources-of-energy">https://ourworldindata.org/safest-sources-of-energy</a></p></li><li><p>Death toll from Chernobyl <a href="https://ourworldindata.org/what-was-the-death-toll-from-chernobyl-and-fukushima">https://ourworldindata.org/what-was-the-death-toll-from-chernobyl-and-fukushima</a></p></li><li><p>Emissions per kWh <a href="https://www.ipcc.ch/site/assets/uploads/2018/02/06_figure_7.6.png">https://www.ipcc.ch/site/assets/uploads/2018/02/06_figure_7.6.png</a></p></li><li><p>World electricity generation <a href="https://commons.wikimedia.org/wiki/File:World_electricity_generation_by_source_pie_chart.svg">https://commons.wikimedia.org/wiki/File:World_electricity_generation_by_source_pie_chart.svg</a> </p></li><li><p>France electricity generation <a href="https://environmentalprogress.org/france">https://environmentalprogress.org/france</a> </p></li><li><p>100% renewables countries <a href="https://en.wikipedia.org/wiki/Renewable_energy_transition#Places_with_near_100%_renewable_electricity">https://en.wikipedia.org/wiki/Renewable_energy_transition#Places_with_near_100%_renewable_electricity</a> </p></li><li><p>Space required for solar <a href="https://www.axionpower.com/knowledge/power-world-with-solar/">https://www.axionpower.com/knowledge/power-world-with-solar/</a> </p></li><li><p>Cost per kWh <a href="https://www.ipcc.ch/site/assets/uploads/2018/02/07_figure_7.7.png">https://www.ipcc.ch/site/assets/uploads/2018/02/07_figure_7.7.png</a></p></li><li><p>Solar costs down 90% <a href="https://bnef.turtl.co/story/neo2019/page/5/1">https://bnef.turtl.co/story/neo2019/page/5/1</a></p></li><li><p>Nuclear plant construction costs <a href="http://large.stanford.edu/courses/2016/ph241/keller2/docs/schlissel.pdf">http://large.stanford.edu/courses/2016/ph241/keller2/docs/schlissel.pdf</a></p></li><li><p>Access to electricity <a href="https://www.iea.org/reports/sdg7-data-and-projections/access-to-electricity#abstract">https://www.iea.org/reports/sdg7-data-and-projections/access-to-electricity#abstract</a></p></li><li><p>Microgrid as solution in rural areas <a href="https://www.iea.org/reports/energy-access-outlook-2017">https://www.iea.org/reports/energy-access-outlook-2017</a></p></li><li><p>Renewables mining costs <a href="https://www.theguardian.com/sustainable-business/rare-earth-mining-china-social-environmental-costs">https://www.theguardian.com/sustainable-business/rare-earth-mining-china-social-environmental-costs</a></p></li><li><p>Uranium mining risks <a href="https://www.ncbi.nlm.nih.gov/books/NBK201052/">https://www.ncbi.nlm.nih.gov/books/NBK201052/</a></p></li><li><p>A1B prediction <a href="https://www.gfdl.noaa.gov/visualizations-climate-prediction/">https://www.gfdl.noaa.gov/visualizations-climate-prediction/</a></p></li><li><p>Nuclear construction time <a href="https://www.statista.com/statistics/712841/median-construction-time-for-reactors-since-1981/">https://www.statista.com/statistics/712841/median-construction-time-for-reactors-since-1981/</a></p></li><li><p>US 80-90% renewables <a href="https://www.nrel.gov/docs/fy13osti/52409-ES.pdf">https://www.nrel.gov/docs/fy13osti/52409-ES.pdf</a></p></li><li><p>Australia 100% renewables [<a href="https://www.researchgate.net/publication/303811410_100_RENEWABLE_ENERGY_FOR_AUSTRALIA_Decarbonising_Australia's_Energy_Sector_Within_One_Generation_Prepared_for_GetUp_and_Solar_Citizens_CITATION_Teske_S_Dominish_E_Ison_N_and_Maras_K_2016_100_Renewable%5D(https://www.researchgate.net/publication/303811410_100_RENEWABLE_ENERGY_FOR_AUSTRALIA_Decarbonising_Australia's_Energy_Sector_Within_One_Generation_Prepared_for_GetUp_and_Solar_Citizens_CITATION_Teske_S_Dominish_E_Ison_N_and_Maras_K_2016_100_Renewable">https://www.researchgate.net/publication/303811410_100_RENEWABLE_ENERGY_FOR_AUSTRALIA_Decarbonising_Australia's_Energy_Sector_Within_One_Generation_Prepared_for_GetUp_and_Solar_Citizens_CITATION_Teske_S_Dominish_E_Ison_N_and_Maras_K_2016_100_Renewable](https://www.researchgate.net/publication/303811410_100_RENEWABLE_ENERGY_FOR_AUSTRALIA_Decarbonising_Australia's_Energy_Sector_Within_One_Generation_Prepared_for_GetUp_and_Solar_Citizens_CITATION_Teske_S_Dominish_E_Ison_N_and_Maras_K_2016_100_Renewable</a>)</p></li><li><p>TV pickup <a href="http://www.todayifoundout.com/index.php/2017/05/uk-really-experience-power-surges-soap-operas-finish/">http://www.todayifoundout.com/index.php/2017/05/uk-really-experience-power-surges-soap-operas-finish/</a></p></li><li><p>Irish wind power <a href="https://www.irishexaminer.com/business/arid-20257673.html">https://www.irishexaminer.com/business/arid-20257673.html</a></p></li><li><p>Firm low carbon definition and paper <a href="https://www.sciencedirect.com/science/article/pii/S2542435118303866">https://www.sciencedirect.com/science/article/pii/S2542435118303866</a></p></li><li><p>Next generation geothermal <a href="https://www.energy.gov/sites/prod/files/2016/05/f31/EGS">https://www.energy.gov/sites/prod/files/2016/05/f31/EGS</a> Fact Sheet May 2016.pdf</p></li><li><p>Note that this is a rather unhelpful idea. See: Marshall, George. Don't Even Think About It: Why our Brains are Wired to Ignore Climate Change. New York: Bloomsbury, 2014</p></li><li><p>Klein, Naomi. This Changes Everything : Capitalism vs. the Climate. New York. Simon &amp; Schuster, 2014</p></li><li><p>Gates nuclear claim <a href="https://www.world-nuclear-news.org/Articles/Nuclear-the-ideal-way-for-dealing-with-climate-c">https://www.world-nuclear-news.org/Articles/Nuclear-the-ideal-way-for-dealing-with-climate-c</a></p></li><li><p>BBC 2030 pathway <a href="https://www.bbc.com/news/science-environment-46347453">https://www.bbc.com/news/science-environment-46347453</a></p></li><li><p>REN21 renewable energy percentage <a href="https://ren21.net/gsr-2018/">https://ren21.net/gsr-2018/</a></p></li></div></div>]]>
            </description>
            <link>https://www.simonoxfphys.com/blog/nuclearreferences</link>
            <guid isPermaLink="false">hacker-news-small-sites-24432524</guid>
            <pubDate>Thu, 10 Sep 2020 14:12:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Clojure Spec is and what you can do with it]]>
            </title>
            <description>
<![CDATA[
Score 257 | Comments 63 (<a href="https://news.ycombinator.com/item?id=24432461">thread link</a>) | @icey
<br/>
September 10, 2020 | https://www.pixelated-noise.com/blog/2020/09/10/what-spec-is/ | <a href="https://web.archive.org/web/*/https://www.pixelated-noise.com/blog/2020/09/10/what-spec-is/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><img src="https://www.pixelated-noise.com/assets/images/people/stathis-sideris.jpeg"></p><div><p>Stathis Sideris</p><p>2020-09-10</p></div></div>
<p>
<i>Pixelated Noise is a software consultancy and we're always looking for interesting projects to help out with. If you have unmet software development needs, we would be happy <a href="https://www.pixelated-noise.com/contact/">to hear from you</a>.</i>
</p>

<p>
This is the blog version of a talk I gave on the 2017-12-13 at the Athens
Clojure Meetup, which was kindly hosted by <a href="https://engineering.skroutz.gr/">Skroutz</a>. <a href="https://www.youtube.com/watch?v=T1qpIaB6_vM">The video of the talk</a> is
available (the talk was given in Greek, but there are English subtitles). This
blog entry is not an exact transcript of the talk, I've added links and more
information where appropriate (plus the "bonus" sections that were not in the
talk). Since the talk was given a while ago, some information will be outdated.
</p>

<p>
There are essentially two parts to this article: the "what it is" part which
introduces the basic concepts and mechanisms of spec, and also provides some
information so that non-Clojurians can see how spec fits into the larger picture
and the "what you can do with it" part which explores some more interesting use
cases that go beyond basic usage.
</p>

<div id="outline-container-orge99096d">
<h2 id="orge99096d">What is it?</h2>
<div id="text-orge99096d">
<p>
Clojure is a dynamic language that doesn't enforce the types of parameters or
the return values of functions. This has been a characteristic of the language
that has drawn criticism both internally and from other language communities and
has possibly been a factor impeding adoption in the past.
</p>

<p>
Spec in a way is the response to that, but it's a response that maybe the
community didn't expect because it does not take the traditional approach of
checking types statically. At a very fundamental level spec is a declarative
language that describes data, their type, their shape. Spec follows the general
philosophy of Clojure in that all of its functionality is available at runtime,
you can use it, introspect it, generate it – there is no extra step before
execution when the compiler checks your whole codebase for errors.
</p>
</div>

<div id="outline-container-org56f06dc">
<h3 id="org56f06dc">What does it look like?</h3>
<div id="text-org56f06dc">
<p>
Spec is still alpha, so the namespace in the <code>require</code> contains <code>.alpha</code> to indicate
that. The following spec defines a <code>username</code> "entity" and says that it has to be
a string:
</p>

<div>
<pre>(require '[clojure.spec.alpha <span>:as</span> s])

(<span>s</span>/<span>def</span> <span>::username</span> string?)
</pre>
</div>

<p>
<code>string?</code> is a simple function that exists in Clojure core, it's a
predicate function that you pass a string to and it returns <code>true</code> or
<code>false</code>, depending on whether the passed value is a string or not.
</p>

<p>
Once you've defined a spec the simplest usage of it is to ask whether
something is valid, by calling <code>valid?</code>, and passing the name of the
spec and then a value:
</p>

<div>
<pre>(println
 (<span>s</span>/valid? <span>::username</span> <span>"foo"</span>))
</pre>
</div>

<pre>true
</pre>
</div>
</div>

<div id="outline-container-orgfa7c72e">
<h3 id="orgfa7c72e">It's just predicates!</h3>
<div id="text-orgfa7c72e">
<p>
Many cases are covered by built-in predicates, but that doesn't mean
we can't use our own. If we need a spec that checks that a number is
above 5, we can simply write an anonymous function like this one,
and then use it normally as it if was a spec itself:
</p>



<pre>true
</pre>


<p>
And it works as expected with different inputs:
</p>



<pre>false
</pre>
</div>
</div>

<div id="outline-container-org6c5c14c">
<h3 id="org6c5c14c">Validate data</h3>
<div id="text-org6c5c14c">
<p>
So, we write a spec and it can validate our data. Let's draw this as a
diagram: the thing on the left that looks like a blueprint is a spec and the
curly braces on the right represents Clojure data (because very often data in
Clojure are maps and maps are written with curly braces). Read the weird arrow
in the middle as "validates":
</p>


<p><img src="https://www.pixelated-noise.com/blog/2020/09/10/what-spec-is/validate-data.png" alt="validate-data.png">
</p>

<p>
It's not much of a diagram, but I'm trying to establish the visual language
for the rest of this article.
</p>
</div>
</div>

<div id="outline-container-orgea7799a">
<h3 id="orgea7799a">Collections specs</h3>
<div id="text-orgea7799a">
<p>
Specs can also be applied to collections by composing and nesting
more basic specs together. Here we define an entity called <code>usernames</code>
made up of a collection of <code>username</code>:
</p>

<div>
<pre>(require '[clojure.spec.alpha <span>:as</span> s])

(<span>s</span>/<span>def</span> <span>::username</span> string?)
(<span>s</span>/<span>def</span> <span>::usernames</span> (<span>s</span>/coll-of <span>::username</span>))

(println
 (<span>s</span>/valid? <span>::usernames</span> [<span>"foo"</span> <span>"bar"</span> <span>"baz"</span>]))
</pre>
</div>

<pre>true
</pre>


<p>
You would normally not define this as a separate entity for something that
simple, as <code>s/coll-of</code> can be used ad-hoc in your program.
</p>
</div>
</div>

<div id="outline-container-org81b3460">
<h3 id="org81b3460">Maps</h3>
<div id="text-org81b3460">
<p>
Maps are a bit more interesting. Other technologies such as <a href="https://github.com/plumatic/schema">plumatic
schema</a> (which at some point was the de facto way to validate data in
Clojure), ask you to define both the keys that have to be present in
a map and the data types of the values that correspond to the
keys. The resulting definition looks a bit like a rigidly-defined
class that you usually see in object-oriented languages. Spec very
deliberately moves away from this mentality: the maps are <b>not</b> like
objects, they are <b>not</b> fixed and do not necessarily exist in that one
shape. Instead, maps simply happen to be aggregations of some named
values.
</p>

<p>
This design decision is embodied in two ways:
</p>

<ul>
<li>A map spec written using <code>s/keys</code> which does not define the types of
the values of the map, we only define which existing entities make
up the map.</li>

<li>The name of the key inside the map has to be the same as the name
of the spec already defined elsewhere.</li>
</ul>

<p>
In this case we have defined some single-value specs like username,
password, last-login and comment, and they are aggregated together
in a map defined by the <code>::user</code> spec.
</p>

<div>
<pre>(<span>ns</span> <span>my-project.users</span>
  (<span>:require</span> [clojure.spec.alpha <span>:as</span> s]))

(<span>s</span>/<span>def</span> <span>::username</span> string?)
(<span>s</span>/<span>def</span> <span>::password</span> string?)

(<span>s</span>/<span>def</span> <span>::last-login</span> number?)
(<span>s</span>/<span>def</span> <span>::comment</span> string?)

(<span>s</span>/<span>def</span> <span>::user</span>
  (<span>s</span>/keys
   <span>:req</span> [<span>::username</span> <span>::password</span>]
   <span>:opt</span> [<span>::comment</span> <span>::last-login</span>]))

(println <span>::username</span>)

(println
 (<span>s</span>/valid?
  <span>::user</span>
  {<span>::username</span>   <span>"rich"</span>
   <span>::password</span>   <span>"zegure"</span>
   <span>::comment</span>    <span>"this is a user"</span>
   <span>::last-login</span> 11000}))
</pre>
</div>

<pre>:my-project.users/username ;;this is what fully-qualified keywords look like
true
</pre>


<p>
Spec also encourages the use of qualified keywords: Until recently
in Clojure people would use keywords with a single colon but the two
colons (<code>::</code>) mean that keywords belong to this namespace, in this
case <code>my-project.users</code>. This is another deliberate choice, which is
about creating strong names (or "fully-qualified"), that belong to a
particular namespace, so that we can mix namespaces within the same
map. This means that we can have a map that comes from outside our
system and has its own namespace, and then we add more keys to this
map that belong to our own company's namespace without having to
worry about name clashes. This also helps with data provenance,
because you know that the <code>:subsystem-a/id</code> field is not simply an ID
– it's an ID that was assigned by subsystem-a.
</p>
</div>
</div>

<div id="outline-container-org3248f46">
<h3 id="org3248f46">Maps are open</h3>
<div id="text-org3248f46">
<p>
The other interesting thing about specs for maps is that they are
open. For example, if we use the same exact map as before, with the
same fields and an additional field called <code>::age</code>, it's still a valid
<code>::user</code>:
</p>

<div>
<pre>(<span>ns</span> <span>my-project.users</span>
  (<span>:require</span> [clojure.spec.alpha <span>:as</span> s]))

(<span>s</span>/<span>def</span> <span>::username</span> string?)
(<span>s</span>/<span>def</span> <span>::password</span> string?)

(<span>s</span>/<span>def</span> <span>::last-login</span> number?)
(<span>s</span>/<span>def</span> <span>::comment</span> string?)

(<span>s</span>/<span>def</span> <span>::user</span>
  (<span>s</span>/keys
   <span>:req</span> [<span>::username</span> <span>::password</span>]
   <span>:opt</span> [<span>::comment</span> <span>::last-login</span>]))

(println
 (<span>s</span>/valid?
  <span>::user</span>
  {<span>::username</span>   <span>"rich"</span>
   <span>::password</span>   <span>"zegure"</span>
   <span>::comment</span>    <span>"this is a user"</span>
   <span>::last-login</span> 11000
   <span>::age</span>        26}))
</pre>
</div>

<pre>true
</pre>


<p>
This happens because spec does not mind if you've defined four keys, if it
sees a fifth key the map does not become invalid. The reason for this is that
when we have a system that accumulates information this accumulation should
not break the system, the code that consumes the map should simply ignore the
keys it doesn't know about. If you're making a system and you're accumulating
extra options, parameters, whatever it is – your code should be able to
continue to run without having to change a lot of code locations, like you
would have to do in an object oriented language or Haskell.
</p>

<p>
This accumulation has also been described by the term "accretion"
and has been discussed in the excellent <a href="https://www.youtube.com/watch?v=oyLBGkS5ICk">Spec-ulation Keynote talk</a> by
Rich Hickey.
</p>

<p>
On the other hand, a lot of people who use spec to validate things coming from
outside their system need to be more strict with maps, and they have
complained about the openness of maps. We'll talk about proposed solutions to
this issue later.
</p>
</div>
</div>

<div id="outline-container-org0b68930">
<h3 id="org0b68930">Explain your problems</h3>
<div id="text-org0b68930">
<p>
Another usage of specs, beyond validation, is "explain" which
essentially can produce errors that tell you what's wrong with your
data. In this case we'll try to create an error by creating a user
that's invalid because it doesn't have a password – a required key:
</p>

<div>
<pre>(<span>ns</span> <span>my-project.users</span>
  (<span>:require</span> [clojure.spec.alpha <span>:as</span> s]))

(<span>s</span>/<span>def</span> <span>::username</span> string?)
(<span>s</span>/<span>def</span> <span>::password</span> string?)

(<span>s</span>/<span>def</span> <span>::last-login</span> number?)
(<span>s</span>/<span>def</span> <span>::comment</span> string?)

(<span>s</span>/<span>def</span> <span>::user</span>
  (<span>s</span>/keys
   <span>:req</span> [<span>::username</span> <span>::password</span>]
   <span>:opt</span> [<span>::comment</span> <span>::last-login</span>]))

(<span>s</span>/explain
 <span>::user</span>
 {<span>::username</span>   <span>"rich"</span>
  <span>::comment</span>    <span>"this is a user"</span>})
</pre>
</div>

<p>
We get an ok-ish error that tells us that for the particular map we
passed, the <code>::user</code> spec fails because it doesn't contain <code>::password</code>.
</p>

<pre>val: #:my-project.users{:username "rich", :comment "this is a user"} fails spec: :my-project.users/user predicate: (contains? % :my-project.users/password)
</pre>
</div>
</div>

<div id="outline-container-orgb0d0b9f">
<h3 id="orgb0d0b9f">Sequence specs - regular expressions for data</h3>
<div id="text-orgb0d0b9f">
<p>
A powerful mechanism in spec is sequences. We've already seen <code>s/coll-of</code> which
contains a uniform type of values (a collection of numbers for example) but
sequences are a bit more like regular expressions for data. In this case we
have a sequence with two things, which describe an ingredient for a recipe:
the first thing is a number for the quantity and the second thing is a unit
encoded as a keyword.
</p>

<div>
<pre>(require '[clojure.spec.alpha <span>:as</span> s])

(<span>s</span>/<span>def</span> <span>::ingredient</span> (<span>s</span>/cat <span>:quantity</span> number? <span>:unit</span> keyword?))
</pre>
</div>

<p>
With <code>s/cat</code> we always have to give a name to each position. <code>s/cat</code>
allows to both validate the shape of the value passed, but it also
enables the "conform" operation, which is somehow similar to parsing
or destructuring. If we pass a vector of two elements – a number and
a keyword –  we get back a map with the defined names:
</p>

<div>
<pre>(prn (<span>s</span>/conform <span>::ingredient</span> [2 <span>:teaspoon</span>]))
</pre>
</div>

<pre>{:quantity 2, :unit :teaspoon}
</pre>


<p>
By using some of the other operators which are reminiscent of regular
expressions, this technique can become quite …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pixelated-noise.com/blog/2020/09/10/what-spec-is/">https://www.pixelated-noise.com/blog/2020/09/10/what-spec-is/</a></em></p>]]>
            </description>
            <link>https://www.pixelated-noise.com/blog/2020/09/10/what-spec-is/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24432461</guid>
            <pubDate>Thu, 10 Sep 2020 14:04:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Curated collection of 82 free beautiful CSS box-shadow ready-to-use]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24432402">thread link</a>) | @guivr
<br/>
September 10, 2020 | https://getcssscan.com/css-box-shadow-examples | <a href="https://web.archive.org/web/*/https://getcssscan.com/css-box-shadow-examples">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
    All of these box-shadow were copied using <a href="https://getcssscan.com/?ref=beautifulboxshadow" target="_blank" data-tippy-content="CSS Scan: Check the CSS of any element you hover over, instantly, and copy its entire rules and selector with a single click."><img src="https://toastlog.com/img/logos/cssscan.svg" alt="CSS Scan logo"> CSS Scan</a> (<a href="https://getcssscan.com/?ref=beautifulboxshadow2" target="_blank">click here</a> to try a free demo)</p><div href="https://getcssscan.com?ref=beautifulboxshadow-bottom" target="_blank">
    <div>
      <p>Have you seen CSS Scan?</p>
      <p>Check the CSS of any element you hover over, instantly.</p>
      <p>Learn more →</p>
      <p><img src="https://toastlog.com/img/logos/cssscan.svg" alt="CSS Scan logo">
    </p></div>
  </div></div>]]>
            </description>
            <link>https://getcssscan.com/css-box-shadow-examples</link>
            <guid isPermaLink="false">hacker-news-small-sites-24432402</guid>
            <pubDate>Thu, 10 Sep 2020 13:58:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Text Classification Using Long Short Term Memory and GloVe Embeddings]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24432379">thread link</a>) | @mwitiderrick
<br/>
September 10, 2020 | https://heartbeat.fritz.ai/text-classification-using-long-short-term-memory-glove-embeddings-6894abb730e1 | <a href="https://web.archive.org/web/*/https://heartbeat.fritz.ai/text-classification-using-long-short-term-memory-glove-embeddings-6894abb730e1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="0f1e">Classify Text using Pre-trained Embeddings and Bidirectional LSTMs</h2><div><div><div><p><a href="https://heartbeat.fritz.ai/@mwitiderrick?source=post_page-----6894abb730e1----------------------" rel="noopener"><img alt="Derrick Mwiti" src="https://miro.medium.com/fit/c/96/96/2*9aohLPF6ipIrrmZ50g8zNQ.jpeg" width="48" height="48"></a></p></div></div></div></div></div><div><p id="e02b">Preparing textual data for machine learning is a little different than the preparation of tabular data. What makes text data different is the fact that it’s majorly in string form. Therefore, we have to find the best way to represent it in numerical form. In this piece, we’ll see how we can prepare textual data using TensorFlow. Eventually, we’ll build a bidirectional <a target="_blank" rel="noopener" href="https://heartbeat.fritz.ai/a-beginners-guide-to-implementing-long-short-term-memory-networks-lstm-eb7a2ff09a27">long short term memory</a> model to classify text data.</p></div></section><hr><section><div><div><h2 id="d8a7">Import the Necessary Packages</h2><p id="c292">As always, we kick off by importing the packages and modules we’ll use for this exercise:</p><ul><li id="b412"><code>Tokenizer</code> for preprocessing the text data</li><li id="3f6a"><code>pad_sequences</code> for ensuring that the final text data has the same length</li><li id="3dda"><code>sequential</code> for initializing the layers</li><li id="0670"><code>Dense</code> for creating the fully connected neural network</li><li id="33aa"><code>LSTM</code> used to create the LSTM layer</li><li id="42b2"><code>Bidirectional</code> to ensure that information is passed in both directions</li><li id="eb2a"><code>pandas</code> to load in the text file</li><li id="1217"><code>numpy</code> will convert the data into NumPy arrays</li></ul><figure><div></div></figure><h2 id="62fd">Load the Data</h2><p id="8dcb">Let’s first import the dataset. The data and code are available on this <a href="https://github.com/mwitiderrick/TensorFlow-GLOVE-LSTM" target="_blank" rel="noopener">repository</a>.</p><figure><div></div></figure><p id="c36c">We can look at a sample from the dataset. This shows us that we have a <code>Review</code> and a <code>Status</code> column.</p><figure><div></div></figure><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/998/1*aqNKfz-GKDSLzCAoBQu_sQ.png" width="499" height="83" srcset="https://miro.medium.com/max/552/1*aqNKfz-GKDSLzCAoBQu_sQ.png 276w, https://miro.medium.com/max/998/1*aqNKfz-GKDSLzCAoBQu_sQ.png 499w" sizes="499px" data-old-src="https://miro.medium.com/max/60/1*aqNKfz-GKDSLzCAoBQu_sQ.png?q=20"></p></div></div></figure><h2 id="e126">Split the Data</h2><p id="2da9">Next, we split the dataset into a training set and a testing set. But before we can do that, we first have to define the features <code>X</code> and the target <code>y</code>.</p><figure><div></div></figure><p id="f1a5">Let’s now use 80% of the data for training and 20% for testing.</p><figure><div></div></figure><h2 id="c69b">Data Preprocessing</h2><p id="d7fb">At this point we need to perform a couple of operations on the text data:</p><ul><li id="9892">convert it to lowercase</li><li id="f5d0">filter out punctuation marks such as <code>?</code> and <code>!</code></li><li id="6bf1">remove any special characters such as <code>@</code> and <code>$</code></li><li id="b9dd">convert the text into a preferred number representation</li></ul><p id="9b58">Now, as we’ll see, doing those operations in TensorFlow is quite straightforward.</p><p id="4a23">In a minute we’ll tokenize the text data to obtain the 1000 most common words. Before we get there, let’s create a couple of variables that we’ll need.</p><ul><li id="8a5f"><code>vocab_size</code> is the number of common words that we want — the maximum number of words that will be included in the word index</li><li id="9a5f"><code>oov_token</code> is the item that will be used to represent words that will not be found in our vocabulary; this is possible when fitting the tokenizer to the testing set. This is represented using the number 1</li><li id="47f5"><code>max_length</code> is the maximum length of each sequence</li><li id="a36c"><code>padding_type</code> is used to fill zeros either at the beginning or at the end of a sequence</li><li id="5445"><code>trunction_type</code> indicates whether to truncate sentences longer than the <code>max_lenth</code> at the beginning or at the end</li></ul><figure><div></div></figure><p id="c154">Now let’s tokenize — convert the text into a numerical representation. We do this by creating a <code>tokenizer</code> instance and calling <code>fit_on_texts</code> to the training set. The <code>tokenizer</code> will remove the punctuation marks and special characters, and then convert the words to lowercase.</p><figure><div></div></figure><p id="32e8">We can see the mapping of the words and text using the word index.</p><figure><div></div></figure><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/398/1*KThrPNpHGGTtlD0OwlEQ-g.png" width="199" height="326" data-old-src="https://miro.medium.com/max/36/1*KThrPNpHGGTtlD0OwlEQ-g.png?q=20"></p></div></div></figure><h2 id="34b7">Create Sequences</h2><p id="c6f2">Let’s now convert the sentences into tokenized sequences. This is done using the <code>texts_to_sequences</code> function.</p><figure><div></div></figure><p id="965d">Now when we visualize the sentence, we see that each sentence contains a numerical representation of the words in that sentence.</p><figure><div></div></figure><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/886/1*X61MItiCQ7HGCabSLtFAkg.png" width="443" height="105" srcset="https://miro.medium.com/max/552/1*X61MItiCQ7HGCabSLtFAkg.png 276w, https://miro.medium.com/max/886/1*X61MItiCQ7HGCabSLtFAkg.png 443w" sizes="443px" data-old-src="https://miro.medium.com/max/60/1*X61MItiCQ7HGCabSLtFAkg.png?q=20"></p></div></div></figure></div></div></section><hr><section></section><hr><section><div><div><h2 id="a691">Pad the Sequences</h2><p id="6527">We can clearly see that the sequences are not of the same length, so let’s pad them to make them of similar length — important before we can pass the data to a deep learning model.</p><figure><div></div></figure><p id="7040">We can now see that there are zeros at the end of the sequences, which makes them all the same length. The padding is taking place at the end of the sequence because we specified the padding type as <code>post</code>.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1310/1*EQpKPdhYEtA2F_lzOordyw.png" width="655" height="188" srcset="https://miro.medium.com/max/552/1*EQpKPdhYEtA2F_lzOordyw.png 276w, https://miro.medium.com/max/1104/1*EQpKPdhYEtA2F_lzOordyw.png 552w, https://miro.medium.com/max/1280/1*EQpKPdhYEtA2F_lzOordyw.png 640w, https://miro.medium.com/max/1310/1*EQpKPdhYEtA2F_lzOordyw.png 655w" sizes="655px" data-old-src="https://miro.medium.com/max/60/1*EQpKPdhYEtA2F_lzOordyw.png?q=20"></p></div></div></figure><p id="1272">Now let’s do the same thing to the testing set.</p><figure><div></div></figure><h2 id="8632">Prepare GloVe Embeddings</h2><p id="dce0">Previously, we’ve seen how we can train our <a target="_blank" rel="noopener" href="https://heartbeat.fritz.ai/using-a-keras-embedding-layer-to-handle-text-data-2c88dc019600">own embedding layer</a>. However, in this article, we’ll use pre-trained embeddings—specifically GloVe embeddings. You can download them from <a href="http://nlp.stanford.edu/data/glove.6B.zip" target="_blank" rel="noopener">here</a>.</p><p id="ab95">We’ll use the guide from the <a href="https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html" target="_blank" rel="noopener">official Keras blog</a> to create an embedding layer from the pre-trained embeddings.</p><p id="a0dc">We start by loading in the GloVe embedding and appending them to a dictionary.</p><figure><div></div></figure><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2498/1*_C4kDxMnRkYjNTyVbapCsg.png" width="1249" height="35" srcset="https://miro.medium.com/max/552/1*_C4kDxMnRkYjNTyVbapCsg.png 276w, https://miro.medium.com/max/1104/1*_C4kDxMnRkYjNTyVbapCsg.png 552w, https://miro.medium.com/max/1280/1*_C4kDxMnRkYjNTyVbapCsg.png 640w, https://miro.medium.com/max/1400/1*_C4kDxMnRkYjNTyVbapCsg.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*_C4kDxMnRkYjNTyVbapCsg.png?q=20"></p></div></div></div></figure><p id="e3ba">Next we need to creating an embedding matrix for each word in the training set. This is done by obtaining the embedding vector for each word from the <code>embedding_index</code>.</p><p id="e3c8">For example, let’s look at the embedding vector for the word ‘attention.’</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1356/1*V_O7ccSazqnui_4w8pDkaQ.png" width="678" height="408" srcset="https://miro.medium.com/max/552/1*V_O7ccSazqnui_4w8pDkaQ.png 276w, https://miro.medium.com/max/1104/1*V_O7ccSazqnui_4w8pDkaQ.png 552w, https://miro.medium.com/max/1280/1*V_O7ccSazqnui_4w8pDkaQ.png 640w, https://miro.medium.com/max/1356/1*V_O7ccSazqnui_4w8pDkaQ.png 678w" sizes="678px" data-old-src="https://miro.medium.com/max/60/1*V_O7ccSazqnui_4w8pDkaQ.png?q=20"></p></div></div></div></figure><figure><div></div></figure><p id="aa8e">Words not found in the embedding index will have a matrix representation with all zeros.</p><h2 id="34c4">Embedding Layer</h2><p id="21e3">We can now prepare the embedding layer:</p><ul><li id="ff21">We set <code>trainable</code> to <code>False</code> because we are using pre-trained word embeddings</li><li id="d209">We set the <code>weights</code> to be the <code>embedding_matrix</code> we created above</li><li id="5adf"><code>len(word_index) + 1</code> is the size of the vocabulary. We add one because 0 is never use— it is reserved for padding</li><li id="43e3"><code>input_length</code> is the length the input sequences</li></ul><figure><div></div></figure><h2 id="13de">Define the Model</h2><p id="3409">Now, the moment we’ve all been waiting for. We define the model with the embedding layer being the first layer, followed by two bidirectional LSTM layers. The bidirectional layers ensure that the model processes the sequence from start to end, as well as backwards. This is very important, especially when working with problems such as predicting the next word in a sentence, because the context of the words before and after a certain word is useful in predicting the next word.</p><p id="8391">After that we define a dense layer with 6 units and a final output layer.</p><figure><div></div></figure><p id="5d0e">Upon checking the summary we can see that the two bidirectional layers show 32 units; however, we’d defined 16. This is because the information moves forward and backwards, hence the units are doubled. We can also see our non-trainable parameters from the embedding layer.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1422/1*r8sBGagRNKSpqhlq3s_hog.png" width="711" height="349" srcset="https://miro.medium.com/max/552/1*r8sBGagRNKSpqhlq3s_hog.png 276w, https://miro.medium.com/max/1104/1*r8sBGagRNKSpqhlq3s_hog.png 552w, https://miro.medium.com/max/1280/1*r8sBGagRNKSpqhlq3s_hog.png 640w, https://miro.medium.com/max/1400/1*r8sBGagRNKSpqhlq3s_hog.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*r8sBGagRNKSpqhlq3s_hog.png?q=20"></p></div></div></div></figure><h2 id="5713">Train the Model</h2><p id="4b6f">We can now train and visualize the performance of the model.</p><figure><div></div></figure><p id="f2dd">Let’s visualize the model’s accuracy.</p><figure><div></div></figure><p id="23cf">We see that the training accuracy starts at around 50% and increases steadily. The validation accuracy starts off at around 60% and increases gradually, but settles a little lower than the training accuracy.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1158/1*u9-7MDWOUmNR3C8zvQ0wKA.png" width="579" height="288" srcset="https://miro.medium.com/max/552/1*u9-7MDWOUmNR3C8zvQ0wKA.png 276w, https://miro.medium.com/max/1104/1*u9-7MDWOUmNR3C8zvQ0wKA.png 552w, https://miro.medium.com/max/1158/1*u9-7MDWOUmNR3C8zvQ0wKA.png 579w" sizes="579px" data-old-src="https://miro.medium.com/max/60/1*u9-7MDWOUmNR3C8zvQ0wKA.png?q=20"></p></div></div></figure><p id="9334">Let’s look at the loss visualization. We see that both losses decrease gradually, but the validation loss settles slightly higher than the training loss. The model can definitely be improved by further fine-tuning.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1166/1*rKRglXKpJ5M51EEADH547A.png" width="583" height="288" srcset="https://miro.medium.com/max/552/1*rKRglXKpJ5M51EEADH547A.png 276w, https://miro.medium.com/max/1104/1*rKRglXKpJ5M51EEADH547A.png 552w, https://miro.medium.com/max/1166/1*rKRglXKpJ5M51EEADH547A.png 583w" sizes="583px" data-old-src="https://miro.medium.com/max/60/1*rKRglXKpJ5M51EEADH547A.png?q=20"></p></div></div></figure></div></div></section><hr><section><div><div><h2 id="89a8">Final Thoughts</h2><p id="ef3d">In this piece, we’ve walked through an example of processing textual data, converting it into a numerical representation, and using pre-trained embeddings to train a model. You can check the performance using different pre-trained <a href="http://vectors.nlpl.eu/repository/" target="_blank" rel="noopener">word embeddings</a>.</p><p id="dbb5">Other things to try include changing the padding and truncation type, as well as changing the size of the vocabulary and the embedding dimensions.</p></div></div></section><hr><section><div><div><p id="1c20"><em>Editor’s Note:</em><a href="http://heartbeat.fritz.ai/" target="_blank" rel="noopener"><em> </em><strong><em>Heartbeat</em></strong></a><strong><em> </em></strong><em>is a contributor-driven online publication and community dedicated to exploring the emerging intersection of mobile app development and machine learning. We’re committed to supporting and inspiring developers and engineers from all walks of life.</em></p><p id="ffa9"><em>Editorially independent, Heartbeat is sponsored and published by</em><a href="http://fritz.ai/" target="_blank" rel="noopener"><em> </em><strong><em>Fritz AI</em></strong></a><em>, the machine learning platform that helps developers teach devices to see, hear, sense, and think. We pay our contributors, and we don’t sell ads.</em></p><p id="765c"><em>If you’d like to contribute, head on over to our</em><a target="_blank" rel="noopener" href="https://heartbeat.fritz.ai/call-for-contributors-october-2018-update-fee7f5b80f3e"><em> </em><strong><em>call for contributors</em></strong></a><em>. You can also sign up to receive our weekly newsletters (</em><a href="https://www.deeplearningweekly.com/" target="_blank" rel="noopener"><strong><em>Deep Learning Weekly</em></strong></a><em> and the </em><a href="https://www.fritz.ai/newsletter/?utm_campaign=fritzai-newsletter&amp;utm_source=heartbeat-statement" target="_blank" rel="noopener"><strong><em>Fritz AI Newsletter</em></strong></a><em>), join us on</em><a href="https://join.slack.com/t/fritz-ai-community/shared_invite/enQtNTY5NDM2MTQwMTgwLWU4ZDEwNTAxYWE2YjIxZDllMTcxMWE4MGFhNDk5Y2QwNTcxYzEyNWZmZWEwMzE4NTFkOWY2NTM0OGQwYjM5Y2U" target="_blank" rel="noopener"><em> </em></a><a href="http://fritz.ai/slack" target="_blank" rel="noopener"><strong><em>Slack</em></strong></a><em>, and follow Fritz AI on</em><a href="https://twitter.com/fritzlabs" target="_blank" rel="noopener"><em> </em><strong><em>Twitter</em></strong></a><em> for all the latest in mobile machine learning.</em></p></div></div></section></div></div>]]>
            </description>
            <link>https://heartbeat.fritz.ai/text-classification-using-long-short-term-memory-glove-embeddings-6894abb730e1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24432379</guid>
            <pubDate>Thu, 10 Sep 2020 13:56:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rewriting Facebook's “Recoil” React library from scratch in 100 lines]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24432177">thread link</a>) | @keenondrums
<br/>
September 10, 2020 | https://bennetthardwick.com/blog/recoil-js-clone-from-scratch-in-100-lines/ | <a href="https://web.archive.org/web/*/https://bennetthardwick.com/blog/recoil-js-clone-from-scratch-in-100-lines/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Recoil is a slick new React library written by some people at Facebook that work on a tool called
<a href="https://www.youtube.com/watch?v=_ISAA_Jt9kI" target="_blank" rel="noreferrer">“Comparison View."</a>
It came about because of ergonomics and
<a href="https://github.com/facebook/react/issues/14620" target="_blank" rel="noreferrer">performance issues with context</a>
and <code>useState</code>.
It’s a very clever library, and almost everyone will find a use for it - check out this
<a href="https://www.youtube.com/watch?v=_ISAA_Jt9kI" target="_blank" rel="noreferrer">explainer video</a>
if you want to learn more.</p><p>At first I was really taken aback by the talk of graph theory and the wondrous magic that Recoil performs, but after a while I started to see that maybe it’s not that special after all. Here’s my shot at implementing something similar!</p><p>Before I get started, please note that the way I’ve implemented my Recoil clone is completely different to how the actual Recoil is implemented.
Don’t assume anything about Recoil from this.</p><h2 id="atoms">Atoms</h2><p>Recoil is built around the concept of “atoms”.
Atoms are small atomic pieces of state that you can subscribe to and update in your components.</p><p>To begin, I’m going to create a class called <code>Atom</code> that is going to wrap some value <code>T</code>.
I’ve added helper methods <code>update</code> and <code>snapshot</code> to allow you to get and set the value.</p><div><pre><code data-lang="typescript"><span>class</span> <span>Atom</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
  <span>constructor</span><span>(</span><span>private</span> <span>value</span>: <span>T</span><span>)</span> <span>{}</span>

  <span>update</span><span>(</span><span>value</span>: <span>T</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span><span>value</span> <span>=</span> <span>value</span><span>;</span>
  <span>}</span>

  <span>snapshot</span><span>()</span><span>:</span> <span>T</span> <span>{</span>
    <span>return</span> <span>this</span><span>.</span><span>value</span><span>;</span>
  <span>}</span>
<span>}</span>
</code></pre></div><p>To listen for changes to the state, you need to use
<a href="https://www.tutorialspoint.com/design_pattern/observer_pattern.htm" target="_blank" rel="noreferrer">the observer pattern</a>
.
This is commonly seen in libraries like
<a href="https://rxjs-dev.firebaseapp.com/guide/overview" target="_blank" rel="noreferrer">RxJS</a>
,
but in this case I’m going to write a simple synchronous version from scratch.</p><p>To know who is listening to the state I use a <code>Set</code> of callbacks.
A <code>Set</code> (or Hash Set) is a data structure that only contains unique items.
In JavaScript it can easily be turned into an array and has helpful methods for quickly adding and removing items.</p><p>Adding a listener is done through the <code>subscribe</code> method.
The subscribe method returns <code>Disconnecter</code> - an interface containing a method that will stop a listener from listening.
This is called when a React component is unmounted and you no longer want to listen for changes.</p><p>Next, a method called <code>emit</code> is added. This method loops through each of the listeners and gives them the current value in the state.</p><p>Finally I update the <code>update</code> method to emit the new values whenever the state is set.</p><div><pre><code data-lang="typescript"><span><span>type</span> <span>Disconnecter</span> <span>=</span> <span>{</span> <span>disconnect</span><span>:</span> <span>()</span> <span>=&gt;</span> <span>void</span> <span>};</span>
</span>
<span>class</span> <span>Atom</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
<span>  <span>private</span> <span>listeners</span> <span>=</span> <span>new</span> <span>Set</span><span>&lt;</span><span>(</span><span>value</span>: <span>T</span><span>)</span> <span>=&gt;</span> <span>void</span><span>&gt;</span><span>();</span>
</span>
  <span>constructor</span><span>(</span><span>private</span> <span>value</span>: <span>T</span><span>)</span> <span>{}</span>

  <span>update</span><span>(</span><span>value</span>: <span>T</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span><span>value</span> <span>=</span> <span>value</span><span>;</span>
<span>    <span>this</span><span>.</span><span>emit</span><span>();</span>
</span>  <span>}</span>

  <span>snapshot</span><span>()</span><span>:</span> <span>T</span> <span>{</span>
    <span>return</span> <span>this</span><span>.</span><span>value</span><span>;</span>
  <span>}</span>

<span>  <span>emit() {</span>
</span><span>    <span>for</span> <span>(</span><span>const</span> <span>listener</span> <span>of</span> <span>this</span><span>.</span><span>listeners</span><span>)</span> <span>{</span>
</span><span>      <span>listener</span><span>(</span><span>this</span><span>.</span><span>snapshot</span><span>());</span>
</span><span>    <span>}</span>
</span><span>  <span>}</span>
</span>
<span>  <span>subscribe</span><span>(</span><span>callback</span><span>:</span> <span>(</span><span>value</span>: <span>T</span><span>)</span> <span>=&gt;</span> <span>void</span><span>)</span><span>:</span> <span>Disconnecter</span> <span>{</span>
</span><span>    <span>this</span><span>.</span><span>listeners</span><span>.</span><span>add</span><span>(</span><span>callback</span><span>);</span>
</span><span>    <span>return</span> <span>{</span>
</span><span>      <span>disconnect</span><span>:</span> <span>()</span> <span>=&gt;</span> <span>{</span>
</span><span>        <span>this</span><span>.</span><span>listeners</span><span>.</span><span>delete</span><span>(</span><span>callback</span><span>);</span>
</span><span>      <span>},</span>
</span><span>    <span>};</span>
</span><span>  <span>}</span>
</span><span>}</span>
</code></pre></div><p>Phew!</p><p>It’s time to write the atom up into our React components. To do this, I’ve created a hook called <code>useCoiledValue</code>. (
<a href="https://recoiljs.org/docs/api-reference/core/useRecoilValue/" target="_blank" rel="noreferrer">sound familiar?</a>
)</p><p>This hook returns the current state of an atom, and listens and re-renders whenever the value changes.
Whenever the hook is unmounted, it disconnects the listener.</p><p>One thing that’s a little weird here is the <code>updateState</code> hook.
By performing a set state with a new object reference (<code>{}</code>), React will re-render the component.
This is a little bit of a hack, but it’s an easy way to make sure the component re-renders.</p><div><pre><code data-lang="typescript"><span>export</span> <span>function</span> <span>useCoiledValue</span><span>&lt;</span><span>T</span><span>&gt;(</span><span>value</span>: <span>Atom</span><span>&lt;</span><span>T</span><span>&gt;)</span><span>:</span> <span>T</span> <span>{</span>
  <span>const</span> <span>[,</span> <span>updateState</span><span>]</span> <span>=</span> <span>useState</span><span>({});</span>

  <span>useEffect</span><span>(()</span> <span>=&gt;</span> <span>{</span>
    <span>const</span> <span>{</span> <span>disconnect</span> <span>}</span> <span>=</span> <span>value</span><span>.</span><span>subscribe</span><span>(()</span> <span>=&gt;</span> <span>updateState</span><span>({}));</span>
    <span>return</span> <span>()</span> <span>=&gt;</span> <span>disconnect</span><span>();</span>
  <span>},</span> <span>[</span><span>value</span><span>]);</span>

  <span>return</span> <span>value</span><span>.</span><span>snapshot</span><span>();</span>
<span>}</span>
</code></pre></div><p>Next I’ve added a <code>useCoiledState</code> method. This has a very similar API to <code>useState</code> - it gives you the current value of the state and allows you to set a new one.</p><div><pre><code data-lang="typescript"><span>export</span> <span>function</span> <span>useCoiledState</span><span>&lt;</span><span>T</span><span>&gt;(</span><span>atom</span>: <span>Atom</span><span>&lt;</span><span>T</span><span>&gt;)</span><span>:</span> <span>[</span><span>T</span><span>,</span> <span>(</span><span>value</span>: <span>T</span><span>)</span> <span>=&gt;</span> <span>void</span><span>]</span> <span>{</span>
  <span>const</span> <span>value</span> <span>=</span> <span>useCoiledValue</span><span>(</span><span>atom</span><span>);</span>
  <span>return</span> <span>[</span><span>value</span><span>,</span> <span>useCallback</span><span>((</span><span>value</span><span>)</span> <span>=&gt;</span> <span>atom</span><span>.</span><span>update</span><span>(</span><span>value</span><span>),</span> <span>[</span><span>atom</span><span>])];</span>
<span>}</span>
</code></pre></div><p>Now that we’ve got those hooks out of the road, it’s time to move onto Selectors.
Before that though, let’s refactor what we’ve got a little bit.</p><p>A selector is a stateful value, just like an atom.
To make implementing them a bit easier,
I’ll move most of the logic out of <code>Atom</code> into a base class called <code>Stateful</code>.</p><div><pre><code data-lang="typescript"><span><span>class</span> <span>Stateful</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
</span>  <span>private</span> <span>listeners</span> <span>=</span> <span>new</span> <span>Set</span><span>&lt;</span><span>(</span><span>value</span>: <span>T</span><span>)</span> <span>=&gt;</span> <span>void</span><span>&gt;</span><span>();</span>

  <span>constructor</span><span>(</span><span>private</span> <span>value</span>: <span>T</span><span>)</span> <span>{}</span>

<span>  <span>protected</span> <span>_update</span><span>(</span><span>value</span>: <span>T</span><span>)</span> <span>{</span>
</span>    <span>this</span><span>.</span><span>value</span> <span>=</span> <span>value</span><span>;</span>
    <span>this</span><span>.</span><span>emit</span><span>();</span>
  <span>}</span>

  <span>snapshot</span><span>()</span><span>:</span> <span>T</span> <span>{</span>
    <span>return</span> <span>this</span><span>.</span><span>value</span><span>;</span>
  <span>}</span>

  <span>subscribe</span><span>(</span><span>callback</span><span>:</span> <span>(</span><span>value</span>: <span>T</span><span>)</span> <span>=&gt;</span> <span>void</span><span>)</span><span>:</span> <span>Disconnecter</span> <span>{</span>
    <span>this</span><span>.</span><span>listeners</span><span>.</span><span>add</span><span>(</span><span>callback</span><span>);</span>
    <span>return</span> <span>{</span>
      <span>disconnect</span><span>:</span> <span>()</span> <span>=&gt;</span> <span>{</span>
        <span>this</span><span>.</span><span>listeners</span><span>.</span><span>delete</span><span>(</span><span>callback</span><span>);</span>
      <span>},</span>
    <span>};</span>
  <span>}</span>
<span>}</span>

<span><span>class</span> <span>Atom</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>extends</span> <span>Stateful</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
</span><span>  <span>update</span><span>(</span><span>value</span>: <span>T</span><span>)</span> <span>{</span>
</span><span>    <span>super</span><span>.</span><span>_update</span><span>(</span><span>value</span><span>);</span>
</span><span>  <span>}</span>
</span><span><span>}</span>
</span></code></pre></div><p>Moving on!</p><h2 id="selectors">Selectors</h2><p>A selector is Recoil’s version of “computed values” or “reducers”. In their
<a href="https://recoiljs.org/docs/basic-tutorial/selectors" target="_blank" rel="noreferrer">own words</a>
:</p><blockquote><p>A selector represents a piece of derived state. You can think of derived state as the output of passing state to a pure function that modifies the given state in some way.</p></blockquote><p>The API for selectors in Recoil is quite simple, you create an object with a method called <code>get</code> and whatever that method returns is the value of your state.
Inside the <code>get</code> method you can subscribe to other pieces of state, and whenever they update so too will your selector.</p><p>In our case, I’m going to rename the <code>get</code> method to be called <code>generator</code>.
I’m calling it this because it’s essentially a factory function that’s supposed to generate the next value of the state, based on whatever is piped into it.</p><p><img src="https://bennetthardwick.com/blog/recoil-js-clone-from-scratch-in-100-lines/atom-selector-flow_hu6c1d970fc33d5ff12c990845e7422d9f_40682_694x0_resize_box_2.png" width="694" height="445" alt="a flowchart demonstrating two atoms (titled “hello” and “bob”) being piped into a selector, with the output becomming “Hello, Bob”"></p><p>In code, we can capture this <code>generate</code> method with the following type signature.</p><div><pre><code data-lang="typescript"><span>type</span> <span>SelectorGenerator</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>=</span> <span>(</span><span>context</span>: <span>GeneratorContext</span><span>)</span> <span>=&gt;</span> <span>T</span><span>;</span>
</code></pre></div><p>For those unfamilar with Typescript, it’s a function that takes a context object (<code>GeneratorContext</code>) as a parameter and returns some value <code>T</code>.
This return value is what becomes the internal state of the selector.</p><p>What does the <code>GeneratorContext</code> object do?</p><p>Well that’s how selectors use other pieces of state when generating their own internal state.
From now on I’ll refer to these pieces of state as “dependencies”.</p><div><pre><code data-lang="typescript"><span>interface</span> <span>GeneratorContext</span> <span>{</span>
  <span>get</span><span>:</span> <span>&lt;</span><span>V</span><span>&gt;(</span><span>dependency</span>: <span>Stateful</span><span>&lt;</span><span>V</span><span>&gt;)</span> <span>=&gt;</span> <span>V</span>
<span>}</span>
</code></pre></div><p>Whenever someone calls the <code>get</code> method on the <code>GeneratorContext</code>, it adds a piece of state as a dependency.
This means that whenever a dependency updates, so too will the selector.</p><p>Here’s what creating a selector’s generate function might look like:</p><div><pre><code data-lang="typescript"><span>function</span> <span>generate</span><span>(</span><span>context</span><span>)</span> <span>{</span>
  <span>// Register the NameAtom as a dependency
</span><span></span>  <span>// and get it's value
</span><span></span>  <span>const</span> <span>name</span> <span>=</span> <span>context</span><span>.</span><span>get</span><span>(</span><span>NameAtom</span><span>);</span>
  <span>// Do the same for AgeAtom
</span><span></span>  <span>const</span> <span>age</span> <span>=</span> <span>context</span><span>.</span><span>get</span><span>(</span><span>AgeAtom</span><span>);</span>

  <span>// Return a new value using the previous atoms
</span><span></span>  <span>// E.g. "Bob is 20 years old"
</span><span></span>  <span>return</span> <span>`</span><span>${</span><span>name</span><span>}</span><span> is </span><span>${</span><span>age</span><span>}</span><span> years old.`</span><span>;</span>
<span>};</span>
</code></pre></div><p>With the generate function out of the way, let’s create the <code>Selector</code> class.
This class should accept the generate function as a constructor parameter and use a <code>getDep</code> method on the class to return the value of the <code>Atom</code> dependencies.</p><p>You might notice in the constructor that I’ve written <code>super(undefined as any)</code>.
This is because <code>super</code> must be the very first line in a derived class’s constructor.
If it helps, in this case you can think of <code>undefined</code> as uninitialised memory.</p><div><pre><code data-lang="typescript"><span>export</span> <span>class</span> <span>Selector</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>extends</span> <span>Stateful</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
  <span>private</span> <span>getDep</span><span>&lt;</span><span>V</span><span>&gt;(</span><span>dep</span>: <span>Stateful</span><span>&lt;</span><span>V</span><span>&gt;)</span><span>:</span> <span>V</span> <span>{</span>
    <span>return</span> <span>dep</span><span>.</span><span>snapshot</span><span>();</span>
  <span>}</span>

  <span>constructor</span><span>(</span>
    <span>private</span> <span>readonly</span> <span>generate</span>: <span>SelectorGenerator</span><span>&lt;</span><span>T</span><span>&gt;</span>
  <span>)</span> <span>{</span>
    <span>super</span><span>(</span><span>undefined</span> <span>as</span> <span>any</span><span>);</span>
    <span>const</span> <span>context</span> <span>=</span> <span>{</span>
      <span>get</span>: <span>dep</span> <span>=&gt;</span> <span>this</span><span>.</span><span>getDep</span><span>(</span><span>dep</span><span>)</span> 
    <span>};</span>
    <span>this</span><span>.</span><span>value</span> <span>=</span> <span>generate</span><span>(</span><span>context</span><span>);</span>
  <span>}</span>
<span>}</span>
</code></pre></div><p>This selector is only good for generating state once.
In order to react to changes in the dependencies, we need to subscribe to them.</p><p>To do this, let’s update the <code>getDep</code> method to subscribe to the dependencies and call the <code>updateSelector</code> method.
To make sure the selector only updates once per change, let’s keep track of the deps using a <code>Set</code>.</p><p>The <code>updateSelector</code> method is very similar to the constructor in the previous example.
It creates the <code>GeneratorContext</code>, runs the <code>generate</code> method and then uses the <code>update</code> method from the <code>Stateful</code> base class.</p><div><pre><code data-lang="typescript"><span>export</span> <span>class</span> <span>Selector</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>extends</span> <span>Stateful</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
<span>  <span>private</span> <span>registeredDeps</span> <span>=</span> <span>new</span> <span>Set</span><span>&lt;</span><span>Stateful</span><span>&gt;();</span>
</span>
  <span>private</span> <span>getDep</span><span>&lt;</span><span>V</span><span>&gt;(</span><span>dep</span>: <span>Stateful</span><span>&lt;</span><span>V</span><span>&gt;)</span><span>:</span> <span>V</span> <span>{</span>
<span>    <span>if</span> <span>(</span><span>!</span><span>this</span><span>.</span><span>registeredDeps</span><span>.</span><span>has</span><span>(</span><span>dep</span><span>))</span> <span>{</span>
</span><span>      <span>dep</span><span>.</span><span>subscribe</span><span>(()</span> <span>=&gt;</span> <span>this</span><span>.</span><span>updateSelector</span><span>());</span>
</span><span>      <span>this</span><span>.</span><span>registeredDeps</span><span>.</span><span>add</span><span>(</span><span>dep</span><span>);</span>
</span><span>    <span>}</span>
</span>
    <span>return</span> <span>dep</span><span>.</span><span>snapshot</span><span>();</span>
  <span>}</span>

<span>  <span>private</span> <span>updateSelector() {</span>
</span><span>    <span>const</span> <span>context</span> <span>=</span> <span>{</span>
</span><span>      <span>get</span>: <span>dep</span> <span>=&gt;</span> <span>this</span><span>.</span><span>getDep</span><span>(</span><span>dep</span><span>)</span>
</span><span>    <span>};</span>
</span><span>    <span>this</span><span>.</span><span>update</span><span>(</span><span>this</span><span>.</span><span>generate</span><span>(</span><span>context</span><span>));</span>
</span><span>  <span>}</span>
</span>
  <span>constructor</span><span>(</span>
    <span>private</span> <span>readonly</span> <span>generate</span>: <span>SelectorGenerator</span><span>&lt;</span><span>T</span><span>&gt;</span>
  <span>)</span> <span>{</span>
    <span>super</span><span>(</span><span>undefined</span> <span>as</span> <span>any</span><span>);</span>
    <span>const</span> <span>context</span> <span>=</span> <span>{</span>
      <span>get</span>: <span>dep</span> <span>=&gt;</span> <span>this</span><span>.</span><span>getDep</span><span>(</span><span>dep</span><span>)</span> 
    <span>};</span>
    <span>this</span><span>.</span><span>value</span> <span>=</span> <span>generate</span><span>(</span><span>context</span><span>);</span>
  <span>}</span>
<span>}</span>
</code></pre></div><p>Almost done! Recoil has some helper functions for creating atoms and selectors.
Since most JavaScript devs consider classes evil, they’ll help mask our atrocities.</p><p>One for creating an atom…</p><div><pre><code data-lang="typescript"><span>export</span> <span>function</span> <span>atom</span><span>&lt;</span><span>V</span><span>&gt;(</span>
  <span>value</span><span>:</span> <span>{</span> <span>key</span>: <span>string</span><span>;</span> <span>default</span><span>:</span> <span>V</span> <span>}</span>
<span>)</span><span>:</span> <span>Atom</span><span>&lt;</span><span>V</span><span>&gt;</span> <span>{</span>
  <span>return</span> <span>new</span> <span>Atom</span><span>(</span><span>value</span><span>.</span><span>default</span><span>);</span>
<span>}</span>
</code></pre></div><p>And one for creating a selector…</p><div><pre><code data-lang="typescript"><span>export</span> <span>function</span> <span>selector</span><span>&lt;</span><span>V</span><span>&gt;(</span><span>value</span><span>:</span> <span>{</span>
  <span>key</span>: <span>string</span><span>;</span>
  <span>get</span>: <span>SelectorGenerator</span><span>&lt;</span><span>V</span><span>&gt;;</span>
<span>})</span><span>:</span> <span>Selector</span><span>&lt;</span><span>V</span><span>&gt;</span> <span>{</span>
  <span>return</span> <span>new</span> <span>Selector</span><span>(</span><span>value</span><span>.</span><span>get</span><span>);</span>
<span>}</span>
</code></pre></div><p>Oh, remember that <code>useCoiledValue</code> hook from before? Let’s update that to accept selectors too:</p><div><pre><code data-lang="typescript"><span><span>export</span> <span>function</span> <span>useCoiledValue</span><span>&lt;</span><span>T</span><span>&gt;(</span><span>value</span>: <span>Stateful</span><span>&lt;</span><span>T</span><span>&gt;)</span><span>:</span> <span>T</span> <span>{</span>
</span>  <span>const</span> <span>[,</span> <span>updateState</span><span>]</span> <span>=</span> <span>useState</span><span>({});</span>

  <span>useEffect</span><span>(()</span> <span>=&gt;</span> <span>{</span>
    <span>const</span> <span>{</span> <span>disconnect</span> <span>}</span> <span>=</span> <span>value</span><span>.</span><span>subscribe</span><span>(()</span> <span>=&gt;</span> <span>updateState</span><span>({}));</span>
    <span>return</span> <span>()</span> <span>=&gt;</span> <span>disconnect</span><span>();</span>
  <span>},</span> <span>[</span><span>value</span><span>]);</span>

  <span>return</span> <span>value</span><span>.</span><span>snapshot</span><span>();</span>
<span>}</span>
</code></pre></div><p>That’s it! We’ve done it! 🎉</p><p>Give yourself a pat on your back!</p><p>Finished?</p><p>For the sake of brevity (and in order to use that clickbaity “100 lines” title) I decided to omit comments, tests and examples.
If you want a more thorough explanation (or want to play with examples), all that stuff is up in my
<a href="https://github.com/bennetthardwick/recoil-clone" target="_blank" rel="noreferrer">“recoil-clone” Github repository.</a></p><p>There’s also an
<a href="https://100-line-recoil-clone.netlify.app/" target="_blank" rel="noreferrer">example site</a>
live so you can test it out.</p><h2 id="conclusion">Conclusion</h2><p>I once read that all good software should be simple enough that anyone could rewrite it if they …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bennetthardwick.com/blog/recoil-js-clone-from-scratch-in-100-lines/">https://bennetthardwick.com/blog/recoil-js-clone-from-scratch-in-100-lines/</a></em></p>]]>
            </description>
            <link>https://bennetthardwick.com/blog/recoil-js-clone-from-scratch-in-100-lines/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24432177</guid>
            <pubDate>Thu, 10 Sep 2020 13:32:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to build a superb go-to-market strategy for SaaS business [with use cases]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24431747">thread link</a>) | @DanaStartupNews
<br/>
September 10, 2020 | https://www.byteant.com/blog/how-to-build-a-superb-go-to-market-strategy-for-saas-startups-with-use-cases/ | <a href="https://web.archive.org/web/*/https://www.byteant.com/blog/how-to-build-a-superb-go-to-market-strategy-for-saas-startups-with-use-cases/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <ol>
            <li>
                    <a href="https://www.byteant.com/">Home</a>
            </li>
            <li>
                    <a href="https://www.byteant.com/blog/">Blog</a>
            </li>
            <li>How To Build a Superb Go-To-Market Strategy for SaaS Startups [With Use Cases]</li>
        </ol>
    </div>

    <section>
        <div>
            <div>
                

                <div>
                            
    

    <div>
        <div>
    <div>
        <div>
            <div>
                <div>
                    
    
    <figure>
        <img src="https://www.byteant.com/media/pxgk0swp/go-to-market-strategy-for-saas-startups.png" alt="">
    </figure>


                </div>
            </div>        </div>
    </div>
    <div>
        <div>
            <div>
                <div>
                    
    
<div><p>Whether you are launching your first SaaS product or you are a serial startup founder, you should plan your go-to-market strategy beforehand. It is the basis of reaching your potential buyers at the right moment and turning them into loyal users. </p><p>Early in this blog, we already covered the basics of the <a href="https://www.byteant.com/blog/go-to-market-strategy-for-startups-a-complete-guide-free-template/">go-to-market strategy for startups</a>. Now, letâ€™s advance on a SaaS GTM strategy and the best practices to build one.</p></div>
<h2><strong>Go-to-market strategy for SaaS: the main specifics</strong></h2>


                </div>
            </div>        </div>
    </div>
    <div>
        <div>
            <div>
                <div>
                    
    
<div><p>First and foremost, users like to try a software product before buying it. Therefore, most SaaS businesses offer a trial period for free. By checking if the SaaS solution matches their business needs, users are more sure of their purchase decisions.</p><p>Meanwhile, <a href="https://blog.close.com/how-to-sell-saas-9-tips-for-startup-sales-success/">the Close recommends keeping your trial periods to under 14 days</a>, thus preventing user procrastination and cutting down churns. By shortening your sales cycle down to 3 weeks, you can reduce your customer acquisition expenses as well.Â&nbsp;</p></div>
<p>Another benefit of a trial period is that customers can self-educate on the SaaS solution without dealing with a sales representative. 3 out of 4 B2B users prefer this selling method over direct communication,<a href="https://go.forrester.com/blogs/16-02-10-how_self_service_research_will_change_b2b_marketing/"> Forrester research states.Â&nbsp;</a></p>


                </div>
            </div>        </div>
    </div>
    
    <div>
        <div>
            <div>
                <div>
                    
    
<div><p>At the same time, users are less inclined to pay with a 30% purchase decline during this period. </p><p>With these facts in mind, it is so much more important to plan your expenses, acquisition, and B2B go-to-market strategy.Â&nbsp;</p></div>


                </div>
            </div>        </div>
    </div>
    <div>
        <div>
            <div>
                <div>
                    
    
<h2>Mistake to avoidÂ&nbsp;</h2>



                    
    
<h2><strong>Mailchimp exampleÂ&nbsp;</strong></h2>
<div><p>Mailchimp is an email automation service that is available as a freemium model. The free app version lets you send up to 12 000 letters per month and have less than 2000 subscribers for free. Once you exceed this amount, you have to pay for the Paid plan.</p><p><strong>Offering a large portion of their features for free, Mailchimp is a brilliant alternative to costly email tools existing in the market.</strong> Since Mailchimp targets primarily small businesses, its SaaS go-to-market strategy is perfect for users with a limited budget. Starting using the service for free, customers eventually face feature limitations and upgrade to the paid version. </p><p>Initially, Mailchimp created a product to answer the market demand for an easy-to-use email marketing tool. They used word-of-mouth marketing to acquire its first customers. The company was growing steadily over the years. As they grew, they adjusted their pricing policies for more flexibility.</p></div>
<p><strong><br></strong>The service used SEO, PR, and digital marketing tactics to create awareness. Mailchimpâ€™s use case is an example of a product-based B2B go-to-market strategy for SaaS startups. It places software features at the center of a client acquisition strategy. SaaS companies like Slack, Grammarly, and HubSpot also used this approach.</p>


                </div>
            </div>        </div>
    </div>
    <div>
        <div>
            <div>
                <div>
                    
    
<h2><strong>The Audience - Sales Matrix is the core of your SaaS GTM strategy.</strong><strong><br></strong></h2>
<p><br>As a SaaS business, you should clearly define the target personas that youâ€™re reaching. For B2B products, they can be:</p>
<ul>
<li>Small companies</li>
<li>Middle-size business</li>
<li>Large enterprises</li>
<li>The mix of the above</li>
</ul>
<p>Once you define your target audience, you can study their preferences, challenges, and set the appropriate SaaS pricing &amp; promotion.Â&nbsp;</p>


                    
    
    <figure>
        <img src="https://www.byteant.com/media/jzghxhod/mission-matrix_saas_go-to-market-strategy.png" alt="">
    </figure>


                </div>
            </div>        </div>
    </div>
    <div>
        <div>
            <div>
                <div>
                    
    
<p>Â&nbsp;</p>
<p>Based on the target audience, you can choose one of the following sales strategies:</p>
<ul>
<li><strong><em>Low-touch</em></strong></li>
<li><strong><em>Medium-touch</em></strong></li>
<li><strong><em>High-touch</em></strong></li>
</ul>
<p>We will explain each of them further in this article.<br>Remember: depending on a sales strategy and target audience you choose, you can get different results. This mix is called the mission matrix. Letâ€™s explore it in more detail.Â&nbsp;</p>


                    
    
<ol>
<li>
<h2><strong>Low-touch sales + small business</strong></h2>
</li>
</ol>


                    
    
<div><p>Cost-per-acquisition: low</p><p>These tactics mean that you minimize the work of your sales team in the initial purchase stages. David Skok calls it a touchless conversion sales model, which sounds a bit like magic. </p><p>What it actually means is that your potential customers make a purchase or enter your sales funnel without direct interaction with your sales representatives. In the case with SaaS startups, it can have a form of a simple sign up for a free trial period.Â&nbsp;</p></div>
<div><p>You may spend time and resources on driving traffic to your website, promoting your SaaS solution via digital channels and PPC, although the final sign up process happens automatically.</p><p>It works well for products with a long-term sales process, preventing annoying sales calls and cold emails.Â&nbsp;</p></div>


                </div>
            </div>        </div>
    </div>
    <div>
        <div>
            <div>
                <div>
                    
    
<h2><strong>Typeform use case<p><img src="https://www.byteant.com/media/1ienr40u/typeform_use_case.png?width=728&amp;height=437&amp;mode=max" alt="" width="728" height="437" data-udi="umb://media/fbd808dc8d5445eb9670e25f244aa08a"></p></strong></h2>
<div><p>Typeform is a go-to-market strategy case study with a low-touch sales tactic. It focuses on inbound marketing and provides value fast enough to convert users. The first purchase happens automatically without your input. </p><p>Its product is easy to onboard and flexible, serving various business needs: passing quizzes, getting employee feedback, or selling products online. The free plan includes three forms with up to 10 questions per survey. You can also add a layout to your webpage. Once a free version doesnâ€™t match your needs anymore, you can upgrade to <strong>Essentials</strong> plan at 35 USD per month, or <strong>Professional </strong>at the same price.<strong><br></strong></p></div>


                    
    
<div><p><strong><em>Pedro Magrico, the Director of Growth at Typeform,</em> </strong>shared some secrets of their growth. He states creating an easy and fun onboarding process crucial to their development. Once a user clicks on a â€˜Get started freeâ€™ button, he sees the 20-seconds video explaining the benefits of SaaS offer and teaching how to use a service. Even if users are not registered yet, they can start using the service right away. </p><p>By delivering value within the Free plan and adding a Typeform signature at the bottom of every survey, Typeform turned their product into the best lead generator. The viral effect ensured a steady flow of customers to this SaaS company. The enjoyable user experience made them upgrade to Premium.</p></div>


                </div>
            </div>        </div>
    </div>
    <div>
        <div>
            <div>
                <div>
                    
    
<h2><strong>2. High-touch sales strategy + large corporations</strong></h2>
<p>High-touch sales mean a significant work of your sales team on the way to user conversion (and after it). This model usually bases on partnerships and trust between the two parties. Due to complex decision making at large businesses, you need to convince the whole team to buy your product. Meanwhile,<a href="https://blog.upscope.io/high-touch-vs-low-touch-sales-models/"> large companies bring lower churn rates and makeup to 80% of software vendorsâ€™ income.</a><em>Cost-per-acquisition: high</em></p>
<h3><strong>Salesforce go-to-market strategy case study</strong></h3>
<p>Salesforce entered the market as a simple-to-use CRM solution. It would work error-free with other systems, be fast to set up, and fast-running. Beginning with aggressive marketing tactics, Salesforce announced the end of software that complicates salespeopleâ€™s work.</p>


                    
    
    <figure>
        <img src="https://www.byteant.com/media/3abhtxty/salesforce_go_to_market_strategy.jpg" alt="Image source: Usefyi.com">
            <figcaption>Image source: Usefyi.com</figcaption>
    </figure>


                </div>
            </div>        </div>
    </div>
    <div>
        <div>
            <div>
                <div>
                    
    
<p><br>With a clear mission to create an accessible fast-functioning product, the SaaS company started building a community around it. They organized events, conferences, and competitions. However, its main force was a tight alignment between sales, marketing, and software. Thanks to a transparent value offer that matched the audienceâ€™s pain points, <strong>Salesforce grew from $5.9 million in income in 2001 to $50.9 million in 2003.</strong><strong><br></strong></p>
<p>They offered a free product version for five users maximum at any company. After a user enjoyed using it without any registration, they upgraded quickly to the paid version. An important point is also that the agency offered two ways to expand the usage to serve each teamâ€™s needs.Â&nbsp; Later on, they started to build other products supporting the core offering and adding additional streams of revenue.Â&nbsp;</p>


                </div>
            </div>        </div>
    </div>
    <div>
        <div>
            <div>
                <div>
                    
    
<div><p>If you decide to reach large corporations, itâ€™s crucial to define the decision-makers in your SaaS GTM strategy. Focus on those stakeholders who make the purchase decision. Then, you can adjust your marketing and messaging to those who use your product. </p></div>
<p>Aligning your sales and marketing in this approach can make or break your market entry. As both marketing and sales should understand who they are targeting, plan the inbound marketing strategy and outbound sales workflow.</p>


                </div>
            </div>        </div>
    </div>
    <div>
        <div>
            <div>
                <div>
                    
    
<h2><strong>3. Middle-touch sales + middle-size companies</strong></h2>
<div><p>As you may guess, this SaaS go-to-market strategy assumes the combination of autonomous user onboarding with salespeople support. </p><p>Within this approach, you need to find the right balance of customer support help and self-managed purchase. In other words, you need to master a hybrid selling strategy. </p><p>Some elements of growth include …</p></div></div></div></div></div></div></div></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.byteant.com/blog/how-to-build-a-superb-go-to-market-strategy-for-saas-startups-with-use-cases/">https://www.byteant.com/blog/how-to-build-a-superb-go-to-market-strategy-for-saas-startups-with-use-cases/</a></em></p>]]>
            </description>
            <link>https://www.byteant.com/blog/how-to-build-a-superb-go-to-market-strategy-for-saas-startups-with-use-cases/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24431747</guid>
            <pubDate>Thu, 10 Sep 2020 12:43:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google, LinkedIn and Other Tech Firms Send Employees into New York Classrooms]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24431603">thread link</a>) | @BinaryBuddha
<br/>
September 10, 2020 | https://www.techtalentpipeline.nyc/tech-in-residence-corps | <a href="https://web.archive.org/web/*/https://www.techtalentpipeline.nyc/tech-in-residence-corps">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="siteWrapper">

      

      

      
        
          
            
            
          
        
      


      
      
      

      <main id="page" role="main">
        
        <!--
        --><!--
        --><div id="content" data-content-field="main-content" data-collection-id="5e32be4ad7315a3d73a0cac9">
         <!-- Create index sections -->

  
  <div id="tech-in-residence-section" data-url-id="tech-in-residence-section" data-collection-id="5e32be88d7315a3d73a0cf5b" data-edit-main-image="">
    
    
      
    

    <div>
      <div data-content-field="main-content">
        <div data-type="page" data-updated-on="1581102404633" id="page-5e32be88d7315a3d73a0cf5b"><div><div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1580897032570_5815"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580897106968-B8Z7K9E0IFK94XE2VZHS/ke17ZwdGBToddI8pDm48kAtQXdLwhyy0vpjAZYkTLANZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7YmDye92LJlx5Z6JHLEUGa2UaMxHmwY4n_De8kJ6Mlb2rNsr1dS9pQZdxMQNj-QpQg/logo-w.png" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580897106968-B8Z7K9E0IFK94XE2VZHS/ke17ZwdGBToddI8pDm48kAtQXdLwhyy0vpjAZYkTLANZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7YmDye92LJlx5Z6JHLEUGa2UaMxHmwY4n_De8kJ6Mlb2rNsr1dS9pQZdxMQNj-QpQg/logo-w.png" data-image-dimensions="222x224" data-image-focal-point="0.5,0.5" alt="logo-w.png" data-load="false" data-image-id="5e3a9352f5b80670ad689683" data-type="image" src="https://www.techtalentpipeline.nyc/logo-w.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1580897032570_7149"><p>Equipping NYC tech leaders to teach college students the skills needed to successfully launch tech careers</p></div></div></div></div>
      </div>
    </div>
  </div>
  
  <div id="quote-carousel-section" data-url-id="quote-carousel-section" data-collection-id="5e32d079f8043d07500cfaca" data-edit-main-image="">
    
    
      
    

    <div>
      <div data-content-field="main-content">
        <div data-type="page" data-updated-on="1580388597021" id="page-5e32d079f8043d07500cfaca"><div><div><div data-block-json="{&quot;collectionId&quot;:&quot;5e32c6768a92c82fc8154439&quot;,&quot;design&quot;:&quot;carousel&quot;,&quot;headerText&quot;:&quot;Quote&quot;,&quot;textSize&quot;:&quot;medium&quot;,&quot;pageSize&quot;:30,&quot;imageAspectRatio&quot;:&quot;1.5&quot;,&quot;columnWidth&quot;:270,&quot;gutter&quot;:60,&quot;listImageSize&quot;:30,&quot;listImageAlignment&quot;:&quot;left&quot;,&quot;slidesPerRow&quot;:1,&quot;textAlignment&quot;:&quot;left&quot;,&quot;showTitle&quot;:true,&quot;showThumbnail&quot;:true,&quot;showExcerpt&quot;:true,&quot;showReadMoreLink&quot;:false,&quot;showPrice&quot;:true,&quot;productQuickViewEnabled&quot;:false,&quot;showPastOrUpcomingEvents&quot;:&quot;upcoming&quot;,&quot;metadataPosition&quot;:&quot;below-content&quot;,&quot;primaryMetadata&quot;:&quot;none&quot;,&quot;secondaryMetadata&quot;:&quot;none&quot;,&quot;filter&quot;:{},&quot;autoCrop&quot;:true,&quot;lightbox&quot;:false,&quot;mixedContent&quot;:true,&quot;blockId&quot;:&quot;0d55d238ae3bdb2957c6&quot;,&quot;hSize&quot;:null,&quot;floatDir&quot;:null}" data-block-type="55" id="block-yui_3_17_2_1_1580388476471_3903"><div>



<div>

  <div>

    

    <div>

      

        <div>

          
            <!-- Thumbnail -->
            

  
  <div>
    <a href="https://www.techtalentpipeline.nyc/quote-carousel/2020/1/30/royce-kok" data-title="Royce Kok" data-description="">
      <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580388347125-2IZNQD0AL2T3TFBWIL4L/ke17ZwdGBToddI8pDm48kBPw4N13dNaFqvN1wFuK0BxZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7Xj1nVWs2aaTtWBneO2WM-t_OL1jkxuzHCtZDSGPDO3iz-j0Y68h3gWhT4w543MCTg/q1.jpg" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580388347125-2IZNQD0AL2T3TFBWIL4L/ke17ZwdGBToddI8pDm48kBPw4N13dNaFqvN1wFuK0BxZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7Xj1nVWs2aaTtWBneO2WM-t_OL1jkxuzHCtZDSGPDO3iz-j0Y68h3gWhT4w543MCTg/q1.jpg" data-image-dimensions="280x280" data-image-focal-point="0.5,0.5" alt="Royce Kok" data-load="false" src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580388347125-2IZNQD0AL2T3TFBWIL4L/ke17ZwdGBToddI8pDm48kBPw4N13dNaFqvN1wFuK0BxZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7Xj1nVWs2aaTtWBneO2WM-t_OL1jkxuzHCtZDSGPDO3iz-j0Y68h3gWhT4w543MCTg/q1.jpg">

    

    

        

        

      </p>
    </a>

    <!-- Products: Quick View -->
    

  </div>
  



          

          <div data-animation-role="content">

            <!-- Metadata (Above Title) -->
            

            
              <!-- Title -->
              
            

            <!-- Metadata (Below Title) -->
            

            
              
            

            
              
              <!-- Excerpt -->
                <div>
                  <p>Teaching at CUNY is one of the most rewarding things I’ve ever done. As a 1st generation college student, I feel honored to have this platform to give back and support students who have not had the same opportunities as me or many of my peers.</p><p><strong>Royce Kok</strong><br> Plaid, Data Warehousing for Analytics at Baruch College</p>
                </div>
              

              

              
            

            <!-- Metadata (Below Content) -->
            

          </div> <!-- End .summary-content -->

        </div> <!-- End .summary-item -->

      

        <div>

          
            <!-- Thumbnail -->
            

  
  <div>
    <a href="https://www.techtalentpipeline.nyc/quote-carousel/2020/2/6/mayor-bill-de-blasio" data-title="Mayor Bill de Blasio" data-description="">
      <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1581000953705-9ODN4HAVTVQ2RXE6SEPH/ke17ZwdGBToddI8pDm48kGpgwyMer3OYDSmBquEbno1Zw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVFA4DTWVYV_9wMcc40WbHTcDgHq5ec0yygagY8rPNynI-ibnjMMQx-vulf6ufIzGWI/geraldinasebastianmbdb.jpg" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1581000953705-9ODN4HAVTVQ2RXE6SEPH/ke17ZwdGBToddI8pDm48kGpgwyMer3OYDSmBquEbno1Zw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVFA4DTWVYV_9wMcc40WbHTcDgHq5ec0yygagY8rPNynI-ibnjMMQx-vulf6ufIzGWI/geraldinasebastianmbdb.jpg" data-image-dimensions="499x499" data-image-focal-point="0.5,0.5" alt="Mayor Bill de Blasio" data-load="false" src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1581000953705-9ODN4HAVTVQ2RXE6SEPH/ke17ZwdGBToddI8pDm48kGpgwyMer3OYDSmBquEbno1Zw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVFA4DTWVYV_9wMcc40WbHTcDgHq5ec0yygagY8rPNynI-ibnjMMQx-vulf6ufIzGWI/geraldinasebastianmbdb.jpg">

    

    

        

        

      </p>
    </a>

    <!-- Products: Quick View -->
    

  </div>
  



          

          <div data-animation-role="content">

            <!-- Metadata (Above Title) -->
            

            
              <!-- Title -->
              
            

            <!-- Metadata (Below Title) -->
            

            
              
            

            
              
              <!-- Excerpt -->
                <div>
                  <p>We have made significant strides to ensure that the growth of New York City’s booming tech ecosystem is fueled by qualified homegrown talent...As part of our administration’s plan to spur 100,000 good paying jobs, I recently announced a new goal of doubling the number of computer science graduates from the City University of New York by 2022. Central to achieving this goal is the launch of a new Tech-in-Residence Corps that will bring NYC industry professionals into local colleges to teach in-demand and emerging skills.</p><p><strong>Mayor Bill de Blasio</strong></p>
                </div>
              

              

              
            

            <!-- Metadata (Below Content) -->
            

          </div> <!-- End .summary-content -->

        </div> <!-- End .summary-item -->

      

        <div>

          
            <!-- Thumbnail -->
            

  
  <div>
    <a href="https://www.techtalentpipeline.nyc/quote-carousel/2020/1/30/nikolai" data-title="Nikolai Avteniev" data-description="">
      <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580388411753-74J7ZTH3IK5ZXHI8MJ9E/ke17ZwdGBToddI8pDm48kMqTWllqAnz46lb6GEtomGZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxFuujnV-2zomHZfzmZ9k8xM2P4oqKbe0u16WF7q12VhpoDEieSQIrrUnihTGrQ3mg/q2.jpg" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580388411753-74J7ZTH3IK5ZXHI8MJ9E/ke17ZwdGBToddI8pDm48kMqTWllqAnz46lb6GEtomGZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxFuujnV-2zomHZfzmZ9k8xM2P4oqKbe0u16WF7q12VhpoDEieSQIrrUnihTGrQ3mg/q2.jpg" data-image-dimensions="706x856" data-image-focal-point="0.5,0.5" alt="Nikolai Avteniev" data-load="false" src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580388411753-74J7ZTH3IK5ZXHI8MJ9E/ke17ZwdGBToddI8pDm48kMqTWllqAnz46lb6GEtomGZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxFuujnV-2zomHZfzmZ9k8xM2P4oqKbe0u16WF7q12VhpoDEieSQIrrUnihTGrQ3mg/q2.jpg">

    

    

        

        

      </p>
    </a>

    <!-- Products: Quick View -->
    

  </div>
  



          

          <div data-animation-role="content">

            <!-- Metadata (Above Title) -->
            

            
              <!-- Title -->
              
            

            <!-- Metadata (Below Title) -->
            

            
              
            

            
              
              <!-- Excerpt -->
                <div>
                  <p>With my final syllabus reviewed and ready…I had no idea what to expect. How many students would register? How would I make it to class on time? What would I actually do for two and a half hours?...I couldn't imagine standing in front of the classroom and lecturing the entire time. With the help of… my mentor at CCNY, I came up with a classroom approach which was sensible.</p><p><strong>Nikolai Avteniev,</strong> <br>LinkedIn, Advanced Topics in Modern Software Engineering @ City College of New York</p>
                </div>
              

              

              
            

            <!-- Metadata (Below Content) -->
            

          </div> <!-- End .summary-content -->

        </div> <!-- End .summary-item -->

      

    </div> <!-- End .summary-item-list -->

  </div> <!-- End .summary-item-list-container -->

</div>
</div></div></div></div></div>
      </div>
    </div>
  </div>
  
  <div id="about-section" data-url-id="about-section" data-collection-id="5e32d2c6b4e70977cf0ed54b" data-edit-main-image="">
    
    
      
    

    <div>
      <div data-content-field="main-content">
        <div data-type="page" data-updated-on="1581008995159" id="page-5e32d2c6b4e70977cf0ed54b"><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1580904761375_2969"><p><strong>The Tech-in-Residence Corps was launched in 2017 by the City of New York, NYC tech companies, and CUNY to equip college students with the in-demand skills they need to enter  the workforce.</strong></p></div></div><div><div data-block-type="2" id="block-yui_3_17_2_1_1580904761375_5947"><p>Co-designed by industry and academia, the program aims to infuse real-world experience and skills, taught by today’s top tech leaders, into tech degree programs. Tech-in-Residence Corps members  are equipped with training and support to teach the next generation of NYC students. </p></div></div></div></div>
      </div>
    </div>
  </div>
  
  <div id="prof-section" data-url-id="prof-section" data-collection-id="5e32d34ecd95a406db1a96f3" data-edit-main-image="">
    
    
      
    

    <div>
      <div data-content-field="main-content">
        <div data-type="page" data-updated-on="1580908853099" id="page-5e32d34ecd95a406db1a96f3"><div><div><div data-block-type="2" id="block-5e32d34ecd95a406db1a96f4"><p><h2>As an adjunct professor, <br>Tech-in-Residence Corps Members:</h2></p></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1580389198961_5554"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580389450190-FMWTGDEKELUQV6XAZTGD/ke17ZwdGBToddI8pDm48kLkXF2pIyv_F2eUT9F60jBl7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iyqMbMesKd95J-X4EagrgU9L3Sa3U8cogeb0tjXbfawd0urKshkc5MgdBeJmALQKw/proff-2.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580389450190-FMWTGDEKELUQV6XAZTGD/ke17ZwdGBToddI8pDm48kLkXF2pIyv_F2eUT9F60jBl7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iyqMbMesKd95J-X4EagrgU9L3Sa3U8cogeb0tjXbfawd0urKshkc5MgdBeJmALQKw/proff-2.jpeg" data-image-dimensions="2500x1667" data-image-focal-point="0.5,0.5" alt="proff-2.jpeg" src="https://www.techtalentpipeline.nyc/proff-2.jpeg"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              
                <div><p>Teach in the Classroom</p></div>
              

              
                <div><p>With the help of faculty, specialized training and other support, teach or co-teach tech courses at colleges across the five boroughs.</p></div>
              

              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1580389198961_4269"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580389372540-KLHI6IY6ZM2H37UX9TQJ/ke17ZwdGBToddI8pDm48kO7Rg1Gpu728H4UqxUIfecJZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PICj5SdZHY9KUswDgTH3eH8sP5PrkY15Dr7CE2CPSRiTEKMshLAGzx4R3EDFOm1kBS/proff-1.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580389372540-KLHI6IY6ZM2H37UX9TQJ/ke17ZwdGBToddI8pDm48kO7Rg1Gpu728H4UqxUIfecJZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PICj5SdZHY9KUswDgTH3eH8sP5PrkY15Dr7CE2CPSRiTEKMshLAGzx4R3EDFOm1kBS/proff-1.jpeg" data-image-dimensions="800x533" data-image-focal-point="0.5,0.5" alt="proff-1.jpeg" src="https://www.techtalentpipeline.nyc/proff-1.jpeg"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              
                <div><p>Inform Curriculum</p></div>
              

              
                <div><p>Teach in your area of expertise, selecting from topics such as software engineering, web development, mobile development, data science and analytics, artificial intelligence, and cybersecurity. <strong>Photo Credit: Benjamin Ohene</strong></p></div>
              

              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1580389198961_7907"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580389582846-9C4YLNMA2VIH61U38RJT/ke17ZwdGBToddI8pDm48kFmfxoboNKufWj-55Bgmc-J7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iXS6XmVv7bUJ418E8Yoc1hjuviiiZmrL38w1ymUdqq4JaGeFUxjM-HeS7Oc-SSFcg/proff-3.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580389582846-9C4YLNMA2VIH61U38RJT/ke17ZwdGBToddI8pDm48kFmfxoboNKufWj-55Bgmc-J7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iXS6XmVv7bUJ418E8Yoc1hjuviiiZmrL38w1ymUdqq4JaGeFUxjM-HeS7Oc-SSFcg/proff-3.jpeg" data-image-dimensions="2500x1668" data-image-focal-point="0.5,0.5" alt="proff-3.jpeg" src="https://www.techtalentpipeline.nyc/proff-3.jpeg"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              
                <div><p>Collaborate with Top NYC Tech Companies</p></div>
              

              
                <div><p>When you sign up, you join a community of top NYC tech companies working together to create a stronger pipeline of NYC tech talent.</p></div>
              

              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div></div></div></div></div></div>
      </div>
    </div>
  </div>
  
  <div id="why-section" data-url-id="why-section" data-collection-id="5e32d7901213336bbc29a31f" data-edit-main-image="">
    
    
      
    

    <div>
      <div data-content-field="main-content">
        <div data-type="page" data-updated-on="1581001620218" id="page-5e32d7901213336bbc29a31f"><div><div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1580910749793_8176"><p>The Tech-in-Residence Corps encourages both companies and individuals to participate</p></div></div></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1580390289837_5286"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580390525658-2KLKEPEMV57590UX9XMN/ke17ZwdGBToddI8pDm48kO7Rg1Gpu728H4UqxUIfecJZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PICj5SdZHY9KUswDgTH3eH8sP5PrkY15Dr7CE2CPSRiTEKMshLAGzx4R3EDFOm1kBS/in1.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580390525658-2KLKEPEMV57590UX9XMN/ke17ZwdGBToddI8pDm48kO7Rg1Gpu728H4UqxUIfecJZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PICj5SdZHY9KUswDgTH3eH8sP5PrkY15Dr7CE2CPSRiTEKMshLAGzx4R3EDFOm1kBS/in1.jpeg" data-image-dimensions="800x533" data-image-focal-point="0.5,0.5" alt="in1.jpeg" src="https://www.techtalentpipeline.nyc/in1.jpeg"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              
                <div><p>A Platform to Give Back</p></div>
              

              
                <div><p>Utilize your expertise to prepare local college students for success <strong>Photo Credit: Benjamin Ohene</strong></p></div>
              

              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1580390289837_6690"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580919040711-B41K1Y0GN7NGKAEO437C/ke17ZwdGBToddI8pDm48kHH9S2ID7_bpupQnTdrPcoF7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0nQwvinDXPV4EYh2MRzm-RRB5rUELEv7EY2n0AZOrEupxpSyqbqKSgmzcCPWV5WMiQ/unnamed.jpg" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580919040711-B41K1Y0GN7NGKAEO437C/ke17ZwdGBToddI8pDm48kHH9S2ID7_bpupQnTdrPcoF7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0nQwvinDXPV4EYh2MRzm-RRB5rUELEv7EY2n0AZOrEupxpSyqbqKSgmzcCPWV5WMiQ/unnamed.jpg" data-image-dimensions="2500x1666" data-image-focal-point="0.5,0.5" alt="unnamed.jpg" src="https://www.techtalentpipeline.nyc/unnamed.jpg"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              
                <div><p>Be a Leader in the NYC Tech Space</p></div>
              

              
                <div><p>Network with other NYC tech professionals while developing your leadership skills</p></div>
              

              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1580390289837_9157"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580390629374-AE5K8SI64HVZLT78HTHE/ke17ZwdGBToddI8pDm48kO7Rg1Gpu728H4UqxUIfecJZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PICj5SdZHY9KUswDgTH3eH8sP5PrkY15Dr7CE2CPSRiTEKMshLAGzx4R3EDFOm1kBS/in3.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580390629374-AE5K8SI64HVZLT78HTHE/ke17ZwdGBToddI8pDm48kO7Rg1Gpu728H4UqxUIfecJZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PICj5SdZHY9KUswDgTH3eH8sP5PrkY15Dr7CE2CPSRiTEKMshLAGzx4R3EDFOm1kBS/in3.jpeg" data-image-dimensions="800x533" data-image-focal-point="0.5,0.5" alt="in3.jpeg" src="https://www.techtalentpipeline.nyc/in3.jpeg"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              
                <div><p>Support Your Company’s Goals</p></div>
              

              
                <div><p>Build your company-to-classroom connection by preparing, identifying, quality, diverse tech talent <strong>Photo Credit: Benjamin Ohene</strong></p></div>
              

              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1580390289837_10984"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580390711916-O8YQHIUU00SUVQHS99D3/ke17ZwdGBToddI8pDm48kLkXF2pIyv_F2eUT9F60jBl7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iyqMbMesKd95J-X4EagrgU9L3Sa3U8cogeb0tjXbfawd0urKshkc5MgdBeJmALQKw/in4.jpg" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580390711916-O8YQHIUU00SUVQHS99D3/ke17ZwdGBToddI8pDm48kLkXF2pIyv_F2eUT9F60jBl7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iyqMbMesKd95J-X4EagrgU9L3Sa3U8cogeb0tjXbfawd0urKshkc5MgdBeJmALQKw/in4.jpg" data-image-dimensions="2500x1667" data-image-focal-point="0.5,0.5" alt="in4.jpg" src="https://www.techtalentpipeline.nyc/in4.jpg"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              
                <div><p>Become a Professor, Keep Your Day Job</p></div>
              

              
                <div><p>Teach a college course without a Master’s degree while maintaining your full time position</p></div>
              

              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div></div></div></div></div></div>
      </div>
    </div>
  </div>
  
  <div id="members-section" data-url-id="members-section" data-collection-id="5e32d5b7d7315a3d73a3b20d" data-edit-main-image="">
    
    
      
    

    <div>
      <div data-content-field="main-content">
        <div data-type="page" data-updated-on="1581007556958" id="page-5e32d5b7d7315a3d73a3b20d"><div><div><div data-block-type="2" id="block-5e32d5b7d7315a3d73a3b20e"><p><h2>Tech-in-Residence <br>Corps members <br>from:</h2></p></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1581001830238_9429"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1581004140978-7VRU85QKTGD2LCNZEF42/ke17ZwdGBToddI8pDm48kCrj8nYSkC8OUQNWb7HrhlJZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVF9ZtAsoRkFUW7RVNbHmMPJX-4VP4LhdXw_2zrJDUNf291lH3P2bFZvTItROhWrBJ0/logo-google.png" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1581004140978-7VRU85QKTGD2LCNZEF42/ke17ZwdGBToddI8pDm48kCrj8nYSkC8OUQNWb7HrhlJZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVF9ZtAsoRkFUW7RVNbHmMPJX-4VP4LhdXw_2zrJDUNf291lH3P2bFZvTItROhWrBJ0/logo-google.png" data-image-dimensions="464x260" data-image-focal-point="0.5,0.5" alt="logo-google.png" data-load="false" data-image-id="5e3c356c1c2cbb6170caa8a6" data-type="image" src="https://www.techtalentpipeline.nyc/logo-google.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1581001830238_10774"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1581004167198-RK5XUMT935NDFSP1U4Y9/ke17ZwdGBToddI8pDm48kCrj8nYSkC8OUQNWb7HrhlJZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVF9ZtAsoRkFUW7RVNbHmMPJX-4VP4LhdXw_2zrJDUNf291lH3P2bFZvTItROhWrBJ0/logo-spotify.png" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1581004167198-RK5XUMT935NDFSP1U4Y9/ke17ZwdGBToddI8pDm48kCrj8nYSkC8OUQNWb7HrhlJZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVF9ZtAsoRkFUW7RVNbHmMPJX-4VP4LhdXw_2zrJDUNf291lH3P2bFZvTItROhWrBJ0/logo-spotify.png" data-image-dimensions="464x260" data-image-focal-point="0.5,0.5" alt="logo-spotify.png" data-load="false" data-image-id="5e3c3587e1a6a03142aaa44a" data-type="image" src="https://www.techtalentpipeline.nyc/logo-spotify.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1581001830238_13611"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1581004206516-QHHM1CX6A8FOXHGZAKHQ/ke17ZwdGBToddI8pDm48kCrj8nYSkC8OUQNWb7HrhlJZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVF9ZtAsoRkFUW7RVNbHmMPJX-4VP4LhdXw_2zrJDUNf291lH3P2bFZvTItROhWrBJ0/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1581004206516-QHHM1CX6A8FOXHGZAKHQ/ke17ZwdGBToddI8pDm48kCrj8nYSkC8OUQNWb7HrhlJZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVF9ZtAsoRkFUW7RVNbHmMPJX-4VP4LhdXw_2zrJDUNf291lH3P2bFZvTItROhWrBJ0/image-asset.png" data-image-dimensions="464x260" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5e3c35ae1ad4fa389de241f0" data-type="image" src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1581004206516-QHHM1CX6A8FOXHGZAKHQ/ke17ZwdGBToddI8pDm48kCrj8nYSkC8OUQNWb7HrhlJZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVF9ZtAsoRkFUW7RVNbHmMPJX-4VP4LhdXw_2zrJDUNf291lH3P2bFZvTItROhWrBJ0/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1581001830238_12252"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1581004189426-8RGQ9GMJ156OTTM170D3/ke17ZwdGBToddI8pDm48kCrj8nYSkC8OUQNWb7HrhlJZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVF9ZtAsoRkFUW7RVNbHmMPJX-4VP4LhdXw_2zrJDUNf291lH3P2bFZvTItROhWrBJ0/logo-linkedin.png" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1581004189426-8RGQ9GMJ156OTTM170D3/ke17ZwdGBToddI8pDm48kCrj8nYSkC8OUQNWb7HrhlJZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVF9ZtAsoRkFUW7RVNbHmMPJX-4VP4LhdXw_2zrJDUNf291lH3P2bFZvTItROhWrBJ0/logo-linkedin.png" data-image-dimensions="464x260" data-image-focal-point="0.5,0.5" alt="logo-linkedin.png" data-load="false" data-image-id="5e3c359d55a46d19cd29b799" data-type="image" src="https://www.techtalentpipeline.nyc/logo-linkedin.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div></div></div>
      </div>
    </div>
  </div>
  
  <div id="cta-section" data-url-id="cta-section" data-collection-id="5e32d97858164e71d27deff8" data-edit-main-image="">
    
    
      
    

    <div>
      <div data-content-field="main-content">
        <div data-type="page" data-updated-on="1581102437381" id="page-5e32d97858164e71d27deff8"><div><div><div data-block-type="2" id="block-5e32d97858164e71d27deff9"><p><h2>To Learn More about the Tech-in-Residence Corps</h2></p></div></div><div><div data-block-type="2" id="block-yui_3_17_2_1_1580912628640_5573"><p><h2>Featured Courses Taught by the NYC Tech-in-Residence Corps</h2></p></div></div></div></div>
      </div>
    </div>
  </div>
  
  <div id="logo-section" data-url-id="logo-section" data-collection-id="5e3c383a55a46d19cd2a5dc3" data-edit-main-image="">
    
    
      
    

    <div>
      <div data-content-field="main-content">
        <div data-type="page" data-updated-on="1582220568614" id="page-5e3c383a55a46d19cd2a5dc3"><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1581004859587_4621"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1581004987579-WC9K9564G8MYWRAPSNM5/ke17ZwdGBToddI8pDm48kEGQ2yHp6dvVmUlNL9i9d9xZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7XxG-9FZQiNMT_ZdcQnlMXZQp8pG38zHqwO21k9T340O6-PGnTZvEhS2sJNwHSRqmA/logo-cybernyc.png" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1581004987579-WC9K9564G8MYWRAPSNM5/ke17ZwdGBToddI8pDm48kEGQ2yHp6dvVmUlNL9i9d9xZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7XxG-9FZQiNMT_ZdcQnlMXZQp8pG38zHqwO21k9T340O6-PGnTZvEhS2sJNwHSRqmA/logo-cybernyc.png" data-image-dimensions="136x146" data-image-focal-point="0.5,0.5" alt="logo-cybernyc.png" data-load="false" data-image-id="5e3c38bb1ad4fa389de2e91d" data-type="image" src="https://www.techtalentpipeline.nyc/logo-cybernyc.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div></div></div>
      </div>
    </div>
  </div>
        </div><!--
        -->
        
      </main>

      

      

    </div></div>]]>
            </description>
            <link>https://www.techtalentpipeline.nyc/tech-in-residence-corps</link>
            <guid isPermaLink="false">hacker-news-small-sites-24431603</guid>
            <pubDate>Thu, 10 Sep 2020 12:25:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Regression Analysis Overview: The Hows and the Whys]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24431542">thread link</a>) | @NaeosPsy
<br/>
September 10, 2020 | https://serokell.io/blog/regression-analysis-overview | <a href="https://web.archive.org/web/*/https://serokell.io/blog/regression-analysis-overview">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Machine learning experts have borrowed the methods of regression analysis from math because they allow making predictions with as little as just one known variable as well as multiple variables. They are useful for financial analysis, weather forecasting, medical diagnosis, and many other fields.</p><h2 id="what-is-regression-in-statistics%3F">What is regression in statistics?</h2><p>Regression analysis determines the relationship between one dependent variable and a set of independent variables. This sounds a bit complicated, so let’s look at an example.</p><p>Imagine that you run your own restaurant. You have a waiter who receives tips. The size of those tips usually correlates with the total sum for the meal. The bigger they are, the more expensive the meal was.</p><p>You have a list of order numbers and tips received. If you tried to reconstruct how large each meal was with just the tip data (a dependent variable), this would be an example of a simple linear regression analysis.</p><p>(This example was borrowed from the <a href="https://www.youtube.com/watch?v=ZkjP5RJLQF4&amp;t=9s">magnificent video by Brandon Foltz</a>.)</p><p>A similar case would be trying to predict how much the apartment will cost based just on its size. While this estimation is not perfect, a larger apartment will usually cost more than a smaller one.</p><p>To be honest, simple linear regression is not the only type of regression in machine learning and not even the most practical one. However, it is the easiest to understand.</p><h2 id="representation-of-the-regression-model">Representation of the regression model</h2><p>The representation of a linear regression model is a linear equation.</p><p>$$Y = a + bX$$</p><p>In this equation, $Y$ is the value that we are trying to predict. $X$ is the independent input value. Regarding parameters: $b$ represents the coefficient that every input value is multiplied with, while $a$ (the intercept coefficient) is a coefficient that we add in the end. Changing $b$ impacts the slope of the line, while changing a lets one move the line up and down the $Y$ axis.</p><p><img src="https://serokell.io/files/bn/bnug59b5.1_(29)_(1).jpg" alt="linear regression model"></p><h2 id="types-of-regression-for-ml">Types of regression for ML</h2><p>Let’s now look at the common types of linear regression analysis that are used in machine learning. There are four basic techniques that we are going to have a look at here. <a href="https://www.analyticsvidhya.com/blog/2015/08/comprehensive-guide-regression/#:~:text=Regression%20analysis%20is%20a%20form,effect%20relationship%20between%20the%20variables.">Other regression models</a> can also be found, but they are not so commonly used.</p><h3 id="simple-linear-regression">Simple linear regression</h3><p>Simple linear regression uses one independent variable to explain or predict the outcome.</p><p>For example, you have a table with the sample data concerning the temperature of cables and their durability. Now, you can do simple linear regression to create a model that can predict the durability of a cable based on its temperature.</p><p><img src="https://serokell.io/files/ab/abu8uep2.2_(21).jpg" alt="temperature durability table"></p><p>The predictions you make with simple regression will usually be rather inaccurate. A cable’s durability depends on many other things than just the temperature: wear, weight of carriage, humidity, and other factors. That is why simple linear regression is not usually used to solve real-life tasks.</p><h3 id="multiple-linear-regression-for-machine-learning">Multiple linear regression for machine learning</h3><p>Unlike simple linear regression, <a href="https://www.investopedia.com/terms/m/mlr.asp">multiple linear regression</a> uses several explanatory variables to predict the dependent outcome of a response variable.</p><p>A multiple linear regression model looks like this:</p><p>$$Y = a + b_1X_1 + b_2X_2 + b_3X_3 + … + b_tX_t$$</p><p>Here, $Y$ is the variable that you are trying to predict, $X$'s are the variables that you are using to predict $Y$, $a$ is the intercept, and $b$'s are the regression coefficients – they show how much a change in certain $X$ predicts a change in $Y$, everything else being equal.</p><p>In real life, multiple regression can be used by ML-powered algorithms to predict the price of stocks based on fluctuations in similar stocks.</p><p>However, it would be erroneous to say that the more variables you have, the more accurate your ML prediction is.</p><h4 id="problems-with-multiple-linear-regression">Problems with multiple linear regression</h4><p>Two possible problems arise with the use of multiple regression: overfitting and multicollinearity.</p><p><strong>Overfitting</strong> means that the model you build with multiple regression becomes too narrow and does not generalize well. It works okay on the training set of your machine learning model but does not function properly on the items not mentioned before.</p><p><strong>Multicollinearity</strong> describes the situation when there is correlation between not only the independent variables and the dependent variable but also between the independent variables themselves. We don’t want this to happen because it leads to misleading results for the model.</p><p>To conduct this type of analysis properly, you need to carefully prepare your data. We are going to talk about that later in this post.</p><h3 id="ordinary-least-squares">Ordinary least squares</h3><p>Another method of linear regression is ordinary least squares. This procedure helps you find the optimal line for a set of data points by minimizing the sum of the residuals.</p><iframe width="560" height="315" src="https://www.youtube.com/embed/JvS2triCgOY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="allowfullscreen"></iframe><p>Every data point represents the relationship between an independent variable and a dependent variable (that we are trying to predict).</p><p><img src="https://serokell.io/files/2t/2t3shpyn.6_(5)_(1).jpg" alt="ordinary least squares"></p><p>To represent the regression visually, you start by plotting the data points and then draw a line that has the smallest sum of squared distances (residuals) between the line and the data points. In ordinary least squares, this is usually done by finding a local minimum through partial derivatives.</p><h3 id="gradient-descent">Gradient descent</h3><p><a href="https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html#:~:text=Gradient%20descent%20is%20an%20optimization,the%20parameters%20of%20our%20model.">Gradient descent</a> is used for the optimization and fine-tuning of models.</p><p>Gradient descent is the process of finding something close to the local minimum of a function by repeatedly changing the parameters in the direction where the function gives a smaller result.</p><p><img src="https://serokell.io/files/vy/vygcbvx1.7_(6)_(1).jpg" alt="Gradient descent"></p><p>In the context of linear regression, we can use it to iteratively find the line with the smallest sum of squared residuals without calculating the optimal values for our coefficients.</p><p>We start with random values for each parameter of the model and calculate the sum of squared errors. Then, we iteratively update the parameters so that the sum of squared differences is smaller than with the original parameters. We do this until the sum doesn’t decrease anymore. At this moment, the GD has <em>converged</em>, and the parameters we have should provide us with a local minimum.</p><p>When you apply this technique, you need to choose a <em>learning rate</em> that determines the size of the improvement step to take on each iteration of the procedure. The process is repeated until a minimum sum squared error is achieved or no further improvement is possible.</p><p>A learning rate is an important concept when we talk about gradient descent. It describes the size of the required step. When the learning rate is high, you can discover more information with each step, but risk impacting the accuracy. In the case of a large enough step, the GD algorithm can not converge at all. A low learning rate is more accurate but we’re recalculating the values so frequently that it becomes inefficient. Gradient descent takes a lot of time, so the increased accuracy is usually not worth it.</p><p>In practice, gradient descent is useful when you have a lot of variables or data points, since calculating the answer might be expensive. In most situations, it will result in a line comparable to one drawn by OLS.</p><h3 id="regularization">Regularization</h3><p>This linear regression technique tries to reduce the complexity of the model by adding restrictions or pre-assumptions that help to avoid overfitting.</p><p>These <a href="https://en.wikipedia.org/wiki/Regularization_(mathematics)">regularization methods</a> help when there is multicollinearity between your independent variables and using the ordinary least squares method causes overfitting:</p><ul>
<li><strong>Lasso Regression:</strong> Ordinary least squares is changed to also minimize the absolute sum of the coefficients (called L1 regularization). Frequently, in the case of overfitting, we get very large coefficients. We could avoid it by minimizing not only the sum of the errors but also some function of the coefficients.</li>
<li><strong>Ridge Regression:</strong> Ordinary least squares is changed to also minimize the squared absolute sum of the coefficients (called L2 regularization).</li>
</ul><h2 id="data-preparation-and-making-predictions-with-regression">Data preparation and making predictions with regression</h2><p>Now let us see step by step how you approach a regression problem in ML.</p><h3 id="1.-generate-a-list-of-potential-variables">1. Generate a list of potential variables</h3><p>Analyze your problem and come up with potential independent variables that will help you to predict the dependent variable. For example, you can use regression to predict the impact of the product price and the marketing budget on sales.</p><h3 id="2.-collect-data-on-the-variables">2. Collect data on the variables</h3><p>Now it is time to collect historical data samples. Every company keeps track of sales, marketing budget, and prices of all the products they make. For our regression model, we need a dataset that looks like this:</p><table>
  <tbody><tr>
   <td>#
   </td>
   <td>Price in 1000$ (x1)
   </td>
   <td>Marketing budget in 1000$(x2)
   </td>
   <td>Number of sales in 1000(y)
   </td>
  </tr>
  <tr>
   <td>1
   </td>
   <td>0.2
   </td>
   <td>5
   </td>
   <td>20
   </td>
  </tr>
  <tr>
   <td>2
   </td>
   <td>0.089
   </td>
   <td>25
   </td>
   <td>50
   </td>
  </tr>
  <tr>
   <td>3
   </td>
   <td>0.3
   </td>
   <td>3
   </td>
   <td>10
   </td>
  </tr>
  <tr>
   <td>4
   </td>
   <td>0.5
   </td>
   <td>5.5
   </td>
   <td>20
   </td>
  </tr>
  <tr>
   <td>5
   </td>
   <td>0.103
   </td>
   <td>2
   </td>
   <td>1
   </td>
  </tr>
  <tr>
   <td>6
   </td>
   <td>0.044
   </td>
   <td>4
   </td>
   <td>20
   </td>
  </tr>
  <tr>
   <td>7
   </td>
   <td>0.289
   </td>
   <td>1.5
   </td>
   <td>5
   </td>
  </tr>
  <tr>
   <td>8
   </td>
   <td>0.170
   </td>
   <td>2
   </td>
   <td>6
   </td>
  </tr>
  <tr>
   <td>9
   </td>
   <td>0.056
   </td>
   <td>30
   </td>
   <td>60
   </td>
  </tr>
  <tr>
   <td>10
   </td>
   <td>0.017
   </td>
   <td>15
   </td>
   <td>40
   </td>
  </tr>
</tbody></table><h3 id="3.-check-the-relationship-between-each-independent-variable-and-the-dependent-variable-using-scatter-plots-and-correlations">3. Check the relationship between each independent variable and the dependent variable using scatter plots and correlations</h3><p>Placing the data points on a scatter plot is an intuitive way to see whether there is a linear relationship between the variables. I used the <a href="http://www.alcula.com/calculators/statistics/linear-regression/#gsc.tab=0">linear regression calculator on Alcula.com</a> but you can use any tool you like.</p><p>Let us start with the relationship between the price and the number of sales.</p><p><img src="https://serokell.io/files/uk/uk44sy66.8_(3)_(1).jpg" alt="price vs number of sales"></p><p>We can fit a line to the observed data.</p><p><img src="https://serokell.io/files/rl/rlzxn3bx.9_(2)_(1).jpg" alt="linear regression line"></p><p>Now we need to check the correlation between the variables. For that, I used an online calculator.</p><p>The correlation equals -0.441. This is called a <em>negative correlation</em>: one variable increases when the other one decreases. The higher the price, the lower the number of sales.</p><p>However, we also want to check the relationship between the money we invested in marketing and the number of sales.</p><p>Here is how our data points look on a scatter plot.</p><p><img src="https://serokell.io/files/c1/c1t95scb.10_(1).jpg" alt="marketing money vs number of sales"></p><p>We can see that there is a clear correlation between the marketing budget and the number of sold items.</p><p><img src="https://serokell.io/files/aq/aqv9u2o3.11_(2)_(1).jpg" alt="another linear regression line"></p><p>Indeed, when we calculate the coefficient (again, using <a href="http://acula.com/">Acula.com</a>), we get 0.967. The closer it is to one, the higher the correlation between the variables is. In this case, we see a <em>strong positive correlation</em>.</p><h3 id="4.-check-the-relationship-between-the-independent-variables">4. Check the relationship between the independent variables</h3><p>An important step to build an accurate model …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://serokell.io/blog/regression-analysis-overview">https://serokell.io/blog/regression-analysis-overview</a></em></p>]]>
            </description>
            <link>https://serokell.io/blog/regression-analysis-overview</link>
            <guid isPermaLink="false">hacker-news-small-sites-24431542</guid>
            <pubDate>Thu, 10 Sep 2020 12:15:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designing The Golem]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24431213">thread link</a>) | @tobr
<br/>
September 10, 2020 | http://www.fastram.co.uk/devblog/2020/09/designing-the-golem/ | <a href="https://web.archive.org/web/*/http://www.fastram.co.uk/devblog/2020/09/designing-the-golem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>	
		<div id="post-188">
				
			
						  	
				<div>
										<div>
						<p><img src="http://www.fastram.co.uk/devblog/wp-content/uploads/2020/09/itch_cover-300x238.jpg" alt="The Golem" width="300" height="238" srcset="http://www.fastram.co.uk/devblog/wp-content/uploads/2020/09/itch_cover-300x238.jpg 300w, http://www.fastram.co.uk/devblog/wp-content/uploads/2020/09/itch_cover.jpg 630w" sizes="(max-width: 300px) 100vw, 300px"><em>The Golem</em>, my block-pushing puzzle game, was released today on <a href="https://store.steampowered.com/app/1270390/The_Golem/">Steam</a> and <a href="https://bateleur.itch.io/the-golem">itch.io</a>. I want to talk about the design of the game and about puzzle games generally and how they've changed over time and where I hope they're going next.</p>
<p>My <a href="http://www.fastram.co.uk/devblog/2019/01/the-golem-open-playtesting/">previous blog post</a> (over a year ago!) was about the open playtesting process for <em>The Golem</em>, which was a surprising success. At the time I speculated about the possibility of turning the game into a small commercial project. I did indeed end up working on it in my free time as a side project, but the arrival of the worldwide COVID-19 pandemic in 2020 disrupted my work enough that I decided to put my main project down and work on <em>The Golem</em> full time for a couple of months to get it ready for launch this year.</p>
<p>As mentioned previously, my initial motivation in designing <em>The Golem</em> was to create a puzzle where the solution could not be found by fiddling around with the puzzle pieces and simply stumbling upon solutions. This being a very negative thing, I eventually focussed more on a more positive goal: that each level should be built around a single key idea and solving the level should be primarily about discovering that idea. This proved to be a very powerful way to design puzzles, but not entirely without controversy.</p>
<p>Before I talk about why this approach is good I want to talk about what you lose. There are puzzles one can design in <em>The Golem</em> which involve a precise set of moves with multiple pieces interacting in very complex ways that are challenging to find, but which cannot easily be described in terms of a single, core idea. These are what I think of as "micro" puzzles (although they need not be physically small), with the idea-based puzzles I favour being in the "macro" category of puzzles which are more about strategy and do not in general require precise moves. There is nothing wrong with micro-based puzzles. Some players enjoy them and <em>The Golem</em>'s ruleset definitely supports them well. There are none in the game because of my rule that all puzzles must have a core idea.</p>
<p>So why is this approach good? The main reason is because it eliminates so many weak level designs before they're even created. I've noticed a tendency for puzzle games to often contain levels which functionally duplicate previous levels or even levels which are little more than doodles in the game's level editor. Whilst it's possible to defend this sort of thing I'm personally not a fan since I feel it's disrespectful of the value of the player's time.</p>
<p>Another reason, perhaps even more important, is that occasionally one comes up with an idea before it's even clear if such a thing can be designed at all. Each level of <em>The Golem</em> began as a single sentence in a text file. In two or three cases it took literally hours of design (once all the iterations and bugfixes were taken into account) to turn that one line concept into a working level. If I'd made levels by sitting down and opening a level editor I don't think those levels would ever have been made.</p>
<hr>
<p><em>The Golem</em> is a difficult game, but not intentionally so. Or at least, it's intentional in the sense that I've been aware of it throughout the project and have chosen to leave it this way. It's not intentional in the sense that I don't think a more approachable version of the game could be as good. I don't mean this as some kind of puzzle-solving elitism. It's simply that the game is about thinking deeply about things and humans aren't very good at that. During playtesting my levels were repeatedly broken by playtesters. A few of these breaks were, of course, stupid errors on my part. But most were because the complexities of my own game were just as challenging to me as to anyone else. Equally, I also found it very enjoyable to watch replays of ingenious but unintended solutions enacted by playtesters, watching for the moment when some clever play unravelled all my intentions and left my level in ruins! A puzzle game is a dialogue between designer and player, but when a level breaks it is the player who speaks and the designer who listens.</p>
<p>It is interesting to me to examine the changes in puzzle games over time, both in terms of the games themselves and the attitudes of the community who play them. Many of the early puzzle games I loved had no undo function, whereas now I won't even bother to play a game without undo in most cases unless it's very short or it's a prototype and the designer plans to add one later. Likewise I used to expect puzzle games to be mostly filler, with maybe only a tenth of the levels being both good and original, whereas now I quickly get bored of repetition and busywork (and to their credit most modern designers avoid it).</p>
<p>More subtly, modern puzzles seem to have a much better awareness of player experience. Who is the game for? What does the target audience actually enjoy? <em>The Golem</em> is a puzzle game for people who already play puzzle games and it makes no effort to appeal to a wider audience. That's OK as far as it goes, but I think the most interesting unexplored design space in puzzle games lies in making games which bring the experience of thinking about interesting puzzles to a wider audience. I'm not talking here about casual games. I'm talking about games which offer serious challenge, but do so in a highly approachable way, welcoming inexperienced players and teaching them.</p>
<p>Another game which released today – <a href="https://www.monsterexpedition.com/">A Monster's Expedition (Draknek and Friends)</a> – takes new steps towards that goal. If I make another puzzle game in the future it will very likely be something inspired by that approach to design. <em>The Golem</em> is a love letter to the puzzle community, but maybe it's time to share our fun with everyone?</p>
	
							
							
					</div>	
					
				</div>
												
								
					</div><!--post -->

	</div></div>]]>
            </description>
            <link>http://www.fastram.co.uk/devblog/2020/09/designing-the-golem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24431213</guid>
            <pubDate>Thu, 10 Sep 2020 11:26:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Multiplication in Vedic Mathematics (2013)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24431147">thread link</a>) | @tosh
<br/>
September 10, 2020 | http://mathlearners.com/vedic-mathematics/multiplication-in-vedic-mathematics/ | <a href="https://web.archive.org/web/*/http://mathlearners.com/vedic-mathematics/multiplication-in-vedic-mathematics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article class="page" itemscope="" itemtype="http://schema.org/CreativeWork"><div itemprop="text"><p><img src="http://mathlearners.com/wp-content/uploads/2013/02/Multiplication-Shorcuts-In-Vedic-Mathematics.jpg" alt="Multiplication shorcuts in Vedic Mathematics" width="661" height="263" srcset="http://mathlearners.com/wp-content/uploads/2013/02/Multiplication-Shorcuts-In-Vedic-Mathematics-300x119.jpg 300w, http://mathlearners.com/wp-content/uploads/2013/02/Multiplication-Shorcuts-In-Vedic-Mathematics.jpg 661w" sizes="(max-width: 661px) 100vw, 661px"></p><p>Tirthaji Maharaj has classified tricks to Multiply Numbers in <a href="http://mathlearners.com/vedic-mathematics/">Vedic Mathematics</a>&nbsp;in&nbsp;Specific and General Methods. Specific Multiplication Methods can be applied when numbers satisfy certain conditions like&nbsp;both numbers closer to 100 or numbers closer to each other or addition of last digits of both numbers is 10, etc. While General Multiplication Methods can be applied to any types of numbers.</p><p>Depending on Specific and General Techniques, Multiplication in Vedic Mathematics are classified in the form of Sutras as below. Lets see the&nbsp;&nbsp;Vedic Mathematics Multiplication techniques.</p><ol><li>Nikhilam Sutra (Specific Technique)</li><li>Anurupyena Sutra (Specific Technique)</li><li>Urdhva Tiryak Sutra and Vinculum Process (General Technique)</li><li>Ekayunena Purvena (Specific Technique)</li><li>Antyaordaske’pi (Specific Technique)</li></ol><h2>Nikhilam Sutra:</h2><p>This is most simplest trick to multiply numbers using Vedic Mathematics. I personally like this method a lot as multiplication can be done in mind as well.</p><p>Using Nikhilam Sutra it is simpler to multiply numbers like 98 &amp; 95, 997 &amp; 987, 102 &amp; 112, 995 &amp; 1008 i.e. the numbers which are closer to power of 10. &nbsp;This Sutra is a Specific method of Multiplication in Vedic Mathematics which shows shortcuts&nbsp;to multiply numbers which are closer to power of 10 (10, 100, 1000, etc.&nbsp;)</p><p>This will generate 3 cases:</p><ul><li>Numbers closer and less than power of 10. Example: 97 * 96, 994 * 992, etc</li><li>Numbers closer and greater&nbsp;than power of 10. Example: 102* 108, 1004&nbsp;* 1012, etc</li><li>Numbers closer and lying on both sides of power of&nbsp;10. Example: 102* 95, 1004&nbsp;* 991, etc</li></ul><p>Let’s see few examples on this:</p><p><img src="http://mathlearners.com/wp-content/uploads/2013/02/Vedic-Mathematics-Nikhilam-Sutra.jpg" alt="Vedic Mathematics trick to multiply numbers" width="509" height="385" srcset="http://mathlearners.com/wp-content/uploads/2013/02/Vedic-Mathematics-Nikhilam-Sutra-300x227.jpg 300w, http://mathlearners.com/wp-content/uploads/2013/02/Vedic-Mathematics-Nikhilam-Sutra.jpg 600w" sizes="(max-width: 509px) 100vw, 509px"></p><p>Click Here To Check &nbsp;Process, Types and<a href="http://mathlearners.com/vedic-mathematics/multiplication-in-vedic-mathematics/nikhilam/"> Examples on Nikhilam Sutra</a></p><h2>Anurupyena Sutra:</h2><p>This is a sub-type of Nikhilam Sutra and another&nbsp;vedic math multiplication trick&nbsp;when numbers are not closer to power of 10 but are closer to themselves. It works on concept of <strong>Working Base</strong> and then apply Nikhilam Sutra.</p><p>For Example – Multiplication of Numbers like &nbsp;63&nbsp;&amp; 67.</p><p>Process:</p><ol><li><strong>Working Base(W.B.) concept</strong>: As the&nbsp;numbers (63&nbsp;&amp; 67) are closer to 60, we take working base as 60 (6*10) instead of 100, here factor is 6.</li><li>Apply concept of Nikhilam as discussed previously i.e. 63 is 3 greater than 60 and 67 is 7 greater than 60</li><li>Multiply 3 and 7 to get 21 in 2nd compartment. As base is *10, thus we&nbsp;need to have only 1 digit in 2nd compartment and hence need to carry forward 2 to 1st compartment.</li><li>Like Nikhilam Sutra,&nbsp;Cross Addition of 63 &amp; 7 or 67 &amp; 3 gives 70.</li><li>In Anurupyena Sutra, before adding carry forward directly to 1st compartment we need to multiply by the factor (6) and then add the carry forward. This Carry Forward (2) is added to 420</li><li>Final Answer: 4221</li></ol><p>Same multiplication 63 and 67 can be solved by considering Working Base of 70 (10 * 7) as below.</p><p><img src="http://mathlearners.com/wp-content/uploads/2013/02/Vedic-Mathematics-Anurupyena-Sutra.jpg" alt="Vedic Mathematics Shortcut to multiply numbers" width="697" height="344" srcset="http://mathlearners.com/wp-content/uploads/2013/02/Vedic-Mathematics-Anurupyena-Sutra-300x148.jpg 300w, http://mathlearners.com/wp-content/uploads/2013/02/Vedic-Mathematics-Anurupyena-Sutra-768x379.jpg 768w, http://mathlearners.com/wp-content/uploads/2013/02/Vedic-Mathematics-Anurupyena-Sutra.jpg 926w" sizes="(max-width: 697px) 100vw, 697px"></p><p>Click Here &nbsp;To understand the Process and More <a href="http://mathlearners.com/vedic-mathematics/multiplication-in-vedic-mathematics/anurupyena/">Examples of Anurupyena Sutra</a></p><h2>Urdhva Tiryak Sutra:</h2><p>This is another great shortcut method of multiplication using Vedic Mathematics.&nbsp;Urdhva Tiryak is General method of multiplication in Vedic Maths which provides shortcut to multiply any types of numbers.</p><p>It can be applied&nbsp;very easily to multiply 3 digit numbers, multiply 4 digits numbers and even more than 4 digit numbers.</p><p>Lets see an example Multiplication of 3 digit numbers:</p><p><strong>Formula Used:</strong> &nbsp;(ax<sup>2</sup>+bx+c)(dx<sup>2</sup>+ex+f) = adx<sup>4</sup> + (ae+bd)x<sup>3</sup> + (af+be+cd)x<sup>2</sup> + (bf+ce)x + cf</p><p><strong>Process:&nbsp;(Left –&gt; Right)</strong></p><p><img src="http://mathlearners.com/wp-content/gallery/Multiplication/VedicMathUT3Digits.jpg" alt="Vedic_Mathematics_Multiplication_UrdhvaTiryak_3Digits" width="375" height="77"></p><ol><li>Vertical Multiplication of 1st digits of 2 numbers.</li><li>Crosswise Multiplication Addition of 1st 2 digits 2 numbers. (i.e. Crosswise Multiplication of 1st 2 digits and adding them.)</li><li>Crosswise Multiplication Addition of all 3 digits of both the numbers.</li><li>Crosswise Multiplication Addition of last 2 digits 2 numbers.</li><li>Vertical Multiplication of last digits 2 numbers.</li><li>For all steps, except 1st step, each compartment needs to have ONLY 1 digits. If not then carry forward initial digits to previous compartment (Check below examples to understand).</li></ol><p><img src="http://mathlearners.com/wp-content/uploads/2013/02/Vedic-Mathematics-UrdhvaTiryak-Sutra-1.jpg" alt="Vedic Mathematics tips to multiply numbers" width="535" height="200" srcset="http://mathlearners.com/wp-content/uploads/2013/02/Vedic-Mathematics-UrdhvaTiryak-Sutra-1-300x112.jpg 300w, http://mathlearners.com/wp-content/uploads/2013/02/Vedic-Mathematics-UrdhvaTiryak-Sutra-1.jpg 535w" sizes="(max-width: 535px) 100vw, 535px"></p><p>Click Here to Check Process, Multiplication of 4 &amp; more examples&nbsp;using <a href="http://mathlearners.com/vedic-mathematics/multiplication-in-vedic-mathematics/urdhva-tiryak/">UrdhvaTiryak Sutra.</a></p><h2>Vinculum&nbsp;Process of Multiplication:<strong> � </strong></h2><p>Vinculum is a special method of Vedic Maths Multiplication which is used with Urdhva Tiryak whenever we have bigger digits like 6,7,8 and 9.</p><p>Vinculum is a process applied when numbers have bigger digits like 6,7,8,9. Carrying out operations like multiplication with bigger digits is time consuming and little tougher as compared to smaller digits. Hence such digits 6,7,8 and 9 are converted to smaller digits like 4,3,2 and 1 using Vinculum Process.</p><p>I highly recommend to go through the� <a href="http://mathlearners.com/vedic-mathematics/basic-requisites/">concept of Vinculum Process</a>.</p><p><img src="http://mathlearners.com/wp-content/gallery/Multiplication/VedicMathUrdhvaTiryak3.jpg" alt="trick in Vedic Mathematics to multiply numbers using Urdhva Tiryak Sutra"></p><h2>Ekayunena Purvena Sutra:</h2><p>This sutra is applicable whenever multiplier has only 9’s as digits.</p><p>Example:</p><p><img src="http://mathlearners.com/wp-content/uploads/2013/02/Vedic-Mathematics-Ekayunena-Purvena-Sutra.jpg" alt="Vedic Mathematics trick to multiply numbers" width="300" height="410"></p><p>Click Here =&gt; To understand the Process and more examples on<a href="http://mathlearners.com/vedic-mathematics/multiplication-in-vedic-mathematics/ekayunena-purvena/"> Ekayunena Purvena Sutra.</a></p><h2><a href="http://mathlearners.com/vedic-mathematics/multiplication-in-vedic-mathematics/antyaordasakepi/">Antyaordasake’pi:</a></h2><p>This sutra has&nbsp;another great multiplication trick in Vedic Mathematics which can be applied when last digits of both numbers totals as 10.</p><p><strong>Steps:</strong></p><ol><li>Check if addition of last digits of the numbers is 10.</li><li>If yes, multiply them and write in 2nd compartment.</li><li>Apply <a href="http://mathlearners.com/vedic-mathematics/squares/ekadhikena-purvena/">Ekadhikena Purvena</a> for the remaining digits i.e. Add 1 to the remaining digits.</li><li>Eg: In case of 34&nbsp;x 36, Apply Ekadhikena Purvena on 3&nbsp;so we have 4. Now multiply 3&nbsp;and 4 and&nbsp;write in the 1st compartment.</li></ol><p><img src="http://mathlearners.com/wp-content/uploads/2013/02/Vedic-Mathematics-Antyaordasake.jpg" alt="Vedic Mathematics Shortcut to multiply numbers" width="322" height="182" srcset="http://mathlearners.com/wp-content/uploads/2013/02/Vedic-Mathematics-Antyaordasake-300x170.jpg 300w, http://mathlearners.com/wp-content/uploads/2013/02/Vedic-Mathematics-Antyaordasake.jpg 322w" sizes="(max-width: 322px) 100vw, 322px"></p><p>Click Here =&gt; <a href="http://mathlearners.com/vedic-mathematics/multiplication-in-vedic-mathematics/antyaordasakepi/">Multiplication Shortcuts of&nbsp;Antyaordasake’pi Sutra in Vedic Mathematics.</a></p></div></article></div>]]>
            </description>
            <link>http://mathlearners.com/vedic-mathematics/multiplication-in-vedic-mathematics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24431147</guid>
            <pubDate>Thu, 10 Sep 2020 11:16:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Rack Elevation Diagram Generator in JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24431134">thread link</a>) | @wjholden
<br/>
September 10, 2020 | https://wjholden.com/rack | <a href="https://web.archive.org/web/*/https://wjholden.com/rack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://wjholden.com/rack</link>
            <guid isPermaLink="false">hacker-news-small-sites-24431134</guid>
            <pubDate>Thu, 10 Sep 2020 11:13:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Voucher System verification using TLA+]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24431082">thread link</a>) | @jayp1418
<br/>
September 10, 2020 | https://www.moritz.systems/blog/voucher-system-verification-using-tlaplus/ | <a href="https://web.archive.org/web/*/https://www.moritz.systems/blog/voucher-system-verification-using-tlaplus/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/money-computer-desk-finance-success-internet-business-banking-e-commerce.jpg" alt="E-Money"></p>

<p>Continuing from our <a href="https://www.moritz.systems/blog/an-introduction-to-formal-verification/">previous article</a>,
let us take an example of how to write a
TLA+ proof for a real-world specification of a distributed system.
For this exercise we will go through
the <em>Voucher Trading System</em> process as specified by the
<a href="https://tools.ietf.org/rfc/rfc3506.txt">RFC3506</a> hosted by <abbr title="Internet Engineering Task Force">IETF</abbr>.
The distributed and concurrent systems require a
<a href="https://en.wikipedia.org/wiki/Consensus_(computer_science)">consensus protocol</a>
to achieve overall system reliability and immunity to failures of nodes.
We decided to select for this VTS network a simple
<a href="https://en.wikipedia.org/wiki/Two-phase_commit_protocol">Two-phase commit</a> protocol.</p>

<p>This article presents how TLA+ and formal methods in general assure correctness of the defined specification,
in our case, of the VTS network and the distributed consensus implementation.
Preparing a formal proof guarantees the 1-to-1 match between a specification and the implementation.
This property of formal methodology verifies not just the fultlessness of a specification, but catches
possible flaws or wrong assumptions in a system at a very early stage and allows fixing them before
it could be too late or too costly.</p>

<p>If you want to avoid your product to
<a href="https://www.theregister.com/2020/08/13/yam_cryptocurrency_bug_governance/">implode</a>,
and easily catch a set of flaws in the specification itself and in an implementation itself, learn more about TLA+.</p>

<h3 id="an-introduction-to-consensus-protocol">An introduction to consensus protocol</h3>

<p>Consensus protocol is a mechanism in distributed computing networks where the
participating nodes propose values and all of them have to agree on one of the
proposed values.</p>

<p>This mechanism assures that all interacting entities can do a transaction
without entering into conflicting conditions and always leading into well
defined accomplished transaction states. The aim is to make the overall system
fault-tolerant and resillent, protecting the network from security attacks and
guaranteeing scalable and efficient implementation of its application.</p>

<p>The elementary properties of consensus protocol are:</p>

<ul>
<li><strong>Validity</strong> - any value decided is value proposed.</li>
<li><strong>Consistency</strong> - no two correct nodes decide differently.</li>
<li><strong>Termination</strong> - every correct node eventually decides.</li>
<li><strong>Integrity</strong> - a node decides at most once.</li>
</ul>

<p>Consensus protocol plays the key role in distributed IoT networks, load
balancing, clock synchronization, robotics, blockchain systems and many more.</p>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/iot_cloud.svg" alt="Internet of Things Cloud"></p>

<p><a href="https://en.wikipedia.org/wiki/Two-phase_commit_protocol">Two-phase commit</a>
(abbreviated as <em>2PC</em>)
is a specialized version of the consensus protocol and consists of two
phases:</p>

<ul>
<li><strong>Phase 1</strong> The request to prepare phase, in which a coordinator process attempts to prepare
all the transaction’s participating processes.</li>
<li><strong>Phase 2</strong> The commit or abort phase, in which the coordinator decides whether
to commit or abort the transaction and notifies the result to all the participant processes.</li>
</ul>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/2pc.svg" alt="Two-phase commit protocol"></p>

<p><abbr title="Two-phase commit">2PC</abbr> is a simple mechanism of
<a href="https://en.wikipedia.org/wiki/Atomic_commit">atomic commitment protocol</a>
and it is used in the
<abbr title="Voucher Trading System">VTS</abbr>
network, where the coordinator (or arbiter) is the
centralized or distributed
<strong>Voucher Trading Provider</strong> and
participating nodes consist of: <strong>issuers</strong>, <strong>holders</strong> and <strong>collectors</strong>.
The participating nodes exchange <strong>vouchers</strong> upon which the consensus is made.</p>

<h3 id="prelude">Prelude</h3>

<p>Before we go deeper into TLA+, we need a general introduction to RFC3506.</p>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/coupon-code-discount-sale-business-music-e-commerce-advertising-mockup.jpg" alt="E-commerce Voucher"></p>

<p><a href="https://tools.ietf.org/rfc/rfc3506.txt">RFC3506</a>
is a specification titled as “Requirements and Design for Voucher Trading System
(VTS)“. It describes how to do trading of vouchers (think of discount
coupons). We will be looking at the process of issuing a voucher as described
in the description in RFC in the chapters “Background”,
“Terminology” and “Model and VTS Requirements”.</p>

<p>Let’s define the necessary terminology regarding the voucher system:</p>

<ul>
<li><strong><em>Issuer</em></strong> - An entity who can issue vouchers with a promise.</li>
<li><strong><em>Holder</em></strong> - An entity who can hold vouchers that are issued.</li>
<li><strong><em>Collector</em></strong> - An entity who can collect the voucher and deliver the promise in
the voucher.</li>
<li><strong><em>Voucher</em></strong> - A digital representation of an “agreement” that is traded among
various entities.</li>
<li><strong><em>Voucher Trading Provider (VTP)</em></strong> - An agreed upon arbiter which helps carry out
the various operations between the entities and the voucher.</li>
</ul>

<p>In addition to the above, we also define a
<a href="https://en.wikipedia.org/wiki/Finite-state_machine">Finite-state Machine</a>
for the
<a href="https://github.com/byisystems/byihive/blob/master/docs/dot/VoucherLifeCycle.gv">voucher life cycle</a>:
this is a simple state machine that makes sure the voucher is in the correct
state at any given point in time. Think of this as similar to the state of the
turnstile from the example that was mentioned in the
<a href="https://www.moritz.systems/blog/an-introduction-to-formal-verification/">previous article</a>.</p>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/voucher-life-cycle.png" alt="Voucher Life Cycle"></p>

<ul>
<li><p><strong><em>Phantom</em></strong> - This is a new meta state introduced (not present in RFC3506), to
indicate a <strong><em>voucher</em></strong> which has not yet been issued. This state is held by
vouchers taking part in an issue transaction, when the transaction aborts,
these <strong><em>vouchers</em></strong> will cease to exist.</p></li>

<li><p><strong><em>Valid</em></strong> - This is the state of voucher that is valid for transfer or redeeming.</p></li>

<li><p><strong><em>Redeemed</em></strong> - This indicates the “agreement” or “promise” in the voucher which has been
delivered and is no longer valid.</p></li>
</ul>

<p>Finally, we also bring in the already described Two-phase commit protocol which helps
with the consensus part of the “trading” of vouchers. We use the TLA+
<a href="https://lamport.azurewebsites.net/video/video6-script.pdf">proof</a> given by
Leslie Lamport as our starting point to write up the proofs for the “trading” of
vouchers.</p>

<p>To present a model of our voucher network and write a TLA+ proof for it,
we start with a simplified case of exactly one Issuer and one Holder trying to
“issue” or “abort” a voucher transaction.
To illustrate the workflow of six possible operations with the Two-phase commit
protocol network, we present a message sequence diagram
and include in it the User, Issuer, Holder, Voucher and
<abbr title="Voucher Trading Provider">VTP</abbr>.
The User and Voucher from a technical point of view are not participating nodes in the network,
but for the sake of simplicity we include them in the drawing.</p>

<p><a href="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/message-sequence-diagram.png">
<img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/message-sequence-diagram.png" alt="Message Sequence Diagram">
</a></p>

<p>The operations are as follows:</p>

<ol>
<li>Propose a decision for each of the Issuer and Holder of the Voucher.</li>
<li>Prepare the Voucher for the transaction.</li>
<li>The Issuer, Holder and the Voucher are added to the <abbr title="Voucher Trading Provider">VTP</abbr>.</li>
<li>The <abbr title="Voucher Trading Provider">VTP</abbr> queries for the decision of the issuer and holder.</li>
<li>If all the parties are in agreement <abbr title="Voucher Trading Provider">VTP</abbr> commits the transaction and the voucher is issued.</li>
<li>If no parties can come to an agreement, <abbr title="Voucher Trading Provider">VTP</abbr> aborts the transaction and the voucher is not issued.</li>
</ol>

<p>We are now ready to break this down into a formal proof in TLA+.</p>

<h3 id="writing-the-tla-proof">Writing the TLA+ proof</h3>

<p>Writing TLA+ proofs would be similar to writing up code for a program but with
some additional attributes. We have the usual programming language features like constants,
variables and functions; however, they look more mathematical to what we might expect from
a typical programming language like C/C++, Python, Go or Rust.
In order to write the formal proof, we need to use some further specifics of the TLA+ syntax,
going beyond the already presented knowledge from the
<a href="http://localhost:1313/blog/an-introduction-to-formal-verification/">previous article</a>,
where we solved the Die Hard problem with two jugs.</p>

<ul>
<li><strong><em>Messages</em></strong> - One of the things that have to be taken into account when designing
a concurrent and distributed system is that the participants within the system
will need to communicate with one another. This results in implementation of
multiple ways of passing messages across processes (for example pipes, sockets
etc). Even though TLA+ does not go into specifics of how this communication is
implemented, all we need to know is that TLA+ abstracts all the various types
of communication among entities as passing around “messages” among them.
<br></li>
</ul>

<pre><code>  Messages ==
    [type : {"Prepared"}, vi : I] \cup
    [type : {"Prepared"}, vh : H] \cup
    [type : {"Issue", "Abort"}]
</code></pre>

<ul>
<li><strong><em>Initial State</em></strong> - Any system within our specification should have a well
defined initial state, this is equivalent to initializing the start of the
program setting up the variables, entry point etc. Our simulation always
begins in this state regardless. For a simple
<a href="https://en.wikipedia.org/wiki/Finite-state_machine">Finite-state Machine</a>
this would be the “Start” state.
<br></li>
</ul>

<pre><code>  VTPInit ==
    (*****************************************************)
    (* The initial predicate.                            *)
    (*****************************************************)
    /\ vState = [v \in V |-&gt; "phantom"]
    /\ vlcState = [v \in V |-&gt; "init"]
    /\ hState = [h \in H |-&gt; "waiting"]
    /\ iState = [i \in I |-&gt; "waiting"]
    /\ vtpState = "init"
    /\ vtpIPrepared   = {}
    /\ msgs = {}
</code></pre>

<ul>
<li><strong><em>Next state</em></strong> - This is usually a combination of various possible states that is
allowed from the initial state and also includes the final states that would be
reached by the system we are trying to verify. Each of the states is
represented by something that looks like a function call representing an
operation that is allowed for the state.</li>
</ul>

<pre><code>  VTPNext ==
    \/ \E v \in V:
         VTPIssue(v) \/ VTPAbort(v)
    \/ \E h,i \in H \cup I:
         VTPRcvPrepared(h,i)
    \/ \E h \in H:
         HPrepare(h) \/ HChooseToAbort(h)
         \/ HRcvAbortMsg(h) \/ HRcvIssueMsg(h)
    \/ \E i \in I:
         IPrepare(i) \/ IChooseToAbort(i)
         \/ IRcvAbortMsg(i) \/ IRcvIssueMsg(i)  
</code></pre>

<p>In the above example, the definition of <code>VTPIssue(v)</code> describes the state of the
  system once a voucher has been issued, where we have to make sure the
  following things are correct.</p>

<ul>
<li>The initial state of the voucher is “phantom”, i.e. the voucher does not exist yet.</li>
<li>The voucher life cycle machine is currently in “init” state.</li>
<li>The voucher transaction provider is currently in the “init” state.</li>
<li>The Holder and Issuer are in the Prepared state.
<br></li>
</ul>

<p>Once the above states are true, we “issue” the voucher and the next expected states are</p>

<ul>
<li>The voucher transaction provider is in “done” state.</li>
<li>The voucher’s state has become “valid”, only the voucher which the entities
were exchanging has actually switched to this state.</li>
<li>The voucher life cycle machine has switched over to “working” state.</li>
<li>Make sure the “message” for the operation “Issue” has arrived in the messages list.
<br></li>
</ul>

<p>In addition to the above, we also make sure things that were not supposed to
  “change” have not changed, this is quite important to make sure that our state
  transition has not caused any unwanted side effects.</p>

<p>In this way we define the various states that the system can be in using our
  TLA+ specification.</p>

<ul>
<li><strong><em>Invariants</em></strong> - This is a very important part of writing TLA+ specifications, an
invariant can easily be described by asking “what are the things within the
system that …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.moritz.systems/blog/voucher-system-verification-using-tlaplus/">https://www.moritz.systems/blog/voucher-system-verification-using-tlaplus/</a></em></p>]]>
            </description>
            <link>https://www.moritz.systems/blog/voucher-system-verification-using-tlaplus/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24431082</guid>
            <pubDate>Thu, 10 Sep 2020 11:05:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Towards a content-addressed model for Nix]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24430823">thread link</a>) | @domenkozar
<br/>
September 10, 2020 | https://www.tweag.io/blog/2020-09-10-nix-cas/ | <a href="https://web.archive.org/web/*/https://www.tweag.io/blog/2020-09-10-nix-cas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><p>This is my first post about content-addressability in Nix — a long-awaited feature that is hopefully coming soon!
In this post I will show you how this feature will improve the Nix
infrastructure. I’ll come back in another post to explain the technical challenges of
adding content-addressability to Nix.</p>
<p>Nix has a wonderful model for handling packages.
Because each derivation is stored under (aka <em>addressed by</em>) a unique
name, multiple versions of the same library can coexist on the same
system without issues: each version of the library has a distinct
name, as far as Nix is concerned.</p>
<p>What’s more, if <code>openssl</code> is upgraded in <a href="https://github.com/NixOS/nixpkgs/">Nixpkgs</a>, Nix knows that all the
packages that depend on <code>openssl</code> (i.e., almost everything) must be
rebuilt, if only so that they point at the name of the new <code>openssl</code>
version. This way, a Nix installation will never feature a package
built for one version of <code>openssl</code>, but dynamically linked against
another: as a user, it means that you will never have an <em>undefined
symbol</em> error. Hurray!</p>
<h2>The input-addressed store</h2>
<p>How does Nix achieve this feat? The idea is that the name of a package
is derived from all of its inputs (that is, the complete list of
dependencies, as well as the package description). So if you change
the git tag from which <code>openssl</code> is fetched, the name changes, if the
name of <code>openssl</code> changes, then the name of any package which has <code>openssl</code> in
its dependencies changes.</p>
<p>However this can be very pessimistic: even changes that aren’t
semantically meaningful can imply mass rebuilding and downloading. As
a slightly extreme example, <a href="https://github.com/NixOS/nixpkgs/pull/83446">this merge-request on
Nixpkgs</a> makes a tiny change to the way <code>openssl</code> is built. It doesn’t actually
change <code>openssl</code>, yet requires rebuilding an insane amount of
packages. Because, as far as Nix is concerned, all these packages have
different names, hence are different packages. In reality, though,
they weren’t.</p>
<p>Nevertheless, the cost of the rebuild has to be born by the Nix
infrastructure: <a href="https://hydra.nixos.org/">Hydra</a> builds all packages to populate the cache,
and all the newly built packages must be stored. It costs both time,
and money (in cpu power, and storage space).</p>
<h2>Unnecessary rebuilds?</h2>
<p>Most distributions, by default, don’t rebuild packages when their dependencies change, and have a (more-or-less automated) process to detect changes that require rebuilding reverse dependencies.
For example, Debian <a href="https://www.debian.org/doc/debian-policy/policy.pdf#81">tries to detect ABI changes automatically</a> and Fedora has a <a href="https://docs.fedoraproject.org/en-US/fesco/Updates_Policy/">more manual process</a>.
But Nix doesn’t.</p>
<p>The issue is that the notion of a “breaking change” is a very fuzzy one.
Should we follow Debian and consider that only ABI changes are breaking?
This criterion only applies for shared libraries, and as the Debian policy acknowledges, only for “well-behaved” programs.
So if we follow this criterion, there’s still need for manual curation, which is <strong>precisely</strong> what Nix tries to avoid.</p>
<h2>The content-addressed model</h2>
<p>Quite happily, there is a criterion to avoid many useless rebuilds without sacrificing correctness: detecting when changes in a package (or one of its dependencies) yields the exact same output.
That might seem like an edge case, but the <code>openssl</code> example above (and many others) shows that there’s a practical application to it.
As another example, <code>go</code> depends on <code>perl</code> for its tests, so an upgrade of <code>perl</code> requires rebuilding all the Go packages in Nixpkgs, although it most likely doesn’t change the output of the <code>go</code> derivation.</p>
<p>But, for Nix to recognise that a package is not a new package, the
new, unchanged, <code>openssl</code> or <code>go</code> packages must have <em>the same name</em>
as the old version. Therefore, the name of a package must not be
derived from its inputs which have changed, but, instead, it should be
derived from the content of the compiled package. This is called
content addressing.</p>
<p>Content addressing is how you can be sure that when you and a
colleague at the other side of the world type <code>git checkout 7cc16bb8cd38ff5806e40b32978ae64d54023ce0</code> you actually have the exact
same content in your tree. Git commits are content addressed, therefore the name
<code>7cc16bb8cd38ff5806e40b32978ae64d54023ce0</code> refers to that exact
tree.</p>
<p>Yet another example of content-addressed storage is <a href="https://ipfs.io/">IPFS</a>. In IPFS storage
files can be stored in any number of computers, and even moved from
computer to computer. The content-derived name is used as a way to give
an intrinsic name to a file, regardless of where it is stored.</p>
<p>In fact, even the particular use case that we are discussing here -
avoiding recompilation when a rebuilt dependency hasn’t changed -
can be found in various build systems such as
<a href="https://bazel.build/">Bazel</a>. In build systems, such recompilation
avoidance is sometimes known as the <em>early cutoff optimization</em> −
see the <a href="https://www.microsoft.com/en-us/research/uploads/prod/2018/03/build-systems.pdf">build systems a la carte paper</a>
for example).</p>
<p>So all we need to do is to move the Nix store from an input-addressed
model to a content-addressed model, as used by many tools
already, and we will be able to save a lot of storage space and CPU
usage, by rebuilding many fewer packages. Nixpkgs contributors will
see their CI time improved. It could also allow <a href="https://github.com/NixOS/nix/issues/859">serving a binary cache
over IPFS</a>.</p>
<p>Well, like many things with computers,
this is actually way harder than it sounds (which explains why this
hasn’t already been done despite being discussed nearly 15 years ago in the
<a href="https://github.com/edolstra/edolstra.github.io/raw/49a78323f6b319da6e078b4f5f6b3112a30e8db9/pubs/phd-thesis.pdf">original paper</a>), but we now believe that there’s <a href="https://github.com/NixOS/rfcs/pull/62">a way forward</a>… more on that in a later post.</p>
<h2>Conclusion</h2>
<p>A content-addressed store for Nix would help reduce the insane load
that <a href="https://hydra.nixos.org/">Hydra</a> has to sustain. While content-addressing is a common technique both in distributed systems
and build systems (Nix is both!), getting to the point where it was
feasible to integrate content-addressing in Nix has been a long journey.</p>
<p>In a future post, I’ll explain why it was so hard, and how we finally
managed to propose a viable design for a content-addressed Nix.</p></div></div></div></section></div>]]>
            </description>
            <link>https://www.tweag.io/blog/2020-09-10-nix-cas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24430823</guid>
            <pubDate>Thu, 10 Sep 2020 10:22:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Worlds first text to video platform]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24430517">thread link</a>) | @Stjerrild
<br/>
September 10, 2020 | https://www.synthesia.io/request-demo | <a href="https://web.archive.org/web/*/https://www.synthesia.io/request-demo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Take a look at some videos created using Synthesia.</p><div id="office-hours"><p><img src="https://assets-global.website-files.com/5ec3eabd13550c7824ab59d7/5efc93568199c9c9e6686558_Information.svg" alt=""></p><p>It’s currently 12:47AM in London. We will review your script in the morning.</p></div><p>What you should expect to happen next:</p><div><p>1</p><p>We will review your video</p></div><div><p>2</p><p>You will receive your video in your email</p></div><div><p>3</p><p>You will receive an account creation invite</p></div><div><p><img src="https://assets-global.website-files.com/5ec3eabd13550c7824ab59d7/5ece3c7e585e43faabc2b143_Nadia%20Profile%20Image.png" alt="Nadia"></p><p>Nadia will approve your video and get back to you to find the date and time that best fits your calendar.</p></div><p>Don't want to wait? You can create account now:</p><p><a href="https://www.synthesia.io/create-account">Create Synthesia account now</a></p></div></div>]]>
            </description>
            <link>https://www.synthesia.io/request-demo</link>
            <guid isPermaLink="false">hacker-news-small-sites-24430517</guid>
            <pubDate>Thu, 10 Sep 2020 09:35:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Loclock – display local time in cities worldwide at one view]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24430386">thread link</a>) | @rlv04343
<br/>
September 10, 2020 | https://www.ionstage.org/loclock/ | <a href="https://web.archive.org/web/*/https://www.ionstage.org/loclock/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.ionstage.org/loclock/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24430386</guid>
            <pubDate>Thu, 10 Sep 2020 09:16:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tips and gotchas for managing AWS costs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24430361">thread link</a>) | @taggun
<br/>
September 10, 2020 | https://www.taggun.io/tips-and-gotchas-for-managing-your-aws-cloud-costs | <a href="https://web.archive.org/web/*/https://www.taggun.io/tips-and-gotchas-for-managing-your-aws-cloud-costs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="post-content"><p><h4><strong>You might be funding Jeff Bezo’s trip to the moon, and you don’t even know it</strong>.</h4></p><p>Are you using AWS as your cloud provider? I have been stung by AWS bills more than once because the AWS Cost Explorer is not user friendly <em>by design</em>. I suspect that it was designed to confuse us, so we could fund Jeff Bezo’s trip to the moon. But, here are a few things I have learned while running TAGGUN, to help you and other SaaS founders reduce AWS costs.</p><div><div><figure><img loading="lazy" src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1016/https://www.taggun.io/wp-content/uploads/2020/09/Jeff-Bezos-Moon.png" alt="" width="508" height="322" srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1016/https://www.taggun.io/wp-content/uploads/2020/09/Jeff-Bezos-Moon.png 1016w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_300/https://www.taggun.io/wp-content/uploads/2020/09/Jeff-Bezos-Moon-300x190.png 300w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_768/https://www.taggun.io/wp-content/uploads/2020/09/Jeff-Bezos-Moon-768x487.png 768w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_600/https://www.taggun.io/wp-content/uploads/2020/09/Jeff-Bezos-Moon-600x380.png 600w" sizes="(max-width: 508px) 100vw, 508px"><figcaption>Are you funding Jeff Bezo’s trip to the moon?</figcaption></figure></div></div><p><h4><strong>🚨 Gotchas: By default, AWS Cost Explorer hides all your credits, Savings Plans and Reservations Plans usage.</strong></h4></p><p>If you can’t see where you are spending your money, you are likely to waste your AWS Start up Credits, Savings Plans and Reservations usage away…</p><div><div><figure><img loading="lazy" src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1024/https://www.taggun.io/wp-content/uploads/2020/09/AWS-1024x800.png" alt="" width="512" height="400" srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1024/https://www.taggun.io/wp-content/uploads/2020/09/AWS-1024x800.png 1024w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_300/https://www.taggun.io/wp-content/uploads/2020/09/AWS-300x234.png 300w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_768/https://www.taggun.io/wp-content/uploads/2020/09/AWS-768x600.png 768w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_600/https://www.taggun.io/wp-content/uploads/2020/09/AWS-600x469.png 600w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1262/https://www.taggun.io/wp-content/uploads/2020/09/AWS.png 1262w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>Default view of AWS Cost Explore shows you nothing if you are using AWS credits.</figcaption></figure></div></div><p><h4><strong>💡 TIPS: Select Charge Type filter to show your&nbsp;<em>true</em>&nbsp;AWS usage</strong></h4></p><p>On the right panel, filter Charge Type to these three usages:</p><div><ul><li>Reservation applied usage</li><li>Savings Plan Covered Usage</li><li>Usage</li></ul></div><div><div><figure><img loading="lazy" src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_586/https://www.taggun.io/wp-content/uploads/2020/09/AWS2.png" alt="" width="293" height="430" srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_586/https://www.taggun.io/wp-content/uploads/2020/09/AWS2.png 586w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_204/https://www.taggun.io/wp-content/uploads/2020/09/AWS2-204x300.png 204w" sizes="(max-width: 293px) 100vw, 293px"><figcaption>Apply Charge Type Filter</figcaption></figure></div></div><div><div><figure><img loading="lazy" src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1024/https://www.taggun.io/wp-content/uploads/2020/09/AWS3-1024x673.png" alt="" width="512" height="337" srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1024/https://www.taggun.io/wp-content/uploads/2020/09/AWS3-1024x673.png 1024w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_300/https://www.taggun.io/wp-content/uploads/2020/09/AWS3-300x197.png 300w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_768/https://www.taggun.io/wp-content/uploads/2020/09/AWS3-768x505.png 768w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1536/https://www.taggun.io/wp-content/uploads/2020/09/AWS3-1536x1009.png 1536w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_600/https://www.taggun.io/wp-content/uploads/2020/09/AWS3-600x394.png 600w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1726/https://www.taggun.io/wp-content/uploads/2020/09/AWS3.png 1726w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>Use Charge Type to show the&nbsp;<em>true</em>&nbsp;AWS usage for the month!!&nbsp;</figcaption></figure></div></div><p>Now, you can use the report to analyse how you are using AWS and reduce waste.</p><div><div><figure><img loading="lazy" src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1024/https://www.taggun.io/wp-content/uploads/2020/09/AWS4-1024x630.png" alt="" width="512" height="315" srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1024/https://www.taggun.io/wp-content/uploads/2020/09/AWS4-1024x630.png 1024w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_300/https://www.taggun.io/wp-content/uploads/2020/09/AWS4-300x185.png 300w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_768/https://www.taggun.io/wp-content/uploads/2020/09/AWS4-768x473.png 768w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1536/https://www.taggun.io/wp-content/uploads/2020/09/AWS4-1536x946.png 1536w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_600/https://www.taggun.io/wp-content/uploads/2020/09/AWS4-600x369.png 600w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1686/https://www.taggun.io/wp-content/uploads/2020/09/AWS4.png 1686w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>True AWS Usage grouped by the type of service</figcaption></figure></div></div><p><h4><strong>🚨 Gotchas: EC2 snapshots cost more when the server is patched<br></strong></h4></p><p>The EC2 snapshot charges are cheap… until you start patching your servers. EC2 snapshot is charged based on the delta of EC2 volume and snapshots. So, your snapshot costs will jump up after you patch the servers for updates.</p><div><div><figure><img loading="lazy" src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1024/https://www.taggun.io/wp-content/uploads/2020/09/AWS5-1024x1013.png" alt="" width="512" height="507" srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1024/https://www.taggun.io/wp-content/uploads/2020/09/AWS5-1024x1013.png 1024w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_300/https://www.taggun.io/wp-content/uploads/2020/09/AWS5-300x297.png 300w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_150/https://www.taggun.io/wp-content/uploads/2020/09/AWS5-150x150.png 150w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_768/https://www.taggun.io/wp-content/uploads/2020/09/AWS5-768x760.png 768w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_600/https://www.taggun.io/wp-content/uploads/2020/09/AWS5-600x593.png 600w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1268/https://www.taggun.io/wp-content/uploads/2020/09/AWS5.png 1268w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>Snapshot costs will jump up after you patch the servers for updates.</figcaption></figure></div></div><p><h4>💡<strong>Tips: Monitor EC2 Snapshots regularly</strong></h4></p><p>In EC2, check the number of EC2 Snapshots in your account. Remove the old ones that are not in use anymore. Otherwise, you will start burning some serious cash,&nbsp;if the delta between your snapshots and your EC2 volume gets bigger.</p><div><div><figure><img loading="lazy" src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1024/https://www.taggun.io/wp-content/uploads/2020/09/AWS7-1024x983.png" alt="" width="512" height="492" srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1024/https://www.taggun.io/wp-content/uploads/2020/09/AWS7-1024x983.png 1024w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_300/https://www.taggun.io/wp-content/uploads/2020/09/AWS7-300x288.png 300w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_768/https://www.taggun.io/wp-content/uploads/2020/09/AWS7-768x737.png 768w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_600/https://www.taggun.io/wp-content/uploads/2020/09/AWS7-600x576.png 600w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1438/https://www.taggun.io/wp-content/uploads/2020/09/AWS7.png 1438w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>EC2 Snapshots</figcaption></figure></div></div><p><h4>💡 <strong>Tips: Use Lifecycle Manager and limit the retention days for your snapshots<br></strong></h4></p><p>AWS snapshot can cost up to 15% of your total AWS Bill. Of course, AWS wants to make it easy to create snapshots, but difficult to remove them.. Only recently, I discovered AWS has quietly released AWS Lifecycle Manager, which allows you to create a snapshot with a retention policy…</p><div><div><figure><img loading="lazy" src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1024/https://www.taggun.io/wp-content/uploads/2020/09/AWS6-1024x735.png" alt="" width="512" height="368" srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1024/https://www.taggun.io/wp-content/uploads/2020/09/AWS6-1024x735.png 1024w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_300/https://www.taggun.io/wp-content/uploads/2020/09/AWS6-300x215.png 300w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_768/https://www.taggun.io/wp-content/uploads/2020/09/AWS6-768x552.png 768w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1536/https://www.taggun.io/wp-content/uploads/2020/09/AWS6-1536x1103.png 1536w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_600/https://www.taggun.io/wp-content/uploads/2020/09/AWS6-600x431.png 600w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1540/https://www.taggun.io/wp-content/uploads/2020/09/AWS6.png 1540w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>AWS EC2 Lifecycle Manager</figcaption></figure></div></div><p><h4>💡 <strong>Tips: Use a USD based credit card</strong> to pay for your cloud bills</h4></p><p>If your company is not based in the US, you will be paying an additional 3% for all your cloud bills like AWS and TAGGUN, that are priced in US dollars. I’d suggest applying for something like Transferwise Business Debit Card to avoid getting charged foreign exchange fees and expensive FX rate by your bank.</p><p><h4>There are many 🚨 gotchas in AWS and AWS Billing</h4></p><p>For example: EC2 M4 is more expensive (and slower) than the new generation M5 series. An upgrade will save you some money. If you know any other tips and gotchas, please email <a href="mailto:ck-lee@taggun.io">me</a> and share your stories. I’d love to learn more.</p></div></div></div>]]>
            </description>
            <link>https://www.taggun.io/tips-and-gotchas-for-managing-your-aws-cloud-costs</link>
            <guid isPermaLink="false">hacker-news-small-sites-24430361</guid>
            <pubDate>Thu, 10 Sep 2020 09:13:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Simple Blogging Platform – QuickPublisher v1.3]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24430338">thread link</a>) | @rotimi_je_suis
<br/>
September 10, 2020 | https://www.quickpublisher.online/features | <a href="https://web.archive.org/web/*/https://www.quickpublisher.online/features">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    



    <!--================Header Menu Area =================-->
    <header>
        <nav>
            <a href="https://www.quickpublisher.online/"><img width="200" src="https://www.quickpublisher.online/img/logo.png" alt=""></a>
            

            
        </nav>
    </header>




<section>
    <div>
        <div>
            <div>
                <div>
                    <p><img src="https://www.quickpublisher.online/img/icon/f-icon-1.png" alt="">
                    </p>
                    <h4>Monetize Your Blog</h4>
                    <p>Our platform provides an easier way to monetize your contents without distracting your users with annoying ads. You can achieve this with micro subscriptions. Our platform has been integrated with 
                        <a href="https://microscriptions.com/" title="Microscriptions" target="_blank">Microscriptions</a></p>                    
                </div>
            </div>
            <div>
                <div>
                    <p><img src="https://www.quickpublisher.online/img/icon/f-icon-2.png" alt="">
                    </p>
                    <h4>Invite Trusted People To Contribute On Your Posts</h4>
                    <p>With the Flying-Solo plan, Invite trusted people such as colleagues, friends, etc to contribute information on your posts. Give access to your "collaborators" and they'll be able to login
                        and edit posts or even write a new post. As administrator, you still have rights to publish or unpublish posts as expected.</p>                    
                </div>
            </div>
            <div>
                <div>
                    <p><img src="https://www.quickpublisher.online/img/icon/f-icon-3.png" alt="">
                    </p>
                    <h4>Easy To Use Template Settings</h4>
                    <p>QuickPublisher by default takes care of all complex activities. In addition to that, you can also edit these settings to suit your taste.</p>                    
                </div>
            </div>
            <div>
                <div>
                    <p><img src="https://www.quickpublisher.online/img/icon/f-icon-4.png" alt="">
                    </p>
                    <h4>Switch On/Off Your Blog When You Want To</h4>
                    <p>Turn off your blog when you are busy loading new articles or in general, whenever you feel like.</p>                    
                </div>
            </div>
            <div>
                <div>
                    <p><img src="https://www.quickpublisher.online/img/icon/f-icon-5.png" alt="">
                    </p>
                    <h4>Custom Domain Name</h4>
                    <p>By default, your blog gets published on a .quickpublisher.online sub domain. Point your blog to your custom domain</p>                    
                </div>
            </div>
            <div>
                <div>
                    <p><img src="https://www.quickpublisher.online/img/icon/f-icon-6.png" alt="">
                    </p>
                    <h4>Build Your Audience</h4>
                    <p>QuickPublisher provides a quick an easy way to build your audience by allowing registration on your blog, moderating comments as well as sending newsletters to your users.</p>                    
                </div>
            </div>
        </div>
    </div>
</section>

<br>


<!--================End Banner Area =================-->

<!--================Circle Chart Area =================-->
<section>
    
</section>
<!--================End Circle Chart Area =================-->


<section>
    <div>
        <div>
            <p><img src="https://www.quickpublisher.online/img/icon/title-icon.png" alt=""></p><h2>Subscribe To Our Newsletter</h2>
        </div>
        
    </div>
</section>



<!--================End Footer Area =================-->




<!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->

<!-- Include all compiled plugins (below), or include individual files as needed -->


<!-- Rev slider js -->








<!-- Extra plugin css -->

 











</div>]]>
            </description>
            <link>https://www.quickpublisher.online/features</link>
            <guid isPermaLink="false">hacker-news-small-sites-24430338</guid>
            <pubDate>Thu, 10 Sep 2020 09:11:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Germany is testing public hazard alerting(now)]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24430275">thread link</a>) | @heredoc
<br/>
September 10, 2020 | https://www.bbk.bund.de/DE/AufgabenundAusstattung/Krisenmanagement/WarnungderBevoelkerung/Bundesweiter_Warntag/Bundesweiter_Warntag_node.html | <a href="https://web.archive.org/web/*/https://www.bbk.bund.de/DE/AufgabenundAusstattung/Krisenmanagement/WarnungderBevoelkerung/Bundesweiter_Warntag/Bundesweiter_Warntag_node.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
      <div>
<p>Am <strong>10. September 2020</strong> haben in ganz Deutschland Warn-Apps gepiept, Sirenen geheult, Rundfunkanstalten ihre Sendungen unterbrochen und Probewarnungen sind auf digitalen Werbetafeln erschienen. An diesem Tag fand der erste bundesweite Warntag seit der Wiedervereinigung statt. Ab diesem Jahr wird ein bundesweiter Warntag jährlich am <strong>zweiten Donnerstag im September</strong> stattfinden.</p><p>Zur Warnung der Bevölkerung nutzen Bund, Länder und Kommunen alle verfügbaren Kommunikationskanäle: so etwa das vom Bundesamt für Bevölkerungsschutz und Katastrophenhilfe (<abbr title="Bundesamt für Bevölkerungsschutz und Katastrophenhilfe">BBK</abbr>) betriebene <a href="https://www.bbk.bund.de/DE/AufgabenundAusstattung/Krisenmanagement/WarnungderBevoelkerung/MoWaS/ModularesWarnsystem_node.html;jsessionid=1B1F2014E22A97E4C5B9AA0C235E6168.1_cid345" target="_blank" rel="noopener noreferrer" title="Modulares Warnsystem (Öffnet&nbsp;neues&nbsp;Fenster)">Modulare Warnsystem</a> und die <a href="https://www.bbk.bund.de/DE/NINA/Warn-App_NINA_node.html;jsessionid=1B1F2014E22A97E4C5B9AA0C235E6168.1_cid345" target="_blank" rel="noopener noreferrer" title="Warn-App NINA (Öffnet&nbsp;neues&nbsp;Fenster)">Warn-<abbr title="Applikation – Anwendungsprogramm">App</abbr> <abbr title="Notfall-Informations- und Nachrichten-App">NINA</abbr></a>, eine Vielzahl von Medien und Rundfunksendern bis hin zu Sirenen und Lautsprecherdurchsagen vor Ort. </p>
<p><span><img src="https://www.bbk.bund.de/SharedDocs/Bilder/BBK/DE/Bilder_aktuelle_Meldungen/2020/Warntag_Graphik.jpg;jsessionid=1B1F2014E22A97E4C5B9AA0C235E6168.1_cid345?__blob=normal&amp;v=2" title="Warntag 2020 - eine graphische Darstellung" alt="Warntag 2020 - eine graphische Darstellung"></span>
</p>

<p>Mithilfe des Modularen Warnsystems wird eine Probewarnung an alle daran angeschlossenen Warnmultiplikatoren versendet. Warnmultiplikatoren sind ein Adressatenkreis, der Warnmeldungen weitergibt. Hierbei kann es sich <acronym title="zum Beispiel">z. B.</acronym> um einen Radio- oder Fernsehsender handeln, der seine laufende Sendung unterbricht und die Meldung verliest <abbr title="beziehungsweise">bzw.</abbr> einen Crawler (Lauftext) in die laufende Fernsehsendung einblendet, oder eine Leitstelle, die ihre Sirenen auslöst.</p>

<p>Diese Warnmultiplikatoren leiten die Probewarnung an die Endgeräte wie zum Beispiel Radios oder die Warn-<abbr title="Applikation – Anwendungsprogramm">App</abbr> <abbr title="Notfall-Informations- und Nachrichten-App">NINA</abbr> und damit direkt an die Bürgerinnen und Bürger weiter. Zeitgleich werden auf Ebene der Länder, in den Landkreisen und in den Kommunen außerdem weitere verfügbare kommunale Warnmittel ausgelöst, zu denen beispielsweise Sirenen und Lautsprecherwagen zählen können. Auf denselben Wegen wird dann um 11.20 Uhr das allgemeine Signal zur Entwarnung erfolgen.</p>
<h3>Vom Sofa aus ins Bundesamt schauen</h3>

<p>Das <abbr title="Bundesamt für Bevölkerungsschutz und Katastrophenhilfe">BBK</abbr> hat im Bund die Aufgabe der Warnung der Bevölkerung vor den besonderen Gefahren eines Verteidigungsfalls und beteiligt sich ebenfalls am Warntag 2020. Wovor und wie das Amt dabei genau warnen kann, darüber hat das <abbr title="Bundesamt für Bevölkerungsschutz und Katastrophenhilfe">BBK</abbr> bereits vorab bei einem virtuellen Tag der offenen Tür informiert – und sich dabei den Bürgerinnen und Bürgern als zuständige Bundesoberbehörde gleich selbst vorgestellt.</p>

<p>In den folgenden drei Gesprächen erfahren Sie mehr über die Aufgabe der Warnung der Bevölkerung, die Warnapp <abbr title="Notfall-Informations- und Nachrichten-App">NINA</abbr> und den bundesweiten Warntag. Die Videos sind auch in Deutsche Gebärdensprache übersetzt.</p>

<p><iframe width="448" height="252" src="https://www.youtube.com/embed/mFlqBinNnuE" frameborder="0" gesture="media" allow="encrypted-media" allowfullscreen="1">Ihr Browser unterstützt iFrame nicht</iframe></p>

<p><iframe width="448" height="252" src="https://www.youtube.com/embed/b3PzZOn40NE" frameborder="0" gesture="media" allow="encrypted-media" allowfullscreen="1">Ihr Browser unterstützt iFrame nicht</iframe></p>

<p><iframe width="448" height="252" src="https://www.youtube.com/embed/DHK6CQpkZv0" frameborder="0" gesture="media" allow="encrypted-media" allowfullscreen="1">Ihr Browser unterstützt iFrame nicht</iframe></p>

<p>Auf Grundlage eines Beschlusses der Innenministerkonferenz wird der bundesweite Warntag ab dem Jahr 2020 jährlich an jedem zweiten Donnerstag im September stattfinden. Er soll dazu beitragen, die Akzeptanz und das Wissen um die Warnung der Bevölkerung in Notlagen zu erhöhen und damit deren Selbstschutzfertigkeiten zu stärken. Die Wichtigkeit und Aktualität des Themas Warnung zeigt sich auch durch die Entwicklungen im Zusammenhang mit dem <a href="https://www.bbk.bund.de/DE/AktuellesundPresse/Informationen_zu_SARS-CoV-2/Corona_node.html;jsessionid=1B1F2014E22A97E4C5B9AA0C235E6168.1_cid345" target="_blank" rel="noopener noreferrer" title="Informationen zu SARS-CoV-2 (Öffnet&nbsp;neues&nbsp;Fenster)">Corona-Virus</a> in diesem Jahr. Zur Warnung und Information der Bevölkerung nutzen Bund, Länder und Kommunen die verfügbaren Kommunikationskanäle. So werden beispielsweise über das vom <abbr title="Bundesamt für Bevölkerungsschutz und Katastrophenhilfe">BBK</abbr> betriebene <a href="https://www.bbk.bund.de/DE/AufgabenundAusstattung/Krisenmanagement/WarnungderBevoelkerung/MoWaS/ModularesWarnsystem_node.html;jsessionid=1B1F2014E22A97E4C5B9AA0C235E6168.1_cid345" target="_blank" rel="noopener noreferrer" title="Modulares Warnsystem (Öffnet&nbsp;neues&nbsp;Fenster)">Modulare Warnsystem</a> und die <a href="https://www.bbk.bund.de/DE/NINA/Warn-App_NINA_node.html;jsessionid=1B1F2014E22A97E4C5B9AA0C235E6168.1_cid345" target="_blank" rel="noopener noreferrer" title="Warn-App NINA (Öffnet&nbsp;neues&nbsp;Fenster)">Warn-<abbr title="Applikation – Anwendungsprogramm">App</abbr> <abbr title="Notfall-Informations- und Nachrichten-App">NINA</abbr></a> Warnungen und Informationen der zuständigen Behörden, wie der Gesundheitsministerien des Bundes und der Länder, bereitgestellt. Bund und Länder bereiten den bundesweiten Warntag in Abstimmung mit kommunalen Vertretern gemeinsam vor. Zuständig sind auf Bundesebene das <abbr title="Bundesamt für Bevölkerungsschutz und Katastrophenhilfe">BBK</abbr>, auf der Ebene der Länder die jeweiligen Innenministerien und auf der Ebene der Kommunen in der Regel die für den Katastrophenschutz zuständigen Behörden.</p>

<p>Ausführliche Informationen zum bundesweiten Warntag stehen auf der Website <a href="https://warnung-der-bevoelkerung.de/" target="_blank" rel="noopener noreferrer" title="Externer Link&nbsp;Externer Link (Öffnet&nbsp;neues&nbsp;Fenster)">www.bundesweiter-warntag.de</a> zur Verfügung.</p>
<p><a href="https://www.bbk.bund.de/DE/AufgabenundAusstattung/Krisenmanagement/WarnungderBevoelkerung/Bundesweiter_Warntag/Bundesweiter_Warntag_node.html;jsessionid=1B1F2014E22A97E4C5B9AA0C235E6168.1_cid345#Start" title="Zum Seitenanfang">nach oben</a></p></div>
    </div></div>]]>
            </description>
            <link>https://www.bbk.bund.de/DE/AufgabenundAusstattung/Krisenmanagement/WarnungderBevoelkerung/Bundesweiter_Warntag/Bundesweiter_Warntag_node.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24430275</guid>
            <pubDate>Thu, 10 Sep 2020 08:59:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Should You Start Using TypeScript?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24430236">thread link</a>) | @ulam_labs
<br/>
September 10, 2020 | https://www.ulam.io/blog/why-use-typescript/ | <a href="https://web.archive.org/web/*/https://www.ulam.io/blog/why-use-typescript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Javascript started as a small scripting language that added some interactivity to web pages. Now it has grown into one of the biggest and most popular programming languages, used for a variety of things: backend, frontend, machine learning, and much more. But JavaScript wasn't created for enterprise-level applications. As your project grows in size and complexity it becomes hard to manage. Luckily Typescript is here to help, designed to support developers via a collection of tools that boost productivity.</p>
<h2>What is TypeScript?</h2>
<p>TypeScript is a <strong>superset</strong> of JavaScript programming language. It gives us the option to use static typing, and it compiles to pure JavaScript. Javascript is dynamically typed and variable type is set at the execution of code. TypeScript, on the other hand, is a static type checker that detects errors in code before execution. Also, TypeScript never changes the behavior of your program - when it successfully compiles your code it removes all the information about types, and runs the same as plain JavaScript. In the <strong>Stackoverflow Survey 2020</strong> TypeScript ranked second in the list of most loved programming languages, one position higher than its 2019 ranking.</p>
<h2>What are the benefits of TypeScript?</h2>
<h3>Optional static typing</h3>
<p>This is the main feature we use TypeScript for. Static typing means that once you declare variable type, it doesn't change. It can take only certain values. If an error occurs, the compiler warns you so you don’t make a mistake.</p>
<h3>More readable and self-documenting code</h3>
<p>Adding types makes your code more self-explanatory, which is helpful for large teams and can make up for a lack of communication. This also makes it easier for junior developers to see the intention behind other people's code.</p>
<h3>Spotting bugs earlier</h3>
<p>Developers can spot a lot of common bugs during the compiling phase, saving time on searching for them later. Some companies even report a reduction of bugs after they switch to TS!</p>
<h3>It makes refactoring faster</h3>
<p>When it comes to refactoring, TypeScript is enormously helpful in keeping the code consistent, thus avoiding changing the behavior of the code. It automatically finds mistakes and alerts us about the issue, which simplifies the refactoring process.</p>
<h3>It makes code easier to merge</h3>
<p>After introducing TypeScript to your project, it’s easier to trust new code from other developers. This makes <strong><a href="https://www.ulam.io/blog/how-to-do-code-review/">code reviews</a></strong> and the whole process of merging faster.</p>
<h2>What are the cons of TypeScript?</h2>
<h3>Takes some effort to set up</h3>
<p>When starting a new app you have to set up your bundler and test runner to work with TypeScript. Also, when adding new libraries you need to install typedefs for them. But this is well worth the effort for the excellent options it provides.</p>
<h3>More code to write</h3>
<p>If you want to use the full potential of TypeScript, you will need to write more code. This could be interpreted as slowing down the development process.</p>
<h3>The extra step of transpiling</h3>
<p>You need to transpile your TypeScript code to JavaScript because browsers can't interpret TypeScript code. This additional step doesn't require much additional time and can be achieved simply using Babel.</p>
<h3>You have to spend some time learning it</h3>
<p>To start coding with TypeScript, first you have to spend some time getting to know it. Not only the semantics but also good practices like how to use it to structure a project correctly.</p>
</div><div><h2>When should you use TypeScript?</h2>
<p>One of the obvious answers to this question is - <strong>when you have a large codebase</strong>. When dealing with a big codebase it's easy to get yourself lost in the code. With really advanced IDE support for TypeScript, you can avoid that. IDE support makes it easier for new and more experienced developers to navigate a large project, speeding up the developing process with features like autocompletion and snippets.</p>
<p>Another case when TypeScript comes in handy is <strong>when you are dealing with a large team of developers</strong>. It saves a massive amount of time that people would otherwise spend understanding the code. In combination with frameworks like Angular and Vue, it makes the codebase consistent and minimizes the risk of someone misusing your code.</p>
<p>While static type checkers shouldn't replace unit tests, sometimes you have tight deadlines and don't have time to write them. Compile-time checking delivers more confidence in situations like this. But remember - TypeScript <strong>should</strong> <strong>never</strong> be a substitute for tests.</p>
<p>Last but not least, TypeScript can be very helpful when you are working with <strong>an</strong> <strong>external API</strong>. You can use it to define the interfaces of objects that are returned from the API, making it more clear for everyone, and when the JSON response changes it’s easy to find out what’s gone wrong.</p>
<h2>And when you should think twice?</h2>
<p><strong>When you are working on your small, pet project</strong> TS may be overkill. When working alone on a small project, TypeScript probably wouldn't benefit you much. You are probably familiar with codebase already, and the boost of productivity TS brings would be marginal. On the other hand, a pet project is a good place to play with TypeScript if you are not experienced in it, because you don’t have to worry about deadlines.</p>
<p>TypeScript can boost productivity. But if your team is experienced, already following test-driven development, switching to TypeScript in a short term may not be beneficial enough to spend time on configuring it, or introducing it to your developers. Having said that, in the long term the pros of TS speak for themselves.</p>
<h2>Should you migrate to TypeScript?</h2>
<p>If we are talking about changing your habits and starting to use TypeScript in your new projects, the answer is almost always ‘yes’. As far as projects that are already in progress go, it depends.</p>
<p>One of the situations where you don’t need TypeScript from the start is when you’re writing an app or website that doesn't operate on data, for example a company landing page. Using TS in this context would be pretty useless. Another case might be when the framework you want to use doesn't support it.</p>
<p>What about switching during an in-progress project? If you constantly come across problems with refactoring, keep getting lost, or current tools can't help you, you probably should consider a migration. Of course, you don't have to rewrite the whole project. You can do it file by file, starting with the essentials. This won’t hurt you too much time-wise.</p>
<p>To sum things up, TypeScript is here. It probably isn’t going anywhere. Given time it may become standard to use TS while <strong><a href="https://www.ulam.io/software-services/javascript-development/">building JavaScript applications</a></strong>. There are alternatives like Flow, created by Facebook, but they only have small communities. TS is getting bigger and bigger, as we see when comparing the number of NPM installs per month. Now is probably the best time to learn it and put yourself ahead of the crowd, ahead of current trends. Learning TypeScript will teach you exactly how to make your coding easier and more efficient.</p>
<p> 
  <a href="https://www.ulam.io/contact/">Contact us</a>
</p>
<h3>Related blogposts:</h3>
<p><a href="https://www.ulam.io/blog/web-accessibility/">A11y: Web accessibility definition and guidelines</a></p>
<p><a href="https://www.ulam.io/blog/test-automation-gains-and-limitations/">Test automation gains and limitations</a></p>
<p><a href="https://www.ulam.io/blog/graphql-from-django-developer-perspective/">GraphQL from Django developer perspective</a></p></div></div></div>]]>
            </description>
            <link>https://www.ulam.io/blog/why-use-typescript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24430236</guid>
            <pubDate>Thu, 10 Sep 2020 08:52:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Scanned Objects by GoogleResearch]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24430161">thread link</a>) | @rbanffy
<br/>
September 10, 2020 | https://app.ignitionrobotics.org/GoogleResearch/fuel/collections/Google%20Scanned%20Objects | <a href="https://web.archive.org/web/*/https://app.ignitionrobotics.org/GoogleResearch/fuel/collections/Google%20Scanned%20Objects">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://app.ignitionrobotics.org/GoogleResearch/fuel/collections/Google%20Scanned%20Objects</link>
            <guid isPermaLink="false">hacker-news-small-sites-24430161</guid>
            <pubDate>Thu, 10 Sep 2020 08:36:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Frequentism vs. bayesianism – The AI paradigm war]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24430142">thread link</a>) | @danroseai
<br/>
September 10, 2020 | https://www.danrose.ai/blog/jx6opb61kehib7w5m8iwp3bt50fw3m | <a href="https://web.archive.org/web/*/https://www.danrose.ai/blog/jx6opb61kehib7w5m8iwp3bt50fw3m">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" id="item-5f155d9c1dfb8122b866ab0c"><div><div><div data-block-type="2" id="block-5bf0535ff4549250ad7b"><div><p>Frequentism and bayesianism is two paradigms or schools of statistics. I’m by no means an expert in statistics and you don’t have to be either to read this post. Actually pretty simple to understand without prior knowledge about statistics.&nbsp;</p><p>So why read this blog post about two statistical paradigms you ask? Because it’ll make you understand AI at a whole different level than before. I promise.</p><p>There are some extremely useful learnings from understanding this paradigm war. It will make you understand the gray areas of AI. By this I mean the reason why a lot of AI often does not have hard conclusions. To boil it down to it’s essence, the two paradigms offer completely different ways of predicting and understanding the world with often completely different results but still being equally correct. That’s it. In statistics that very often the foundation of AI models different results can be equally correct. How can that be possible? Let’s dig deeper with an example.</p><p>I’m stealing this great example from the book The Signal and Noise by Nate Silver. A book that will definitely make you think differently about the world. I really recommend it.&nbsp;</p><p>The example is simple. You come home one day early and you find underwear in your bedroom that is definitely not yours. How do you explain this? Did your partner cheat on you or is there another explanation? The frequentist will only look at the observed evidence, the underwear. Suggesting a very high probability of adultery. The bayesian would take into account the prior beliefs. This could be the overall adultery rates and your trust with your partner. With high trust you might dismiss the evidence.&nbsp;</p><p>Both paradigms provide equally true ways to view the world but come with pros and cons. In this underwear example I at least don’t see a right or wrong way to approach the problem. But I see that there might be very different outcomes depending on what school you prefer in this scenario.</p><p>Now let’s learn a bit about each paradigm.</p><h2>The Frequentists paradigm</h2><p>The core of frequentism is that only observed data is taken into account when calculating the probability of the occurrence of an event. So what does that mean? It means that when calculating the probability of an event you take a sample of the domain you are trying to measure and observe the frequency of events. Say you want to measure the probability of landing tails when flipping a coin. The maths look like this:</p><p>P(A) = n/N</p><p>The probability of A is the number of times an event happened(landing tails) divided by the number of possible events(The number of coin flips). The frequentist reservation is that they can assume that the world is random and the results they predict are looked upon in the long term. It’s also crucial that what we do can be replicated. In the coin toss problem we will see 50% tails over the long term and this makes a lot of sense.&nbsp;</p><h2>The Bayesianists paradigm</h2><p>Bayesianism offers a way to take into account our prior beliefs when calculating a probability. In other words, we are not only looking at the observed data but including our own biases. So the bayesian statistician would start with a prior belief, observe data, add the data to the prior and end with a posterior belief. The posterior is the new probability. Bayenists divide the problem of probability into two cases. The probability of the evidence given an event is happening and the probability of evidence given the event is not happening. The maths looks like this:</p><p>P = xy * (xy + z(1-x))</p><p>x = you prior probability of event</p><p>y = conditional probability of evidence given event <em>did</em> occur</p><p>z = conditional probability of evidence given event <em>did not</em> occur</p><p>&nbsp;It might look a little confusing but the explanation is simple. Say you get a fever and you want to know the probability of you now having Covid-19. Let’s try it out. I’m going to be loose with the numbers here but the idea is the same. In Denmark, where I’m located, the Covid-19 virus is not very present. Only about 1.200 out of 5.8 million people are currently affected. That’s 0.02% and that’s our x. Due to social distancing other viral diseases and as a result fever is very rare too. So I’m going to put the probability of having a fever without being affected by Covid-19 low. Let’s say 20%. That’s our “z”. If you have Covid-19 then fever is very likely. It’s a common symptom. Let’s say 80%. That’s our “y”. So the math is now like this:</p><p>P = 0.0002 * 0.8 / ( 0.0002 * 0.8 + 0.2(1-0.0002)) =0.08%</p><p>So what just happened? Before you had a fever your chance of having Covid-19 you had a 0.02%. But after this new piece of evidence(the fever) your chance was still low but had risen to 0.08%. Interesting right?</p><p>If you want to know more about Bayes and conditional probability the wikipedia article is really good: <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem"><span>Bayes Theorem</span></a>.</p><h2>So what approach should you take?</h2><p>Bayesian statistics takes into account your prior beliefs or in other words, <em>your biases</em>. If you think it would not objectively harm then you might go for a bayesian method. If you have an easily repeatable low bias situation then you might like to go for a more frequentist approach. This is of course put on the edge. It’s never just that simple.</p><p>One thing I would add is when I hear people saying stuff like “I’m really data driven in my decision making” or even worse “I only act on data never on” I hear a sign of danger. Believing that data should be blindly trusted is a naive world view. The fundamental error in that is that you never know what data you haven’t seen and if the data is biased. One good example is the housing market crash in 2007. The logic was that the housing market had never crashed and by frequentist reasoning it could not crash. The result was that the market was pushed to extremes that it hadn’t been in before.&nbsp;</p><h2>How does this relate to AI?</h2><p>So to make the connection here to AI a lot of AI is based on statistical methods. Several approaches can be taken to make AI understand the world and they may be very different. There’s no given correct way. You just have to be wary of whatever results you see since the underlying mechanics is just not so black and white. Preparing for being wrong is my best advice.</p><p>I would like to end the post with a personal pet peeve. The media today seem to have a clear tendency to prefer frequentism regardless of the matter and rarely offers the alternative view. To make it even worse, journalists will often require politicians to be totally sure that their politics are going to have the desired effects when it’s not possible to be sure. That discourages testing new politics on a small scale before going all in. If a bit more bayesianism could be applied in journalism giant political failures could be avoided. </p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.danrose.ai/blog/jx6opb61kehib7w5m8iwp3bt50fw3m</link>
            <guid isPermaLink="false">hacker-news-small-sites-24430142</guid>
            <pubDate>Thu, 10 Sep 2020 08:32:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Primer to the Indian Stock Market]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24429976">thread link</a>) | @JayeshSidhwani
<br/>
September 10, 2020 | https://blog.jupiter.money/2020/09/a-retail-investors-tryst-with-the-markets-part-1/ | <a href="https://web.archive.org/web/*/https://blog.jupiter.money/2020/09/a-retail-investors-tryst-with-the-markets-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			
<p>Back in 1850, a group of five stockbrokers used to conduct brokerage meetings under a banyan tree in front of Mumbai’s town hall. This small group moved to Dalal Street in 1874 (Dalal means broker in many regional languages), giving birth to the iconic Bombay Stock Exchange.&nbsp;</p>



<p>While the concept of investing has been around since the 1800s, the stock market remained unfamiliar territory to most people in India, until some liberalization reforms, digitization, and stock market frauds were thrown into the mix.&nbsp;</p>



<p>As people marvel over the unexpected market rally in the midst of a pandemic, we thought it’s worth taking a look at how the retail investor has traversed the turbulent path of risk and reward. This story is almost as intriguing as the one in Gangs of Wasseypur (and just like the movie, it has two parts).</p>







<p>Reeling from the hangover of the colonial era, trade, and commerce in the 1950s and 60s was mostly controlled by state-owned institutions. This setup was a way for the government to mobilize funds through banks. However, it also aimed at reducing monopoly and providing fair credit access to people.</p>



<p>This bid to control citizens’ economic lives meant that for most people ‘saving’ was synonymous with instruments such as bank FDs. Bank facilities were thinly spread and other avenues of wealth-creation such as the stock market was mostly a closed-door one that involved steep fees and waiting for weeks until the paperwork arrived.&nbsp;</p>



<p>It wasn’t until 1963 that the idea of ‘Mutual funds’ was introduced to the public. The RBI set up the Unit Trust of India (UTI), an incentive to get people interested in retail investment. But most people still stuck to their first love- Fixed Deposits (This wouldn’t change for a few decades, but we’ll get to that in a bit).&nbsp;</p>



<h2 id="the-age-of-the-equity-emperor"><strong>The age of the equity emperor</strong></h2>



<p>Before we hit the late 70s, India had started to grapple with a new challenge: the unforeseen effects of the License Raj. The bureaucratic nature of this system stifled fundraising, hampering private businesses, and restricting innovation. This led to the country evidencing a ‘Hindu rate of growth’, the low growth rate which was in sharp contrast to our Asian counterparts with similar incomes.&nbsp;</p>



<p>Now during the license raj, there was one man who was still establishing huge industries- Dhirubhai Ambani aka the ‘Equity emperor’. And here’s what he wanted to do: he wanted to convince the common man to invest in his dreams. To lure him away from just saving to investing he turned to convertible debentures issues. A convertible debenture (CD) is a kind of long-term loan which can be transformed into a company’s stock after a specific period of time.&nbsp;</p>



<p>CDs were a win-win from the word go. They allowed industrialists to raise capital for their ambitions directly from retail investors, bypassing banks that insisted on securing loans through project assets and promoter guarantees. At the same time, they provided retail investors a higher rate of interest than bank fixed deposits, while also giving holders potential kicker in the form of additional returns through appreciation on the conversion of debentures into equity.&nbsp;</p>



<p>Those who invested in the Reliance Industries Ltd CDs became millionaires as they stayed invested, fuelling the appetite and aspirations of others. A small portion of the population finally started getting a taste of what wealth creation beyond bank FDs looked like.&nbsp;</p>



<h2 id="rising-from-the-ashes"><strong>Rising from the ashes</strong></h2>



<p>By the summer of 1991, India was a high-cost economy at the brink of collapse. Millions watched in anticipation as a seemingly timid man was to make a televised announcement to the people; Manmohan Singh began this address with a fitting Urdu composition that read ‘the desire for revolution is in our hearts’. This was the introduction of liberalization reforms.&nbsp;</p>



<p>The intent of these reforms was clear: the government was keen to dismantle socialistic doctrines in the pursuit of a free-market economy. It encouraged the industry to raise capital from the open market and the government would go from being a controller to a regulator. The markets reacted well, and the reforms evoked a decade of renewed growth and expansion.</p>



<p>However, the birth of this new economic charter began with a rather dubious transition- the Harshad Mehta securities scam. You must have heard of this story as some sort of lore when people talk about the history of stock markets in India. For the uninitiated, Harshad Mehta became a subject of infamy after he led a diversion of bank funds worth Rs 3,500 crore to the stock market by exploiting the paperwork-heavy processes to his advantage.</p>



<p>It was the fraudulent and analog nature of this scam that served as a wake-up call to restructure the entire stock market system. The National Stock Exchange of India (NSE) (1992), which provided a fully automated screen-based electronic trading system was one of the outcomes of the government’s initiatives to curtail bureaucracy. This accelerated digitization at the BSE in 1995 and laid the foundation for wider participation of people in the markets. The government also issued licenses for private sector Mutual Funds which gave investors more options.</p>



<h2 id="the-golden-era-of-growth"><strong>The golden era of growth</strong></h2>



<p>Meanwhile, somewhere in a remote corner of Bengaluru, a freshly minted graduate was fielding phone calls for twelve hours a day, while his superiors made him practice his American accent while watching the TV show ‘Friends’. Thus began the birth of a new industry- Business Process Outsourcing. BPOs were the holy grail for the young workforce, an avenue for 18-year-olds to make and manage their own money.&nbsp;</p>



<p>In the 2000s,&nbsp; investing was starting to become alluring to the common man for a few reasons:</p>



<ul><li>Creation of more jobs in service sectors like ITeS and BPOs.</li></ul>



<ul><li>Drop in inflation and interest rates, coupled with more availability of loans.</li></ul>



<ul><li>Lower barriers to investment because of improved accessibility to the stock markets.</li></ul>



<ul><li>Akshay Kumar’s character in Hera Pheri claiming he became ‘25 din mein crorepati’</li></ul>



<p>Alright jokes apart, the 2000s was heralded as the golden era of growth- with India averaging a remarkable ~7% annual growth in GDP between 2000-2007. Internationally, this was the period when consumerism reached its peak with consumers getting easy access to money via NINJA (No income no job no asset) loans. These excesses eventually led to the global financial crisis and a total meltdown in 2008.</p>



<p>India withstood the 2008 recession better than most countries. Despite the ripple effect of the event that was felt in every part of the world, our regulated market and RBI’s conservative approach ensured that we stayed relatively insulated. It was also the thrifty and risk-averse nature of most Indians that shielded them from a dire financial crisis.&nbsp;</p>



<h2 id="gen-x-a-force-to-be-reckoned-with"><strong>Gen X- A force to be reckoned with&nbsp;</strong></h2>



<p>In 2015, the penetration of smartphones into tier 2 and tier 3 cities, coupled with Jio’s affordable data plans allowed people from small towns developed a new world-view. The introduction of <strong><em>Digital India</em></strong> and JanDhan-Aadhar-Mobile (J-A-M) accelerated the opening of bank accounts with KYC, and banking started to become ‘digital’ in the true sense of the word.&nbsp;</p>



<p>Also get this: The average age of the population was 25 years old. This meant that there was an immense number of young people in the workforce who were seeking new ways to grow their money. With inflation under control, the bank interest rates started their southward journey. So the people started looking for investments other than bank FDs.&nbsp;</p>



<p>Enter ‘SIP’s. The Systematic Investment Plan (SIP) was the shiny new toy for the middle-class Indian. With monthly payments as low as 500 rupees, SIPs not only allowed people the opportunity to ‘invest’, but also assuaged their biggest fears about the jargon-heavy risk-laden world of ‘stocks’. One no longer needed to learn the difference between scalping and swing trading, if they wanted to be a retail investor.&nbsp;</p>



<p>Towards the end of the decade, the average Indian investor had overcome his shyness about investing beyond FDs, and I’d have to conjecture that all was kosher. But hold your horses. As history has taught us ‘What’s past is prologue’. This story only gets super riveting as we realize that this new-age investor had a lot more than just his returns to worry about. More on this in part 2 of this series.&nbsp;</p>


		</div></div>]]>
            </description>
            <link>https://blog.jupiter.money/2020/09/a-retail-investors-tryst-with-the-markets-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24429976</guid>
            <pubDate>Thu, 10 Sep 2020 08:00:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The path to net zero – Climate Assembly UK full report]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24429895">thread link</a>) | @wcerfgba
<br/>
September 10, 2020 | https://www.climateassembly.uk/report/ | <a href="https://web.archive.org/web/*/https://www.climateassembly.uk/report/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Climate Assembly UK’s report, <i>The Path to Net Zero</i>, shows how a representative sample of the population believe the UK should meet its<a href="https://www.climateassembly.uk/about/path-net-zero/"> net zero emissions</a> commitment with detailed recommendations across ten areas including: how we travel; what we eat and how we use the land; what we buy; heat and energy use in the home; how we generate our electricity; and greenhouse gas removals.</p><h3>A guide to the report</h3><div><p>The report begins with <b>forewords</b> from the commissioning select committee Chairs and the assembly’s Expert Leads that place the assembly and its report in context.</p><p> These forewords are followed by an <b>opening statement from the assembly members</b> that highlights the key themes emerging from their recommendations.</p><p> The <b>Executive Summary</b> provides an overview of the key considerations and conditions agreed by Assembly members as well as the balance of support for each recommendation.</p><p> Chapter 1 then provides <b>detail of the assembly's process and membership</b>.</p><p> Chapters 2 - 11 outline in depth the assembly’s <b>recommendations and the rationale behind them</b>.</p></div><hr><h3>Chapters and recommendations</h3><p><a href="https://www.climateassembly.uk/documents/83/Chapter_1.pdf"><b>Chapter 1</b></a> provides detail of the assembly's process and membership.</p><p>Chapters 2 -11 of the report details assembly members’ views on the advantages and disadvantages - including the trade-offs and co-benefits - of different ways of reaching net zero, and the results of the votes by secret ballot that followed.</p><p>A snapshot of the Assembly's recommendations and links to each individual chapter are below:</p><ul><li>Assembly members began the process by agreeing a <b>set of principles</b> they believe should underpin the path to net zero. They agreed 25 underpinning principles. <a href="https://www.climateassembly.uk/documents/84/Chapter_2.pdf"><b>Read chapter 2.</b></a></li><li>On <b>surface transport</b>, the Assembly aims to minimise restrictions on travel recommending an early shift to electric vehicles and improvement of public transport to make it cheaper, reliable and more accessible. They also backed more local services, amenities and transport links. <a href="https://www.climateassembly.uk/documents/85/Chapter_3.pdf"><b>Read chapter 3.</b></a></li><li>For <b>air travel,</b> the Assembly aims to balance protection of travel and lifestyles with a limit to how much air passenger numbers can grow. Its recommendations include taxes that increase as people fly more often and as they fly further, as well as investment in new, cleaner technologies. <a href="https://www.climateassembly.uk/documents/86/Chapter_4.pdf"><b>Read chapter 4.</b></a></li><li>On <b>heat and energy use in the home</b>, the assembly looked at areas including retrofits and zero carbon heating. Its recommendations include solutions tailored to local areas and households, greater choice for householders including through steps to increase competition, and reliable and clear information for the public. <a href="https://www.climateassembly.uk/documents/87/Chapter_5.pdf"><b>Read chapter 5.</b></a></li><li>On the topic of <b>what we eat and how we use the land</b>, the Assembly stressed the importance of support for farmers during the net zero transition and recommended greater reliance on local produce and local food production, a voluntary change in diet to reduce meat and dairy consumption supported by education and incentives and a “managed diversity” of land use. <a href="https://www.climateassembly.uk/documents/88/Chapter_6.pdf"><b>Read chapter 6.</b></a></li><li>When considering <b>what we buy</b>, Assembly members strongly supported a future in which businesses make products using less energy and materials, and low(er) carbon energy and materials, as well as the idea of individuals repairing and sharing more. They also backed better information to promote information choice, including product labelling and steps to increase recycling. <a href="https://www.climateassembly.uk/documents/89/Chapter_7.pdf"><b>Read chapter 7.</b></a></li><li>Large majorities of assembly members agreed that three ways of <b>generating electricity</b> should be key part of how the UK gets to net zero: offshore wind, onshore wind and solar power. <a href="https://www.climateassembly.uk/documents/90/Chapter_8.pdf"><b>Read chapter 8.</b></a></li><li>Large majorities of assembly members backed three ways of <b>removing greenhouse gases from the atmosphere</b>: forests and forest management; restoring and managing peatlands and wetlands; and using wood in construction. <a href="https://www.climateassembly.uk/documents/91/Chapter_9.pdf"><b>Read chapter 9.</b></a></li><li>Assembly members also made <b>further recommendations they wanted to make to Parliament and government.</b> They worked together to draft suggested additions, which could be on any aspect of the path to net zero. <a href="https://www.climateassembly.uk/documents/92/Chapter_10.pdf"><b>Read chapter 10.</b></a></li><li>The report also includes the assembly’s recommendations on <b>Covid-19, recovery and the path to net zero</b>, the key elements of which were originally <a href="https://www.climateassembly.uk/news/interim-briefing-post-lockdown-steps-aid-economic-recovery-should-drive-progress-net-zero-target/">published in June</a> to help inform the Government's response to the Covid-19 crisis. <a href="https://www.climateassembly.uk/documents/93/Chapter_11.pdf"><b>Read chapter 11.</b></a></li></ul><p>In total, the report contains over 50 recommendations for policy measures designed to meet the net zero target by 2050.</p><hr><h3>Recurring themes</h3><p>The report also conveys Assembly members’ agreement on <b>themes that recurred throughout their discussions</b>, on the need for:</p><ul><li>improved information and education for all on climate change;</li><li>fairness, including across sectors, geographies, incomes and health;</li><li>freedom and choice for individuals and local areas;</li><li>and strong leadership from government.</li></ul><p>It also stresses the assembly’s support for <b>protecting and restoring nature</b>, and the <b>value of ‘co-benefits’</b> to tackling climate change, such as improved health, advantages for local communities, high streets and the economy, including by the promotion of innovation in technology. It calls on policy makers to make use of the report as an “<i>invaluable resource</i>” for decision making.</p><h4><a href="https://www.climateassembly.uk/news/uk-path-net-zero-must-be-underpinned-education-choice-fairness-and-political-consensus-urges-climate-assembly/">Read the news story about the report here.</a></h4></div></div>]]>
            </description>
            <link>https://www.climateassembly.uk/report/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24429895</guid>
            <pubDate>Thu, 10 Sep 2020 07:47:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fastlane – making the deployment process more seamless, simple, and fast]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24429658">thread link</a>) | @hikeapp
<br/>
September 10, 2020 | https://blog.hike.in/we-drive-in-fastlane-hike-223cd6fa2a42 | <a href="https://web.archive.org/web/*/https://blog.hike.in/we-drive-in-fastlane-hike-223cd6fa2a42">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><p id="c6df">During our brainstorming on how to make our deployment process more seamless, simple, and faster we came across <a href="https://fastlane.tools/" target="_blank" rel="noopener">Fastlane</a>, which is an easy way to build, test, and deploy apps for Mobile Platform.</p><h2 id="1634"><strong>🙌 Easy and customizable Setup</strong></h2><p id="8def">Setting up Fastlane was a breeze, just install Fastlane gem and initialize Fastlane in your iOS project and you are set. You can find the detailed instructions <a href="https://docs.fastlane.tools/getting-started/ios/setup/" target="_blank" rel="noopener">here</a>.</p><h2 id="19cc"><strong>📃 Manage Certificates</strong></h2><p id="47cb">Anyone who has worked on iOS knows, managing certificates on iOS is a tedious job. No more! We simply use “<a href="https://docs.fastlane.tools/actions/match/" target="_blank" rel="noopener">match</a>” to ensure that we share one code signing identity across the development team to simplify our code signing setup and prevent code signing issues.</p><h2 id="817e"><strong>🔧 Manage Build Configurations</strong></h2><p id="d382">At Hike, we have multiple application configurations, such as “Debug (development-oriented), Alpha (for internal users), Release (production rollout)”. Through Fastlane, we have added a simple switch mechanism that helps us trigger the build flavor of our choice. We no longer need to manually switch flags, change schemes and configurations. This simply eliminates human error.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3200/0*bjkWs3J41MYoSAJ7" width="1600" height="299" srcset="https://miro.medium.com/max/552/0*bjkWs3J41MYoSAJ7 276w, https://miro.medium.com/max/1104/0*bjkWs3J41MYoSAJ7 552w, https://miro.medium.com/max/1280/0*bjkWs3J41MYoSAJ7 640w, https://miro.medium.com/max/1400/0*bjkWs3J41MYoSAJ7 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*bjkWs3J41MYoSAJ7?q=20"></p></div></div></div></figure><h2 id="f0c6"><strong>🧪 Build Enterprise builds for Testing</strong> <strong>with Lanes</strong></h2><p id="3eab">We have made life easier for testers in the organization by utilizing <a href="https://developer.apple.com/programs/enterprise/" target="_blank" rel="noopener">Apple’s enterprise program</a>. Since, this includes a separate bundle identifier, switching this manually to distribute builds in-house became a challenge. To avoid all this, we used the “<a href="https://docs.fastlane.tools/advanced/lanes/#lanes" target="_blank" rel="noopener">lane</a>” concept in Fastlane, where we write up all our configs in the <a href="https://docs.fastlane.tools/advanced/Appfile/#appfile" target="_blank" rel="noopener">AppFile</a> and now switching to enterprise build is now, one command away!!</p><h2 id="5b7c"><strong>🎉 Single push to Test Flight</strong></h2><p id="297d">Deploying a build on Test Flight needed Application Launcher, Sign Up, Uploading, etc. All this is now configured via Fastlane and is done in a single push. Further, we have configured notifications to <a href="https://slack.com/intl/en-in/" target="_blank" rel="noopener">Slack</a> where the appropriate teams get a ping that Alpha/Beta is now available on Test Flight.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3200/0*5EbdLRUyEVnyfEDe" width="1600" height="370" srcset="https://miro.medium.com/max/552/0*5EbdLRUyEVnyfEDe 276w, https://miro.medium.com/max/1104/0*5EbdLRUyEVnyfEDe 552w, https://miro.medium.com/max/1280/0*5EbdLRUyEVnyfEDe 640w, https://miro.medium.com/max/1400/0*5EbdLRUyEVnyfEDe 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*5EbdLRUyEVnyfEDe?q=20"></p></div></div></div></figure><h2 id="ac92"><strong>📈 Version Increment</strong></h2><p id="d1b2">Though this looks like a small change, the impact is high. Versioning of Hike Sticker Chat is done in a semantic fashion and we have no margin for error hence, we have simply eliminated the human intervention. Fastlane helps us <a href="https://docs.fastlane.tools/actions/increment_version_number/#increment_version_number" target="_blank" rel="noopener">versioning</a> the app by adding correct incremental values to each build based on our business logic. Here is what our versioning looks like — majorversion.minorversion.patch.timestamp — 6.2.21 (201905041233)</p><h2 id="0f52"><strong>🕐 Save Time</strong></h2><p id="ff71">Time is money! Cliche but true. In Hike, we have multiple feature development going on in parallel across various cross-functioning teams. Thus, we require teams to deploy Alpha or Betas in a fast-paced manner. Fastlane can save up to <strong>30 minutes per deploy</strong>. YES!! It’s true! If you do not believe us, take a look at the screenshot below.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1394/0*cxkODYXq4JHeR2ig" width="697" height="805" srcset="https://miro.medium.com/max/552/0*cxkODYXq4JHeR2ig 276w, https://miro.medium.com/max/1104/0*cxkODYXq4JHeR2ig 552w, https://miro.medium.com/max/1280/0*cxkODYXq4JHeR2ig 640w, https://miro.medium.com/max/1394/0*cxkODYXq4JHeR2ig 697w" sizes="697px" data-old-src="https://miro.medium.com/max/52/0*cxkODYXq4JHeR2ig?q=20"></p></div></div></figure></div></div></section></div>]]>
            </description>
            <link>https://blog.hike.in/we-drive-in-fastlane-hike-223cd6fa2a42</link>
            <guid isPermaLink="false">hacker-news-small-sites-24429658</guid>
            <pubDate>Thu, 10 Sep 2020 07:00:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Weakness of Anthropic Arguments]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 80 (<a href="https://news.ycombinator.com/item?id=24429625">thread link</a>) | @srl
<br/>
September 9, 2020 | https://ineffectivetheory.com/weakness-anthropic-arguments/ | <a href="https://web.archive.org/web/*/https://ineffectivetheory.com/weakness-anthropic-arguments/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><time datetime="2020-09-10">10 Sep 2020</time></header><p>Physicists are often bothered by the question “why do fundamental physical constants have the values they do?” Sometimes this concern can be answered by “well it had to take <em>some</em> value”, <a href="https://en.wikipedia.org/wiki/Fine-tuning">but not always</a>. Seeking explanations for patterns in what appear to be fundamental constants is a <a href="https://en.wikipedia.org/wiki/Periodic_table">historically</a> <a href="https://en.wikipedia.org/wiki/Eightfold_way_(physics)">successful</a> way to probe for the next undiscovered piece of physics.</p><p>The anthropic principle attempts to answer that sort of question. Crudely, an anthropic argument is one taking the form:</p><blockquote><p>The universe is the way it is because if it weren’t, we wouldn’t be here to discuss the issue.</p></blockquote><p>It shouldn’t surprise you to learn that most physicists are, at the very least, a little uncomfortable with this form of argument. The best pro-anthropic-argument summary I know of is frequently given by Nima Arkani-Hamed. Unfortunately I cannot find a video, so my own thoroughly inferior retelling will have to do:</p><blockquote><p>Suppose you walk into a room and see a table. On the table is a pencil, balanced perfectly on its tip. This is unlikely, to say the least. It needs explanation. The first thing to do is look for a string holding it up, or some glue on the tip, or the like. You check, and there’s no such mechanism. The next thing to do is look around — are there thousands of other pencils, lying normally on the table and the floor? If so, then the balancing pencil may reasonably be called coincidence. Alas, there are none.</p></blockquote><blockquote><p>There’s one last thing to do, to explain the magic pencil: look under the table. Is there a bomb, rigged to explode the moment the pencil falls over? Step outside: do you see the remains of thousands of detonated houses? If so, then it may be correct to say “the pencil was standing because, were it any other way, we would not have been in that room”.</p></blockquote><p>That last check is what an anthropic argument is all about. We can’t actually look for other rooms, destroyed by bombs (that would be called “the multiverse”), but we can at least try and look for the bomb.</p><p>The problem is, what qualifies as a bomb? The canonical example: if the cosmological constant were larger by a factor of say, $10^{100}$, the universe would have promptly blown itself apart. I wouldn’t be here to write this, you wouldn’t be here to read it. Surely we should not be surprised that the cosmological constant is not, in fact, so large.</p><p>Does that still make you uncomfortable? Perhaps it should. This type of argument is very slippery (like a slope). Thinking along the lines of the <a href="https://en.wikipedia.org/wiki/Butterfly_effect">butterfly effect</a>, it’s clear that even a one-part-in-$10^{10}$ change in the fine structure constant would build up dramatic differences in the evolution and course of life on Earth. In this universe, where $\alpha \approx 0.007297352569$, you’re reading an article about the anthropic principle; in the universe where $\alpha \approx 0.007297352570$, at the very least, it’s reasonable to guess that you would not be. (Good news: in that universe, you’re a billionaire playboy philanthropist!) Does this explain (to high precision) the value of the fine structure constant? After all, were the fine structure constant different by even $10^{-10}$, you would not be considering the question.</p><p>This has the basic structure of an anthropic argument, but there’s clearly something wrong with it. In that alternate universe, there are other people who <em>are</em> considering the question “why does $\alpha$ have that value?” The puzzle would still exist, even if you and I specifically have no interest.</p><p>Let’s consider, then, a universe where $\alpha$ is different by a full one part in a million. Chemical and nuclear physics don’t look substantially different, but again, the butterfly effect suggests that we should expect large differences in the situation on Earth. Suppose intelligent life exists on Earth, but not in anything remotely resembling human form. Now, it’s true that “there are no humans considering the question”. But again, there are <em>beings</em> on this planet considering the question. Shouldn’t that be enough?</p><p>Suppose $\alpha$ were different by one part in one hundred thousand. Now there’s no intelligent life on Earth at all — instead, intelligent life (tripedal, if you were wondering) evolves on Alpha Centauri! Questions of fine tuning are not considered anywhere in our solar system, but there are intelligent beings in the galaxy considering the question. It’s entirely accurate to say “were $\alpha$ different by one part in $10^5$, we would not be here to discuss these questions”, but <em>someone</em> would be <em>somewhere</em>, so that doesn’t seem like much of an explanation.</p><p>As far as I can tell, the best prototype for a good anthropic argument is:</p><blockquote><p>You have asked why proposition $P$ (which you find <em>a priori</em> surprising) should be true in our universe. You are able to ask this question in part because $P$ is true. Were $P$ false, you would not be able to ask such a question. In fact, were $P$ false, intelligent beings would not exist at all. Therefore, questions such as “why $P$” or “why not $P$” would never be expressed. Since questions like “what should be my prior probability of $P$” require $P$ to be true in order to be asked, the answer can only be “your prior should be near $1$”. Therefore $P$ is not, in fact, <em>a priori</em> surprising.</p></blockquote><p>The problem is, this anthropic principle is <em>extremely weak</em>. One proposed use of the anthropic principle is to <a href="https://doi.org/10.1111%2Fj.1749-6632.2001.tb02133.x">explain the fine structure constant</a>. Suppose the fine structure constant were in fact 10% different — enough to prevent stellar fusion from producing carbon. This would prevent carbon-based life from existing, sure; but would it prevent <em>intelligent</em> life from existing? Perhaps the question “why is $\alpha$ that particular value” could still be asked! It’s hard to know, without an unprecedentedly high-fidelity simulation of an alternate universe with $\alpha = 0.01$. That simulation isn’t coming soon.</p><p>The book <a href="https://en.wikipedia.org/wiki/Dragon%27s_Egg">Dragon’s Egg</a> is based around intelligent life living in the crust of a neutron star. The existence of such life certainly can’t be ruled out with our current understanding of the physics of dense matter. That’s a <em>very different</em> environment than our own; for starters, the strong surface gravity and magnetic field deform atoms by as much as a substantial change to the fine structure constant. If the anthropic principle can’t “explain why” we don’t live on the surface of a neutron star, then it certainly can’t account for a few percentage points in the fine structure constant.</p><p>This isn’t just yet another case of “we suck at creating efficient first-principles simulations”, either. One of the most famous stylized facts about <a href="https://mathworld.wolfram.com/CellularAutomaton.html">cellular automata</a> is that if you sneeze at them, they <a href="https://mathworld.wolfram.com/UniversalCellularAutomaton.html">become Turing-complete</a>. (This isn’t really a special fact about cellular automata, just a reflection of the fact that systems that support complex dynamics tend to also support universal computation.) A Turing-complete cellular automaton can simulate any classical process, and therefore displays phenomena like self-reproducing organisms. Moreover, a Turing-complete cellular automaton can support any intelligence exhibited by a computer. In principle (although of course this is too expensive to have been directly demonstrated) a cellular automaton like <a href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life">Conway’s</a>, beginning from a random position, ought to eventually evolve various levels of intelligence — intelligence is evolutionarily favorable in our world, and ought to be in others as well. So, shouldn’t such automata be capable of asking <em>the question</em>?</p><p>(In the case of Conway’s game, I guess <em>the question</em> is “why is the grid rectangular instead of hexagonal?")</p><p>The framework of modern fundamental physics is slightly more complicated than “it’s a cellular automaton” (this is <a href="https://writings.stephenwolfram.com/2020/04/finally-we-may-have-a-path-to-the-fundamental-theory-of-physics-and-its-beautiful/">only slightly controversial</a>), but the intuition gained from cellular automata is sticky: even large modifications to physical laws shouldn’t prevent intelligent structures from forming. This is the fundamental weakness of anthropic arguments. A properly formed anthropic argument should be based on an inability for intelligence to form, but intelligence is quite resilient. Almost any non-trivial universe can support intelligent life which will, inevitably, ask <em>the question</em>.</p><p>In a few cases, this issue may be circumvented: if the cosmological constant was too small/large, the universe would have collapsed/blown itself to smithereens before having a chance to develop anything resembling intelligence. This is largely independent of the other physical laws. That requirement is not strong enough to remove fine-tuning issues with the cosmological constant, and it certainly provides nothing resembling an explanation for the fine structure constant or any other part of the standard model.</p><p>I don’t think this weakness is repairable. Intelligent life is “existentially resilient”. The particular fundamental constants that describe the universe are unlikely to be the only ones that would allow someone to complain about fine-tuning and speculate about anthropic arguments.</p></article></div>]]>
            </description>
            <link>https://ineffectivetheory.com/weakness-anthropic-arguments/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24429625</guid>
            <pubDate>Thu, 10 Sep 2020 06:54:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Artificial Intelligence Technologies Trends]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24429526">thread link</a>) | @di_ra22
<br/>
September 9, 2020 | https://blog.digitalogy.co/artificial-intelligence-technologies/ | <a href="https://web.archive.org/web/*/https://blog.digitalogy.co/artificial-intelligence-technologies/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="https://schema.org/CreativeWork"><div itemprop="text"><p><img src="https://blog.digitalogy.co/wp-content/uploads/2020/04/10-Artificial-Intelligence-Technologies-Trends-that-Can-Take-Your-Business-to-New-Heights.png" alt="10 Artificial Intelligence Technologies Trends that Can Take Your Business to New Heights" width="1600" height="1267" srcset="https://blog.digitalogy.co/wp-content/uploads/2020/04/10-Artificial-Intelligence-Technologies-Trends-that-Can-Take-Your-Business-to-New-Heights.png 1600w, https://blog.digitalogy.co/wp-content/uploads/2020/04/10-Artificial-Intelligence-Technologies-Trends-that-Can-Take-Your-Business-to-New-Heights-300x238.png 300w, https://blog.digitalogy.co/wp-content/uploads/2020/04/10-Artificial-Intelligence-Technologies-Trends-that-Can-Take-Your-Business-to-New-Heights-1024x811.png 1024w, https://blog.digitalogy.co/wp-content/uploads/2020/04/10-Artificial-Intelligence-Technologies-Trends-that-Can-Take-Your-Business-to-New-Heights-768x608.png 768w, https://blog.digitalogy.co/wp-content/uploads/2020/04/10-Artificial-Intelligence-Technologies-Trends-that-Can-Take-Your-Business-to-New-Heights-1536x1216.png 1536w" sizes="(max-width: 1600px) 100vw, 1600px"></p>
<blockquote>
<p><strong>AI is everywhere</strong> and it is already impacting our lives. There’s no escaping from it as AI is inevitable. <strong>Take the internet, for example</strong>, it is always suggesting you things to do, videos to watch, even places to visit next.</p>
</blockquote>
<p>Unlike a couple of years ago, <a href="https://blog.digitalogy.co/artificial-intelligence-in-banking-opportunities-and-risks/" target="_blank" rel="noopener noreferrer">Artificial Intelligence</a> in today’s world is not just a buzzword anymore and has come a long way since.</p>
<p>It has turned into a full-blown domain that affects every sector of the industry with practical applications that can be seen everywhere.</p>
<p>Artificial Intelligence technologies, can now back several of your business processes, improving and optimizing them many-fold.</p>
<p>With crowds of organizations actively looking into the potential of AI and investing in them, their transformation into a smarter and more optimized version of themselves is inevitable.</p>
<blockquote><p>“The thing that’s going to make artificial intelligence so powerful is its ability to learn, and the way AI learns is to look at human culture .”<br>
<strong>— Dan Brown</strong></p></blockquote>
<h2><strong>Top 10 Artificial Intelligence Technologies</strong></h2>
<p>With dozens of applications available out there, we will be focussing on a certain few to showcase the latest technology in Artificial Intelligence.</p>
<p>The Artificial Intelligence technologies list below can <a href="https://blog.digitalogy.co/how-to-choose-the-best-digital-marketing-agency-for-your-business-growth/" target="_blank" rel="noopener noreferrer">take your business to new heights</a> and provide solutions to the most complex of your challenges without breaking a sweat –</p>
<h4><strong>1. Speech Recognition</strong></h4>
<blockquote>
<p>“The computer takes in the waveform of your speech. Then it breaks that up into words, which it does by looking at the micro pauses you take in between words as you talk.”</p>
<p><strong>– <a href="https://nymag.com/intelligencer/smarthome/make-me-smarter-voice-speech-recognition-alexa-siri-cortana-google.html" target="_blank" rel="noopener nofollow noreferrer" data-href="http://nymag.com/intelligencer/smarthome/make-me-smarter-voice-speech-recognition-alexa-siri-cortana-google.html">Meredith Broussard</a>, Data Journalist and Professor at NYU</strong></p>
</blockquote>
<p>Speech Recognition is one of the Artificial Intelligence technologies that all of us have used in the form of smart assistants on our phones by the likes of <strong>Google Assistant</strong>, <strong>Alexa</strong>, or <strong>Siri</strong>.</p>
<p>These intelligent speech recognition systems work by analyzing and storing your voice as input and when triggered, match your voice with the stored one.</p>
<p>These systems are responsible for driving <a href="https://uxdesign.cc/what-is-a-conversation-designer-and-why-will-the-role-grow-in-2020-a6d6210af28e?source=your_stories_page---------------------------">conversational systems</a> that work on speech data, often used to carry out a broad range of tasks from simpler ones to more complex ones.</p>
<h4><img src="https://blog.digitalogy.co/wp-content/uploads/2020/04/Ai-Speech-Recognition.gif" alt="Latest technology in artificial intelligence - Speech Recognition" width="400" height="300"></h4>
<p>Tap to speak by <a href="https://dribbble.com/samm" target="_blank" rel="contact noopener nofollow noreferrer" data-href="https://dribbble.com/samm">Sam Mularczyk</a></p>
<h4><strong>2. Emotion Recognition</strong></h4>
<p>Humans use a lot of non-verbal cues while interacting with someone, which includes our tone of voice, body language, facial expressions and gestures.</p>
<p>For machines to understand these, we needed a system that could pick up and identify them.</p>
<p>With the advancements in Image and Speech Recognition, a new discipline was born, called Emotion Recognition.</p>
<p>Emotion Recognition using AI was built to capture and, identify human emotions using facial and speech data.</p>
<p>It’s being used in a variety of industries ranging from law enforcement, interviews, market research, product feedback and more.</p>
<h4><strong>3. Biometrics (Facial Recognition)</strong></h4>
<blockquote>
<p>“Biometrics is certainly the most secure form of authentication. It’s the hardest to imitate and duplicate.”<br>
<strong>– Avivah Litan</strong></p>
</blockquote>
<p>Artificial Intelligence biometrics has seen immense growth in the industry and is empowering its offerings to further boost their accuracy.</p>
<p>The traditional methods that included fingerprints, voice, face, palm and iris recognition have all received their long due Artificial Intelligence integration.</p>
<p>This integration has drastically reduced the chances of errors in systems, making them more secure and robust.</p>
<blockquote>
<p>Some newer additions to this domain are <strong>gait detection</strong>, <strong>DNA recognition</strong>,<strong> keystroke dynamics</strong>, <strong>ear acoustic authentication</strong>.</p>
</blockquote>
<p><img src="https://blog.digitalogy.co/wp-content/uploads/2020/04/Artificial-intelligence-Biometrics.gif" alt="Artificial intelligence biometrics" width="800" height="600"></p>
<p>Facial biometrics recognition by <a href="https://dribbble.com/glebich" target="_blank" rel="contact noopener nofollow noreferrer" data-href="https://dribbble.com/glebich">Gleb Kuznetsov</a> for <a href="https://dribbble.com/milkinside" target="_blank" rel="contact noopener nofollow noreferrer" data-href="https://dribbble.com/milkinside">Milkinside</a></p>
<h4><strong>4. Machine Learning Platforms</strong></h4>
<blockquote>
<p>“A breakthrough in machine learning would be worth ten Microsofts.”</p>
<p><strong>-Bill Gates</strong></p>
</blockquote>
<p>One of the major ideas behind creating Artificial Intelligence technologies is to train it to think and execute.</p>
<p>The Machine Learning branch of AI aims to do precisely that by giving the machines a batch of training data for analysis and drawing inferences.</p>
<p>When put into practical use, these systems draw conclusions based on the collected assumptions and offer insight on the data.</p>
<p>Various businesses have adopted ML to ensure they have the necessary information to gain the upper hand in their trade.</p>
<h4><strong>5. Language Generation</strong></h4>
<p><a href="https://www.geeksforgeeks.org/artificial-intelligence-natural-language-generation/" target="_blank" rel="noopener nofollow noreferrer">Natural Language Generation</a> is a part of a broader process that includes <strong>NLU</strong>, <strong>NLP</strong> and <strong>NLG.</strong></p>
<p>Its purpose is to transform the structured data into a more natural-looking language that doesn’t look repetitive.</p>
<p>The content of which, can be further used to create custom reports, applications such as chatbots, automated journalism and websites.</p>
<p>Some of the well-known service providers for Natural Language Generation are <strong>Visual NLG</strong>, <strong>United Robots</strong>, <strong>Arria NLG</strong>, <strong>Narrative Science</strong> and <strong>Phrasetech</strong>.</p>
<p><iframe title="Natural Language Generation at Google Research (AI Adventures)" width="500" height="281" src="https://www.youtube.com/embed/MNvT5JekDpg?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<h4><strong>6. AI Optimized Hardware</strong></h4>
<blockquote>
<p>“In the long term, artificial intelligence and automation are going to be taking over so much of what gives humans a feeling of purpose.”<br>
<strong>– Matt Bellamy</strong></p>
</blockquote>
<p><strong>Traditional hardware like CPUs and GPUs</strong> were not built keeping Artificial Intelligence in mind, which led to slower processing and incompatibilities.</p>
<p>Advancements in AI are boosting the R&amp;D of optimized chips for processors and graphic processors.</p>
<p>With these newer chips, it is becoming easier to learn and implement AI on even consumer-grade hardware, making AI adoption global and open for everyone.</p>
<p>As the <a href="https://towardsdatascience.com/top-google-ai-tools-for-everyone-60346ab7e08" target="_blank" rel="noopener nofollow noreferrer">AI software</a> increases in complexity, silicon manufacturers are tasked with developing and equipping problem solvers with better hardware.</p>
<h4><strong>7. Virtual Agents(Chatbots)</strong></h4>
<p>Virtual Agents are smart programs that are powered by Artificial Intelligence technologies.</p>
<p>They are created to assist your customers and visitors by answering their questions, taking orders and such.</p>
<p>The idea behind these virtual agents is to have an agent available for support at all times with a human touch.</p>
<p>These virtual agents come in the form of chatbots or smart assistants and, they’re found on your phones and websites.</p>
<p>Some modern examples of virtual agents are <strong>Google Assistant</strong>, <strong>Alexa</strong>, <strong>Cortana</strong>, <strong>Siri</strong>, followed by hundreds of chatbots by loads of websites.</p>
<p><iframe title="Engage customers with Microsoft's Power Virtual Agents" width="500" height="281" src="https://www.youtube.com/embed/J5i7h4Uzju4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>

<h4><strong>8. Deep Learning Platforms</strong></h4>
<p>Deep Learning could be considered as the next step in Machine Learning with the introduction of Neural Networks for smarter and more efficient learning.</p>
<p>By replicating deep neural networks intricately similar to the human brain, ML algorithms can utilize these deep neural layers to train any model with optimum effectiveness.</p>
<p>A typical application of DL is found in training models dealing with vast amounts of data in mission-critical industries such as aerospace, medical, military, scientific research.</p>
<h4><strong>9. Decision Management</strong></h4>
<p><img src="https://blog.digitalogy.co/wp-content/uploads/2020/04/Decision-Management.jpeg" alt="Decision Management" width="750" height="500" srcset="https://blog.digitalogy.co/wp-content/uploads/2020/04/Decision-Management.jpeg 750w, https://blog.digitalogy.co/wp-content/uploads/2020/04/Decision-Management-300x200.jpeg 300w" sizes="(max-width: 750px) 100vw, 750px"></p>
<p>Photo by <a href="https://unsplash.com/@rosam2020?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank" rel="noopener nofollow noreferrer" data-href="https://unsplash.com/@rosam2020?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Roland Samuel</a> on <a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank" rel="noopener nofollow noreferrer" data-href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></p>
<p>Businesses use all kinds of management systems for handling their workflow.</p>
<p>These systems can generate loads of data, which, when pieced together, offer valuable insights on the business, providing for better decision making.</p>
<p>Artificial Intelligence technologies, when paired with traditional systems, extend their output and bring automation and predictions to the table.</p>
<p>Having the right knowledge from a decision management system can give <a href="https://blog.digitalogy.co/video-testimonials-an-effective-tool-for-establishing-your-business/">businesses a significant edge</a> and help in avoiding risks.</p>
<h4><strong>10. Content Creation</strong></h4>
<p>Content plays a role so crucial in the modern world that it is impossible to overlook it.</p>
<p>The right content can help you target your desired audience group faster and boost your business at the same time.</p>
<p>Content has the potential to create an impact on the audience, keeping businesses alive.</p>
<p>With the introduction of AI, creating content has never been easier with AI-powered content writing platforms, keyword research tools, content intelligence platforms.</p>
<blockquote>
<p>Quill, WordAI, Atomic AI, Twinword and Keyword tool are some of the modern examples of AI-backed content creation tools.</p>
</blockquote>
<h4><strong>11. Robotic Process Automation</strong></h4>
<blockquote><p>“The relationship between technology and people has to change in the future for the better, and I think RPA is one of the great tools to enable that change”.</p>
<p><strong>– Leslie Willcocks, professor of technology, work, and globalization at the London School of Economics</strong></p>
</blockquote>
<p>Robotic Process Automation is a domain of AI where robots are programmed to carry out repetitive tasks, requiring zero human intervention.</p>
<p>Having robots manage repetitive activities proves beneficial for enterprises as it eliminates chances of human errors.</p>
<p><img src="https://media.giphy.com/media/8gRgYeXD3rKUcjWlzB/giphy.gif"></p>
<p>GIF By <a href="https://ubtrobot.com/pages/walker" target="_blank" rel="noopener noreferrer">UBTech</a></p>
<p>It increases the throughput of the system while makes room for human employees to be placed at sections where human judgment is vital.</p>
<p>The applications for RPA can be often be seen in the banking industry, customer service sector, data extraction processes, eCommerce platforms and such.</p>
<h3><strong>For More Read –</strong></h3>
<blockquote data-secret="YxwHPirF2f"><p><a href="https://blog.digitalogy.co/top-robotics-companies-in-world-to-watch-2020/">Top Robotics Companies in World to Watch Out for in 2020</a></p></blockquote>

<h4><strong>12. Cyber Defence</strong></h4>
<blockquote>
<p>“Cyber security is much more than a matter of IT.”<br>
<strong>– Stephane Nappo</strong></p>
</blockquote>
<p>As cyber-crooks figure out new ways to cause harm to enterprises online, a more robust security solution is becoming the need of the hour.</p>
<p>With businesses going digital, keeping them safe online is of utmost priority. Cyber-Defence, coupled with Artificial Intelligence, creates an additional layer of <a href="https://blog.digitalogy.co/the-importance-of-information-security-for-your-business/" target="_blank" rel="noopener noreferrer">security</a>, countering most modern-day attacks.</p>
<p>AI can help predict, prevent, analyze and recover from cyber threats by deploying its artificial neural networks, machine learning and behavioral analytics subsets, to enhance the security measures in place.</p>
<h4><strong>13. </strong><strong>Text Analytics and Natural Language Processing (NLP)</strong></h4>
<h4><strong><img src="https://blog.digitalogy.co/wp-content/uploads/2020/04/Text-Analytics-and-Natural-Language-Processing-NLP-scaled.jpg" alt="Text Analytics and Natural Language Processing (NLP)" width="2560" height="1707" srcset="https://blog.digitalogy.co/wp-content/uploads/2020/04/Text-Analytics-and-Natural-Language-Processing-NLP-scaled.jpg 2560w, https://blog.digitalogy.co/wp-content/uploads/2020/04/Text-Analytics-and-Natural-Language-Processing-NLP-300x200.jpg 300w, https://blog.digitalogy.co/wp-content/uploads/2020/04/Text-Analytics-and-Natural-Language-Processing-NLP-1024x683.jpg 1024w, https://blog.digitalogy.co/wp-content/uploads/2020/04/Text-Analytics-and-Natural-Language-Processing-NLP-768x512.jpg 768w, https://blog.digitalogy.co/wp-content/uploads/2020/04/Text-Analytics-and-Natural-Language-Processing-NLP-1536x1024.jpg 1536w, https://blog.digitalogy.co/wp-content/uploads/2020/04/Text-Analytics-and-Natural-Language-Processing-NLP-2048x1365.jpg 2048w" sizes="(max-width: 2560px) 100vw, 2560px"></strong></h4>
<p>Photo by <a href="https://unsplash.com/@thisisengineering?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank" rel="noopener noreferrer" data-href="https://unsplash.com/@thisisengineering?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">ThisisEngineering RAEng</a> on <a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank" rel="noopener noreferrer" data-href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></p>
<p>Text Analytics is a branch of Artificial Intelligence that is radically simplifying how we extract information from exceedingly large volumes of text.</p>
<p>Whereas <a href="https://towardsdatascience.com/python-libraries-for-natural-language-processing-be0e5a35dd64?source=your_stories_page---------------------------" target="_blank" rel="noopener nofollow noreferrer">NLP </a>enables us to train various AI models using datasets containing a vast collection of words, grammar and speech from human language to create a more seamless interaction between humans and machines.</p>
<p>The insights generated from this data help in making important decisions. The practical application of text analytics technologies can be observed in security and fraud detection systems.</p>
<h4><strong>14. Digital Twin/AI Modeling</strong></h4>
<p>A Digital Twin is essentially a digital simulation of a …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.digitalogy.co/artificial-intelligence-technologies/">https://blog.digitalogy.co/artificial-intelligence-technologies/</a></em></p>]]>
            </description>
            <link>https://blog.digitalogy.co/artificial-intelligence-technologies/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24429526</guid>
            <pubDate>Thu, 10 Sep 2020 06:37:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amiga Fast File System Return to the Linux Kernel]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24429275">thread link</a>) | @todsacerdoti
<br/>
September 9, 2020 | https://cubiclenate.com/2020/09/09/amiga-fast-file-system-return-to-the-linux-kernel/ | <a href="https://web.archive.org/web/*/https://cubiclenate.com/2020/09/09/amiga-fast-file-system-return-to-the-linux-kernel/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<figure><img data-attachment-id="7350" data-permalink="https://cubiclenate.com/amiga-ffs-linux-kernel/" data-orig-file="https://cubiclenate.files.wordpress.com/2020/09/amiga-ffs-linux-kernel.png" data-orig-size="1920,768" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="amiga-ffs-linux-kernel" data-image-description="" data-medium-file="https://cubiclenate.files.wordpress.com/2020/09/amiga-ffs-linux-kernel.png?w=300" data-large-file="https://cubiclenate.files.wordpress.com/2020/09/amiga-ffs-linux-kernel.png?w=1024" src="https://cubiclenate.files.wordpress.com/2020/09/amiga-ffs-linux-kernel.png?w=1024" alt="" srcset="https://cubiclenate.files.wordpress.com/2020/09/amiga-ffs-linux-kernel.png?w=1024 1024w, https://cubiclenate.files.wordpress.com/2020/09/amiga-ffs-linux-kernel.png?w=150 150w, https://cubiclenate.files.wordpress.com/2020/09/amiga-ffs-linux-kernel.png?w=300 300w, https://cubiclenate.files.wordpress.com/2020/09/amiga-ffs-linux-kernel.png?w=768 768w, https://cubiclenate.files.wordpress.com/2020/09/amiga-ffs-linux-kernel.png 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>When I say “Return” what I mean is, return to a fully functional state. </p>



<p>I fancy myself a vintage computer enthusiast, although I haven’t done a whole lot with my Amigas as of late, a part of that has been my apprehension in being able to access the data on my old drives. I also realize that ALL my Amigas need to be recapped in order to function correctly. This series of projects will begin in the near future as I have received new pressures to make it so. One <a rel="noreferrer noopener" href="https://lkml.org/lkml/2020/8/27/990" target="_blank">Max Staudt authored a patch</a> that was reviewed and committed by David Sterba, a SUSE developer and kernel maintainer that have removed all my excuses.</p>



<div><figure><img data-attachment-id="7359" data-permalink="https://cubiclenate.com/image-1-6/" data-orig-file="https://cubiclenate.files.wordpress.com/2020/09/image-1.png" data-orig-size="743,235" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-1" data-image-description="" data-medium-file="https://cubiclenate.files.wordpress.com/2020/09/image-1.png?w=300" data-large-file="https://cubiclenate.files.wordpress.com/2020/09/image-1.png?w=743" src="https://cubiclenate.files.wordpress.com/2020/09/image-1.png?w=743" alt="" srcset="https://cubiclenate.files.wordpress.com/2020/09/image-1.png 743w, https://cubiclenate.files.wordpress.com/2020/09/image-1.png?w=150 150w, https://cubiclenate.files.wordpress.com/2020/09/image-1.png?w=300 300w" sizes="(max-width: 743px) 100vw, 743px"></figure></div>



<p>Max Staudt has noted that “The basic permission bits (protection bits in AmigaOS) have been broken in Linux AFFS. It would only set bits, but never delete them. Also, contrary to the documentation, the Archived bit was not handled.” My guess is, reading and archiving any AFFS drives was not an issue but manipulating the data from Linux was an issue. “Let’s fix this for good, and set the bits such that Linux and classic AmigaOS can coexist in the most peaceful manner,” he added. Torvalds appears to have agreed as Staudt’s code has made it into rc4 of version 5.9 of the Linux kernel. That is slated to be released to the masses in October 2020.</p>



<figure><img data-attachment-id="7354" data-permalink="https://cubiclenate.com/image-22/" data-orig-file="https://cubiclenate.files.wordpress.com/2020/09/image.png" data-orig-size="752,617" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-medium-file="https://cubiclenate.files.wordpress.com/2020/09/image.png?w=300" data-large-file="https://cubiclenate.files.wordpress.com/2020/09/image.png?w=752" src="https://cubiclenate.files.wordpress.com/2020/09/image.png?w=752" alt="" srcset="https://cubiclenate.files.wordpress.com/2020/09/image.png 752w, https://cubiclenate.files.wordpress.com/2020/09/image.png?w=150 150w, https://cubiclenate.files.wordpress.com/2020/09/image.png?w=300 300w" sizes="(max-width: 752px) 100vw, 752px"></figure>



<p>I am excited about the upcoming improved interaction between my current love of Linux and my historic love of Amiga in what I think is a huge kernel improvement. I don’t know how many people it will truly affect but the fact that Linus Torvalds agreed to include it in rc4 means it can’t just be an isolated edge case. As much as I would like to think that Mr. Staudt, Mr. Sterba, and Mr. Trovalds and are doing this just for me, I know that I am not alone in the love for this old technology.</p>



<div><figure><img data-attachment-id="7351" data-permalink="https://cubiclenate.com/2020/09/09/amiga-fast-file-system-return-to-the-linux-kernel/amiga-1200/" data-orig-file="https://cubiclenate.files.wordpress.com/2020/09/amiga-1200.png" data-orig-size="504,341" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="amiga-1200" data-image-description="" data-medium-file="https://cubiclenate.files.wordpress.com/2020/09/amiga-1200.png?w=300" data-large-file="https://cubiclenate.files.wordpress.com/2020/09/amiga-1200.png?w=504" src="https://cubiclenate.files.wordpress.com/2020/09/amiga-1200.png" alt=""></figure></div>



<p>I will be interested in seeing how this works out. I am hoping that I will be able to use the Amiga Fast File systems natively on Linux like any other file system. This should most certainly be fun. I am also happy to see that an Amiga enthusiast, a developer of SUSE and the top-dog of the Linux Kernel made effort to bring a needed enhancement to the Linux Kernel. It makes me wonder, are there other Amiga fans roaming the halls of SUSE? What kind of Amiga Computers does Max Staudt have? Has Linus Torvalds ever run Linux on an Amiga? It sure would be interesting to know! </p>



<h2>Final Thoughts</h2>



<p>I am super excited to see that Classic Amiga lives on, in part, within the Linux Kernel. This spectacular news is telling me that it is time to revisit with a lot more emphasis all the fun and excitement that the Amiga brought to me. There is much to do on my Amigas, data to archive and capacitors to replace. This David Sterba from SUSE has taken action to make Linux and Amiga interoperability much better and bridges a 25 year technology gap that helps to bring my 1990s platform of choice do the present. </p>



<p>Thank you, Max Staudt, David Sterba and all those involved on the Kernel team, so much, for what I consider to be the best Linux kernel submissions of 2020. This brings to me a smile that crosses from ear-to-ear to my face and now presses me hard to do more with my Amiga computers. </p>



<h2>References</h2>



<p><a rel="noreferrer noopener" href="https://lkml.org/lkml/2020/8/27/990" target="_blank">AFFS Patch https://lkml.org/lkml/2020/8/27/990<br></a><a rel="noreferrer noopener" href="https://www.theregister.com/2020/09/07/linux_5_9_rc_4/" target="_blank">TheRegister.com Article Linux 5.9 rc4</a><br><a rel="noreferrer noopener" href="https://kernel.googlesource.com/pub/scm/linux/kernel/git/kdave/linux/+/refs/tags/affs-for-5.9-tag" target="_blank">Amiga Fast File System Tag for 5.9<br></a><a rel="noreferrer noopener" href="https://lkml.org/lkml/2020/9/6/264" target="_blank">Linux Kernel Mailing List announcement</a></p>
			
			
				</div><div>
			<div>
				<p><img alt="" src="https://1.gravatar.com/avatar/d9a100d8b48299082b9ee42189f0a42e?s=80&amp;d=identicon&amp;r=G" height="80" width="80">		</p><!-- .author-avatar -->
		
		<p>
			<h2>Published by <span>CubicleNate</span></h2>
		</p><!-- .author-heading -->

		<p>
			I am a Linux and fitness geek that loves Jesus, people and freedom. Big believer in education &amp; self-empowerment in all things. Teach, train, uplift and edify.			<a href="https://cubiclenate.com/author/cubiclenate/" rel="author">
				View all posts by CubicleNate			</a>
		</p><!-- .author-bio -->
	</div><!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2020-09-09T14:40:42-04:00">9 September 2020</time><time datetime="2020-09-10T14:47:46-04:00">10 September 2020</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://cubiclenate.com/2020/09/09/amiga-fast-file-system-return-to-the-linux-kernel/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24429275</guid>
            <pubDate>Thu, 10 Sep 2020 05:50:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Annoying website features I face as a blind person]]>
            </title>
            <description>
<![CDATA[
Score 440 | Comments 213 (<a href="https://news.ycombinator.com/item?id=24429012">thread link</a>) | @Garbage
<br/>
September 9, 2020 | https://bighack.org/5-most-annoying-website-features-i-face-as-a-blind-screen-reader-user-accessibility/ | <a href="https://web.archive.org/web/*/https://bighack.org/5-most-annoying-website-features-i-face-as-a-blind-screen-reader-user-accessibility/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span>These are the five most annoying inaccessible web elements I face as a blind screen reader user every day, and how to fix them.
</span>
					</p><div>
						<p><span>For blind and visually impaired people like me, accessibility is the difference between us being able to use a website and clicking off it.&nbsp;</span></p>
<h2>How screen readers work</h2>
<p><span>Screen readers allow blind and visually impaired people to use computers, phones and tablets independently. Most screen readers use software, and a Text To Speech (TTS) engine, which is what converts the text from the screen reader into speech. Screen readers convert the text displayed on screen into a format that blind users can process.</span></p>
<p><span>Screen readers read out loud everything that’s on the screen and allow people to navigate using touch gestures and shortcut keys. They also work with other output devices such as a braille display.</span></p>
<p><span>As a screen reader user, here are the most common issues I encounter on a daily basis.&nbsp;</span></p>
<h2>Unlabelled links and buttons</h2>
<p><span>Screen reader users rely on links and buttons to navigate around a website and to find the information we need. If links and buttons are not labelled correctly or if at all, then it makes it difficult for screen reader users to find the information they need. Ultimately, unlabelled links make it much harder to navigate the website easily, quickly and independently.</span></p>
<p><span>For example, when linking to an about page, ‘click here’ doesn’t give any clue as to where it leads to, but ‘find out more about who we are’ is clear.</span></p>
<p><span>If links and buttons are labelled correctly, screen readers can read the label out loud. It means that blind and visually impaired people don’t have to press the link or button without knowing where it will take them.</span></p>
<p><span>As well as unlabelled elements, links and buttons that do not have a clear description are also really frustrating. They must have a clear description of where they will lead to when pressed, rather than ‘click here’. Never make your users guess where a link will take them or force them into a trial-and-error situation. This makes for tedious user experience.</span></p>
<h2>No image descriptions</h2>
<p><span>This is probably the most common issue I encounter when browsing the web.&nbsp;</span><span>Using image descriptions is essential for accessibility. Image descriptions are also known as alt text (alternative text) which is a written description of an image.</span></p>
<p><span>Screen readers read image descriptions out loud. This means that blind and visually impaired people can understand the content of the image in an accessible way.&nbsp;</span><span>If images do not have alt text, then screen readers will simply say “image” or “graphic” which gives no context or meaning.</span></p>
<p><span>Images often convey valuable information. It’s therefore important that people with a visual impairment can access this information as well.&nbsp;</span><span>Alt text should be clearly written and give an accurate description of the image.</span></p>
<p><strong>Check out <a href="https://bighack.org/how-to-write-better-alt-text-descriptions-for-accessibility/">our tips for writing better alt text</a> to ensure your images are fully accessible.</strong></p>
<h2>Poor use of headings</h2>
<p><span>For quick and easy navigation, many screen reader users navigate using various elements on the page such as headings. They are a great way to find the information we need quickly and effectively. Especially when they follow a logical heading structure with H1s, H2s and H3s helping to prioritise the content.</span></p>
<p><img src="https://bighack.org/wp-content/uploads/2020/05/Headings@2x.jpg" alt="Logical heading structure begins with Heading 1, with Heading 2 sitting beneath heading 1. Heading 3 sits within heading 2 and so on." width="1958" height="1236" srcset="https://bighack.org/wp-content/uploads/2020/05/Headings@2x.jpg 1958w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-300x189.jpg 300w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-768x485.jpg 768w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-1536x970.jpg 1536w" sizes="(max-width: 1958px) 100vw, 1958px" data-srcset="https://bighack.org/wp-content/uploads/2020/05/Headings@2x.jpg 1958w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-300x189.jpg 300w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-768x485.jpg 768w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-1536x970.jpg 1536w" data-src="https://bighack.org/wp-content/uploads/2020/05/Headings@2x.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>
<p><span>If websites don’t use headings, it means screen reader users are unable to use the keyboard shortcuts to navigate through the webpage this way. If that’s the case, we have to resort to tabbing or arrowing through a long web page to find the information we need.</span></p>
<p>Headings also help to break up the web content visually and improve readability. Other elements that screen reader users use to navigate webpages include links, lists or landmarks.</p>
<h2>Inaccessible web forms</h2>
<p><span>Most websites use forms in one way or another. Whether it’s to help you search for a product or to get in touch through a contact form. However, when these forms are not labelled, or not labelled correctly, it means we cannot use them.</span></p>
<p><span>For example, if a search box is not labelled, it means screen reader users have no idea of the purpose of that box. It means people who use screen readers cannot access the same functionality.</span></p>
<p><span>Contact forms are an effective way for customers to get in touch with your brand or business. And as a screen reader user, there’s nothing more frustrating than these forms being labelled incorrectly.</span></p>
<p><span>Especially CAPTCHA checkout requirements. Without an option to hear the audio, it’s not accessible. It means we are unable to fill in the form independently. I often have to enlist help from a sighted person, but this isn’t possible for everyone.</span><b>&nbsp;</b></p>
<h2>Auto-playing audio and video</h2>
<p><span>Most people will know how annoying it is to load a web page with noisy adverts that start playing suddenly. But for screen reader users, it can be even more alarming. When video or audio starts playing automatically, it can drown out the voice of the screen reader. This makes it harder to find the pause or stop buttons.</span></p>
<p><span>(And if these buttons are unlabelled, then it’s practically impossible for me to stop the video quickly which causes extra frustration.) If I’m unable to stop the sound or video, I normally click off.</span></p>
<p><span>The solution? Make sure there’s no auto-playing video or audio when your website loads. If you really want to use video, make sure the audio is muted and the user can pause, stop or hide the media player.</span></p>
<p><span>These issues may seem small to sighted users. But they’re the difference between me being able to use a website independently or not. And they make a huge difference when implemented correctly.</span></p>
					</div></div>]]>
            </description>
            <link>https://bighack.org/5-most-annoying-website-features-i-face-as-a-blind-screen-reader-user-accessibility/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24429012</guid>
            <pubDate>Thu, 10 Sep 2020 04:55:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Security by Obscurity Is Underrated]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24428930">thread link</a>) | @zdw
<br/>
September 9, 2020 | https://utkusen.com/blog/security-by-obscurity-is-underrated.html | <a href="https://web.archive.org/web/*/https://utkusen.com/blog/security-by-obscurity-is-underrated.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>
08 September 2020
</p>
<p>In the information security field, we have developed lots of thoughts that can’t be discussed (or rarely discussed):</p>
<ul>
<li>
<p>Never roll your own crypto</p>
</li>
<li>
<p>Always use TLS</p>
</li>
<li>
<p>Security by obscurity is bad</p>
</li>
</ul>
<p>And goes like this. Most of them are very generally correct. However, I started to think that people are telling those because everyone is telling them. And, most of the people are actually not thinking about exceptional cases. In this post, I will raise my objection against the idea of “Security by obscurity is bad”.</p>
<h2 id="risk-defense-in-depth-and-swiss-cheese">Risk, Defense in Depth and Swiss Cheese</h2>
<p>One of the main goal of defensive security is reducing the risk for the target business. According to the OWASP’s methodology, the risk of an issue is calculated with the formula below:</p>
<p><code>Risk = Likelihood * Impact</code></p>

<p>According to this formula, a Remote Code Execution issue poses more risk than a Cross Site Scripting one since the RCE causes more impact. This is easy. But what about the likelihood metric. According to the OWASP, likelihood refers that:</p>
<div><div><pre><code>At the highest level, this is a rough measure of how likely this particular vulnerability is to be uncovered and exploited by an attacker
</code></pre></div></div>
<p>So, if we can reduce the likelihood, we can reduce the overall risk. That’s good. It’s actually very similar to a very common idea called “Defense in Depth”. It’s also referred as “Swiss Cheese Model”</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/0/07/Swiss_cheese_model.svg" alt="Swiss Cheese"></p>
<p>According to this model, you need to build your defense mechanisms in a layered model so that even the attackers pass the first one, they will get caught on the others.</p>
<h2 id="security-by-obscurity">Security by Obscurity</h2>
<p>So let’s talk about security by obscurity. It’s a bad idea to use it as a single layer of defense. If the attacker passes it, there is nothing else to protect you. But it’s actually would be good to use it as an “additional” layer of defense. Because it has a low implementation cost and it usually works well.</p>
<p>Let’s think about a couple of scenarios here:</p>
<ul>
<li>I have a server that runs the SSH with it’s default port <code>22</code> and my credentials are: <code>root:123456</code>. What is the likelihood of being compromised?</li>
</ul>
<p>It’s almost 100% since the hackers are conducting brute force attacks to the services with common credentials globally.</p>
<ul>
<li>SSH runs in port <code>22</code> and my credentials are <code>utku:123456</code>. What is the likelihood of being compromised?</li>
</ul>
<p>Well, we have eliminated the global brute forcers since we are not using a common username. The likelihood and risk are reduced. However, we still have to deal with targeted attackers. A targeted attacker can guess the username as <code>utku</code> since it’s my name.</p>
<ul>
<li>SSH runs in port <code>64323</code> and my credentials are <code>utku:123456</code>. What is the likelihood of being compromised?</li>
</ul>
<p>Now we changed the default port number. Does it help? Firstly, we’ve eliminated the global brute forcers again since they scan only the common ports. What about the others? To find this out, I did a small survey on my Twitter to find out people’s port scan behaviors.</p>
<blockquote><div lang="en" dir="ltr"><p>I'm trying to prove a point for my new article. I need your answers for the question below. (please be honest)</p><p>-When you do a port scan with nmap to find open ports on the target, are you specify a custom port range to scan all 65,535 ports? (with -p0-65535 parameter)</p></div>— Utku Şen (@utkusen) <a href="https://twitter.com/utkusen/status/1303021175556145154?ref_src=twsrc%5Etfw">September 7, 2020</a></blockquote>

<p>As you can see here, lots of people tend to scan the default/most popular ports only. So, if you switch your port from 22 to 64323, you will eliminate some of them. You will reduce the likelihood and risk.</p>
<p>The same thing goes for software vulnerabilities as well. If a vulnerability found in the Microsoft Remote Desktop Protocol, everybody will scan for the port 3389 globally. You can reduce your risk just by changing the default port.</p>
<h2 id="other-applications">Other Applications</h2>
<p>Of course, it’s possible to use the same methodology in other fields other than changing the defaults. For example, the following ideas might be a good idea for some specific cases (not always)</p>
<ul>
<li>
<p><strong>Obfuscating codes:</strong> Of course, it’s common knowledge. Hackers are people too. If you obfuscate your code well, they will need to spend more time to find issues. They may give up eventually.</p>
</li>
<li>
<p><strong>Using random variable names for a web application:</strong> Instead of using clear variable names, you can switch them with random strings. It might help just like the code obfuscation.</p>
</li>
<li>
<p><strong>Using Symmetric Encryption in the Database:</strong> When you write data to the database, use a function like <code>encryption_algorithm(data,key)</code>. Likewise, when you read data, use a function like <code>decryption_algorithm(data,key)</code>. If the attacker can read your backend code, obviously he/she can decrypt your database. But if there is an issue that allows an attacker to read data from the database, but not the backend code (like SQL Injection), the gathered data won’t be helpful for the attacker.</p>
</li>
</ul>
<h2 id="real-life-applications">Real Life Applications</h2>
<p>Security by obscurity is widely used in physical/real-life security. For example, the president goes from point A to point B with his 30 cars convoy. But he’s not sitting on his own presidential car so that the attacker won’t target him easily. He can be in any car and it reduces the risk of an attack.</p>
<p><img src="https://i.dailymail.co.uk/1s/2019/06/04/00/14330600-0-image-a-38_1559605545988.jpg" alt="President"></p>
<p>Camouflaged animals are using security by obscurity as well. Obscurity reduces the likelihood of being killed. Therefore, they gained this ability in the evolutionary process.</p>
<p><img src="https://static.boredpanda.com/blog/wp-content/uuuploads/animal-camouflage/animal-camouflage-4.jpg" alt="Animal"></p>
<h2 id="conclusion">Conclusion</h2>
<p>Security by obscurity is not enough by itself. You should always enforce the best practices. However, if you can reduce the risk with zero cost, you should do that. Obscurity is a good layer of security.</p>


</div></div>]]>
            </description>
            <link>https://utkusen.com/blog/security-by-obscurity-is-underrated.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24428930</guid>
            <pubDate>Thu, 10 Sep 2020 04:36:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rewriting Facebook's “Recoil” React library from scratch in 100 lines]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24428923">thread link</a>) | @bennettbackward
<br/>
September 9, 2020 | https://bennetthardwick.com/blog/recoil-js-clone-from-scratch-in-100-lines/ | <a href="https://web.archive.org/web/*/https://bennetthardwick.com/blog/recoil-js-clone-from-scratch-in-100-lines/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Recoil is a slick new React library written by some people at Facebook that work on a tool called
<a href="https://www.youtube.com/watch?v=_ISAA_Jt9kI" target="_blank" rel="noreferrer">“Comparison View."</a>
It came about because of ergonomics and
<a href="https://github.com/facebook/react/issues/14620" target="_blank" rel="noreferrer">performance issues with context</a>
and <code>useState</code>.
It’s a very clever library, and almost everyone will find a use for it - check out this
<a href="https://www.youtube.com/watch?v=_ISAA_Jt9kI" target="_blank" rel="noreferrer">explainer video</a>
if you want to learn more.</p><p>At first I was really taken aback by the talk of graph theory and the wondrous magic that Recoil performs, but after a while I started to see that maybe it’s not that special after all. Here’s my shot at implementing something similar!</p><p>Before I get started, please note that the way I’ve implemented my Recoil clone is completely different to how the actual Recoil is implemented.
Don’t assume anything about Recoil from this.</p><h2 id="atoms">Atoms</h2><p>Recoil is built around the concept of “atoms”.
Atoms are small atomic pieces of state that you can subscribe to and update in your components.</p><p>To begin, I’m going to create a class called <code>Atom</code> that is going to wrap some value <code>T</code>.
I’ve added helper methods <code>update</code> and <code>snapshot</code> to allow you to get and set the value.</p><div><pre><code data-lang="typescript"><span>class</span> <span>Atom</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
  <span>constructor</span><span>(</span><span>private</span> <span>value</span>: <span>T</span><span>)</span> <span>{}</span>

  <span>update</span><span>(</span><span>value</span>: <span>T</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span><span>value</span> <span>=</span> <span>value</span><span>;</span>
  <span>}</span>

  <span>snapshot</span><span>()</span><span>:</span> <span>T</span> <span>{</span>
    <span>return</span> <span>this</span><span>.</span><span>value</span><span>;</span>
  <span>}</span>
<span>}</span>
</code></pre></div><p>To listen for changes to the state, you need to use
<a href="https://www.tutorialspoint.com/design_pattern/observer_pattern.htm" target="_blank" rel="noreferrer">the observer pattern</a>
.
This is commonly seen in libraries like
<a href="https://rxjs-dev.firebaseapp.com/guide/overview" target="_blank" rel="noreferrer">RxJS</a>
,
but in this case I’m going to write a simple synchronous version from scratch.</p><p>To know who is listening to the state I use a <code>Set</code> of callbacks.
A <code>Set</code> (or Hash Set) is a data structure that only contains unique items.
In JavaScript it can easily be turned into an array and has helpful methods for quickly adding and removing items.</p><p>Adding a listener is done through the <code>subscribe</code> method.
The subscribe method returns <code>Disconnecter</code> - an interface containing a method that will stop a listener from listening.
This is called when a React component is unmounted and you no longer want to listen for changes.</p><p>Next, a method called <code>emit</code> is added. This method loops through each of the listeners and gives them the current value in the state.</p><p>Finally I update the <code>update</code> method to emit the new values whenever the state is set.</p><div><pre><code data-lang="typescript"><span><span>type</span> <span>Disconnecter</span> <span>=</span> <span>{</span> <span>disconnect</span><span>:</span> <span>()</span> <span>=&gt;</span> <span>void</span> <span>};</span>
</span>
<span>class</span> <span>Atom</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
<span>  <span>private</span> <span>listeners</span> <span>=</span> <span>new</span> <span>Set</span><span>&lt;</span><span>(</span><span>value</span>: <span>T</span><span>)</span> <span>=&gt;</span> <span>void</span><span>&gt;</span><span>();</span>
</span>
  <span>constructor</span><span>(</span><span>private</span> <span>value</span>: <span>T</span><span>)</span> <span>{}</span>

  <span>update</span><span>(</span><span>value</span>: <span>T</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span><span>value</span> <span>=</span> <span>value</span><span>;</span>
<span>    <span>this</span><span>.</span><span>emit</span><span>();</span>
</span>  <span>}</span>

  <span>snapshot</span><span>()</span><span>:</span> <span>T</span> <span>{</span>
    <span>return</span> <span>this</span><span>.</span><span>value</span><span>;</span>
  <span>}</span>

<span>  <span>emit() {</span>
</span><span>    <span>for</span> <span>(</span><span>const</span> <span>listener</span> <span>of</span> <span>this</span><span>.</span><span>listeners</span><span>)</span> <span>{</span>
</span><span>      <span>listener</span><span>(</span><span>this</span><span>.</span><span>snapshot</span><span>());</span>
</span><span>    <span>}</span>
</span><span>  <span>}</span>
</span>
<span>  <span>subscribe</span><span>(</span><span>callback</span><span>:</span> <span>(</span><span>value</span>: <span>T</span><span>)</span> <span>=&gt;</span> <span>void</span><span>)</span><span>:</span> <span>Disconnecter</span> <span>{</span>
</span><span>    <span>this</span><span>.</span><span>listeners</span><span>.</span><span>add</span><span>(</span><span>callback</span><span>);</span>
</span><span>    <span>return</span> <span>{</span>
</span><span>      <span>disconnect</span><span>:</span> <span>()</span> <span>=&gt;</span> <span>{</span>
</span><span>        <span>this</span><span>.</span><span>listeners</span><span>.</span><span>delete</span><span>(</span><span>callback</span><span>);</span>
</span><span>      <span>},</span>
</span><span>    <span>};</span>
</span><span>  <span>}</span>
</span><span>}</span>
</code></pre></div><p>Phew!</p><p>It’s time to write the atom up into our React components. To do this, I’ve created a hook called <code>useCoiledValue</code>. (
<a href="https://recoiljs.org/docs/api-reference/core/useRecoilValue/" target="_blank" rel="noreferrer">sound familiar?</a>
)</p><p>This hook returns the current state of an atom, and listens and re-renders whenever the value changes.
Whenever the hook is unmounted, it disconnects the listener.</p><p>One thing that’s a little weird here is the <code>updateState</code> hook.
By performing a set state with a new object reference (<code>{}</code>), React will re-render the component.
This is a little bit of a hack, but it’s an easy way to make sure the component re-renders.</p><div><pre><code data-lang="typescript"><span>export</span> <span>function</span> <span>useCoiledValue</span><span>&lt;</span><span>T</span><span>&gt;(</span><span>value</span>: <span>Atom</span><span>&lt;</span><span>T</span><span>&gt;)</span><span>:</span> <span>T</span> <span>{</span>
  <span>const</span> <span>[,</span> <span>updateState</span><span>]</span> <span>=</span> <span>useState</span><span>({});</span>

  <span>useEffect</span><span>(()</span> <span>=&gt;</span> <span>{</span>
    <span>const</span> <span>{</span> <span>disconnect</span> <span>}</span> <span>=</span> <span>value</span><span>.</span><span>subscribe</span><span>(()</span> <span>=&gt;</span> <span>updateState</span><span>({}));</span>
    <span>return</span> <span>()</span> <span>=&gt;</span> <span>disconnect</span><span>();</span>
  <span>},</span> <span>[</span><span>value</span><span>]);</span>

  <span>return</span> <span>value</span><span>.</span><span>snapshot</span><span>();</span>
<span>}</span>
</code></pre></div><p>Next I’ve added a <code>useCoiledState</code> method. This has a very similar API to <code>useState</code> - it gives you the current value of the state and allows you to set a new one.</p><div><pre><code data-lang="typescript"><span>export</span> <span>function</span> <span>useCoiledState</span><span>&lt;</span><span>T</span><span>&gt;(</span><span>atom</span>: <span>Atom</span><span>&lt;</span><span>T</span><span>&gt;)</span><span>:</span> <span>[</span><span>T</span><span>,</span> <span>(</span><span>value</span>: <span>T</span><span>)</span> <span>=&gt;</span> <span>void</span><span>]</span> <span>{</span>
  <span>const</span> <span>value</span> <span>=</span> <span>useCoiledValue</span><span>(</span><span>atom</span><span>);</span>
  <span>return</span> <span>[</span><span>value</span><span>,</span> <span>useCallback</span><span>((</span><span>value</span><span>)</span> <span>=&gt;</span> <span>atom</span><span>.</span><span>update</span><span>(</span><span>value</span><span>),</span> <span>[</span><span>atom</span><span>])];</span>
<span>}</span>
</code></pre></div><p>Now that we’ve got those hooks out of the road, it’s time to move onto Selectors.
Before that though, let’s refactor what we’ve got a little bit.</p><p>A selector is a stateful value, just like an atom.
To make implementing them a bit easier,
I’ll move most of the logic out of <code>Atom</code> into a base class called <code>Stateful</code>.</p><div><pre><code data-lang="typescript"><span><span>class</span> <span>Stateful</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
</span>  <span>private</span> <span>listeners</span> <span>=</span> <span>new</span> <span>Set</span><span>&lt;</span><span>(</span><span>value</span>: <span>T</span><span>)</span> <span>=&gt;</span> <span>void</span><span>&gt;</span><span>();</span>

  <span>constructor</span><span>(</span><span>private</span> <span>value</span>: <span>T</span><span>)</span> <span>{}</span>

<span>  <span>protected</span> <span>_update</span><span>(</span><span>value</span>: <span>T</span><span>)</span> <span>{</span>
</span>    <span>this</span><span>.</span><span>value</span> <span>=</span> <span>value</span><span>;</span>
    <span>this</span><span>.</span><span>emit</span><span>();</span>
  <span>}</span>

  <span>snapshot</span><span>()</span><span>:</span> <span>T</span> <span>{</span>
    <span>return</span> <span>this</span><span>.</span><span>value</span><span>;</span>
  <span>}</span>

  <span>subscribe</span><span>(</span><span>callback</span><span>:</span> <span>(</span><span>value</span>: <span>T</span><span>)</span> <span>=&gt;</span> <span>void</span><span>)</span><span>:</span> <span>Disconnecter</span> <span>{</span>
    <span>this</span><span>.</span><span>listeners</span><span>.</span><span>add</span><span>(</span><span>callback</span><span>);</span>
    <span>return</span> <span>{</span>
      <span>disconnect</span><span>:</span> <span>()</span> <span>=&gt;</span> <span>{</span>
        <span>this</span><span>.</span><span>listeners</span><span>.</span><span>delete</span><span>(</span><span>callback</span><span>);</span>
      <span>},</span>
    <span>};</span>
  <span>}</span>
<span>}</span>

<span><span>class</span> <span>Atom</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>extends</span> <span>Stateful</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
</span><span>  <span>update</span><span>(</span><span>value</span>: <span>T</span><span>)</span> <span>{</span>
</span><span>    <span>super</span><span>.</span><span>_update</span><span>(</span><span>value</span><span>);</span>
</span><span>  <span>}</span>
</span><span><span>}</span>
</span></code></pre></div><p>Moving on!</p><h2 id="selectors">Selectors</h2><p>A selector is Recoil’s version of “computed values” or “reducers”. In their
<a href="https://recoiljs.org/docs/basic-tutorial/selectors" target="_blank" rel="noreferrer">own words</a>
:</p><blockquote><p>A selector represents a piece of derived state. You can think of derived state as the output of passing state to a pure function that modifies the given state in some way.</p></blockquote><p>The API for selectors in Recoil is quite simple, you create an object with a method called <code>get</code> and whatever that method returns is the value of your state.
Inside the <code>get</code> method you can subscribe to other pieces of state, and whenever they update so too will your selector.</p><p>In our case, I’m going to rename the <code>get</code> method to be called <code>generator</code>.
I’m calling it this because it’s essentially a factory function that’s supposed to generate the next value of the state, based on whatever is piped into it.</p><p><img src="https://bennetthardwick.com/blog/recoil-js-clone-from-scratch-in-100-lines/atom-selector-flow_hu6c1d970fc33d5ff12c990845e7422d9f_40682_694x0_resize_box_2.png" width="694" height="445" alt="a flowchart demonstrating two atoms (titled “hello” and “bob”) being piped into a selector, with the output becomming “Hello, Bob”"></p><p>In code, we can capture this <code>generate</code> method with the following type signature.</p><div><pre><code data-lang="typescript"><span>type</span> <span>SelectorGenerator</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>=</span> <span>(</span><span>context</span>: <span>GeneratorContext</span><span>)</span> <span>=&gt;</span> <span>T</span><span>;</span>
</code></pre></div><p>For those unfamilar with Typescript, it’s a function that takes a context object (<code>GeneratorContext</code>) as a parameter and returns some value <code>T</code>.
This return value is what becomes the internal state of the selector.</p><p>What does the <code>GeneratorContext</code> object do?</p><p>Well that’s how selectors use other pieces of state when generating their own internal state.
From now on I’ll refer to these pieces of state as “dependencies”.</p><div><pre><code data-lang="typescript"><span>interface</span> <span>GeneratorContext</span> <span>{</span>
  <span>get</span><span>:</span> <span>&lt;</span><span>V</span><span>&gt;(</span><span>dependency</span>: <span>Stateful</span><span>&lt;</span><span>V</span><span>&gt;)</span> <span>=&gt;</span> <span>V</span>
<span>}</span>
</code></pre></div><p>Whenever someone calls the <code>get</code> method on the <code>GeneratorContext</code>, it adds a piece of state as a dependency.
This means that whenever a dependency updates, so too will the selector.</p><p>Here’s what creating a selector’s generate function might look like:</p><div><pre><code data-lang="typescript"><span>function</span> <span>generate</span><span>(</span><span>context</span><span>)</span> <span>{</span>
  <span>// Register the NameAtom as a dependency
</span><span></span>  <span>// and get it's value
</span><span></span>  <span>const</span> <span>name</span> <span>=</span> <span>context</span><span>.</span><span>get</span><span>(</span><span>NameAtom</span><span>);</span>
  <span>// Do the same for AgeAtom
</span><span></span>  <span>const</span> <span>age</span> <span>=</span> <span>context</span><span>.</span><span>get</span><span>(</span><span>AgeAtom</span><span>);</span>

  <span>// Return a new value using the previous atoms
</span><span></span>  <span>// E.g. "Bob is 20 years old"
</span><span></span>  <span>return</span> <span>`</span><span>${</span><span>name</span><span>}</span><span> is </span><span>${</span><span>age</span><span>}</span><span> years old.`</span><span>;</span>
<span>};</span>
</code></pre></div><p>With the generate function out of the way, let’s create the <code>Selector</code> class.
This class should accept the generate function as a constructor parameter and use a <code>getDep</code> method on the class to return the value of the <code>Atom</code> dependencies.</p><p>You might notice in the constructor that I’ve written <code>super(undefined as any)</code>.
This is because <code>super</code> must be the very first line in a derived class’s constructor.
If it helps, in this case you can think of <code>undefined</code> as uninitialised memory.</p><div><pre><code data-lang="typescript"><span>export</span> <span>class</span> <span>Selector</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>extends</span> <span>Stateful</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
  <span>private</span> <span>getDep</span><span>&lt;</span><span>V</span><span>&gt;(</span><span>dep</span>: <span>Stateful</span><span>&lt;</span><span>V</span><span>&gt;)</span><span>:</span> <span>V</span> <span>{</span>
    <span>return</span> <span>dep</span><span>.</span><span>snapshot</span><span>();</span>
  <span>}</span>

  <span>constructor</span><span>(</span>
    <span>private</span> <span>readonly</span> <span>generate</span>: <span>SelectorGenerator</span><span>&lt;</span><span>T</span><span>&gt;</span>
  <span>)</span> <span>{</span>
    <span>super</span><span>(</span><span>undefined</span> <span>as</span> <span>any</span><span>);</span>
    <span>const</span> <span>context</span> <span>=</span> <span>{</span>
      <span>get</span>: <span>dep</span> <span>=&gt;</span> <span>this</span><span>.</span><span>getDep</span><span>(</span><span>dep</span><span>)</span> 
    <span>};</span>
    <span>this</span><span>.</span><span>value</span> <span>=</span> <span>generate</span><span>(</span><span>context</span><span>);</span>
  <span>}</span>
<span>}</span>
</code></pre></div><p>This selector is only good for generating state once.
In order to react to changes in the dependencies, we need to subscribe to them.</p><p>To do this, let’s update the <code>getDep</code> method to subscribe to the dependencies and call the <code>updateSelector</code> method.
To make sure the selector only updates once per change, let’s keep track of the deps using a <code>Set</code>.</p><p>The <code>updateSelector</code> method is very similar to the constructor in the previous example.
It creates the <code>GeneratorContext</code>, runs the <code>generate</code> method and then uses the <code>update</code> method from the <code>Stateful</code> base class.</p><div><pre><code data-lang="typescript"><span>export</span> <span>class</span> <span>Selector</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>extends</span> <span>Stateful</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>{</span>
<span>  <span>private</span> <span>registeredDeps</span> <span>=</span> <span>new</span> <span>Set</span><span>&lt;</span><span>Stateful</span><span>&gt;();</span>
</span>
  <span>private</span> <span>getDep</span><span>&lt;</span><span>V</span><span>&gt;(</span><span>dep</span>: <span>Stateful</span><span>&lt;</span><span>V</span><span>&gt;)</span><span>:</span> <span>V</span> <span>{</span>
<span>    <span>if</span> <span>(</span><span>!</span><span>this</span><span>.</span><span>registeredDeps</span><span>.</span><span>has</span><span>(</span><span>dep</span><span>))</span> <span>{</span>
</span><span>      <span>dep</span><span>.</span><span>subscribe</span><span>(()</span> <span>=&gt;</span> <span>this</span><span>.</span><span>updateSelector</span><span>());</span>
</span><span>      <span>this</span><span>.</span><span>registeredDeps</span><span>.</span><span>add</span><span>(</span><span>dep</span><span>);</span>
</span><span>    <span>}</span>
</span>
    <span>return</span> <span>dep</span><span>.</span><span>snapshot</span><span>();</span>
  <span>}</span>

<span>  <span>private</span> <span>updateSelector() {</span>
</span><span>    <span>const</span> <span>context</span> <span>=</span> <span>{</span>
</span><span>      <span>get</span>: <span>dep</span> <span>=&gt;</span> <span>this</span><span>.</span><span>getDep</span><span>(</span><span>dep</span><span>)</span>
</span><span>    <span>};</span>
</span><span>    <span>this</span><span>.</span><span>update</span><span>(</span><span>this</span><span>.</span><span>generate</span><span>(</span><span>context</span><span>));</span>
</span><span>  <span>}</span>
</span>
  <span>constructor</span><span>(</span>
    <span>private</span> <span>readonly</span> <span>generate</span>: <span>SelectorGenerator</span><span>&lt;</span><span>T</span><span>&gt;</span>
  <span>)</span> <span>{</span>
    <span>super</span><span>(</span><span>undefined</span> <span>as</span> <span>any</span><span>);</span>
    <span>const</span> <span>context</span> <span>=</span> <span>{</span>
      <span>get</span>: <span>dep</span> <span>=&gt;</span> <span>this</span><span>.</span><span>getDep</span><span>(</span><span>dep</span><span>)</span> 
    <span>};</span>
    <span>this</span><span>.</span><span>value</span> <span>=</span> <span>generate</span><span>(</span><span>context</span><span>);</span>
  <span>}</span>
<span>}</span>
</code></pre></div><p>Almost done! Recoil has some helper functions for creating atoms and selectors.
Since most JavaScript devs consider classes evil, they’ll help mask our atrocities.</p><p>One for creating an atom…</p><div><pre><code data-lang="typescript"><span>export</span> <span>function</span> <span>atom</span><span>&lt;</span><span>V</span><span>&gt;(</span>
  <span>value</span><span>:</span> <span>{</span> <span>key</span>: <span>string</span><span>;</span> <span>default</span><span>:</span> <span>V</span> <span>}</span>
<span>)</span><span>:</span> <span>Atom</span><span>&lt;</span><span>V</span><span>&gt;</span> <span>{</span>
  <span>return</span> <span>new</span> <span>Atom</span><span>(</span><span>value</span><span>.</span><span>default</span><span>);</span>
<span>}</span>
</code></pre></div><p>And one for creating a selector…</p><div><pre><code data-lang="typescript"><span>export</span> <span>function</span> <span>selector</span><span>&lt;</span><span>V</span><span>&gt;(</span><span>value</span><span>:</span> <span>{</span>
  <span>key</span>: <span>string</span><span>;</span>
  <span>get</span>: <span>SelectorGenerator</span><span>&lt;</span><span>V</span><span>&gt;;</span>
<span>})</span><span>:</span> <span>Selector</span><span>&lt;</span><span>V</span><span>&gt;</span> <span>{</span>
  <span>return</span> <span>new</span> <span>Selector</span><span>(</span><span>value</span><span>.</span><span>get</span><span>);</span>
<span>}</span>
</code></pre></div><p>Oh, remember that <code>useCoiledValue</code> hook from before? Let’s update that to accept selectors too:</p><div><pre><code data-lang="typescript"><span><span>export</span> <span>function</span> <span>useCoiledValue</span><span>&lt;</span><span>T</span><span>&gt;(</span><span>value</span>: <span>Stateful</span><span>&lt;</span><span>T</span><span>&gt;)</span><span>:</span> <span>T</span> <span>{</span>
</span>  <span>const</span> <span>[,</span> <span>updateState</span><span>]</span> <span>=</span> <span>useState</span><span>({});</span>

  <span>useEffect</span><span>(()</span> <span>=&gt;</span> <span>{</span>
    <span>const</span> <span>{</span> <span>disconnect</span> <span>}</span> <span>=</span> <span>value</span><span>.</span><span>subscribe</span><span>(()</span> <span>=&gt;</span> <span>updateState</span><span>({}));</span>
    <span>return</span> <span>()</span> <span>=&gt;</span> <span>disconnect</span><span>();</span>
  <span>},</span> <span>[</span><span>value</span><span>]);</span>

  <span>return</span> <span>value</span><span>.</span><span>snapshot</span><span>();</span>
<span>}</span>
</code></pre></div><p>That’s it! We’ve done it! 🎉</p><p>Give yourself a pat on your back!</p><p>Finished?</p><p>For the sake of brevity (and in order to use that clickbaity “100 lines” title) I decided to omit comments, tests and examples.
If you want a more thorough explanation (or want to play with examples), all that stuff is up in my
<a href="https://github.com/bennetthardwick/recoil-clone" target="_blank" rel="noreferrer">“recoil-clone” Github repository.</a></p><p>There’s also an
<a href="https://100-line-recoil-clone.netlify.app/" target="_blank" rel="noreferrer">example site</a>
live so you can test it out.</p><h2 id="conclusion">Conclusion</h2><p>I once read that all good software should be simple enough that anyone could rewrite it if they …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bennetthardwick.com/blog/recoil-js-clone-from-scratch-in-100-lines/">https://bennetthardwick.com/blog/recoil-js-clone-from-scratch-in-100-lines/</a></em></p>]]>
            </description>
            <link>https://bennetthardwick.com/blog/recoil-js-clone-from-scratch-in-100-lines/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24428923</guid>
            <pubDate>Thu, 10 Sep 2020 04:35:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The rate of obsolescence of knowledge in software engineering]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24428810">thread link</a>) | @dgs_sgd
<br/>
September 9, 2020 | https://daltyboy11.github.io/obsolescence-of-knowledge-in-software-engineering/ | <a href="https://web.archive.org/web/*/https://daltyboy11.github.io/obsolescence-of-knowledge-in-software-engineering/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>A physicist loses half the value of their physics knowledge in just four years whereas
an English professor would take over 25 years to lose half the value of the
knowledge they had at the beginning of their career [1]. These estimates are
taken form a paper written in 1982 so software engineers obviously weren’t
included. But it begs the question… What would the half-life of the value of a
software engineer’s knowledge be? I suspect it’s somewhere between the physicist’s
and the English professor’s because a software engineer’s knowledge is a combination
of eternal computer science/engineering principles and ephemeral technologies that
drift in and out of popularity over time.</p>

<h2 id="knowledge-that-doesnt-expire">Knowledge that doesn’t expire</h2>
<p>Software engineers with a traditional computer science background learn things
that never expire with age: data structures, algorithms, compilers,
distributed systems, etc. But most of us don’t work with these concepts
directly. Abstractions and frameworks are built on top of these well studied
ideas so we don’t have to get into the nitty-gritty details on the job
(at least most of the time). Examples are the C++ standard library which
implements optimized sorting for arrays, and Apache Spark which provides fault
tolerant cluster computing out of the box.</p>

<h2 id="knowledge-that-does-expire">Knowledge that does expire</h2>
<p>The unavoidable ephemeral knowledge one accumulates during their career comes in
many forms and this isn’t an exhaustive list:</p>

<ol>
  <li>A vogue framework or programming paradigm that falls out of favor in a couple of years.</li>
  <li>Domain knowledge in a rapidly evolving industry/field.</li>
  <li>Knowledge of proprietry technology: e.g. internal tools at your company.</li>
</ol>

<p>Knowledge of this kind can quickly transition from zealous adoption to every company who
uses said knowledge trying to sunset everything they’ve built with it.</p>

<h2 id="my-experience">My Experience</h2>
<p>I’m inclined to say I use ephemeral knowledge more than eternal knowledge to perform
my job. And then there’s the added pressure in our industry of always having to learn
new and useful things.</p>

<p>A theoretical physicist who spends a great deal of time mastering a theory and
the mathematical techniques behind it, only to see that theory rendered obsolete
by a new and improved theory several years later, is analogous to a software
engineer who spends a great deal of time mastering a web development framework,
learning its intricacies and gotcha’s, only to see that framework rendered
obsolete by a new framework several years later, leaving no more demand for
that knowledge in the labor market.</p>

<p>I relate to the physicist more than the English professor. What do you think?</p>



<p>[1] McDowell, John M. “Obsolescence of Knowledge and Career Publication Profiles: Some Evidence of Differences among Fields in Costs of Interrupted Careers.” The American Economic Review, vol. 72, no. 4, 1982, pp. 752–768. JSTOR, www.jstor.org/stable/1810015. Accessed 9 Sept. 2020.</p>

  </div></div>]]>
            </description>
            <link>https://daltyboy11.github.io/obsolescence-of-knowledge-in-software-engineering/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24428810</guid>
            <pubDate>Thu, 10 Sep 2020 04:10:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interfacing Microcontrollers with SD Card]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24428745">thread link</a>) | @peter_d_sherman
<br/>
September 9, 2020 | https://openlabpro.com/guide/interfacing-microcontrollers-with-sd-card/ | <a href="https://web.archive.org/web/*/https://openlabpro.com/guide/interfacing-microcontrollers-with-sd-card/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><img height="1" width="1" src="https://www.facebook.com/tr?id=720372835040462&amp;ev=PageView&amp;noscript=1">    <meta name="generator" content="WordPress Download Manager 3.0.4">
<a href="#content">Skip to content</a><div id="boxed-wrapper"><div id="wrapper"><header></header><main id="main"><div><section id="content"><article id="post-2339"><div><p>The secure digital card (SD) is a low cost, non-volatile memory card format developed by the SD Card Association. Since its inception back at the start of the century, the demand for this medium-sized, energy and space-efficient, the memory storage device has been growing at a fast rate. Therefore, to meet the market requirements, the SDA was set up as a non-profit organization to promote and create SD Card standards. There are various topics related to the SD card such as the different device families, speed classes, smart cards, card security and so on and it is used in various markets like digital cameras, personal computers, and embedded systems. Some of the standard variations include SD, SDHC, SDXC, SD-ultra high speed etc. The microSD is the miniaturized SD memory card format with a small form factor and is widely used in various electronic devices.<br>
What we are going to learn is the use of SD cards in an embedded system. To be specific, we will be dealing with the use of SD cards in small embedded systems.</p><h2>Circuit&nbsp;and Interfacing</h2><p>SD card has a native host interface apart from the SPI mode for communicating with master devices. The native interface uses four lines for data transfer where the microcontroller has SD card controller module and it needs separate license to use it. Since the SPI is a widely used protocol and it is available in most low-cost microcontrollers, the SPI mode is the widely used interface in low cost embedded systems. The working voltage range of SD family is 2.7V to 3.6V and this is indicated in the operation condition register (OCR).</p><p><img src="https://openlabpro.com/wp-content/uploads/2016/12/2000px-SD_Pins.svg_-1.png" alt="2000px-sd_pins-svg" width="214" height="292"></p><div id="attachment_2345"><img aria-describedby="caption-attachment-2345" src="https://openlabpro.com/wp-content/uploads/2016/12/SD-card.png" alt="sd-card" width="371" height="229" srcset="https://openlabpro.com/wp-content/uploads/2016/12/SD-card-200x124.png 200w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-300x185.png 300w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-400x247.png 400w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-600x371.png 600w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-768x475.png 768w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-800x495.png 800w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card.png 1024w" sizes="(max-width: 371px) 100vw, 371px"><p id="caption-attachment-2345">SD Card pinout</p></div><div id="attachment_2347"><img aria-describedby="caption-attachment-2347" src="https://openlabpro.com/wp-content/uploads/2016/12/SD-card-2.png" alt="sd-card-2" width="381" height="213" srcset="https://openlabpro.com/wp-content/uploads/2016/12/SD-card-2-200x112.png 200w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-2-300x168.png 300w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-2-400x223.png 400w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-2-600x335.png 600w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-2-768x429.png 768w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-2-800x447.png 800w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-2.png 1024w" sizes="(max-width: 381px) 100vw, 381px"><p id="caption-attachment-2347">MicroSD Card pinout</p></div><p>Most micro-controllers use the SPI communication protocol to interface with the SD cards. The SD cards have a microcontroller that shows their availability to the master controller(microcontroller). The micro-controller sees the SD card as an addressable sector on which read/write functions are possible. Once the microcontroller is in the SPI mode, communication between the master and the slave is done via 4 pins viz. clock, chip select, data in and data out. It should be kept in mind that throughout the communication between the two devices, the micro-controller will be sending out the clock.<br>
Most development boards have a dedicated SD card slot. But to understand the connections, let us analyze this fairly simple circuit.</p><div id="openl-2052981604"><div data-animationoffset="100%"><div><div data-link="https://openlabpro.com/online-courses/pic-microcontroller/" data-link-target="_self" data-animationoffset="100%"><div>From the very basic I/O control to the advaced SD Card interfacing, this course covers what you need to get started in Embedded Systems.<div><div><iframe src="https://player.vimeo.com/video/362065141?autoplay=0&amp;autopause=0" width="600" height="360" allowfullscreen="" title="vimeo362065141" allow="autoplay; fullscreen"></iframe></div></div></div><a href="https://openlabpro.com/online-courses/pic-microcontroller/" target="_self">Learn more about the course</a></div></div></div></div><h3>Circuit</h3><p><img src="https://openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit.png" alt="sd-card-circuit" width="506" height="284" srcset="https://openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-200x113.png 200w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-300x169.png 300w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-400x225.png 400w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-600x338.png 600w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-768x432.png 768w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-800x450.png 800w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-1024x576.png 1024w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-1200x675.png 1200w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit.png 1280w" sizes="(max-width: 506px) 100vw, 506px"></p><p>If the logic level of the microcontroller is different than the SD card, level shifter needs to be used for converting the line voltages.<br>
The MISO (master in serial out) pin should be connected to the SDI (serial data in) pin on the microcontroller.<br>
The MOSI (master out serial in) pin should be connected to the SDO (serial data out) pin on the microcontroller.<br>
The SCK (serial clock) pin should be connected to the SCK (serial clock) pin on the microcontroller.<br>
The CS (chip select) pin should be connected to the corresponding CS pin on the microcontroller or on any digital I/O pin on the microcontroller. A common ground is provided.</p><p><b>IMPORTANT NOTE</b>: While connecting the power supply, make sure that the supply is drawn from a 3.3V supply as a 5V supply would see your card go up in smoke.</p><h3>Interfacing</h3><p>Once the connections are set up, we are ready to interface our hardware with the software.<br>
Set the directions of each of the four pins correctly. While activating the SPI mode, an ideal configuration should be, mode(0,0) and the phase with input sampled at the middle of data out. Also, the clock frequency should be set in the range of 100 kHz and 400 kHz prior to initializing the card. Once the initialization is done, the clock can be set to a more desired frequency.</p><h2>SD Commands</h2><p>Next comes the tricky part, initializing the SD card and performing the raw data communication. A systematic approach to programming the software would make the task pretty easy.<br>
But first, it is important to learn how the micro-controller activates the SD card. There are a fixed set of commands and responses, which must be followed to create a command to response structure in our program. The data is transmitted in a byte-oriented format with a definite length.<br>
The following table shows the necessary<b> commands</b> to the card and the corresponding response from the card.</p><p><img src="https://openlabpro.com/wp-content/uploads/2016/12/SD-card-3.png" alt="sd-card-3" width="507" height="1118" srcset="https://openlabpro.com/wp-content/uploads/2016/12/SD-card-3-136x300.png 136w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-3-200x441.png 200w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-3-400x882.png 400w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-3-464x1024.png 464w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-3-600x1323.png 600w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-3-768x1694.png 768w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-3-800x1765.png 800w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-3-1200x2647.png 1200w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-3.png 1274w" sizes="(max-width: 507px) 100vw, 507px"></p><p>Every command has a constant length of 6 bytes.<br>
The first byte is the addition of the command number and the number 64.<br>
<b>Example</b>:<br>
For CMD0: command number 0 + 64 = 64 = 0x40 in hexadecimal.<br>
For CMD1: command number 1 + 64 = 65 = 0x41 in hexadecimal.<br>
And so on.<br>
This is followed by a set of four bytes which are known as the arguments. These arguments usually contain the address of a data or the length of a block.<br>
The last byte is the CRC (Cyclic Redundancy Check) Byte. Most commands in the SPI mode does not require a check byte if the CRC feature isn’t enabled. For some commands like CMD0, the CRC is 0x95 and in most cases, a 0xFF is sent. Enabling the CRC requires you to send the correct check byte from the micro-controller. So, ensure whether the CRC feature is enabled or disabled.<br>
A <b>command frame</b> looks like this-</p><p><img src="https://openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-800x267.png" alt="Interfacing Microcontrollers with SD Card - Command frame" width="800" height="267" srcset="https://openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-200x67.png 200w, https://openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-300x100.png 300w, https://openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-400x133.png 400w, https://openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-600x200.png 600w, https://openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-768x256.png 768w, https://openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-800x267.png 800w, https://openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-1024x342.png 1024w, https://openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-1200x400.png 1200w, https://openlabpro.com/wp-content/uploads/2016/12/Clr_frame1.png 1280w" sizes="(max-width: 800px) 100vw, 800px"></p><p>The card will receive a command when the DO pin (Data Out) is driven high as shown above. The CS pin (Chip Select) must be driven high to low before sending the command and must be kept low during the process. The time between a command and its response is known as the command response time (NCR). As mentioned earlier, regarding the clock pulses from the micro-controller, the corresponding response byte sent back from the card to the microcontroller should be driven by the serial clock pulses of the micro-controller. There is a chance that the response byte from the card might get skipped by the microcontroller due to the absence of a driving clock pulse. Hence it is necessary to make sure that an 8-Bit clock pulse is sent to the Card soon after the Command Frame is sent (Refer the <b>TECHNICAL NOTE </b>below). Also while receiving a Byte from the card, the DI pin (Data In) must be driven high.</p><p>Furthermore, let us analyze the different<b> types of responses</b> that we get from the card and what they mean.</p><p><img src="https://openlabpro.com/wp-content/uploads/2016/12/Response_Color-1.jpg" alt="response_color" width="568" height="289"></p><p>An R1 response, 0x01 means that the command sent prior to the response has resulted in the card going into an idle state.<br>
A response byte 0x00 means that the command has been accepted and the card will be waiting for the proposed event to take place. If any other bits in an R1 response is set, it is the result of an error and it’ll be down to the factor mentioned in each R1 response bit in the figure.</p><h2>Initializing&nbsp;the SD Card</h2><p>Now, as far as sending the commands are concerned, there is an order in which they must be sent. Only the commands, CMD0, CMD1, ACMD41, CMD58 and CMD59 will be accepted when the card is in its idle state. Sending any other command will likely to yield an illegal response.</p><p><b>TECHNICAL NOTE</b>: After interfacing the card, the micro-controller must always send a set of bytes, which we will refer to as dummy bytes. One dummy byte is 0xFF. These dummy bytes have a simple yet significant purpose. Prior to the initialization, the card must know the frequency at which the data is being sent. By sending around 75 dummy bits approximately (dummy byte * 10 times = 80 bits), the card will be ready for communication. Also even after every command is sent, it is a good practice to send at least one dummy byte. A logical explanation for this is that communication is driven by the clock pulse of the micro-controller. The clock pulse is sent only when the data buffer is filled. After every response is sent and prior to the next command or between command and response, the SCK will stop generating pulses due to an empty data buffer. To ensure the continual transmission of clock pulses between every command, fill the data buffer with a junk value such as a dummy byte. To create a dummy byte function with the number of loops as the argument.</p><p>The<b> first command</b> to be sent to the card is the <b>CMD0</b> command. The structure of every other command-response should be based on this model.</p><ul><li>Drive the DO pin high.</li><li>Drive the CS pin from high to low.</li><li>Send a dummy byte.</li><li>Then send the following 6-byte command continuously<br>
First byte: 0x40<br>
Next four bytes: 0x00000000<br>
CRC byte: 0x95</li></ul><ul><li>Send another dummy byte or as many as required, to generate the SCK giving time for the SD card to respond to the command request.</li><li>Wait for the receive flag bit to set and then read the response from the SD card or create a loop to read the response a few number of times. The response should reach back within the command to response (Ncr) time. Or else, something must be wrong.</li></ul><ul><li>The desired response is 0x01, meaning the card is in the idle state and we are good to go.</li></ul><p>Send the <b>CMD8</b> command next to check the version of your SD card.<br>
The difference in the 6-byte commands are<br>
First byte: 0x48<br>
Next four bytes: 0x000001AA<br>
CRC byte: 0x87</p><p>We are looking for two possibilities in our response byte. Either 0x01 or 0x05.</p><p>A 0x01 response means that you have a version 2 SD card. The 0x01 response is followed by the 4 bytes 0x00, 0x00, 0x01, 0xAA in the order of their transmission from the SD card which is, in fact, the argument you send in your command.</p><p>If the response is 0x05, it means the card is a version 1 or an MMC card. If the card is actually a version 2 SD card, then this response is the result of an illegal command. Also, the card is now in the idle state.</p><p>Once the above two commands (CMD0 and CMD8) are done, it is safe to say that our SD Card is working in good condition and ready for data Read/Write.<br>
Additionally, just to ensure whether the SD Card is functioning in the correct working voltage, send the <b>CMD58</b> Command.</p><p>Next, we must initiate the i<b>nitialization</b> process. For this send a <b>CMD1</b> command and wait for response 0x00, meaning the idle state bit is cleared.<br>
If you are using an SDC or for the purpose of creating a general code, it is …</p></div></article></section></div></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://openlabpro.com/guide/interfacing-microcontrollers-with-sd-card/">https://openlabpro.com/guide/interfacing-microcontrollers-with-sd-card/</a></em></p>]]>
            </description>
            <link>https://openlabpro.com/guide/interfacing-microcontrollers-with-sd-card/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24428745</guid>
            <pubDate>Thu, 10 Sep 2020 03:55:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On moving away from a six figure consultancy to becoming an indie hacker]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24428473">thread link</a>) | @jv22222
<br/>
September 9, 2020 | https://matteomosca.io/how-covid-and-a-kick-scooter-turned-me-into-an-indie-hacker | <a href="https://web.archive.org/web/*/https://matteomosca.io/how-covid-and-a-kick-scooter-turned-me-into-an-indie-hacker">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://matteomosca.io/how-covid-and-a-kick-scooter-turned-me-into-an-indie-hacker</link>
            <guid isPermaLink="false">hacker-news-small-sites-24428473</guid>
            <pubDate>Thu, 10 Sep 2020 02:52:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Invoke HTTP without waiting in AWS Lambda]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24428421">thread link</a>) | @johmiller390
<br/>
September 9, 2020 | https://www.sensedeep.com/blog/posts/stories/lambda-fast-http.html | <a href="https://web.archive.org/web/*/https://www.sensedeep.com/blog/posts/stories/lambda-fast-http.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div class="page"><div><p><time datetime="2020-09-07T05:48:00+10:00">Sep 7, 2020</time></p><p><img src="https://www.sensedeep.com/images/direct-connect.jpg" alt="direct-connect"></p><p>What is the fastest way to invoke a HTTP/REST URL from an AWS Lambda?</p><p>The answer is pretty straight forward if you need a response. But what if you don't want to wait for a reply?</p><h2 id="non-waiting-http">Non-Waiting HTTP</h2><p>Consider the case of a Lambda function that after processing, accumulates some metrics and then emits those back to a REST aggregator service for processing. If the metrics are counters, it may not matter if the metrics request fails occasionally, as the next request will send the updated counter totals. In cases like these, it will be faster not to wait for the HTTP response.</p><blockquote><p>So how would we do this in NodeJS?</p></blockquote><p>Let's look first at a naive example request (without error handling) where we wait for the response.</p><p>Just for this example, we'll create an async "request" node function that returns a promise that we can wait on.</p><pre><code>const https = require('https')
const URL = require('url')

async function request(url, data) {
    return new Promise((resolve, reject) =&gt; {
        let req = https.request(URL.parse(url), function (res) {
            let body = ''
            res.on('data', (chunk) =&gt; { body += chunk })
            res.on('end', () =&gt; { resolve(body) })
        })
        req.write(data)
        req.end()
    })
}</code></pre><p>Our Lambda would then look like:</p><pre><code>exports.handler = async (event, context) {
    ...
    let result = await request('https://metric-service.com', metrics)
    return result
}</code></pre><p>To invoke our HTTP request inside a Lambda, we use "await" which issues the request and then waits for the response.</p><p>If the metric aggregator service takes 950 milliseconds to process the request and return a status code we will be billed for an additional second on every invocation. During this wait time, our Lambda function is asleep, but AWS is still billing us for that time. With AWS Lambda, you are billed for elapsed time, not for utilized CPU time. While Lambda is extraordinarily cheap, with high transaction volumes, these short waits of 950 milliseconds can add up to a significant bill.</p><h2 id="dont-wait">Don't Wait</h2><p>So what happens if we simply do not call "await" and thus not wait on the response from our HTTP request?</p><pre><code>exports.handler = async (event, context) {
    /* nowait */ request('https://example.com', metrics)
    return 'done'
}</code></pre><blockquote><p>Strange things happen.</p></blockquote><p>Sometimes the request is sent and sometimes the request is not.</p><p>Sometimes the request is received immediately by the metrics aggregator and sometimes the request is received after our Lambda next runs. What is happening?</p><h2 id="freezing-lambda-containers">Freezing Lambda Containers</h2><p>Lambda functions run inside an AWS Firecracker container. When you return from your Lambda function, AWS immediately freezes the container and its global state. When the Lambda is next invoked, it will thaw the container to service the new invocation.</p><p>If we send a HTTP request and that request is not fully sent over the network, if we return from the Lambda function, AWS will immediately suspend our Lambda container AND the partially sent request will be suspended as well. The request will remain frozen until the Lambda is next invoked and the Node event loop will then resume processing and the request will be fully transmitted.</p><h2 id="how-to-solve">How to Solve?</h2><p>We could try a short sleep to give time for the request to be sent? But how long should we wait.</p><pre><code>exports.handler = async (event, context) {
    /* nowait */ request('https://example.com', metrics)
    await sleep(100)
    return 'done'
}</code></pre><blockquote><p>This hardly seems reliable.</p></blockquote><h2 id="wait-for-request-transmission">Wait for Request Transmission</h2><p>The correct solution is to use the Node <strong>req.end(,,callback)</strong> API and wait until the request is fully sent, but not wait for the response to be received. Here is a sample:</p><pre><code>const https = require('https')
const URL = require('url')

async function request(url, data) {
    return new Promise((resolve, reject) =&gt; {
        let req = https.request(URL.parse(url))
        req.write(data)
        req.end(null, null, () =&gt; {
            /* Request has been fully sent */
            resolve(req)
        })
    })
}</code></pre><p>Notice that the request is resolved via the end callback on the "req" object and not on the "res" object in the previous example.</p><p>This modified request function should be invoked by our Lambda with "await". In this case, we are not waiting for the HTTP response, but rather for the request to be fully sent. This is much faster than the 750 milliseconds to receive our metrics response, typically under 20 milliseconds.</p><pre><code>exports.handler = async (event, context) {
    await request('https://example.com', metrics)
    return 'done'
}</code></pre><h2 id="alternative-design-patterns">Alternative Design Patterns</h2><p>There are many other excellent ways to avoid waiting and blocking in Lambda functions such as using Step functions, SQS queues and directly invoking Lambda functions as Events without waiting. Consider the best approach for your app, but if you must use HTTP and you don't need to wait for a response, consider the technique above to lower your wait time and AWS bill.</p><h2 id="sensedeep">SenseDeep</h2><p>Our SenseDeep serverless troubleshooting platform uses this technique in a Watcher Lambda that monitors your Lambdas, runs alarms and ingests log data. We needed the Watcher to be exceptionally fast and not wait for any REST/HTTP API requests. So the Watcher uses this non-waiting technique when sending status back to the SenseDeep service.</p><p><img src="https://www.sensedeep.com/images/sensedeep/lambda-show.png" alt="SenseDeep Troubleshooting"></p><p>To learn more about the SenseDeep Serverless Troubleshooting platform and try it for free, please go to: <a href="https://www.sensedeep.com/">https://www.sensedeep.com</a>.</p><p>Please let me know if you have any comments using similar or different techniques. <a href="mailto:support@sensedeep.com">support@sensedeep.com</a>.</p><h2 id="references">References</h2><p>Here are some other good reads about Lambda and AWS asynchronous programming.</p><ul><li><p>Node event loop freezing: <a href="https://levelup.gitconnected.com/avoiding-the-pitfalls-of-async-node-js-functions-in-aws-lambda-941220582e7a">https://levelup.gitconnected.com/avoiding-the-pitfalls-of-async-node-js-functions-in-aws-lambda-941220582e7a</a></p></li><li><p>Lambda Billing: <a href="https://www.jeremydaly.com/serverless-tip-dont-overpay-when-waiting-on-remote-api-calls/">https://www.jeremydaly.com/serverless-tip-dont-overpay-when-waiting-on-remote-api-calls/</a></p></li><li><p>Async programming: <a href="https://read.acloud.guru/save-time-and-money-with-aws-lambda-using-asynchronous-programming-3548ea65f751">https://read.acloud.guru/save-time-and-money-with-aws-lambda-using-asynchronous-programming-3548ea65f751</a></p></li><li><p>Perils of step functions: <a href="https://blog.scottlogic.com/2018/06/19/step-functions.html">https://blog.scottlogic.com/2018/06/19/step-functions.html</a></p></li><li><p>Invoke Lambda async: <a href="https://docs.aws.amazon.com/lambda/latest/dg/invocation-async.html">https://docs.aws.amazon.com/lambda/latest/dg/invocation-async.html</a></p></li><li><p>Lambda invocation overview: <a href="https://docs.aws.amazon.com/lambda/latest/dg/lambda-invocation.html">https://docs.aws.amazon.com/lambda/latest/dg/lambda-invocation.html</a></p></li></ul></div></div></div></div></div>]]>
            </description>
            <link>https://www.sensedeep.com/blog/posts/stories/lambda-fast-http.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24428421</guid>
            <pubDate>Thu, 10 Sep 2020 02:42:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A career cold start algorithm]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24428353">thread link</a>) | @enigmatic0202
<br/>
September 9, 2020 | https://boz.com/articles/career-cold-start | <a href="https://web.archive.org/web/*/https://boz.com/articles/career-cold-start">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><p>Several times in my career, I’ve joined a team whose work was already well
under way, where I had a massive knowledge deficit, and didn’t have
pre-existing relationships. None of those excuses relieved me from the pressure
I felt to establish myself and contribute. Over time, I realized that the
natural instinct to push for early impact leads many incoming leaders into
challenging relationships as they expose their knowledge deficit and waste
time. So, I developed an algorithm that has helped me ramp up quickly — and
in several cases — have an impact in a relatively short period of time, while
minimizing collateral damage.</p>
<p>The first step is to find someone on the team and ask for 30 minutes with them.
In that meeting you have a simple agenda:</p>
<ul>
<li>For the first 25 minutes: ask them to tell you everything they think you
should know. Take copious notes. Only stop them to ask about things you don’t
understand. Always stop them to ask about things you don’t understand.</li>
<li>For the next 3 minutes: ask about the biggest challenges the team has right
now.</li>
<li>In the final 2 minutes: ask who else you should talk to. Write down every
name they give you.</li>
</ul>
<p>Repeat the above process for every name you’re given. Don’t stop until there
are no new names.</p>
<p>The sum of the answers from the first 25 mins will not give you a complete
picture of the team’s work. That will take months to develop. But they will
give you a framework for integrating new information more quickly, which will
speed up how fast you ramp. It will also heavily over index on the areas of
work under active discussion, which will help you dive in productively to the
most critical discussions immediately. The nature of what people choose to
discuss is a very valuable signal about the problems the team face, as it may
be about the work, the organization, or process. Finally, it will give you a
sense of the language and terminology that can very often be a barrier to
working smoothly with teams.</p>
<p>The answers from the second question give you a cheat sheet on how to impress
the team with early positive impact. Some of the things you’ll hear will take
time to fix, such as “we need a bigger team” or “our infrastructure isn’t
scaling.” Those are important and it will be good for the team to hear you
internalize those challenges. But a surprising number of the issues you’ll
hear repeatedly will be things you can easily help with, like “we waste a
bunch of time in meetings every week” or “we need a dedicated conference
room.” I start with the latter as quickly as I can because those are the
types of things teams often neglect to prioritize, in spite of a compounding
negative impact on progress.</p>
<p>The third question will give you a valuable map of influence in the
organization. The more often names show up and the context in which they show
up tends to provide a very different map of
the organization than the one in the <a href="http://boz.com/articles/damn-the-org-chart.html">org chart</a>.</p>
<p>For all the value I just described, the greatest value in this process isn’t
in the answers — it is in the asking. Taking these meetings and listening
shows proper respect for the team that’s in place. It can be hard to remember,
but while you may be insecure about taking a new role because you feel like
you’re at a disadvantage, the people you’re speaking with may also be unsure
about you taking that role and what it means for them. Demonstrating mutual
respect builds the trust required to make progress.</p></section></div></div>]]>
            </description>
            <link>https://boz.com/articles/career-cold-start</link>
            <guid isPermaLink="false">hacker-news-small-sites-24428353</guid>
            <pubDate>Thu, 10 Sep 2020 02:30:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[North Paw is an anklet that tells the wearer which way is North]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24428288">thread link</a>) | @bobbiechen
<br/>
September 9, 2020 | https://sensebridge.net/projects/northpaw/ | <a href="https://web.archive.org/web/*/https://sensebridge.net/projects/northpaw/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">

<div id="blog-body">

	

	<div id="content">

				<div id="post-5">
		<h2>North Paw</h2>
			<div>
				<p><a href="https://sensebridge.net/projects/northpaw/?page_id=40">Order</a> | <a href="http://sensebridge.net/projects/northpaw/instructions">Assembly Instructions</a> | <a href="https://sensebridge.net/projects/northpaw/?page_id=43">Downloads</a></p>
<p><a href="http://sensebridge.net/wp-includes/images/instructions/V1p6/final/Final009_large.JPG"><img src="http://sensebridge.net/wp-includes/images/instructions/V1p6/final/Final009.JPG" alt="Assembled North Paw V1.6"></a>A North Paw is an anklet that tells the wearer which way is North. The anklet holds eight cellphone vibrator motors around your ankle. A control unit senses magnetic north and turns on and off the motors. At any given time only one motor is on and this motor is the closest to North. The skin senses the vibration, and the wearer’s brain learns to associate the vibration with direction, giving the wearer an intuitive sense of which way is North. Most people “get it” mere seconds after putting it on, and can then reliably point north when asked.</p>
<p>What makes it way more awesome than a regular compass? Persistence. With a regular compass the owner only knows the direction when he or she checks it. With this compass, the information enters the wearer’s brain at a subconscious level, giving the wearer a true feeling of absolute direction, rather than an intellectual knowledge as with a regular compass.</p>
<p>Because of the plasticity of the brain, it has been shown that most wearers gain a new sense of absolute direction, giving them a superhuman ability to navigate their surroundings. The original idea for North Paw comes from research done at University of Osnabrück in Germany. In this study, rather than an anklet, the researchers used a belt. They wore the belt non-stop for six weeks, and reported successive stages of integration. </p>
<p>The North Paw kit comes with everything that you will need to build a fully functional compass anklet. This includes a circuit board, through-hole components, 8 pager motors, an enclosure, a battery pack, and a comfortable fabric anklet to hold it all on your ankle.  Plus bragging rights after you finish building it, of course.  Take a look at the <a href="http://sensebridge.net/projects/northpaw/instructions/">assembly instructions</a>.</p>
<p>If you want to order a North Paw V2.0 kit, please check out the <a href="https://sensebridge.net/projects/northpaw/?page_id=40">Order</a> page, where you’ll get all the details. &nbsp;Each North Paw V2.0 Kit costs $149 (incl. the lithium polymer battery and integrated charger) plus shipping and handling.</p>
<p>If you’re interested in receiving (very low frequency) updates about the North Paw, such as details of any new versions we create, please add yourself in the following form:</p>



				
			</div>
		</div>
				</div>





</div>
</div></div>]]>
            </description>
            <link>https://sensebridge.net/projects/northpaw/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24428288</guid>
            <pubDate>Thu, 10 Sep 2020 02:20:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Plotting Reddit Comment Trends with Pandas]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24428149">thread link</a>) | @m4rtyr
<br/>
September 9, 2020 | https://sshawarma.github.io/posts/2020/09/plotting-reddit-comment-trends-with-pandas/ | <a href="https://web.archive.org/web/*/https://sshawarma.github.io/posts/2020/09/plotting-reddit-comment-trends-with-pandas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>Hey there!</p>
<p>I wanted to learn more about Pandas, a Python library for data analysis, so I decided to embark on a mini-project to experiment with it. If you use Reddit, you’ve probably seen a chain of comments like below:</p>
<p><img src="https://sshawarma.github.io/reddit-comment-chain.png" alt=""></p>
<p>Clearly, you can see that there’s a pattern in the number of upvotes. Every reply to the parent comment receives less upvotes compared to the previous reply. It would be interesting to create a bar graph, comparing the number of upvotes the parent comment received, the number of upvotes the first reply received, the number of upvotes the second reply received, …, the number of upvotes the <code>nth</code> reply received. Using Reddit’s API and Pandas, I implemented a program that would do just that. You can find it on GitHub <a href="https://github.com/sshawarma/comment_analyzer">here</a>.</p>
<p>First, we need to import the following:</p>
<div><pre><code data-lang="python"><span>import</span> praw
<span>import</span> pandas <span>as</span> pd
<span>import</span> matplotlib.pyplot <span>as</span> plt
<span>import</span> sys
<span>import</span> math
<span>from</span> concurrent.futures <span>import</span> ThreadPoolExecutor
</code></pre></div><p>PRAW is a Python wrapper for Reddit’s API. <code>matplotlib</code> is a library for creating static, animated, and interactive visualizations in Python. These imports will become clearer as we move on.</p>
<p>Next, we need to define authenticate to Reddit’s API. PRAW allows us to do this pretty easily with OAuth2:</p>
<div><pre><code data-lang="python"><span># Authenticate using our client secret</span>
<span>def</span> <span>authenticate</span>():
    <span>with</span> open(<span>'client_secret.txt'</span>, <span>'r'</span>) <span>as</span> f:
        data <span>=</span> f<span>.</span>read()<span>.</span>split()
        CLIENT_ID <span>=</span> data[<span>0</span>]
        CLIENT_SECRET <span>=</span> data[<span>1</span>]

    <span>return</span> praw<span>.</span>Reddit(client_id<span>=</span>CLIENT_ID,
                    client_secret<span>=</span>CLIENT_SECRET,
                    user_agent<span>=</span>USER_AGENT)
</code></pre></div><p>In this case, the client ID and client secret is stored in a file (called <code>client_secret.txt</code>). We read this and return an instance of PRAW’s <code>Reddit</code> class, which allows us to interact with Reddit’s APIs.</p>
<p>Now, we break down what we have to do in logical chunks. First, we need to get a list of submissions, so that we can look at the comments under each post. PRAW allows us to get a list of the hottest submissions from r/all, which is basically an amalgamation of a bunch of submissions from different subreddits:</p>
<div><pre><code data-lang="python"><span>def</span> <span>get_submission_upvotes</span>(reddit, m, n):
    upvotes_list <span>=</span> []
    submissions <span>=</span> list(reddit<span>.</span>subreddit(<span>'all'</span>)<span>.</span>hot(limit<span>=</span>m))
    <span>with</span> ThreadPoolExecutor() <span>as</span> executor:
        futures <span>=</span> [executor<span>.</span>submit(count_upvotes, submissions[i], n) <span>for</span> i <span>in</span> range(<span>0</span>, m)]
        [upvotes_list<span>.</span>append(future<span>.</span>result()) <span>for</span> future <span>in</span> futures]
    <span>return</span> upvotes_list
</code></pre></div><p>The reason we use <code>concurrent.futures</code> is because, depending on the length of the comment chain we are examining, we might end up taking very long to collect upvotes on one submission but a very short time to collect upvotes on another submission (we will see what the <code>count_upvotes</code> function does next). Here, <code>m</code> represents the number of submissions to look at and <code>n</code> represents the number of comments in a comment chain to examine.</p>
<p>Next, we need to count the number of upvotes of each comment in a comment chain in each submission. This can be done as follows:</p>
<div><pre><code data-lang="python"><span>def</span> <span>count_upvotes</span>(submission, n):
    upvotes <span>=</span> []
    submission<span>.</span>comments<span>.</span>replace_more(limit<span>=</span><span>0</span>)

    count <span>=</span> <span>0</span>
    comment <span>=</span> submission<span>.</span>comments[<span>0</span>]
    <span>while</span> count <span>&lt;</span> n:
        upvotes<span>.</span>append(comment<span>.</span>score)
        count <span>+=</span> <span>1</span>
        <span>if</span> len(comment<span>.</span>replies) <span>&gt;</span> <span>0</span>:
            comment <span>=</span> comment<span>.</span>replies[<span>0</span>]
        <span>else</span>:
            <span>break</span>

    <span>while</span> len(upvotes) <span>&lt;</span> n:
        upvotes<span>.</span>append(float(<span>'nan'</span>))
    <span>return</span> upvotes
</code></pre></div><p>In essence, we get the top comment and keep examining each reply until we have gotten <code>n</code> comments or until the comment chain ends (to get more comment chains of length <code>n</code>, we can increase <code>m</code>). If the comment chain ends prematurely, we add <code>nan</code> (Not a Number) to indicate that no data was collected for the particular reply in the comment chain because that reply did not exist (the comment chain ended, so there were no more upvotes to count).</p>
<p>After counting the upvotes of each comment in the top comment chain, we only have to process the data. First, we compute the average number of upvotes for the top comments, the 1st reply, the 2nd reply, etc:</p>
<div><pre><code data-lang="python"><span>def</span> <span>compute_data</span>(upvotes_list):
    avg_upvotes <span>=</span> []
    <span>for</span> col <span>in</span> range(<span>0</span>, len(upvotes_list[<span>0</span>])):
        avg <span>=</span> <span>0.0</span>
        n <span>=</span> len(upvotes_list)
        <span>for</span> row <span>in</span> range(<span>0</span>, len(upvotes_list)):
            <span>if</span> math<span>.</span>isnan(upvotes_list[row][col]) <span>==</span> False:
                avg <span>+=</span> upvotes_list[row][col]
            <span>else</span>:
                n <span>-=</span> <span>1</span>
        <span>if</span> n <span>&gt;</span> <span>0</span>:
            avg_upvotes<span>.</span>append(avg <span>/</span> n)
        <span>else</span>:
            avg_upvotes<span>.</span>append(<span>0</span>)
    <span>return</span> avg_upvotes
</code></pre></div><p>We return a list called <code>avg_upvotes</code>, which contains the average number of upvotes for the top comment, first reply, second reply, etc. We now convert this list into a bar graph:</p>
<div><pre><code data-lang="python"><span>def</span> <span>render_data</span>(avg_upvotes, n):
    <span># Solution from https://stackoverflow.com/questions/9647202/ordinal-numbers-replacement</span>
    ordinal <span>=</span> <span>lambda</span> n: <span>"</span><span>%d%s</span><span>"</span> <span>%</span> (n,<span>"tsnrhtdd"</span>[(n<span>//</span><span>10</span><span>%</span><span>10</span><span>!=</span><span>1</span>)<span>*</span>(n<span>%</span><span>10</span><span>&lt;</span><span>4</span>)<span>*</span>n<span>%</span><span>10</span>::<span>4</span>])
    x <span>=</span> [str(ordinal(i)) <span>for</span> i <span>in</span> range(<span>0</span>, n)]
    df <span>=</span> pd<span>.</span>DataFrame({<span>'Comment Reply Number'</span>: x, <span>'Average Upvotes'</span>: avg_upvotes})
    df<span>.</span>plot<span>.</span>bar(x<span>=</span><span>'Comment Reply Number'</span>, y<span>=</span><span>'Average Upvotes'</span>, rot<span>=</span><span>0</span>, legend<span>=</span>False)
    plt<span>.</span>xlabel(<span>'Comment Reply Number'</span>)
    plt<span>.</span>ylabel(<span>'Average Upvotes'</span>)
    plt<span>.</span>xticks(size<span>=</span><span>4</span>)
    plt<span>.</span>yticks(size<span>=</span><span>4</span>)
    plt<span>.</span>show()
</code></pre></div><p>Now all we have to do is put it together:</p>
<div><pre><code data-lang="python"><span>if</span> __name__ <span>==</span> <span>'__main__'</span>:
    <span>if</span> len(sys<span>.</span>argv) <span>&lt;</span> <span>3</span>:
        <span>print</span>(<span>'./comment_analyzer.py [number of submissions to analyze] [number of comments]'</span>)
        exit()
    m <span>=</span> int(sys<span>.</span>argv[<span>1</span>])
    n <span>=</span> int(sys<span>.</span>argv[<span>2</span>])
    reddit <span>=</span> authenticate()
    upvotes_list <span>=</span> get_submission_upvotes(reddit, m, n)
    avg_upvotes <span>=</span> compute_data(upvotes_list)
    render_data(avg_upvotes, n)
</code></pre></div><p>The program takes two parameters: the number of submissions to look at and the “depth” of the comment chain we have to look at.</p>
<p>Running the program (assuming you have the necessary libraries installed with Python 3.6+), you get a bar graph like so:</p>
<p><img src="https://sshawarma.github.io/pandas.png" alt="a right-skewed bar graph"></p>
<p>(The “0th” comment represents the top comment).</p>
<p>The above graph allows us to visualize the distribution of upvotes on comments on Reddit. Clearly, the distribution is right-skewed: the number of upvotes diminish as we get deeper down the reply chain. This is to be expected, since the top comment tends to be seen first.</p>
<p>Hopefully, you can see how tools like Pandas and PRAW allow us to collect data and visualize it.</p>

      </div></div>]]>
            </description>
            <link>https://sshawarma.github.io/posts/2020/09/plotting-reddit-comment-trends-with-pandas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24428149</guid>
            <pubDate>Thu, 10 Sep 2020 01:59:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Signs Your Team Is Suffering from 'Burnout Debt']]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24427973">thread link</a>) | @doorknobguy
<br/>
September 9, 2020 | https://www.usehaystack.io/blog/3-signs-your-team-is-suffering-from-burnout-debt | <a href="https://web.archive.org/web/*/https://www.usehaystack.io/blog/3-signs-your-team-is-suffering-from-burnout-debt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-w-id="0ea0c8ae-8333-a516-8908-f86a85ef9373"><blockquote>One of my key goals this month is to make sure we're not burning ourselves out. We've got a lot of priorities but there's no need to stretch ourselves thin and run the risk of longer-term issues.<p>- Jean Vincent (CTO, Lytehouse)</p></blockquote><p>‍</p><p>Unhealthy working patterns can build up over time and create longer-term issues. </p><p>In this article, we'll be showing you signs of burnout debt - and how to recognize it before it's too late.</p><p>‍</p><h3>What is 'Burnout Debt'</h3><p>Symptoms of burnout can slowly grow on a team. As sprints go on it's easy to overlook the signs that build up over time. We refer to this build up as 'burnout debt'.</p><p>You should treat burnout debt in the same way we treat technical debt. Identify it early and take measures to reduce longer-term negative effects.</p><p>‍</p><h3>Signs of 'Burnout Debt'</h3><ol role="list"><li>Unhealthy Working Patterns</li><li>High Workloads</li><li>Spikes in Weekend Activity</li></ol><p>‍</p><h3>Sign #1: &nbsp;Unhealthy Working Patterns</h3><p>One key factor in burnout is overwork. It's important we help our teams manage their workloads and reduce burnout. If your team feels the need to work late nights and weekends - it's time to have a conversation about workloads.</p><p>This team for example consistently works late nights and weekends. This is a strong signal that your team is overworking and may approach burnout. We'll see the effect of this below.</p><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f593cd3ba2ac780cf72cc15_unsustainable-working-patterns.png" loading="lazy" alt=""></p></figure><p>‍</p><h3>Sign #2: Unusually High Workloads</h3><p>Spikes in workload can be early warning signs of burnout.</p><p>The team below was under tight deadlines - working nights and weekends. You can a large spike in Throughput followed by immediate burnout which lasted ~3 months.</p><p>This is a typical situation. We take on too much work and burn out. The following weeks remain unproductive. As leaders it's our job to make sure our teams have a more sustainable, manageable workload.</p><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f593cecff346bf77d54af02_unusually-high-workload.png" loading="lazy" alt=""></p></figure><p>‍</p><h3>Sign #3: Spikes in Weekend Activity</h3><p>Large spikes in weekend activity can be an incredibly high signal for overworked. Are your current tasks too much to handle in a week? Did we poorly estimate that workload? Is the workload unmanageable?</p><p>As engineering leaders we have to protect our team from situations like that which can cause long term effects to team morale, culture, and overall productivity. As we saw in the image above, the effects of burnout can be long lasting and in some cases can lead to the highest cost for an engineering team - turnover.</p><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f593d086702304230624666_high-weekend-activity.png" loading="lazy" alt=""></p></figure><p>‍</p><h3>Is your team accumulating 'burnout debt'?</h3><p>Just like technical debt, burnout debt silently builds up in the background. As it accumulates it not only gets harder to resolve but it's impact becomes more severe.</p><p>When left unchecked 'burnout debt' impacts team culture, creates an environment of overwork, and degrades trust among the team. At an individual level it decreases satisfaction, happiness, and productivity while boiling up to team-wide frustration, low morale, and high turnover.</p><p>So.. Is your team affected by burnout debt?</p><p>‍</p><h3>What should I do about it?</h3><p>It’s important to identify these signs early so you can intervene. Luckily, there are ways to identify and resolve burnout debt.</p><p>‍</p><h5>Make it a ritual</h5><p>The first step is having conversations around workload and sustainability. Make it a recurring ritual. At Haystack we bring this up every week. We're constantly adjusting workloads and introducing new, challenging work - to combat burnout.</p><p>‍</p><h5>Get data-driven</h5><p>As engineers, we often feel productive (and happy) when we're pushing new features. There's a certain rush to grabbing a coffee, throwing on some headphones, and getting that #todo closed out - even if it takes staying up late to do it.</p><p>Unfortunately, this makes it difficult to see or address burnout debt. In the moment, we feel great about the work we did - unknowingly allowing burnout debt to build over time. What feels great now build up in the background and soon enough you'll start feeling burnt out.</p><p>In this case, having data helps quite a bit. Being able to see trends and alert on them helps us catch burnout debt before it's too late. It also gives us a more objective picture on what our typical workload looks like so we can make sure to keep it in check.</p><p>‍</p><h3>Stop taking on 'Burnout Debt'</h3><p>If you're managing a team and you want them to be motivated, happy, and productive then burnout should be a key item to address. Just like technical debt, burnout debt can eat at teams and cause an undertone of frustration. It's not always easy to catch but if you're looking in the right direction you'll be able to spot the signs and address it before it's too late.</p><p>Of course, Haystack can help too. If you'd like to see your team's typical bandwidth, working patterns or if they are experiencing signs of burnout debt <a href="https://usehaystack.io/">sign up for Haystack</a>.</p><p>‍</p><p>‍</p><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f5123c19bb423a1492c778d_Haystack_Designed_Presentation.png" loading="lazy" alt=""></p></figure><p><a href="https://usehaystack.io/?utm_source=blog&amp;utm_medium=subscription-sequence&amp;utm_campaign=3-ways-to-identify-blockers">Haystack</a> helps engineering leaders identify burnout and team health patterns. Instead of guessing if you're improving, or constantly bothering your team for updates, simply use Haystack to get alerts in your inbox every morning. Plus a dashboard to track improvements over time.</p><p><a href="https://usehaystack.io/?utm_source=blog&amp;utm_medium=subscription-sequence&amp;utm_campaign=3-ways-to-identify-blockers">Try it for free</a></p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.usehaystack.io/blog/3-signs-your-team-is-suffering-from-burnout-debt</link>
            <guid isPermaLink="false">hacker-news-small-sites-24427973</guid>
            <pubDate>Thu, 10 Sep 2020 01:30:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The 3-Day Domain Name Rule]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24427934">thread link</a>) | @stanislavb
<br/>
September 9, 2020 | https://stanbright.com/3-day-rule/ | <a href="https://web.archive.org/web/*/https://stanbright.com/3-day-rule/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      <div>
        

<p>I will share one of my little “secrets” that have saved me hundreds
or thousands of dollars - “The 3 Day Domain Name Rule”.</p>

<p><strong>The Rule</strong></p>
<blockquote>
  <p>Whenever you have an idea of a great domain name,
wait for 3 days, at least, before buying it.</p>
</blockquote>

<p>It’s that simple. However, be warned, there might be an uneasy feeling
that someone is going to grab the domain before you. It will be haunting you
on the back of your mind. You have to resist it and stick to the rule.
Both your future self and your money will thank you.</p>

<p>Also, you could be thinking “<em>But, it’s only $8.95</em>”. Yet, <strong>it’s more</strong>. Usually, a few times more.
Let me tell you why. We, people, hate losing things that we own.
Hence, once you own the domain and have put your credit card in, it is very very likely
you will be paying for that name for a few years. Domain registrars
are aware of that, too. That’s why the registration price, on many platforms, is
%30 - %50 less compared to the following up renewals.</p>

<p>Here it is an example with GoDaddy: Reg $12; Renewal: $18 (+50%).</p>

<p><img src="https://stanbright.com/assets/images/posts/3-day-rule/godaddy-dotcom-price-2020.png" alt="3-day-rule/godaddy-dotcom-price-2020.png"></p>

<p>I’d say that you will keep your shiny new domain, on average, for 3 years at least.<br>
That makes ~$50!, and NOT $11.99.</p>

<p><strong>.io</strong> domains are the worst. First, they are heaps more expensive - $54 to reg it
and $60 to renew =&gt; a $174 <a href="https://stanbright.com/idea-ownership-cost">idea ownership cost</a>. What is more,
they seem short, trendy, and many of them are not registered yet. If you are building
a tech product, you will be lured into buying one of those. Do yourself a favour and
either try coming up with a <strong>.com</strong> name or at least apply the rule and don’t rush.</p>

<p>Now, back to the rule. At some point, after buying many domains and losing some money,
I realised that my enthusiasm for the “great” idea I had the day before would
start disappering more often than not. Only the “good” ideas stuck for longer than a few days.
Then, I came with this rule of thumb for myself - never buy a domain name without waiting for
at least 3 days after coming up with the idea of it. I’ve never had a single case when
someone else would grab the domain before me. NEVER. The closest one was about 3 months afer I had the idea.
The domain name was <em>vivanotes.com</em> if you are curious. To be honest, it felt a bit bad,
as I still had the idea written down in my notes. Yet, I will most probably never build
that project and have saved hundreds or thousands of dollars along the way.</p>

<p><strong>Why 3 days</strong>? There is no scientific reason! It’s easy to remember, it’s longer than a weekend
and it works for me.</p>



<div>
  <p>
    Stan
  </p>
  <p>
    Sep 10, 2020<br>
    // Ideas
  </p>
</div>




<hr>


      </div>
    </div>
  </div></div>]]>
            </description>
            <link>https://stanbright.com/3-day-rule/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24427934</guid>
            <pubDate>Thu, 10 Sep 2020 01:24:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Obverse and Under (2019)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24427663">thread link</a>) | @lelf
<br/>
September 9, 2020 | http://www.petecorey.com/blog/2019/09/13/obverse-and-under/ | <a href="https://web.archive.org/web/*/http://www.petecorey.com/blog/2019/09/13/obverse-and-under/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    

    <article>
        <p>I previously wrote about <a href="http://www.petecorey.com/blog/2019/08/26/prime-parallelograms/">plotting an “amazing graph”</a> using <a href="https://www.jsoftware.com/">the J programming language</a>. The solution I landed on looked something like this:</p>

<pre><code>
require 'plot'
f =: ] - [: #. [: |. #:
'type dot' plot f"0 p: i. 10000
</code></pre>

<p>Our verb, <code>f</code>, is taking a very explicit approach by making judicious use of “capped” (<a href="https://www.jsoftware.com/help/dictionary/d502.htm"><code>[:</code></a>) verb trains. We’re essentially saying that <code>f</code> is (<a href="https://www.jsoftware.com/help/dictionary/d001.htm"><code>=:</code></a>) the given number (<a href="https://www.jsoftware.com/help/dictionary/d500.htm"><code>]</code></a>) minus (<a href="https://www.jsoftware.com/help/dictionary/d120.htm"><code>-</code></a>) the base two (<a href="https://www.jsoftware.com/help/dictionary/d401.htm"><code>#.</code></a>) of the reverse (<a href="https://www.jsoftware.com/help/dictionary/d231.htm"><code>|.</code></a>) of the antibase two (<a href="https://www.jsoftware.com/help/dictionary/d402.htm"><code>#:</code></a>) of the given number.</p>

<p>Several members of the J community pointed out to me that this verb could be simplified with the help of the “under” (<a href="https://www.jsoftware.com/help/dictionary/d631.htm"><code>&amp;.</code></a>) conjunction. Let’s dig into what “under” is, and how we can use it.</p>

<h2 id="under-what">Under What?</h2>

<p>The best way to think about “under” (<a href="https://www.jsoftware.com/help/dictionary/d631.htm"><code>&amp;.</code></a>), <a href="https://code.jsoftware.com/wiki/Vocabulary/ampdot">as explained by the NuVoc page on “under”</a>, is to think in terms of <a href="https://en.wikipedia.org/wiki/Domain_of_a_function">domains</a> and transformations in and out of those domains.</p>

<blockquote>
  <p>Verb v defines a transformation of the argument(s) (x and) y into the v-domain.
Next, verb u operates on the transformed argument(s).
Lastly the result is transformed back from the v-domain to the original domain.</p>
</blockquote>

<p>In our example, the domain of our input is base ten, but the transformation we want to apply (reversal) needs to happen in the base two domain. “Under” (<a href="https://www.jsoftware.com/help/dictionary/d631.htm"><code>&amp;.</code></a>) can be used to transform our input into base two (<a href="https://www.jsoftware.com/help/dictionary/d402.htm"><code>#:</code></a>), apply our reversal (<a href="https://www.jsoftware.com/help/dictionary/d231.htm"><code>|.</code></a>), and transform the result of that reversal back to our original base ten domain with the obverse, or opposite, of our base two verb, anti base (<a href="https://www.jsoftware.com/help/dictionary/d401.htm"><code>#.</code></a>):</p>

<pre><code>
f =: ] - |. &amp;. #:
</code></pre>

<p>Notice that we’re not explicitly stating how to transform the result of our reversal back into our original domain. J knows that the obverse of <a href="https://www.jsoftware.com/help/dictionary/d402.htm"><code>#:</code></a> is <a href="https://www.jsoftware.com/help/dictionary/d401.htm"><code>#.</code></a>, and automatically applies it for us.</p>

<p>Out of the box, J comes with many obverse pairings. “Open” (<a href="https://www.jsoftware.com/help/dictionary/d020.htm"><code>&gt;</code></a>), for example, is the obverse of “box” (<a href="https://www.jsoftware.com/help/dictionary/d010.htm"><code>&lt;</code></a>), and visa versa. This pairing is especially useful when applying transformations to boxed values:</p>

<pre><code>
   1+&amp;.&gt;1;2;3
┌─┬─┬─┐
│2│3│4│
└─┴─┴─┘
</code></pre>

<p>Check out a full listing of obverse pairs <a href="https://code.jsoftware.com/wiki/Fifty_Shades_of_J/Chapter_12#Obverse_to_Adverse">at the end of this Shades of J article</a>.</p>

<h2 id="inferred-obverses">Inferred Obverses</h2>

<p>Even compound verbs built up of verbs with well-defined obverse pairings can be used with “under” (<a href="https://www.jsoftware.com/help/dictionary/d631.htm"><code>&amp;.</code></a>). J will correctly infer and apply the compound obverse without any intervention or instruction.</p>

<p>For example, if we wanted to unbox a list of values and then work with them in the “square root domain” (whatever that means), we could do something like this:</p>

<pre><code>
   1+&amp;.([:%:&gt;)1;2;3
┌────────────────┐
│4 5.82843 7.4641│
└────────────────┘
</code></pre>

<p>J takes each value, opens it and finds its square root (<code>[:%:&gt;</code>), adds one to the result, and then squares and boxes up (<code>[:*:&lt;</code>) the incremented value.</p>

<h2 id="explicit-obverses">Explicit Obverses</h2>

<p>Even more interestingly, if an obverse pairing isn’t defined or inferable for a given verb, J lets us define our own pairing using the “obverse” (<a href="https://www.jsoftware.com/help/dictionary/d311.htm"><code>:.</code></a>) verb.</p>

<p>As an example, imagine that we have a JSON string holding an array of values. We want to parse our string, perform some operation on those values, and then serialize the resulting list back into JSON.</p>

<p>We can use the <code>dec_json</code> and <code>enc_json</code> verbs provided by <a href="https://github.com/jsoftware/convert_json">the <code>convert/json</code> package</a>, and tell J that the obverse of <code>dec_json</code> is <code>enc_json</code>:</p>

<pre><code>
   json =: dec_json :. enc_json
</code></pre>

<p>Running <code>dec_json</code> on a JSON array like <code>'[1, 2, 3]'</code> will return a list of boxed numbers, so we’ll want to open each of these boxes, perform our operation, and box the results back up. This sounds like another job for “under” (<a href="https://www.jsoftware.com/help/dictionary/d631.htm"><code>&amp;.</code></a>):</p>

<pre><code>
   transform =: 1&amp;+&amp;.&gt;
</code></pre>

<p>All together, we can perform our <code>transform</code> “under” (<a href="https://www.jsoftware.com/help/dictionary/d631.htm"><code>&amp;.</code></a>) the <code>json</code> domain:</p>

<pre><code>
   transform &amp;. json '[1, 2, 3]'
[2,3,4]
</code></pre>

<p>And our result is the JSON string <code>'[2,3,4]'</code>!</p>

<p>“Under” is definitely a very powerful conjunction, and I can see myself using it extensively in the future. Thanks to everyone in the J community who was kind enough to point it out and teach me something new!</p>

    </article>
  </div></div>]]>
            </description>
            <link>http://www.petecorey.com/blog/2019/09/13/obverse-and-under/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24427663</guid>
            <pubDate>Thu, 10 Sep 2020 00:36:47 GMT</pubDate>
        </item>
    </channel>
</rss>
