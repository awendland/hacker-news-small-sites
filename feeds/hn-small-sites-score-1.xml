<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 13 Nov 2020 20:19:28 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 13 Nov 2020 20:19:28 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[The Essential Guide to Design Strategy]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068234">thread link</a>) | @mmanja
<br/>
November 12, 2020 | https://designstrategy.guide/the-ultimate-design-strategy-e-book/ | <a href="https://web.archive.org/web/*/https://designstrategy.guide/the-ultimate-design-strategy-e-book/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">

	
	

	
	<main id="main">
<div id="content" role="main">
	<div>
		<div>
			<div>
				
				
														
							<section id="section_957370157">
		

		<div>
			
<div>
<p><img src="https://designstrategy.guide/wp-content/uploads/2020/03/white-layer.png"><br>
<img src="https://designstrategy.guide/wp-content/uploads/2020/10/bg-blurb.png"></p>
<div id="row-299603387">

	

	

	<div id="col-1103953439">
		<div>
			
			
<h3>The Ultimate Design Strategy e-book</h3>
<p>Learn how to leverage design strategy to increase ROI, enhance your design‚Äôs value and much more.</p>
<p><a rel="noopener noreferrer" href="https://designstrategy.mykajabi.com/pl/237579" target="_blank">
    <span>CLAIM YOUR FREE COPY</span>
  </a>

		</p></div>
			</div>

	

	

	


</div>
		</div>

		

	</div></section>
	
	<section id="section_434841296">
		

		<div>
			
	<div>

		<div>
						<p><img width="1200" height="890" src="https://designstrategy.guide/wp-content/uploads/2020/11/Ipad-with-hand-small.gif" alt="DesignStrategyEbook" loading="lazy">											</p>
					</div>

		
	</div>
	
<div id="row-487225450">

	<div id="col-1748784608">
		<div>
			
			
	<div id="image_760246233">
								<p><img width="1020" height="427" src="https://designstrategy.guide/wp-content/uploads/2020/10/longest-white-1024x429.png" alt="" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/10/longest-white-1024x429.png 1024w, https://designstrategy.guide/wp-content/uploads/2020/10/longest-white-300x126.png 300w, https://designstrategy.guide/wp-content/uploads/2020/10/longest-white-768x322.png 768w, https://designstrategy.guide/wp-content/uploads/2020/10/longest-white-600x251.png 600w, https://designstrategy.guide/wp-content/uploads/2020/10/longest-white.png 1181w" sizes="(max-width: 1020px) 100vw, 1020px">						
					</p>
								

	</div>
	
		</div>
			</div>

	
</div>
<div id="row-1685843560">

	<div id="col-1105584655">
		<div>
			
			
<h2>Why am I giving<br>you this eBook for free?</h2>
<p>Plenty of designers and product managers feel lost and frustrated while trying to prove their product design‚Äôs value and making a tangible impact. I will show you how to leverage design strategy to raise your profit.</p>
<p>I BELIEVE THAT THERE ARE 4 THINGS TO FOCUS ON:</p>
		</div>
			</div>

	
</div>

<div id="row-851672329">

	

	

	<div id="col-1402776952">
		<div>
			
			
<p>Embrace your<br>metrics and KPIs</p>

		</div>
			</div>

	


</div>
<div id="row-1947243166">

	<div id="col-1469675148">
		<div>
			
			
	<div id="image_1452210033">
								<p><img width="1020" height="505" src="https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-1024x507.png" alt="" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-1024x507.png 1024w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-300x148.png 300w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-768x380.png 768w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-600x297.png 600w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1.png 1144w" sizes="(max-width: 1020px) 100vw, 1020px">						
					</p>
								

	</div>
	
		</div>
			</div>

	
</div>
<div id="row-233738086">

	<div id="col-632620501">
		<div>
			
			
<h3><img loading="lazy" src="https://designstrategy.guide/wp-content/uploads/2020/11/03-cut-noshadow-SMALL.png" alt="The Design Strategy E-book" width="325" height="462" srcset="https://designstrategy.guide/wp-content/uploads/2020/11/03-cut-noshadow-SMALL.png 500w, https://designstrategy.guide/wp-content/uploads/2020/11/03-cut-noshadow-SMALL-211x300.png 211w" sizes="(max-width: 325px) 100vw, 325px"></h3>
<h3><span>Why and how? </span></h3>
<p><span>That‚Äôs what I unpack in the ebook.</span></p>
<p>It‚Äôs a bull***-free guide that‚Äôll help you to create your design strategy, raise your conversion rates and implement better processes.</p>
		</div>
			</div>

	
</div>
<div id="row-823407278">

	<div id="col-1036649520">
		<div>
			
			
	<div id="image_244687897">
								<p><img width="1020" height="445" src="https://designstrategy.guide/wp-content/uploads/2020/10/line-white-1024x447.png" alt="" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/10/line-white-1024x447.png 1024w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-300x131.png 300w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-768x335.png 768w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-600x262.png 600w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white.png 1199w" sizes="(max-width: 1020px) 100vw, 1020px">						
					</p>
								

	</div>
	
		</div>
			</div>

	
</div>
<div id="row-309473329">

	<div id="col-1143919990">
		<p>
			
			
<h2>Goodies that come with this book</h2>
		</p>
			</div>

	
</div>
<div id="row-1955344219">

	

	

	<div id="col-1653086785">
		<p>Research diagrams and insights</p>
		

	</div>

	
</div>
<div id="row-1744573423">

	

	

	<div id="col-1868045590">
		<p>Links that‚Äôll expand your knowledge</p>
		

	</div>

	
</div>

<div id="row-1750670354">

	<div id="col-517151931">
		<div>
			
			
	<div id="image_2029446052">
								<p><img width="1020" height="505" src="https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-1024x507.png" alt="" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-1024x507.png 1024w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-300x148.png 300w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-768x380.png 768w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-600x297.png 600w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1.png 1144w" sizes="(max-width: 1020px) 100vw, 1020px">						
					</p>
								

	</div>
	
		</div>
			</div>

	
</div>
		</div>

		

	</section>
	
	<section id="section_1478453551">
		

		<div>
			

<div id="row-905436927">

	<div id="col-1204503576">
		<div>
			
			
<p><span>It is an eye-opener for every designer.<br>
</span></p>
<p><span>Claudia, UX designer</span></p>
		</div>
			</div>

	

	

	

	<div id="col-389252725">
		<div>
			
			
<p><span>Too many startups fail because they don‚Äôt know which part they need to focus on (UX, dev, design). This e-book showed me new methods that I need to try out. </span></p>
<p><span>Jessica, Project Manager</span></p>
		</div>
			</div>

	
</div>
	
	
<div id="row-618885592">

	<div id="col-395815769">
		<div>
			
			
<p><span>This book challenged my knowledge and showed me how and where to level up my design knowledge. Romina, thanks for choosing me to be part of your UX testing group. Plus, the design is just wow.<br></span></p>
<p><span>Monika, CMO</span></p>
		</div>
			</div>

	

	

	

	<div id="col-2032876642">
		<div>
			
			
<p><span>Now I know how to choose Design metrics. üôÇ</span></p>
<p><span>Sara, Front-End Developer</span></p>
		</div>
			</div>

	
</div>
		</div>

		

	</section>
	
	<section id="section_336754572">
		

		<div>
			
<div id="row-44495520">

	<div id="col-1803190315">
		<div>
			
			
	<div id="image_1536779616">
								<p><img width="1020" height="445" src="https://designstrategy.guide/wp-content/uploads/2020/10/line-white-1024x447.png" alt="" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/10/line-white-1024x447.png 1024w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-300x131.png 300w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-768x335.png 768w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-600x262.png 600w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white.png 1199w" sizes="(max-width: 1020px) 100vw, 1020px">						
					</p>
								

	</div>
	
		</div>
			</div>

	
</div>
<div id="row-431031104">

	<div id="col-157694071">
		<div>
			
			
<h3><span>Meet the author</span></h3>
	
	
<div id="row-117016235">

	<div id="col-104348027">
		<div>
			
			
	<div id="image_1049819035">
								<p><img width="682" height="1024" src="https://designstrategy.guide/wp-content/uploads/2020/11/03-682x1024.jpg" alt="Romina Kavcic Websi 2020" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/11/03-682x1024.jpg 682w, https://designstrategy.guide/wp-content/uploads/2020/11/03-200x300.jpg 200w, https://designstrategy.guide/wp-content/uploads/2020/11/03-768x1152.jpg 768w, https://designstrategy.guide/wp-content/uploads/2020/11/03-1024x1536.jpg 1024w, https://designstrategy.guide/wp-content/uploads/2020/11/03-600x900.jpg 600w, https://designstrategy.guide/wp-content/uploads/2020/11/03.jpg 1141w" sizes="(max-width: 682px) 100vw, 682px">						
					</p>
								

	</div>
	
		</div>
			</div>

	

	

	

	<div id="col-1991841128">
		<p><span>Romina is an award-winning Design Strategist who holds a Master of Business Administration. She has 15+ years of career experience in design work and consulting across both tech startups and several marquee tech unicorns such as Stellar.org, Outfit7, Databox, Xamarin, Chipolo, Singularity.NET, etc. She is currently advising, coaching and consulting with companies on design strategy &amp; management, visual design and user experience. Her work has been published on Forbes, Hackernews, Blockgeeks, Newsbtc, Bizjournals, and featured on Apple Store.</span></p>
			</div>

	
</div>
		</div>
			</div>

	
</div>
		</div>

		

	</section>
	

						
												</div>
		</div>
	</div>
</div>


</main><!-- #main -->

<!-- .footer-wrapper -->

</div></div>]]>
            </description>
            <link>https://designstrategy.guide/the-ultimate-design-strategy-e-book/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068234</guid>
            <pubDate>Thu, 12 Nov 2020 09:55:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Neurohacking the World Sleep Championships]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068156">thread link</a>) | @pedalpete
<br/>
November 12, 2020 | https://soundmind.co/blog/neurohacking-the-world-sleep-championships | <a href="https://web.archive.org/web/*/https://soundmind.co/blog/neurohacking-the-world-sleep-championships">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-e2b9e06d42ac6600e580"><div><p>I‚Äôm the last person you‚Äôd expect to compete in the <a href="https://www.worldsleepchampionships.com/">World Sleep Championships</a>. A life-long insomniac with Central Sleep Apnea, I‚Äôve spent the last 10 months diving into the latest in neuroscience research with the goal of not only helping insomnia sufferers, but improving Sleep Performance for the greater population.&nbsp;</p><p>The competition used the data from Oura rings which classifies sleep as REM, light or deep, and factors in the number of hours you slept, how quickly you fell asleep, and how much time you spent in each sleep state.&nbsp;</p><h3>More people have died in their sleep than during any other activity, making this the most dangerous and extreme competition that has ever taken place! </h3><p>The organizers of the World Sleep Championships decided on a tournament type structure for the competition. We started with the seeding process to get our baseline sleep data, and build the competition tree. Seeding was followed by 5 alternating nights of head-to-head competition where the highest score for each pair of competitors made it through to the next round .</p><p>The only rule was that we couldn‚Äôt take sleeping pills, everything else was fair game. Rumour had it that sleep deprivation on non-competition nights was the strategy of choice for many competitors.</p><h3>I didn‚Äôt stoop to such tactics, instead relying on the SoundMind prototype to guide me through the competition.</h3><p>It started off very well, when I averaged the 2nd highest scores through seeding, and managed the 2nd highest score of 92 points on the first night of competition<br></p><p>I believed Oura was removing points for a low amount REM sleep as a percentage of my overall sleep, so I made an adjustment to the sounds played by SoundMind to promote more REM sleep. I had a hint that this would work, but, it was a bit like running a marathon in a new pair of sneakers. A wrong move and my competition would be over.</p><p>My competitor that night put in a very solid score of 93, and apparently began his celebrations early, before seeing the 96 points I achieved with the updated version of SoundMind. This turned out to be the highest score of the entire tournament.</p><p>This was followed-up by a score of 95 the next night of competition. Far above my pre-SoundMind average in the low 70s.</p><p>Going into the semi-finals, a win looked unlikely. At 2am, somebody rang the buzzer at my apartment, it was a food delivery guy who had the wrong address. When the buzzer rang a 2nd time at 2:30am, I was wondering if this was a new tactic my opponent had discovered as the only way to destroy my sleep and chances at winning the night. Waking up, I felt pretty good, but didn‚Äôt know if I‚Äôd have the high score to win with only 89 points. However, potentially my opponent's guilt over interfering in my sleep, if she actually had done this, kept her awake fretting, and I had a few points lead over her, which led me into the finals.</p><p>I felt confident going into the finals. Not only because of the high scores I had been seeing, but due to the consistency. Anybody can have one or two nights of great sleep, but to consistently be able to sleep great every night, that‚Äôs the real challenge, and also why the competition rewards the person who can get the high score night after night.</p><div><p>Potentially with a bit of nerves coming into play, I only managed to eke out a 93 on the final night, and I wasn‚Äôt sure if that would be enough to take the win from a man with a history of scoring in the low 90s. To add to the suspense, the competition takes place around the world, and living in Australia, we‚Äôre the 2nd country to be awake, so I had to wait a day to get the final results!</p><p>It was a close final, but I managed to win out by a mere 2 points! Though I don‚Äôt feel a strong need to give an acceptance speech or thank my sponsors, I do want to thank Damian and Todd for organizing the event, and to all my fellow competitors. </p><p>The most important result here for me is that we had a fun way to test out the SoundMind tech, and see it in action as more than just another score or another great night sleep. As I‚Äôve been using SoundMind it‚Äôs been interesting to see how quickly I‚Äôve adapted to just accepting that a good night sleep is what happens. I almost forget what it was like being awake all night, and the agony which comes with that.&nbsp;</p></div><p>We‚Äôll have more updates, and be sharing more data as we progress, and sign-up to the wait list to reserve your spot and get one of the first headbands so you can have amazing sleep too!</p><p>Soon we‚Äôll all be sleeping well with SoundMind.</p></div></div></div>]]>
            </description>
            <link>https://soundmind.co/blog/neurohacking-the-world-sleep-championships</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068156</guid>
            <pubDate>Thu, 12 Nov 2020 09:40:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pascal Implementation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067899">thread link</a>) | @z3phyr
<br/>
November 12, 2020 | https://homepages.cwi.nl/~steven/pascal/book/pascalimplementation.html | <a href="https://web.archive.org/web/*/https://homepages.cwi.nl/~steven/pascal/book/pascalimplementation.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<h2>The P4 Compiler and Interpreter</h2>
<p><em>by <a href="http://www.cwi.nl/~steven/">Steven Pemberton</a>, 
<a href="http://www.cwi.nl/~steven/amsterdam.html">Amsterdam</a>, 
and <a href="http://www.it.bton.ac.uk/staff/mcd/">Martin Daniels</a></em>
</p>
<p>
<a href="https://homepages.cwi.nl/~steven/pascal/book/0intro.html">Chapter 0: Preface and Introduction</a></p>
<h2>Part 1: The Compiler</h2>
<p>
<a href="https://homepages.cwi.nl/~steven/pascal/book/1lexical.html">Chapter 1: Input and Lexical Analysis</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/2syntax.html">Chapter 2: Syntax Analysis</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/3semantic.html">Chapter 3: Semantic Analysis</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/4codegen.html">Chapter 4: Code Generation</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/5expressions.html">Chapter 5: Compiling Expressions</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/6procfunc.html">Chapter 6: Compiling Procedures and Functions</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/7statements.html">Chapter 7: Compiling Statements</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/8declarations.html">Chapter 8: Compiling Declarations</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/9program.html">Chapter 9: Compiling the Program</a>
</p>
<h2>Part 2: The Interpreter</h2>
<p>
<a href="https://homepages.cwi.nl/~steven/pascal/book/10pcode.html">Chapter 10: The P-code Machine</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/11assembler.html">Chapter 11: The Assembler</a><br>
<a href="https://homepages.cwi.nl/~steven/pascal/book/12interpreter.html">Chapter 12: The Interpreter</a>
</p>
<h2>Appendices</h2>
<p>
<a href="https://homepages.cwi.nl/~steven/pascal/book/13appendices.html">Chapter 13: Appendices</a>
</p>
<p>Copyright ¬© 1982, 2002 Steven Pemberton and Martin Daniels, all rights reserved.</p>
<!--
<pre>
ok	recreate diags
ok	em F
ok	em equationvariables
ok	div
ok	p class=body
	` to '
	heading types
	pre for programs (done for 6)
li for numbered lists
	li for notes
dl's for class="Line" (to do for 3, 4, 5, 6, 7, 8, 9, 10, 11, 12)
var
kw
&lt;code&gt;
line nos: make them links to the code

deal with single note ols
fix part 2 notes
italicise comments in program fragments
move labels diagrams to semantics
redate preface
add navigation to all chapters
</pre>
-->




</div>]]>
            </description>
            <link>https://homepages.cwi.nl/~steven/pascal/book/pascalimplementation.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067899</guid>
            <pubDate>Thu, 12 Nov 2020 09:03:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Migrating our dev-sec Ansible roles to a collection]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067897">thread link</a>) | @zufallsheld
<br/>
November 12, 2020 | https://dev-sec.io/blog/2020-10-11-ansible-collection/ | <a href="https://web.archive.org/web/*/https://dev-sec.io/blog/2020-10-11-ansible-collection/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  <div>
    <article>
      
      

<p>In July 2020 we decided to move our existing Ansible roles for Linux, ssh, nginx and MySQL into an Ansible collection (<a href="https://docs.ansible.com/ansible/latest/user_guide/collections_using.html">what is a collection?</a>).</p>



<p>Having only one repository for all roles means we don‚Äôt have to duplicate code. We have one common test-suite for all roles that works the same for every role.
Also Collections are the future, as there is possibly no support for roles in the next version of Ansible Galaxy (see <a href="https://github.com/ansible/galaxy_ng/issues/58">ansible/galaxy_ng#58</a>).</p>



<p>Collections are only supported from Ansible 2.9 and onwards. However Ansible 2.8 is still supported (<a href="https://docs.ansible.com/ansible/latest/reference_appendices/release_and_maintenance.html#release-status">https://docs.ansible.com/ansible/latest/reference_appendices/release_and_maintenance.html#release-status</a>). This means we need to support the separate roles until 2.9 is the oldest maintained release.</p>



<p>We decided to use the ansible-os-hardening git repository for our new collection because it has the most stars. We didn‚Äôt want to lose our precious internet points!
We created a separate branch and worked on this one until the migration to the main branch was ready.
All the roles that lived in separate repositories should move to the <code>roles</code>-directory. It was important for us to keep the history of all roles. Fortunately we weren‚Äôt the first ones who wanted to migrate one repository with its history to another. So with the help of StackOverflow, migrating them wasn‚Äôt too hard.</p>

<p>The roles were tested with the help of test-kitchen (I wrote about it <a href="https://www.zufallsheld.de/2016/01/05/testing-ansible-roles/">here</a>) and our trusted <a href="https://dev-sec.io/baselines/">Inspec Baselines</a>. We kept the baselines but replaced test-kitchen with molecule, the de-facto standard for testing Ansible content. This made it possible to test our collection in the same way locally as done in CI. Speaking of CI: We replaced travis (good riddance - Travis <a href="https://blog.travis-ci.com/2020-11-02-travis-ci-new-billing">changed</a> their pricing model) with <a href="https://github.com/features/actions">Github Actions</a>.
Now every role inside the collection has its own pipeline that only runs when files from the role change. We still test our roles on a plethora of operating systems and the most important ones (CentOS and Ubuntu in its various versions) are all supported with all roles.</p>

<p>One problem with the new releases existed: since we wanted to re-use the ansible-os-hardening repository for the collection, we could not start from version 1.0.0 for the collection since the tag already existed. So to no break the old role we decided to continue the version from the role in the collection. This is why we started with version 7 in the collection.</p>

<p>Releasing new versions with a changelog was something we already <a href="https://github.com/dev-sec/ansible-os-hardening/issues/269">automated</a> some time ago. We wanted to keep the nicely formatted changelogs and automatic releases and modifying the existing Github Actions was no problem.</p>

<p>Our plan how to actually migrate the roles into the collection looked like this: Start building the collection and use the roles as submodules inside the monorepo. This way we can continue to support the separate roles and the roles inside the collection cannot diverge from the legacy roles.</p>

<p>When everything was migrated, we planned to archive the old roles and link to the collection.</p>



<p>There were some problems along the way but nothing we couldn‚Äôt fix.</p>

<p>Along the creation of the collection we needed to update our inspec-baselines as they needed more features to support all our operating systems.
That means we now support newer versions of MySQL and MariaDB (<a href="https://github.com/dev-sec/mysql-baseline/pull/59">https://github.com/dev-sec/mysql-baseline/pull/59</a>, <a href="https://github.com/dev-sec/mysql-baseline/pull/57">https://github.com/dev-sec/mysql-baseline/pull/57</a>) and we support Arch Linux in the linux-baseline (<a href="https://github.com/dev-sec/linux-baseline/pull/136">https://github.com/dev-sec/linux-baseline/pull/136</a>).</p>

<p>We also wanted to replace Inspec with its free distribution <a href="https://cinc.sh/">cinc-auditor</a>. This was surprisingly easy as the people behind cinc made it very easy to install cinc-auditor and use it as a drop-in replacement for Inspec. See this <a href="https://github.com/dev-sec/ansible-os-hardening/pull/291/commits/e7a47a1d342e1b45ceeeae7a1ff247f58ce3434e">commit</a> for details.</p>

<p>There was an <a href="https://github.com/ansible/ansible/issues/66304">issue</a> in Ansible that we needed to work around. This was done by <a href="https://github.com/schurzi/">@schurzi</a> here: <a href="https://github.com/dev-sec/ansible-os-hardening/pull/291/commits/3f7598b5bae80f96cad3ad068f0d57b3e1e538ed">https://github.com/dev-sec/ansible-os-hardening/pull/291/commits/3f7598b5bae80f96cad3ad068f0d57b3e1e538ed</a></p>

<p>Our mysql-hardening-role relies on a existing installation of MySQL or MariaDB. For this we used geerlingguys mysql-role because it supports many operating systems. However the role has some issues and unmerged pull requests that prevented us to use geerlingguys role as is. We had to <a href="https://github.com/dev-sec/ansible-role-mysql/">fork</a> the role and incorporate some PRs and fixes. We hope we don‚Äôt have to continuously support the fork though.</p>

<p>The hardest bug we encountered was a problem with AppArmor and MySQL on recent Ubuntu distributions. Here‚Äôs the bug: <a href="https://bugs.launchpad.net/ubuntu/+source/mysql-5.7/+bug/1610765">https://bugs.launchpad.net/ubuntu/+source/mysql-5.7/+bug/1610765</a>.
A faulty AppArmor profile prevents MySQL from starting because AppArmor blocks access to MySQL‚Äôs configuration files.
And Github Actions run on a Ubuntu 18.04 virtual machine with AppArmor enabled. So I wondered why the role does work when running molecule locally (btw: I use Arch) but not in the CI-pipeline.
It took some days to figure this one out. However once I found out the reason for this, the solution was found much faster. <a href="https://robertdebock.nl/">Robert de Bock</a> also had this problem and fixed it <a href="https://github.com/robertdebock/ansible-role-mysql/commit/7562e99099b06282391ab7ed102b393a0406d212">here</a></p>

<p>We also dropped support for some operating systems:</p>

<ul>
<li>CentOS 6 because support ends in November 2020</li>
<li>Oracle-Linux because supporting it is really cumbersome and we don‚Äôt know anyone that uses our roles on Oracle</li>
</ul>



<p>It‚Äôs here:</p>

<ul>
<li><a href="https://galaxy.ansible.com/devsec/hardening">Galaxy</a></li>
<li><a href="https://github.com/dev-sec/ansible-os-hardening/">Repository on Github</a></li>
</ul>

<p>Please share your feedback with us, ask questions on the mailing list, open issues and pull requests on our repo!</p>



<p>We plan to archive the repositories of the roles incorporated in the collection and redirect everyone to the collection. The open issues and pull requests will be moved or closed.
This way, no code gets lost and (almost) no links will be broken.</p>

<p>Of course we want to continue working on the collection and support more operating systems and more software! If you want to help, reach out!</p>



<p>I want to thank the devsec team, especially <a href="https://github.com/micheelengronne">@micheelengronne</a>, <a href="https://github.com/schurzi/">@schurzi</a> and <a href="https://github.com/chris-rock">@chris-rock</a> for their work and support in creating the collection and this awesome opensource community!</p>

    </article>
  </div>
</section></div>]]>
            </description>
            <link>https://dev-sec.io/blog/2020-10-11-ansible-collection/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067897</guid>
            <pubDate>Thu, 12 Nov 2020 09:02:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Acing your technical interview ‚Äì a hiring manager‚Äôs guide]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067800">thread link</a>) | @ochronus
<br/>
November 12, 2020 | https://ochronus.online/acing-the-tech-interview/ | <a href="https://web.archive.org/web/*/https://ochronus.online/acing-the-tech-interview/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><section><p>Even though interviewing for a software engineering job can be intimidating and frustrating (with whiteboard exercises, remote coding challenges, and even full days of onsite interviews), it‚Äôs a lot easier when you know what to expect and are well-prepared.</p><p>I‚Äôve interviewed a few hundred software engineering candidates in the past 10+ years and designed hiring processes. My experience is limited to startups and mid-sized companies, so take everything you read here with that in mind. My advice may not get you into Facebook or Google but will definitely increase your chances at mid-sized companies with a good culture!</p><p>In the first part of this article, I‚Äôll give some context, then give you an actionable list to improve your experience and chances in your next interview</p><p>If you‚Äôre only interested in the actionable list, feel free to skip ahead to it.</p><hr><h2 id="what-you-think-about-the-technical-interview-might-be-incomplete">What you think about the technical interview might be incomplete <a href="#what-you-think-about-the-technical-interview-might-be-incomplete"></a></h2><p>First and foremost, a technical interview is almost never only technical. Up to a certain (and honestly, very useful!) level growing as a ‚Äòcoder‚Äô is not that complicated. Many candidates perform pretty well if we purely look at their coding skills.</p><p>The thing is, you‚Äôll rarely work alone in isolation on your own codebase. You‚Äôll have teammates, you‚Äôll need to agree on things with them, you‚Äôll build on others‚Äô code and others will build on your code. You‚Äôll need to build solutions with a certain level of quality, in a future-proof way, for extensibility, and with performance in mind. Depending on your role and level, you‚Äôll need to architect systems. You‚Äôll need to mentor other engineers. You‚Äôll need to onboard new team members. You‚Äôll need to proactively reach out to other teams in the company and understand their points of view and problems. You‚Äôll talk to product managers, UX researchers, designers, even customers sometimes. You‚Äôll need to manage projects, make tradeoffs and decisions, and align other engineers with that.</p><p>Read my article on <a href="https://ochronus.online/technical-interview-myths/">the most common 11 technical interview myths</a></p><hr><h2 id="types-and-stages-of-technical-interviews">Types and stages of technical interviews <a href="#types-and-stages-of-technical-interviews"></a></h2><p>Most companies use a combination of these steps:</p><ul><li>Screening call with a recruiter ‚Äì We‚Äôre interested in your basic motivations, we‚Äôd like to have a gut feeling about what you‚Äôre looking for and do some sanity check here. You might get asked about your salary requirements, support you need for visa or relocation, and timelines (when could you start, etc.). Some recruiters will also ask you whether you have applied elsewhere so they know how urgent this is for them and you.</li><li>Screening call with the hiring manager ‚Äì Expect some deeper dive into your experience on multiple fronts ‚Äì tech and ‚Äòsoft skills‚Äô alike. As a hiring manager, I‚Äôll prepare by checking out your CV for talking points, maybe even your LinkedIn profile, and definitely GitHub. I‚Äôm not trying to judge you, I‚Äôm just looking for points of connection. I‚Äôll answer any questions you have about the role, the company, the culture, potential teams you‚Äôd be joining, etc. etc. My ultimate goal with this is twofold: would we be a good match for your (and vice versa) and whether I think you‚Äôd be successful in the role.</li><li>Remote technical screening ‚Äì An alternative, or at some places precursor to the online coding exercise. This is with a human on the other end of the line ‚Äì solving tech problems together, usually, you walk them through your solution.</li><li>Online coding exercises (LeetCode, HackerRank, etc.) ‚Äì I know you all hate this. We need such a step to filter out people who can‚Äôt even code at all early on. You‚Äôd be surprised about the number of such applicants. I avoid algorithm/data structure exercises here and try to come up with somewhat interesting ones. Some companies use a much heavier set of exercises and base their judgment of your technical skills solely on this. While I don‚Äôt agree with that strategy, you need to get prepared for this, too.</li><li>Take-home assignment ‚Äì this is one of the most polarizing interview steps for engineers. Some hate it, claiming it‚Äôs just free labor for the companies and it takes too much time, others love it because they feel they have the freedom of giving it much time, really showing off their skills in their own comfortable environment. Whichever camp you‚Äôre in, you can expect some companies requiring this. You usually get a somewhat specified problem to solve and you‚Äôre given different levels of freedom on how to solve it ‚Äì some companies don‚Äôt mind you choosing whichever stack you like, others will even specify the framework.</li><li>Onsite workshop / remote workshop ‚Äì I think this is the most interesting of all steps (well, for me at least). It‚Äôs about solving problems together with people from the company in a simulated environment. You‚Äôll need to show your communication, decision-making, and even prioritization skills here. Sure, people will look at the quality of your code, too, but ‚Äòsoft skills‚Äô are just as important here. We‚Äôll get strong signals about how it would be having you on the team.</li></ul><hr><h2 id="cracking-the-technical-interview">Cracking the technical interview <a href="#cracking-the-technical-interview"></a></h2><h3 id="ask-the-recruiter-or-the-hiring-manager-before-the-interview">Ask the recruiter or the hiring manager before the interview <a href="#ask-the-recruiter-or-the-hiring-manager-before-the-interview"></a></h3><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://ochronus.online/img/acing-the-technical-interview/ask-the-recruiter-or-hiring-manager-1920w.webp 1920w, https://ochronus.online/img/acing-the-technical-interview/ask-the-recruiter-or-hiring-manager-1280w.webp 1280w, https://ochronus.online/img/acing-the-technical-interview/ask-the-recruiter-or-hiring-manager-640w.webp 640w, https://ochronus.online/img/acing-the-technical-interview/ask-the-recruiter-or-hiring-manager-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://ochronus.online/img/acing-the-technical-interview/ask-the-recruiter-or-hiring-manager-1920w.jpg 1920w, https://ochronus.online/img/acing-the-technical-interview/ask-the-recruiter-or-hiring-manager-1280w.jpg 1280w, https://ochronus.online/img/acing-the-technical-interview/ask-the-recruiter-or-hiring-manager-640w.jpg 640w, https://ochronus.online/img/acing-the-technical-interview/ask-the-recruiter-or-hiring-manager-320w.jpg 320w" type="image/jpeg"><img height="300" src="https://ochronus.online/img/acing-the-technical-interview/ask-the-recruiter-or-hiring-manager.jpg" width="300" alt="Ask the recruiter or the hiring manager before the interview" decoding="async" loading="lazy"></picture>Take the guesswork out of the equation. If you feel you don‚Äôt have enough information to prepare, just ask for more! We‚Äôre here to help you succeed. I really mean it. Sometimes we aren‚Äôt doing a great job with sharing enough information proactively about the interview steps but that‚Äôs not intentional! I‚Äôm always happy to help you prepare better ‚Äì ask about anything, please. You‚Äôre doing both of us a favor with that. Ask during the previous interview step or just drop me an email at any time.</p><h3 id="show-up-on-time">Show up on time <a href="#show-up-on-time"></a></h3><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://ochronus.online/img/acing-the-technical-interview/arrive-on-time-1920w.webp 1920w, https://ochronus.online/img/acing-the-technical-interview/arrive-on-time-1280w.webp 1280w, https://ochronus.online/img/acing-the-technical-interview/arrive-on-time-640w.webp 640w, https://ochronus.online/img/acing-the-technical-interview/arrive-on-time-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://ochronus.online/img/acing-the-technical-interview/arrive-on-time-1920w.jpg 1920w, https://ochronus.online/img/acing-the-technical-interview/arrive-on-time-1280w.jpg 1280w, https://ochronus.online/img/acing-the-technical-interview/arrive-on-time-640w.jpg 640w, https://ochronus.online/img/acing-the-technical-interview/arrive-on-time-320w.jpg 320w" type="image/jpeg"><img height="300" src="https://ochronus.online/img/acing-the-technical-interview/arrive-on-time.jpg" width="300" alt="Show up on time" decoding="async" loading="lazy"></picture>Make sure you‚Äôre there on time. If you can‚Äôt, for some reason, please let us know, we‚Äôll happily organize for another time, no hard feelings. Showing up on time isn‚Äôt only about respecting each other‚Äôs schedule ‚Äì interview time slots are usually 100% utilized and by arriving 10 minutes late you‚Äôre reducing your own chance to be successful. You‚Äôre also making it more stressful for yourself than necessary. If you need time for commute or for your Zoom/Google Meet setup, think ahead and give yourself a buffer before the start.</p><h3 id="don't-jump-right-into-solution-mode---read%2C-distill%2C-paraphrase">Don't jump right into solution mode - read, distill, paraphrase <a href="#don't-jump-right-into-solution-mode---read%2C-distill%2C-paraphrase"></a></h3><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://ochronus.online/img/acing-the-technical-interview/read-distill-paraphrase-1920w.webp 1920w, https://ochronus.online/img/acing-the-technical-interview/read-distill-paraphrase-1280w.webp 1280w, https://ochronus.online/img/acing-the-technical-interview/read-distill-paraphrase-640w.webp 640w, https://ochronus.online/img/acing-the-technical-interview/read-distill-paraphrase-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://ochronus.online/img/acing-the-technical-interview/read-distill-paraphrase-1920w.jpg 1920w, https://ochronus.online/img/acing-the-technical-interview/read-distill-paraphrase-1280w.jpg 1280w, https://ochronus.online/img/acing-the-technical-interview/read-distill-paraphrase-640w.jpg 640w, https://ochronus.online/img/acing-the-technical-interview/read-distill-paraphrase-320w.jpg 320w" type="image/jpeg"><img height="300" src="https://ochronus.online/img/acing-the-technical-interview/read-distill-paraphrase.jpg" width="300" alt="Don't jump right into solution mode - read, distill, paraphrase" decoding="async" loading="lazy"></picture>The biggest mistake you can do is thinking you understand the problem or what‚Äôs asked of you and jumping right into coding. Take your time, carefully read the problem statement, distill it, don‚Äôt think of solutions just yet. When you feel you understand what‚Äôs asked of you or when you thought about clarifying questions to ask, communicate. Paraphrase what you understood from the problem statement so you can verify it with your interviewers. Only when you‚Äôre on the same page can you shift into solution mode. Even if you come up with the best solution ultimately if you skip this step I‚Äôll remember and have doubts about how it‚Äôd be to work with you. Thinking aloud is really useful here - it will help you and help me too to understand what's on your mind.</p><h3 id="be-articulate-and-communicate-clearly">Be articulate and communicate clearly <a href="#be-articulate-and-communicate-clearly"></a></h3><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://ochronus.online/img/acing-the-technical-interview/communicate-clearly-1920w.webp 1920w, https://ochronus.online/img/acing-the-technical-interview/communicate-clearly-1280w.webp 1280w, https://ochronus.online/img/acing-the-technical-interview/communicate-clearly-640w.webp 640w, https://ochronus.online/img/acing-the-technical-interview/communicate-clearly-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://ochronus.online/img/acing-the-technical-interview/communicate-clearly-1920w.jpg 1920w, https://ochronus.online/img/acing-the-technical-interview/communicate-clearly-1280w.jpg 1280w, https://ochronus.online/img/acing-the-technical-interview/communicate-clearly-640w.jpg 640w, https://ochronus.online/img/acing-the-technical-interview/communicate-clearly-320w.jpg 320w" type="image/jpeg"><img height="300" src="https://ochronus.online/img/acing-the-technical-interview/communicate-clearly.jpg" width="300" alt="Be articulate and communicate clearly" decoding="async" loading="lazy"></picture>Even if you know your trade, if you fail to communicate clearly during your interview we‚Äôll have no way of knowing. This takes practice for most people, so take your time and prepare! Use standard terms that other engineers can relate to, avoid passive voice, and be able to articulate what‚Äôs going on in your mind while you‚Äôre thinking. If you need some time to think quietly, say so, don‚Äôt just fall silent suddenly. We‚Äôre trying our best to communicate our expectations around this but it might be a bit late when you‚Äôre in the interview. Trust me on this one, practice here goes a long way.</p><h3 id="ask-clarifying-questions">Ask clarifying questions <a href="#ask-clarifying-questions"></a></h3><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://ochronus.online/img/acing-the-technical-interview/ask-clarifying-questions-1920w.webp 1920w, https://ochronus.online/img/acing-the-technical-interview/ask-clarifying-questions-1280w.webp 1280w, https://ochronus.online/img/acing-the-technical-interview/ask-clarifying-questions-640w.webp 640w, https://ochronus.online/img/acing-the-technical-interview/ask-clarifying-questions-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://ochronus.online/img/acing-the-technical-interview/ask-clarifying-questions-1920w.jpg 1920w, https://ochronus.online/img/acing-the-technical-interview/ask-clarifying-questions-1280w.jpg 1280w, https://ochronus.online/img/acing-the-technical-interview/ask-clarifying-questions-640w.jpg 640w, https://ochronus.online/img/acing-the-technical-interview/ask-clarifying-questions-320w.jpg 320w" type="image/jpeg"><img height="300" src="https://ochronus.online/img/acing-the-technical-interview/ask-clarifying-questions.png" width="300" alt="Ask clarifying questions" decoding="async" loading="lazy"></picture>While you‚Äôd think the interview is about you answering questions, expect that you will need to ask a lot of questions! When you are in the interview and something is not clear don‚Äôt default to thinking ‚ÄúOh god, I should know this, I should understand‚Äù ‚Äì sometimes we are interested in how you behave in such situations, and sometimes we‚Äôre just simply not good enough in giving enough context. If you‚Äôre stuck, a good technique is to ask for clarification! It‚Äôs also 100% OK to say things like ‚ÄúI didn‚Äôt quite get that. Could you rephrase please?‚Äù or ‚ÄúI‚Äôm not sure I understand what you‚Äôre asking‚Äù. These are good signals! I expect my team members to behave like this. These are not signals of you failing. I know it feels like that, but trust me, it‚Äôs just your brain playing tricks on you. I highlight this during the interview several times, to make sure the candidate feels safe asking such questions. Another technique I wholeheartedly welcome is paraphrasing ‚Äì e.g. ‚ÄúWhat I understood from what you said is that I should implement this using co-monads‚Äù (said nobody ever).</p><h3 id="demonstrate-your-tech-skills-the-right-way">Demonstrate your tech skills the right way <a href="#demonstrate-your-tech-skills-the-right-way"></a></h3><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://ochronus.online/img/acing-the-technical-interview/t-shaped-engineer-1920w.webp 1920w, https://ochronus.online/img/acing-the-technical-interview/t-shaped-engineer-1280w.webp 1280w, https://ochronus.online/img/acing-the-technical-interview/t-shaped-engineer-640w.webp 640w, https://ochronus.online/img/acing-the-technical-interview/t-shaped-engineer-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://ochronus.online/img/acing-the-technical-interview/t-shaped-engineer-1920w.jpg 1920w, https://ochronus.online/img/acing-the-technical-interview/t-shaped-engineer-1280w.jpg 1280w, https://ochronus.online/img/acing-the-technical-interview/t-shaped-engineer-640w.jpg 640w, https://ochronus.online/img/acing-the-technical-interview/t-shaped-engineer-320w.jpg 320w" type="image/jpeg"><img height="300" src="https://ochronus.online/img/acing-the-technical-interview/t-shaped-engineer.jpg" width="300" alt="T-shaped engineer" decoding="async" loading="lazy"></picture>Make us see that you‚Äôre deeply proficient in at least one technology. This can be a programming language, for example. Also, demonstrate that you know the adjacent technologies ‚Äì most companies are looking for so-called T-shape engineers. This means that mentioning other aspects of the problem and the solution goes a long way. For example, if you‚Äôre asked to implement a service in NodeJS, mention how you‚Äôd deploy, monitor, and scale it, even if that‚Äôs not explicitly asked. No need to go into too many details (unless people ask you). If you‚Äôre only focused on a single piece of the puzzle I‚Äôll have a hard time seeing how you‚Äôd perform well in a changing environment (where you‚Äôll need to make connections and work on multiple zoom levels and be ready). This is a very generic statement and might not be true in the case of highly specialized roles, of course. On the other hand, if you say your primary language is Python yet you can‚Äôt seem to show even a basic understanding of it, that‚Äôs a no-no. Work on the stem of that T, too. Hopefully, you‚Äôve clarified what you‚Äôd be doing on the interview upfront (see advice #1) so you can think about adjacent technologies in advance.</p><h3 id="don%E2%80%99t-get-too-focused-or-stuck-on-a-solution">Don‚Äôt get too focused or stuck on a solution <a href="#don%E2%80%99t-get-too-focused-or-stuck-on-a-solution"></a></h3><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://ochronus.online/img/acing-the-technical-interview/you-have-options-1920w.webp 1920w, https://ochronus.online/img/acing-the-technical-interview/you-have-options-1280w.webp 1280w, https://ochronus.online/img/acing-the-technical-interview/you-have-options-640w.webp 640w, https://ochronus.online/img/acing-the-technical-interview/you-have-options-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://ochronus.online/img/acing-the-technical-interview/you-have-options-1920w.jpg 1920w, https://ochronus.online/img/acing-the-technical-interview/you-have-options-1280w.jpg 1280w, https://ochronus.online/img/acing-the-technical-interview/you-have-options-640w.jpg 640w, https://ochronus.online/img/acing-the-technical-interview/you-have-options-320w.jpg 320w" type="image/jpeg"><img height="300" src="https://ochronus.online/img/acing-the-technical-interview/you-have-options.jpg" width="300" alt="Don‚Äôt get too focused or stuck on a solution" decoding="async" loading="lazy"></picture>Sometimes a solution you came up with ‚Ä¶</p></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ochronus.online/acing-the-tech-interview/">https://ochronus.online/acing-the-tech-interview/</a></em></p>]]>
            </description>
            <link>https://ochronus.online/acing-the-tech-interview/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067800</guid>
            <pubDate>Thu, 12 Nov 2020 08:47:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You don't need a blockchain solution for your next project]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25067702">thread link</a>) | @shrmv
<br/>
November 12, 2020 | https://exyte.com/blog/why-you-dont-need-a-blockchain-solution-for-your-next-project | <a href="https://web.archive.org/web/*/https://exyte.com/blog/why-you-dont-need-a-blockchain-solution-for-your-next-project">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <p>Blockchain is one of the hottest technology fields of the last decade, together with machine learning and big data. According to the <a rel="nofollow" href="https://www2.deloitte.com/content/dam/insights/us/articles/6608_2020-global-blockchain-survey/DI_CIR%202020%20global%20blockchain%20survey.pdf">Deloitte 2020 Global Blockchain Survey</a>, businesses worldwide find blockchain an integral part of organizational innovation. </p>
<p>Properly implemented, a blockchain solution can make parts of your business transparent or enable different actors to cooperate quickly and trustlessly. </p>
<p>But today, we won√¢‚Ç¨‚Ñ¢t examine blockchain√¢‚Ç¨‚Ñ¢s strengths. Instead, we will look at why it√¢‚Ç¨‚Ñ¢s not the perfect choice for all your software projects.  </p>
<h2>Blockchain is more expensive</h2>
<p>From our experience, infrastructure and maintenance costs for a blockchain solution are typically 10-15 times higher compared to an ordinary server with a database running on AWS or a custom AWS/GCP/Azure solution.</p>
<p>Even when using economically efficient Azure solutions, it can cost up to ten times more when compared to a centralized DB with similar functionality running on AWS.</p>
<p>Therefore, it√¢‚Ç¨‚Ñ¢s necessary to seriously weigh the costs of running your solution vs. the need for transparency and distribution that blockchain offers. </p>
<h2>Blockchain scales worse</h2>
<p>Performance and scalability are the two major bottlenecks for any blockchain project. </p>
<p>From our experience working for large enterprise companies such as Bayer AG, Delta, PwC, and others, blockchain solutions that work fine for hundreds and thousands of users degrade in performance quite quickly when they need to serve more than ten thousand users.</p>
<p>Scaling blockchain, on the other hand, usually requires a complete rework of the core. Sometimes, there might even be no viable solution. So, despite some ambitious claims by blockchain companies, scaling is still an immature topic in the blockchain world.</p>
<h2>Blockchain is about transparency, not privacy</h2>
<p>Privacy is an issue. It is challenging to maintain privacy on the blockchain. In contrast to regular solutions, existing blockchain solutions are often all about transparency rather than privacy.</p>
<p>Solutions that provide the required level of privacy typically have to compromise on performance through zero-knowledge proofs or other kinds of encryption, which is costly.</p>
<p>Another problem with privacy is that most of the time, blockchain is permissionless or has very primitive permissions levels. Therefore, solutions for permissions are built on top of it as an additional middle layer, which, of course, adds performance overhead, degrades scalability, adds implementation and execution costs, etc.
Conclusion</p>
<p>There are three significant challenges that blockchain projects face: performance, scalability, and privacy. While there are multiple benefits for using blockchain, such as transparency and the ability to operate trustlessly, they need to be weighed against the downsides. </p>
<p>We want to share our knowledge with you about potential problems not to talk you away from blockchain, but to make sure the choice is clear and the right one for your project. If you still aren√¢‚Ç¨‚Ñ¢t sure and would like to have a 30-minute consultation with an expert in the field, you√¢‚Ç¨‚Ñ¢re welcome to <a href="https://exyte.com/contacts">contact us</a>. </p>
                </div></div>]]>
            </description>
            <link>https://exyte.com/blog/why-you-dont-need-a-blockchain-solution-for-your-next-project</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067702</guid>
            <pubDate>Thu, 12 Nov 2020 08:25:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WSL explained ‚Äì crucial Q&A to get to know near-native Linux experience]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067677">thread link</a>) | @Pabloemm
<br/>
November 12, 2020 | https://solidstudio.io/blog/windows-subsystem-for-linux-explained.html | <a href="https://web.archive.org/web/*/https://solidstudio.io/blog/windows-subsystem-for-linux-explained.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p><a href="https://solidstudio.io/index.html">Solidstudio</a>
                    &gt;&gt;
                    <a href="https://solidstudio.io/blog/blog.html">Blog</a>
                    &gt;&gt;
                    &gt;Windows Subsystem for Linux (WSL) explained ‚Äì Q&amp;A
                </p>
                <p>No matter if you program in <a href="https://solidstudio.io/technologies/java.html">Java</a> or <a href="https://solidstudio.io/technologies/kotlin.html">Kotlin</a> or with other technologies, operating on Linux has a number of advantages. One of them is access to Linux Bash with its useful commands.</p>
                <p>However, some developers have to or prefer working on Windows. As stackoverflow.com 2020 <a href="https://insights.stackoverflow.com/survey/2020#development-environments-and-tools" rel="nofollow">survey</a> showed, almost half of developers (45,8%) work in the Windows environment. There are tools that bring them closer to the Linux world like <a href="https://www.cygwin.com/" ref="nofollow">Cygwin</a>.</p>
                
                <h2>The WSL provides a near-native Linux experience</h2>
                <p>Some time ago Microsoft introduced WSL, a new tool that brings Windows users even closer to the Linux experience. Here you can find gathered some frequently asked questions and our expert‚Äôs experience to help you get a better understanding of the WSL.</p>
                
                <h3>What is WSL?</h3>
                <p>WSL or Windows Subsystem for Linux is a part of the Windows operating system that allows running native Linux binaries. A number of distributions exist that can be installed and used. </p>
                
                <h3>How can I install WSL?</h3>
                <p>First thing to do before installing any Linux distribution is to install the WSL itself.</p>
                <p>Go to <i>Control Panel</i> ‚Üí <i>Programs</i> ‚Üí <i>Programs and Features</i> ‚Üí <i>Turn Windows features on and off</i>.</p>
                <p>Select <i>Windows Subsystem for Windows</i>, confirm, and restart the system.</p>
                <p><img src="https://solidstudio.io/img/blog/windows-subsystem-for-linux-explained/wsl-install.png" alt="Turn Windows features on and off dialog with Windows Subsystem for Linux selected"></p><p>Now you are ready to select and install a Linux distribution of your choice.</p>
                                
                <h3>What Linux distributions are available on WSL?</h3>
                <p>To find a list of available distributions open Windows Store and search for "Linux".<br>
                The most popular are:
                </p><ul>
                <li>Ubuntu 18.04 and 20.04</li>
                <li>SUSE Linux Enterprise Server</li>
                <li>Debian</li>
                <li>Fedora Remix for WSL</li>
                <li>Kali Linux</li>
                </ul>                
                <p><img src="https://solidstudio.io/img/blog/windows-subsystem-for-linux-explained/windows-store-search.png" alt="Windows Store search result for term Linux"></p><h3>Is it possible to run graphical Linux applications from WSL?</h3>
                <p>Yes, it is possible. You need to install an X Window System server application on your Windows, for example <a href="https://sourceforge.net/projects/xming/" rel="nofollow">Xming X Server for Windows</a>.</p>
                <p>Then check if your WSL system has a <span>DISPLAY</span> environment variable set up. If not set it to <span>:0</span>.</p>
                <pre>export DISPLAY=:0</pre>
                <p>After this configuration you are free to run native Linux applications with user interface.</p>
                <p><img src="https://solidstudio.io/img/blog/windows-subsystem-for-linux-explained/xclock.png" alt="WSL running xclock via Xming"></p><h3>Where is wsl.conf located?</h3>
                <p>Each WSL instance can be further configured by creating and editing a config file <span>/etc/wsl.conf</span>.</p>
                
                <h3>How to access Windows files from WSL?</h3>
                <p>All fixed drives with the NTFS or ReFS file system are automatically mounted in <span>/mnt</span> directory. For example a C: drive can be accessed in <span>/mnt/c/</span>. The directory where drives are mounted can be specified in <span>/etc/wsl.conf</span> as follows:</p>
                <pre>[automount]
root=/</pre>
                <p>This setting will cause drives to be mounted under the root folder, so the C: drive would be accessible through <span>/c</span> folder.</p>

                <h3>How to access pendrive from WSL?</h3>
                <p>Unlike fixed drives, removable drives are not mounted automatically. To access files stored on a USB stick you need to mount it yourself. For this purpose, use these commands (assume the drive letter in Windows is F):</p>
                <pre>sudo mkdir /mnt/f
sudo mount -t drvfs H: /mnt/f</pre>

                <h3>How to connect to a DVD drive from WSL?</h3>
                <p>Optical drives are not as popular nowadays as they used to be. Nonetheless, they can be accessed the same way as pendrives (assume G is the drive letter):</p>
                <pre>sudo mkdir /mnt/g
sudo mount -t drvfs G: /mnt/g</pre>

                <h3>Where are WSL files stored?</h3>
                <p>WSL files are exposed through a network share <span>\\wsl$\[distro name]</span>, for example my home directory is at <span "="">\\wsl$\Ubuntu-20.04\home\pawelb</span>.</p>
                <p>Physically the WSL files are located at <span>%USERPROFILE%\AppData\Local\Packages\[distro name]</span>. My home folder is at this rather long path <span>C:\Users\pawelb\AppData\Local\Packages\CanonicalGroupLimited.Ubuntu18.04onWindows_79rhkp1fndgsc\LocalState\rootfs\home\pawelb</span>.</p>
                <p>However, it is worth noting that manipulating WSL files from within Windows should be avoided as it can destroy Linux-specific file metadata. If you need to manipulate files on both WSL and Windows, store them on a Windows drive and access them from within WSL via <span>/mnt</span>.</p>
                
                <h3>Is it possible to run Windows programs from within WSL?</h3>
                <p>Yes, the WSL was built with interoperability in mind. It can run native Windows programs. However, if this feature is not needed, the user can disable it by adding <span>enabled=false</span> into <span>[interop]</span> section in <span>wsl.conf</span>.</p>
                <pre>[interop]
enabled=false</pre>

                
                <h3>What terminal application to use?</h3>
                <p>Any terminal can do the job, even the good old <span>cmd.exe</span>. Just run the WSL command in. There is however one great application that makes running the WSL console easier. It‚Äôs <a href="https://docs.microsoft.com/en-us/windows/terminal/get-started" rel="nofollow">Windows Terminal</a> and it can be installed from Windows Store. It automatically detects any WSL distributions installed and adds an option to run its console. It also supports regular Windows Command Line, PowerShell, and Azure console out of the box. Also, it supports tabs and split view inside a tab.</p>
                <p><img src="https://solidstudio.io/img/blog/windows-subsystem-for-linux-explained/windows-terminal.png" alt="Windows Terminal application"></p><h3>Caveats of interoperability with Windows</h3>
                <p>By default, WSL can run Windows binaries and also appends its <span>%PATH%</span> variable into the <span>$PATH</span> variable of Linux running under WSL. In most cases, this is useful or at least does no harm. However, sometimes unexpected behavior occurs.</p>
                <p>This happened when I tried to run <span>npm</span>.</p>
                <pre>$ npm -v
module.js:471
    throw err;
    ^

Error: Cannot find module '\\wsl$\Ubuntu-20.04\c\Programs\nvm\v6.10.2\node_modules\npm\bin\npm-cli.js'
    at Function.Module._resolveFilename (module.js:469:15)
    at Function.Module._load (module.js:417:25)
    at Module.runMain (module.js:604:10)
    at run (bootstrap_node.js:393:7)
    at startup (bootstrap_node.js:150:9)
    at bootstrap_node.js:508:3</pre>
                
                <p>This error message is not helpful at all. What happened?</p>
                <p>After some investigation, I found out that I had also installed npm on Windows and WSL was using this executable to run. This unfortunately failed under WSL environment.</p>
                <p>A fix was rather simple. I disabled appending Windows <span>%PATH%</span> to WSL <span>$PATH</span>.</p>
                <p>This can be done in two ways.</p>
                <p>The first is to use the Registry Editor (regedit) to add a DWORD <span>AppendNtPath</span> with value <span>0</span> under <span>HKEY_CURRENT_USER\SOFTWARE\Microsoft\Windows\CurrentVersion\Lxss</span>. This affects all WSL distributions.</p>
                <p>The second way is to set a property in <span>/etc/wsl.conf</span>. This affects only a single distribution.</p>
                <pre>[interop]
appendWindowsPath=false</pre>

                <h2>The WSL is a great subsystem for Windows </h2>
                <p>With the introduction of Windows 10, a lot has changed. It seems that the system and its features are more and more thought-out and intuitive. A programmer needs a proper working environment. With WSL, Windows is keeping up with developments in this area, and looks like it is a step in the right direction. It‚Äôs worth having an eye on the development of this solution, hoping that in the future the developers will have a variety of systems that can really compete with each other. Looking for a good and stable, seamless tool, it is worth trying with the WSL.</p>
                
                
                
            </div></div>]]>
            </description>
            <link>https://solidstudio.io/blog/windows-subsystem-for-linux-explained.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067677</guid>
            <pubDate>Thu, 12 Nov 2020 08:21:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deno is the same as Node.js, but different]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067625">thread link</a>) | @velmu
<br/>
November 12, 2020 | https://developers.ibexa.co/blog/deno-is-the-same-as-node.js-but-different | <a href="https://web.archive.org/web/*/https://developers.ibexa.co/blog/deno-is-the-same-as-node.js-but-different">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>JavaScript has been on a roll for more than a decade now. What started as a language used for sprinkling some interactivity to static HTML has grown to be arguably the world's most widespread general purpose programming language. The hegemony of JavaScript is also evident on the server side, with Node.js being a staple of job ads for many years. Recently there's been some buzz around a similar technology:&nbsp;<a href="https://deno.land/" title="">Deno</a></p><div><p>Let's find out what Deno is and how it compares with <a href="https://nodejs.org/" title="">Node.js</a>. First things first: The name Deno is an <a href="https://www.arrak.fi/en/ag" title="">anagram</a> of Node, and they are two&nbsp;different open source software projects.&nbsp;Deno&nbsp;sounds like a cheap knock-off of the more established Node.js, given the two technologies' problem domain and overall similarity. But once you learn both were originally kicked off by the same person, <a href="https://en.wikipedia.org/wiki/Ryan_Dahl" title="">Ryan Dahl</a>,&nbsp;it changes the perception.</p><p>Dahl released the first version of Node.js in May 2009. In January 2012 he stepped aside from the project to focus on other things. To the surprise of many he announced Deno in 2018 at a conference talk titled&nbsp;<a href="https://www.youtube.com/watch?v=M3BM9TB-8yA" title="">10 Things I Regret About Node.js</a>. in his talk, the primus motor of Node.js outlines some of the things he'd do differently today.&nbsp;That is what Deno is: An alternative&nbsp;take on a server-side JavaScript runtime.</p><p>Since the unveiling of&nbsp;Deno a developer community has grown&nbsp;around it. To many outside of the dev realm their efforts culminated in the <a href="https://deno.land/posts/v1" title="">launch of&nbsp;1.0</a> in May 2020.</p><h3>What do Node.js and Deno have in common?</h3><p>Both Deno and Node run on the same technology platform: The <a href="https://en.wikipedia.org/wiki/V8_(JavaScript_engine)" title="">V8 JavaScript engine</a>. This is a widespread JavaScript runtime that is largely developed by Google for their <a href="https://en.wikipedia.org/wiki/Google_Chrome" title="">Chrome</a> web browser, but is also present in&nbsp;<a href="https://www.chromium.org/" title="">Chromium</a> variants like <a href="https://opera.com/" title="">Opera</a> and <a href="https://www.microsoft.com/en-us/edge" title="">Microsoft Edge</a>. The&nbsp;<a href="https://v8.dev/" title="">V8 project</a> has&nbsp;received huge investments in time and resources from volunteers and companies. In short,&nbsp;V8 is a killer: It's blazing fast and gets new language features from&nbsp;<a href="https://www.ecma-international.org/publications/standards/Ecma-262.htm" title="">ECMAScript-262</a> (the standard that defines <a href="https://en.wikipedia.org/wiki/JavaScript" title="">JavaScript</a>).</p><p>Node and Deno both do more or less the same thing: They run JavaScript code on a server (yes, there is always a server, even if you're <a href="https://en.wikipedia.org/wiki/Serverless_computing" title="">serverless</a>). The range of apps that can be&nbsp;built&nbsp;is wide; a&nbsp;data pump proxying streams of data from one location and format to another is a common use case, as are API backends for <a href="https://en.wikipedia.org/wiki/Single-page_application" title="">SPAs</a>,&nbsp;but you can also write complex full-stack backend apps like the <a href="https://ghost.org/" title="">Ghost blogging platform</a> or custom apps with <a href="https://developers.ibexa.co/content-root/blog/getting-started-with-next.js-and-ez-platform">a framework like Next.js</a>&nbsp;that runs&nbsp;<a href="https://en.wikipedia.org/wiki/Isomorphic_JavaScript" title="">on the server and the client</a>.</p><p>The shared architecture of JavaScript/V8 means both share similar performance characteristics. There can be some differences, where one is better than the other - but as a baseline both are performant enough for most uses and can be scaled horizontally. If you're looking for the absolute best throughput you should probably <a href="https://www.ageofascent.com/2019/02/04/asp-net-core-saturating-10gbe-at-7-million-requests-per-second/" title="">look at something like .NET Core</a> or something very&nbsp;low level. There are areas where V8 performance won't cut it, but if you're in those fields then you probably know it.</p><p>The JavaScript ecosystem is massive. The core skills you need to work with either Node or Deno are very similar. The syntax is identical, even though Deno actually enforces the use of <a href="https://www.typescriptlang.org/" title="">TypeScript</a>&nbsp;in the <a href="https://en.wikipedia.org/wiki/User_space" title="">userland</a>. TypeScript is a superset of JavaScript, adding optional typing and other features that can be useful in development phase. It's also worth noting that you can also develop Node.js apps in TypeScript, and ultimately the V8 engine executes loosely JavaScript that is compiled from the TypeScript source.</p><h3>How is Deno different from Node.js?</h3><p>Unlike with Node, the use of TypeScript is a requirement with Deno. Some parts of Deno itself are written in TypeScript, but <a href="https://startfunction.com/deno-will-stop-using-typescript/" title="">the team is looking to change that</a> as it is not well suited for that purpose. TS is <a href="https://basarat.gitbook.io/typescript/type-system" title="">not strictly typed</a> and does not offer a bullet proof runtime enforcing 100% <a href="https://en.wikipedia.org/wiki/Type_safety" title="">type safety</a>, but relies quite a bit&nbsp;on <a href="https://en.wikipedia.org/wiki/Type_inference" title="">type inference</a>&nbsp;to <a href="https://symfony.fi/entry/a-practical-introduction-to-typescript-for-php-developers#make-javascript-great-again" title="">enable type checking and associated development time tooling in&nbsp;IDEs for JavaScript</a>.</p><p>Another significant difference is the security model. Node.js never had a universal security model baked in. This means that it easy to write code that will do a lot of harm in the wrong hands,&nbsp;maliciously&nbsp;or accidentally. The approach in Deno is different,&nbsp;in line with browsers and the <a href="https://developers.ibexa.co/content-root/blog/secure-by-default-why-the-role-based-permission-model-offers-powerful-security" title="">Ibexa DXP permissions&nbsp;model</a>:</p><blockquote><p>Deno is secure by default. Therefore, unless you specifically enable it, a deno module has no file, network, or environment access for example. Access to security-sensitive areas or functions requires the use of permissions to be granted to a deno process on the command line.<br>- <a href="https://deno.land/manual/getting_started/permissions" title="">Deno Manual: Permissions</a></p></blockquote><p>The <a href="https://en.wikipedia.org/wiki/Standard_library" title="">standard library</a> is another area where Deno is different from Node.js. Node has a fairly small standard library, which has lead into a large number of&nbsp;external packages for (what some think) should be offered by default in the distribution. For Deno this is again different, as they offer a more comprehensive standard library inspired by&nbsp;<a href="https://golang.org/" title="">Go</a>:</p><blockquote><p>deno_std is a loose port of&nbsp;<a href="https://golang.org/pkg/">Go's standard library</a>. When in doubt, simply port Go's source code, documentation, and tests. There are many times when the nature of JavaScript, TypeScript, or Deno itself justifies diverging from Go, but if possible we want to leverage the energy that went into building Go. We generally welcome direct ports of Go's code.<br>- <a href="https://deno.land/std" title="">Deno Standard Library</a></p></blockquote><p>Related to external packages, this is another big difference between the two. Node.js relies on a central repository, <a href="https://www.npmjs.com/" title="">NPM</a>, for storing and delivering libraries and other code. This ecosystem is a huge benefit for developers as it reduces duplication. With <a href="https://snyk.io/blog/npm-passes-the-1-millionth-package-milestone-what-can-we-learn/" title="">over a million packages on NPM</a>,&nbsp;it's a common phrase to say <em>there's an NPM package for that</em>&nbsp;in the developer circles. And often this is true, and the benefits are obvious.</p><p>Shared code is good code, and Deno does not intend to implement everything in the <em>stdlib</em>. What is fundamentally different is the distribution model. Instead of a central repository, any URL can contain a package. The project hosts a set of packages over at&nbsp;<a href="https://deno.land/x">deno.land/x</a>, but it is not enforced anywhere. This means there is no central owner like NPM (now owned by GitHub owned by Microsoft). This approach means you can host a HTTP server (public or private) and reference libraries from there.</p><p>Another area related to extensions is the simplification of code packaging. When Node.js came around, there was no standard module format in the ECMAScript spec. This is why Node.js rolled&nbsp;its&nbsp;own module format, known as&nbsp;<a href="https://en.wikipedia.org/wiki/CommonJS" title="">CommonJS</a>. Because of the popularity of Node.js, CommonJS became the <a href="https://en.wikipedia.org/wiki/De_facto_standard" title="">de facto standard</a>&nbsp;for modules in the JavaScript ecosystem. Since that time the ECMAScript has received regular updates and now includes a <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Modules" title="">standard JavaScript Modules</a>&nbsp;that also <a href="https://jakearchibald.com/2017/es-modules-in-browsers/" title="">work in browsers</a>.</p><p>Nowadays <a href="https://nodejs.medium.com/announcing-core-node-js-support-for-ecmascript-modules-c5d6dc29b663" title="">Node.js also&nbsp;supports JavaScript&nbsp;modules</a>, but much of the ecosystem continues to use CommonJS. Both formats do more or less the same thing, but with a different syntax. This can make it confusing to work with Node since you can use two different ways for a core functionality. <a href="https://deno.land/manual/examples/import_export" title="">Deno standardizes on ES modules</a>.</p>        
<div>
    
    
    <figure><img src="https://developers.ibexa.co/var/site/storage/images/_aliases/medium/0/0/3/2/112300-1-eng-GB/deno-mascot.png" alt="" height="188" width="200"></figure>

</div>
<p>Finally there's the mascot, Deno. Just take a look at the <a href="https://deno.land/artwork" title="">artwork from the collection</a> (blog post main image courtesy of&nbsp;<a href="https://www.dimitrijagal.com/" title="">Dimitrij Agal</a>).&nbsp;Who could say no to the lil' one?</p><h3>Conclusion</h3><p>As we've learnt there are a number of similarities between Deno and Node.js, but also some key differences in philosophy and implementation. Perhaps the <a href="https://github.com/denoland/deno/issues/47" title="">most controversial difference</a> is the novel take on dependency management in Deno. Resolving a complex set of dependencies could be more challenging (and potentially more unreliable)&nbsp;in this fully distributed model. It's worth noting that you can use packages from the&nbsp;NPM catalogue with <a href="https://jspm.org/" title="">jspm&nbsp;that hosts NPM packages as ES modules</a>.</p><p>Node.js has massive clout on the market, it is a hot technology and developers are sought after by both startups and enterprises. The vibrant ecosystem&nbsp;proves that there is nothing fundamentally wrong with Node.js and it&nbsp;is a big part of the JavaScript success story of the last decade. Node.js is not going anywhere, but&nbsp;Deno could carve out&nbsp;a niche for itself. One thing&nbsp;that comes to mind is&nbsp;FaaS (<a href="https://en.wikipedia.org/wiki/Function_as_a_service" title="">Function as a Service</a>), whose development could be simpler&nbsp;with Deno's more&nbsp;extensive&nbsp;standard library.</p><p>But wait a minute... This is the <a href="https://www.ibexa.co/" title="">Ibexa</a> blog. What's Deno got to do with you? Well, nothing as of now. We're using plenty of JavaScript, for example,&nbsp;<a href="https://www.reactjs.org/" title="">React.js components</a> for the administration user interface, and our asset build pipeline is Node.js based, courtesy of <a href="https://symfony.com/doc/current/frontend/encore/installation.html" title="">Symfony Encore</a>. But as of now the&nbsp;<a href="https://developers.ibexa.co/content-root/products">Ibexa DXP</a> line of products aren't utilizing any active JavaScript server daemons in Node.js, Deno or <a href="https://cs.nyu.edu/~yap/html/tutorial/getstart.htm" title="">Netscape Livewire</a>.</p><p>Implementations where Ibexa DXP is deployed are a different case. Our technology is often a piece of a puzzle involving many technology components, from&nbsp;<a href="https://en.wikipedia.org/wiki/A/B_testing" title="">A/B testing</a> services to&nbsp;integrations to enterprise backend systems like ERPs. This is where server side JavaScript is widely used, most commonly as <a href="https://developers.ibexa.co/content-root/blog/running-a-node.js-application-on-ibexa-cloud">Node.js apps&nbsp;that also run on Ibexa Cloud</a>, but increasingly as cloud functions like <a href="https://docs.microsoft.com/en-us/azure/azure-functions/functions-overview" title="">Azure Functions</a> or <a href="https://aws.amazon.com/lambda/" title="">AWS Lambda</a>.</p><p>As a melting pot of data and services a Digital Experience Platform needs to be able to interface with everything. This is why it is good for <a href="https://developers.ibexa.co/content-root/success-stories">our clients</a>, <a href="https://developers.ibexa.co/content-root/partners">partners</a> and us to be aware of&nbsp;emerging technologies. Integrations are key for DXPs&nbsp;and Deno could be a contender in that space in the near future. And even if it is not, you always learn by&nbsp;studying&nbsp;alternative solutions to problems. Even the ones you choose not to go for.</p>
</div></div>]]>
            </description>
            <link>https://developers.ibexa.co/blog/deno-is-the-same-as-node.js-but-different</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067625</guid>
            <pubDate>Thu, 12 Nov 2020 08:11:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React Native Is the Future of Mobile at Shopify]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067617">thread link</a>) | @hijklmno
<br/>
November 12, 2020 | https://shopify.engineering/react-native-future-mobile-shopify | <a href="https://web.archive.org/web/*/https://shopify.engineering/react-native-future-mobile-shopify">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p>After years of native mobile development, we‚Äôve decided to go full steam ahead building all of our new mobile apps using React Native. As I‚Äôll explain, that decision doesn‚Äôt come lightly.</p>
<p>Each quarter, the majority of buyers purchase on mobile (with 71% of our buyers purchasing on mobile in Q3 of last year). Black Friday and Cyber Monday (together, BFCM) are the busiest time of year for our merchants, and buying activity during those days is a bellwether. During this year‚Äôs BFCM, Shopify merchants saw another 3% increase in purchases on <a href="https://news.shopify.com/shopify-merchants-break-records-with-29-billion-in-worldwide-sales-over-black-fridaycyber-monday-weekend" target="_blank" title="Shopify merchants break records with $2.9+ billion in worldwide sales over Black Friday/Cyber Monday weekend" rel="noopener noreferrer">mobile, an average of 69% of sales</a>.</p>
<p>So why the switch to React Native? And why now? How does this fit in with our native mobile development? It‚Äôs a complicated answer that‚Äôs best served with a little background.</p>

<p>We have an engineering culture at Shopify of making specific early technology bets that help us move fast.</p>
<p>On the whole, we prefer to have few technologies as a foundation for engineering. This provides us multiple points of leverage:</p>
<ul>
<li>we build <em>extremely</em> specific expertise in a small set of deep technologies (we often become core contributors)</li>
<li>every technology choice has quirks, but we learn them intimately</li>
<li>those outside of the initial team contribute, transfer and maintain code written by others</li>
<li>new people are onboarded more quickly.</li>
</ul>
<p>At the same time, there are always new technologies emerging that provide us with an opportunity for a step change in productivity or capability. We experiment a lot for the opportunity to unlock improvements that are an order of magnitude improvement‚Äîbut ultimately, we adopt few of these for our core engineering.</p>
<p>When we do adopt these early languages or frameworks, we make a calculated bet. And instead of shying away from the risk, we meticulously research, explore and evaluate such risks based on our unique set of conditions. As is often within risky areas, the unexplored opportunities are hidden. We instead think about how we can mitigate that risk:</p>
<ul>
<li>what if a technology stops being supported by the core team?</li>
<li>what if we run into a bug we can‚Äôt fix?</li>
<li>what if the product goes in a direction against our interests?</li>
</ul>
<p>Ruby on Rails was a nascent and obscure framework when Tobi (our CEO) first got involved as a <a href="https://github.com/tobi" target="_blank" title="Tobi on GitHub" rel="nofollow noopener noreferrer">core contributor</a> in 2004. For years, Ruby on Rails has been seen as a non-serious, <a href="https://m.signalvnoise.com/ruby-has-been-fast-enough-for-13-years/" target="_blank" title="Ruby has been fast enough for 13 years - Signal vs. Noise" rel="nofollow noopener noreferrer">non-performant</a> language choice. But that early bet gave Shopify the momentum to outperform the competition even though it was not a popular technology choice. By using Ruby on Rails, the team was able to build faster and attract a different set of talent by using something more modern and with a higher level of abstraction than traditional programming languages and frameworks. <a href="http://www.paulgraham.com/avg.html" target="_blank" title="Beating the Averages - PaulGraham.com" rel="nofollow noopener noreferrer">Paul Graham talks about his decision to use Lisp in building Viaweb to similar effect</a>&nbsp;and <a href="https://twitter.com/mhartl/status/1179561691857616896" target="_blank" title="Michael Hartl on Twitter" rel="nofollow noopener noreferrer">6 of the 10 most valuable Y Combinator companies today all use Ruby on Rails (even though again, it still remains largely unpopular)</a>. As a contrast, none of the Top 10 most valuable Y Combinator companies use Java; largely considered the battle tested enterprise language.</p>
<p>Similarly two years ago, Shopify decided to make the jump to <a href="https://engineering.shopify.com/blogs/engineering/shopify-infrastructure-collaboration-with-google" target="_blank" title="Shopify‚Äôs Infrastructure Collaboration with Google" rel="noopener noreferrer">Google Cloud</a>.&nbsp;<span>Again, a scary proposition for the 3rd largest US Retail eCommerce site in 2019‚Äîto do a cloud migration away from our own data centers, but to also pick an early cloud contender.&nbsp;</span>We saw the technology arc of value creation moving us to focusing on what we‚Äôre good at‚Äîenabling entrepreneurship and letting others (in this case Google Cloud) focus on the undifferentiated heavy lifting of maintaining physical hardware, power, security, the operating system updates, etc.</p>
<h2>What is React Native?</h2>
<p>In 2015, <a href="https://www.youtube.com/watch?v=KVZ-P-ZI6W4" target="_blank" title="React.js Conf 2015 Keynote - Introducing React Native" rel="nofollow noopener noreferrer">Facebook announced</a> and open sourced <a href="https://facebook.github.io/react-native/" target="_blank" title="React Native" rel="nofollow noopener noreferrer">React Native</a>; it was already being used internally for their mobile engineering. React Native is a framework for building native mobile apps using <a href="https://reactjs.org/" target="_blank" title="ReactJS" rel="nofollow noopener noreferrer">React</a>. This means you can use a best-in-class JavaScript library (React) to build your native mobile user interfaces.</p>
<p>At Shopify, the idea had its skeptics at the time (and still does), but many saw its promise. At the company‚Äôs next <a href="https://twitter.com/ShannonKarleen/status/1204881060213002240?s=20" target="_blank" title="Shannon Gallagher on Twitter" rel="nofollow noopener noreferrer">Hackdays</a>&nbsp;the entire company spent time on React Native. While the early team saw many benefits, they decided that we couldn‚Äôt ship an app we‚Äôd be proud of using React Native in 2015. For the most part, this had to do with performance and the absence of first-class Android support. What we did learn was that we liked the <a href="https://en.wikipedia.org/wiki/Reactive_programming" target="_blank" title="Reactive Programming - Wikipedia" rel="nofollow noopener noreferrer">Reactive programming</a> model and <a href="https://help.shopify.com/en/api/getting-started/shopify-and-graphql/graphql-benefits" title="GraphQL Benefits" target="_blank" rel="noopener noreferrer">GraphQL</a>. Also, we built and open-sourced a&nbsp;<a href="https://github.com/Shopify/FunctionalTableData" target="_blank" title="FunctionalTableData on GitHub" rel="nofollow noopener noreferrer">functional rendere</a>r for iOS after working with React Native. We adopted these technologies in 2015 for our native mobile stack, but not React Native for mobile development en masse. <a href="https://www.theglobeandmail.com/report-on-business/how-shopify-finally-got-smart-about-mobile/article33184093/" target="_blank" title="Shopify Grows Up" rel="nofollow noopener noreferrer">The Globe and Mail documented our aspirations</a> in a comprehensive story about the first version of our mobile apps.</p>
<p>Until now, the standard for all mobile development at Shopify was native mobile development. We built <a href="https://engineering.shopify.com/blogs/engineering/tagged/mobile-tooling" target="_blank" title="Mobile Tooling on Shopify Engineering" rel="noopener noreferrer">mobile tooling and foundations</a> teams focused on iOS and Android helping accelerate our development efforts. While these teams and the resulting applications were all successful, there was a suspicion that we could be more effective as a team if we could:</p>
<ul>
<li>bring the power of JavaScript and the web to mobile</li>
<li>adopt a reactive programming model across all client-side applications</li>
<li>consolidate our iOS and Android development onto a single stack.</li>
</ul>
<h3>How React Native Works</h3>
<p>React Native provides a way to build native cross platform mobile apps using JavaScript. React Native is similar to React in that it allows developers to create declarative user interfaces in JavaScript, for which it internally creates a hierarchy tree of UI elements or in React terminology a virtual DOM. Whereas the output of ReactJS targets a browser, React Native translates the virtual DOM into mobile native views using platform native bindings that interface with application logic in JavaScript. For our purposes, the target platforms are Android and iOS, but community driven effort have brought React Native to other platforms such as Windows, macOS and Apple tvOS.</p>
<p><img alt="ReactJS targets a browser, whereas React Native can can target mobile APIs." data-src="//cdn.shopify.com/s/files/1/0779/4361/files/React_Native_Blog_Post_2.jpg?v=1580316281" src="https://cdn.shopify.com/s/files/1/0779/4361/files/React_Native_Blog_Post_2.jpg?v=1580316281"></p>

<p><em>ReactJS targets a browser, whereas React Native can target mobile APIs.</em></p>
<h3>When Will We Not Default to Using React Native?</h3>
<p>There are situations where React Native would not be the default option for building a mobile app at Shopify. For example, if we have a requirement of:</p>
<ul>
<li>deploying on older hardware (CPU &lt;1.5GHz)</li>
<li>extensive processing</li>
<li>ultra-high performance</li>
<li>many background threads.</li>
</ul>
<p>Reminder: Low-level libraries including many open sourced SDKs will remain purely native. And we can always create our own native modules when we need to be close to the metal.</p>
<h3>Why Move to React Native Now?</h3>
<p>There were 3 main reasons now is a great time to take this stance:</p>
<ol>
<li>we learned from our acquisition of Tictail (a mobile first company that focused 100% on React Native) in 2018 how far React Native has come and made 3 deep product investments in 2019</li>
<li>Shopify uses React extensively on the web and that know-how is now transferable to mobile</li>
<li>we see the performance curve bending upwards (think what‚Äôs now possible in Google Docs vs. desktop Microsoft Office) and we can long-term invest in React Native like we do in Ruby, Rails, Kubernetes and Rich Media.</li>
</ol>

<p>We have many mobile surfaces at Shopify for buyers and merchants to interact, both over the web and with our mobile apps. We spent time over the last year experimenting with React Native with three separate teams over three apps: Arrive, Point of Sale, and Compass.</p>
<p>From our experiments we learned that:</p>
<ul>
<li>in rewriting the Arrive app in React Native, the team felt that they were twice as productive than using native development‚Äîeven just on one mobile platform</li>
<li>testing our Point of Sale app on low-power configurations of Android hardware let us set a lower CPU threshold than previously imagined (1.5GHz vs. 2GHz)</li>
<li>we estimated ~80% code sharing between iOS and Android, and were surprised by the extremely high-levels in practice‚Äî95% (Arrive) and 99% (Compass)</li>
</ul>
<p>As an aside, even though we‚Äôre making the decision to build all new apps using React Native, that doesn‚Äôt mean we‚Äôll automatically start rewriting our old apps in React Native.</p>
<h2>Arrive</h2>
<p>At the end of 2018, we decided to rewrite one of our most popular consumer apps, <a href="https://tryarrive.com/" target="_blank" title="Arrive by Shopify" rel="nofollow noopener noreferrer">Arrive</a> in React Native. Arrive is no slouch, it‚Äôs a highly rated, high performing app that has millions of downloads on iOS. It was a good candidate because we didn‚Äôt have an Android version. Our efforts would help us reach all of the Android users who were clamoring for Arrive. It‚Äôs now React Native on both iOS and Android and shares 95% of the same code. We‚Äôll do a deep dive into Arrive in a future blog post.</p>
<p>So far this rewrite resulted in:</p>
<ul>
<li>less crashes on iOS than our native iOS app</li>
<li>an Android version launched</li>
<li>team composed of mobile + non-mobile developers.</li>
</ul>
<p>The team also came up with this cool way to instantly test work-in-progress pull requests. You simply scan a QR code from an automated GitHub comment on your phone and the JavaScript bundle is updated in your app and you‚Äôre now running the latest code from that pull request. JML, <a href="https://twitter.com/jmwind/status/1185268708383645698?s=20" target="_blank" title="JML on Twitter" rel="nofollow noopener noreferrer">our CTO, shared the process on Twitter recently</a>.</p>
<h2>Point of Sale</h2>
<p>At the beginning of 2019, we did a 6-week experiment on our flagship <a href="https://www.shopify.ca/pos" target="_blank" title="Shopify POS" rel="noopener noreferrer">Point of Sale (POS) app</a> to see if it would be a good candidate for a rewrite in React Native. We learned a lot, including that our retail merchants expect almost 2x the responsiveness in our POS due to the muscle memory of using our app while also talking to customers.</p>
<p>In order to best serve our retail merchants and learn about React Native in a physical retail setting, we decided to build out the new POS natively for iOS and use React Native for Android.</p>
<p>We went ahead with 2 teams for the following reasons:</p>
<ol>
<li>we already had a team ramped up with iOS expertise, including many of the folks that built the original POS apps</li>
<li>we wanted to be able to benchmark our React Native engineering velocity as well as app performance against the gold standard which is native iOS</li>
<li>to meet the high performance requirements of our merchants, we felt that we‚Äôd need all of the <a href="https://github.com/react-native-community/discussions-and-proposals/issues/4" target="_blank" title="React Native Fabric (UI-Layer Re-architecture) on GitHub" rel="nofollow noopener noreferrer">Facebook ‚Ä¶</a></li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shopify.engineering/react-native-future-mobile-shopify">https://shopify.engineering/react-native-future-mobile-shopify</a></em></p>]]>
            </description>
            <link>https://shopify.engineering/react-native-future-mobile-shopify</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067617</guid>
            <pubDate>Thu, 12 Nov 2020 08:09:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Release Notes for Regolith 1.5]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067509">thread link</a>) | @pedrokost
<br/>
November 11, 2020 | https://regolith-linux.org/docs/reference/releases/regolith-1.5-release-notes/ | <a href="https://web.archive.org/web/*/https://regolith-linux.org/docs/reference/releases/regolith-1.5-release-notes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
	<p>Release notes for Regolith 1.5.</p>
	<p>Regolith R1.5 is a feature release which includes several improvements and optimizations.  To summarize, Regolith 1.5 ships simpler workspace management, a Rofi-based Look switcher, and numerous internal optimizations and cleanup.  Read below for more details.</p>
<h2 id="known-issues">Known Issues</h2>
<p>Issues and fixes are being tracked in <a href="https://github.com/orgs/regolith-linux/projects/13">this project</a>.</p>
<h2 id="features">Features</h2>
<table>
    <tbody>
        <tr>
            <td>Next Free Workspace</td>
            <td colspan="2">A typical part of managing workspaces in an i3-based desktop is moving to unused workspaces and then loading some applications. Before this feature, a user has to determine which unused workspace they prefer.  This is done by scanning the list of existing used workspaces to determine an unused one. Now, the system can do this automatically.  The <span><span>super</span> <span>`</span></span> keybinding will move to the next free workspace.  <span><span>super</span> <span>alt</span> <span>`</span></span> will move the focused window into the next free workspace.</td>
        </tr>
        <tr>
            <td>View and Change Looks via Rofi</td>
            <td><a href="https://regolith-linux.org/docs/reference/releases/regolith-select-look.png"><img width="640px" src="https://regolith-linux.org/docs/reference/releases/regolith-select-look.png"></a></td>
            <td>Looks can be changed now via a Rofi dialog rather than having to configure the Xresource override via the command-line.  To do this, use keybinding `<super>-<alt>l` and then select from the dialog to load a Look.</alt></super></td>
        </tr>
        <tr>
            <td>GSettings Overrides</td>            
            <td colspan="2">Regolith now uses [gsettings overrides](https://help.gnome.org/admin/system-admin-guide/stable/overrides.html.en) to configure various GNOME settings for use with Regolith.  In previous versions of Regolith, settings were written globally to the user session from within the Regolith startup code.  This could cause issues if the user works in multiple desktop environments.  Now, Regolith GNOME settings are defined in an override file that is only in effect while using a Regolith session.  This allows switching between desktop environments without settings from Regolith impacting other environments.</td>
        </tr>
        <tr>
            <td>New Looks</td>
            <td>
              <a href="https://regolith-linux.org/docs/reference/releases/regolith-dracula.png"><img width="640px" src="https://regolith-linux.org/docs/reference/releases/regolith-dracula.png">
              </a><a href="https://regolith-linux.org/docs/reference/releases/regolith-gruvbox.png"><img width="640px" src="https://regolith-linux.org/docs/reference/releases/regolith-gruvbox.png">
              </a><a href="https://regolith-linux.org/docs/reference/releases/regolith-pop-os.png"><img width="640px" src="https://regolith-linux.org/docs/reference/releases/regolith-pop-os.png">
            </a></td>
            <td>Users have contributed some new Looks to Regolith: dracula, gruvbox, and pop-os.  Each of these looks presents a distinctive color palate, typeface, and GTK theme.</td>
        </tr>
        <tr>
            <td>i3-gaps upgraded to 4.18.2</td>
            <td colspan="2">See i3-gaps <a href="https://github.com/Airblader/i3/blob/a4a1a44275ea402b25d2d1365e1163e496024358/RELEASE-NOTES-4.18.2">release notes here</a>.</td>
        </tr>
        <tr>
            <td>More Refined Customizations</td>
            <td colspan="2">Numerous small changes allow more granular system customization, such as specifying the temperature unit, custom Compositor settings, and a more comprehensive way of changing i3 keybindings without having to copy the entire config file.</td>
        </tr>
        <tr>
            <td>More Desktop Environment Packages</td>
            <td colspan="2">The following packages can be installed in place of <code>regolith-desktop</code> for specific sets of packages based on user needs: <code>regolith-desktop-minimal</code>, <code>regolith-desktop-standard</code>, <code>regolith-desktop-mobile</code>, and <code>regolith-desktop-complete</code></td>
        </tr>
        <tr>
            <td>New default compositor: Picom version 8</td>
            <td colspan="2">See Picom's <a href="https://github.com/yshui/picom/releases">releaes notes here</a>.</td>
        </tr>
        <tr>
            <td>Remontoire upgraded to version 1.4</td>
            <td colspan="2">Includes better multi-monitor support and other bug fixes and enhancements.</td>
        </tr>
        <tr>
            <td>Optional integration with <b>td-cli</b></td>
            <td><a href="https://regolith-linux.org/docs/reference/releases/regolith-td.png"><img width="640px" src="https://regolith-linux.org/docs/reference/releases/regolith-td.png"></a></td>
            <td>Access a simple todo app via Rofi.</td>
        </tr>
        <tr>
            <td>Documentation of development process.</td>
            <td colspan="2">The <a href="https://regolith-linux.org/docs/policy-and-process/development/">Regolith development process</a> is now better documented to enable greater transparency and inclusion.</td>
            <td></td>
        </tr>
      
    </tbody>
</table>
<h2 id="fixes">Fixes</h2>
<p>Have a look at the R1.5 project page for a <a href="https://github.com/orgs/regolith-linux/projects/12">list of bug fixes</a>.</p>
<h2 id="changelog-delta-from-regolith-141-to-regolith-15">Changelog Delta from Regolith 1.4.1 to Regolith 1.5</h2>
<pre><code>########################################
# Release Notes for dracula-gtk
########################################
dracula-gtk (1.0.1-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Remove unnecessary files


dracula-gtk (1.0-1) bionic; urgency=medium

  * [ Ken Gilmer ]
  * Packaging version add4f8c 

########################################
# Release Notes for fonts-materialdesignicons-webfont
########################################
fonts-materialdesignicons-webfont (1.6.50-3regolith3) bionic; urgency=medium

  * Backporting to bionic for Regolith. 


########################################
# Release Notes for gruvbox-gtk
########################################
gruvbox-gtk (1.0.1-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Rename root directory of theme to Gruvbox for consistency w/ other GTK themes.
  * Add gbp config for package management.


gruvbox-gtk (1.0-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * New upstream version 1.0


gruvbox-gtk (1.0-1) bionic; urgency=medium

  [ eximus ]
  * Initial commit
  * gruvbox theme


########################################
# Release Notes for i3-gaps-wm
########################################
i3-gaps-wm (4.18.2-1~regolith2) bionic; urgency=medium

  * Package source from upstream https://github.com/Airblader/i3/releases/tag/4.18.2


########################################
# Release Notes for i3ipc-python
########################################
i3ipc-python (2.1.1-1ubuntu1~ppa6) bionic; urgency=medium

  * Update build dependencies hoping to resolve packaing problems. 



########################################
# Release Notes for i3xrocks
########################################
i3xrocks (1.3.4-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Version bump to match changelog.  Cleanup.


i3xrocks (1.3.3-1) bionic; urgency=medium

  [ Will Winder ]
  * Add optional default resource value.
  * Minor cleanup.
  * Free resource allocated by xcb_xrm_resource_get_string
  * Fix possible truncated resource value.

  [ Ken Gilmer ]
  * Add gbp config file


########################################
# Release Notes for picom
########################################
picom (8-1~1.gbp353272ubuntu1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Remove github files from debian branch.


picom (8-1~1.gbp353272) bionic; urgency=medium

  [ Ken Gilmer ]
  * New upstream version 8


########################################
# Release Notes for plano-theme
########################################
plano-theme (3.36-1-1regolith1) bionic; urgency=medium

  [ Ken Gilmer ]
  * New upstream version 3.36-1


########################################
# Release Notes for plymouth-theme-regolith
########################################
plymouth-theme-regolith (1.0.3-1) focal; urgency=medium

  * Tweaks to config files. 


plymouth-theme-regolith (1.0.2-1) focal; urgency=medium

  * Ship grub file. 


plymouth-theme-regolith (1.0.1-1) focal; urgency=medium

  * Add package hooks. 



########################################
# Release Notes for pop-fonts
########################################
pop-fonts (1.0.3~1555617065~18.04~a86eb73) bionic; urgency=medium

  * Auto Build

########################################
# Release Notes for python3-i3ipc
########################################
python3-i3ipc (2.1.1-1ubuntu1~ppa7) bionic; urgency=medium

  * Changes to python version.


i3ipc-python (2.1.1-1ubuntu1~ppa6) bionic; urgency=medium

  * Update build dependencies hoping to resolve packaing problems. 


i3ipc-python (2.1.1-1ubuntu1~ppa4) eoan; urgency=medium

  * Add python-xlib dependency. 


i3ipc-python (2.1.1-1ubuntu1~ppa2) eoan; urgency=medium

  * Initial release from https://github.com/altdesktop/i3ipc-python/archive/v2.1.1.tar.gz.


########################################
# Release Notes for regolith-compositor-compton-glx
########################################
regolith-compositor-compton-glx (1.1.0-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Init script will kill pre-existing app instance before starting new. Part of fix for https://github.com/regolith-linux/regolith-desktop/issues/475.


regolith-compositor-compton-glx (1.0.10-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Fix typo in compton config file, found by @gservat.


regolith-compositor-compton-glx (1.0.9-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Add xrender-sync-fence to handle issue https://github.com/regolith-linux/regolith-desktop/issues/116.


regolith-compositor-compton-glx (1.0.8-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Ship config file.


regolith-compositor-compton-glx (1.0.7-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Add gbp conf file, cleanup.



########################################
# Release Notes for regolith-compositor-none
########################################
regolith-compositor-none (1.0.3-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Add gbp conf file, cleanup.



########################################
# Release Notes for regolith-compositor-picom-glx
########################################
regolith-compositor-picom-glx (1.1.1-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Fix typo found in https://github.com/regolith-linux/regolith-compositor-picom-glx/issues/1.
  * Init script will kill pre-existing app instance before starting new. Part of fix for https://github.com/regolith-linux/regolith-desktop/issues/475.


regolith-compositor-picom-glx (1.0.1-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Fix typo found in 
  https://github.com/regolith-linux/regolith-compositor-picom-glx/issues/1.


regolith-compositor-picom-glx (1.0.0-1) bionic; urgency=medium

  * Initial release


########################################
# Release Notes for regolith-compositor-xcompmgr
########################################
regolith-compositor-xcompmgr (1.2.0-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Init script will kill pre-existing app instance before starting new. Part of fix for https://github.com/regolith-linux/regolith-desktop/issues/475.


regolith-compositor-xcompmgr (1.1.0-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Add ability to override xcompmgr defaults. Fixes https://github.com/regolith-linux/regolith-desktop/issues/382.


regolith-compositor-xcompmgr (1.0.3-1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Add gbp conf file, cleanup.



########################################
# Release Notes for regolith-default-settings
########################################
regolith-default-settings (1.0-1bionic1) bionic; urgency=medium

  [ Ken Gilmer ]
  * Add bionic specific gsettings overrides.


regolith-default-settings (1.0-1) focal; urgency=medium

  * Initial release, files moved from package regolith-gnome-flashback.


########################################
# Release Notes for regolith-desktop
########################################
regolith-desktop (2.78-1bionic) bionic; urgency=medium

  [ Ken Gilmer ]
  * Move from compton to picom as default compositor.

</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://regolith-linux.org/docs/reference/releases/regolith-1.5-release-notes/">https://regolith-linux.org/docs/reference/releases/regolith-1.5-release-notes/</a></em></p>]]>
            </description>
            <link>https://regolith-linux.org/docs/reference/releases/regolith-1.5-release-notes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067509</guid>
            <pubDate>Thu, 12 Nov 2020 07:51:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Become a Shopify Developer ‚Äì Resources to Become a Shopify Dev]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067407">thread link</a>) | @iliashad
<br/>
November 11, 2020 | https://iliashaddad.com/blog/how-to-become-shopify-developer | <a href="https://web.archive.org/web/*/https://iliashaddad.com/blog/how-to-become-shopify-developer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main><div><article><div><p><span>
      <a href="https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/af240/how-to-become-shopify-developer-0.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="how to become shopify developer 0" title="how to become shopify developer 0" src="https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/0a251/how-to-become-shopify-developer-0.jpg" srcset="https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/bce2d/how-to-become-shopify-developer-0.jpg 250w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/953fe/how-to-become-shopify-developer-0.jpg 500w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/0a251/how-to-become-shopify-developer-0.jpg 1000w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/e3932/how-to-become-shopify-developer-0.jpg 1500w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/451a4/how-to-become-shopify-developer-0.jpg 2000w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/af240/how-to-become-shopify-developer-0.jpg 2600w" sizes="(max-width: 1000px) 100vw, 1000px" loading="lazy">
  </a>
    </span></p><p>Shopify has been growing so fast in the last couple of years. ‚ÄúWe made history in 2018: no other SaaS company has crossed the $1 billion-dollar revenue mark at a faster growth rate than Shopify has,‚Äù said <a href="https://investors.shopify.com/Investor-News-Details/2019/Shopify-Announces-Fourth-Quarter-and-Full-Year-2018-Financial-Results/default.aspx">Tobi L√ºtke</a></p><p>I‚Äôm a self-taught developer who worked as a freelancer and indie maker in 2019 and I learned Shopify app and theme development and I want to share with you resources that help me to become a Shopify developer</p><h3><strong>Prerequisite to learn Shopify Theme Development&nbsp;:</strong></h3><p>Shopify theme is like WordPress themes but Shopify use their markup language (Liquid ) instead of PHP</p><p>You need to</p><ul><li>have basic knowledge with HTML5, CSS3, and JavaScript</li><li>have basic knowledge with jQuey (Many Shopify libraries use jQuery )‚Ää‚Äî‚ÄäOptional</li><li>have basic knowledge with Command Line</li><li>Create a <a href="https://accounts.shopify.com/signup">Shopify Partner account</a> to upload and test your Shopify theme (Free with unlimited Shopify store for development)</li></ul><h3>Prerequisite to learn Shopify App Development&nbsp;:</h3><p>Shopify app is a web app and you can use any programming language like Ruby, Python, PHP or Node JS to build one and in this guide, I‚Äôll focus on Node JS in this guide</p><p>You need to&nbsp;:</p><ul><li>have basic knowledge with HTML5, CSS3</li><li>a good understanding of JavaScript and React (Shopify Polaris built With React but you can use any framework or just vanilla JS)</li><li>good understanding of how to build a full-stack web application (Authentication, consume external API, Send Requests from the front end and deal with it in the back end )</li><li>have basic knowledge with GraphQL (Shopify API built with GraphQL)</li><li>Create a <a href="https://accounts.shopify.com/signup">Shopify Partner account</a> to create, test and publish your Shopify app (Free)</li></ul><h3>Ressources to learn Shopify Theme Development</h3><ul><li><a href="https://www.shopify.com/partners/blog/">Shopify Partner Blog</a>: Articles and guides about design inspiration, Shopify development tips</li><li><a href="https://www.shopify.com/partners/academy">Shopify Partner Academy</a>: Free courses from Shopify team to learn how to work with Shopify tools</li><li><a href="https://www.skillshare.com/classes/Shopify-Essentials-for-Web-Developers-From-Store-Setup-to-Custom-Themes/1070001866/projects">Shopify for web dev</a>elopers: (Free course) Set up your first Shopify store and create your first custom Shopify theme by a Shopify Expert</li><li><a href="https://www.skillshare.com/classes/Advanced-Shopify-Theme-Development/708093439?utm_campaign=video-embed-708093439&amp;utm_source=Video&amp;utm_medium=video-embed">Advanced Shopify</a> Theme: (Free course) Create advanced Shopify theme (Make Shopify theme a single web app using AJAX ) by a Shopify expert</li><li><a href="https://www.shopify.co.uk/partners/shopify-cheat-sheet">Liquid Cheatsheet</a>: Cheatsheet to get all Shopify liquid variables, filters, and helpers</li><li><a href="https://shopify.github.io/liquid-code-examples/">Liquid Code Examples:</a> Collection of code snippets to speed up your development process and understand how to write liquid code</li><li><a href="https://www.youtube.com/playlist?list=PLXQCP3o-w1Pvras8iuflJKO3tfkBT8c0c">Shopify YB Playlist:</a> Youtube course to learn Shopify theme development</li><li><a href="https://shopify.github.io/themekit/">Shopify Theme Kit</a>: a command-line tool to upload your Shopify theme to a Shopify store automatically when changes are made locally</li><li><a href="https://help.shopify.com/en/themes/development">Shopify Theme Docs</a>: Shopify docs to create your Shopify theme</li></ul><h3>Ressources to learn Shopify App Development</h3><ul><li><a href="https://www.shopify.com/partners/blog/">Shopify Partner Blog</a>: Articles and guides about design inspiration, Shopify development tips</li><li><a href="https://www.shopify.com/partners/academy">Shopify Partner Academy</a>: Free courses from Shopify team to learn how to work with Shopify tools</li><li><a href="https://developers.shopify.com/tutorials/build-a-shopify-app-with-node-and-react/set-up-your-app">Shopify React Node App</a>: Tutorial by Shopify team to create your first React and Node JS Shopify app using Polaris (Shopify React design system) and KOA Js to handle server-side rendering</li><li><a href="https://github.com/Shopify/shopify-app-cli">Shopify App CLI:</a> Create your Shopify app like (Create React App), serve your shopify app in Ngrok server (Free) and update your Ngrok server link automatically in your Shopify App dashboard</li></ul><h3>Conclusion</h3><p>Thanks for reading, I wish you the best on your new journey.</p></div></article></div></main></div></div>]]>
            </description>
            <link>https://iliashaddad.com/blog/how-to-become-shopify-developer</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067407</guid>
            <pubDate>Thu, 12 Nov 2020 07:32:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I learned Django so well ‚Äì Blog post]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067291">thread link</a>) | @codewithstein
<br/>
November 11, 2020 | https://codewithstein.com/how-i-learned-django-so-well/ | <a href="https://web.archive.org/web/*/https://codewithstein.com/how-i-learned-django-so-well/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			    	
<div>
    <article itemprop="blogPost" itemscope="" itemtype="https://schema.org/BlogPosting">
	

        

        <p>
            <time datetime="20-11-11">Code With Stein / Nov 11, 20 / 0 comments</time>

            /

            
                <a href="https://codewithstein.com/misc/">#Misc</a>
            
        </p>

        <hr>

        <p itemprop="description">
            People of ask me here on YouTube and by e-mail how I have learned Django so well. I thought I could create a video where I explain it to all of you at once.... and here it is.
        </p>

         

        <div itemprop="articleBody">
            <p>I was introduced to Django when it was released back in around 2005/2006. I watched a video conference called Snakes and Rubies where they talked about Django and Ruby on Rails. I was really impressed with the talk about Django. Adrian made a great talk about the framework.</p>

<p>After the video, I played around with both of the frameworks, but Django quickly became my favorite. I already knew basic Python, so I understood much of the Django code.</p>

<p>I learned the basics and built a couple of small projects. After a few years, I built the biggest project I had done so far. This was a website called "finn en frilanser" which is Norwegian for "find a freelancer". So it was basically a Norwegian version of elance, guru and similar. I learned a lot during this process and it was a really cool project to build.</p>

<p>A few years after this, I built a new really big project using Django. This was a project called "FinnFido". This is kind of an amber alert web application for lost and found pets. I also built an API for the same application which I used for an iPhone and Android app.</p>

<p>So, most of why knowledge has comes from building different projects. Each time I start something new, I try to think of new features I can implement so I can learn even more. For the API I built, I had to learn a lot about JSON and security.</p>

<p>What I think has made me learn most of the Django I know, is actually making videos about the subject. Because when I make videos, I need to explain many different things in my own words. This make it stick better in my head. </p>

<p>When I go through someone elses tutorials, I like to play around with code. I use different variable names and values, change the function names etc. Doing this makes it easier to understand why things are done the way they are.</p>

<p>People learn differently, and the best way for me to learn is "learn by doing" and making it stick better by explaining things in my own words. So this sums up what I have done to learn Django. </p>

<p>This also applies to everything else I know. I learn by doing and becomes even better when I try to teach other about it.</p>

<p>And that's it.</p>

<h2>Video</h2>

<p><iframe width="100%" height="400" src="https://www.youtube.com/embed/PA1AC1vDOfk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
        </div>

        <hr>

        <h3>Comments</h3>

        
            <p>No comments yet...</p>
        

        <h3>Add comment</h3>

        

        
    </article>
</div>

			    </div></div>]]>
            </description>
            <link>https://codewithstein.com/how-i-learned-django-so-well/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067291</guid>
            <pubDate>Thu, 12 Nov 2020 07:12:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Abu Dhabi launches applied research centre (Middle East AI News)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066909">thread link</a>) | @asiaainews
<br/>
November 11, 2020 | https://www.getrevue.co/profile/middleeastainews/issues/abu-dhabi-launches-applied-research-centre-160m-ai-traffic-systems-centre-in-dubai-291113 | <a href="https://web.archive.org/web/*/https://www.getrevue.co/profile/middleeastainews/issues/abu-dhabi-launches-applied-research-centre-160m-ai-traffic-systems-centre-in-dubai-291113">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.getrevue.co/profile/middleeastainews/issues/abu-dhabi-launches-applied-research-centre-160m-ai-traffic-systems-centre-in-dubai-291113</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066909</guid>
            <pubDate>Thu, 12 Nov 2020 05:54:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Decentralized Internet Pt 1: Blockchain Domains]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25066874">thread link</a>) | @guttertec
<br/>
November 11, 2020 | https://www.axelquack.capital/blockchain-domains/ | <a href="https://web.archive.org/web/*/https://www.axelquack.capital/blockchain-domains/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<!-- .cover -->
			<div>
				<div id="post-content">
					<!--kg-card-begin: markdown--><p>It is a common misunderstanding to exclusively associate blockchain technology with cryptocurrencies like Bitcoin. The technology itself offers already a wide range of services like decentralized messaging services, marketplaces and ‚Äì importantly ‚Äì decentralized domain names, which cannot be censored or taken down completely. Imagine payments could be universally shared and owners have full control over their domain asset.</p>
<p>You might ask yourself "What is so special about this?" A simple answer is:  <strong>the internet of today is broken.</strong> We can use the internet, but we do not own anything we do. Here are a few reason why:</p>
<ol>
<li><a href="https://en.wikipedia.org/wiki/Domain_name_registrar">Registrars</a> are mandatory custodians of centralized domains like .com or .net.</li>
<li><a href="https://en.wikipedia.org/wiki/Domain_name_registry">Registries</a> can revoke domains or be taken down</li>
<li>Hosting services can take content offline entirely, not just off their service platform</li>
</ol>
<p>For the first time in history with the creation of blockchain networks like <a href="https://coinmarketcap.com/currencies/ethereum/">Ethereum</a>, <a href="https://filecoin.io/">Filecoin</a> and others there are new possibilities in regards of ownership and control. On the contrary, blockchain domains are not only decentralized but also secured using cryptographic encryption. They represent a new class of assets that truly belong to the owner, and not to a third party or central authority.</p>
<p>This has several advantages, both for the asset owners and their users ‚Äì these include:</p>
<ul>
<li><strong>(Real) Ownership:</strong> The owner has a private key to their domain, so the domain will be entirely under their control. Current solutions are not governed by and do not require approval from e.g. <a href="https://www.icann.org/">ICANN</a>.</li>
<li><strong>Censorship-resistant:</strong> A blockchain domain also makes a website censorship-resistant for the owner, as private keys should be stored in a (ideally non-custodial) wallet to which only the owner has the keys. No third-party can interfere with or disable the site without the private keys.</li>
<li><strong>Replace cryptocurrency addresses with human-readable names:</strong> A blockchain domain replaces the need for copying and pasting rather cryptic wallet addresses and at the same time simplifies sending and receiving payments dramatically. The domains become <strong>payment gateways</strong> by attaching a cryptocurrency wallet address to a domain name; giving users the chance to send or pay money.</li>
<li><strong>Transfer speed:</strong> Blockchain domains do not require an escrow agent to securely exchange the domain or funds. This transfer can happen in less than 1 minute, from or to anywhere in the world.</li>
</ul>
<!--kg-card-end: markdown--><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/pLDDbCZXvTE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><!--kg-card-begin: markdown--><h2 id="ethereumnameservices">Ethereum Name Services</h2>
<p><a href="https://en.wikipedia.org/wiki/Nick_Johnson_(software_engineer)">Nick Johnson</a> and <a href="https://medium.com/@avsa">Alex Van de Sande</a> of the Ethereum Foundation initially conceptualized the <a href="https://ens.domains/">ENS</a> (Ethereum Name Service).</p>
<p>It offers a names system on Blockchain that integrates with the traditional DNS, unlike some of its competitors, <a href="https://ens.domains/">ENS</a> does not want to replace DNS. Additionally the system provides a secure and decentralized way to address different resources using human-readable names. Instead of sending someones ETH to <em>0xa4edd4f3b6a3f15ecce4b73fd9a196cffc7d28ad</em>, a user can simply send to axelquack.eth.<br>
Lastly, another excellent property that <a href="https://ens.domains/">ENS</a> possesses is its interoperability with the rest of the Ethereum ecosystem. <a href="https://ens.domains/">ENS</a> can interact with all Ethereum-based smart contracts. One contract records all the domains and subdomains, as well the owner's details and the link to the Resolver, which is another smart contract that handles the translations from names to addresses or other types of resources and vice-versa.</p>
<p>It should be noted that <a href="https://ens.domains/">ENS</a> has an annual fee for an .eth domain. This fee is about 5 EUR/year for available domains of "normal length", payable in corresponding ETH value. Even though this might not sound expensive, but one should not forget that the provider can change the fee at any time. Since the user cannot simply move the domain to another provider, this is already a point that might be a disadvantage.</p>
<p>If you are using a browser like Brave or even Chrome, the <a href="https://metamask.io/">MetaMask</a> browser extension will give you support. For example, if you are using Chrome with MetaMask, enter "<a href="http://almonit.eth/">http://almonit.eth</a>" into the URL bar and a website search engine will be loaded.</p>
<!--kg-card-end: markdown--><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/g45ofhOyACg?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><!--kg-card-begin: markdown--><h2 id="unstoppabledomainscryptozil">Unstoppable Domains (.crypto/.zil)</h2>
<p><a href="https://unstoppabledomains.com/r/2df713a3dc584f7">Unstoppable Domains</a> was born in 2018 of <a href="https://www.linkedin.com/in/bradley-kam-444aa228/">Brad Kam's</a> desire to "build something at the intersection of tech and policy". Kam studied politics before he met co-founder <a href="https://www.linkedin.com/in/matthew-gould-7877361/">Matthew Gould</a> while working at his first startup, <a href="https://www.talkable.com/">Talkable</a>, a SaaS marketing platform. The startup is backed by <a href="https://draper.vc/">Draper Associates</a> &amp; <a href="https://www.boost.vc/">Boost VC</a> and also received grants from the Ethereum Foundation and the Zilliqa Foundation.</p>
<p>Users can connect with crypto domains such as .zil (live on the <a href="https://www.zilliqa.com/">Zilliqa</a> blockchain) or .crypto (live on Ethereum), to get paid as an example. All someone needs to know is their blockchain domain.<br>
The difference is that .zil domains are stored on and process transactions through the <a href="https://www.zilliqa.com/">Zilliqa</a> blockchain which has low fees. In contrast, .crypto domains are stored on and process transactions through the Ethereum blockchain. Both are capable of pointing to multiple cryptocurrency wallet addresses (for <a href="https://community.unstoppabledomains.com/t/what-cryptocurrencies-are-currently-supported/246">payments</a>) and censorship-resistant website content.</p>
<p>The exciting thing about Unstoppable Domains: A user really buys the domain. Once the domain has been paid for and ended up in a wallet (there is for instance a simple way to store your domains within Coinbase Wallet, Atomic Wallet and so on ‚Äì&nbsp;but also the possibility to store in hardware wallets), nobody can take it away from the owner. Furthermore, <strong>there are no further costs</strong>. That puts the somewhat higher initial costs into perspective quickly. 40 USD are payable for a .crypto domain, 20 USD are payable for .zil domains. Another option is payment by PayPal or Credit Card.</p>
<p>There are multiple ways to access .crypto domains browsers with native support for decentralized websites include Brave (desktop version), Opera (mobile), Status (mobile), MetaMask Mobile (mobile), and Unstoppable Browser (desktop). Besides that it is always possible to install an official Chrome or Mozilla <a href="https://unstoppabledomains.com/extension">extension</a> to access websites built on p2p networks like <a href="https://ipfs.io/">IPFS</a>. The company itself offers a template marketplace and upload functionalities which are interconnected with <a href="https://pinata.cloud/">Pinata</a>.</p>
<p>In May 2020 Unstoppable Domains mentioned they have 200K+ domains registered, 4K+ IPFS websites launched, 12K+ unique Ethereum addresses that own domains just to share some of their key facts. Possible future functionalities mentioned  were support of Decentralized Databases like <a href="https://orbitdb.org/">OrbitDB</a> or <a href="https://gun.eco/">GUN</a> alongside paid hosting.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="finalthoughts">Final thoughts</h2>
<p>Decentralized systems, which do not require a central mediator to function, were already around at the time the Web was invented. Most notably, the Internet was increasingly gaining traction as a large-scale decentralized network. The rise of Blockchain Domains enables not only censorship-resistance, or a shift towards self-ownership, but also simplifies payments with crypto that could drive further adoption of digital assets.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: html--><hr>
<p><i>Website and the information contained herein is not intended to be a source of advice or credit analysis with respect to the material presented, and the information and/or documents contained in this website do not constitute investment advice.</i></p><!--kg-card-end: html-->
				</div><!-- .post-content -->
				<!-- .post-footer -->
			</div><!-- .inner -->
		</article></div>]]>
            </description>
            <link>https://www.axelquack.capital/blockchain-domains/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066874</guid>
            <pubDate>Thu, 12 Nov 2020 05:48:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Key to Consistency]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066783">thread link</a>) | @lassmaglio
<br/>
November 11, 2020 | https://www.sandromaglione.com/2020/11/10/key-to-consistency/ | <a href="https://web.archive.org/web/*/https://www.sandromaglione.com/2020/11/10/key-to-consistency/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Doing things is not easy. The simple act of starting some task can become daunting at times. It is often true that the hardest step is starting the work. Everything else from there will most of the time just flow smoothly.</p><p>We can summarize the secret of getting things done in one rule: <strong>how to make sure I will be able to start</strong>.</p><p>There could be many reasons that stop you from starting something. Some reasons more valid than others.</p><p>Generally, though, the main source of resistance is the mind. People conjure intricated excuses for why they should not do something. One of the most frequent is the maxim: ‚ÄúI do not have time right now, maybe later‚Äù.</p><p>We also know that, in order to achieve a goal, oftentimes consistency is more important than intensity.</p><p>It could be learning a new language, exercising, eating healthy. Consistency means doing a little bit of work every day to ensure success in the long run.</p><p>There are mainly three problems with this model:</p><ol><li>Consistency means starting a task every day</li><li>The results of your work may not be visible for a relatively long period of time</li><li>Doing something every day means forgoing some other activities to find the time to work consistently</li></ol><h3>The solution is simple</h3><p>The key to solving the riddle is called <strong>scheduling</strong>.</p><p>Scheduling means assigning a specific date and time to a task. It is as simple as opening an app (or using pen and paper) and picking a time frame in which you commit to doing the work.</p><p>Scheduling solves all the three problems we identified:</p><ol><li>When you schedule a task, you assign it a time slot every day. You won‚Äôt need to think about it anymore. The trigger will be the clock: when the time comes, you know what to do. There could be no reasonable excuses.</li><li>Scheduling allows you to look into the future and plan how long the whole process will take. Every day you show up will be another success. You will visually see yourself getting closer to the day in which all your discipline will bear its fruits.</li><li>Scheduling is not limited to a single task. You can easily schedule all your day to make sure you will be able to complete all the activities that you want. This process is liberating. It frees you from the burden of thinking what and when to do something in any given moment.</li></ol><h3>How to schedule</h3><p>There is no specific secret about scheduling. It is all about observing your day, from when you wake up to when you go to bed, and writing down what you will do in this time window.</p><p>It will take you 5 to 10 minutes to organize your activities and assign to each of them a start and finish time. Then you can simply stop bothering and go about your day.</p><p>Basically it all comes down to:</p><ol><li>List all the activities you need to perform, with an estimate of how long each activity will take to be completed</li><li>Sort your activities by priority</li><li>Choose when you are going to wake up and go to sleep</li><li>Build your day like a puzzle, assigning a time frame to each activity in order of priority</li></ol><p>These four steps are the basic blueprint. Many strategies and tricks exist to improve the efficiency and effectiveness of your scheduling.</p><p>Nonetheless, the core of the process is all about <strong>prioritizing and executing</strong>.</p><h3>Some secrets to help</h3><p>Some guidelines exist to help you with scheduling. Simple rules you can follow to increase even more you productivity.</p><h5><strong>Reduce context switching</strong></h5><p>Context switching is the time that it takes to switch from one activity to another. This time may vary based on the specific activity you perform.</p><p>For example, switching from studying to working out takes time: you need to reorder your books, prepare your clothes, go to the gym, etc.</p><p>In order to increase productivity, you should try to group similar task together, one after the other. This will help to reduce idle time and completing more tasks during the day (or maybe completing them faster and having more leisure time).</p><h5><strong>Schedule in the evening or in the morning</strong></h5><p>The process of scheduling may not be exciting at times. Scheduling must become a habit during your day. It is important to pick a moment during the day devoted to your scheduling plan. The same time every day.</p><p>Generally, first thing in the morning or last thing in the evening is ideal. That is because you will always have time in these moments of the day (by simply waking up a little earlier or going to bed a little later).</p><p>Furthermore, scheduling in the evening or morning allows you to take a look at your day before starting it, so you will know exactly what you are going to achieve for the day.</p><h5><strong>Never schedule on task after the other with no time in between</strong></h5><p>This rule refers back to the problem of context switching. No task can usually be started with no idle time from the previous one. And it shouldn‚Äôt be.</p><p>We need to give some time to our mind to reload. Therefore, always consider some time in between each task to relax.</p><h5><strong>Review the results at the end of the day</strong></h5><p>No matter if you write your schedule in the morning or evening, reviewing your results is paramount to your success. Take some time in the evening to look at your activities during the day.</p><p>This process will help you to estimate better your times and also have a critical look at what you do during your day.</p><h5><strong>Learn to estimate the time it takes for each activity</strong></h5><p>Scheduling is an estimation. We cannot know how much time each activity will actually take. Nonetheless, we assign it a time frame, from start to finish.</p><p>With time, our ability to estimate the amount of time to assign to each task will improve. Eventually, you should be able to schedule your day with a high degree of accuracy.</p><h5><strong>Schedule leisure time</strong></h5><p>Scheduling does not mean 24 hours of work. Scheduling is all about avoiding procrastination and improving efficiency. If you schedule your day properly, you will accomplish more in less time.</p><p>And guess what? All the time you gain in your day can be used to getting more things done or just chill and relax. <strong>You can literally increase your free time</strong>. All it takes is a little bit of planning and a little bit of consistency.</p><hr><h3>What are you waiting for?</h3><p>Scheduling is really a superpower. You will start seeing results in no time. You will feel less stressed during your day. You won‚Äôt need to think about what do to next. This habit will also give more meaning to your time. I cannot recommend it enough. Just try it and see how it goes.</p></div></div></div>]]>
            </description>
            <link>https://www.sandromaglione.com/2020/11/10/key-to-consistency/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066783</guid>
            <pubDate>Thu, 12 Nov 2020 05:30:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Member (Open Source, P2P, Decentralized Twitter Clone) Releases Windows App]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066663">thread link</a>) | @FreeTrade
<br/>
November 11, 2020 | https://member.cash/p/0cd5f21a46 | <a href="https://web.archive.org/web/*/https://member.cash/p/0cd5f21a46">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="previewcontent">
        <p>Member Desktop (Ember) is Twitter meets Bittorrent.

magnet:?xt=urn:btih:E1E4C04EFEA99A16A992FEF7F8E8F3C5964E865E

It runs on Windows with a single click. Includes pre-synced Bitcoin node, server, db, client. <a href="https://member.cash/m/freetrade">@freetrade</a></p><p><a href="https://member.cash/t/member">member</a></p><p><a href="https://member.cash/p/a058ec8564">Interesting.

Is it a bundled Virtual Machine?</a> <a href="https://member.cash/m/shadowofharbringer">@shadowofharbringer</a></p><p><a href="https://member.cash/p/c813d814a2">It is not a virtual machine - it requires Windows to run. Might look at Linux/Macos releases in the future. </a> <a href="https://member.cash/m/freetrade">@freetrade</a></p><p><a href="https://member.cash/p/3e4fe5c003">&gt;  it requires Windows to run

Well, that's unfortunate but I am no longer interested. I will wait for Linux release.</a> <a href="https://member.cash/m/shadowofharbringer">@shadowofharbringer</a></p><p><a href="https://member.cash/p/dc3a9e51f3">Whens the mobile app coming? ;) </a> <a href="https://member.cash/m/%F0%9D%90%85%F0%9D%90%84%F0%9D%90%84%F0%9D%90%8B%F0%9D%90%92">@ùêÖùêÑùêÑùêãùêí</a></p><p><a href="https://member.cash/p/89d6d52caf">I'm not sure. Seems like a lot of work just to get banned doesn't it ? ;) PWA FTW</a> <a href="https://member.cash/m/freetrade">@freetrade</a></p><p><a href="https://member.cash/p/f3bedd316a">Just in case you missed this on Reddit - here's how to run on Linux. (member.cash uses ubuntu)

Yes, I just updated the repo with the latest 5.0.7 release - here it is - https://github</a> <a href="https://member.cash/m/freetrade">@freetrade</a></p><p><a href="https://member.cash/p/e961c4ab94">|.com/memberapp/server

Let me know if you have any problems.
</a> <a href="https://member.cash/m/freetrade">@freetrade</a></p><p><img src="https://member.cash/img/profilepics/19RyV6XQEww5td2LPWDpK8o5V8at7Vpwgv.640x640.jpg">
    </p></div></div>]]>
            </description>
            <link>https://member.cash/p/0cd5f21a46</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066663</guid>
            <pubDate>Thu, 12 Nov 2020 05:07:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Music-Related Copyright Claims and Twitch]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066598">thread link</a>) | @captn3m0
<br/>
November 11, 2020 | https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/ | <a href="https://web.archive.org/web/*/https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-i18n="ba2fc6a46b864e1cc0b2afadb1eff0cf-content">
    <p>Creators, we hear you. Your frustration and confusion with recent music-related copyright issues is completely justified. Things can‚Äìand should‚Äìbe better for creators than they have been recently, and this post outlines our next steps to get there. Moving forward, we‚Äôll be more transparent with what‚Äôs happening and what tools and resources we‚Äôre building to help.</p>

<p>Copyright law and the DMCA are not small or simple topics, so this won‚Äôt be a brief post. We‚Äôll do our best to keep the legalese to a minimum, though there‚Äôs bound to be technical terms here and there.&nbsp;</p>

<h4 id="dmca-and-twitch"><strong>DMCA and Twitch</strong></h4>

<p>First off, a quick review of what DMCA actually is. The Digital Millennium Copyright Act (‚ÄúDMCA‚Äù) is a set of US laws that allows you to create and share content on digital service providers like Twitch. We comply with the DMCA and similar laws worldwide. Part of complying means that when a copyright holder thinks a streamer has used their content without permission, we have a process in place for them to be able to request the content be taken down.</p>

<p>When we receive a DMCA notification, we process the notification in accordance with our <a href="https://www.twitch.tv/p/legal/dmca-guidelines/">DMCA Guidelines</a>. This includes removing the content, sharing the details with the channel owner, and tracking the allegation.&nbsp;</p>

<p>DMCA takedown notifications can affect your ability to stream because we, as part of our efforts to comply with the DMCA and similar global laws, issue and track copyright strikes and ban the accounts of those who repeatedly infringe the copyrights of others.&nbsp;</p>

<p>This policy is important because we respect the rights of all creators, including those who create or record music, as well as the rights of those who own and control copyrights. As a company that is built around a community of people who create content, we take allegations of copyright infringement seriously.&nbsp;</p>

<h4 id="recent-dmca-notifications"><strong>Recent DMCA notifications</strong></h4>

<p>How did we get to this moment? Until May of this year, streamers received <strong>fewer than 50 music-related DMCA notifications each year</strong> on Twitch. Beginning in May, however, representatives for the major record labels started sending <strong>thousands of DMCA notifications each week</strong> that targeted creators‚Äô archives, mostly for snippets of tracks in years-old Clips. We continue to receive large batches of notifications, and we don‚Äôt expect that to slow down.&nbsp;</p>

<p>This means two things: 1) if you play recorded music on your stream, you need to stop doing that and 2) if you haven‚Äôt already, you should review your historical VODs and Clips that may have music in them and delete any archives that might.&nbsp;</p>

<p>We were as surprised by this sudden avalanche of notifications as many of you were. We also realized that we needed to provide streamers with more educational programs and content management tools to help you deal with this unprecedented number of notifications coming in all at once. So, while we continued to remove content targeted by these notifications as required by the DMCA, we understood VODs and Clips from years ago may not necessarily reflect your current approach to music. Therefore, we also paused the processing of strikes associated with these batched notifications in order to give you the tools, information, and time that you would need to deal with them.</p>

<p>We have analyzed the notifications we received during that period from the end of May through the middle of October. What we found is that more than 99% of the notifications were for tracks that streamers were playing in the background of their stream.&nbsp;</p>

<p>The point of the DMCA is to strike a balance between the interests of rights holders (the major record labels in this case) and creators. Because of this, we were compelled to delete the VODs and Clips that were identified in the notifications. This showed our commitment to upholding our obligations under the DMCA, while affording us the opportunity to sort out the best way to handle issuing strikes in these circumstances. Under these extraordinary circumstances, we recognized creators should have a reasonable chance to understand that content created in the past was being targeted as allegedly infringing and be given an opportunity to change their approach to music use before they got hit with strikes.</p>

<p>This led to the current situation, which is understandably frustrating and worrying for many of you. Given the circumstances, the warning email many of you received didn‚Äôt include all the information that you‚Äôd typically get in a DMCA notification (normally, when we receive a DMCA notification against your channel, we send you an email that includes information about the allegedly infringed work, who the claimant is, how the claimant can be contacted, and possible penalties under our repeat infringer policy, so that you can make an informed decision about whether to submit a counter notification or seek a retraction). We hear your feedback about how frustratingly little information we provided, and we should have made that warning email a lot more informative and helpful.</p>

<p>Over the last several months, we have done our best to manage this situation on behalf of both rights holders and creators. One of the mistakes we made was not building adequate tools to allow creators to manage their own VOD and Clip libraries. You‚Äôre rightly upset that the only option we provided was a mass deletion tool for Clips, and that we only gave you three-days notice to use this tool. We could have developed more sophisticated, user-friendly tools awhile ago. That we didn‚Äôt is on us. And we could have provided creators with a longer time period to address their VOD and Clip libraries ‚Äì that was a miss as well. We‚Äôre truly sorry for these mistakes, and we‚Äôll do better.</p>

<h4 id="how-to-avoid-dmca-notifications"><strong>How to avoid DMCA notifications&nbsp;</strong></h4>

<p>One important question we‚Äôve heard from you is: how can I stream safely and confidently on Twitch without having to worry about getting DMCA notifications from music use?</p>

<p>Most importantly, <strong>don‚Äôt play recorded music in your stream</strong> unless you own all rights in the music, or you have the permission of the necessary rights holder(s). Doing this is the best protection for your streams going forward. If you‚Äôre unsure whether you own all the rights, it‚Äôs pretty likely you don‚Äôt. If you want to include recorded music in your stream, use a fully licensed alternative like Soundtrack by Twitch, or other rights cleared music libraries such as Soundstripe, Monstercat Gold, Chillhop, Epidemic Sound, and NCS.</p>

<p>While we haven‚Äôt received more than a handful of DMCA notifications targeting in-game music, if you‚Äôre playing games with recorded music in them, we recommend you review their End User License Agreements (that wall of text at the beginning of a game) to see how the terms cover streaming with that music. One way to do this is to search for a game‚Äôs official EULA online and then do a ctrl+f (Command+f on Mac) search for words like ‚Äústream,‚Äù ‚Äúlicensed,‚Äù and ‚Äúmusic‚Äù to point you toward the correct sections. If you‚Äôre unsure about the rights, some games allow you to turn off music when streaming, or you can mute the game audio yourself. If neither of those apply, consider turning off VODs and Clips.&nbsp;</p>

<p>For your stream archives (VODs and Clips), right now your only options, if you think they contain unauthorized music, is to either go through them one by one, or, for Clips, use the ‚Äúdelete all‚Äù tool we‚Äôve provided. We understand both of these options have downsides, and we‚Äôre working to provide you more and better options as soon as possible. These things will take time to get right, and new challenges may appear in the future. Regardless, we‚Äôre committing here and now to investing in building better tools and keeping you posted on our progress.</p>

<h4 id="new-products-and-tools"><strong>New products and tools</strong></h4>

<p>Ever since the influx of DMCA notifications began, we have been working on building new (and improving existing) tools to help creators (such as the Clips mass deletion tool). This work is still happening. Many of these changes won‚Äôt be visible to the community, but we‚Äôre focused on three areas where we heard you need more support from us:</p>

<p>First, you don‚Äôt have enough control over the recorded content on your channel. We have made improvements to enable you to mass delete Clips, but in addition, we will (1) expand the use of technology to detect copyrighted audio, and (2) give you more granular ways to manage your archive instead of just a ‚Äúdelete all‚Äù option.</p>

<p>Second, we‚Äôll make it easier for you to control what audio from your live streams will show up in your recorded content. Soundtrack by Twitch has some of this technology built into it, and we‚Äôll work to make it available for everyone regardless of whether you want to use Soundtrack, for which we‚Äôve cleared all necessary rights, or music from others that provide rights-cleared music.</p>

<p>Third, we need to give you the ability to actually review your allegedly infringing content when you receive a DMCA notification, in addition to the details already provided in our takedown notifications - that is, information about what copyrighted work was allegedly infringed, who the claimant is, and how the claimant can be contacted. We also need to help you more easily file counter notifications if you believe you have the rights to use the content‚Äìfor example, because you‚Äôve secured a license, believe the use is a fair use,&nbsp; the claimant does not control the rights, or believe you have the right to use the music without permission.</p>

<p>Some of you have asked why we don‚Äôt have a license covering any and all uses of recorded music. We are actively speaking with the major record labels about potential approaches to additional licenses that would be appropriate for the Twitch service. That said, the current constructs for licenses that the record labels have with other services (which typically take a cut of revenue from creators for payment to record labels) make less sense for Twitch. The vast majority of our creators don‚Äôt have recorded music as a part of their streams, and the revenue implications to creators of ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/">https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/</a></em></p>]]>
            </description>
            <link>https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066598</guid>
            <pubDate>Thu, 12 Nov 2020 04:57:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Good Data Viz Is About the Small Things]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066475">thread link</a>) | @tagawa
<br/>
November 11, 2020 | https://hamiltonulmer.com/notes/data-viz-small-things/ | <a href="https://web.archive.org/web/*/https://hamiltonulmer.com/notes/data-viz-small-things/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
<main>
<article>
    <header>
      
        <p>data visualization</p>
        
      
    
      <p>It's all too common to fixate on the choice of data visualization method at the expense of the just-as-important small choices ‚Äì labels, annotations, animation, and other bits you can add to tell the story better. That‚Äôs really where good data viz shines.</p>
    
    <dl>

      <dt>published</dt>
      <dd>Nov 11, 2020</dd>

      

      
        <dt>topics</dt>
        <dd>
          
            <a href="https://hamiltonulmer.com/topics/dataviz">dataviz</a>
          
            <a href="https://hamiltonulmer.com/topics/communication">communication</a>
          
            <a href="https://hamiltonulmer.com/topics/data%20science">data science</a>
          
        </dd>
      
    </dl>
    </header>
    <p>I recently consulted on an internal data visualization project at work, where someone asked this question: <em>‚ÄúWhat's type of data graphic best shows this particular insight?‚Äù</em> I've been asked variations of this a lot over the years, and thought it might be better to just write an answer for posterity's sake.</p>
<p>In my experience, picking a data visualization method to convey some kind of insight is really the start of your journey, not the end. This is not to say that the choice isn‚Äôt important. There‚Äôs plenty of reading material on the internet that addresses the tradeoffs between, say, <a href="https://towardsdatascience.com/not-a-funnel-use-sankey-to-represent-your-sales-process-9621b6578c42">a funnel chart and a Sankey diagram</a>. It's just that fixating on the graphic type focuses the solution on a specific output, not a desired outcome. You have to go so much further.</p>

<p>To that end, I try to get others to reframe the question to this: <em>‚Äúhow can this data visualization enable the reader to effortlessly see the story I see?‚Äù</em>. This question can change your tactics in profound ways. After all, getting someone to understand your viz requires you to practice basic reader empathy. Your readers don't always have the time, the context, nor the skills to uncover insights from the data on their own. Your job is to make it easy ‚Äì hell, I'd say <em>trivial</em> ‚Äì for them to reach that "aha!" moment, where their thinking changes and the possibilities open up.</p>

<p>When you shift your focus to <em>telling the story well</em>, you'll begin to understand why your work doesn't stop at picking a visualization method or graphic type, and what to do next. It's the <em>small things</em> that really make the story stick ‚Äì labels, annotations, design choices, animations, mouse interactions, tooltips, data sources, documentation, and other extraneous details not always covered in your favorite data viz book.</p>
<p>The small things make the reader's journey possible. They're the contextual pieces needed to see the story clearly. They're the details that delight them into trusting your expertise; that one annotation that guides their attention; that helpful tooltip that explains a complicated metric; all the pre-empted answers to their immediate questions. Sometimes, they even make room for the reader to explore on their own.</p>
<p>Your graphic choice may point the reader in the right direction. It may even get them part-way there. But the road that leads them to that "aha!" moment is almost always paved with small things.</p>
<figure>
<p><a href="https://hamiltonulmer.com/img/road-dataviz.jpg">
<img src="https://hamiltonulmer.com/img/road-dataviz.jpg">
</a>
</p>
<figcaption>
  Ridge hiking near Muir Beach, San Francisco in the distance. 

</figcaption></figure>
<p>"Small" may not be the right word ‚Äì not all of these things are visually small ‚Äì but I think it works in this context. Juxtaposed with the "big" choice of graphic type, these other parts are seen as smaller and more numerous. This is probably why they're considered afterthoughts, if they're even considered at all. But without them, readers are liable to:</p>
<ul>
<li><strong>get lost</strong> ‚Äì misinterpreting the visualization can push them to form the wrong conclusion or make the wrong decision.</li>
<li><strong>get stuck in the mud</strong> ‚Äì they might fixate on a meaningless part of the visualization, assuming there is something important that isn't really there, without arriving at the core insight.</li>
<li><strong>give up and head elsewhere</strong> ‚Äì if your data visualization is hard to understand, they may just give up, making a decision without any data.</li>
</ul>
<p>Building intuition about what small things to add is a byproduct of hands-on experience and relentless reader empathy. It requires putting a data visualization in front of someone and seeing them struggle to understand, and having the drive to understand and address their confusion and frustration. The more you do it, the easier it gets to anticipate the ways you can make your visual story clearer.</p>

<p>When a reader does truly understand the story, it's a rewarding experience. The insights will often lead to deeper, more interesting questions and explorations (I sometimes call this the <em>data viz happy path</em>). Isn't this the whole point of telling visual stories with data ‚Äì helping others reach a new understanding?</p>
<p>It's not controversial to say that this idea ‚Äì small details transforming a work from "meh" to "good" ‚Äì is true in just about every communication medium. Small things reduce the cognitive load and make the medium itself disappear, leaving only the story. A great screenplay, an enthralling book, a song that grooves so well it can either fade into the setting or command your attention. "Good" work is not contructed by accident yet feels natural. And so it is with good data visualization. When it's really good, the graphic choices disappear, and the insights remain.</p>
<h3 id="an-example"><a href="#an-example">¬∂</a> An Example</h3>
<p>Let's see the difference between these two framings ‚Äì <em>picking a graphic</em> vs. <em>telling the story well</em> ‚Äì  through a practical example. Say you are fixated on ‚Äúwhich graphic?‚Äù and pick a Sankey chart as a way of expressing some sort of user acquisition funnel for your company's newly-launched product, Sprockets Desktop. The software package you're using can easily express a series of state transitions as a static Sankey diagram, and you're surprised by how easy it is to get something together. You share the chart below with the product manager, who has never seen the acquisition funnel numbers before: <em>"Here's the acquisition funnel we talked about. Any thoughts?"</em></p>

<figure>

<figcaption>
  Stopping at "what graphic to use?"

</figcaption></figure>
<p>The response you get back from the very busy product manager is, well, terse:</p>

<blockquote>
<p><em>Looks good, thanks.<p>
‚Äì the PM</p></em></p>
</blockquote>
<p>You've reached a crucial moment. The product manager may never give you feedback on what's wrong, especially if they are not particularly data-savvy or don't have the time. But you can tell they're underwhelmed.</p>
<p>And this is where people sometimes screw it up. They assume it's because the visualization method isn't right. Before you change directions, let's say you prod this product manager for some real feedback. This encourages them to unleash a longer critique:</p>

<blockquote>
<p><em>What period of time is this chart for? These labels look like columns in a SQL resultset and I don't understand all of them. This Sankey chart gives me a good sense of the overall funnel dynamics but it's missing the numbers. Are these user states big or small in practice? I'd like to just SEE the numbers on the thing directly ‚Äì there‚Äôs so much room available. This is for Sprockets Desktop, right? Why isn‚Äôt the title more descriptive? How do you define these different states? Can I get the raw data somehow? It's neat to see this funnel, but I'm struggling to understand it. Sorry, just being honest!<p>
‚Äì the PM</p></em></p>
</blockquote>
<p>Changing what type of graphic you use won't answer these questions. The reader didn't even criticize the choice of Sankey chart.</p>
<p>Now, let's say you shift your thinking from  <em>picking a graphic</em> to <em>telling the story well</em>, and add the small things they complained about:</p>
<figure>
  <div>
    <a href="https://hamiltonulmer.com/img/sankey-annotation.svg"><!--?xml version="1.0" encoding="UTF-8" standalone="no"?-->

<svg width="100%" viewBox="350 100 1020 475" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" xmlns:serif="http://www.serif.com/" style="fill-rule:evenodd;clip-rule:evenodd;">
    <use xlink:href="#_Image1" x="366" y="308.577" width="237.942px" height="187.8px" transform="matrix(0.999756,0,0,0.998939,0,0)"></use>
    <use xlink:href="#_Image2" x="613.709" y="309.25" width="237.894px" height="127.972px" transform="matrix(0.999553,0,0,0.999779,0,0)"></use>
    <use xlink:href="#_Image3" x="861.72" y="293.8" width="237.796px" height="75.992px" transform="matrix(0.999145,0,0,0.9999,0,0)"></use>
    <use xlink:href="#_Image4" x="862.125" y="371.316" width="237.698px" height="30.788px" transform="matrix(0.998733,0,0,0.993152,0,0)"></use>
    <use xlink:href="#_Image5" x="1108.53" y="294.43" width="237.971px" height="61.826px" transform="matrix(0.999877,0,0,0.997191,0,0)"></use>
    <use xlink:href="#_Image6" x="1109.85" y="356.285" width="238.618px" height="29.857px" transform="matrix(0.998401,0,0,0.995235,0,0)"></use>
    <use xlink:href="#_Image7" x="1109.85" y="387.947" width="238.618px" height="40.569px" transform="matrix(0.998401,0,0,0.989495,0,0)"></use>
    <use xlink:href="#_Image8" x="1110.55" y="330.721" width="239.382px" height="79.74px" transform="matrix(0.997426,0,0,0.996748,0,0)"></use>
    <use xlink:href="#_Image9" x="366.112" y="184" width="980.45px" height="125.94px" transform="matrix(0.999439,0,0,0.999521,0,0)"></use>
    <use xlink:href="#_Image10" x="862.37" y="400.37" width="485.236px" height="71.658px" transform="matrix(0.998428,0,0,0.995255,0,0)"></use>
    <use xlink:href="#_Image11" x="613.795" y="436.307" width="732.691px" height="109.832px" transform="matrix(0.999578,0,0,0.998473,0,0)"></use>
    <rect x="356.132" y="190.476" width="10" height="296"></rect>
    <text x="372.132px" y="204.676px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">W<tspan x="385.093px 392.879px " y="204.676px 204.676px ">eb</tspan> Sessions</text>
    <text x="372.132px" y="220.676px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">100% (163,500)</text>
    <rect x="603.632" y="317.825" width="10" height="177.6"></rect>
    <text x="619.632px" y="332.025px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Signups</text>
    <text x="619.632px" y="348.025px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">60% (98,100)</text>
    <rect x="851.132" y="310.11" width="10" height="118.4"></rect>
    <text x="867.132px" y="324.31px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">New Installs</text>
    <text x="867.132px" y="340.31px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">40% (65,400)</text>
    <rect x="1098.63" y="294.224" width="10" height="59.2"></rect>
    <text x="973.604px" y="308.424px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Complete ProÔ¨Åles</text>
    <text x="1012.58px" y="324.424px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">20% (32,700)</text>
    <rect x="1098.63" y="369.424" width="10" height="29.6"></rect>
    <text x="982.935px" y="383.624px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Skipped ProÔ¨Åles</text>
    <text x="1014.58px" y="399.624px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">10% (16,350)</text>
    <rect x="1346.13" y="319.288" width="10" height="50.32"></rect>
    <text x="1264.67px" y="333.488px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Activations</text>
    <text x="1265.08px" y="349.488px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">17% (27,795)</text>
    <rect x="1346.13" y="385.608" width="10" height="38.48" style="fill:rgb(177,177,177);"></rect>
    <text x="1242.2px" y="399.808px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Didn't Activate</text>
    <text x="1267.08px" y="415.808px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">13% (21,255)</text>
    <rect x="1346.13" y="184.888" width="10" height="118.4" style="fill:rgb(177,177,177);"></rect>
    <text x="1244.27px" y="199.088px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Didn't Sign Up</text>
    <text x="1256.08px" y="215.088px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">40% (65,400)</text>
    <rect x="1346.13" y="440.088" width="10" height="29.6" style="fill:rgb(177,177,177);"></rect>
    <text x="1178.73px" y="454.288px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Never Launched the App</text>
    <text x="1263.08px" y="470.288px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">10% (16,350)</text>
    <rect x="1346.13" y="485.688" width="10" height="59.2" style="fill:rgb(177,177,177);"></rect>
    <text x="1250.69px" y="499.888px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:14px;fill:var(--color--text);">Didn't Install</text>
    <text x="1260.08px" y="515.888px" style="font-family: var(--font--text), 'Arial', sans-serif;font-size:14px;fill:var(--color--text);">20% (32,700)</text>
    <circle cx="362" cy="525px" r="2" fill="gray"></circle>
    <line x1="362" x2="450" y1="525px" stroke-dasharray="4,1" y2="525px" fill="gray" opacity=".5" stroke="gray" marker-end="url(#arrow)"></line>
    <text x="460px" y="524px" dy=".35em" font-size="12" font-style="italic" fill="gray" text-anchor="start">funnel direction</text>
    <g transform="matrix(1,0,0,1,278.507,75.402)">
        <text x="81.948px" y="47.486px" style="font-family: var(--font--comment), 'Arial', sans-serif;font-size:16px; fill: var(--color--comment)">SPROCKETS DESKTOP</text>
        <text x="81.948px" y="72.271px" style="font-family: var(--font--text), 'Arial', sans-serif;font-weight:700;font-size:24px; fill:var(--color--text);">User Acquisition Journey</text>
        <text x="81.948px" y="93.729px" style="font-family: var(--font--comment), 'Arial', sans-serif; font-size:14px; fill:var(--color--comment)"><tspan style="font-style: italic">% of Web Sessions</tspan>, October 25th - October 31st, 2020</text>
            <text x="1075" y="50" text-anchor="end" font-size="12" style="font-family: var(--font--comment); fill: var(--color--link);">query</text>
            <text x="1075" y="75" text-anchor="end" font-size="12" style="font-family: var(--font--comment); fill: var(--color--link);">dataset</text>
    </g>
    <defs>
        <marker id="arrow" viewBox="0 0 10 10" refX="5" refY="5" markerWidth="5" markerHeight="5" orient="auto-start-reverse">
            <path d="M 0 0 L 10 5 L 0 10 z"></path>
        </marker>
        <image id="_Image1" width="238px" height="188px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAO4AAAC8CAYAAAB/qJLeAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAELklEQVR4nO3aTXLaWBiG0Y8fx7E7M6Y9yVZ6LZqxHs3YTW8lU8262k78Qw8sEgzGAUwDr31O1S2jaw8urnpAutKgabuvVXVVVfN+PC69PurxbDqZF/Bb46r6q6r+PPVCqqqatqt6HvVy2Pcr427LuV3n76rqfjadPPzPbxf2Nj71Al4w6Meqy2Muov8QWQ36R1V9r6rb/ufyeGnu57wPAg7pHMM9J+M60P+oabuHej3y1bnbqvq3qm76cetSggXhHs+oqq77sZem7RYR39TzqDcez6aT729bNudIuFmu+rG1pu0e63nQW0U/m07uDrdsDk2479+wqv7ox9b6U/udvt3r6Rv+/mArZyPhssmoqr70Y2sr1/K7XNM/m5tNJ48HeRfvlHA5tDdfy1dVNW13X+tB/6jD3fZbzD8kbvoJl3O12NHf6RR/H/1ZwqbQH+rEDya9cPyPcOHpLGFUR35W4A2+DU+9AmB3woVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAw/n8cXDqRQC7GQ4Gw/mpFwHsxqkyBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBpX1d9V9aWeIh4sjVMeD6tq1K9vdVz0v4MPa3DqBeyjabtBrYd9UZtD32b+oqo+VdXlyrg40tuCbX2LDPeYmrYb1nrMn/eYc5bAoQj3WJq2G9dTyNdVdbU0Xju+LsGzTrjnrmm7i3o97E2/s/H4fgn3vWra7lNtH/ni9ecK3ff4YITLL/2m32WtR7567f7adf346Av/eITLYTVtN6r9N/MW4S/v9LNOuJy3/oNgm1t8u9wO/N3fbnq+4FwIF3bR3x489YNKN/8BaBQxe31z5s0AAAAASUVORK5CYII="></image>
        <image id="_Image2" width="238px" height="128px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAO4AAACACAYAAAAMEFUIAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAC8UlEQVR4nO3YPW5aQQCF0YuD4yitm6wg+8he6FgPnZvsLg1tFPwDaXDkWGDg2QZf+xxpBBq9J81DfGKYUYA3ZTKbj5KMkpytXx+P1eh0y4PDTGbzsyTjJJ/Wrw/fPzU35PpNwTwc26J67j37+DXe80I4yGQ2P09ysWF82TL/cJxnc2Cs+TD4Z71F+5zdYe0z7OZekXDfgXVwLxHbxbHXzjDCPaH1f7Z9Ytq1vTw/9to5LeEOMJnNx3mZXzefP4O8my/OZDYfeoL4eG7bocrDcXakx4KNxpPZ/HuSr3nZI+1Dj8u3XXvI8T18GOMkP5J8O/VCgP3Z8kEh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UIh4UKZ1WopXGgzGp0JFxoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwqNT70AOIHbJHePXjfN3SVZJlkdMA69fsh9v4XLW7BM8ifJYsu4TnKT3aHtnLuaXt4d66Fek3B5jttsj+1+PBXkIsnivcR0TML9mK6zO7id42p6uTz6ykki3Db7RrXpV+56PX99Nb1cHX3lvCjhvr5VBmwfN4wbwXFPuP9bZfOhxm2Gxba4ml7eHPcR+AgODXfokfeQI/L7e5LDju+fc+LoPxsVxkl+rt9vjcgWDd6Wvyp5ER6r/UC5AAAAAElFTkSuQmCC"></image>
        <image id="_Image3" width="238px" height="76px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAO4AAABMCAYAAABqOovHAAAACXBIWXMAAA7EAAAOxAGVKw4bAAADGElEQVR4nO3cX26iUBiH4R/WsXXi/Om4g9nObIM71sMde5qVMGrbpGpHmQtxShFUVDh88D4JQU/a5Nj0zSkHrScAlflhfCdpkDvyY3V9zdJr4DUCjfPD2JN0L+khdy57nB0b6Xg8rrv5M3Q8AeBAupqdiuvU2KfGJ94gwkVj/DAeSfqSOSa55/uxkas5WkG4uJofxvcqDjH/vNOrYJMIF6XS68SJpO/pURYlQTaMcHvOD+PP2kX5mDvvjzt3s0MZwu249M/YfYRFcXI9aRDhGueH8VCHYWYfj93NDnUh3Jbzw3gg6asOV8v9eeJudnCFcB3LbAAVrZaP2kXr+oY/WoZwa+aH8ViH9yq/iQ0gXIFwL5Tuxp66dzkRUaIGhJuRXk8+qPwNBBMRJFqgM+Gmu6uXvKc1O9aZnwe67aa/qOmKdeojSlU+2lQlvsEtXwvQZkM/jH9pt1lSNbaiMQANGEr6KemH64kAOB+rJGAQ4QIGES5gEOECBhEuYBDhAgYRLmAQ4QIGES5gEOECBhEuYBDhAgYRLmBMkmwJF7DG8waEC1hEuIBBhAsYRLiAQYQLGES4gEGECxhEuIBBhAsYRLiAQYQLGES4gEGECxg0SJKt6zkAqGjgeSy6gDVUCxhEuIBBhAsYRLiAQYQLGES4gEGECxhEuIBBhAsYRLiAQYQLGES4gEFD1xMAemYraZOes0d+7NjXLAgXfbOVtJS0ypxXJWMrvcdyTmxHA4yCaXKrF0G4sORN5wVXOhYF07/NT/v2CBeubSS9SHrOHEXPl1Ew5b8+pAgXddmoPML/z6Ng+upshoYRLi6xkTSXNEvPC+XCJMh6ES6KJNrFmI1zf55LernlRguqI9z+etZ7iPk4n7iebDfC7a5XFa+WM0mLruyu9hXh2rVW8Wo5kzSPguna4dxQM8Jtr/wG0Ic42fzpN8J1400fb5Fkb5OwAYSTCPe21jrv3iV/xuIqhHuefZDH3tlDkGhMH8Jd64L3tGbHomC6aX7aQLm2hJvo+CctLo1vxXUiumgo6beksa7/jOBF38eNfqC6f8+VOQrUh4p7AAAAAElFTkSuQmCC"></image>
        <image id="_Image4" width="238px" height="31px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAO4AAAAfCAYAAADgIPGeAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAyUlEQVR4nO3asQ3CUBBEwQVBRjH0QCu0RB1URkYGkkmIQYDF90oziaM7X/LkxKvj6bJPss1vpvL5Jdwwen4JN7TPz7nn1Y77JskhyW6GFwH/cV2PvgD4nHChkHChkHChkHChkHChkHChkHChkHChkHChkHChkHChkHChkHChkHChkHChkHChkHCh0DrJavQRwGd8caHPJFwoJFwoJFwoJFwoJFwoJFwoJFwoJFwotElyfj6/9eufV6Pnl3DD6Pkl3NA+P+eedztuD61fFUrO8zSAAAAAAElFTkSuQmCC"></image>
        <image id="_Image5" width="238px" height="62px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAO4AAAA+CAYAAAAs0CcNAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAEj0lEQVR4nO3dXW7bRhQF4EOZVuwodmJTrpMGRYsCbVEURVF0A13MvHE986ZldEcBmqTyJKjt2q1/xD7w0uafZEoiORzyfMAFacqW5sEHHJEzQ09p8y2AfQALAJFs8/urXlv2e7ezMLgDEdXOB/A7gK+aeHOlTQTgVupmg22yfw3gCsD1LAxum2grkUv8ht/fAzCWmtTxhkqbO0iIZfvk/iwM/qvjs4m6oungNsEHcChVidJmAeACwPmKupyFwaL21hI1wMXgbmIE4KXUMpHS5hLlof4M4IxnbuqKoQS3Cg/AgdTbsl+QYJ8BmMv2DHGgz9tqJBHA4K7rhdQ36YNKmxukgpyqT7MwuG+5jTQADG49xgC+lEqLlDafkA3zHOx205YY3GZ5AAKpH9IvpLrd6a73fBYGF203ktzD4NqzrNv9D4A/0zULg8vWW0edxuB2zwTAd1IAAKXNBYphvrLTPOoCBtcNB4i72g/dbaXN3yiG+V87zaO2MbjuSu5L/5gcUNp8RjbM73kRrJ8Y3H45kvopOaC0MciG+cMsDG7sNI/qwuD2X3JV++fkgNJmjmyYP3LyhlsY3GE6kfpFfo6UNn+hGGYOHukoBpeA+H7zqdSvcmyhtPmIbJjnDHM3MLi0zAjAG6nf5Ni90uYDgPfIhpmzqlrmLxb33mi0Y7sd5IYdxBMw0pMw7uQ7c35YJ8dpN8gfjXYi240gp/l4PDOnRXJ7qmycNu83b4ldZWqKB+BY6vv0CzKsMz9O+wzA+SwMeCKpgMElGyZSX+eO38p953zX27DbncXgUpfsAngtlbFidZKHGlK4GVxyRTKbKj/n+YHS5grFQF+hZCFB16+EM7jUJ8+lCmfsPFm1pMoqoaVLB9v+Ls7g0lAlywa/2uSPZZngddYJr/qAgSoPI7hmcIk240vtW/jsdyMLH0pEW2JwiRzE4BI5iMElchCDS+QgBpfIQQwukYMYXCIHMbhEDvIB/AFgD3GIPdmOKvy86rVdqXGFLUdvEa3Js90ApY2H5aHel0oGj5ftP2u/1URWvbMe3G0pbUYoD/QE8aM7DlM1sdRMojq5H9x1KG12UAxzvg6sNZCommEFtwoJ9zHiBcOnudq12DSiBINblXwXP0QxzCdgF5zaxeDWQWmzh/JAH6EDFwCpdxjcJqW63ekwJ1veBqONRNGCwbVBroRPES98ltRrxE8KIHoKg9sVcnY+QTbMp+DoNipicLtMwnyKbJi/AL83Dx2D6xqljY+4W50O8xQM85AwuH2gtBmjGObAaqOoSQxuXyltnqEY5mOrjaK6MLhDIveb3yAb5o0WBCerGNyhU9o8RzHMh1YbRU9hcKlIafMC2TC/BYd1dgmDS9UobQ5QnHhxgvgJetQuBpe2IxfB8mGeIr4Qxv+vZjC41AwZPHKEbJiTGltsWh8wuNS+Jd3uKbiIQVUMLnVHqtv9CstXJ+H/LINLLpFZVROUh/olHsPd94kZDC71j5y5n1odNL/v0vxoBpcIAJQ2u3gM8h6yywRXWR+8bNtUvhhcoqbITK4kwOs+VGDVa9f/A97Fr1H4MhUiAAAAAElFTkSuQmCC"></image>
        <image id="_Image6" width="239px" height="30px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAO8AAAAeCAYAAADEvkkFAAAACXBIWXMAAA7EAAAOxAGVKw4bAAACcElEQVR4nO3bXW7aQBiF4dfglBIgqeSldBHdiO9Yj+/YUTfQ2y7AUhIIBRJMLzxuB2wr/JnxxOeRPuEYKfmU5GQmM+MAEfknTtIeMDDVB3oX1jU+R1X9DJv6JojcSpykAfCF/6GzrwdH3Lff8yUTv3xpVD65OEn7wMjU2NQ9H4etuO4chVcaY0bEIox2KMcV94aO2vSWwisni5P0nvoQ2vdGrnrsAoVX9pjp6wPwaOqbdV2Ufm9aQD+EjomTdEg5jHZIx+66k1MovJ+I2eaYUD1aFtXJxZ3PZpdtA4XXI3GSDqgeLYuaAIGzBuVmgl5/p/C2hFmZnVA/nX0k3xYRATRtbpyZytqrs4crs0VgH8hPzogcReE9gxklh2i7RBzqfHjjJA2pPzZXd8BghP63FMe8DK+Zih5zTvWY+5qqipfCOEnvgK808+TDNZ6yuKMcOC//6IhcUwh8B364bkTEsTdgDWzM69rc2wLZjeqUr7XWCCY+y4AV+4E7rLr37Pub2TTKbt38pRReaYMMeAUW1mtRS/KAloI4m0ZbJ922hMIrTToMYt3Hf2bTaOeqSV8pvHKqDHgBnoG5qcNQLoClAtkshVcOrciDeVhP5nWhULaDwtstO/KRsghiqWbTaO2uPTlFuMu2QdDru+5DrmNDeaR8sa7nPq6qSrUw6PU1BfLHnPrp7PNsGq0c9iY3pmlze7xTP519Ih81O701IvsU3mbtyPcpP9wumU2jpasmxU8K73mWVG+PlA4YaGVWmtLl8B5zbG5NHkg7lK9a9JE28C2875x/ftWuN42I4ruQfAXzN5c/5dDUkxRbPD48LtKUv+t6N2dNwxFeAAAAAElFTkSuQmCC"></image>
        <image id="_Image7" width="239px" height="41px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAO8AAAApCAYAAADdwX4QAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAC2klEQVR4nO2d227bMAxAaTtthw3YHxfgN++pyMXbg6mGURTPTnyR5XMAIopjNEaRE9G6MJWqfojID+n4K1debT8MVfXnAsATHCx+LvmmqipyK3Qr/cK3qeBLAPbMYcX3rixERJpn/oB9CSTFTsRFVduXrhggI9aUdypqi/9isl9ctPFzVb3McpUAE1OCvGNppKend4J7sc8h6L0hF/Yo7xCC4G/xCybvOQ56bFga5B1PLSLvFt/Y4FlK6vPiVwi7oPr8/PzVNM3vtS+kcO6klk5sRsvhaQ5N89RAL4wjTMndYKm2F/qkqqeFrw02CmnzuoR7649wwKXfRxE5SSc0qTfcgbz5UUk3UPY9WGZCn3wgNCDvNqgkGiSzUe9YaEa8dwTybpdaunTbp9yx0EfmpcsFecsiJfRF7ntohC4A5C2fMCgWdo4hdCFUqtpIJ3Hlj0/QDhsPatdOBeTBWe6FZh46Y1aXR1VTQtdRu47adXQc5sELfRQWlmTF5j/4Jn+f4I17ZEXK65yiQOiV2Ly8Y7HbBC9z6jmMI14pxg6sBdidvENQ1VquSxoP0gmdXOIIvbADa0aQdwSWonuRffC/HE5yB5Z01U5IwQfCB24i3Kh9HIOqfMA3pOADQd6ZSaTgPhWHcVDCyIG8K2Ep+EGumxBuNiPA08RihwKEd1VIt56iI29GREK/2yODZPORKiscH0uVIc6i/jjyZo4JHffOCJ0PvT8wIFfZ/flx+9HrfeeckXeDuPvo0Du/CffQe+MP8haCCR330AhdLshbMia0753fhKmrUkDevWHz0XEPjdDbA3lBRFVTU1Z8NvIGeSENQmcP8sJwVNVPVbFSbF2QF17DLSxJBcxE27bIC/NhqTc7sOYBeWF52IE1CcgL+WDz0mEqK9xPU8IoDfLCdqCE0Q3IC2Xheu9UpdFUbBXkhX0TVR9NlRXuC3/O0iAvwBQ8qD/+6AcGpmh//QPYWllTHlRvWgAAAABJRU5ErkJggg=="></image>
        <image id="_Image8" width="240px" height="80px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPAAAABQCAYAAAAnSfh8AAAACXBIWXMAAA7EAAAOxAGVKw4bAAAFhElEQVR4nO2dS27jOhBFr/x3nGkDvRztKtNampfzgJ52J7ZsS2/AYqwociwn+pCsewBCdiB02DFPSlX8JBORDMAvOKpaa75vfq3L/SWAUkRKEEJ6Z6HX+ZDfREQA4AIntL+WbV8Tkar9XyGENFncv6U35tqWX92k0bpN9AuAs4icB+4nIdEwpsBdmWlr7ZtG6HOzUWxikRAFvkcGF8U/RPIbYp9E5DJ6DwkZiRgFvkUXsU8AChE5jd89QvonJYFvURd7C7xLXdTaicUzEiMWBG4jA7DWBgCVRuUCwBEUmkRCpvPAv6fuSIDUI3RBoUmIWI3AXVhpAwBohD4CODCHJqFAgbvj8+hnrWwf4GQupu0WsUz28vKSbbdbPkJ/nxJXmY9Td4bYgjlwv5TQx2wAR+bNZGj4CN0vM7ipqi1cZdvLfKDMZAgo8HBkADbaKhF5A/DGnJn0CQUehwzAE4AnXbP9Ciczt1mSHzHP8zwD8Dx1Rwwxg1tA8pzn+TLP82q/33O9NvkWjMDTsgGw0UjsozJ3VZHOsAodHgWczCx8kbswAoeHXwFWisg/AK/MlcktmAOHi99wscvzfJ7n+Xm/3zMikw9Q4PDx2yF3WvQqWfQiHgocFwsAT3mer7V6zYKXcXwOfIH7TQ+9Zu23k0BYAVjppoq/cNVrPl4b5KaoWp3299Sl7vp+Djfn6a+zr74f+RF+GuofC162GFUoEfEi16VuE302Zr8SogLwBicyH68NEGRE1Ojvj5ZtNsrdjSOAv1x7nTZBCvwVIjLHZ6mXiPD/MhInuIj8NnVHSP8kM+hbxP50xKxxLgD8whAWvBIhGYHb0EfxVa0xUrs82Re8OJ8cOaYGswq9xEepTf0MGviCFw/pixTLgxcAICJLuCWLloUu4ApePNMrMiwO1i9Rof1JGtY2e5zh8mQuDIkECvwFIrLAVWZLBbES14IXF4YEDAXuiFa5vcyrO7enAheGBA4F/ga6oqwus4Wf4wFOZC4MCQgLA29QtLK9gTu0zkJkLuBEPkzdEUKBe0Vz5i2czKkv+eROqACgwAMhIhs4mTdT92VguBNqQijwwGi+/AQnc8rTUhVcnvzKPHk8KPCIiMgKTuYN0v7Zn+Gq15yGGpiUB1GwaFTewUaufIDLk1n0GgAKPCFawd7CnUk2n7g7Q8PD6weAAgeCFr12sDMV5f/YGyvYP4ACB4bmyTukX70GXOGrwPVPsDJffhAKHCg6p7yDe8S28jnVZeZe5Q5YGRjRUpuG2iH9gledE64yM2e+AQWOhFrBa4e055PbOOMqMw8fqEGBI0RE1nCVawsFryY+by4AHK0LTYEjRg8f8HmyVepCFwBOlirbFDgBdK+yXxhi/TOt4PLnd6lTFtr6h50Umif7glfqC0Me4QSXR/vrOZUqNwVOFBHxBS9LRwE9QoWG1IhQbAqcOLow5Bnu5E1yH/8Ifm60MsRHcQpsBKMLQ/qmrLVL4/r+eswVZfwgjWFsJ9RUVPgsum9V7Z6q6/tb0Z8CG8XYTqhUaMr9hwITazuhUuI/CkzeMbYTKgUoMPkMC17RQIHJbQzvhIoFCkzuY/Dw+ligwOQxjB1eHzoUmHwf3dboj8kl40OByc/RXNlHZWuHDUwJBSb9olNRW7CCPQYUmAxDrfC1gdtIwbHWPxSYDI/KvMZVZha/+oECk/HR4pePzpT5+1BgMi2aM3uZuaniMSgwCQc9pM9HZ54kch8KTMJE8+ZVo5GPUGASByr0Ek7ktb62Pn4pMImThtC+WRvPFJikg+bQKzixF9pSHuMUmKSNHnq/wEepUxGbAhOb6K6qthaTExSYkDo1sefaZtrqr0OBAhPyCFo8a0rdJvoYi1IoMCFDodssfctqDT29//M/oU4NlA/K/ZQAAAAASUVORK5CYII="></image>
        <image id="_Image9" width="981px" height="126px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA9UAAAB+CAYAAAAqeTKvAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAD9ElEQVR4nO3czWrbQBhA0Ukxhfap9cR9gEJpV4FSnDTc6GdGnLOTxtY32uki7JcBAAAAvGvbtpdn55+eBACAMzx5SP3f8Vvn3ju/yvoMezh6j2fsrzqzjc6aZc7xfj6u3gEAwNFCuB19fJcZewYxwJJENQDsYKe3bbMfrzoDAA4jqgEWMuHbtrOC6Or7Em0AwFOiGib21p8h/OWu63cIwSNmAAAwmce2bd/GGF/Cd/2Qf51ZZ8/cY87sf7JxxjoAADC5xxjj+xjj69UbAQAAgNWUN9QAAADAENUAAACQiWoAAACIRDUAAABEohoAAAAiUQ0AAACRqAYAAIBIVAMAAEAkqgEAACAS1QAAABCJagAAAIhENQAAAESiGgAAACJRDQAAAJGoBgAAgEhUAwAAQCSqAQAAIBLVAAAAEIlqAAAAiEQ1AAAARKIaAAAAIlENAAAAkagGAACASFQDAABAJKoBAAAgEtUAAAAQiWoAAACIRDUAAABEohoAAAAiUQ0AAACRqAYAAIBIVAMAAEAkqgEAACAS1QAAABCJagAAAIhENQAAAESiGgAAACJRDQAAAJGoBgAAgEhUAwAAQCSqAQAAIBLVAAAAEIlqAAAAiEQ1AAAARKIaAAAAIlENAAAAkagGAACASFQDAABAJKoBAAAgEtUAAAAQiWoAAACIRDUAAABEohoAAAAiUQ0AAACRqAYAAIBIVAMAAEAkqgEAACAS1QAAABCJagAAAIhENQAAAESiGgAAACJRDQAAAJGoBgAAgEhUAwAAQCSqAQAAIBLVAAAAEIlqAAAAiEQ1AAAARKIaAAAAIlENAAAAkagGAACASFQDAABAJKoBAAAgEtUAAAAQiWoAAACIRDUAAABEohoAAAAiUQ0AAACRqAYAAIBIVAMAAEAkqgEAACAS1QAAABCJagAAAIhENQAAAESiGgAAACJRDQAAAJGoBgAAgEhUAwAAQCSqAQAAIBLVAAAAEIlqAAAAiEQ1AAAARKIaAAAAIlENAAAAkagGAACASFQDAABAJKoBAAAgEtUAAAAQiWoAAACIRDUAAABEohoAAAAiUQ0AAACRqAYAAIBIVAMAAEAkqgEAACAS1QAAABCJagAAAIhENQAAAESiGgAAACJRDQAAAJGoBgAAgOhx9QYAAIBP+z35+lkzjvjujHOumHnmva10T79ENQDAGv59+Pvs8RHXvGKPb527zfq2bVeEGvBBohoAeLVCtB1xzen2KKIA1iGqATjb1cGzQrQdPkO0AcA+RDVwR8sFzg7HU15TuAEAdzdTVK/0Y/TZZt3tnqb+XdMO15h9f2esv/cZ0QYAwDIeY4wfrwceTgEAAODj/gCkWqOVAS8SegAAAABJRU5ErkJggg=="></image>
        <image id="_Image10" width="486px" height="72px" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeYAAABICAYAAAAj8lblAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAE5klEQVR4nO3dbW/aSBSA0UtId6XV/uj531vi/YCdjidjg8EYv5wjWQ44raKq4ckdGHJKKf0bEaf4o4m+5s5rUz53yt+T324iIlJK5XUA2IXPiPgnIs7v/kKmSClFXCOdH7X77rl213U/DACwhM93fwFPOEV/0n+pgR8G8qh/jZx796WUvpb6ugHYli2H+R1m+WEgi/xYzEfPJniAfRLm9znFE08htHH/MY2350t2rTsuYg6wfsK8bR/tcZc2zL1YRyXgcZ3ILbcDvIEwH0s3pd+c1IuJfDDg3WEaB5iHMDOmm8hv/j9pJ+xLdvRup5QuL/w6AXZDmJlLF/FftYvtBD4Y7rjG2/I5cHjCzJJGl9Hb5fBb8bZkDuyaMLMmp7j+nxz8f1ksmf/Oz5bLgT0QZrZmcMk8m7h/l2fRBrZCmNmTwYm7fY77R7DDEjmwMsLMkXTR/ru80E7UtUn796JfIXB4wgxX1RemZZN2d/wXf57TNmUDs/tsmiZOp8V+FwRs0dDyeB7s70OwgWd8ijI8bCjY3XJ4PmELNnAXS9kwv25ZvPdcdhHsfML2xirAN2GG5QwF+yvqE7ZgwwEJM7zfR0T81R7fimDnE7Y92bBjwgzrNRTsJorpOgQbdkOYYXtOcX3ns967n2XBLidse7FhQ4QZ9mMs2JcoJuywFxtWSZhh/8beqtRebFgZYYZjG9uLXU7Ygg0LEGagZugtSu3FhhcTZmCKW3uxy1eKCzZMJMzAHOzFhpkIM/BK9mLDRMIMvMOtrV35c9mXuG7tsh+bQzillLo4l79m6jTw8ZRrr/h7TwNHeQ3Yny7YP85eMc5e7DZgKaWxaN+K+tTru/13hA3JJ+3eWbTZEkGZSUrpI67/nveca/cBr9O9CO1SO4SbNRHmlWgn/Clxr52Bx3y1RzXcEfEl3izFg/lOZGE/x5+pvHa7O4BpxsJ9sWebuQjzAWURvxXw7j7gtiZ+xvsr+tP4l4BzizBzU/v8eS3g5+ywnA7368U6KgHvDkvox+OBlNm0AT8PHN01YJpub/dgvLv7RHwfhJnFFM+DD4Xb0jk8rltOf+gs7OsgzKxKG++hqfszhBtebUrQe/d5/nwewsymtOH+jH6s89vAezUjx6zX9zrhCzO7UUzbZbC9Lzzs09Sol3+29vG7PjciohFmDiOl1AW6dva9AKzBxYMRRC/a5eE5bWBJwgxj2i1gv0KwgWUIMzyiDXZtwvYCNOAZwgxzEmzgScIMS8i2edUOgI4wwzsJNlAQZlijbE92Ldi+b2G/hBm2JqU0NGH7fobtE2bYi8pe7G6bl+9z2A5hhr3z5imwKcIMR1XZ2tVN2IIN7yPMQJ+92PBWwgzcp7K1q5uwBRvmI8zAc+zFhvk0TSPMwGtU9mLnvwwEqBNmYHnZXuza78aGIxNmYD2yKbsWbJM2RyDMwHZke7JrZ49n7IEwA/vQRrsW7HPYm812CDOwf8USeRfqc3F4PGQNhBkg4vuNVcbC7YVpLEGYAe6VLZcPxduSOc8SZoC5tEvmH9lxLm6X90NJmAHepV0+H4p4edvj9TEIM8AWZC9gG5q+T8XZRL5NwgywV23Ma8Eu7xs7syxhBmBYu9x+b8jzmJ8qB7cJMwDLyab4oXA/en3o2tYIMwD71f4gENGP9NDHU28/em3sc5v/AUtziAX6Vf5OAAAAAElFTkSuQmCC"></image>
        <image id="_Image11" width="733px" height="110px" xlink:href="data:image/png;base64,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"></image>
    </defs>
</svg>
</a>
  </div>
  <figcaption>
    Focusing on "how do I get the reader to see the story I see?"
  
</figcaption></figure>
<p>The product manager's response is effusive:</p>

<blockquote>
<p><em>This is fascinating. One in three signups never install? Wow ‚Äì what a big opportunity. And this is for the last week, so it could be a result of changes we made a couple weeks ago but never tracked. I am going to share these numbers in our next strategy meeting and see if anyone else has ideas. I think we've been fixated on converting web sessions to signups, but we haven't been considering all the other weak points. Nice that there's a link to the data source. I'm going to pair this with data from our external data vendor. I have so many follow-up questions about where we can go from here!<p>
‚Äì the PM</p></em></p>
</blockquote>
<p>Your updated chart got the reader to an "aha!" moment quickly, answered all of their immediate contextual questions, and put them on the path to asking the next set of deeper product questions. All of these were achieved by focusing on the small things that made the data visualization more immediately interpretable.</p>
<p>This is obviously a contrived example. The data visualization does have to be relevant to the audience. In our example, it'd be a problem if the product manager didn't care about the user journey of the product they're working on. If your data visualization isn't showing something meaningful to the reader, it probably won't get them to care. This said, it's not always so straightforward to get someone to understand that a new insight <em>is</em> relevant, especially if the visual story you're telling is novel to them in some way. But then again, that's why we've reframed the challenge to <em>telling the story well</em>, isn't it?</p>
<h3 id="the-two-constraints"><a href="#the-two-constraints">¬∂</a> The Two Constraints</h3>
<p>The reality is, even if you have the desire to take your data visualization further, there are two things that are likely to get in your way: <strong>limitations with your tools</strong>, and <strong>diminishing returns</strong>.</p>
<h4 id="limitations-with-your-tools"><a href="#limitations-with-your-tools">¬∂</a> limitations with your tools</h4>
<p>If you‚Äôve used a visualization library before, you‚Äôve probably discovered that there are always limits to what you can do. The lower level you go, the more work it is to get annotations and animations to do what you want.</p>
<p>This said, most libraries support all the basic small things in some way. I'm hesitant to suggest what things to add to your charts, since building intuition around effective visual storytelling is more important than having a checklist. This said, there are some common easy-to-implement small things that always immediately improve the readability and interpretation of your graphic:</p>
<ul>
<li><strong>human-readable labels</strong> ‚Äì labels are always the easiest thing to add, and often the most impactful. Make sure they're expressed in clear, simple language. Don't ‚Ä¶</li></ul></article></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hamiltonulmer.com/notes/data-viz-small-things/">https://hamiltonulmer.com/notes/data-viz-small-things/</a></em></p>]]>
            </description>
            <link>https://hamiltonulmer.com/notes/data-viz-small-things/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066475</guid>
            <pubDate>Thu, 12 Nov 2020 04:33:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Occult History Behind NASA‚Äôs Jet Propulsion Laboratory]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066293">thread link</a>) | @jtmarino
<br/>
November 11, 2020 | https://www.supercluster.com/editorial/the-occult-history-behind-nasas-jet-propulsion-laboratory/ | <a href="https://web.archive.org/web/*/https://www.supercluster.com/editorial/the-occult-history-behind-nasas-jet-propulsion-laboratory/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span>Jack Parsons was one of the most influential figures in the history of the American space program. He was also a Marxist, stood accused of espionage, and held a deep fascination with the occult. His interest in the supernatural went far beyond vaudeville magicians and astrology. By 1939, Parsons and his wife Helen Parsons-Smith had fully embraced the teachings of the Ordo Templis Orientis, a central hub for Aleister Crowley‚Äôs spiritual and religious philosophy ‚Äî Thelema.</span></p></div><div><p><span>Aleister Crowley taught that a Thelemite‚Äôs central ambition was to achieve a higher state of existence by embracing one‚Äôs ‚ÄúTrue Will,‚Äù or one‚Äôs ultimate purpose beyond selfishness or ego. In pursuit of that goal, many aspects of Parsons‚Äôs life blurred the boundaries between science and mysticism. As a Thelemite, he performed ritual magic, including banishing impure elements with pentagrams, invocating the power of the ‚ÄúHoly Guardian Angel,‚Äù and offering daily adorations to the sun. </span></p></div><div><p><span>All while pushing the limits in the nascent field of rocket science.</span></p></div><div><p><span>Jack Parsons was born Marvel Whiteside Parsons on October 2nd, 1914, to Ruth Virginia Whiteside and Marvel H. Parsons in Los Angeles, California. For the first two years of their marriage, the Parsons were swept into a dark whirlwind romance in the heart of the City of Angels. By the 1900s Los Angeles had become </span><a href="https://www.nytimes.com/2005/03/06/books/chapters/strange-angel.html" rel="noopener noreferrer" target="_blank">a hotbed of new-age spiritualism and occult fascination</a><span>, in which the Parsons were active participants. It was turn-of-the-century America‚Äôs Williamsburg, perfect for the upper-middle-class pseudo-bohemian who wanted a crystal ball that matched their silverware set.</span></p></div><div><p><span>Jack‚Äôs father was perhaps too taken by the city‚Äôs attractive social loosening. He made his rapid exodus from California after Ruth exposed him as an adulterer, who had frequented a local prostitute in the months leading up to and following their son‚Äôs birth. After the newlyweds' bitter split, Ruth excised the elder Parsons from their son‚Äôs life both physically and legally, insisting her son be referred to as ‚ÄúJohn Whiteside Parsons‚Äù on all legal documents. The rechristened Parsons was brought up by his mother and his maternal grandparents. Using their </span><a href="https://www.nytimes.com/2005/03/06/books/chapters/strange-angel.html" rel="noopener noreferrer" target="_blank">wealth from the manufacturing industry</a><span>, the Whitesides moved Ruth and John, or ‚ÄúJack‚Äù, to Orange Grove Avenue, Pasadena‚Äôs ‚ÄúMillionaire‚Äôs Mile.‚Äù </span></p></div><div><p><span>Spending a majority of his childhood in solitude, Parsons soon found a personal hideaway in science fiction. Enraptured by Jules Verne and the pulp magazine </span><em>Amazing Stories</em><span>, Parsons developed an interest in rocketry at a young age.</span></p></div><div><p><span>By age 12, the future father of modern rocketry was </span><a href="http://www.spacesafetymagazine.com/aerospace-engineering/rocketry/jack-parsons-occult-roots-jpl/" rel="noopener noreferrer" target="_blank">conducting backyard experiments</a><span> with his classmate Edward Forman. The two boys designed gunpowder-based rockets with aluminum foil, cherry bomb fireworks, and glue. Around the same time, Parsons was performing bedtime incantations to invoke the Devil - another practice he‚Äôd learned from reading </span><em>Amazing </em><span>comics. In an effort to ‚Äústraighten out‚Äù her wayward son, who was so distracted that he started flunking out of grade school, Parsons‚Äôs mother sent him to the Brown Military Academy for Boys in San Diego‚Äîa sprawling, 100-acre private boys‚Äô school known as ‚ÄúThe West Point of the West.‚Äù</span></p></div><div><p><span>It didn‚Äôt work. Parsons was expelled for blowing up the toilets.</span></p></div><div><p><span>With a renewed confidence that only vandalizing private property can give, Parsons resumed his rocket engineering experiments at home. After a brief stint back in school and a year at Stanford University, Parsons was forced to take up working weekends, holidays, and eventually full-time employment at the Hercules Powder Company after his family experienced financial losses during the Great Depression. He was no older than 19. Directly dealing with chemicals and munitions, Parsons not only learned more about the properties of gunpowder and its potential as a rocket propellant, but he also occasionally stole materials from work for his and Forman‚Äôs experiments. Parsons and Forman continued these after-hour experiments well into their mid-to-late 20s.</span></p></div><div><p><span>By 1933, Parsons had constructed his first solid-fuel rocket engine. He was only 29 years old. His boyhood interest in magic and the supernatural only grew stronger as he delved further into rocket science. That same year, Parsons turned his Orange Avenue estate into a bohemian haven, renting rooms out to artists, occultists, and dropouts galore. In 1934, Jack Parsons and Edward Forman met PhD candidate Frank Malina at a public CalTech lecture. The trio soon managed to impress Malina‚Äôs supervising professor Dr. Theodore van K√°rm√°n enough that he allowed the young engineers to conduct experiments at the university‚Äôs Guggenheim Aeronautical Laboratory‚ÄîGALCIT. </span></p></div><div><p><span>With access to CalTech‚Äôs resources and equipment, the trio formed the GALCIT Rocket Research Group. Thus, the blueprint for NASA‚Äôs Jet Propulsion Lab was born. What resulted was a bachelor pad for rocket pioneers.</span></p></div><div><p><span>Between rocket experiments, the trio would wax poetic about their shared socialist values, smoke marijuana, and drink to excess. Parsons and Malina even wrote a sci-fi screenplay and pitched it around to several Hollywood production companies. Making it big on the silver screen was starting to seem like a more viable option than rocket engineering for the GALCIT Group. Most of their experiments increasingly ended in violent explosions, that terrified neighboring CalTech academics so much the three researchers were </span><a href="https://www.kcet.org/shows/blue-sky-metropolis/the-bad-boys-of-space-exploration-and-the-origins-of-the-jet-propulsion" rel="noopener noreferrer" target="_blank">nicknamed the ‚ÄúSuicide Squad.‚Äù</a><span> </span></p></div><div><p><span>Parsons came to a crossroads during his later years with GALCIT. On the one hand, he integrated himself into the academic fold. While working with GALCIT by day, Parsons studied chemistry at USC by night. On the other hand, the wild rocket scientist was falling further into his obsession with Thelema. By 1939 he was enraptured with Aleister Crowley‚Äôs revival of what began as a sixteenth-century philosophy. Thelema was by this time a sprawling esoteric movement, incorporating ancient Egyptian deities, sex rituals, and a range of Eastern and Western mysticism. Eventually, Parsons was forced to choose between his new religious craze or pursuing his degree at USC. Ultimately, Parsons dropped out of school and chose to dedicate himself to Thelema, becoming a member of the local California chapter: the Ordo Templis Orientis. </span></p></div><div><p><span>Parsons‚Äô own religious and scientific pursuits have proven screen worthy. His life has recently been adapted in the CBS All Access series, </span><em>Strange Angel</em><span>, based on the biography </span><em>Strange Angel: The Otherworldly Life of Rocket Scientist John Whiteside Parsons </em><span>by George Pendle. Supercluster sat down with Pendle and show creator, producer, and writer Mark Heyman for exclusive interviews about the life of this rocket-scientist-genius-occultist-playboy.</span></p></div><div><p><span>‚ÄúI first came across a mention of him in reading that book </span><em>Going Clear</em><span>, which you know is about L. Ron Hubbard and Scientology. It was a fascinating moment in that book, and I sort of just filed it away,‚Äù says Heyman. The occult is no real shock to one of the minds behind Academy Award-nominated </span><em>Black Swan</em><span>. ‚ÄúI grew up in Santa Fe, New Mexico, and my parents were involved in a sort of new-age religion that some people would call a cult. I always felt like it was more cult-ish, but it wasn‚Äôt like a full-blown cult. So I‚Äôd always been interested in those sorts of organizations and groups, which is why I was reading ‚ÄúGoing Clear‚Äù in the first place. A year or two after that, I was sent the book for </span><em>Strange Angel</em><span> by a producer. It was my first real deep dive into who Jack Parsons was and my first introduction to him, and it blew my mind on multiple levels.‚Äù</span></p></div><div><p><span>‚ÄúWe tend to think of the 30s and 40s as a more buttoned-down time, a more conservative time, but they were as wild and crazy as anything that happened in the 60s and 70s. And then, there was this sort of intersection of that with the sciences, and the birth of this new fangled science‚Äîrocket science. Which, back then, was not taken seriously at all and was considered just as fringe and out there as some of [Parsons‚Äô] religious preferences.‚Äù</span></p></div><div><p><span>Pendle had this to say about the era, ‚ÄúBecause [Jack‚Äôs] personal life and personal interests were so at odds to the time he lived in, his scientific work‚Äîwhich was so groundbreaking‚Äîwas kind of swept under the carpet‚Ä¶ A lot of people who are very interesting are forgotten by history because they don‚Äôt fit into the pigeon holes we view history through. I often think you can get a better view of history from the edges rather than from the middle.‚Äù</span></p></div><div><p><span>Parsons without a doubt existed on the fringes. When the GALCIT Group first formed, aerospace engineering hadn‚Äôt even been invented yet. The first definition of the phrase would crop up in 1958, more than 20 years after GALCIT Group‚Äôs experiments started, and 6 years after Parsons‚Äô death.</span></p></div><div><p><span>‚ÄúNow, rocket science is sort of synonymous with the most esoteric of sciences. We have that expression, ‚ÄòIt‚Äôs not rocket science.‚Äô It‚Äôs implied that it‚Äôs meant to be the stuff of really, really educated experts,‚Äù says Heyman, ‚ÄúWhereas, back then, it was almost the opposite where it was the stuff of science fiction. It existed in popular culture, but in the way that dragons and time travel existed. It was actually the stuff of entertainment. So, it wasn‚Äôt taken seriously not because it was too complicated or too difficult. It wasn‚Äôt taken seriously because it was seen as imaginary.‚Äù</span></p></div><div><p><span>A figure like Parsons might seem to presage later eccentric innovators like Elon Musk or Steve Jobs. For Pendle, the parallel isn‚Äôt totally accurate. ‚ÄúImagine like a Musk without a fortune, without people backing him, basically plucking spare parts from the garbage to build his electric cars. That‚Äôs the kind of thing you‚Äôd be looking at if you wanted to make them equal."</span></p></div><div><p><span>The scientific community took notice of Jack‚Äôs rag-tag methods in 1938 when his group successfully tested a static motor rocket that could run for over a minute. With funding from the federal government (and at the request of their CalTech peers), the Group relocated to ‚Ä¶</span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.supercluster.com/editorial/the-occult-history-behind-nasas-jet-propulsion-laboratory/">https://www.supercluster.com/editorial/the-occult-history-behind-nasas-jet-propulsion-laboratory/</a></em></p>]]>
            </description>
            <link>https://www.supercluster.com/editorial/the-occult-history-behind-nasas-jet-propulsion-laboratory/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066293</guid>
            <pubDate>Thu, 12 Nov 2020 04:01:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Speed reading with command-line utilty shirah-reader]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066170">thread link</a>) | @ThorBhai
<br/>
November 11, 2020 | https://diode.zone/videos/watch/0065aec7-de6c-48a4-b075-fb6d8a9096c8 | <a href="https://web.archive.org/web/*/https://diode.zone/videos/watch/0065aec7-de6c-48a4-b075-fb6d8a9096c8">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://diode.zone/videos/watch/0065aec7-de6c-48a4-b075-fb6d8a9096c8</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066170</guid>
            <pubDate>Thu, 12 Nov 2020 03:42:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Custom GitHub Actions with Docker]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066079">thread link</a>) | @sethetter
<br/>
November 11, 2020 | https://sethetter.com/posts/github-actions-with-docker/ | <a href="https://web.archive.org/web/*/https://sethetter.com/posts/github-actions-with-docker/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <section>
        <p>I finally decided to dip my toes into GitHub actions recently, for a relatively simple task: build and deploy my personal site. The site is built with <a href="https://getzola.org/">zola</a> and deployed to <a href="https://netlify.com/">netlify</a>.</p>
<p>My needs are pretty straightforward.</p>
<ul>
<li>The zola binary</li>
<li>Node, and <a href="https://www.npmjs.com/package/netlify-cli">netlify-cli</a> installed</li>
<li>Secure way to provide netlify config</li>
</ul>
<p>Then I simply make sure my site source is checked out and run the <code>build</code> and <code>deploy</code> commands.</p>
<h2 id="some-terminology">Some terminology</h2>
<p>An <a href="https://docs.github.com/en/free-pro-team@latest/actions/creating-actions/about-actions"><strong>action</strong></a> is a single step that may be performed in a larger <a href="https://docs.github.com/en/free-pro-team@latest/actions/reference/workflow-syntax-for-github-actions"><strong>workflow</strong></a>, which strings together multiple actions and is kicked off in response to various events (like a <code>git push</code>, or a PR). You can have a workflow that calls a single action, but an action can't be used without being called in a workflow.</p>
<h2 id="first-impression-with-actions">First impression with Actions</h2>
<p>I noticed the marketplace approach first of all, and the emphasis on actions that did one small thing which you compose together. This can definitely be a nice approach to things, but my preferred way of working on CI tasks like this is to have access to a Docker container where I have a bit more control of my environment, and can codify it into a familiar Dockerfile.</p>
<p>My thinking is, if I can get this sort of approach to work, I'll have less required domain knowledge of GitHub actions, and can instead just lean on my Docker knowledge to set up whatever operations I may need.</p>
<p>Needless to say, I simply sidestepped the marketplace and found the <a href="https://docs.github.com/en/free-pro-team@latest/actions/creating-actions/creating-a-docker-container-action">documentation for utilizing Docker</a>, which thankfully is a valid option! üéâ</p>
<h2 id="my-setup">My setup</h2>
<p>I stumbled through this quite a bit, but ultimately am happy with the approach. I'm able to have a <code>Dockerfile</code> and custom <a href="https://docs.docker.com/engine/reference/builder/#entrypoint"><code>entrypoint.sh</code></a> file that can receive inputs via env vars from the action configuration. I'm also able to pipe secrets, stored in my GitHub repo, into the action from the workflow file.</p>
<h3 id="the-action-file"><a href="https://github.com/sethetter/sethetter.com/blob/1e916825348e2ee2f401b5204811c18e394432e3/.github/actions/build-and-deploy/action.yml">The action file</a></h3>
<pre><code><span># .github/actions/build-and-deploy/action.yml
</span><span>name</span><span>: </span><span>'</span><span>Build and deploy</span><span>'
</span><span>description</span><span>: </span><span>'</span><span>Build site with Zola and deploy to Netlify</span><span>'
</span><span>inputs</span><span>:
  </span><span>auth_token</span><span>:
    </span><span>description</span><span>: </span><span>'</span><span>Netlify auth token</span><span>'
    </span><span>required</span><span>: </span><span>true
  </span><span>site_id</span><span>:
    </span><span>description</span><span>: </span><span>'</span><span>Netlify site ID to deploy to</span><span>'
    </span><span>required</span><span>: </span><span>true
  </span><span>deploy_dir</span><span>:
    </span><span>description</span><span>: </span><span>'</span><span>Directory to deploy to netlify</span><span>'
    </span><span>required</span><span>: </span><span>true
  </span><span>zola_version</span><span>:
    </span><span>description</span><span>: </span><span>'</span><span>Version of zola to pull</span><span>'
    </span><span>required</span><span>: </span><span>true
    </span><span>default</span><span>: </span><span>'</span><span>0.12.2</span><span>'
</span><span>runs</span><span>:
  </span><span>using</span><span>: </span><span>'</span><span>docker</span><span>'
  </span><span>image</span><span>: </span><span>'</span><span>Dockerfile</span><span>'
  </span><span>env</span><span>:
    </span><span>ZOLA_VERSION</span><span>: </span><span>${{ inputs.zola_version }}
    NETLIFY_AUTH_TOKEN</span><span>: </span><span>${{ inputs.auth_token }}
    NETLIFY_SITE_ID</span><span>: </span><span>${{ inputs.site_id }}
    NETLIFY_DEPLOY_DIR</span><span>: </span><span>${{ inputs.deploy_dir }}
</span></code></pre>
<p>This file defines our action, which will be called from a workflow which we will configure later. The main thing to notice here is how we are accepting inputs, and passing those on to our Docker container through environment variables.</p>
<p><strong>This was one of the things I stumbled over</strong>. Currently there is no support for passing <a href="https://docs.docker.com/engine/reference/commandline/build/#set-build-time-variables---build-arg">build args</a> to our Dockerfile, and the environment variables we provide are not available during the build stage, only once the <a href="https://docs.docker.com/engine/reference/builder/#entrypoint"><code>ENTRYPOINT</code></a> is called.</p>
<p>I was stuck on this for a decent chunk of time before realizing that <a href="https://docs.github.com/en/free-pro-team@latest/actions/creating-actions/metadata-syntax-for-github-actions#runsargs"><code>runs.args</code> with <code>docker</code> are <em>not</em> build args</a>, they are arguments sent to the <code>entrypoint</code>. Don't make the same mistakes I did!</p>
<p>The implication here is that any steps in your action that require one of these inputs must happen in the <code>ENTRYPOINT</code> provided via <code>env</code>. I'll mention this again shortly.</p>
<h3 id="docker-setup">Docker setup</h3>
<p>The <a href="https://github.com/sethetter/sethetter.com/blob/4fdf1675084628f6ddd3aaa31aaa05a1a118b1d6/.github/actions/build-and-deploy/Dockerfile">Dockerfile</a> is pretty minimal, simply setting up the base environment I want, which is <code>node:lts</code> in this case, and then copy in my custom <code>[entrypoint.sh](http://entrypoint.sh)</code> script.</p>
<pre><code><span># .github/actions/build-and-deploy/Dockerfile
</span><span>FROM node:lts
COPY entrypoint.sh /entrypoint.sh
ENTRYPOINT ["/entrypoint.sh"]
</span></code></pre>
<p><strong>Tip!</strong> <a href="https://docs.github.com/en/free-pro-team@latest/actions/creating-actions/dockerfile-support-for-github-actions#workdir">Don't set a <code>WORKDIR</code></a>. The action sets the workdir to the <code>$GITHUB_WORKSPACE</code> variable which is where your project source will be located.</p>
<p>All the action happens in the <a href="https://github.com/sethetter/sethetter.com/blob/1e916825348e2ee2f401b5204811c18e394432e3/.github/actions/build-and-deploy/entrypoint.sh"><code>entrypoint.sh</code></a> file.</p>
<pre><code><span># .github/actions/build-and-deploy/entrypoint.sh

#!/usr/bin/env bash
</span><span>ZOLA_URL=https://github.com/getzola/zola/releases/download/v${ZOLA_VERSION}/zola-v${ZOLA_VERSION}-x86_64-unknown-linux-gnu.tar.gz
curl -L $ZOLA_URL | tar xz -C /usr/local/bin

</span><span># Install netlify
</span><span>npm i -g netlify-cli

</span><span># Kick off build and deploy
</span><span>zola build
netlify deploy \
  --prod \
  --dir=$NETLIFY_DEPLOY_DIR \
 --auth=$NETLIFY_AUTH_TOKEN \
 --site=$NETLIFY_SITE_ID
</span></code></pre>
<p>You can see here we're referencing the <code>env</code> vars we defined in our action file. Originally I had the zola and netlify install steps happening in the <code>Dockerfile</code>, but due to the inability to pass build args to the image, I wasn't able to get the <code>$ZOLA_VERSION</code> passed in. Once I had that realization, it seemed just as viable to put everything in <code>entrypoint.sh</code>.</p>
<h3 id="the-workflow-file"><a href="https://github.com/sethetter/sethetter.com/blob/4fdf1675084628f6ddd3aaa31aaa05a1a118b1d6/.github/workflows/build-and-deploy.yml">The workflow file</a></h3>
<pre><code><span># .github/workflows/build-and-deploy.yml
</span><span>name</span><span>: </span><span>build-and-deploy
</span><span>on</span><span>:
  </span><span>push</span><span>:
    </span><span>branches</span><span>: [</span><span>master</span><span>]
</span><span>jobs</span><span>:
  </span><span>build-and-deploy</span><span>:
    </span><span>runs-on</span><span>: </span><span>ubuntu-latest
    steps</span><span>:
      - </span><span>uses</span><span>: </span><span>actions/checkout@v2
      </span><span>- </span><span>uses</span><span>: </span><span>./.github/actions/build-and-deploy
        with</span><span>:
          </span><span>zola_version</span><span>: </span><span>'</span><span>0.12.2</span><span>'
          </span><span>auth_token</span><span>: </span><span>${{ secrets.NETLIFY_AUTH_TOKEN }}
          site_id</span><span>: </span><span>${{ secrets.NETLIFY_SITE_ID }}
          deploy_dir</span><span>: </span><span>'</span><span>public</span><span>'
</span></code></pre>
<p>This is our final configuration file, turning our new custom action into a workflow. We start by setting our workflow triggers in the <code>on</code> block. In this case we just want to run this workflow on pushes to <code>master</code>.</p>
<p>Next is our <code>jobs</code> block. We can define multiple jobs which would all run in parallel. If we need anything serial, it should happen within a single job. In our case, we have just one job with two actions.</p>
<p>The job itself starts with the checkout action, which handles checking out the repo's source into the job workspace, then we call our custom action by providing a path to the action folder.</p>
<p>In our <code>with</code> block we provide values for the inputs we defined on our action. You'll notice that two of the values are provided via <code>secrets</code>, which is a <a href="https://docs.github.com/en/free-pro-team@latest/actions/reference/encrypted-secrets">feature of GitHub</a> I wasn't aware of before this. It's very easy to work with!</p>
<h2 id="room-for-improvement">Room for improvement</h2>
<p>I think the main drawback here is potentially slow job run times, since we're installing our dependencies each time. Depending on what's actually slow, there are a number of ways it could be addressed.</p>
<p>In general, finding a base Docker image that has as much of what you need as possible (without too much bloat) is going to help. Maintaining your own images in a registry somewhere comes with it's own overhead, but that's also an option.</p>
<p>I'm sure using the marketplace approach could also be a way to address the performance issues, assuming you find actions that have your dependencies installed and configured appropriately, but the goal of this post was to explore a minimal action configuration while leveraging the power of Docker üòÑ.</p>
<p><strong>That's it!</strong> üëã</p>

    </section>
</article></div>]]>
            </description>
            <link>https://sethetter.com/posts/github-actions-with-docker/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066079</guid>
            <pubDate>Thu, 12 Nov 2020 03:28:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pyxell ‚Äì a programming language that combines Python's elegance with C++'s speed]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25066058">thread link</a>) | @masijo
<br/>
November 11, 2020 | https://www.pyxell.org/docs/manual.html | <a href="https://web.archive.org/web/*/https://www.pyxell.org/docs/manual.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>Pyxell [<em>pixel</em>] is a multi-paradigm, statically typed programming language, compiled to machine code via C++.</p> <p>This manual should let you quickly learn all the details to start programming in Pyxell.
It is assumed that you already know some programming language (preferably Python), since basic programming concepts are not explained here.</p> <p>You are encouraged to run the code snippets and experiment with them for yourself.
To run Pyxell code, go to the <a href="https://www.pyxell.org/docs/playground.html">Playground</a>,
clone the repository and follow the instructions on <a href="https://github.com/adamsol/Pyxell#requirements" target="_blank" rel="noopener noreferrer">Github<span> <span>(opens new window)</span></span></a>,
or download Windows binaries from the <a href="https://github.com/adamsol/Pyxell/releases" target="_blank" rel="noopener noreferrer">Releases<span> <span>(opens new window)</span></span></a>.</p> <h2 id="hello-world"><a href="#hello-world">#</a> Hello, world!</h2> <p>If you can run the following code and see the message on the screen, you are ready to start.</p> <h2 id="variables-and-types"><a href="#variables-and-types">#</a> Variables and types</h2> <h3 id="variable-declaration"><a href="#variable-declaration">#</a> Variable declaration</h3> <p>Pyxell is statically typed. Variables have types assigned during compilation.
In most cases, type of an expression is automatically inferred and the value can be directly assigned to a variable.</p> <p>In other cases, when the type cannot be inferred or you want to declare a variable without initializing it, you can set the type explicitly.
When not directly initialized, variable is automatically initialized with the default value for a given type.
You can find the list of all available types and their default values in the <a href="https://www.pyxell.org/docs/specification.html#types">Specification</a>.</p> <p>Variable name must start with a letter, but may also contain digits, underscores, and apostrophes.
Once a variable has been created, its type cannot be changed.</p> <h3 id="type-coercion"><a href="#type-coercion">#</a> Type coercion</h3> <p>Values of some types can be automatically converted to more general types: <code>Int -&gt; Rat -&gt; Float</code> or <code>Char -&gt; String</code>.</p> <p>The coercion doesn't work in the other direction.</p> <h2 id="arithmetic-and-logic"><a href="#arithmetic-and-logic">#</a> Arithmetic and logic</h2> <h3 id="numbers"><a href="#numbers">#</a> Numbers</h3> <p>Standard integers in Pyxell have 64 bits of precision and range from <code>-2^63</code> to <code>2^63-1</code>.
Binary, octal, and hexadecimal literals are supported.</p> <p>Rational numbers have unlimited precision.
They can be written either as integers with <code>r</code> suffix, or non-integers in decimal form.
They are also created as the result of division or exponentiation
(to obtain an integer from a division or exponentiation, use lossy <code>//</code> and <code>^^</code> operators).</p> <p>You can retrieve the numerator and denominator from a rational number.</p> <p>Floating-point numbers have 64 bits of precision and follow the IEEE 754 standard.
They can be written with <code>f</code> suffix or in scientific notation.</p> <p>Underscores can be additionally used in all numeric literals, to enhance readability of long numbers.</p> <h3 id="boolean-values"><a href="#boolean-values">#</a> Boolean values</h3> <p>There are two boolean values: <code>true</code> and <code>false</code>.
Logical negation and short-circuiting conjunction and disjunction operators are available.</p> <p>Boolean values are most often obtained in the result of comparisons.
When comparison operators are chained, they behave as if connected with <code>and</code> operator.</p> <h2 id="characters-and-strings"><a href="#characters-and-strings">#</a> Characters and strings</h2> <h3 id="characters"><a href="#characters">#</a> Characters</h3> <p>Characters are written in single quotes.</p> <p>You can get character's ASCII code, as well as obtain character corresponding to a given integer.</p> <p>You can also perform some arithmetic operations on characters.</p> <h3 id="strings"><a href="#strings">#</a> Strings</h3> <p>Strings are immutable sequences of characters. They are written in double quotes.</p> <p>You can access string's length, as well as its individual characters. Negative indexing and slicing is also supported, like in Python.</p> <p>Strings can be concatenated with <code>+</code> operator and repeated with <code>*</code> operator.</p> <p>You can construct formatted strings using interpolation syntax.</p> <h2 id="control-flow"><a href="#control-flow">#</a> Control flow</h2> <p>Pyxell uses indentation-based syntax, similar to Python's. Only spaces are allowed (tab character will cause a syntax error).
Rather than <code>:</code> character, Pyxell uses <code>do</code> keyword for indicating beginning of a block, and <code>def</code> keyword for function and class definitions.
The scope of a variable declared in a block is limited to that block.</p> <h3 id="if-statement"><a href="#if-statement">#</a> <code>if</code> statement</h3> <p>The first branch whose condition evaluates to <code>true</code> is executed.</p> <h3 id="while-loop"><a href="#while-loop">#</a> <code>while</code> loop</h3> <p>The loop runs while the condition is satisfied.</p> <h3 id="until-loop"><a href="#until-loop">#</a> <code>until</code> loop</h3> <p>This loop is similar to <code>while</code> loop, but it is always executed at least once and runs until the condition is satisfied.</p> <h3 id="for-loop"><a href="#for-loop">#</a> <code>for</code> loop</h3> <p>It can be used to loop over ranges (of numbers or characters) and other iterables.
Range can be inclusive (<code>a..b</code>), exclusive (<code>a...b</code>), or infinite (<code>a...</code>).</p> <p>You can optionally provide a step value, which can be either positive or negative (it is 1 by default).</p> <p>It is possible to loop over multiple iterables at once and provide custom step values to any of them.</p> <h3 id="continue-and-break"><a href="#continue-and-break">#</a> <code>continue</code> and <code>break</code></h3> <p>Inside loops you can use statements to exit the current iteration or the whole loop.</p> <h2 id="containers"><a href="#containers">#</a> Containers</h2> <h3 id="arrays"><a href="#arrays">#</a> Arrays</h3> <p>Arrays are similar to strings, but they are mutable and can have elements of any type.</p> <p>Containers have reference semantics, so they are not implicitly copied when variables are passed.
Mutation of one instance is reflected in all other instances of the same container.</p> <p>When an empty array is used, its type must be explicitly given.</p> <p>Arrays can be concatenated, repeated, and compared using standard operators.</p> <p>You can use array comprehension, as well as range literals and spread operator with optional step.</p> <p>For type safety, containers in Pyxell are invariant, which means they cannot be implicitly converted to another type,
even if types of the elements match (see <a href="https://stackoverflow.com/q/2745265" target="_blank" rel="noopener noreferrer">here<span> <span>(opens new window)</span></span></a> for a broader explanation).
However, container literals can be automatically converted.</p> <h3 id="sets"><a href="#sets">#</a> Sets</h3> <p>Sets contain no duplicates and do not preserve order of elements.</p> <p>Empty set can be created like an empty array.</p> <p>To check if an element is in the set, use <code>in</code> operator.</p> <p>There exist operators for set union, difference, and intersection.</p> <p>Like with arrays, you can use comprehensions, ranges, and spread syntax to create sets.</p> <p>Containers are not hashable, so they cannot be stored in sets.</p> <h3 id="dictionaries"><a href="#dictionaries">#</a> Dictionaries</h3> <p>Dictionaries are hash maps. Like sets, they do not preserve order of elements.
They work similarly to <code>defaultdict</code> in Python: if a key is not present, the default value for a given type is automatically created in the dictionary.</p> <p>Empty dictionary literal has an additional colon.</p> <p>Use <code>in</code> operator for checking if the dictionary contains a given key.</p> <p>Dictionaries can be merged with <code>+</code> operator. In the case of repeated keys, the second value wins.</p> <p>Dictionary comprehension works similarly to array and set comprehension.</p> <p>When iterated over, dictionaries produce pairs of key and value.</p> <p>Spread operator for dictionaries consists of an extra colon.</p> <h2 id="nullable-types"><a href="#nullable-types">#</a> Nullable types</h2> <p>To accept <code>null</code> value, variable's type must be explicitly marked as nullable.</p> <p>You can either directly check if a value is <code>null</code>, or use special coalescing and conditional operators.</p> <p>There is also an operator to directly retrieve the value, for cases when you are sure it is not null.</p> <h2 id="tuples"><a href="#tuples">#</a> Tuples</h2> <p>Two or more values separated with a comma (outside of a container, function call, and print statement) form a tuple.</p> <p>Values can be retrieved using alphabetical properties or tuple destructuring (unneeded part can be discarded with an underscore).</p> <p>Tuples are mutable, but they have value semantics, so they are hashable and can be passed around as if they were immutable.</p> <h2 id="functions"><a href="#functions">#</a> Functions</h2> <h3 id="function-definition-and-call"><a href="#function-definition-and-call">#</a> Function definition and call</h3> <p>Basic definition of a function consists of its name, list of arguments, return type, and body.</p> <p>When a function does not return anything, the return type may be written as <code>Void</code> or may be omitted completely.</p> <p>You can provide default values for optional arguments.
The expressions will be evaluated every time the function is called (if they are needed), so mutable container literals can be safely used.</p> <p>Arguments can be also passed in any order using their names.</p> <p>Variadic functions are supported too. This is just a syntactic sugar for passing an array.
Ranges and spread syntax can be used when such a function is called.</p> <p>Functions can be stored in variables, passed to other functions as arguments, etc.
However, when a function is converted to a variable, all information about its arguments except for their types is lost.</p> <h3 id="generic-functions"><a href="#generic-functions">#</a> Generic functions</h3> <p>Generic functions are standard functions with additional type variables, which can be used just like normal types.
They are compiled independently for each combination of types they are called with.</p> <p>Function declaration may contain default values for generic arguments, and the body may contain any code dependent on the real types.
Errors will be reported when the function cannot be compiled with given types.</p> <p>When a type name is used more than once, the compiler will try to unify types of the arguments, following the coercion rules.</p> <h3 id="lambda-functions"><a href="#lambda-functions">#</a> Lambda functions</h3> <p>Lambda is a simpler version of generic function, where all arguments, as well as the return type, are generic.</p> <p>You can use placeholder syntax to write even more concise functions. Each underscore corresponds to one argument.</p> <p>Placeholder resolving doesn't run through function calls by default (placeholders inside a function call form their own functions for corresponding arguments).
To create a partial function, add <code>@</code> character.</p> <p>Lambdas can also be multi-line, so that you can define normal functions without any type annotations.</p> <p>Note that lambda functions currently work only with arguments of known types.
You cannot pass a lambda function to another lambda function.
In the case of functional arguments, it's better to use the full generic definition instead.</p> <h3 id="generators"><a href="#generators">#</a> Generators</h3> <p>Generator is a function producing a sequence of values that can be iterated over without storing it in memory.
To create a generator, add an asterisk symbol to the function definition.</p> <p>Lambdas can be generators as well.</p> <p>Note that generators are currently supported only with Clang.</p> <h2 id="classes"><a href="#classes">#</a> Classes</h2> <h3 id="class-definition-and-object-construction"><a href="#class-definition-and-object-construction">#</a> Class definition and object construction</h3> <p>Definition of a class consists of its name and list of fields.
Each field may have an explicit default value; if not provided, it will be the default value for a given type.</p> <p>Every class has a default constructor function that accepts field values in the order of definition, or as named arguments.
Fields not directly initialized will receive their default values.</p> <p>Remember that class objects must always be explicitly constructed before use (they have no valid default ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pyxell.org/docs/manual.html">https://www.pyxell.org/docs/manual.html</a></em></p>]]>
            </description>
            <link>https://www.pyxell.org/docs/manual.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066058</guid>
            <pubDate>Thu, 12 Nov 2020 03:25:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Complete Guide to PyTorch for Data Scientists]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065771">thread link</a>) | @shirappu
<br/>
November 11, 2020 | https://mlwhiz.com/blog/2020/09/09/pytorch_guide/ | <a href="https://web.archive.org/web/*/https://mlwhiz.com/blog/2020/09/09/pytorch_guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em><strong>PyTorch</strong></em> has sort of became one of the de facto standards for creating Neural Networks now, and I love its interface. Yet, it is somehow a little difficult for beginners to get a hold of.</p><p>I remember picking PyTorch up only after some extensive experimentation a couple of years back. To tell you the truth, it took me a lot of time to pick it up but am I glad that I moved from
<a href="https://towardsdatascience.com/moving-from-keras-to-pytorch-f0d4fff4ce79" target="_blank" rel="nofollow noopener">Keras to PyTorch</a>
. With its high customizability and pythonic syntax,PyTorch is just a joy to work with, and I would recommend it to anyone who wants to do some heavy lifting with Deep Learning.</p><p>So, in this PyTorch guide, <em><strong>I will try to ease some of the pain with PyTorch for starters</strong></em> and go through some of the most important classes and modules that you will require while creating any Neural Network with Pytorch.</p><p>But, that is not to say that this is aimed at beginners only as <em><strong>I will also talk about the</strong></em> <em><strong>high customizability PyTorch provides and will talk about custom Layers, Datasets, Dataloaders, and Loss functions</strong></em>.</p><p>So let‚Äôs get some coffee ‚òï Ô∏èand start it up.</p><hr><h2 id="tensors">Tensors</h2><p>Tensors are the basic building blocks in PyTorch and put very simply, they are NumPy arrays but on GPU. In this part, I will list down some of the most used operations we can use while working with Tensors. This is by no means an exhaustive list of operations you can do with Tensors, but it is helpful to understand what tensors are before going towards the more exciting parts.</p><h3 id="1-create-a-tensor">1. Create a Tensor</h3><p>We can create a PyTorch tensor in multiple ways. This includes converting to tensor from a NumPy array. Below is just a small gist with some examples to start with, but you can do a whole lot of
<a href="https://pytorch.org/docs/stable/tensors.html" target="_blank" rel="nofollow noopener">more things</a>
with tensors just like you can do with NumPy arrays.</p><div><pre><code data-lang="py"><span># Using torch.Tensor</span>
t <span>=</span> torch<span>.</span>Tensor([[<span>1</span>,<span>2</span>,<span>3</span>],[<span>3</span>,<span>4</span>,<span>5</span>]])
<span>print</span>(f<span>"Created Tensor Using torch.Tensor:</span><span>\n</span><span>{t}"</span>)

<span># Using torch.randn</span>
t <span>=</span> torch<span>.</span>randn(<span>3</span>, <span>5</span>)
<span>print</span>(f<span>"Created Tensor Using torch.randn:</span><span>\n</span><span>{t}"</span>)

<span># using torch.[ones|zeros](*size)</span>
t <span>=</span> torch<span>.</span>ones(<span>3</span>, <span>5</span>)
<span>print</span>(f<span>"Created Tensor Using torch.ones:</span><span>\n</span><span>{t}"</span>)
t <span>=</span> torch<span>.</span>zeros(<span>3</span>, <span>5</span>)
<span>print</span>(f<span>"Created Tensor Using torch.zeros:</span><span>\n</span><span>{t}"</span>)

<span># using torch.randint - a tensor of size 4,5 with entries between 0 and 10(excluded)</span>
t <span>=</span> torch<span>.</span>randint(low <span>=</span> <span>0</span>,high <span>=</span> <span>10</span>,size <span>=</span> (<span>4</span>,<span>5</span>))
<span>print</span>(f<span>"Created Tensor Using torch.randint:</span><span>\n</span><span>{t}"</span>)

<span># Using from_numpy to convert from Numpy Array to Tensor</span>
a <span>=</span> np<span>.</span>array([[<span>1</span>,<span>2</span>,<span>3</span>],[<span>3</span>,<span>4</span>,<span>5</span>]])
t <span>=</span> torch<span>.</span>from_numpy(a)
<span>print</span>(f<span>"Convert to Tensor From Numpy Array:</span><span>\n</span><span>{t}"</span>)

<span># Using .numpy() to convert from Tensor to Numpy array</span>
t <span>=</span> t<span>.</span>numpy()
<span>print</span>(f<span>"Convert to Numpy Array From Tensor:</span><span>\n</span><span>{t}"</span>)
</code></pre></div><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="https://mlwhiz.com/images/pytorch_guide/0_hu498d9dc39892132ab99f755c5b75f03e_77051_500x0_resize_box_2.png 500w
, https://mlwhiz.com/images/pytorch_guide/0_hu498d9dc39892132ab99f755c5b75f03e_77051_800x0_resize_box_2.png 800w
, https://mlwhiz.com/images/pytorch_guide/0_hu498d9dc39892132ab99f755c5b75f03e_77051_1200x0_resize_box_2.png 1200w" src="https://mlwhiz.com/images/pytorch_guide/0.png" alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><h3 id="2-tensor-operations">2. Tensor Operations</h3><p>Again, there are a lot of operations you can do on these tensors. The full list of functions can be found
<a href="https://pytorch.org/docs/stable/torch.html?highlight=mm#math-operations" target="_blank" rel="nofollow noopener">here</a>
.</p><div><pre><code data-lang="py">A <span>=</span> torch<span>.</span>randn(<span>3</span>,<span>4</span>)
W <span>=</span> torch<span>.</span>randn(<span>4</span>,<span>2</span>)
<span># Multiply Matrix A and W</span>
t <span>=</span> A<span>.</span>mm(W)
<span>print</span>(f<span>"Created Tensor t by Multiplying A and W:</span><span>\n</span><span>{t}"</span>)
<span># Transpose Tensor t</span>
t <span>=</span> t<span>.</span>t()
<span>print</span>(f<span>"Transpose of Tensor t:</span><span>\n</span><span>{t}"</span>)
<span># Square each element of t</span>
t <span>=</span> t<span>**</span><span>2</span>
<span>print</span>(f<span>"Square each element of Tensor t:</span><span>\n</span><span>{t}"</span>)
<span># return the size of a tensor</span>
<span>print</span>(f<span>"Size of Tensor t using .size():</span><span>\n</span><span>{t.size()}"</span>)
</code></pre></div><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="https://mlwhiz.com/images/pytorch_guide/1_hufb8162ba4b3c0b49f946179a1702f5a7_45468_500x0_resize_box_2.png 500w
, https://mlwhiz.com/images/pytorch_guide/1_hufb8162ba4b3c0b49f946179a1702f5a7_45468_800x0_resize_box_2.png 800w
, https://mlwhiz.com/images/pytorch_guide/1_hufb8162ba4b3c0b49f946179a1702f5a7_45468_1200x0_resize_box_2.png 1200w" src="https://mlwhiz.com/images/pytorch_guide/1.png" alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><p><strong>Note:</strong> What are PyTorch Variables? In the previous versions of Pytorch, Tensor and Variables used to be different and provided different functionality, but now the Variable API is
<a href="https://pytorch.org/docs/stable/autograd.html#variable-deprecated" target="_blank" rel="nofollow noopener">deprecated</a>
, and all methods for variables work with Tensors. So, if you don‚Äôt know about them, it‚Äôs fine as they re not needed, and if you know them, you can forget about them.</p><hr><h2 id="the-nnmodule">The nn.Module</h2><p>Photo by
<a href="https://unsplash.com/@fernanddecanne?utm_source=medium&amp;utm_medium=referral" target="_blank" rel="nofollow noopener">Fernand De Canne</a>
on
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="https://mlwhiz.com/images/pytorch_guide/2_huf957eb7cc0803733802fcc4099cfd7cb_2203390_500x0_resize_box_2.png 500w
, https://mlwhiz.com/images/pytorch_guide/2_huf957eb7cc0803733802fcc4099cfd7cb_2203390_800x0_resize_box_2.png 800w
, https://mlwhiz.com/images/pytorch_guide/2_huf957eb7cc0803733802fcc4099cfd7cb_2203390_1200x0_resize_box_2.png 1200w
, https://mlwhiz.com/images/pytorch_guide/2_huf957eb7cc0803733802fcc4099cfd7cb_2203390_1500x0_resize_box_2.png 1500w" src="https://mlwhiz.com/images/pytorch_guide/2.png" alt="<a href=&quot;https://unsplash.com?utm_source=medium&amp;amp;utm_medium=referral&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;>Unsplash</a>"></p><p>Here comes the fun part as we are now going to talk about some of the most used constructs in Pytorch while creating deep learning projects. nn.Module lets you create your Deep Learning models as a class. You can inherit from nn.Moduleto define any model as a class. Every model class necessarily contains an<code> __init__</code> procedure block and a block for the <code>forward</code> pass.</p><ul><li><p>In the <code>__init__</code> part, the user can define all the layers the network is going to have but doesn‚Äôt yet define how those layers would be connected to each other.</p></li><li><p>In the <code>forward</code> pass block, the user defines how data flows from one layer to another inside the network.</p></li></ul><p>So, put simply, any network we define will look like:</p><div><pre><code data-lang="py"><span>class</span> <span>myNeuralNet</span>(nn<span>.</span>Module):
    <span>def</span> __init__(self):
        super()<span>.</span>__init__()
        <span># Define all Layers Here</span>
        self<span>.</span>lin1 <span>=</span> nn<span>.</span>Linear(<span>784</span>, <span>30</span>)
        self<span>.</span>lin2 <span>=</span> nn<span>.</span>Linear(<span>30</span>, <span>10</span>)
    <span>def</span> <span>forward</span>(self, x):
        <span># Connect the layer Outputs here to define the forward pass</span>
        x <span>=</span> self<span>.</span>lin1(x)
        x <span>=</span> self<span>.</span>lin2(x)
        <span>return</span> x
</code></pre></div><p>Here we have defined a very simple Network that takes an input of size 784 and passes it through two linear layers in a sequential manner. But the thing to note is that we can define any sort of calculation while defining the forward pass, and that makes PyTorch highly customizable for research purposes. For example, in our crazy experimentation mode, we might have used the below network where we arbitrarily attach our layers. Here we send back the output from the second linear layer back again to the first one after adding the input to it(skip connection) back again(I honestly don‚Äôt know what that will do).</p><div><pre><code data-lang="py"><span>class</span> <span>myCrazyNeuralNet</span>(nn<span>.</span>Module):
    <span>def</span> __init__(self):
        super()<span>.</span>__init__()
        <span># Define all Layers Here</span>
        self<span>.</span>lin1 <span>=</span> nn<span>.</span>Linear(<span>784</span>, <span>30</span>)
        self<span>.</span>lin2 <span>=</span> nn<span>.</span>Linear(<span>30</span>, <span>784</span>)
        self<span>.</span>lin3 <span>=</span> nn<span>.</span>Linear(<span>30</span>, <span>10</span>)

    <span>def</span> <span>forward</span>(self, x):
        <span># Connect the layer Outputs here to define the forward pass</span>
        x_lin1 <span>=</span> self<span>.</span>lin1(x)
        x_lin2 <span>=</span> x <span>+</span> self<span>.</span>lin2(x_lin1)
        x_lin2 <span>=</span> self<span>.</span>lin1(x_lin2)
        x <span>=</span> self<span>.</span>lin3(x_lin2)
        <span>return</span> x
</code></pre></div><p>We can also check if the neural network forward pass works. I usually do that by first creating some random input and just passing that through the network I have created.</p><div><pre><code data-lang="py">x <span>=</span> torch<span>.</span>randn((<span>100</span>,<span>784</span>))
model <span>=</span> myCrazyNeuralNet()
model(x)<span>.</span>size()
<span>--------------------------</span>
torch<span>.</span>Size([<span>100</span>, <span>10</span>])
</code></pre></div><hr><h2 id="a-word-about-layers">A word about Layers</h2><p>Pytorch is pretty powerful, and you can actually create any new experimental layer by yourself using <code>nn.Module</code>. For example, rather than using the predefined Linear Layer <code>nn.Linear</code> from Pytorch above, we could have created our <strong>custom linear layer</strong>.</p><div><pre><code data-lang="py"><span>class</span> <span>myCustomLinearLayer</span>(nn<span>.</span>Module):
    <span>def</span> __init__(self,in_size,out_size):
        super()<span>.</span>__init__()
        self<span>.</span>weights <span>=</span> nn<span>.</span>Parameter(torch<span>.</span>randn(in_size, out_size))
        self<span>.</span>bias <span>=</span> nn<span>.</span>Parameter(torch<span>.</span>zeros(out_size))
    <span>def</span> <span>forward</span>(self, x):
        <span>return</span> x<span>.</span>mm(self<span>.</span>weights) <span>+</span> self<span>.</span>bias
</code></pre></div><p>You can see how we wrap our weights tensor in nn.Parameter. This is done to make the tensor to be considered as a model parameter. From PyTorch
<a href="https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#parameter" target="_blank" rel="nofollow noopener">docs</a>
:</p><blockquote><p>Parameters are
<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" rel="nofollow noopener">&lt;code&gt;*Tensor*&lt;/code&gt;</a>
subclasses, that have a very special property when used with <em>Module</em> - when they‚Äôre assigned as Module attributes they are automatically added to the list of its parameters, and will appear in <em><code>parameters()</code></em> iterator</p></blockquote><p>As you will later see, the <code>model.parameters()</code> iterator will be an input to the optimizer. But more on that later.</p><p>Right now, we can now use this custom layer in any PyTorch network, just like any other layer.</p><div><pre><code data-lang="py"><span>class</span> <span>myCustomNeuralNet</span>(nn<span>.</span>Module):
    <span>def</span> __init__(self):
        super()<span>.</span>__init__()
        <span># Define all Layers Here</span>
        self<span>.</span>lin1 <span>=</span> myCustomLinearLayer(<span>784</span>,<span>10</span>)

    <span>def</span> <span>forward</span>(self, x):
        <span># Connect the layer Outputs here to define the forward pass</span>
        x <span>=</span> self<span>.</span>lin1(x)
        <span>return</span> x
x <span>=</span> torch<span>.</span>randn((<span>100</span>,<span>784</span>))
model <span>=</span> myCustomNeuralNet()
model(x)<span>.</span>size()
<span>------------------------------------------</span>
torch<span>.</span>Size([<span>100</span>, <span>10</span>])
</code></pre></div><p>But then again, Pytorch would not be so widely used if it didn‚Äôt provide a lot of ready to made layers used very frequently in wide varieties of Neural Network architectures. Some examples are:
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" target="_blank" rel="nofollow noopener">nn.Linear</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" target="_blank" rel="nofollow noopener">nn.Conv2d</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d" target="_blank" rel="nofollow noopener">nn.MaxPool2d</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" target="_blank" rel="nofollow noopener">nn.ReLU</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d" target="_blank" rel="nofollow noopener">nn.BatchNorm2d</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout" target="_blank" rel="nofollow noopener">nn.Dropout</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding" target="_blank" rel="nofollow noopener">nn.Embedding</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.GRU.html#torch.nn.GRU" target="_blank" rel="nofollow noopener">nn.GRU</a>
/
<a href="https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM" target="_blank" rel="nofollow noopener">nn.LSTM</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html#torch.nn.Softmax" target="_blank" rel="nofollow noopener">nn.Softmax</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html#torch.nn.LogSoftmax" target="_blank" rel="nofollow noopener">nn.LogSoftmax</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html#torch.nn.MultiheadAttention" target="_blank" rel="nofollow noopener">nn.MultiheadAttention</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoder.html#torch.nn.TransformerEncoder" target="_blank" rel="nofollow noopener">nn.TransformerEncoder</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.TransformerDecoder.html#torch.nn.TransformerDecoder" target="_blank" rel="nofollow noopener">nn.TransformerDecoder</a></p><p>I have linked all the layers to their source where you could read all about them, but to show how I usually try to understand a layer and read the docs, I would try to look at a very simple convolutional layer here.</p><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="https://mlwhiz.com/images/pytorch_guide/3_hu6bac2fdb22e4c85a567731e38a09e400_109832_500x0_resize_box_2.png 500w
, https://mlwhiz.com/images/pytorch_guide/3_hu6bac2fdb22e4c85a567731e38a09e400_109832_800x0_resize_box_2.png 800w
, https://mlwhiz.com/images/pytorch_guide/3_hu6bac2fdb22e4c85a567731e38a09e400_109832_1200x0_resize_box_2.png 1200w" src="https://mlwhiz.com/images/pytorch_guide/3.png" alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><p>So, a Conv2d Layer needs as input an Image of height H and width W, with <code>Cin</code> channels. Now, for the first layer in a convnet, the number of <code>in_channels</code> would be 3(RGB), and the number of <code>out_channels</code> can be defined by the user. The <code>kernel_size</code> mostly used is 3x3, and the <code>stride</code> normally used is 1.</p><p>To check a new layer which I don‚Äôt know much about, I usually try to see the input as well as output for the layer like below where I would first initialize the layer:</p><div><pre><code data-lang="py">conv_layer <span>=</span> nn<span>.</span>Conv2d(in_channels <span>=</span> <span>3</span>, out_channels <span>=</span> <span>64</span>, kernel_size <span>=</span> (<span>3</span>,<span>3</span>), stride <span>=</span> <span>1</span>, padding<span>=</span><span>1</span>)
</code></pre></div><p>And then pass some random input through it. Here 100 is the batch size.</p><div><pre><code data-lang="py">x <span>=</span> torch<span>.</span>randn((<span>100</span>,<span>3</span>,<span>24</span>,<span>24</span>))
conv_layer(x)<span>.</span>size()
<span>--------------------------------</span>
torch<span>.</span>Size([<span>100</span>, <span>64</span>, <span>24</span>, <span>24</span>])
</code></pre></div><p>So, we get the output from the convolution operation as required, and I have sufficient information on how to use this layer in any Neural Network I design.</p><hr><h2 id="datasets-and-dataloaders">Datasets and DataLoaders</h2><p>How would we pass data to our Neural nets while training or while testing? We can definitely pass tensors as we have done above, but Pytorch also provides us with pre-built Datasets to make it easier for us to pass data to our neural nets. You can check out the complete list of datasets provided at
<a href="https://pytorch.org/docs/stable/torchvision/datasets.html" target="_blank" rel="nofollow noopener">torchvision.datasets</a>
and
<a href="https://pytorch.org/text/datasets.html" target="_blank" rel="nofollow noopener">torchtext.datasets</a>
. But, to give a concrete example for datasets, let‚Äôs say we had to pass images to an Image Neural net using a folder which has images in this structure:</p><pre><code>data
    train
        sailboat
        kayak
        .
        .
</code></pre><p>We can use torchvision.datasets.ImageFolder dataset to get an example image like below:</p><div><pre><code data-lang="py"><span>from</span> torchvision <span>import</span> transforms
<span>from</span> torchvision.datasets <span>import</span> ImageFolder
traindir <span>=</span> <span>"data/train/"</span>
t <span>=</span> transforms<span>.</span>Compose([
        transforms<span>.</span>Resize(size<span>=</span><span>256</span>),
    transforms<span>.</span>CenterCrop(size<span>=</span><span>224</span>),
        transforms<span>.</span>ToTensor()])
train_dataset <span>=</span> ImageFolder(root<span>=</span>traindir,transform<span>=</span>t)
<span>print</span>(‚Ä¶</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mlwhiz.com/blog/2020/09/09/pytorch_guide/">https://mlwhiz.com/blog/2020/09/09/pytorch_guide/</a></em></p>]]>
            </description>
            <link>https://mlwhiz.com/blog/2020/09/09/pytorch_guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065771</guid>
            <pubDate>Thu, 12 Nov 2020 02:30:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Fastest Way of Computing All Universes (2012) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065400">thread link</a>) | @optimalsolver
<br/>
November 11, 2020 | http://people.idsia.ch/~juergen/fastestuniverse.pdf | <a href="https://web.archive.org/web/*/http://people.idsia.ch/~juergen/fastestuniverse.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>√§√àh√ìY2_√ä¬≤√©[le√≥≈í‚Äö√∑*L√äx√§√±√é√£√â√á√É‚Ç¨√éd≈Ω√≠√¢¬¢S√º
√ß√Æl'8√∫}GV¬≥¬±¬Øz‚Ç¨‚Äû{@≈°√ÉRX√îB√ä‚Ç¨3¬¥¬£\ÀÜ√å≈ΩÔøΩe3∆í9‚Ñ¢√∫P%‚Äò'¬ªO]D?Al√à√ø‚Äô¬πf¬ßÀÜÀÜY=¬≥{‚Äô√ÇJ√òEy‚Ä†√≥6√ã√Ω`√Ø
lh&lt;√üt{√†T_¬±√£E‚Äò¬¶¬∞
¬¥"‚Ç¨∆í‚Äû‚Ä∫√ö?√ö√Ç¬™z‚Äû√¨√ÜFe√àÔøΩ√®U#¬Æ#qR¬¢√∫LG√ú√πa¬æ√ò)
√ò‚Ä∞F√¶√å\$√Ñn√ø¬©√ÆE¬¥≈°√∏√∑√£¬£‚Ä∞+4√è‚Ä°√ê¬¨¬≥¬∂A¬®-√±√à¬π√´j√†]ÔøΩ√ë¬¶a!√Ø√∂√π√Å√èi8Q	0)ÔøΩ√©eFx¬∫‚Äû¬º√¨]‚Äò√åI+√¥√ò'_√î)‚Ä†√é!√π√ß"r‚Äô√†√ê√Ñ0√∞0L√®√ù√ò¬ºy√†#RZbV√Ω~&amp;6√êA7√ç√§h6¬±√Ü		¬§√Å.¬Ω√û√äÀÜR√è)¬∫¬•√û≈ΩT¬∂√îN`=DÔøΩ4C¬ßEY¬™1¬ª¬π2¬°CM√∞ÔøΩ¬§b√ú√Å√Å√Æ85¬°b√¨√ÖDl6e‚Äòj√¨¬º√ë¬º8¬º√®LB≈í7√°~LÀú¬≤‚Äì¬ø√ä√ù‚Ä∞D√©	K%‚Ä†¬∑&gt;¬∏KÔøΩ √∫
√≤≈†(D√àkX√â√≥√É3‚Äû{‚Ä¶‚Ñ¢≈ΩJ‚Ä¢√ù¬≤!m√¥Sb4¬∑!√ÜÀú¬¥F‚Äò√®ÀÜ√ó(|ÀÜ"√ã‚Ñ¢N¬∞&nbsp;√ºq68≈°√ö√µ‚Ä¶√•mÔøΩ,√Øy@
¬∞‚Äî√ç
{‚Ä∞ByG8√ë'√∑2√±v¬º7√ï¬®¬¥√é¬∂*ÔøΩ}√é∆í√¶¬°√π√™Y^aE0√ô5i¬∞;$√áD√±	x¬º4√ßÀÜtC√á=√ê0√ü¬≠‚Ä∫Q√è2√ä≈°!~f¬£]√∞√ù]Àú8√´('&gt;=Àú√ü¬™`√ª≈í*√®[]‚Äì&amp;vW√°‚Äû√†]P,K√®w√§√ô¬º‚Ä∞44_√à¬π
&lt;¬¢W¬º_√ï√•√è√â√û9¬°√∞ESI=gF‚Äò7√µ]√ï¬ªj¬°on√º√ö√¨¬¥/~≈æ√ì&gt;√â√©¬π¬¶YqB/P2¬ß√Ω0‚Ñ¢√ë¬∂5et¬≠‚Äπ¬¶*y‚Äò√µq√ã¬Æ$√üp~√í‚Äù√É¬¢&gt;¬∫@√ãP¬º‚Ñ¢v√õÔøΩ$P&amp;YcW√£B√ô‚Ä∞≈æs¬ß√∫√ú¬Æ√©¬´‚ÄìRY¬π√∫A√ù√Å√µ%√π√•√¨‚Ä°‚Äì√µ√¥@3¬≠√ô≈°√õ1oD√è√¨6 E√µ¬£‚Ä¶¬≥
"‚Äòa√õ‚Äìbn√ñ√ñ√™≈æ¬∫H√ô‚ÄöGqwnrm?u√≥¬ÆjÔøΩ¬∏.B√é‚Äòh.Z≈æj√å√∂¬æJ Àú√úN^√äx√ç¬§e√Ö√´Fj]%√™√∂‚Äùx,√ì&amp;~√ù‚Ä¢√∞¬¢n‚Äô≈†‚ÄπD√ç√Ñ≈ís√°√æ¬™P√¶|
ÔøΩ;ÔøΩ√æ_
X;YJ{p√©Z¬∫i¬≥;7¬Ø¬Ω¬•√∫¬±≈°‚Ä¶S√é√æE√øf‚Ä°¬§M
√ö¬µ‚ÄötGt‚Ä†¬¥Cj√µ¬´¬º√ût‚Ñ¢k√ï¬≠√Ö¬®≈ì¬Æ¬º√éTj}≈ì√™√û{q6g√ºJw¬±√∞√Ç9√¢"¬Ø√ë¬º‚Äûc√æ√ç√∑¬æ‚Äì\D√≥√ú√öK√Å√ª‚Ä∞√¶¬ª6H√ø√ïqcokC{‚Ä¢_[R‚ÄìÔøΩ¬ª¬§¬∏ ‚Äû¬´B7E¬∞≈Ω¬™√π^√≠√æ¬°OdÔøΩ≈∏¬π4√Æo\SÔøΩ√®¬™√≠*√∫√â‚Ñ¢√∂≈†√Ö+ &amp;√¶X(√£¬¢&amp;WF¬ø¬¶√ätCU√Ñ‚Äö,‚Ä¢4‚Äò}'√ï8√∂√é]√•¬∫G√Å√ü√õW
‚Äô¬∑√ï0¬¢Zx)3‚Äπp¬£‚Äú2t√è√∫¬¨‚Ç¨√ï,√Å√∂‚Äú√∂≈†Z:)i√∏√ç‚Äùo‚Äìh¬§√•≈í√ßÀú√Æ;¬≠‚Äö|√á√üYxXk√àÀÜ√ê√¥U√ü√àGo‚Ä∫‚Ç¨√§ÔøΩ¬™√∑h√π√ç¬¢:√õ¬™¬´8‚Ñ¢T‚Ä¢,√çefR)‚Ä¶r√§‚Äû¬¢‚ÄùxI1E√óÀú‚Äπ‚Äîx8ÔøΩVDF¬∫¬™F√≤≈°o√ó:√´}√ät6≈†√Æ%√≥e¬Ø‚Ä†√µ√£v‚Ä∞√êU,Y¬¶0ÔøΩÔøΩ√Çh¬∑≈∏√±√ø√ú√£c≈Ωpx-√¨¬∂√®√ß%‚Äú√±¬Æ√π√ú¬≠√Ü√©√à0O√Ñ√¥D¬Ω8√¶m¬°√ûNÀúP√ÇXHB≈Ω√ò‚Äú¬´√ö‚Ä∞a.√ª9fÀÜÔøΩ¬≠‚ÄöN!!U:¬ª7√•‚Äò-p‚Ä†¬∏√æ=√ë√ß&gt;¬¢r0J≈†¬∑√å‚Äô	2¬≥!√éA√É‚Äö√∫S@√ë@‚Ç¨¬™∆í√∫¬Ωm&amp;f7/≈†E‚Äì`b7&lt;¬≤√ª	]√¥13	u‚Ä∞E‚Ñ¢√ñ√∞9/≈°√ã0√¥*7√§¬´a¬•^√á8D√Ü√¨√ñ
√©√Üp√∞)≈í¬•√Ü√ç√æ@
√¢√Ωee¬≠n√ª√∑√©"‚Ä∫¬±≈ì√Øn√∂v√ß}ÔøΩ
√Ñp¬Ø¬¶ÔøΩ¬µb√òa√Æ¬¥K1i√≠%r√Ω√µ√¢¬ø3ds√ë$?¬°&nbsp;x√Øx≈ì√ºXne~√õ¬æ√•ÔøΩ¬•V√¥√å
I√äy‚Ä∞√íj√¥i'=√®‚Äö√õ≈°ÔøΩ√ò‚Äπ‚Ç¨a¬æZ ro√à√±¬©√†j√±√î√èM‚Ç¨√¥18c√ã√æ¬∏√Ü√ê√±M√£√ïgÔøΩ‚Äî!Àúq¬µ√∞.√ä¬Ω¬¶H√é√Å
ÔøΩ√Ö√°J≈Ω'√¥=¬π i√õ√™√î√´0pÔøΩ+%‚Ä¶‚Äì7‚Äìw¬≠√£¬•p¬®w¬∑¬º¬¢ÔøΩ√•≈Ω‚ÄùCSKt√´¬¢-Rcy√¢n"¬™¬∑H√µ0/√ï)√Å7√Üv√ôJUIzÀúlY√ß≈í	hz√ô√®p&nbsp;^ÔøΩ&gt;¬©√ä‚Äπ!7√ô√ï¬•√©‚Äû√Æ≈∏q‚Ä†3ÔøΩ
$QK≈Ω4/√¥&nbsp;LAÔøΩ√≠s&gt;¬´[√†K√µz‚Ä¢√ú¬ª√´.√ë√°c√èf√ú√åT-¬°¬Ø¬£¬™}R!ÔøΩ√≠^¬≥¬™√ö√§√Æ√∞¬≤]Z√†-
≈íT√ØR√±q√∏≈æ@eZ√èy¬±"‚Äπi¬¶¬§‚Ñ¢M¬™¬¨¬™0¬Øj‚Äú‚Äπ
3≈ì*√≤‚Äì4√á√åÀúVy¬Ωp‚Äî¬æ√Ü√ú‚Äö√ï√≤gY|bÀÜ¬Æ‚Äú&gt;¬∞i√â[-√á#√°√áR-"B√ô2¬°^¬®≈∏‚Ä¢≈†ÔøΩ\√Üj4√Ée√¨&amp;s1√±)eS&lt;+‚Äπ‚Äô3$n¬°√∂w1Rw}^¬§x√ê¬∂&nbsp;≈ì4ÔøΩ}√á=WÔøΩs¬®‚Ä∫9ÀÜ√ßj¬≠√ô√è"√π≈Ωs¬•l√Ñ:√º√∏‚Ä†1√µld=√Ñ[ÔøΩ¬∫ÀúÔøΩ√íbg¬•¬∂√ßL¬´√â√ò√ì√ë?Q√®¬°√¶√ñ¬™9√ñg≈∏G√í¬§√ÖÀú√≥√ß√ß‚Ç¨√ê¬°ÔøΩ¬°3¬©OSc√èB√ûTT}≈†√á8!√å¬Ø,NW#PÔøΩC√é¬π√∫¬Æ/√ñ‚Ç¨,(=√¨6j√∏r√çw√∫√¥√ÑÔøΩ|e√û¬¨h¬∞d^)‚Ä∫YY
¬¥‚Äì^¬ø√à=	j‚Ñ¢√±√°b
¬Æ√ô-ÔøΩy√ßyu(ÔøΩ¬®¬¨r;¬©√™e¬∑√ãj,√ÜJ3¬¥√∏√öd√ö√∑ÔøΩ¬≤≈í¬•G≈ím¬´¬™√Ω5‚Ä°q¬πd¬µ9¬©-¬¶√ç¬πkÔøΩ‚Ä¢¬∂¬ß√±‚Äû≈æ+√≤‚Äìl6√Ω&lt;9MPw√±R√∂¬¢y√Ü√ãT√∂p
K‚Äπ[ukb≈†¬∂ÔøΩ√™*4?Yq√ø$¬¢¬´‚Äô¬±1&gt;w"√ö‚Ä°S√ù√É¬±_np#√´¬Ω2√Æ‚Ä∫"√ï¬Æ√¶jÔøΩ≈æ¬Ω≈Ωd¬∂‚ÄùS¬∂¬™¬∏ow!ÔøΩ√™OPrR√ê√ë$√¢√ç√∑√ñ<l}k&r>√πÔøΩd√ë24√Ø√é√•‚Äô+√ç;X-≈†¬•x‚Äî√úÔøΩ√±¬•j√ì¬ø√Æ√è≈æ‚ÄùuC8)√ñxÔøΩ&nbsp;¬∫‚Ä¢m3¬æÔøΩW√âsRM8‚Ä¶√ª‚Ä∞T‚Äπ2d¬º¬¢¬§√†z‚Äπ‚Äπ√∫¬¢√öq√Ü(g&nbsp;√Æ‚ÄúÔøΩ√∫V√ã`¬•√â‚Äô ¬ª6¬Ø!=¬µ7√í*‚Äû¬§w"~¬π‚Äû‚Äôe‚Ä∫8ybJ‚Äö*6¬≠√∑ ¬Ω‚Ä°¬π√πi‚Äú∆í√º≈ì¬π√¢LK√Ç‚Äú]√¶‚ÄôE√Ö¬¨√Ä&nbsp;¬Æ([√ê√Ø√≤√∂√àz_T‚Ñ¢u¬¨ÔøΩ¬£2√∏√∑¬Ω√æ|√ë$√ü‚Äπ¬ø_~\√æ¬∑√û‚Äô[
endstream
endobj
4 0 obj
   3245
endobj
2 0 obj
&lt;&lt;
   /ExtGState &lt;&lt;
      /a0 &lt;&lt; /CA 1 /ca 1 &gt;&gt;
   &gt;&gt;
   /Font &lt;&lt;
      /f-0-0 5 0 R
      /f-1-0 6 0 R
      /f-2-0 7 0 R
      /f-3-0 8 0 R
      /f-4-0 9 0 R
      /f-5-0 10 0 R
      /f-6-0 11 0 R
      /f-7-0 12 0 R
      /f-8-0 13 0 R
   &gt;&gt;
&gt;&gt;
endobj
14 0 obj
&lt;&lt; /Type /Page
   /Parent 1 0 R
   /MediaBox [ 0 0 611.999983 791.999983 ]
   /Contents 3 0 R
   /Group &lt;&lt;
      /Type /Group
      /S /Transparency
      /CS /DeviceRGB
   &gt;&gt;
   /Resources 2 0 R
&gt;&gt;
endobj
16 0 obj
&lt;&lt; /Length 17 0 R
   /Filter /FlateDecode
&gt;&gt;
stream
x≈ì‚Ä¢Z√â≈†4√á¬æ√óS√¥L+√∑‚Ä†&gt;‚ÄûA√†∆í√¨~|√®¬Æ≈æ√ã √π√†√ów|¬±df√çt[2B√≥WeeFF√Ü√≤√Ö‚Äô√Ω√´√¶N¬µ‚Ä°S√±√æ√¥R¬ª?√Ω√∂~√∫√ª√©_4≈†√ø~√ª√©√¥√ù√ïÔøΩ~√∫√∑√∂¬ß¬∑¬≠≈ì{ÔøΩÔøΩ√á√µ¬±¬ªs-¬Ω√∑z*C¬•¬∑xz√ªe√ª√Æ√£√Ö¬Ω¬∏‚Äú?¬Ω}l√ü^ÔøΩw√°√∫¬´‚Äπ‚Äî‚ÄîÀú√ì¬´K‚Äî√ø√™√≤‚Ä¶√ær‚Ä¢√±√ù‚Ä¢‚Ç¨¬∑1¬±o√Æ√äo√ó√ã?√û~√ò|?¬∑√ñ#¬±√≤v√á¬∑Kh¬Øn¬øD√∑√™√Æ√Æ√ù}]√Ø¬º√á*ÀÜ‚Ä†ÔøΩ&gt;√π&lt;_?zÔøΩY7√∫≈Ω√≠√©#√Ü#;&gt;√¶We√Ç;3√∞√Æo~√∑z√ó√ü}√∞I≈∏u√≥√†6¬ø¬°≈∏k,√ô√∏
	`C¬®√∫ÔøΩC$√í√ô‚Ä¶ÔøΩh‚Äú‚Äû√ï4Yb√Æ"3q√á√¥¬¢≈íb∆í√Ø√üTe√Ω√≥√âÔøΩC√Ø¬ß√ø√ê√Ä√¥√ø√è√õ¬∑√êÔøΩ;√ù7√ØN9√ΩJz√ÅD√º%‚Ä¶≈∏IP√õ√æ√ã√ñ√Ç¬π¬ß~z√±¬æ≈ìc√ç¬ß_N6√í√É9√∑√ø&lt;√Ω√≠√¥√£√∂≈ì@g√ß√±{#5≈∏{XF~‚Äî)6I√§√è√©√ø¬£A√ú¬∂¬∂≈æc√Ω√Å∆í√ò¬π‚Ä∫s√ßT√£"‚Ä∞J‚Ä†≈æK√∏√É¬¢ ≈∏8‚Ä°¬∏≈†√ÇF√æ√∞1&amp;c√®s?√±ae√¢¬¨!~√¶c√∏;9z%WvBR}√å√ßÀú[√Ø‚Ä¶‚Ç¨¬¢≈æc¬Ωe√µ√¥f≈æ√é≈ΩNN√æ√∂3‚Ä†¬ª
√ì√º∆í¬£¬£‚Ä∫¬≥^b#¬∑ÔøΩ√§√∏√ôW]¬£;97√Ä√†F&gt;‚Ä∫√Æ√ß^x‚Ñ¢;√©√£√ÇGn√≠√ú‚Ä∫√´¬≠(aA≈ì‚Ä∫#<sw√Ø. ¬°‚Äô¬∑√ÄubÀÜ¬Ø√Ñvxsp√Øp∆í√®√ç√ùh6¬π¬¢¬º√ü7≈°≈°√ún~"6ÔøΩÔøΩ√ä;w√É‚Ä¢√à√ë√∑¬ª&¬ºr√∑%t¬•√ç√û√´‚Äô‚Äö≈ì¬∫¬¨√õ7√óvx="">‚Äòa√ò√Ä≈†√¢√û‚Ä∞√ù√ö‚Äòa)√¶√∞l‚Ñ¢√ßF¬¥4n¬¥y√º¬¥G&nbsp;√≥¬¶√§/z@¬∑‚Ä°N,A≈°≈Ω√Ä@‚Äö=‚Ç¨YBDZC√ÄG¬∏√ÜgyaZ√æ5&amp;‚Ä¶%√∫	¬Ø‚Ä∞M¬≤K√ùmc¬π√†5‚Äúhy=√≠√°¬ªJÔøΩ9√û]W√±`6t√¨√¥ÔøΩ‚Ä¢2≈Ω√†√ù¬¶√´√â v√ñX√¶√¥S√ê(¬´bd‚Ñ¢√Æ5≈°P√ê(√ÇnC√ó¬π≈∏h-M√ÅD√ß≈ì‚Ä†‚ÄùI√üI≈°b√ä√û,‚ÄπfBuEM¬π√π√õ√•¬•8√µ‚Ä°ÔøΩkX¬æ√í+ÔøΩ8/Àú)6√Ü&nbsp;
¬§√£√∞‚Äò≈íÔøΩ
√°√ö‚Ä∞m√ö¬∏&gt;√ñ‚Äö√â√ï√Ä‚Ñ¢ÔøΩ√®K.I5√πÔøΩ√ß√™ √ö‚ÄπBV‚Äû[up‚ÄûahO'¬§s√à√†s√®&nbsp;L¬π¬∞m√ë√õ√©Xz√•X)√´%jN:W√µ‚Ä¶4f√ü¬ß&amp;yF≈∏&amp;J4%¬§y√ô√ã√±'0^√îX√ó∆í√´¬∫√à√â&lt;√ãP¬Ω_¬£(;¬ß¬¢o¬§X≈∏√ü≈∏√ò;‚Ä∞√¥√òÔøΩ√â√ñ‚Ñ¢"‚Ä†Àúj‚Ä¶‚Ä∞VF√û0"x¬°√è"√öB¬¢ÔøΩN√ç&lt;√∫
≈Ω√ó*}*‚ÄîY XSL‚Ä¢¬∂eaOO√Ö1|\m?√ï√ÜG!&amp;
¬±Z√û√û√ò¬∏N#+&amp;√¢!√º9	G≈°d√Ö¬°∆íp}$0.0√µ¬Ø	≈æ√è√±L√ûR√ú¬°√®‚Ä∫z√´≈†¬∑e√¢~¬¢C√ê√∫x]
√Ö√ö.√ì√∫t¬Æ¬µ√è√µ¬º≈æ√ê‚Ä∫jb¬®∆íP√®¬ø‚Ä∫≈íÔøΩ);&lt;{+‚Äùl‚Äô√Ö√ß¬≥√£√ìn"¬∑4TÀúa√∫√û'5√Ä7L√±jw&nbsp;a¬¢√éF¬≠ÀÜ$I√ä
k¬¨√•√í^c‚Ç¨f√Ü`3¬≤≈†¬§¬™√òp=¬øC√¥/$K:~?√Ç√ç7s√é√®√≠√ú√ª#ci√É¬£≈°√¥√åK6v¬ºKa7‚Ä∞~√¶√ë!√Ö‚Ä†¬Ø√à&lt;‚Ä∞√ÇD'√Å√Ö'‚Äù≈æ≈æ‚Ä¶T¬≤3$≈°)√Æ2]O√ÄÀú√°6√Ö≈í+√û√≥√¢+¬¢B√π√™¬•√ô%√∏√™√ç¬¢Z√Ø≈íÀÜW≈Ω√à‚Ä¶(86Z√≤¬°¬¢√à√•√µ√•¬™R¬¢√ß√ê)√£e√∂¬ª¬∞√íqX√±P‚Äò#¬ΩI¬§√â&gt;4V/G√êi7¬≤√º.ÀÜ)√≤√û¬¨√≤√ØMAQva&nbsp;8¬µG√Å√¶‚Ä∫Z¬∂ ¬±‚Äî¬∞¬•√ß¬π≈æ@√ø)√π∆í]¬æ+x.√©√ÖK√¢√Ä¬∫¬±¬µ#√∫x√ë3¬®‚Äú¬≤≈°;¬¢&nbsp;Àú;√áC√ë√è√Ö√ª
√≠¬¨C'√∫¬™√ôJ¬¥√óUMI¬´√†7&amp;√ì#ÔøΩJ√ú√≥≈Ω√Å!√±√∂%B≈Ω‚Äû"√•¬Ω
&gt;√¥	∆í¬æÔøΩ√ø√¨√Ç≈í6¬∏√Çj√£√ßKN¬≤T¬¢¬´~N¬∏√ç	≈í¬¢¬∑Y&nbsp;.√ä¬§p‚Ä∫*‚Äò	t√ûm√ù4¬π√ù√πo√†¬ø2R≈∏¬§¬π√ëQ√ö¬®¬≤√∂t√¢)√¥¬®√â√æ¬∞K~
√´√±x
!O¬π‚Äπ¬ß√≥√àÔøΩ‚ÄùÔøΩ-√≤√ïM≈í√ä¬®ÀÜeGo¬©¬≤RxO9√πj¬º≈íWd{‚Ä°√§+:√ø√òRDj√™dÔøΩ‚Äò{U(fc,≈†√º¬¢+√´L+≈†,?B¬£‚Äù√Ω%√ã≈∏a√Ék‚Äö√ö<k‚Äúi√ê"{¬¨‚Ç¨¬π√âf¬∫‚Ä¶√â‚Ä°√à5√≤ pb‚Ç¨mf√´b√òn≈†√±r√á¬º="" √Æ≈Ω√Ñ¬£p¬¥q¬≤√ö‚Ä¢)2¬£√∏@b¬£‚Ä¢‚Äö√ß√™6ÔøΩ¬§√å@¬°i<ÔøΩ√ß"√ªqz%√ô="">√å4√´(z9√ÉFs√ì√å√ñ()u∆íÀú√≤¬ø‚Ä†ÀúgYFF!√Ç‚Ä∫&gt;√â3√à√ÖC‚Ä†‚Äπ√á^√è5&amp;√ò√æ‚Äî&lt;√£¬™~√£≈∏dT‚Äî‚Äô‚ÄòmP¬¶r√∂‚Äù¬∑*¬´√üH%¬£`o¬∂¬±X¬™lo√¥M√•*2U=r~y√£√±‚Ä°\√ójCÀú√£
‚Äú√≥H%Ef√ß√µ√¨N√°\√ï√µ¬≥7/-¬§¬®√•√°U√öc√†E#¬¶¬º‚Ä∞Aq√π‚Äû√ó+¬≤√ç√¢x√Ñ]7¬´o√Ñ√∏√ùÀÜ√ë¬º@√é√èOX‚Ä†√ß√∞:‚Ñ¢¬¶√≥))¬´XZ√¶~
√ªi√∏aK√∫r√±ZÔøΩ,F¬∂√õ≈ìp	‚Äπe√ª¬™xs√é$√ø√Ö√Å$√óJMK8tx;b√è¬±2$√™¬µu‚Ä¢¬≠¬¨√ù,ÔøΩ√Ä@√•‚Ä¢√µX¬£√âcQ√ëUd¬ªm¬æ¬π¬´%
√ª0√∏√êx√´$
ZN√ª3√àY≈†D\√°≈Ω#cy‚Äô;ÔøΩ@√ï√∑¬§√Ö;?g√ì≈°W¬≠J2√ÑOT¬æÔøΩ!‚Äö√≥y‚Ä†√±d√Ä`¬¥√æ¬™‚Äù√¨√ó√Ü√®Y‚Äò√Ω¬¢}≈†¬©√£¬ªn¬≠¬¢cSjME‚Ñ¢7~√úQa√üw√ô√äz*b√°A¬∫+¬±¬≤¬•√®¬¨√ê√á√£
¬®√Ü√û√õ√ÜWnH√∞ :¬ª√¶√â√úHpÔøΩqX2C	√®≈í¬¨ÔøΩ√ô‚Ä¶¬≤ÔøΩ‚Ä∞¬´9√Ωj&amp;¬∑‚Äò¬Æ!w¬∂E√õ√Æ¬∫¬™&nbsp;¬µ≈ìG\√ô‚ÄπMÔøΩ√æQ.ÔøΩ¬Ø√û√∫1C√ü√Ü‚Äπ√Å‚Äî‚Ñ¢‚Äπ≈í¬®*Àú¬æ?1≈°$√â¬∏@6√É√†!¬∫√ú√ú√ÄB‚Ä∞l√™2√Ø√Äke#ÔøΩ√¢7¬•,-√≥¬°*ixX¬≥√¨ÔøΩ√ì√õ¬§‚Ä∞:7&gt;(=V}D‚Ä†√•√ë3u√ìÔøΩ¬•((%8√ß‚Ç¨√±)√ów√•n6@√ü√å
√ügK√®¬Æ≈íI¬æ¬©ÔøΩ‚Ä¢√ß
‚Äö
m√∞‚Äû√Ä‚Äî
D.√Ñ¬©‚Ä¢ÔøΩÔøΩ|¬µ‚ÄöJu√Äs¬§√ìg2d√£ ‚Ä∞√®√á√Ü√ÇÔøΩ¬æ√≥√ÆCVV E≈íFÀú¬©√ë√πt√ï¬∑√†∆í‚Äù!ÔøΩ≈í√É√ö¬ø[¬Ø≈í√Ç¬æ¬ø≈Ω(√±¬©
√á√ü√¢√ö¬æB√Ül√∏ÔøΩÀú¬∑}≈†‚Ñ¢√ú¬¨[¬Ωzi√û√çZ√î√ú
¬≠O3o¬ÆadIg‚Ä°ec‚Äì¬Æ_√ä[?2√¶t‚Ä∞D¬æY√øJ√ö‚Äùj‚Äö‚Äô¬ÆsSXKBe√™E[≈†√è¬≤‚Äîo√Ç√°.¬≠√ö‚Äù‚Ä∫5xr√ø‚Äô‚Äù∆í2√Æ√ã‚Äö¬™√ÜfÀú√ò¬≠D21pX√¢‚Ñ¢≈í≈æw[u&amp;‚Äî.√â‚Ä∞‚Ç¨√ú
"√∫√ò√¶.\√í√°√âÔøΩ√ñ√∑√íY√â√ç√†ilb&nbsp;;r¬¢√∑8¬ªUF‚Ä¢
√ñ√ã‚Äö~YÔøΩp"‚Äú‚Äûk√ó¬™√ßN;√ô¬§-#‚Ñ¢%‚Äú√†"≈Ω N&lt;|X√ëC2&nbsp;‚Äù~@8‚Ä°√Ö¬®;/¬π√É≈†z√±√Üi‚Ä¶√Ñ√ß√Üh√û‚Äö√ûM¬æ"∆í2z√´‚Äò#¬±ew√ú‚Ä∞√©`=&nbsp;√î√∑9√ß√ò√ô≈í3Q¬™√è√º√¨¬∞√≥@Z≈Ω√Ç√Ärv)$¬ΩL¬ΩK√ò√ª≈∏¬π√π√±√ç¬™
M√íT<h[√ûg*√†-√ú√ë9√íyq3√î?n2¬Æ&≈æÔøΩm≈†¬Æ¬∏‚Ä°93√ó√ë¬´√åvvu#;.¬∏∆í≈†√êj‚Ä¶:√∫!‚Ä∞b¬π&ÔøΩy√õ\√áj¬∑ÔøΩ√ò√è¬∏j√ü¬≤‚Äù√É3y‚Äìw-‚Ä°‚Äû√£¬π√Äfg¬π√ô¬•qb√´√£>√£¬¨d√í¬±M‚Ä∫√É√≤YQ¬Ø&nbsp;√µ√å√ï√≤√Ä/'+√Ör√∫Jl√≤`P¬∫¬≠M√∂V√¶#q√Ü7R‚Ä∞9¬ºk√ó9¬¶√§5√ë‚ÄùGA√≠z√≥¬≥¬•¬©√á¬≠z~√ª¬Ω|≈í2√Æ‚ÄòI)√û¬¨√ó[MR‚Äî≈†√£√ÑÔøΩ$≈æ[_.J√ô√ç6"√öa‚Ä∫√πh=¬§,Y≈°^√Å≈íh¬•¬æ√î√π√íM√àVÔøΩUX@¬£¬™∆í√ΩS√¥RC√ú¬æ%r(√¨n√≥lk‚Ä∞V5√ç√ç?h$¬≥¬∑‚Ä∞‚Ä¢√∏‚Äò}[¬¶L¬ºh√æÀÜ√π¬∑%v!(√§¬º√§¬∂:d¬≤‚ÄôD2¬¥c‚Äù=(√á√ªZ¬æ√á√è%&nbsp;I√•√ï√¢√Å√£'!_¬™√∑√∞√¨‚Äì‚Ç¨&lt;√≥√ú_-√∏VHry¬Æ_o	√û√µ^ÔøΩ√ºY!√ò√≠@‚Äî7¬´$¬§√†Ng≈∏B√´√©KP¬ªy+{wDo√ºÔøΩ√ÉU√Æ
}√ó*HK9¬´√§√≥¬µs¬≠¬¶9√º√±‚Äú‚ÄöS(√ôB,.ÔøΩÔøΩE√£b}√Éu√ì√≠√ì¬ÆLaI√µÔøΩm+‚Äò‚Ñ¢¬ß√û√≤¬¶‚Äî [3√∞M¬Ω√ß\~¬¥√®‚Ä°~N'√±)‚Äì√ó√∞√Åi?8
√∏k¬≠√ÖJR/f√úV¬∞.*&gt;√è√ëo‚Äô√•K√¥U√Ø¬∏H√´z‚Ä°√ü‚Äöc√µ≈í√ê√º1√ì√ê&amp;√¶¬ÆS¬µÔøΩ‚Ä†√§OÔøΩÔøΩ%√ëe‚Ä∫9√´‚Ä¢&nbsp;7,√Ñ‚Äπ¬π√ÇÀÜN‚Äô√öK√¶&amp;≈ìAjÔøΩcHEM√¨fG‚Ä¶ÔøΩP√¢¬∂√ø√ßI√ë--√ø√ß√ù‚Ä¢‚Ç¨≈∏√ç√ãc√≠]√≥¬©√πwO#‚Ä∫≈†‚ÄôT√ª√õ8¬µ\¬ªp√ö√§¬∫'M√çl‚Äô;√à2¬µ√ï8¬¢¬Ωx√´%¬Æ√ó/√Ü]PÀÜg&gt;¬∫√Ö*E¬¶a¬•‚Ä†√à]ÔøΩ-r\¬Ω√É‚Äò‚Äî≈∏¬¨k\√É√ù√Ö`√§.√ó√ô√µ¬ª√ú-o√∫√É≈†xH@@¬ªÔøΩ√å‚Ä°¬Ω√õ√•X‚Äπuy)L¬¢√ù¬∞√èÔøΩ‚Äπ¬º#uÔøΩ√ª8y√º√§‚Äû(2¬¢b√µ‚Äô‚Ä∞c√ê~\¬∞S&lt;√•√ª¬°}¬≤‚Ä°√≤¬µO‚Ä∫‚Ä°,√≠≈æ‚Äô3√åq√´√Å¬ß{‚Äô√ü√áEb√©∆í√ë¬•¬£¬¨e¬Ø&nbsp;‚Äò%‚Äî√ìG√æ√≤ÔøΩ√∞U‚Ä¢_√ô‚Ä∞D¬©w√∂Y4√Ω‚Äôf√ô√õ7√±k√á¬≠gIR√á,&nbsp;*~7:‚Ä°≈ì√ú¬ª≈°√Æ√ß√ä√àu≈í¬©√±&amp;≈í=√´√à/≈í¬ß¬±z)√Ö¬´¬∑√≠Hs≈æ¬Ø¬πvWd8√¢fY"¬º#‚Äπ√≥‚Ä°¬Æ¬´auF¬±‚Ñ¢√´√±
√º√≥Àú&amp;kÀÜ‚Äù¬≥¬Ω7√Ω_√†¬´$¬Ø+e¬¶¬±√®NN(√®EÔøΩ&gt;e¬æk√≤≈° ÔøΩY‚Äù‚Ä†T√≤YB[¬µ¬≥√ßFr¬ß√≤ÔøΩ.&lt;√êpt¬™a√æY‚Äûi‚ÄîG√≠:UqW-√≥‚Äî%K¬©&amp;¬øV5√¢√ßÔøΩ_√ªP√ê√ª√≠cQ√Æ~≈°√ù'¬´√üp√∫=√ê&amp;ÔøΩBP¬π7√Çi¬∂rO8‚Äù3u+t¬¥xq√≥&gt;F{√Ö√Ω√ó√ã√™√Ø√ü¬∂¬∑√ø√ñ¬±8≈ì
endstream
endobj
17 0 obj
   3732
endobj
15 0 obj
&lt;&lt;
   /ExtGState &lt;&lt;
      /a0 &lt;&lt; /CA 1 /ca 1 &gt;&gt;
   &gt;&gt;
   /Font &lt;&lt;
      /f-0-0 5 0 R
      /f-8-0 13 0 R
      /f-9-0 18 0 R
      /f-2-0 7 0 R
      /f-1-0 6 0 R
      /f-6-0 11 0 R
      /f-10-0 19 0 R
      /f-7-0 12 0 R
   &gt;&gt;
&gt;&gt;
endobj
20 0 obj
&lt;&lt; /Type /Page
   /Parent 1 0 R
   /MediaBox [ 0 0 611.999983 791.999983 ]
   /Contents 16 0 R
   /Group &lt;&lt;
      /Type /Group
      /S /Transparency
      /CS /DeviceRGB
   &gt;&gt;
   /Resources 15 0 R
&gt;&gt;
endobj
22 0 obj
&lt;&lt; /Length 23 0 R
   /Filter /FlateDecode
&gt;&gt;
stream
x≈ì‚Ä¢Z√â¬Æ+√á
√ù√∑W√®√î¬Æy-d√°√§Y^H-√â‚Ç¨¬∞¬≥√à√Ø‚Ä°‚Ä°d
¬≠√°√π‚Ä†√ØkU√ó√Äb‚Äò‚Ä°‚Ä°¬¨√æ}1‚Ä°\√ù!Y{8√¶j√ú√ø&lt;√º‚Ä∫Z√±√ü¬ø¬æ¬ªÀú√É/√øY¬æ√ø¬≤¬§¬µf_¬∏]¬´Ys¬™¬µ√¶C√ähJ¬µ√∏√É‚Äî√ü‚Äì√ØGs4{√∏√≤X~:k√ú√ô√ï‚Äú√±√ß¬£ÔøΩ√°d√Ç√πhO&amp;≈æ√©OjM&amp;scA#√û‚Ä∫√§√∞¬´w¬¨‚Äπ¬π√∞¬Ø√ã√π√ß/?,¬∂¬Æ¬•TO¬¢|¬πa‚Ä∞√´√ô‚Ä¢‚Äú√ô√é√û≈ì√å√ç√ú√çC√¶¬µ√ÜZ≈í¬≤≈Ω√¶¬∞√û√á√è√ÑÔøΩV{√¶‚Ä¶√ûcyz‚Ä∞vÔøΩ√á≈†‚Äî√±d/&lt;√±√Ü√ú√≠√ïnV√∑bo√∫√Ø√ù:√¥Ywf√°F√à√´√™≈°}≈†M^g¬°1dV¬ª√ë¬£√≥4u4√éZ√Ñ;5‚ÄòX:√èB√ú√ê=¬©&nbsp;X√†/_√¥√à√æ√æ√ó∆íY]¬≠‚Ä°√øR√É√¥√ø¬Ø√ãO?S‚Äú9√úk;√ºN√ß‚Äö≈Ω√∏K¬æ√í√π√°√ò¬∂√ü‚Äì√¢√ñ√™√°hmZ}≈Ω‚Ä°√ü¬≠¬•¬∫5ÔøΩ√¥√ø:√º√£√∞√£√≤y‚Äö√®VcM√†√º√™k¬°	r\¬´‚Ä∫Z√æt:√ò¬∏≈∏"¬ø‚Ä†√øo‚Äô¬∂‚Äùy¬Ω√©7√í√∂]≈íYC√∂‚Äú&amp;2zL√Æ‚Ä∫UA&gt;¬±:?¬´¬¢¬µ|√≥6‚Ä†¬Ω√©‚Ä∫¬•‚Ç¨≈∏X7‚Äπuf√ß≈∏√•√®√æN≈Ω≈æ√â‚Ä¢ÔøΩL¬©ÔøΩ√éD≈°√á√ñ(√≤√™ÔøΩ¬´%¬™¬ß√ó√â√ìo&amp;‚Äô+}!‚Äî¬æ≈∏¬π√∞.ÀÜ6¬´√é√®‚Äπ'{‚Ä†∆í≈†1√≥oF√∏&amp;F‚ÄôcZm2i¬±‚Ñ¢√ù_√º√òd[√ò)1√®rv√©di√™√®√π_√àS7[¬®√ì√ç\√çfÔøΩ¬πZ√É√ûAb‚Äì!√¶√πXJ0‚ÄöK7√®R√ó≈°√®x¬∞i}¬¥&gt;¬Æ&gt;‚ÄìZ√ì!‚Äì¬≤√ñbjI¬∫i7m√∫B¬ª√∑$y‚Ç¨h¬§√ö¬¨ ≈°¬´g√∂nj¬¨'√ïC2y8~4@√™√ÜoRV"√Ø‚Äì√Æ7√öD0√º√ä‚Ä¶K@V_$t√¨&amp;(√Ω¬•y	ÔøΩ√∞&amp;b√´√ãx¬¥√≥√¨‚ÄòV√ä√¥¬∞√æf¬£g‚Ç¨1fÀú0¬´‚Ç¨v1√©√ú&amp;J‚Ç¨&gt;ÀúqF‚Ä¢√ê{3w‚Ä†T‚Ç¨√ù√ê{(√ïÔøΩ≈íH≈∏|¬¥√ù@gr‚Äû¬æ≈í¬Ω`‚Ä†√†√©√∏/u√ë_V¬±&gt;¬±≈°w
;‚Äû√Öx√ö¬¢mLRix√ôp√π$√ö√Ñp≈°/a:&amp;‚Ä∞Iq√®X¬Ω√∂LX¬∞√û‚Ä∞%√ã√â√â$ÔøΩ√É‚Äò√§9ÔøΩ~¬Ω√à]√™√¥‚Äú¬∏i√Å√≥&amp;≈æ‚Äîs‚Äî¬°)R¬æi≈°√¢¬£d√πo√íq‚ÄùL6¬πJ√ü≈°Y√ß√ô¬¨¬π√ìF√ñ≈∏√âlR√´√¢^¬ª√Ä6∆í‚ÄúM¬°‚Ä¶|
f#v¬º√©;+≈°‚Äû¬πrRCL‚Ñ¢√Ü¬≠¬∞Àú
O‚Äöc‚Äú-‚Ä∫√©aXi√Æ¬æ¬æ√Å`s√õ%√¨√Æ¬Ω√µm:Ax√ï≈ì¬∫√•√£u≈í7¬§XU√å‚Äπ√ù‚Äò√¢≈°9¬ª√µUE√Ö7√µ¬¢¬£√è√¥√´:√î√†s√ß ?m√ª‚Äîw¬±1¬º√åJ¬¥√ö√Å√Ä≈ìy√Ü¬≠√ª}4√¨¬´Y&lt;≈Ω1√¢¬æ2+√Ø√äJo+¬≤	¬∞∆í¬≠%+√∂¬§v≈æ@¬∞√ã√π√ã¬Øo¬∞√ã"&amp;
ÀÜ√ë¬¨√ñ¬•1|2√ì=V√ÜJ
¬º01i√≥‚Ñ¢}√Ö¬≥V¬´@‚Ä∫	√û0√ãic¬≤Z√Ø√ë≈†G6¬æ¬∏{√ÄA√ºIfMCRhÔøΩ≈æ√¶U√Å¬®*qzUÔøΩ√≥ÀÜ√°¬¥5O¬±≈íh5oUs%e√ó√∑√äq!S√§√ã&lt;∆í√è¬´√ç√±¬≠v`√∏l]$,l¬ª	√Æ√Ø,YXCp√Ñ√ØG"WÔøΩ√¥
6}¬¢&nbsp;B¬´≈°√É¬Æ√µ'√òCU√åÀú¬´Y‚Ä¶c≈∏a¬¶k‚Ñ¢√ÖRT¬™M¬∫¬∏g

√ú5‚Äπ‚Äö\¬¢.√Ø¬µD≈†'¬™*¬±‚Ä¶¬Øi)
√≠¬¶√ê¬¥o5EÀÜ¬µ√ö√™y‚Äì¬Øi¬™√í≈Ω√®√åx√ç"h≈†S	/√Ä¬∂√Å√îhÔøΩ9%≈í)trz`)ds√Å√†√°k≈í√à¬∞&amp;√≠
)ZÔøΩyhV'√ó‚Äì√ä√†s‚Ñ¢f√¶v≈Ω¬∫
.Uu√™[&lt;√à'6√ä]8‚ÄúQ√ó≈Ω¬¥≈∏¬™‚Äú2yÔøΩ
√®√ûW[d∆í¬ªÔøΩ√∂≈∏√ö¬©72
‚ÄìADq]√êK√£¬Æ√∑ÔøΩÔøΩ¬£¬ºe √£q
Z√≤√ñR!√≠ja√ö≈Ω¬£$¬∂¬µC√∑;[√ó√∞|√àV¬≤≈æ‚Äöa√ñP‚Ä¢}a¬ø√â¬¥5‚Ä∞√ç√∞q¬∫D√îÔøΩ2‚ÄîwÔøΩ√ä[,d√ØB2DJ¬≤D√±‚Äö‚Ä°√Ñ‚Äì¬∑Q√ë√™√∂‚Ç¨¬≤‚Äì¬¥0x¬∞‚Äô"‚ÄûIÔøΩ¬µÔøΩ‚Ñ¢√∑h¬∞√ö4‚Ä∞‚Äô|‚Äò¬ª;√â√â-√§¬∞q√àl√π√Å√ì≈ΩlX¬£+√ôg$Y¬¶√î√ÇrQ√¶√ø! ¬∞)g	√£-I(¬∑¬¥¬¥x‚Ä¢%√ìI#4?;≈†
¬¶√à^H-√º√Ç1.√¥‚Äù]ÀÜ√∂G√ú√üuÔøΩ6Gd‚Äö√∂√¢√∂6√Ö5^¬´≈†u)¬µd√Ø¬§}√∏√§¬≤√ç/ÀÜ=‚Ä¢S_≈Ω√Ä@%¬´‚Ç¨‚Ä¶‚Äò0Lb∆íl¬∂¬¢¬±√é1Z&lt; ¬¶≈Ω&nbsp;√º√åH√Ånz√ï‚Ä∞‚ÄìÀú√§zV≈†L√≥√≥)&gt;R&amp;D¬¶‚Ä†√∏Àú‚Ä∫√í√ïWxs¬§¬Ω√∑√±‚Äò%‚Äö2≈æh~¬™c√º¬§Z√∑‚Ç¨D√´√â√∫√Ö√µ≈æ≈í?√é√©c¬ß√íÔøΩ‚Äû√±?√°‚Äö¬∞'RÀÜU4√ß}‚Ä°≈Ω@4$¬∂pj√ã≈íg√≥‚Äî√ê√àY+¬Æ≈æ‚Äö√≠hi¬°P
√ê‚Äò=*√µ‚Äûd¬æ+√ë≈∏¬§‚Äö,¬¢i¬´t+J≈°@B~ÀÜ¬æ‚ÄùS8¬Ø√ï%¬°√Ü√ª≈†√ø@L\%√ã¬≥E√ÜS ¬∑√π¬≠√¢‚Ä∫jPÀÜ¬•√õ√è‚Äù
a‚ÄîÔøΩ¬≤`√á.¬§kQ√è√Å √ñf[√å¬∑
~E√ª‚Äù¬©√áÀúrxAi√Ö√•]¬≤5	¬•n≈°/+√≠3√¶6√ä¬£x:;√ç~0√ô‚Ä∞‚Ä°∆íif√£¬Ω√û¬∞¬∫√ú¬≠n1√ö¬°√á
¬©ÔøΩd√©)√ìH$w¬ø¬≥√¶√¢ÔøΩ‚Äù√Ö&lt;(k¬ß9√°Y-w√¢‚ÄòvÔøΩd‚Äì√∂=C¬Ø\&gt;sed√Öq√â√†√ö5 ¬¶√Ø5√åzÔøΩn√®|√ì√à√ñ%‚Äú7d≈ìd¬¥[W+
¬ª√âÀÜ¬æ‚Äπ‚ÄìJ*¬∑√¨9√ß‚Ä¢‚Äö."√©√ô]√π√Çd√•√î]ÀÜ√ß¬°√≥C1I¬¨D√û‚Ñ¢h¬®√èU¬§BK¬∫¬´√¶5t¬∑√≥√≠*√®√©9√Å¬≠-√Å√ù√¶L√¨¬π$P√î¬®-‚Äì¬±r
Q√îj√∑tÔøΩy#C√â≈°√ü√ç
B√çx√Ç√´2√•‚Ä¶h]√µb√ÇÀú¬±¬ø¬ºKdm√í\¬∫√äZ√ª√à	)∆í {¬∂9A‚Äì√≠√æ)_¬∫67√í&nbsp;NB¬£‚Ä†z¬∂:k‚Äú¬±√ê√µ≈°ÔøΩm‚Ç¨C√≥;¬¢¬´√éT
√òÔøΩ)!¬¨r¬©≈†¬±√ëC√∫√≥&nbsp;ÀÜ≈æ‚Ä∫√™‚Ä¢#p≈∏√òk√áFT√Ø√î√Ö‚Äπ‚Äì-ÀÜ√≥ OB%:‚Ä∞
LdrN¬™√Ø√ñY√§9√¢¬≥¬∞√û¬•H6√Ñ√í√∫‚Äô_T&nbsp;8¬ß¬§√ë
yu
¬ªup&nbsp;s+ÔøΩ¬§ÔøΩ¬≥tX¬≠Y√¨XF¬±‚Äúr√Ø√ï¬¶‚Ç¨¬ª≈ì√ì%√ëi√≠945‚Äù¬ª1‚ÄôUfkJ√Ω;E√®√ì¬µ√†≈†√≤Pj‚Ä∞√≠lG≈ìe√â√Ñ√™√Ω√ígiu(¬•≈°¬Ø%'¬≤@√é7:‚Ä†xOXq√©√å‚Ä¶√çM(t√ô√≥_8¬¢7ÔøΩ√≤¬¢¬∫‚Ä∫≈Ω!.D√øo3√ãÀÜ-_√Ø¬¶Q‚Äî_¬≥R√åF'¬¶,¬∫6z¬§^g)√çD1¬ª‚Ä∫√¥S√∏[)ÔøΩcs¬®h)&lt;\√úo.2√≠√ãq?[¬º¬ªqI,¬≤v;√¢w¬≠.4√äe≈ì.ÔøΩ=y&nbsp;√ÖÀÜ√®√≠√Ω√Ä&nbsp;¬æPo√ÇY‚Äú¬∑ÔøΩXLpÔøΩ&lt;‚ÄûÔøΩ,√™√•√õ8g√ã¬Ø√ó@[^¬¨P\{x√Ç√ê¬©¬∑√å√ßx√âbH
Kh√ØUD¬Ω√å@¬¥√ãf/√Äd√°^√çx"&amp;¬¥√Ñ‚Äìv‚Ä¶√ü√ç≈í√ûy√†√í:Ij√á√Ä≈í!(√éV≈ΩÔøΩ√Ö¬¶[W√ò‚Äô+^¬∏√∫‚Ä∫√®`n‚Äπ√îÔøΩ&amp;√∏√ßi':‚Äúw9¬¶L&lt;¬∂[Qu‚Ñ¢W√†3‚Ä∞√ª  ;√¨(√ø√ô√∞√ò√¨n\√©¬±jN√∑s‚ÄúN√ã√ç√ñÔøΩ2√•≈†\q√µ¬¶L¬•¬º)≈∏‚Ä¢4√É√§)≈í√∞¬Ø‚Ä†~4≈ΩrR?ÔøΩw√ç}f √ô‚Ä¶≈†√Ö}√å&gt;¬±YK9√•!u
√Ñ kxW≈ì√ªPU¬°√åkMDÔøΩ1&lt;¬Æ‚Ä¶¬¢N&gt;√ß‚ÄìS"S√∂F√â
√µ√ârdÔøΩ¬º/T√õ‚Äôh√ès√±√æ√Ç√Æ-5¬∑[(√ö¬æ√ñd8OF¬≠¬©¬•f^√≤‚Ä†√õ√ªB3√™w‚Ä¶z}(2√£¬µÀÜ√å√á¬≥¬´√ªq√ç√ô0√≤]8√î‚Ä¢¬ßrÔøΩo√à¬∫√∂l≈†	¬§¬´=]‚Ñ¢~T≈Ω√ΩIXM√™√πjHm¬æ[:DTn8√ú%‚Äö√ñ√≠'ri√•/√¨&gt;s‚Äû√´≈ì‚Äò)H√¶‚Äö√û√ÅMÔøΩS9‚Äî√ú		¬Ø‚ÄπT`{M√å¬ª0Àú√≤≈æ√â√Å%¬ªÀú(¬ø¬µ√±^Ab√ë5&amp;√∂7_‚Ä∫≈í[‚Äû)∆í√≤√üu-‚Ñ¢p:ÔøΩ¬π‚Äì¬ø√¥√öu√ßR(¬≠√õ≈í¬¶gd‚Ä¢√∞√πKi-ÔøΩ√ïz4‚Äò≈æ√ªsP√Ü√≠(√ß‚ÄùO‚Ä¶√ño‚Äò≈Ω√æ√§√î√Ñ‚Äπf2≈æb`Q√µ√æ¬©¬§√ü√î¬µ√ßuq√éy√©√ØOAw√∑{¬±L√ë‚Ä¢mN√§√¥√∏)‚Ä¶</h[√æg*√†-√º√±9√≤yq3√¥?n2¬Æ&≈æÔøΩm≈°¬Æ¬∏‚Ä°93√ó√±¬´√¨vvu#;.¬∏∆í≈°√∞j‚Ä¶:√∫!‚Ä∞b¬π&ÔøΩy√ª\√ßj¬∑ÔøΩ√∏√Ø¬∏j√ü¬≤‚Äù√£3y‚Äìw-‚Ä°‚Äû√£¬π√†fg¬π√π¬•qb√´√£></k‚Äúi√∞"{¬¨‚Ç¨¬π√©f¬∫‚Ä¶√©‚Ä°√®5√≤></sw√Ø.></l}k&r></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://people.idsia.ch/~juergen/fastestuniverse.pdf">http://people.idsia.ch/~juergen/fastestuniverse.pdf</a></em></p>]]>
            </description>
            <link>http://people.idsia.ch/~juergen/fastestuniverse.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065400</guid>
            <pubDate>Thu, 12 Nov 2020 01:37:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux Kernel Bug Fixing Mentorship]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065177">thread link</a>) | @simonpure
<br/>
November 11, 2020 | https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship | <a href="https://web.archive.org/web/*/https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="634481719919165440">
                    
                        
                            <h3><a href="https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship">Linux Kernel Bug Fixing Mentorship</a></h3>
                        <p>I recently finished a three months long <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmentorship.lfx.linuxfoundation.org%2F&amp;t=Y2U1OTljMjEzMDMxYmM5MzQxMDI2NmRlZmNlNjcxZTIxOGM1YjFiMyxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605298774" target="_blank">CommunityBridge(now knows as LFX)</a> mentorship with <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.linuxfoundation.org%2F&amp;t=NmI2YWFjMWNkZTQ1YTZiZTg1YTlmNTIzMGNiOTkxZTA0YTA2NGI5YSxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605298774" target="_blank">The Linux Foundation</a>. I worked as a <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmentorship.lfx.linuxfoundation.org%2Fproject%2Ff06db0d5-537e-4e0f-8ca4-0a471f95a04d&amp;t=YzhhYWIzMjA5ZGUxZmRhNTgyOGZlYTUyMDZiMzkyNGYyODJkODkzNyxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605298774" target="_blank">Linux kernel bug fixing</a> mentee under <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fwww.kroah.com%2Flog%2Fabout.html&amp;t=NGRkNGYxNWM2NTk2Y2EwMDRkM2MwMWM0MjFiOGE4NTk2YTZlN2ZjNCxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605298774" target="_blank">Greg Kroah-Hartman</a>. This post is about my experience and work during the mentorship program.</p><p>In
the first week of the mentorship program, I learned about debugging
techniques for the Linux kernel, how to use decode_stacktrace.sh, and
what is CONFIG_KASAN. These were all unfamiliar concepts for me, and
I found the mentors‚Äô learning resources very useful. My first task
was to write summaries of my understanding of these concepts. I found
these summaries quite helpful while fixing real bugs in the kernel
later in the mentorship.</p><p>I
was also unfamiliar with syzkaller and syzbot before becoming part of
the mentorship. So after completing the summary tasks, I spent the
next few days getting familiar with these tools. The syzbot dashboard
has hundreds of reported bugs, and I found it a little challenging to
decide which one I should pick first.</p><p>In
the meantime, my mentor, Greg KH, redirected me towards an ongoing
discussion regarding a bug produced due to a short read in
usb_control_msg() call. There existed a few ways to fix it, and after
discussing them with the mentor, I proposed a fix. The patch
generated a fair amount of discussion, and I also received comments
that the proposed fix wasn‚Äôt the right way to handle the bug. The
discussion also concluded that many other usages of
usb_control_msg(), which don‚Äôt have proper error checks, are also
prone to similar bugs. I fixed the bug by adding an adequate error
check to prevent short reads in the caller, and Greg KH wrote new
wrapper functions for usb_control_msg() to be used in such scenarios
to avoid similar bugs.</p><p>Apart
from this bug, I also explored two other bugs. I found them
fascinating because inspite of being listed on the dashboard, their
reproducers weren‚Äôt triggering any issues. I learned that a commit
had fixed one of these bugs, and it was yet to be applied to all
kernel trees. But the other bug didn‚Äôt have any reported fix, yet the
reproducer wasn‚Äôt triggering the issue. I discussed this with the
mentor and learned that the syzbot dashboard isn‚Äôt quite dynamic. So
we decided to mark the bug as ‚Äúinvalid.‚Äù On a later
discussion with other community members I learned that it was not a
good idea, and I‚Äôve ended up marking a potentially valid bug as
‚Äúinvalid‚Äù!</p><p>As
a follow-up work on the first usb_control_msg() bug, I submitted a
cleanup patch series for some of the drivers/net/usb files. One of
those patches ignored the GFP_NOIO flag used in the original code and
replaced it with the GFP_KERNEL flag used in the new wrapper API
functions. It was a blunder that resulted in a discussion to add a
new argument for memory allocation flags in the wrapper functions.
Now the wrapper functions take memory flags as arguments preventing
mentees like me from repeating such blunders.</p><p>I
continued the follow-up work by investigating drivers/usb/serial/
files. I noticed that many usages of usb_control_msg() rely on its
return value of the number of bytes read/wrote. And the new wrapper
functions don‚Äôt retain that information. So I had a discussion with
the mentor about if that information was really necessary. We
concluded that it is almost always unnecessary, and having an error
code returned is a better way.</p><p>I
ended up submitting 19 patches as part of the mentorship program. The
first one is a fix for the usb_control_msg() short read bug. The next
three are cleanup patches for usb_control_msg() wrapper functions for
drivers/net/usb files, which were rejected because of the memory flag
blunder. And the remaining 15 are usb_control_msg() cleanup patches
for drivers/usb/serial/ files. Greg KH has reviewed them, but they
are not yet merged in the mainline.</p><p>Apart
from the bug fixing, I also learned few other interesting things
about the Linux kernel and its developer community, like how we test
various changes in the kernel and why we strictly use plain text
emails. I also attended talks at the Linux Plumber‚Äôs Conference and
the Open Source Summit Europe during the mentorship, which helped me
catch up with what is happening in the kernel world, learn new
things, and make new connections.</p><p>
My
mentorship program experience has been fantastic, and I recommend it
to everyone interested in pursuing Linux kernel development and
looking for mentoring. I am heartily thankful to my mentor Greg KH,
Shuah Khan, and The Linux Foundation, for providing me with this
opportunity and a great learning experience. 
</p><p>Patches can be found on&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Flore.kernel.org%2Flkml%2F%3Fq%3Dhimadrispandya&amp;t=MGEzOGVkMTE2ODI0MThhMjgwMDRhZDVjNzdkOTBjOWYxYjAyMzJkZixxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605298774" target="_blank"> https://lore.kernel.org/lkml/?q=himadrispandya.<br></a></p>
                    </article></div>]]>
            </description>
            <link>https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065177</guid>
            <pubDate>Thu, 12 Nov 2020 01:13:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Illustrated Children's Guide to Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065144">thread link</a>) | @tomasreimers
<br/>
November 11, 2020 | https://www.cncf.io/phippy/ | <a href="https://web.archive.org/web/*/https://www.cncf.io/phippy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<article>
		
<div><figure><img loading="lazy" width="472" height="487" src="https://www.cncf.io/wp-content/uploads/2020/07/phippy-01-1.svg" alt=""></figure><p><strong>Phippy</strong>&nbsp;is a simple PHP app, trying to find a home in a cloud native world.</p></div>







<div><div>




<h2>Introducing Phippy and friends</h2>












</div></div>







<div>
<div>
<figure><img loading="lazy" width="849" height="651" src="https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes.jpg 849w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-300x230.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-768x589.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-261x200.jpg 261w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-700x537.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-222x170.jpg 222w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-352x270.jpg 352w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-443x340.jpg 443w" sizes="(max-width: 849px) 100vw, 849px"></figure>




</div>



<div>
<h3>The Illustrated Children‚Äôs Guide to Kubernetes</h3>



<p><em>The Illustrated Children‚Äôs Guide to Kubernetes</em> is a simple, gentle answer a father gave his daughter when she inquisitively asked about Kubernetes. It‚Äôs dedicated to all the parents who try to explain software engineering to their children.</p>



<p>The star of <em>The Illustrated Children‚Äôs Guide to Kubernetes</em>, Phippy and her friends explain the core concepts of Kubernetes in simple terms.</p>




</div>
</div>







<div>
<div>
<h3>Phippy Goes to the Zoo</h3>



<p>Follow the tale of Phippy and her niece Zee as they take an educational trip to the Kubernetes Zoo.</p>








</div>



<div>
<figure><img loading="lazy" width="851" height="655" src="https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo.jpg 851w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-300x231.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-768x591.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-260x200.jpg 260w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-700x539.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-221x170.jpg 221w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-351x270.jpg 351w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-442x340.jpg 442w" sizes="(max-width: 851px) 100vw, 851px"></figure>
</div>
</div>







<div>
<div>
<h3>Phippy and Zee go to the Mountains</h3>



<p>Another work featuring Phippy and friends: Join Phippy and Zee on a 4-dimensional hike!</p>




</div>



<div>
<figure><img loading="lazy" width="1024" height="768" src="https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-1024x768.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-1024x768.jpg 1024w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-300x225.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-768x576.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-267x200.jpg 267w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-700x525.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-227x170.jpg 227w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-360x270.jpg 360w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-453x340.jpg 453w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8.jpg 1367w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
</div>
</div>







<div>
<div>
<h3>Phippy In Space: Adventures in Cloud-Native Recovery</h3>



<p>In the not-so-distant future, space outposts (cloud-native infrastructure) are the next frontier for settlement and Captain Kube is in charge of the cutting-edge Mars outpost. As the outpost has grown in size and complexity, Captain Kube needs to find solutions for many of the settlement‚Äôs growing pains. He has recruited Phippy to work with him on the outpost‚Äôs Day 2 challenges.</p>



<p>Join them on their adventure, as they journey to Mars and brainstorm solutions.</p>




</div>



<div>
<figure><img loading="lazy" width="1024" height="792" src="https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-1024x792.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-1024x792.jpg 1024w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-300x232.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-768x594.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-1536x1187.jpg 1536w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-259x200.jpg 259w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-700x541.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-220x170.jpg 220w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-349x270.jpg 349w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-440x340.jpg 440w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space.jpg 1568w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
</div>
</div>















<p>The characters Phippy, Captain Kube, Goldie, and Zee and the two books are owned by The Linux Foundation, on behalf of the Cloud Native Computing Foundation, and licensed under the Creative Commons Attribution License (<a href="https://creativecommons.org/licenses/by/4.0/">CC-BY</a>), which means that you can remix, transform, and build upon the material for any purpose, even commercially. If you use the characters, please include the text ‚Äú<a href="https://phippy.io/">phippy.io</a>‚Äù to provide attribution (and online, please include a link to&nbsp;<a href="https://phippy.io/">https://phippy.io</a>).</p>



<p>The characters and the two books were created by&nbsp;<a href="https://twitter.com/technosophos">Matt Butcher</a>,&nbsp;<a href="https://twitter.com/karenhchu">Karen Chu</a>, and&nbsp;<a href="https://www.baileyjeanstudio.com/">Bailey Beougher</a>&nbsp;and donated by Microsoft to CNCF. Goldie is based on the Go Gopher, created by&nbsp;<a href="https://blog.golang.org/gopher">Renee French</a>, which is also licensed under&nbsp;<a href="https://creativecommons.org/licenses/by/3.0/" target="_blank" rel="noreferrer noopener">CC-BY</a>.</p>



<p>Images of Phippy, Captain Kube, Goldie, and Zee are available in the CNCF&nbsp;<a href="https://github.com/cncf/artwork/blob/master/examples/other.md#phippy--friends-group-logos">artwork</a>&nbsp;repo in svg and png formats and in color, black, and white.</p>
	</article>
</div></div>]]>
            </description>
            <link>https://www.cncf.io/phippy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065144</guid>
            <pubDate>Thu, 12 Nov 2020 01:10:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Version 11 of Angular Now Available]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25065091">thread link</a>) | @mgechev
<br/>
November 11, 2020 | https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7 | <a href="https://web.archive.org/web/*/https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://medium.com/@markathompson?source=post_page-----74721b7952f7--------------------------------" rel="noopener"><img alt="Mark Techson" src="https://miro.medium.com/fit/c/96/96/1*2hqK0rVXWghtk_RLFx33oA.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Photo of a Torch Ginger by Jules Kremer" src="https://miro.medium.com/max/2368/0*55kr1t601sp22pkE" width="1184" height="1091" srcset="https://miro.medium.com/max/552/0*55kr1t601sp22pkE 276w, https://miro.medium.com/max/1104/0*55kr1t601sp22pkE 552w, https://miro.medium.com/max/1280/0*55kr1t601sp22pkE 640w, https://miro.medium.com/max/1400/0*55kr1t601sp22pkE 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*55kr1t601sp22pkE?q=20"></p></div></div></div><figcaption>Photo of a Torch Ginger by Jules Kremer</figcaption></figure><p id="1feb"><strong>Welcome to the Angular version 11 release.</strong></p><p id="1877">Version 11.0.0 is here and we‚Äôve got some great updates for Angular developers everywhere. This release has updates across the platform including the framework, the CLI and components. Let‚Äôs dive in!</p><h2 id="1182">Updates on Operation Byelog</h2><p id="593b">When we shared <a href="https://angular.io/guide/roadmap" rel="noopener">Angular‚Äôs Roadmap</a>, one of the items was Operation Byelog where we committed to putting a significant engineering effort towards triaging issues and PRs until we have a clear understanding of the broader community needs. We can now report that the original goal is complete! We‚Äôve triaged all the issues in all three of the monorepos and will continue this as an ongoing effort as new issues get reported.</p><p id="bc06">This is our commitment: Going forward all new issues reported will be triaged within 2 weeks.</p><p id="2104">In the process, we resolved a few <a href="https://github.com/angular/angular/issues/12842" rel="noopener">popular</a> <a href="https://github.com/angular/angular/issues/18469" rel="noopener">issues</a> in the <a href="https://github.com/angular/angular/issues/13011" rel="noopener">router</a> and <a href="https://github.com/angular/angular/issues/14542" rel="noopener">forms</a>.</p><p id="a1cd">Also, we‚Äôve closed the <a href="https://github.com/angular/angular/issues/11405" rel="noopener"><em>third most popular issue</em></a><em>!</em></p><p id="5773">Now, we‚Äôre planning the next steps to support the Angular community. We‚Äôll continue triaging and fixing issues, and work towards improving our processes for accepting community contributions.</p><h2 id="4683">Automatic Inlining of Fonts</h2><p id="6a67">To make your apps even faster by speeding up their <a href="https://web.dev/first-contentful-paint/" rel="noopener">first contentful paint</a>, we‚Äôre introducing automatic font inlining. During compile time Angular CLI will download and inline fonts that are being used and linked in the application. We enable this by default in apps built with version 11. All you need to do to take advantage of this optimization is update your app!</p><h2 id="124e">Component Test Harnesses</h2><p id="78d2">In Angular v9 we introduced Component Test Harnesses. They provide a robust and legible API surface to help with testing Angular Material components. It gives developers a way to interact with Angular Material components using the supported API during testing.</p><p id="2932">Releasing with version 11, we have harnesses for all of the components! Now developers can create more robust test suites.</p><p id="3e07">We‚Äôve also included performance improvements and new APIs. The <em>parallel</em> function makes working with asynchronous actions in your tests easier by allowing developers to run multiple asynchronous interactions with components in parallel. The <em>manualChangeDetection</em> function gives developers access to finer grained control of change detection by disabling automatic change detection in unit tests.</p><p id="752c">For more details and examples of these APIs and other new features, be sure to check out the <a href="http://material.angular.io/cdk/test-harnesses/overview" rel="noopener">documentation for Angular Material</a> Test Harnesses!</p><h2 id="173a">Improved Reporting and Logging</h2><p id="968c">We‚Äôve made changes to the builder phase reporting to make it even more helpful during development. We are bringing in new CLI output updates to make logs and reports easier to read.</p><figure><div><div><p><img alt="Screenshot of angular CLI output nicely formatted into columns." src="https://miro.medium.com/max/1214/0*-dCa80651cnfbjpX" width="607" height="355" srcset="https://miro.medium.com/max/552/0*-dCa80651cnfbjpX 276w, https://miro.medium.com/max/1104/0*-dCa80651cnfbjpX 552w, https://miro.medium.com/max/1214/0*-dCa80651cnfbjpX 607w" sizes="607px" data-old-src="https://miro.medium.com/max/60/0*-dCa80651cnfbjpX?q=20"></p></div></div><figcaption>Improved CLI output formatting</figcaption></figure><h2 id="970e">Updated Language Service Preview</h2><p id="650a">The Angular Language Service provides helpful tools to make development with Angular productive and fun. The current version of the language service is based on View Engine and today we‚Äôre giving a sneak peek of the Ivy-based language service. The updated language service provides a more powerful and accurate experience for developers.</p><p id="15e6">Now, the language service will be able to correctly infer generic types in templates the same way the TypeScript compiler does. For example, in the screenshot below we‚Äôre able to infer that the iterable is of type string.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Screenshot of intellisense style insights in Angular templates." src="https://miro.medium.com/max/3000/0*L1Tg13gdu3PCqUNN" width="1500" height="902" srcset="https://miro.medium.com/max/552/0*L1Tg13gdu3PCqUNN 276w, https://miro.medium.com/max/1104/0*L1Tg13gdu3PCqUNN 552w, https://miro.medium.com/max/1280/0*L1Tg13gdu3PCqUNN 640w, https://miro.medium.com/max/1400/0*L1Tg13gdu3PCqUNN 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*L1Tg13gdu3PCqUNN?q=20"></p></div></div></div><figcaption>Angular Language Service inferring iterable types in templates</figcaption></figure><p id="e67f">This powerful new update is still in development but we wanted to share an update as we keep preparing it for a full release in an upcoming version.</p><h2 id="48a5">Updated Hot Module Replacement (HMR) Support</h2><p id="303f">Angular has offered support for HMR but enabling it required configuration and code changes making it less than ideal to quickly include in Angular projects. In version 11 we‚Äôve updated the CLI to allow enabling HMR when starting an application with ng serve. To get started, run the following command:</p><pre><span id="3ac4">ng serve --hmr</span></pre><p id="f3bc">After the local server starts the console will display a message confirming that HMR is active:</p><p id="f521">NOTICE: Hot Module Replacement (HMR) is enabled for the dev server.</p><p id="5155">See <a href="https://webpack.js.org/guides/hot-module-replacement" rel="noopener">https://webpack.js.org/guides/hot-module-replacement</a> for information on working with HMR for webpack.</p><p id="3796">Now during development the latest changes to components, templates and styles will be instantly updated into the running application. All without requiring a full page refresh. Data typed into forms are preserved as well as scroll position providing a boost to developer productivity.</p><h2 id="6de3">Faster Builds</h2><p id="630c">We‚Äôre bringing a faster development and build cycle by making updates to some key areas.</p><ul><li id="4336">When installing dependencies, the ngcc update process is now 2‚Äì4x faster.</li><li id="b30d">Faster compilation with TypeScript v4.0.</li></ul><p id="ed18">Now, teams can opt-in to webpack v5. Currently, you could experiment with <a href="https://webpack.js.org/concepts/module-federation/" rel="noopener">module federation</a>. In the future, webpack v5 will clear the path for:</p><ul><li id="db89">Faster builds with persistent disk caching</li><li id="7ab4">Smaller bundles thanks to <a href="https://webpack.js.org/guides/tree-shaking/" rel="noopener">cjs tree-shaking</a></li></ul><p id="dae8">Support is experimental and under development so we don‚Äôt recommend opting in for production uses.</p><p id="4ca8">Want to try out webpack 5? To enable it in your project, add the following section to your package.json file:</p><pre><span id="386c">"resolutions": {<br>     "webpack": "5.4.0"<br>}</span></pre><p id="65a0">Currently, you‚Äôll need to use <strong>yarn</strong> to test this as npm does not yet support the resolutions property.</p><h2 id="d0a9">Linting</h2><p id="e4b2">In previous versions of Angular, we‚Äôve shipped a default implementation for linting (TSLint). Now, TSLint is deprecated by the project creators who recommend migration to ESLint. <a href="https://twitter.com/mrjameshenry" rel="noopener">James Henry</a> together with other folks from the open-source community developed a third-party solution and migration path via <a href="https://github.com/typescript-eslint/typescript-eslint" rel="noopener">typescript-eslint</a>, <a href="https://github.com/angular-eslint/angular-eslint" rel="noopener">angular-eslint</a> and <a href="https://github.com/typescript-eslint/tslint-to-eslint-config" rel="noopener">tslint-to-eslint-config</a>! We‚Äôve been collaborating closely to ensure a smooth transition of Angular developers to the supported linting stack.</p><p id="6071">We‚Äôre deprecating the use of TSLint and Codelyzer in version 11. This means that in future versions the default implementation for linting Angular projects will not be available.</p><p id="806d">Head over to the <a href="https://github.com/angular-eslint/angular-eslint#migrating-from-codelyzer-and-tslint" rel="noopener">official project page</a> for a guide to incorporate angular-eslint in a project and migrate from TSLint.</p><h2 id="98a6">Housekeeping</h2><p id="0727">In this update we‚Äôre removing support for IE9/IE10 and IE mobile. IE11 is the only version of IE <a href="https://angular.io/guide/browser-support" rel="noopener">still supported</a> by Angular. We‚Äôve also <a href="https://angular.io/guide/deprecations" rel="noopener">removed deprecated APIs</a> and added a few to the deprecation list. Be sure to check this out to make sure you are using the latest APIs and following our recommended best practices.</p><h2 id="a3c7">Roadmap</h2><p id="9aad">We‚Äôve also updated the <a href="https://angular.io/guide/roadmap" rel="noopener">roadmap</a> to keep you posted on our current priorities. Some of the announcements in this post are updates on in-progress projects from the roadmap. This reflects our approach to incrementally rollout larger efforts and allows developers to provide early feedback that we can incorporate it into the final release.</p><p id="8c07">We collaborated with <a href="https://twitter.com/simpulton" rel="noopener">Lukas Ruebbelke</a> from the Angular community on updating the content of some of the projects to better reflect the value they provide to developers.</p><h2 id="6939">How to update to get version 11</h2><p id="0170">When you are ready to go run this command to update Angular and CLI:</p><pre><span id="5983">ng update @angular/cli @angular/core</span></pre><p id="ac5f">Head over to <a href="https://update.angular.io/" rel="noopener">update.angular.io</a> to find detailed information and guidance on updating. We always recommend upgrading one major release at a time to have the best update experience.</p><p id="732f">We hope you enjoy this feature update and be sure to let us know what you think here or on <a href="https://twitter.com/angular" rel="noopener">Twitter</a>!</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065091</guid>
            <pubDate>Thu, 12 Nov 2020 01:06:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ransomware Prohibition]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065057">thread link</a>) | @SCHiM
<br/>
November 11, 2020 | https://gru.gq/2020/10/18/ransomware-prohibition/ | <a href="https://web.archive.org/web/*/https://gru.gq/2020/10/18/ransomware-prohibition/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><main><article itemscope="" itemtype="https://schema.org/CreativeWork"><div itemprop="text"><h2>Theres nothing that can‚Äôt be made worse</h2>
<p><a href="https://home.treasury.gov/policy-issues/financial-sanctions/recent-actions/20201001">The Treasury has moved to prohibit payment of ransomware ransoms</a>. They‚Äôve said there will be some exceptions, and it is obvious that this won‚Äôt be an effective complete global ban on payment. The result, a partial ban on payment, is the worst possible ransomware environment for victims. The impact of different legal regimes governing ransom payments are well documented and understood, <a href="https://rusi.org/publication/occasional-papers/closing-gap-assessing-responses-terrorist-related-kidnap-ransom">see RUSI here</a>.</p>
<p>Banning ransomware payments seems like a means of removing the financial reward for the gangs. It makes intuitive sense that if the victims cannot pay, then the gangs will stop using ransomware. Unfortunately the counterintuitive truth is that an incomplete, ineffective, partial ban will actually make objectively ransomware worse for everyone.</p>
<p>If there is a complete universal global ban, then ransomware ceases to be a source of money and the ransomware gangs stop. Or at least migrate to something else that makes money. We know this scenario is not going to happen.</p>
<h3>What‚Äôs the worst that can happen?</h3>
<p>A partial ban creates significant unintended consequences. Firstly, the ransomware gangs still make money from ransomware, so they do <strong>not</strong> cease operations. Then, to encourage payment they become more drastic and extreme in their actions. They have to make a stronger incentive to encourage people who are dissuaded by the ban, but might pay if given sufficient ‚Äúencouragement‚Äù. Then, because the prohibition on payment drives it underground ‚Äì with all the limited transparency and brutal mechanisms for enforcing compliance ‚Äî the ransom prices rise. This environment: higher prices, more aggressive ransomware gangs, fewer reputable companies negotiating and handling the ransom payments (and thereby managing the gangs); it is the worst possible situation for everyone.</p>
<h3>How to control attacker behaviour</h3>
<p>The only entity with power to control the behaviour of ransomware gangs is the one providing their protection. The gangs need a place to operate and somewhere to convert their crypto currency into hard currency. They are cashing out hundreds of thousands of dollars in crypto, and there is no way that isn‚Äôt raising ‚Äúknow your customer‚Äù alerts for money laundering.</p>
<p>The only controlling entity is the one that allows the gangs to operate. The gangs are completely at the mercy of whichever entity provides protection (yes, it‚Äôs Russia). This is the rule everywhere that kidnapping gangs operate, and ransomware gangs share this trait with kidnap&amp;ransom (K&amp;R) gangs with regards to their operational requirements.</p>
<h3>Private governance. Better than nothing? Hmm</h3>
<p>The current situation, where there is no criminalisation of payment has created a market place where a number of companies working with insurers are handling the vast majority of ransomware incidents. There are crisis responders who help the companies recover, who arrange a minimal payment, and who get paid by the insurers. This is market governance and it keeps the prices down because there is a sort of gentlemen‚Äôs agreement between the gangs and the payment companies. Also, the lack of prohibition means these companies operate in the open and they can share information about pricing etc internally and with each other. (Transparency)</p>
<p>The status quo is not the ideal world, but it is far better than the nightmare of ineffective partial prohibition.</p>
<div><p>Liked it? Take a second to support grugq on Patreon!</p><p><a rel="nofollow" target="_blank" href="https://www.patreon.com/oauth2/become-patron?response_type=code&amp;min_cents=100&amp;client_id=XPz53m5BPTmu-cnihK1RXoEaRoNywCco8VIPCNbwnAexV5YWdi_YG5Asup2LeG9p&amp;scope=identity%20identity[email]&amp;redirect_uri=https://gru.gq/patreon-authorization/&amp;state=eyJmaW5hbF9yZWRpcmVjdF91cmkiOiJodHRwczpcL1wvZ3J1LmdxXC8yMDIwXC8xMFwvMThcL3JhbnNvbXdhcmUtcHJvaGliaXRpb25cLyJ9&amp;utm_source=https%3A%2F%2Fgru.gq%2F2020%2F10%2F18%2Fransomware-prohibition%2F&amp;utm_medium=patreon_wordpress_plugin&amp;utm_campaign=457796&amp;utm_term=&amp;utm_content=post_unlock_button"><img src="https://i2.wp.com/gru.gq/wp-content/plugins/patron-button-and-widgets-by-codebard/images/become_a_patron_button.png?ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/gru.gq/wp-content/plugins/patron-button-and-widgets-by-codebard/images/become_a_patron_button.png?ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p></div>
<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://gru.gq/2020/10/18/ransomware-prohibition/"
    dc:identifier="https://gru.gq/2020/10/18/ransomware-prohibition/"
    dc:title="Ransomware Prohibition"
    trackback:ping="https://gru.gq/2020/10/18/ransomware-prohibition/trackback/" />
</rdf:RDF>-->
</div></article>
		

		
		

		</main></div></div></div></div>]]>
            </description>
            <link>https://gru.gq/2020/10/18/ransomware-prohibition/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065057</guid>
            <pubDate>Thu, 12 Nov 2020 01:01:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MacBook Air in Pure CSS]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25064721">thread link</a>) | @ent101
<br/>
November 11, 2020 | https://www.outpan.com/app/e47219f7aa/macbook-air-in-pure-css | <a href="https://web.archive.org/web/*/https://www.outpan.com/app/e47219f7aa/macbook-air-in-pure-css">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><nav role="navigation"><div><div><form action="/search" method="get"></form><p><img src="https://opimg.s3.amazonaws.com/e47219f7aa-200x200.jpg" id="app-toolbar-icon"></p><div id="app-options-wrapper"><div><div><p data-toggle="modal" data-target="#review-modal" id="reviews-modal-link" title="View reviews or write one"><span></span> <span>7</span></p></div></div></div></div><div id="navbar-user-items" aria-expanded="false"><p><a href="https://www.outpan.com/signup">Sign Up</a></p><ul><li></li></ul><ul><li><a href="https://www.outpan.com/">Home</a></li><li><a href="https://www.outpan.com/login?ref=https://www.outpan.com/app/e47219f7aa/macbook-air-in-pure-css">Login</a></li><li><a href="https://www.outpan.com/signup">Sign Up</a></li></ul><form action="/search" method="get"></form></div></div></nav><div><div><div><div></div></div></div></div></div>]]>
            </description>
            <link>https://www.outpan.com/app/e47219f7aa/macbook-air-in-pure-css</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064721</guid>
            <pubDate>Thu, 12 Nov 2020 00:24:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Booting a macOS Apple Silicon Kernel in QEMU]]>
            </title>
            <description>
<![CDATA[
Score 201 | Comments 52 (<a href="https://news.ycombinator.com/item?id=25064593">thread link</a>) | @empyrical
<br/>
November 11, 2020 | https://worthdoingbadly.com/xnuqemu3/ | <a href="https://web.archive.org/web/*/https://worthdoingbadly.com/xnuqemu3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>I booted the arm64e kernel of macOS 11.0.1 beta 1 kernel in QEMU up to launchd. It‚Äôs completely useless, but may be interesting if you‚Äôre wondering how an Apple Silicon Mac will boot.</p>

<h2 id="howto">Howto</h2>

<p>This is similar to my previous guide on running <a href="https://worthdoingbadly.com/xnuqemu2/">iOS kernel in QEMU</a>:</p>

<ul>
  <li>install macOS 11.0.1 beta 1 (20B5012D)</li>
  <li>run <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/build_arm64e_kcache.sh"><code>build_arm64e_kcache.sh</code></a> to create an Apple Silicon Boot Kext Collection</li>
  <li>build the modified QEMU:
    <div><div><pre><code>git clone https://github.com/zhuowei/qemu
cd qemu
git checkout a12z-macos
mkdir build
cd build
../configure --target-list=aarch64-softmmu
make
</code></pre></div>    </div>
  </li>
  <li>create a modified device tree by running <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/FourthTry/DTRewriter.java">DTRewriter</a> on <a href="https://updates.cdn-apple.com/2020SummerSeed/fullrestores/001-30235/6D8C0CA3-5952-4FD8-AEB3-4B4CADB626BC/iPad8,11,iPad8,12_14.0_18A5332f_Restore.ipsw">iPad Pro firmware</a>:
    <div><div><pre><code>python3 extractfilefromim4p.py Firmware/all_flash/DeviceTree.j421ap.im4p DeviceTree_iPad_Pro_iOS_14.0_b3.devicetree
java DTRewriter DeviceTree_iPad_Pro_iOS_14.0_b3.devicetree DeviceTree_iPad_Pro_iOS_14.0_b3_Modified.dtb
</code></pre></div>    </div>
  </li>
  <li>run QEMU:
    <div><div><pre><code>./aarch64-softmmu/qemu-system-aarch64 -M virt -cpu max \
  -kernel /path/to/bootcache-arm64e \
  -dtb /path/to/DeviceTree_iPad_Pro_iOS_14.0_b3_Modified.dtb  \
  -monitor stdio -m 6G -s -S -d unimp,mmu \
  -serial file:/dev/stdout -serial file:/dev/stdout -serial file:/dev/stdout \
  -append "-noprogress cs_enforcement_disable=1 amfi_get_out_of_my_way=1 nvram-log=1 debug=0x8 kextlog=0xffff io=0xfff serial=0x7 cpus=1 rd=md0 apcie=0xffffffff" \
  -initrd /path/to/ios14.0b3/ramdisk.dmg $@
</code></pre></div>    </div>
  </li>
  <li>run gdb with <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/bootit.gdbscript">this script</a>:
    <div><div><pre><code>~/Library/Android/sdk/ndk/21.0.6113669/prebuilt/darwin-x86_64/bin/gdb \
-D /any/emptydir \
-x bootit.gdbscript
</code></pre></div>    </div>
    
  </li>
</ul>

<p>And the macOS kernel will <a href="https://gist.github.com/zhuowei/5aa668e76f387374cd56848313aa2197">boot into launchd</a>.</p>

<h2 id="is-this-useful">Is this useful?</h2>

<p><img src="https://worthdoingbadly.com/assets/blog/xnuqemu3/wwdc2018_no.jpg" alt="&quot;No.&quot; - Craig Federighi, WWDC 2018"></p>

<p>No:</p>

<ul>
  <li>Absolutely nothing is supported: literally only the kernel and the serial port works, not even the userspace since there‚Äôs no disk driver</li>
  <li>Userspace is instead borrowed from iOS 14 b3</li>
  <li>This will never boot anything close to graphical macOS UI</li>
  <li>Most importantly, even if I ever managed to fully boot the macOS kernel, emulating macOS is useless anyways.</li>
</ul>

<p>There are only three reasons I can think of for emulating macOS: security research, software development without a real Apple Silicon machine, and Hackintoshing. This approach will help with none of these:</p>

<ul>
  <li>Emulating iOS is useful for security research when jailbreak is not available. Apple Silicon Macs already support kernel debugging.</li>
  <li>Not useful for software dev: QEMU‚Äôs CPU emulation doesn‚Äôt support Apple Silicon-specific features, such as Rosetta‚Äôs memory ordering or the APRR JIT.</li>
  <li>as for Hackintosh: macOS uses CPU instructions that aren‚Äôt available yet on non-Apple ARM CPUs, so you can‚Äôt have hardware accelerated virtualization, only very slow emulation. Besides, Hackintoshes are often built when Apple‚Äôs own hardware isn‚Äôt fast enough; in this case, Apple‚Äôs ARM processors are already some of the fastest in the industry.</li>
</ul>

<p>I researched this this not because it‚Äôll be practical, but only to understand how an Apple Silicon Mac works. This will never be a <a href="https://www.youtube.com/watch?v=1AtE54HpXBM">Time Train</a>: only a <a href="https://youtu.be/UswpJh6Zvd8?t=119">science experiment</a>.</p>

<h2 id="what-i-did">What I did</h2>

<h2 id="create-kext-collection">Create kext collection</h2>

<p>On iOS, the kernel and its Kexts are packed together into a bootable file called the <strong>Kernel Cache</strong>.</p>

<p>macOS 11 uses an evolved version of this format, called the <strong>Boot Kext Collection</strong>.</p>

<p>Like the iOS kernelcache, it contains all Kexts required for booting, so the bootloader only needs to load it into memory and jump into it.</p>

<p>To create a boot kext collection, macOS 11 introduces the <a href="https://developer.apple.com/documentation/kernel/installing_a_custom_kernel_extension?language=objc"><code>kmutil</code></a> tool.</p>

<p>Here‚Äôs <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/build_arm64e_kcache.sh">my script</a> to get <code>kmutil</code> to generate an arm64e kext collection.</p>

<p>It manually excludes some kexts because they cause kmutil to error out. Most are because they depend on ACPI, which is not available on Apple Silicon. I made a <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/printexcludekexts.sh">script</a> to detect them.</p>

<p>Debugging <code>kmutil</code> failures on macOS 11 beta 3 was easy because it dumped out the entire NSError message. However, on macOS 11.0.1 beta, Apple decided to hide the full error message and only print an error code. I had to disable SIP and put a breakpoint on <code>swift_errorRetain</code> to get at the underlying error.</p>

<p>Once the <code>build_arm64e_kcache.sh</code> runs, a Boot Kext Collection is created at <code>~/kcache_out/bootcache-arm64e</code>, which can be booted in QEMU.</p>

<h2 id="disassembling-the-boot-kext-collection">Disassembling the boot kext collection</h2>

<p>For debugging, I also had to disassemble the newly created Boot Kext Collection in Ghidra.</p>

<p>Unfortunately, Ghidra isn‚Äôt updated for macOS 11 and will refuse to load the file, first giving an error about XML DOCTYPE, then - once that‚Äôs worked around - an <a href="https://github.com/NationalSecurityAgency/ghidra/issues/2192">IOException</a> from the invalid <code>ntools</code> value in the <code>LC_BUILD_VERSION</code> load command.</p>

<p>I created a <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/patch_boot_kext_collection_for_ghidra.py">script</a> to fix up the kext collection so that Ghidra can load it.</p>

<p>Note that this is still not perfect - Ghidra still doesn‚Äôt fixup pointers or read symbols.</p>

<p>To get method names, I also disassembled the raw kernel file (<code>/System/Library/Kernels/kernel.release.t8020</code>) for cross reference. Note that the raw kernel is based at a different address - you can either rebase it in Ghidra, or just be careful to convert addresses.</p>

<h2 id="disable-pac">Disable PAC</h2>

<p>I already had a <a href="https://worthdoingbadly.com/xnuqemu2/">modified QEMU to boot an iOS kernel</a> (which has inspired others, such as <a href="https://alephsecurity.com/">Aleph Security</a>, to build much better open-source iOS emulation platforms)</p>

<p>In early 2019 I updated my modified QEMU to work with PAC for the iPhone Xs/Xr.</p>

<p>QEMU by that time already supported PAC instructions; however, Apple <a href="https://googleprojectzero.blogspot.com/2019/02/examining-pointer-authentication-on.html">modified</a> the crypto algorithm when implementing PAC, so the kernel fails to boot.</p>

<p>I decided to instead <a href="https://github.com/zhuowei/qemu/commit/16613b67ad15a902791109077ebfb1091f1873aa">turn PAC instructions</a> into no-ops, since I don‚Äôt know how Apple‚Äôs algorithm worked. This also makes it easier to debug the kernel.</p>

<p>Since the macOS DTK used an A12z processor, the modified QEMU just worked.</p>

<h2 id="device-tree">Device tree</h2>

<p>Like iOS, macOS on Apple Silicon uses a <strong>device tree</strong> to describe hardware to the kernel, and to pass boot arguments.</p>

<p>macOS 11.0.1 beta‚Äôs installer doesn‚Äôt contain a device tree for the DTK: I suspect it would be in the .ipsw files, which are not publically available. Instead, I borrowed the iPad Pro‚Äôs device tree from iOS 14 beta 3.</p>

<p>Like the <a href="https://worthdoingbadly.com/xnuqemu2/">iOS in QEMU experiments</a>, I first disabled every piece of hardware in the device tree except the serial port.</p>

<p>Unlike iOS, macOS expects some more information in the device tree:</p>
<ul>
  <li>ram size (since Macs have upgradeable RAM)</li>
  <li>nvram, otherwise panics with a null pointer while reading nonce-seed. (I copied nvram from <a href="https://gist.github.com/bazad/1faef1a6fe396b820a43170b43e38be1">bazad‚Äôs dump of an iPhone device tree</a>.)</li>
  <li>AMCC (KTRR) register positions</li>
  <li>System Integrity Protection status</li>
</ul>

<p>I rewrote my <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/FourthTry/DTRewriter.java">device tree editor</a> to allow populating these extra params.</p>

<h2 id="up-to-launchd">Up to launchd</h2>

<p>I can‚Äôt actually boot a macOS root filesystem as I don‚Äôt have an emulated hard disk.</p>

<p>I don‚Äôt have a recovery ramdisk either: that would likely only be included in the DTK IPSW, which is not public.</p>

<p>Instead, I decided to boot with an iOS ramdisk to test the kernel, and disable signature checking using a GDB breakpoint.</p>

<p>I also couldn‚Äôt get the trustcache (list of executables trusted by the kernel) to load. I tried following <a href="https://alephsecurity.com/2019/06/25/xnu-qemu-arm64-2/">Aleph Security‚Äôs guide</a>, but macOS 11 is more strict than iOS 12 and needs it below the kernel; I couldn‚Äôt figure out the correct memory address.</p>

<h2 id="why-it-took-so-long">Why it took so long</h2>

<p>I actually had this blog post ready since <a href="https://gist.github.com/zhuowei/27816d39f234468cf2956479c0dea7ad">August 9th</a>, but I spent an extra 3 months trying to fix issues, since I really wanted to at least get to a shell!</p>

<p>Unfortunately:</p>
<ul>
  <li>debugging why drivers wasn‚Äôt loading was hard</li>
  <li>I couldn‚Äôt disable signature checking properly</li>
  <li>I wanted to wait until Apple released an A14 kernel instead of the DTK‚Äôs A12, so that we can look at how virtualization works, but they never did</li>
</ul>

<p>It‚Äôs now November 9th and Apple‚Äôs holding their press conference tomorrow: so it‚Äôs <a href="https://www.youtube.com/watch?v=9tAbhrDUrqM">now or never</a>.</p>

<h2 id="whats-left">What‚Äôs left</h2>

<p>I‚Äôm probably not going to be working further on this, but here‚Äôs what one can do to make this an actual useful research platform:</p>

<ul>
  <li>Figure out why half the drivers aren‚Äôt loading at all</li>
  <li>Write basic drivers/emulations:
    <ul>
      <li>probably emulate AIC in QEMU (based on Project Sandcastle‚Äôs Linux driver) since a custom interrupt controller Kext would be hard to write</li>
      <li>port Apple‚Äôs old <a href="https://opensource.apple.com/source/AppleMacRiscPCI/AppleMacRiscPCI-3.4/AppleMacRiscPCI.cpp.auto.html">PowerPC PCIE</a> drivers, since it‚Äôs too hard to emulate the Apple Silicon PCIE controller. This will allow us to connect a virtual hard drive.</li>
    </ul>
  </li>
  <li>Switch to the A14 kernel when Apple releases Apple Silicon Macs, so we can test virtualization</li>
</ul>

<h2 id="what-i-learned">What I learned</h2>

<ul>
  <li>How to modify QEMU to disable PAC</li>
  <li>How iBoot on Apple Silicon passes boot options in the device tree</li>
  <li>How to generate an Apple Silicon kernel cache without an Apple Silicon Mac</li>
  <li>How to fight <code>kmutil</code> for the real error message</li>
  <li>Never procrastinate on a blog post for three months</li>
</ul>

  </div>
</article>

      </div>
      
    </div></div>]]>
            </description>
            <link>https://worthdoingbadly.com/xnuqemu3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064593</guid>
            <pubDate>Thu, 12 Nov 2020 00:09:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Overlooked source of Apple M1 performance]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25064570">thread link</a>) | @kwiromeo
<br/>
November 11, 2020 | https://kwiromeo.com/explaining-apple-m1-products-performance/ | <a href="https://web.archive.org/web/*/https://kwiromeo.com/explaining-apple-m1-products-performance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>When watching <a href="https://youtu.be/5AwdkGKmZ0I">Apple's Arm laptops</a> event, I couldn't help but wonder: where is all that performance coming from? During the event, there were two key points (that are not obvious, IMHO), that further explain where they are getting all that extra performance from.</p><p>But first, let's mention the obvious stuff, that plenty of analysts will anchor on, and that are valid:</p><ul><li><strong>More transistors is better</strong>: 5nm process allows more transistors in a chip. More transistors = more instructions processed = faster performance</li><li><strong>Small means low power consumption:</strong> 5nm process allows for lower power consumption. This is because, at that size, the transistor can operate between 0.7V - 1.2V per transistor[<a href="https://www.anandtech.com/show/15219/early-tsmc-5nm-test-chip-yields-80-hvm-coming-in-h1-2020">1</a>] (instead of 1V - 1.35V)[<a href="https://www.anandtech.com/show/16107/what-products-use-intel-10nm-superfin-demystified">2</a>]. At the numbers of billions of transistors, a small voltage difference means a lot for battery consumption.</li><li><strong>Specialized hardware gives an edge</strong>: Accelerators (like the neural engine) allow the Mac to offload specific tasks to another core, which leaves the main processor, M1 to do the work that is less specific (like compiling your code from XCode üòâ )</li></ul><h2 id="unified-memory-architecture-or-making-friends-with-physics-">Unified Memory Architecture (or Making Friends with Physics)</h2><p>When I was transitions careers to become a software developer, I came across this post about latency numbers of common computer components ( a link at <a href="http://norvig.com/21-days.html#answers">Peter Norvig post about it</a>), it occurred to me that all these numbers were proportional to the distance between the CPU and the location of the data. The further the electrons need to travel, the more time they will take. This is a massive oversimplification but illustrates the point well. There are other details to take into account as well. &nbsp;The one that comes to mind is that having the electrical signal only traveling though the SoC instead of the printed circuit board, avoid a lot of signal conditioning that would need to happen to keep signal integrity. Apple brought all their chips closer, which reduced the amount of travel time for every critical signal, as well as reduced the number of medium transitions (from an integrated circuit to a printed circuit board, back to an integrated circuit) as shown in the figure below. This results in higher data access speed by the CPU and the GPU, which translates to a faster experience for the end-user.</p><figure><img src="https://kwiromeo.com/content/images/2020/11/apple_m1_soc_vs_logic_board.jpg" alt="sketch of a logic board with separate chips compared to an apple M1 SoC"><figcaption>Showing the reduced distance of signal traveling for a logic board vs. a SoC :-)&nbsp;</figcaption></figure><h2 id="avoid-unnecessary-copies-or-the-gospel-by-a-c-performance-engineer-">Avoid Unnecessary Copies (or the gospel by a C++ performance engineer)</h2><p>In my year of learning and using C++, I've learned that (unnecessary) copies are bad, and Craig Federighi also knows this. During the presentation, he says</p><blockquote>"We built macOS on Apple Silicon to use the same data formats for things like video decode, GPU and display, so there's no need for expensive copying or translation"</blockquote><p>Why are copies they bad? This has to do with what happens when an object is copied. Here's a simple way to look at the process. Whenever a program issues a copy command, then the CPU needs to:</p><ul><li>read the memory location of the data,</li><li>then reserve memory where the data will be copied</li><li>then copy the data</li><li>then decide what to do with the original data</li></ul><p>When the source of the data copied remains, then the CPU is done. However, when the source data needs to be deleted, then there's the additional step of de-allocating memory space so that other instructions can use it. This problem is sometimes caught by the compiler, whenever possible, and performs an optimization called <a href="https://en.wikipedia.org/wiki/Copy_elision">copy elision</a> whenever it is obvious that a copy is unnecessary. However, while <a href="https://youtu.be/bSkpMdDe4g4">compilers are awesome</a>, they can't undo a programmer's lack of optimization knowledge. One solution that the C++ community found useful, is that we can help the compiler by specifying when copies are not needed. Since C++ 14, programmers can also tell the compilers that we don't need to go through a deep copy, instead, use a command <code>std::move</code>, which does the magic of not destroying and recreate the same thing. This saves CPU cycles, and improves performance.</p><p>From the Apple M1 MacBook presentation, Apple makes the above behavior default: <strong>instead of having the programmer choose between copying or reusing data, reuse of the data is the default</strong>. This makes the efficient behavior to be the default, and save programs from being slowed down by unnecessary copies</p><h2 id="things-i-may-have-missed-and-things-i-don-t-know-about-">Things I May Have Missed (and Things I Don't Know About)</h2><p>The above is a simplified view of the programming model of Apple's new M1 chip. By not having programmed for one, the above is my best guess at how the items noted in the keynote mentions would translate in hardware and software. It's possible that Apple simplified the programming paradigm of CPU vs GPU programming by obfuscating calls to GPU instructions in the macOS APIs. If all the hardware is one the same chip, the programmer doesn't need to know what sub-chip (CPU, GPU, Neural Engine, etc...) is doing the job, but just that the chip (M1) is doing it. From there, the job is for compiler optimization to take over, and make the best decision as to which sub-chip needs to process the instruction.</p><p>‚Äî</p><p>PS: if someone who knows the nitty gritty details of this, hit me up <a href="https://twitter.com/kwiromeo">@kwiromeo</a> on twitter. I would love to learn more about this.</p><hr><p>[1] AnandTech - <a href="https://www.anandtech.com/show/15219/early-tsmc-5nm-test-chip-yields-80-hvm-coming-in-h1-2020">Early TSMC 5nm Test Chip Yields 80%, HVM Coming in H1 2020</a></p><p>[2] AnandTech - <a href="https://www.anandtech.com/show/16107/what-products-use-intel-10nm-superfin-demystified">What Products Use Intel 10nm? SuperFin and 10++ Demystified</a></p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://kwiromeo.com/explaining-apple-m1-products-performance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064570</guid>
            <pubDate>Thu, 12 Nov 2020 00:06:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Government Mandated Backdoors ‚Äì Security Explained]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25064542">thread link</a>) | @sec-explained
<br/>
November 11, 2020 | http://securityexplained.fm/1245467/6099736-government-mandated-backdoors | <a href="https://web.archive.org/web/*/http://securityexplained.fm/1245467/6099736-government-mandated-backdoors">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      <p>Security Explained</p>
      <p>Government Mandated Backdoors</p>
      <p><span>Nov 11, 2020</span>
        <span>Season 1</span>
        <span>Episode 6</span>
      </p>
      <p>Chris Grayson, Drew Porter, Logan Lamb</p>
      <div>
        <div><p>The Department of Justice has recently released a new memo entitled "International Statement: End-To-End Encryption and Public Safety," and while it says a lot about helping trafficked kids and combating other crime, the memo outlines proposals that will do nothing of the sort. In this episode we discuss the content of this memo and the eerily similar-sounding EARN IT act, pick apart which parts of both are valid and which aren't, and talk about the real motivations behind these documents. We cover the current processes for gaining lawful access to data and how these new proposals don't amount to any true improvement upon existing capabilities.</p><p>As has been the standard theme for the past two decades, American privacy is under attack. These new positions reflect a stark step in the wrong direction if you care to preserve human privacy.</p></div>
      </div>
    </div>
  </div></div>]]>
            </description>
            <link>http://securityexplained.fm/1245467/6099736-government-mandated-backdoors</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064542</guid>
            <pubDate>Thu, 12 Nov 2020 00:00:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running Python on .NET 5]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25064143">thread link</a>) | @eatox
<br/>
November 11, 2020 | https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html | <a href="https://web.archive.org/web/*/https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
                <p><em>This post is an update on the Pyjion project to plug the .NET 5 CLR JIT compiler into Python 3.9.</em></p>
<p>.NET 5 was released on November 10, 2020. It is the cross-platform and open-source replacement of the <a href="https://github.com/dotnet/core"><strong>.NET Core</strong></a> project and the <strong>.NET</strong> project that ran exclusively on Windows since the late 90‚Äôs.</p>
<p>.NET is formed of many components:</p>
<ul>
<li>3 builtin languages, C#, F# and VB.NET, each with its own compiler</li>
<li>A standard library</li>
<li>A common intermediate language to abstract the high level languages from the core runtime. This is a standard known as <a href="https://github.com/tonybaloney/ecma-335/tree/master/docs">ECMA 335 CIL</a>.</li>
<li>A common language runtime (CLR) that compiles CIL into native machine code so that it can be executed and packages executables into .exe formats.</li>
</ul>
<p><img alt=".NET architecture" src="https://tonybaloney.github.io/img/posts/Common_Language_Infrastructure.png"></p>
<p>.NET 5 CLR comes bundled with a performant JIT compiler (codenamed RyuJIT) that will compile .NETs CIL into native machine instructions on Intel x86, x86-64, and ARM CPU architectures.</p>
<p>You can write code in a number of languages, like C++, C#, F# and compile those into CIL and then into native machine code (as a binary executable) on macOS, Linux, and Windows. Pretty neat.</p>
<p>But this is a blog about Python. So what does this have to do with Python?</p>
<p>Pyjion is a project to replace the core execution loop of CPython by transpiling CPython bytecode to ECMA CIL and then using the .NET 5 CLR to compile that into machine code. It then executes the machine-code compiled JIT frames at runtime instead of using the native execution loop of CPython.</p>
<h2>Very-quick overview of Python‚Äôs compiler</h2>
<p>When CPython compiles Python code, it compiles it into an intermediate format, similar to .NET, called Python bytecode. This bytecode is cached on disk so that when you import a module that hasn‚Äôt changed, it doesn‚Äôt compile it every time. You can see the bytecode by disassembling any Python function:</p>
<pre><code>&gt;&gt;&gt; import dis
&gt;&gt;&gt; def half(x):
...    return x/2
... 
&gt;&gt;&gt; dis.dis(half)
  2           0 LOAD_FAST                0 (x)
              2 LOAD_CONST               1 (2)
              4 BINARY_TRUE_DIVIDE
              6 RETURN_VALUE
</code></pre>

<p>To execute anything on a CPU, you have to provide the OS with machine-code instructions. This can be accomplished by compiling them up-front using a compiled like the C or C++ compilers. They compile code into executable formats as either shared libraries or standalone executables. <a href="https://tonybaloney.github.io/posts/extending-python-with-assembly.html"><em>See my post on Python/assembly for a bit more info on this topic</em></a>.</p>
<p>CPython converts the bytecode into machine code instructions like looping over them in a precompiled function, called the evaluation loop. This is essentially a big for loop with a switch statement. The compiled version of CPython that you‚Äôre running already has the instructions required. This is why CPython‚Äôs evaluation loop is an ‚ÄúAOT‚Äù, or ‚ÄúAhead of Time‚Äù compiled library:</p>
<p><img alt="diagram 1" src="https://tonybaloney.github.io/img/posts/Slide1.png"></p>
<p><strong>Note: There is a lot more to CPython‚Äôs compiler. I‚Äôve written a <a href="https://realpython.com/products/cpython-internals-book/">whole book on the CPython compiler and the internals of CPython</a> if you want to learn more.</strong></p>
<p>There are a few issues with this approach. The biggest is speed. A series of inline machine-code instructions is very performant. CPython has to make judgements at runtime for which code branch to follow every time your function is run. This leads to CPython being 100x slower in ‚Äútight-loop‚Äù problems where its executing the same thing again and again. The machine-code is compiled ahead of time and it has to loop around to get to the right instructions. Checkout my PyCon talk for a more in-depth explanation:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/I4nkgJdVZFA" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>The most common way around this performance barrier is to compile Python extensions from C. This produces a custom binary with inline machine-code instructions for the task at hand. This is how most machine-learning and data science libraries like numpy, pandas, SKL are put together. This approach is still AOT compiling the code. It also requires a lot of knowledge of C. This approach has worked really well for the data science community, where algorithms can be performant and leverage low-level platforms <a href="https://numba.pydata.org/numba-doc/latest/cuda/index.html">like GPUs or specialised AI chipsets</a>.</p>
<p>There are a few issues with the AOT extension module approach. One is that it still uses the evaluation loop. C extension modules are a set of functions. Once you call the C-compiled function, its in the performant code, but your Python code that‚Äôs calling it still lives inside Python‚Äôs loop. If you want to leverage a compiled library and your Python code is doing some heavy number crunching, you end up having to use an API of functions, like numpy, instead of a more fluent Python API:</p>
<pre><code>&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; a = np.ones([9, 5, 7, 4])
&gt;&gt;&gt; c = np.ones([9, 5, 4, 3])
&gt;&gt;&gt; np.dot(a, c).shape
(9, 5, 7, 9, 5, 3)
&gt;&gt;&gt; np.matmul(a, c).shape
(9, 5, 7, 3)
</code></pre>

<h2>What Pyjion does to solve this issue</h2>
<p>A few releases of Python ago (CPython specifically, the most commonly used version of Python) in 3.7 a new API was added to be able to swap out ‚Äúframe execution‚Äù with a replacement implementation. This is otherwise known as <a href="https://www.python.org/dev/peps/pep-0523/">PEP 523</a>. PEP 523 also added the capability to store additional attributes in <em>code objects</em> (compiled Python code.</p>
<p>Pyjion does not compile Python code. It compiles Python frames (code objects, like blocks, functions, methods, classes) into machine-code at runtime using a performant JIT:</p>
<p><img alt="diagram 2" src="https://tonybaloney.github.io/img/posts/Slide2.png"></p>
<p>CPython compiles the Python code, so whatever language features and behaviours there are in CPython 3.9, like the walrus operator, <a href="https://www.python.org/dev/peps/pep-0584">the dictionary union operator</a>, will all work exactly the same with this extension enabled. This also means that this extension uses the same standard library as Python 3.9.</p>
<p>Pyjion is a ‚Äúpip installable‚Äù package for standard CPython that JIT compiles all Python code at runtime using the .NET 5 JIT compiler. You can use off-the-shelf CPython 3.9 on macOS, Linux or Windows. After installing this package you just import the module and enable the JIT.</p>
<p>Once a frame has been compiled, the binary code is cached in memory and reused every time the function is called:</p>
<p><img alt="diagram 3" src="https://tonybaloney.github.io/img/posts/Slide3.png"></p>
<h2>Using Pyjion</h2>
<p>To get started, you need to have .NET 5 installed, with Python 3.9 and the Pyjion package (I also recommend using a virtual environment).</p>
<p>After importing pyjion, enable it by calling <code>pyjion.enable()</code> which sets a compilation threshold to 0 (the code only needs to be run once to be compiled by the JIT):</p>
<pre><code>&gt;&gt;&gt; import pyjion
&gt;&gt;&gt; pyjion.enable()
</code></pre>

<p>Any Python code you define or import after enabling pyjion will be JIT compiled. You don‚Äôt need to execute functions in any special API, its completely transparent:</p>
<pre><code>&gt;&gt;&gt; def half(x):
...    return x/2
&gt;&gt;&gt; half(2)
1.0
</code></pre>

<p>Pyjion will have compiled the <code>half</code> function into machine code on-the-fly and stored a cached version of that compiled function inside the function object.
You can see some basic stats by running <code>pyjion.info(f)</code>, where <code>f</code> is the function object:</p>
<pre><code>&gt;&gt;&gt; pyjion.info(half)
{'failed': False, 'compiled': True, 'run_count': 1}
</code></pre>

<p>You can see the machine code for the compiled function by disassembling it in the Python REPL.
Pyjion has essentially compiled your small Python function into a small, standalone application.
Install <code>distorm3</code> first to disassemble x86-64 assembly and run <code>pyjion.dis.dis_native(f)</code>:</p>
<pre><code>&gt;&gt;&gt; import pyjion.dis
&gt;&gt;&gt; pyjion.dis.dis_native(half)
00000000: PUSH RBP
00000001: MOV RBP, RSP
00000004: PUSH R14
00000006: PUSH RBX
00000007: MOV RBX, RSI
0000000a: MOV R14, [RDI+0x40]
0000000e: CALL 0x1b34
00000013: CMP DWORD [RAX+0x30], 0x0
00000017: JZ 0x31
00000019: CMP QWORD [RAX+0x40], 0x0
0000001e: JZ 0x31
00000020: MOV RDI, RAX
00000023: MOV RSI, RBX
00000026: XOR EDX, EDX
00000028: POP RBX
00000029: POP R14
...
</code></pre>

<p>The complex logic of converting a portable instruction set into low-level machine instructions is done by .NET‚Äôs CLR JIT compiler.</p>
<p>All Python code executed after the JIT is enabled will be compiled into native machine code at runtime and cached on disk. For example, to enable the JIT on a simple <code>app.py</code> for a Flask web app:</p>
<pre><code>import pyjion
pyjion.enable()

from flask import Flask
app = Flask(__name__)

@app.route('/')
def hello_world():
    return 'Hello, World!'

app.run()
</code></pre>

<p>That‚Äôs it.</p>
<h2>Will this be compatible with my existing Python code? What about C Extensions?</h2>
<p>The short answer is- if your existing Python code runs on CPython 3.9 ‚Äì <strong>yes</strong> it will be compatible. To make sure, Pyjion has been tested against the full CPython ‚Äútest suite‚Äù on all platforms. In fact, it was the first JIT ever to pass the test suite.</p>
<p>Thats because this isn‚Äôt a Python runtime, it uses the existing Python compiler to compile your code into Python bytecode (low level instructions).</p>
<p>Pyjion uses the same dynamic module loader as CPython, so if you import a Python extension from your virtual environment, it will work just the same in Pyjion.</p>
<h2>Project History</h2>
<p>Pyjion isn‚Äôt new. Brett Cannon and Dino Viehland started the Pyjion project 4 years ago. This was the first JIT to pass the full CPython test suite.
There were some limitations to the original proof-of-concept:</p>
<ul>
<li>Written against an old version of .NET Core</li>
<li>Required custom patches of .NET and compiling from source</li>
<li>Required custom patches of CPython and compiling from source</li>
<li>Only worked on Windows</li>
<li>It was written for Python 3.6 before PEP 523 was agreed and merged</li>
</ul>
<p>Has much changed since Python 3.6? To the average user, not really. But under the hood, the implementation of a few things has completely changed:</p>
<ul>
<li>Function calls</li>
<li>Iterators</li>
<li>Exception Handling</li>
<li>Dictionary, list and set comprehensions</li>
<li>Generators and coroutines</li>
</ul>
<p>Actually, a <strong>lot</strong> has changed in the last few releases of CPython. The <a href="https://github.com/microsoft/Pyjion/pull/237">patch that I‚Äôm talking about</a> to get Pyjion working with the latest version of everything was a big undertaking‚Ä¶</p>
<p><img alt="not-much-has-changed" src="https://tonybaloney.github.io/img/posts-original/not-much-has-changed.png"></p>
<p>The goal with the latest patch was to get the project up to the condition of:</p>
<ul>
<li>Using the release binaries of .NET 5 and CPython 3.9</li>
<li>Making it work across all platforms</li>
<li>Implement the PEP523 interface</li>
<li>Implement all the new features of Python 3.9</li>
<li>Making the package ‚Äúpip installable‚Äù from PyPi</li>
<li>Improving the test coverage</li>
<li>Adding a disassembler (both machine-code and CIL) to aid development</li>
</ul>
<h2>Is this faster?</h2>
<p>The short answer a little, but not by much (yet).</p>
<p>JIT ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html">https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html</a></em></p>]]>
            </description>
            <link>https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064143</guid>
            <pubDate>Wed, 11 Nov 2020 23:11:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[All known, public ACME servers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25063759">thread link</a>) | @riffic
<br/>
November 11, 2020 | https://docs.https.dev/list-of-acme-servers | <a href="https://web.archive.org/web/*/https://docs.https.dev/list-of-acme-servers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><div><p><span>All known, public ACME servers</span></p></div></div></div></div><div><div data-editioncontainer="true"><div data-slate-editor="true" data-key="3b72c1eb76324fcea60749a49d24393c" autocorrect="on" spellcheck="true" data-gramm="false"><p data-key="a7423c5bafea4eb385c7e07d0826ea40"><span><span data-key="2d2fcbc1b03349468d8ed1673c1750e0"><span data-offset-key="2d2fcbc1b03349468d8ed1673c1750e0:0">All endpoints on this list are compliant with RFC 8555.</span></span></span></p><p data-key="43f617bd0df447d6b37ca47b12b0a2b7"><span><span data-key="48583dcada4646548bc5caa4bbdd9b9b"><span data-offset-key="48583dcada4646548bc5caa4bbdd9b9b:0">Please note that different CAs have varying legal terms, pricing, and some difference in their ACME issuance policies. Consult each CA's documentation for more information.</span></span></span></p><ul data-key="7ae709311946447e951eaf568ddef55a"><li></li><li></li><li></li><li></li><li></li></ul></div></div></div></div></div></div>]]>
            </description>
            <link>https://docs.https.dev/list-of-acme-servers</link>
            <guid isPermaLink="false">hacker-news-small-sites-25063759</guid>
            <pubDate>Wed, 11 Nov 2020 22:27:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Deploy professionally built algo-traders in 5 mins with 0 code]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25063678">thread link</a>) | @tjs8rj
<br/>
November 11, 2020 | https://areyouinterested.co/site/quantbase/ | <a href="https://web.archive.org/web/*/https://areyouinterested.co/site/quantbase/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="hero-1"><p id="subheading">Deploy algorithms from top hedge funds,<br> rank and use 100s of users‚Äô algorithms,<br> or create new algo-traders effortlessly</p>

              <div id="interested">
                <h3>Are you interested?</h3>
                <div id="buttons">
                  <p><a href="https://areyouinterested.co/site/quantbase/yes" id="yes">Yes</a>
                  <a href="https://areyouinterested.co/site/quantbase/no" id="no">No</a>
                </p></div>
              </div>

            </div></div>]]>
            </description>
            <link>https://areyouinterested.co/site/quantbase/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25063678</guid>
            <pubDate>Wed, 11 Nov 2020 22:18:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Case for Make: The New Old Build Tool]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25063540">thread link</a>) | @chill1
<br/>
November 11, 2020 | https://degreesofzero.com/article/the-case-for-make-the-new-old-build-tool.html | <a href="https://web.archive.org/web/*/https://degreesofzero.com/article/the-case-for-make-the-new-old-build-tool.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>If you've never had to migrate a project from one build system to another, I envy you. How sweet it is to have not experienced the psychological torture that is unwinding years of hacks and work-arounds layered on-top of one another during a legacy project's lifetime. But nothing lasts forever. You too will know this feeling eventually. Or maybe not. Let's talk about how you can avoid this fate by using a new (very old) build system called <a href="https://www.gnu.org/software/make/">Make</a>.</p>
<h2 id="the-case-against-modern-build-systems">The Case Against Modern Build Systems</h2>
<p>Modern build systems use an insane number of dependencies:</p>
<ul>
<li><a href="https://npm.anvaka.com/#/view/2d/gulp">gulp</a> - 296 nodes, 513 links</li>
<li><a href="https://npm.anvaka.com/#/view/2d/grunt">grunt</a> - 170 nodes, 277 links</li>
<li><a href="https://npm.anvaka.com/#/view/2d/webpack">webpack</a> - 82 nodes, 119 links</li>
</ul>
<div>
  <div>
    <p><img width="1920" height="1080" src="https://degreesofzero.com/article/the-case-for-make-the-new-old-build-tool/images/dep-tree-gulp.jpg" alt="" title="gulp's dependency graph">
      <img width="1920" height="1080" src="https://degreesofzero.com/article/the-case-for-make-the-new-old-build-tool/images/dep-tree-grunt.jpg" alt="" title="grunt's dependency graph">
      <img width="1920" height="1080" src="https://degreesofzero.com/article/the-case-for-make-the-new-old-build-tool/images/dep-tree-webpack.jpg" alt="" title="webpack's dependency graph">
    </p>
    <p><b>gulp</b> (left), <b>grunt</b> (center), <b>webpack</b> (right)</p>
  </div>
</div>

<p>Of the build systems mentioned above, only one is still under active development. That one is <a href="https://webpack.js.org/">webpack</a>, which is used by the popular web framework <a href="https://reactjs.org/">React</a>. If you are unfamiliar with webpack, good for you. It is a gigantic piece of software that does too many things. From my experience, webpack can be nice to bootstrap a simple proof-of-concept project, but eventually you will hit a wall where you need to do some extremely hacky work-arounds to do something that it doesn't easily support.</p>
<p>Why am I talking about dependencies? Well...</p>
<blockquote>
<p>Earlier this week, many npm users suffered a disruption when a package that many projects depend on ‚Äî directly or indirectly ‚Äî was unpublished by its author, as part of a dispute over a package name. The event generated a lot of attention and raised many concerns, because of the scale of disruption, the circumstances that led to this dispute, and the actions npm, Inc. took in response.</p>
</blockquote>
<p>This was the <a href="https://blog.npmjs.org/post/141577284765/kik-left-pad-and-npm">"leftpad incident"</a> as it has become to be known.</p>
<p>The package author mentioned in the above quote unpublished more than 250 packages from the npm registry in a very short time. This broke thousands of projects and caused a lot of headaches for maintainers and developers throughout the ecosystem.</p>
<p>This alone should be a strong reason to try to limit your project's exposure to huge dependency graphs.</p>
<p>But in case you are not yet convinced, here are a few more reasons:</p>
<ul>
<li>Less time wasted fixing the build process after upgrading dependencies.</li>
<li>Reduce the attack surface that could allow malicious/rogue dependencies to:<ul>
<li><a href="https://www.veracode.com/blog/research/abusing-npm-libraries-data-exfiltration">Exfiltrate sensitive data</a> such as keys or secrets via the file system or environment variables.</li>
<li>Utilize (abuse) system resources to mine cryptocurrencies.</li>
<li>Use system's network capacity to spam, run proxy servers, or DOS attack other services.</li>
</ul>
</li>
</ul>
<h2 id="the-case-for-make">The Case For Make</h2>
<p>Make. Is. Everywhere. You very likely already have it installed on your system. Or if not, it will be available to install via your system's package repository.</p>
<p>Make is ideal for running builds or as a general purpose task runner. It allows you to easily incorporate bash commands and tools that already exist on your system. All of these tools have been around forever, are well tested, and they are stable.</p>
<h3 id="make-in-practice">Make In Practice</h3>
<p>Here is an example Makefile that includes comments that explain each section:</p>
<pre><code>







BUILD<span>=</span>build
ALL_CSS<span>=</span><span>$</span><span>(</span>BUILD<span>)</span>/css/all.css
SRC<span>=</span>src















<span>.PHONY</span><span>:</span> build\
clean\
fonts\
images

<span>build</span><span>:</span> fonts images <span>$</span><span>(</span>ALL_CSS<span>)</span>

<span>clean</span><span>:</span>
  
  rm -rf <span>$</span><span>(</span>BUILD<span>)</span>/*


CSS_FILES<span>=</span><span>$</span><span>(</span>SRC<span>)</span>/css/fonts.css\
<span>$</span><span>(</span>SRC<span>)</span>/css/reset.css\
<span>$</span><span>(</span>SRC<span>)</span>/css/styles.css\
<span>$</span><span>(</span>SRC<span>)</span>/css/responsive.css

<span><span>$</span>(ALL_CSS)</span><span>:</span> <span>$</span><span>(</span>SRC<span>)</span>/css/
  mkdir -p <span>$$</span><span>(</span>dirname <span>$@</span><span>)</span>
  rm -f <span>$</span><span>(</span>ALL_CSS<span>)</span>
  for file in <span>$</span><span>(</span>CSS_FILES<span>)</span><span>;</span> do \
    echo <span>"/* $$file */"</span> &gt;&gt; <span>$</span><span>(</span>ALL_CSS<span>)</span><span>;</span> \
    cat <span>$$file</span> &gt;&gt; <span>$</span><span>(</span>ALL_CSS<span>)</span><span>;</span> \
    echo <span>""</span> &gt;&gt; <span>$</span><span>(</span>ALL_CSS<span>)</span><span>;</span> \
  done

<span>fonts</span><span>:</span>
  
  mkdir -p <span>$</span><span>(</span>BUILD<span>)</span>/fonts/OpenSans
  cp -r node_modules/open-sans-fontface/fonts/**/* <span>$</span><span>(</span>BUILD<span>)</span>/fonts/OpenSans/

<span>images</span><span>:</span>
  
  mkdir -p <span>$</span><span>(</span>BUILD<span>)</span>/images/
  cp -r <span>$</span><span>(</span>SRC<span>)</span>/* <span>$</span><span>(</span>BUILD<span>)</span>/images/</code></pre>
<p>It is basically bash with the added syntax for build targets. Make will only build files whose inputs have been modified. So in this example, if you change one of your CSS source files then the all.css build file will be recompiled.</p>
<p>The example above is quite simple. It only includes copying and concatenating files. You can add dependencies as you need them to perform minification of JavaScript files, syntax highlighting, templating, and more.</p>
<p>For more advanced build processes, it's a good idea to execute bash (or node.js) scripts from within the Makefile. This gives you the structure and functionality of Make with the flexibility of whichever scripting language you prefer.</p>
<p>During the last few years, I've migrated several projects to Make and it has turned out to be a great move for the long-term maintainability of those projects. You can have a look at some of these projects for more complex, real-world examples using Make:</p>
<ul>
<li><a href="https://github.com/samotari/pay-no-way">PayNoWay</a> - Bitcoin double-spending app for Android</li>
<li><a href="https://github.com/samotari/bleskomat">Bleskomat</a> - Lightning Network ATM hardware + software project</li>
</ul>
<p>Choose Make as your next project's build system. Your future self will thank you!</p>

		</div></div>]]>
            </description>
            <link>https://degreesofzero.com/article/the-case-for-make-the-new-old-build-tool.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25063540</guid>
            <pubDate>Wed, 11 Nov 2020 22:01:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reviving Yo: How to Patch an APK]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25063163">thread link</a>) | @wesleyac
<br/>
November 11, 2020 | https://blog.wesleyac.com/posts/patching-apks | <a href="https://web.archive.org/web/*/https://blog.wesleyac.com/posts/patching-apks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>I got talking to a friend the other day about <a href="https://en.wikipedia.org/wiki/Yo_(app)">Yo</a>, the app where you can send your friends the word "Yo." It's nominally still around, run off donations, but the SSL certificate for the API server has been expired for a little while, so the app doesn't work anymore. Not to worry, though, that's something we can fix by patching the APK pretty quickly.</p>

<p>First, <a href="https://play.google.com/store/apps/details?id=com.justyo">download Yo on the Play Store</a>. Then, download <a href="https://play.google.com/store/apps/details?id=com.ext.ui">APK Extractor</a>, and use it to download the APK off your phone (you'll need to get it onto your computer somehow, I emailed it to myself). You should have a file called <code>Yo_base.apk</code>.</p>

<p>Next, install <a href="https://ibotpeaches.github.io/Apktool/"><code>apktool</code></a>, and use it to decompile the APK:</p>
<div><pre><code data-lang="">apktool if Yo_base.apk
apktool d Yo_base.apk
</code></pre></div>
<p>This should make a directory called <code>Yo_base</code>, which you can edit however you want. I changed <code>https://newapi.justyo.co</code> to <code>http://newapi.justyo.co</code> in <code>res/values/strings.xml</code>, but you could also make other changes as well. Once you've done that, recompile the APK like so:</p>

<p>Now there should be a <code>Yo_base/dist/Yo_base.apk</code> file, but it's not signed, so we can't use it. Signing it isn't too tricky though. Using the <code>keytool</code> and <code>jarsigner</code> tools that come with the JDK:</p>
<div><pre><code data-lang="">keytool -genkey -v -keystore my-release-key.keystore -alias alias_name -keyalg RSA -keysize 2048 -validity 10000
jarsigner -verbose -sigalg SHA1withRSA -digestalg SHA1 -keystore my-release-key.keystore Yo_base/dist/Yo_base.apk alias_name
</code></pre></div>
<p>It'll ask you to make a password and enter your name and things, I don't think it really matters what you choose. Once you've done all that, you can move the <code>Yo_base/dist/Yo_base.apk</code> file to your phone, click through all the fuss that Android makes about running a unsigned APK, and start Yoing away! This also works for other apps just as well :)</p>

          </div></div>]]>
            </description>
            <link>https://blog.wesleyac.com/posts/patching-apks</link>
            <guid isPermaLink="false">hacker-news-small-sites-25063163</guid>
            <pubDate>Wed, 11 Nov 2020 21:24:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to master being high on ownership-a guide for Product Managers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25062859">thread link</a>) | @justanotherpm
<br/>
November 11, 2020 | https://blog.justanotherpm.com/how-to-master-being-high-on-ownership/ | <a href="https://web.archive.org/web/*/https://blog.justanotherpm.com/how-to-master-being-high-on-ownership/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<div>
    <main>
            <article>
    
    <div>
            <p>This post is a follow up to the last one: <a href="https://blog.justanotherpm.com/why-is-ownership-such-an-important-quality-for-great-product-managers-5-reasons/">Why is Ownership Important for Product Managers</a>.</p><p>Today, we talk about different ways to build high ownership as a product manager, especially a new product manager.</p><ol><li><strong>Be the most knowledgable person on the team.</strong> Its easier said than done. That is why you should make learning a priority when you join a new team or organization. Learn about your product, business, customers and industry. Read internal and external documents, get access to the relevant data / dashboards, and talk to those who have the most information. Every time I join a new team, I regularly meet with senior leaders from different teams to get as much knowledge as possible.</li><li><strong>Understand your team's and the company's goals</strong>. The direct manager and other PMs on the team are usually the best people to share the most relevant context. Talking to the engineers will &nbsp;always bring a different perspective. In these discussions, your main aim should be to uncover "what" is the goal and "why" is it the focus at that time.</li><li><strong>Strong relationships with stakeholders.</strong> If you've been reading my posts, you know that I mention <em>building relationships</em> in almost all my guides. And that is because building relationships is truly one of the most important things to do. I always actively work on building relationships from day one. It helps me gain more knowledge, influence the same stakeholders (if and when required), and to remove blockers in critical situations. Basically, these relations make execution seamless.</li><li><strong>Visibility, transparency, openness.</strong> Create processes that encourage transparency and openness to share feedback. Create visibility for others in your progress. It is a signal of strength. It conveys a simple yet powerful message: "you are doing your best. Despite that, things will go wrong. And when that happens, you are open to feedback and to learn from others' experience"</li><li><strong>Execution. Get shit done.</strong> There is nothing that speaks louder of a PM's ownership than her ability to <em>ship</em> products. Executing projects and tasks is the most tangible signal that non-technical stakeholders use to assess you. Exceptions do exist.</li></ol><p>High ownership is sometimes confused with owning a large set of projects or an extended portfolio of products. But high ownership is more about identifying and working only on critical projects, and <strong>always delivering</strong> on them.</p><hr><p>Get bite-sized summaries of the best product management content in your WhatsApp inbox: <a href="http://bit.ly/wajapm">http://bit.ly/wajapm</a></p>
    </div>
        
</article>                            </main>
</div>
        </div></div>]]>
            </description>
            <link>https://blog.justanotherpm.com/how-to-master-being-high-on-ownership/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25062859</guid>
            <pubDate>Wed, 11 Nov 2020 20:54:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on Owning Your Own Business]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25062764">thread link</a>) | @rossdavidh
<br/>
November 11, 2020 | https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/ | <a href="https://web.archive.org/web/*/https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<p>So, you want to strike out on your own, and start your own business?  Great!  Here are a few things you might want to know about that.  They are based on my own experience as an independent contractor (computer programmer), what I've seen being married to an owner (with a partner) of a small retail shop, and what I've seen and heard talking to multiple small business owners of various kinds in the last twenty years.  Some of them are successful, some of them were not, and some were successful but didn't like it, and stopped.  The recurring thing I've seen (and my own lived experience) is that owning and running your own business is not what most people think it is like, so perhaps this will be useful to you as you set out on a different path.</p>



<h2>Lesson 1: You Still Have A Boss</h2>
<p>The most important thing to know, is that being a business owner is NOT like being an employee, except without the boss.  This is, I think, the number one misconception that most people have.  In fact, not only do you still have a boss, but your boss:</p>
<ul>
<li>gives you no paid vacation</li>
<li>gives you no paid sick leave</li>
<li>docks your pay if you break the rules</li>
<li>...but doesn't tell you what those rules are</li>
<li>doesn't (generally) pay overtime if you work long hours or on weekends</li>
<li>does (usually) dock your pay if you take off early</li>
<li>may occasionally pay bonuses, but won't tell you ahead of time what you have to do to get them</li>
</ul>

<p>Your boss is, of course, the market.  New small business owners (and even old ones, sometimes) think they get to decide when they will work, and therefore that customers will show up when they want them to.  But in practice, customers show up when THEY want to, and you need to be ready for them.  If you are not, generally speaking, they will go elsewhere or just forego spending entirely.  The same logic applies to all of the rest of the items in the list above.  The market does all of this, and it is up to you to figure it out, because it won't tell you ahead of time.</p>

<p>Which means really, you have to figure out the rules, and impose them on yourself.  So, when owning your own business, it is not as if you no longer have a boss who makes you do stuff you don't want to do.  It's more like, you also have to be that boss, forcing yourself to do things you don't feel like doing, because there isn't anyone else there to tell you to do it.  That's what "being your own boss" really means; it's not the same as not having a boss.  If you aren't able to make yourself do things when they need doing, even though you don't feel like it right then, then being your own boss may not be for you.</p>

<h2>Lesson 2: The Loop</h2>
<p>There is a process, which you need to know about and think about, as you run a small business.  It is a loop, which can be divided into four parts:</p>
<ol>
<li>Try something (typically involves spending $$ and/or time)</li>
<li>Get results (typically involves receiving $$ or saving time)</li>
<li>Observe that result (notice what just happened)</li>
<li>Plan your next thing to try</li>
</ol>

<img src="https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/loop.png">

<p>It may seem so simple and straightforward, that there's no point in stating it.  But, most business failures can be traced ultimately to one of the following breaks in the loop:</p>
<ul>
<li>Not keeping enough data about what happened (failure in the "observe" step, above)</li>
<li>Not taking time to plan what to do (failure in the "plan" step)</li>
<li>Not actually doing what was planned (failure in the "try" step)</li>
</ul>

<p>Let's look at each of these failures in more detail.</p>
<h3>Failure to Observe</h3>

<img src="https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/loop_without_observe.png">

<p>Part of this, is the common conception that keeping a lot of data about what happened is a drag, and only corporate losers do that sort of thing and starting your own business is all about getting away from that.  Part of it is a failure to understand (per Lesson 1: You Still Have A Boss) that having your own business doesn't mean you get to do whatever you want.  One example I've often seen, is in the decision of what hours a day, and what days of the week, to be open.</p>

<p>Now, it is certainly true that you have the right to close your store whenever you want to.  Perhaps you don't want to be open on Sundays, because your religious beliefs prohibit it.  It's your life.  More typically, though, people just sort of don't want to be open on Sundays, but don't want to pay any penalty for this.  Therefore, they convince themselves that nobody shops on Sundays anyway.  This is, essentially, trying to get out of working on Sundays, without letting your boss see you doing it and docking your pay.  This is employee-type thinking.  Once you are a business owner, not an employee, this way of thinking makes no sense anymore.  If you want to know the cost of not being open on Sundays, you need to collect some data.  For example, you can keep your store open 7 days a week at the beginning, and keep track of how much your sales are each day.  If you do, you will probably find that, just as you want to do a good bit of your shopping on Sunday, so do your (potential) customers.  Sunday is not quite as busy as Saturday, but probably it is more busy than, say, Monday or Tuesday.</p>

<p>But, the lesson is NOT that you should be open on Sundays.  The lesson is that you should not take my word for it, or your own intuition; you should keep track of exactly what happens when you do stay open on Sundays, and look at the cold, hard, unfeeling, pitiless numbers in a spreadsheet before you decide that it's not worth staying open on Sunday.  Of course, if it's a religious thing, or you just don't care about making money, or for whatever other reason you decide to close on Sundays anyway, that is entirely up to you.  But DON'T fail to collect the data.  Don't make decisions based only on your intuition, because when you do that it's the equivalent of the boss asking his employees, "I dunno, should we be open on Sundays?".  What they tell him is based on what they want, not what's good for the business.  You are the boss, and your intuition is like the employees here.  Your intuition will tell you what it wants to be true.  Keep track, numerically, in a spreadsheet, of what happened.  That's what tells you what really is true.</p>

<p>The same logic applies to having a 25% off sale, having a special event at your business, selling a new product, and so forth.  It's your decision, but fortify yourself against wishful thinking by keeping careful, numerical, track of what happened.  You should have, in a spreadsheet, a record of what happened at this time last week, last month, last year.  If sales are slow, is this because they always are slow this time of year?  Or this day of the week?  Or is there something new going on, that you need to look into?  If you spent money to get a new kind of merchandise in your store, how much did you pay for it, and how much did it sell for?  How much do you spend on things, and how much of that goes to waste?  You should know, and you should not rely on your memory or your intuitive hunch.  Put it in a spreadsheet, and look at it.  When it comes time to pay the bills, the bank's computer will take a cold, hard, pitiless look at how much money is in your bank account.  Therefore, you need to be taking a cold, hard, pitiless look at what is working, and what isn't, so that you will be able to pay those bills.</p>

<h3>Failure to Plan</h3>

<img src="https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/loop_without_plan.png">

<p>Let's assume, for the moment, that you have a decent work ethic.  You're willing to hustle to get things done.  This is mostly a good thing, but there is one case where it can get you into trouble, and that's when you're not willing to pause, and plan, because there's so much work to do and you want to get started.  Many times, there are more things that need doing, than there is time to get it all done.  It may seem like this means you need to hustle more.  In fact, it means you need to stop hustling, at least for a little while, and think carefully about what needs to be done first.</p>

<p>Once again,this may mean you end up acting a little like those boring loser corporations that you were wanting to get away from when you decided to start your own business.  Planning, to some people, is boring and seems pointless because nothing gets actually accomplished.  But you don't have enough time, energy, and money to do everything you can think of that needs doing.  When you have your own business, you NEVER run out of things that need doing.  This means you need to carefully plan, and prioritize, so that what you actually do is what is most likely to help.  Just because you are working hard, doesn't mean you are doing what is most important right then.  Make a list of all the things that need doing, put them in an order from highest priority to lowest, and start from the top.  Don't work on the first thing you happen to see that needs doing.  Work on the thing at the top of the list of priorities, and leave some time in your schedule for making sure that list is right.  Is the thing at the top more important than what is below it?  If you cannot get everything done, is the stuff at the top of your list what you would choose to do?  Or will you discover that you have been sprinting nonstop for weeks and much of what you did turned out to be pointless, because (for example) you spent a lot of time painting the great looking sign for your bakery's special Easter sidewalk sale, but never got the permit from the city to have a sidewalk sale so you cannot do that, and the time spent on painting that sign is wasted.  Work on the most necessary things first, and realize that not everything you can think of, will get done.  Even though stopping to plan takes away some of your (already insufficient) time, it also helps increase the odds that you are spending your time wisely, and not wasting it.</p>

<p>All of the above discussion about prioritizing your time, also applies to prioritizing your money.  You will run out of money, if you spend it on anything that seems like a good idea.  There are absolutely more sensible-sounding, good ideas to spend your money on, than you have money.  So prioritize.  You cannot run your business, if you don't pay rent.  You cannot ‚Ä¶</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/">https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/</a></em></p>]]>
            </description>
            <link>https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25062764</guid>
            <pubDate>Wed, 11 Nov 2020 20:45:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software engineering photonics and color science]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25062325">thread link</a>) | @pete314
<br/>
November 11, 2020 | https://www.softcolorsoftware.com/resources/software-engineering-photonics-and-color-science/ | <a href="https://web.archive.org/web/*/https://www.softcolorsoftware.com/resources/software-engineering-photonics-and-color-science/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<hr><h2>Software engineering photonics and color science</h2>

<p>

<img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science.png">

</p>
<p>Hi everybody, I am Petri Piirainen, a co-founder and chief technology officer of SoftColor company. Welcome to this video lecture about SoftColor's fifteen-year software engineering photonics and color science story. </p>

<p>This lecture is part of the University of Eastern Finland's photonics applications course and lecture series. </p>

<p>Since 2005 we have made photo editing automation software. Our photonics journey is slightly different from traditional optics-focused companies, which you have met during this lecture series. </p>

<p>During this lecture, I will tell you what we have learned about developing and selling photonics applications. </p>

<hr><h2>My history with photonics and software engineering </h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_2.png"></p><p>I have an MSc degree in computer science (from the University of Eastern Finland). I studied computer science in a digital signal processing program, and then I had mandatory applied mathematics and physics as minor studies. With physics studies, there was a lot of photonics and color science courses. </p>

<p>I started by software business and engineering career during high school in the 90s.  In 2005 we founded SoftColor Oy, and since that, we have developed faster, easier, and better photo editing automation software.</p>


<hr><h2>Photonics applications: What have we learned?</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_3.png"></p><p>First, I would like to talk a little bit about photonics applications, the beauty and the beast of engineering photonics applications. We have learned that developing useful photonics applications is very hard and requires a lot of engineering and math knowledge. It is challenging because photonics applications (software or hardware) usually have to quickly process tons of data and calculations. </p>

<hr><h2>Technical elements of useful photonics application</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_4.png"></p><p>My favorite thing with photonics is that all photonics applications contain four types of engineering. </p>
<ul>
<li>Physics</li>
<li>Mathematics</li>
<li>Electrical engineering</li>
<li>Computer science </li>

</ul>

<p>But there is also one thing, which is fascinating.  All photonics applications require a lot of arts too.</p>

<ul>
<li>Image quality</li>
<li>Industrial design</li>
<li>User experience</li>
<li>User interaction</li>
<li>User interfaces</li>

</ul>

<p>This mixture of arts and engineering is my main topic for you today.</p>

<hr><h2>Topics</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_5.png"></p><p>My topics today are:</p>

<ul>
<li>A short history and introduction to our company</li>
<li>What we do and how products work</li>
<li>How have we mixed photonics with software engineering</li>
<li>What we learned about to make useful photonics applications</li>
<li>And there will be a bonus "homework" for  you</li>

</ul>


<hr><h2>Story of SoftColor Oy</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_6.png"></p><p>Let's have a quick look at our products and technology. </p>

<hr><h2>What we do</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_7.png"></p><p>We make faster, easier, and better photo edition automation software. Our software runs on Windows PCs and servers.</p>

<hr><h2>SoftColor Oy</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_8.png"></p><p>We founded SoftColor in 2005, so our company is now a teenager. </p>

<p>We have three products: Automata Server, Automata Pro, and PhotoEQ.</p>

<p>We are located in Joensuu, Finland. </p>

<hr><h2>Our business</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_9.png"></p><p>We sell our software on the internet. And all our products are free to try before buying.  Our customers are:</p>

<ul>
<li>Printing industry</li>
<li>Photographers</li>
<li>360 photography</li>
<li>Newspapers</li>
<li>Ad agencies</li>
<li>Repro</li>
<li>Real estate</li>
<li>Car retail</li>
<li>Photo editors</li>
<li>Office workers</li>
<li>Developers</li>

</ul>

<p>Our customers are from the English speaking world. But we have a lof customers from Germany and Spain too.</p>

<hr><h2>Our research and development</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_10.png"></p><p>Our research and development work is to make our photo editing automation software faster, more comfortable, and better to use.</p>

<hr><h2>SoftColor engine </h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_11.png"></p><p>Our applications use the SoftColor engine. It is the brains and heart of our software. </p>

<p>SoftColor engine does all photo editing automation tasks, color correction, image editing, and color management. </p>

<p>To get this automation working. We have combined computer vision, color science, computer graphics, digital signal processing, and machine learning techniques into one packet. </p>

<p>This combination of different engineering tools has made our photo editing automation to work very well.</p>

<hr><h2>How does our color and tone correction work?</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_12.png"></p><p>Let's check how our photo enhancement automation works, with good or bad photos. </p>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_13.png"></p><p>We can fix white balance, exposure, and contrast problems automatically. Results are very natural and good looking.</p>

<p>Our correction works with challenging photos too.</p>

<p>Our white balance correction will you very natural results.</p>

<p>It works with all kinds of photos and cameras.</p>

<p>You will never lose any shots. We can fix them.</p>

<hr><h2>SoftColor and photonics</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_14.png"></p><p>Let's talk a little bit about photonics. </p>

<hr><h2>We are processing colors, not pixels.</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_15.png"></p><p>To get photo editing automation working better. We have learned computers to process colors, not pixels. </p>

<hr><h2>A good photo is a combination of art and science.</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_16.png"></p><p>The most challenging part of photo editing automation is to get results that make our customers happy. The problem is that the excellent photo is a combination of art and science. There is eighty percent of art in the superb picture and only twenty percent of engineering.  </p>

<p>For this problem, we managed to create an excellent solution.</p>

<hr><h2>Traditional image editing and photonics</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_17.png"></p><p>There is photonics behind every camera, display, and photo-editing algorithms. </p>

<hr><h2>SoftColor engine and photonics</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_18.png"></p><p>We have changed to traditional photo editing. We built our engine to take colors first.  This solution has helped us to make better photo enhancement automation.</p>

<hr><h2>We have made a color correction automation that has tools for science and art.</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_19.png"></p><p>Our applications offer tools to our customers to combine art and science with photo editing automation. </p>

<p>Science part:</p>

<ul>
<li>Layer based processing</li>
<li>Statistical analysis </li>
<li>Metadata analysis</li>
<li>Machine vision</li>
<li>Machine learning</li>

</ul>

<p>and the arts:</p>

<ul>
<li>Color grading for mass photo processing</li>
<li>Selective color adjustments </li>
<li>No workflow limitations</li>

</ul>

<hr><h2>SoftColor engine benefits</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_20.png"></p><p>We are processing the colors, not pixels. This approach gives three significant benefits:</p>

<ul>
<li>More accurate automatic correction</li>
<li>Batch color grading for photos</li>
<li>Easier and accurate customization</li>

</ul>


<hr><h2>SoftColor engine technical details</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_21.png"></p><p>Let's take a look inside our engine.</p>

<hr><h2>Layer based processing</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_22.png"></p><p>We use layers based processing, which means that all correction and image processing tools are separate layers. </p>

<p>You will full control of how each step works. For automatic color and tone correction, we have six layers. </p>

<ul>
<li>Rich dynamics enhancer</li>
<li>Luminosity enhancer</li>
<li>White balance </li>
<li>Natural color temperature</li>
<li>Exposure and contrast</li>
<li>Color grading</li>

</ul>


<hr><h2>Spectral illumination estimation technology for better color correction</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_23.png"></p><p>To get better automatic results for all kinds of photos. We have developed spectral illumination estimation technology. </p>

<hr><h2>Same parameters for human and computer</h2>
<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_24.png"></p><p>We use spectral illumination detection to create the same parameters for the user and the computer. </p>

<p>We calculate these parameters from the original image by using:</p>

<ul>
<li>Spectral  illumination estimation from RGB image</li>
<li>Metadata analysis EXIF &amp; camera data</li>
<li>Machine learning for estimated data</li>

</ul>

<p>From this data, we generate parameters for automatic correction.</p>

<p>When users change parameters, they will alter the same settings as our automatic correction uses.</p>

<p>The solution is possible by mixing spectral illumination data with computer graphics techniques.</p>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_25.png"></p><hr><h2>What we have learned about photonics applications during the last fifteen years</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_26.png"></p><p>There six things which we have learned. Which are the requirements for good photonics software or hardware applications.</p>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_27.png"></p><ol>
<li>Software is the glue for photonics applications</li>
<li>Optical engineering</li>
<li>Software engineering</li>
<li>Electrical engineering</li>
<li>User experience engineering</li>

</ol>

<p>These are things and skills which are required. But there is always one challenge, battery, and CPU limitations.  It is the reason why we all need to tune our algorithms, software, and hardware better every day.</p>

<hr><h2>Bonus "homework." Useful resources for your entrepreneur career</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_28.png"></p><p>There has been a lot of questions about how to get started with the photonics business.  Here are two great resources to read or watch.</p>


<hr><h2>To watch "Halt and Catch Fire" tv-series.</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_29.png"></p><p>Halt and Catch Fire is an excellent and very realistic business world tv-series.  The tv-series follows some players in the 80s technological revolution that lead to an information society. It is quite an unknown series, but now it is available in streaming services. </p>



<p>You will learn a lot about the hardware and software business. </p>

<p>The tv-series covers the following useful topics:</p>

<ul>
<li>Venture capital</li>
<li>Bootstrapping</li>
<li>Human resources</li>
<li>Risk management </li>
<li>Work/life balance</li>
<li>Legal stuff (due diligence, intellectual property rights, revenge engineering process) </li>
<li>Fortune 500 vs. startup life </li>

</ul>

<p>And there is a lot of 80s and 90s retro computing and nostalgia too.</p>

<p>
<a href="https://en.wikipedia.org/wiki/Halt_and_Catch_Fire_(TV_series)" target="_blank">Halt and Catch Fire in Wikipedia</a>
</p>


<hr><h2>To read "Masters of Doom" book.</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_30.png"></p><p>Masters of Doom book tells the story of ID software. The makers of Wolf3D, Doom, and Quake games. </p>

<p>There are fascinating stories about how small teams can change the world. For the photonics industry, there is interesting how ID software took the latest research topics from computer graphics and science. And how they utilized them to make their games better.</p>

<p>This book is also available as an audiobook.</p>

<p>
<a href="https://en.wikipedia.org/wiki/Masters_of_Doom" target="_blank">Masters of Doom book in Wikipedia</a>
</p>


<hr><h2>Summary </h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_31.png"></p><p>That was our 15 years story with software engineering, photonics, and color science. I hope that you have learned something new for photonics career or business.</p>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_32.png"></p><p>Here is a summary of the main topics:</p>

<ul>
<li>A good photo is a combination of art and science</li>

</ul>

<ul>
<li>Software is the glue for photonics applications.</li>

</ul>

<ul>
<li>Photonics is a mixture of science, engineering, and arts.</li>

</ul>

<hr><h2>Feedback and comments</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_33.png"></p><p>
It would be great to hear your feedback about this lecture! <a href="https://www.softcolorsoftware.com/contact/">
</a></p><a href="https://www.softcolorsoftware.com/contact/">
</a><center><a href="https://www.softcolorsoftware.com/contact/">
Just drop us a message.</a>
</center>


</div></div>]]>
            </description>
            <link>https://www.softcolorsoftware.com/resources/software-engineering-photonics-and-color-science/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25062325</guid>
            <pubDate>Wed, 11 Nov 2020 20:02:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[.new TLD Shortcuts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25062243">thread link</a>) | @twapi
<br/>
November 11, 2020 | https://whats.new/shortcuts/ | <a href="https://web.archive.org/web/*/https://whats.new/shortcuts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://whats.new/shortcuts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25062243</guid>
            <pubDate>Wed, 11 Nov 2020 19:56:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust as a productive high-level language]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25062055">thread link</a>) | @praveenperera
<br/>
November 11, 2020 | https://omarabid.com/rust-high-level-language | <a href="https://web.archive.org/web/*/https://omarabid.com/rust-high-level-language">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="container">
  <article id="wBiL7EUi4Kw16ahNjk6hmU">
	<time datetime="2020-11-10">November 10, 2020</time>
  
	<p>Rust is often critiqued as a <a href="https://news.ycombinator.com/item?id=24536645">not a very productive</a> programming language. It is true that there is a bit of a learning curve to be able to program in Rust; but beyond that, I think it pays off in productivity; and massively I must say.</p>

<p>I haven‚Äôt been using Rust for production much; maybe a bit more than a year. The static type checks means I‚Äôm getting much less bugs in my code, and spend considerably less time in debugging. I can safely say that, for me, Rust is more productive than JavaScript, PHP or Python and the margin keeps getting larger as I get more acquainted with the ecosystem.</p>

<hr>

<p>To entice your interest, here is a situation that I handled lately: I have a program that writes logs to <a href="https://en.wikipedia.org/wiki/Syslog">syslog</a> and the terminal. The program compiles and functions correctly on my development machine. However, it returned an error when I deployed it to an <a href="https://alpinelinux.org/">Alpine</a> Docker container. Turns out, Alpine doesn‚Äôt have a running syslog service by default.</p>

<p>Now that‚Äôs fine, the program functioned correctly. But I don‚Äôt care much for syslog on deployment since the program is running inside a container. One solution is to remove the syslog <a href="https://en.wikipedia.org/wiki/Sink_(computing)">drain</a> but I need that for development. I can use <a href="https://doc.rust-lang.org/reference/conditional-compilation.html">conditional compilation</a>; but there is a better option: If syslog fails, for whatever reason, just ignore that and move on.</p>

<p>So let‚Äôs take a look at the old code. </p>

<pre><code>    let syslog_drain = syslog_drain()?;
    let term_drain = term_drain()?;
</code></pre>

<p>This code creates two logging drains: one for syslog and one for the terminal. It uses the <a href="https://doc.rust-lang.org/edition-guide/rust-2018/error-handling-and-panics/the-question-mark-operator-for-easier-error-handling.html">? operator</a> to evaluate the result. If the function returns an error, execution will stop and the error bubbles back to the top of the program.</p>

<p>I have no idea how the syslog or any particular drain fails. And honestly, I don‚Äôt want to get into these details. What I want is to check if there is a failure; and if so ignore that particular drain. Or return a <a href="https://docs.rs/slog/2.5.2/slog/struct.Discard.html">Discard drain</a>.</p>

<p>The <a href="https://doc.rust-lang.org/std/result/">Result</a> type and <code>? operator</code> make this particularly easy. So here is the code that does that.</p>

<pre><code>    let syslog_drain = syslog_drain().unwrap_or(discard_drain()?);
    let term_drain = term_drain().unwrap_or(discard_drain()?);
</code></pre>

<p>And that‚Äôs it. This code now compiles and runs correctly. If syslog is running, it‚Äôll write logs to syslog and the terminal. Otherwise, it‚Äôll write logs to the terminal and syslog is skipped. There are no conditions, no complicated checks and it‚Äôs perfectly readable.</p>

<hr>

<p>There is more to Rust productivity than that. Macros, Iterators, Advanced Traits and Types, the new Async system. Once you are comfortable with all of these, you are now able to be productive, safe and fast.</p>

  <figure id="kudo_wBiL7EUi4Kw16ahNjk6hmU">
    <a href="#kudo">
      
    </a>
    <p>128</p>
    <p>Kudos</p>
  </figure>
  <figure id="kudo_side_wBiL7EUi4Kw16ahNjk6hmU">
    <a href="#kudo">
      
    </a>
    <p>128</p>
    <p>Kudos</p>
  </figure>
</article>

</section></div>]]>
            </description>
            <link>https://omarabid.com/rust-high-level-language</link>
            <guid isPermaLink="false">hacker-news-small-sites-25062055</guid>
            <pubDate>Wed, 11 Nov 2020 19:40:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the fractal nature of effort estimates]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25061983">thread link</a>) | @adamkl
<br/>
November 11, 2020 | https://realfiction.net/2016/02/28/on-the-fractal-nature-of-effort-estimates | <a href="https://web.archive.org/web/*/https://realfiction.net/2016/02/28/on-the-fractal-nature-of-effort-estimates">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><div><p><span>February 28, 2016</span> in<span><a href="https://realfiction.net/tags/software-development">software-development</a></span></p></div><p>We still live in a world where people want to play the game of estimates. Indeed, in some industries this may (kind of) work (Yes, this is the 30th automobile we are designing, and the requirements may be more or less the same (not really) than for the 1st automobile we designed). Alas, in software development we are still regularly in trouble if we try to estimate what it will cost us to finalize some software project.</p><p><a href="https://www.quora.com/Why-are-software-development-task-estimations-regularly-off-by-a-factor-of-2-3">I am not the first one</a> to compare the creation of software to a hike following some coast-line. Let's play along, though. Our project needs us to walk around the Lake Constance. First, we have a broad overview of what software we want to build. We look at the lake at the 50km scale of Google Maps:</p><p><img src="https://realfiction.net/assets/LakeConstance-50kmScale.png"></p><p>192 km, nice. We start adding more detail, i.e. we look closer to the aim of walking around the lake...</p><p><img src="https://realfiction.net/assets/LakeConstance-20kmScale.png"></p><p>205 km, still on track.</p><p><img src="https://realfiction.net/assets/LakeConstance-5kmScale.png"></p><p>231 km. Only 20% more expensive than the original estimate, looks like we are gaining confidence. We do see that we may be taking some shortcuts for which we could account with some risk percentages.</p><p>We decide to start the project...</p><p><img src="https://realfiction.net/assets/LakeConstanceProject-Leg1.png"></p><p>We have burned through almost a quarter of the original budget. <strong>50%</strong> more than what we wanted to burn up to now. We also had to make up some additional rules with regard to rivers and the like (we go to the next bridge and cross there).</p><p>The next leg then became a total disaster...</p><p><img src="https://realfiction.net/assets/LakeConstanceProject-Leg2.png"></p><p>57 km...compare this to the estimate on the 20km scale:</p><p><img src="https://realfiction.net/assets/LakeConstance-20kmScaleFromNear.png"></p><p>15 km...<strong>it took almost 4 times the estimate to cover the desired distance!</strong> What happened?!</p><p><img src="https://realfiction.net/assets/LakeConstance-Unforeseen1.png"></p><p>We didn't find a damn bridge!</p><p><img src="https://realfiction.net/assets/LakeConstance-Unforeseen2.png"></p><p>A place where our efforts were about to explode. We took a shortcut!</p><p>And so on, and so on. The scope of the project didn't change, but the expenses are exploding!</p><p>Do I see affirmative nods by fellow software developers?</p><p>If this metaphor works so well, the question is: <strong>Why</strong> does it work so well?</p><p>It may have to do with the nature of fractals. One of the main characteristics of fractals is that they are self-similar. Zoom into a structure, and you will find additional structures, very similar to the ones you already saw from <em>"higher up"</em>. We find self-similarities in large projects, too. On a large scale, we may draw up necessary activities to get from one place to the other. The activities are inter-dependent. We identify problems for which we provide slack. <strong>This happens again and again while we zoom into activities</strong>. Some time into the process we will arrive at the point where we don't see additional value in planning - we will start walking. Whatever detail we put into the planning (Check our 3rd plan of the lake circumference, it looks pretty exact!), it doesn't protect us from additional activities, inter-dependencies and problems that we did not foresee.</p><p><img src="https://realfiction.net/assets/zoominto.jpg"></p><p>Other things that we haven't even gotten into, but will probably greatly affect our estimating efforts:</p><ul><li>The effort involved in monitoring the activities (as witnessed by measuring out the distance) grows exponentially.</li><li>In an actual software project, the expected results of the project will inevitably change - In our metaphor this amounts to either a changing coast line, or, when facing the sheer amount of effort required to trace a particular part of the line, to the statement <em>"we will do this later"</em>.</li></ul><p>Does all of this information help us in any way? I am not sure. However, especially in the case of tracing coastlines, mathematics has a concept that encapsulates the increase in effort with increasing detail: The <a href="http://fractalfoundation.org/OFC/OFC-10-4.html">fractal dimension</a>. Hence, if there is more to tracing coastlines than being a metaphor to developing software, there may be a chance that the mathematics of fractals can help us in understanding better the capabilities and, more importantly, the inadequacies of estimating efforts in a large software project.</p><h2>Previous &amp; Next</h2><h2>Comments</h2></article></div></div>]]>
            </description>
            <link>https://realfiction.net/2016/02/28/on-the-fractal-nature-of-effort-estimates</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061983</guid>
            <pubDate>Wed, 11 Nov 2020 19:33:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The most misunderstood billion dollar industry in the world?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25061784">thread link</a>) | @mattob
<br/>
November 11, 2020 | https://www.fourpm.co/p/cannabis-is-the-most-misunderstood | <a href="https://web.archive.org/web/*/https://www.fourpm.co/p/cannabis-is-the-most-misunderstood">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I woke up on Wednesday, June 21st <em>ready</em>.&nbsp;   </p><p>It was my final day of high school and I was preparing to take an economics exam later that day. It was also same day that I was preparing to move half-ways across the world from a small town in rural Ireland to Toronto, Canada. </p><p>About 4 hours later after the completion of my economics exam, I found myself on the way to the airport some 5 hours away to Dublin in order to fly to Toronto at at 2.AM the next morning - all of this coming courtesy of reading a book called Narconomics just one year earlier.</p><p>Within this book, I found one of the most logical arguments that I had ever heard, an argument that we as a society should effectively embrace legalizing all drugs. This was not a moral argument, it was a highly convincing argument based on economic theory and practical use cases from around the world, and I wanted to learn more. </p><p>After many months of diligent planning, I arrived in Toronto Canada, slightly jet lagged after 15 hours of travel and with less than $500 CAD in my bank account I had a modest first few months upon my arrival in Canada, however, shortly afterwards I found myself working as a budtender at a dispensary in Vancouver, B.C. </p><p>Starting off at this ground level provided me with the best foundation that I could have asked for as an entry point into the cannabis industry, and it was from here that I worked tirelessly over the next two years to gain all of the insights that I craved into everything that encompassed the cannabis industry to learn exactly how it operated.</p><p>As I fast approach the three year anniversary for my joining the cannabis. Here are the five biggest things I‚Äôve learned over the last three years.</p><h4><strong>1.</strong> Assume everything you know about cannabis is wrong</h4><p> When I first started working in the cannabis industry, I had little to no understanding of cannabis. </p><p>Although in the beginning this seemed to serve as a significant disadvantage by making my initial interactions with consumers very uninformed, within four weeks of working as a budtender my understanding of cannabis had already surpassed everyone I was directly working with by virtue of assuming that I knew nothing to begin with.</p><p>My own approach was to spend every moment I either wasn‚Äôt working or wasn‚Äôt serving a customer to read as much of the research that has been done on cannabis to date, of which their was surprisingly a lot more than what I had expected there to be.     </p><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F52e41090-cae2-4424-8754-d5b591f7362a_3872x2581.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F52e41090-cae2-4424-8754-d5b591f7362a_3872x2581.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/52e41090-cae2-4424-8754-d5b591f7362a_3872x2581.jpeg&quot;,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:539504,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><h4><strong>2.</strong> Get very comfortable with constant change</h4><p>One of the most important lessons I have learned from working within the cannabis industry is to get very comfortable with the idea of constant change. </p><p>In the three years that I have worked within the cannabis industry I have seen the industry transition out of the black market into a fully federally legal framework -  with cannabis company stocks being traded on some of the most prestigious stock exchanges in the world and with this we have seen cannabis companies valuations experience meteoric rises and meteoric declines shortly afterwards. </p><p>Although all of these changes may seem significant, I suspect that many of these changes will seem minor in comparison to some of the changes I see on the horizon for the cannabis industry in the coming years. </p><h4><strong>3.</strong> <a href="https://www.youtube.com/watch?v=jtRFd1N43y4">The best is yet to come</a></h4><p>When I joined the cannabis industry three years ago working in the store below, what captivated me the most was not where the industry was at this point, what captivated me was where I think the industry will be 20 years from now.</p><p>Here in Canada it‚Äôs estimated that 15% of Canadians over the age of 15 have consumed cannabis within the past 12 months, while this number is 78.5% for those who have consumed alcohol. As someone who no longer consumes alcohol in favor of cannabis derived products, I am perhaps blinded by my own basis here, however, the approach that I took to make this determination of not consuming alcohol was by analyzing the known impacts of consuming it.</p><p>Truthfully, when presented with the known evidence, going <a href="https://myhighly.com/cannabis-101/the-rise-of-cali-sober">Cali Sober</a> was the easiest decision I have every made.</p><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Faab6ddb0-7d5b-42c9-9310-3a4472738a2b_1328x747.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Faab6ddb0-7d5b-42c9-9310-3a4472738a2b_1328x747.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/aab6ddb0-7d5b-42c9-9310-3a4472738a2b_1328x747.png&quot;,&quot;height&quot;:747,&quot;width&quot;:1328,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1461029,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></p><p><em>4.PM is a weekly newsletter that provides valuable industry insights from the ever evolving cannabis industry &nbsp;<a href="https://fourpm.substack.com/">Sign up here.</a></em></p><h4><strong>4.</strong> We stand on the shoulders of giants</h4><p>Sometimes we have to look to the the past to understand the future. To understand the future of the cannabis industry I personally think it‚Äôs essential to understand the path that has brought us to where we are today. </p><p>This path has been paved by activists who‚Äôs endless passion for this amazing plant has ensured that the draconian policies our politicians have sought to implement don‚Äôt prevail and that those who need access to cannabis will be provided that access. </p><p>We also have a long list of researchers to thank for providing the cannabis industry with the evidence that it needed to fights its case in court to prove that cannabis is not the cause of many modern problems, rather the solution. </p><h4><strong>5.</strong> An enormous regulatory burden </h4><p>As someone who operates a cannabis business, operating in the industry is by no means an easy challenge as it requires a level of attention to detail that adds on significant costs to cannabis companies who choose to operate in the legal market.</p><p>In the long run I personally think it‚Äôs inevitable that the legal industry will overtake the existing legacy markets that exist around the world today through cheer innovations, of which their is no shortage on the horizon.</p><p>In the meantime all cannabis operators will have to operate within a high fragmented regulatory environment that will make it harder to expand into new markets at the rate which perhaps many would would like to, however, many are already paving the way. </p><h4><strong>A final word.</strong></h4><p>In an industry whereby the only constant is change, it‚Äôs abundantly clear that the cannabis industry will undergo many additional changes in the coming years.</p><p>Courtesy of being a member of this community, my aim is to provide you with the most up to date information to allow you to understand all of the complexity that is the cannabis industry.</p><p>If learning about this billion industry is something of interest to you then sign up now so you don‚Äôt miss the first issue which will be published Saturday the 17th of October 2020. Did I mention that it‚Äôs free for the first 1,000 members? </p><p>- Matthew O‚ÄôBrien</p><p>üëâ&nbsp;If you enjoyed reading this post, feel free to share it with friends!  </p><p data-attrs="{&quot;url&quot;:&quot;https://fourpm.substack.com/?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share 4 PM&quot;,&quot;class&quot;:null}"><a href="https://fourpm.substack.com/?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share"><span>Share 4 PM</span></a></p><p>‚Ä¶ For more like this, make sure to sign up here:  </p></div></div>]]>
            </description>
            <link>https://www.fourpm.co/p/cannabis-is-the-most-misunderstood</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061784</guid>
            <pubDate>Wed, 11 Nov 2020 19:16:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notion Timeline View]]>
            </title>
            <description>
<![CDATA[
Score 287 | Comments 147 (<a href="https://news.ycombinator.com/item?id=25061781">thread link</a>) | @AlphaWeaver
<br/>
November 11, 2020 | https://www.notion.so/guides/timeline-view-unlocks-high-output-planning-for-your-team | <a href="https://web.archive.org/web/*/https://www.notion.so/guides/timeline-view-unlocks-high-output-planning-for-your-team">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/guides/timeline-view-unlocks-high-output-planning-for-your-team</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061781</guid>
            <pubDate>Wed, 11 Nov 2020 19:15:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On solving your own tiny annoyances]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25061753">thread link</a>) | @rjyoungling
<br/>
November 11, 2020 | https://www.younglingfeynman.com/essays/airbnb2 | <a href="https://web.archive.org/web/*/https://www.younglingfeynman.com/essays/airbnb2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-8f03ceb2cec309b9bc66"><div><p><em>EDIT: I‚Äôm gonna open this essay up with the caveat that there‚Äôs a lot of non-Airbnb stuff in here. That‚Äôs because I wanted to draw parallels between Airbnb and other startups. I‚Äôm less interested in lazily inspiring you with examples like most sites do, and more in what you should take away to increase your probability of success.</em></p><p><em>I‚Äôve also decided to split the original essay up into 4 parts (shipping 1 part each day). It was almost half an hour long and I feel like that just would‚Äôve been too cumbersome to consume.</em></p><p><em>Hope you enjoy.</em></p><p><em>RJ</em></p><p><em>Links to the rest of the good stuff:</em></p><p><a href="https://www.younglingfeynman.com/essays/airbnb"><em>The Dumbest Startup That Ever Worked‚Ää ‚Äî What You Can Learn From Airbnb‚Ää ‚Äî PART 1</em></a></p><p><a href="https://www.younglingfeynman.com/essays/airbnb2"><em>The Dumbest Startup That Ever Worked‚Ää ‚Äî What You Can Learn From Airbnb‚Ää ‚Äî PART 2</em></a></p><p><a href="https://www.younglingfeynman.com/essays/airbnb3" target="_blank"><em>The Dumbest Startup That Ever Worked‚Ää ‚Äî What You Can Learn From Airbnb‚Ää ‚Äî PART 3</em></a></p><p><a href="https://www.younglingfeynman.com/essays/airbnb4" target="_blank"><em>The Dumbest Startup That Ever Worked‚Ää ‚Äî What You Can Learn From Airbnb‚Ää ‚Äî PART 4</em></a></p><p><em>TLDR: Lesson 1: It‚Äôs possible for you to make things better. Lesson 2: Solve your own tiny problem. Lesson 3: Validate quickly and double down when it works. Lesson 4: It‚Äôs easy to connect the dots ex-post-facto. Lesson 5: Finding product/market fit from day one is fiction.</em></p><p><em>We‚Äôll cover lessons 2 and 3 today. Let‚Äôs get this show on the road, yes?</em></p><p>When Brian moved to SF and decided to live with Joe to figure out what their billion-dollar startup was gonna be, he quickly learned that in order to make rent in SF, you have to sell a kidney. Probably both if you‚Äôre one of those fancy, pampered types that enjoys the finer things in life such as, you know, nutrition.</p><p>He didn‚Äôt have his part of the rent though ($1150).</p><p>But that weekend, there just so happened to be <a href="https://www.sxsw.com/news/2016/sxsw-eco-award-winners-and-conference-highlights/" target="_blank">an international design conference at SXSW</a>, and they noticed that all the hotels on the website were listed fully booked.</p><p>They figured: well, designers are gonna have to stay somewhere, we don‚Äôt have the money to make rent, so what if we made a makeshift Bed and Breakfast?</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603187267518_29128"><div><p>But Brian and Joe didn‚Äôt have any beds. However, Joe had some airbeds leftover from camping so they changed their idea to an Airbed and Breakfast (Airbnb).</p><p>They ended up hosting a 35yr old woman from Boston, a 45yr old father of 5 from Utah, and a <a href="https://nextshark.com/meet-man-became-airbnbs-first-guest/" target="_blank">30yr old man from India</a>. Oh‚Ä¶ and they made rent.</p><p><em>If you just want to read about Airbnb, skip the following section and pick back up at: BUILD SOMETHING SMALL THAT YOU WANT AND THINK IS DOPE.</em></p><p><strong>Notice that they weren‚Äôt trying to build a unicorn</strong>. They just needed to make rent and it seemed like a cool, fun thing to try.</p><p>This is a surprisingly common theme in startups. Travis made a similar remark about the origins of Uber:&nbsp;</p><blockquote><p>‚Äò‚ÄôWhen we first started it wasn‚Äôt about taking over the world. It wasn‚Äôt about taking on corruption in every city around the world. It was actually just about being baller in San Francisco.‚Äô‚Äô</p></blockquote><p><em>Because literally every POS article on Business Insider type websites doesn‚Äôt have the accurate quote and more annoyingly can‚Äôt be bothered with a source either, here it is:</em></p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603187267518_32526"><div><p><em>Travis Kalanick at Startup School 2012 (2 years after founding Uber).</em></p><p>Back when computers were expensive, Woz built his own because he wanted one for himself. That was the origin of Woz, Jobs, and for 12 days Wayne‚Äôs, Apple.</p><blockquote><p>‚Äò‚ÄôI had no idea that I was taking exactly the right steps up this nice smooth ladder that leads up to the Apple II.‚Äô‚Äô</p></blockquote><p>Notice the nice smooth ladder he‚Äôs talking about. You start small and incrementally work your way up. You don‚Äôt start with the vision of the trillion-dollar Apple we have today.</p><blockquote><p>‚Äò‚ÄôI told my father: ‚ÄòSomeday, I‚Äôm gonna own a 4K Nova Computer, so I can write programs.‚Äô And he said: ‚ÄòThat‚Äôll cost as much as a house.‚Äô And I said: ‚ÄòI‚Äôll live in an appartment.‚Äô I would rather have a computer in my life than a house.‚Äô‚Äô&nbsp;</p></blockquote></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603187267518_36039"><div><blockquote><p>‚Äò‚ÄôI was giving away the schematics, passing them out. No copyright notices, no nothing. Passing out the listings of the code I wrote to other people in my club [<a href="https://en.wikipedia.org/wiki/Homebrew_Computer_Club" target="_blank">The Homebrew Computer Club</a>]. I was saying: ‚ÄòHere, you can build your own.‚Äô And nobody really had the time to build it. And, so Steve Jobs came by and said: ‚ÄòWhy don‚Äôt we make a PC board to save them the time to build it.‚Äô</p></blockquote></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603187267518_38102"><div><p>There‚Äôs this idea that in order to change the world you have to start with the vision to cure cancer or build a quantum computer or something.</p><p>I don‚Äôt really like that approach. Maaaybe it‚Äôs useful for a second-time founder but for a first-time founder, I think it‚Äôs way too overwhelming.</p><p>When you‚Äôre ambitions are so grandiose, it‚Äôll scare you into inaction.</p><p>We know from BJ Fogg‚Äôs work (2009) on behavior science that if ability is low (something is extremely hard to do), then even with high levels of motivation, behavior won‚Äôt occur. And reminders (called prompts) will just make you frustrated.&nbsp;</p><p>But there‚Äôs another problem too. Namely, there are just so many examples of solutions to tiny irritations that escalate into big companies.</p><p>There are a few reasons for that but one of them is that it brings clarity, simplicity, and focus. My favorite example of this is The Point vs. Groupon. [4]</p><p>So be open to solving small problems in your life. Yesterday I saw Mikael Cho, founder of Unsplash talk about this on Twitter. It‚Äôs a good reminder that small stuff really can become big.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603187267518_48211"><div><p>And if after that you‚Äôre still inspired to tackle the hard and obvious problems, you‚Äôll be in a much more favorable position. [5]</p><p>They went from idea to execution fast. There was no complex infrastructure. No complicated back-end designed to handle the influx of millions of people. No, it was all very ghetto. We need to pay the rent, so can we get 3 people to <a href="https://nextshark.com/meet-man-became-airbnbs-first-guest/" target="_blank">pay us $80</a> to stay with us and sleep on our Airbeds during the conference?</p><p>Most of the time when founders do that stuff, it‚Äôs just another way to hide.</p><p>One of the best models we have today is the <a href="https://okdork.com/resources/validate-business/" target="_blank">Kagan Validation Model</a>: Get 3 paying customers in 48 hours without spending any money. (Sumo Group founder and early Facebook/Mint employee <a href="https://www.youtube.com/c/OkDork" target="_blank">Noah Kagan</a>.)</p><p>Sure, that might eliminate ideas that would‚Äôve worked had you spend more resources (false negatives). But it also prevents you from spending months or even years on ideas that are never gonna work (false positives).&nbsp;</p><p>Since the latter is a far more common problem, it‚Äôs more important to prevent that from happening.</p><p>By making the system overly sensitive, you‚Äôll prevent wasting resources on ideas that‚Äôll never work and the stuff that does make it through your filter is much more likely to succeed.</p><p>Think about it. If you can presell something based on a phone call then that leaves all the tools in your toolbox available to grow it. Whereas if you launch with the perfect product and marketing after years of refining it behind closed doors, then where exactly are you gonna take it from there? What‚Äôs left to optimize?</p><p>This does beg the question: ‚Äò‚ÄòWhy make the system overly sensitive in the first place? Why not adjust it so it‚Äôs perfect?‚Äô‚Äô Because that‚Äôs not possible. There‚Äôs no way to create a system that will sort good ideas from bad ideas perfectly. So you‚Äôll always have to be biased toward identifying good ideas and throwing away good ones that seemed bad (false negative) or identifying bad ideas and continuing to work on bad ideas that seem good (false positives).</p><p><em>This essay </em><a href="https://www.younglingfeynman.com/essays/paradigm" target="_blank"><em>Paradigm Shift: Drastically Increase The Odds of Success</em></a><em> goes into depth on how to think about false positives and negatives.</em></p><p><em>[4] From </em><a href="https://www.younglingfeynman.com/essays/startstartup" target="_blank"><em>The Right Way To Start A Startup</em></a><em>:</em></p><blockquote><p>Andrew at the NY Tech Meetup in 2008:</p><p>‚Äò‚ÄôThe biggest mistake we made with The Point was being encumbered by this vision of what I wanted it to be. And taking 10 months to build the product and making all these assumptions of what people would want, that we then spend the next 10 months backtracking on. Instead of focussing on the one little piece of the product that people actually liked. </p><p>So, uhm, If there‚Äôs any advice that I have it‚Äôs you‚Äôre way too dumb to figure out if your idea is any good. It‚Äôs up to the masses. So build that very small thing and get it out there and keep on trying different things and eventually you‚Äôll get it right.‚Äô‚Äô</p></blockquote><p><em>[5] Elon Musk is a role model for many founders nowadays but what he‚Äôs doing now is much less accessible than what Jack Dorsey, Drew Houston, or Mark Zuckerberg have done. In fact, it was so inaccessible that he couldn‚Äôt raise enough from investors. Which is why half a billion dollars in loans from the government was required. As for the hundreds of millions to kickstart Tesla and SpaceX? His own money. Which he made from‚Ä¶ yup‚Ä¶ internet startups. His first project was a small video game called Blastar. After that, he created Zip2 (Internet version of the yellow pages telephone directory with maps included.), then PayPal.</em></p><p><em>Also, SpaceX grew in ambition. Originally </em><a href="https://en.wikipedia.org/wiki/History_of_SpaceX#cite_note-1"><em>the idea</em></a><em> was just to use 100 of the 180 million dollar payout of the PayPal acquisition to eBay, to get people excited about space again. He wanted to land a miniature experimental greenhouse containing seeds with dehydrated gel on Mars to grow plants on Martian soil, ‚Äúso this would be the furthest that life‚Äôs ever traveled‚Äù in an attempt to regain public interest in space exploration and increase the budget of NASA.</em></p><p><em>As for Tesla, that wasn‚Äôt even founded by Elon. Which most founders know but gen. pop. or the up and coming founder might not. The </em><a href="https://www.wired.com/2009/06/tesla-founder/" target="_blank"><em>original idea</em></a><em> came from AC Propulsion where Tom Gage and Alan Cocconi had built </em><a href="http://www.discoverychannel.co.uk/video/future-cars-t-zero/" target="_blank"><em>the t zero</em></a><em>.</em></p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603187267518_53941"><div><p><em>Point is, he didn‚Äôt start with his current vision and you shouldn‚Äôt either.</em></p><p>Berkeley Haas. (2008). <em>Steve Wozniak on the Early Days of Apple [Video]. </em>Retrieved 20 October 2020, from https://youtu.be/5WBX6SACViI.</p><p>Dang, L., &amp; General, R. (2016).&nbsp;<em>Meet the Man Who Became Airbnb's Very First Guest</em>. NextShark. Retrieved 20 October 2020, from https://nextshark.com/meet-man-became-airbnbs-first-guest/.</p><p>Fogg, BJ. (2009).<em> </em>A behavior model for persuasive design. <em>Persuasive ‚Äô09: Proceedings Of The 4Th International Conference On Persuasive Technology</em>, <em>40</em>, 1‚Äì7. <a href="https://d1wqtxts1xzle7.cloudfront.net/36817028/Behavior-Model-for-Persuasive-Design.pdf?1425238284=&amp;response-content-disposition=inline%3B+filename%3DBehavior_Model_for_Persuasive_Design.pdf&amp;Expires=1602589095&amp;Signature=KPddqP810HPTN~SZLDPWhUoEbIIz7rKXZmSs6MVnhCNnTISRH6k60ORCxlQfh8WphZtdJtu85lxVfbuneBEPDVfDlWS7tD8UNBn3Y5YpqvS5TjiQ3c0h9gcHWG00op6Fl5wmABWosDACoudSqS-9p471kocL7es~kQLdvan5FLVH7boNVWk7rS9QOBNU67k95h7Xl1xg1YasOC43BbLs4qeVzNeuZ-mOR7i32gtScEOWvu97ODs48SYSFSmdpXUFaap~Nln2ICvLEsCYdRbs3RN1toGCRHAsuwl1MBUKq8aZxMEKPBn3YCadIiBfwzWGaWuGKCj1ya1cIdrZVhXUSg__&amp;Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA" target="_blank"><em>https://doi.org/10.1145/1541948.1541999</em></a></p><p>FORA.tv. (2014).<em> Steve Wozniak Remembers Building the First Apple Computer. </em>Retrieved 20 October 2020, from ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.younglingfeynman.com/essays/airbnb2">https://www.younglingfeynman.com/essays/airbnb2</a></em></p>]]>
            </description>
            <link>https://www.younglingfeynman.com/essays/airbnb2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061753</guid>
            <pubDate>Wed, 11 Nov 2020 19:12:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Source Code Is Not the Whole Story: Understanding Software Through APIs]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25061745">thread link</a>) | @jeanyang
<br/>
November 11, 2020 | https://www.akitasoftware.com/blog/2020/11/10/kbgnmpu9bdi6qsgkkxo1amqptellna | <a href="https://web.archive.org/web/*/https://www.akitasoftware.com/blog/2020/11/10/kbgnmpu9bdi6qsgkkxo1amqptellna">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-0b8680fe602586cc73eb"><div><p>üëã hunters!</p><p>After putting out an early iteration a few months ago, we‚Äôre excited to officially launch our private beta‚Äîand to make our docs public for the first time!</p><p>And we'd like to give a big thank-you to all the users and friends of Akita who got us here. üòä<br></p><h2><strong>üöó How we got here</strong></h2><p>In 2018, I was a <a href="http://jeanyang.com/">CS professor at Carnegie Mellon University</a>. When Cambridge Analytica hit, I started asking friends in industry how they knew what data their apps were sending around. It turned out that there was no good solution for understanding interactions across APIs‚Äînot just for privacy and security but also for reliability and diagnostics. When I realized that this was the exact problem I‚Äôd been teeing up to solve, I took leave from my job, sold my furniture, and drove across the country to start Akita.</p><p>There is now a small team of us working on Akita, coming from places like Twilio and Amazon. Our team‚Äôs experience building in service-oriented environments made everyone especially excited to build a product that would help developers move faster together.</p><h2><strong>üîé Source code isn‚Äôt the whole story.</strong></h2><p>At Akita, we believe the way to understand your software is through your APIs. Our solution builds dynamic models of API behavior to automatically:</p><p>‚úÖCatch breaking changes on every pull request<br>‚úÖGenerate specs for any API<br>‚úÖUpdate API specs on every pull request<br>‚úÖDiscover and document endpoints</p><h2>üèó <strong>How we built it</strong></h2><p>From the beginning of Akita, I knew where I wanted us to go: automatically map out the graph of API interactions. This would be key to improving reliability, diagnostics, and security in modern web apps.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1605055841399_25008"><div><p>What we didn‚Äôt know was exactly how we would get there. Should we integrate with a tracing library? Should we build a proxy?</p><p>After <a href="https://blog.sigplan.org/2020/10/27/whats-the-role-of-developer-experience-in-programming-languages-research/">talking with dozens of developers and engineering leaders</a>, we came up with three main requirements. First, whatever we built needed to work with any tech stack. Second, people needed to be able to integrate our solution in minutes. Finally, we wanted something that could run in production without adding overhead or exposing sensitive data. These were not easy requirements to balance!</p><p>After over a year of building, we‚Äôre super excited to launch a solution that requires no code changes, no proxies, works with any language, and integrates in just minutes. Akita works by watching API traffic, analyzing, and sanitizing the traffic locally to share only metadata back to our cloud. This means you can Akita deploy Akita anywhere: your laptop, CI/CD, or production‚Äîwithout having to worry about us seeing your data. We are really proud of our approach and believe it is the future of cloud observability.</p><p>And for those who are curious, our tech stack is Go, typed Python, and React. üòä</p><h2><strong>üíñ Let‚Äôs make software development better</strong></h2><p>We believe that Akita can help anybody with a web app who wants to move quickly without losing customers. We understand that we have a long way to go to achieve the vision‚Äîand that the only way to get there is by getting feedback early and often from people like you.</p><p>We‚Äôd love to have you <a href="https://www.akitasoftware.com/get-invite?utm_campaign=2020_private_launch&amp;utm_medium=blog&amp;utm_source=2020_11_11_producthunt">try out the private beta</a>! We‚Äôll also be checking the comments on <a href="https://www.producthunt.com/posts/akita-private-beta">ProductHunt</a> for feedback and questions. We look forward to hearing from you.</p><p>Onward ‚ö°Ô∏è,<br>Jean Yang (<a href="https://www.linkedin.com/in/jean-yang-96575030/">LinkedIn</a>; <a href="https://twitter.com/jeanqasaur">Twitter</a>)<br>Founder and CEO, Akita Software</p><p>P.S. Thank you to the veterans out there!<br>P.P.S. Follow our updates and tell us what you think on Twitter <a href="https://twitter.com/AkitaSoftware">@AkitaSoftware</a>!</p></div></div></div>]]>
            </description>
            <link>https://www.akitasoftware.com/blog/2020/11/10/kbgnmpu9bdi6qsgkkxo1amqptellna</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061745</guid>
            <pubDate>Wed, 11 Nov 2020 19:12:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Cotter ‚Äì Restrict Login to ‚ÄúAllowed‚Äù Emails Only, No Code]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25061724">thread link</a>) | @mmarcelline
<br/>
November 11, 2020 | https://blog.cotter.app/how-to-restrict-your-webflow-website-to-allowed-emails-only/ | <a href="https://web.archive.org/web/*/https://blog.cotter.app/how-to-restrict-your-webflow-website-to-allowed-emails-only/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<div>
<figure><iframe width="480" height="270" src="https://www.youtube.com/embed/w9kJyBDcm9w?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><h3 id="prerequisites">Prerequisites</h3><p>Before we begin, make sure you have done the following:</p><ul><li><strong>Follow Cotter's Basic Webflow Tutorial</strong>: <a href="https://blog.cotter.app/integrate-cotter-magic-link-to-webflow-in-less-than-15-minutes/">How to Integrate Cotter's Magic Link to Your Webflow Site in Less Than 7 minutes</a></li></ul><h3 id="how-it-works">How it works</h3><p>We'll have 3 pages in this tutorial: <strong>A Waitlist Page (/waitlist), a Login Page (/), and a Protected Page (/protected)</strong>. </p><p>Users can sign up to the waitlist by entering their email on the Waitlist Page. You can manage people on the waitlist in your Google Sheets. Only people who are marked as <code>Allowed: TRUE</code> on the waitlist can login to your website using the Login Page and access the Protected Page.</p><p>In this tutorial,<strong> we'll make the Waitlist Page, </strong>and then<strong> update the Login and Protected Page </strong>that you have made in the prerequisite tutorial<strong>.</strong></p><h2 id="make-a-waitlist-page">Make a Waitlist Page</h2><h3 id="step-1-set-up-google-sheets">Step 1: Set up Google Sheets</h3><p>Go to <a href="https://cotteremaillist.herokuapp.com/">https://cotteremaillist.herokuapp.com</a> to connect your Google Sheets that contains a list of emails and follow the instructions there. See an <a href="https://docs.google.com/spreadsheets/d/1EYaErpQUCOhfXgCb0vhObEwDMFBqi_-gmRJ8C7DcOAA/edit?usp=sharing">example Google Sheet here.</a> (You can make this sheet private - you just need to connect your Google Account in the website above).</p><h3 id="step-2-make-elements-to-show-the-waitlist-email-form-and-a-success-message">Step 2: Make elements to show the waitlist email form and a success message</h3><ul><li>Include a section element to load Cotter's login form. <strong>We need to set that section id "cotter-form-container"</strong>.<strong> </strong>Make the section <strong>width </strong>and<strong> height </strong>to<strong> <code>300px</code> </strong>for best results.</li><li>Include a text element with <strong>id "waitlist-message"</strong>. We will show if the email is successfully added to the waitlist here.</li></ul><h3 id="step-3-add-cotter-js-sdk">Step 3: Add Cotter JS SDK</h3><p>After finishing the page setup we can start with adding custom code to the Waitlist Page. Copy paste the code below to the custom code tab on the Waitlist Page settings.</p><figure><img src="https://blog.cotter.app/content/images/2020/11/image-4.png"><figcaption>Waitlist Page Settings</figcaption></figure><figure><img src="https://blog.cotter.app/content/images/2020/11/image-5.png"><figcaption>Scroll Down to "Custom Code" section</figcaption></figure><p>Add the code below to the <strong>head</strong> of Waitlist page:</p><pre><code>&lt;!--Get Cotter JS SDK--&gt;
&lt;script
  src="https://unpkg.com/<a href="https://blog.cotter.app/cdn-cgi/l/email-protection" data-cfemail="21424e5555445361110f120f1312">[email&nbsp;protected]</a>/dist/cotter.min.js"
  type="text/javascript"
&gt;&lt;/script&gt;</code></pre><h3 id="step-4-add-a-function-to-insert-email-to-your-google-sheets">Step 4: Add a function to insert email to your Google Sheets</h3><p>Make sure you have already done Step 1 by going to <a href="https://cotteremaillist.herokuapp.com/">https://cotteremaillist.herokuapp.com</a> and connecting your Google Sheets that contains the waitlist (this can be empty, but make sure you follow the format specified).</p><p>Add the code below to the <strong>body</strong> of Waitlist page:</p><pre><code>&lt;script&gt;
  const insertEmail = async (payload) =&gt; {
    try {
      const body = {
        spreadsheetId: "&lt;YOUR SPREADSHEET ID&gt;", //üëà Add your Spreadsheet ID
        apiKeyID: "&lt;YOUR API KEY ID&gt;", //üëà Add your API KEY ID
        email: payload.email,
        allowed: false // By default, new emails are not allowed to login
      };
      let resp = await fetch(
        "https://cotteremaillist.herokuapp.com/api/insertemail",
        {
          method: "POST",
          headers: {
            "Content-Type": "application/json"
          },
          body: JSON.stringify(body)
        }
      );
      let respBody = await resp.json();
      if (respBody.success) {
        document.getElementById("waitlist-message").innerHTML =
          "Added to waitlist";
      } else {
        document.getElementById("waitlist-message").innerHTML =
          "Something went wrong";
      }
    } catch (e) {
      document.getElementById("waitlist-message").innerHTML =
        "Something went wrong";
    }
  };
&lt;/script&gt;</code></pre><p>Make sure that you have pasted your<strong> <u>Spreadsheet ID</u> </strong>and your<strong> <u>API Key ID</u> </strong>on the code block above.</p><p>You can grab a Cotter API Key ID by visiting <a href="https://dev.cotter.app/">https://dev.cotter.app</a> and creating an account. Once you have created an account, make sure to create a new project and grab the API Key ID.</p><h3 id="step-5-add-the-code-below-to-show-the-email-form-join-waitlist-form-">Step 5: Add the code below to show the email form ("Join Waitlist" form)</h3><p>Below the code on step 4, add this code:</p><pre><code>&lt;script&gt;
    var cotter = new Cotter({
      ApiKeyID: "&lt;YOUR_API_KEY_ID&gt;",  // üëà Specify your API KEY ID here
      ButtonText: "Join Waitlist",
    });
    cotter
      .signInWithLink() // Verify email with Magic Link
      .showEmailForm() // Send Magic Link via email
      .then((payload) =&gt; {
        insertEmail(payload);
      })
      .catch((err) =&gt; {
      // handle error
      });
&lt;/script&gt;</code></pre><p>Make sure that you have pasted your<strong> <u>API Key ID</u> </strong>on the code block above.</p><h2 id="login-page-setup-where-the-login-form-will-show-up-">Login Page Setup (where the login form will show up)</h2><p>You should already have a Login Page after following the prerequisite tutorial above. Only users who are allowed in your Google Sheets can login. We are going to modify and add some of the necessary code.</p><h3 id="step-1-add-the-code-below-to-the-body-of-the-login-page">Step 1. Add the code below to the body of the Login Page</h3><p>Add this code before you Initialize Cotter</p><pre><code>&lt;script&gt;
  const checkEmail = async (payload) =&gt; {
    try {
      const body = {
        spreadsheetId: "&lt;YOUR SPREADSHEET ID&gt;", //üëà Add your Spreadsheet ID
        apiKeyID: "&lt;YOUR API KEY ID&gt;",  // üëà Specify your API KEY ID here
        email: payload.identifier
      };
      let resp = await fetch(
        "https://cotteremaillist.herokuapp.com/api/checkemail",
        {
          method: "POST",
          headers: {
            "Content-Type": "application/json"
          },
          body: JSON.stringify(body)
        }
      );
      let respBody = await resp.json();
      if (!respBody.allowed) {
        return "You are not allowed to log in";
      } else {
        return null;
      }
    } catch (e) {
      console.log(e);
      return "You are not allowed to log in";
    }
  };
&lt;/script&gt;</code></pre><p><strong>Make sure that you have pasted your <u>Spreadsheet ID</u> and your <u>API Key ID</u> on the code block above.</strong></p><h3 id="step-2-change-the-code-in-the-body-of-the-login-page-to-the-code-below">Step 2. Change the code in the body of the Login Page to the code below</h3><pre><code>&lt;script&gt;
  var cotter = new Cotter("&lt;YOUR_API_KEY_ID&gt;"); // üëà Specify your API KEY ID
  cotter
    // Choose what method of login do you want
    // Sign In with Magic Link
-   .signInWithLink()
+   .signInWithLink(checkEmail)
    // Send Magic Link via email
    .showEmailForm()
    
    .then(payload =&gt; {
      // redirect to the protected page
      window.location.href = "/protected";
    })
    .catch(err =&gt; {
      // handle error
    });
 &lt;/script&gt;</code></pre><p>Make sure you deleted the line ".signInWithLink()" and added the line ".signInWithLink(checkEmail)".</p><p>Also, make sure that you have pasted your <u>API Key ID</u> on the code block above.</p><h2 id="protected-page-setup-and-any-other-page-you-want-to-protect-">Protected Page Setup (and any other page you want to protect)</h2><p>You should already have a Protected Page after following the prerequisite tutorial above. We are going to modify and add some of the necessary code.</p><pre><code>&lt;script
  src="https://unpkg.com/<a href="https://blog.cotter.app/cdn-cgi/l/email-protection" data-cfemail="d4b7bba0a0b1a694e4fae7fae6e7">[email&nbsp;protected]</a>/dist/cotter.min.js"
  type="text/javascript"
&gt;&lt;/script&gt;

&lt;script&gt;
  async function checkLoggedIn() {
    //Initialize Cotter
    var cotter = new Cotter("&lt;YOUR_API_KEY_ID&gt;"); // üëà Specify your API KEY ID
    
    // 1. We check if a user has already logged in
    const accessTokenObject = await cotter.tokenHandler.getAccessToken();
    const accessToken = accessTokenObject ? accessTokenObject.token : null;

    // 2. If user is not logged in then we redirect to the login page
    if (!accessToken) window.location.href = "/";

    // 3. Construct the body for access token verification
    let body = {
      oauth_token: {
        access_token: accessToken
-     } 
+     },
+     spreadsheetId: "&lt;YOUR SPREADSHEET ID&gt;",  //üëà Add your Spreadsheet ID
+     apiKeyID: "&lt;YOUR API KEY ID&gt;" // üëà Specify your API KEY ID here
    };

    // 4. If user is logged in then we fetch the user data
+   //    and check if the email is allowed based on our Google sheets
-   let url = "https://worker.cotter.app/verify";
+   let url = "https://cotteremaillist.herokuapp.com/api/login"
    fetch(url, {
      method: "POST",
      cache: "no-cache",
      headers: {
        "Content-Type": "application/json",
-        API_KEY_ID: "&lt;YOUR_API_KEY_ID&gt;"   // üëà Specify your API KEY ID here
      },
-     mode: "cors",
      body: JSON.stringify(body)
    })
      .then((resp) =&gt; resp.json())
      .then((data) =&gt; {
        if (!data.success) { window.location.href = "/" }
      });
  }
  
  //Call the CheckLoggedIn function
  checkLoggedIn();
  
&lt;/script&gt;</code></pre><p><strong>Make sure you delete all lines with the "-" symbol and added all lines with the "+" symbol.</strong> (Do not include the <code>+</code> sign itself).</p><p>Also, make sure that you have pasted your <u>Spreadsheet ID</u> and your <u>API Key ID</u> on the code block above.</p><hr><h3 id="questions-feedback">Questions &amp; Feedback</h3><p>Come and talk to the founders of Cotter and other developers who are using Cotter on <a href="https://join.slack.com/t/askcotter/shared_invite/zt-dxzf311g-5Mp3~odZNB2DwYaxIJ1dJA">Cotter's Slack Channel</a>.</p><h3 id="ready-to-use-cotter">Ready to use Cotter?</h3><p>If you enjoyed this tutorial and want to integrate Cotter into your website or app, you can <a href="https://dev.cotter.app/">create a free account</a> and <a href="https://docs.cotter.app/">check out our documentation</a>.</p><p>If you need help, ping us on our <a href="https://join.slack.com/t/askcotter/shared_invite/zt-dxzf311g-5Mp3~odZNB2DwYaxIJ1dJA">Slack channel</a> or email us at <a href="https://blog.cotter.app/cdn-cgi/l/email-protection" data-cfemail="1b6f7e7a765b78746f6f7e69357a6b6b35">[email&nbsp;protected]</a></p>
</div>
</section></div>]]>
            </description>
            <link>https://blog.cotter.app/how-to-restrict-your-webflow-website-to-allowed-emails-only/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061724</guid>
            <pubDate>Wed, 11 Nov 2020 19:11:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gantt Charts Arrive in Notion]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25061649">thread link</a>) | @saviorand
<br/>
November 11, 2020 | https://optemization.com/timeline-view-notion | <a href="https://web.archive.org/web/*/https://optemization.com/timeline-view-notion">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article id="block-timeline-view-notion"><blockquote id="block-659ced01cffc486ca3fa1b6e01fb482d"><span><span>It's about time: gantt charts, page customization and more arrive to Notion ‚Äî
here's our breakdown.</span></span></blockquote><div id="block-9ce0f17fa5904c5ba88176d78f03d8ff"><div id="block-f4c2486805a1467cb60c4a5aa1db40e5"><p><span><span>Hello there! Welcome to </span><span><em>Digital Opsessions</em></span><span> issue #0003</span></span></p></div></div><div id="block-e49dbd8e89f34444b7a9118c475aa629"><div id="block-2c66366dc9994fae8d874f1f30735471"><p><span><span>Today, marvelous talents at Notion decided to make it a bright Wednesday for us and share three major updates in the app! As part of the Notion Ambassadors group, we were fortunate enough to beta test these features and help spread the announcement news. </span></span></p><p><span><span>Here's what's up </span></span></p></div></div><div id="block-d85f6c16c65a4a098d6794d204a0267b"><div id="block-67d522c072b8469b8543221c3b19634a"><p><span><span>It has been a loooong dark 469 days since this Tweet has swept the world of project management. Frankly, it feels like the gap between season seven and season eight of the Game of Thrones. Only this time, you're going to be very happy. </span></span></p><p><span><span>Now that I think about it: Pfizer's vaccine announcement to COVID-19 is like Arya to the Night King (if you know what I mean ‚Äî </span><span><span><span>no spoilers</span></span></span><span>). </span></span></p></div></div><h2 id="block-8854e6d47bc8427ba082691fcd7e95e6"><span id="8854e6d47bc8427ba082691fcd7e95e6"></span><span><span>How to Timeline View</span></span></h2><p><span><span>Starting today, you will see the timeline view option show up in all your databases and linked database views. This is how it looks like:</span></span></p><div id="block-cb36fbb3f3d742e59a7052a3434dc403"><picture><source srcset="https://api.super.so/asset/optemization.com/d9fb8f55-918d-4d1d-8f1a-b07973ad41e9.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/d9fb8f55-918d-4d1d-8f1a-b07973ad41e9.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/d9fb8f55-918d-4d1d-8f1a-b07973ad41e9.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/d9fb8f55-918d-4d1d-8f1a-b07973ad41e9.png?w=1500" alt="image" loading="lazy"></picture></div><p><span><span>Here are some main configuration options to be aware of.</span></span></p><h3 id="block-3a98d91ea0c7408b9d38b302d0a9cf96"><span id="3a98d91ea0c7408b9d38b302d0a9cf96"></span><span><span>Timeline by</span></span></h3><p><span><span>Just like with board and calendar views, you can choose what dates the Timeline view indexes by. </span></span></p><div id="block-056fc67a35f34ed38fe2deff5ea12a8b"><picture><source srcset="https://api.super.so/asset/optemization.com/77a66cc4-c069-4f8c-8a2a-066b925dad3b.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/77a66cc4-c069-4f8c-8a2a-066b925dad3b.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/77a66cc4-c069-4f8c-8a2a-066b925dad3b.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/77a66cc4-c069-4f8c-8a2a-066b925dad3b.gif?w=1500" alt="image" loading="lazy"></picture></div><p><span><span>In our case, we're arranging our content calendar by two date properties. To do that, toggle the </span><span><code>use separate start and end dates</code></span><span> option. We also like to enter both start and end dates in one property, but needed filtered visibility in the view. 
So we added a two simple formula properties:</span></span></p><ol><li id="block-f89f02f1bac2425789e0f9ecddeee9f4"><span><span>Start date: </span><span><code>start(prop("Promotion Dates"))</code></span></span></li><li id="block-7861a869b8284263831a9a9b58104177"><span><span>End date </span><span><code>end(prop("Promotion Dates"))</code></span></span></li></ol><div id="block-afad72a4ccbe4f1580bd7a0f1f142601"><p><span><span>Note that the "timeline by" setting will </span><span><strong>not</strong></span><span> sort your records chronologically by default. You need to enable this option if you need it.</span></span></p></div><h3 id="block-afa3f89aff864e099417bc191809b611"><span id="afa3f89aff864e099417bc191809b611"></span><span><span>Show table </span></span></h3><p><span><span>For the first time in Notion databases-and-views history you can fully hide the table! That comes in handy with timeline view ‚Äî if you just want to see that beautiful timeline. 
You'll also notice that you can limit the amount of records that show up without filtering, but more on that below</span></span></p><div id="block-2f1dc0d7047146d095c018880c646883"><picture><source srcset="https://api.super.so/asset/optemization.com/35e655b8-664c-4b96-8db3-239615ae3184.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/35e655b8-664c-4b96-8db3-239615ae3184.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/35e655b8-664c-4b96-8db3-239615ae3184.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/35e655b8-664c-4b96-8db3-239615ae3184.gif?w=1500" alt="image" loading="lazy"></picture></div><h2 id="block-2f419ddfbd474c8e9744b4b41831f8f7"><span id="2f419ddfbd474c8e9744b4b41831f8f7"></span><span><span>The Good / The Bad</span></span></h2><div id="block-98a043c9f3d54cbfaf16507beddb2f56"><picture><source srcset="https://api.super.so/asset/optemization.com/a4e87755-cc22-423d-9d79-877a3650d6b7.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/a4e87755-cc22-423d-9d79-877a3650d6b7.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/a4e87755-cc22-423d-9d79-877a3650d6b7.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/a4e87755-cc22-423d-9d79-877a3650d6b7.png?w=1500" alt="image" loading="lazy"></picture></div><h3 id="block-3595a6e3558e48f9815ea8277e41a6dd"><span id="3595a6e3558e48f9815ea8277e41a6dd"></span><span><span>Things we love</span></span></h3><p><span><span><strong>Moving multiple date-specific records is seamless</strong></span><span>. Now, if you need to adjust a project timeline that has multiple pieces to it, whether its tasks, milestones, or events, you can just select them all, drag and all the dates will adjust accordingly. We use this, for example, to adjust whole complex project schedules to start from a given date ‚Äî very handy!</span></span></p><div id="block-633f34747c1f45bb9bcd4b392939fe48"><picture><source srcset="https://api.super.so/asset/optemization.com/add5b1ab-14c2-485d-812f-809bf50c452f.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/add5b1ab-14c2-485d-812f-809bf50c452f.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/add5b1ab-14c2-485d-812f-809bf50c452f.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/add5b1ab-14c2-485d-812f-809bf50c452f.gif?w=1500" alt="image" loading="lazy"></picture></div><p><span><span><strong>Hiding the property table is possible! </strong></span><span>If you'd like to see the timeline view in its full glory you can now toggle the table on and off. In the other Notion views, you cannot hide the main "Name" / ID property. </span></span></p><div id="block-50d1fed52f7c4101beb7d215660af070"><picture><source srcset="https://api.super.so/asset/optemization.com/9ba9dc57-2389-40b4-84ca-c93bdc43ab4a.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/9ba9dc57-2389-40b4-84ca-c93bdc43ab4a.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/9ba9dc57-2389-40b4-84ca-c93bdc43ab4a.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/9ba9dc57-2389-40b4-84ca-c93bdc43ab4a.gif?w=1500" alt="image" loading="lazy"></picture></div><p><span><span><strong>You can timeline by separate properties. </strong></span><span>The default Notion date property does not allow filtering or sorting by the date range. It uses the start date. That can be tricky and annoying when you want to filter your timeline view. Luckily, you have the option to timeline by separate fields!</span></span></p><div id="block-e347aea8615f4fb68f3dd07579d1d4af"><picture><source srcset="https://api.super.so/asset/optemization.com/b681c448-961e-438f-98b3-4977ca6ee06f.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/b681c448-961e-438f-98b3-4977ca6ee06f.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/b681c448-961e-438f-98b3-4977ca6ee06f.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/b681c448-961e-438f-98b3-4977ca6ee06f.gif?w=1500" alt="image" loading="lazy"></picture></div><h3 id="block-b01c6b44c6eb42b8a0e4d062c85b586f"><span id="b01c6b44c6eb42b8a0e4d062c85b586f"></span><span><span>Things we hate</span></span></h3><p><span><span><strong>Data overflow: </strong></span><span>Items look bad when you show more than one property in the timeline, or when an event takes place on a single day (then item is just a small white dot, and text overflows). When more than a few properties toggled on the timeline, the UI of each becomes visible cluttered. For both the table and timeline, a "wrap cells" options would be great.</span></span></p><div id="block-b126bbb5b6e546db81fe1c95982de683"><picture><source srcset="https://api.super.so/asset/optemization.com/875b03db-e9f6-4958-bbf0-a9942da504af.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/875b03db-e9f6-4958-bbf0-a9942da504af.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/875b03db-e9f6-4958-bbf0-a9942da504af.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/875b03db-e9f6-4958-bbf0-a9942da504af.png?w=1500" alt="image" loading="lazy"></picture></div><p><span><span><strong>Only full width. C</strong></span><span>urrently timelines with a table toggles "on", do not adjust to standard width.That's annoying because for some it might be useful to see the table and timeline on the standard width.</span></span></p><div id="block-9c638003ac144730b036479a2d56bf6c"><picture><source srcset="https://api.super.so/asset/optemization.com/b0d2431d-bdc3-4125-9edd-17549894a669.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/b0d2431d-bdc3-4125-9edd-17549894a669.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/b0d2431d-bdc3-4125-9edd-17549894a669.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/b0d2431d-bdc3-4125-9edd-17549894a669.gif?w=1500" alt="image" loading="lazy"></picture></div><p><span><span><strong>Paid plans limits</strong></span></span></p><div id="block-4058fc818edf482ab647cb0d6a4790ba"><div id="block-6c4afe4fb0934ecba8c9d341c6e955e9"><div id="block-6fc04eb8d9bf427c81b524a58a270ae5"><picture><source srcset="https://api.super.so/asset/optemization.com/9322832a-461e-4806-bc46-4be82e9cfd4e.png?w=434&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/9322832a-461e-4806-bc46-4be82e9cfd4e.png?w=434" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/9322832a-461e-4806-bc46-4be82e9cfd4e.png?w=434&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/9322832a-461e-4806-bc46-4be82e9cfd4e.png?w=434" alt="image" loading="lazy"></picture></div></div><div id="block-ad57120d749247d08823002a95441e09"><p><span><span>With the introduction of Timelines, Notion team added a new pricing tweak ‚Äî a limit on the number of Timelines you can use. You can only add 3 timelines on a Personal plan and up to 5 on Team plan. For unlimited timelines you have to buy Enterprise</span></span></p></div></div><p><span><span>We managed to lay our hands on the Timeline view before the release, and had the chance to prepare this proposal template with a Gantt chart included!</span></span></p><p><span><span>It's easy to try ‚Äî just duplicate it into your workspace and drag all milestones, meetings, deliverables and billing activities to your project's start date. Voila! You now have a complete, detailed project schedule aligned with your preferred dates.</span></span></p><p><span><span>You can change any part of this template ‚Äî remove or add new records, change default structure, introduce new types of project activities, such as legal (marking the date when the contract is signed), holidays, events.</span></span></p><p><span><span>We use this template ourselves to spin up new client proposals ‚Äî it saves tons of time on routine editing and allows us to focus on things that are essential, like pain points we help clients address, or our unique approach. </span></span></p><p><span><span>Making these kinds of documents in Notion is enjoyable ‚Äî you can templatize pretty much any common structure. If the lack of Gantt Charts is something that was stopping you from going all-in on Notion, now is the time. </span></span></p><h2 id="block-3c4bd798e6b34e7abd3977fbe0825efb"><span id="3c4bd798e6b34e7abd3977fbe0825efb"></span><span><span>Get the template!</span></span></h2><h3 id="block-f851a8c9110c4392a445c1f5aa42fd57"><span id="f851a8c9110c4392a445c1f5aa42fd57"></span><span><span>Properties</span></span></h3><p><span><span>Power users know that complex. data-heavy workflows in Notion were tough to work with so far. When making structures that's more sophisticated than a simple "Basic CRM" workflow, properties tend to pile up ‚Äî at some point, when opening a page, you don't see its content on the first screen, just properties.</span></span></p><p><span><span>Not anymore! Now you can hide properties you don't use and get straight to that page content every time you open a page. </span></span></p><div id="block-1fd0baefcc3d4939af7c1f0dcf418a19"><picture><source srcset="https://api.super.so/asset/optemization.com/52e79bf6-392b-4d85-911f-2660d3d4d596.png?w=406&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/52e79bf6-392b-4d85-911f-2660d3d4d596.png?w=406" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/52e79bf6-392b-4d85-911f-2660d3d4d596.png?w=406&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/52e79bf6-392b-4d85-911f-2660d3d4d596.png?w=406" alt="image" loading="lazy"></picture></div><p><span><span>The best part is that you can set up advanced rules on when to show or hide specific properties ‚Äî for example, you can show a property only when it's not empty for the current page, or always hide a specific property on a page (you can always open it up manually).</span></span></p><div id="block-6b34b9caaab340d9a69316d845cee4cb"><picture><source srcset="https://api.super.so/asset/optemization.com/1d64c6a2-b8d3-4a5c-923f-f2bff59e5179.png?w=350&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/1d64c6a2-b8d3-4a5c-923f-f2bff59e5179.png?w=350" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/1d64c6a2-b8d3-4a5c-923f-f2bff59e5179.png?w=350&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/1d64c6a2-b8d3-4a5c-923f-f2bff59e5179.png?w=350" alt="image" loading="lazy"></picture></div><h3 id="block-e0e751d263f64ecc9596b3e091381dd9"><span id="e0e751d263f64ecc9596b3e091381dd9"></span><span><span>Comments, Backlinks</span></span></h3><p><span><span>It's simple with comments ‚Äî you can just hide them for a page. Same with backlinks, but you can also select "Show in a popover". That option will display a small "X backlinks" button indicating how many backlinks a page has. Then you can press that button and view the backlinks.</span></span></p><div id="block-3e1f67ea498d4fa0ad79e33295222f8e"><picture><source srcset="https://api.super.so/asset/optemization.com/d7e691c5-25eb-433d-82a9-0d35f6b7fb0d.png?w=320&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/d7e691c5-25eb-433d-82a9-0d35f6b7fb0d.png?w=320" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/d7e691c5-25eb-433d-82a9-0d35f6b7fb0d.png?w=320&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/d7e691c5-25eb-433d-82a9-0d35f6b7fb0d.png?w=320" alt="image" loading="lazy"></picture></div><p><span><span>This functionality allows to keep any workspace clean, and the main use case is for large organizations managing tons of data. </span></span></p><p><span><span>Previously, when you shared access to a page with someone, they would automatically get access to all the subpages in it. Now when you open up a subpage you can see exactly what page it inherits permissions form ‚Äî and then change permissions for this specific subpage.</span></span></p><div id="block-87a9344e6a4a4313aaa9430e7ef34cdc"><picture><source srcset="https://api.super.so/asset/optemization.com/af87fb42-e8d3-4377-b5e7-d7eab0996d37.png?w=620&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/af87fb42-e8d3-4377-b5e7-d7eab0996d37.png?w=620" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/af87fb42-e8d3-4377-b5e7-d7eab0996d37.png?w=620&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/af87fb42-e8d3-4377-b5e7-d7eab0996d37.png?w=620" alt="image" loading="lazy"></picture></div><p><span><span>This is useful when you have private pages that live inside a larger page ‚Äî and you want to share the parent one without sharing these specific private pages. Think company's internal wiki with a subpage that contains sensitive data. </span></span></p><p><span><span>You can also add group permissions ‚Äî Notion team mentions the use case of giving Engineering team access to most of the workspace except a couple read-only pages.</span></span></p><p><span><span>Notion will now show you a "Show X records" option when working with database settings ‚Äî and will clip all the records above the number selected. Previously, if you had a huge database, it will display all the records in an infinite scroll as you move down the page ‚Äî this might have been okay for small databases, but quickly got hard to manage with additional information load.</span></span></p><p><span><span>Timeline view, page customization, advanced permissions and row number limits ‚Äî all of this seems to be targeting enterprise users, who need more control over large setups, Notion team is obviously hitting the nerve with big teams here. </span></span></p><p><span><span>Some features will also be handy for small teams and individual makers ‚Äî authors can use the timeline view to manage their content editorial, freelancers can use it to control their work load. Advanced customization is valuable for anyone who keeps data in Notion.</span></span></p><div id="block-35eebc7612e34ff79f23e056bf85977e"><div id="block-ca65c34a263e4c7881ef4767fca59df4"><p><span><span>The </span><span><em>Digital Opsessions</em></span><span> newsletter helps you figure out how to use digital productivity systems, tools and habits to free up time, energy and focus </span><span><span>for more important or fun </span></span><span>things in life.</span></span></p><p><span><span><strong>Subscribe + share</strong></span><span> </span><span><span><span>(if you haven't already)</span></span></span><span> üëâ</span></span></p></div></div></article></div></div></div>]]>
            </description>
            <link>https://optemization.com/timeline-view-notion</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061649</guid>
            <pubDate>Wed, 11 Nov 2020 19:05:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mathematicians Estimate Ethereum 2.0 Launch Date]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25061381">thread link</a>) | @npguy
<br/>
November 11, 2020 | https://doublespend.io/2020/10/28/breakthrough-mathematicians-estimate-ethereum-2-0-launch-date/ | <a href="https://web.archive.org/web/*/https://doublespend.io/2020/10/28/breakthrough-mathematicians-estimate-ethereum-2-0-launch-date/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

			
<article id="post-445">
	
				<p><a href="https://doublespend.io/wp-content/uploads/2020/10/eth2.jpg"><img width="800" height="445" src="https://doublespend.io/wp-content/uploads/2020/10/eth2-800x445.jpg" alt="" loading="lazy" srcset="https://doublespend.io/wp-content/uploads/2020/10/eth2.jpg 800w, https://doublespend.io/wp-content/uploads/2020/10/eth2-300x167.jpg 300w, https://doublespend.io/wp-content/uploads/2020/10/eth2-768x427.jpg 768w" sizes="(max-width: 800px) 100vw, 800px"></a>
								</p>
			
	<div>

		
		

		
		<div>
			
<p>A group of elite mathematicians have finally solved a problem that has puzzled millions of crypto folks for about two decades now. ‚ÄúIt took us about four years to get here, but man does it feel good‚Äù John Calculus, the lead mathematician, told DoubleSpend. </p>



<p>‚ÄúI was working on the P versus NP problem for about 10 years before moving onto solving two problems in parallel: discovering the largest prime number, and estimating the launch date of Ethereum 2.0. But when&nbsp;<a href="http://www.sciencedaily.com/releases/2013/02/130213225424.htm">Curtis Cooper beat me</a>&nbsp;to discovering the largest known prime number, I started focusing on the Ethereum 2.0 problem one hundred percent‚Äù a visibly excited John Calculus told our reporter.</p>
		</div>

	</div>

	</article>

		</div></div>]]>
            </description>
            <link>https://doublespend.io/2020/10/28/breakthrough-mathematicians-estimate-ethereum-2-0-launch-date/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061381</guid>
            <pubDate>Wed, 11 Nov 2020 18:41:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AndroWish ‚Äì run desktop Tcl/Tk programs almost unaltered on the Android Platform]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25061292">thread link</a>) | @jakobdabo
<br/>
November 11, 2020 | https://www.androwish.org/index.html/home | <a href="https://web.archive.org/web/*/https://www.androwish.org/index.html/home">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<tbody><tr><td>
<p>Tcl (Tool Command Language) is a very powerful but easy to learn dynamic programming language, suitable for a very wide range of uses, including web and desktop applications, networking, administration, testing and many more. Open source and business-friendly, Tcl is a mature yet evolving language that is truly cross platform, easily deployed and highly extensible.

</p><p>Tk is a graphical user interface toolkit that takes developing desktop applications to a higher level than conventional approaches. Tk is the standard GUI not only for Tcl, but for many other dynamic languages, and can produce rich, native applications that run unchanged across Windows, Mac OS X, Linux and more. 

</p><p>AndroWish allows to run desktop Tcl and Tk programs almost unaltered on the Android Platform while it opens the door to script a rich feature set of a mobile platform. Its sibling <a href="https://www.androwish.org/index.html/wiki?name=undroidwish">undroidwish</a> uses the same code base and  offers a similar feature set on various desktop and embedded platforms.

</p></td><td>
<img width="160px" height="160px" src="data:image/png;base64,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">
</td></tr>
</tbody></div><p>The current AndroWish-debug.apk can be downloaded <a href="https://www.androwish.org/download/AndroWish-c48f047f5b-debug.apk">here</a> (about 36 MByte, requires "install from unknown sources" in Android settings). Prehistoric versions are <a href="http://www.ch-werner.de/sdltk/AndroWish">still available here</a>.


</p></div>]]>
            </description>
            <link>https://www.androwish.org/index.html/home</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061292</guid>
            <pubDate>Wed, 11 Nov 2020 18:36:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Music-Related Copyright Claims and Twitch]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25061259">thread link</a>) | @haunter
<br/>
November 11, 2020 | https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/ | <a href="https://web.archive.org/web/*/https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-i18n="ba2fc6a46b864e1cc0b2afadb1eff0cf-content">
    <p>Creators, we hear you. Your frustration and confusion with recent music-related copyright issues is completely justified. Things can‚Äìand should‚Äìbe better for creators than they have been recently, and this post outlines our next steps to get there. Moving forward, we‚Äôll be more transparent with what‚Äôs happening and what tools and resources we‚Äôre building to help.</p>

<p>Copyright law and the DMCA are not small or simple topics, so this won‚Äôt be a brief post. We‚Äôll do our best to keep the legalese to a minimum, though there‚Äôs bound to be technical terms here and there.&nbsp;</p>

<h4 id="dmca-and-twitch"><strong>DMCA and Twitch</strong></h4>

<p>First off, a quick review of what DMCA actually is. The Digital Millennium Copyright Act (‚ÄúDMCA‚Äù) is a set of US laws that allows you to create and share content on digital service providers like Twitch. We comply with the DMCA and similar laws worldwide. Part of complying means that when a copyright holder thinks a streamer has used their content without permission, we have a process in place for them to be able to request the content be taken down.</p>

<p>When we receive a DMCA notification, we process the notification in accordance with our <a href="https://www.twitch.tv/p/legal/dmca-guidelines/">DMCA Guidelines</a>. This includes removing the content, sharing the details with the channel owner, and tracking the allegation.&nbsp;</p>

<p>DMCA takedown notifications can affect your ability to stream because we, as part of our efforts to comply with the DMCA and similar global laws, issue and track copyright strikes and ban the accounts of those who repeatedly infringe the copyrights of others.&nbsp;</p>

<p>This policy is important because we respect the rights of all creators, including those who create or record music, as well as the rights of those who own and control copyrights. As a company that is built around a community of people who create content, we take allegations of copyright infringement seriously.&nbsp;</p>

<h4 id="recent-dmca-notifications"><strong>Recent DMCA notifications</strong></h4>

<p>How did we get to this moment? Until May of this year, streamers received <strong>fewer than 50 music-related DMCA notifications each year</strong> on Twitch. Beginning in May, however, representatives for the major record labels started sending <strong>thousands of DMCA notifications each week</strong> that targeted creators‚Äô archives, mostly for snippets of tracks in years-old Clips. We continue to receive large batches of notifications, and we don‚Äôt expect that to slow down.&nbsp;</p>

<p>This means two things: 1) if you play recorded music on your stream, you need to stop doing that and 2) if you haven‚Äôt already, you should review your historical VODs and Clips that may have music in them and delete any archives that might.&nbsp;</p>

<p>We were as surprised by this sudden avalanche of notifications as many of you were. We also realized that we needed to provide streamers with more educational programs and content management tools to help you deal with this unprecedented number of notifications coming in all at once. So, while we continued to remove content targeted by these notifications as required by the DMCA, we understood VODs and Clips from years ago may not necessarily reflect your current approach to music. Therefore, we also paused the processing of strikes associated with these batched notifications in order to give you the tools, information, and time that you would need to deal with them.</p>

<p>We have analyzed the notifications we received during that period from the end of May through the middle of October. What we found is that more than 99% of the notifications were for tracks that streamers were playing in the background of their stream.&nbsp;</p>

<p>The point of the DMCA is to strike a balance between the interests of rights holders (the major record labels in this case) and creators. Because of this, we were compelled to delete the VODs and Clips that were identified in the notifications. This showed our commitment to upholding our obligations under the DMCA, while affording us the opportunity to sort out the best way to handle issuing strikes in these circumstances. Under these extraordinary circumstances, we recognized creators should have a reasonable chance to understand that content created in the past was being targeted as allegedly infringing and be given an opportunity to change their approach to music use before they got hit with strikes.</p>

<p>This led to the current situation, which is understandably frustrating and worrying for many of you. Given the circumstances, the warning email many of you received didn‚Äôt include all the information that you‚Äôd typically get in a DMCA notification (normally, when we receive a DMCA notification against your channel, we send you an email that includes information about the allegedly infringed work, who the claimant is, how the claimant can be contacted, and possible penalties under our repeat infringer policy, so that you can make an informed decision about whether to submit a counter notification or seek a retraction). We hear your feedback about how frustratingly little information we provided, and we should have made that warning email a lot more informative and helpful.</p>

<p>Over the last several months, we have done our best to manage this situation on behalf of both rights holders and creators. One of the mistakes we made was not building adequate tools to allow creators to manage their own VOD and Clip libraries. You‚Äôre rightly upset that the only option we provided was a mass deletion tool for Clips, and that we only gave you three-days notice to use this tool. We could have developed more sophisticated, user-friendly tools awhile ago. That we didn‚Äôt is on us. And we could have provided creators with a longer time period to address their VOD and Clip libraries ‚Äì that was a miss as well. We‚Äôre truly sorry for these mistakes, and we‚Äôll do better.</p>

<h4 id="how-to-avoid-dmca-notifications"><strong>How to avoid DMCA notifications&nbsp;</strong></h4>

<p>One important question we‚Äôve heard from you is: how can I stream safely and confidently on Twitch without having to worry about getting DMCA notifications from music use?</p>

<p>Most importantly, <strong>don‚Äôt play recorded music in your stream</strong> unless you own all rights in the music, or you have the permission of the necessary rights holder(s). Doing this is the best protection for your streams going forward. If you‚Äôre unsure whether you own all the rights, it‚Äôs pretty likely you don‚Äôt. If you want to include recorded music in your stream, use a fully licensed alternative like Soundtrack by Twitch, or other rights cleared music libraries such as Soundstripe, Monstercat Gold, Chillhop, Epidemic Sound, and NCS.</p>

<p>While we haven‚Äôt received more than a handful of DMCA notifications targeting in-game music, if you‚Äôre playing games with recorded music in them, we recommend you review their End User License Agreements (that wall of text at the beginning of a game) to see how the terms cover streaming with that music. One way to do this is to search for a game‚Äôs official EULA online and then do a ctrl+f (Command+f on Mac) search for words like ‚Äústream,‚Äù ‚Äúlicensed,‚Äù and ‚Äúmusic‚Äù to point you toward the correct sections. If you‚Äôre unsure about the rights, some games allow you to turn off music when streaming, or you can mute the game audio yourself. If neither of those apply, consider turning off VODs and Clips.&nbsp;</p>

<p>For your stream archives (VODs and Clips), right now your only options, if you think they contain unauthorized music, is to either go through them one by one, or, for Clips, use the ‚Äúdelete all‚Äù tool we‚Äôve provided. We understand both of these options have downsides, and we‚Äôre working to provide you more and better options as soon as possible. These things will take time to get right, and new challenges may appear in the future. Regardless, we‚Äôre committing here and now to investing in building better tools and keeping you posted on our progress.</p>

<h4 id="new-products-and-tools"><strong>New products and tools</strong></h4>

<p>Ever since the influx of DMCA notifications began, we have been working on building new (and improving existing) tools to help creators (such as the Clips mass deletion tool). This work is still happening. Many of these changes won‚Äôt be visible to the community, but we‚Äôre focused on three areas where we heard you need more support from us:</p>

<p>First, you don‚Äôt have enough control over the recorded content on your channel. We have made improvements to enable you to mass delete Clips, but in addition, we will (1) expand the use of technology to detect copyrighted audio, and (2) give you more granular ways to manage your archive instead of just a ‚Äúdelete all‚Äù option.</p>

<p>Second, we‚Äôll make it easier for you to control what audio from your live streams will show up in your recorded content. Soundtrack by Twitch has some of this technology built into it, and we‚Äôll work to make it available for everyone regardless of whether you want to use Soundtrack, for which we‚Äôve cleared all necessary rights, or music from others that provide rights-cleared music.</p>

<p>Third, we need to give you the ability to actually review your allegedly infringing content when you receive a DMCA notification, in addition to the details already provided in our takedown notifications - that is, information about what copyrighted work was allegedly infringed, who the claimant is, and how the claimant can be contacted. We also need to help you more easily file counter notifications if you believe you have the rights to use the content‚Äìfor example, because you‚Äôve secured a license, believe the use is a fair use,&nbsp; the claimant does not control the rights, or believe you have the right to use the music without permission.</p>

<p>Some of you have asked why we don‚Äôt have a license covering any and all uses of recorded music. We are actively speaking with the major record labels about potential approaches to additional licenses that would be appropriate for the Twitch service. That said, the current constructs for licenses that the record labels have with other services (which typically take a cut of revenue from creators for payment to record labels) make less sense for Twitch. The vast majority of our creators don‚Äôt have recorded music as a part of their streams, and the revenue implications to creators of ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/">https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/</a></em></p>]]>
            </description>
            <link>https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061259</guid>
            <pubDate>Wed, 11 Nov 2020 18:33:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nyxt Release 2 Pre-release 4]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25061101">thread link</a>) | @jmercouris
<br/>
November 11, 2020 | https://nyxt.atlas.engineer/article/release-2-pre-release-4.org | <a href="https://web.archive.org/web/*/https://nyxt.atlas.engineer/article/release-2-pre-release-4.org">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>Nyxt 2 Pre-release 4</title>
  
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->


<header>

</header>
<p>We are happy to announce the fourth pre-release of Nyxt version 2.0.0. If you missed the previous pre-release announcement, see <a href="https://nyxt.atlas.engineer/article/release-2-pre-release-3.org">here</a>.</p>
<p>Nyxt 2 is a massive overhaul of the Nyxt 1 series. A lot of effort has been geared towards improving the code quality under the hood which should reflect on the overall user experience with better performance, increased stability and better accessibility.</p>
<p>This is a test release for everyone to try out before the final release. It contains experimental features and some parts are still unfinished. Please feel free to share your feedback on our <a href="https://github.com/atlas-engineer/nyxt/issues">GitHub issue tracker</a>!</p>
<p>Notable highlights:</p>
<ul>
<li><p>Overhauled status area view to resemble powerline.</p>
<ul>
<li>Hold <code>shift</code> to scroll the tabs horizontally.</li>
</ul></li>
<li><p>New <code>dark-mode</code> (experimental).</p></li>
<li><p>New universal package manager interface.</p>
<p>Install, uninstall, describe packages, list their files, change generations, etc. See the various <code>*-package-*</code> and <code>*-generation-*</code> commands.</p>
<ul>
<li><p>Currently only interfaces the Guix package manager.</p></li>
<li><p>Help to implement additional backends is welcome!</p></li>
</ul></li>
<li><p>New <code>nowebgl-mode</code>.</p></li>
<li><p>New <code>nyxt-init-file</code> helper to derive a file name relative to the Nyxt configuration folder.</p></li>
<li><p>No longer ask to restore session when there is none.</p></li>
</ul>
<p>For the complete change list, please consult the <a href="https://github.com/atlas-engineer/nyxt/blob/2-pre-release-4/documents/CHANGELOG.org#2-pre-release-4">CHANGELOG.org</a> file.</p>
<p>We hope you enjoy these new features, and that they help make you more productive. Thanks for reading :-)</p>

<h2 id="nyxt-powerline">Nyxt Powerline</h2>
<p><img src="https://nyxt.atlas.engineer/static/image/article/status-area.png"></p>
<h2 id="package-manager">Package Manager</h2>
<p><img src="https://nyxt.atlas.engineer/static/image/article/describe-os-package.png"></p>
<p><img src="https://nyxt.atlas.engineer/static/image/article/git-package.png"></p>
<h2 id="dark-mode">Dark Mode</h2>
<p><img src="https://nyxt.atlas.engineer/static/image/article/wiki-normal.png"></p>
<p><img src="https://nyxt.atlas.engineer/static/image/article/wiki-dark.png"></p>


</div></div>]]>
            </description>
            <link>https://nyxt.atlas.engineer/article/release-2-pre-release-4.org</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061101</guid>
            <pubDate>Wed, 11 Nov 2020 18:21:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Raspberry Pi Homelab with Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 47 (<a href="https://news.ycombinator.com/item?id=25061097">thread link</a>) | @amitpm
<br/>
November 11, 2020 | https://amithm.ca/2020/10/kubernetes-raspberrypi-homelab/ | <a href="https://web.archive.org/web/*/https://amithm.ca/2020/10/kubernetes-raspberrypi-homelab/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>I‚Äôve been running <a href="https://pi-hole.net/">Pi-Hole</a> on a Raspberry Pi 3b wired into my wifi router for most of last year and its been great. So when the new Raspberry Pi 4 came out, I picked one up. It sits on my desk, mostly for easy access to its USB ports, which allows me to hook it up to some of my esp32 devkits and push micropython code onto them. The pi4 has been a great general purpose development environment.</p><p>Recently, I‚Äôve been wanting to write some trivial web endpoints for ‚Äúinternal‚Äù dashboards and such for the house. Plus, its a great excuse to learn Golang. In this day and age, clearly a dockerized golang dev environment is the way to go. Have I truly built something, if my dev environment isn‚Äôt dockerized?</p><p>So we‚Äôre agreed that dockerizing my dev environment is the way to go. Surely if my dev environment is dockerized, how much more should my app deployments use containers? Nothing less will do. But now I need a way to deploy and orchestrate said containers? I know! I should run a kubernetes cluster across my two Pi‚Äôs! Might as well run the Pi-hole on it as well, how hard can it be?</p><p>So that is what I spent the better part of last week figuring out.</p><figure><img src="https://imgs.xkcd.com/comics/automation.png" alt="Mandatory xkcd"><figcaption><center>Mandatory xkcd</center></figcaption></figure><p>This blog post walks through what I did, and how I did it, It‚Äôs purpose is two-fold -</p><ol><li>It is a map to allow me to retrace my steps if I need to</li><li>Perhaps it may prove of (dubious) use to you.</li></ol><p>So, both my Pi‚Äôs run Ubuntu server. I decided I should start from scratch, and flashed the latest ubuntu server image onto the SD cards for both Pi‚Äôs. Being a very optimistic person by nature, I expected to have Pi-hole back up and running on this new Kubernetes cluster within a day, and a day of unfiltered ads was a small price to pay for the experience. Alas, it was close to a week before I had Pi-Hole working on my network again, but yay! you get to learn from my experience!</p><p>I didn‚Äôt have much of an understanding of Kubernetes components going into this project - but hey, that‚Äôs what these projects are meant to give you, and boy, did it. So fret not if you don‚Äôt understand some of these terms, the kubernetes documentation pages are great!</p><p>None of this work is original. I cobbled together guides and walkthroughts from various sources to get to this frankenstein‚Äôs monster of a post that you see here. You can find links to the sources I used at the end of this page.</p><p>The first step to this journey involves making sure you have the required packages on all your machines. In my case, this was two machines - the Pi4 (called Terminus) and the Pi3b (called Trantor). You need <code>docker</code>, <code>kubelet</code>, <code>kubeadm</code> and <code>kubectl</code>. You want this installed on all your nodes. Terminus will be my master node, Trantor will be my worker. Asimov fans may protest that the Second Foundation was on Trantor after all, but let‚Äôs go with this for now. Setting static IPs on the master and workers on your cluster also helps, but I won‚Äôt cover that here.</p><p>Update apt repos and packages.</p><div><pre><code data-lang="bash">sudo apt-get update
sudo apt-get upgrade
</code></pre></div><p>Install Docker using the Convenience script. Yes, shame on you for blindly running a script you downloaded from the internet.</p><div><pre><code data-lang="bash">curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
</code></pre></div><p>Let‚Äôs make sure our non-root user can use Docker.</p><div><pre><code data-lang="bash">sudo usermod -aG docker $USER
</code></pre></div><p>Now there‚Äôs some additional setup that needs to be done in order to get Kubernetes to work on the Raspberry Pi - specifically enabling <code>cgroups</code>. You can do this by editing the file <code>/boot/firmware/cmdline.txt</code> and adding the following options at the end.</p><pre><code>cgroup_enable=cpuset cgroup_enable=memory cgroup_memory=1 swapaccount=1
</code></pre><p>You‚Äôll need to reboot the Pi after this.</p><p>Add the K8s apt repo.</p><div><pre><code data-lang="bash">curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -

cat <span>&lt;&lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list
</span><span>deb https://apt.kubernetes.io/ kubernetes-xenial main
</span><span>EOF</span>
</code></pre></div><p>You‚Äôll notice we‚Äôre using <code>kubernetes-xenial</code> which was the latest release at the time of writing this. Update this to the latest release available if you need to.</p><p>Let‚Äôs install our main K8s helpers. We‚Äôll also make sure they‚Äôre excluded freom any system upgrades. As the kubernetes <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/">documentation</a> says, ‚Äú<code>kubeadm</code> and <code>kubectl</code> require special attention to upgrade.‚Äù</p><div><pre><code data-lang="bash">sudo apt update <span>&amp;&amp;</span> sudo apt install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl
</code></pre></div><figure><img src="https://raw.githubusercontent.com/kubernetes/kubernetes/master/logo/logo.png" width="200" height="200"></figure><p>Create the cluster by running the following commands on the master node only. Pay special attention to the <code>--pod-network-cidr</code> parameter. You‚Äôll need this CIDR range later on when setting up Flannel.</p><div><pre><code data-lang="bash"><span># Create the bootstrap token</span>
TOKEN<span>=</span><span>$(</span>sudo kubeadm token generate<span>)</span>
sudo kubeadm init --token<span>=</span><span>${</span>TOKEN<span>}</span> --pod-network-cidr<span>=</span>10.10.0.0/16
</code></pre></div><p>Congratulations. You are now the proud owner of a bare-metal kubernetes cluster (with one node). Admire the output, and consider running the commands they ask you to. For example, you‚Äôll need a config file in <code>$HOME/.kube/config</code> if you want <code>kubectl</code> to work without too much hassle. Also make special note of the <code>kubeadm join</code> command as well, you‚Äôll need to run that on your worker nodes.</p><p>These are the commands that the output from the previous step suggest you to run. Run this on the master node, in case that isn‚Äôt clear.</p><div><pre><code data-lang="bash">mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown <span>$(</span>id -u<span>)</span>:<span>$(</span>id -g<span>)</span> $HOME/.kube/config
</code></pre></div><p>Go run the <code>kubeadm join</code> commands on all the worker nodes you‚Äôd like to dedicate to this cluster. I‚Äôll wait.</p><p>Going through this guide, you‚Äôll quickly become familiar with the command <code>kubectl apply</code>. This command ‚Äúapplies a configuration to a resource‚Äù in kubernetes parlance and is typically provided a YAML ‚Äúmanifest‚Äù file as parameter.</p><p>So now we have a cluster, but technically Kubernetes doesn‚Äôt know how to handle networking between any pods that are scheduled on this cluster - atleast, that‚Äôs what I‚Äôve understood. This is why you need an addon like Flannel to handle this for you. You can find a full list of Networking and Network Policy Addons <a href="https://kubernetes.io/docs/concepts/cluster-administration/addons/">here</a>. But in case it isn‚Äôt clear yet, we‚Äôll use Flannel.</p><figure><img src="https://raw.githubusercontent.com/coreos/flannel/master/logos/flannel-horizontal-color.png"></figure><p>If you‚Äôve specified a <code>pod-network-cidr</code> parameter when creating your cluster, you‚Äôll need to edit the Flannel manifest with this CIDR before you apply it to the cluster.</p><p>Let‚Äôs download the default flannel manifest</p><div><pre><code data-lang="bash">curl https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml --output kube-flannel-updated.yml
</code></pre></div><p>Open it the file up in your favourite editor, and find the key <code>net-conf.json</code>. Update the CIDR given there with the right CIDR for your cluster. Once done, apply the manifest like so.</p><div><pre><code data-lang="bash">kubectl apply -f ./kube-flannel-updated.yml
</code></pre></div><p>To check if this worked, run the following command to get all pods running on your cluster.</p><p>You should see <code>core-dns</code> and <code>kube-flannel</code> pods running like so. I have two pods for each because I have two nodes in my cluster.</p><div><pre><code data-lang="bash">NAMESPACE              NAME                                          READY   STATUS    RESTARTS   AGE
kube-system            coredns-f9fd979d6-h9m47                       1/1     Running   <span>1</span>          3d2h
kube-system            coredns-f9fd979d6-m5jrd                       1/1     Running   <span>1</span>          3d2h
kube-system            kube-flannel-ds-2ngxd                         1/1     Running   <span>1</span>          3d2h
kube-system            kube-flannel-ds-kqflv                         1/1     Running   <span>1</span>          3d2h
</code></pre></div><p>Namespaces are used to isolate pods and services running on the same cluster. My data engineer brain thinks of the cluster as a database and namespaces as schemas, but I could be mistaken and maybe should be thinking of the cluster as a single database install, and the namespaces as individual databases. Or maybe, this is entirely the wrong abstraction to bring in. Scratch all of this, let‚Äôs move on.</p><p>We now have a cluster, that knows how to handle pod networking. Let‚Äôs run something on it! How about the <a href="https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/">Kubernetes dashboard</a>, so that you have something pretty to show your non-technically inclined significant other as the output of your hard work?</p><figure><img src="https://raw.githubusercontent.com/kubernetes/dashboard/master/docs/images/dashboard-ui.png" alt="Behold! The fruits of your labour!"><figcaption><center>Behold! The fruits of your labour!</center></figcaption></figure><p>We‚Äôll create a namespace to hold everything related to the Kubernetes Dashboard. I‚Äôm calling the namespace - <code>kubernetes-dashboard</code>. Very imaginative, no?</p><div><pre><code data-lang="bash">kubectl create namespace kubernetes-dashboard
</code></pre></div><p>We‚Äôll now download the manifest file for Kubernetes dashboard, because we need to make some changes.</p><div><pre><code data-lang="bash">curl https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.4/aio/deploy/recommended.yaml --output kubernetes-dashboard.yaml
</code></pre></div><p>I spent a few days trying to figure out why the manifest did not work out of the box, it kept failing when trying to pull the docker image. I worked around this by doing two things -</p><ol><li>Ran <code>docker pull kubernetesui/dashboard:v2.0.0</code> to cache a local copy of the docker image.</li><li>Commented out the <code>imagePullPolicy: Always</code> in the manifest file under the <code>kubernetes-dashboard</code> deployment block.</li></ol><p>For the more K8s experienced among you, you may be wondering why I did not try using the Helm chart - I did. Kubernetes-dashboard needs to run two services - <code>dashboard-metrics-scraper</code> and <code>kubernetes-dashboard</code>. The Helm chart only seemed to bring up <code>kubernetes-dashboard</code>. I‚Äôm sure I must be doing something wrong, but at this point my patience was wearing thin and I just wanted to get on with it.</p><p>Ok, so now we have an edited manifest, let‚Äôs apply it.</p><div><pre><code data-lang="bash">kubectl apply -f kubernetes-dashboard.yaml
</code></pre></div><p>It takes a little bit of time for the dashboard to come up. You can amuse yourself by looking at the pods as they spin up as follows -</p><div><pre><code data-lang="bash">watch kubectl get pods -n kubernetes-dashboard
</code></pre></div><p>You can get details on a specific pod by running -</p><div><pre><code data-lang="bash">kubectl describe pod &lt;pod_name&gt; -n kubernetes-dashboard
</code></pre></div><p>You can also tail logs on a specific pod by running -</p><div><pre><code data-lang="bash">kubectl -n kubernetes-dashboard logs &lt;pod_name&gt; -f
</code></pre></div><p>Once you see the dashbaord services up and running, let‚Äôs figure out how we actually get access to the dashboard UI.</p><p>We‚Äôll assume that you haven‚Äôt configured kubectl on your local machine and are instead, running all these commands from your (headless) raspberry pi.</p><p>Run <code>kubectl proxy</code> first. This exposes the cluster API server over HTTP to the ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://amithm.ca/2020/10/kubernetes-raspberrypi-homelab/">https://amithm.ca/2020/10/kubernetes-raspberrypi-homelab/</a></em></p>]]>
            </description>
            <link>https://amithm.ca/2020/10/kubernetes-raspberrypi-homelab/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061097</guid>
            <pubDate>Wed, 11 Nov 2020 18:21:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Ultimate Guide to All in One CRM Solutions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25061084">thread link</a>) | @pstephenson5
<br/>
November 11, 2020 | https://1crm.com/ultimate-guide-all-in-one-crm-solutions/ | <a href="https://web.archive.org/web/*/https://1crm.com/ultimate-guide-all-in-one-crm-solutions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">

<div>
<div>
<div id="content" role="main">
<article id="post-43451">
<div><div><div><div><div>
<div>
<p><span>You‚Äôre in the right place If you‚Äôre looking to learn more about all in one CRM solutions. Please use the links below to read the full articles and discover more. We‚Äôll be adding more articles over the coming weeks so be sure to bookmark this valuable resource!</span></p>
</div>
<div id="ultimate-heading-11465faeb539340f4" data-hspacer="no_spacer" data-halign="left"><p data-ultimate-target=".uvc-heading.ultimate-heading-11465faeb539340f4 h2" data-responsive-json-new="{&quot;font-size&quot;:&quot;desktop:25px;&quot;,&quot;line-height&quot;:&quot;&quot;}"><h2>What is an All In One CRM?</h2></p></div>
<div>
<p><span>Learn which customer relationship management software is defined as an all in one CRM and what makes this different from other CRMs.</span></p>
</div>
<div id="ultimate-heading-72105faeb53935e60" data-hspacer="no_spacer" data-halign="left"><p data-ultimate-target=".uvc-heading.ultimate-heading-72105faeb53935e60 h2" data-responsive-json-new="{&quot;font-size&quot;:&quot;desktop:25px;&quot;,&quot;line-height&quot;:&quot;&quot;}"><h2>Who Needs an All In One CRM and Why?</h2></p></div>
<div>
<p><span>Now you know what an all in one CRM is, learn more about the size and type of organizations that can benefit. Use our simple decision flowchart to work out if an all in one CRM is right for you.</span></p>
</div>
</div></div></div></div><div><div><div><div><div id="ultimate-heading-46195faeb53936526" data-hspacer="no_spacer" data-halign="left"><p data-ultimate-target=".uvc-heading.ultimate-heading-46195faeb53936526 h2" data-responsive-json-new="{&quot;font-size&quot;:&quot;desktop:25px;&quot;,&quot;line-height&quot;:&quot;&quot;}"><h2>The Best All In One CRM Solutions in 2021</h2></p></div>
<div>
<p><span>We‚Äôve shortlisted 11 of the best all in one CRM solutions in the market today. Each review covers the product, its pricing, and pros and cons. We‚Äôve even added some recommendations based on some typical buying criteria organizations like yours use.</span></p>
</div>
<div id="ultimate-heading-52175faeb539367a3" data-hspacer="no_spacer" data-halign="left"><p data-ultimate-target=".uvc-heading.ultimate-heading-52175faeb539367a3 h2" data-responsive-json-new="{&quot;font-size&quot;:&quot;desktop:25px;&quot;,&quot;line-height&quot;:&quot;&quot;}"><h2>All in One CRMs and E-Commerce</h2></p></div>
<div>
<p><span>Understand the benefits of integrating an all in one CRM with your e-commerce store to make your operations seamless and efficient.</span></p>
</div>
<div id="ultimate-heading-76965faeb53938205" data-hspacer="no_spacer" data-halign="left"><p data-ultimate-target=".uvc-heading.ultimate-heading-76965faeb53938205 h2" data-responsive-json-new="{&quot;font-size&quot;:&quot;desktop:25px;&quot;,&quot;line-height&quot;:&quot;&quot;}"><h2>All in One CRM with Order Management</h2></p></div>
<div>
<p><span>Implementing an all in one CRM that includes order management offers you extensive business management benefits in the areas of Customer Service, Project Management, plus extended capabilities in your customer portal.</span></p>
</div>
<div id="ultimate-heading-15985faeb53938660" data-hspacer="no_spacer" data-halign="left"><p data-ultimate-target=".uvc-heading.ultimate-heading-15985faeb53938660 h2" data-responsive-json-new="{&quot;font-size&quot;:&quot;desktop:25px;&quot;,&quot;line-height&quot;:&quot;&quot;}"><h2>All in One CRM with a Customer Portal</h2></p></div>
<div>
<p><span>A self-service customer portal is a key part of any CRM implementation. And when you implement an all in one CRM your portal gets turbo-charged with an extensive set of additional capabilities!</span></p>
</div>
<div id="ultimate-heading-37425faeb5393882d" data-hspacer="no_spacer" data-halign="left"><p data-ultimate-target=".uvc-heading.ultimate-heading-37425faeb5393882d h2" data-responsive-json-new="{&quot;font-size&quot;:&quot;desktop:25px;&quot;,&quot;line-height&quot;:&quot;&quot;}"><h2>All in One CRM and Integrations</h2></p></div>
<div>
<p><span> Making sure that all of your business systems play well together is really important, but can potentially be so complex that it is a major distraction. One approach to minimizing the effort required on this front is the adoption of an All in One CRM. </span></p>
</div>
</div></div></div></div><div><div><div><div><div id="ultimate-heading-76325faeb5393a88a" data-hspacer="no_spacer" data-halign="left"><p data-ultimate-target=".uvc-heading.ultimate-heading-76325faeb5393a88a h4" data-responsive-json-new="{&quot;font-size&quot;:&quot;desktop:30px;&quot;,&quot;line-height&quot;:&quot;&quot;}"><h4>Get Your 1CRM 30-Day Free Trial</h4></p></div>
<div>
<div>
<p><span>Want to test drive 1CRM 8.6? Try it out for 30 days ‚Äì on us! </span></p>
<p><span>With no credit card required, you can sign up and be online within minutes!</span></p>
</div>
</div>
</div></div></div><div><div><div><div><div><p><img src="https://1crm.com/wp-content/uploads/2018/07/1CRM-8.5-laptop-500x289.png" data-src="https://1crm.com/wp-content/uploads/2018/07/1CRM-8.5-laptop-500x289.png" data-srcset="https://1crm.com/wp-content/uploads/2018/07/1CRM-8.5-laptop-500x289.png 500w, https://1crm.com/wp-content/uploads/2018/07/1CRM-8.5-laptop-1000x578.png 1000w" width="500" height="289" data-dt-location="https://1crm.com/whats-new-8-5/1crm-8-5-laptop/" alt="1CRM-laptop" srcset="https://1crm.com/wp-content/uploads/2018/07/1CRM-8.5-laptop-500x289.png 500w, https://1crm.com/wp-content/uploads/2018/07/1CRM-8.5-laptop-1000x578.png 1000w"></p></div></div></div></div></div></div>
</div> <div>
<p><img src="https://1crm.com/wp-content/uploads/2018/04/suzanne-pic--150x150.jpg" width="80" height="80" alt="Suzanne Louis" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2080%2080'%3E%3C/svg%3E" data-lazy-src="https://1crm.com/wp-content/uploads/2018/04/suzanne-pic--150x150.jpg"></p> <div>
<h4><span>Author:</span>&nbsp;Suzanne Louis</h4>
<p>Suzanne is an independent marketing consultant, in charge of product marketing at 1CRM Corp. Her responsibilities include web design and content, videos, social media, analytics, public relations, advertising, and the 1CRM Blog.</p>
</div>
</div>

</article>

</div>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://1crm.com/ultimate-guide-all-in-one-crm-solutions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061084</guid>
            <pubDate>Wed, 11 Nov 2020 18:20:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lyft, Netflix, Expedia, Slack, and Segment: Comparing DIY Cloud Cost Tools]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25061054">thread link</a>) | @CloudZero
<br/>
November 11, 2020 | https://www.cloudzero.com/blog/cloud-cost-management-tools | <a href="https://web.archive.org/web/*/https://www.cloudzero.com/blog/cloud-cost-management-tools">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        
        
        <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>Breakthroughs in engineering best practices often stem from a handful of top tech companies. &nbsp;</p>
<!--more-->
<p>Many of them share their behind-the-scenes stories at <a href="https://www.youtube.com/watch?v=ChupgIbZr5Q">conferences</a>, in <a href="https://blog.twitter.com/engineering/en_us/a/2013/observability-at-twitter.html">blogs</a>, and <a href="https://www.slideshare.net/reed2001/culture-1798664">slide decks</a> ‚Äî or <a href="https://netflix.github.io/chaosmonkey/">open source</a> code.</p>
<p>These companies invest millions of dollars and dedicated headcount in optimizing everything from uptime to engineering velocity ‚Äî so why wouldn‚Äôt you look to them for inspiration?</p>
<p>CloudZero is a company that enables engineering to build more profitable applications, so we thought it would be interesting to investigate and share how these top companies think about cloud cost ‚Äî and what kinds of cloud cost management tools they use and build. Luckily for us, a lot of them have blogged and spoken about it.</p>
<p>By the way, if you want to achieve results like these companies, without pulling your best engineers off your roadmap to build a homegrown system, <a href="https://www.cloudzero.com/platform">check CloudZero out</a>.</p>

<h2>Part 1: The Common Threads</h2>
<p>Before we dive in to the specifics, here are a few of the patterns that emerged across each DIY cloud cost management tool:</p>
<h3>They‚Äôve built cultures of cost-conscious engineering.</h3>
<ul>
<li>Top companies <a href="https://www.cloudzero.com/engineering-teams">decentralize cost management</a> to engineering teams. All of them have reported that when engineers have visibility into their spending, they make better decisions.</li>
<li>These companies know it‚Äôs all about balance between cost and velocity. An engineer shouldn‚Äôt spend hours on something to save five dollars. Cost visibility is all about making better decisions and tradeoffs ‚Äî not saving money at all costs.</li>
<li>They want <a href="https://www.cloudzero.com/engineering-teams">engineering teams to have autonomy and move quickly</a> ‚Äî and understand that‚Äôs a key pillar to move quickly. At the same time, many of them have built guardrails to control cost while they.</li>
</ul>
<h3>They view cost in context of business.</h3>
<ul>
<li>Their disruptive business models have been enabled by strong command of cost and unit economics. The reason why they have revolutionized their respective categories is that they deliver innovative solutions to customers in cost effective ways. To do this, they understand their <a href="https://www.cloudzero.com/blog/cloud-unit-economics">cloud unit economics</a>, like cost per ride or stream, and discuss cost in the context of their business.</li>
<li>They have built custom ways to make the data <a href="https://www.cloudzero.com/solutions/cost-per-customer">speak to the different stakeholders</a>, including leadership and individual dev teams.</li>
<li>They‚Äôve had to figure out ways to automate or supplement their tagging in order to be able to report on cost. They‚Äôve also allocated container spend in custom ways.</li>
</ul>
<h3>They are complex and customized, but all achieving similar outcomes.</h3>
<ul>
<li>Existing offerings weren‚Äôt enough. Cloud cost management tools ‚Äî at least the players you might see listed in the Gartner Magic Quadrant or Forrester Wave ‚Äî weren‚Äôt doing the trick. Their engineering teams have all adopted next generation practices and services ‚Äî and they needed a cost solution that could keep up.</li>
<li>These systems are an enormous amount of work and custom engineering. They have entire teams of full-time employees building these homegrown systems.</li>
</ul>


<h2>Part 2: The Homegrown Cloud Cost Management Tools</h2>

<p><img src="https://lh5.googleusercontent.com/kAplBll6TH9hj9tdoBc-wiySRwJX0oieyx1wGPTgf_vsiO3wDdCzPlrBh5n_X0WxucHwIf2WW2mXEfghckjD5GHYeK5oIA8EclrwCGN79VuoMLdau7wdA_FwQ7rkM9NmJLOu3XAB" width="139" height="69" alt="Lyft Logo"></p>
<p><strong><span>How We Know</span></strong></p>
<p>The Lyft team spoke at re:Invent in 2019 in a session called ‚ÄúManaging Your Cloud Financials as you Scale on AWS.‚Äù</p>
<p>You can watch it <a href="https://www.youtube.com/watch?v=ChupgIbZr5Q">here</a>. Lyft starts talking at around the 35 minute mark.</p>
<p><strong><span>How They Do It</span></strong></p>
<ul>
<li>Lyft has built a system of customized dashboards for all of their stakeholders, including leadership, engineering, and capacity planning.</li>
<li>Each engineering team lead has their own dashboard where they can drill in and investigate spend.</li>
<li>They measure cost per ride to track unit cost.</li>
<li>They have processing that sits on top of tags to be able to attribute spend to teams and projects.</li>
<li>They had to build a way to allocate container costs ‚Äî a project which was much more challenging than expected.</li>
</ul>
<p><strong><span>Cost Culture</span></strong></p>
<p>Lyft has said that once their engineers had visibility into what they were spending, they started to make better decisions around cost. Teams are now shown how much they spend compared to other teams, which has led to some good-spirited competition to reduce costs.</p>
<p><img src="https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-01.png?width=800&amp;name=cloud-cost-management-tools-01.png" width="800" alt="Lyft's Cloud Cost Management Best Practices" srcset="https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-01.png?width=400&amp;name=cloud-cost-management-tools-01.png 400w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-01.png?width=800&amp;name=cloud-cost-management-tools-01.png 800w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-01.png?width=1200&amp;name=cloud-cost-management-tools-01.png 1200w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-01.png?width=1600&amp;name=cloud-cost-management-tools-01.png 1600w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-01.png?width=2000&amp;name=cloud-cost-management-tools-01.png 2000w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-01.png?width=2400&amp;name=cloud-cost-management-tools-01.png 2400w" sizes="(max-width: 800px) 100vw, 800px"></p>
<p><em>A slide from the re:Invent presentation detailing Lyft‚Äôs custom cost management solution.</em></p>

<p><img src="https://lh3.googleusercontent.com/BKAFIAGWqHo0wrdlf__Sr-1RyiQqs8lN5VkU833O-Q7IDPwnSTspC7yATG5hZ-8lmDuHGPceHjIr3Ujx_nvy3zP5BfYWebmNxsIGr0wXEGH7Rtl5X19_A6rI0QsmFJCViIowisWm" width="175" height="117" alt="Netflix Logo"></p>
<p><span><strong>How We Know</strong></span></p>
<p>Netflix wrote a very detailed blog about their home grown efficiency and cost management system.</p>
<p>You can read it <a href="https://netflixtechblog.com/byte-down-making-netflixs-data-infrastructure-cost-effective-fee7b3235032">here</a>.</p>
<p><span><strong>How They Do It</strong></span></p>
<ul>
<li>Netflix has a ‚Äúa custom dashboard that serves as a feedback loop to data producers and consumers ‚Äî it is the single holistic source of truth for cost and usage trends for Netflix‚Äôs data users.‚Äù</li>
<li>They break down cost into ‚Äúmeaningful resource unit (table, index, column family, job, etc).‚Äù</li>
<li>They categorize AWS billing data by service, such as Amazon EC2 and Amazon S3. However, they have built custom ways to get further granularity into each.</li>
<li>They found AWS billing data was not granular enough for them, so they have built custom methods to align cost to the business metrics they care about like teams and products.</li>
<li>They provide optimization for some scenarios, such as storage.</li>
<li>They deliver cost alerts directly to their engineers.</li>
</ul>
<p><span><strong>Cost Culture</strong></span></p>
<p>Netflix sums up their approach as: ‚ÄúAt many other organizations, an effective way to manage data infrastructure costs is to set budgets and other heavy guardrails to limit spending. However, due to the highly distributed nature of our data infrastructure and our emphasis on freedom and responsibility, those processes are counter-cultural and ineffective.</p>
<p>Our efficiency approach, therefore, is to provide cost transparency and place the efficiency context as close to the decision-makers as possible.‚Äù</p>
<p><img src="https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-02.png?width=800&amp;name=cloud-cost-management-tools-02.png" width="800" alt="Netflix's Cloud Cost Management Best Practices" srcset="https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-02.png?width=400&amp;name=cloud-cost-management-tools-02.png 400w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-02.png?width=800&amp;name=cloud-cost-management-tools-02.png 800w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-02.png?width=1200&amp;name=cloud-cost-management-tools-02.png 1200w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-02.png?width=1600&amp;name=cloud-cost-management-tools-02.png 1600w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-02.png?width=2000&amp;name=cloud-cost-management-tools-02.png 2000w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-02.png?width=2400&amp;name=cloud-cost-management-tools-02.png 2400w" sizes="(max-width: 800px) 100vw, 800px"></p>
<p><em>A picture of Netflix‚Äôs dashboard that shows cost by organizational hierarchy. This kind of reporting helps give every team ownership of their cost.</em></p>


<p><strong><img src="https://lh4.googleusercontent.com/NFqGI195_7US8FTRoEbUYloGvtOaXxwOrIYgGBOPT--iAe5Et9VAI2mOJMW8_s_YI9M_eWkVEzkU_FAQTUF37FX5VmymWHs-3I5FhOGnLe8qlSdQ1BxRDZl2M_yaZAHnoyty_l3J" width="247" height="98" alt="Expedia Logo"></strong></p>
<p><strong><span>How We Know</span></strong></p>
<p>Expedia spoke at re:Invent in 2017. This is a few years old at this point, but Expedia was quite sophisticated, even back then. You can watch it <a href="https://www.youtube.com/watch?v=iOWNZqG0RN4&amp;feature=emb_logo">here</a>.</p>
<p><strong><span>How They Do It</span></strong></p>
<p>At the time of this presentation, they were just embarking on building their own custom tool to get the metrics they needed, so this is a bit light on the details of what they eventually built.</p>
<p>However, they did share that their cost optimization practices are:</p>
<ul>
<li>Automation to tag all resources</li>
<li>Visualization and monitoring tools</li>
<li>Measure, measure, measure</li>
<li>Leveraged RI pricing</li>
<li>Decentralized forecasting and planning process</li>
<li>Encouraged teams to share optimization best practices</li>
</ul>
<p><strong><span>Cost Culture</span></strong></p>
<p>In 2017, Expedia wasn‚Äôt just focusing on cost optimization. They were building ‚Äúcost transparency‚Äù for their engineering teams and decentralizing responsibility for cost management. One of the major changes they made was involving engineering teams in the forecasting and budgeting.</p>
<p><img src="https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-03.png?width=800&amp;name=cloud-cost-management-tools-03.png" alt="Expedia's Cloud Cost Management Best Practices" width="800" srcset="https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-03.png?width=400&amp;name=cloud-cost-management-tools-03.png 400w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-03.png?width=800&amp;name=cloud-cost-management-tools-03.png 800w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-03.png?width=1200&amp;name=cloud-cost-management-tools-03.png 1200w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-03.png?width=1600&amp;name=cloud-cost-management-tools-03.png 1600w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-03.png?width=2000&amp;name=cloud-cost-management-tools-03.png 2000w, https://www.cloudzero.com/hs-fs/hubfs/blog/cloud-cost-management-tools-03.png?width=2400&amp;name=cloud-cost-management-tools-03.png 2400w" sizes="(max-width: 800px) 100vw, 800px"></p>
<p><em>A slide from Expedia's Re:Invent talk in 2017.&nbsp;</em></p>


<p><img src="https://lh5.googleusercontent.com/NI7jOF1kxFDxmn_q3P-_70Gw251xlwBtnJXXk6YOtEOFy1-qkpIOX9pRCJN_tE_vdT7N1JQMS6S57rEi33S_KdoDSYmJgKrgFajCmTIdD3hLzAIr6C99i-S9YfyOWy8N7Yf905ue" width="228" height="58" alt="Slack Logo"></p>
<p><strong><span>How We Know</span></strong></p>
<p>Slack published a <a href="https://angel.co/company/slack/jobs/1025669-software-engineer-cloud-economics">job posting</a> for a cloud economics engineer. While it is not quite as extensive as the blogs and re:Invent talks, it still gives us a glimpse into what Slack does for cost management. We suspect this posting won‚Äôt last forever, so we pasted it into a document <a href="https://docs.google.com/document/d/1ZC9e3dhGrAcKXdQR5wTz8Dpg9ZGc-1-PimGsn-K-FZY/edit?usp=sharing">here</a>.</p>
<p><strong><span>How They Do It</span></strong></p>
<ul>
<li>Slack has a cloud economics engineering team composed of cloud engineers, financial analysts, and AWS subject matter experts working to make Slack more performant, available, and cost-efficient each day.</li>
<li>They are developing a new platform to provide engineering teams visibility into their cloud spend and efficiency.</li>
<li>They are building a home-grown chargeback system to ensure the correct service owners know the cost they place onto other systems.</li>
</ul>
<p>They monitor cloud spend, track and alert on changes over time.</p>
<p><strong><span>Cost Culture</span></strong></p>
<p>This about sums it up: ‚ÄúWe advise teams within Slack on how to maximize their value from the cloud and ultimately aim to build a culture where all our engineers are cost-conscious and building a business scalable for the long term. We get excited about making Slack cost-efficient whilst ensuring we use the right technology stack.‚Äù</p>


<p><strong><img src="https://lh5.googleusercontent.com/k2T9Lahj1hs0np6zRfTBUhtTEKY1HNxItg6ItI5O0wxAWg0RrlDD5p68IiYsTFf7opSlcgwo7_9JxF2AE2uJDpNHCzUxwcrxaHJxEXmpG5kbq7olC4zeMWNxHzHfCy2sLHgDZNHV" width="257" height="52" alt="Segment Logo"></strong></p>
<p><span><strong>How We Know</strong></span></p>
<p>Segment has written two blogs about how they do cost management.</p>
<p>You can check them out here:</p>
<ul>
<li><a href="https://segment.com/blog/the-million-dollar-eng-problem/">The Million Dollar Engineering Problem </a> (2017)</li>
<li><a href="https://segment.com/blog/the-10m-engineering-problem/">The Ten Million Dollar Engineering Problem </a> (2019)</li>
</ul>
<p>Both blogs focus on how they cut down existing costs to improve margins (which we‚Äôre guessing helped that really, really big <a href="https://techcrunch.com/2020/10/12/twilios-3-2b-segment-acquisition-about-helping-developers-build-data-fueled-apps/">acquisition number</a>). We‚Äôre going to focus more on how they do ongoing monitoring and proactively reduce spend, which is covered in the 2019 blog.</p>
<p><span><strong>How They Do It</strong></span></p>
<ul>
<li>Today, they monitor their spend on an ongoing basis, so they won‚Äôt have to worry about their margins creeping up on them anymore.</li>
<li>To get the ongoing visibility they need, Segment built a set of repeatable pricing drivers, calculated daily. The entire cost pipeline feeds into their Redshift instance, and they get daily monitoring on their ‚Äúcost drivers‚Äù, visualized in Tableau. They have now built custom alerting to detect spikes and send teams an email.</li>
</ul>
<p><span><strong>Cost Culture</strong></span></p>
<p>Segment lists 36 people who are part of their ‚Äúgross margin team.‚Äù It‚Äôs clear they‚Äôve helped their engineering team understand the value of building cost-effective products.</p>

<h2>Part 3: Intelligence vs. Management</h2>
<p>Each company uses slightly different terminology. Expedia and Netflix both say they‚Äôve built ‚Äúcost transparency,‚Äù for example. But what is more striking ‚Äî are the similarities.</p>
<p>Each team has built essentially the same solution to transform cloud cost from centralized and reactive to autonomous and proactive ‚Äî while integrating cost as a key metric in their development process. They have also found metrics that align to their business, so everyone from their CEO down to an individual engineer can make better decisions based on cost.</p>
<p>At CloudZero, we call this <a href="https://www.cloudzero.com/cloud-cost-intelligence">cloud cost intelligence</a>.</p>
<p>Cloud cost management is about reporting retroactively on how much you have spent. Cloud cost intelligence is about leveraging cost data to outperform your competition ‚Äî or know exactly what levers you can pull when times get tough.</p>
<p>These companies have wielded this power to their advantage to generate resilient growth ‚Äî and you can too.</p>

<h2>Add Cloud Cost Intelligence the Easy Way</h2>
<p>Here‚Äôs the ‚Ä¶</p></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cloudzero.com/blog/cloud-cost-management-tools">https://www.cloudzero.com/blog/cloud-cost-management-tools</a></em></p>]]>
            </description>
            <link>https://www.cloudzero.com/blog/cloud-cost-management-tools</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061054</guid>
            <pubDate>Wed, 11 Nov 2020 18:18:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacking Structured Interviewing: Hiring for Jobs You Don't Understand]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25061052">thread link</a>) | @nickpresta
<br/>
November 11, 2020 | https://mikedebo.com/work/2020/11/06/hacking-structured-interviewing-for-jobs-you-dont-understand/ | <a href="https://web.archive.org/web/*/https://mikedebo.com/work/2020/11/06/hacking-structured-interviewing-for-jobs-you-dont-understand/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Have you ever hired for a job you didn‚Äôt understand? It‚Äôs scary. If you don‚Äôt know how to do the job yourself, how can you assess what a strong candidate looks like?</p>

<p>In this post, we‚Äôll see how to modify a well-researched interview methodology to quickly build a process  that helps you hire for the unknown in 4 steps. And, in the spirit of incrementalism, you‚Äôll have something useful after each step.</p>

<!--more-->

<p>(This post was also published as a series of articles on LinkedIn. See part <a href="https://www.linkedin.com/pulse/hacking-structured-interviewing-hiring-jobs-you-dont-part-dibernardo/">one.</a>)</p>

<h2 id="different-people-same-problem">Different People, Same Problem</h2>

<p>A couple of weeks ago, I spoke to two very different people who had the same problem. The first was a senior engineering leader at a ~300 person company who needed to hire a data analytics lead, a role that was very unfamiliar to them. The second was a founder who was hiring their first software engineer.</p>

<p>They were pretty stressed about it. Perhaps you can relate.</p>

<p>In my experience, people tend to approach this problem in one of two ways:</p>
<ol>
  <li>‚ÄúWe don‚Äôt know how to hire for this position, and we could spend a lot of time creating an interview process that doesn‚Äôt even work. We should hire based on ‚Äòculture fit‚Äô, which we can figure out by getting to know them. Sometimes we have to take risks.‚Äù</li>
  <li>‚ÄúWe don‚Äôt know how to hire for this position, It would be very expensive to hire the wrong person. We should create an exhaustive interview that assesses everything needed in this role, since this is a foundational hire. We don‚Äôt want to take too many risks.‚Äù</li>
</ol>

<p>These are both natural reactions. Both have clear downsides, and my experience is that both can easily lead to bad hiring decisions. So, perhaps the lesson is that if these are your only options, it‚Äôs probably better to take the former!</p>

<p>However, I think we can do better.</p>

<p>With a few hours of work, we can build a process that:</p>
<ul>
  <li>Reduces hiring risk</li>
  <li>Reduces bias and unfairness</li>
  <li>Creates a good experience for both candidate and the interviewers</li>
</ul>

<p>Furthermore, you can have something <em>usable</em>‚Äînot great, but usable‚Äîin under an hour.</p>

<p>How will we do this?</p>

<p>Starting from scratch would take too long. Luckily, there‚Äôs a lot of research-based practice that we can hack to make a good first hire without prohibitive effort.</p>

<p>In this article, we‚Äôll look to and oldie-but-goodie as a guide.</p>

<h2 id="hacking-structured-interviewing">Hacking Structured Interviewing</h2>

<p>Structured interviewing is a hiring methodology that has been heavily researched and practices for decades. Google has summarized the research and their own experiences with it on <a href="https://rework.withgoogle.com/guides/hiring-use-structured-interviewing/steps/introduction/">re:work</a>, which is a super useful resource that I‚Äôve often referred to.</p>

<p>In their introduction to the topic, the writers state:</p>

<blockquote>
  <p>Structured interviewing simply means using the same interviewing methods to
assess candidates applying for the same job. Research shows that structured
interviews can be predictive of candidate performance, even for jobs that are
themselves unstructured.</p>
</blockquote>

<p>Sounds great! If we‚Äôre hiring this role for the first time, the job is likely to be pretty unstructured.</p>

<p>However, in the very next paragraph, we read:</p>

<blockquote>
  <p>So why don‚Äôt more organizations use structured interview questions? Well,
they are hard to develop. You have to write them, test them, and make sure
interviewers stick to them.</p>
</blockquote>

<p>Oof. And here I am assuring you this won‚Äôt take long. Maybe it‚Äôll just be easier to go with what you were originally planning. After all, how hard can it be?</p>

<p>Well:</p>

<blockquote>
  <p>Research has also shown that structured interviews aren‚Äôt more frequently used because, in general, interviewers everywhere think they‚Äôre good at interviewing and don‚Äôt need the help. Surely many of us like to think we‚Äôre excellent judges of character.</p>
</blockquote>

<blockquote>
  <p>But when it comes to hiring, don‚Äôt trust your gut. Research shows that during first encounters we make snap, unconscious judgments heavily influenced by our existing unconscious biases and beliefs. For example, in an interview context, without realizing it, we shift from assessing the complexities of a candidate‚Äôs competencies to hunting for evidence that confirms our initial impression. Psychologists call this <em>confirmation bias</em>.</p>
</blockquote>

<p>This cautionary clause helps us define our design problem.</p>

<p>We want to <em>quickly</em> create a hiring process that reduces our confirmation bias, because that will lead to better decisions.</p>

<p>The resources in re:work help with the confirmation bias part, but they don‚Äôt show us how to do it quickly. Let‚Äôs see how we can hack what they‚Äôve shown us to get some speed out of it.</p>

<h2 id="the-raw-materials">The Raw Materials</h2>

<p>There are a handful of <a href="https://rework.withgoogle.com/guides/hiring-use-structured-interviewing/steps/know-the-components/">key elements</a> to a structured interview:</p>

<ol>
  <li>A small set of <strong>competencies</strong> that we‚Äôre looking for from candidates.</li>
  <li>Standard <strong>questions</strong> that test those competencies.</li>
  <li>Comprehensive <strong>feedback</strong> gathered by interviewers asking the questions.</li>
  <li>A <strong>rubric</strong> that helps interviewers consistently deliver their feedback.</li>
</ol>

<p>That seems like a lot to consider. However, this short list helps focus our hacking on techniques that are known to work.</p>

<p>We‚Äôre going to transform this list into a 4-step recipe for your own structured interview process. In the spirit of incrementalism, you‚Äôll have something useful after each step.</p>

<p>If you follow the whole thing, it should take about 3-4 hours.</p>

<h2 id="step-1-define-competencies">Step 1: Define Competencies</h2>

<p>Take 15-30 mins. and come up with a list of 3-5 <em>competencies</em> that are important in this role.</p>

<p>It can be tempting to pick more than that, but please start small. If Google can reduce their hiring criteria to <a href="https://rework.withgoogle.com/guides/hiring-use-structured-interviewing/steps/define-hiring-attributes/">4 competencies</a>, I think we can get there too.</p>

<p>Each one should have a short 1-3 word ‚Äúslug‚Äù that captures its spirit, and a sentence or two to describe what it means in more detail.</p>

<p>If you‚Äôre not sure how to start, you can hack this boring-but-effective list:</p>

<ol>
  <li><strong>Technically Skilled.</strong> Has the hard skills and knowledge required to do the job well.</li>
  <li><strong>Effective Communicator.</strong> Talks about their work in a way that we understand and trust.</li>
  <li><strong>Has Soft Skills We Value.</strong> There are certain strengths or skills that each company uniquely values, so articulate this here.</li>
</ol>

<p>Each of these higher-level competencies can be broken down into more specific ones, but remember to keep the total to 5 or fewer.</p>

<p>To help with the hacking, let‚Äôs explore each of these suggested competencies a bit further.</p>

<h3 id="technical-skills">Technical Skills</h3>

<p>‚ÄúWait,‚Äù you may be thinking. ‚ÄúThe whole reason I‚Äôm reading this article is because I don‚Äôt know how to do this person‚Äôs job. Now you‚Äôre telling me to figure out how to assess their technical ability? What gives?!‚Äù</p>

<p>I know. It sucks. This will likely be the hardest competency for you to define. If you are hiring for a role that is the first of its kind in your company, you may not be able to describe it any more precisely than I already have, and that‚Äôs OK. We‚Äôll talk about some ways to manage this in the next step.</p>

<p>Most people in this position will get help from a teammate or other connection who knows the technicals of the job. This is especially true if you‚Äôre hiring a new leader to level-up a more junior team that is already doing the work.</p>

<p>Your role is to keep their ideas <em>focused</em>. This is important, because subject-matter experts can have a hard time keeping this list under control. I‚Äôve seen people struggle to pick fewer than 10 separate technical competencies that are important in their jobs.</p>

<p>You can help by finding ways to:</p>

<ul>
  <li>Coalesce competencies into larger areas of concern, and</li>
  <li>Eliminate things.</li>
</ul>

<p>If this is nerve-wracking, remember that time is always a constraint. More things on the list means longer interviews, and longer interviews mean less time for other important work. We‚Äôre not trying to cover every single thing that is important to the job; we‚Äôre trying to assess the most critical things with the time that we have.</p>

<h3 id="effective-communicator">Effective Communicator</h3>

<p>You may be unsurprised to find this in the list, but I want to highlight why I think this is especially important for a pioneering role.</p>

<p>If you‚Äôre creating a new kind of job in your team‚Äîeven if it already exists somewhere else at your company‚Äî it‚Äôs really important that you can trust this person to furnish you with information in a way that helps you make effective decisions.</p>

<p>When we‚Äôre hiring for something new, we can get so focused on the person‚Äôs ability to do the job that we lose sight of how important it is for everyone to meaningfully understand <em>how the work is going</em>. This is especially important if this person is responsible for building an entirely new competency within the company, because it‚Äôs hard for new things to build momentum without understanding and trust.</p>

<p>To summarize: It‚Äôs important that this person can do the job. It‚Äôs also super important that they can explain it to you and others in a way that‚Äôs easy to understand. This understanding creates trust, and trust fuels meaningful results.</p>

<h3 id="has-soft-skills-we-value">Has Soft Skills We Value</h3>

<p>I once spoke to a founder who was looking for people who were ‚Äúnaturally inquisitive.‚Äù That sounded off to me, because it requires more than testing for curiosity; it requires us to determine whether that curiosity is <em>intrinsic</em>.</p>

<p>I asked for a concrete example of what ‚Äúnatural inquisitiveness‚Äù looked like. They said: ‚ÄúWell, at the lunch table, we‚Äôll often have big debates about political or social issues. These are really fun, because people won‚Äôt just state their thoughts: They‚Äôll try to find the logical arguments or fallacies behind the different positions. It‚Äôs not just an emotional conversation. We‚Äôre always looking to verify the underlying principles.‚Äù</p>

<p>From this starting point, we were eventually able to articulate the ‚Äúsoft skill‚Äù that they were looking for: A good candidate would <em>effectively apply the scientific method to everyday problems</em>.</p>

<p>This re-framing improves on the original in several ways:</p>

<ul>
  <li>It‚Äôs easier to assess than ‚Äúnaturally inquisitive‚Äù.</li>
  <li>It has less to do with <em>identity</em> and more to do with <em>ability</em>.</li>
  <li>It connects to a unique part of the company‚Äôs history, which was founded by scientists out of a university research project.</li>
</ul>

<p>Because first-time hires tend to be fraught with risk, I find that interviewers naturally want to latch onto something that helps ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mikedebo.com/work/2020/11/06/hacking-structured-interviewing-for-jobs-you-dont-understand/">https://mikedebo.com/work/2020/11/06/hacking-structured-interviewing-for-jobs-you-dont-understand/</a></em></p>]]>
            </description>
            <link>https://mikedebo.com/work/2020/11/06/hacking-structured-interviewing-for-jobs-you-dont-understand/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061052</guid>
            <pubDate>Wed, 11 Nov 2020 18:18:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Overview of 3D meshing methods using open source tools]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25060942">thread link</a>) | @alibabaSX
<br/>
November 11, 2020 | https://www.sesamx.io/blog/3d_mesh_with_free_tools/ | <a href="https://web.archive.org/web/*/https://www.sesamx.io/blog/3d_mesh_with_free_tools/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <div>
    <div>
      <article role="main">
        

<p>The Internet is full of beautiful 3D mesh examples, but it is difficult to get clues
about how they were constructed. In fact, <strong>creating a good 3D mesh can be very
painful without the right tools or training</strong>. Furthermore, most of commercial
pre-processing software have been improving and propose powerful 3D meshing algorithm,
capable of building hybrid or full hexahedron mesh. <strong>The aim of
this article is to give an overview of the constraints involved when building
a 3D mesh for structural finite element, as well as exposing various meshing
methods relying on free and open source tools</strong>.</p>

<h2 id="introduction">Introduction</h2>

<p>Before we start, let‚Äôs give some background information about 3D mesh
construction. Usually a 3D mesh can be composed of 4 types of elements:</p>

<ul>
<li><p>tetrahedron (4 corners),</p></li>

<li><p>wedge (6 corners),</p></li>

<li><p>hexahedron (8 corners),</p></li>

<li><p>and rarely pyramids (5 corners).</p></li>
</ul>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/3d_mesh_element_types.png" alt="3D mesh element types"></p>

<p><strong>The goal is to get a mesh with the lowest number of
degrees of freedom (‚Äúdofs‚Äù), while maintaining a good representative capability</strong>.
We may be
tempted to race for tetrahedrons, which have only 4 nodes (for a linear
element). But reality is more involved: <strong>certain types of elements behave better
than others</strong>. Without entering to much into the details, we can provide some hints
about this:</p>

<ul>
<li><p><strong>4-node tetrahedron (linear element) must be avoided as mush as possible</strong>. It
behaves poorly and a lot of them are needed to get meaningful results. If you
have no other choice, try to convert them to 10-node tetrahedron which is much
better.</p></li>

<li><p>if you want to stay with linear elements, <strong>you must aim towards hexahedron</strong>. Most
finite element software (you can guess that SesamX is part of them) propose an
improved version of the hexahedron element. That makes it a better choice than
the other elements.</p></li>

<li><p><strong>6-node wedge (linear element)</strong> is better than 4-node tetrahedron but worse than
8-node hexahedron. <strong>It is ok to use them, but go for hexahedron wherever possible</strong>.</p></li>

<li><p>I have not tested the pyramid enough to give relevant advice. Nevertheless,
from the fact that this element is seldom used in 3D mesh, this article will not
shed light on it.</p></li>
</ul>

<p>It is easy to build a full tetrahedron mesh using an automatic mesher
(and it is widespread among various software). On the contrary, <strong>full hexahedron or
hybrid automatic meshers are more involved and harder to find</strong> (you can find them
among commercial solutions but almost not among free ones).</p>

<p><strong>However, using only free and open source tools, we are still able to build
quality 3D meshes</strong>.</p>

<p>The remaining of <strong>this article exhibits 4 methods to build 3D meshes using Salome or
Gmsh</strong>. The goal is not to enter into every detail about the options used, but to
give an overview of how 3D meshes can be built. Whatever the tool we use, changing
the element order is usually a trivial task (either linear or quadratic).
Therefore I will not detail it here. Instead, <strong>I will focus on controlling the
element shapes while meshing</strong>.</p>

<p>For each method, I provide a step by step guide with illustrative screenshots. And, when
appropriate, I also provide the final result file that you can edit and modify
on your own.</p>

<h2 id="geometry-used">Geometry used</h2>

<p>I will use the following con rod to showcase how to build each mesh.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/con_rod_geometry.PNG" alt="Con rod geometry"></p>

<p>One important feature to mention here, is that <strong>this con rod geometry is made of
a compound of 3 solids</strong> (this reason will make sense when talking about the hybrid
mesh generation method) corresponding to each color on the image above.</p>

<p>You can find the corresponding step file
<a href="https://www.sesamx.io/blog/files/008_3d_mesh_with_free_tools/con_rod_to_mesh.step">here</a>.</p>

<h2 id="full-tetrahedron-automatic-meshing-method">Full tetrahedron automatic meshing method</h2>

<p>As mentioned before, <strong>it is pretty straightforward to get a full tetrahedron<br>
mesh</strong>. To build this mesh, we use <strong>Salome</strong>.</p>

<p>First, we go to the geometry module and import the step file. The Salome tree
should look like this:</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/salome_import_tree.PNG" alt="Salome import tree"></p>

<p>Then we have to explode the compound geometry into its 3 sub-solids and create a
partition from these solids. <strong>This step is necessary to ensure that Salome will merge
coincident nodes from each solid faces</strong>. The result tree is then:</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/salome_partition_tree.PNG" alt="Salome partition"></p>

<p>Next we go to the mesh module, and create a new mesh on the partition. Under
algorithm we can select ‚ÄúNETGEN 1D-2D-3D‚Äù and under hypothesis ‚ÄúNETGEN 3D
Simple Parameters‚Äù. Finally we have to input the edge size that our elements should
have.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/tetrahedron_mesh_parameters.png" alt="Salome tetrahedron mesh parameters"></p>

<p>Eventually we have to right click on the mesh and hit ‚ÄúCompute‚Äù. The mesh should
look like this:</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/tetrahedron_mesh.PNG" alt="Salome tetrahedron mesh"></p>

<p>As you can see, the mesh is made of tetrahedron but also triangles and edges
elements. To get rid of the 2D and 1D elements, the first step is to
click on the mesh and select ‚ÄúCreate Group‚Äù. A panel appear and we can create one
group containing all the 2D elements (as shown on the picture below) and
similarly for the 1D elements.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/salome_create_group.png" alt="Salome create group"></p>

<p>Next to delete these elements, we have to right
click on each group and select ‚ÄúDelete Group with Content‚Äù. <strong>And we get
the following full tetrahedron mesh</strong>.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/final_tetrahedron_mesh.PNG" alt="Salome final tetrahedron mesh"></p>

<p>Finally, <strong>to check that the mesh does not contain any duplicated nodes</strong> we have to
select the mesh and use ‚ÄúControls / Node Controls / Double Nodes‚Äù.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/full_tet_double_nodes.PNG" alt="Tetrahedron duplicated nodes check"></p>

<p>If you want to manipulate this mesh, you can find the corresponding Salome database
<a href="https://www.sesamx.io/blog/files/008_3d_mesh_with_free_tools/full_tet_con_rod.hdf">here</a>.</p>

<h2 id="full-hexahedron-automatic-meshing-method">Full hexahedron automatic meshing method</h2>

<p>Next come the full hexahedron mesh. To build this mesh, we use <strong>Gmsh</strong>.</p>

<p>First, <strong>it is necessary to create a volume physical group containing the 3
solids of the model. It ensure afterwards that the mesh export will, in fact,
export only the 3D elements.</strong></p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/gmsh_volume_physical_group.PNG" alt="Gmsh volume physical group"></p>

<p>Next we go to ‚ÄúTools / Options‚Äù then ‚ÄúMesh / General‚Äù to select the meshing
parameters. We can
choose whatever makes it for the 2D algorithm, 3D algorithm and 2D recombination
algorithm. These parameters influence how the mesh is built, feel free to change
them to notice the difference in the mesh. As a first guess, we can
stay with ‚ÄúDelaunay‚Äù and ‚ÄúBlossom‚Äù. However, <strong>make sure to select ‚ÄúAll Hexas‚Äù as the
‚ÄúSubdivision algorithm‚Äù so that the volumes will be filled with hexahedron only.</strong></p>

<p>Finally under ‚ÄúMin/Max element size‚Äù we can fix the element size.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/gmsh_meshing_parameters.PNG" alt="Gmsh meshing parameters"></p>

<p>Eventually, we have to go back to the Gmsh tree and click ‚Äú3D‚Äù under ‚ÄúMesh‚Äù to
build the mesh.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/gmsh_mesh_creation.png" alt="Gmsh mesh creation"></p>

<p>We can check the mesh content under ‚ÄúTools / Statistics‚Äù. As you can see, the mesh
is made of 1D, 2D and 3D-hexahedron elements. <strong>Because we have created a physical
group for the 3 volumes, only the 3D mesh will be exported.</strong></p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/final_hexaedron_mesh.PNG" alt="Gmsh mesh creation"></p>

<p>If you have troubles visualizing the 3D elements, you can adjust the visibility
parameters in the ‚ÄúMesh‚Äù options window under the ‚ÄúVisibility‚Äù tab.</p>

<p>Unfortunately, there is a trap here. <strong>The mesh obtained has duplicated nodes</strong>
at the interfaces between the 3 solids. To visualize them, we can export the mesh
as a .med file, import it in Salome, and use the ‚Äúdouble nodes‚Äù tool mentioned
previously.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/full_hexahedron_duplicated_nodes.PNG" alt="Hexahedron duplicated nodes"></p>

<p>Finally, to solve this issue, we have to use the ‚ÄúMerge Nodes‚Äù tool under
‚ÄúModification / Transformation‚Äù.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/full_hexahedron_remove_duplicated.PNG" alt="Hexahedron remove duplicated nodes"></p>

<h2 id="hybrid-meshing-method">Hybrid meshing method</h2>

<p>Next <strong>I am showcasing how to build an efficient hybrid mesh with Salome.</strong> This
method is my favorite because <strong>it leads to a well structured mesh, which can
capture more efficiently the details of the geometry</strong> (if you have a close look
to the automatic tetrahedron and hexadreon meshes, you can see that the fillet
is not always ‚Äúwell captured‚Äù for instance). The drawback of this method is that it does not
lead to a full hexahedron mesh but an hybrid mesh made with a majority of
hexahedrons, and a minority of wedges used to fill gaps.</p>

<p><strong>The 3D mesh will be built first by meshing 2D surfaces and then by extruding
them.</strong> To make this process workable, the geometry has been split into 3 solids
beforehand. Each of these solids can then be meshed as an extrusion of the surface
meshes.</p>

<table>
<thead>
<tr>
<th><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybride_mesh_solid_1.PNG" alt="Solid 1"></th>
<th><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybride_mesh_solid_2.PNG" alt="Solid 2"></th>
<th><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybride_mesh_solid_3.PNG" alt="Solid 3"></th>
</tr>
</thead>

<tbody>
<tr>
<td><center><em>Solid 1</em></center></td>
<td><center><em>Solid 2</em></center></td>
<td><center><em>Solid 3</em></center></td>
</tr>
</tbody>
</table>

<p>As explained for the full-tetrahedron mesh, <strong>we first need to explode the
compound geometry and build a partition.</strong></p>

<p>Then, in order to build the 2D meshes on the surfaces and the 3D extrusion meshes,
we need to extract (using explode) the relevant geometries from this partition:</p>

<ul>
<li>the 3 solids geometries,</li>
<li>the top face of solid 1 (red face on solid 1 image), that will drive the
3D mesh on solid 1,</li>
<li>the ‚Äúfillet face‚Äù of solid 2 and 3 (red face on solid 3 image) that will drive
the 3D mesh on solid 2 and solid 3.</li>
</ul>

<p>The Salome tree should look like this:</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/salome_partition_tree_hybrid.PNG" alt="Salome tree for hybrid mesh"></p>

<p>Next, we go to the mesh module. The meshing process is the following:</p>

<ul>
<li><p>Create a mesh object and assign default 3D mesh parameters to the whole
partition,</p></li>

<li><p>Create 2 sub-meshes for the 2 surfaces to mesh,</p></li>

<li><p>Create 3 sub-meshes for the 3 solids to mesh.</p></li>
</ul>

<p><strong>The default 3D meshing parameters will not be used while computing the mesh,
because the sub-meshes definition will cover the whole partition.</strong> Nevertheless, Salome
still requires these default parameters.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/tetrahedron_mesh_parameters.png" alt="Salome import tree"></p>

<p>To create the faces sub-meshes, we have to right click on the mesh and
select ‚ÄúCreate Sub-mesh‚Äù. We then need to select one of the faces and choose the
‚ÄúNETGEN 1D-2D‚Äù
algorithm with ‚ÄúNETGEN 2D Simple Parameters‚Äù. Then we can input the element size
and <strong>make sure to check ‚ÄúQuad-dominated‚Äù (to avoid at most triangles)</strong>.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/face_submesh_parameters.png" alt="Salome face submesh parameters"></p>

<p>To compute the sub-mesh, we have to right click on it and select ‚ÄúCompute
Sub-mesh‚Äù. And we repeat these operations for the second face.</p>

<p><strong>Creating the 3D sub-meshes is similar.</strong> Once we have selected the solid to mesh,
we choose ‚ÄúExtrusion 3D‚Äù as the meshing algorithm and no hypothesis needs to be associated.
However, we have to provide the 1D algorithm and hypothesis to define
how the mesh extrusion should behave.</p>

<p>We select ‚ÄúWire Discretisation‚Äù as the 1D algorithm, and the previous local length
used for the 2D sub-meshes as the hypothesis.</p>

<table>
<thead>
<tr>
<th><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybrid_3d_submesh_parameters.png" alt="Hybrid 3D submesh parameters"></th>
<th><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybrid_1d_submesh_parameters.png" alt="Hybrid 1D submesh parameters"></th>
</tr>
</thead>

<tbody>
<tr>
<td><center><em>3D submesh parameters</em></center></td>
<td><center><em>1D submesh parameters</em></center></td>
</tr>
</tbody>
</table>

<p>We repeat this for the 2 other solids. The mesh tree should look like this:</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybrid_mesh_tree.PNG" alt="Salome hybrid mesh tree"></p>

<p><strong>Before computing the mesh, we need to tell Salome in which order the sub-meshes
should be computed.</strong> To avoid meshing conflict while extruding, it is best in
our case, to fully mesh solid 1 before meshing the driving surface of solid 2
and solid 3. We have to right click on the mesh and select ‚ÄúChange sub-mesh Priority‚Äù.
The meshing order should be the following:</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybrid_mesh_order.PNG" alt="Salome hybrid mesh tree"></p>

<p>After ‚Ä¶</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.sesamx.io/blog/3d_mesh_with_free_tools/">https://www.sesamx.io/blog/3d_mesh_with_free_tools/</a></em></p>]]>
            </description>
            <link>https://www.sesamx.io/blog/3d_mesh_with_free_tools/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060942</guid>
            <pubDate>Wed, 11 Nov 2020 18:07:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remote Work: 5 Tips for Finding the Best Remote Jobs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25060843">thread link</a>) | @martin_crd
<br/>
November 11, 2020 | https://remoteworkers.net/blog/5-tips-for-finding-best-remote-jobs | <a href="https://web.archive.org/web/*/https://remoteworkers.net/blog/5-tips-for-finding-best-remote-jobs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The pandemic has caused an enormous shift in the way the world works. Companies had to adapt, and we see that <strong>remote working</strong> has become a reality for many employees. Many people are now considering if this transition could be a more permanent work situation after the Covid crisis is over and asking: What if I could work remotely forever?</p><p>If you are thinking about taking the plunge, here are the best tips for you to find the best <strong>remote jobs</strong>:</p><h2>1) Is this the Right kind of Job for You?</h2><p><strong>Remote work</strong> is not for everybody, some people thrive in an office environment, and others easily succeed in working remotely. Be honest and ask yourself which one are you. Only you can define if it is a fit for your work and lifestyle.</p><h2>2) Get to know the remote work community</h2><p>Most job sites don‚Äôt have a very good ‚Äúremote work‚Äù filter, but that has changed in the past couple of years with more platforms out there advertising exclusively for remote jobs.</p><p>Once you start your search it‚Äôs important to understand the differences between fully and partially distributed companies. A fully distributed company is one in which everyone in the company works remotely. Partially distributed companies are any companies with one or more remote workers, also known as ‚Äúremote-friendly‚Äù or ‚Äúremote-flexible‚Äù.&nbsp;</p><p>But why does that matter?</p><p>Most fully distributed companies have solid onboarding systems and ongoing training programs, so you‚Äôll be set up for success. There are also many partially distributed companies that have successfully integrated a remote workforce. Keep that in mind while searching for a position and ask about it in the interview process.</p><h2>3) Know What Remote Employers Are Looking For</h2><p>Trustworthy people that truly love their work are, by far, the most important traits that employers are looking for in a candidate for a remote job position.</p><p>It seems pretty obvious if you consider that they need to trust that each team member will do their job, as well as create high-quality work, all outside an office environment. If you‚Äôre not motivated to work, you likely won‚Äôt succeed if no one is looking over your shoulder. Show your remote interviewer how much you care about your work;&nbsp; it will definitely resonate with them.</p><h2>4) Tailor your resume for remote job applications.</h2><p>To land an interview, your resume needs to be tailored to remote companies. Consider including the following points to stand out to remote employers:</p><p><strong>List all important tools:</strong> software tools that you are familiar with using are great to mention. Remote companies are very dependent on these tools to assure that the work and communication flows. Some examples: Slack, Google Hangouts, Trello,&nbsp; Zoom, etc.</p><p><strong>Communication:</strong> Remote companies fail because of bad communication, consequently they look to hire amazing communicators. Your resume should talk about your communication skills, and your email communication with hiring managers and recruiters should be impeccable.</p><p><strong>Autonomy:</strong> Any time you worked with low or no supervision is valuable and will be well noticed on your resume.</p><h2>5) Take Timezone and Location into consideration</h2><p>Looking to start <strong>working remotely</strong> for a company that has its team spread around the globe sounds exciting, but pay attention to the working hours and what your working schedule would look like. Some companies offer total flexibility and you only have to consider their time zone in case of a virtual team meeting from time to time.</p><p>This might be very different for other companies, in which your "online presence" will be expected according to the time zone of where the company has its headquarters. It's easy if you live in Portugal, applying for a remote position in a french company.&nbsp; Figuring out a good time for a meeting from Lisbon while the rest of your team is based in Tokyo might be a much more complicated task. Pay attention to these details while searching for the perfect remote job for you.</p><p>The <strong>remote job</strong> application is not harder but indeed a bit different from other traditional office jobs. To stand out from other candidates, it‚Äôs imperative that you immerse yourself in the remote community and show passion for your work.</p><h2>Are you ready?</h2><p>Start now looking for your dream remote job at a remote-friendly company looking to hire the best talent, join <a href="https://remoteworkers.net/signup">Remote Workers</a> today!</p></div></div>]]>
            </description>
            <link>https://remoteworkers.net/blog/5-tips-for-finding-best-remote-jobs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060843</guid>
            <pubDate>Wed, 11 Nov 2020 17:58:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Datasaur (YC W20) CEO Ivan on how to build/label NLP data]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25060816">thread link</a>) | @cl42
<br/>
November 11, 2020 | https://phaseai.com/resources/datasaur-label-build-nlp-datasets | <a href="https://web.archive.org/web/*/https://phaseai.com/resources/datasaur-label-build-nlp-datasets">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
   <div>
     <div>

     <p>&nbsp;

<iframe src="https://player.vimeo.com/video/477875501?title=0&amp;byline=0&amp;portrait=0" width="640" height="360" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe>

     </p><h3>Best Practices for NLP Data Collection and Design</h3>
     <p><i>Ivan Lee on November 10, 2020</i>

     </p><p>You can't build NLP-powered products and services without robust, detailed data sets. Unfortunately, building such data sets can be time consuming and expensive; a poorly designed data set will also prevent your models from actually helping users. Ivan Lee is the CEO and founder of <a href="https://datasaur.ai/" target="_blank">Datasaur</a>, which provides an end-to-end solution for labeling data and using it to build and train NLP-powered models and products. He will discuss best practices for data set design and labelling.
     
     </p><p>Datasaur recently raised <a href="https://techcrunch.com/2020/09/29/datasaur-snags-3-9m-investment-to-build-intelligent-machine-learning-labeling-platform/" target="_blank">$3.9M to build their NLP data platform</a>, and the company is part of Y Combinator's Winter 2020 batch.

     </p></div>
   </div>
</div></div>]]>
            </description>
            <link>https://phaseai.com/resources/datasaur-label-build-nlp-datasets</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060816</guid>
            <pubDate>Wed, 11 Nov 2020 17:56:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fixing leaky logs: how to find a bug and ensure it never returns]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25060456">thread link</a>) | @pabloest
<br/>
November 11, 2020 | https://r2c.dev/blog/2020/fixing-leaky-logs-how-to-find-a-bug-and-ensure-it-never-returns/ | <a href="https://web.archive.org/web/*/https://r2c.dev/blog/2020/fixing-leaky-logs-how-to-find-a-bug-and-ensure-it-never-returns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><blockquote>
<p><strong>TL;DR</strong> I lay out a case for moving security enforcement into the hands
of developers. I show how I and another developer at r2c successfully identified data
leakage in our logs, fixed the issue, and prevented it from happening in the
future. We did this <em>in a matter of hours, without assistance from our AppSec team</em>.</p>
</blockquote>
<h2>Introduction</h2>
<p>As a developer and engineering manager, I‚Äôve become obsessed with finding ways
to rapidly solve security issues across the engineering organization without ever
needing to fully involve our security team.</p>
<p>Why is this important? I see multiple benefits:</p>
<ul>
<li>Fixing security issues is <em>fast</em>. So fast, in fact, that we can solve them in
minutes after identifying them, without security issues languishing for days
or weeks. In previous roles, I've seen internally known security issues lie
open with only obscurity protecting my organization from fallout.</li>
<li>When developers can solve security issues easily themselves, it frees the
security team to focus on ‚Äúbig picture‚Äù security. I want security engineers
to be thinking how to choose frameworks, set up tools, help with secure
architecture, and build defense-in-depth‚Äînot finding my last XSS mistake.</li>
</ul>
<p>I call this concept ‚Äúself-service DevSec‚Äù.</p>
<p>In the rest of this blog post, I'll walk through a security bug we encountered
during the day-to-day course of regular development work. I'll discuss how we
discovered the issue, and how, within just a few hours, fixed the security
issue, and used Semgrep to prevent the bug from reoccurring.</p>
<p>Here's the story:</p>
<h2>Story</h2>
<p>Last month, I was debugging a Flask web-app authentication workflow with
Clara McCreery, another engineer at r2c. Like many engineers faced with
a confusing debugging problem, one of our first steps was to throw the web-app
into debug logging.</p>
<p>Specifically, we wanted to know what was going on with our database operations,
so we set our ORM (in this case, we use SQLAlchemy) into INFO-level logging with:</p>
<div data-language="py"><pre><code>logging<span>.</span>getLogger<span>(</span><span>"sqlalchemy.engine.base.Engine"</span><span>)</span><span>.</span>setLevel<span>(</span>logging<span>.</span>INFO<span>)</span></code></pre></div>
<p>This configures SQLAlchemy to log all SQL statements, together with passed
parameters. Let's look at some of the output we saw:</p>
<div data-language="shell-session"><pre><code><span>INFO:werkzeug:127.0.0.1 - - [25/Sep/2020 11:50:01] "POST /api/auth/authenticate HTTP/1.1" 200 -
INFO:sqlalchemy.engine.base.Engine:BEGIN (implicit)
INFO:sqlalchemy.engine.base.Engine:SELECT token.id AS token_id, token.token AS token_token, token.name AS token_name
FROM token
WHERE token.token = %(token_1)s
 LIMIT %(param_1)s
</span><span>INFO<span>:</span><span>sqlalchemy.engine.base.Engine:{'token_1': </span></span><span><span>$</span><span>2a<span>$10</span><span>$KVsyW1jjKn</span>.pvkVi3w9Rn.1mwnZFd7F2SFveGDG8flIhbe.MoJH4G, <span>'param_1'</span><span>:</span> <span>1</span><span>}</span></span></span></code></pre></div>
<p>...Uh-oh.</p>
<p>We definitely shouldn‚Äôt be logging tokens (even if they're securely hashed).
(In this example the actual token value has been changed to protect
the innocent.)</p>
<h2>Let‚Äôs make a plan</h2>
<p>At this point we‚Äôve identified a security issue, and we want to stomp it out
while preserving our ability to inspect logs. Our plan:</p>
<ol>
<li>Mitigate the immediate security issue.</li>
<li>Find a permanent solution to the problem that‚Äôs future proof. A permanent
solution means a baked-in change to our systems. Ideally this solution is
automated and seamless across our entire organization.</li>
<li>Add a mechanism to enforce our solution‚Äôs use organization-wide.</li>
</ol>
<p>In the rest of this post, I‚Äôll walk you through how we addressed each step.
Notably, we were able to accomplish this entire flow in a couple hours, without
engaging the security team at all.</p>
<h3>1. Mitigation</h3>
<p>Mitigation here was fairly straightforward, as we already knew the root cause
of our problem. We can quickly revert our logging change. Then we can do
a quick audit of our logs to ensure that only development test tokens were
leaked.</p>
<h3>2. The permanent solution</h3>
<p>How do we prevent SQLAlchemy from logging sensitive data?</p>
<p><em>A valiant attempt</em></p>
<p>Step 1 was to read the docs. A quick web search of ‚Äúsqlalchemy hide parameters
in engine logging‚Äù linked us to the SQLAlchemy <a href="https://docs.sqlalchemy.org/en/13/core/engines.html" target="_blank" rel="noopener">Engine
documentation</a>. A detailed
read later, we found the <code>hide_parameters</code> flag, which prevents the logging
framework from emitting <em>any</em> parameters in logs or exceptions.</p>
<p>While this certainly would prevent our security issue, it was too blunt of a hammer
for us: we wanted to know (for example) database IDs, and the like, for debugging.</p>
<p><em>The real solution</em></p>
<p>We then inspected the relevant SQLAlchemy <a href="https://github.com/sqlalchemy/sqlalchemy/tree/master/lib/sqlalchemy" target="_blank" rel="noopener">source
code</a>. The
relevant code is in <code>sqlalchemy/engine/base.py</code>:</p>
<div data-language="py"><pre><code>    <span>if</span> self<span>.</span>_echo<span>:</span>
        self<span>.</span>engine<span>.</span>logger<span>.</span>info<span>(</span>statement<span>)</span>
        <span>if</span> <span>not</span> self<span>.</span>engine<span>.</span>hide_parameters<span>:</span>
            self<span>.</span>engine<span>.</span>logger<span>.</span>info<span>(</span>
                <span>"%r"</span><span>,</span>
                sql_util<span>.</span>_repr_params<span>(</span>
                    parameters<span>,</span> batches<span>=</span><span>10</span><span>,</span> ismulti<span>=</span>context<span>.</span>executemany
                <span>)</span><span>,</span>
            <span>)</span></code></pre></div>
<p><code>sql_util._repr_params</code>, in turn, runs:</p>
<div data-language="py"><pre><code><span>def</span> <span>_repr_params</span><span>(</span>self<span>,</span> params<span>,</span> typ<span>)</span><span>:</span>
    trunc <span>=</span> self<span>.</span>trunc
    <span>if</span> typ <span>is</span> self<span>.</span>_DICT<span>:</span>
        <span>return</span> <span>"{%s}"</span> <span>%</span> <span>(</span>
            <span>", "</span><span>.</span>join<span>(</span>
                <span>"%r: %s"</span> <span>%</span> <span>(</span>key<span>,</span> trunc<span>(</span>value<span>)</span><span>)</span>
                <span>for</span> key<span>,</span> value <span>in</span> params<span>.</span>items<span>(</span><span>)</span>
            <span>)</span>
        <span>)</span>
    <span>.</span><span>.</span><span>.</span></code></pre></div>
<p>Investigating <code>trunc</code>, we found that it converts the parameter value by
truncating the parameter‚Äôs <code>repr</code> to a maximum number of characters.</p>
<p>This meant that we should override the <code>repr</code> method of the parameter object to
prevent sensitive logging.</p>
<p>At this point, like good engineers, we took the lazy route: stand on your
peers‚Äô shoulders. I found <a href="https://github.com/sqlalchemy/sqlalchemy/issues/4806" target="_blank" rel="noopener">this GitHub
issue</a>, where <a href="https://techspot.zzzeek.org/" target="_blank" rel="noopener">Mike
Bayer</a> had already posted a nice solution.</p>
<p>Some shameless copying later (and adding some types to make <code>mypy</code> happy), we
had <a href="https://gist.github.com/nbrahms/2fee940f4d87f09ffc3823be5a334cf3" target="_blank" rel="noopener">this
Gist</a>. The
key code is:</p>
<div data-language="py"><pre><code><span>class</span> <span>ObfuscatedString</span><span>(</span>types<span>.</span>TypeDecorator<span>)</span><span>:</span>
    <span>"""
    String column type for use with SQLAlchemy models whose
    content should not appear in logs or exceptions
    """</span>

    impl <span>=</span> types<span>.</span>String

    <span>class</span> <span>Repr</span><span>(</span><span>str</span><span>)</span><span>:</span>
        <span>def</span> <span>__repr__</span><span>(</span>self<span>)</span> <span>-</span><span>&gt;</span> <span>str</span><span>:</span>
            <span>return</span> <span>"********"</span>

    <span>def</span> <span>process_bind_param</span><span>(</span>self<span>,</span> value<span>:</span> Optional<span>[</span><span>str</span><span>]</span><span>,</span> dialect<span>:</span> Any<span>)</span> <span>-</span><span>&gt;</span> Optional<span>[</span>Repr<span>]</span><span>:</span>
        <span>return</span> self<span>.</span>Repr<span>(</span>value<span>)</span> <span>if</span> value <span>else</span> <span>None</span>

    <span>def</span> <span>process_result_value</span><span>(</span>
        self<span>,</span> value<span>:</span> Optional<span>[</span>Repr<span>]</span><span>,</span> dialect<span>:</span> Any
    <span>)</span> <span>-</span><span>&gt;</span> Optional<span>[</span><span>str</span><span>]</span><span>:</span>
        <span>return</span> <span>str</span><span>(</span>value<span>)</span> <span>if</span> value <span>else</span> <span>None</span>


<span>setattr</span><span>(</span>db<span>,</span> <span>"ObfuscatedString"</span><span>,</span> ObfuscatedString<span>)</span></code></pre></div>
<p>What does this code accomplish? It replaces our original <code>str</code> parameters
with a new <code>ObfuscatedString.Repr</code> parameter. When logged (or when emitted
into an exception message), the string is replaced by our <code>********</code>
obfuscation sentinel. Since the parameter is still bound as a raw string (via
<code>impl = types.String</code>), the correct value is still inserted and selected from
the database.</p>
<p>To use this new column type, we set our <code>token</code>‚Äôs column type:</p>
<div data-language="py"><pre><code><span>class</span> <span>Token</span><span>(</span>db<span>.</span>Model<span>)</span><span>:</span>
    <span>.</span><span>.</span><span>.</span>
    token <span>=</span> db<span>.</span>Column<span>(</span>db<span>.</span>ObfuscatedString<span>,</span> <span>.</span><span>.</span><span>.</span><span>)</span>
    <span>.</span><span>.</span><span>.</span></code></pre></div>
<p>We then re-enabled INFO logging, and checked that we were properly obfuscating
text:</p>
<div data-language="shell-session"><pre><code><span>INFO:werkzeug:127.0.0.1 - - [25/Sep/2020 13:48:55] "GET /api/agent/deployments/1/policies HTTP/1.1" 200 -
INFO:sqlalchemy.engine.base.Engine:BEGIN (implicit)
INFO:sqlalchemy.engine.base.Engine:SELECT token.id AS token_id, token.token AS token_token, token.name AS token_name
FROM token
WHERE token.token = %(token_1)s
 LIMIT %(param_1)s
INFO:sqlalchemy.engine.base.Engine:{'token_1': ********, 'param_1': 1}</span></code></pre></div>
<p>For completeness, we also validated in our development database console that the
correct values were stored and retrieved.</p>
<p>Great success! üö¢ Ship it.</p>
<h3>3. Enforcement</h3>
<p>It was tempting to rest on our laurels here. We had solved our security issue for
the time being, and we could get back to debugging our original auth issue.</p>
<p>But we wanted to guarantee that <em>we would never see this issue again</em>. How would we do
this?</p>
<p>Here are some ideas that I‚Äôm sure we‚Äôve all encountered before:</p>
<ol>
<li>Block all commits to SQLAlchemy models on security review!</li>
<li>Host a yearly security training for all devs, including the pitfalls of
logging sensitive data!</li>
<li>Audit logs weekly!</li>
<li>File an issue with your SAST provider, demanding they add checks to catch
sensitively logged data!</li>
</ol>
<p>If there is a central take-away from this blog post, it is this: these are not
ideal solutions:</p>
<ol>
<li>Blocking commits introduces needless friction into the development
process, slows development velocity, and needlessly distracts the security
team.</li>
<li>Security trainings are an important component to a security program, and
necessary to keep developers aware of evolving security threats, but humans
have fallible memory, and we can forget things we've heard months or even
days in the past.</li>
<li>Regular audits, like blocking commits, introduce a heavy workload on an
almost certainly overloaded security team.</li>
<li>Your SAST provider will certainly welcome your suggestion, but you will be
beholden to their software release cycle, and may not see checks be
available for months; furthermore, if your issue is domain-specific, it may
not even make sense for a check to be implemented within a generalist product.</li>
</ol>
<p>Fortunately, Semgrep gave us a simple solution here: Define an
<em>invariant</em> in your code, and <em>enforce</em> it using a Semgrep scan on every CI
run.</p>
<p>At r2c, we use GitHub Actions to run Semgrep on every merge request. We define
what checks Semgrep should run using <em>a managed policy</em>, a list of rules and
notification settings managed by <a href="https://semgrep.dev/" target="_blank" rel="noopener">semgrep.dev</a>.</p>
<p>To guarantee our code against future issues, I went to
<a href="https://semgrep.dev/editor" target="_blank" rel="noopener">semgrep.dev/editor</a> and wrote <a href="https://semgrep.dev/s/nbrahms:obfuscate-sensitive-string-columns-2" target="_blank" rel="noopener">a quick rule</a>
to detect potential insecurely logged SQLAlchemy columns.</p>
<p>Here's the rule definition in Semgrep's YAML definition language:</p>
<div data-language="yaml"><pre><code><span>rules</span><span>:</span>
<span>-</span> <span>id</span><span>:</span> obfuscate<span>-</span>sensitive<span>-</span>string<span>-</span>columns
  <span>patterns</span><span>:</span>
    <span>-</span> <span>pattern</span><span>:</span> <span>|</span><span>
        $COLUMN = db.Column(db.String, ...)</span>
    <span>-</span> <span>metavariable-regex</span><span>:</span>
        <span>metavariable</span><span>:</span> $COLUMN
        <span>regex</span><span>:</span> <span>'.*(?&lt;![A-Za-z])(token|key|email|secret)(?![A-RT-Za-rt-z]).*'</span>
  <span>message</span><span>:</span> <span>|</span><span>
    '$COLUMN' may expose sensitive information in logs and exceptions. Use
    'db.ObfuscatedString' instead of 'db.String'.</span>
  <span>severity</span><span>:</span> WARNING</code></pre></div>
<p>What does this rule do? Let‚Äôs break it down:</p>
<ul>
<li><code>id</code>: We give our rule a concise descriptive ID for easy reference by any developer who
sees it pop up in their editor or CI output.</li>
<li>
<p><code>patterns</code>: This is composed of two parts:</p>
<ul>
<li><code>pattern</code>: This expression tells Semgrep to ‚Ä¶</li></ul></li></ul></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://r2c.dev/blog/2020/fixing-leaky-logs-how-to-find-a-bug-and-ensure-it-never-returns/">https://r2c.dev/blog/2020/fixing-leaky-logs-how-to-find-a-bug-and-ensure-it-never-returns/</a></em></p>]]>
            </description>
            <link>https://r2c.dev/blog/2020/fixing-leaky-logs-how-to-find-a-bug-and-ensure-it-never-returns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060456</guid>
            <pubDate>Wed, 11 Nov 2020 17:29:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Doomsday prepping ‚Äì Disaster planning for less crazy folk (2016)]]>
            </title>
            <description>
<![CDATA[
Score 168 | Comments 111 (<a href="https://news.ycombinator.com/item?id=25060418">thread link</a>) | @VBprogrammer
<br/>
November 11, 2020 | https://lcamtuf.coredump.cx/prep/ | <a href="https://web.archive.org/web/*/https://lcamtuf.coredump.cx/prep/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

 

<a name="1"></a>
<h2>1. Introduction <span>[<a href="#1">link</a>]</span></h2>

<p>
The prepper culture begs to be taken with a grain of salt. In a sense, it has
all the makings of a doomsday cult: a tribe of unkempt misfits who hoard gold
bullion, study herbalism, and preach about the imminent collapse of our society.
</p>

<p>
Today, we see such worries as absurd. It's not that life-altering disasters are
rare: every year, we hear about millions of people displaced by wildfires, earthquakes,
hurricanes, or floods. Heck, not a decade goes by without at least one first-class
democracy lapsing into armed conflict or fiscal disarray. But having grown up in a period
of unprecedented prosperity and calm, we take our way of life for granted - and find
it difficult to believe that an episode of bad weather or a currency crisis could
upend our lives for good.
</p>

<p>
I suspect that we dismiss such hazards not only because they seem surreal, but also because
worrying about them makes us feel helpless and lost. What's more, we follow the same instincts
to tune out far more pedestrian and avoidable risks; for example, 
most of us don't plan ahead for losing a job, for dealing with a week-long water outage, or
for surviving the night if our home goes up in smoke.
</p>

<p>
For many, the singular strategy for dealing with such dangers is to pray for the
government to bail us out. But no matter if our elected officials prefer to school us with
passages from
<a href="https://smile.amazon.com/dp/0156334607">Milton
Friedman</a> or from
<a href="https://smile.amazon.com/dp/0486477487" title="I'm sorry... I'm really sorry!">Thomas
Piketty</a>, the hard truth is that no state can provide a robust safety net for all
of life's likely contingencies; in most places, government-run social programs are severely deficient in funding, in
efficiency, and in scope. Large-scale disasters pit us against even worse odds; from New Orleans in 2005 to
Fukushima in 2011, there are countless stories of people left behind due to political dysfunction, poorly
allocated resources, or lost paperwork.
</p>

<p>
And so, the purpose of this guide is to combat the mindset of learned helplessness by
promoting simple, level-headed, personal preparedness techniques that are easy to
implement, don't cost much, and will probably help you cope with whatever life throws your way.
</p>

<p>
Oh, one thing: in contrast to most other docs of its kind, this page an
unadulterated labor of love; there are no affiliate links, paid product placements, or ads anywhere in the guide.
</p>

<a name="2"></a>
<h2>2. Mapping out the unknown <span>[<a href="#2">link</a>]</span></h2>

<p>
Effective preparedness can be simple, but it has to be rooted in an honest and
systematic review of the risks you are likely to face. Plenty of excited newcomers begin
by shopping for ballistic vests and night vision goggles; they would be better
served by grabbing a fire extinguisher, some bottled water, and then putting the rest of
their money in a rainy-day fund.
</p>

<p>
To maintain sanity while trying to enumerate risks, I found that it's best to focus on
broad outcomes instead of trying to track down every single way for things to go south.
Say, it should not matter if you are laid off because of a downsizing, because
your new boss hates you, or because they finally catch you stealing paperclips. The
outcome is the same: you are out of a job and urgently need a way to pay your bills.
</p>

<p>
Another insidious distraction is the desire to immediately figure out how to respond to all the scenarios
we end up dreaming of. Let's save that for later; by prematurely focusing on the second half of the
problem, we may end up glossing over some of the less tractable scenarios - or make
haphazard assumptions that will cloud our judgment in other ways.
</p>

<p>
I also found that to come up with a rational threat model, we need to think of "risk" as a product of
both the probability and the consequences of a given event. By that metric, stubbed toes
and zombie outbreaks are equally uninteresting; one of them has nearly zero significance,
the other, nearly zero odds.
</p>

<p>
What else? Ah, right: the final piece of advice I have is to keep things uncomplicated. There are
popular doomsday predictions that deal with cutting-edge particle physics, god-like computer
hackers, vast government conspiracies, or extraterrestrial messages hidden in pop songs. I suppose
we can't <i>really</i> rule that stuff out, but historical data suggests that there's a lot more
merit in worrying about falling off a ladder or getting hit by a car.
</p>

<p>
All right! With these caveats in mind, let's go over some canonical scenarios that are worth thinking about.
</p>

<a name="2.1"></a>
<h3>2.1. Problem space #1: Small-scale events <span>[<a href="#2.1">link</a>]</span></h3>

<p>
It's always fun to speculate about solar flares and supervolcanoes; it's far more mind-numbing to
seriously evaluate the consequences of backed up sewage or burst water mains. But in reality,
such unglamorous, small-scale incidents are far more likely to disrupt and reshape our
lives.
</p>

<p>
Broadly speaking, disastrous outcomes of such humdrum contingencies can be divided into
several groups:
</p>

<ul>

<li>
<p>
<b>Insolvency.</b>
  If a person over the age of 40 tells you that they have never lost a job, they are
  pretty lucky (or lying). Yet, the risk is seldom taken seriously; many middle-class,
  single-income families would be in deep trouble if it ever took them more than 2-3 months
  to find a new, equally well-paying gig.
</p>

</li><li>
<p>
<b>Disrupted access to water, food, energy, or transportation.</b>
  Substantial and prolonged outages happen everywhere; many of us will experience
  at least one at some point in our lives. A week without electricity may be just
  inconvenient and scary, especially in a high-rise or
  in a seedy neighborhood; but even a single hot day without potable water is really
  bad news.
</p>

</li><li>
<p>
<b>Loss of shelter.</b>
  Every year, there are over 350,000 house fires in the United States. Such accidents
  usually aren't deadly - but if you are unlucky, they can leave you stranded in the middle
  of the night in your PJs, with no documents or credit cards in hand.
</p>

</li><li>
<p>
<b>Unintentional injury.</b>
  Largely preventable and predictable incidents - such as falls, vehicle collisions, and poisonings -
  account for some 40 million ER visits annually. And lest you say people are simply too
  quick to rush to the hospital, said incidents also result in about 100,000 US
  deaths every year.
</p>

</li><li>
<p>
<b>Intentionally inflicted harm.</b>
  Violent crime is essentially <i>normal</i> almost everywhere in the world.
  In the US in the 90s, your lifetime likelihood of victimization was
  estimated to be around 80%; the odds of suffering criminal injury hovered at 40%. More recent
  research is hard to come by - but rest assured, life-threatening encounters remain a very real risk.
</p>

</li><li>
<p>
<b>Debilitating illness or death.</b>
  It's going to get you; maybe next week, maybe in 50 years. We can't really predict the day,
  but we can understand and meaningfully manage the impact it will have on those who depend on us -
  say, our stay-at-home partners or young kids.
</p>

</li></ul>

<p>
All in all, the risks discussed in this section have three defining characteristics: they are relatively
likely to happen; are strikingly easy to mitigate (we'll get into that soon); and tend to be so
unglamorous that they seldom make the cut in any "serious" guide to emergency preparedness.
</p>

<a name="2.2"></a>
<h3>2.2. Problem space #2: Mass calamities <span>[<a href="#2.2">link</a>]</span></h3>

<p>
If an errant backhoe took out the utilities for your block, you would probably head to the
grocery store to pick up bottled water (and use their restrooms, too). But if a
once-in-a-century storm damaged major roads and left half the city without running water, your
options wouldn't be as clear-cut.
</p>


<p>
That's why we have to look at larger-scale emergencies through somewhat different lens, taking into
account their likely magnitude, duration, and the nature of the forces at play. Some of the
plausible scenarios to think about include:
</p>

<ul>

<li>
<p>
<b>Natural disasters.</b>
  Common examples include floods, hurricanes, earthquakes, wildfires, and heatwaves. In some
  regions, such events are very rare; in others, they are almost guaranteed every decade or two.
</p>

</li><li>
<p>
<b>Industrial accidents.</b>
  Many people live in the proximity of heavy industries - say, refineries, freight railroads, or power plants.
  Depending on the type of industrial facilities nearby, you may want to evaluate the potential
  consequences of upwind and upstream explosions or chemical spills.
</p>

</li><li>
<p>
<b>Social unrest.</b>
  Riots are a distinct risk in many urban and suburban areas around the world. When angry mobs
  take it to the streets, widespread arson and violent crime are not unheard of, sometimes going
  on for days or weeks.
</p>

</li><li>
<p>
<b>Economic crises.</b>
  All highly developed countries go through cyclic recessions and periods of high unemployment;
  the US had about ten big ones in the past 100 years alone. Sometimes, such events
  are accompanied by bank runs and collapses of financial institutions; other times,
  they involve hyperinflation, product rationing, and currency controls.
</p>

</li><li>
<p>
<b>Pandemic.</b>
  It's been a while since the highly developed world experienced a devastating outbreak, but it
  may be premature to flat out dismiss the risk. In 1918, an unusual strain of flu managed to kill 75
  million people. Few years later, a mysterious sleeping sickness - probably also of viral origin -
  swept the globe, crippling millions, some for life. We aren't necessarily better prepared
  for similar events today.
</p>

</li><li>
<p>
<b>Terrorism or conventional war.</b>
  We think we would see it coming - but history shows that such events tend to catch nations
  off guard. These phenomena are noteworthy not only because of their immediate death toll,
  which can be relatively low - but because of the far-reaching and long-term socioeconomic
  disruption they can cause.
</p>

</li></ul>

<p>
Most of us will probably not get tangled up in a large-scale disaster of any sort, but it
is only wise to hedge your bets. There are countless examples to demonstrate that such events
happen often and can strike close to home - say:
</p>

<ul>

<li>
<p>
The EU debt crisis, from 2009 onward. A series of events that led to staggering unemployment rates
in Greece, deposit confiscations in Cyprus, and uncertain prospects for the entire
eurozone.
</p></li></ul></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lcamtuf.coredump.cx/prep/">https://lcamtuf.coredump.cx/prep/</a></em></p>]]>
            </description>
            <link>https://lcamtuf.coredump.cx/prep/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060418</guid>
            <pubDate>Wed, 11 Nov 2020 17:26:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Event Sourcing and CQRS with Incident ‚Äì Part 1]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25060270">thread link</a>) | @pedroassumpcao
<br/>
November 11, 2020 | https://pedroassumpcao.ghost.io/event-sourcing-and-cqrs-using-incident-part-1/ | <a href="https://web.archive.org/web/*/https://pedroassumpcao.ghost.io/event-sourcing-and-cqrs-using-incident-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
        <main id="main">
            <div>

                

                
<section>

    <header>
        <span>November 2, 2020</span>
        
            <p>Event Sourcing and CQRS are design patterns that are great for some domains. The Incident library will help implement them without compromising other parts of your application.</p>
    </header>

    <p><img src="https://pedroassumpcao.ghost.io/content/images/2020/11/e227890b80a0c1ca5436721579babc8b.jpg" alt="Using Event Sourcing and CQRS with Incident -  Part 1"></p>

    <div>
        <p>This is the first of a series of posts that I will present on how your application can use <strong>Event Sourcing</strong> and <strong>CQRS</strong> for specific domains with an open-source library that I am developing called <strong><a href="https://github.com/pedroassumpcao/incident">Incident</a></strong>.</p><hr><p>My first contact with Event Sourcing was back in 2016 when I was working for Raise Marketplace and I led a project that the goal was to solve an accounting burden regarding seller payments. As a marketplace, in a nutshell, a buyer pays for something, the company gets a commission and the seller receives the remaining funds. Track the money flow, depending on the options the marketplace offers, can become complex. In that specific case, sellers could opt for combining funds to be paid daily, via different methods such as check, PayPal, ACH, and so on, or decide to request funds one by one. Around all of that, there was a fraud detection process, transfer limits, a different category of sellers, and so on.</p><p>Before Event Sourcing, there was a lack of a cohesive way to track the steps of each fund, from buyer to seller, and all possible scenarios. And when that comes to accounting people, it becomes a nightmare.</p><p>With well-defined commands, events, and logic associated with them, it became more clear the information the Accounting department needed at the time.</p><p>Later on, I had the opportunity to work on other personal projects using Event Sourcing so I decided to build something to help me moving forward, and from that learning came <a href="https://github.com/pedroassumpcao/incident">Incident</a>.</p><h2 id="what-is-event-sourcing">What is Event Sourcing?</h2><p><strong>Event Sourcing</strong> is a design pattern that defines that the state changes of an entity are stored as a sequence of events. Events are the source of truth and immutable, and the current state of any entity is playing all events of the entity in the order they happened.</p><p>If you are new to <strong>Event Sourcing</strong> and <strong>CQRS</strong> I highly recommend watch <a href="https://www.youtube.com/watch?v=JHGkaShoyNs" rel="nofollow">Greg Young's presentation at Code on the Beach 2014</a> before moving forward as my intention with this blog post series is not to present Event Sourcing principles per se and the details but how those principles were used in the implementation.</p><h2 id="what-event-sourcing-is-not">What Event Sourcing is not?</h2><p>One of the misconceptions that I often see is that if you decide to use Event Sourcing you should apply it to your entire system, to all your domains. This is &nbsp;wrong in my opinion, an anti-pattern and you should avoid at all costs as unlikely all your domains will suit.</p><p>Another fact, Event Sourcing is not new, many industries using "Event Sourcing" concepts even not naming the same way. Accounting keeps track of all account operations, your medical record is about your health history, contracts don't change, they have addendums, and so on.</p><h2 id="incident-main-goals">Incident Main Goals</h2><p>When I decided to implement a new library, based on my learning through other projects, I had some goals in mind that I'd like to achieve:</p><ul><li>incentivize the usage of Event Sourcing and CQRS as a great choice for domains that can leverage the main benefits of this design pattern;</li><li>offer the essential building blocks for using Event Sourcing in your system with proper contracts, but allowing specific needs to leverage what Elixir already brings to the table, for example, concurrency;</li><li>leverage functions and reducers for executing commands and applying events in the aggregate logic, facilitating stateless tests;</li><li>be extensible without compromising the main principles;</li></ul><h2 id="events-vs-projections">Events vs Projections</h2><p>Events are the <strong>source of truth</strong> in any Event Sourcing domain, they are immutable and they are used to calculate the current state of any aggregate (or entity) at any time. All the events of any type, for any aggregate type, are stored in the Event Store in a single table.</p><p>The projections are the <strong>representation of the current state</strong> of an aggregate and they are very similar to what any system that does not use Event Sourcing has. The domain will have as many projection tables as you need but usually, you will have one table for each entity type. All projection tables are stored in the Projection Store.</p><p>The following diagram helps understand the separation between the command model from the query model, and their responsibilities as well.</p><ol><li>UI/API issues a <strong>Command</strong> to attempt to change the state;</li><li><strong>Aggregate</strong> logic that lives in the <strong>Command Model</strong> is used (including past events) and if everything is fine, a new <strong>Event</strong> will be persisted in the <strong>Event Store</strong>;</li><li>The <strong>Event Handler</strong> will receive the new event and project the new aggregate state into the <strong>Projection Store</strong>;</li><li>UI/API will query the <strong>Aggregate Current State</strong> from the <strong>Query Model</strong>;</li></ol><figure><img src="https://pedroassumpcao.ghost.io/content/images/2020/10/Event-Sourcing.png" alt="Event Sourcing - Command and Query Model" srcset="https://pedroassumpcao.ghost.io/content/images/size/w600/2020/10/Event-Sourcing.png 600w, https://pedroassumpcao.ghost.io/content/images/2020/10/Event-Sourcing.png 710w"></figure><h2 id="aggregate-vs-aggregate-state">Aggregate vs Aggregate State</h2><p>One of the things that I see when implementing Event Sourcing that makes it harder is to try to manage aggregate logic, aggregate state data structure, and aggregate state logic in the same place. Incident does a little differently.</p><p>The <strong>Aggregate</strong> will define how a specific entity (<em>Bank Account</em>, for example) will execute each of its allowed commands and apply each of its allowed events. The aggregate itself only defines the logic but not the current state calculation.</p><p>The <strong>Aggregate State</strong> defines the initial state of an Aggregate and it is able to calculate the current state by replaying all the events through the aggregate logic.</p><p>Back in 2013, Greg Young tweeted the following:</p><!--kg-card-begin: html--><blockquote><div lang="en" dir="ltr"><p>want to learn event sourcing? </p><p>f(state, event) =&gt; state</p></div>‚Äî Greg Young (@gregyoung) <a href="https://twitter.com/gregyoung/status/313358540821647360?ref_src=twsrc%5Etfw">March 17, 2013</a></blockquote> <!--kg-card-end: html--><p>Incident follows that principle with the <strong>Aggregate</strong> logic in a nutshell being:</p><ul><li>Command &gt; Function &gt; Event;</li><li>Event and State &gt; Function &gt; New State;</li></ul><p>And part of the <strong>Aggregate State</strong> logic is similar to:</p><!--kg-card-begin: markdown--><pre><code>Enum.reduce(events, state, fn event, state -&gt;
  aggregate.apply(event, state)
end)
</code></pre>
<!--kg-card-end: markdown--><hr><h2 id="let-s-get-started">Let's Get Started</h2><p>In this series we will be using Incident to implement the <strong>Account</strong> domain of a <strong>Bank</strong> system for these main reasons:</p><ul><li>it is a domain that benefits from the Event Sourcing principles;</li><li>it contains simple scenarios such as <strong>opening an account</strong>, <strong>depositing funds</strong>;</li><li>it contains complex scenarios such as <strong>transferring funds</strong> from one account to another;</li></ul><p>Other common domains of a typical Bank system, for example, Client Profile, Authentication/Authorization won't be the focus of the Incident implementation as they are not a good fit, at least not in our case. This is to emphasize the fact that you don't need to have Event Sourcing in your entire system.</p><h3 id="application-and-incident-setup">Application and Incident Setup</h3><p>Let's create a new application for our Bank, including the supervision tree. As a side note, I am using <strong>Elixir 1.11</strong> in this series so some of the Elixir configuration details might vary depending on the version you are using.</p><!--kg-card-begin: markdown--><pre><code>~&gt; mix new bank --sup
</code></pre>
<!--kg-card-end: markdown--><p>Add <strong>Incident</strong> in <code>mix.exs</code>, fetch and compile the dependencies:</p><!--kg-card-begin: markdown--><pre><code>defmodule Bank.MixProject do
  use Mix.Project

  # hidden code
  
  def deps do
    [
      {:incident, "~&gt; 0.5.1"}
    ]
  end
end
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code>~&gt; mix do deps.get, deps.compile
</code></pre>
<!--kg-card-end: markdown--><p>Generate Ecto Repos for the <strong>Event Store</strong> and <strong>Projection Store</strong>, this will create the repo modules:</p><!--kg-card-begin: markdown--><pre><code>~&gt; mix ecto.gen.repo -r Bank.EventStoreRepo
...
~&gt; mix ecto.gen.repo -r Bank.ProjectionStoreRepo
...
</code></pre>
<!--kg-card-end: markdown--><p>In your application <code>config/config.exs</code> specify the Ecto repos and configure Incident:</p><!--kg-card-begin: markdown--><pre><code># hidden code

config :bank, ecto_repos: [Bank.EventStoreRepo, Bank.ProjectionStoreRepo]

config :incident, :event_store,
  adapter: Incident.EventStore.PostgresAdapter,
  options: [
    repo: Bank.EventStoreRepo
  ]

config :incident, :projection_store,
  adapter: Incident.ProjectionStore.PostgresAdapter,
  options: [
    repo: Bank.ProjectionStoreRepo
  ]

import_config "#{config_env()}.exs"
</code></pre>
<!--kg-card-end: markdown--><p>In your application <code>config/dev|test|prod.exs</code> (the example below defines two separated databases but it could be the same one), set up the database access for Ecto for each environment:</p><!--kg-card-begin: markdown--><pre><code># config/dev.exs

# hidden code

config :bank, Bank.EventStoreRepo,
  username: "postgres",
  password: "postgres",
  hostname: "localhost",
  database: "bank_event_store_dev"

config :bank, Bank.ProjectionStoreRepo,
  username: "postgres",
  password: "postgres",
  hostname: "localhost",
  database: "bank_projection_store_dev"
</code></pre>
<!--kg-card-end: markdown--><p>Add the Ecto repo modules to the supervision tree in your <code>lib/bank/application.ex</code>:</p><!--kg-card-begin: markdown--><pre><code>defmodule Bank.Application do
  @moduledoc false

  use Application

  @impl true
  def start(_type, _args) do
    children = [
      Bank.EventStoreRepo,
      Bank.ProjectionStoreRepo
    ]

    opts = [strategy: :one_for_one, name: Bank.Supervisor]
    Supervisor.start_link(children, opts)
  end
end
</code></pre>
<!--kg-card-end: markdown--><p>Create the database(s), generate the Incident <strong>events table</strong> migration, and run the migrations:</p><!--kg-card-begin: markdown--><pre><code>~&gt; mix ecto.create
...
~&gt; mix incident.postgres.init -r Bank.EventStoreRepo
...
~&gt; mix ecto.migrate
...
</code></pre>
<!--kg-card-end: markdown--><p>The setup is done, it seems a lot but most of it is a common setup needed for any application using Ecto.</p><h2 id="the-bank-account">The Bank Account</h2><p>As we will keep track of bank accounts, we will define some initial components that are defined only once, and then later evolve the aggregate with the logic that will be based on the operations we want the aggregate to respond to.</p><h3 id="projection">Projection</h3><p>We will need to present to the user some bank account information. So we will define one projection that will contain the current state of the bank accounts. Generate an Ecto migration as below, please notice the <code>-r</code> flag that specifies which repo the migration will be:</p><!--kg-card-begin: markdown--><pre><code>~&gt; mix ecto.gen.migration CreateBankAccountsTable -r Bank.ProjectionStoreRepo
</code></pre>
<!--kg-card-end: markdown--><p>Populate the migration with the following fields. Besides the desired fields related to bank account data, every projection should also contain <code>version</code>, <code>event_id</code>, and <code>event_date</code> fields. They inform the last event that updated the projection and how many events were applied to it:</p><!--kg-card-begin: markdown--><pre><code>defmodule Bank.ProjectionStoreRepo.Migrations.CreateBankAccountsTable do
  use Ecto.Migration

  def change do
    create table(:bank_accounts) do
      add(:aggregate_id, :string, null: false)
      ‚Ä¶</code></pre></div></section></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pedroassumpcao.ghost.io/event-sourcing-and-cqrs-using-incident-part-1/">https://pedroassumpcao.ghost.io/event-sourcing-and-cqrs-using-incident-part-1/</a></em></p>]]>
            </description>
            <link>https://pedroassumpcao.ghost.io/event-sourcing-and-cqrs-using-incident-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060270</guid>
            <pubDate>Wed, 11 Nov 2020 17:13:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advance Electromagnetism Notes (Site)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25060248">thread link</a>) | @E-Reverance
<br/>
November 11, 2020 | https://andrealommen.github.io/PHY309/lectures | <a href="https://web.archive.org/web/*/https://andrealommen.github.io/PHY309/lectures">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article>

  

  <div>
    <h3 id="for-reference">For reference</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/derivatives">All the Fundamental Theorems Together</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/maxwell">Maxwell‚Äôs Equations</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/minus_signs">Minus Signs</a><br></p>
<h3 id="chapter-1-vector-analysis">Chapter 1: Vector Analysis</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/grad">Gradients Theorem</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/div">Divergence Theorem</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/curl">Stokes‚Äô Theorem (Curl)</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/dirac">Dirac Delta Function</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/potentials">Potentials and Boundary Conditions</a><br></p>
<h3 id="chapter-2-electrostatics">Chapter 2: Electrostatics</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/chapt2">Andrea‚Äôs Crash Course in Chapter 2</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/electric">Electric Field</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/divcurlE">Divergence and Curl of Electric Field, Gauss‚Äôs Law</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/PotentialWorkEnergy">Potential, Work, Energy</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/conductors">Boundary Conditions and Conductors</a><br></p>
<h3 id="chapter-3-potentials">Chapter 3: Potentials</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/chapt3">Andrea‚Äôs Crash Course in Chapter 3</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/laplace">Laplace‚Äôs Equation and the Method of Images</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/separation">Separation of Variables</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/multipole">Multipole Expansion </a><br></p>
<h3 id="chapter-4-electric-fields-in-matter">Chapter 4: Electric Fields in Matter</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/chapt4">Andrea‚Äôs Crash Course in Chapter 4</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/polarization">Polarization</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/debrief">Debrief HW3</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/displacement">Displacement</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/boundaryD">Boundary Values in the Presence of a Dielectric</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/SolutionToInClassDielectricCylinderProblem.pdf">Full solution to the Dielectric Cylinder Problem</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/final_words_displacement">Final Words (Rant?) on Displacement</a><br></p>
<h3 id="one-third-of-the-way-through-the-course-we-reflect">One-third of the way through the course, we reflect‚Ä¶</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/CumulativeSummary1">Summary of Course so Far</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/Survey.html">Survey Results</a><br></p>
<h3 id="first-exam">First Exam</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/firstexamformat">What will be the format of the 1st exam?</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/practice_problems_1st">Practice Problems for 1st exam</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/firstexam">First Exam</a><br></p>
<h3 id="chapter-5-magnetostatics">Chapter 5: Magnetostatics</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/chapt5">Andrea‚Äôs Crash Course in Chapter 5</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/lorentz">Lorentz and Biot-Savart</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/ampere">Ampere‚Äôs Law and the Vector Potential</a><br></p>
<h3 id="chapter-6-magnetic-fields-in-matter">Chapter 6: Magnetic Fields in Matter</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/chapt6">Andrea‚Äôs Crash Course in Chapter 6</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/magnetized_matter">Magnetization and the Field of a Magnetized Object</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/auxiliary">The Auxiliary Field</a><br></p>
<h3 id="chapter-7-electrodynamics">Chapter 7: Electrodynamics</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/allChapt7">Andrea‚Äôs Crash Course in Chapter 7</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/induction">Electromotive Force and Induction</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/maxwellChapt7">Maxwell‚Äôs Equations</a><br></p>
<h3 id="chapter-8-griffiths-calls-it-conservation-laws-at-this-point-we-only-picked-up-the-continuity-equation-and-saved-the-rest-for-after-chapter-9">Chapter 8: Griffiths calls it Conservation laws, at this point we only picked up the Continuity Equation and saved the rest for after Chapter 9</h3>
<p>(We‚Äôre kind of picking up Chapter 8 along the way‚Ä¶)<br>
<a href="https://andrealommen.github.io/PHY309/lectures/allChapt8">Andrea‚Äôs Crash Course in Chapter 8</a><br></p>
<h3 id="chapter-9-electromagnetic-waves">Chapter 9: Electromagnetic Waves</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/allChapt9">Andrea‚Äôs Crash Course in Chapter 9</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/light">Light!!!!!</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/polarization">Polarization of Waves in Linear and Conducting Media</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/reflection">Boundary Conditions, Reflection and Transmission</a><br></p>
<h3 id="second-exam">Second Exam</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/secondexamreview">Review for the second exam</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/secondexamformat">What will be the format of the 2nd exam?</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/practice_problems_2nd">Practice Problems for 2nd exam</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/secondexam">Second Exam</a><br></p>
<h3 id="poynting-vector-energy-transmission-coefficient-parts-of-chapters-8-and-9">Poynting Vector, Energy, Transmission coefficient (parts of chapters 8 and 9)</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/quarterwaveplate">In a quarter wave plate, can we really assume the transmission coefficients are the same?</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/poynting">Poynting Theorem, Poynting Vector, Energy, Momentum</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/transmission">Poynting Theorem in EM Waves, Transmission and Reflection Coefficients</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/plasma">Waves in a Tenuous Plasma, Dispersion</a> <br></p>
<h3 id="chapter-10-potentials-and-fields">Chapter 10: Potentials and Fields</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/Chapt10ReviewPlusTensors">Andrea‚Äôs Crash Course in Chapter 10</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/potentialformulation">The Potential Formulation</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/deferred">The Deferred Potential</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/leinard">Leinard-Wiechert Potential</a> <br></p>
<h3 id="chapter-11-radiation">Chapter 11: Radiation</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/allChapt11">Andrea‚Äôs Crash Course in Chapter 11</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/radiation">Radiation</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/dipole">Dipole Radiation</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/point">Radiation from a Point Charge</a> <br></p>
<h3 id="the-final-week-looking-backwards-and-forwards">The Final Week: Looking backwards and forwards</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/Chapt10ReviewPlusTensors">Chapter 10 Review (emphasis Gauge and Deferred) Plus Relativity, Chapt 12</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/Chapt10ReviewPt2">Chapter 10 Review cont‚Äôd including Deferred Potential</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/allChapt11">Pancake breakfast party, and Review Chapter 11.  We‚Äôll do a questionnaire here to get your thoughts about the class</a></p>
<h3 id="the-final-exam">The Final Exam</h3>
<p>You may look at the following whenever you want.  It explains the format of the exam and what kind of problems
to expect.
<a href="https://andrealommen.github.io/PHY309/lectures/finalexamformat">Format of the Final Exam</a><br></p>

<p>When you‚Äôre ready to take the exam please click <a href="https://andrealommen.github.io/PHY309/lectures/finalexam">here.</a></p>

  </div>


</article>


      </div>
    </div></div>]]>
            </description>
            <link>https://andrealommen.github.io/PHY309/lectures</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060248</guid>
            <pubDate>Wed, 11 Nov 2020 17:11:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Will Futhark Work on Apple Silicon?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25060172">thread link</a>) | @Athas
<br/>
November 11, 2020 | https://futhark-lang.org/blog/2020-11-11-will-futhark-work-on-apple-silicon.html | <a href="https://web.archive.org/web/*/https://futhark-lang.org/blog/2020-11-11-will-futhark-work-on-apple-silicon.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
      

<p>
    Posted on November 11, 2020
    
        by Troels Henriksen
    
</p>

<p>Apple is coming out with computers that are basically ARM64, <a href="https://en.wikipedia.org/wiki/Think_different">but with a different ABI than existing ARM64 for some reason</a>. They call the architecture <a href="https://en.wikipedia.org/wiki/Mac_transition_to_Apple_Silicon">Apple Silicon</a>, which is a wonderful term that will undoubtedly never become dated or insufficiently precise.</p>
<p>Anyway, you see various posts such <a href="https://developer.r-project.org/Blog/public/2020/11/02/will-r-work-on-apple-silicon/">Will R Work on Apple Silicon?</a> where language developers answer whether their language will work on these new machines. Since these machines will support transparent emulation of x86, the simple answer is <em>yes</em>. Apple‚Äôs emulation was quite good during the PPC-to-x86 transition, so this is trustworthy. Of course, emulation is never going to be as fast as native compilation. For R, the problem is that they depend on some Fortran code, and there is <a href="https://developer.apple.com/forums/thread/651476">not yet a Fortran compiler available for Apple Silicon</a>.</p>
<p>Well, I can confirm that Futhark depends on absolutely no Fortran. Futhark compiles to C (or Python), and does not care about the specific target architecture. Therefore, Futhark programs should run fine on Apple Silicon. The bigger problem is that <a href="https://www.extremetech.com/computing/270902-apple-defends-killing-opengl-opencl-as-developers-threaten-revolt">Apple has deprecated OpenCL</a>, and <a href="https://www.provideocoalition.com/officially-official-nvidia-drops-cuda-support-for-macos/">does not support CUDA at all</a> due to being grumpy with NVIDIA, so there may eventually be no way to run Futhark <em>on a GPU</em> on macOS. It is unlikely that we will find the time to add a backend for Apple‚Äôs <a href="https://developer.apple.com/metal/">proprietary Metal API</a> that is supported <em>absolutely nowhere else</em>, but it‚Äôs possible that we‚Äôll finish Futhark‚Äôs embryonic Vulkan backend. While macOS does not come bundled with Vulkan, <a href="https://github.com/KhronosGroup/MoltenVK">even Apple probably cannot hold back this eruption</a>.</p>
<p>And of course, the Futhark multi-core backend should run well on any Unix-like system.</p>


    </div></div>]]>
            </description>
            <link>https://futhark-lang.org/blog/2020-11-11-will-futhark-work-on-apple-silicon.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060172</guid>
            <pubDate>Wed, 11 Nov 2020 17:04:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Minimal 3D creative coding tool ‚Äì control 8√ó8√ó8 dots with JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25060146">thread link</a>) | @doersino
<br/>
November 11, 2020 | https://doersino.github.io/tixyz/ | <a href="https://web.archive.org/web/*/https://doersino.github.io/tixyz/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://doersino.github.io/tixyz/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060146</guid>
            <pubDate>Wed, 11 Nov 2020 17:02:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A look at how LinkedIn exfiltrates extension data from their users (2020)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25060089">thread link</a>) | @coreyprophitt
<br/>
November 11, 2020 | https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-their-users | <a href="https://web.archive.org/web/*/https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-their-users">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <div>
          <p><img src="https://prophitt.me/assets/images/posts/linkedins-gambit.svg" width="300" height="300"></p><div>
            
            <p><time datetime="2020/11/05T00:00:00Z">Published on November 5th, 2020</time>
          </p></div>
        </div>

        <p><span>√Ç¬∑</span><span>√Ç¬∑</span><span>√Ç¬∑</span></p>

        <h2>What did I find?</h2>
        <p>
          LinkedIn is actively spraying their users' browser with web requests and dom queries in an attempt to determine
          if certain browser extensions are installed. The data is then exfiltrated back to LinkedIn.
        </p>
        <p>
          It is not clear what the data is used for or how it is used by LinkedIn. However, it is clear LinkedIn is
          targeting certain sales and recruiting tools. It is also common knowledge in the sales and recruiting
          communities that LinkedIn restricts or outright bans accounts based on the use of unapproved tools.
        </p>
        <p>
          LinkedIn is within their right to detect malicious user behavior and take action. However, the means they are
          employing are problematic for a number of reasons:
          </p><ol>
            <li>
              LinkedIn doesn't verify you are actually using the extension, they only check if the extension is currently
              installed and/or enabled.
            </li>
            <li>
              A number of the tools LinkedIn does not allow have legitimate uses and can be used on public web pages.
            </li>
            <li>
              The exfiltrated data could be further used for nefarious things such as browser finger printing.
            </li>
          </ol>
        

        <p>
          Furthermore, the methods employed by LinkedIn to detect extensions take advantage of developer oversights and
          browser extension limitations. This comes across as shady to me.
        </p>

        <h2>Unraveling the Mystery</h2>
        <p>
          I was initially turned on to LinkedIn's data exfiltration when I noticed a large number of failed web requests while visiting
          a LinkedIn profile. Initially, I thought my adblocker was blocking network requests. However, upon a closer look I noticed the
          web requests were not being sent across the web. They were actually being sent locally, to the browser itself. This can be
          seen clearly when viewing the network request's path. The paths were all being made using Chrome's own extension protocol. All
          requests began with <strong>chrome-extension://</strong>.
        </p>
        <p>
          For the uninitiated, the Chrome extension protocol is used to make web requests directly to an installed browser extension.
          Typically, this is used by the extension itself to retrieve resources or assets. However, any resources listed in an extension's
          manifest under the <strong>"web_accessible_resources"</strong> key are available to all web page contexts. Ironically, this
          section of the manifest was designed to minimize browser fingerprinting and protect the privacy of the extension user. Here's
          an excerpt directly from <a target="_blank" rel="noopener noreferrer" href="https://developer.chrome.com/extensions/manifest/web_accessible_resources">
          Google's own documentation</a> regarding the web accessible resources:
        </p>

        <blockquote>
         Prior to manifest version 2 all resources within an extension could be accessed from any page on the web. This allowed a malicious website to fingerprint the extensions that a user has installed or exploit vulnerabilities (for example XSS bugs) within installed extensions. Limiting availability to only resources which are explicitly intended to be web accessible serves to both minimize the available attack surface and protect the privacy of users.
        </blockquote>

        <p>
         Unfortunately, Google's changes only minimized the attack surface and did not prevent browser fingerprinting or privacy violations.
         It is this very issue that is leveraged by LinkedIn to identify installed extensions.
        </p>

        <p>
          My curiosity got the best of me and I set out to learn more about how LinkedIn was performing the scan and what they were doing
          with the data.
        </p>

        <h2>Eeny, Meeny, Miny, Moe</h2>
        <p>
          The sheer number of Chrome extension web requests performed by LinkedIn were staggering. I began to wonder how they were storing
          all of the extension information in order to make those web requests. The hunt began.
        </p>
        <p>
          Initially, I jotted down a few of the unique extension ids in hopes of finding references to them. I looked for any reference
          to the ids within LinkedIn's web responses but I had no luck. I looked within LinkedIn's web resources and code, but again I had no
          luck. Another idea crossed my mind; <i>Maybe they were hiding the extension information in their cookies or local storage?</i>
        </p>
        <p>
          My hunch led me to LinkedIn's local storage and a curious key, <strong>C_C_M</strong>. The value for the key was a large,
          seemingly random set of characters seen below:
        </p><pre><code>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‚Ä¶</code></pre></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-their-users">https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-their-users</a></em></p>]]>
            </description>
            <link>https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-their-users</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060089</guid>
            <pubDate>Wed, 11 Nov 2020 16:58:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Xilinx-Samsung SmartSSD Computational Storage Drive Launched]]>
            </title>
            <description>
<![CDATA[
Score 104 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25059946">thread link</a>) | @blopeur
<br/>
November 11, 2020 | https://www.servethehome.com/xilinx-samsung-smartssd-computational-storage-drive-launched/ | <a href="https://web.archive.org/web/*/https://www.servethehome.com/xilinx-samsung-smartssd-computational-storage-drive-launched/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://www.servethehome.com/wp-content/uploads/2020/11/smartssd-pr-1120x560-1.jpg" data-caption="Smartssd Pr 1120x560"><img width="696" height="461" src="https://www.servethehome.com/wp-content/uploads/2020/11/smartssd-pr-1120x560-1-696x461.jpg" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/smartssd-pr-1120x560-1-696x461.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/11/smartssd-pr-1120x560-1-400x265.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/11/smartssd-pr-1120x560-1-634x420.jpg 634w, https://www.servethehome.com/wp-content/uploads/2020/11/smartssd-pr-1120x560-1.jpg 800w" sizes="(max-width: 696px) 100vw, 696px" alt="Smartssd Pr 1120x560" title="Smartssd Pr 1120x560"></a><figcaption>Smartssd Pr 1120x560</figcaption></figure></div>
            <!-- content --><p>Computational storage is a small but growing segment of the market. To address this, the Samsung SmartSSD is being launched with a Xilinx Kintex FPGA inside to bring computational storage capabilities in a standard form factor. In this article, we are going to discuss how Xilinx and Samsung are delivering a computational storage platform.<span id="more-48283"></span></p>
<h2>Xilinx-Samsung SmartSSD Background</h2>
<p>First, why computational storage. One of the big drivers is that moving data, at high speeds, across systems can use a lot of power and consumes bandwidth. With computational storage, data can be processed without bringing it back to the main CPU.</p>
<figure id="attachment_48289" aria-describedby="caption-attachment-48289"><a href="https://www.servethehome.com/?attachment_id=48289" rel="attachment wp-att-48289"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand.png" alt="Xilinx SmartSSD Computational Storage Demand" width="1511" height="825" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand.png 1511w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand-400x218.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand-800x437.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand-696x380.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand-1068x583.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand-769x420.png 769w" sizes="(max-width: 1511px) 100vw, 1511px"></a><figcaption id="caption-attachment-48289">Xilinx SmartSSD Computational Storage Demand</figcaption></figure>
<p>Part of the other driver here is that Xilinx sees computational storage as becoming mainstream, projected to be 5% of the market in only a few years. For its part, Xilinx is covering a number of different types of accelerators aside form the Samsung SmartSSD including those from Pliops, ScaleFlux, and BittWare.</p>
<figure id="attachment_48288" aria-describedby="caption-attachment-48288"><a href="https://www.servethehome.com/?attachment_id=48288" rel="attachment wp-att-48288"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream.png" alt="Xilinx SmartSSD Computational Storage Becoming Mainstream" width="1481" height="781" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream.png 1481w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream-400x211.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream-800x422.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream-696x367.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream-1068x563.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream-796x420.png 796w" sizes="(max-width: 1481px) 100vw, 1481px"></a><figcaption id="caption-attachment-48288">Xilinx SmartSSD Computational Storage Becoming Mainstream</figcaption></figure>
<p>The basic Samsung SmartSSD has two main sets of components. One is basically a 4TB Samsung V-NAND SSD. This includes a NAND controller, and we are told DRAM for the controller to use as well. The second part of the solution is a Xilinx Kintex FPGA with its own 4GB of memory.</p>
<figure id="attachment_48285" aria-describedby="caption-attachment-48285"><a href="https://www.servethehome.com/?attachment_id=48285" rel="attachment wp-att-48285"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components.png" alt="Samsung Xilinx SmartSSD Internal Components" width="1263" height="783" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components.png 1263w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components-400x248.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components-800x496.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components-696x431.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components-1068x662.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components-677x420.png 677w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components-356x220.png 356w" sizes="(max-width: 1263px) 100vw, 1263px"></a><figcaption id="caption-attachment-48285">Samsung Xilinx SmartSSD Internal Components</figcaption></figure>
<p>The basic flow is that commands can be issued to either the SSD or the FPGA portion of the drive and processing can occur at the FPGA instead of going back to the host system.</p>
<figure id="attachment_48286" aria-describedby="caption-attachment-48286"><a href="https://www.servethehome.com/?attachment_id=48286" rel="attachment wp-att-48286"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation.png" alt="Samsung Xilinx SmartSSD Internal Operation" width="1456" height="836" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation.png 1456w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation-400x230.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation-800x459.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation-696x400.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation-1068x613.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation-731x420.png 731w" sizes="(max-width: 1456px) 100vw, 1456px"></a><figcaption id="caption-attachment-48286">Samsung Xilinx SmartSSD Internal Operation</figcaption></figure>
<p>We are going to show an example later but a common question will be how are these programmed. One can use a standard storage stack or the OpenCL stack for computational storage aspects.</p>
<figure id="attachment_48291" aria-describedby="caption-attachment-48291"><a href="https://www.servethehome.com/?attachment_id=48291" rel="attachment wp-att-48291"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack.png" alt="Xilinx SmartSSD IP Runtime Stack" width="1470" height="723" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack.png 1470w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-400x197.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-800x393.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-696x342.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-1068x525.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-854x420.png 854w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-324x160.png 324w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-533x261.png 533w" sizes="(max-width: 1470px) 100vw, 1470px"></a><figcaption id="caption-attachment-48291">Xilinx SmartSSD IP Runtime Stack</figcaption></figure>
<p>As one would expect with a FPGA, there is a tie in with partner IP solutions as well as those that Xilinx and Samsung will have.</p>
<figure id="attachment_48290" aria-describedby="caption-attachment-48290"><a href="https://www.servethehome.com/?attachment_id=48290" rel="attachment wp-att-48290"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development.png" alt="Xilinx SmartSSD IP Development" width="1487" height="727" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development.png 1487w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development-400x196.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development-800x391.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development-696x340.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development-1068x522.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development-859x420.png 859w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development-533x261.png 533w" sizes="(max-width: 1487px) 100vw, 1487px"></a><figcaption id="caption-attachment-48290">Xilinx SmartSSD IP Development</figcaption></figure>
<p>The Xilinx Storage Services (XSS) are offloads available for the platform. These include compression and crypto offloads.</p>
<figure id="attachment_48292" aria-describedby="caption-attachment-48292"><a href="https://www.servethehome.com/?attachment_id=48292" rel="attachment wp-att-48292"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services.png" alt="Xilinx SmartSSD IP Xilinx Storage Services" width="1531" height="786" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services.png 1531w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services-400x205.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services-800x411.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services-696x357.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services-1068x548.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services-818x420.png 818w" sizes="(max-width: 1531px) 100vw, 1531px"></a><figcaption id="caption-attachment-48292">Xilinx SmartSSD IP Xilinx Storage Services</figcaption></figure>
<p>Taking the compression in VDO as an example, the following slides have the basic flow:</p>
<figure id="attachment_48294" aria-describedby="caption-attachment-48294"><a href="https://www.servethehome.com/?attachment_id=48294" rel="attachment wp-att-48294"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1.png" alt="Xilinx SmartSSD VDO 1" width="1379" height="780" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1.png 1379w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1-400x226.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1-800x453.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1-696x394.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1-1068x604.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1-743x420.png 743w" sizes="(max-width: 1379px) 100vw, 1379px"></a><figcaption id="caption-attachment-48294">Xilinx SmartSSD VDO 1</figcaption></figure>
<p>For reads, the FPGA is used to decompress data at the SmartSSD. By putting the compression on the SSD, Xilinx says it can get better compression ratios.</p>
<figure id="attachment_48295" aria-describedby="caption-attachment-48295"><a href="https://www.servethehome.com/?attachment_id=48295" rel="attachment wp-att-48295"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2.png" alt="Xilinx SmartSSD VDO 2" width="1447" height="784" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2.png 1447w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2-400x217.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2-800x433.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2-696x377.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2-1068x580.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2-775x420.png 775w" sizes="(max-width: 1447px) 100vw, 1447px"></a><figcaption id="caption-attachment-48295">Xilinx SmartSSD VDO 2</figcaption></figure>
<p>In terms of examples, we wanted to highlight one from Lewis Rhodes Labs where they are doing NPUSearch using computational storage. Effectively here the SmartSSDs are being used to scale out the number of accelerators with the number of SSDs. An application can send requests to the storage, data can be evaluated at the drives, and only results passed back to the main system.</p>
<figure id="attachment_48293" aria-describedby="caption-attachment-48293"><a href="https://www.servethehome.com/?attachment_id=48293" rel="attachment wp-att-48293"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search.png" alt="Xilinx SmartSSD Lewis Rhodes Labs Search" width="1538" height="837" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search.png 1538w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search-400x218.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search-800x435.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search-1536x836.png 1536w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search-696x379.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search-1068x580.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search-772x420.png 772w" sizes="(max-width: 1538px) 100vw, 1538px"></a><figcaption id="caption-attachment-48293">Xilinx SmartSSD Lewis Rhodes Labs Search</figcaption></figure>
<p>Since many of our readers will have noticed this, we asked about the PCIe Gen3 and we were told that there is a roadmap to the future.</p>
<h2>Final Words</h2>
<p>For STH readers, an immediate question is going to be why computational storage? Part of this model is that accelerators are tied to storage. For accelerator companies, this is great. Many of our readers though are going to ask about why not use DPUs instead. If you missed it&nbsp;<a href="https://www.servethehome.com/what-is-a-dpu-a-data-processing-unit-quick-primer/">What is a DPU A Data Processing Unit Quick Primer</a> is a good resource there. We asked since if the only goal is offload, and the SmartSSD is in many ways two devices that are co-packaged, then it could make sense to offload to a bigger chip. We were told that it is less expensive to use a smaller accelerator on each drive than to scale to a larger accelerator. This is one area that we know there is a lot of momentum behind each model in the data center. It will be interesting to see which ultimately wins.</p>
        </div></div>]]>
            </description>
            <link>https://www.servethehome.com/xilinx-samsung-smartssd-computational-storage-drive-launched/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059946</guid>
            <pubDate>Wed, 11 Nov 2020 16:46:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Miniselect: Practical and Generic Selection Algorithms]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25059942">thread link</a>) | @cristaloleg
<br/>
November 11, 2020 | https://danlark.org/2020/11/11/miniselect-practical-and-generic-selection-algorithms/ | <a href="https://web.archive.org/web/*/https://danlark.org/2020/11/11/miniselect-practical-and-generic-selection-algorithms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-555">

	

	
	<div>
		
<p>Today I present a big effort from my side to publish <a href="https://github.com/danlark1/miniselect">miniselect</a> ‚Äî generic C++ library to support multiple selection and partial sorting algorithms. It is already <a href="https://github.com/ClickHouse/ClickHouse/pull/16825">used</a> in <a href="https://clickhouse.tech/">ClickHouse</a> with huge performance benefits. Exact benchmarks and results will be later in this post and now let‚Äôs tell some stories about how it all arose. I publish this library under Boost License and any contributions are highly welcome.</p>



<h2>It all started with sorting</h2>



<p>While reading lots of articles, papers, and posts from Hacker News, I found it pretty funny each several months new ‚Äúshiny‚Äù, ‚Äúfastest‚Äù, ‚Äúgeneric‚Äù sorting algorithms to come or remembered from old papers such as the recent paper on <a href="https://blog.acolyer.org/2020/10/19/the-case-for-a-learned-sorting-algorithm/">learned sorting</a>, <a href="https://sortingsearching.com/2020/06/06/kirkpatrick-reisch.html">Kirkpatrick-Reisch</a> sort or <a href="https://news.ycombinator.com/item?id=14661659">pdqsort</a>. It is that we are essentially 65+ years into writing sorting algorithms, and we still find improvements. Shouldn‚Äôt sorting items be a ‚Äúsolved‚Äù problem by now? Unfortunately, not. New hardware features come, we find that sorting numbers can be actually done faster than best comparison <img src="https://s0.wp.com/latex.php?latex=O%28n+%5Clog+n%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n \log n)" title="O(n \log n)"> time complexity and we still find improvements in sorting algorithms like avoiding <a href="https://www.researchgate.net/publication/301614727_BlockQuicksort_How_Branch_Mispredictions_don't_affect_Quicksort">branches in partitions</a> and trying to find good pivots as pdqsort does. Also, there are many open questions in that area as ‚Äúwhat is the minimum number of comparisons needed?‚Äù.</p>



<p>Huge competition is still going on in sorting algorithms and I believe we are not near the optimal sorting and learned sorting looks like the next step. But it uses the fundamental fact that no one expects sorting to be completed in a couple of passes and we can understand something about data during first array passes. We will understand why it matters later.</p>



<p>My favorite general sorting is <a href="https://github.com/orlp/pdqsort">pdqsort</a>, it proves to be currently the best general sorting algorithm and it shows a significant boost over all standard sorts that are provided in C++. It is also <a href="https://docs.rs/pdqsort/1.0.3/pdqsort/">used</a> in Rust.</p>



<h2>Selection and Partial Sorting</h2>



<p>Nearly a couple of months ago I started thinking about a slightly different approach when it comes to sorting ‚Äî partial sorting algorithms. It means that you don‚Äôt need to sort all <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n" title="n"> elements but only find <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> smallest and sort them. For example, it is widely used in SQL queries when you do <code>ORDER BY LIMIT N</code> and <code>N</code> is often small, from 1-10 to ideally couple of thousands, bigger values still happen but rare. And, oh god, how little engineering and theoretical research has been done there compared to full sorting algorithms. In fact, the question of specifically finding <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k">th order statistics when <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> is small is open and no good solution is presented. Also, partial sorting is quite easy to obtain after that, you need to sort the first <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> elements by some sorting algorithm to get optimal <img src="https://s0.wp.com/latex.php?latex=O%28n+%2B+k+%5Clog+k%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n + k \log k)" title="O(n + k \log k)"> comparisons and we will look at only one example when it is not the case. Yes, there are a bunch of median algorithms that can be generalized to find the <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k">th smallest element. So, what are they? Yeah, you may know some of them but let‚Äôs revise, it is useful to know your enemies.</p>



<h3>QuickSelect</h3>



<p>This is almost the very first algorithm for finding the <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k">th smallest element, just do like <a href="https://en.wikipedia.org/wiki/Quicksort">QuickSort</a> but don‚Äôt go recursively in two directions, that‚Äôs it. Pick middle or even random element and partition by this element, see in which of two parts <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> is located, update the one of the borders, voila, after maximum of <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n" title="n"> partitions you will find <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k">th smallest element. Good news that on average it takes <img src="https://s0.wp.com/latex.php?latex=O%28n%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n)" title="O(n)"> comparisons if we pick random pivot. That is because if we define <img src="https://s0.wp.com/latex.php?latex=C%28n%2C+k%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="C(n, k)" title="C(n, k)"> is the expected number of comparisons for finding <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k">th element in <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n" title="n"> elements and <img src="https://s0.wp.com/latex.php?latex=C%28n%29+%3D+%5Cmax_%7B1%7D%5E%7Bn%7D+C%28n%2C+k%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="C(n) = \max_{1}^{n} C(n, k)" title="C(n) = \max_{1}^{n} C(n, k)">, then during one stage we do <img src="https://s0.wp.com/latex.php?latex=n+-+1&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n - 1" title="n - 1"> comparisons and uniformly pick any pivot, then even if we pick the biggest part on each step</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+C%28n%29+%5Cleq+n+-+1+%2B+%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bn%2F2%7D%5E%7Bn+-+1%7D+C%28i%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="\displaystyle C(n) \leq n - 1 + \frac{1}{n}\sum_{n/2}^{n - 1} C(i)" title="\displaystyle C(n) \leq n - 1 + \frac{1}{n}\sum_{n/2}^{n - 1} C(i)"></p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+C%28n%29+%5Cleq+%28n+-+1%29+%2B+%5Cmathrm%7Bavg%7D%28C%28n%2F2%29%2C+%5Cldots%2C+C%28n%29%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="\displaystyle C(n) \leq (n - 1) + \mathrm{avg}(C(n/2), \ldots, C(n))" title="\displaystyle C(n) \leq (n - 1) + \mathrm{avg}(C(n/2), \ldots, C(n))"></p>



<p>If assuming by induction that <img src="https://s0.wp.com/latex.php?latex=C%28i%29+%5Cleq+4i&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="C(i) \leq 4i" title="C(i) \leq 4i"> with an obvious induction base, we get</p>



<p><img src="https://s0.wp.com/latex.php?latex=C%28n%29+%5Cleq+%28n+-+1%29+%2B+%5Cmathrm%7Bavg%7D%28C%28n%2F2%29%2C+%5Cldots%2C+C%28n%29%29+%5Cleq+n+-+1+%2B+4%283n%2F4%29+%3C+4n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="C(n) \leq (n - 1) + \mathrm{avg}(C(n/2), \ldots, C(n)) \leq n - 1 + 4(3n/4) < 4n" title="C(n) \leq (n - 1) + \mathrm{avg}(C(n/2), \ldots, C(n)) \leq n - 1 + 4(3n/4) < 4n"> </p>



<p>Bad news is that the worst case will still be <img src="https://s0.wp.com/latex.php?latex=O%28n%5E2%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n^2)" title="O(n^2)"> if we are unfortunate and always pick the biggest element as a pivot, thus partitioning .</p>



<p>In that sense that algorithm provides lots of pivot ‚Äústrategies‚Äù that are used nowadays, for example, picking pivot as a <img src="https://s0.wp.com/latex.php?latex=n%2F2&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n/2" title="n/2"> element of the array or picking pivot from 3 random elements . Or do like <code>std::nth_element</code> from libcxx ‚Äî choose the middle out out of <img src="https://s0.wp.com/latex.php?latex=A%5B0%5D%2C+A%5Bn%2F2%5D%2C+A%5Bn+-+1%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="A[0], A[n/2], A[n - 1]" title="A[0], A[n/2], A[n - 1]">.</p>



<p>I decided to visualize all algorithms I am going to talk about today, so quickselect with a median of 3 strategy on random input looks something like this:</p>



<figure><img data-attachment-id="579" data-permalink="https://danlark.org/nth-element-clang-2020-11-09_11-18-38/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/nth-element-clang-2020-11-09_11.18.38.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="nth-element-clang-2020-11-09_11.18.38" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/nth-element-clang-2020-11-09_11.18.38.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/nth-element-clang-2020-11-09_11.18.38.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/nth-element-clang-2020-11-09_11.18.38.gif?w=1024" alt=""><figcaption>nth_element in libcxx, median of 3 strategies</figcaption></figure>



<p>And random pivot out of 3 elements works similar</p>



<figure><img data-attachment-id="581" data-permalink="https://danlark.org/median-of-3-random-2020-11-09_11-06-02/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/median-of-3-random-2020-11-09_11.06.02.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="median-of-3-random-2020-11-09_11.06.02" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/median-of-3-random-2020-11-09_11.06.02.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/median-of-3-random-2020-11-09_11.06.02.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/median-of-3-random-2020-11-09_11.06.02.gif?w=1024" alt=""><figcaption>Finding median in median of 3 random algorithm</figcaption></figure>



<p>For a strategy like <a href="https://github.com/llvm/llvm-project/blob/3ed89b51da38f081fedb57727076262abb81d149/libcxx/include/algorithm#L5159">libcxx</a> (C++ llvm standard library) does, there are quadratic counterexamples that are pretty easy to detect, such patterns also appear in real data. The counterexample looks like that:</p>



<figure><div>
<div id="gist106376435">
    <div>
      <div>
        

      </div>
      
    </div>
</div>

</div></figure>



<figure><img data-attachment-id="584" data-permalink="https://danlark.org/nth_element_clang_median_3_killer-2020-11-10_22-55-30/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/nth_element_clang_median_3_killer-2020-11-10_22.55.30.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="nth_element_clang_median_3_killer-2020-11-10_22.55.30" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/nth_element_clang_median_3_killer-2020-11-10_22.55.30.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/nth_element_clang_median_3_killer-2020-11-10_22.55.30.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/nth_element_clang_median_3_killer-2020-11-10_22.55.30.gif?w=1024" alt=""><figcaption>std::nth_element in libcxx for Medianof3Killer</figcaption></figure>



<p>This is definitely quadratic. By the way, this is perfectly ok with the C++ standard wording as it says:</p>



<figure><img data-attachment-id="587" data-permalink="https://danlark.org/2020-11-10-230126_795x63_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png" data-orig-size="795,63" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-11-10-230126_795x63_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png?w=795" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png 795w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png?w=768 768w" sizes="(max-width: 795px) 100vw, 795px"><figcaption><a href="https://eel.is/c++draft/alg.nth.element#5">https://eel.is/c++draft/alg.nth.element#5</a></figcaption></figure>



<h2>Median of Medians</h2>



<p>For a long time, computer scientists thought that it is impossible to find medians in worst-case linear time, however, Blum, Floyd, Pratt, Rivest, Tarjan came up with BFPRT algorithm or like sometimes it is called, median of medians algorithm.</p>



<p>Median of medians algorithm: Given array <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="A" title="A"> of size <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n" title="n"> and integer <img src="https://s0.wp.com/latex.php?latex=k+%5Cleq+n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k \leq n" title="k \leq n">,</p>



<ol><li>Group the array into <img src="https://s0.wp.com/latex.php?latex=n%2F5&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n/5" title="n/5"> groups of size 5 and find the median of each group. (For simplicity, we will ignore integrality issues.)</li><li>Recursively, find the true median of the medians. Call this <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="p" title="p">.</li><li>Use <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="p" title="p"> as a pivot to partition the array.</li><li>Recurse on the appropriate piece.</li></ol>



<p>When we find the median <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="p" title="p"> of <img src="https://s0.wp.com/latex.php?latex=g+%3D+n%2F5&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="g = n/5" title="g = n/5"> groups, at least <img src="https://s0.wp.com/latex.php?latex=g%2F2&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="g/2" title="g/2"> of them have at least 3 out of 5 elements that are smaller or equal than <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="p" title="p">, that said the biggest out of 2 partitioned chunks have size <img src="https://s0.wp.com/latex.php?latex=7n%2F10&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="7n/10" title="7n/10"> and we have the reccurence</p>



<p><img src="https://s0.wp.com/latex.php?latex=C%28n%29+%5Cleq+cn+%2B+C%28n%2F5%29+%2B+C%287n%2F10%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="C(n) \leq cn + C(n/5) + C(7n/10)" title="C(n) \leq cn + C(n/5) + C(7n/10)"></p>



<p>If we appropriately build the recurse tree we will see that</p>



<figure><img data-attachment-id="589" data-permalink="https://danlark.org/2020-11-10-232345_1330x458_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png" data-orig-size="1330,458" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-11-10-232345_1330x458_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=1024" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=1024 1024w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=768 768w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png 1330w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>This is the geometric series with <img src="https://s0.wp.com/latex.php?latex=cn%281+%2B+9%2F10+%2B+%289%2F10%29%5E2+%2B+%289%2F10%29%5E3+%2B+%5Cldots+...%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="cn(1 + 9/10 + (9/10)^2 + (9/10)^3 + \ldots ...)" title="cn(1 + 9/10 + (9/10)^2 + (9/10)^3 + \ldots ...)"> which gives us the result <img src="https://s0.wp.com/latex.php?latex=C%28n%29+%5Cleq+10+c+n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="C(n) \leq 10 c n" title="C(n) \leq 10 c n">.</p>



<p>Actually, this constant 10 is really big. For example, if we look a bit closer, <img src="https://s0.wp.com/latex.php?latex=c&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="c" title="c"> is at least 1 because we need to partition the array, then finding median out of 5 elements cannot be done in less than 6 comparisons (can be proven by only brute-forcing) and in 6 comparisons it can be done in the following way</p>



<ol><li>Use three comparisons and shuffle around the numbers so that <img src="https://s0.wp.com/latex.php?latex=a%5B1%5D+%3C+a%5B2%5D%2C+a%5B4%5D+%3C+a%5B5%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[1] < a[2], a[4] < a[5]" title="a[1] < a[2], a[4] < a[5]">, and <img src="https://s0.wp.com/latex.php?latex=a%5B1%5D+%3C+a%5B4%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[1] < a[4]" title="a[1] < a[4]">.</li><li>If <img src="https://s0.wp.com/latex.php?latex=a%5B3%5D+%3E+a%5B2%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[3] > a[2]" title="a[3] > a[2]">, then the problem is fairly easy. If <img src="https://s0.wp.com/latex.php?latex=a%5B2%5D+%3C+a%5B4%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[2] < a[4]" title="a[2] < a[4]">, the median value is the smaller of <img src="https://s0.wp.com/latex.php?latex=a%5B3%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[3]" title="a[3]"> and <img src="https://s0.wp.com/latex.php?latex=a%5B4%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[4]" title="a[4]">. If not, the median value is the smaller of <img src="https://s0.wp.com/latex.php?latex=a%5B2%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[2]" title="a[2]"> and <img src="https://s0.wp.com/latex.php?latex=a%5B5%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[5]" title="a[5]">.</li><li>So <img src="https://s0.wp.com/latex.php?latex=a%5B3%5D+%3C+a%5B2%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[3] < a[2]" title="a[3] < a[2]">. If <img src="https://s0.wp.com/latex.php?latex=a%5B3%5D+%3E+a%5B4%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[3] > a[4]" title="a[3] > a[4]">, then the solution is the smaller of <img src="https://s0.wp.com/latex.php?latex=a%5B3%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[3]" title="a[3]"> and <img src="https://s0.wp.com/latex.php?latex=a%5B5%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[5]" title="a[5]">. Otherwise, the solution is the smaller of <img src="https://s0.wp.com/latex.php?latex=a%5B2%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[2]" title="a[2]"> and <img src="https://s0.wp.com/latex.php?latex=a%5B4%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[4]" title="a[4]">.</li></ol>



<p>So that maximum <img src="https://s0.wp.com/latex.php?latex=c&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="c" title="c"> can be <img src="https://s0.wp.com/latex.php?latex=11%2F5&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="11/5" title="11/5"> and it gives us the upper bound <img src="https://s0.wp.com/latex.php?latex=22n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="22n" title="22n"> comparisons which looks like it can be achieved. Some other tricks can be done in place to achieve a bit lower constants like <img src="https://s0.wp.com/latex.php?latex=18n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="18n" title="18n"> (for example, sorting arrays of 5 and comparing less afterwards). In practice, the constant is really big and you can see it from the following demonstration which was even fastened because it took quite a few seconds:</p>



<figure><img data-attachment-id="593" data-permalink="https://danlark.org/median-of-medians-2020-11-09_11-04-33/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/median-of-medians-2020-11-09_11.04.33.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="median-of-medians-2020-11-09_11.04.33" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/median-of-medians-2020-11-09_11.04.33.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/median-of-medians-2020-11-09_11.04.33.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/median-of-medians-2020-11-09_11.04.33.gif?w=1024" alt=""><figcaption>Median of medians for random input</figcaption></figure>



<h2>HeapSelect</h2>



<p>Another approach to finding <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k">th element is to create a <a href="https://en.wikipedia.org/wiki/Heap_(data_structure)">heap</a> on an array of size <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> and push other <img src="https://s0.wp.com/latex.php?latex=n+-+k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n - k" title="n - k"> elements into this heap. C++ <code>std::partial_sort</code> works that way (with additional heap sorting of the first heap). It shows good results for very small <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> and random/ascending arrays, however starts to significantly degrade with growing <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> and becomes impractical. Best case <img src="https://s0.wp.com/latex.php?latex=O%28n%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n)" title="O(n)">, worst <img src="https://s0.wp.com/latex.php?latex=O%28n+%5Clog+k%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n \log k)" title="O(n \log k)">, average <img src="https://s0.wp.com/latex.php?latex=O%28n+%5Clog+k%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n \log k)" title="O(n \log k)">.</p>



<figure><img data-attachment-id="596" data-permalink="https://danlark.org/partial_sort-2020-11-09_12-28-40/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/partial_sort-2020-11-09_12.28.40.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="partial_sort-2020-11-09_12.28.40" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/partial_sort-2020-11-09_12.28.40.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/partial_sort-2020-11-09_12.28.40.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/partial_sort-2020-11-09_12.28.40.gif?w=1024" alt=""><figcaption>std::partial_sort, two stages, first HeapSelect then heap sort of the first half, accelerated for speed</figcaption></figure>



<h2>IntroSelect</h2>



<p>As the previous algorithm is not very much practical and QuickSelect is really good on average, in 1997 <a href="http://www.cs.rpi.edu/~musser/gp/introsort.ps">‚ÄúIntrospective Sorting and Selection Algorithms‚Äù</a>  from David Musser came out with a sorting algorithm called ‚ÄúIntroSelect‚Äù. </p>



<p>IntroSelect works by optimistically starting out with QuickSelect and only switching to MedianOfMedians if it recurses too many times without making sufficient progress. Simply limiting the recursion to constant depth is not good enough, since this would make the algorithm switch on all sufficiently large arrays. Musser discusses a couple of simple approaches:</p>







<p>This algorithm came into <a href="https://github.com/gcc-mirror/gcc/blob/e0af865ab9d9d5b6b3ac7fdde26cf9bbf635b6b4/libstdc%2B%2B-v3/include/bits/stl_algo.h#L4748">libstdcxx</a> and guess which strategy was chosen? Correct, none of them. Instead, they try <img src="https://s0.wp.com/latex.php?latex=2%5Clog+n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="2\log n" title="2\log n"> QuickSelect steps and if not successful, fallback to HeapSelect algorithm. So, worst case <img src="https://s0.wp.com/latex.php?latex=O%28n+%5Clog+n%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n \log n)" title="O(n \log n)">, average <img src="https://s0.wp.com/latex.php?latex=O%28n%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n)" title="O(n)"></p>



<figure><img data-attachment-id="598" data-permalink="https://danlark.org/nth-element-gcc-2020-11-09_11-06-37/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/nth-element-gcc-2020-11-09_11.06.37.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="nth-element-gcc-2020-11-09_11.06.37" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/nth-element-gcc-2020-11-09_11.06.37.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/nth-element-gcc-2020-11-09_11.06.37.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/nth-element-gcc-2020-11-09_11.06.37.gif?w=1024" alt=""><figcaption>std::nth_element in libstdcxx, ‚ÄúIntroSelect‚Äù</figcaption></figure>



<h2>PDQSelect</h2>



<p>Now that most of the known algorithms come to an end üòà, we can start looking into something special and extraordinary. And the first one to look at is pdqselect which comes pretty straightforward from <a href="https://github.com/orlp/pdqsort">pdqsort</a>, the algorithm is basically QuickSelect but with some interesting ideas on how to choose an appropriate pivot:</p>



<ol><li>If there are <img src="https://s0.wp.com/latex.php?latex=n+%3C+24&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n < 24" title="n < 24"> elements, use <a href="https://en.wikipedia.org/wiki/Insertion_sort">insertion sort</a> to partition or even sort them. As insertion sort is really fast for a small amount of elements, it is reasonable</li><li>If it is more, choose <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="p" title="p"> ‚Äî pivot:<ol><li>If there are less or equal than 128 elements, choose pseudomedian (or ‚Äúninther‚Äù, or median of medians which are all them same) of the following 3 groups:<ol><li>begin, mid, end</li><li>begin + 1, mid ‚Äì 1, end ‚Äì 1</li><li>begin + 2, mid + 1, end ‚Äì 2</li></ol></li><li>If there are more than 128 elements, choose median of 3 from begin, mid, end</li></ol></li><li>Partition the array by the chosen pivot with avoiding <a href="https://www.researchgate.net/publication/301614727_BlockQuicksort_How_Branch_Mispredictions_don't_affect_Quicksort">branches</a>:<ol><li>The partition is called bad if it splits less than <img src="https://s0.wp.com/latex.php?latex=1%2F8n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="1/8n" title="1/8n"> elements</li><li>If the total number of bad partitions exceeds <img src="https://s0.wp.com/latex.php?latex=%5Clog+n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="\log n" title="\log n">, use <code>std::nth_element</code> or any other fallback algorithm and return</li><li>Otherwise, try to defeat some patterns in the partition by (sizes are l_size and r_size respectively):<ol><li>Swapping begin, begin + l_size / 4</li><li>Swapping p ‚Äì 1 and p ‚Äì l_size / 4</li><li>And if the number of elements is more than 128<ol><li>begin + 1, begin + l_size / 4 + 1</li><li>begin + 2, begin + l_size / 4 + 2</li><li>p ‚Äì 2, p ‚Äì l_size / 4 + 1</li><li>p ‚Äì 3, p ‚Äì l_size / 4 + 2</li></ol></li><li>Do the same with the right partition</li></ol></li></ol></li><li>Choose the right partition part and repeat like in QuickSelect</li></ol>



<figure><img data-attachment-id="605" data-permalink="https://danlark.org/pdqselect-2020-11-09_11-03-23/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/pdqselect-2020-11-09_11.03.23.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="pdqselect-2020-11-09_11.03.23" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/pdqselect-2020-11-09_11.03.23.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/pdqselect-2020-11-09_11.03.23.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/pdqselect-2020-11-09_11.03.23.gif?w=1024" alt=""><figcaption>pdqselect on random input</figcaption></figure>



<h2>Media‚Ä¶</h2></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://danlark.org/2020/11/11/miniselect-practical-and-generic-selection-algorithms/">https://danlark.org/2020/11/11/miniselect-practical-and-generic-selection-algorithms/</a></em></p>]]>
            </description>
            <link>https://danlark.org/2020/11/11/miniselect-practical-and-generic-selection-algorithms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059942</guid>
            <pubDate>Wed, 11 Nov 2020 16:46:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is It Time to Modernize the PostgreSQL Core Team?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25059852">thread link</a>) | @ahachete
<br/>
November 11, 2020 | https://postgresql.fund/blog/is-it-time-to-modernize-postgresql-core/ | <a href="https://web.archive.org/web/*/https://postgresql.fund/blog/is-it-time-to-modernize-postgresql-core/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        <div>
            <div>
                
                <div>
                    
<p>The PostgreSQL Community is large, diverse and global. There are users, enthusiasts, developers, contributors, advocates and commercial entities from around the world. All of them working in a loosely collaborative fashion to grow and make PostgreSQL succeed.</p>
<p>The Postgres Core Team is considered to be the steering committee for the Community. The definition of the group responsibilities can be <a href="https://www.postgresql.org/developer/core/">found here</a>. The core team members are listed on the <a href="https://www.postgresql.org/community/contributors/">Contributor Profiles</a> page.</p>
<p>On September 30th EnterpriseDB acquired 2ndQuadrant. At the time of the acquisition there were five members in Core; two of them were EnterpriseDB employees and another one a 2ndQuadrant employee. This meant that 60% of the Core members would be employed by EnterpriseDB. On October 20th, in an effort to diffuse concerns about a single commercial entity having majority control, the <a href="https://www.postgresql.org/about/news/statement-from-the-postgresql-core-team-on-the-edb-acquisition-of-2ndquadrant-2094/">Core Team announced</a> that this is an issue that they would be addressing:</p>
<p>‚Äú<em>There has long been an unwritten rule that there should be no more than 50% of the membership of the Core Team working for the same company</em>‚Äù</p>
<p>This rule was enacted back in the days of the <a href="https://www.postgresql.org/message-id/39181CCD.99531ADA@greatbridge.com">Great Bridge</a>. Core addressed the unwritten rule by appointing on November 2nd <a href="https://www.postgresql.org/about/news/new-postgresql-core-team-members-2103/">two new members: Andres Freund and Jonathan Katz</a>. This change in Core reduced the proportion of EnterpriseDB members to three out of seven. <strong>Fundaci√≥n PostgreSQL</strong> would like to extend a very warm welcome to Andres and Jonathan. They are both well known and long time community contributors.</p>
<p>The addition of the new members allowed Core to be compliant with the 50% rule. However: was this organizational change the best choice? Was it the only change that could have been implemented? Could we have looked at the culture of our global community and used this opportunity to strengthen our ties?</p>
<p>Here are some facts about Core‚Äôs structure and membership:</p>
<ul>
<li><strong>Company influence</strong>:
<ul>
<li>Core has switched from having 40% of its members from a single company to now having 43% from a single company and 71% from two companies.</li>
<li>100% of the members are from only 4 companies.</li>
</ul>
</li>
<li><strong>Diversity</strong>:
<ul>
<li>100% of the current Core team members are white men.</li>
<li>All of the Core members are either US or European. No other region is represented.</li>
<li>All but one Core member work for US companies.</li>
</ul>
</li>
<li><strong>Democracy:</strong>
<ul>
<li>Core members are only appointed by existing Core members. In contrast, the ‚Äú<a href="https://www.postgresql.org/community/recognition/#npos">Recognised Postgres Nonprofit Organisations</a>‚Äù (created and enforced by Core) has as a requirement that the ‚Äú<em>board of directors MUST be elected by the membership</em>‚Äù. These rules were, in turn, created by Core itself.</li>
<li>Core members serve for an <em>unlimited</em> term. In contrast, the same Community recognition rules above also require that ‚Äú<em>Lifetime directorships MUST NOT be allowed</em>‚Äù. Four of the current Core members <a href="https://web.archive.org/web/20051023004218/http://www.postgresql.org/developer/bios">have been serving in the Core team for more than 15 years</a>.</li>
</ul>
</li>
<li><strong>Transparency</strong>:
<ul>
<li>The election process, candidate selection, selection criteria, etc are all secret.</li>
<li>Core Team meeting minutes are secret.</li>
<li>Core team policies are enacted by declaration, without involvement of the global community.</li>
</ul>
</li>
</ul>
<p>Facts aside, there are some organizational concerns that may require some further analysis.</p>
<p>In the PostgreSQL distributed community, the <a href="https://www.postgresql.org/developer/core/">Core Team</a> acts as the <em>de facto</em> ‚Äúcentral authority‚Äù for the project. The <a href="https://www.postgres.ca/">Postgres Association of Canada</a> (‚ÄúCA‚Äù, in short), acts as its legal arm, holding assets (including intellectual property, like domain names and trademarks).</p>
<p>However, this presents an interesting dichotomy: Core makes decisions, but if these require a legal entity to be executed, they are executed by CA. Which has its own board of directors, that needs to approve them. What if they don‚Äôt? What if they don‚Äôt follow Core? Similarly, how is Core accountable, if it is not backed directly by a legal entity? Because of this, are there any potential liabilities faced directly by their members, as individuals? And what happens if CA‚Äôs Board goes haywire?</p>
<p>Other mature and successful open source projects, while distributed as Postgres and built from the contributions of people and organizations all around the world, are nowadays backed by clear and strong legal and organizational structure. Take for example the <a href="https://www.apache.org/foundation/">Apache Foundation</a>, or the <a href="https://www.fsf.org/working-together/fiscal-sponsorship">Free Software Foundation</a>. Or the <a href="https://www.cncf.io/">Cloud Native Computing Foundation (CNCF)</a>, which is a Charter of the Linux Foundation. Its structure <a href="https://www.cncf.io/blog/2019/12/06/cncf-toc-governance-structure-elections-2020/">has three main bodies</a>:</p>
<p>‚Äú<em>A <strong>Governing Board (GB)</strong> that is responsible for marketing, budget and other business oversight decisions for the CNCF, a <strong>Technical Oversight Committee (TOC)</strong> that is responsible for defining and maintaining the technical vision, and an <strong>End User Community (EUC)</strong> that is responsible for providing feedback from companies and startups to help improve the overall experience for the cloud native ecosystem</em>‚Äù</p>
<p>The <a href="https://www.cncf.io/people/governing-board/">Governing Board has currently 24 members</a>, and their <a href="https://www.cncf.io/about/governing-board-meeting-minutes/">meeting minutes are public</a> (they are not alone: MariaDB Foundation <a href="https://mariadb.org/bodminutes/2020-10-21/">is now publishing their board meetings too</a>); the <a href="https://www.cncf.io/people/technical-oversight-committee/">Technical Committee consists of 11 members and 77 contributors</a>; the <a href="https://docs.google.com/presentation/d/194SyKdHL7ws_DBOdbrXdowEJi54kIzDdDK_h-6Ag0uo/edit#slide=id.g9ffb40d42b_0_161">End User Community has more than 150 companies</a>; furthermore, there are dozens of <a href="https://www.cncf.io/people/ambassadors/">ambassadors</a>; and also dozens of <a href="https://www.cncf.io/people/staff/">staff</a> members. While possibly operating at a different scale than PostgreSQL, they all contribute, in different manners, to the steering, development and vision of the CNCF.</p>
<p>What do you think? <strong>Is PostgreSQL Core today what the PostgreSQL Community needs, or is it time to modernize its processes, structure and governance?</strong> If you think it is the latter, please leave your comments below. I hope this post serves as the starting point for a broader and constructive discussion that can serve as feedback to Core. Let‚Äôs ensure the best future for our beloved open source database!</p>

                </div>
                
                    
                
            </div>
        </div>
    </div>
</section></div>]]>
            </description>
            <link>https://postgresql.fund/blog/is-it-time-to-modernize-postgresql-core/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059852</guid>
            <pubDate>Wed, 11 Nov 2020 16:39:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What I Wish I Knew About Incident Management]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059769">thread link</a>) | @ronaknnathani
<br/>
November 11, 2020 | https://ronaknathani.com/blog/2020/11/what-i-wish-i-knew-about-incident-management/ | <a href="https://web.archive.org/web/*/https://ronaknathani.com/blog/2020/11/what-i-wish-i-knew-about-incident-management/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I gave this talk last year at LinkedIn‚Äôs internal SRE conference, thought I‚Äôd share it here as well.</p><hr><h2 id="why-i-am-writing-this-post">Why I am writing this post</h2><p>Like every Software Engineer / SRE, I‚Äôve had my share of troubleshooting software. However, I had never been oncall before I joined Linkedin and the impact of a system outage that affects thousands of engineers made the first week of oncall pretty overwhelming.</p><p><img src="https://ronaknathani.com/blog/2020/11/what-i-wish-i-knew-about-incident-management/then-with-caption.gif" alt="first week of me handling production issues"></p><p>But things got better overtime.</p><p>In this post, I would like to share the incident management practices I have picked up over the years as an SRE at Linkedin that help me keep calm under pressure and effectively drive incidents to resolution.</p><p><img src="https://ronaknathani.com/blog/2020/11/what-i-wish-i-knew-about-incident-management/now-with-caption.gif" alt="present me handling production issues"></p><h2 id="what-this-post-is-not-about">What this post is not about</h2><p>In this post, I am not going to talk about how to debug linux or distributed systems or the various debugging tools. (For stories from the frontlines,
<a href="https://ronaknathani.com/#subscribe">stay tuned for a podcast coming soon</a>!)</p><h2 id="first-oncall-week">First oncall week</h2><p>My first few weeks at Linkedin - they were great! I was meeting smart engineers and learning new things. It wasn‚Äôt until my first oncall rotation that I started thinking <em>what if there‚Äôs an outage and I need to fix it?</em></p><p><img src="https://ronaknathani.com/blog/2020/11/what-i-wish-i-knew-about-incident-management/anxious.gif" alt="anxiety before first week of oncall"></p><p>Now, don‚Äôt get me wrong. LinkedIn has really good systems in place for monitoring/alerting, triaging issues and a very well defined process for incident response. Those are absolutely critical. And to prepare, I had shadowed our oncall the week prior and even had an experienced team member shadow me to guide and help me out, but still, I was anxious.</p><p>Here‚Äôs what I wish I had known.</p><ul><li><a href="#before-oncall-starts">Before oncall starts</a><ul><li><a href="#oncall-handoff">Oncall handoff</a></li><li><a href="#organizing-slack-during-an-oncall-week">Organizing Slack during an oncall week</a></li></ul></li><li><a href="#signal-vs-noise">Signal vs Noise</a><ul><li><a href="#trust-but-verify---not-all-alerts-are-created-equal">Trust, but verify - not all alerts are created equal</a></li><li><a href="#declaring-an-incident">Declaring an incident</a></li></ul></li><li><a href="#communication-during-an-incident">Communication during an incident</a><ul><li><a href="#the-incident-title-and-scoping-the-impact">The incident title and scoping the impact</a></li><li><a href="#establish-communication-channels-and-an-incident-lead">Establish communication channels and an incident lead</a></li><li><a href="#communicate-changes-to-the-system">Communicate changes to the system</a></li><li><a href="#provide-regular-updates">Provide regular updates</a></li></ul></li><li><a href="#incident-response-is-a-collaborative-process">Incident response is a collaborative process</a><ul><li><a href="#get-help-early">Get help early</a></li><li><a href="#working-with-others">Working with others</a></li><li><a href="#video-conferencing-is-your-friend">Video conferencing is your friend</a></li></ul></li><li><a href="#towards-a-resolution">Towards a resolution</a><ul><li><a href="#looking-at-changes">Looking at changes</a></li><li><a href="#keep-calm-and-carry-on---one-step-at-a-time">Keep calm and carry on - one step at a time</a></li></ul></li><li><a href="#learning-from-the-incident">Learning from the incident</a></li></ul><h2 id="before-oncall-starts">Before Oncall Starts</h2><h3 id="oncall-handoff">Oncall handoff</h3><p>Before an oncall week starts, I talk to the person who is currently oncall to get context on any incidents that happened during the week or any weird bugs that were discovered in our stack. It gives me perspectives on issues that could be getting carried over from the previous week and any critical changes I should be aware of.
Although you can‚Äôt plan for all that happens during an oncall week, a proper handoff helps you prepare for it.</p><h3 id="organizing-slack-during-an-oncall-week">Organizing Slack during an oncall week</h3><p>As an SRE on LinkedIn‚Äôs container scheduler and deployment infrastructure team, our users are engineers at LinkedIn. We use Slack for internal communication and we have certain channels where users share issues they are experiencing with the tooling or to get our oncall‚Äôs attention. During an oncall week, I star these channels and organize my sidebar so that I can easily notice messages from our users and distinguish them from the other messages I receive. As an optional tip - I also like to mute/leave channels that I am not actively participating in to reduce clutter.</p><p>As compared to a normal week, I spend more time on Slack when I am oncall - responding to people, answering support requests, helping users with tooling. These Slack notifications can create a little bit of distraction, however, considering all our users are internal, a rise in messages on our channels can also indicate that something might be wrong with our system and our alerting hasn‚Äôt caught it yet.</p><p><img src="https://ronaknathani.com/blog/2020/11/what-i-wish-i-knew-about-incident-management/slack-pings.gif" alt="slack pings during oncall"></p><h2 id="signal-vs-noise">Signal vs Noise</h2><h3 id="trust-but-verify---not-all-alerts-are-created-equal">Trust, but verify - not all alerts are created equal</h3><p><img src="https://ronaknathani.com/blog/2020/11/what-i-wish-i-knew-about-incident-management/trust-but-verify-you-must.jpg" alt="trust-but-verify-you-must"></p><p><i>This is something I learned during my interview at LinkedIn and it has been very applicable in my experience since.</i></p><p>In early days of oncall and incident management, it is very common to feel as if things are on fire when any alert gets triggered. Over time, I have realized that gaining context and verifying that the alert is actually indicating an issue helps with the right next steps. It is important to distinguish signal from noise because:</p><ul><li>An alert could be non-actionable as it was recently configured with a threshold that‚Äôs making it too noisy</li><li>The monitoring stack is down and the alert is being triggered because the configuration treats a lack of data points as an issue</li><li>Your service is operating perfectly fine, however, the traffic tier routing requests to your service had an issue</li><li>Timer on a deliberately silenced alert expired and the alert started triggering</li></ul><p>I have experienced all of the above at some point in time. Now when I either receive an alert or a user reports an issue, I check our services (metrics, logs, reproduce the reported problem etc.) to verify that the issue is real.</p><h3 id="declaring-an-incident">Declaring an incident</h3><p>Not all actionable alerts result in an incident. To be effective at identifying the ones that do, it is extremely crucial to think about the bigger picture of mitigating the issue than be overwhelmed by the technical task of resolving the alert.</p><p>Some of the qualitative measures that help make this differentiation is to consider whether an issue requires coordinating the fix with other teams or whether the issue is impacting customers or violating an SLO. If any of the conditions are true, declare an incident. It is always better to declare an incident early in the process than waiting too long.</p><p>At LinkedIn, we have defined guidelines for all teams about what warrants an incident along with different levels of severity. This takes guesswork out of the picture, and provides a shared understanding to every team member.</p><h2 id="communication-during-an-incident">Communication during an incident</h2><h3 id="the-incident-title-and-scoping-the-impact">The incident title and scoping the impact</h3><p>Every incident gets a title. I didn‚Äôt realize it initially, but giving an incident a title forces one to define the problem and communicate it to the stakeholders very succinctly. When communicating to stakeholders, <strong>scoping the incident is very important</strong>. What I mean by scoping is identifying how big the impact is - which environment is impacted, is the impact limited to a region or is it global, how many customers are impacted, etc. For instance, ‚Äúthe login feature on the site is not working‚Äù vs ‚Äúthe login feature on the site is not working for traffic originating from Asia Pacific‚Äù say two very different things.</p><h3 id="establish-communication-channels-and-an-incident-lead">Establish communication channels and an incident lead</h3><p>We heavily rely on Slack to communicate during an incident. A dedicated slack channel helps focus all the energy and inputs from everyone in one place. It helps the incident lead collect data about symptoms that the users are experiencing and also captures a log of considered/discarded hypotheses and any changes made to the system. Once the Slack channel is created, establish an incident lead and let everyone know who is driving the incident forward.</p><p>Eslablishing explicit comms channels for reporting and identifying issues and establishing an incident lead reduce the delay in action and disambiguate any confusion.</p><h3 id="communicate-changes-to-the-system">Communicate changes to the system</h3><p>If there‚Äôs a fix you‚Äôd like to try out, let others know who are and encourage everyone to do the same. This ensures that the potential fix doesn‚Äôt make an already bad situation worse and helps catch any blind spots early. If you do end up making a change to the system after getting consensus, let others know and follow up on its effects.</p><h3 id="provide-regular-updates">Provide regular updates</h3><p>While working towards a resolution for the incident, it is very easy to get overwhelmed by the technical details and miss to communicate an update. This leads to angry leadership and annoyed customers who have no insight into what‚Äôs happening.</p><p>An update provides visibility to the customers that the issue is being worked upon and lets the leadership identify if they can help out with anything. Depending on the severity of the incident, an update every 15-30 mins serves pretty well. The update doesn‚Äôt have to be extremely detailed, rather a brief summary describing the current state and immediate next steps is sufficient. An example update:</p><blockquote><p><strong>[UPDATE]</strong> Our hypothesis about the memory leak checks out and we have validated the fix in the staging environment. We have pushed out the change and as soon as it goes through the CI pipeline, we‚Äôll canary the new release, monitor metrics and promote the change after verifying the fix.</p></blockquote><h2 id="incident-response-is-a-collaborative-process">Incident response is a collaborative process</h2><h3 id="get-help-early">Get help early</h3><p>In my earlier days, I used to think that it was solely my responsibility to mitigate the issue, find the root cause, and roll out the fix. If I couldn‚Äôt do it, it wouldn‚Äôt reflect well on me. In reality, incident management, like much of software development, is a very collaborative process.</p><p>One of the big differences in how I approach it now is I focus on actively pulling in other engineers who could help with debugging or resolving the issue early in the process. This change in perspective has relieved me of a lot of unnecessary stress and also made me more effective at resolving incidents.</p><p>When requesting help, be specific about the task as well as the urgency. It helps others calibrate their response and manage things they might have at hand.</p><h3 id="working-with-others">Working with others</h3><p>One of the most important things while handling incidents is working with others. Considering the multi-faceted nature of an SRE role, it‚Äôs one of the most important while underrated skills.</p><p>With multiple people involved, various possibilities get shared and one of the responsibilities of the incident lead is to guide these discussions in a productive direction while filtering out the noise. One should be cautious about going down any rabbit holes and focus on stopping the bleeding first. If there‚Äôs a probable cause, share it early - it helps rule out possibilities. And it‚Äôs okay to ask questions that seem obvious, but specific questions are more helpful.</p><p>Being fearlessly curious, and keeping an open mind enables one to consider possibilities that could be overseen otherwise. Remember, you are working together as a team on sharing and ruling out hypotheses to solve a challenging problem.</p><h3 id="video-conferencing-is-your-friend">Video Conferencing is your friend</h3><p>We work ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ronaknathani.com/blog/2020/11/what-i-wish-i-knew-about-incident-management/">https://ronaknathani.com/blog/2020/11/what-i-wish-i-knew-about-incident-management/</a></em></p>]]>
            </description>
            <link>https://ronaknathani.com/blog/2020/11/what-i-wish-i-knew-about-incident-management/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059769</guid>
            <pubDate>Wed, 11 Nov 2020 16:33:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Are Package Registries Holding Open-Source Hostage?]]>
            </title>
            <description>
<![CDATA[
Score 88 | Comments 67 (<a href="https://news.ycombinator.com/item?id=25059755">thread link</a>) | @aviaviavi
<br/>
November 11, 2020 | https://about.scarf.sh/post/package-registries-and-open-source | <a href="https://web.archive.org/web/*/https://about.scarf.sh/post/package-registries-and-open-source">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>A few days ago, I received an email from Docker about a change I already knew was coming:<em>‚Äç</em></p><blockquote><em>Docker will begin enforcing rate limits on container pulls for Anonymous and Free users.</em><br></blockquote><p>To many, this came as no surprise. For years, <a href="http://hub.docker.com/">Docker Hub</a> has offered free hosting of container images, which typically range in size from a few megabytes to many gigabytes. Docker workflows as a result use a <em>lot</em> of bandwidth, and that bandwidth costs money.<br></p><p>Should we OSS (open-source software)&nbsp;developers have to think about the business and financial models of the platforms we host our software on? In a perfect world, we wouldn't have to‚Äîbut in the real world we very much do. The incentives between OSS maintainers and the registries they use are often misaligned.&nbsp;<br></p><p>Docker Hub, <a href="http://npmjs.com/">npm</a>, and other comparable registries are incentivized to create lock-in, even if it makes the product experience worse for their users and customers. This is especially true of the for-profit companies behind the registries, but we see similar issues from many of the not-for-profit registries. </p><p>Maintainers, on the other hand, are incentivized to choose the best product for their needs at the lowest cost, which depends on being able to switch providers when a better service comes on the market.&nbsp;<br></p><p>This situation is fundamentally at odds with the today's package management ecosystem, where immutability is paramount in order to achieve stability. We avoid breaking things at all costs, on principle, since OSS packages are the nuts and bolts of the software ecosystem, the internet, and thus society itself.<br></p><h6><strong>Mechanics of registry lock-in</strong><br></h6><p>The registry where you host your packages and containers might be free today, but if that changes later, as is the case now with Docker, you and your users might be stuck paying whatever price the vendor chooses to set. Your users might even agree to access your package without the rate limit, but<strong> </strong><em>you</em> will not be seeing any of that revenue. Access to your open-source software was effectively just sold for a profit, and you, the author of that software, were cut out of the transaction.<br></p><p>While you could in theory just host your software somewhere else, can you really do that without breaking things for your current users? If you maintain and distribute a popular Docker image, switching the package registry is likely difficult.<br></p><p>Currently, any image on Docker Hub is installable as:<br></p><div><pre><code>$ docker run org-name/image-name</code></pre></div><p><em>‚Äç</em>If you decide later you actually want to move your container hosting somewhere else - let's say <a href="https://cloud.google.com/container-registry" target="_blank">Google Container Registry</a> for this example - the Docker client is reasonable and lets you pull down images by their URL:<br></p><div><pre><code>$ docker run gcr.io/org-name/image-name</code></pre></div><p><em>‚Äç</em>The problem here is that once you've changed the URL to your images, all of your existing users will stop getting updates! Even worse, this can break builds or pipelines for your users whenever they hit the new rate limits, which are not under your control. </p><p>At the point where your container has a sizable user-base all going through one of the existing container registries, your lock-in is substantial. Moving platforms will be painful. The crux of the problem here is that <em>you</em> don't own the distribution channel. The registry is the&nbsp; first place the web traffic goes, and everything that happens after that is at <em>the registry vendor‚Äôs</em><strong> </strong>discretion and to their advantage, not yours.<br></p><h6><strong>Effects of registry lock-in</strong><br></h6><p>Some might respond: <em>"This still seems like more of a theoretical problem than a practical one."</em><br></p><p>There are several practical downstream effects of the misaligned incentive structures to open-source package hosting. One major effect of registry lock-in is that maintainers cannot access their usage data. The data that registries naturally collect from package downloads can be quite useful to maintainers in a myriad of ways, yet registries typically don't share anything beyond a download count. </p><p>Registries know where the downloads are coming from, the devices, the package versions, which other packages are installed alongside, and a whole lot more. Little to none that information is shared with maintainers. Thus, maintainers are effectively locked out from observing the usage traffic.&nbsp;<br></p><p>Why is this the case? It's not because developers don't ask for it (<a href="https://github.com/npm/npm/issues/279">https://github.com/npm/npm/issues/279</a>). It's because the registries have no incentive to do so. It would cost the registries money to build and maintain the features to provide this data. Some registries even claim that exposing this data publicly would incentivize maintainers to game the system. Meanwhile, the extreme levels of inertia in software distribution keep maintainers locked in. </p><p>The registries' demonstrated distrust of maintainers seems counterproductive in a space where there's opportunity to work together cooperatively. If registry incentives were aligned accordingly, a registry like npm, for instance, would be in a great position to empower maintainers to leverage their own distribution data to deliver the best software possible.<br></p><p>What makes npm‚Äôs particular scenario even worse is that they've made it so difficult to use a registry that is<em> not</em> npm. There's no way to pull a single package from an alternate registry without switching to that registry. Which makes it quite impossible to actually publish a widely used JavaScript package without putting it on npm.&nbsp;<br></p><p>Contrast this scenario to Docker: Docker Hub creates different tradeoffs that both help and harm OSS maintainers. They've loosened their grip on OSS maintainers by making it user-friendly to pull containers down from alternative registries besides Docker Hub. However, even if you switch away from Docker Hub, you're still jumping from one company to another. This is because, at the end of the day, the registries‚Äînot the maintainers‚Äîown the distribution URL. The power imbalance continues.<br></p><p>My argument is not intended to dismiss the efforts of the registries as a whole. Package registries serve an essential role in software distribution, and have collectively serviced billions upon billions of package downloads. They‚Äôve made it easy for anyone in the world to interact with open-source, and as a result have helped push open-source forward. Astonishingly, they have, for most part, remained free to use! But as software continues to eat the world and the distribution of that software becomes more important, conflicting interests in this space become increasingly problematic.<br></p><h6><strong>Looking forward</strong><br></h6><p>How do we solve this? Ultimately, package registries need to align their incentives with those of maintainers. Registries should build products maintainers <em>want</em> to use rather than products they <em>have</em> to use.&nbsp;The entire OSS&nbsp;community can benefit. <br></p><p>Part of this means registries must be more intentional about giving maintainers back control over the distribution of their own software, even when it means the maintainers could take their packages elsewhere. As a community, we should be empowering maintainers to do their best work rather than constraining them to work within a specific&nbsp; platform or framework.&nbsp;<br></p><p>For the health of the open source ecosystem, it's critical to ensure that maintainers are not locked out from accessing the data about their own software distribution. Maintainers must be able to make data-informed decisions and treat distribution data as something that rightfully belongs to them, instead of just the registry providers.<br></p><p>Unfortunately, the current software distribution model works to cut maintainers out, making all downstream actions more difficult and strictly less informed. When we as a community decide to better align ourselves with open-source maintainers and build platforms to empower them, the result will be better software for the entire ecosystem.</p><p>Scarf is working on new tooling to address these problems, so stay tuned! Follow <a href="https://twitter.com/scarf_oss" target="_blank">@scarf_oss</a> on Twitter or subscribe below for periodic updates.<br></p></div></div></div></div>]]>
            </description>
            <link>https://about.scarf.sh/post/package-registries-and-open-source</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059755</guid>
            <pubDate>Wed, 11 Nov 2020 16:32:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intro to the Scrypt Hash]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059496">thread link</a>) | @lanecwagner
<br/>
November 11, 2020 | https://qvault.io/2020/07/25/very-basic-intro-to-the-scrypt-hash/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/07/25/very-basic-intro-to-the-scrypt-hash/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>Scrypt is a slow-by-design <a href="https://qvault.io/2020/01/01/very-basic-intro-to-hash-functions-sha-256-md-5-etc/">hash function</a> or more accurately, a <a href="https://qvault.io/2019/12/30/very-basic-intro-to-key-derivation-functions-argon2-scrypt-etc/">KDF</a> function. Simply put, the purpose of the Scrypt hash is to take some input data, and create a fingerprint of that data, but to do it very slowly. A common use-case is to take a password and create an n-bit private key, which is much longer and more secure. Here at <a href="https://app.qvault.io/">Qvault,</a> we use a similar KDF for securing user passwords.</p>



<p>For example, let‚Äôs pretend your password is <code>password1234</code>. By using Scrypt, we can extend that deterministically into a 256-bit key:</p>



<pre><code>password1234 -&gt; 
AwEEDA4HCwQFAA8DAwwHDQwPDwUOBwoOCQACAgUJBQ0JAAYNBAMCDQ4JCQgLDwcGDQMDDgMKAQsNBAkLAwsACA==</code></pre>



<p>That long 256-bit key can now be used as a private key to encrypt and decrypt data. For example, it could be the key in an <a href="https://qvault.io/2020/01/02/very-basic-intro-to-aes-256-cipher/">AES-256</a> cipher.</p>



<h2>Why Not Encrypt With The Password Directly?</h2>



<p>Most encryption algorithms, including AES-256, require that a key of sufficient length is used. By hashing the password, we can derive a longer, more secure, fixed-size key.</p>



<p>Furthermore, using a KDF like Scrypt provides additional benefits over a traditional hash function like <a href="https://qvault.io/2020/07/08/how-sha-2-works-step-by-step-sha-256/">SHA-2</a>:</p>



<ul><li>Computationally expensive and slow</li><li>Memory intensive (potentially several gigabytes of RAM is used to execute the hash)</li></ul>



<p>Often times <a href="https://qvault.io/2020/02/11/how-do-brute-force-attackers-know-they-found-the-key/">brute-force attackers</a> will try to break encryption by guessing passwords over and over until they get it right. AES-256 and SHA-2 are fast, so an attacker would be able to guess many passwords per second. By using a slow hashing function like Scrypt to derive a key, we can force the attacker to waste more resources trying to break in.</p>



<h2>Scrypt Step-by-Step</h2>



<p>Scrypt can be visualized by some psuedo-code:</p>



<pre><code lang="go">func Scrypt(
	passphrase, // string of characters to be hashed
	salt,  // random salt
	costFactor, // CPU/Memory cost, must be power of 2
	blockSizeFactor,
	parallelizationFactor, // (1..232-1 * hLen/MFlen)
	desiredKeyLen // Desired key length in bytes
) derivedKey {
	// we'll get to this
}</code></pre>



<p>Let‚Äôs go through the steps of converting those inputs into the desired <code>derivedKey</code></p>



<h3>1 ‚Äì Define Blocksize</h3>



<pre><code lang="go">const blockSize = 128 * blockSizeFactor</code></pre>



<h3>2 ‚Äì Generate Initial Salt</h3>



<p>Scrypt uses <a aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/PBKDF2" target="_blank" rel="noreferrer noopener nofollow">PBKDF2</a> as a child key-derivation function. We use it to generate an initial salt. <code>PBKDF2</code> has the following signature:</p>



<pre><code lang="go">func PBKDF2(
	prf,
	password,
	salt,
	numIterations,
	desiredKeyLen
) derivedKey {}</code></pre>



<p>We use it as follows:</p>



<pre><code lang="go">const initialSalt = PBKDF2(HMAC-SHA256, passphrase, salt, 1, blockSize * parallelizationFactor)</code></pre>



<h3>3 ‚Äì Mix Salt</h3>



<p>Next, we mix the salt. We split <code>initialSalt</code> into <code>splitSalt</code>, which is a 2D array of bytes. Each sub-array contains 1024 bytes</p>



<pre><code lang="go">splitSalt := [][1024]byte(initialSalt)
for i, block := range splitSalt {
	newBlock := roMix(block, costFactor)
	splitSalt[i] = newBlock
}</code></pre>



<p>Where <code>roMix</code> is the following function:</p>



<pre><code lang="go">func roMix(block, iterations){
	v := []
	x := block
	for i := 0; i &lt; iterations; i++ {
		v[i] = x
		x = blockMix(x)
	}
	for i := 0; i &lt; iterations; i++ {
		j := integerify(x) % iterations
		x = blockMix(x ^ v[j])
	}
	return x
}</code></pre>



<p><code>integerify</code> is defined by <a aria-label=" (opens in a new tab)" href="https://tools.ietf.org/html/rfc7914" target="_blank" rel="noreferrer noopener nofollow">RFC-7914</a> and <code>blockMix</code> is:</p>



<pre><code lang="go">func blockMix(block){
	r := len(block) / 128
	// split block into an array of 2r 64-byte chunks
	chunks := get2r64ByteChunks()

	x := chunks[len(chunks)-1]
	y := []
	for i := 0; i &lt; len(chunks); i++{
		x = salsa20-8(x ^ chunks[i])
		y[i] = x
	}
	return [y[0], y[2], ...y[2r-2], y[1], y[3], ...y[2r-1]]
}</code></pre>



<p><code>salsa20-8</code> is the 8-round version of the algorithm defined <a href="https://en.wikipedia.org/wiki/Salsa20" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener nofollow">here</a>.</p>



<h3>4 ‚Äì Finalize Salt</h3>



<p>Now <code>splitSalt</code> has been mixed in such a computationally exhausting way that we will call it an <code>expensiveSalt</code>. Expensive salt will be a single array of bytes, so we need to concatenate all the subarrays in <code>splitSalt</code>.</p>



<pre><code lang="go">expensiveSalt := append([], splitSalt...)</code></pre>



<h3>5 ‚Äì Return Final KDF</h3>



<pre><code lang="go">return PBKDF2(HMAC-SHA256, passphrase, expensiveSalt, 1, desiredKeyLen)</code></pre>



<p>The final pseudocode for our top level function is as follows:</p>



<pre><code lang="go">func Scrypt(
	passphrase, // string of characters to be hashed
	salt,  // random salt
	costFactor, // CPU/Memory cost, must be power of 2
	blockSizeFactor,
	parallelizationFactor, // (1..232-1 * hLen/MFlen)
	desiredKeyLen // Desired key length in bytes
) derivedKey {
	const blockSize = 128 * blockSizeFactor

	const initialSalt = PBKDF2(HMAC-SHA256, passphrase, salt, 1, blockSize * parallelizationFactor)

	splitSalt := [][1024]byte(initialSalt)
	for i, block := range splitSalt {
		newBlock := roMix(block, costFactor)
		splitSalt[i] = newBlock
	}

	expensiveSalt := append([], splitSalt...)

	return PBKDF2(HMAC-SHA256, passphrase, expensiveSalt, 1, desiredKeyLen)
}</code></pre>



<p>Or, if you prefer, the pseudocode as defined by <a href="https://en.wikipedia.org/wiki/Scrypt" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener nofollow">Wikipedia</a>:</p>



<pre><code lang="">Function scrypt
   Inputs:
      Passphrase:                Bytes    string of characters to be hashed
      Salt:                      Bytes    random salt
      CostFactor (N):            Integer  CPU/memory cost parameter - Must be a power of 2 (e.g. 1024)
      BlockSizeFactor (r):       Integer  blocksize parameter (8 is commonly used)
      ParallelizationFactor (p): Integer  Parallelization parameter. (1..232-1 * hLen/MFlen)
      DesiredKeyLen:             Integer  Desired key length in bytes
   Output:
      DerivedKey:                Bytes    array of bytes, DesiredKeyLen long

   Step 1. Generate expensive salt
   blockSize ‚Üê 128*BlockSizeFactor  //Length (in bytes) of the SMix mixing function output (e.g. 128*8 = 1024 bytes)

   Use PBKDF2 to generate initial 128*BlockSizeFactor*p bytes of data (e.g. 128*8*3 = 3072 bytes)
   Treat the result as an array of p elements, each entry being blocksize bytes (e.g. 3 elements, each 1024 bytes)
   [B0...Bp‚àí1] ‚Üê PBKDF2HMAC-SHA256(Passphrase, Salt, 1, blockSize*ParallelizationFactor)

   Mix each block in B Costfactor times using ROMix function (each block can be mixed in parallel)
   for i ‚Üê 0 to p-1 do
      Bi ‚Üê ROMix(Bi, CostFactor)

   All the elements of B is our new "expensive" salt
   expensiveSalt ‚Üê B0‚à•B1‚à•B2‚à• ... ‚à•Bp-1  //where ‚à• is concatenation
 
   Step 2. Use PBKDF2 to generate the desired number of bytes, but using the expensive salt we just generated
   return PBKDF2HMAC-SHA256(Passphrase, expensiveSalt, 1, DesiredKeyLen);</code></pre>




		</div></div>]]>
            </description>
            <link>https://qvault.io/2020/07/25/very-basic-intro-to-the-scrypt-hash/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059496</guid>
            <pubDate>Wed, 11 Nov 2020 16:09:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mental Models for Product Managers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059450">thread link</a>) | @laybak
<br/>
November 11, 2020 | https://informedpm.com/posts/mental-models | <a href="https://web.archive.org/web/*/https://informedpm.com/posts/mental-models">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><span>It is trendy to talk about mental models these days, especially in the tech industry. But really, it's just a fancy way of saying "useful ways of thinking".</span></p> <p><span>In this post, I present a collection of mental models that are most relevant to the work of product managers. Some of these are borrowed from other disciplines. And they can be valuable additions to your toolbox for dealing with complexity.</span></p> <p><span>I intend for these to be jumping-off points for further thinking and learning. And not an exhaustive list. For a general introduction to mental models, here is a </span> <a href="https://fs.blog/mental-models/" target="_blank"><span>useful article by Farnam Street</span></a> <span>.</span></p> <p><span>Let's get started.</span></p>  <p><h2><span>Part 1: Learning </span></h2></p> <p><h3><span>Ensemble of Models</span></h3></p> <p><span>All models are wrong because they simplify. They omit details. For this reason, we should not rely on any single model. Instead, a many-model approach allows you to explain more and avoid blindspots. This works because the wrongness in each model tends to cancel out.</span></p> <p><span>Charlie Munger, an investor who popularized mental models, advocates combining them in a "latticework of models". And in machine learning, </span> <a href="https://en.wikipedia.org/wiki/Ensemble_learning" target="_blank"><span>ensemble methods</span></a> <span> can be an effective approach. </span></p> <p><span>This is useful when considering the diverse perspectives and opinions of your stakeholders.</span></p>  <p><h3><span>Learning by Doing</span></h3></p> <p><span>Which mental models matter in which circumstances? Knowing that is the hard part. </span></p> <p><span>A lot of skills and knowledge are implicit. They are hard to codify, or even articulate. You won't find them in neatly packaged books or elegant theories. </span></p> <p><span>But you can hone your judgment by maintaining contact with reality. You can put in iterations, and let your learning compound over time.</span></p>  <p><h3><span>Bayesian Updating</span></h3></p> <p><span>We get new information all the time. Feedback from a customer, changes in the industry, unforeseen challenges etc.</span></p> <p><span>Bayes' theorem provides a mathematical approach to weigh the old hypothesis (the "prior", initial belief) and new evidence. Bayesian inference is widely applicable in many areas, including AI and machine learning. Fun fact, it is also effective for </span> <a href="https://en.wikipedia.org/wiki/Bayesian_search_theory" target="_blank"><span>finding missing aircrafts</span></a> <span>.</span></p> <p><span>Here is an engaging introductory video on the topic.</span></p> <div><p><iframe src="https://www.youtube.com/embed/HZGCoVF3YvM?title=0&amp;byline=0&amp;portrait=0" frameborder="0"></iframe></p></div>  <p><h3><span>Process vs Outcome</span></h3></p> <p><span>It is tempting to judge our decisions by the outcome. But good decisions can lead to bad outcomes. And vice versa.</span></p> <p><span>Having a good process with a good outcome is ideal. Whereas a bad process with a good outcome is just gambling with blind luck.</span></p> <p><span>One way to calibrate your decisions over time is to document your decisions in a </span> <a href="https://fs.blog/2014/02/decision-journal/" target="_blank"><span>decision journal</span></a> <span>. Good things to write down include the context for the decision, alternatives and the range of outcomes, what you expect to happen, and how you feel mentally and physically.</span></p>  <p><h3><span>Dumb Idea Paradox</span></h3></p> <p><span>Many of the big success stories sounded stupid. Red Bull is an expensive drink that tastes disgusting. Snapchat is an app for sending disappearing photos. </span></p> <p><span>In the book </span> <a href="https://www.amazon.com/Loonshots-Nurture-Diseases-Transform-Industries-ebook/dp/B07D2BKVQR" target="_blank"><span>Loonshots</span></a> <span>, Safe Bahcall gave examples of brilliant ideas that had to survive "the Three Deaths" before finally succeeding. He wrote, "In the real world, ideas are ridiculed, experiments fail, budgets are cut, and good people are fired for stupid reasons." Andrew Chen also wrote about this in </span> <a href="https://andrewchen.co/dumb-idea-paradox/" target="_blank"><span>Dumb Idea Paradox</span></a> <span>.</span></p>  <p><h3><span>Satisficing</span></h3></p> <p><span>We make decisions in a world of uncertainty, with incomplete and imperfect information. Certainty is an illusion. It is better to be vaguely right than precisely wrong. </span></p> <p><span>Ôªø</span> <a href="https://en.wikipedia.org/wiki/Satisficing" target="_blank"><span>Satisficing</span></a> <span> (satisfy + suffice), introduced by&nbsp;</span> <a href="https://en.wikipedia.org/wiki/Herbert_A._Simon" target="_blank"><span>Herbert A. Simon</span></a> <span>, is about making decisions that are not perfect, but good enough. You can satisfice either by finding optimal solutions for a simplified world, or satisfactory solutions for a realistic one.</span></p>  <p><h2><span>Part 2: Collaboration &amp; Execution</span></h2></p> <p><h3><span>Maker's Schedule. Manager's Schedule</span></h3></p> <p><span>Context switching is costly, especially for creative work. In </span> <a href="http://www.paulgraham.com/makersschedule.html" target="_blank"><span>Paul Graham's popular essay</span></a> <span>, he discussed the cost of meetings and interruptions:</span></p> <p><em>"When you're operating on the maker's schedule, meetings are a disaster. A single meeting can blow a whole afternoon, by breaking it into two pieces each too small to do anything hard in."</em></p> <p><span>It is important to recognize the nature of different types of work. This way we can get more focused time for deep work, for ourselves and for our team.</span></p>  <p><h3><span>Working Memory and Cognitive Load</span></h3></p> <p><span>Ôªø</span> <a href="https://en.wikipedia.org/wiki/Working_memory" target="_blank"><span>Working memory</span></a> <span> is basically </span> <em>"how much stuff you can think about at the same time"</em> <span>. Each of us has a limited capacity. The "</span> <a href="https://en.wikipedia.org/wiki/The_Magical_Number_Seven%2C_Plus_or_Minus_Two" target="_blank"><span>magic number</span></a> <span>" of objects an average human can hold in short-term memory is 7, plus or minus 2.</span></p> <p><span>In the workplace, there is a lot of information to process. And the sheer load can quickly overwhelm our working memory.</span></p> <p><span>This calls for building a system to work around this. It could mean regular follow-ups, reminders, repetition, and good note-taking and documentation.</span></p>  <p><h3><span>Circle of Competence</span></h3></p> <p><span>Ôªø</span> <a href="https://en.wikipedia.org/wiki/Circle_of_competence" target="_blank"><span>Circle of competence</span></a> <span> is a mental model developed by Warren Buffett and Charlie Munger. Here's how Buffett summarized it:</span></p> <p><em>"Know your circle of competence, and stick within it. The size of that circle is not very important; knowing its boundaries, however, is vital."</em></p> <p><span>Being clear about what you know and what you think you know can keep your hubris in check. It can also help you identify blind spots and areas of improvement. </span></p> <p><img src="https://storage.googleapis.com/rumin-gcs-bucket/newsletter/circle-of-competence.png"></p>  <p><h3><span>Batch Processing</span></h3></p> <p><span>Instead of completing tasks in the order that they come, you can often save time by grouping similar tasks together. It reduces costly context switching and interrupts by consolidating repetitive tasks that are not time-sensitive.</span></p> <p><span>This approach can be helpful in answering emails, reading news articles, processing customer feedback etc. As an added benefit, once you batch the tasks, they also tend to be easier to delegate or automate.</span></p> <p><img src="https://storage.googleapis.com/rumin-gcs-bucket/newsletter/batch-processing.png"></p>  <p><h3><span>Incentives</span></h3></p> <p><span>All living creatures respond to incentives. That is, the proverbial carrot and stick. Behaviours that are rewarded are reinforced.</span></p> <p><span>Knowing this helps us understand the true motivation of our partners, stakeholders, and even customers. This allows us to influence without direct power.</span></p>  <p><h3><span>Goodhart's Law</span></h3></p> <p><span>It is important to consider incentives when deciding measurements of success and metrics to focus on. </span></p> <p><span>Goodhart's Law was named after the economist Charles Goodhart. The general version, phrased by anthropologist Marilyn Strathern, states that "</span> <em>When a measure becomes a target, it ceases to be a good measure</em> <span>."
to be a good measure." </span></p> <p><span>It is possible that some stakeholders can "game the system" and artificially inflate metrics in ways that don't reflect customer value.</span></p> <p><span>We need to be careful about what to measure and consider the incentives of the individual stakeholders. </span></p>  <p><h3><span>Persuasion</span></h3></p> <p><span>To make change happen, persuasion is essential. I have compiled the models, principles, and tactics on this topic in a </span> <a href="https://informedpm.com/posts/persuasion-product-manager" target="_blank"><span>separate post</span></a> <span>. </span></p>  <p><h2><span>Part 3: Systems Thinking</span></h2></p> <p><span>Product managers routinely deal with complex systems. A product is a system of features, stakeholders, processes, customers, other players in the market, changing industry and economic trends etc.</span></p> <p><span>A system is more than the sum of its parts. Systems thinking allows us to better understand the interconnections of the different parts.</span></p>  <p><h3><span>Feedback Loops</span></h3></p> <p><span>A feedback loop is a closed chain of causal connections formed by routing an output of a system back as an input. </span></p> <p><span>Different feedback structures can produce drastically different behaviours. Balancing feedback loops lead to stability or an equilibrium. Whereas reinforcing feedback loops lead to exponential growth or collapses. </span></p> <p><span>Understanding the structure of the system helps us understand its behaviours.</span></p> <p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/General_Feedback_Loop.svg/330px-General_Feedback_Loop.svg.png"></p>  <p><h3><span>Flywheel</span></h3></p> <p><span>The "</span> <a href="https://www.jimcollins.com/article_topics/articles/the-flywheel-effect.html" target="_blank"><span>flywheel effect</span></a> <span>" is a concept developed by researcher Jim Collins. It is a special kind of feedback loop (positive/reinforcing). Push the flywheel. Accelerate momentum. Then repeat.</span></p> <p><span>It is said that Bezos considered Amazon's application of the flywheel concept to be its "secret sauce". </span></p> <p><img src="https://storage.googleapis.com/rumin-gcs-bucket/newsletter/Amazon%20flywheel.png"></p>  <p><h3><span>Non-Linearity</span></h3></p> <p><span>A linear relationship between two variables can be drawn on a chart with a straight line. In a non-linear relationship, the cause does not produce a proportional effect.     </span></p> <p><span>In a linear system, twice the push can produce twice the response. But in a nonlinear system, twice the push can produce the response squared, a sixth, or no response at all.</span></p> <p><span>For example, doubling the team headcount may yield 1.2X the output. Tripling the price may yield 10X the revenue. </span></p> <p><span>Many relationships in systems are non-linear. This is often a source of surprise. Beware of the trap of assuming (though more intuitive) linear relationships. </span></p>  <p><h3><span>Leverage Points </span></h3></p> <p><span>To get more of a desired outcome, we may have to change the structure of a system. There are leverage points in all systems, where the efforts you apply can yield disproportionate results. For instance, identifying and resolving a bottleneck in a process can be a force multiplier for your efforts.</span></p> <p><span>But as systems scientist </span> <a href="https://en.wikipedia.org/wiki/Donella_Meadows" target="_blank"><span>Donella Meadows</span></a> <span> pointed out, leverage points are often counter-intuitive. And there is no cheap way to mastering the art of identifying leverage points. Though in her book </span> <a href="https://www.amazon.com/Thinking-Systems-Primer-Donella-Meadows/dp/1603580557" target="_blank"><span>Thinking in Systems</span></a> <span>, she proposed a ranked list of leverage point candidates based on her experience. </span></p>  <p><h3><span>Second and Higher Order Effects</span></h3></p> <p><span>First-order effects are the direct consequences of an action. They tend to be immediate. They tend to be obvious. They tend to be static. Thinking in first-order effects often a dangerous over-simplification.</span></p> <p><span>In real life, each agent in the system can respond to changes. Second (and higher) order effects include the effects of subsequent actions. </span></p> <p><span>An example of first-order thinking would be to assume that introducing a new feature will lead to more users coming. Higher-order effects would include increasing technical complexity internally, cluttering and degrading the overall UX, competitors responding by copying the feature or launching a new product etc.</span></p>  <p><h2><span>Part 4: Strategy &amp; Planning</span></h2></p> <p><h3><span>Inversion</span></h3></p> <p><span>Inversion as a thinking tool turns the problem upside down. </span></p> <p><span>Instead of always starting at the beginning, sometimes it is beneficial to start at the end. This thinking can be useful in planning, where we start with the end goal and work backward. For instance, at Amazon, there is a practice of writing a ‚Ä¶</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://informedpm.com/posts/mental-models">https://informedpm.com/posts/mental-models</a></em></p>]]>
            </description>
            <link>https://informedpm.com/posts/mental-models</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059450</guid>
            <pubDate>Wed, 11 Nov 2020 16:04:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why an IDE?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059374">thread link</a>) | @matklad
<br/>
November 11, 2020 | https://matklad.github.io/2020/11/11/yde.html | <a href="https://web.archive.org/web/*/https://matklad.github.io/2020/11/11/yde.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article>
  
  <p>Nov 11, 2020</p>
  <p>Some time ago I wrote a reddit comment explaining the benefits of IDEs.
Folks refer to it from time to time, so I decided to edit it into an article form.
Enjoy!</p>
<p>I think I have a rather balanced perspective on IDEs.
I used to be a heavy Emacs user (<a href="https://github.com/matklad/.emacs.d/tree/475de5db99f8729c57fed7e6fde4cd06f5ccb62f">old config</a>, <a href="https://github.com/matklad/config/blob/d555642a5a9e4e8b0ca0c77f188ffd976f06327c/home/.emacs.d/init.el">current config</a>).
I worked at JetBrains on <a href="https://github.com/intellij-rust/intellij-rust">IntelliJ Rust</a> for several years.
I used evil mode and vim for a bit, and tried tmux and kakoune.
Nowadays, I primarily use VS Code to develop <a href="https://github.com/rust-analyzer/rust-analyzer/">rust-analyzer</a>: LSP-based editor-independent IDE backend for Rust.</p>
<p>I will be focusing on IntelliJ family of IDEs, as I believe these are the most advanced IDEs today.</p>
<p>The main distinguishing feature of IntelliJ is semantic understanding of code.
The core of IntelliJ is a compiler which parses, type checks and otherwise understands your code.
<a href="https://martinfowler.com/bliki/PostIntelliJ.html">PostIntelliJ</a> is the canonical post about this.
That article also refutes the claim that ‚ÄúSmalltalk IDE is the best we‚Äôve ever had‚Äù.</p>
<p>Note that ‚Äúsemantic understanding‚Äù is mostly unrelated to the traditional interpretation of ‚ÄúIDE‚Äù as <em>Integrated</em> Development Environment.
I personally don‚Äôt feel that the ‚ÄúIntegrated‚Äù bit is all that important.
I commit&amp;push from the command line using Julia scripts, rebase in magit, and do code reviews in a browser.
If anything, there‚Äôs an ample room for improvement for the integration bits.
For me, <strong>I</strong> in ‚Äú<strong>I</strong>DE‚Äù stands for ‚Äúintelligent‚Äù, smart.</p>
<p>Keep in mind this terminology difference.
I feel it is a common source of misunderstanding.
‚ÄúUnix and command line can do anything an IDE can do‚Äù is correct about integrated bits, but is wrong about semantical bits.</p>
<p>Traditional editors like Vim or Emacs understand programming languages very approximately, mostly via regular expressions.
For me, this feels very wrong.
It‚Äôs <a href="https://stackoverflow.com/a/1732454">common knowledge</a> that HTML shall not be parsed with regex.
Yet this is exactly what happens every time one does <code>vim index.html</code> with syntax highlighting on.
I sincerely think that almost every syntax highlighter out there is wrong and we, as an industry, should do better.
I also understand that this is a tall order, but I do my best to change the status quo here :-)</p>
<p>These are mostly theoretical concerns though.
The question is, does semantic understanding help in practice?
I am pretty sure that it is non-essential, especially for smaller code bases.
My <a href="https://github.com/matklad/rustraytracer">first non-trivial Rust program</a> was written in Emacs, and it was fine.
Most of rust-analyzer was written using pretty spartan IDE support.
There are a lot of insanely-productive folks who are like ‚Äúsometimes I type vim, sometimes I type vi, they are sufficiently similar‚Äù.
Regex-based syntax highlighting and regex based fuzzy symbol search (<a href="https://github.com/universal-ctags/ctags">ctags</a>) get you a really long way.</p>
<p>However, I do believe that features unlocked by deep understanding of the language help.
The funniest example here is extend/shrink selection.
This features allows you to extend current selection to the next encompassing syntactic construct.
It‚Äôs the simplest feature a PostIntelliJ IDE can have, it only needs the parser.
But it is sooo helpful when writing code, it just completely blows vim‚Äôs text objects out of the water, especially when combined with multiple cursors.
In a sense, this is structural editing which works for text.</p>
<div>
<p><img src="https://user-images.githubusercontent.com/1711539/98809232-80e3db00-241d-11eb-883a-5aece9a1dbfc.gif" alt="98809232 80e3db00 241d 11eb 883a 5aece9a1dbfc">
</p>
</div>
<p>If you add further knowledge of the language into a mix, you‚Äôll get the ‚Äúassists‚Äù system: micro-refactoring which available in a particular context.
For example, is the cursor is on a comma in a list of function arguments, you can <span><kbd>alt</kbd>+<kbd>enter</kbd></span> &gt; ‚Äúswap arguments‚Äù, and the order of arguments will be changed in the declaration and on various call-sites as well.
(See <a href="https://rust-analyzer.github.io/blog/2020/09/28/how-to-make-a-light-bulb.html">this post</a> to learn how assists are implemented).</p>
<p>These small dwim things add up to a really nice editing experience, where you mostly express the intention, and the IDE deals with boring syntactical aspects of code editing:</p>
<div>
<p><img src="https://user-images.githubusercontent.com/1711539/98812121-37e25580-2422-11eb-8541-2c5a32926845.gif" alt="98812121 37e25580 2422 11eb 8541 2c5a32926845">
</p>
</div>
<p>For larger projects, complex refactors are a huge time-saver.
Doing project-wide renames and signature changes automatically and without thinking reduces the cost of keeping the code clean.</p>
<p>Another transformative experience is navigation.
In IntelliJ, you generally don‚Äôt ‚Äúopen a file‚Äù.
Instead you think directly in terms of functions, types and modules, and navigate to those using file structure, goto symbol, to do definition/implementation/type, etc:</p>

<p>When I used Emacs, I really admired its buffer management facilities, because they made opening a file I want a breeze.
When I later switched to IntelliJ, I stopped thinking in terms of a set of opened files altogether.
I disabled editor tabs and started using editor splits less often‚Äâ‚Äî‚Äâyou don‚Äôt need bookmarks if you can just find things.</p>
<p>For me, there‚Äôs one aspect of traditional editors which is typically not matched in IDEs out of the box‚Äâ‚Äî‚Äâbasic cursor motion.
Using arrow keys for that is slow and flow-breaking, because one needs to move the hand from the home row.
Even Emacs' horrific <kbd>C-p</kbd>, <kbd>C-n</kbd> are a big improvement, and vim‚Äôs <kbd>hjkl</kbd> go even further.
One fix here is to configure each tool to use your favorite shortcuts, but this is a whack-a-mole game.
What I do is remapping <kbd>CapsLock</kbd> to act as an extra modifier, such that <kbd>ijkl</kbd> <strong>are</strong> arrow keys.
(There are also keyboards with <a href="https://ultimatehackingkeyboard.com/">hardware</a> <a href="https://ergodox-ez.com/">support</a> for this).
This works in all applications the same way.
Easy motion / ace jump functionality for jumping to any visible character is also handy, and usually is available <a href="https://plugins.jetbrains.com/plugin/9803-acejump-lite">via</a> <a href="https://marketplace.visualstudio.com/items?itemName=lucax88x.codeacejumper">a plugin</a>.</p>
<p>Recent advancements with LSP protocol promise to give one the best of both worlds, where semantic-aware backend and light-weight editor frontend are different processes, which can be mixed and matched.
This is nice in theory, but not as nice in practice as IntelliJ yet, mostly because IntelliJ is way more polished.</p>
<p>To give a simple example, in IntelliJ for ‚Äúgo to symbol by fuzzy name‚Äù functionality, I can filter the search scope by:</p>
<div>
<ul>
<li>
<p>is this my code/code from a dependency?</p>
</li>
<li>
<p>is this test/production code?</p>
</li>
<li>
<p>is a symbol a type-like thing, or a method-like thing?</p>
</li>
<li>
<p>path to the module where the symbol is defined.</p>
</li>
</ul>
</div>
<p>VS Code and LSP simply do not have capabilities for such filters yet, they have to be bolted on using hacks.
Support for LSP in other editors is even more hit-and-miss.</p>
<p>LSP did achieve a significant breakthrough‚Äâ‚Äî‚Äâit made people care about implementing IDE backends.
Experience shows that re-engineering an existing compiler to power an IDE is often impossible, or isomorphic to a rewrite.
How a compiler talks to an editor is the smaller problem.
The hard one is building a compiler that can do IDE stuff in the first place.
Check out <a href="https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html">this post</a> for some of the technical details.
Starting with this use-case in mind saves a lot of effort down the road.</p>
<p>This I think is a big deal.
I hypothesize that the reason why IDEs do not completely dominate tooling landscape is the lack of good IDE backends.</p>
<p>If we look at the set of languages fairly popular recently, a significant fraction of them is dynamically typed: PHP, JavaScript, Python, Ruby.
The helpfulness of an IDE for dynamically typed languages is severely limited: while approximations and heuristics can get you a long way, you still need humans in the loop to verify IDE‚Äôs guesses.</p>
<p>There‚Äôs C++, but its templates are effectively dynamically typed, with exactly the same issues (and a very complex base language to boot).
Curiously, C looks like a language for which implementing a near-perfect IDE is pretty feasible.
I don‚Äôt know why it didn‚Äôt happen before CLion.</p>
<p>This leaves C# and Java.
Indeed, these languages are dominated by IDEs.
There‚Äôs a saying that you can‚Äôt write Java without an IDE.
I think it gets the causation direction backwards: Java is one of the few languages for which it is possible to implement a great IDE without great pain.
Supporting evidence here is Go.
According to <a href="https://blog.golang.org/survey2019-results#TOC_5.">survey results</a>, text editors are stably declining in popularity in favor of IDEs.</p>
<p>I think this is because Go actually has good IDEs.
This is possible because the language is sufficiently statically typed for an IDE to be a marked improvement.
Additionally, the language is very simple, so the amount of work you need to put in to make a decent IDE is much lower than for other languages.
If you have something like JavaScript‚Ä¶‚Äã
Well, you first need to build n alternative language for which you can actually implement and an IDE (<a href="https://www.typescriptlang.org/">TypeScript</a>) and only then you can build the IDE itself (<a href="https://github.com/microsoft/vscode">VS Code</a>).</p>
</article>

  </div></div>]]>
            </description>
            <link>https://matklad.github.io/2020/11/11/yde.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059374</guid>
            <pubDate>Wed, 11 Nov 2020 15:56:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TypeScript splits the atom A first look at TS 4.1's new template literal types]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059336">thread link</a>) | @danvk
<br/>
November 11, 2020 | https://effectivetypescript.com/2020/11/05/template-literal-types/ | <a href="https://web.archive.org/web/*/https://effectivetypescript.com/2020/11/05/template-literal-types/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p><img src="https://effectivetypescript.com/images/split-atom.png" width="324" height="298" alt="Splitting a string type"></p><p>TypeScript's type system has grown steadily more powerful over the past five years, allowing you to precisely type more and more patterns in JavaScript. The upcoming <a href="https://github.com/microsoft/TypeScript/issues/40124" target="_blank" rel="noopener" onclick="return trackOutboundLink('', 'https://github.com/microsoft/TypeScript/issues/40124', event);">TypeScript 4.1 release</a> includes a particularly exciting new <a href="https://github.com/microsoft/TypeScript/pull/40336" target="_blank" rel="noopener" onclick="return trackOutboundLink('', 'https://github.com/microsoft/TypeScript/pull/40336', event);">addition</a> to the type system: <em>template literal types</em>.</p>
<p>Template literal types solve a <a href="https://github.com/microsoft/TypeScript/issues/12754" target="_blank" rel="noopener" onclick="return trackOutboundLink('', 'https://github.com/microsoft/TypeScript/issues/12754', event);">long-standing gap</a> in TypeScript's type system and, as I'll argue at the end of the post, they solve it in a particularly <em>TypeScripty</em> way.</p>
<p>To understand template literal types, let's start with a seemingly simple question: what can't you type?</p>
<h2 id="The-limits-of-type-safety-in-TypeScript"><a href="#The-limits-of-type-safety-in-TypeScript" title="The limits of type safety in TypeScript"></a>The limits of type safety in TypeScript</h2><p>My standard example of a pattern you <em>couldn't</em> type has always been the <code>camelCase</code> function, which maps something like <code>"foo_bar"</code> ‚Üí <code>"fooBar"</code>. It's easy to implement in JavaScript using a regular expression:</p>
<figure><div><pre><code><span><span>function</span> <span>camelCase</span>(<span>term</span>) </span>{<br>  <span>return</span> term.replace(<span>/_([a-z])/g</span>, <span><span>m</span> =&gt;</span> m[<span>1</span>].toUpperCase());<br>}<br></code></pre></div></figure>

<p>This function is trivial to <em>simply</em> type:</p>
<figure><div><pre><code><span>declare</span> <span><span>function</span> <span>camelCase</span>(<span>term: <span>string</span></span>): <span>string</span></span>;<br></code></pre></div></figure>

<p>So that's not quite what I'm getting at. Ideally you'd like to be able to use this to convert objects with <code>snake_cased</code> properties (like you'd get from a database) into one with <code>camelCased</code> properties (like you typically use in JS/TS). In other words, what should the return type of this function be to make the following code type check (or not) as you'd expect?</p>
<figure><div><pre><code><span><span>function</span> <span>objectToCamel</span>&lt;<span>T</span> <span>extends</span> <span>object</span>&gt;(<span>obj: T</span>) </span>{<br>  <span>const</span> out: <span>any</span> = {};<br>  <span>for</span> (<span>const</span> [k, v] of <span>Object</span>.entries(obj)) {<br>    out[camelCase(k)] = v;<br>  }<br>  <span>return</span> out;<br>}<p><span>const</span> snake = {foo_bar: <span>12</span>}; <br><span>const</span> camel = objectToCamel(snake);<br><br><span>const</span> val = camel.fooBar;  <br><span>const</span> val2 = camel.foo_bar;  </p></code></pre></div></figure>

<p>Prior to TypeScript 4.1 (now a release candidate) this just wasn't possible. The reason was that string literal types like <code>"foo_bar"</code> were "atomic" in the sense that you couldn't observe any structure inside of them. They were indivisible. But clearly there <em>is</em> structure in strings. Just look at <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String#Instance_methods" target="_blank" rel="noopener" onclick="return trackOutboundLink('the limits of type safety in typescript', 'https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String#Instance_methods', event);">all the methods</a> on <code>String.prototype</code>.</p>
<p>Enter: TypeScript 4.1!</p>
<h2 id="TypeScript-splits-the-atom"><a href="#TypeScript-splits-the-atom" title="TypeScript splits the atom"></a>TypeScript splits the atom</h2><p>TypeScript 4.1 introduce a few features that make it possible to precisely type the <code>objectToCamel</code> function:</p>
<ol>
<li><em>Template literal types</em> This is the key advance. Template literal types allow you to find structure inside string literal types and create infinite, strict subsets of <code>string</code> (think "strings starting with <code>on</code>").</li>
<li><em>Key Remapping in Mapped Types</em> While it was possible to change the keys in an object before using tricks like <a href="https://effectivetypescript.com/2020/05/12/unionize-objectify/">Unionize and Objectify</a>, this new feature makes it much more straightforward.</li>
</ol>
<p>Let's use these two features to implement <code>objectToCamel</code>.</p>
<p>First, let's look at template literal types. They look like ES template literals:</p>
<figure><div><pre><code><span>type</span> OnString = <span>`on<span>${<span>string</span>}</span>`</span>;<br><span>const</span> onClick: OnString = <span>'onClick'</span>;<br><span>const</span> handleClick: OnString = <span>'handleClick'</span>;<br>   <br></code></pre></div></figure>

<p>This lets you create a type for "strings starting with <code>on</code>." Before TypeScript 4.1, you either had <code>string</code> or an enumerated union of string literal types (<code>"a" | "b" | "c"</code>). Now you can define structured subsets of <code>string</code>.</p>
<p>Here are a few other patterns:</p>
<figure><div><pre><code><span>type</span> IdNum = <span>`id<span>${<span>number</span>}</span>`</span>;<br><span>const</span> id1: IdNum = <span>'id123'</span>;  <br><span>const</span> id2: IdNum = <span>'idABC'</span>;   <p><span>type</span> Digit = <span>'0'</span> | <span>'1'</span> | <span>'2'</span> | <span>'3'</span> | <span>'4'</span> |<br>             <span>'5'</span> | <span>'6'</span> | <span>'7'</span> | <span>'8'</span> | <span>'9'</span>;<br><span>type</span> ThreeDigitNum = <span>`<span>${Digit}</span><span>${Digit}</span><span>${Digit}</span>`</span>;</p></code></pre></div></figure>

<p>What makes this really powerful is that you can use the <a href="https://artsy.github.io/blog/2018/11/21/conditional-types-in-typescript/" target="_blank" rel="noopener" onclick="return trackOutboundLink('typescript splits the atom', 'https://artsy.github.io/blog/2018/11/21/conditional-types-in-typescript/', event);"><code>infer</code> keyword</a> in a template literal type to do pattern matching:</p>
<figure><div><pre><code><span>type</span> ToCamel1&lt;S <span>extends</span> <span>string</span>&gt; =<br>    S <span>extends</span> <span>`<span>${infer Head}</span>_<span>${infer Tail}</span>`</span><br>    ? <span>`<span>${Head}</span><span>${Capitalize&lt;Tail&gt;}</span>`</span><br>    : S;<p><span>type</span> T = ToCamel1&lt;<span>'foo_bar'</span>&gt;;  </p></code></pre></div></figure>

<p>The conditional matches string literal types of the form <code>"head_tail"</code>. The "<code>_</code>" acts as a delimiter to split the string. Because <a href="https://mariusschulz.com/blog/conditional-types-in-typescript#distributive-conditional-types" target="_blank" rel="noopener" onclick="return trackOutboundLink('typescript splits the atom', 'https://mariusschulz.com/blog/conditional-types-in-typescript#distributive-conditional-types', event);">conditional types distribute over unions</a>, this also works for union types:</p>
<figure><div><pre><code><span>type</span> TU = ToCamel1&lt;<span>'first_name'</span> | <span>'last_name'</span>&gt;;<br><br></code></pre></div></figure>

<p>There's a big issue, though. What if there's two <code>_</code>s in the string literal type?</p>
<figure><div><pre><code><span>type</span> T2 = ToCamel1&lt;<span>'foo_bar_baz'</span>&gt;;  <br></code></pre></div></figure>

<p>We can't stop after the first "<code>_</code>", we need to keep going. We can do this by making the type recursive:</p>
<figure><div><pre><code><span>type</span> ToCamel&lt;S <span>extends</span> <span>string</span>&gt; =<br>    S <span>extends</span> <span>`<span>${infer Head}</span>_<span>${infer Tail}</span>`</span><br>    ? <span>`<span>${Head}</span><span>${Capitalize&lt;ToCamel&lt;Tail&gt;&gt;}</span>`</span><br>    : S;<br><span>type</span> T0 = ToCamel&lt;<span>'foo'</span>&gt;;  <br><span>type</span> T1 = ToCamel&lt;<span>'foo_bar'</span>&gt;;  <br><span>type</span> T2 = ToCamel&lt;<span>'foo_bar_baz'</span>&gt;;  <br></code></pre></div></figure>

<p>The recursive bit is where we call <code>ToCamel&lt;Tail&gt;</code>.</p>
<p>Pretty neat! Now let's put it all together.</p>
<h2 id="A-typed-objectToCamel"><a href="#A-typed-objectToCamel" title="A typed objectToCamel"></a>A typed objectToCamel</h2><p>Recall that a <a href="https://medium.com/@danvdk/a-typed-pluck-exploring-typescript-2-1s-mapped-types-c15f72bf4ca8" target="_blank" rel="noopener" onclick="return trackOutboundLink('a typed objecttocamel', 'https://medium.com/@danvdk/a-typed-pluck-exploring-typescript-2-1s-mapped-types-c15f72bf4ca8', event);">mapped type</a> in TypeScript looks and works something like this:</p>
<figure><div><pre><code><span>interface</span> Vector {<br>  x: <span>number</span>;<br>  y: <span>number</span>;<br>}<br><span>type</span> Promisify&lt;T <span>extends</span> object&gt; = {<br>  [K <span>in</span> keyof T]: <span>Promise</span>&lt;T[K]&gt;  <br>};<br><span>type</span> VectorPromise = Promisify&lt;Vector&gt;;<br><br></code></pre></div></figure>

<p>The <code>keyof T</code> here produces a union of string literal types (<code>"x" | "y"</code>) and the mapped type produces an object type from this given a way to produce the values (the <code>Promise&lt;T[K]&gt;</code>). But the keys are set by the union. You can't change them.</p>
<p>With Key Remapping, you can add an <code>as</code> clause to the key in a mapped type to change things around. This works particularly well with template literal types:</p>
<figure><div><pre><code><span>interface</span> Student {<br>  name: <span>string</span>;<br>  age: <span>number</span>;<br>}<br><span>type</span> Evented&lt;T <span>extends</span> object&gt; = {<br>  [K <span>in</span> keyof T <span>as</span> <span>`<span>${K &amp; <span>string</span>}</span>Changed`</span>]: <span>(<span>val: T[K]</span>) =&gt;</span> <span>void</span>;<br>}<br><span>type</span> StudentEvents = Evented&lt;Student&gt;;<br><br><br><br><br></code></pre></div></figure>

<p>(The <code>&amp; string</code> is there for technical reasons that I don't want to get into.)</p>
<p>Using this, we can plug in our <code>ToCamel</code> generic to put it all together:</p>
<figure><div><pre><code><span>type</span> ObjectToCamel&lt;T <span>extends</span> object&gt; = {<br>  [K <span>in</span> keyof T <span>as</span> ToCamel&lt;K&gt;]: T[K]<br>};<p><span><span>function</span> <span>objectToCamel</span>&lt;<span>T</span> <span>extends</span> <span>object</span>&gt;(<span>obj: T</span>): <span>ObjectToCamel</span>&lt;<span>T</span>&gt; </span>{<br>  <br>}</p><p><span>const</span> snake = {foo_bar: <span>12</span>}; <br><span>const</span> camel = objectToCamel(snake);<br><br><span>const</span> val = camel.fooBar;  <br><span>const</span> val2 = camel.foo_bar;<br>                <br>                </p></code></pre></div></figure>

<p>Here's a <a href="https://www.typescriptlang.org/play?ts=4.2.0-dev.20201109#code/C4TwDgpgBAKg9gYQIYFsIBsA8BlKEAewEAdgCYDOU5wATgJbEDmAfFALwBQU3UuBRZSgAMAJAG8GAMwg0oACQhJSAXwD64qTNhI66ZUK48A-FFFiFS5eORg6wJOjoAvCJnjI0WGDvTNm+w24ALl4Abg5QSFgABnZYRFQMTABySTg4ZOZQ7gB6HKhI6DpKACI0uBKI8GgYAEY490SsVPTVACMkGkzsqDyC6qhiqDL0gCFOysLYACYGhM8U8vbO5adu3PypoZG4cZpxp0qOSQBXYgBjYDo4YihzpuRyVxg8QhIKKloGFgAKIhoUCEYABKIHzJIwVhiQw0CDAE40W7-FAAOlhYHQSHOEB+OVUPwA2kgALROAC6wJyjAANFAUOxWCgCbUySjgHAAKpgSA0R444HAqBISiNBaQ8LKDhVKIAeTaACsIJdRRDXgIPnAFUrgKw2FBodwCQBpQa3ADWEBAcEksCFIvBWBNADJPvQmMwyUDjWSOMpwsczpdrrdNYrlQ63Gr3pRQ9rmD9Q0DQVA5WHgCqvFDDOcbtQoHATsAQkhiCA4mI-YY0rIfjniHmCWbaQA3Mn5m2p7UokhfCDkBMKgX6wL5wsE+6ePk-M3Att65vhbiS7iw+GI0fACVSut5sDC+7octLDo0EK1aZ+3qbAZDMTHzohYgnFBtGSSnfAO5NOKx8MeDA-Hu5AHsC4R9FslBiFA5R7I+z6vrI765p+zYOHEE4YCiMGdD04E3pQT4vjIHAflAqHoLMeoYegWGtCei48IxTE8H0AB+7EcaxUAAAo0HAPKgFALRwMsXRQKQcB9lAxBwJ+BDFJ+Nz9JAI7McxfRqUJUHYae0nwTI2TKMkKJQAAInQpBQFaJx0ootzCXsyRGBwQA" target="_blank" rel="noopener" onclick="return trackOutboundLink('a typed objecttocamel', 'https://www.typescriptlang.org/play?ts=4.2.0-dev.20201109#code/C4TwDgpgBAKg9gYQIYFsIBsA8BlKEAewEAdgCYDOU5wATgJbEDmAfFALwBQU3UuBRZSgAMAJAG8GAMwg0oACQhJSAXwD64qTNhI66ZUK48A-FFFiFS5eORg6wJOjoAvCJnjI0WGDvTNm+w24ALl4Abg5QSFgABnZYRFQMTABySTg4ZOZQ7gB6HKhI6DpKACI0uBKI8GgYAEY490SsVPTVACMkGkzsqDyC6qhiqDL0gCFOysLYACYGhM8U8vbO5adu3PypoZG4cZpxp0qOSQBXYgBjYDo4YihzpuRyVxg8QhIKKloGFgAKIhoUCEYABKIHzJIwVhiQw0CDAE40W7-FAAOlhYHQSHOEB+OVUPwA2kgALROAC6wJyjAANFAUOxWCgCbUySjgHAAKpgSA0R444HAqBISiNBaQ8LKDhVKIAeTaACsIJdRRDXgIPnAFUrgKw2FBodwCQBpQa3ADWEBAcEksCFIvBWBNADJPvQmMwyUDjWSOMpwsczpdrrdNYrlQ63Gr3pRQ9rmD9Q0DQVA5WHgCqvFDDOcbtQoHATsAQkhiCA4mI-YY0rIfjniHmCWbaQA3Mn5m2p7UokhfCDkBMKgX6wL5wsE+6ePk-M3Att65vhbiS7iw+GI0fACVSut5sDC+7octLDo0EK1aZ+3qbAZDMTHzohYgnFBtGSSnfAO5NOKx8MeDA-Hu5AHsC4R9FslBiFA5R7I+z6vrI765p+zYOHEE4YCiMGdD04E3pQT4vjIHAflAqHoLMeoYegWGtCei48IxTE8H0AB+7EcaxUAAAo0HAPKgFALRwMsXRQKQcB9lAxBwJ+BDFJ+Nz9JAI7McxfRqUJUHYae0nwTI2TKMkKJQAAInQpBQFaJx0ootzCXsyRGBwQA', event);">complete playground</a>.</p>
<h2 id="What-can-should-you-do-with-template-literal-types"><a href="#What-can-should-you-do-with-template-literal-types" title="What can should you do with template literal types?"></a>What <del>can</del> should you do with template literal types?</h2><p>After template literal types landed, the TypeScript Twittersphere went crazy. I shared a use case around <a href="https://expressjs.com/en/guide/routing.html" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://expressjs.com/en/guide/routing.html', event);">express</a>, which quickly became the most popular tweet I've ever posted:</p>
<blockquote><p lang="en" dir="ltr">Another use of <a href="https://twitter.com/typescript?ref_src=twsrc%5Etfw" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://twitter.com/typescript?ref_src=twsrc%5Etfw', event);">@TypeScript</a> 4.1's template literal types: extracting the URL parameters from an express route. Pretty amazing you can do this in the type system! <a href="https://t.co/gfZQy70whg" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://t.co/gfZQy70whg', event);">https://t.co/gfZQy70whg</a> <a href="https://t.co/aEyfMwjjqX" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://t.co/aEyfMwjjqX', event);">pic.twitter.com/aEyfMwjjqX</a></p>‚Äî Dan Vanderkam (@danvdk) <a href="https://twitter.com/danvdk/status/1301707026507198464?ref_src=twsrc%5Etfw" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://twitter.com/danvdk/status/1301707026507198464?ref_src=twsrc%5Etfw', event);">September 4, 2020</a></blockquote> 

<p>A <a href="https://twitter.com/buildsghost/status/1301976526603206657" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://twitter.com/buildsghost/status/1301976526603206657', event);">JSON parser</a> made the rounds and then someone <a href="https://github.com/codemix/ts-sql" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://github.com/codemix/ts-sql', event);">implemented a full SQL engine</a> in the type system. Hacker news <a href="https://news.ycombinator.com/item?id=24615185" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://news.ycombinator.com/item?id=24615185', event);">was impressed</a>.</p>
<p>As with any new tool, it will take some time for the community to figure out the best ways to use it. Here are a few ideas. We'll see how they pan out!</p>
<ul>
<li><p>Dotted access: <strong>easy win</strong></p>
<p>Lodash allows you to write <a href="https://stackoverflow.com/a/43395675/388951" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://stackoverflow.com/a/43395675/388951', event);">"iteratee" expressions</a> like <code>xs.map('a.b.c')</code>, which is roughly the same as <code>xs.map(x =&gt; x.a.b.c)</code>. Template literal types will make it possible for this sort of API to be typed.</p>
<p>I've never been a big fan of this style. I'd prefer to write <code>x =&gt; x.a.b.c</code>. But perhaps some of this is just bias from not being able to type these properly in the past. Using string literals for enums, for example, is frowned upon in Java as unsafe, <a href="https://cocoacasts.com/the-danger-of-string-literals-and-stringly-typed-code" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://cocoacasts.com/the-danger-of-string-literals-and-stringly-typed-code', event);">stringly typed</a>, code. But it turns out to be fine in TypeScript because the type system is rich enough to capture it. So we'll see!</p>
</li>
<li><p>Parsing routes: <strong>huge win!</strong></p>
<p>See my tweet above. Parsing <code>{userId: string}</code> out of <code>/users/:userId</code> will be a big win for express users.</p>
<p>Going the other direction is also compelling. In a server I use at work, we issue API calls via something like <code>get('/users/:userId', {userId: 'id'})</code>. We have types defined for the parameters for each route. But now we can just let TypeScript infer them to ensure that nothing will ever get out of sync.</p>
<p>Similar considerations apply to routes with <a href="https://reactrouter.com/web/example/url-params" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://reactrouter.com/web/example/url-params', event);">react-router</a>.</p>
</li>
<li><p>Better types for <code>querySelector</code> / <code>querySelectorAll</code>: <strong>nice win</strong></p>
<p>The <a href="https://github.com/microsoft/TypeScript/blob/b5b0437a86661c8d7bc76c5860c07305df17899c/lib/lib.dom.d.ts#L11341-L11349" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://github.com/microsoft/TypeScript/blob/b5b0437a86661c8d7bc76c5860c07305df17899c/lib/lib.dom.d.ts#L11341-L11349', event);">DOM typings</a> are clever enough to infer a subtype of <code>Element</code> here:</p>
<figure><div><pre><code><span>const</span> input = <span>document</span>.queryQuerySelector(<span>'input'</span>);<br><br></code></pre></div></figure>

<p>But once you add anything more complex to the selector, you lose this:</p>
<figure><div><pre><code><span>const</span> input = <span>document</span>.queryQuerySelector(<span>'input.my-class'</span>);<br><br></code></pre></div></figure>

<p>With template literal types, it will be possible to fix this. I wouldn't be surprised if it becomes common practice to replace calls to <code>getElementById</code> with equivalent calls to <code>querySelector</code>:</p>
<figure><div><pre><code><span>const</span> el1 = <span>document</span>.getElementById(<span>'foo'</span>);<br><br><span>const</span> div = <span>document</span>.querySelector(<span>'div#foo'</span>);<br><br></code></pre></div></figure>

<p>This will no doubt require me to rewrite Item 55 of <a href="https://amzn.to/38s1oCK" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://amzn.to/38s1oCK', event);"><em>Effective TypeScript</em></a> ("Understand the DOM hierarchy"). Oh well!</p>
</li>
<li><p>Parsing options in <a href="https://www.npmjs.com/package/commander" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://www.npmjs.com/package/commander', event);">Commander</a> or <a href="https://github.com/docopt/docopt.coffee" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://github.com/docopt/docopt.coffee', event);">docopt</a>: <strong>a small win</strong></p>
<p>With <a href="https://www.npmjs.com/package/commander" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://www.npmjs.com/package/commander', event);">Commander</a>, you define your command line tool's arguments using something like this:</p>
<figure><div><pre><code>program<br>  .option(<span>'-d, --debug'</span>, <span>'output extra debugging'</span>)<br>  .option(<span>'-s, --small'</span>, <span>'small pizza size'</span>)<br>program.parse(process.argv);<br><span>console</span>.log(program.debug, program.small);<br></code></pre></div></figure>

<p>Setting aside the mutation style, which is hard to model in TypeScript, template literal types should make it possible to extract the parameter names from the calls to <code>.option</code>.</p>
</li>
<li><p>Parsing SQL or GraphQL: <strong>I could go either way!</strong></p>
<p>The <a href="https://github.com/codemix/ts-sql" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://github.com/codemix/ts-sql', event);">ts-sql</a> demo <a href="https://news.ycombinator.com/item?id=24615185" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://news.ycombinator.com/item?id=24615185', event);">raised some eyebrows</a>, but it also made a real point about the power of template literal types. Given a TypeScript version of your database schema (which can be generated using <a href="https://github.com/PSYT/schemats" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://github.com/PSYT/schemats', event);">schemats</a> or <a href="https://github.com/danvk/schemats" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://github.com/danvk/schemats', event);">pg-to-ts</a>), it should be possible to infer result types for a SQL query:</p>
<figure><div><pre><code><span>import</span> {Schema} <span>from</span> <span>'./dbschema'</span>;<p><span>async</span> <span><span>function</span> <span>getStudentsByAge</span>(<span>db: Pool, age: <span>number</span></span>) </span>{<br>  <span>const</span> result = <span>await</span> db.query&lt;Schema&gt;(<span>`</span><br><span>  SELECT first_name, last_name FROM students</span><br><span>  WHERE age = $1;</span><br><span>  `</span>, [age]);  <br>  <span>return</span> result.rows;<br>  <br>}</p></code></pre></div></figure>

<p>This seems potentially amazing, but also perhaps brittle. You'd have to work in the subset of SQL that your types understood: presumably you wouldn't want to implement all of <a href="https://en.wikipedia.org/wiki/PL/pgSQL" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://en.wikipedia.org/wiki/PL/pgSQL', event);">PL/pgSQL</a> in the type system. But I could imagine getting a large class of queries, including joins, to work.</p>
<p>So I'm on the fence on this one! Similar considerations apply to GraphQL queries, which would be a bit easier to join with a schema in the type system than raw SQL.</p>
</li>
</ul>
<p>Template literal types open up many new doors for TypeScript library authors and should improve the overall experience of using TypeScript for everyone by capturing more JavaScript patterns in the type system.</p>
<p>I'd like to conclude by pointing out that this is a very <em>TypeScripty</em> solution to this problem. ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://effectivetypescript.com/2020/11/05/template-literal-types/">https://effectivetypescript.com/2020/11/05/template-literal-types/</a></em></p>]]>
            </description>
            <link>https://effectivetypescript.com/2020/11/05/template-literal-types/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059336</guid>
            <pubDate>Wed, 11 Nov 2020 15:52:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ZX Spectrum 8-Bit Chiptune Music Collection: AY-3-8910, Beeper, Digital]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059328">thread link</a>) | @elvis70
<br/>
November 11, 2020 | https://zxart.ee/eng/music/ | <a href="https://web.archive.org/web/*/https://zxart.ee/eng/music/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://zxart.ee/eng/music/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059328</guid>
            <pubDate>Wed, 11 Nov 2020 15:51:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using the Webmention.io API]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059318">thread link</a>) | @todsacerdoti
<br/>
November 11, 2020 | https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/ | <a href="https://web.archive.org/web/*/https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article>
    <header>
      <p>Fetching my IndieWeb mentions with HTTPie and Requests</p><section>
      <p><time datetime="2020-11-10T00:00:00+00:00">
            <a href="https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/">
              Tuesday, 10 November, 2020
            </a>
          </time>‚Äî by
          <br>
        <a href="https://randomgeekery.org/post">Post</a>
        ‚Äî <a href="https://randomgeekery.org/categories/tools/">Tools</a>
      
      
      
        ‚Äî
        
          <a href="https://randomgeekery.org/tags/python">Python</a>
        
          <a href="https://randomgeekery.org/tags/indieweb">IndieWeb</a>
        
          <a href="https://randomgeekery.org/tags/fixing-my-site">fixing my site</a>
        
          <a href="https://randomgeekery.org/tags/site">Site</a>
        
      <br>
        Around 1,300 words, or 6 minutes of reading</p><section><p>Part 1 of 1 in the
              <a href="https://randomgeekery.org/series/fixing-my-webmentions">fixing my webmentions</a> series.</p>
          <dl></dl></section>
        

        
        
<nav>
  <section>
    <header>
      
      Previous Post
    </header>
    
      <p>
        <a href="https://randomgeekery.org/post/2020/07/tangling-code-from-hugo-content-with-raku/">Tangling code from Hugo content with Raku</a>
      </p>
      
    
  </section>
  <section>
    <header>
      Next Post
      
    </header>
    
      <p><em>You are reading the newest post</em></p>
    
  </section>
</nav>

      </section>
  
  
  
    
  

  <figure>
    <a href="https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/cover.jpg">
      <img src="https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/cover.jpg" alt="A spiderweb! For Webmention! Get it? Okay, yeah. Sorry.">
    </a><figcaption>A spiderweb! For Webmention! Get it? Okay, yeah. Sorry.</figcaption></figure>


    </header>
    <section>

      <p>So I hosed a local copy of my mentions feed the other month.
What‚Äôs my ‚Äúmentions feed,‚Äù I hear you wondering?</p>
<p>Whenever somebody shares a reaction to something here ‚Äî like, reshare, reply, mention ‚Äî that reaction gets sent to <a href="https://webmention.io/">Webmention.io</a>.
There are more moving parts than that, of course.
<a href="https://brid.gy/">Bridgy</a> aggregates reactions to my announcement toots and tweets and sends those to Webmention.
It shows in my mentions feed as a reaction to site content when someone reacts to a relevant tweet.</p>
<p><em>Sometimes</em> folks even post mentions, replies, and reactions directly to the Webmention endpoint.
Mostly it‚Äôs just social media reactions, though.</p>
<p>The <a href="https://github.com/aaronpk/webmention.io#api">Webmention.io API</a> lets me gather all of these reactions.</p>
<p>Let‚Äôs acquaint ourselves with the important parts of this API.
You‚Äôll need your API token, which can be found in the Webmention <a href="https://webmention.io/settings">Settings</a> once you sign up.</p>
<h2 id="reading-the-feed-with-httpie">Reading the feed with HTTPie</h2>
<p>I‚Äôll use <a href="https://httpie.io/">HTTPie</a> for my little exploration.
I like the way it works.</p>
<h3 id="getting-recent-reactions">Getting recent reactions</h3>
<p>We mainly care about the mentions endpoint.
Hand it your domain and API token, and it will send you the 20 most recent responses for your site.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>domain</span><span>==</span>randomgeekery.org <span>token</span><span>==</span><span>$WEBMENTION_KEY</span>
</code></pre></div><p>HTTPie‚Äôs double-equals <code>==</code> syntax means ‚Äúmake a query string,‚Äù so I end up with something like this:</p>
<div><pre><code data-lang="text">https://webmention.io/api/mentions.jf2?domain=randomgeekery.org&amp;token=xxxxx
</code></pre></div><p>When <code>http</code> fetches that URL, I get back a <a href="https://www.w3.org/TR/jf2/">JF2</a> feed that looks something like this.</p>
<div><pre><code data-lang="json"><span>{</span>
    <span>"children"</span><span>:</span> <span>[</span>
        <span>{</span>
            <span>"author"</span><span>:</span> <span>{</span>
                <span>"name"</span><span>:</span> <span>"Jumpei KAWAMI"</span><span>,</span>
                <span>"photo"</span><span>:</span> <span>"https://webmention.io/avatar/‚Ä¶"</span><span>,</span>
                <span>"type"</span><span>:</span> <span>"card"</span><span>,</span>
                <span>"url"</span><span>:</span> <span>"https://twitter.com/junkw"</span>
            <span>},</span>
            <span>"content"</span><span>:</span> <span>{</span>
                <span>"text"</span><span>:</span> <span>"I wrote a note:\n\nI added this note from org mode‚Ä¶"</span>
            <span>},</span>
            <span>"published"</span><span>:</span> <span>"2020-10-25T23:32:25+00:00"</span><span>,</span>
            <span>"repost-of"</span><span>:</span> <span>"https://randomgeekery.org/note/2020/10/i-added-this-note-from-org-mode/"</span><span>,</span>
            <span>"type"</span><span>:</span> <span>"entry"</span><span>,</span>
            <span>"url"</span><span>:</span> <span>"https://twitter.com/junkw/status/1320508544601509889"</span><span>,</span>
            <span>"wm-id"</span><span>:</span> <span>887739</span><span>,</span>
            <span>"wm-private"</span><span>:</span> <span>false</span><span>,</span>
            <span>"wm-property"</span><span>:</span> <span>"repost-of"</span><span>,</span>
            <span>"wm-received"</span><span>:</span> <span>"2020-10-26T04:07:20Z"</span><span>,</span>
            <span>"wm-source"</span><span>:</span> <span>"https://brid-gy.appspot.com/repost/twitter/brianwisti/‚Ä¶"</span><span>,</span>
            <span>"wm-target"</span><span>:</span> <span>"https://randomgeekery.org/note/2020/10/i-added-this-note-from-org-mode/"</span>
        <span>},</span>
        <span>‚ãÆ</span>
    <span>],</span>
    <span>"name"</span><span>:</span> <span>"Webmentions"</span><span>,</span>
    <span>"type"</span><span>:</span> <span>"feed"</span>
<span>}</span>
</code></pre></div><p>What‚Äôs JF2?
It‚Äôs obviously JSON.
Maybe something to do with <a href="https://jsonfeed.org/">JSON Feed</a>?
Similar, but no.
JF2 is a JSON format for IndieWeb‚Äôs <a href="http://microformats.org/wiki/microformats2">microformats2</a>.
The mnemonic I‚Äôve been trying to drill into my head is ‚ÄúJSON (micro)Formats 2.‚Äù</p>
<p>It‚Äôs not a very good mnemonic.</p>
<p>Each entry summarizes the reaction, including which of my posts they were reacting to.
That‚Äôs kind of important.
Most recently, Twitter user <a href="https://twitter.com/junkw">junkw</a> retweeted my announcement about <a href="https://randomgeekery.org/note/2020/10/i-added-this-note-from-org-mode/">adding a note from Org mode</a>.</p>
<div>
  <p>Note</p><p>

  There‚Äôs also a <code>.json</code> endpoint for every feed that presents a different structure for mentions.
I prefer it, because it contains fewer <code>wm-*</code> fields.
But the documentation uses JF2, so that‚Äôs what I‚Äôll do.</p></div>

<h3 id="checking-for-new-reactions">Checking for new reactions</h3>
<p>Maybe I‚Äôm checking again later and only want to see the <em>new</em> reactions.
I request mentions received since the value of the <code>wm-received</code> field in the last entry I have.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>\
</span><span></span>  <span>domain</span><span>==</span>randomgeekery.org <span>\
</span><span></span>  <span>token</span><span>==</span><span>$WEBMENTION_KEY</span> <span>\
</span><span></span>  <span>since</span><span>==</span><span>"2020-10-26T04:07:20Z"</span>
</code></pre></div><div><pre><code data-lang="json"><span>{</span>
    <span>"children"</span><span>:</span> <span>[],</span>
    <span>"name"</span><span>:</span> <span>"Webmentions"</span><span>,</span>
    <span>"type"</span><span>:</span> <span>"feed"</span>
<span>}</span>
</code></pre></div><p>Well, yeah.
That makes sense.
I don‚Äôt get the kind of traffic where you‚Äôd expect fresh reactions every time you check.</p>
<h3 id="fetching-the-oldest-reactions-first">Fetching the oldest reactions first</h3>
<p>As I mentioned at the start, my site is a little broken.
I need to rebuild the full list of reactions so my <a href="https://randomgeekery.org/tags/hugo">Hugo</a> site can work with a complete record.
To do that, I should probably start from the oldest mentions and work my way forward.</p>
<p>Rather than the default <code>sort-dir</code> of <code>down</code>, I specify <code>up</code>.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>\
</span><span></span>  <span>domain</span><span>==</span>randomgeekery.org <span>\
</span><span></span>  <span>token</span><span>==</span><span>$WEBMENTION_KEY</span> <span>\
</span><span></span>  sort-dir<span>==</span>up
</code></pre></div><div><pre><code data-lang="json"><span>{</span>
    <span>"children"</span><span>:</span> <span>[</span>
        <span>{</span>
            <span>"author"</span><span>:</span> <span>{</span>
                <span>"name"</span><span>:</span> <span>"Steve Scaffidi"</span><span>,</span>
                <span>"photo"</span><span>:</span> <span>"https://webmention.io/avatar/‚Ä¶"</span><span>,</span>
                <span>"type"</span><span>:</span> <span>"card"</span><span>,</span>
                <span>"url"</span><span>:</span> <span>"https://twitter.com/hercynium"</span>
            <span>},</span>
            <span>"content"</span><span>:</span> <span>{</span>
                <span>"html"</span><span>:</span> <span>"This is where I wish Perl5 had something like Python's AST class hierarchy‚Ä¶"</span><span>,</span>
                <span>"text"</span><span>:</span> <span>"This is where I wish Perl5 had something like Python's AST class hierarchy‚Ä¶"</span>
            <span>},</span>
            <span>"in-reply-to"</span><span>:</span> <span>"https://randomgeekery.org/2020/02/17/python-invoke/"</span><span>,</span>
            <span>"published"</span><span>:</span> <span>"2020-02-18T03:11:58+00:00"</span><span>,</span>
            <span>"type"</span><span>:</span> <span>"entry"</span><span>,</span>
            <span>"url"</span><span>:</span> <span>"https://twitter.com/hercynium/status/1229604443651526656"</span><span>,</span>
            <span>"wm-id"</span><span>:</span> <span>757935</span><span>,</span>
            <span>"wm-private"</span><span>:</span> <span>false</span><span>,</span>
            <span>"wm-property"</span><span>:</span> <span>"in-reply-to"</span><span>,</span>
            <span>"wm-received"</span><span>:</span> <span>"2020-02-18T22:32:20Z"</span><span>,</span>
            <span>"wm-source"</span><span>:</span> <span>"https://brid-gy.appspot.com/comment/twitter/brianwisti/‚Ä¶"</span><span>,</span>
            <span>"wm-target"</span><span>:</span> <span>"https://randomgeekery.org/2020/02/17/python-invoke/"</span>
        <span>}</span>
    <span>],</span>
    <span>"name"</span><span>:</span> <span>"Webmentions"</span><span>,</span>
    <span>"type"</span><span>:</span> <span>"feed"</span>
<span>}</span>
</code></pre></div><p>Aww, my first site reply.
From <a href="https://twitter.com/hercynium">hercynium</a>.</p>
<p>I only get 20 results by default, though.
Here.
Let‚Äôs make <a href="https://stedolan.github.io/jq/">jq</a> show us.
Here‚Äôs a default page.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>\
</span><span></span>  <span>domain</span><span>==</span>randomgeekery.org <span>token</span><span>==</span><span>$WEBMENTION_KEY</span> sort-dir<span>==</span>up <span>\
</span><span></span>  <span>|</span> jq <span>'.children | length'</span>
</code></pre></div><pre><code>20
</code></pre><h3 id="handling-result-pagination">Handling result pagination</h3>
<p>I can specify how many responses I want in each response with the <code>per-page</code> parameter.
With <code>per-page</code> set to 100, I get a hundred entries.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>\
</span><span></span>  <span>domain</span><span>==</span>randomgeekery.org <span>token</span><span>==</span><span>$WEBMENTION_KEY</span> per-page<span>==</span><span>100</span> <span>\
</span><span></span>  <span>|</span> jq <span>'.children | length'</span>
</code></pre></div><pre><code>100
</code></pre><p>Of course, if there aren‚Äôt a hundred entries to fill the page, I only get what‚Äôs available.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>\
</span><span></span>  <span>domain</span><span>==</span>randomgeekery.org <span>token</span><span>==</span><span>$WEBMENTION_KEY</span> <span>since</span><span>==</span><span>"2020-10-26T04:07:20Z"</span> per-page<span>=</span><span>100</span> <span>\
</span><span></span>  <span>|</span> jq <span>'.children | length'</span>
</code></pre></div><pre><code>0
</code></pre><p>The <code>page</code> parameter ‚Äî which starts at zero ‚Äî lets me step through the feed in batches.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>\
</span><span></span>  <span>domain</span><span>==</span>randomgeekery.org <span>\
</span><span></span>  <span>token</span><span>==</span><span>$WEBMENTION_KEY</span> <span>\
</span><span></span>  sort-dir<span>==</span>up <span>\
</span><span></span>  <span>page</span><span>==</span><span>1</span>
</code></pre></div><div><pre><code data-lang="json"><span>{</span>
    <span>"children"</span><span>:</span> <span>[</span>
        <span>{</span>
            <span>"author"</span><span>:</span> <span>{</span>
                <span>"name"</span><span>:</span> <span>"brian wisti"</span><span>,</span>
                <span>"photo"</span><span>:</span> <span>"https://webmention.io/avatar/‚Ä¶"</span><span>,</span>
                <span>"type"</span><span>:</span> <span>"card"</span><span>,</span>
                <span>"url"</span><span>:</span> <span>"https://twitter.com/brianwisti"</span>
            <span>},</span>
            <span>"content"</span><span>:</span> <span>{</span>
                <span>"html"</span><span>:</span> <span>"‚Ä¶"</span><span>,</span>
                <span>"text"</span><span>:</span> <span>"‚Ä¶"</span><span>,</span>
            <span>},</span>
            <span>"in-reply-to"</span><span>:</span> <span>"https://randomgeekery.org/2020/01/19/restructuredtext-basics-for-blogging/"</span><span>,</span>
            <span>"published"</span><span>:</span> <span>"2020-03-10T06:24:45+00:00"</span><span>,</span>
            <span>"type"</span><span>:</span> <span>"entry"</span><span>,</span>
            <span>"url"</span><span>:</span> <span>"https://twitter.com/brianwisti/status/1237263101482823681"</span><span>,</span>
            <span>"wm-id"</span><span>:</span> <span>766993</span><span>,</span>
            <span>"wm-private"</span><span>:</span> <span>false</span><span>,</span>
            <span>"wm-property"</span><span>:</span> <span>"in-reply-to"</span><span>,</span>
            <span>"wm-received"</span><span>:</span> <span>"2020-03-10T06:38:55Z"</span><span>,</span>
            <span>"wm-source"</span><span>:</span> <span>"https://brid-gy.appspot.com/comment/twitter/brianwisti/‚Ä¶"</span><span>,</span>
            <span>"wm-target"</span><span>:</span> <span>"https://randomgeekery.org/2020/01/19/restructuredtext-basics-for-blogging/"</span>
        <span>},</span>
        <span>‚ãÆ</span>
    <span>],</span>
    <span>"name"</span><span>:</span> <span>"Webmentions"</span><span>,</span>
    <span>"type"</span><span>:</span> <span>"feed"</span>
<span>}</span>
</code></pre></div><p>Right.
That‚Äôs Bridgy catching a Twitter thread.
At least I can see the full conversation from my site.
Or I wil once I‚Äôm done fixing everything.</p>
<h3 id="bonus-checking-for-reactions-to-a-specific-post">Bonus: checking for reactions to a specific post</h3>
<p>I could get a JF2 feed for specific URLs on my site if I was so inclined.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>target</span><span>==</span>https://randomgeekery.org
</code></pre></div><div><pre><code data-lang="json"><span>{</span>
    <span>"children"</span><span>:</span> <span>[</span>
        <span>{</span>
            <span>"author"</span><span>:</span> <span>{</span>
                <span>"name"</span><span>:</span> <span>""</span><span>,</span>
                <span>"photo"</span><span>:</span> <span>""</span><span>,</span>
                <span>"type"</span><span>:</span> <span>"card"</span><span>,</span>
                <span>"url"</span><span>:</span> <span>""</span>
            <span>},</span>
            <span>"mention-of"</span><span>:</span> <span>"https://randomgeekery.org"</span><span>,</span>
            <span>"published"</span><span>:</span> <span>null</span><span>,</span>
            <span>"type"</span><span>:</span> <span>"entry"</span><span>,</span>
            <span>"url"</span><span>:</span> <span>"https://kevq.uk/blogroll/"</span><span>,</span>
            <span>"wm-id"</span><span>:</span> <span>796241</span><span>,</span>
            <span>"wm-private"</span><span>:</span> <span>false</span><span>,</span>
            <span>"wm-property"</span><span>:</span> <span>"mention-of"</span><span>,</span>
            <span>"wm-received"</span><span>:</span> <span>"2020-05-14T11:25:47Z"</span><span>,</span>
            <span>"wm-source"</span><span>:</span> <span>"https://kevq.uk/blogroll/"</span><span>,</span>
            <span>"wm-target"</span><span>:</span> <span>"https://randomgeekery.org"</span>
        <span>}</span>
    <span>],</span>
    <span>"name"</span><span>:</span> <span>"Webmentions"</span><span>,</span>
    <span>"type"</span><span>:</span> <span>"feed"</span>
<span>}</span>
</code></pre></div><p>I deal with my site reactions in bulk so they can be incorporated in the Hugo build.
This could be handy for JavaScript-driven update on reactions since the site was last built and pushed, though.</p>
<h2 id="rebuilding-the-local-mentions-file">Rebuilding the local mentions file</h2>
<p>Now I want to take what I learned about the API to build a local copy of my site‚Äôs mention history.
Let‚Äôs step away from HTTPie and the command line before I try something dangerous.</p>
<p>The <a href="https://requests.readthedocs.io/en/master/">requests</a> library for <a href="https://randomgeekery.org/tags/python">Python</a> can help me build one list of Webmentions.</p>
<div><pre><code data-lang="python"><span>import</span> <span>json</span>
<span>import</span> <span>os</span>
<span>import</span> <span>time</span>

<span>import</span> <span>requests</span>

<span>def</span> <span>rebuild_full_feed</span><span>(</span><span>domain</span><span>:</span> <span>str</span><span>,</span> <span>token</span><span>:</span> <span>str</span><span>,</span> <span>target_file</span><span>:</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>None</span><span>:</span>
    <span>endpoint</span> <span>=</span> <span>"https://webmention.io/api/mentions.jf2"</span>
    <span>page_size</span> <span>=</span> <span>100</span>
    <span>all_entries</span> <span>=</span> <span>[]</span>
    <span>page_index</span> ‚Ä¶</code></pre></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/">https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/</a></em></p>]]>
            </description>
            <link>https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059318</guid>
            <pubDate>Wed, 11 Nov 2020 15:49:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Instacart Web Performance Audit]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25059265">thread link</a>) | @toddgardner
<br/>
November 11, 2020 | https://requestmetrics.com/web-performance/performance-profiling-instacart | <a href="https://web.archive.org/web/*/https://requestmetrics.com/web-performance/performance-profiling-instacart">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Grocery shopping is tedious and time consuming.  In search of a more streamlined experience, I decided to try Instacart.  Unfortunately, using their site is <em>also</em> tedious and time consuming.</p>

<!--more-->

<h2 id="common-actions-take-too-long">Common Actions Take Too Long</h2>
<p>In the video you‚Äôll see I attempt to visit the landing page of my local grocery store and, after that loads, do a search for <em>yogurt</em>.</p>

<figure>
    <video controls="" muted="" preload="metadata">
        <source src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-load-and-search.mp4" type="video/mp4">
    </video>
    <figcaption>Visiting a grocery store homepage and searching for items.</figcaption>
</figure>

<p>Over <strong>25</strong> seconds to perform a single load and search.  Just loading the Cub Foods ‚Äústorefront‚Äù page took <strong>14</strong> seconds and <strong>154</strong> requests.</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-total-stats.png" alt="Loading a single storefront">
    <figcaption>Network stats for loading a single storefront in Instacart.</figcaption>
</figure>

<p>On the plus side there were some very nice placeholder graphics that set the mood while I waited.</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-placeholder.png" alt="Placeholder graphics for days">
</figure>

<h3 id="when-its-not-javascripts-fault">When it‚Äôs not JavaScript‚Äôs Fault</h3>
<p>Usually when I look at ‚Äúmodern‚Äù websites the main performance culprit is JavaScript.  Too many scripts doing too much rendering.  While Instacart <em>does</em> have too much JavaScript, they have a bigger problem: <strong>the server</strong>.</p>

<h4 id="the-initial-page-load-is-slow">The Initial Page Load is Slow</h4>
<p>Instacart uses some combination of server and client rendering.  On the one hand, it‚Äôs great that they don‚Äôt just load a blank page with a big spinner in the middle and wait for 20MB of JavaScript to load.</p>
<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-slow-page.png" alt="3 seconds to load the basic page skeleton">
</figure>
<p>On the other hand it took <strong>3</strong> seconds to get the single page layout skeleton back.</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-skeleton.png" alt="Just a basic SPA template">
    <figcaption>Three seconds for some placeholder template HTML is a bit long.</figcaption>
</figure>

<p>The images to populate the placeholder template took another few seconds:</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-slow-image.png" alt="4 seconds for a background image">
</figure>

<p>If you notice the first segment of the URL after the Cloudfront domain is <code>/156x/</code>. These endpoints will return custom sized images and that first segment is the requested dimensions.  You can change that segment to <code>/300x/</code>, for example, and you‚Äôll get a bigger image that maintains aspect ratio (it will be 300px wide by whatever the height should be to keep the ratio).  You can also specify a height if you want a different effect:</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-custom-image-size.png" alt="Custom images sizes are great, but costly for performance">
</figure>

<p>Cool, but this is almost certainly part of the reason loading uncached images is so slow. The origin behind Cloudfront is doing a lot of work to make a custom image and send it over the wire on-demand.</p>

<p>In all fairness, these images have the proper cache response headers, so subsequent page loads will have the images served from the browser memory cache.  But that first hit is very slow.</p>

<h4 id="the-api-is-slow-too">The API is Slow Too</h4>
<p>It isn‚Äôt just the page load and images that are slow.  The servers responding to API requests are taking their time as well.  Some of the calls to populate data on the page took over <strong>5</strong> seconds!</p>
<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-slow-api.png" alt="Several API calls took over 5 seconds">
</figure>

<p>One of the endpoints shown here fetches coupon information.  In the initial loading video you can see the coupon section is particularly slow to render.  Even though there is content loaded below the fold, the user has no idea since the placeholders are still shown for the coupon section until that call returns.</p>

<h4 id="placeholders-are-nice-but-faster-endpoints-are-better">Placeholders are Nice But Faster Endpoints are Better</h4>

<p>This is where the hybrid rendering model falls apart a bit.  There is a lot of dynamic content being rendered post page load.  And since the API is slow the user is getting even more placeholders.</p>

<p>As the user scrolls down the page there are on-demand API calls made to show products from each grocery department.  These calls can take upwards of 2 seconds each.  And there‚Äôs a lot of them.</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-slow-department.png" alt="On-demand API calls to load additional products are slow.">
</figure>

<p>For each one we get more placeholder graphics until the server returns its response:</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-more-placeholders.png" alt="Placeholders are cool, but speed would be better.">
</figure>

<p>Placeholders do a nice job of minimizing jank or <a href="https://requestmetrics.com/web-performance/cumulative-layout-shift">cumulative layout shift</a> but they are a poor substitute for the actual content.  Paradoxically I find they can also make a site feel slower since the UI is changing out from under the user so frequently.</p>

<h3 id="maybe-instacart-doesnt-think-it-has-a-performance-problem">Maybe Instacart Doesn‚Äôt Think It Has a Performance Problem?</h3>
<p>There‚Äôs a <a href="https://tech.instacart.com/building-instacarts-view-model-api-part-1-why-view-model-4362f64ffd2a">few articles</a> on <a href="https://tech.instacart.com/scaling-at-instacart-distributing-data-across-multiple-postgres-databases-with-rails-13b1e4eba202">the Instacart engineering blog</a> discussing the back-end technical implementation of the site.  In both the linked articles they discuss ‚Äúimproved performance‚Äù and the existing ‚Äúhealthy performance‚Äù of the site.  Perhaps the main problem is they don‚Äôt think there‚Äôs a performance issue to fix?</p>

<p>Most modern technical stacks are capable of serving pages and API calls in sub-second time if that‚Äôs the company‚Äôs goal.  I suspect in this case they have limited resources and other priorities.  Maybe things are better in the phone app, but I think I‚Äôll stick with going to the grocery store for now, it‚Äôs faster.</p>

</div></div>]]>
            </description>
            <link>https://requestmetrics.com/web-performance/performance-profiling-instacart</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059265</guid>
            <pubDate>Wed, 11 Nov 2020 15:44:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Productivity vs. Privacy]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25059205">thread link</a>) | @jessems
<br/>
November 11, 2020 | https://jessems.com/productivity-vs-privacy | <a href="https://web.archive.org/web/*/https://jessems.com/productivity-vs-privacy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>In recent years there's been a steady growth in privacy focused companies. Some examples that have reached large-scale adoption are <a href="https://protonmail.com/">ProtonMail</a>, <a href="https://signal.com/">Signal</a>, and <a href="https://duckduckgo.com/">DuckDuckGo</a>. These are companies that have put privacy front and center to their value proposition and can be considered <em>privacy-preserving products</em>. I've come to beleive a goal of preserving user privacy is often inherently in tension with the goal of advancing user productivity.</p><p>What these services have in common is that they promise their users a higher degree of privacy relative to their competitors. Instead of the usual encryption in transit (protection from eavesdroppers) and encryption at rest (protection against unauthorized users), services like Signal and ProtonMail enable their users to hide data from anyone except the intended recipient, which ‚Äî crucially ‚Äî includes the service providers themselves.</p><p>This category of encryption is known as end-to-end encryption (e2e) and has found adopters in anyone from principled libertarians to journalists and human rights activitists whose lives may depend on their conversations remaining unwiretapped.</p><h2>Early privacy-preserving software was too difficult to use</h2><p>The canonical implementation of e2e for email is known as Pretty Good Privacy (PGP) and its reference implementation is GPG. GPG never reached mass adoption and there seems to be a myriad of reasons for that. The most salient reason, however, seems to be that to this day, it continues to be difficult to use. As the founder of Signal, Moxie Marlinspike <a href="https://moxie.org/2015/02/24/gpg-and-me.html">explains</a>, the spirit behind GPG was the following:</p><blockquote><p>Instead of developing opinionated software with a simple interface, GPG was written to be as powerful and flexible as possible.</p></blockquote><p>Powerful, flexible software written by nerds, unfortunately also tends to be prohibitively complex for normal users. Combined with the fact that <a href="https://signal.org/blog/the-ecosystem-is-moving/">decentralized technology seems unable to quickly adapt to change</a>, the result has been a clunky solution that has, quite frankly, stayed clunky. With no feasible privacy-preserving alternative <!-- -->[1]<!-- -->, non-privacy preserving email providers became the norm.</p><h2>Surveillance capitalist companies will not encrypt your data, because they rely on being able to read it</h2><p>One such email provider, Gmail by Google, gained millions of users by offering a free plan. Their initial monetization strategy was scanning your emails and serving you personalized ads. Although they've stopped personalizing the ads, they're still scanning your email's contents to serve you a better experience across their services. Similarly, Facebook tracks what you do to shape your experience and keep you glued (they would say 'engaged') to their platform.</p><p>What unites platforms like Google and Facebook, is described by Professor Shoshana Zuboff as ‚Äú<a href="https://en.wikipedia.org/wiki/Surveillance_capitalism">surveillance capitalism</a>‚Äù. The business model of surveillance capitalist companies is to harvest personal data about you to build a model that predicts your behavior. These prediction models are packaged and sold as advertisement opportunities to companies eager to buy your attention. You might be the user, but you're not the customer ‚Äî the advertisers are.</p><p>It should come as no surprise then, that none of these platforms has shipped with end-to-end encryption by default. Doing so would go against the incentives that undergird their very business model. Their ability to predict your behavior, and sell ads based on those predictions, hinges on their ability to harvest your data.</p><h2>Data is also collected to improve the service</h2><p>A company like Google has other business models of course. Google Workspace, aimed at businesses, is a collection of collaboration and productivity tools. This ranges from Google Docs, to chat, to video conferencing, and more. By offering this as a paid service, Google exposes itself to a different incentive, one where the customer and the user are now one and the same.</p><p>Even if you're both the user and the customer, your data is still being harvested. This data might not feed into personalized ads (because that‚Äôs no longer the primary business model) but rather into improving your experience. But as a business user, when does your experience improve? And as a service provider, how do you know what improves the experience?</p><h2>Improvements are productivity gains</h2><p>There's an inclination to think of improvements as things that help you do the thing you want to do quicker, better and/or with less frustration. We can go one step further and borrow some of the thinking used in economics and treat productivity simply as the ratio between outputs (salaries and corporate profits) and inputs (hours worked). Productivity increases if inputs can be decreased (for equal outputs) or outputs can be increased (for equal inputs). What's more, we would expect this quantity to improve along with advances in technology.</p><p>How does technology lead to increases in productivity? One obvious way is by making us more efficient. If some new technology saves us time doing a certain task (decreased input), all other things being equal, we‚Äôll end up seeing those gains reflected in our outputs.</p><h2>Productivity gains are discovered, not planned</h2><p>What exactly are the things that increase efficiency? Here's where it gets tricky. In the realm of knowledge work, we don't always know where the gains will come from ‚Äî that is, before they are made. We are still discovering new ways in which we can be more productive and especially so in the domain of collaborative productivity. An illustrative example of how productivity gains are discovered comes from Kevin A. Kwok's description of Figma's road to success.</p><p>In "Why Figma Wins", <a href="https://kwokchain.com/2020/06/19/why-figma-wins/">Kwok details</a> how the product team discovered a way to enable more efficient collaboration in the design process. That this potential existed wasn't at all  obvious to even those within the scene. While Sketch had broken new ground with their vector based design tool geared towards product designers, Figma took it to another level by taking many of the same (dare I say revolutionary) UX patterns and offering them in a web-native, multiplayer web application.</p><blockquote><p>The core insight of Figma is that design is larger than just designers. Design is all of the conversations between designers and PMs about what to build. It is the mocks and prototypes and the feedback on them. It is the handoff of specs and assets to engineers and how easy it is for them to implement them.</p></blockquote><p>As Kevin explains, Figma brought together the disparate disciplines that are involved in a design process into a synced browser window for everybody. This helped democratize design and remove a lot of friction that had existed before.</p><p>Not only did Figma push the frontier of productivity into new territory, it wasn‚Äôt obvious beforehand what that territory would look like. The lesson is that productivity improvements are won through a process of <em>discovery</em>. Kevin explains:</p><blockquote><p>As disciplines evolve, they figure out the social norms needed to operate better, build tools that can be shared across the industry, and invent abstractions that allow offloading more and more of the workload. They learn how to collaborate better, not just with each other but with all the other functions as well.</p></blockquote><p>Although there's some inherent uncertainty about what the productivity gains will look like (and where to look for them), there's no uncertainty about whether they will be made at all. If one thing can be counted on, it's the tech industry's relentless march towards higher productivity. The big tech platforms know this and don't shy away from investing heavily in innovation (discovery) in that direction.</p><h2>Productivity gains are unlocked by harvesting data</h2><p>Although there is some inherent tension between preserving privacy vs. allowing for a multiplayer mode like Figma, we can find even stronger tensions when it comes to harvesting data in favor of productivity gains.</p><p>A search feature relies on indexing your data. A recommendation feature relies on mining your browsing history. An autocomplete feature relies on what you (or other users) typed before.</p><p>All these potential features which are made possible through harvesting your user data are not available to privacy-preserving products. The user data isn't readable to them ‚Äî and that's the whole point.</p><p>This creates a trade-off from the user's perspective. Whatever your particular motivation might be, as soon as you opt for a privacy-preserving service you're opting for a service that is not able to read your data, and by extension, not able to harvest it. Because the harvesting of data is what is driving many of the improvements in productivity, in choosing to preserve user privacy, these services are forgoing their ability to provide additional gains in productivity.</p><p>Historically, as we saw with the origins of GPG, there has always been additional friction involved in replicating a workflow in a privacy-preserving manner. Although using e2e services such as Signal and ProtonMail has become nearly frictionless, they lack many features their non-privacy preserving counterparts offer.</p><h2>The productivity gap between privacy-preserving and non-preserving services</h2><p>If you compare the productivity gains between privacy-preserving and non-preserving products from the perspective of the user, it's hard not to arrive at the conclusion that there‚Äôs a gap between the two ‚Äî and it appears to be growing.</p><p>There is perhaps no better example of a feature which hinges on the ability to read user data than search. Although ProtonMail is reminiscent of Gmail in many ways, one area where it falls short is the absence of any ability to  search the contents of your emails. Search only works if the provider of such functionality can scan and index your content. It works even better if the provider is able to harvest search queries and use those to build predictive models (e.g. autocomplete and smart suggestions). These are features which make Gmail users more productive but aren't available to ProtonMail users <!-- -->[3]<!-- -->.</p><p>The absence of search might not be a dealbreaker for a ‚Ä¶</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jessems.com/productivity-vs-privacy">https://jessems.com/productivity-vs-privacy</a></em></p>]]>
            </description>
            <link>https://jessems.com/productivity-vs-privacy</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059205</guid>
            <pubDate>Wed, 11 Nov 2020 15:37:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Public Safety Announcement: The 2020 Election Is Not Over]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25059009">thread link</a>) | @lettergram
<br/>
November 11, 2020 | https://austingwalters.com/public-safety-announcement-the-2020-election-is-not-over-as-of-nov-11-2020/ | <a href="https://web.archive.org/web/*/https://austingwalters.com/public-safety-announcement-the-2020-election-is-not-over-as-of-nov-11-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3754">

<div>
<p>I have been listening to my friends and family and am concerned that many are not aware of the election process. Having the presidential election flip from Democrat to Republican at this point can cause massive rioting, violence, etc.</p>
<p>We should all be aware of the current situation and the news outlets do not appear to be informing people.</p>
<blockquote><p><strong>Disclaimer</strong>: I‚Äôm am not pro-democrat or pro-republican. Personally, I believe neither party is fit to run the country.</p></blockquote>
<p>I wanted to share what appears to be the Republican strategy and why it‚Äôs possible (though still unlikely) Trump could win.</p>
<p>At time of writing Trump the betting markets have <a href="https://electionbettingodds.com/4hr.html" target="_blank" rel="noopener noreferrer">13% odds of winning the election</a> (odds calculated average from <a href="https://www.betfair.com/exchange/plus/politics">Betfair</a> and <a href="https://www.predictit.org/promo/electionbetting">PredictIt</a>).</p>
<p><a href="https://www.predictit.org/markets/detail/3698/Who-will-win-the-2020-US-presidential-election" target="_blank" rel="noopener noreferrer">PredictIt</a> currently has 16% odds of Trump winning:</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png" alt="" width="500" height="344" srcset="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png 666w, https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12-300x206.png 300w" sizes="(max-width: 500px) 100vw, 500px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png 666w, https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12-300x206.png 300w"></a></p>
<h3>Biden is not Officially the President-Elect</h3>
<p>The president elect is determined by the electoral college or the General Services Administration (aka Trump conceding). That did not occur.</p>
<p>This is not uncommon, from <a href="https://en.wikipedia.org/wiki/President-elect_of_the_United_States" target="_blank" rel="noopener noreferrer">wikipedia</a>:</p>
<blockquote><p>The closest instance of there being no qualified person to take the presidential oath of office on Inauguration Day happened in 1877 when the disputed election between Rutherford B. Hayes and Samuel J. Tilden was decided and certified in Hayes‚Äô favor just three days before the inauguration (then March 4).</p></blockquote>
<h3>Evidence, Pending Review</h3>
<p>It takes time to build evidence. Last night on <a href="https://www.youtube.com/watch?v=7WzYTSwt18k" target="_blank" rel="noopener noreferrer">Fox News (Hannity, 11/10/2020)</a> the Republicans discussed some of the election (video may be removed, not on Fox News website).</p>
<p>The Republicans claim 11,000+ incident reports of vote manipulation, currently being vetted by attorneys. 250+ affidavits already signed, many have corroborating physical evidence, photos or additional witnesses (unclear how much). In a section below, some specific claims are covered.</p>
<h3>The Voting Recount Process</h3>
<ol>
<li>Affidavit is necessary to challenge some ballots</li>
<li>After canvassing, Republicans can request a recount</li>
<li>A judges in each county can review evidence (aka affidavits, photos, etc)</li>
<li>The judge can remove ballots (at random) based on evidence</li>
<li>Judgements can be challenged to a higher court</li>
<li>Recount occurs after ballots removed</li>
<li>IF it‚Äôs so wide spread or there‚Äôs a major error. The house or senate decide (or special elections), it depends on the State.</li>
<li>Electors vote on to December 14 and delivered December 23rd [<a href="https://crsreports.congress.gov/product/pdf/IF/IF11641">1</a>]</li>
</ol>
<h4>State Government Affiliation(s)</h4>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Pennsylvania_General_Assembly" target="_blank" rel="noopener noreferrer">PA</a>, <a href="https://en.wikipedia.org/wiki/Michigan_Legislature" target="_blank" rel="noopener noreferrer">MI</a>, <a href="https://en.wikipedia.org/wiki/Wisconsin_Legislature" target="_blank" rel="noopener noreferrer">WI</a> and <a href="https://en.wikipedia.org/wiki/Georgia_General_Assembly" target="_blank" rel="noopener noreferrer">GA</a> have a fairly large republican majority of both houses</li>
<li><a href="https://en.wikipedia.org/wiki/Arizona_State_Legislature" target="_blank" rel="noopener noreferrer">AZ</a> has a slight republican majority of both houses</li>
<li><a href="https://en.wikipedia.org/wiki/Nevada_Legislature" target="_blank" rel="noopener noreferrer">NV</a> has a large Democrat majority in both houses</li>
</ul>
<p>It‚Äôs also still possible the United States Supreme Court could still toss hundreds of thousands of ballots out of PA (Biden‚Äôs up by 40k)[<a href="https://www.washingtonexaminer.com/news/republican-state-attorneys-general-ask-supreme-court-to-take-up-pennsylvania-late-mail-in-ballot-case" target="_blank" rel="noopener noreferrer">2</a>].</p>
<h3>Affidavit Claims</h3>
<p>Selected claims on Fox / Hannity (on 11/10/2020):</p>
<p>1. There was a ‚Äúsoftware bug‚Äù in one jurisdiction, the exact same software was used in half of Michigan and multiple states. Only the one county noted the fix. They want to re-evaluate and manually recount in said counties. Code reviews requested.</p>
<p>2. Pennsylvania USPS (more than one) said the postal service was backdating ballots AND collecting ballots after the date (prior to back dating, i.e. they knew)</p>
<p>3. Michigan had a lot of dead people vote &gt;50 for one county, thus far that they‚Äôve found.</p>
<p>4. All the states have laws enabling the voting process to be accessible to the public, due to COVID-19 they limited public observers, particularly from independents. Legal challenges can occur, as that is against many states laws.</p>
<p>5. Democrat poll watchers were handing out pamphlets on ‚Äúhow to distract GOP poll watchers‚Äù</p>
<p>6. Poll watchers claim to have seen ballots with the same or no signatures be counted in Michigan</p>
<h3>Personal Opinion</h3>
<p>Personally, I believe this is the correct course of action. I‚Äôm not sure I believe all the claims.</p>
<p>However, I think it‚Äôs very important we challenge the votes, see where it falls and improve the Republic. Even if we do it after the election, it‚Äôs important we identify fraud and / or improve the process so this doesn‚Äôt happen again.</p>
<p>Unfortunately, the news media is not presenting this very well. I am concerned this will lead to a civil war. The Democratic party knows they are not officially the president elect, yet hold press conferences, that look like this‚Ä¶</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/11/president-elect.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png" alt="" width="792" height="530" srcset="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png 1024w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-300x201.png 300w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-768x514.png 768w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect.png 1514w" sizes="(max-width: 792px) 100vw, 792px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png 1024w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-300x201.png 300w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-768x514.png 768w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect.png 1514w"></a>I‚Äôm not convinced this wont lead to violence. I‚Äôm concerned because it looks like <em>if the Democrats lose the election.</em> There will be a rival government setup. Several <a href="https://www.cnn.com/2020/11/07/americas/biden-global-reaction-election-intl/index.html" target="_blank" rel="noopener noreferrer">foreign powers have already acknowledged Biden as the victor</a>, for instance.</p>
<p>Personally, I just want a safe environment for my friends and family. I think most of us do.</p>

</div>

</article></div>]]>
            </description>
            <link>https://austingwalters.com/public-safety-announcement-the-2020-election-is-not-over-as-of-nov-11-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059009</guid>
            <pubDate>Wed, 11 Nov 2020 15:14:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to setup EKS on AWS with Terraform]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058923">thread link</a>) | @shuron
<br/>
November 11, 2020 | http://alexander.holbreich.org/eks-on-aws-with-terraform/ | <a href="https://web.archive.org/web/*/http://alexander.holbreich.org/eks-on-aws-with-terraform/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

        

        <section>
            <p>After setup of several kubernetes clusters i would like to share how we do it. I hope this helps people to get start with <a href="http://alexander.holbreich.org/tag/k8n/">kubernetes</a>. But also im keen to read your feedback and improvement proposals.</p>

<h3 id="whyterraform">Why Terraform</h3>

<p>From time to to time i do explore <a href="http://alexander.holbreich.org/tag/terrafrom/">terraform</a>, in log term since it appearence (See my exploration on <a href="http://alexander.holbreich.org/aws-automation/">AWS automation</a>). Basically i think this tool (as many other from Hashicorp) just had right idea to the right time. Let me explain: The nature of the IT infrastructure is more or less static. No surprize, that declarative approach is very situative here. And here terraform creators seem to have clear vision on this when they evolve terraform language design and elaborated tooling around it. Terraformes has become favorit tool for cloud resources provisioning in many teams.</p>

<p>Meanwhile the concept of "state" finally evolved and found place in new hashicorp <em>terraform cloud</em> (with free tier for small or mid-size projects). It's very convinient and impoves teamworking. Btw. i'm not affilatet with Hashicorp.</p>

<h2 id="bootstraping">Bootstraping</h2>

<p>Ok, how do i start with it. Well I usually start with AWS Sub Account for the project. It makes sence anyway especially if there is no connection to other projects or parts of your systems. See <a href="https://docs.aws.amazon.com/organizations/latest/userguide/orgs_introduction.html">AWS Organization</a>. New Organization has at least one user whith enough rights. However for terraform i do addtional user 'terraform user' that has sufficient rights to create my enviroments. Basically i give him <code>AdministratorAccess</code></p>

<p>From this point on we can bootstrap terraform.  </p>

<h3 id="terrafomconfig">Terrafom config</h3>

<pre><code># See docu https://learn.hashicorp.com/tutorials/terraform/cloud-workspace-configure
provider "aws" {  
  region = "us-west-1" 
}

#https://www.terraform.io/docs/backends/types/remote.html
terraform {  
  backend "remote" {
    hostname = "app.terraform.io"
    organization = "YourOrga"

    workspaces {
      name = "your-aws-infa-workspace"
    }
  }
}
</code></pre>

<p>This is basically everything for bootstraping. </p>

<p>This setup assumes you have <code>aws-cli</code> installed and configured<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> on your development Maschine, meaning  your local terraform executions are able to conntect to AWS API. <br>
Secondly it assumes that terraform state will be hostet and terrafor cloud: <code>backend "remote"</code> </p>

<p>Provided configuration changes your local terrafom workspace to be the remote one.  </p>

<p>To be more specific. The terraform cloud can be operated in two ways:</p>

<ol>
<li>Hosting only your terrafrom state</li>
<li>Hosting state but also be single point of the change and the hostory of that change (full remote operations)</li>
</ol>

<p>Here i'm talking about the second scenario, where <code>terraform apply</code> is only possibly from the cloud UI only. Please also keep in mind that, when using terraform cloud, the <code>terraform plan</code> and other commands will use variable values from the associated Terraform Cloud workspace. So it's TF-Cloud where you should configure access to you AWS account with the secret key of your terraform IAM user or role. </p>

<p>To summ this up: You need an account at: <strong><a href="https://app.terraform.io/">https://app.terraform.io</a></strong> <br>
And you're can enable team-members not only participate in commiting terraform code, but also for provisioning the infrastruture, without sharing and maintaning admin credentials to the AWS cloud.</p>

<p>Last step is to setup a Workspace and connect your git repository with it. Now you can provision the Infrastructure. <br>
At the end your terraform rund of <code>terraform plan</code> and <code>terraform apply</code> will look something like this: <br>
<img src="http://alexander.holbreich.org/content/images/2020/09/terraform_cloud.png" alt="">
and <br>
<img src="http://alexander.holbreich.org/content/images/2020/09/terraform_cloud2.png" alt=""></p>

<h3 id="provisioningnetwork">Provisioning Network</h3>

<pre><code># VPC for kubernetes and all other cluster related resources

resource "aws_vpc" "main" {  
  cidr_block           = "10.100.0.0/16"
  enable_dns_support   = true
  enable_dns_hostnames = true

  tags = {
    Name      = "main"
    managedby = "terraform"
  }
}
</code></pre>

<p>The subnets. The number of your Subnets should correspond to the number of AZ in the Region.</p>

<pre><code>## ==== Kubernetes subnets =====

#us-west-2a
resource "aws_subnet" "eks_a" {  
  vpc_id            = aws_vpc.main.id
  cidr_block        = "10.100.1.0/24"
  availability_zone = "us-west-2a"
  map_public_ip_on_launch = true

  tags = {
    managedby                                          = "terraform"
    Name                                               = "EKS, AZ a"
    "kubernetes.io/cluster/${local.cluster_name}"      = "shared"
    "kubernetes.io/role/elb"                           = "1"
    "kubernetes.io/role/internal-elb"                  = "1"
  }
}

#us-west-2b
resource "aws_subnet" "eks_b" {  
  vpc_id            = aws_vpc.main.id
  cidr_block        = "10.100.2.0/24"
  availability_zone = "us-west-2b"
  map_public_ip_on_launch = true

  tags = {
    managedby                                          = "terraform"
    Name                                               = "EKS, AZ b"
    "kubernetes.io/cluster/${local.cluster_name}" = "shared"
    "kubernetes.io/role/elb"                           = "1"
    "kubernetes.io/role/internal-elb"                  = "1"
  }
}

#us-west-2c
resource "aws_subnet" "eks_c" {  
  vpc_id            = aws_vpc.main.id
  cidr_block        = "10.100.3.0/24"
  availability_zone = "us-west-2c"
  map_public_ip_on_launch = true

  tags = {
    managedby                                          = "terraform"
    Name                                               = "EKS, AZ c"
    "kubernetes.io/cluster/${local.cluster_name}" = "shared"
    "kubernetes.io/role/elb"                           = "1"
    "kubernetes.io/role/internal-elb"                  = "1"
  }

}
</code></pre>

<p>This is pretty forward, for details consult Terraform Docu on <a href="https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/subnet">Resource: aws_subnet</a>, for the kubernetes cluster the provided tags are of interest. <br>
The tags are used by AWS EKS to understand where to put <a href="https://docs.aws.amazon.com/eks/latest/userguide/load-balancing.html">automatically requested LoadBalancers</a>. <br>
ESK requires <a href="https://docs.aws.amazon.com/eks/latest/userguide/network_reqs.html#vpc-subnet-tagging">special subnet tagging</a> <br>
<code>kubernetes.io/role/elb</code> with cluster name. The rest of it is up to you and not much pitfalls here except: <code>map_public_ip_on_launch = true</code>. This is needed because in this scenario i use <em>public sub-nets</em>. EKS Master nodes are managed by AWS and are deployed outside of my VPC while workers inside my VPC need to accessed their masters. So they need to have public IP addresses. The Fine grane access to the worker nodes is defined by Security Groups later. If it not suitable for you there is more defensive option to use private Workers with <em>private sub-nets</em> (not covered here).</p>

<p>Well and while we establihing the communication with Public Addresses, in the AWS universum we need the <em>Internet Gateway</em>.  </p>

<pre><code>resource "aws_internet_gateway" "igw1" {  
  vpc_id = aws_vpc.main.id

  tags = {
    Name = "main-igw1"
    managedby         = "terraform"
  }
}

resource "aws_route" "route_to_igw1" {  
  route_table_id            = "rtb-someId" #haven't found better way than hardcoding so far.
  destination_cidr_block    = "0.0.0.0/0"
  gateway_id                =  aws_internet_gateway.igw1.id

}
</code></pre>

<p><br>
With that basic networking is in place and it's time for kubernetes.</p>

<h2 id="theekscluster">The EKS Cluster</h2>

<p>We have good experinces with the <a href="https://registry.terraform.io/modules/terraform-aws-modules/eks/aws/">official Terraform EKS module</a>. <br>
Later versions of it utilize special <em>terraform kubernetes provider</em> for the provisioning of cluster Users and roles. So my examples show it. </p>

<pre><code>## 1 Cluster Module starts here.

module "eks_cluster" {  
  source                 = "terraform-aws-modules/eks/aws"
  version                = "12.2.0"
  cluster_name           = "${local.cluster_name}"
  cluster_version        = "1.17"
  subnets                = ["${aws_subnet.eks_a.id}", "${aws_subnet.eks_b.id}", "${aws_subnet.eks_c.id}"]
  vpc_id                 = "${aws_vpc.main.id}"
  cluster_create_timeout = "30m" # need to increase module defaults
  write_kubeconfig       = false # Disabled permanent writing of config files
  providers = {
    # Reference to kuberntes provider, see below
    kubernetes = kubernetes.eks_cluster
  }

  manage_aws_auth = true //TODO enable it https://github.com/terraform-aws-modules/terraform-aws-eks/issues/699

  node_groups_defaults = {
    ami_type  = "AL2_x86_64" #alternative is e.g. AL2_x86_64_GPU
    disk_size = 50
  }


  node_groups = {
    # EKS managed Nodes group with name prefix "ram"
    ram = {
      desired_capacity = 3
      max_capacity     = 10
      min_capacity     = 1

      public_ip = true

      instance_type = "r5.large"
      #Labels for nodes and tags
      k8s_labels = {
        node_type = "default"
      }
      # Resource tags are not labels
      additional_tags = {
        managedby   = "terraform"
      }
    }
  }

  #Users
  # Can be checked with: kubectl describe configmap -n kube-system aws-auth
  map_users = [
    {
      userarn  = "${aws_iam_user.my_addtionaluser.arn}"
      username = "${aws_iam_user.my_addtionaluser.name}"
      groups   = ["system:masters"]
    }
  ]

  tags = {
    managedby   = "terraform"
  }
}

## Configuration of kubernetes provides starts here
data "aws_eks_cluster" "eks-cluster" {  
  name = module.eks_cluster.cluster_id
}

data "aws_eks_cluster_auth" "eks-cluster" {  
  name = module.eks_cluster.cluster_id
}

provider "kubernetes" {  
  host                   = data.aws_eks_cluster.eks-cluster.endpoint
  cluster_ca_certificate = base64decode(data.aws_eks_cluster.eks-cluster.certificate_authority.0.data)
  token                  = data.aws_eks_cluster_auth.eks-cluster.token
  load_config_file       = false
  alias   = "eks_cluster"
  version = "~&gt; 1.10"
}
</code></pre>

<p>I think this the configuration is more or less self-explanatory. <br>
It starts with EKS module, that takes a list of agruments like version, list of users and List of node groups with Details to machines inside of such group. <br>
Also reference to kubernetes provider is present. <br>
The configuration is the kubernetes provider has to be placed here but is basically reference to the cluster. See EKS Modul documentation for Details.</p>

<h2 id="alternatives">Alternatives</h2>

<p>Of course there are alternatives and you can exchange any of the tools here. Meanwile the EKS has evolved (and got a bit simlier) and also terraform *nativ" Resource <a href="https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/eks_cluster">eks_cluster</a> hase evolved. I'm interested in your experienced with it... ‚Ä¶</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://alexander.holbreich.org/eks-on-aws-with-terraform/">http://alexander.holbreich.org/eks-on-aws-with-terraform/</a></em></p>]]>
            </description>
            <link>http://alexander.holbreich.org/eks-on-aws-with-terraform/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058923</guid>
            <pubDate>Wed, 11 Nov 2020 15:03:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You may not need Redis with Elixir]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058805">thread link</a>) | @wojtekmach
<br/>
November 11, 2020 | https://dashbit.co/blog/you-may-not-need-redis-with-elixir | <a href="https://web.archive.org/web/*/https://dashbit.co/blog/you-may-not-need-redis-with-elixir">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    
<ul>
  <li>
    <i></i> Jos√© Valim
  </li>
  <li>
    <i></i> November 11th, 2020
  </li>
  <li>
    <i></i><a href="https://dashbit.co/blog/tags/redis">redis</a>, <a href="https://dashbit.co/blog/tags/phoenix">phoenix</a>, <a href="https://dashbit.co/blog/tags/pubsub">pubsub</a>, <a href="https://dashbit.co/blog/tags/processes">processes</a>
  </li>
</ul>
<p>
If you have participated in a discussion about Elixir, you may have heard ‚Äúyou may not need Redis with Elixir‚Äù. Given that Redis has many use cases, this sentence may confuse developers as they try to match Elixir‚Äôs different features against Redis‚Äô capabilities. This article aims to explore different scenarios where the above is true, when they are not, and which trade-offs you may want to consider. We will discuss four cases:</p>
<ol>
  <li>
<a href="#post-pubsub">Distributed PubSub</a>  </li>
  <li>
<a href="#post-presence">Presence</a>  </li>
  <li>
<a href="#post-caching">Caching</a>  </li>
  <li>
<a href="#post-async">Asynchronous processing</a>  </li>
</ol>
<p>
Before we start, I want to emphasize we find Redis a fantastic piece of technology. This is not a critique of Redis but rather a discussion of the different options Elixir developers may have available.</p>
<h2 id="post-pubsub">
  Case #1: Distributed PubSub</h2>
<p>
The first scenario where you may not need Redis with Elixir is Distributed <a href="https://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern">PubSub</a>. Throughout this section, we will consider PubSub systems to provide <strong>at-most-once delivery</strong>: they broadcast events to the currently available subscribers. If a subscriber is not around, they won‚Äôt receive the message later.</p>
<p>
For this reason, PubSub systems are often paired with databases to offer persistence. For example, every time someone sends a message in a chat application, the system can save the contents to the database and then broadcast it to all users. This means everyone connected at a given moment sees the update immediately, but disconnected users can catch up later.</p>
<p>
Imagine that you have multiple nodes, and you want to exchange messages between said nodes. In Elixir, thanks to the Erlang VM, which ships with distribution support, this can be as simple as:</p>
<pre><code><span>for</span><span> </span><span>node</span><span> </span><span>&lt;-</span><span> </span><span>Node</span><span>.</span><span>list</span><span data-group-id="8737372369-1">(</span><span data-group-id="8737372369-1">)</span><span> </span><span data-group-id="8737372369-2">do</span><span>
  </span><span>send</span><span data-group-id="8737372369-3">(</span><span data-group-id="8737372369-4">{</span><span>:known_name</span><span>,</span><span> </span><span>node</span><span data-group-id="8737372369-4">}</span><span>,</span><span> </span><span>:hello_world</span><span data-group-id="8737372369-3">)</span><span>
</span><span data-group-id="8737372369-2">end</span></code></pre>
<p>
In <a href="https://github.com/phoenixframework/phoenix_pubsub/blob/master/lib/phoenix/pubsub.ex">200LOC or less</a>, you can implement a PubSub system that broadcasts to all subscribers within the same node or anywhere else in a cluster, without bringing any third-party tools. At best, you will need <a href="https://github.com/bitwalker/libcluster">libcluster</a> - an Elixir library - to establish the connection between the nodes based on some strategy (K8s, AWS, DNS, etc.).</p>
<p>
In other words, PubSub pretty much ships out of the box with Elixir. Technologies without distribution would need to rely on Redis PubSub, PostgreSQL Notifications, or similar to achieve the same.</p>
<p>
Of course, the above assumes your infrastructure allows you to directly establish connections between nodes, which may not be possible in some PaaS, such as Heroku. In those cases, you can use any of the technologies above (Phoenix <a href="https://dashbit.co/blog/github.com/phoenixframework/phoenix_pubsub_redis/">has a Redis adapter</a> for its PubSub), or alternatively use platforms, such as <a href="https://www.gigalixir.com/">Gigalixir</a>, that make it trivial to setup a cluster.</p>
<h2 id="post-presence">
  Case #2: Presence</h2>
<p>
Presence is the ability to track who is connected in a cluster right now ‚Äî the ‚Äúwho‚Äù may be users, phones, IoT devices, etc. For example, if Alice is connected to node A, she wants to see that Bob is also available, even if he has joined node B.</p>
<p>
Presence is one of the problems that are more complicated to implement than it sounds. For example, let‚Äôs consider implementing Presence by storing the connected entities in a database. However, what happens if a node crashes or leaves the cluster? Because the node crashed, all the users connected to it must be removed, but the node itself cannot do so. Therefore the other nodes need to detect those failure scenarios and act accordingly. But observing failures in a distributed system is also complicated: how do you differentiate between a temporarily unresponsive node from one that permanently failed?</p>
<p>
Another common approach to solve this problem is to frequently write to a database while users are connected. If you have seen no writes within a timeframe, you consider those users to be disconnected. However, such solutions have to choose between being write-intensive or inaccurate. For instance, let‚Äôs say that users become disconnected after 1 minute. This means that you need to write to the database every 1 minute for every user. If you have 10k users, that‚Äôs 167 writes per second, only to track that the users are connected. Meanwhile, the gap between a user leaving and having their status reflected in the UI is, in the worst-case scenario, also 1 minute. Any attempt at reducing the number of writes implies an increased gap.</p>
<p>
Given Elixir‚Äôs clustering support, we can once more implement <a href="https://hexdocs.pm/phoenix/Phoenix.Presence.html">Presence</a> without a need for third-party dependencies! We use a PubSub system to implement Presence, as we need to notify as users join and leave. Instead of relying on centralized storage, the nodes directly communicate and exchange information about who is around. This removes the need for frequent writes. When a user leaves, this is also reflected immediately.</p>
<p>
So while you can use Redis or another storage to provide Presence, Elixir can deliver a solution that is efficient and doesn‚Äôt require third-party tools.</p>
<h2 id="post-caching">
  Case #3: Caching</h2>
<p>
The solutions to previous cases were built on top of Erlang‚Äôs unique distribution capabilities. In the following sections, the distinguishing factor between needing Redis or not will be <strong>multi-core concurrency</strong>, so this discussion is more generally applicable. Therefore, when we say Elixir in this section, it will also apply to JVM, Go, and other environments. They will contrast to Ruby, Python, and Node.js, in which their primary runtimes do not provide adequate multi-core concurrency within a single Operating System process.</p>
<p>
Let‚Äôs start with the non-concurrent scenario. Consider you are building a web application in Ruby, Python, etc. To deploy it, you get two eight-core machines. In languages that do not provide satisfactory multi-core concurrency, a common option for deployment is to start 8 instances of your web application, one per core, on each node. Overall, you will have CxN instances, where C is the number of cores, and N is the number of nodes.</p>
<p>
Now consider a particular operation in this application that is expensive, and you want to cache its results. The easiest solution, regardless of your programming environment, is to cache it in memory. However, given we have 16 instances of this application, caching it in memory is suboptimal: we will have to perform this expensive operation at least 16 times, one for each instance. For this reason, it is widespread to use Redis, Memcached, or similar for caching in environments like Ruby, Python, etc. With Redis, you would cache it only once, and it will be shared across all instances. The trade-off is that we are replacing memory access by a network round-trip, and the latter is orders of magnitude more expensive.</p>
<p>
Now let‚Äôs consider environments with multi-core concurrency. In languages like Elixir, you start one instance per node, regardless of the number of cores, since the runtime will share memory and efficiently spread the work across all cores. When it comes to caching, keeping the cache in-memory is a much more affordable scenario, as you will only have to compute once per node. Therefore, you have the <em>option</em> to skip Redis or Memcached altogether and avoid network round-trip.</p>
<p>
Of course, this depends on how many nodes you are effectively running in production. Luckily, many companies report being able to <a href="https://dev.to/erlangsolutions/why-elixir-is-the-programming-language-you-should-learn-in-2020-5g00">run Elixir with an order of magnitude less nodes</a> than technologies they have migrated from.</p>
<p>
You can also choose a mixed approach and store the cache both in-memory and in Redis. First, you look up in memory and, if missing, you fallback to Redis. If unavailable in both, then you execute the operation and cache it in each. The critical part to highlight here is that multi-core environments give you more flexibility to tackle these problems while reducing resource utilization. In Elixir/Erlang, you can also keep the cache in memory and use PubSub to distribute it across nodes. You can see this last approach in action <a href="https://github.com/tompave/fun_with_flags">in the excellent FunWithFlags library</a>.</p>
<p>
Another trade-off to consider is that all in-memory cache will be gone once you deploy new nodes. Therefore, if you need data to persist across deployments, you will want to use Redis as a cache layer, as detailed above, or dump the cache in a storage, such as database, S3, or Redis, before each deployment.</p>
<h2 id="post-async">
  Case #4: Asynchronous processing</h2>
<p>
Another scenario you may not need Redis in Elixir is to perform asynchronous processing. Let‚Äôs continue the discussion from the previous case.</p>
<p>
In environments without or with limited multi-core concurrency, given each instance is assigned to one core, they are limited in their ability to handle requests concurrently. This has led to a common saying that ‚Äúyou should avoid blocking the main thread‚Äù. For example, imagine that your application has to deliver emails on sign up or generate some computationally expensive reports. While one of your 16 web instances is doing this, it cannot handle other incoming requests efficiently. For this reason, a common choice here is to move the work elsewhere, typically a background-job processing queue. First, you store the work to be done on Redis or similar. Then one of the 16 web instances (or more commonly a completely different set of workers) grabs it from the queue.</p>
<p>
In multi-core concurrent environments, requests can be handled concurrently regardless if they are doing CPU or IO work. Sending the email from the request itself won‚Äôt block other requests. Generating the report is not a problem, as requests can be served by other CPUs. These platforms typically get assigned as many requests as they can handle and they distribute the work over the machine resources. Even if you prefer to deliver emails outside of the request, in order to send an earlier response to users, you can spawn an asynchronous worker without a need to move the delivery to an external queue or to another machine. Once again, concurrency gives us a more straightforward option to tackle these scenarios.</p>
<p>
Note the Erlang VM takes care of multiplexing CPU and IO work without a need for developers to tag functions as async or similar. Workers in Erlang/Elixir are ‚Ä¶</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dashbit.co/blog/you-may-not-need-redis-with-elixir">https://dashbit.co/blog/you-may-not-need-redis-with-elixir</a></em></p>]]>
            </description>
            <link>https://dashbit.co/blog/you-may-not-need-redis-with-elixir</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058805</guid>
            <pubDate>Wed, 11 Nov 2020 14:48:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Systematically removing code]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 44 (<a href="https://news.ycombinator.com/item?id=25058632">thread link</a>) | @jerodsanto
<br/>
November 11, 2020 | https://thepugautomatic.com/2020/11/systematically-removing-code/ | <a href="https://web.archive.org/web/*/https://thepugautomatic.com/2020/11/systematically-removing-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><hgroup><p><span>Written November 8, 2020. <span>Tagged <a href="https://thepugautomatic.com/tag/methodology">Methodology</a>.</span></span></p></hgroup><div><p>It's easy to miss things when removing code, leaving behind unused methods, templates, CSS classes or translation keys. (Especially in a dynamic language like Ruby, without a compiler to help you spot dead code.)</p><p>I avoid this by removing code systematically, line by line, depth-first.</p><p>This is one of those things that seems obvious when you do it, but in my experience, many people do it haphazardly.</p><p>Say we wanted to remove the "item box" from this page:</p><p>page.html.erb</p><pre><code><span><span><span>&lt;</span>p</span><span>&gt;</span></span>Welcome to my page!<span><span><span>&lt;/</span>p</span><span>&gt;</span></span><p><span><span>&lt;%=</span> render<span>(</span><span>"item_box"</span><span>,</span> item<span>:</span> item<span>)</span> <span>%&gt;</span></span></p></code></pre><p>_item_box.html.erb</p><pre><code><span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>box box--fancy<span>"</span></span><span>&gt;</span></span><br>  <span><span><span>&lt;</span>h2</span><span>&gt;</span></span><span><span>&lt;%=</span> item<span>.</span>title <span>%&gt;</span></span><span><span><span>&lt;/</span>h2</span><span>&gt;</span></span><br>  <span><span>&lt;%=</span> format_description<span>(</span>item<span>.</span>description<span>)</span> <span>%&gt;</span></span><br>  <span><span><span>&lt;</span>p</span><span>&gt;</span></span><span><span>&lt;%=</span> <span>I18n</span><span>.</span>translate<span>(</span><span>"my.translation.key"</span><span>)</span> <span>%&gt;</span></span><br><span><span><span>&lt;/</span>div</span><span>&gt;</span></span></code></pre><p>So our end goal is to remove the <code>&lt;%= render("item_box", item: item) %&gt;</code> line.</p><p>First, we search the project to check that <code>_item_box.html.erb</code> isn't used somewhere else, or referenced in docs that we'll need to update. It isn't, so we're OK to remove it ‚Äì but before we do that, we must go through it line by line.</p><p>The first line is <code>&lt;div class="box box--fancy"&gt;</code>. So we search the project for these two CSS classes, checking if they're in use somewhere else. If not, we remove them from the CSS files.</p><p>We go deeper if required ‚Äì perhaps the CSS for <code>.box--fancy</code> uses a CSS variable. Then we check if that variable is in use elsewhere. <a href="https://thepugautomatic.com/2014/03/stacked-vim-searches-down-cold/">Stacked searches in Vim</a> are helpful here.</p><p>Once we've checked a line in the file, we delete that line. This helps us keep track of what we've already checked.</p><p>So after we've checked and removed that line, we're left with</p><p>_item_box.html.erb</p><pre><code>  <span><span><span>&lt;</span>h2</span><span>&gt;</span></span><span><span>&lt;%=</span> item<span>.</span>title <span>%&gt;</span></span><span><span><span>&lt;/</span>h2</span><span>&gt;</span></span><br>  <span><span>&lt;%=</span> format_description<span>(</span>item<span>.</span>description<span>)</span> <span>%&gt;</span></span><br>  <span><span><span>&lt;</span>p</span><span>&gt;</span></span><span><span>&lt;%=</span> <span>I18n</span><span>.</span>translate<span>(</span><span>"my.translation.key"</span><span>)</span> <span>%&gt;</span></span><br><span><span><span>&lt;/</span>div</span><span>&gt;</span></span></code></pre><p>And we continue this way, line by line. Is the <code>item.title</code> used elsewhere? If not, we should probably remove it, too. What about <code>format_description</code>, <code>item.description</code>, the <code>my.translation.key</code> translation key?</p><p>Again, we go deeper if required, not removing the <code>format_description</code> method until we've gone through <em>it</em> line by line.</p><p>When we've looked at every line in <code>_item_box.html.erb</code> and deleted them as we went, the file will be empty, and we can start popping the stack.</p><p>We remove the empty <code>_item_box.html.erb</code> file.</p><p>And we can finally remove the <code>&lt;%= render("item_box", item: item) %&gt;</code> line, fairly confident that we didn't leave dead code behind.</p><p>This probably sounds more tedious than it is. It tends to be quick work, and you can take shortcuts ‚Äì removing a swathe of lines that don't reference anything else, or that only call methods that you know are used elsewhere.</p></div></section></div><div><p>Content and design ¬© <a href="https://henrik.nyh.se/">Henrik Nyh</a> (<a href="https://twitter.com/henrik">@henrik</a>). Code is under a <a href="http://en.wikipedia.org/wiki/MIT_License">MIT License</a> unless otherwise stated.</p><p>Pug art by <a href="https://johannaost.com/">Johanna √ñst</a>; other graphics are under a <a href="http://creativecommons.org/licenses/by/3.0/">CC BY License</a>.</p><p>Powered by <a href="https://11ty.dev/">Eleventy</a>.</p></div></div>]]>
            </description>
            <link>https://thepugautomatic.com/2020/11/systematically-removing-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058632</guid>
            <pubDate>Wed, 11 Nov 2020 14:26:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Linear Algebra for Applied Machine Learning with Python]]>
            </title>
            <description>
<![CDATA[
Score 380 | Comments 48 (<a href="https://news.ycombinator.com/item?id=25058619">thread link</a>) | @Anon84
<br/>
November 11, 2020 | https://pabloinsente.github.io/intro-linear-algebra | <a href="https://web.archive.org/web/*/https://pabloinsente.github.io/intro-linear-algebra">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <section id="main_content">
        
<!-- https://docs.mathjax.org/en/latest/configuration.html#local-config-files -->




<article>
  <h2>Introduction to Linear Algebra for Applied Machine Learning with Python</h2>
  <time datetime="2020-05-26T00:00:00+00:00">26 May 2020</time>
  

  

<p>Linear algebra is to machine learning as flour to bakery: <strong>every machine learning model is based in linear algebra, as every cake is based in flour</strong>. It is not the only ingredient, of course. Machine learning models need vector calculus, probability, and optimization, as cakes need sugar, eggs, and butter. Applied machine learning, like bakery, is essentially about combining these mathematical ingredients in clever ways to create useful (tasty?) models.</p>

<p>This document contains <strong>introductory level linear algebra notes for applied machine learning</strong>. It is meant as a reference rather than a comprehensive review. If you ever get confused by matrix multiplication, don‚Äôt remember what was the $L_2$ norm, or the conditions for linear independence, this can serve as a quick reference. It also a good introduction for people that don‚Äôt need a deep understanding of linear algebra, but still want to learn about the fundamentals to read about machine learning or to use pre-packaged machine learning solutions. Further, it is a good source for people that learned linear algebra a while ago and need a refresher.</p>

<p>These notes are based in a series of (mostly) freely available textbooks, video lectures, and classes I‚Äôve read, watched and taken in the past. If you want to obtain a deeper understanding or to find exercises for each topic, you may want to consult those sources directly.</p>

<p><strong>Free resources</strong>:</p>

<ul>
  <li><strong>Mathematics for Machine Learning</strong> by Deisenroth, Faisal, and Ong. 1st Ed. <a href="https://mml-book.github.io/">Book link</a>.</li>
  <li><strong>Introduction to Applied Linear Algebra</strong> by Boyd and Vandenberghe. 1sr Ed. <a href="http://vmls-book.stanford.edu/">Book link</a></li>
  <li><strong>Linear Algebra Ch. in Deep Learning</strong> by Goodfellow, Bengio, and Courville. 1st Ed. <a href="https://www.deeplearningbook.org/contents/linear_algebra.html">Chapter link</a>.</li>
  <li><strong>Linear Algebra Ch. in Dive into Deep Learning</strong> by Zhang, Lipton, Li, And Smola. <a href="https://d2l.ai/chapter_preliminaries/linear-algebra.html">Chapter link</a>.</li>
  <li><strong>Prof. Pavel Grinfeld‚Äôs Linear Algebra Lectures</strong> at Lemma. <a href="https://www.lem.ma/books/AIApowDnjlDDQrp-uOZVow/landing">Videos link</a>.</li>
  <li><strong>Prof. Gilbert Strang‚Äôs Linear Algebra Lectures</strong> at MIT. <a href="https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/video-lectures/">Videos link</a>.</li>
  <li><strong>Salman Khan‚Äôs Linear Algebra Lectures</strong> at Khan Academy. <a href="https://www.khanacademy.org/math/linear-algebra">Videos link</a>.</li>
  <li><strong>3blue1brown‚Äôs Linear Algebra Series</strong> at YouTube. <a href="https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab">Videos link</a>.</li>
</ul>

<p><strong>Not-free resources</strong>:</p>

<ul>
  <li><strong>Introduction to Linear Algebra</strong> by Gilbert Strang. 5th Ed. <a href="https://www.amazon.com/Introduction-Linear-Algebra-Gilbert-Strang/dp/0980232775">Book link</a>.</li>
  <li><strong>No Bullshit Guide to Linear Algebra</strong> by Ivan Savov. 2nd Ed. <a href="https://www.amazon.com/No-bullshit-guide-linear-algebra/dp/0992001021">Book Link</a>.</li>
</ul>

<p>I‚Äôve consulted all these resources at one point or another. Pavel Grinfeld‚Äôs lectures are my absolute favorites. Salman Khan‚Äôs lectures are really good for absolute beginners (they are long though). The famous 3blue1brown series in linear algebra is delightful to watch and to get a solid high-level view of linear algebra.</p>

<p>If you have to pic one book, I‚Äôd pic <strong>Boyd‚Äôs and Vandenberghe‚Äôs Intro to applied linear algebra</strong>, as it is the most beginner friendly book on linear algebra I‚Äôve encounter. Every aspect of the notation is clearly explained and pretty much all the key content for applied machine learning is covered. The Linear Algebra Chapter in Goodfellow et al is a nice and concise introduction, but it may require some previous exposure to linear algebra concepts. Deisenroth et all book is probably the best and most comprehensive source for linear algebra for machine learning I‚Äôve found, although it assumes that you are good at reading math (and at math more generally). Savov‚Äôs book it‚Äôs also great for beginners but requires time to digest. Professor Strang lectures are great too but I won‚Äôt recommend it for absolute beginners.</p>

<p>I‚Äôll do my best to keep notation consistent. Nevertheless, learning to adjust to changing or inconsistent notation is a useful skill, since most authors will use their own preferred notation, and everyone seems to think that its/his/her own notation is better.</p>

<p>To make everything more dynamic and practical, I‚Äôll introduce bits of Python code to exemplify each mathematical operation (when possible) with <code>NumPy</code>, which is the facto standard package for scientific computing in Python.</p>

<p>Finally, keep in mind this is created by a non-mathematician for (mostly) non-mathematicians. I wrote this as if I were talking to myself or a dear friend, which explains why my writing is sometimes conversational and informal.</p>

<p>If you find any mistake in notes feel free to reach me out at pcaceres@wisc.edu and to https://pablocaceres.org/ so I can correct the issue.</p>



<p><strong>Note:</strong> <em>underlined sections</em> are the newest sections and/or corrected ones.</p>

<p><strong><a href="#preliminary-concepts">Preliminary concepts</a></strong>:</p>
<ul>
  <li><a href="#sets">Sets</a></li>
  <li><a href="#belonging-and-inclusion">Belonging and inclusion</a></li>
  <li><a href="#set-specification">Set specification</a></li>
  <li><a href="#ordered-pairs">Ordered pairs</a></li>
  <li><a href="#relations">Relations</a></li>
  <li><a href="#functions">Functions</a></li>
</ul>

<p><strong><a href="#vectors">Vectors</a></strong>:</p>
<ul>
  <li><a href="#types-of-vectors">Types of vectors</a>
    <ul>
      <li><a href="#geometric-vectors">Geometric vectors</a></li>
      <li><a href="#polynomials">Polynomials</a></li>
      <li><a href="#elements-of-r">Elements of R</a></li>
    </ul>
  </li>
  <li><a href="#zero-vector-unit-vector-and-sparse-vector">Zero vector, unit vector, and sparse vector</a></li>
  <li><a href="#vector-dimensions-and-coordinate-system">Vector dimensions and coordinate system</a></li>
  <li><a href="#basic-vector-operations">Basic vector operations</a>
    <ul>
      <li><a href="#vector-vector-addition">Vector-vector addition</a></li>
      <li><a href="#vector-scalar-multiplication">Vector-scalar multiplication</a></li>
      <li><a href="#linear-combinations-of-vectors">Linear combinations of vectors</a></li>
      <li><a href="#vector-vector-multiplication-dot-product">Vector-vector multiplication: dot product</a></li>
    </ul>
  </li>
  <li><a href="#vector-space-span-and-subspace">Vector space, span, and subspace</a>
    <ul>
      <li><a href="#vector-space">Vector space</a></li>
      <li><a href="#vector-span">Vector span</a></li>
      <li><a href="#vector-subspaces">Vector subspaces</a></li>
    </ul>
  </li>
  <li><a href="#linear-dependence-and-independence">Linear dependence and independence</a></li>
  <li><a href="#vector-null-space">Vector null space</a></li>
  <li><a href="#vector-norms">Vector norms</a>
    <ul>
      <li><a href="#euclidean-norm">Euclidean norm: $L_2$</a></li>
      <li><a href="#manhattan-norm">Manhattan norm: $L_1$</a></li>
      <li><a href="#max-norm">Max norm: $L_\infty$</a></li>
    </ul>
  </li>
  <li><a href="#vector-inner-product-length-and-distance">Vector inner product, length, and distance</a></li>
  <li><a href="#vector-angles-and-orthogonality">Vector angles and orthogonality</a></li>
  <li><a href="#systems-of-linear-equations">Systems of linear equations</a></li>
</ul>

<p><strong><a href="#matrices">Matrices</a></strong>:</p>

<ul>
  <li><a href="#basic-matrix-operations">Basic matrix operations</a>
    <ul>
      <li><a href="#matrix-matrix-addition">Matrix-matrix addition</a></li>
      <li><a href="#matrix-scalar-multiplication">Matrix-scalar multiplication</a></li>
      <li><a href="#matrix-vector-multiplication-dot-product">Matrix-vector multiplication: dot product</a></li>
      <li><a href="#matrix-matrix-multiplication">Matrix-matrix multiplication</a></li>
      <li><a href="#matrix-identity">Matrix identity</a></li>
      <li><a href="#matrix-inverse">Matrix inverse</a></li>
      <li><a href="#matrix-transpose">Matrix transpose</a></li>
      <li><a href="#hadamard-product">Hadamard product</a></li>
    </ul>
  </li>
  <li><a href="#special-matrices">Special matrices</a>
    <ul>
      <li><a href="#rectangular-matrix">Rectangular matrix</a></li>
      <li><a href="#square-matrix">Square matrix</a></li>
      <li><a href="#diagonal-matrix">Diagonal matrix</a></li>
      <li><a href="#upper-triangular-matrix">Upper triangular matrix</a></li>
      <li><a href="#lower-triangular-matrix">Lower triangular matrix</a></li>
      <li><a href="#symmetric-matrix">Symmetric matrix</a></li>
      <li><a href="#identity-matrix">Identity matrix</a></li>
      <li><a href="#scalar-matrix">Scalar matrix</a></li>
      <li><a href="#null-or-zero-matrix">Null or zero matrix</a></li>
      <li><a href="#echelon-matrix">Echelon matrix</a></li>
      <li><a href="#antidiagonal-matrix">Antidiagonal matrix</a></li>
      <li><a href="#design-matrix">Design matrix</a></li>
    </ul>
  </li>
  <li><a href="#matrices-as-systems-of-linear-equations">Matrices as systems of linear equations</a></li>
  <li><a href="#the-four-fundamental-matrix-subsapces">The four fundamental matrix subsapces</a>
    <ul>
      <li><a href="#the-column-space">The column space</a></li>
      <li><a href="#the-row-space">The row space</a></li>
      <li><a href="#the-null-space">The null space</a></li>
      <li><a href="#the-null-space-of-the-transpose">The null space of the transpose</a></li>
    </ul>
  </li>
  <li><a href="#solving-systems-of-linear-equations-with-matrices">Solving systems of linear equations with matrices</a>
    <ul>
      <li><a href="#gaussian-elimination">Gaussian Elimination</a></li>
      <li><a href="#gauss-jordan-elimination">Gauss-Jordan Elimination</a></li>
    </ul>
  </li>
  <li><a href="#matrix-basis-and-rank">Matrix basis and rank</a></li>
  <li><a href="#matrix-norm">Matrix norm</a></li>
</ul>

<p><strong><a href="#linear-and-affine-mappings">Linear and affine mappings</a></strong>:</p>

<ul>
  <li><a href="#linear-mappings">Linear mappings</a></li>
  <li><a href="#examples-of-linear-mappings">Examples of linear mappings</a>
    <ul>
      <li><a href="#negation-matrix">Negation matrix</a></li>
      <li><a href="#reversal-matrix">Reversal matrix</a></li>
    </ul>
  </li>
  <li><a href="#examples-of-nonlinear-mappings">Examples of nonlinear mappings</a>
    <ul>
      <li><a href="#norms">Norms</a></li>
      <li><a href="#translation">Translation</a></li>
    </ul>
  </li>
  <li><a href="#affine-mappings">Affine mappings</a>
    <ul>
      <li><a href="#affine-combination-of-vectors">Affine combination of vectors</a></li>
      <li><a href="#affine-span">Affine span</a></li>
      <li><a href="#affine-space-and-subspace">Affine space and subspace</a></li>
      <li><a href="#affine-mappings-using-the-augmented-matrix">Affine mappings using the augmented matrix</a></li>
    </ul>
  </li>
  <li><a href="#special-linear-mappings">Special linear mappings</a>
    <ul>
      <li><a href="#scaling">Scaling</a></li>
      <li><a href="#reflection">Reflection</a></li>
      <li><a href="#shear">Shear</a></li>
      <li><a href="#rotation">Rotation</a></li>
    </ul>
  </li>
  <li><a href="#projections">Projections</a>
    <ul>
      <li><a href="#projections-onto-lines">Projections onto lines</a></li>
      <li><a href="#projections-onto-general-subspaces">Projections onto general subspaces</a></li>
      <li><a href="#projections-as-approximate-solutions-to-systems-of-linear-equations">Projections as approximate solutions to systems of linear equations</a></li>
    </ul>
  </li>
</ul>

<p><strong><a href="#matrix-decompositions">Matrix decompositions</a></strong>:</p>
<ul>
  <li><a href="#lu-decomposition">LU decomposition</a>
    <ul>
      <li><a href="#elementary-matrices">Elementary matrices</a></li>
      <li><a href="#the-inverse-of-elementary-matrices">The inverse of elementary matrices</a></li>
      <li><a href="#lu-decomposition-as-gaussian-elimination">LU decomposition as Gaussian Elimination</a></li>
      <li><a href="#lu-decomposition-with-pivoting">LU decomposition with pivoting</a></li>
    </ul>
  </li>
  <li><a href="#qr-decomposition">QR decomposition</a>
    <ul>
      <li><a href="#orthonormal-basis">Orthonormal basis</a></li>
      <li><a href="#orthonormal-basis-transpose">Orthonormal basis transpose</a></li>
      <li><a href="#gram-schmidt-orthogonalization">Gram-Schmidt Orthogonalization </a></li>
      <li><a href="#qr-decomposition-as-gram-schmidt-orthogonalization">QR decomposition as Gram-Schmidt Orthogonalization</a></li>
    </ul>
  </li>
  <li><a href="#determinant">Determinant</a>
    <ul>
      <li><a href="#determinant-as-measures-of-volume">Determinant as measures of volume</a></li>
      <li><a href="#the-2-x-2-determinant">The 2X2 determinant</a></li>
      <li><a href="#the-n-x-n-determinant">The NXN determinant</a></li>
      <li><a href="#determinants-as-scaling-factors">Determinants as scaling factors</a></li>
      <li><a href="#the-importance-of-determinants">The importance of determinants</a></li>
    </ul>
  </li>
  <li><a href="#eigenthings">Eigenthings</a>
    <ul>
      <li><a href="#change-of-basis">Change of basis</a></li>
      <li><a href="#eigenvectors-eigenvalues-and-eigenspaces">Eigenvectors, Eigenvalues, and Eigenspaces</a></li>
      <li><a href="#trace-and-determinant-with-eigenvalues">Trace and determinant with eigenvalues</a></li>
      <li><a href="#eigendecomposition">Eigendecomposition</a></li>
      <li><a href="#eigenbasis-are-a-good-basis">Eigenbasis are a good basis</a></li>
      <li><a href="#geometric-interpretation-of-eigendecomposition">Geometric interpretation of Eigendecomposition</a></li>
      <li><a href="#the-problem-with-eigendecomposition">The problem with Eigendecomposition</a></li>
    </ul>
  </li>
  <li><a href="#singular-value-decomposition">Singular Value Decomposition</a>:
    <ul>
      <li><a href="#singular-value-decomposition-theorem">Singular Value Decomposition Theorem</a></li>
      <li><a href="#singular-value-decomposition-computation">Singular Value Decomposition computation</a></li>
      <li><a href="#geometric-interpretation-of-the-singular-value-decomposition">Geometric interpretation of the Singular Value Decomposition</a></li>
      <li><a href="#singular-value-decomposition-vs-eigendecomposition">Singular Value Decomposition vs Eigendecomposition</a></li>
    </ul>
  </li>
  <li><a href="#matrix-approximation">Matrix Approximation</a>:
    <ul>
      <li><a href="#best-rank-k-approximation-with-svd">Best rank-k approximation with SVD</a></li>
      <li><a href="#best-low-rank-approximation-as-a-minimization-problem">Best low-rank approximation as a minimization problem</a></li>
    </ul>
  </li>
</ul>

<p><strong><a href="#epilogue">Epilogue</a></strong></p>



<p>While writing about linear mappings, I realized the importance of having a basic understanding of a few concepts before approaching the study of linear algebra. If you are like me, you may not have formal mathematical training beyond high school. If so, I encourage you to read this section and spent some time wrapping your head around these concepts before going over the linear algebra content (otherwise, you might prefer to skip this part). I believe that reviewing these concepts is of great help to understand the <em>notation</em>, which in my experience is one of the main barriers to understand mathematics for nonmathematicians: we are <em>non</em>native speakers, so we are continuously building up our vocabulary. I‚Äôll keep this section very short, as is not the focus of this mini-course.</p>

<p>For this section, my notes are based on readings of:</p>

<ul>
  <li><strong>Geometric transformations (Vol. 1)</strong> (1966) by Modenov &amp; Parkhomenko</li>
  <li><strong>Naive Set Theory</strong> (1960) by P.R. Halmos</li>
  <li><strong>Abstract Algebra: Theory and Applications</strong> (2016) by Judson &amp; Beeer. <a href="http://abstract.pugetsound.edu/download/aata-20160809.pdf">Book link</a></li>
</ul>

<h2 id="sets">Sets</h2>

<p>Sets are one of the most fundamental concepts in mathematics. They are so fundamental that they are not defined in terms of anything else. On the contrary, other branches of mathematics are defined in terms of sets, including linear algebra. Put simply, <strong>sets are well-defined collections of objects</strong>. Such objects are called <strong>elements or members</strong> of the set. The crew of a ship, a caravan of camels, and the LA Lakers roster, are all examples of sets. The captain of the ship, the first camel in the caravan, and LeBron James are all examples of ‚Äúmembers‚Äù or ‚Äúelements‚Äù of their corresponding sets. We denote a set with an upper case italic letter as $\textit{A}$. In the context of linear algebra, we say that a line is a set of points, and the set of all lines in the plane is a set of sets. Similarly, we can say that <em>vectors</em> are sets of points, and <em>matrices</em> sets of vectors.</p>

<h2 id="belonging-and-inclusion">Belonging and inclusion</h2>

<p>We build sets using the notion of <strong>belonging</strong>. We denote that $a$ <em>belongs</em> (or is an <em>element</em> or <em>member</em> of) to $\textit{A}$ with the Greek letter epsilon as:</p>



<p>Another important idea is <strong>inclusion</strong>, which allow us to build <em>subsets</em>. Consider sets $\textit{A}$ and $\textit{B}$. When every element of $\textit{A}$ is an element of $\textit{B}$, we say that $\textit{A}$ is a <em>subset</em> of $\textit{B}$, or that $\textit{B}$ <em>includes</em> $\textit{A}$. The notation is:</p>



<p>or</p>



<p>Belonging and inclusion are derived from <strong>axion of extension</strong>: <em>two sets are equal if and only if they have the same elements</em>. This axiom may sound trivially obvious but is necessary to make belonging and ‚Ä¶</p></article></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pabloinsente.github.io/intro-linear-algebra">https://pabloinsente.github.io/intro-linear-algebra</a></em></p>]]>
            </description>
            <link>https://pabloinsente.github.io/intro-linear-algebra</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058619</guid>
            <pubDate>Wed, 11 Nov 2020 14:24:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Retention Revenue Is Important in SaaS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058588">thread link</a>) | @randrews543
<br/>
November 11, 2020 | https://talkinsaasy.com/blog/why-retention-revenue-is-important-in-saas | <a href="https://web.archive.org/web/*/https://talkinsaasy.com/blog/why-retention-revenue-is-important-in-saas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" id="item-5fab3ba5a829a03e790cfc93"><div><div><div data-block-type="2" id="block-83f2beced4fc56fd9669"><div><p>Retention Revenue is the measure of how much revenue is left over after a startup has retained their customer month-to-month. It‚Äôs an important metric for subscription startups to calculate in order to understand their true CAC payback and profitability, so how do we get there?</p><p>First you take topline revenue, or the total amount of all of the subscriptions paid to you in that month. First you will want to calculate your gross revenue which is your total revenue minus your CORS (cost of revenue sold) which is typically hosting costs for software/tech companies, for services or physical goos this is more complicated, but the formula for Gross Revenue is below:</p><ul data-rte-list="default"><li><p><strong>Gross Revenue = Revenue - Cost of Goods Sold</strong></p></li></ul><p>After finding Gross Revenue we can now calculate our Retention Revenue. To get retention revenue you need to find your cost of servicing, marketing and success for your existing customer each month. Similar to how you calculate CAC by adding up sales and marketing costs.</p><p>You will wan to add up the cost of your customer success, customer service teams and customer marketing expenses to get your ‚Äúretention expense‚Äù which is the cost that you had to incur to keep your customers (and their revenue). The formula to then calculate retention revenue is as follows:</p><ul data-rte-list="default"><li><p><strong>Retention Revenue = Gross Revenue - Customer Service Costs- Customer Success Costs - Customer Marketing Costs</strong></p></li></ul><p>Retention Revenue is the take how revenue at the end of the month after you have kept your customers. Using retention revenue is a more accurate way to understand the profitability. While there are other operating expenses that fall outside of the above retention expenses, on a per customer basis that is the best way for a startup, particularly one with recurring revenue, to understand your unit economics.</p><p>Think about a startup with a $2,500 CAC and a customer with a MRR of $300, that is a CAC Payback period of 8.3 months which is pretty good. But if we calculate their retention revenue that same customer only generates $180 in take home revenue at the end of the month making that CAC payback closer to 14 months. Now that might seem like a negative, but what this reveals us is an opportunity. We now have multiple levers to pull to drive towards profitability and sustainable growth. Maybe you do an analysis and realize you could automate the most common customer service requests and drive down your retention costs. Maybe you highlight your idea customer and tailor marketing messaging to drive down CAC. You can always upsell/add new features to increase your average monthly revenue as well.</p><p>A lot of early-stage SaaS companies avoid digging this deep for fear of the initial negative picture it paints. But the reporting economics off of top-line revenue actually can hurt growth long term and limits your visibility into growth levers and operational efficiency. Take the time to drill down to retention level metrics and you uncover a path to growth and sustainability for your startup.</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://talkinsaasy.com/blog/why-retention-revenue-is-important-in-saas</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058588</guid>
            <pubDate>Wed, 11 Nov 2020 14:21:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Off-BRAND ‚Äì A high-fashion brand, a local ice cream shop and IP]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058570">thread link</a>) | @VegetableArmy
<br/>
November 11, 2020 | https://www.legallyinsightful.com/2020/11/off-brand-how-high-fashion-brand-and.html | <a href="https://web.archive.org/web/*/https://www.legallyinsightful.com/2020/11/off-brand-how-high-fashion-brand-and.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<h3>
OFF-BRAND - How a high-fashion brand and a local ice cream shop have come to blows over intellectual property
</h3>
</div><div>
<div id="post-body-4397561652220542783">
<h2><span>How a high-fashion brand and an ice cream shop have come to blows over intellectual property</span></h2><div><p><a href="https://1.bp.blogspot.com/-M9DU9zcfGEM/X6vx7TBn83I/AAAAAAAA5Uc/FcCL5fs2b-wqCxNbl6Evh7ZG5F0TgOaTACLcBGAsYHQ/s1920/ice%2Bcream.jpg"><img data-original-height="1281" data-original-width="1920" height="291" src="https://1.bp.blogspot.com/-M9DU9zcfGEM/X6vx7TBn83I/AAAAAAAA5Uc/FcCL5fs2b-wqCxNbl6Evh7ZG5F0TgOaTACLcBGAsYHQ/w435-h291/ice%2Bcream.jpg" width="435"></a></p></div><p><span data-preserver-spaces="true">In the various industries that are out there, not too many are as different as fashion and ice cream. One is involved in providing happiness, comfort and everything nice in this world and that other provides a sharp reminder that maybe that extra scoop of ice cream was too much. But suffice to say, a rift between the two industries is not something that you would expect to find.&nbsp;</span></p><p><span data-preserver-spaces="true">But as hype culture and the obsessive fandom on the internet have grown, the industries have been growing closer and closer together. But sadly, not in the way you think, we are still a few years off wearable ice cream. Instead, there is now a good chance that your local ice creamery sells merchandise. Less impressive, for sure. But this has become a staple for restaurants with even just a modicum of goodwill attached to their name and why not? If customers are willing to pay an extra $50 so that people will mistake them as an 'off the clock' employee, then go for it. However, it is always important to keep in mind that merely the fact that a store does not typically deal in goods from a particular industry, this does not exempt that store from the standard business conventions of that industry.&nbsp;</span></p><p><span data-preserver-spaces="true">This lesson was learnt recently by Afters Ice Cream, which after launching a line of merchandise was reportedly</span><span data-preserver-spaces="true">&nbsp;sued by the high-fashion brand, Off-White.&nbsp;</span></p><p><span data-preserver-spaces="true">Afters Ice Cream advertised a number of different types of clothing that featured the phrase 'Off-Diet' and using images similar to very notable Off-White works. Off-White claims that the merchandise is 'confusingly similar' to Off-White's graphics and registered trademarks. It also stated that "retail fixtures, signage, [and] interior d√©cor" is intended to "confuse consumers into believing that [its] products are Off-White products and/or that [it or its] business is affiliated with Off-White."&nbsp;</span></p><p><span data-preserver-spaces="true">While it is ironic that the Off-White, a company which has been at the other end of numerous copyright infringement claims, even to the extent of a case being called&nbsp;</span><em>OffWhite Co v Off-White</em><span data-preserver-spaces="true">&nbsp;</span><em>LLC</em><span data-preserver-spaces="true">, was so quick to launch their own proceeding, however, the law is pretty straightforward concerning unlicensed reproduction of copyrighted works.&nbsp;</span></p><p><span data-preserver-spaces="true">But it is not all doom and gloom, and there is hope for the plucky ice cream store yet as due to use of humour in the respective shirts, a reproduction of copyrighted works could be okay if it is for the purposes of parody or satire.&nbsp;&nbsp;</span></p><p><span data-preserver-spaces="true">This concept was demonstrated in a recent case in the Ninth Circuit, where the makers of a dog toy that resembled a bottle of Jack Daniels Whiskey were found not to be infringing copyright as the dog toy was found to be humourous and expressive and not a sign of your dog falling off the wagon.&nbsp;</span></p><p><span data-preserver-spaces="true">As for the Off-White matter, we will have to wait and see if this matter progresses to court or if cooler heads prevail and the case is dropped.&nbsp;</span></p>
</div>

</div></div>]]>
            </description>
            <link>https://www.legallyinsightful.com/2020/11/off-brand-how-high-fashion-brand-and.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058570</guid>
            <pubDate>Wed, 11 Nov 2020 14:18:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Online conversation is the attention system of society ‚Äì and it's broken]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25058548">thread link</a>) | @etherio
<br/>
November 11, 2020 | http://norse.horse/articles/attention-system-of-society.html | <a href="https://web.archive.org/web/*/http://norse.horse/articles/attention-system-of-society.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>
Humans are hypersocial animals; as soon as we invent something new, from signal fires to electricity,  we use it to communicate. Users of the very first computers would leave notes on the system for friends to read; today, Internet users spend on average over two hours per day using social media. As a cognitive scientist, I√¢‚Ç¨‚Ñ¢m interested in how we use online tools to communicate, adjust our views, and make decisions; and I√¢‚Ç¨‚Ñ¢m concerned about the effects of for-profit social media on conversation and debate. My generation is the last to have grown up writing letters - handwritten, meaningful messages from friends - and for-profit social media is psychologically very different.
</p><p>
In October 2017 three academics, concerned about Whatsapp√¢‚Ç¨‚Ñ¢s influence on the Brazilian election, called for the Facebook-owned company to make it harder to share messages. Instant sharing means that an individual can reach many more people and that events, rumours and viewpoints can go viral in a few hours, sweeping across a country as a wave of copies is made. Importantly, the reader has no sense that the sender has taken the time to craft a communication; sharing is not an act of expression. Oversharing also swamps readers with the cognitive demand of reading hundreds of low-effort posts per day. Luckily for big social media, there is a solution at hand: the algorithm.
</p><p>
Facebook, Snapchat and Twitter originally showed new posts in chronological order. Today, they use news-feed algorithms to select the posts you see. The details of how these algorithms work and what they prioritise are murky, but two things are certain: they collect huge amounts of data on our behaviour, and they aim to maximise the time we spend logged in - not to give us the most interesting or meaningful material. If we argue with someone over an offensive post, the algorithm may counterproductively show us more posts like it. If you turn Facebook√¢‚Ç¨‚Ñ¢s algorithm off, it swiftly switches itself back on.
</p><p>
The tools we use to communicate online play a huge role in our lives: they help us choose our friends, fix our political and moral beliefs, and construct our personalities. I study attention, the set of brain processes which decide what details of the outside world are important. When you notice a bright light, screen out a distracting noise, or select the most trustworthy panellist in a debate, your attention system is at work. In the modern world, online communication tools enable and support social trends; they host flurries of political discourse during elections; and they allow the viral spread of ideas, from memes to movements. They are the attention system of society.
</p><p>
Before sharing and before the news-feed algorithm, individual people played a huge role in society√¢‚Ç¨‚Ñ¢s online attention system. Millions of small decisions by individuals combined to select the topics that would dominate the headlines. But we have given up the job. With our news feeds curated by algorithms, we no longer decide what to read. We can still choose which groups to subscribe to or which friends to follow, but we have completely abnegated the most basic and central decision - what messages are put in front of our eyes.
</p><p>
So, using social media is a very different experience from reading or writing a letter. There is no natural end to the experience; there is little incentive to put time and care into writing a message; and there is no control over what you read. For-profit social media, being free, is not a product. Neither is it a a service; it does not give us the options we need to control it. Social media is an experience designed to attract and retain us - so that we can provide the attention which earns Facebook √Ç¬£20 per year per user in advertising revenue, and the behaviour data which is its most valuable asset.
</p><p>
The consequences of our society√¢‚Ç¨‚Ñ¢s new attention system are extremely serious. Before the 2016 referendum on EU membership, over √Ç¬£2.7m was spent on often-misleading Facebook adverts by an unregulated consortium of lobbying organisations which conspired to break the Electoral Commission√¢‚Ç¨‚Ñ¢s rules on data sharing. Shortly before the last US election, $70 million per month was spent on social media advertising by the Trump campaign, using voter data stolen through a Facebook loophole to predict personalities and target political ads. 
</p><p>
I believe that the best way to highlight the harmful effects of oversharing and news-feed algorithms is to build a platform that supports conversation, discussion, and independent thought rather than prioritising sharing and screen time. A communication tool should not be an experience; it should be a true service, one which puts readers√¢‚Ç¨‚Ñ¢ and writers√¢‚Ç¨‚Ñ¢ needs first by giving them the tools to control what they read and who reads their conversations.
</p><p>
We all have a right to freedom of speech - but we don't automatically have the right to broadcast. We need to think carefully about public groups - spaces which can go viral and take on a life of their own. A closed group can√¢‚Ç¨‚Ñ¢t go viral or expand into a huge community. Public groups can connect you with like-minded people and show you interesting material, but when people disagree on topics close to their heart - human rights, economic policy - public groups descend into chaos or censorship. Their owners or controllers may be unclear; they must use moderators, whose rules are often unfair; and by suppressing conflicting opinions they encourage the development of filter bubbles. What we read online should be selected by individuals√¢‚Ç¨‚Ñ¢ decisions, not by the moderators of anonymous groups or by algorithms trained for profit.
</p><p>
It is certainly easier to immerse yourself in the experience of for-profit social media. But I believe that conversation and debate should be more than a passive experience: they require effort, engagement and attention. Every day, we spend hours reading and conversing online. Just as we are careful with what we eat and drink, we should be careful with what we read, what we allow to influence us, and to whom we delegate the responsibility of choosing what is put in front of our eyes. The days of letter-writing may have passed, but the experience of reading a message carefully written for you, conveyed to you by a system whose only purpose is to support communication, should live on.
</p>





</div></div>]]>
            </description>
            <link>http://norse.horse/articles/attention-system-of-society.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058548</guid>
            <pubDate>Wed, 11 Nov 2020 14:15:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What mother never told you about VM service (1983) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058543">thread link</a>) | @fanf2
<br/>
November 11, 2020 | http://www.leeandmelindavarian.com/Melinda/tutorial.pdf | <a href="https://web.archive.org/web/*/http://www.leeandmelindavarian.com/Melinda/tutorial.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.leeandmelindavarian.com/Melinda/tutorial.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058543</guid>
            <pubDate>Wed, 11 Nov 2020 14:15:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Covid-19 Beta]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058503">thread link</a>) | @simonpure
<br/>
November 11, 2020 | https://reasonabledeviations.com/2020/11/09/covid-beta/ | <a href="https://web.archive.org/web/*/https://reasonabledeviations.com/2020/11/09/covid-beta/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  
  
  
  <p>In this short post, we compute and visualise ‚ÄúCOVID-19 betas‚Äù for stocks in the S&amp;P500 index, to quantitatively and visually understand which companies were most affected (positively and negatively) by COVID-19.</p>

<!--more-->
<p>For those of you who just want to see the (interactive!) result, here it is. Click on any sector to zoom in on its constituents:</p>





<p>If you would like to generate this plot for yourself, perhaps using a different basket of stocks, the Jupyter notebook is <a href="https://github.com/robertmartin8/RandomWalks/blob/master/COvidBeta/CovidBeta.ipynb">here</a>.</p>

<p><em>Note: most of this post was written before November 9th 2020, the day on which Pfizer announced incredibly encouraging results regarding their vaccine.</em></p>

<h2 id="motivation">Motivation</h2>

<p>Let‚Äôs go back in time to the start of 2020. Despite aggressive trade rhetoric, 2019 has been a great year for markets, with the S&amp;P500 up about 30%. Thanks to low rates (and the Fed‚Äôs commitment to loose monetary policy), the ‚Äúblip‚Äù of 2018Q4 is nothing more than a distant bad dream. Big tech is killing it; multiples are expanding; volatility is at a comfortable low.</p>

<p>On January 4th, the World Health Organisation (WHO) <a href="https://twitter.com/WHO/status/1213523866703814656?s=20">tweets</a> that there is a cluster of pneumonia cases in Wuhan, China. As far as the West is concerned, this is a non-event, happening way ‚Äúover there‚Äù in the East. On January 13th, a case is recorded in Thailand. What follows is two months of health officials gathering and mulling over the evidence (on January 23rd an independent committee reports that there is insufficient evidence to make a decision), while the rest of the world continues on blissfully unaware of the worsening situation. The markets continue their steady rise, largely unperturbed.</p>

<p>In February, the situation becomes hard to ignore; by February 13th, COVID-19 is present in 25 countries, with more than 60,000 cases (<a href="https://www.thinkglobalhealth.org/article/updated-timeline-coronavirus">source</a>). On the 14th of February, market participants suddenly seem to appreciate the gravity of the situation; in one short month, the S&amp;P500 loses 1/3 of its value. People who have been diligently following the prevailing personal finance advice and investing their money in the stock markets are suddenly faced with an unprecedentedly rapid loss of net worth. Speculators, who have been riding the rally with leverage, are caught with their trousers down.</p>

<p>By March, there is full-on panic as the worldwide number of cases hits 100,000 and nations start to impose heavy travel restrictions.  What had started as whispers of a viral cough ‚Äúfar away in the East‚Äù has now blown up into the terrifying spectre of an omnipresent contagion ‚Äì $R_0$ numbers suggest that before long, the majority of the world population will be infected by a virus whose severity is still unknown. Readers of mainstream news could be forgiven for thinking that it is the end of the world as we know it.</p>

<p>Cut to 18th August ‚Äì 6 months later. The S&amp;P500 has just posted a new all-time high, having appreciated about 50% from the low of March 20th.</p>

<center>
<img src="https://reasonabledeviations.com/assets/images/covid_beta/spy_covid.png">
</center>

<p>I have written this dramatised account largely as a note-to-self. With the rose-tinted spectacles of hindsight, it is now clear that the widespread and indiscriminate risk-off in March created a fantastic opportunity for level-headed investors to pick up high-quality companies, well suited to a social-distanced society, at steep discounts. Many of us are now kicking ourselves for not having bought more, but we must remember that in the moment, the future was murky indeed.</p>

<p>All this said, things certainly aren‚Äôt back to where they were. Only a handful of companies (mostly big tech) have been responsible for the majority of the market‚Äôs rebound. Whether you are optimistic or pessimistic about how the pandemic plays out from here, as long as you think COVID-19 is a key driver for stock markets it is important to know how different sectors or companies are affected by the virus. Optimists might be keen to identify which stocks have been hardest hit, to play the rebound, while those who think that the situation will stay unresolved for longer than consensus expects may want to remain overweight the companies that thrive in a pandemic environment.</p>

<p>The goal of this investigation, therefore, is to develop a highly intuitive tool to allow the viewer to understand, at a glance, which companies respond <em>well</em> and <em>badly</em> to COVID-19 news.</p>

<h2 id="methodology">Methodology</h2>

<p>The standard approach is ‚Äúarmchair reasoning‚Äù: sitting down and logically thinking through what the impacts of COVID-19 have been / will be.
On April 2nd 2020, I made this brainstorming mindmap to reason about some of the second-order implications of the pandemic. Several of the companies I mentioned, which may seem obvious in hindsight, have done very well:</p>

<center>
<img src="https://reasonabledeviations.com/assets/images/covid_beta/covid_brainstorming.png">
</center>

<p>Alternatively, we might adopt the ‚Äúdata-driven‚Äù approach: let market performance tell you which stocks benefitted most and least from COVID-19. Naively, we could simply look at which stocks/sectors have performed best/worst this year. This is a reasonable starting point but contains a lot of noise because stocks move up and down for all sorts of reasons.</p>

<p>A better methodology for understanding how some factor (in our case, COVID-19) affects stock prices is is to compute the <strong>beta</strong> of the asset returns to the factor. Concretely, we examine the correlation between the daily change in stock prices and the daily increases in COVID-19 cases: if a stock tends to have negative returns whenever COVID cases rise, we may believe that there is some association between COVID and the stock. The nice thing about this approach is that we can remove the effects of as many other variables as we want by introducing them as additional regression variables.</p>

<p>In this post, we will regress stock returns against both COVID-19 cases and the overall S&amp;P500 index (the latter being what people typically call <em>the</em> beta, though it is really just <em>a</em> beta). This serves to identify the effect of COVID-19 on the stock <em>in excess</em> of the overall market effects, which should give a more accurate picture of how COVID-19 is affecting a stock.</p>

<p>I pulled COVID data from the New York Times‚Äô <a href="https://github.com/nytimes/covid-19-data">GitHub repo</a>, and as usual, I used Yahoo Finance (via the <code>yfinance</code> python library) for stock/index pricing data. The ‚Äúheavy lifting‚Äù ‚Äì regressing stock returns against SPY returns and the change in daily cases ‚Äì was done by the linear regression class within <code>scikit-learn</code>.</p>

<h2 id="analysis-and-visualisation">Analysis and Visualisation</h2>

<p>A higher COVID beta means that a stock‚Äôs returns were <em>positively</em> correlated with the change in COVID cases, i.e. more COVID cases helped the stock. Perhaps unsurprisingly, among the stocks with the highest COVID betas were Netflix, Walmart, Hasbro, Intel, and Citrix (enterprise technology). Conversely, the stocks with the most negative COVID betas include hard-hit companies in the energy and consumer discretionary sectors. This is encouraging, as our methodology passes the basic sanity check. Tech companies like Netflix were clear winners from national lockdowns, while energy companies faced a massive demand shock as people no longer drove to work or travelled overseas.</p>

<p>To summarise the betas in one clear diagram, I drew inspiration from the Bloomberg terminal heatmap, which gives an instant ‚Äúpulse‚Äù of the market with respect to one key variable (with the size of a rectangle representing market caps):</p>

<center>
<img src="https://reasonabledeviations.com/assets/images/covid_beta/CovidBeta.png">
</center>

<p>(Note: we don‚Äôt see a large blue rectangle corresponding to Zoom because Zoom isn‚Äôt yet in the S&amp;P500 index)</p>

<p>At a first glance, this graphic seems to accurately describe much of our intuition regarding what COVID has benefitted/harmed. Tech is largely blue (benefitting), as are healthcare and consumer staples. Energy has been particularly hard hit, with financials having a tough time also. But the effect of COVID on other sectors may not be as obvious, and it is here where the visualisation becomes especially helpful.</p>

<p><em>Note regarding the Pfizer news of November 9th 2020</em></p>

<p>On 9 November, while I was halfway through writing this post, Pfizer announced very promising results from their vaccine. I found the heatmap to be a very useful reference ‚Äì the red companies/sectors posted stunning returns, while many of the blue companies (e.g big tech) had a lacklustre day ‚Äì and actually ended up using the heatmap to help identify some stocks to trade. Based on my qualitative judgment post-hoc, the betas on the heatmap do seem to properly reflect the economic link between COVID-19 and the companies.</p>

<h2 id="conclusion">Conclusion</h2>

<p>In this post, we have constructed a ‚Äúquick and dirty‚Äù method of understanding and visualising the effects of COVID-19 on different companies. There are several important caveats which should be considered before you use the heatmap for anything important.</p>

<p>Firstly, betas are essentially correlations, so we must be careful about using them to retroactively create narratives to explain <em>why</em> certain stocks did well/badly with respect to COVID-19. One must exercise judgment in determining which betas represent broad economic impacts due to COVID-19, rather than idiosyncratic company effects. For example, I noticed that within the financials sector, Goldman Sachs stood out as having a positive COVID beta ‚Äì I reasoned that this was <em>because</em> GS doesn‚Äôt have significant commercial banking exposure, instead being focused on trading (which benefits from volatility) and investment banking. However, this narrative is somewhat contradicted by the fact that Morgan Stanley also lacks commercial banking exposure, yet had a negative COVID beta anyway.</p>

<p>Secondly, this analysis treats beta as if it is a static parameter. In reality, to compute beta (or any other time-series property), one must decide on a rolling window for the calculation. In this post, we used all year-to-date stock price data, but the plot below shows how the 2-month rolling beta for the 10 highest/lowest beta stocks (averaged) varied over time.</p>

<center>
<img src="https://reasonabledeviations.com/assets/images/covid_beta/rolling_beta.png">
</center>

<p>Lastly, we have all likely heard the many complaints about the market diverging from reality, along with the standard response that ‚Äúmarkets are forward-looking‚Äù. Our methodology is not at all forward-looking, as it is simply ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://reasonabledeviations.com/2020/11/09/covid-beta/">https://reasonabledeviations.com/2020/11/09/covid-beta/</a></em></p>]]>
            </description>
            <link>https://reasonabledeviations.com/2020/11/09/covid-beta/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058503</guid>
            <pubDate>Wed, 11 Nov 2020 14:09:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why an IDE?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058502">thread link</a>) | @todsacerdoti
<br/>
November 11, 2020 | https://matklad.github.io//2020/11/11/yde.html | <a href="https://web.archive.org/web/*/https://matklad.github.io//2020/11/11/yde.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article>
  
  <p>Nov 11, 2020</p>
  <p>Some time ago I wrote a reddit comment explaining the benefits of IDEs.
Folks refer to it from time to time, so I decided to edit it into an article form.
Enjoy!</p>
<p>I think I have a rather balanced perspective on IDEs.
I used to be a heavy Emacs user (<a href="https://github.com/matklad/.emacs.d/tree/475de5db99f8729c57fed7e6fde4cd06f5ccb62f">old config</a>, <a href="https://github.com/matklad/config/blob/d555642a5a9e4e8b0ca0c77f188ffd976f06327c/home/.emacs.d/init.el">current config</a>).
I worked at JetBrains on <a href="https://github.com/intellij-rust/intellij-rust">IntelliJ Rust</a> for several years.
I used evil mode and vim for a bit, and tried tmux and kakoune.
Nowadays, I primarily use VS Code to develop <a href="https://github.com/rust-analyzer/rust-analyzer/">rust-analyzer</a>: LSP-based editor-independent IDE backend for Rust.</p>
<p>I will be focusing on IntelliJ family of IDEs, as I believe these are the most advanced IDEs today.</p>
<p>The main distinguishing feature of IntelliJ is semantic understanding of code.
The core of IntelliJ is a compiler which parses, type checks and otherwise understands your code.
<a href="https://martinfowler.com/bliki/PostIntelliJ.html">PostIntelliJ</a> is the canonical post about this.
That article also refutes the claim that ‚ÄúSmalltalk IDE is the best we‚Äôve ever had‚Äù.</p>
<p>Note that ‚Äúsemantic understanding‚Äù is mostly unrelated to the traditional interpretation of ‚ÄúIDE‚Äù as <em>Integrated</em> Development Environment.
I personally don‚Äôt feel that the ‚ÄúIntegrated‚Äù bit is all that important.
I commit&amp;push from the command line using Julia scripts, rebase in magit, and do code reviews in a browser.
If anything, there‚Äôs an ample room for improvement for the integration bits.
For me, <strong>I</strong> in ‚Äú<strong>I</strong>DE‚Äù stands for ‚Äúintelligent‚Äù, smart.</p>
<p>Keep in mind this terminology difference.
I feel it is a common source of misunderstanding.
‚ÄúUnix and command line can do anything an IDE can do‚Äù is correct about integrated bits, but is wrong about semantical bits.</p>
<p>Traditional editors like Vim or Emacs understand programming languages very approximately, mostly via regular expressions.
For me, this feels very wrong.
It‚Äôs <a href="https://stackoverflow.com/a/1732454">common knowledge</a> that HTML shall not be parsed with regex.
Yet this is exactly what happens every time one does <code>vim index.html</code> with syntax highlighting on.
I sincerely think that almost every syntax highlighter out there is wrong and we, as an industry, should do better.
I also understand that this is a tall order, but I do my best to change the status quo here :-)</p>
<p>These are mostly theoretical concerns though.
The question is, does semantic understanding help in practice?
I am pretty sure that it is non-essential, especially for smaller code bases.
My <a href="https://github.com/matklad/rustraytracer">first non-trivial Rust program</a> was written in Emacs, and it was fine.
Most of rust-analyzer was written using pretty spartan IDE support.
There are a lot of insanely-productive folks who are like ‚Äúsometimes I type vim, sometimes I type vi, they are sufficiently similar‚Äù.
Regex-based syntax highlighting and regex based fuzzy symbol search (<a href="https://github.com/universal-ctags/ctags">ctags</a>) get you a really long way.</p>
<p>However, I do believe that features unlocked by deep understanding of the language help.
The funniest example here is extend/shrink selection.
This features allows you to extend current selection to the next encompassing syntactic construct.
It‚Äôs the simplest feature a PostIntelliJ IDE can have, it only needs the parser.
But it is sooo helpful when writing code, it just completely blows vim‚Äôs text objects out of the water, especially when combined with multiple cursors.
In a sense, this is structural editing which works for text.</p>
<div>
<p><img src="https://user-images.githubusercontent.com/1711539/98809232-80e3db00-241d-11eb-883a-5aece9a1dbfc.gif" alt="98809232 80e3db00 241d 11eb 883a 5aece9a1dbfc">
</p>
</div>
<p>If you add further knowledge of the language into a mix, you‚Äôll get the ‚Äúassists‚Äù system: micro-refactoring which available in a particular context.
For example, is the cursor is on a comma in a list of function arguments, you can <span><kbd>alt</kbd>+<kbd>enter</kbd></span> &gt; ‚Äúswap arguments‚Äù, and the order of arguments will be changed in the declaration and on various call-sites as well.
(See <a href="https://rust-analyzer.github.io/blog/2020/09/28/how-to-make-a-light-bulb.html">this post</a> to learn how assists are implemented).</p>
<p>These small dwim things add up to a really nice editing experience, where you mostly express the intention, and the IDE deals with boring syntactical aspects of code editing:</p>
<div>
<p><img src="https://user-images.githubusercontent.com/1711539/98812121-37e25580-2422-11eb-8541-2c5a32926845.gif" alt="98812121 37e25580 2422 11eb 8541 2c5a32926845">
</p>
</div>
<p>For larger projects, complex refactors are a huge time-saver.
Doing project-wide renames and signature changes automatically and without thinking reduces the cost of keeping the code clean.</p>
<p>Another transformative experience is navigation.
In IntelliJ, you generally don‚Äôt ‚Äúopen a file‚Äù.
Instead you think directly in terms of functions, types and modules, and navigate to those using file structure, goto symbol, to do definition/implementation/type, etc:</p>

<p>When I used Emacs, I really admired its buffer management facilities, because they made opening a file I want a breeze.
When I later switched to IntelliJ, I stopped thinking in terms of a set of opened files altogether.
I disabled editor tabs and started using editor splits less often‚Äâ‚Äî‚Äâyou don‚Äôt need bookmarks if you can just find things.</p>
<p>For me, there‚Äôs one aspect of traditional editors which is typically not matched in IDEs out of the box‚Äâ‚Äî‚Äâbasic cursor motion.
Using arrow keys for that is slow and flow-breaking, because one needs to move the hand from the home row.
Even Emacs' horrific <kbd>C-p</kbd>, <kbd>C-n</kbd> are a big improvement, and vim‚Äôs <kbd>hjkl</kbd> go even further.
One fix here is to configure each tool to use your favorite shortcuts, but this is a whack-a-mole game.
What I do is remapping <kbd>CapsLock</kbd> to act as an extra modifier, such that <kbd>ijkl</kbd> <strong>are</strong> arrow keys.
(There are also keyboards with <a href="https://ultimatehackingkeyboard.com/">hardware</a> <a href="https://ergodox-ez.com/">support</a> for this).
This works in all applications the same way.
Easy motion / ace jump functionality for jumping to any visible character is also handy, and usually is available <a href="https://plugins.jetbrains.com/plugin/9803-acejump-lite">via</a> <a href="https://marketplace.visualstudio.com/items?itemName=lucax88x.codeacejumper">a plugin</a>.</p>
<p>Recent advancements with LSP protocol promise to give one the best of both worlds, where semantic-aware backend and light-weight editor frontend are different processes, which can be mixed and matched.
This is nice in theory, but not as nice in practice as IntelliJ yet, mostly because IntelliJ is way more polished.</p>
<p>To give a simple example, in IntelliJ for ‚Äúgo to symbol by fuzzy name‚Äù functionality, I can filter the search scope by:</p>
<div>
<ul>
<li>
<p>is this my code/code from a dependency?</p>
</li>
<li>
<p>is this test/production code?</p>
</li>
<li>
<p>is a symbol a type-like thing, or a method-like thing?</p>
</li>
<li>
<p>path to the module where the symbol is defined.</p>
</li>
</ul>
</div>
<p>VS Code and LSP simply do not have capabilities for such filters yet, they have to be bolted on using hacks.
Support for LSP in other editors is even more hit-and-miss.</p>
<p>LSP did achieve a significant breakthrough‚Äâ‚Äî‚Äâit made people care about implementing IDE backends.
Experience shows that re-engineering an existing compiler to power an IDE is often impossible, or isomorphic to a rewrite.
How a compiler talks to an editor is the smaller problem.
The hard one is building a compiler that can do IDE stuff in the first place.
Check out <a href="https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html">this post</a> for some of the technical details.
Starting with this use-case in mind saves a lot of effort down the road.</p>
<p>This I think is a big deal.
I hypothesize that the reason why IDEs do not completely dominate tooling landscape is the lack of good IDE backends.</p>
<p>If we look at the set of languages fairly popular recently, a significant fraction of them is dynamically typed: PHP, JavaScript, Python, Ruby.
The helpfulness of an IDE for dynamically typed languages is severely limited: while approximations and heuristics can get you a long way, you still need humans in the loop to verify IDE‚Äôs guesses.</p>
<p>There‚Äôs C++, but its templates are effectively dynamically typed, with exactly the same issues (and a very complex base language to boot).
Curiously, C looks like a language for which implementing a near-perfect IDE is pretty feasible.
I don‚Äôt know why it didn‚Äôt happen before CLion.</p>
<p>This leaves C# and Java.
Indeed, these languages are dominated by IDEs.
There‚Äôs a saying that you can‚Äôt write Java without an IDE.
I think it gets the causation direction backwards: Java is one of the few languages for which it is possible to implement a great IDE without great pain.
Supporting evidence here is Go.
According to <a href="https://blog.golang.org/survey2019-results#TOC_5.">survey results</a>, text editors are stably declining in popularity in favor of IDEs.</p>
<p>I think this is because Go actually has good IDEs.
This is possible because the language is sufficiently statically typed for an IDE to be a marked improvement.
Additionally, the language is very simple, so the amount of work you need to put in to make a decent IDE is much lower than for other languages.
If you have something like JavaScript‚Ä¶‚Äã
Well, you first need to build n alternative language for which you can actually implement and an IDE (<a href="https://www.typescriptlang.org/">TypeScript</a>) and only then you can build the IDE itself (<a href="https://github.com/microsoft/vscode">VS Code</a>).</p>
</article>

  </div></div>]]>
            </description>
            <link>https://matklad.github.io//2020/11/11/yde.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058502</guid>
            <pubDate>Wed, 11 Nov 2020 14:09:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[$200k in sales from a $6k advertisement]]>
            </title>
            <description>
<![CDATA[
Score 371 | Comments 102 (<a href="https://news.ycombinator.com/item?id=25058363">thread link</a>) | @mildlyclassic
<br/>
November 11, 2020 | https://www.wifidabba.com/blog/200000-dollars-in-sales-from-one-daringfireball-ad | <a href="https://web.archive.org/web/*/https://www.wifidabba.com/blog/200000-dollars-in-sales-from-one-daringfireball-ad">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <div>
        <div>
          <div>


          
            <table>
                <thead>
                  <tr>
                    <th>
                      Metric
                    </th>
                    <th>
                      Count
                    </th>
                  </tr>
                </thead>
                <tbody>
                <tr data-href="#!">
                    <td>
                      Time period
                    </td>
                    <td>
                      Aug 17,2020 - Aug 24,2020
                    </td>
                  </tr>
                  <tr data-href="#!">
                    <td>
                      Visitors
                    </td>
                    <td>
                      7,200
                    </td>
                  </tr>
                  <tr data-href="#!">
                    <td>
                      Emails
                    </td>
                    <td>
                      45
                    </td>
                    
                  </tr>
                  <tr data-href="#!">
                    <td>
                      Video calls
                    </td>
                    <td>
                      30
                    </td>
                    
                  </tr>
                  <tr data-href="#!">
                    <td>
                      <strong>Units sold</strong>
                    </td>
                    <td>
                      <b>10</b>
                    </td>
                  </tr>   
                  <tr data-href="#!">
                    <td>
                      <strong>Unit price</strong>
                    </td>
                    <td>
                      <b>$20,000</b>
                    </td>
                  </tr>
                  <tr data-href="#!">
                    <td>
                      <strong>Total revenue from DF</strong>
                    </td>
                    <td>
                      <b>$200,000</b>
                    </td>
                  </tr>
                  
                </tbody>
              </table>
              
              
          <ul>
              <li>
                Build cheap broadband distribution technology.
              </li>
              <li>
                Prove the tech works by connecting 1M people in one city.
              </li>
              <li>
                Deploy across 1,000 cities in India
              </li>
            </ul>

            

            <p>
                Our goal at <a href="https://www.wifidabba.com/">Wifi Dabba</a> is to lower the cost of broadband access in India. We use lasers instead of underground fiber as our core network and commodity components to dramatically lower the cost of deploying a broadband network.
            
                We've been running a beta network in Bengaluru, India for the last 9 months serving thousands of live customers. We're now ready to deploy a city wide network and provide cheap internet access to a million people.
            </p>

            <iframe width="100%" height="450" src="https://www.youtube.com/embed/LwVWJXBNQg8?autoplay=1" srcdoc="<style>*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}</style><a href=https://www.youtube.com/embed/LwVWJXBNQg8?autoplay=1><img width='100%' style='min-height:250px;' src='https://img.youtube.com/vi/LwVWJXBNQg8/hqdefault.jpg' alt='Wifi Dabba overview'><span>‚ñ∂</span></a>" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" title="Wifi Dabba overview"></iframe>

            
            <p>
              A core tenet of the Wifi Dabba network is distributed ownership. We believe that ownership of the internet should be in the hands of as many people as possible. If the cost of broadband tech drops, then more people can help pay for the cost of the network.
              And if you're one of the people paying for the distribution, we believe you should get revenue in return.
            </p>

            <p>
              We've divided the city of Bengaluru into 100 regions called PoPs. Anyone can buy a region and get a share in the revenue from those subscribers. 
            </p>

            <p>
              The Wifi Dabba franchise model:
            </p>

            <ul>
              <li>
                <strong>$20,000</strong> to purchase a 4sqkm. PoP.
              </li>
              <li>
                <strong>Minimum guaranteed revenue</strong> Paid quarterly with a 6 year rev share agreement.
              </li>
              <li>
                <strong>Fully managed service</strong> Be an absentee landlord
              </li>
            </ul>

            

            <p>
              <span>We've sold 40 as of the time of writing this.</span>
              <br>
              
              Wifi Dabba is insanely lucky for the amount of public support we have as a company. We regularly get phone calls, emails and even people dropping by our office just to tell us they like our service. Over the last 3 years we've received dozens of emails from people requesting franchises or other types of partnerships.
              We're incredibly humbled and thankful for this support on a daily basis.
            </p>

            
            <p>
              We believe there is a large group of people that care about the future of the internet and would be willing to put their money where their mouths are. As long as the price and the level of risk involved is reasonable.
              Our gut told us that this group would most likely be people that have seen success in the technology business as engineers, operators and entreprenuers.
            </p>

            
            <p>
              We've had our heads down over the last three years building and testing our network stack. Publicity or notariety has never been high on our list. 
              We've begun ramping up our social media efforts but it was clear that to kickstart our outreach, we had to do a little bit of advertising.
            </p>

            
            
              <p><img src="https://www.wifidabba.com/images/df-venn.png" height="300" width="330" alt="...">
                <br>
              </p>
            <p>
              <a href="https://www.daringfireball.net/">Daringfireball.net</a> is a great blog authored by <a href="https://en.wikipedia.org/wiki/John_Gruber">John Gruber</a> who is also the creator of <a href="https://daringfireball.net/projects/markdown/">Markdown</a>.
              DF was a natural choice for us as we've been readers of the blog for a long while and we knew from experience that DF readers would fit our target market rather well. Given the high quality of John's writing and insights into the industry, we felt that there would be a large pool of senior tech veterans that would be interested in Wifi Dabba among DF's audience.
            </p>

            <p>
                The sponsorship cost us $6,500 and ran for the week starting Aug 17, 2020 and we got:
                </p><ul>
                <li>
                  A display ad in the sidebar on every page of the site, all week long.
                </li>
                <li>
                  A post from the sponsor in the RSS feed at the start of the week. Us, the sponsor, got to address Daring Fireball‚Äôs most dedicated readers directly.
                </li>
                <li>
                  At the end of the week, John also posts an item thanking and linking to the feed sponsor.
                </li>
              </ul>
            

            <p>
                Stats about DF readership
                </p><ul>
                <li>
                Typical weekday web page views: 80,000‚Äì100,000.
                </li>
                <li>
                Estimated monthly web page views: 2.5 million.
                </li>
                <li>
                Estimated Daring Fireball RSS feed subscribers: Over 200,000.
                </li>
                <li>
                Twitter followers on the @daringfireball  account: Over 92,000.
                </li>
              </ul>
            
            

            
            <p>
                We created two variants of our message. Designed in bold colours to stand out against DF's dark theme. These creatives rotated randomly.
                We decided to focus on the technology because of the nature of the audience and hoped that the website did a good job of explaining the product.  
                </p><p><img src="https://www.wifidabba.com/images/df-ads.png" width="100%" alt="Buy internet POP">
                </p>
            

            
            <div>
                <p><strong>Click Ad -&gt; Browse site -&gt; Setup a call</strong></p><p>

                We expected visitors to click on the ad in DF and land on our homepage. Once on our site, we hoped that visitors would check out our videos as well as browse through a few pages.
                If they liked what they saw, we had a prominent buy button on the front page which led to a page to setup a video call.
            </p></div>

            <p>
                It's worth noting here that we knew going in that a large percentage of DF's audience would be using Ad-blockers. Nothing wrong with that, we use ad-blockers ourselves.
            </p>

            <p>
              Furthermore, we made a deliberate choice to add a high friction call to action and contact process. In order to purchase a PoP, a visitor would be directed to a calendar managed by calendly that would help them setup a call with someone from our team at a convenient time.
            </p>
            <p><a href="https://wifidabba.com/buy">
              <img width="100%" src="https://www.wifidabba.com/images/df-buy.png" alt="Setup Call">
            </a></p><p>
              The reason for this is that we knew DF would deliver a few hundred visitors a day to our site. We're a small team and our core focus is deploying the network, not necessarily sales and our goal is to sell the PoPs to people that are really excited a lot about our idea and show a high level of interest.
              The $20,000 price point of our product + the high friction of the contact process + users that are OK with ads = A high signal to noise ratio from DF visitors. 
              We'd love to hear any feedback on what you think about this.
            </p>

            
              

              <p>
                Our thesis turned out to be pretty spot on. Senior engineers from Google, Apple and a host of other technology companies purchased the PoPs.
                The actual sales process turned out to be fairly quick and straight forward. Most of the people that purchased the PoPs did so within a period of 48 hours of having the call.
              </p>

              



          </div>
        </div>
    </div>
    </section></div>]]>
            </description>
            <link>https://www.wifidabba.com/blog/200000-dollars-in-sales-from-one-daringfireball-ad</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058363</guid>
            <pubDate>Wed, 11 Nov 2020 13:51:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Executing GraphQL Queries]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058361">thread link</a>) | @chmaynard
<br/>
November 11, 2020 | https://jemma.dev/blog/executing-graphql-queries | <a href="https://web.archive.org/web/*/https://jemma.dev/blog/executing-graphql-queries">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><a href="https://graphql.org/">GraphQL</a> is surging in popularity as a preferred choice for APIs over REST APIs. One of the reasons many companies cite for converting their APIs from REST to GraphQL is its ease of use. If you know JSON, GraphQL is incredibly intuitive. And there are helpful tools like <a href="https://github.com/graphql/graphiql">GraphiQL</a>, an in browser GraphQL IDE.</p>

<p>Even with its usability, there are still a few pointers which are helpful to learning GraphQL. GitHub implemented their <a href="https://developer.github.com/v4/">API v4</a> using GraphQL. Let‚Äôs work through an example using <a href="https://developer.github.com/v4/explorer/">GitHub‚Äôs GraphiQL explorer</a> to hit the GitHub API as a way to learn some basic GraphQL:</p>

<h3 id="graphiql-keyboard-shortcuts">GraphiQL Keyboard Shortcuts</h3>

<p>Before we start, take a look at these keyboard shortcuts I frequently use when working in the GraphiQL IDE:</p>

<ul>
  <li>Auto Complete: Ctrl-Space (or Option-Space)</li>
  <li>Run query: Ctrl-Enter</li>
  <li>Format query: Ctrl-Shift-P</li>
</ul>

<h3 id="githubs-graphiql-explorer">GitHub‚Äôs GraphiQL Explorer</h3>

<p>When you open up <a href="https://developer.github.com/v4/explorer/">GitHub‚Äôs GraphiQL explorer</a>, you‚Äôll see three panes. The top left is a query editor for our GraphQL query to GitHub‚Äôs API; bottom left is for query variables; and the right side will display query results when we hit the API.</p>

<p>After signing in with your GitHub account details, Hit play (Ctrl-Enter) on the query which GitHub autofills! You‚Äôll see your login displayed on the right side of the screen. The first item to note here is that the result mirrors the syntax and format of the query. This is a big part of what makes GraphQL so intuitive! The API responses mirror the API requests.</p>

<h3 id="reading-the-docs">Reading the Docs</h3>

<p>Towards the right of the GraphiQL explorer, there‚Äôs a <code>&lt; Docs</code> button. Toggle it! (This is not to be confused with the topbar menu <code>Docs</code> dropdown.) The <code>&lt; Docs</code> will toggle a little interface which tells us what to expect in our queries, and helps us when we use incorrect syntax. It will let us search by type.</p>

<p>Your first question, though, might be, how will we know the type of our data? In GraphQL, we can use <code>__typename</code> on any data to get its type. For instance, we can edit the query we just wrote:</p>

<div><div><pre><code>query <span>{</span>
  viewer <span>{</span>
    __typename
  <span>}</span>
<span>}</span>
</code></pre></div></div>
<p>and we‚Äôll see that <code>viewer</code> has the type <code>"User"</code>. If we now search the docs for <code>"User"</code>, we‚Äôll see there are many <code>"Fields"</code> on user which we can explore. Try adding a few fields to your initial query.</p>

<h3 id="user">User</h3>

<p>Well, there must also be other <code>"User"</code>s we can access instead of just ourselves. Let‚Äôs try it! Replace <code>viewer</code> in the query from above with <code>user</code>. When we run this snippet, we‚Äôll see an error:</p>

<div><div><pre><code>query <span>{</span>
  user <span>{</span>
    name
    login
    createdAt
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>The error will appear on our right pane. The error message tells us our problem, <code>"Field 'user' is missing required arguments: login"</code> Ah! We haven‚Äôt told GraphQL <em>which</em> user we‚Äôre interested in. As it suggests, let‚Äôs pass in a user‚Äôs login. <a href="https://github.com/torvalds">Linus Torvalds</a> created git, so he seems like an appropriate user to play with. His login is <code>torvalds</code>:</p>

<div><div><pre><code>query <span>{</span>
  user<span>(</span>login: <span>"torvalds"</span><span>)</span> <span>{</span>
    name
    login
    createdAt
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Neat. On the right side of your screen you should see that he‚Äôs had a GitHub account since 2011.</p>

<h3 id="connections">Connections</h3>

<p>When looking at the <code>User</code> docs, you might have noticed a type suffixed with <code>"Connection"</code>, for instance, <code>followers</code> has type <code>"FollowerConnection"</code>.</p>

<p>In GraphQL, <code>User</code> is a <code>Node</code>. Nodes have edges, and lists of these edges are called <code>Connections</code>. A <code>Connection</code> is a way to see all nodes that are connected to a certain node in a specific way. In our case, we‚Äôre looking for all <code>followers</code> nodes which are connected to Linus Torvalds. (See <a href="https://www.apollographql.com/blog/explaining-graphql-connections-c48b7c3d6976/">this Apollo blog post</a> for further reading about connections.)</p>

<p>If we try typing <code>followers</code> in the query, GraphiQL will give us an indication of an error. Hovering, we can read the error message, saying that <code>followers</code> must have a selection of subfields. This is where GraphiQL is incredibly helpful. Hit run (Ctrl-enter) after typing <code>followers</code>, and GraphiQL will autocomplete what its asking for:</p>

<div><div><pre><code>query <span>{</span>
  user<span>(</span>login: <span>"torvalds"</span><span>)</span> <span>{</span>
    name
    login
    createdAt
    followers <span>{</span>
      edges <span>{</span>
        node <span>{</span>
          <span>id</span>
        <span>}</span>
      <span>}</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>GraphiQL has auto-filled in the <code>edges</code>, <code>node</code> and <code>id</code> field on <code>followers</code> as defaults to give us some data about Linus‚Äô followers. This makes sense given what we know about edges and nodes: followers has <code>edges</code> and each of these is a <code>node</code>.</p>

<p>But, if we look to the right side of our screen, we‚Äôll see we have an error instead of results. The type <code>"MISSING_PAGINATION_BOUNDARIES"</code> and message <code>"You must provide a 'first' or 'last' value to properly paginate the 'followers' connection."</code> are both helpful here.</p>

<p>One of GraphQL‚Äôs real features is that it never returns more data than you ask it for. That said, we must tell it exactly how much data we want, by using (as prompted), the <code>first</code> or <code>last</code> field to limit the number of followers we‚Äôre asking for. Let‚Äôs look at Linus‚Äô last 5 followers:</p>

<div><div><pre><code>query <span>{</span>
  user<span>(</span>login: <span>"torvalds"</span><span>)</span> <span>{</span>
    name
    login
    createdAt
    followers<span>(</span>last: 5<span>)</span> <span>{</span>
      edges <span>{</span>
        node <span>{</span>
          <span>id</span>
        <span>}</span>
      <span>}</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This worked! But the <code>id</code>s aren‚Äôt particularly informative. We can see the type of <code>followers</code> by again using <code>__typename</code>. Or, we can use Ctrl-space to autoprompt some fields we might be interested in. Instead of the <code>id</code> field on a <code>node</code>, let‚Äôs look at <code>name</code>:</p>

<div><div><pre><code>query <span>{</span>
  user<span>(</span>login: <span>"torvalds"</span><span>)</span> <span>{</span>
    name
    login
    createdAt
    followers<span>(</span>last: 5<span>)</span> <span>{</span>
      edges <span>{</span>
        node <span>{</span>
          name
        <span>}</span>
      <span>}</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Aha, we can see the name of a few of Linus‚Äô followers. But, exactly how popular is he? For that, we can use the <code>totalCount</code> field under <code>followers</code>:</p>

<div><div><pre><code>query <span>{</span>
  user<span>(</span>login: <span>"torvalds"</span><span>)</span> <span>{</span>
    name
    login
    createdAt
    followers<span>(</span>last: 5<span>)</span> <span>{</span>
      totalCount
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>As of the writing of this post, he has 124,812 followers. Notably, <code>totalCount</code> was <em>not</em> limited by our pagination. This is because it is only returning a single value, not a series of values.</p>

<h3 id="query-variables">Query Variables</h3>

<p>Reading this, you might have been curious how many followers a different user has. For that, we could replace <code>"torvalds"</code> with a different user‚Äôs login. Or, we could learn about Query Variables!</p>

<p>This is the last remaining pane (on the bottom left) which we haven‚Äôt touched yet.</p>

<p>We first need to declare the argument within our query. GraphQL requires a type here. We‚Äôll need to declare it in two places. The first is passing it into the query itself. The syntax is <code>query ($variable_name:type!) { ...</code> In our case, we want to pass a <code>login</code> of type <code>String</code>, so <code>query ($login:String!) {...</code>. Secondly, we want this to be our user‚Äôs login. So we can replace <code>torvalds</code> with <code>$login</code> as follows:</p>

<div><div><pre><code>query <span>(</span><span>$login</span>:String!<span>)</span> <span>{</span>
  user<span>(</span>login: <span>$login</span><span>)</span> <span>{</span>
    name
    followers<span>(</span>last: 5<span>)</span> <span>{</span>
     totalCount
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>If we run this, our error message tells us that <code>"Variable $login of type String! was provided invalid value"</code>! Ah! We still didn‚Äôt use our bottom left ‚ÄúQuery Variables‚Äù pane. Let‚Äôs fill it in. Again, we can use the Ctrl-space to help us out: <code>{"login": "jemmaissroff"}</code>. If we now hit run, we‚Äôll see (among other things) that I have <em>significantly</em> fewer followers than Linus Torvalds.</p>

<h3 id="tldr">TL;DR</h3>

<p>For those short on time or attention:</p>

<ul>
  <li>GraphQL query results mirror JSON, making them easy to parse, write and reason about</li>
  <li><a href="https://github.com/graphql/graphiql">GraphiQL</a> is a helpful GraphQL IDE</li>
  <li><code>__typename</code> gives the type of an item, helpful for reading the docs</li>
  <li>Some queries have required arguments to limit the scope of a search, like <code>login</code> for user</li>
  <li>Pagination is a feature of GraphQL, requiring us to limit our queries, sometimes using <code>first</code> or <code>last</code></li>
  <li>Query variables must have a type and be named in the query declaration</li>
  <li>Query variables then can be used throughout the query itself by referencing the name in the declaration</li>
</ul>

<p>For an example of a queries which uses a few additional features of GraphQL, check out the queries I wrote <a href="https://github.com/jemmaissroff/find_github_email/blob/main/lib/find_github_email/queries.rb">here</a> for a Ruby gem to <a href="https://github.com/jemmaissroff/find_github_email">find GitHub users‚Äô emails</a>.</p>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://jemma.dev/blog/executing-graphql-queries</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058361</guid>
            <pubDate>Wed, 11 Nov 2020 13:50:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NodeJVM]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058252">thread link</a>) | @mooreds
<br/>
November 11, 2020 | https://mikehearn.github.io/nodejvm/ | <a href="https://web.archive.org/web/*/https://mikehearn.github.io/nodejvm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        
      
      
      <main role="main">
        <div data-md-component="container">
          
            
              
            
            
              
            
          
          <div>
            <article>
              
                
                  <a href="https://github.com/mikehearn/nodejvm/edit/master/docs/index.md" title="Edit this page">Óèâ</a>
                
                
                
<p>This repository demonstrates how to use NodeJS/npm modules directly from Java and Kotlin. Why is it useful:</p>
<ul>
<li>Gain access to unique JavaScript modules, like the Dat peer to peer file sharing framework shown in the samples.</li>
<li>Combine your existing NodeJS and Java servers together, eliminating the overheads of REST, serialisation, two separate
  virtual machines. Simplify your microservices architecture into being a polyglot architecture instead.</li>
<li>Use it to start porting NodeJS apps to the JVM world and languages, incrementally, one chunk at a time, whilst always
  having a runnable app. Or do the reverse.</li>
</ul>
<h2 id="how-does-it-work">How does it work?<a href="#how-does-it-work" title="Permanent link">¬∂</a></h2>
<p><a href="https://www.graalvm.org/">GraalVM</a> is a modified version of OpenJDK that includes the cutting edge Graal and Truffle compiler infrastructure.
It provides an advanced JavaScript engine that has competitive performance with V8, and also a modified version of
NodeJS 10 that swaps out V8 for this enhanced JVM. In this way you can fuse together NodeJS and the JVM, allowing apps
to smoothly access both worlds simultaneously with full JIT compilation.</p>
<h2 id="known-limitations">Known limitations<a href="#known-limitations" title="Permanent link">¬∂</a></h2>
<p>NodeJS really wants to load module files from the filesystem and nowhere else, so your Java app will need a <code>node_modules</code>
directory from where it's started. There are tricks to work around this and allow bundling of JS into JAR files as
libraries, but nothing done at the moment.</p>
<p>GraalVM uses NodeJS 10, not the latest versions.</p>
<p>You change <code>java</code> on the command line to <code>nodejvm</code> and that's all it needs, but many tools and IDEs expect the java
launcher to always be called <code>java</code>.  </p>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        

      
    </div></div>]]>
            </description>
            <link>https://mikehearn.github.io/nodejvm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058252</guid>
            <pubDate>Wed, 11 Nov 2020 13:36:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Headless E-Commerce and Jamstack]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058125">thread link</a>) | @rcymerys
<br/>
November 11, 2020 | https://upsidelab.io/blog/e-commerce-headless-jamstack/ | <a href="https://web.archive.org/web/*/https://upsidelab.io/blog/e-commerce-headless-jamstack/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The Web has gone a tremendously long way since it's conception in 1989. It has progressed to the point where it‚Äôs so omnipresent and the user base is so vast that it‚Äôs becoming harder and harder to scale and expand existing services to satisfy the ever growing demand. &nbsp;The <em>traditional </em>architecture is starting to show its limitations and suddenly it‚Äôs becoming clear that what was considered <strong>the way</strong> to develop web applications is not going to cut it under the current circumstances.</p><p><strong>Monolithic architecture</strong></p><p>Also known as the <em>traditional </em>architecture, is what powers the vast majority of what the Web has to offer. It‚Äôs the all-in-one bundle of web applications - the backend is tightly coupled with the frontend and the whole app is just one big ecosystem.</p><figure><img src="https://publish.upsidelab.io/blog/content/images/2020/09/final4.png" alt=""><figcaption>The monolithic architecture</figcaption></figure><p>For a big chunk of time this approach was the undisputed king of web development. And while it‚Äôs without a doubt still reigning and growing steadily, the consumer trends evolve in a direction that makes many service providers reconsider the usage of this kind of tools, namely WordPress.</p><p>Back in the day running a website was enough to ensure that you target the majority of Internet dwellers. Nowadays, thanks to some monumental advancements in technology, the users have many more ways to go online - phones, smartwatches, voice assistants, AR glasses etc.</p><figure><img src="https://publish.upsidelab.io/blog/content/images/2020/09/monolith_fail2.png" alt=""><figcaption>A monolith's problems with multi-channelled user base</figcaption></figure><p>This makes one of the problems very clear - because of how tightly coupled the presentational layer is with the backend logic it‚Äôs a major hassle (or downright impossible) to expand the application so it can support more channels than it was originally designed to do.</p><p>For example, one could imagine that it would be solvable by running multiple instances of the application, each designed to handle a specific medium. Apart from the obvious development overhead this would generate, managing multiple systems simultaneously would be a major headache - e.g. in e-commerce websites product discounts would have to be entered and synchronized separately for each running instance.</p><p>This is especially true for businesses that are heavily reliant on how accessible their web services are, most notably e-commerce websites. Expansion beyond the web is often the key to new market penetration and is often what distinguishes ‚Äújust‚Äù successful ventures from market leaders.</p><p>Another thing that caused the shift away from monolithic architecture is the fact that the server would render pages visited by users with each request. This greatly impacts the user experience and makes the website feel less ‚Äúsnappy‚Äù.</p><p>While this is but a drop in the sea of shortcomings, it‚Äôs what widely believed to be the turning point and reason why alternative solutions are gaining traction exponentially.</p><p><strong>Headless architecture</strong></p><p>Despite its <em>buzzwordy</em> status nowadays, the concept of <em>headless </em>software is dead simple and has been around for ages. ‚ÄúHead‚Äù in this context means ‚Äúgraphical interface‚Äù - you can probably see where this is going. The <em>headless </em>approach completely removes the presentational layer, leaving just the backend logic that can be exposed through a universally accessible API layer.</p><figure><img src="https://publish.upsidelab.io/blog/content/images/2020/09/headless2.png" alt=""><figcaption>The headless architecture</figcaption></figure><p>Instead of a singular, tightly coupled with the logic and heavily specialized frontend, its focused on providing applications with the raw content/services it offers. One of such apps can be responsible for consuming the data and presenting it to the end user.</p><p>That‚Äôs precisely what‚Äôs needed when it comes to building multi-channel applications. Since the presentational layer is completely interchangeable and the core API is universally accessible, there could be multiple entry points interacting with the app, each designed to support a different medium.</p><figure><img src="https://publish.upsidelab.io/blog/content/images/2020/09/headless2-1-.png" alt="" srcset="https://publish.upsidelab.io/blog/content/images/size/w600/2020/09/headless2-1-.png 600w, https://publish.upsidelab.io/blog/content/images/size/w715/2020/09/headless2-1-.png 715w"><figcaption>Headless handling multi-channeled user base</figcaption></figure><p><strong>External integrations</strong></p><p>Nowadays, a big portion of an application‚Äôs features can be extracted to third-party SaaS platforms. Not only does this reduce a product‚Äôs time-to-market but, since they usually cover some highly technical features, can also improve the systems overall security. Some of them could be payment gateways, delivery services, ERP systems etc.</p><p>The most common monolithic choice on the Web is WordPress - a staple among traditional Content Management Systems. It offers a user-friendly interface for managing content and basic customizability through various plugins. There are extensions providing integrations with the most <em>common</em> of services which could prove sufficient for some very generic applications.</p><p>The word ‚Äúcommon‚Äù was emphasised for a reason though. If the chosen platform doesn‚Äôt offer a specific plugin that is required by the project‚Äôs requirements, there is no other way but to either write it from scratch (often in some obscure technology) or change the platform. Keep in mind that even the largest of traditional CMSs doesn‚Äôt support a portion of the third-party platforms, so you can expect to run into situations where a part of your project‚Äôs scope gets blocked by an unexisting plugin.</p><p>On the other hand, headless architecture ties in very nicely with external services and applications. As emphasised before, headless benefits greatly by dividing its functionalities between multiple components. To draw comparison with the aforementioned WordPress, we can consider what‚Äôs called a <em>headless CMS</em>, such as GraphCMS or Contentful. It provides the same functionality, that is content storage and a user friendly administration panel, without coupling it with any presentational layer and crippling it‚Äôs extendability in the process.</p><p><strong>Scalability</strong></p><p>At first glance scaling monolithic applications seems trivial - multiple instances of it can be hidden behind a load balancer to scale horizontally. However, as the application grows in size, scaling becomes increasingly difficult and inefficient.</p><p>For example, it‚Äôs impossible to scale one single part of the application independently. In cases when there are few different bottlenecks scaling the entire system is very cost inefficient.</p><p>Moreover, for stateful applications, you have to take user sessions into account and incorporate mechanisms like <em>sticky sessions </em>to ensure that users with existing sessions are routed to the same physical machine each time.</p><p>On the other hand, it‚Äôs easy to imagine how headless can improve scalability - the application can be divided into autonomous services and scaled independently.</p><p><strong>Workflow differences</strong></p><p>Apart from the obvious structural differences, both approaches differ heavily when it comes to implementation, maintenance and development workflow in general.</p><p>Developer teams working on large monolithic applications have to constantly be aware of all the systems components and it‚Äôs impossible to work on a single part independently.</p><p>Moreover, continuous deployment is, to put it lightly, problematic when working on monolithic apps. With each new release the entire application has to be redeployed. This forces teams working on different parts of the system, e.g. the UI and the business logic, to coordinate their deployments.</p><p>On the other hand the compartmentalised nature of headless architecture makes it an ideal choice for teams consisting of multiple developers. Each part of the application can be independently managed, tested and deployed without interfering with the rest of the system.</p><p><strong>Enter Jamstack</strong></p><p>Jamstack is one of the hottest trends in web development right now. It‚Äôs focused on certain assumptions and best practices rather than on certain technologies. The performance and security improvements it brings to the table make it very popular among modern website developers and service providers.</p><p>At its core is the premise that the frontend doesn‚Äôt depend on a web server. All dynamic data is requested and handled by <strong>J</strong>avascript, delivered through <strong>A</strong>PI‚Äôs and all the <strong>M</strong>arkup is pre-generated during build time. The entire application is then distributed through a Content Delivery Network which greatly increases the websites responsiveness and improves overall user experience.</p><figure><img src="https://publish.upsidelab.io/blog/content/images/2020/09/headless1-1.png" alt="" srcset="https://publish.upsidelab.io/blog/content/images/size/w600/2020/09/headless1-1.png 600w, https://publish.upsidelab.io/blog/content/images/size/w714/2020/09/headless1-1.png 714w"><figcaption>The Jamstack</figcaption></figure><p>Jamstack stands in complete opposition to traditional, monolithic applications. It shifts the focus from an omniscient, one-man-army backend to lean and powerful frontend. Extracting all logic to external API‚Äôs improves the sites overall security by reducing the number of potential attack vectors.</p><p>As it happens, Jamstack works hand in glove with headless applications.</p><p><strong>Headless + Jamstack in practice</strong></p><p>Building Jamstack websites has become very easy since the conception of tools such as Nuxt or Gatsby. They are based on tools very familiar to developers, Vue and React respectively, so they are right there in the comfort-zone.</p><p>Such frameworks intelligently build HTML files from templates filled with pre-fetched data so they can be served through CDNs as static assets. This, as one might expect, is a huge boost to the site‚Äôs performance, making navigation almost instantaneous. CDN service providers also make it easy to force the use of SSL on your sites (sometimes it‚Äôs as simple as flipping a switch), which can otherwise be problematic since, by design, there is no underlying server.</p><p>Serving static assets is not that useful if there is no way of populating the site with easily modifiable content. That‚Äôs where the aforementioned headless CMS‚Äôs come into play. They offer exactly the same content modeling functionality as traditional solutions, such as WordPress, and expose it through a blazing fast API. The chosen Jamstack framework will pre-fetch all the data it needs during the page generation phase and build static HTML files according to the templates that were defined. That‚Äôs an ideal setup for websites like blogs or product catalogs, where user interaction is scarce and content serving speed is the main bottleneck.</p><p>There is one caveat though - since the pages are pre-generated, they won‚Äôt automatically display new content that was created. A good majority of SaaS‚Äôs offer a well-known mechanism to automatically trigger rebuilds when a change in content is ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://upsidelab.io/blog/e-commerce-headless-jamstack/">https://upsidelab.io/blog/e-commerce-headless-jamstack/</a></em></p>]]>
            </description>
            <link>https://upsidelab.io/blog/e-commerce-headless-jamstack/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058125</guid>
            <pubDate>Wed, 11 Nov 2020 13:22:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Defense of GnuPG]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058064">thread link</a>) | @m3rcury
<br/>
November 11, 2020 | https://www.oyd.org.tr/en/articles/defense-of-gpg/ | <a href="https://web.archive.org/web/*/https://www.oyd.org.tr/en/articles/defense-of-gpg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">
  <article>
    
     
      
    <p>For several years, there has been an uprasing against GPG. Every now and then someone writes up a blog post and condemn OpenPGP and it‚Äôs implementations for being too hard to use or too easy to mess up. The GPG side is mostly silent. So, this article is in defence of GPG.</p>
<p>Main points made against GPG can be listed like this:</p>
<ol start="0">
<li>GPG is too complicated for ‚Äúnormal‚Äù users</li>
<li>Because GPG is too complicated, it‚Äôs userbase is minuscule</li>
<li>Email is inherently impossible to secure so don‚Äôt even bother encrypting it. Just abandon GPG</li>
<li>Nobody bothers to read emails of ‚Äúnormal‚Äù people so don‚Äôt encrypt</li>
<li>TLS has done much more for email security than GPG</li>
<li>GPG is error prone and security wise it is dangerous for people to use it when actual security is needed</li>
<li>For various reasons, only cryptonerds use it and take pride on GPG so it is lame</li>
<li>GPG‚Äôs trust model (web of trust) is broken and only cryptonerds are keeping it alive</li>
<li>GPG is old</li>
<li>There are better [insert anything involving app like crypto tool] why bother with GPG</li>
<li>GPG crypto has [Insert any long term RSA based cryptography‚Äôs short comings and trust problems] why not use modern crypto</li>
</ol>
<p>During these discussion, these point are mostly assumed to be true;</p>
<ol start="0">
<li>People are stupid and lazy so are the users of encryption tools</li>
<li>Since users are stupid and lazy tools should be designed keeping that in mind</li>
<li>Designing for stupid and lazy requires stripping people from anything than needed(i.e freedom)</li>
<li>If security is not absolute it is worthless</li>
<li>If privacy is not absolute, anonymity is worthless</li>
<li>If your adversary cannot compromise  of your security then there is no need for GPG even for privacy</li>
</ol>
<h2 id="whats-the-problem">What‚Äôs The Problem</h2>
<p>We name periods of human history by their defining property. That property is mainly what drives human society and culture at that current age. The iron age was shaped by the superiority of iron as a material for weapons and agricultural tools. Today‚Äôs digitally shaped age is called <a href="https://www.schneier.com/essays/archives/2012/11/when_it_comes_to_sec.html">digital feudalism</a> and it governs our lives. Just like regular feudalism the resources of society is controlled by few, generated by many and the feudal lords of ours claim their right to their thrones through their infrastructure.</p>
<p>We as users are fueling the rise of the digital technologies but handful of companies are controlling and profiting from it. Just like peasants of the middle ages, you are seen as basic people who cannot understand the complex life that only a few selected elites can. It is what you are asusmed to be: simple people who wants simple things, like ‚Äúapps‚Äù that will give you what you assumed to need and nothing more. It is the same old condescending view of serfs, now given to you by companies, ignorant and arrogant developers and overall by capitalism.</p>
<p>Today saying ‚Äúwhat do I understand about computers‚Äù is equivalent to saying ‚ÄúI don‚Äôt know how to light a fire‚Äù in stone age! Just because someone might be feeding you back in those days did not mean that you could survive on your own. The same applies to current digital age. Just because someone is doing <strong>stuff</strong> for you does not ensure your digital survival. There was no easy way to light a fire back then and there will be no ‚Äúpress this button‚Äù easy way to take back the power in the digital age. Whoever claims people <strong>want</strong> or <strong>need</strong> only simple stupid apps and whoever denies the fact that we are living in digital feudalism are building a dystopian future where few elite unprecedentedly controls the future. Self determination is never given by anyone but can only be taken by everyone!</p>
<p>This ideology that ‚Äúpeople are stupid‚Äù and ‚Äúpeople want easy(read:stupid)‚Äù things dominates today‚Äôs end user software development. Good UX does not equal to simple. The real meaning in these expressions is: ‚Äúyou are too stupid to take responsibility for your self and to understand what‚Äôs going on, so we as technological elites will take care of you‚Äù. This is what‚Äôs the base of almost all GPG related criticism. GPG is too hard for people!</p>
<p>PGP, the preceder of GPG, was conceived in 1991 and this era was shaped by hackers. Not the hackers that main stream media shows in black hoods and authorities around the world paint as people with no moral boundaries. Hackers are the people who playfully expanded what is available to what is possible. This attitude brought general public; personal computers, GNU/Linux operating system that are now powering almost every backbone in the world, 3D printers etc. PGP was shaped by the empowerment of that era, not the ‚Äúthere is an app for that‚Äù era of today which is shaped by multi-billion dollar cooperation built upon the cultural and technological accumulation of hackers.</p>
<p>That brings us to the point: GPG is hard for people, but so were the general purpose computers around 20 years ago. Everything requires individual dedication and determination to learn and maintain. What happened with computers is that some people capitalised on the opportunity, poured money into devices and after hundreds of hours long R&amp;D those computers became ‚Äúeasy‚Äù. The outcome of that process was loss of the right to fix, more enclosed and restricted user environments and computers that works against us! So those who invested in computers can profit from their investment.</p>
<p>The same problem also exists for encryption. There was no real incentive for capitalists to invest in publicly accessible encryption. Solid encryption would make reaching data possible only for the user who owns it and this would be counter intuitive to the interest of capitalism. But today there is an incentive: people are afraid of what our digital world has become. They are afraid of their <a href="https://en.wikipedia.org/wiki/Global_surveillance_disclosures_(2013%E2%80%93present)">government‚Äôs abuse of power</a>, they are afraid of <a href="https://www.theguardian.com/technology/2017/sep/26/tinder-personal-data-dating-app-messages-hacked-sold">companies taking advantage of their lives</a>, they are afraid that their <a href="https://en.wikipedia.org/wiki/Facebook%E2%80%93Cambridge_Analytica_data_scandal">involment in democracy will be lost</a>. People are afraid and there is no better time to sell something. That‚Äôs why Apple is now selling <a href="https://en.wikipedia.org/wiki/FBI%E2%80%93Apple_encryption_dispute">privacy as a product</a> and that is why every communication service regardless their privacy invasive tendencies are <a href="https://faq.whatsapp.com/en/android/28030015/">promoting encryption</a>. What is missing is that people are still an object in this case. Whoever holds the key holds the future and there is no alternative to GPG that gives the user the best self determination!</p>
<p>So, how is GPG doing while the craze to own next killer encryption app continiue? <a href="https://en.wikipedia.org/wiki/Werner_Koch"><strong>Werner Koch</strong></a>, is the single person maintaining GPG. He was almost about to give up on GPG for <a href="https://www.propublica.org/article/the-worlds-email-encryption-software-relies-on-one-guy-who-is-going-broke">economic reasons</a> when the <a href="https://en.wikipedia.org/wiki/Edward_Snowden">Snowden incident</a> has chanced his decision. The world‚Äôs whole server infrastructure security and personal freedom rests on his shoulder and he had to ask for help. It is a huge difference in investment/impact ratio when compared to every other encryption tool. GPG exist by determination and not through capital pressure.</p>
<p>In every ‚ÄúGPG is dead‚Äù cry almost always includes some <strong>killer</strong> new technology that makes more <strong>sense</strong> than GPG. Let‚Äôs talk about them for a while.</p>
<h2 id="signal">Signal</h2>
<p>A big hit in secure instant messaging. Signal is build upon proprietary software Textsecure and RedPhone that had been once developed by <a href="https://en.wikipedia.org/wiki/Moxie_Marlinspike">Moxie Merlinspike</a> and his co-founder Stuart Anderson. Signal Protocol utilizing <a href="https://en.wikipedia.org/wiki/Double_Ratchet_Algorithm">double ratchet</a> encryption is a game changer for modern connectivity and implemented in [several applications[(https://signal.org/blog/whatsapp-complete/). Signal applications and server code is free software but <a href="https://oyd.org.tr/en/articles/stop-saying-freedom-is-a-private-matter/">their developers and business model is not</a>. It is <a href="#https://matrix.org/blog/2020/01/02/on-privacy-versus-freedom/">yet another walled garden with no federation</a> and <a href="https://moxie.org/blog/gpg-and-me/">claiming GPG is dead</a>.</p>
<h2 id="matrix-protocol">Matrix Protocol</h2>
<p><a href="https://en.wikipedia.org/wiki/Matrix_(protocol)">Matrix protocol</a> is an open standard for general communication needs. Like <a href="https://en.wikipedia.org/wiki/Xmpp">XMPP -Extensible Messaging and Presence Protocol-</a> it is designed to be implemented widely and serve various modern needs of communication. End-to-end encryption is falling behind and there are still implementation problems but if everything goes well Matrix Protocol could be a modern free future for communication. The only problem is that Matrix Protocol is still an instant communication system and the cryptography behind it is specialized only for that purpose.</p>
<h2 id="insert-any-app-or-protocol">[Insert Any App or Protocol]</h2>
<p>Almost all have some of these short comings:</p>
<ul>
<li>Walled Gardens with no federation</li>
<li>Non-free dependencies</li>
<li>Single purpose</li>
<li>Symmetrical communication while e-mail being asymmetrical</li>
<li>Opaque key generation and management</li>
</ul>
<p>Modern messaging softwares do have merits that are desirable such as <a href="https://en.wikipedia.org/wiki/Forward_secrecy">forward secrecy</a>, <a href="https://en.wikipedia.org/wiki/Elliptic_curve_cryptography">recent algorithms with shorter keys</a>(read: not necessarily more secure) and more frictionless key management(which heavily depends on central key servers and personal data). All these merits are, to some degree, desireable for GPG too but those tool‚Äôs have different design requirements than GPG. GPG can and will become better at most points. When the case is single person against a multi-billion dollar industry, this should not count as a fair trial.</p>
<p>What GPG is offering in exchange is <strong>freedom</strong>, not just another ‚Äúapp‚Äù that walls it‚Äôs users in and here is why:</p>
<h2 id="gpg-giving-you-the-total-control-of-your-key-and-identity">GPG giving you the TOTAL control of your key and identity</h2>
<p>This primary point is so important, the rest seems moot. GPG is the most liberating piece of software EVER. What GPG is capable of and how it is implemented almost always secondary to the fact that <strong>you</strong> as the user in need of cryptography <strong>control</strong> the key. You can export it, expand it, change it, renew it, <a href="https://github.com/intra2net/paperbackup">print it on paper</a>, revoke it. The fact that you own and control your key actually makes it possible for you to build your identity around that key. This is almost like being your own certificate authority and issuing your certificates as you please.</p>
<p>This comes with the trust problem of cryptopgraphy. If anyone can generate a key with any metadata, then who is deciding on a particular key belong to an individual. The answer is <strong>no one</strong> and <strong>everyone</strong>. <a href="https://en.wikipedia.org/wiki/Web_of_trust">Web of trust</a> is an answer to this question for most part. You basically sign keys of people who you know and the people who trust you, trusts your friends.</p>
<p>This implementation is <a href="https://web.archive.org/web/20131009142806/https://www.rubygems-openpgp-ca.org/blog/theres-trust-and-then-theres-trust-and-then-theres-trust.html">considered broken</a> by a lot of people and there is a natural down side of making your social network public. That being said building trust ‚Ä¶</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.oyd.org.tr/en/articles/defense-of-gpg/">https://www.oyd.org.tr/en/articles/defense-of-gpg/</a></em></p>]]>
            </description>
            <link>https://www.oyd.org.tr/en/articles/defense-of-gpg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058064</guid>
            <pubDate>Wed, 11 Nov 2020 13:14:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Graphical Output from Our Custom RISC-V Operating System in Rust]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058039">thread link</a>) | @pavehawk2007
<br/>
November 11, 2020 | https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/ | <a href="https://web.archive.org/web/*/https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
								
								<div>
									
<p>An operating system is used to make our job easier when using graphics. In our instance, in addition to everything else. In this post, we will be writing a GPU (graphics processing unit) driver using the VirtIO specification. In here, we will allow user applications to have a portion of the screen as RAM‚Äìwith what is commonly known as a <em>framebuffer</em>.</p>



<hr>



<h2>Contents</h2>



<ol><li><a href="#overview">Overview</a></li><li><a href="#pixels">Pixels and Resolution</a></li><li><a href="#virtio">The GPU VirtIO Device</a></li><li><a href="#init">Initialization</a></li><li><a href="#invalid">Invalidation and Transfer</a></li><li><a href="#response">Device Responses</a></li><li><a href="#user">User Space</a></li><li><a href="#api">Simple Graphics API</a></li><li><a href="#conclusion">Conclusions and Further Reading</a></li></ol>



<hr>



<h2 id="overview">Overview</h2>



<p>We command the virtual GPU (virtio-gpu) by sending certain commands to the host (the device). The guest (the OS driver) has an allocation of RAM that becomes the framebuffer. The driver then tells the device, ‚Äúhey, here‚Äôs the RAM that we‚Äôre going to use to store pixel information.‚Äù</p>



<p>The RAM is contiguous in our OS, but according to the specification, this isn‚Äôt strictly required. We will give the driver a rectangle. Everything that falls within that rectangle will be copied to the host. We don‚Äôt want to keep copying the entire buffer over and over again.</p>



<p>We will be using the virtio protocol that we used for the block driver here, so I won‚Äôt rehash the general virtio protocol. However, the device-specific structures are a bit different, so we‚Äôll cover that part more in depth.</p>



<hr>



<h2 id="pixels">Pixels and Resolution</h2>



<p>A framebuffer must be large enough to store \(\text{width}\times\text{height}\times\text{pixel size}\) number of bytes. There are \(\text{width}\times\text{height}\) number of pixels. Each pixel has a 1-byte red, green, blue, and alpha channels. So, each pixel is exactly 4 bytes with the configuration we‚Äôre going to specify.</p>



<p>The framebuffer for our junior GPU driver is going to support a fixed resolution of \(640\times 480\). If you‚Äôre a child of the 90s, you saw this resolution a lot. In fact, my first computer, a Laser Pal 386, had a 16-color monitor with a resolution of 640 pixels wide with 480 pixels tall.</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png" alt="" width="458" height="281" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png 611w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13-300x184.png 300w" sizes="(max-width: 458px) 100vw, 458px"></a></figure></div>



<p>There are red, green, and blue pixels so close together that by varying the intensity of these three channels, we can change the color. The closer we get to our monitors, the easier a pixel is to see.</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png" alt="" width="285" height="288" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png 380w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14-297x300.png 297w" sizes="(max-width: 285px) 100vw, 285px"></a><figcaption>Pixels on a Viewsonic VX2770SMH-LED monitor.</figcaption></figure></div>



<p>You can see these little squares. If you squint enough, you can see that they aren‚Äôt pure white. Instead, you can see bits of red, blue, and green. That‚Äôs because each one of these little squares is subdivided into three colors: yep, red, green, and blue! To make white, these pixels are turned up to 11 (get the joke?). To make black, we turn off all three channels of that pixel.</p>



<p>The resolution refers to how many of these squares are on our monitor. This is a 1920√ó1080 monitor. That means that there are 1920 of these squares going left to right, and there are 1080 of these squares from top to bottom. All in all, we have \(1920\times 1080=2,073,600\) number of pixels. Each one of these pixels is expressed using 4 bytes in the framebuffer, meaning we need \(2,073,600\times 4=8,294,400\) bytes in RAM to store the pixel information.</p>



<p>You can see why I limited our resolution to 640√ó480, which only requires \(640\times 480\times 4=1,228,800\) bytes‚Äìa bit over a megabyte.</p>



<hr>



<h2 id="virtio">The GPU VirtIO Device</h2>



<p>The GPU device requires us to read a more up-to-date VirtIO specification. I‚Äôll be reading from version 1.1, which you can get a copy here: <a href="https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.html">https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.html</a>. Specifically, chapter 5.7 ‚ÄúGPU Device‚Äù. This is an <em>unaccelerated</em> 2D device, meaning that we must use the CPU to actually form the framebuffer, then we transfer our CPU formulated memory location to the host GPU, which is then responsible for drawing it to the screen.</p>



<p>The device uses a request/response system, where we the driver make a command to request something from the host (the GPU).  We add a bit of extra memory into our request so that the host can formulate its response. When the GPU interrupts us, we can take a look at this response memory location to see what the GPU told us. This is much like the <em>status</em> field on the block driver, where the block device tells us the status of our last request.</p>



<p>Each request starts with a <em>Command Header</em>, which in Rust looks as follows:</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(C)]
struct CtrlHeader {
	ctrl_type: CtrlType,
	flags: u32,
	fence_id: u64,
	ctx_id: u32,
	padding: u32
}</pre>



<p>The header is common for all requests and all responses. We can differentiate by the CtrlType enumeration, which is:</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(u32)]
enum CtrlType {
	/* 2d commands */
	CmdGetDisplayInfo = 0x0100,
	CmdResourceCreate2d,
	CmdResourceUref,
	CmdSetScanout,
	CmdResourceFlush,
	CmdTransferToHost2d,
	CmdResourceAttachBacking,
	CmdResourceDetachBacking,
	CmdGetCapsetInfo,
	CmdGetCapset,
	CmdGetEdid,
	/* cursor commands */
	CmdUpdateCursor = 0x0300,
	CmdMoveCursor,
	/* success responses */
	RespOkNoData = 0x1100,
	RespOkDisplayInfo,
	RespOkCapsetInfo,
	RespOkCapset,
	RespOkEdid,
	/* error responses */
	RespErrUnspec = 0x1200,
	RespErrOutOfMemory,
	RespErrInvalidScanoutId,
	RespErrInvalidResourceId,
	RespErrInvalidContextId,
	RespErrInvalidParameter,
}</pre>



<p>I took this directly from the specification, but Rust-ified the names to avoid getting yelled at by the linter.</p>



<h3>Pixel Formats</h3>



<p>Recall that the framebuffer is just a bunch of bytes in memory. We need to put a structure behind the framebuffer so the host (the GPU) knows how to interpret your sequence of bytes. There are several formats, but all-in-all, they just re-arrange the red, green, blue, and alpha channels. All are exactly 4 bytes, which makes the <em>stride</em> the same. The stride is the spacing from one pixel to another‚Äì4 bytes.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(u32)]
enum Formats {
	B8G8R8A8Unorm = 1,
	B8G8R8X8Unorm = 2,
	A8R8G8B8Unorm = 3,
	X8R8G8B8Unorm = 4,
	R8G8B8A8Unorm = 67,
	X8B8G8R8Unorm = 68,
	A8B8G8R8Unorm = 121,
	R8G8B8X8Unorm = 134,
}</pre>



<p>The type, <em>unorm</em>, is an 8-bit (1-byte) unsigned value from 0 through 255, where 0 represents no intensity and 255 represents full intensity, and a number in between is a linear-interpolation between no and full intensity. Since there are three color (and one alpha), that gives us \(256\times 256\times 256=16,776,216\) different colors or levels of colors.</p>



<p>For this tutorial, I selected <code>R8G8B8A8Unorm = 67</code>, which has red first, green second, blue third, and alpha fourth. This is a common ordering, so I‚Äôll select it to make it easy to follow along.</p>



<p>Our selected format makes the pixel structure look as follows:</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1024x614.png" alt="" width="512" height="307" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1024x614.png 1024w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-300x180.png 300w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-768x461.png 768w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1536x921.png 1536w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-2048x1228.png 2048w" sizes="(max-width: 512px) 100vw, 512px"></a></figure></div>



<p>Recall that each individual component R, G, B, and A are each one byte a piece, so each Pixel referred to by (x, y) is 4 bytes. This is why our memory pointer is a Pixel structure instead of a byte.</p>



<hr>



<h2 id="init">Initialization</h2>



<p>Just like all other virtio devices, we set up the virtqueues first and then we work on device-specific initialization. In my code, I just directly copied-and-pasted from the block driver into the gpu driver. The only thing I added to the Device structure was the framebuffer and dimensions of the framebuffer.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">pub struct Device {
	queue:        *mut Queue,
	dev:          *mut u32,
	idx:          u16,
	ack_used_idx: u16,
	framebuffer:  *mut Pixel,
	width:        u32,
	height:       u32,
}</pre>



<p>The specification tells us to do the following in order to initialize the device and get things ready to draw. I Rust-ified some of the content to match our enumerations.</p>



<h4>Create a framebuffer and configure scanout</h4>



<ol><li>Create a host resource using <code>CmdResourceCreate2d</code>.</li><li>Allocate a framebuffer from guest ram, and attach it as backing storage to the resource just created, using <code>CmdResourceAttachBacking</code>.</li><li>Use <code>CmdSetScanout</code> to link the framebuffer to a display scanout.</li></ol>



<h3>A Request Structure</h3>



<p>Recall that our request and response come packaged together. We will put them in separate descriptors, but whenever we get a response back from the device, it is going to be easier if we free just once to free both the request and response. So, in Rust, I created the Request structure to support doing this.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">struct Request&lt;RqT, RpT&gt; {
	request: RqT,
	response: RpT,
}
impl&lt;RqT, RpT&gt; Request&lt;RqT, RpT&gt; {
	pub fn new(request: RqT) -&gt; *mut Self {
		let sz = size_of::&lt;RqT&gt;() + size_of::&lt;RpT&gt;();
		let ptr = kmalloc(sz) as *mut Self;
		unsafe {
			(*ptr).request = request;
		}
		ptr
	}
}</pre>



<h4>Step 1: Create host resource</h4>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">let rq = Request::new(ResourceCreate2d {
	hdr: CtrlHeader {
		ctrl_type: CtrlType::CmdResourceCreate2d,
		flags: 0,
		fence_id: 0,
		ctx_id: 0,
		padding: 0,
	},
	resource_id: 1,
	format: Formats::R8G8B8A8Unorm,
	width: dev.width,
	height: dev.height,
});
let desc_c2d = Descriptor {
	addr: unsafe { &amp;(*rq).request as *const ResourceCreate2d as u64 },
	len: size_of::&lt;ResourceCreate2d&gt;() as u32,
	flags: VIRTIO_DESC_F_NEXT,
	next: (dev.idx + 1) % VIRTIO_RING_SIZE as u16,
};
let desc_c2d_resp = Descriptor {
	addr: unsafe { &amp;(*rq).response as *const CtrlHeader as u64 },
	len: size_of::&lt;CtrlHeader&gt;() as u32,
	flags: VIRTIO_DESC_F_WRITE,
	next: 0,
};
unsafe {
	let head = dev.idx;
	(*dev.queue).desc[dev.idx as usize] = desc_c2d;
	dev.idx = (dev.idx + 1) % VIRTIO_RING_SIZE as u16;
	(*dev.queue).desc[dev.idx as usize] = desc_c2d_resp;
	dev.idx = (dev.idx + 1) % VIRTIO_RING_SIZE as u16;
	(*dev.queue).avail.ring[(*dev.queue).avail.idx as usize % VIRTIO_RING_SIZE] = head;
	(*dev.queue).avail.idx = (*dev.queue).avail.idx.wrapping_add(1);
}</pre>



<p>All we‚Äôre really telling the GPU here is our resolution and the format of the framebuffer. When we create this, the host gets to configure itself, such as allocating an identical buffer to make transfers from our OS.</p>



<h4>Step 2: Attach framebuffer backing.</h4>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">let rq = Request3::new(AttachBacking {
	hdr: CtrlHeader {
		ctrl_type: CtrlType::CmdResourceAttachBacking,
		flags: 0,
		fence_id: 0,
		ctx_id: 0,
		padding: 0,
	},
	resource_id: 1,
	nr_entries: 1,
},
MemEntry {
	addr: dev.framebuffer as u64,
	length: dev.width * dev.height * size_of::&lt;Pixel&gt;() as u32,
	‚Ä¶</pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/">https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/</a></em></p>]]>
            </description>
            <link>https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058039</guid>
            <pubDate>Wed, 11 Nov 2020 13:11:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visualization of connections between politicians and orgs awarded gov contracts]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25057931">thread link</a>) | @roxanneonhacker
<br/>
November 11, 2020 | https://sophieehill.shinyapps.io/my-little-crony/ | <a href="https://web.archive.org/web/*/https://sophieehill.shinyapps.io/my-little-crony/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>
          A visualization of the connections between
          <strong>Tory politicians</strong>
          and
          <strong>companies being awarded government contracts during the pandemic,</strong>
          based on reporting by
          <a href="https://www.opendemocracy.net/en/dark-money-investigations/">openDemocracy,</a>
          <a href="https://bylinetimes.com/">Byline Times,</a>
          and more.
        </p>
    </div></div>]]>
            </description>
            <link>https://sophieehill.shinyapps.io/my-little-crony/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057931</guid>
            <pubDate>Wed, 11 Nov 2020 12:57:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advanced System-on-Chip Design Lecture Notes]]>
            </title>
            <description>
<![CDATA[
Score 204 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25057889">thread link</a>) | @allending
<br/>
November 11, 2020 | https://iis-people.ee.ethz.ch/~gmichi/asocd/lecturenotes/ | <a href="https://web.archive.org/web/*/https://iis-people.ee.ethz.ch/~gmichi/asocd/lecturenotes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://iis-people.ee.ethz.ch/~gmichi/asocd/lecturenotes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057889</guid>
            <pubDate>Wed, 11 Nov 2020 12:51:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[92% efficacy of Sputnik V Covid-19 vaccine]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057881">thread link</a>) | @pama
<br/>
November 11, 2020 | https://sputnikvaccine.com/newsroom/pressreleases/the-first-interim-data-analysis-of-the-sputnik-v-vaccine-against-covid-19-phase-iii-clinical-trials-/ | <a href="https://web.archive.org/web/*/https://sputnikvaccine.com/newsroom/pressreleases/the-first-interim-data-analysis-of-the-sputnik-v-vaccine-against-covid-19-phase-iii-clinical-trials-/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<ul>
<li><i>The Sputnik V vaccine efficacy amounted to 92% (calculation based on the 20 confirmed COVID-19 cases split between vaccinated individuals and those who received the placebo). Currently 40,000 volunteers are taking part in double-blind, randomized, placebo-controlled Phase III of Sputnik V clinical trials, out of which over 20,000 have been vaccinated with the first dose of the vaccine and more than 16,000 with both the first and second doses of the vaccine. </i></li>
<li><i>Efficacy was demonstrated on the basis of a first interim analysis obtained 21 days after the first injection. </i></li>
<li><i>There were no unexpected adverse events during the trials. Monitoring of the participants is ongoing. </i></li>
<li><i>The world‚Äôs first registration of COVID-19 vaccine, done in Russia on the 11th of August under the emergency use authorization mechanism, enables the Russian Federation to administer the vaccine outside of the clinical trials to volunteers such as medics and other high-risk groups. Trials conducted under the civil use of the vaccine in Russia (not being a part of clinical trials) based on the monitoring of additional 10,000 vaccinated confirmed vaccine efficacy at a rate of over 90%. </i></li>
<li><i>The interim research data will be published by the Gamaleya Center team in one of the leading international peer-reviewed medical journals. Following the completion of Phase III clinical trials of the Sputnik V vaccine, Gamaleya Center will provide access to the full clinical trial report. </i></li>
<li><i>Currently Sputnik V Phase III clinical trials are approved and are undergoing in Belarus, UAE, Venezuela and other countries, as well as Phase II-III ‚Äì in India. </i></li>
<li><i>The Sputnik V vaccine is based on a well-studied human adenoviral vector platform that had proven safe and effective with no long-term side effects in more than 250 clinical trials globally conducted during the past two decades (while the history of use of human adenoviruses in vaccine development started in 1953). More than 100,000 people have received approved and registered drugs based on the human adenoviral vectors. </i></li>
<li><i>The uniqueness of the Russian vaccine is in using two different human adenoviral vectors that enable to provide strong and long-term immune response after the second injection.</i> </li>
</ul>
<p>
<b>Moscow, 11.11.2020</b> ‚Äì The National Research Center for Epidemiology and Microbiology named after N.F. Gamaleya of the Ministry of Health of the Russian Federation (Gamaleya Center) and the Russian Direct Investment Fund (RDIF, Russia‚Äôs sovereign wealth fund), announce that the Sputnik V vaccine, the world's first registered vaccine against coronavirus (registered on the 11th of August under the emergency use authorization mechanism) created on the well-studied platform of human adenoviral vectors, demonstrated high efficacy. The confirmation is based on the first interim data from the largest double-blind, randomized, placebo-controlled Phase III clinical trials in Russia involving 40,000 volunteers.
</p>
<p>
The trials evaluated efficacy among over 16,000 volunteers who received the vaccine or placebo 21 days after the first injection. As a result of a statistical analysis of 20 confirmed cases of coronavirus, the case split between vaccinated individuals and those who received the placebo indicates that the Sputnik V vaccine had an efficacy rate of 92% after the second dose.
</p>
<p>
Separately, in September the vaccine was first administered to a group of volunteers from the ‚Äúred zones‚Äù of Russian hospitals. The observation of additional 10,000 vaccinated volunteers representing medics and other high-risk groups under the civil use of the vaccine out of clinical trials also confirmed the vaccine‚Äôs efficacy rate of over 90 percent.
</p>
<p>
The data received will be published by Gamaleya&nbsp;Center researchers in one of the world‚Äôs leading peer-reviewed medical academic journals following an independent valuation of the data by leading epidemiology experts. Following the completion of Phase III clinical trials of the Sputnik V vaccine, Gamaleya Center will provide access to the full clinical trial report.
</p>
<p>
As of November 11, as part of the clinical trials in Russia‚Äôs 29 medical centers, more than 20,000 volunteers were vaccinated with first dose and over 16,000 volunteers with the first and the second dose of the vaccine.
</p>
<p>
In addition, as of November 11, no unexpected adverse events were identified as part of the research. Some of those vaccinated had short-term minor adverse events such as pain at the injection site, flu-like syndrome including fever, weakness, fatigue, and headache.
</p>
<p>
During the clinical trials, the safety of the vaccine is constantly being monitored; information is analysed by the Independent Monitoring Committee comprising of leading Russian scientists. Collection, quality control and data processing is conducted in line with ICH GCP standards and involving active participation of Moscow‚Äôs Health Department and Crocus Medical, the contract research organization (CRO).
</p>
<p>
Observation of study participants will continue for six months after which the final report will be presented. Currently Sputnik V Phase III clinical trials are approved and are undergoing in Belarus, the UAE, Venezuela and other countries, as well as Phase II-III in India. A separate detailed study of the vaccine‚Äôs safety and immunogenicity for elderly people is being conducted.
</p>
<p>
The research data will be provided by RDIF to the national regulators of countries interested in purchasing the Russian vaccine in order to streamline the registration process.
</p>
<p>
<b>Mikhail Murashko, Minister of Health of the Russian Federation: </b><br>
‚ÄúThe use of the vaccine and the results of clinical trials demonstrate that it is an efficient solution to stop the spread of coronavirus infection, –∞ preventive healthcare tool, and this is the most successful path to defeat the pandemic.‚Äù
</p>
<p>
<b>Alexander Gintsburg, Gamaleya Center Director: </b><br>
‚ÄúThe publication of the interim results of the post-registration clinical trials that convincingly demonstrate Sputnik V vaccine‚Äôs efficacy gives way to mass vaccination in Russia against COVID-19 in the coming weeks. Thanks to the production scale up at new manufacturing sites, Sputnik V vaccine will soon be available for a wider population. This will break the current trend and lead to an eventual decrease in COVID-19 infection rates, first in Russia, then globally.‚Äù
</p>
<p>
<b>Denis Logunov, Gamaleya Center Deputy Director: </b><br>
‚ÄúPositive interim results of Phase III give reasons to expect a successful outcome of Sputnik V clinical trials. We will continue to process and analyse all the data and look to the future with optimism, expecting that results of our work will help end the pandemic sooner.‚Äù
</p>
<p>
<b>Kirill Dmitriev, CEO, Russian Direct Investment Fund: </b><br>
‚ÄúSputnik V is the first registered vaccine against COVID-19 in the world, the vaccine is based on safe and effective platform of human adenoviral vectors. More and more countries are recognizing the human adenoviral vector platform and plan to include these vaccines, as the most studied and known, in their respective national vaccine portfolio. I would also like to stress the importance of international cooperation and close partnership among vaccine-developing states. Vaccines should be above politics. The world needs a diversified portfolio of high-quality vaccines with Sputnik V, based on the well-tested human adenoviral vector platform, being an important element of it.‚Äù
</p>
<p>
The safety of vaccines based on human adenoviruses was confirmed in more than 75 international publications and more than 250 clinical trials conducted during the past two decades (while the history of use of human adenoviruses in vaccine development started in 1953). Adenovirus vectors are genetically modified viruses of the regular flu that cannot reproduce in a human body. When Sputnik V vaccine is used, the coronavirus itself does not enter the body as the vaccine only contains genetic information about part of its outer protein coat, the so called "spikes" forming its crown. This completely eliminates the possibility of getting infected as a result of vaccination while also causing the body's stable immune response.
</p>
<p>
On September 4, The Lancet, one of world‚Äôs leading medical journals, published a research paper on the results of Phase I and Phase II clinical trials of the vaccine that showed no serious adverse events and an effective immune response of those vaccinated.
</p>
<p>
Requests for more than 1.2 billion doses of Sputnik V vaccine came from over 50 countries. The vaccine supplies for the global market will be produced by RDIF‚Äôs international partners in India, Brazil, China, South Korea and other countries. The existing RDIF contracts with international partners enable the production of 500 million doses of the Sputnik V vaccine outside Russia annually. RDIF is now considering additional requests from a number of countries and companies to further increase its foreign production capacities.
</p>
<p>
On August 11, the Sputnik V vaccine developed by the Gamaleya Center was registered by Russia‚Äôs Health Ministry and became the world‚Äôs first registered vaccine against COVID-19. Detailed information on the Sputnik V vaccine, its human adenoviral vectors technological platform, and other details are available at&nbsp;<a href="http://" target="_blank">sputnikvaccine.com</a><a target="_blank" href="http://"></a>
</p>
<p>
<b>Be the first to learn about Sputnik V on social networks:</b>
</p>
<p>
<a href="https://twitter.com/sputnikvaccine" target="_blank">Twitter</a>
</p>
<p>
<a href="https://www.facebook.com/sputnikvaccine" target="_blank">Facebook</a>
</p>
<p>
<a href="https://www.instagram.com/sputnik_vaccine/" target="_blank">Instagram</a>
</p>
<p>
<a href="https://www.youtube.com/channel/UCLvQuKL3Nn7NnT9Jyi_dlgQ" target="_blank">Youtube</a>
</p>
<p>
***
</p>
<p>
<b>Russian Direct Investment Fund (RDIF) </b>is Russia's sovereign wealth fund established in 2011 to make equity co-investments, primarily in Russia, alongside reputable international financial and strategic investors. RDIF acts as a catalyst for direct investment in the Russian economy. RDIF‚Äôs management company is based in Moscow. Currently, RDIF has experience of the successful joint implementation of more than 80 projects with foreign partners totaling more than RUB1.9 trillion and covering 95% of the regions of the Russian Federation. RDIF portfolio companies employ more than 800,000 people and generate revenues which ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sputnikvaccine.com/newsroom/pressreleases/the-first-interim-data-analysis-of-the-sputnik-v-vaccine-against-covid-19-phase-iii-clinical-trials-/">https://sputnikvaccine.com/newsroom/pressreleases/the-first-interim-data-analysis-of-the-sputnik-v-vaccine-against-covid-19-phase-iii-clinical-trials-/</a></em></p>]]>
            </description>
            <link>https://sputnikvaccine.com/newsroom/pressreleases/the-first-interim-data-analysis-of-the-sputnik-v-vaccine-against-covid-19-phase-iii-clinical-trials-/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057881</guid>
            <pubDate>Wed, 11 Nov 2020 12:51:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Richard Feynman and How to Learn Anything Well]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25057821">thread link</a>) | @stanrivers
<br/>
November 11, 2020 | https://www.butwhatfor.com/feynman-technique/ | <a href="https://web.archive.org/web/*/https://www.butwhatfor.com/feynman-technique/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Disclosure: Links to Amazon are generally affiliated links. As an Amazon Associate, we earn from qualifying purchases, meaning a commission may be generated on purchased items.</p><div>
<div>
<div>
<div>
<p><strong><a href="https://www.butwhatfor.com/richard-feynman/">Richard P. Feynman </a></strong> (1918 ‚Äì 1988) was an American theoretical physicist often referred to as ‚ÄúThe Great Explainer‚Äù due to his ability to make complex topics understandable. While he won the Nobel Price in Physics in 1965 for his work developing quantum electrodynamics, today he is also famous for his forays into bongo drum playing, Tuvan throat singing, and safe cracking.</p>
<div>
<figure>
<p><a href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa27b9e93-62e5-4bb9-9632-c333e7503580_600x315.jpeg" target="_blank" rel="noopener noreferrer"><br>
<img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa27b9e93-62e5-4bb9-9632-c333e7503580_600x315.jpeg" alt="" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/a27b9e93-62e5-4bb9-9632-c333e7503580_600x315.jpeg&quot;,&quot;height&quot;:315,&quot;width&quot;:600,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:53211,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}"><br>
</a></p>
</figure>
</div>
<p data-pm-context="[]">It is 1941 and you have a problem. While you haven‚Äôt yet gotten around to defining quantum electrodynamics or even started your work helping design the atomic bomb, you are nearing the end of your second year of graduate school. This means you have an exam soon.</p>
<p>That‚Äôs OK though. You know what to do. After all, you have made it this far already. You just do what you always do ‚Äì you pull out a notebook. And not just any notebook, but one especially well-prepared for the task at hand. Namely, a blank one.</p>
<p>A fitting title is needed for the first page. You think for a moment, smiling to yourself as you creatively run through all the options you could pick. But, alas, none of them seem right. You opt for the tried-and-true but never worn out choice. You write it down.</p>
<p>You are Richard P. Feynman, arguably the brightest young physics mind in the United States at the time, and you have just written ‚ÄúNotebook Of Things I Don‚Äôt Know About‚Äù on the title page.</p>
<p><em>Note: For more on Richard Feynman, check out <a href="https://amzn.to/36pgDxt">Genius: The Life and Science of Richard Feynman, </a>the definitive biography by James Gleick, or Feynman‚Äôs autobiographical writings in<a href="https://amzn.to/35krIk7"> ‚ÄúSurely You‚Äôre Joking, Mr. Feynman!‚Äù</a></em></p>
<h4>The Feynman Learning Technique</h4>
<p>Feynman realized early on that people can trick themselves into believing they understand something more deeply than they truly do. This self-delusion often comes from an earnest effort focused on learning the wrong thing ‚Äì learning the name of something as opposed to that which it truly is.</p>
<blockquote><p>The next Monday we were playing in a field, and a kid said to me, ‚ÄúWhat‚Äôs that bird? Do you know the name of that bird?‚Äù I said, ‚ÄúI haven‚Äôt the slightest idea.‚Äù He said, ‚ÄúWell, it is a brown‚Äëthroated thrush.‚Äù He said, ‚ÄúYour father doesn‚Äôt teach you anything.‚Äù</p>

<p>But my father had already taught me about the names of birds. Once we walked, and he said, ‚ÄúThat is a brown-throated thrush. In German it is called the Pfleegel fl√ºgel. In Chinese it is called Keewontong. In Japanese a Towhatowharra‚Äù, and so on.</p>

<p>And when you know all the names of that bird in every language, you know nothing, know absolutely nothing, about the bird‚Ä¶ So I had learned already that names don‚Äôt constitute knowledge‚Ä¶</p>

<p>We have to learn that these are the kinds of disciplines in the field of science that you have to learn ‚Äì to know when you know, and when you don‚Äôt know, and what it is you know, and what it is you don‚Äôt know.</p>

<p>You‚Äôve got to be very careful not to confuse yourself.</p></blockquote>
<p>Understanding this, Feynman was very careful to not delude himself into a superficial understanding of important topics. He developed a more holistic, multidisciplinary approach to learning that served him well throughout his career. While never specifically stated by Feynman as a set technique with steps, Feynman loved sharing with others enough that we can piece together his teachings, along with stories of his life, to better understand how he naturally approached learning anything new.</p>
<p>The combination of ideas, which many different authors outline slightly differently but are holistically the same, is known as <em>The Feynman Learning Technique</em>.</p>
<p>So how does this technique actually work?</p>
<h4>Step 1: Whatever you are trying to learn, take a stab at learning it</h4>
<p>The way that Feynman learned and internalized new ideas was to first attack them head on the old fashioned way ‚Äì by reading and thinking through them. The key emphasis in that sentence is on the word <em>thinking</em>. Famously, Feynman would read the abstract of a scientific paper, and before reading any further, attempt to solve the stated problem. Only then would he read through the rest of the paper. He was focused on mentally wrestling with an idea as opposed to letting someone else walk him to the final answer.</p>
<p>So the first step in the process is to pick something that you need (or better yet, desire) to learn and spend time with the new idea until you have internalized it to the best of your ability.</p>
<p>Now, you might aptly question, ‚ÄúWhat is this <em>hogwash</em>? Step 1 of this supposed wonderfully useful learning technique is to learn something? I‚Äôm out.‚Äù</p>
<p>Stop your <em>swining</em> and don‚Äôt worry ‚Äì there is more to it than that. Which brings us to the second step.</p>
<h4>Step 2: Write everything down, in as simple a way as possible, as if you were preparing a lecture for an inquisitive child</h4>
<p>This is where the notebook comes in. Open it. Close everything else.</p>
<p>From memory, write down everything you can about what you are trying to learn as if you were preparing to teach it to someone else. Preferably, pretend you are planning to teach the topic to a child ‚Äì the more you can simplify your language and the ideas, the more likely you are to find areas where you are hiding behind the name of something as opposed to true understanding.</p>
<blockquote><p>Test it this way: You say, ‚ÄúWithout using the new word which you have just learned, try to rephrase what you have just learned in your own language. Without using the word ‚Äòenergy,‚Äô tell me what you know now about the dog‚Äôs motion.‚Äù You cannot. So you learned nothing about science. That may be all right. You may not want to learn something about science right away.</p>

<p>You have to learn definitions. But for the very first lesson, is that not possibly destructive?</p></blockquote>
<p>At this point, you will probably notice that there are things that you are missing or don‚Äôt remember as well as you thought you did. Write those items down ‚Äì make a list of all the things you don‚Äôt know.</p>
<p>Now open everything back up and search out the answers to those items. Get to a point where you feel like you have conveyed what is required for your theoretical student to deeply understand the topic.</p>

<h4>Step 3: Ask questions as if you were a child to identify gaps in your understanding</h4>
<p data-pm-context="[]">Now you need to channel your inner child. Feynman‚Äôs neverending child-like curiosity is often viewed as the core, natural foundation that differentiated Feynman from other equally intelligent individuals. As children are wont to do, <a href="https://www.butwhatfor.com/invert-always-invert-avoid-failure-to-succeed/">start questioning every line you have written down</a>.</p>
<p>If we take a concept ‚Äì for example, the calculation of <a href="https://www.investopedia.com/terms/n/npv.asp">net present value</a>. Why do we discount cash received in the future? How do you choose a discount rate? Can the rate change between people? Should it change over time? Can you use a different discount rate in different periods? How many years of cash do you think about? How do you determine what those cash numbers will be in the future? What happens if cash is negative in the future? And so on.</p>
<p>If you are seeking Feynman-level understanding, it is not enough to merely know the math formula as that is akin to just knowing the name of something. You need to understand the information qualitatively and quantitatively supporting the formula ‚Äì only then should you feel confident in your understanding.</p>
<p>As you write out these new questions, you‚Äôll find you can answer some of these. Maybe even most of these. However, at some point, you will run out of answers for the incessant child ‚Äì write all these things down as items you ‚Äúdon‚Äôt know about.‚Äù Then go find the answers to these new topics.</p>
<p>By doing this, you are strengthening the foundation upon which your primary new learnings are ingrained in your head.</p>
<blockquote><p>But the problem, you see, when you ask&nbsp;<em>why</em>&nbsp;something happens, how does a person answer why something happens? For example, Aunt Minnie is in the hospital. <em>Why?</em> Because she went out, slipped on the ice, and broke her hip. That satisfies people. It satisfies, but it wouldn‚Äôt satisfy someone who came from another planet and who knew nothing about why when you break your hip do you go to the hospital‚Ä¶</p>

<p>And you begin to get a very interesting understanding of the world and all its complications. If you try to follow anything up, you go deeper and deeper in various directions. For example, if you go, ‚Äú<em>Why did she slip on the ice?‚Äù</em> Well, ice is slippery. Everybody knows that, no problem. But you ask&nbsp;<em>why is ice slippery?</em>&nbsp;That‚Äôs kinda curious. Ice is extremely slippery. It‚Äôs very interesting. <em>You say, how does it work?</em> You could either say, ‚ÄúI‚Äôm satisfied that you‚Äôve answered me. Ice is slippery; that explains it,‚Äù or you could go on and say, ‚Äú<em>Why is ice slippery?‚Äù</em> and then you‚Äôre involved with something, because there aren‚Äôt many things as slippery as ice‚Ä¶</p>

<p><em>A solid that‚Äôs so slippery?</em> Because it is, in the case of ice, when you stand on it (they say) momentarily the pressure melts the ice a little bit so you get a sort of instantaneous water surface on which you‚Äôre slipping. W<em>hy on ice and not on other things?</em> Because water expands when it freezes, so the pressure tries to undo the expansion and melts it. It‚Äôs capable of melting, but other substances get cracked when they‚Äôre freezing, and when you push them they‚Äôre satisfied to be solid.</p>

<p><em>Why does water expand when it freezes and other substances don‚Äôt?</em> I‚Äôm not answering your question, but I‚Äôm telling you how difficult the&nbsp;<em>why&nbsp;</em>question is. You have to know what it is that you‚Äôre permitted to understand and allow to be understood and known, and what it is you‚Äôre not. You‚Äôll notice, in this example, that the more I ask why, the deeper a thing is, the more interesting it gets. We could even go further and say, ‚Äú<em>Why did she fall down when she slipped?‚Äù</em> It has to do with gravity, involves all the planets and everything else. Nevermind! It goes on and on.</p></blockquote>

<h4>Step 4: Repeat step 3 until the questioning adds no incremental value</h4>
<p data-pm-context="[]">Now you iterate with yourself. After you have written down the ‚Ä¶</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.butwhatfor.com/feynman-technique/">https://www.butwhatfor.com/feynman-technique/</a></em></p>]]>
            </description>
            <link>https://www.butwhatfor.com/feynman-technique/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057821</guid>
            <pubDate>Wed, 11 Nov 2020 12:39:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Started with PromQL]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057754">thread link</a>) | @thechiefio
<br/>
November 11, 2020 | https://thechief.io/c/metricfire/getting-started-promql/ | <a href="https://web.archive.org/web/*/https://thechief.io/c/metricfire/getting-started-promql/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://thechief.io/c/metricfire/getting-started-promql/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057754</guid>
            <pubDate>Wed, 11 Nov 2020 12:25:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unix ASCII Games]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057750">thread link</a>) | @elvis70
<br/>
November 11, 2020 | https://ligurio.github.io/awesome-ttygames/ | <a href="https://web.archive.org/web/*/https://ligurio.github.io/awesome-ttygames/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>

      

<p><a href="https://travis-ci.org/ligurio/awesome-ttygames"><img src="https://travis-ci.org/ligurio/awesome-ttygames.svg?branch=master" alt="Build Status"></a></p>

<p>See additional resources about games in console:</p>
<ul>
  <li>https://inconsolation.wordpress.com/tag/game/</li>
  <li>https://ttygames.wordpress.com/</li>
  <li>https://theouterlinux.gitlab.io/RecommendedSoftware/Linux/Games/RecommendedSoftware_Linux_Games.html</li>
</ul>

<p>Feel free to submit pull requests to add new games and improve information about
those already in the database.</p>

<h2 id="how-to-contribute">How to contribute</h2>

<p>Check <code>games.yaml</code> out. All information is inside, and you should more or less
understand what‚Äôs going on by reading it. Sorting is alphabetical.</p>

<p>Simplest way to contribute: edit <a href="https://ligurio.github.io/awesome-ttygames/games.yaml">games.yaml</a>, and then
your changes will be submitted as a pull request.</p>

<p>Use this template:</p>

<div><div><pre><code>- name: hangman
  url: http://www.openbsd.org/cgi-bin/man.cgi/OpenBSD-current/man6/hangman.6?query=hangman&amp;sec=6&amp;arch=i386
  info: computer version of the game hangman
  screencast:
  play:
</code></pre></div></div>

<ul>
  <li><code>name</code>: Name of the game</li>
  <li><code>url</code>: URL of main page</li>
  <li><code>info</code>: free text with game description</li>
  <li><code>screencast</code>: link to screencast (for example on asciinema)</li>
  <li><code>play</code>: server hostname where game is available via telnet or ssh</li>
</ul>

<h2 id="license">License</h2>

<p><a href="http://creativecommons.org/publicdomain/zero/1.0/"><img src="http://i.creativecommons.org/p/zero/1.0/88x31.png" alt="CC0 Public Domain"></a></p>

<p>To the extent possible under law, <a href="https://bronevichok.ru/">Sergey Bronnikov</a> has
waived all copyright and related or neighboring rights to this work.</p>

<h3 id="0verkill">0verkill</h3>

<p>0verkill is bloody 2D action deathmatch-like game in ASCII-ART.</p>

<h3 id="2048"><a href="https://github.com/mevdschee/2048.c">2048</a></h3>

<p>This is an ncurses version of the game ‚Äò2048‚Äô.</p>

<h3 id="2048-cli"><a href="https://github.com/Tiehuis/2048-cli">2048-cli</a></h3>

<p><a href="https://asciinema.org/a/34067"><img src="https://asciinema.org/a/34067.svg" alt="asciicast"></a></p>

<p>A cli version of the game 2048 for your Linux terminal.</p>

<h3 id="n2048"><a href="http://freshmeat.sourceforge.net/projects/n2048">n2048</a></h3>

<p><a href="https://asciinema.org/a/35973"><img src="https://asciinema.org/a/35973.svg" alt="asciicast"></a></p>

<p>n2048 is a console-based game based on the highly addictive sliding puzzle 2048. Slide the tiles together to combine them, until you reach the highest one.</p>

<h3 id="ascii-patrol"><a href="http://ascii-patrol.com/">ascii patrol</a></h3>

<p>None</p>

<p><strong>Play</strong>: <code>http://ascii-patrol.com/area51/ascii-patrol-html5.html</code></p>

<h3 id="abura-tan"><a href="http://aburatan.sourceforge.net/">abura tan</a></h3>

<p>A roguelike game of Cowboy Knights and Lurking Horror.</p>

<h3 id="ad-astra"><a href="https://code.google.com/archive/p/ad-astra-game/">ad astra</a></h3>

<p>Ad Astra is a turn-based space strategy game written in Python that uses curses for its display.</p>

<h3 id="adom-ancient-domains-of-mystery"><a href="https://www.adom.de/">ADOM (Ancient Domains of Mystery)</a></h3>

<p>ADOM is a roguelike game.</p>

<h3 id="adventure"><a href="https://man.openbsd.org/OpenBSD-current/man6/adventure.6">adventure</a></h3>

<p>An exploration game. It‚Äôs a BSD game.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Colossal_Cave_Adventure">Wikipedia</a>.</p>

<p><strong>Play</strong>: <code>https://grack.com/demos/adventure/</code></p>

<h3 id="alienrl"><a href="https://alien.chaosforge.org/">alienrl</a></h3>

<p>AliensRL is a tactical roguelike game, inspired by the ‚ÄúAliens‚Äù movie.</p>

<h3 id="alienwave"><a href="https://www.alessandropira.org/alienwave/aw.html">alienwave</a></h3>

<p>another good variant of the space invaders game.</p>

<h3 id="angband"><a href="https://rephial.org/">angband</a></h3>

<p>Angband is a free, single-player dungeon exploration game.</p>

<h3 id="anonymine"><a href="https://oskog97.com/projects/anonymine/">Anonymine</a></h3>

<p><a href="https://asciinema.org/a/82455"><img src="https://asciinema.org/a/82455.svg" alt="asciicast"></a></p>

<p>A curses mode minesweeper solvable without guessing, and the only with von Neumann neighbourhoods.</p>

<p><strong>Play</strong>: <code>ssh play@anonymine-demo.oskog97.com -p 2222; Password is "play"</code></p>

<h3 id="aop"><a href="https://raffi.at/view/code/aop">aop</a></h3>

<p><a href="https://asciinema.org/a/34678"><img src="https://asciinema.org/a/34678.svg" alt="asciicast"></a></p>

<p>Ambassador of Pain (aop). A very nice and challenging arcade game.</p>

<h3 id="apple-trek"><a href="http://peyre.x10.mx/GWBASIC/index.htm#AppleTrek">Apple Trek</a></h3>

<p>See also <a href="https://en.wikipedia.org/wiki/Apple_Trek">Wikipedia</a>.</p>

<h3 id="arkanoid-bash"><a href="https://github.com/bolknote/shellgames/blob/master/arcanoid.sh">arkanoid-bash</a></h3>

<p><a href="https://asciinema.org/a/36415"><img src="https://asciinema.org/a/36415.svg" alt="asciicast"></a></p>

<p>Arkanoid is an arcade game developed by Taito in 1986. Written in Bash.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Arkanoid">Wikipedia</a>.</p>

<h3 id="arkanoidpy"><a href="https://blog.yjl.im/2015/12/arkanoid-example-from-pygamii-ascii.html">arkanoid.py</a></h3>

<p>Arkanoid is an arcade game developed by Taito in 1986. Written in Python.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Arkanoid">Wikipedia</a>.</p>

<h3 id="arkanoid-sed"><a href="http://sed.sourceforge.net/local/games/arkanoid.sed.html">arkanoid-sed</a></h3>

<p>Arkanoid is an arcade game developed by Taito in 1986. Written in Sed.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Arkanoid">Wikipedia</a>.</p>

<h3 id="arithmetic"><a href="https://man.openbsd.org/arithmetic.6">arithmetic</a></h3>

<p>quiz on simple arithmetic</p>

<h3 id="asciijump"><a href="http://freshmeat.sourceforge.net/projects/asciijump">asciijump</a></h3>

<p><a href="https://asciinema.org/a/31340"><img src="https://asciinema.org/a/31340.svg" alt="asciicast"></a></p>

<p>asciijump is an ASCII art game about ski jumping.</p>

<h3 id="ascii-portal"><a href="https://github.com/cymonsgames/ASCIIpOrtal">ascii portal</a></h3>

<p>ASCIIpOrtal is a text based puzzle game inspired by the popular video game.</p>

<h3 id="asciisector"><a href="http://www.asciisector.net/">asciisector</a></h3>

<p>asciisector is a free space combat/exploration/trading game.</p>

<h3 id="astwar"><a href="https://savannah.nongnu.org/projects/astwar">astwar</a></h3>

<p>Astwar is a ncurses based game that features two little ships on each side of the screen shooting each other.</p>

<h3 id="atc"><a href="https://man.openbsd.org/OpenBSD-current/man6/atc.6">atc</a></h3>

<p>air traffic controller game. It‚Äôs a BSD game.</p>

<h3 id="avanor"><a href="http://avanor.sourceforge.net/">avanor</a></h3>

<p>Rogue-like game with easy ADOM-like user interface.</p>

<h3 id="awkaster"><a href="https://github.com/TheMozg/awk-raycaster">awkaster</a></h3>

<p>Pseudo-3D shooter written completely in gawk using raycasting technique</p>

<h3 id="backgammon"><a href="https://man.openbsd.org/OpenBSD-current/man6/backgammon.6">backgammon</a></h3>

<p>A backgammon game; you can play against the computer. It‚Äôs a BSD game.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Backgammon">Wikipedia</a>.</p>

<h3 id="bastet"><a href="http://fph.altervista.org/prog/bastet.html">bastet</a></h3>

<p>Bastet (short for Bastard Tetris).</p>

<h3 id="battleships"><a href="http://www.catb.org/~esr/bs/">battleships</a></h3>

<p>Uses character-cell graphics with a visual point-and-shoot interface.</p>

<h3 id="battlestar"><a href="https://man.openbsd.org/OpenBSD-current/man6/battlestar.6">battlestar</a></h3>

<p>A tropical adventure game. It‚Äôs a BSD game.</p>

<h3 id="bcd"><a href="https://man.openbsd.org/bcd.6">bcd</a></h3>

<p>punched card</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Punched_card">Wikipedia</a>.</p>

<h3 id="beasts"><a href="https://peteg.org/beasts/beasts.html">beasts</a></h3>

<p>The game Beasts is a Linux version of the old DOS game called Beast.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Beast_(video_game)">Wikipedia</a>.</p>

<h3 id="beyond-the-tesseract"><a href="https://www.wurb.com/if.php/game/211">beyond the tesseract</a></h3>

<p>A highly conceptual game in which you interact with abstract concepts and mathematical entities as if they were tangible.</p>

<p><strong>Play</strong>: <code>telnet or ssh on sdf.org</code></p>

<h3 id="blocks">blocks</h3>

<p>A block-based puzzle game.</p>

<h3 id="bluemoon"><a href="http://www.catb.org/~esr/bluemoon/">bluemoon</a></h3>

<p>The Blue Moon card solitaire.</p>

<h3 id="bj">bj</h3>

<p>a black-jack card game.</p>

<p><strong>Play</strong>: <code>telnet or ssh on sdf.org</code></p>

<h3 id="boggle"><a href="https://man.openbsd.org/OpenBSD-current/man6/boggle.6">boggle</a></h3>

<p>Word search game. It‚Äôs a BSD game.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Boggle">Wikipedia</a>.</p>

<p><strong>Play</strong>: <code>telnet mud.darkerrealms.org 2000</code></p>

<h3 id="bombardier"><a href="https://packages.debian.org/en/sid/i386/games/bombardier">bombardier</a></h3>

<p>This game is the same as the old Blitz16 game on Commodore 16/Plus 4, written by Simon Taylor.</p>

<h3 id="boulder-dash">boulder dash</h3>

<p>A Boulder Dash game clone for your favorite terminal. You are trapped in the CAVEZ of PHEAR, your mission is to escape through all the caves and make it out alive. To escape through a cave you will have to find all the diamonds located in it. Once you‚Äôve found all the diamonds, their powers combined will help you get to the next cave, one step closer to freedom.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Boulder_Dash">Wikipedia</a>.</p>

<h3 id="bowling"><a href="https://github.com/haliphax/pybowl">bowling</a></h3>

<p><a href="https://asciinema.org/a/41475"><img src="https://asciinema.org/a/41475.svg" alt="asciicast"></a></p>

<p>Python bowling game using the Blessed terminal library.</p>

<h3 id="braincurses"><a href="https://sourceforge.net/projects/braincurses/">braincurses</a></h3>

<p>A nice version of the mastermind game.</p>

<h3 id="brogue"><a href="https://sites.google.com/site/broguegame/">brogue</a></h3>

<p>Brogue is a Roguelike game.</p>

<h3 id="bs"><a href="https://man.openbsd.org/OpenBSD-current/man6/bs.6">bs</a></h3>

<p>Battleships game. It‚Äôs a BSD game.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Battleship_%28game%29">Wikipedia</a>.</p>

<h3 id="caesar"><a href="https://man.openbsd.org/caesar.6">caesar</a></h3>

<p>decrypt caesar cyphers</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Caesar_cipher">Wikipedia</a>.</p>

<h3 id="canfield"><a href="https://man.openbsd.org/OpenBSD-current/man6/canfield.6">canfield</a></h3>

<p>The solitaire card game canfield. It‚Äôs a BSD game.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Canfield_%28solitaire%29">Wikipedia</a>.</p>

<h3 id="caribbean-stud">Caribbean Stud</h3>

<p>a multi-player card game, written by Hero</p>

<p><strong>Play</strong>: <code>telnet mud.darkerrealms.org 2000</code></p>

<h3 id="cataclysm-dark-days-ahead"><a href="https://web.archive.org/web/20190209031801/http://en.cataclysmdda.com/">cataclysm: dark days ahead</a></h3>

<p>Cataclysm: Dark Days Ahead is a roguelike set in a post-apocalyptic world. Surviving is difficult: you have been thrown, ill-equipped, into a landscape now riddled with monstrosities of which flesh eating zombies are neither the strangest nor the deadliest.</p>

<h3 id="cavez-of-phear">cavez of phear</h3>

<p>cavez of phear is a boulder dash / digger like game for console using ncurses.</p>

<h3 id="cbattleship"><a href="https://github.com/gnomengineer/cBattleship">cbattleship</a></h3>

<p>A implementation of the classic Battleship game in C++. Includes a server program, and multiple different client programs. The server program wait‚Äôs until two client program connected to start a game. The server dictates the rules of the game.</p>

<h3 id="cblocks"><a href="https://www.muppetlabs.com/~breadbox/software/cgames.html">cblocks</a></h3>

<p>a set of sliding-block puzzles.</p>

<h3 id="checkers">Checkers</h3>

<p>a two-player board game, written by Alexi</p>

<p><strong>Play</strong>: <code>telnet mud.darkerrealms.org 2000</code></p>

<h3 id="chess"><a href="https://github.com/bolknote/SedChess">chess</a></h3>

<p>Chess implemented in sed utility.</p>

<h3 id="gnuchess"><a href="https://www.gnu.org/software/chess/">gnuchess</a></h3>

<p>GNU Chess is a chess-playing program.</p>

<p><strong>Play</strong>: <code>telnet freechess.org 5000 (login guest)</code></p>

<h3 id="chimaera"><a href="https://www.mipmip.org/C_games/">chimaera</a></h3>

<p>A highly unusual ‚Äúinfinite‚Äù adventure game written by Chris Newall.</p>

<h3 id="chroma"><a href="http://www.level7.org.uk/chroma/">chroma</a></h3>

<p>A challenging puzzle game.</p>

<h3 id="ckhet"><a href="https://mbays.freeshell.org/ckhet/">ckhet</a></h3>

<p>Curses implementation of the laser board game Khet.</p>

<p><strong>Play</strong>: <code>ssh ckhet@sshgames.thegonz.net; password: ckhet</code></p>

<h3 id="clines"><a href="http://manticore.2y.net/prj/clines-a.html">clines</a></h3>

<p>Clines is a standard ‚ÄúLines‚Äù game, implemented as a curses application.</p>

<h3 id="clines-1"><a href="https://github.com/veselov/clines">clines</a></h3>

<p>Color Lines clone in console.</p>

<h3 id="cmines"><a href="https://www.muppetlabs.com/~breadbox/software/cgames.html">cmines</a></h3>

<p>minesweeper.</p>

<h3 id="cnibbles"><a href="http://cnibbles.sourceforge.net/">cnibbles</a></h3>

<p>Another Nibbles game with good and smooth animations.</p>

<h3 id="open-adventure"><a href="https://gitlab.com/esr/open-adventure">Open Adventure</a></h3>

<p>Colossal Cave Adventure (also known as ADVENT, Colossal Cave, or Adventure) is one of the earliest computer adventure games and a precursor form of role playing video game. The original version was designed by Will Crowther, a programmer and caving enthusiast who based the layout on part of the Mammoth Cave system in Kentucky.</p>

<h3 id="connect-four">Connect Four</h3>

<p>a two-player slot game, written by Sarac</p>

<p><strong>Play</strong>: <code>telnet mud.darkerrealms.org 2000</code></p>

<h3 id="connect4"><a href="https://github.com/badescunicu/connect4">connect4</a></h3>

<p>The Connect4 game using ncurses C library.</p>

<h3 id="conquest"><a href="https://github.com/beejjorgensen/conquest">Conquest</a></h3>

<p>Port of the old Amiga Conquest text-based game</p>

<h3 id="conquest-1"><a href="https://github.com/jtrulson/conquest/">conquest</a></h3>

<p>a real-time, multi-player space warfare game.</p>

<p><strong>Play</strong>: <code>telnet mud.darkerrealms.org 2000</code></p>

<h3 id="gnu-conquest"><a href="https://sourceforge.net/projects/gnu-conquest/">gnu-conquest</a></h3>

<p>A multiplayer galactic game.</p>

<h3 id="corewar"><a href="http://www.corewar.info/">corewar</a></h3>

<p>Core War is a programming game created by D. G. Jones and A. K. Dewdney in which two or more battle programs (called ‚Äúwarriors‚Äù) compete for control of a virtual computer.</p>

<h3 id="cpat"><a href="http://cpat.sourceforge.net/">cpat</a></h3>

<p>CPat is probably the best card game for the Linux console; it is a collection of many solitaire/patience games from the most famous to less known games.</p>

<h3 id="crawl"><a href="https://crawl.develz.org/wordpress/">crawl</a></h3>

<p><a href="https://asciinema.org/a/524"><img src="https://asciinema.org/a/524.svg" alt="asciicast"></a></p>

<p>One of the best games for the Linux console.</p>

<h3 id="cribbage"><a href="https://man.openbsd.org/OpenBSD-current/man6/cribbage.6">cribbage</a></h3>

<p>The card game cribbage. It‚Äôs a BSD game.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Cribbage">Wikipedia</a>.</p>

<h3 id="cryptrover"><a href="https://code.google.com/archive/p/cryptrover/">cryptrover</a></h3>

<p>Escape From The Crypt.</p>

<h3 id="ctris"><a href="https://github.com/dominikhackl/ctris">ctris</a></h3>

<p>Another version of the tetris game.</p>

<h3 id="cursedmate"><a href="https://web.archive.org/web/20130804035452/http://www.uberwall.org/~dash/">cursedmate</a></h3>

<p>A game with a hacking atmosphere.</p>

<h3 id="curse-of-war"><a href="https://a-nikolaev.github.io/curseofwar/">curse-of-war</a></h3>

<p>Curse of War is a fast-paced action strategy game for Linux originally implemented using ncurses user interface.</p>

<h3 id="dab"><a href="https://netbsd.gw.com/cgi-bin/man-cgi?dab+6+NetBSD-6.0">dab</a></h3>

<p>Dots and Boxes game.</p>

<h3 id="diablorl"><a href="https://diablo.chaosforge.org/">diablorl</a></h3>

<p>DiabloRL is a roguelike ‚Äúunmake‚Äù of the popular Blizzard game Diablo.</p>

<h3 id="doomrl"><a href="https://drl.chaosforge.org/">doomrl</a></h3>

<p>DoomRL (Doom, the Roguelike) is a fast and furious coffee-break Roguelike game, that is heavily inspired by the popular FPS game Doom by ID Software.</p>

<h3 id="dopewars"><a href="https://dopewars.sourceforge.io/">dopewars</a></h3>

<p>A funny game about trading drugs. Dopewars is a free rewrite of a game originally based on Drug Wars by John E. Dell.</p>

<p><strong>Play</strong>: <code>telnet or ssh on sdf.org</code></p>

<h3 id="dsol"><a href="https://feld.me/pub/vga_cardgames-1.3.1.tgz">dsol</a></h3>

<p>dSol is a command line solitaire card game.</p>

<h3 id="duel-commander"><a href="https://sourceforge.net/projects/duelcommander/">duel commander</a></h3>

<p>Duel Commander is a turn based command line fighting game for Windows and Unix-like systems.</p>

<h3 id="dungeon-crawl"><a href="http://www.dungeoncrawl.org/">dungeon crawl</a></h3>

<p>Dungeon Crawl, a text-based roguelike game.</p>

<h3 id="dwarf-fortress"><a href="https://www.bay12games.com/dwarves/">dwarf fortress</a></h3>

<p>Dwarf Fortress is a single-player fantasy game.</p>

<h3 id="emacs"><a href="https://www.emacswiki.org/emacs/CategoryGames">emacs</a></h3>

<p>Actually it is not a game, but text editor. It includes a bunch of text games like chess, sokoban, pong etc.</p>

<h3 id="encircled"><a href="http://www.roguebasin.com/index.php?title=Encircled">encircled</a></h3>

<p>Encircled is a roguelike game.</p>

<h3 id="enigma"><a href="https://www.chiark.greenend.org.uk/~sgtatham/enigma/">enigma</a></h3>

<p>A puzzle game where items have to be collected in the right order.</p>

<h3 id="eyangband"><a href="http://eyangband.sourceforge.net/">eyangband</a></h3>

<p>Another variant of Angband.</p>

<h3 id="factor"><a href="https://man.openbsd.org/factor.6">factor</a></h3>

<p>factor a number, generate primes</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Factorization">Wikipedia</a>.</p>

<h3 id="fbird-screencast"><a href="https://github.com/nanochess/fbird">fbird</a> <a href="https://www.youtube.com/watch?v=p31XFFAeze4">Screencast</a></h3>

<p>F-Bird, a text bootsector game</p>

<h3 id="fish"><a href="https://man.openbsd.org/OpenBSD-current/man6/fish.6">fish</a></h3>

<p>Play ``Go Fish‚Äô‚Äô. It‚Äôs a BSD game.</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Go_Fish">Wikipedia</a>.</p>

<h3 id="fortune"><a href="https://man.openbsd.org/fortune.6">fortune</a></h3>

<p>print a random, hopefully interesting, adage</p>

<p>See also <a href="https://en.wikipedia.org/wiki/Fortune_%28Unix%29">Wikipedia</a>.</p>

<h3 id="freecell"><a href="https://www.linusakesson.net/software/freecell.php">freecell</a></h3>

<p>This is a console (ncurses) version of the popular and addictive solitaire game.</p>

<p><strong>Play</strong>: <code>telnet mud.darkerrealms.org 2000</code></p>

<h3 id="freesweep"><a href="https://code.google.com/archive/p/freesweep/">freesweep</a></h3>

<p>minesweeper game using curses.</p>

<h3 id="freesweep-1"><a href="https://github.com/rwestlund/freesweep">freesweep</a></h3>

<p>Freesweep is a console minesweeper-style game written in C for Unix-like systems.</p>

<h3 id="fkmines"><a href="https://sourceforge.net/projects/fkmines/">fkmines</a></h3>

<p>Another minesweeper-style game.</p>

<h3 id="frozen-depths"><a href="https://frozendepths.net/">frozen depths</a></h3>

<p>A very nice roguelike game with an entertaining atmosphere.</p>

<h3 id="frotz"><a href="https://davidgriffith.gitlab.io/frotz/">frotz</a></h3>

<p>Frotz is an interpreter for Infocom games and other Z-machine games.</p>

<h3 id="galaxis"><a href="http://www.catb.org/esr/galaxis/">galaxis</a></h3>

<p>Find the lost lifeboats from an interstellar liner.</p>

<h3 id="gameroom">gameroom</h3>

<p>11 arcade games</p>

<p><strong>Play</strong>: <code>ssh gameroom@bitreich.org</code></p>

<h3 id="gearhead"><a href="http://www.gearheadrpg.com/">gearhead</a></h3>

<p>GearHead is the first roguelike to explore the world of ‚Äúmechas‚Äù (giant robots).</p>

<h3 id="gnake">gnake</h3>

<p>Another variant of the snake game with a smooth movement.</p>

<h3 id="gnugo"><a href="https://www.gnu.org/software/gnugo/">gnugo</a></h3>

<p>GNU Go is a free ‚Ä¶</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ligurio.github.io/awesome-ttygames/">https://ligurio.github.io/awesome-ttygames/</a></em></p>]]>
            </description>
            <link>https://ligurio.github.io/awesome-ttygames/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057750</guid>
            <pubDate>Wed, 11 Nov 2020 12:24:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hardly Working with Cloudflare Workers]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25057709">thread link</a>) | @malthejorgensen
<br/>
November 11, 2020 | https://blog.notifly.io/2020/11/04/hardly-working-with-cloudflare-workers | <a href="https://web.archive.org/web/*/https://blog.notifly.io/2020/11/04/hardly-working-with-cloudflare-workers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <!-- Possible titles:
Cloudflare workers are hard to work with
Working with Cloudflare Workers
Hardly working with Cloudflare Workers
-->

<p><em>Note: The team behind Notifly also runs <a href="https://www.eduflow.com/">Eduflow</a> and <a href="https://www.peergrade.io/">Peergrade</a>.</em></p>

<h2 id="introduction">Introduction</h2>

<p>This is the story of me trying to replace a simple NGINX reverse proxy (plus some basic redirects) with a Cloudflare Worker.</p>

<p>Our old landing page is a Wordpress blog hosted on WPEngine. Historically, this has always been set up behind an NGINX reverse proxy serving at <a href="http://peergrade.io/">peergrade.io</a> and <a href="http://www.peergrade.io/">www.peergrade.io</a>. The reverse proxy was needed for doing various redirects outside of Wordpress and doing some cookie trickery to redirect to <a href="http://app.peergrade.io/">app.peergrade.io</a> if the session cookie for the app was present.</p>

<p>The reverse proxy is hosted on DigitalOcean and is the only thing we have hosted there, so I wanted to get rid of it. We already use Cloudflare and so I thought ‚Äúthis would be a good test to try out Cloudflare Workers‚Äù. And less infrastructure is better, right?</p>

<h2 id="the-good-parts">The good parts</h2>

<p>Getting set up with <code>wrangler</code> ‚Äì the CLI for Cloudflare Workers ‚Äì was a breeze. It gives you a webpack setup out of the box which allowed me to install NPM packages and use them without any extra work on my part. I eventually downgraded to a setup without webpack (called ‚Äújavascript‚Äù in <code>wrangler</code>) ‚Äì since I ended up not needing any packages.</p>

<p>The vanilla Javascript setup allows you to ‚Äúlive edit‚Äù the worker at <code>https://dash.cloudflare.com/&lt;account-id&gt;/workers/edit/&lt;worker-slug&gt;</code></p>

<p>Here you can edit and run the updated script without saving and deploying the worker, allowing for a very fast and easy ‚Äúedit-compile-run‚Äù loop.</p>

<p>Another cool thing is that you can change the URL in the small ‚Äúbrowser‚Äù on the page to your liking ‚Äì this is very useful for testing out proxies and other things that depend on the domain name or precise URL being sent to the worker. The debugger part of the UI is also incredibly useful but does have a tendency to disconnect from time to time.</p>

<h2 id="page-rules-vs-workers">Page Rules vs. Workers</h2>

<p>In a classic setup you‚Äôll usually have a couple of redirects alongside your reverse proxy ‚Äì and so do we. We use <a href="http://www.peergrade.io/">www.peergrade.io</a> as our canonical domain so we redirect peergrade.io to www.peergrade.io and we redirect http:// to https://.</p>

<p>This can be set up easily in Cloudflare by adding a couple of redirects in your Page Rules.</p>

<p>However, redirects from page rules are applied after any worker on the same URL. Since my worker‚Äôs default action is to reverse proxy, the redirect page rule will never be hit.</p>

<p>Annoyingly, this isn‚Äôt clearly described in the docs and you‚Äôll have to find <a href="https://community.cloudflare.com/t/cf-workers-and-rate-limiting-firewall-rules-bot-management/132164/3">this forum post</a> from the official Cloudflare forum to know that.
The post notes that ‚Äú<em>security-related ones will run before [workers]</em>‚Äù ‚Äì but which ones are those? (All respect to Kenton Varda who wrote the post and is the main architect behind Cloudflare Workers. Cloudflare Workers <em>are</em> very very cool, but they are also a bit more quirky than I‚Äôd like at the moment)</p>

<p>In order to preserve these redirects, I‚Äôll have to manually write them in the worker code (or relay the URLs that need to redirect to Cloudflare itself ‚Äì which is basically the same amount of code).</p>

<!-- 
- An aside:

    Apparently *Always Use HTTPS* is such a "security-related" page rule, even though it's basically an http:// to https:// redirect. Cloudflare even admits to that [in the docs](https://support.cloudflare.com/hc/en-us/articles/204144518-SSL-FAQ#h_a61bfdef-08dd-40f8-8888-7edd8e40d156). 

    Cloudflare Page Rules allows you to set up multiple rules for a single URL-pattern, but then only allows you to use that pattern once. However, *Always Use HTTPS* is special and doesn't allow any other rules once it's used on a URL-pattern. This means if you want *Automatic HTTPS Rewrites* on top of *Always Use HTTPS* you have to specify 2 rules:

    1. www.peergrade.io ‚Äì *Always Use HTTPS*
    2. [https://www.peergrade.io](https://www.peergrade.io) ‚Äì *Automatic HTTPS Rewrites*
-->

<p>The same thing goes for cache rules. I had previously been using a page rule to aggressively cache static assets and user-uploaded content served from Wordpress. That now has to be written inside the worker as well.</p>

<p>Page rules have an internal ordering that you can set. Rules that match the given URL are executed in order ‚Äì so that if two redirect rules match the URL, the first one in the ordering will be used. It would be <em>really nice</em> if workers could be added to the same list ‚Äì that would mean I could put the redirects and cache rules before my worker and much more easily handle this scenario. <em>In principle</em> this would be easy if all the built-in page rules were reimplemented as workers, but there‚Äôs probably legacy behaviors and tie-ins to the rest of the stack that makes that impossible or at least non-trivial. (Still hoping for a future update on this ü§ûüèª)</p>

<h2 id="the-reverse-proxy">The reverse proxy</h2>

<p>Back to the main task at hand ‚Äì we‚Äôre implementing a simple reverse proxy and that happens to be <a href="https://developers.cloudflare.com/workers/examples/bulk-origin-proxy">one of the examples</a> in the Cloudflare Worker docs. However, getting it set up myself I quickly ran into issues with redirect loops and cases where my origin would redirect for seemingly no reason. To be fair, proxying can be tricky to get right since it‚Äôs hard to test properly before rollout, and on top of that you have DNS propagation and caching, which means there might be timing issues. But even with that, it seemed extra tricky with Cloudflare Workers.</p>

<p>On closer inspection, the example from the Cloudflare docs seems to defy reasoning. The incoming request in the example must have the header <code>Host: google.yourdomain.com</code> in order for it to match the Google entry in <code>ORIGINS</code>. I was able to confirm as much by inspecting the incoming request in the Cloudflare worker debugger. That incoming request is then relayed directly to <code>www.google.com</code>. Let‚Äôs try that ourselves:</p>

<div><div><pre><code>curl -H 'Host: google.yourdomain.com' https://www.google.com
</code></pre></div></div>

<p>The response we get is a 404 page (which makes sense since the host doesn‚Äôt match). However, the Cloudflare worker doesn‚Äôt get a 404 ‚Äì it renders the familiar Google search frontpage. Something must be happening behind the scenes. That something is what I call ‚ÄúThe Web Platform‚Äù part of Cloudflare Workers.</p>

<h2 id="the-web-platform">The Web Platform</h2>

<p>Cloudflare Workers uses Chrome‚Äôs V8 as its execution engine and this also sets the context in which your script is run.</p>

<p>The available API is a very small subset of <a href="https://platform.html5.org/">The Web Platform</a> (the Javascript API available in modern browsers) ‚Äì specifically Ecmascript/Javascript itself, plus <code>Fetch</code>, <code>URL</code>, and <code>Blob</code>. I believe Cloudflare chose this API because it melds well with V8, but also because web devs will be familiar with those APIs. But how familiar are you <em>really</em> with <code>fetch</code>, <code>Request</code>, and <code>Response</code>? (all part of the <code>Fetch</code>-spec)<br>
I don‚Äôt think I actually knew the <code>Request</code> and <code>Response</code>-objects in any detail before using Cloudflare Workers ‚Äì having gotten along just fine with variations of</p>

<div><div><pre><code>fetch('http://example.org', { options }).then((r) =&gt; r.json())
</code></pre></div></div>

<p>plus some error handling on top for many years.</p>

<p>When working with Workers what you‚Äôll mostly be doing is to manipulate the incoming <code>Request</code>-object  and pass it on to <code>fetch</code>, or manipulate the outgoing <code>Response</code>-object and passing that on to Cloudflare‚Äôs handler. Have you ever manually created a <code>Request</code>-object in the browser? I haven‚Äôt. The reason this gets complicated is the fact that the spec for <code>fetch</code> itself is very ‚Äúloose‚Äù. For example, <code>fetch</code> can take either a <code>Request</code>-object or a simple Javascript object that just looks a lot like a <code>Request</code>-object as its argument ‚Äì and it not really clear what differences between the two are.
<code>fetch</code> also allows passing a <code>Request</code>-objects as both its first and second argument <code>fetch(Request(...), Request(...))</code> ‚Äì good luck trying to figure out what that does!</p>

<p>If we go back to the example from the Cloudflare docs ‚Äì what‚Äôs going on ‚Äúbehind the scenes‚Äù in our proxy example from earlier is that you can‚Äôt change the <code>Host</code>-header when doing a <code>fetch</code>. This makes a lot of security sense in the browser where <code>fetch</code> normally lives, but it‚Äôs quite normal behavior for a reverse proxy and actually something I was doing in my NGINX setup in order to have WPEngine respond with the right content. It‚Äôs not a behavior you‚Äôve ever needed or thought about when using <code>fetch</code> in the browser.
The server is just a very different environment than the browser. The browser Javascript API is not built with server functionality in mind, and it ends up being a hamstring when working with Cloudflare Workers.</p>

<h2 id="maybe-maybe-maybe">Maybe, maybe, maybe‚Ä¶?</h2>

<p>A bunch of forum posts on community.cloudflare.com talk about this issue</p>

<ul>
  <li><strong>Only available on the Enterprise plan?</strong> <a href="https://community.cloudflare.com/t/override-host-header-using-workers/73434/2">This forum post</a> describes that setting the <code>Host</code> -header in workers is not possible. Followed up with <a href="https://community.cloudflare.com/t/override-host-header-using-workers/73434/5">a later answer</a> that it‚Äôs possible but only for Enterprise accounts.
 <a href="https://community.cloudflare.com/t/reverse-proxy-using-page-rules/47836/16">This other post</a> says the same.</li>
  <li><strong>Kenton Varda to the rescue</strong> In response to <a href="https://community.cloudflare.com/t/not-possible-to-override-the-host-header-on-workers-requests/13077/7">this post</a> Kenton Varda actually extends Cloudflare Workers with the <code>cf.resolveOverride</code>-flag on the <code>Request</code>-object,
which should allow at least part of the reverse proxy setup to work.
Unfortunately, to explain the new feature the post just links to the top-level URL of the documentation for Cloudflare Workers ‚Äì which currently doesn‚Äôt
describe how  <code>cf.resolveOverride</code> works and how to use it.</li>
  <li><strong>The missing documentation</strong> <a href="https://community.cloudflare.com/t/different-hostname-with-same-origin-in-workers/16662/12">This older post</a> seemingly cites documentation that no longer exists! :(<br>
 I have been unable to find any meaningful documentation of <code>cf.resolveOverride</code> outside of the community forum, and I was unable to have it allow me to switch the <code>Host</code>-header.</li>
</ul>

<h2 id="the-final-nail-in-the-coffin">The final nail in the coffin</h2>

<p>For a brief moment I actually thought my setup was working, but it only ‚Äúlooked‚Äù like it was working due to the following sequence of events:</p>

<ul>
  <li>A request for <code>www.peergrade.io</code> would hit the worker</li>
  <li>The worker would then do a request to <code>peergrade.wpengine.com</code></li>
  <li>Wordpress/WPEngine would then respond with a redirect to <code>www.peergrade.io</code> since the <code>Host</code>-header is incorrect</li>
  <li>Cloudflare by default then follows that redirect and makes a new request to <code>www.peergrade.io</code>.
Since Cloudflare is the host of <code>www.peergrade.io</code> you‚Äôd think we‚Äôd hit infinite recursion here.
But magically, it doesn‚Äôt just enter the worker script again ‚Äì it knows (somehow) it has to go further down the Cloudflare stack.
Since the DNS A-record in Cloudflare still had the IP of the DigitalOcean instance, that final fetch would simply fetch the page from the old proxy server which worked as it always had ü§¶üèª</li>
</ul>

<!--
Another example of this "familiar but unfamiliar" API is when I was trying to inspect the session cookie: I had to do a base64 decode into a `Uint8Array` (in order to do a zlib decompression). The function available for decoding base64 is `atob` which you may know from the browser.

However, in order to get the actual binary data you'll have to do this Javascript incantation:

```jsx
const weirdstr = atob(cookiestr);
const bytearray = new Uint8Array(new ArrayBuffer(weirdstr.length));

for (let i = 0; i < weirdstr.length; i++) {
  bytearray[i] = weirdstr.charCodeAt(i);
}
```

Again, this isn't Cloudflare's fault per se, but they're inheriting a bad choice from The Web Platform where they could have done something else. That bad choice becomes accentuated by the fact that most workers need to implement something that is basically backend or proxy server behavior, which by now you can see The Web Platform really isn't set up for. 

Similarly, you'll inherit this weird quirk directly from the browser Javascript engine:

```jsx
console.log(btoa('Ê±âÂ≠ó'))
// The above raises a DOMException in your Cloudflare Worker with the
// following message:
// "btoa() can only operate on characters in the Latin1 (ISO/IEC 8859-1) range."
```

Yes yes, there's some sense to this ‚Äì Javascript strings are UTF-16 and that's why this example doesn't work. But take a look at Node.js where `btoa` and `atob` are not available ‚Äì Node.js has a much better answer to many of these problems.

Lastly, since many things are iterables or DOM-objects, you won't get anything useful out of console logging `request.headers`, `request.headers.keys()`, `request.headers.values()`, `request.headers.entries()`. This wouldn't be a problem if the `request`-object was fully inspectable in the debugger but nothing shows up when you open up `request.headers`.
The solution to this is just `console.log([...request.headers])`.
-->

<h2 id="conclusion">Conclusion</h2>

<p>Overall, Cloudflare Workers are really cool and the tooling around them is pretty great. But I do feel like it was an unfortunate choice to adopt The Web Platform
instead of using parts of the Node standard library or a different, more server-oriented API. Lastly, while the documentation feels fairly complete and fleshed out ‚Äì the fact
that the answers on the forum tell 2-3 different stories about whether it‚Äôs possible to change the <code>Host</code>-header means that it‚Äôs something that is ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.notifly.io/2020/11/04/hardly-working-with-cloudflare-workers">https://blog.notifly.io/2020/11/04/hardly-working-with-cloudflare-workers</a></em></p>]]>
            </description>
            <link>https://blog.notifly.io/2020/11/04/hardly-working-with-cloudflare-workers</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057709</guid>
            <pubDate>Wed, 11 Nov 2020 12:15:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Ruby on Rails Patterns and Anti-Patterns]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057531">thread link</a>) | @nikolalsvk
<br/>
November 11, 2020 | https://pragmaticpineapple.com/introduction-to-ruby-on-rails-patterns-and-anti-patterns/ | <a href="https://web.archive.org/web/*/https://pragmaticpineapple.com/introduction-to-ruby-on-rails-patterns-and-anti-patterns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><span>
      <span></span>
  <img alt="Rails Patterns" title="Rails Patterns" src="https://pragmaticpineapple.com/static/7f940e1f59fb7478eacebcbcf26b6f7c/1c72d/cover.jpg" srcset="https://pragmaticpineapple.com/static/7f940e1f59fb7478eacebcbcf26b6f7c/a80bd/cover.jpg 148w,
https://pragmaticpineapple.com/static/7f940e1f59fb7478eacebcbcf26b6f7c/1c91a/cover.jpg 295w,
https://pragmaticpineapple.com/static/7f940e1f59fb7478eacebcbcf26b6f7c/1c72d/cover.jpg 590w,
https://pragmaticpineapple.com/static/7f940e1f59fb7478eacebcbcf26b6f7c/a8a14/cover.jpg 885w,
https://pragmaticpineapple.com/static/7f940e1f59fb7478eacebcbcf26b6f7c/fbd2c/cover.jpg 1180w,
https://pragmaticpineapple.com/static/7f940e1f59fb7478eacebcbcf26b6f7c/e5166/cover.jpg 1200w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></p>

<p>Welcome to the first post in our series about Ruby on Rails Patterns and Anti-patterns. In each of the posts, we‚Äôll take a deep dive into all sorts of patterns you might come across while working with Rails apps.</p>
<p>Today, we‚Äôll show what a (design) pattern is and then try to explain what an anti-pattern is as well. To better illustrate explanations, we will use the Ruby on Rails framework that has been around for quite some time. If Rails isn‚Äôt your cup of tea for some reason, hang on, the ideas (or patterns) described here might resonate with whatever technology you wind up using.</p>
<p>But before we jump into explaining what patterns and anti-patterns are, how did we get to the point where we need them? Why do we need to have all these things for our software? Why do we need to <strong>design</strong> our solution?</p>
<h2 id="yes-you-are-a-designer"><a href="#yes-you-are-a-designer" aria-label="yes you are a designer permalink"></a>Yes, You Are a Designer</h2>
<p>Even from early computer programming days, people had to deal with the design of the programs they were writing. To write a program (or software) is to design a solution for a problem. When you write software, you are a designer‚Äîfeel free to append that to your job title. Designing good solutions is important because the software we write will be read and/or edited by others. Also, the solutions we come up with will be built on by others in the future.</p>
<p>Having all this in mind, generations of engineers started seeing similar designs in code and architecture throughout their careers. Folks started extracting and documenting standard solutions to problems. Some would say it‚Äôs a natural way of how we as humans function. We like to <a href="https://en.wikipedia.org/wiki/Principles_of_grouping">categorize</a> and <a href="https://en.wikipedia.org/wiki/Gestalt_psychology#Pr%C3%A4gnanz">find patterns</a> in everything, and software is no exception to that.</p>
<p>Being human, as we are, patterns started emerging more and more as software engineering got more complex. Software design patterns began to develop and cement themselves with engineers around the world. Books, essays, and talks were given, further spreading ideas of well thought out and battle-tested solutions. Those solutions saved a lot of people time and money, so let‚Äôs go over the term design pattern, and see what it truly is.</p>
<h2 id="what-is-a-design-pattern"><a href="#what-is-a-design-pattern" aria-label="what is a design pattern permalink"></a>What Is a Design Pattern?</h2>
<p>In software engineering, a pattern is described as a solution that can be reused to solve a common problem. The pattern is something that is considered a good practice among software engineers. Since software engineers set them, they can quickly go from patterns to their opposite‚Äîanti-patterns‚Äîbut we‚Äôll get to that later.</p>
<p>A design pattern will show you the way to the solution but it won‚Äôt give you a piece of code ready to be plugged into the rest of your software. Think of a pattern as a guide for writing well-designed code, but you have to come up with the implementation. Using patterns in day-to-day coding emerged in the late ‚Äò80s, where Kent Beck and Ward Cunningham came up with an idea of using a <a href="http://c2.com/doc/oopsla87.html">‚Äòpattern language‚Äô</a>.</p>
<p>The idea of pattern languages came in the late ‚Äô70s by Christopher Alexander in his book <a href="https://www.goodreads.com/book/show/79766.A_Pattern_Language">A Pattern Language</a>. You might be surprised, but the book is not about software engineering but the architecture of buildings. The pattern language is an organized and coherent set of patterns, each of which describes a problem and the core of a solution that can be used in many ways. Sounds familiar? (Hint: frameworks, another hint: Rails)</p>
<p>Later on, design patterns in software engineering became famous with large audiences after the legendary book <a href="https://www.goodreads.com/book/show/85009.Design_Patterns">Design Patterns</a> by the <a href="http://wiki.c2.com/?GangOfFour">Gang Of Four</a> published in 1994. In the book, there are explanations and definitions of patterns that are used nowadays ‚Äî Factory, Singleton, Decorator, just to name a few.</p>
<p>Great, now that we got acquainted or refreshed our knowledge on design and patterns, let‚Äôs find out what anti-patterns are.</p>
<h2 id="what-is-a-design-anti-pattern"><a href="#what-is-a-design-anti-pattern" aria-label="what is a design anti pattern permalink"></a>What Is a Design Anti-Pattern?</h2>
<p>If you think of patterns as the good guys, the anti-patterns are the bad ones. To be more precise, a software anti-pattern is a pattern that may be commonly used but is considered ineffective or counterproductive. Typical examples of anti-patterns are God objects that contain many functions and dependencies, which could be extracted and separated into different objects.</p>
<p>Common causes of anti-patterns in code are many. For example, a good one is when the good guy (pattern) becomes the bad guy (an anti-pattern). Let‚Äôs say you got used to using a particular technology at your previous company, and you gained a high level of competence in it. For the sake of the example, let‚Äôs use Docker. You know how to efficiently pack applications into Docker containers, orchestrate them in the cloud, and pull their logs down from the cloud. Suddenly, you get a new job where you need to ship front end applications. Since you know a lot about Docker and how to ship apps with it, your first decision is to package everything up and deploy it to the cloud.</p>
<p>But, little did you know, the front end apps are not that complex at your current job, and putting them into containers might not be the most effective solution. It first sounds like a good idea, but later down the road, it proves as counterproductive. This anti-pattern is called <a href="https://en.wikipedia.org/wiki/Law_of_the_instrument">‚ÄúGolden Hammer‚Äù</a>.</p>
<p>It can be summed up with the saying, ‚ÄúIf you have a hammer, everything looks like a nail‚Äù. If you are really good with Docker and orchestration of services, everything is a Docker service made to be orchestrated in the cloud.</p>
<p>These things happen and will happen. Good guys turn to bad buys, and vice-versa. But where do Ruby and Rails fit into this picture?</p>
<h2 id="ruby-first-then-rails"><a href="#ruby-first-then-rails" aria-label="ruby first then rails permalink"></a>Ruby First, Then Rails</h2>
<p>Most folks were introduced to Ruby by using Ruby on Rails, a popular framework for building websites quickly. I got acquainted with Ruby in the same way, nothing wrong with that. Rails is based on this well-established software pattern called Model-View-Controller, or MVC for short. But before we dive into details of the MVC pattern in Rails, one big fallacy that often happens is using Rails without learning Ruby properly.</p>
<p>The Rails framework was one of the go-to frameworks when you had an idea and wanted to build it fast. Nowadays, it‚Äôs a whole different story, Rails is still used, but not to the extent it was in its prime. Being so easy to use and run, a lot of beginners set out to build their web apps using rails new command. What happened then, along the road, problems started occurring. As a beginner, you are lured by the speed and simplicity of development with Rails, and everything works so magically and smoothly at first. Then you see you‚Äôve taken a lot of ‚Äòmagic‚Äô for granted, and you don‚Äôt understand what is going on behind the curtain.</p>
<p>I had this problem, and I‚Äôm sure many beginners and advanced beginners are suffering from it. You start with a framework in hand, you build on it, and when you try to add something highly custom, you can‚Äôt, because you‚Äôve used up all the magic points from that framework. At that point, you have to go back to the beginning and learn the basics. Going back is no biggie, happens to the best of us. But the problem grows more significant if you move on without learning the essential things, like in Ruby. One good book that can help you in this regard is <a href="https://www.goodreads.com/book/show/3892688-the-well-grounded-rubyist">The Well-Grounded Rubyist</a>.</p>
<p>As a beginner, you don‚Äôt have to read it from start to end. But keep it by your side so you can consult it quickly. I am not saying that you should suddenly stop whatever you were doing and read the whole book, but stop from time to time and refresh your knowledge of the Ruby basics, it might open some new horizons for you.</p>
<h2 id="mvc-rails-bread--butter"><a href="#mvc-rails-bread--butter" aria-label="mvc rails bread  butter permalink"></a>MVC: Rails‚Äô Bread &amp; Butter</h2>
<p>OK, but what about MVC? The Model-View-Controller pattern has been around for ages. It‚Äôs been adopted by many frameworks across a plethora of languages like Ruby (Rails), Python (Django), Java (Play, Spring MVC). The idea is to have separate components that each do their job:</p>
<ul>
<li>The Model handles data and business logic.</li>
<li>The View is for the presentation of the data and the user interface.</li>
<li>The Controller ties the two together by getting data from the Model and showing the View to the user.</li>
</ul>
<p>Sounds great in theory, and it‚Äôs excellent when the logic is minimal and your website doesn‚Äôt hold complex logic. That is where things get tricky, but we‚Äôll get to that in a second.</p>
<p>MVC spread out like wildfire throughout the web development community. Even libraries like React, which is insanely popular these days is explained as the view layer of your web app. No other pattern has been popularized so much that it cannot be shaken off. Rails added the <a href="https://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern">Publish-Subscribe</a> with ActionCable, where the concept of <a href="https://guides.rubyonrails.org/action_cable_overview.html#terminology">channels is described as the controller</a> of the MVC pattern.</p>
<p>But what are the anti-patterns there, in the so widely used pattern? Let‚Äôs go over some of the most common anti-patterns for each part of the MVC pattern.</p>
<h3 id="model-problems"><a href="#model-problems" aria-label="model problems permalink"></a>Model Problems</h3>
<p>As an application grows and business logic gets expanded, folks tend to overcrowd their models. Constant growth can lead to an anti-pattern called the Fat Model.</p>
<p>The famous ‚ÄòFat Model, Skinny Controller‚Äô pattern identifies as a bad guy, some as the good guy. We will say that having any of the fat is an anti-pattern. To better understand it, let‚Äôs get into an example. Imagine we have a streaming service like Spotify or Deezer. Inside it, we have a model for songs like this:</p>
<div data-language="rb"><pre><code><span>class</span> <span>Song</span> <span>&lt;</span> <span>ApplicationRecord</span>
  belongs_to <span>:album</span>
  belongs_to <span>:artist</span>
  belongs_to <span>:publisher</span>

  has_one <span>:text</span>
  has_many <span>:downloads</span>

  validates <span>:artist_id</span><span>,</span> presence<span>:</span> <span>true</span>
  validates <span>:publisher_id</span><span>,</span> presence<span>:</span> <span>true</span>

  after_update <span>:alert_artist_followers</span>
  after_update <span>:alert_publisher</span>

  <span>def</span> <span><span>alert_artist_followers</span></span>
    <span>return</span> <span>if</span> unreleased<span>?</span>

    artist<span>.</span>followers<span>.</span><span>each</span> <span>{</span> <span>|</span>follower<span>|</span> follower<span>.</span>notify<span>(</span><span>self</span><span>)</span> <span>}</span>
  <span>end</span>

  <span>def</span> <span><span>alert_publisher</span></span>
    <span>PublisherMailer</span><span>.</span>song_email<span>(</span>publisher<span>,</span> <span>self</span><span>)</span><span>.</span>deliver_now
  <span>end</span>

  <span>def</span> <span><span>includes_profanities</span></span><span>?</span>
    text<span>.</span>scan_for_profanities<span>.</span>any<span>?</span>
  <span>end</span>

  <span>def</span> <span><span>user_downloaded</span></span><span>?</span><span>(</span>user<span>)</span>
    user<span>.</span>library<span>.</span>has_song<span>?</span><span>(</span><span>self</span><span>)</span>
  <span>end</span>

  <span>def</span> <span><span>find_published_from_artist_with_albums</span></span>
    <span>.</span><span>.</span><span>.</span>
  <span>end</span>

  <span>def</span> <span><span>find_published_with_albums</span></span>
    <span>.</span><span>.</span><span>.</span>
  <span>end</span>

  <span>def</span> <span><span>to_wav</span></span>
    <span>.</span><span>.</span><span>.</span>
  <span>end</span>

  <span>def</span> <span><span>to_mp3</span></span>
    <span>.</span><span>.</span><span>.</span>
  <span>end</span>

  <span>def</span>‚Ä¶</code></pre></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pragmaticpineapple.com/introduction-to-ruby-on-rails-patterns-and-anti-patterns/">https://pragmaticpineapple.com/introduction-to-ruby-on-rails-patterns-and-anti-patterns/</a></em></p>]]>
            </description>
            <link>https://pragmaticpineapple.com/introduction-to-ruby-on-rails-patterns-and-anti-patterns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057531</guid>
            <pubDate>Wed, 11 Nov 2020 11:42:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The rise of the bystander as a complicit historical actor]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057512">thread link</a>) | @rbanffy
<br/>
November 11, 2020 | https://psyche.co/ideas/the-bystanders-rise-as-a-morally-complicit-actor-in-history | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/the-bystanders-rise-as-a-morally-complicit-actor-in-history">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>At about 3 o√¢‚Ç¨‚Ñ¢clock</strong> one morning in the early spring of 1964, Kitty Genovese, 28, arrived home from the bar in New York City where she worked, as she did morning after morning. While she walked in darkness from the lot where she√¢‚Ç¨‚Ñ¢d parked her car, an assailant attacked her, drove away and then returned to assault her some more. Genovese repeatedly screamed for help. Several neighbours reported hearing her but, as the <a href="https://aeon.co/essays/why-don-t-people-come-to-the-rescue-of-victims-of-crime" rel="noopener">story</a> goes, no one answered her calls. The assailant left her eventually to die.</p>
<p><em>The New York Times</em> gave the incident routine coverage: Genovese was one more victim of brutal assault on the streets of the city. But a couple of weeks later, the story made front-page news. There were no new facts or startling discoveries; what was new was the reframing of the story: where were the neighbours? How could they so heartlessly ignore the victim√¢‚Ç¨‚Ñ¢s cries for help? What was just another violent crime turned into a sensational murder case. Genovese became a household name associated with what grew into a controversial story about bystanders and their complicit silence. The residents of the Mowbray, an apartment complex in Queens across the street from the crime scene, were in the unenviable position of having to defend themselves from international criticism. They asserted that it was, after all, three in the morning and they were asleep √¢‚Ç¨‚Äú moreover, with windows shut tight against the outside cold. Some claimed that, even if they√¢‚Ç¨‚Ñ¢d called the police, they wouldn√¢‚Ç¨‚Ñ¢t have responded to yet another street crime.</p>
<p>Bystander incrimination has taken root. Over time, bystanders were called out for summary condemnation. The activist Abbie Hoffman remarked: √¢‚Ç¨ÀúAnd so you ask, √¢‚Ç¨≈ìWhat about innocent bystanders?√¢‚Ç¨ÔøΩ But we are in a time of revolution. If you are a bystander, you are not innocent.√¢‚Ç¨‚Ñ¢ The political philosopher Hannah Arendt, also writing in the 1960s, made the point by referring to the requirements of civil conduct: our √¢‚Ç¨Àúvicarious responsibility for things we have not done, this taking upon ourselves the consequences for things we are entirely innocent of, is the price we pay for the fact that we live our lives not by ourselves but among our fellow [citizens].√¢‚Ç¨‚Ñ¢</p>
<p>The alleged responsibilities of bystanders acquired such moral force that critics have pushed back. Victoria Barnett, author of <em>Bystanders: Conscience and Complicity During the Holocaust</em> (1999), asked: √¢‚Ç¨ÀúWhat lies beneath the surface [of silence]?√¢‚Ç¨‚Ñ¢ suggesting that fear or perpetrator allegiance explains the reticence of onlookers. Henrik Edgren, another scholar who has written about bystanders, posits assertions that are similarly exculpatory, explaining that bystanders are often coerced from interfering in harmful acts. Offering canonic justification for bystander inertia, the evidence-based theory of the bystander effect proposed in 1968 by the social psychologists John Darley and Bibb Latan√É¬© <a href="https://psycnet.apa.org/record/1968-08862-001" rel="nofollow noreferrer noopener">argued</a> that onlookers fail to intervene when they believe that others will.</p>
<p>The presumption of bystanders√¢‚Ç¨‚Ñ¢ responsibility has, however, crystallised into the predominant opinion. Good Samaritan laws ratify intervention and protect √¢‚Ç¨Àúupstanders√¢‚Ç¨‚Ñ¢ from liability. Bystander intervention is now axiomatic, a paragon of civic behaviour. Consider, by contrast, an image from the Tulsa race massacre of 1921 in Oklahoma: men and women blithely go about their business while the city within view burns. Images of lynchings are also revealing: onlookers, hardly indifferent, are downright jubilant. Nazi authorities made a point of including onlookers in their documentation of persecution. Edgren is no doubt right about the risks of intervention, but it is just as likely that German onlookers felt lucky to be on the right side of history or were even impressed with the clarity that the Nazis achieved about who belonged to the new Germany and who didn√¢‚Ç¨‚Ñ¢t. Other images from the Nazi period confirm that looking on was acceptable behaviour, if not a joyful experience, often serving to bind observers into a community of privileged insiders. Images of <em>Kristallnacht</em>, for example, show spectators gazing inertly at a burning synagogue and urban passers-by oblivious to the effects of racially inspired vandalism.</p>
<p>Jews remonstrated as strongly against the indifference of onlookers as they did against their assailants</p>
<p><strong>Paradoxically, the Nazi</strong> period was pivotal in turning public opinion against bystanders. Victims were making themselves heard. In 1935, Joachim Prinz, a leader of the German Jewish community, wrote an early and classic statement of bystander incrimination when racism was again on the rise after a two-year lull in state-inspired antisemitism. The notorious Nuremberg Laws, which emerged later that year, would codify national apartheid. Jews, wrote Prinz, were dangerously vulnerable, but just as ominous, he asserted, was the silence of his compatriots: √¢‚Ç¨ÀúThe Jews of small towns, who live at the market square without neighbours, whose children go to school without neighbouring children, feel the isolation √¢‚Ç¨¬¶√¢‚Ç¨‚Ñ¢ It √¢‚Ç¨Àúmight be the hardest lot anyone can befall√¢‚Ç¨‚Ñ¢ √¢‚Ç¨‚Äú as hard as persecution itself.</p>
<p>Jews, whose demise accelerated during the Second World War, remonstrated as strongly against the indifference of onlookers as they did against their assailants. Writing in 1944 from his hiding place in Warsaw, Tadeusz Obr√Ñ‚Ñ¢ski reviled the Polish government-in-exile:</p>
<blockquote>Why √¢‚Ç¨¬¶ didn√¢‚Ç¨‚Ñ¢t it order the Poles, back in 1939, to help Jews hide from the German murderers? Why did they keep silent? Why did they let, and why are they still letting, us be destroyed, here on the Aryan side? √¢‚Ç¨¬¶ The Polish people betrayed three and a half million Jews. This is a fact which will be discussed in [future] history.</blockquote>
<p>Obr√Ñ‚Ñ¢ski made sure that, in losing hope for survival, he would save his final, bitter words for feckless officials and ordinary citizens alike.</p>
<p>It√¢‚Ç¨‚Ñ¢s unlikely that the turn from bystander innocence to bystander incrimination started during the Nazi period. We need more research on the history of bystander construction to clarify its emergence as consensus opinion. Did Black people in the United States, for example, implore white neighbours for protection against the systems of slavery and Jim Crow? We find little evidence for this until the mobilisation of the civil rights movement in the 1950s and √¢‚Ç¨‚Ñ¢60s, and Black people did so then in good part because the Holocaust and its legacy exposed bystanders√¢‚Ç¨‚Ñ¢ complicity. Writing in 1963, Martin Luther King, Jr commented that, though it was √¢‚Ç¨Àú√¢‚Ç¨≈ìillegal√¢‚Ç¨ÔøΩ to aid and comfort a Jew in Hitler√¢‚Ç¨‚Ñ¢s Germany √¢‚Ç¨¬¶ had I lived in Germany at the time I would have aided and comforted my Jewish brothers.√¢‚Ç¨‚Ñ¢ At the time, the Black militant magazine <em>The Liberator</em> frequently referred to the consequences of passivity during the Holocaust era, as it saw it, to inspire action as well, turning its attention to Black people themselves.</p>
<p>Historically, European Jews could hardly imagine that their neighbours wouldn√¢‚Ç¨‚Ñ¢t provide protection whenever they were collectively threatened. Obr√Ñ‚Ñ¢ski√¢‚Ç¨‚Ñ¢s reference to betrayal is significant. For Jews, the system had been favourable. Their statutory emancipation from medieval ghettos, spanning the late-18th to late-19th centuries, promised their recognition as citizens, which entitled them to equal protections secured by the rule of law. It was not unreasonable for Jews to expect protection, if not from the state then from other Germans. As Prinz wrote: √¢‚Ç¨ÀúWe would not find it all [isolation] so painful if we did not have the feeling that we once did have neighbours.√¢‚Ç¨‚Ñ¢</p>
<p>Black Americans, by contrast had no choice but to rely on other Black Americans. Some even argue, and argue persuasively, that it√¢‚Ç¨‚Ñ¢s more prudent this way because relying on others for help would put Black people at the mercy of their capricious neighbours, a policy that ultimately proved fatal for Jews. In retrospect, Jews rued their naivety. They suffered from the unanticipated abandonment of their compatriots. Abandonment, <a href="https://www.jstor.org/stable/1344023?seq=1" rel="nofollow noreferrer noopener">wrote</a> the Holocaust survivor Vladimir Jank√É¬©l√É¬©vitch, was √¢‚Ç¨Àúone of the most frightful aspects of their ordeal√¢‚Ç¨‚Ñ¢. Simon Wiesenthal, another survivor, elaborated: √¢‚Ç¨ÀúOur fathers had crept out of the confines of the [premodern] ghetto into the open world. They had worked hard and done all they could to be recognised by their fellow creatures. But it was all in vain.√¢‚Ç¨‚Ñ¢ Like Prinz, Wiesenthal felt the sting of abject betrayal.</p>
<p>Informed by the memory of the Holocaust, onlookers metamorphosed into accessories to crime</p>
<p><strong>The discourse of bystander</strong> incrimination grew stronger in the 1960s. Bystanders were roundly condemned for their indifference. While onlookers and others offered exculpatory reasons for inaction, victims were unwavering: bystanders were unconditionally complicit. King, writing from a Birmingham jail, observed: √¢‚Ç¨ÀúWe will have to repent in this generation not merely for the hateful words and the actions of the bad people but for the appalling silence of the good people.√¢‚Ç¨‚Ñ¢ Jewish survivors were also vocal. At the signature Great March on Washington the same year, Prinz, now a German expatriate and American citizen, echoed what he wrote three decades before:</p>
<blockquote>When I was a rabbi of the Jewish community in Berlin under the Hitler regime √¢‚Ç¨¬¶ the most important thing that I learned √¢‚Ç¨¬¶ is that bigotry and hatred are not the most urgent problem. The most urgent, the most disgraceful, the most shameful and the most tragic problem is silence. A great people which had created a great civilisation had become a nation of onlookers √¢‚Ç¨¬¶ America must not become a nation of onlookers. America must not remain silent.</blockquote>
<p>The 1960s was the decade when Holocaust survivors started to publish their accounts for a largely unsympathetic audience: Jank√É¬©l√É¬©vitch in 1967, Wiesenthal in 1969 and, among the most reflective memoirists, Jean Am√É¬©ry in 1966. Later, Am√É¬©ry wrote with bitter irony that: √¢‚Ç¨ÀúThe expectation of help, the certainty ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/ideas/the-bystanders-rise-as-a-morally-complicit-actor-in-history">https://psyche.co/ideas/the-bystanders-rise-as-a-morally-complicit-actor-in-history</a></em></p>]]>
            </description>
            <link>https://psyche.co/ideas/the-bystanders-rise-as-a-morally-complicit-actor-in-history</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057512</guid>
            <pubDate>Wed, 11 Nov 2020 11:37:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Connect your on-premises databases to Kubernetes in the cloud]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057481">thread link</a>) | @alexellisuk
<br/>
November 11, 2020 | https://inlets.dev/blog/2020/11/06/hybrid-cloud-with-inlets.html | <a href="https://web.archive.org/web/*/https://inlets.dev/blog/2020/11/06/hybrid-cloud-with-inlets.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Learn how to connect private on-premises services to the public cloud with inlets</p>

<h2 id="what-is-hybrid-cloud-anyway">What is ‚Äúhybrid cloud‚Äù anyway?</h2>

<p>Before we get started, let‚Äôs have a clear idea what ‚Äúhybrid cloud‚Äù is all about.</p>

<blockquote>
  <p>‚Äú<strong>Hybrid Cloud</strong> is a composition of a public cloud and a private environment, such as a private cloud or on-premises resources, offering the benefits of multiple deployment models. ‚Ä¶ For example, an organization may store sensitive client data in house on a private cloud application, but interconnect that application to services provided on a public cloud as a software service.‚Äù ‚Äì <a href="https://en.wikipedia.org/wiki/Cloud_computing#Hybrid_cloud">Wikipedia</a></p>
</blockquote>

<p>A hybrid cloud strategy can give a huge benefit for your business by moving workloads to a public cloud, leveraging the flexibility and robustness of managed services, while keeping sensitive data on a private cloud or local data center.</p>

<p>In this post, we‚Äôll demonstrate how you can bring your on-premises services or databases into a Kubernetes cluster running on a public cloud.</p>

<p>This model applies for different use-cases:</p>
<ul>
  <li>perhaps you are in the middle of a digital transformation where some parts of the architecture is deployed on a public cloud, but they still need to integrate with some legacy services</li>
  <li>you have some sensitive data to be kept in a private data center due to data residency regulation</li>
</ul>

<h2 id="tutorial">Tutorial</h2>

<p>You‚Äôll need:</p>
<ul>
  <li>A Kubernetes cluster running on a public cloud (e.g. GKE, AKS, EKS, DOKS, ‚Ä¶)</li>
  <li><code>kubectl</code>, configured to connect to the cluster</li>
  <li>A domain and access to your DNS admin panel to create a sub-domain</li>
  <li>A service, like a database, running locally</li>
  <li>An inlets PRO license, start <a href="https://docs.google.com/forms/d/e/1FAIpQLScfNQr1o_Ctu_6vbMoTJ0xwZKZ3Hszu9C-8GJGWw1Fnebzz-g/viewform?usp=sf_link">a 14-day free trial</a>.</li>
</ul>

<p>As an example, we will connect a WordPress instance running in the cloud with a MySQL server running locally. Still, this solution is perfectly applicable to other databases or services like e.g. an Oracle database, a MinIO cluster or a RabbitMQ service.</p>

<p><img src="https://inlets.dev/images/2020-11-06-hybrid-cloud-with-inlets/mysql-wordpress.png" alt="hybrid-mysql-wordpress"></p>

<blockquote>
  <p>Picture above: our target architecture, a WordPress in the cloud connecting to a MySQL on-prem via inlets PRO</p>
</blockquote>

<h3 id="create-the-inlets-pro-exit-server">Create the inlets PRO exit server</h3>

<p>Before we start an inlets-pro exit service, create a Kubernetes secret with a token:</p>

<div><div><pre><code>kubectl create secret generic inlets-token <span>--from-literal</span><span>=</span><span>token</span><span>=</span>&lt;a random token&gt;
</code></pre></div></div>

<p>First, start an inlets-pro exit server pod and make it public with a LoadBalancer service:</p>

<div><div><pre><code><span>apiVersion</span><span>:</span> <span>apps/v1</span>
<span>kind</span><span>:</span> <span>Deployment</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>inlets-pro-server</span>
<span>spec</span><span>:</span>
  <span>replicas</span><span>:</span> <span>1</span>
  <span>selector</span><span>:</span>
    <span>matchLabels</span><span>:</span>
      <span>app</span><span>:</span> <span>inlets-pro-server</span>
  <span>template</span><span>:</span>
    <span>metadata</span><span>:</span>
      <span>labels</span><span>:</span>
        <span>app</span><span>:</span> <span>inlets-pro-server</span>
    <span>spec</span><span>:</span>
      <span>containers</span><span>:</span>
        <span>-</span> <span>name</span><span>:</span> <span>inlets-pro</span>
          <span>image</span><span>:</span> <span>inlets/inlets-pro:0.7.2</span>
          <span>imagePullPolicy</span><span>:</span> <span>IfNotPresent</span>
          <span>command</span><span>:</span> <span>[</span> <span>"</span><span>inlets-pro"</span> <span>]</span>
          <span>args</span><span>:</span>
            <span>-</span> <span>"</span><span>server"</span>
            <span>-</span> <span>"</span><span>--auto-tls"</span>
            <span>-</span> <span>"</span><span>--common-name=inlets.example.com"</span>
            <span>-</span> <span>"</span><span>--token-from=/etc/inlets/token"</span>
          <span>volumeMounts</span><span>:</span>
            <span>-</span> <span>name</span><span>:</span> <span>temp-volume</span>
              <span>mountPath</span><span>:</span> <span>/tmp</span>
            <span>-</span> <span>name</span><span>:</span> <span>inlets-token</span>
              <span>mountPath</span><span>:</span> <span>/etc/inlets</span>
              <span>readOnly</span><span>:</span> <span>true</span>   
      <span>volumes</span><span>:</span>
        <span>-</span> <span>name</span><span>:</span> <span>temp-volume</span>
          <span>emptyDir</span><span>:</span> <span>{}</span>        
        <span>-</span> <span>name</span><span>:</span> <span>inlets-token</span>
          <span>secret</span><span>:</span>
            <span>secretName</span><span>:</span> <span>inlets-token</span>
</code></pre></div></div>

<p>After applying this on the cluster, a exit server pod is available with:</p>

<ul>
  <li><code>auto-tls</code> enabled, meaning a TLS certificate for the <code>common-name</code> is automatically generated</li>
  <li>the default control port 8123</li>
  <li>the token available in the previously created secret</li>
</ul>

<p>Now expose the exit server with a LoadBalancer service:</p>

<div><div><pre><code><span>apiVersion</span><span>:</span> <span>v1</span>
<span>kind</span><span>:</span> <span>Service</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>inlets-pro-server</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>inlets-pro-server</span>
<span>spec</span><span>:</span>
  <span>type</span><span>:</span> <span>LoadBalancer</span>
  <span>ports</span><span>:</span>
    <span>-</span> <span>name</span><span>:</span> <span>control</span>
      <span>port</span><span>:</span> <span>8123</span>
      <span>targetPort</span><span>:</span> <span>8123</span>
  <span>selector</span><span>:</span>
    <span>app</span><span>:</span> <span>inlets-pro-server</span>
</code></pre></div></div>

<blockquote>
  <p>Instead of using a LoadBalancer service, a Kubernetes Ingress can also be used here, especially when bringing multiple services into your cluster.</p>
</blockquote>

<p>As you can see, we‚Äôll only expose the control port 8123 to the outside world.
This is actually a good thing, as our database will only reachable from within our Kubernetes cluster, making it more secure.</p>

<p>Wait a little bit until the load balancer is created, grab it‚Äôs public IP address and point your domain (remember the common-name) to it.</p>

<div><div><pre><code><span>$ </span>kubectl get service inlets-pro-server
NAME                TYPE           CLUSTER-IP       EXTERNAL-IP       PORT<span>(</span>S<span>)</span>          AGE
inlets-pro-server   LoadBalancer   192.168.197.17   185.136.232.105   8123:31981/TCP   8m11s
</code></pre></div></div>

<blockquote>
  <p>TIP: Some cloud providers honor the <code>loadBalancerSourceRanges</code> field in the Service spec, which allows you to provide a list of IP CIDR blocks allowed to connect to the load balancer. By creating firewall rules, only connections coming from your on-prem data center are allowed.</p>
</blockquote>

<h3 id="start-the-inlets-pro-client">Start the inlets-pro client</h3>

<p>Now that the server part of the tunnel is running, it is time to start the client in our private data center.
Let‚Äôs say we have a MySQL instance available with an internal IP address <code>10.1.0.50</code>, start the inlets-pro client:</p>

<div><div><pre><code><span>$ </span>inlets-pro client <span>--license-file</span> ~/inlets-license <span>--port</span> 3306 <span>--url</span> wss://inlets.example.com:8123/connect <span>--upstream</span> 10.1.0.50 <span>--token</span> &lt;your token&gt; 
2020/11/05 13:23:21 Welcome to inlets-pro! Client version 0.7.2
2020/11/05 13:23:21 Licensed to: Johan Siebens &lt;xxxx@gmail.com&gt;, expires: xxx day<span>(</span>s<span>)</span>
2020/11/05 13:23:21 Upstream server: 10.1.0.50, <span>for </span>ports: 3306
inlets-pro client. Copyright Alex Ellis, OpenFaaS Ltd 2020
INFO[2020/11/05 13:23:21] Connecting to proxy                           <span>url</span><span>=</span><span>"wss://inlets.example.com:8123/connect"</span>
</code></pre></div></div>

<p>Perfect! Now the client made the connection, port 3306 of the server pod in our public cloud is accepting connection and will tunnel traffic to the MySQL instance.</p>

<h3 id="create-a-mysql-service">Create a MySQL service</h3>

<p>When we deploy WordPress, we could configure it to connect directly to the inlets-pro server pod, but it is better to create Kubernetes Service:</p>

<div><div><pre><code><span>apiVersion</span><span>:</span> <span>v1</span>
<span>kind</span><span>:</span> <span>Service</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>mysql</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>mysql</span>
<span>spec</span><span>:</span>
  <span>ports</span><span>:</span>
    <span>-</span> <span>name</span><span>:</span> <span>mysql</span>
      <span>port</span><span>:</span> <span>3306</span>
      <span>targetPort</span><span>:</span> <span>3306</span>
  <span>selector</span><span>:</span>
    <span>app</span><span>:</span> <span>inlets-pro-server</span>
</code></pre></div></div>

<p>The set of Pods targeted by this Service is determined by the same selector as the previous service, but this time it is a service of type ClusterIP, making it only accessible from inside the cluster.</p>

<h3 id="deploy-wordpress">Deploy WordPress</h3>

<p>The only thing left for our example is deploying a WordPress instance, connecting to the MySQL database via the inlets-pro tunnel:</p>

<div><div><pre><code><span>apiVersion</span><span>:</span> <span>apps/v1</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>wordpress</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>wordpress</span>
<span>spec</span><span>:</span>
  <span>selector</span><span>:</span>
    <span>matchLabels</span><span>:</span>
      <span>app</span><span>:</span> <span>wordpress</span>
  <span>template</span><span>:</span>
    <span>metadata</span><span>:</span>
      <span>labels</span><span>:</span>
        <span>app</span><span>:</span> <span>wordpress</span>
    <span>spec</span><span>:</span>
      <span>containers</span><span>:</span>
      <span>-</span> <span>image</span><span>:</span> <span>wordpress</span>
        <span>name</span><span>:</span> <span>wordpress</span>
        <span>env</span><span>:</span>
        <span>-</span> <span>name</span><span>:</span> <span>WORDPRESS_DB_HOST</span>
          <span>value</span><span>:</span> <span>mysql</span>
        <span>ports</span><span>:</span>
        <span>-</span> <span>containerPort</span><span>:</span> <span>80</span>
          <span>name</span><span>:</span> <span>wordpress</span>
</code></pre></div></div>

<blockquote>
  <p>note: this WordPress is not production-ready as it is missing the required volumes for the content</p>
</blockquote>

<p>Mission accomplished! Our WordPress application, running in a public cloud environments is using the MySQL server located in the private data center.</p>

<h2 id="wrapping-up">Wrapping up</h2>

<p>This tutorial gives us a short introduction on how inlets PRO can help us to build a hybrid cloud between existing servers and public cloud.
As a cheaper, easier alternative to a data-center uplink or managed product like AWS Direct Connect or Azure Express Route it is a very lightweight, but powerful, tool to bring your on-prem services to a cloud workload.</p>

<p>For the example we chose WordPress, but the same technique can be applied to any other applications that use TCP traffic.</p>

<ul>
  <li>Resource heavy ETL processes on the cloud, combining multiple data sources like private legacy databases and event streams in the public cloud.</li>
  <li>Data migrations from and to on-prem databases</li>
  <li>Connect your new application to legacy service during a digital transformation</li>
  <li>Keep your LDAP side on-premises in Active Directory and connect to a SaaS IDP product like Auth0. That way anyone can log into a website using their corporate identity without having to migrate Active Directory to the cloud.</li>
</ul>

<p>Further resources:</p>

<ul>
  <li><a href="https://docs.inlets.dev/">Read tutorials and documentation for inlets PRO and OSS</a></li>
  <li><a href="https://inlets.dev/">Kick the tires with free 14-day trial of inlets PRO</a></li>
  <li><a href="https://twitter.com/inletsdev/">Follow @inletsdev on Twitter</a></li>
</ul>

        </div></div>]]>
            </description>
            <link>https://inlets.dev/blog/2020/11/06/hybrid-cloud-with-inlets.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057481</guid>
            <pubDate>Wed, 11 Nov 2020 11:32:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EmacsConf ‚Äì 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057456">thread link</a>) | @ProfDreamer
<br/>
November 11, 2020 | https://emacsconf.org/2020/ | <a href="https://web.archive.org/web/*/https://emacsconf.org/2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">



<div id="pagebody">







<div id="content" role="main">
<p>EmacsConf 2020 | Online Conference | <strong>November 28 and 29, 2020</strong><br>
<a href="https://emacsconf.org/i/emacsconf-logo1-256.png"><img src="https://emacsconf.org/i/emacsconf-logo1-256.png" width="256" height="256" alt="EmacsConf logo"></a><br>
<a href="https://emacsconf.org/2020/schedule/"><strong>Schedule</strong></a> | <a href="https://emacsconf.org/2020/poster/"><strong>Poster</strong></a> | <a href="https://emacsconf.org/2020/planning/">Planning</a> |
<a href="https://emacsconf.org/conduct/">Code of Conduct</a></p>

<p>EmacsConf is the conference about the joy of Emacs, Emacs Lisp, and
memorizing key sequences.</p>

<p>We are holding EmacsConf 2020 as a virtual (online) conference again
this year, especially now, given the current state of the world with
the ongoing global pandemic. We remain fully committed to freedom, and
we will continue using our infrastructure and streaming setup
consisting entirely of <a href="https://www.gnu.org/philosophy/free-sw.html">free software</a>, much like the last
EmacsConf. Check out the <a href="https://emacsconf.org/2020/schedule/"><strong>Schedule</strong></a> and
<a href="https://emacsconf.org/2020/poster/"><strong>Poster</strong></a> for more details.</p>

<h2>Watching</h2>

<p>On November 28 and 29 you will be able to watch the livestreams via
<a href="https://live.emacsconf.org/">https://live.emacsconf.org</a>, which also has details on how to watch the
streams using media players that support streaming (like mpv and VLC).</p>

<p>We'll record the conference and post the videos and links on the
individual talk pages. In the meantime, please enjoy
<a href="https://emacsconf.org/2019/talks/">last year's talks</a>.</p>

<h2>Participating</h2>

<p>For audience questions specifically, we will be experimenting with
using a collaboratively-editable Etherpad as the primary means of
collecting audience questions. We will be posting a link to the pad
closer to the event. If, however, you are unable to access the pad to
add your question(s), we will still try to take questions from our
questions-specific IRC channel (<code>#emacsconf-questions</code> on
<code>chat.freenode.net</code>), and ask one or two volunteers to kindly add
questions from that channel to the pad on behalf of folks who are not
able to or prefer not to use the web-based questions pad.</p>

<p>Come hang out with us in <code>#emacsconf</code> on <code>chat.freenode.net</code>.  You can
join the chat using <a href="ircs://chat.freenode.net:6697/emacsconf">your favourite IRC client</a>, or by visiting
<a href="https://chat.emacsconf.org/">chat.emacsconf.org</a> in your web browser, a self-hosted instance
of <a href="https://thelounge.chat/">The Lounge</a> free software web IRC client for EmacsConf.</p>

<h2>Updates</h2>

<p>Be sure to subscribe to our mailing list
<a href="https://lists.gnu.org/mailman/listinfo/emacsconf-discuss">emacsconf-discuss</a> for discussion and
announcements about the conference.</p>

</div>







</div>



</div></div>]]>
            </description>
            <link>https://emacsconf.org/2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057456</guid>
            <pubDate>Wed, 11 Nov 2020 11:26:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[hystreet.com]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25057455">thread link</a>) | @weinzierl
<br/>
November 11, 2020 | https://hystreet.com/en/methodology | <a href="https://web.archive.org/web/*/https://hystreet.com/en/methodology">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><section><div><div><div><h2>Technical principles</h2><p>hystreet.com measures the number of people crossing an imaginary line on a shopping street 24 hours a day, 365 days a year. The laser scanners attached to the facades of houses generate a fourfold light curtain for reliable pedestrian frequency counting. This enables the counter not only to distinguish between different zones, but also to determine the walking directions of pedestrians. Pedestrians who cross an imaginary line several times within a measuring interval are counted anew.</p><p>Furthermore, with this technique, it is possible to distinguish between children and adults, as body size is also a measurable feature. On our website you will find only the pedestrian frequencies of pedestrians over a size of 80 cm.</p></div></div></div></section><section><div><div><div><h2>Live Data</h2><p>Be in the picture at any time and anywhere about the passersby frequency - with the mobile version of hystreet.com you also have the opportunity to conveniently access and analyze all data on the go. All important features and settings are available in the mobile version as well as the ability to save data.</p></div></div></div></section><section><div><div><h2>Hourly retrieval</h2><p>The pedestrian frequency is available for every hour of the year. Thus all daily maximum values are recognizable.</p></div></div></section><section><div><div><h2>Weather data for all metering points</h2><p>We show additional weather data for each measured value of our locations, to provide more context for each measurement. <a href="https://darksky.net/poweredby/">Powered by Dark Sky</a>.</p><ul><li><span>Clear sky, after sunrise</span></li><li><span>Clear sky, after sunset</span></li><li><span>Partly cloudy, after sunrise</span></li><li><span>Partly cloudy, after sunset</span></li><li><span>Mostly cloudy</span></li><li><span>Rainy</span></li><li><span>Windy</span></li><li><svg viewBox="0 0 512 512" width="32"><path fill="currentColor" d="M416 128c-.6 0-1.1.2-1.6.2 1.1-5.2 1.6-10.6 1.6-16.2 0-44.2-35.8-80-80-80-24.6 0-46.3 11.3-61 28.8C256.4 24.8 219.3 0 176 0 114.2 0 64 50.1 64 112c0 7.3.8 14.3 2.1 21.2C27.8 145.8 0 181.5 0 224c0 53 43 96 96 96h320c53 0 96-43 96-96s-43-96-96-96zm57.5 239.5h-435c-8.8 0-16 7.2-16 16v16c0 8.8 7.2 16 16 16h435c8.8 0 16-7.2 16-16v-16c0-8.8-7.2-16-16-16zm0 96h-435c-8.8 0-16 7.2-16 16v16c0 8.8 7.2 16 16 16h435c8.8 0 16-7.2 16-16v-16c0-8.8-7.2-16-16-16z"></path></svg><span>Fog</span></li><li><span>Snowfall</span></li><li><svg id="cloud-sleet_svg__Layer_1" x="0" y="0" viewBox="0 0 512 512" xml:space="preserve" width="32"><g fill="currentColor"><path d="M144.7 395.5c15.4 0 27.8 12.5 27.8 27.8 0 15.4-12.5 27.8-27.8 27.8-15.4 0-27.8-12.5-27.8-27.8-.1-15.4 12.4-27.8 27.8-27.8zM256 451.1c15.4 0 27.8 12.5 27.8 27.8 0 15.4-12.5 27.8-27.8 27.8-15.4 0-27.8-12.5-27.8-27.8s12.4-27.8 27.8-27.8zM367.3 395.5c15.4 0 27.8 12.5 27.8 27.8 0 15.4-12.5 27.8-27.8 27.8-15.4 0-27.8-12.5-27.8-27.8 0-15.4 12.5-27.8 27.8-27.8z"></path><path d="M416 128c-.6 0-1.1.2-1.6.2 1.1-5.2 1.6-10.6 1.6-16.2 0-44.2-35.8-80-80-80-24.6 0-46.3 11.3-61 28.8C256.4 24.8 219.3 0 176 0 114.2 0 64 50.1 64 112c0 7.3.8 14.3 2.1 21.2C27.8 145.8 0 181.5 0 224c0 53 43 96 96 96h32.7l.1 35.5c0 8.9 7.2 16 16.1 15.9 2.9 0 5.6-.8 7.9-2.1 4.8-2.7 8-7.9 8-13.9l-.1-35.4H240l.2 84.4c0 8.9 7.2 16 16.1 15.9 2.9 0 5.6-.8 7.9-2.1 4.8-2.7 8-7.9 8-13.9L272 320h79.4l.1 35.5c0 8.9 7.2 16 16.1 15.9 2.9 0 5.6-.8 7.9-2.1 4.8-2.7 8-7.9 8-13.9l-.1-35.4H416c53 0 96-43 96-96s-43-96-96-96z"></path></g></svg><span>Sleet</span></li></ul></div></div></section><section><div><div><h2>Eye-safe and safe under data protection law</h2><p>The technique we use is eye-safe and invisible.
Personal data is not collected with this technology. Thus
we work with a 100% GDPR compliant solution.</p><h2>99% counting accuracy</h2><p>According to the manufacturer, a counting accuracy of 99% can be achieved with the technology used up to a flow rate of approx. 500 persons per minute.</p><h2>Precise positioning of the laser scanners</h2><p>Laser scanners (type PeCo LC) are permanently installed on the facades at all metering points. The devices are installed at a height between 4 and 20 metres. The device can thus optimally measure a road width of up to 32 metres.</p><p>For street widths over 32 metres, it is possible to measure from two opposite sides. The published data is always the pedestrian frequency of the entire street width (unless otherwise specified).</p><h2>Verification of data</h2><p>The laser must have a clear view in its measuring lines. If these once blocked by external circumstances (e.g. scaffolding, cranes, superstructures or treetops), temporary measurement inaccuracies may occur as a result. Even in case of power failures it is not possible to measure the frequencies. The measured data are therefore randomly checked and corrected if necessary.</p></div></div></section><section><div><div><p><span>Peco LC</span></p><div><h2>Technical data PeCo LC</h2><ul><li>Laser class 1</li><li>Weight: 3,4kg</li><li>Dimension: 247x121x109 (hxdxw)</li><li>Minimum installation height 4m, Maximum height: 20 m</li><li>Power consumption: 0.047 kW/h, electricity costs: ca. 45‚Ç¨/year</li></ul></div></div></div><p><img src="https://hystreet.com/packs/media/sections/assets/lase-logo-713d4738753630d32ce040de8be25fc4.png"></p></section><section><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" preserveAspectRatio="none" style="bottom:100%"><polygon points="0,100 100,100 0,0"></polygon></svg></section></div></div></div>]]>
            </description>
            <link>https://hystreet.com/en/methodology</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057455</guid>
            <pubDate>Wed, 11 Nov 2020 11:26:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fork Awesome: a fork of the iconic font and CSS toolkit]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057452">thread link</a>) | @edward
<br/>
November 11, 2020 | https://forkaweso.me/Fork-Awesome/ | <a href="https://web.archive.org/web/*/https://forkaweso.me/Fork-Awesome/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrap"> <!-- necessary for sticky footer. wrap all content except footer -->
    


    




<div>
  <section id="why">
  <div>
    <div>
      <h4> One Font, 744 Icons</h4><p>
      In a single collection, Fork Awesome is a pictographic language of web-related actions.
    </p></div>
    <div>
      <h4> No JavaScript Required</h4><p>
      Fewer compatibility concerns because Fork Awesome doesn't require JavaScript.
    </p></div>
    <div>
      <h4> Infinite Scalability</h4><p>
      Scalable vector graphics means every icon looks awesome at any size.
    </p></div>
    <div>
      <h4> Free, as in Speech</h4><p>
      Fork Awesome is completely free for commercial use. Check out the <a href="https://forkaweso.me/Fork-Awesome/license/">license</a>.
    </p></div>
    <div>
      <h4> CSS Control</h4><p>
      Easily style icon color, size, shadow, and anything that's possible with CSS.
    </p></div>
    <div>
      <h4> Perfect on Retina Displays</h4><p>
      Fork Awesome icons are vectors, which mean they're gorgeous on high-resolution displays.
    </p></div>
    <div>
      <h4> Plays Well with Others</h4><p>
      Originally designed for <a href="http://getbootstrap.com/">Bootstrap</a>, Fork Awesome works great with all frameworks.
    </p></div>
    <div>
      <h4> Desktop Friendly</h4><p>
      To use on the desktop or for a complete set of vectors,
      check out the <a href="https://forkaweso.me/Fork-Awesome/cheatsheet/">cheatsheet</a>.
    </p></div>
    
  </div>
</section>

  <section id="thanks-to">
  
  <div>
    <p>
        Thanks to <a href="https://twitter.com/davegandy">@davegandy</a> for his
        original work on Font Awesome and to
        <a href="https://twitter.com/gtagliala">@gtagliala</a> for managing pull
        requests and issues on the Font Awesome Github repo.
      </p>
    <p>
        Thanks to the still growing community of <a href="https://github.com/ForkAwesome/Fork-Awesome/blob/master/CONTRIBUTORS.md">115 contributors</a> who've carried this project from the early days of Font Awesome and who have joined this project since the fork.
        If you feel your contribution has not been recognized. Please file an issue, we'll happily add you to the list.
      </p>
  </div>
</section>

</div>




  </div></div>]]>
            </description>
            <link>https://forkaweso.me/Fork-Awesome/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057452</guid>
            <pubDate>Wed, 11 Nov 2020 11:25:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Write Unit Tests for Logging]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 35 (<a href="https://news.ycombinator.com/item?id=25057372">thread link</a>) | @JanVanRyswyck
<br/>
November 11, 2020 | https://principal-it.eu/2020/11/unit-tests-for-logging/ | <a href="https://web.archive.org/web/*/https://principal-it.eu/2020/11/unit-tests-for-logging/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<div>
					<h2>
						How To Write Unit Tests For Logging
					</h2>
					<p><span>
						November 11, 2020
					</span>
				</p></div>

				
<p>Once in a while I get asked the question whether one should write <a href="https://principal-it.eu/2019/10/taxonomy-of-tests/">solitary tests</a> for 
logging functionality. My answer to this question is the typical consultant answer: ‚ÄúIt depends‚Äù. In essence, logging 
is an infrastructure concern. The end result is log data that is being written to a resource which is external to 
an application. Usually the generated data ends up in a file, a database or it might even end up in a cloud service.</p>

<p>Because logging crosses the process boundary of an application, it is more useful to write 
<a href="https://principal-it.eu/2019/10/taxonomy-of-tests/">sociable tests</a> to verify this particular functionality. It doesn‚Äôt make sense to 
use solitary tests in this particular case.</p>

<p>That being said, there are situations where business requirements explicitly state that logging should be a part of the 
interface of an application. In this situation, the intent of logging should be expressed explicitly by the code which 
in turn should also be exercised by solitary tests. The excellent book 
<a href="https://bit.ly/tdd-goos2" target="blank" rel="noopener noreferrer nofollow">Growing Object Oriented Software 
Guided By Tests</a>, written by Steve Freeman and Nat Pryce, mentions that there are generally two separate types of 
logging:</p>

<ul>
  <li>Support logging</li>
  <li>Diagnostic logging</li>
</ul>

<p>A support log contains messages that are intended for those that perform operational activities. These messages are used 
to determine whether the system behaves correctly or not. The log level for these messages is usually of type <em>error</em> 
or <em>info</em>.</p>

<p>A diagnostic log on the other hand holds messages that are targeted towards software developers. These messages provide 
valuable insights into the details of a running system. The log level for these messages is usually of type <em>debug</em> or 
<em>trace</em>.</p>

<p>Given these two types of logging, the basic idea is that code which expresses the intent of support logging should be 
exercised by solitary tests. Code statements that initiate diagnostic logging are usually not covered by tests.</p>

<p>Let‚Äôs have a look at an example that demonstrates both support and diagnostic logging in action.</p>

<pre><code>public class ExpenseSheetController : Controller
{
    private readonly ICommandHandler&lt;CreateExpenseSheet&gt; _commandHandler;
    private readonly ISupportNotifier _supportNotifier;

    public ExpenseSheetController(ICommandHandler&lt;CreateExpenseSheet&gt; commandHandler,
                                  ISupportNotifier supportNotifier)
    {
        _commandHandler = commandHandler;
        _supportNotifier = supportNotifier;
    }
    
    [HttpPost]
    [ServiceFilter(typeof(PerformanceTracing))]
    public IActionResult Create(CreateExpenseSheetFormModel formModel)
    {
        try
        {
            var command = new CreateExpenseSheet(Guid.NewGuid(), formModel.EmployeeId);
            _commandHandler.Handle(command);
        }
        catch(Exception ex)
        {
            _supportNotifier.ErrorDuringExpenseSheetCreation(ex, formModel.EmployeeId);
            return BadRequest();
        }
        
        _supportNotifier.ExpenseSheetCreated(formModel.EmployeeId);
        return Ok();
    }
}
</code></pre>

<p>Here we have the implementation of a controller that can receive a request for creating a new expense sheet. Notice that 
the constructor of this controller class expects an instance of the <em>ISupportNotifier</em> interface. This dependency is 
being used by the implementation of the <em>Create</em> method for logging an error when an exception occurs. It is also used 
for logging when an expense sheet has been successfully created.</p>

<p>This is how the implementation of the <em>SupportNotifier</em> looks like.</p>

<pre><code>public class SupportNotifier : ISupportNotifier
{
    private readonly ILogger&lt;SupportNotifier&gt; _logger;

    public SupportNotifier(ILogger&lt;SupportNotifier&gt; logger)
    {
        _logger = logger;
    }
    
    public void ExpenseSheetCreated(Guid employeeId)
    {
        _logger.LogInformation("Expense sheet created for employee with ID '{employeeId}'.");
    }

    public void ErrorDuringExpenseSheetCreation(Exception ex, Guid employeeId)
    {
        _logger.LogError(ex, $"Unable to create a new expense sheet for employee with ID '{employeeId}'");
    }
}
</code></pre>

<p>This code demonstrates that support logging uses log levels <em>error</em> or <em>info</em> depending on the context. Verifying the
code of the <em>SupportNotifier</em> class itself can be done by using sociable tests. It‚Äôs not a good idea to write
solitary tests for the <em>SupportNotifier</em> class. This would imply that a test double should be used as an instance of 
<em>ILogger</em>. As we already touched on in a <a href="https://principal-it.eu/2020/05/test-double-heuristics/">previous blog post</a>, it‚Äôs much better to 
avoid using test doubles for types that you don‚Äôt own. In this particular case it would even be quite hard to do as 
the <em>Logxx</em> methods of <em>ILogger</em> are actually extension methods and not regular methods.</p>

<p>Let‚Äôs have a look at the tests for the <em>ExpenseSheetController</em>.</p>

<pre><code>[Specification]
public class When_handling_a_request_for_creating_a_new_expense_sheet
{
    [Establish]
    public void Context()
    {
        var commandHandler = Substitute.For&lt;ICommandHandler&lt;CreateExpenseSheet&gt;&gt;();
        _supportNotifier = Substitute.For&lt;ISupportNotifier&gt;();

        _sut = new ExpenseSheetController(commandHandler, _supportNotifier);
    }

    [Because]
    public void Of()
    {
        var formModel = new CreateExpenseSheetFormModel 
        { 
            EmployeeId = new Guid("94EDE8F3-9675-4DD7-A18F-E37B1F323699") 
        };

        _sut.Create(formModel);
    }
    
    [Observation]
    public void Then_it_should_notify_support()
    {
        _supportNotifier.Received()
            .ExpenseSheetCreated(new Guid("94EDE8F3-9675-4DD7-A18F-E37B1F323699"));
    }

    private ExpenseSheetController _sut;
    private ISupportNotifier _supportNotifier;
}

[Specification]
public class When_an_error_occurs_while_handling_a_request_for_creating_a_new_expense_sheet
{
    [Establish]
    public void Context()
    {
        _supportNotifier = Substitute.For&lt;ISupportNotifier&gt;();
        _exception = new InvalidOperationException("Meltdown");
        
        var commandHandler = Substitute.For&lt;ICommandHandler&lt;CreateExpenseSheet&gt;&gt;();
        commandHandler.WhenForAnyArgs(ch =&gt; ch.Handle(null))
            .Throw(_exception);
        
        _sut = new ExpenseSheetController(commandHandler, _supportNotifier);
    }
    
    [Because]
    public void Of()
    {
        var formModel = new CreateExpenseSheetFormModel 
        { 
            EmployeeId = new Guid("D1067157-5C73-4140-9D29-0FE5C1C4C2FB") 
        };

        _sut.Create(formModel);
    }
    
    [Observation]
    public void Then_it_should_notify_support_that_a_new_expense_sheet_has_been_created()
    {
        _supportNotifier.Received()
            .ErrorDuringExpenseSheetCreation(_exception, 
                new Guid("D1067157-5C73-4140-9D29-0FE5C1C4C2FB"));
    }
    
    private ExpenseSheetController _sut;
    private ISupportNotifier _supportNotifier;
    private Exception _exception;
}
</code></pre>

<p>These tests verify whether support logging occurs when an expense sheet has been created or when an exception gets 
raised. This way we express the intent of the operational requirements.</p>

<p>Notice that controller method has been decorated with a <em>ServiceFilter</em> attribute.</p>

<pre><code>[HttpPost]
[ServiceFilter(typeof(PerformanceTracing))]
public IActionResult Create(CreateExpenseSheetFormModel formModel)
{
    ...
}
</code></pre>

<p>By applying this attribute, the <em>PerformanceTracing</em> action filter is being registered to surround the execution of the 
controller method. Let‚Äôs have a look at the implementation of this action filter.</p>

<pre><code>public class PerformanceTracing : ActionFilterAttribute
{
    private readonly ILogger&lt;PerformanceTracing&gt; _logger;
    private readonly Stopwatch _stopWatch;

    public PerformanceTracing(ILogger&lt;PerformanceTracing&gt; logger)
    {
        _logger = logger;
        _stopWatch = new Stopwatch();
    }

    public override void OnActionExecuting(ActionExecutingContext context)
    {
        _stopWatch.Start();
    }

    public override void OnActionExecuted(ActionExecutedContext context)
    {
        _stopWatch.Stop();

        var controllerName = context.Controller.GetType().Name;
        var controllerActionName = context.ActionDescriptor.DisplayName;
        
        _logger.LogTrace($"Action '{controllerActionName}' of controller {controllerName} executed in " + 
            $"{_stopWatch.ElapsedMilliseconds} ms.");
    }
}
</code></pre>

<p>This implementation is a nice example of diagnostic logging. The action filter measures the execution time of a 
controller method and logs the result. Notice that we‚Äôre injecting the <em>ILogger</em> interface directly into the constructor.
By registering the <em>PerformanceTracing</em> action filter using the <em>ServiceFilter</em> attribute, we ensure that an instance 
of <em>ILogger</em> gets resolved and properly injected. We didn‚Äôt provide any tests for this implementation.</p>

<p>I think it‚Äôs useful to consider support logging and diagnostic logging as two separate concepts, even though they quite 
often use the same mechanisms under the hood.</p>


				<p>
						<em>
							If you and your team want to learn more about how to <u>write maintainable unit tests</u>
							and <u>get the most out of TDD practices</u>, make sure to have look at our
							<a href="https://principal-it.eu/training.html">trainings and workshops</a> or checkout
							the <a href="https://principal-it.eu/books.html">books section</a>. Feel free to reach
							out at <span>info@principal-it.be</span>.
						</em>
					</p>

				

				

				
			</div></div>]]>
            </description>
            <link>https://principal-it.eu/2020/11/unit-tests-for-logging/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057372</guid>
            <pubDate>Wed, 11 Nov 2020 11:06:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Revolutionize your support with Chat Bot]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25057330">thread link</a>) | @eugen_2pay
<br/>
November 11, 2020 | https://tap2pay.me/revolutionize-support-chat-bot/ | <a href="https://web.archive.org/web/*/https://tap2pay.me/revolutionize-support-chat-bot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<p>Robots are taking over our daily routine in every aspect of our life: from paying bank bills to cleaning the house. It does not mean that within a year you will be leaving in a Matrix, but modern robots will for sure simplify your life in many ways.</p>

<p>Automation is everything. Chat support on smartphone saves our time and energy for more important things.</p>

<p>According to a survey, <strong>over 80% of customer problems will be solved with the help of chatbots.</strong></p>

<p>What kind of customers can really use the help of live support?</p>

<h4>Here are the Top 5 Business Areas that benefit from ChatBot support:</h4>

<p><strong>Banks</strong></p>
<p>‚Ä¢ prompting nearest branch locations, self-service terminals<br>
‚Ä¢ sending information about available credit programs and its terms<br>
‚Ä¢ helping to choose the necessary type of deposit<br>
‚Ä¢ accepting the request for required documents</p>

<p><strong>Events selling agencies</strong></p>
<p>‚Ä¢ registering of new clients<br>
‚Ä¢ answering basic queries about cost, time, and location<br>
‚Ä¢ performing support functions<br>
‚Ä¢ booking tickets online</p>

<p><strong>Online Stores</strong></p>
<p>‚Ä¢ registering new customers<br>
‚Ä¢ processing order placements<br>
‚Ä¢ processing payments for products<br>
‚Ä¢ conducting marketing surveys</p>

<p><strong>Mobile operators</strong></p>
<p>‚Ä¢ onboarding of new users<br>
‚Ä¢ processing payments<br>
‚Ä¢ answering basic queries about cost, time, and location</p>

<p><iframe width="1140" height="641" src="https://www.youtube.com/embed/yCcQpyYSvks?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>

<p><strong>Providers of Education services</strong></p>
<p>‚Ä¢ processing payments<br>
‚Ä¢ helping to choose an educational program<br>
‚Ä¢ accepting requests for required programs</p>

<p><img src="https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture.jpg" alt="" width="700" height="393" srcset="https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture.jpg 700w, https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture-300x168.jpg 300w, https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture-71x40.jpg 71w, https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture-255x143.jpg 255w, https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture-142x80.jpg 142w, https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture-360x202.jpg 360w, https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture-500x281.jpg 500w, https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture-600x337.jpg 600w" sizes="(max-width: 700px) 100vw, 700px"></p>

<p><a href="https://secure.tap2pay.me/users/signup">Tap2Pay</a> strives for excellence in every aspect of creating smooth and friendly chat support on smartphones.</p>
<p>We have developed stunning software for effortless payment processing via the most well-known social media messengers Facebook, Instagram, Telegram, WhatsApp with built-in chatbot client support.</p>

<p><iframe width="1140" height="641" src="https://www.youtube.com/embed/jJxIfNR99Do?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>

<p>If you need any assistance with updating your payment processing method with built-in chat support, please <a href="https://tap2pay.me/contacts/">connect with our Customer Support Team.</a></p>
	
                </div></div>]]>
            </description>
            <link>https://tap2pay.me/revolutionize-support-chat-bot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057330</guid>
            <pubDate>Wed, 11 Nov 2020 10:58:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Telegram Bot with Azure Functions and Node.js]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057328">thread link</a>) | @qpbp_user
<br/>
November 11, 2020 | http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/ | <a href="https://web.archive.org/web/*/http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><ul><li><a href="#introduction">Introduction</a></li><li><a href="#flow-review">Flow Review</a></li><li><a href="#prerequisites">Prerequisites</a></li><li><a href="#create-an-azure-function-in-visual-studio-code">Create an Azure function in Visual Studio Code</a></li><li><a href="#folder-structure">Folder structure</a></li><li><a href="#run-function-locally">Run function locally</a></li><li><a href="#implement-the-bot">Implement the bot</a></li><li><a href="#running-bot-locally">Running bot locally</a></li><li><a href="#deploy-azure-function-to-the-portal">Deploy Azure Function to the portal</a></li><li><a href="#conclusion">Conclusion</a></li></ul><h2 id="introduction">Introduction</h2><p>In this tutorial, we will create an Azure Function with a simple Telegram Bot (Echo Bot). We will test it locally and then deploy it to Azure Portal. It means our bot will work only at the moment when someone is using it. So the function will be triggered only when someone is sending a message to a bot.</p><h2 id="flow-review">Flow Review</h2><ol><li>The user sends any message to Telegram Bot</li><li>Telegram sends requests via Webhook to our Azure Function</li><li>Azure Function replies to Webhook with a copied message</li></ol><h2 id="prerequisites">Prerequisites</h2><ul><li>node.js - v10.16.2</li><li>npm - v6.14.5</li><li>telegraf - v3.38.0</li><li>ngrok - v2.3.35</li><li>Azure subscribtion</li><li>you need to install <a href="https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-azurefunctions">Azure Functions extension</a> to Visual Studio Code</li></ul><h2 id="create-an-azure-function-in-visual-studio-code">Create an Azure function in Visual Studio Code</h2><ol><li><p>click on Azure Icon in Visual Studio Code</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.48.39-1024x885.png" alt="Azure Icon in VSC"></p></li><li><p>login under your Azure subscription</p></li><li><p>click on ‚ÄúCreate Function Icon‚Äù</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.51.16.png" alt="Create Function Icon"></p></li><li><p>you will be asked to use an existing project or create a new. Let‚Äôs create a new:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.54.40-1024x281.png" alt="Create a new project"></p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.55.13-1024x589.png" alt="Create new project folder"></p></li><li><p>select the function template. We will use <strong>HTTP trigger</strong>:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.55.36-1024x607.png" alt="Choose a Function Template"></p></li><li><p>provide a function name and select Enter:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.56.16-1024x213.png" alt="Enter the name of the function"></p></li><li><p>please provide a <strong>Function</strong> key for a <strong>Function authorization</strong>:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.56.27-1024x280.png" alt="Function Authorization level"></p></li><li><p>penultimate step. Select how you would like to open a project. We will use the current window:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.56.39-1024x291.png" alt="How to open a function project in Visual Studio Code"></p></li><li><p>you will be redirected to the <strong>default HTTP trigger function with Javascript code</strong>:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.57.02-1024x618.png" alt="The default function Code"></p></li><li><p>now this function will appear in Azure Functions section:</p></li></ol><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-11.23.30-1024x340.png" alt="Newly created function"></p><h2 id="folder-structure">Folder structure</h2><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-11.29.34-300x256.png" alt="Function Folder Structure"></p><ul><li><strong>package.json</strong> - metadata relevant to the Node.js project</li><li><strong>proxies.json</strong> - you can modify requests and responses from function</li><li><strong>host.json</strong> - metadata file relevant to the Azure project. It‚Äôs a global configuration for all functions in an application</li><li><strong>azure-bot-cloud-function</strong> - it‚Äôs our function folder. Each function has a separate folder with code file (.js in our case) and function.json. Function.json it‚Äôs a <a href="https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-expressions-patterns">binding configuration file</a>.</li></ul><h2 id="run-function-locally">Run function locally</h2><ol><li><p>Select Run -&gt; Start Debugging in Visual Studio Code menu</p></li><li><p>If you have no Azure Functions Core Tools locally, you need to install them on this step. The instruction can be found in <a href="https://github.com/Azure/azure-functions-core-tools#installing">Azure repo:</a></p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-20.48.48-1024x127.png" alt="Install Azure Function Core Tools"></p></li><li><p>You should see how the NPM tasks will executing and finally get a link to the working function:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-21.08.28-1024x601.png" alt="Link to the local Azure function"></p></li><li><p>Let‚Äôs open our function in the browser:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-21.20.46-1024x274.png" alt="Azure Function is working locally"></p><p>As you see, the function responds to us with the behavior by default. Also, you can simply run the function using the <strong>func start</strong> command.</p></li></ol><h2 id="implement-the-bot">Implement the bot</h2><p>For work with Telegram API, we will use the most popular library for Node.js - <a href="https://github.com/telegraf/telegraf">Telegraf.js</a>. We need to install it in the project folder:</p><div><pre><code data-lang="bash">npm install telegraf --save
</code></pre></div><p>Please make sure the <code>package.json</code> has Telegraf after the running previous command.</p><p>Because Telegram will send webhook requests to our bot, we need to make an external HTTPS URL. For this purpose we can use <a href="https://ngrok.com/">ngrok library</a>:</p><p>If all is good, we can go to <code>function-folder&gt;/index.js</code> and create a simple Echo-bot:</p><div><pre><code data-lang="javascript"><span>const</span> <span>Telegraf</span> <span>=</span> <span>require</span>(<span>'telegraf'</span>)
<span>const</span> { <span>TELEGRAM_BOT_TOKEN</span>, <span>WEBHOOK_ADDRESS</span> } <span>=</span> <span>process</span>.<span>env</span>

<span>const</span> <span>bot</span> <span>=</span> <span>new</span> <span>Telegraf</span>(<span>TELEGRAM_BOT_TOKEN</span>, {<span>telegram</span><span>:</span> { <span>webhookReply</span><span>:</span> <span>true</span> }})

<span>bot</span>.<span>telegram</span>.<span>setWebhook</span>(<span>WEBHOOK_ADDRESS</span>)
<span>bot</span>.<span>on</span>(<span>'message'</span>, (<span>ctx</span>) =&gt; <span>ctx</span>.<span>telegram</span>.<span>sendCopy</span>(<span>ctx</span>.<span>chat</span>.<span>id</span>, <span>ctx</span>.<span>message</span>))

<span>module</span>.<span>exports</span> <span>=</span> <span>async</span> <span>function</span> (<span>context</span>, <span>req</span>) {
	<span>return</span> <span>bot</span>.<span>handleUpdate</span>(<span>req</span>.<span>body</span>, <span>context</span>.<span>res</span>)
}
</code></pre></div><p>You can take <code>TELEGRAM_BOT_TOKEN</code> value from <a href="https://telegram.me/BotFather">BotFather bot</a>. The <code>WEBHOOK_ADDRESS</code> will contain a link to the Azure Function. We will talk about this variable later. Our bot will work in Webhook mode - it‚Äôs a more preferable way to run Telegram bot. The Telegram will automatically inform our bot about all updates. In the polling mechanism, our bot needs to frequently ask Telegram about updates, so it requires non-stop work for our bot (most cases).</p><h2 id="running-bot-locally">Running bot locally</h2><p>To run this bot locally we need to create a public address using ngrok. By default, the local Azure function is running on port <code>7071</code>. We can use the following combination in the terminal to create a public URL:</p><p>In the terminal you will get your HTTPS link for testing Webhook:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-22.29.42-1024x400.png" alt="HTTPS public URL using ngrok"></p><p>Copy the ngrok-created link and add the route to the function. Something similar to this:</p><div><pre><code data-lang="javascript"><span>bot</span>.<span>telegram</span>.<span>setWebhook</span>(<span>'https://&lt;random-value&gt;.ngrok.io/api/azure-bot-cloud-function'</span>)
</code></pre></div><p>Also, don‚Äôt forget to pass a real Telegram token to the Telegraf constructor:</p><div><pre><code data-lang="javascript"><span>const</span> <span>bot</span> <span>=</span> <span>new</span> <span>Telegraf</span>(<span>'some-token-value'</span>, {
	<span>telegram</span><span>:</span> { <span>webhookReply</span><span>:</span> <span>true</span> },
})
</code></pre></div><p>It‚Äôs very dirty, but for a quick test it‚Äôs OK, so please remember to remove all real keys from the code.</p><p>Then you can run a function just using the simple command:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-22.49.14-1024x709.png" alt="Azure Functions is running locally"></p><p>Good job! Now open your bot in Telegram and send any message. Our bot should copy it and resend to you:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-23.41.16.png" alt="Echo-Bot example"></p><h2 id="deploy-azure-function-to-the-portal">Deploy Azure Function to the portal</h2><p>To deploy Azure Function we just need to click on this button:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-22.52.40-1024x730.png" alt="Deploy Azure Function"></p><p>Then choose your resource and press ‚ÄúDeploy‚Äù. The process will be started:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-22.53.55-1024x406.png" alt="The process of deploying Azure Function"></p><p>After successful deployment, we need to go to Azure Portal and update <strong>WEBHOOK_ADDRESS</strong> and <strong>TELEGRAM_BOT_TOKEN</strong> variables with real values.</p><p>To get a real function URL, go to ‚ÄúFunctions‚Äù, then choose your Azure Function and press ‚ÄúGet Function Url‚Äù button:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-23.05.24-1024x275.png" alt="How to get Azure Function URL"></p><p>We need to copy this value and paste to Application Settings along with Telegram Token:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-22.59.12-1024x343.png" alt="Application Settings in Azure"></p><p>After adding our secret keys, press ‚ÄúSave‚Äù and restart our application:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-23.09.41-1024x424.png" alt="Restart Azure application"></p><p>That‚Äôs all. Our bot should work in the cloud and you can track all function executions in real-time:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-23.13.07-1024x325.png" alt="Azure Dashboard"></p><p>Each function execution means that our bot handled 1 single message.</p><h2 id="conclusion">Conclusion</h2><p>In this tutorial, we have created an Azure Function with a simple Echo-Bot for Telegram. Azure Functions its a cool way to host your bots. You will be chargeable by the simple formula - (Memory size)X(Execution time in ms)X(Executions per month) and also remember that the first 400,000 GB/s of execution and 1,000,000 executions are free. If you need to estimate your pricing costs you can use <a href="https://azure.microsoft.com/en-us/pricing/calculator/">this pricing calculator</a>.</p><p>P.s. don‚Äôt forget to delete/clean/stop all resources.</p><p><a href="https://disqus.com/">comments powered by </a></p></div></div></section></div>]]>
            </description>
            <link>http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057328</guid>
            <pubDate>Wed, 11 Nov 2020 10:57:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debugging the Kernel with QEMU]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057309">thread link</a>) | @__rompy
<br/>
November 11, 2020 | https://blog.k3170makan.com/2020/11/linux-kernel-exploitation-0x0-debugging.html | <a href="https://web.archive.org/web/*/https://blog.k3170makan.com/2020/11/linux-kernel-exploitation-0x0-debugging.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-4480419177723293408">
<p>Hi folks, in this post I'm going to walk through how to setup the linux kernel for debugging. I will also demonstrate that the setup works by setting a break-point to a test driver I wrote myself. All the code will be available from my gitlab, all the links to my gitlab will be re-posted at the end.&nbsp;</p><p>The setup I describe here re-uses some parts of the syzkaller setup, and for good reason later on in the post series I will break into a tutorial for the syzkaller tool as well. So lets get on with it.</p><table><tbody><tr><td><a href="https://1.bp.blogspot.com/-u2vPJD5mvfQ/X6v9Jig2QOI/AAAAAAAAQFA/AeLKhrX1BXM8HY7pN694qJFyvWDilFojACLcBGAsYHQ/s1109/Screenshot%2Bfrom%2B2020-11-11%2B17-00-44.png" imageanchor="1"><img data-original-height="625" data-original-width="1109" height="360" src="https://1.bp.blogspot.com/-u2vPJD5mvfQ/X6v9Jig2QOI/AAAAAAAAQFA/AeLKhrX1BXM8HY7pN694qJFyvWDilFojACLcBGAsYHQ/w640-h360/Screenshot%2Bfrom%2B2020-11-11%2B17-00-44.png" width="640"></a></td></tr><tr><td>Screenshot of a successful debug session with full debug symbols for the kernel! We can even see the call to start_kernel and a frame before that as well!<br></td></tr></tbody></table><br>&nbsp;<h2>The Process</h2><p>Okay so we want to study kernel exploitation but given that the kernel isn't something totally accessible in userspace, its not as convenient to debug as userpace stuff, we need a bit of a run up before we can actually poke and prod the kernel to figure out how to write our exploits. So there's a number of important steps to how we get this done, here's what we're going to do:</p><ol><li>Build a kernel</li><li>Build an image</li><li>Launch the virtual machine&nbsp;</li><li>Attach and setup the debugger</li><li>Building, loading and debugging a test module <br></li></ol><p>We also need to be able to build our kernel because there may be build options that are important to configure in order to control exploit protection or include modules and functionality to the kernel when needed. <br></p><h2>Building a Kernel</h2><p>Okay so before we get going with launching our Qemu instances and debugging modules we need an environment. For convenience sake I'm working off of a fresh Ubuntu 18.04.5 LTS machine. I'll document the processes from fresh install to first successful kernel build.</p><p>To start we need to make sure we have everything we need to build a kernel:</p><p><span>$<b>sudo apt-get update</b></span></p><p><span>$<b>sudo apt-get upgrade </b><br></span></p><p><span>$<b>sudo apt-get install git fakeroot build-essential ncurses-dev xz-utils libssl-dev bc flex libelf-dev bison qemu-system-x86</b></span></p><p>Next we obviously need a kernel so lets download a brand new kernel:</p><p><span>$<b>wget https://cdn.kernel.org/pub/linux/kernel/v5.x/linux-5.9.7.tar.xz</b><br>--2020-11-10 23:00:26--&nbsp; https://cdn.kernel.org/pub/linux/kernel/v5.x/linux-5.9.7.tar.xz<br>Resolving cdn.kernel.org (cdn.kernel.org)... 151.101.225.176, 2a04:4e42:35::432<br>Connecting to cdn.kernel.org (cdn.kernel.org)|151.101.225.176|:443... connected.<br>HTTP request sent, awaiting response... 200 OK<br>Length: 115538096 (110M) [application/x-xz]<br>Saving to: ‚Äòlinux-5.9.7.tar.xz‚Äô<p>linux-5.9.7.tar.xz&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 42%[=============&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ]&nbsp; 46.79M&nbsp; 3.08MB/s&nbsp;&nbsp;&nbsp; eta 23s&nbsp;&nbsp; &nbsp;</p></span></p><p><span>... <br></span></p><p><span>$<b>tar -xf linux-5.9.7.tar.xz</b></span></p><p>We're just a couple steps from sending the final build commands, before we get to that lets make sure the kernel config is ready to rock. Because we're working on a Linux host we can simply swipe the .config for the virtual machine's Ubuntu kernel like so:</p><p><span>$<b>cp /boot/config-5.4.0-52-generic .config</b></span></p><p>We then need to select some options that make debugging and exploit dev a little easier. First thing we need is to merge some options for making the kernel easier to run in a virtual machine:</p><p><span>$<b>make kvmconfig</b></span></p><p><span>Using .config as base<br>Merging ./kernel/configs/kvm_guest.config<br>#<br># merged configuration written to .config (needs make)<br>#</span></p><p><span>...</span></p><p>Great, now we need to enable some options for debug symbols, kaslr and other awesome things. So open the <span>.config</span> somewhere in a text editor and make sure you either add or modify the file so these options are set:</p><p><span>CONFIG_KCOV=y<br>CONFIG_DEBUG_INFO=y<br>CONFIG_KASAN=y<br>CONFIG_KASAN_INLINE=y<br>CONFIG_CONFIGFS_FS=y<br>CONFIG_SECURITYFS=y </span><br><span><span># CONFIG_RANDOMIZE_BASE is not set<br></span></span></p><p>Cool now we need to make sure the config is ready to go for a build:</p><p><span>$<b>make savedefconfig</b></span></p><p><span>$<b>make -j4</b></span></p><p><span>&nbsp;...</span></p><p>Now you should grab some coffee, play a startcraft2 game because this may take a while. Okay so if your build worked you should have an object file in the following location:</p><p><span>[kernel_dir]/arch/x86_64/boot/bzImage</span>&nbsp;</p><h2>Build an image</h2><p>We're going to build an image for this kernel so we might as well plop a "image" directory in this folder:</p><p><span>$<b>mkdir [kernel_dir]/image/</b></span></p><p>Once you're kernel is build we need to start thinking about how to build a file system for this. Here I'm going to cheat and steal some tips from the syzkaller folks. We need to first download syzkaller, as follows:</p><p><span>$<b>git clone https://github.com/google/syzkaller.git</b></span></p><p><span>Cloning into 'syzkaller'...<br>remote: Enumerating objects: 1, done.<br>remote: Counting objects: 100% (1/1), done.<br>...<br></span></p><p>Move back to the kernel build and setup an image:</p><p><span>$<b>cd [kernel_dir]/image/</b></span></p><p><span>$<b>cp [syzkaller_dir]/tools/create_image.sh .</b></span></p><p>Okay so we can now create an image, all we need to do is simply invoke create_image.sh:</p><p><span>$<b>./create_image.sh&nbsp;</b></span></p><p><span>+ DIR=chroot<br>+ PREINSTALL_PKGS=openssh-server,curl,tar,gcc,libc6-dev,time,strace,sudo,less,psmisc,selinux-utils,policycoreutils,checkpolicy,selinux-policy-default,firmware-atheros,python,xrdp,g++,make,libtool,autoconf,nasm<br>+ '[' -z ']'<br>+ ADD_PACKAGE=make,sysbench,git,vim,tmux,usbutils,tcpdump</span></p><p><span>...</span><br></p><p>If that worked you should have the following in your folder:</p><p><span>$<b>ls</b>&nbsp;</span></p><p><span>chroot/</span></p><p><span>create-image.sh</span></p><p><span>stretch.id_rsa</span></p><p><span>stretch.id_rsa.pub</span></p><p><span>stretch.img</span><br></p><h2>Launch the virtual machine <br></h2><p>Now we can launch qemu with all the goodies in place:</p><p><span>qemu-system-x86_64 \<br>&nbsp; -kernel <b>../arch/boot/x86_64/bzImage</b> \<br>&nbsp; -append "console=ttyS0 root=/dev/sda earlyprintk=serial nokaslr"\<br>&nbsp; -hda <b>./stretch.img</b> \<br>&nbsp; -net user,hostfwd=tcp::10021-:22 -net nic \<br>&nbsp; -enable-kvm \<br>&nbsp; -nographic \<br>&nbsp; -m 2G \<br>&nbsp; -s \<br>&nbsp; -S \<br>&nbsp; -smp 2 \<br>&nbsp; -pidfile vm.pid \<br>&nbsp; 2&gt;&amp;1 | tee vm.log</span></p><p><span>...</span></p><p><br>The <span>-s</span> is a shorthand for <span>-gdb tcp::1234</span>, which means the gdbserver will be hosted at port 1234. -S tells qemu not to start the cpu automatically, this gives us a chance to set a breakpoint before the kernel starts executing. </p><p>So that's the image running smoothly, lets setup our debugging environment.</p><h2>Attach and setup the debugger<br></h2><p>We can then attach a gdb debugger to the qemu instance as follows. On another terminal, separate from the one running your qemu instance, start up gdb and issue the following commands:</p><p><span>$<b>cd [kernel_dir]/image/ </b><br></span></p><p><span>$<b>gdb ../vmlinux<br></b></span></p><p><span>Reading symbols from ../vmlinux...</span></p><p><span>(gdb)<b> target remote :1234<br></b></span></p><p><span>Remote debugging using :1234<br>0x000000000000fff0 in exception_stacks ()<br></span></p><p><span>(gdb) <b>c</b></span></p><p>We give the "c" command to continue execution. We can now set some of our own breakpoints. As part of the tutorial I've included a custom IOCTL driver and app code (code that invokes the ioctl from userspace), i thought this would be nifty since it shows full ability to develope and debug a driver, something crucial to hunting down modern bugs and exploit development. Anyway lets code and build our own module.</p><h2>Building, Loading and debugging a test module<br></h2><p>Okay so we need to make a test ioctl driver, so lets head over the to kernel source directory and make a new folder in the /driver/ subfolder:</p><p><span>$</span><b><span>cd&nbsp; [kernel_dir]/drivers/</span></b></p><p><span>$</span><b><span>mkdir debug_driver/</span></b></p><p><span>$</span><b><span>cd debug_driver/ <br></span></b></p><p><span>$</span><b><span>touch debug_driver.c</span></b></p><p><span>$</span><b><span>touch debug_driver_app.c</span></b></p><p><span>$</span><b><span>touch Makefile</span></b></p><p>The code for <span>debug_driver.c</span> and <span>debug_driver_app.c </span>as we well as the <span>Makefile</span> are available at this repo <a href="https://gitlab.com/k3170makan/linux-kernel-exploit-development">https://gitlab.com/k3170makan/linux-kernel-exploit-development</a>. All you need to do is download the repo and stick this in its own folder under <span>[kernel_dir]/drivers/</span>. To build the module the we need to set the "M" variable in the kernel make script:</p><p><span>$<b>cd [kernel_dir]; make -C . M=drivers/debug_driver/</b></span></p><p><span>make: Entering directory '/home/kh3m/Research/Kernel/debug_image/linux-5.5.3'<br>&nbsp; AR&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; drivers/debug_driver//built-in.a<br>&nbsp; CC [M]&nbsp; drivers/debug_driver//debug_driver.o</span></p><p><span>...</span></p><p>Now we need to get this module on our qemu host somehow, I do this the hard way, I'm sure there's all sorts of nifty ways to scp files onto the qemu host but I actually just re-create the image after copying the drivers to a folder to be baked into the start up filesystem. First we need to edit create-image.sh so it includes everything in a folder we specify, that way we can just dump stuff in the folder and run create-image.sh whenever we want those files on a live instance.</p><p>So before create-image.sh builds the disk image on line 129, stick this in there:</p><p>++ <span>sudo cp -r ./add/* $DIR/home/.</span><br></p><p>now we make a "add" folder and stick the kernel module and app code in there:</p><p><span>$<b> cd [kernel_dir]/image/</b></span></p><p><span>$ <b>mkdir add/</b></span></p><p><span>$ <b>cd add/</b></span></p><p><span>$ <b>cp ../../drivers/debug_driver/debug_driver.ko .</b><br></span></p><p><span>$ <b>cp ../../drivers/debug_driver/debug_driver_app.c .</b></span></p><p><span>$ <b>./create-image.sh</b> </span></p><p>Okay so we have a module, we have a symbol file debug_driver.ko, with stuff we need to set breakpoints. Lets load the module into the kernel, then check where it gets loaded before we actually set the breakpoint:</p><p><span>root@syzkaller:$ <b>cd /home/</b></span></p><p><span>root@syzkaller:$ insmod debug_driver.ko</span></p><p><span> [&nbsp;&nbsp; 32.792570] audit: type=1400 audit(1605058227.605:7): avc:&nbsp; denied&nbsp; { module_load } for&nbsp; pid=249 comm="insmod" path="/home/debug_driver.ko" dev="sda" ino=21253 scontext=system_u:system_r:kernel_t:s0 1<br>[&nbsp;&nbsp; 32.793766] debug_driver: loading out-of-tree module taints kernel.<br>[&nbsp;&nbsp; 32.800394] [debug_driver] loaded! <br>[&nbsp;&nbsp; 32.800826] [debug_driver] device registered successfully<br>[&nbsp;&nbsp; 32.802298] [debug_driver] device has been successfully created <b><br></b></span></p><p>Before we can debug it properly we need to know where it is loaded in kernel memory:</p><p><span>root@syzkaller:/home# <b>cat /proc/modules</b> <br>debug_driver 16384 0 - Live <b>0xffffffffa0000000</b> (O)</span></p><p>Okay lets now set our breakpoint and load the symbol file using the base address of the module:</p><div><p><span>&nbsp;(gdb) <b>add-symbol-file ../drivers/debug_driver/debug_driver.ko&nbsp; 0xffffffffa0000000</b><br>add symbol table from file "../drivers/debug_driver/debug_driver.ko" at<br>&nbsp;&nbsp; &nbsp;.text_addr = 0xffffffffa0000000<br>(y or n) <b>y</b><br>Reading symbols from ../drivers/debug_driver/debug_driver.ko...<br>(gdb) <b>break dev_read</b><br>Breakpoint 1 at <b>0xffffffffa0000010: file drivers/debug_driver//debug_driver.c</b>, line 81.<br>(gdb) c</span></p></div><p>Cool lets execute the driver program so we can trigger the code we want:</p><p><span>root@syzkaller:$ <b>gcc -o debug_driver_app.elf debug_driver_app.c<br></b></span></p><p><span><span>root@syzkaller:/home# <b>./debug_driver_app.elf </b><br>Usage: ./debug_driver_app.elf [message to write] [read length] <br></span></span></p><p><span><span>root@syzkaller:</span>$ <b>./debug_driver_app.elf "hello" 10</b></span></p><p><span>[&nbsp; 160.083320] [debug_driver] message successfully copied message =&gt; [hello]<br>[&nbsp; 160.083326] [debug_driver] buffer copied to message holder<br>[debug_driv‚Ä¶</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.k3170makan.com/2020/11/linux-kernel-exploitation-0x0-debugging.html">https://blog.k3170makan.com/2020/11/linux-kernel-exploitation-0x0-debugging.html</a></em></p>]]>
            </description>
            <link>https://blog.k3170makan.com/2020/11/linux-kernel-exploitation-0x0-debugging.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057309</guid>
            <pubDate>Wed, 11 Nov 2020 10:53:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why electronic voting is dangerous]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057302">thread link</a>) | @ian_starts
<br/>
November 11, 2020 | https://blog.iankok.com/risk-electronic-voting | <a href="https://web.archive.org/web/*/https://blog.iankok.com/risk-electronic-voting">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>With the 2020 US elections having mail in ballots,
I found myself wondering if a digital solution would be safer, more reliable and easier. As usual the answer isn't straightforward. </p>
<p>In this post I'll talk you through some possible solutions and their potential downsides.</p>
<p>I will mostly focus on Dutch elections, seeing as I can provide the best insights, and most arguments are easily
transferable to other nations.</p>
<h2>Requirements</h2>
<p>If we would develop a voting system from scratch it would need to have some features that protect our rights and make
sure the elected ruler is the one the people really wanted (questionable if that's the case with current electoral systems, but that's for another time).</p>
<ol>
<li><strong>Accuracy</strong> - are all the votes counted, do they represent the will o' the people?</li>
<li><strong>Anonymity</strong> - very difficult this one. We don't want the votes to be signed, that would leave opportunities for
coercion and intimidation. However, we do need to verify that the voter is eligible to vote (or a real person at all for that matter).</li>
<li><strong>Verifiability</strong> - we need to be able to verify if the process went correctly.</li>
<li><strong>Speed</strong> - it would be useful if votes would be counted quicker. </li>
</ol>
<p>A big problem with anonymity and verifiability is that making votes anonymous makes them difficult to verify.</p>
<p>If we had a database with all the people who voted, and their cast vote, verifiability would be tackled. However, it wouldn't be anonymous.</p>
<h2>e-voting vs i-voting</h2>
<p>When discussing electronic voting there are essentially two things at play. </p>
<ol>
<li><strong>e-voting</strong> - voting on a machine on location. Like 35 municipalities did in the Netherlands between roughly 1970 and 2007.</li>
<li><strong>i-voting</strong> - voting online using a device connected to the internet.</li>
</ol>
<p>e-voting is usually seen as the easier one. You can tackle anonymity by submitting anonymous votes, and verify it
manually with a passport check before entering the voting booth.</p>
<p>i-voting is much more difficult, because you can't have the manual check.</p>
<h2>We can protect our back accounts, so how hard can protecting votes be, right?</h2>
<p>Well, unless you're part of a secret society with unlimited wealth, chances are your bank account is not a very interesting target.</p>
<p>The scale of an election is massive. The decision made there has so much influence,
that it's an incredibly high value target.</p>
<blockquote>
<p>Most hackers aren't hardcore geeks typing away on their kali linux distro. It's usually a game of
influencing people, leaked data or a weak password. This can be summarised as the <em>human error</em>.</p>
</blockquote>
<p>It's much more likely hackers will pour resources into hacking an election than a bank account.</p>
<h2>e-voting</h2>
<p>e-voting seems like a pretty good idea. it's pretty straight forward on an abstract level: keep everything the same, only make the counting digital.</p>
<p>Too bad it's an oversimplification. It's impossible for most voters to check how the system works internally.
Even if the voters were all programmers, the source code doesn't have to be open-source. There's no rule against making the source code private. </p>
<p>So basically, it's a black box which we have to trust with one of the most important things in a democracy, and impossible for any voter to check the process.</p>
<p>This fear is backed by a <a href="https://www.bundesverfassungsgericht.de/SharedDocs/Pressemitteilungen/EN/2009/bvg09-019.html">2009 decision</a> by the Federal Constitutional Court of Germany:</p>
<blockquote>
<p>The use of voting machines which electronically record the voters‚Äô votes and electronically ascertain the election
result only meets the constitutional requirements if the essential steps of the voting and of the ascertainment of the
result can be examined reliably and without any specialist knowledge of the subject.  </p>
</blockquote>
<p>Beside these 'lack of control' fears, a lot of systems have failed miserably over the years.</p>
<p>The lack of pen-testing (inviting good-guy hackers to attack your system and check for vulnerabilities) makes it very hard to pinpoint exact failures, but here's a curated list of found problems in the US:</p>
<ul>
<li>2003 ‚Äì In Fairfax, new voting machines either didn‚Äôt work, or would lose the voter‚Äôs choice after a few moments.</li>
<li>2003 ‚Äì The State of Maryland found that the Diebold Election Systems, Inc. (now rebranded as Premier Election Solutions) AccuVote-TS system ‚Äúas implemented in policy, procedure, and technology, is at high risk of compromise.‚Äù</li>
<li>2002-2006 ‚Äì During this period, Election Systems and Software, the US‚Äôs leading voting machine manufacture was shipping some of its systems with remote access software, making them vulnerable to hacking.  </li>
<li>2006 ‚Äì Researchers from the Voting Systems Technology Assessment Advisory Board (VSTAAB) and the University of California corroborated previous research that found various Diebold voting machines can have the votes on their memory cards tampered with in a way that cannot be detected. They found a number of other security vulnerabilities as well.</li>
<li>2006 ‚Äì Princeton researchers studied the Diebold AccuVote-TS and found that it was vulnerable to a range of serious attacks. These included the possibility of malware installation which could be used to alter the vote.</li>
<li>2015 ‚Äì The Virginia Information Technologies Agency assessed the WinVote machine, which is manufactured by Advanced Voting Solutions. The agency recommended discontinuing the use of these machines after they found a range of serious flaws such as weak passwords, outdated security protocols, and insufficient system hardening.</li>
<li>2018 ‚Äì At DEFCON, J. Alex Halderman showed that Diebold AccuVote TSX voting machines could be manipulated remotely in a mock election. The same vulnerable machines were being used in 18 different states. After the event, a 50 page report was released, detailing vulnerabilities in Election Systems &amp; Software‚Äôs M650 machine and the Diebold AccuVote TSX. Together, these machines are used in as many as 23 states.</li>
<li>2018 ‚Äì Some voters in Texas allege that the Hart InterCivic‚Äôs eSlate machine was switching their vote to another candidate in the state‚Äôs election for senator.</li>
</ul>
<p>And of course a Dutch problem:</p>
<ul>
<li>2007 - It was possible to read and analyse the Electromagnetic radiation of voting machines from dozens of meters away. This caused the anonymity to be completely compromised.</li>
</ul>
<p>Side-note; this was known before an election took place. Still, parts of the election were held with the voting machines,
causing the Dutch government to be sued, losing, and going back to paper ballots.</p>
<p>So yeah, e-voting; not perfect.</p>
<h2>Hopes for e-voting</h2>
<p>More recently there has been talk of re-instating e-voting with some big adaptations. </p>
<p>The new version would basically be a computer with a printer. You can cast your vote in a voting booth with no
connectivity to the web. The voting machine would print your vote on a piece of paper, which you can then check for errors and deposit in the voting box.
These printed votes are easily read by a central computer, making counting them a lot easier and quicker.</p>
<p>Though this seems like an interesting concept, it's also doesn't have a lot of benefits over paper ballots. As the software axiom goes "keep it simple, stupid",
this doesn't really comply.</p>
<h2>i-voting</h2>
<p>I-voting, also known as remote e-voting, is casting your vote from the comfort of your own couch.
The only country which implemented such a system is Estonia. With tech giants migrating more of your life to the internet,
it seems that it's only logical to move to i-voting. Let's take a look at Estonia. How their system works,
what the vulnerabilities are, and whether we should follow suit.</p>
<h3>How it works</h3>
<p>Estonia's i-voting system builds on their ID card. This ID card is also a smart card and allows owners to digitally
sign documents and facilitates secure authentication. This already laid infrastructure makes it possible to tackle one of our demands; <strong>verifiability</strong>.</p>
<p>The i-voting system is available in an early voting period (sixth day to fourth day prior to Election Day). You can
change your vote an unlimited amount of times in that timeframe. You can also overwrite your vote by going to a
polling station, invalidating your i-vote.</p>
<p>When this new voting method was first introduced, the president Arnold R√º√ºtel challenged i-voting, claiming breach of the principle of equality of voting.
The president brought a petition against the e-voting provisions to Estonian Supreme Court but lost. R√º√ºtel was mostly
popular amongst the still Russian speaking elderly minority. About 1.9% voted online in the
<a href="https://archive.is/20120713045721/http://news.com.com/Estonia+pulls+off+nationwide+Net+voting/2100-1028_3-5898115.html">2005 election</a>.
This has increased over the years to <a href="https://rk2019.valimised.ee/en/voting-result/voting-result-main.html">43.8% in 2019</a>.</p>
<p>Estonia also open-sourced much of their source code to make the system as transparent as possible. They haven't
released everything (annoying some critics). Most notably, all the client side code is missing (more in that later).</p>
<p>One of the biggest things going for i-voting is potentially increasing voter turnout, however that
claim has been <a href="https://core.ac.uk/download/pdf/95665595.pdf">mostly invalidated.</a></p>
<h3>Vulnerabilities</h3>
<p>One peer <a href="https://estoniaevoting.org/findings/paper/">reviewed research paper</a> claims the researchers could be able to
breach the system, change votes and vote totals, and erase any evidence of their actions if they could install
malware on the election servers. Now of course, it's basically impossible to breach the security of election servers.
However, circling back to human error; what if someone is bribed, careless, or just malicious? The stakes are immense,
and these edge cases can not be ignored.</p>
<p>Another gaping security hole is the personal device of the voter. This may be the weakest link in the chain.
The system is quite robust after the ballot has been cast. However, sending that ballot is not trivial. </p>
<p>It's easy to write a fake web client (hence the hidden source code. That would make it too easy),
tricking people into thinking they've already voted. Or a piece of malware, sending a different vote than you typed.</p>
<p>The Estonian National Electoral parried these criticisms, <a href="http://vvk.ee/valimiste-korraldamine/vvk-uudised/vabariigi-valimiskomisjoni-vastulause-the-guardianis-ilmunud-artiklile">claiming</a>
they "give us no reason to suspend online balloting". The purported vulnerabilities were said to be either not feasible in reality or already accounted for in the design of the e-voting system.</p>
<p>The Estonian Information System Authority also responded. Claiming the criticisms as a political, rather ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.iankok.com/risk-electronic-voting">https://blog.iankok.com/risk-electronic-voting</a></em></p>]]>
            </description>
            <link>https://blog.iankok.com/risk-electronic-voting</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057302</guid>
            <pubDate>Wed, 11 Nov 2020 10:52:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux Kernel Bug Fixing Mentorship]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057256">thread link</a>) | @janvdberg
<br/>
November 11, 2020 | https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship | <a href="https://web.archive.org/web/*/https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="634481719919165440">
                    
                        
                            <h3><a href="https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship">Linux Kernel Bug Fixing Mentorship</a></h3>
                        <p>I recently finished a three months long <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmentorship.lfx.linuxfoundation.org%2F&amp;t=Y2U1OTljMjEzMDMxYmM5MzQxMDI2NmRlZmNlNjcxZTIxOGM1YjFiMyxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605298774" target="_blank">CommunityBridge(now knows as LFX)</a> mentorship with <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.linuxfoundation.org%2F&amp;t=NmI2YWFjMWNkZTQ1YTZiZTg1YTlmNTIzMGNiOTkxZTA0YTA2NGI5YSxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605298774" target="_blank">The Linux Foundation</a>. I worked as a <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmentorship.lfx.linuxfoundation.org%2Fproject%2Ff06db0d5-537e-4e0f-8ca4-0a471f95a04d&amp;t=YzhhYWIzMjA5ZGUxZmRhNTgyOGZlYTUyMDZiMzkyNGYyODJkODkzNyxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605298774" target="_blank">Linux kernel bug fixing</a> mentee under <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fwww.kroah.com%2Flog%2Fabout.html&amp;t=NGRkNGYxNWM2NTk2Y2EwMDRkM2MwMWM0MjFiOGE4NTk2YTZlN2ZjNCxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605298774" target="_blank">Greg Kroah-Hartman</a>. This post is about my experience and work during the mentorship program.</p><p>In
the first week of the mentorship program, I learned about debugging
techniques for the Linux kernel, how to use decode_stacktrace.sh, and
what is CONFIG_KASAN. These were all unfamiliar concepts for me, and
I found the mentors‚Äô learning resources very useful. My first task
was to write summaries of my understanding of these concepts. I found
these summaries quite helpful while fixing real bugs in the kernel
later in the mentorship.</p><p>I
was also unfamiliar with syzkaller and syzbot before becoming part of
the mentorship. So after completing the summary tasks, I spent the
next few days getting familiar with these tools. The syzbot dashboard
has hundreds of reported bugs, and I found it a little challenging to
decide which one I should pick first.</p><p>In
the meantime, my mentor, Greg KH, redirected me towards an ongoing
discussion regarding a bug produced due to a short read in
usb_control_msg() call. There existed a few ways to fix it, and after
discussing them with the mentor, I proposed a fix. The patch
generated a fair amount of discussion, and I also received comments
that the proposed fix wasn‚Äôt the right way to handle the bug. The
discussion also concluded that many other usages of
usb_control_msg(), which don‚Äôt have proper error checks, are also
prone to similar bugs. I fixed the bug by adding an adequate error
check to prevent short reads in the caller, and Greg KH wrote new
wrapper functions for usb_control_msg() to be used in such scenarios
to avoid similar bugs.</p><p>Apart
from this bug, I also explored two other bugs. I found them
fascinating because inspite of being listed on the dashboard, their
reproducers weren‚Äôt triggering any issues. I learned that a commit
had fixed one of these bugs, and it was yet to be applied to all
kernel trees. But the other bug didn‚Äôt have any reported fix, yet the
reproducer wasn‚Äôt triggering the issue. I discussed this with the
mentor and learned that the syzbot dashboard isn‚Äôt quite dynamic. So
we decided to mark the bug as ‚Äúinvalid.‚Äù On a later
discussion with other community members I learned that it was not a
good idea, and I‚Äôve ended up marking a potentially valid bug as
‚Äúinvalid‚Äù!</p><p>As
a follow-up work on the first usb_control_msg() bug, I submitted a
cleanup patch series for some of the drivers/net/usb files. One of
those patches ignored the GFP_NOIO flag used in the original code and
replaced it with the GFP_KERNEL flag used in the new wrapper API
functions. It was a blunder that resulted in a discussion to add a
new argument for memory allocation flags in the wrapper functions.
Now the wrapper functions take memory flags as arguments preventing
mentees like me from repeating such blunders.</p><p>I
continued the follow-up work by investigating drivers/usb/serial/
files. I noticed that many usages of usb_control_msg() rely on its
return value of the number of bytes read/wrote. And the new wrapper
functions don‚Äôt retain that information. So I had a discussion with
the mentor about if that information was really necessary. We
concluded that it is almost always unnecessary, and having an error
code returned is a better way.</p><p>I
ended up submitting 19 patches as part of the mentorship program. The
first one is a fix for the usb_control_msg() short read bug. The next
three are cleanup patches for usb_control_msg() wrapper functions for
drivers/net/usb files, which were rejected because of the memory flag
blunder. And the remaining 15 are usb_control_msg() cleanup patches
for drivers/usb/serial/ files. Greg KH has reviewed them, but they
are not yet merged in the mainline.</p><p>Apart
from the bug fixing, I also learned few other interesting things
about the Linux kernel and its developer community, like how we test
various changes in the kernel and why we strictly use plain text
emails. I also attended talks at the Linux Plumber‚Äôs Conference and
the Open Source Summit Europe during the mentorship, which helped me
catch up with what is happening in the kernel world, learn new
things, and make new connections.</p><p>
My
mentorship program experience has been fantastic, and I recommend it
to everyone interested in pursuing Linux kernel development and
looking for mentoring. I am heartily thankful to my mentor Greg KH,
Shuah Khan, and The Linux Foundation, for providing me with this
opportunity and a great learning experience. 
</p><p>Patches can be found on&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Flore.kernel.org%2Flkml%2F%3Fq%3Dhimadrispandya&amp;t=MGEzOGVkMTE2ODI0MThhMjgwMDRhZDVjNzdkOTBjOWYxYjAyMzJkZixxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605298774" target="_blank"> https://lore.kernel.org/lkml/?q=himadrispandya.<br></a></p>
                    </article></div>]]>
            </description>
            <link>https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057256</guid>
            <pubDate>Wed, 11 Nov 2020 10:41:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Choosing Boring Tech]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057240">thread link</a>) | @amzans
<br/>
November 11, 2020 | https://panelbear.com/blog/boring-tech/ | <a href="https://web.archive.org/web/*/https://panelbear.com/blog/boring-tech/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Over the years I have observed that many engineers tend to attribute much of the success or failure of a company to the technical choices made. I know I‚Äôm often guilty of this too. And while it is often justified, I would argue that for the vast majority of startups out there, the choice of programming language, framework, or even database doesn‚Äôt matter that much. This seems especially true during the early stages.</p><h2>Through the engineering lens</h2><p>This perception is understandable, we as engineers tend to look at the world from a specific lens, and are often biased by what we know best. Our daily activities may include things such as debugging CI pipelines, implementing new features, pairing with colleagues, or migrating the always present legacy codebase. The environment that surrounds us makes it easy to believe that it all boils down to those things that we see and understand. It‚Äôs an illusion that makes us feel like we‚Äôre fully in control of what makes or breaks the product.</p><p>Don‚Äôt get me wrong, it can be a huge advantage for many companies to make their product 3x more efficient than competitors, or to have elegant, composable code. But you might be focusing on the wrong problems if nobody cares about the product you‚Äôre actually building, and sooner or later your business will hit this wall.</p><p>I‚Äôm not saying that software doesn‚Äôt matter. A solid foundation for your startup goes a long way. If investing in this allows you to build better features faster than your competitors, more power to you. But finding the right balance is highly dependent on what you‚Äôre trying to solve and the resources you have at hand. There‚Äôs no right or wrong way to do it, and as usual, it mainly comes down to tradeoffs.</p><p><img src="https://panelbear.com/static/img/blog/lenses.png" alt="Different lenses"></p><h2>Boring makes me happy</h2><p>I believe aiming for a healthy balance of risk vs reward when it comes to your technical choices is something to strive for. In particular, if it decreases the chances you get stuck on the wrong problems down the road.</p><p>This is why I have come to appreciate ideas such as <a href="https://mcfunley.com/choose-boring-technology">Choose Boring Technology</a>. This is often interpreted as ‚Äúpicking old technologies over newer ones‚Äù, but it doesn‚Äôt necessarily mean that. For me, this comes down to using proven technologies in which the ways it can fail are mostly known, but occasionally experimenting with different, possibly newer tools that might suit me better.</p><p>Maybe you want to gain more experience by using the latest framework or programming language, or you just want to have some fun. You do what makes you happy. But if you‚Äôre trying to make a decision to increase the odds that your product or business will succeed, it‚Äôs worth stepping back and considering your options.</p><p>For me, mainly choosing software that has been around for longer is not about it being boring or older, it‚Äôs about the fact that the ways in which it fails are better known. There are fewer unknowns for you to deal with and this maximizes your chances of actually shipping the project.</p><p>For example the other day I had an issue with my Django app, and a quick search led me to tens of answers to this problem in various forums and websites. It took me at most 10 minutes to get back on track and that was the end of this issue.</p><p>I experienced the exact opposite a few years ago with a popular, but not so battle-tested Scala library my team had been using for a while. We were probably among the first to encounter the issues we were facing, and it seemed nobody had walked down this path before. Maybe it sounds like a fun challenge or a great chance to contribute back to OSS (which I‚Äôm happy to), but once you solve it, do your customers really care about it? How many days, weeks, or even months are you willing to invest in such issues? In my case, I‚Äôd rather use that time to ship new features or improve the existing ones.</p><h2>Proven tech vs new tools</h2><p>I try to follow an 80/20 distribution when it comes to my choice of tools. This means my stack consists of about 80% software I already know well, but I do allow myself 20% of the stack to explore tech I have less experience with. The exact ratio is not what‚Äôs important here, it‚Äôs more the fact that you should lean towards using proven technologies.</p><p>This also resonates with how <a href="https://en.wikipedia.org/wiki/Multi-armed_bandit">Multi-armed bandits</a> work. You try to maximize your expected gain by taking advantage of what worked well in the past, while sometimes exploring new things to avoid missing out on a possible goldmine.</p><p><img src="https://panelbear.com/static/img/blog/bandits.png" alt="Balance new vs proven"></p><p>A more recent example of mine is <a href="https://panelbear.com/">Panelbear</a>, it started as an embarrassingly simple Django app with no charts, all metrics were rendered on a plain HTML table, and all data was stored on a SQLite database. Took literally a weekend to get it up and running including manually deploying to a $5/mo VM. Low risk and high reward for my needs at the time.</p><p>Fast forward and as I added more features and began handling more page views for various websites, I started to notice that the codebase could use some refactoring. It also became increasingly repetitive to do things like deploying to new instances, issuing SSL certs, and keeping the DNS records up to date in case the IP address of my instances changed.</p><p>As a second iteration, I upgraded to a docker-compose setup plus lots of glue code. But soon enough I found myself reinventing what other tools already do well. There are multiple ways to solve each of these pain points, but in my case, it came down to using a tool I am very familiar with from my full-time job: Kubernetes.</p><p>Yes, I am well aware Kubernetes is an absolute overkill for a lot of projects out there, and I could have gotten away with a more traditional solution. But it allowed me to simplify the operational aspects tremendously, and I feel comfortable working with it after having the pleasure of putting down multiple production fires for my employer over the years. That‚Äôs why I wouldn‚Äôt bindly recommend it to everyone. Do what you know best.
As an added benefit, it also made it trivial when I migrated from DigitalOcean to Linode, and most recently to AWS (each migration took mostly an evening of changing my Terraform files and deploying them - I‚Äôm being serious). But that‚Äôs for another post.</p><p>Another case in which it paid off once again, was when I wanted to experiment with using Clickhouse for data ingestion and the aggregation queries. It took me less than 10 minutes to write a basic deployment manifest and have it up and running. This included automated SSL certs, in-cluster service discovery, and unified logging/monitoring out of the box. It was a huge win since it allowed me to try things out faster than before.</p><p>Even better, I can deploy any container and operate it the exact same way as I deploy anything else on my cluster. Need more volume storage with zero downtime? It‚Äôs a simple manifest change, commit and deploy. Same thing when I needed Redis for caching, I was up and running in minutes, without increasing my costs or adding operational complexity.</p><h2>Focus on shipping</h2><p>My point is, I moved into these technologies as the pain with the previous solution was higher than dealing with the new tech. But more importantly, it helped me ship features even faster to my customers while reducing the operational overhead for me.</p><p>If I had started with the more advanced setup from day one, I might have lost all motivation before I would have had the first version of Panelbear. The key is to solve the problems that are getting between you and your goals, not potential issues you believe one day will be yours.</p><p>Hope you enjoyed this blog post. I plan on writing more about Panelbear‚Äôs tech stack, and lessons learned along the way. So stay tuned!</p></div></div></div>]]>
            </description>
            <link>https://panelbear.com/blog/boring-tech/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057240</guid>
            <pubDate>Wed, 11 Nov 2020 10:37:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Option Hacking the Tektronix TDS 420A]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25057162">thread link</a>) | @segfaultbuserr
<br/>
November 11, 2020 | https://tomverbeure.github.io/2020/07/11/Option-Hacking-the-Tektronix-TDS-420A.html | <a href="https://web.archive.org/web/*/https://tomverbeure.github.io/2020/07/11/Option-Hacking-the-Tektronix-TDS-420A.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>Previous installments in this series: <a href="https://tomverbeure.github.io/2020/06/27/In-the-Lab-Tektronix-TDS420A.html">In the Lab - Tektronix TDS 420A Oscilloscope</a>, 
 <a href="https://tomverbeure.github.io/2020/06/27/Tektronix-TDS420A-Remote-Control-over-GPIB.html">Tektronix TDS 420A Remote Control over GPIB</a>, 
 <a href="https://tomverbeure.github.io/2020/07/02/Extracting-the-Tektronix-TDS420A-Firmware.html">Extracting the Tektronix TDS 420A Firmware</a>, 
 <a href="https://tomverbeure.github.io/2020/07/03/TDS420A-Serial-Debug-Console-Symbol-Table-Ghidra.html">A Tektronix TDS 420A, a Serial Debug Console, a Symbol Table, and Ghidra</a></em></p>

<ul id="markdown-toc">
  <li><a href="#introduction" id="markdown-toc-introduction">Introduction</a></li>
  <li><a href="#how-a-tds400-oscilloscope-manages-hardware-features" id="markdown-toc-how-a-tds400-oscilloscope-manages-hardware-features">How a TDS400 Oscilloscope Manages Hardware Features</a></li>
  <li><a href="#the-key-to-enabling-option-05---video-triggering" id="markdown-toc-the-key-to-enabling-option-05---video-triggering">The Key to Enabling Option 05 - Video Triggering</a></li>
  <li><a href="#the-key-to-enabling-option-2f---advanced-dsp-math" id="markdown-toc-the-key-to-enabling-option-2f---advanced-dsp-math">The Key to Enabling Option 2F - Advanced DSP Math</a></li>
  <li><a href="#options-05-and-2f-enabled" id="markdown-toc-options-05-and-2f-enabled">Options 05 and 2F Enabled!</a></li>
  <li><a href="#option-1m---120k-sample-points---a-different-story" id="markdown-toc-option-1m---120k-sample-points---a-different-story">Option 1M - 120K Sample Points - A Different Story</a></li>
  <li><a href="#in-search-of-the-missing-memory" id="markdown-toc-in-search-of-the-missing-memory">In Search of the Missing Memory</a></li>
  <li><a href="#success-at-last" id="markdown-toc-success-at-last">Success at Last!</a></li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
  <li><a href="#references" id="markdown-toc-references">References</a></li>
</ul>



<p>I wrote <a href="https://tomverbeure.github.io/2020/06/27/In-the-Lab-Tektronix-TDS420A.html#the-tektronix-tds-420a-in-brief">earlier</a>
about the optional features of TDS 400 series of oscilloscopes:</p>

<ul>
  <li>Option 05: Video Trigger</li>
  <li>Option 13: RS-232/Centronics Hardcopy Interface</li>
  <li>Option 1F: File System/Floppy</li>
  <li>Option 2F: Advanced DSP Math</li>
  <li>Option 1M: 120k waveform sample points</li>
</ul>

<p>Most scopes, including mine, come with options 13 and 1F, but the remaining ones are less common.</p>

<p>The video triggering and advanced DSP math options are pure firmware functions, but even 
the 120k sample points option seemed like something that could be enabled with a software hack, since
the signal acquisition board has the 512KB of RAM available to store the data.</p>

<p>Here, I‚Äôll describe how the TDS 400 series manages option enablement, and
how you can hack the scope into getting them to work.</p>



<p>Using Ghidra and the debug console, I figured out how the scope manages hardware
features: it has a function called <code>hwAccountantQuery</code> that has a single
parameter which I‚Äôll call the ‚Äòfeature ID‚Äô.</p>

<p><code>hwAccountantQuery</code> will return an integer value for that feature ID. These values
can be boolean in nature (‚ÄúIs a certain feature present or not‚Äù) or can be the
amount of DSP memory etc.</p>

<p>Here‚Äôs a very non-exhaustive list of codes that I‚Äôve been able to identify:</p>

<div><div><pre><code>0x20d: number of scope channels
0x20f: size of acquisition RAM
0x216: ProbeD2MemSize
0x248: CPU clock period
0x255: InstrumentNameStringPtr
0x271: hwProbeSpecialDiagModeActive
0x2a0: hwProbeSpecialDiagLoopCount
0x2a1: hwProbeSpecialDaigSeqId
0x2b8: 30000 points -&gt; value when 1M option is not possible
0x2bf: TDS420A
0x2d2: RS232 Debug uart present
0x317: MathPak      -&gt; this is the advanced DSP math function
0x461: Floppy drive present
0x537: flashRomDateStringPtr
0x54c: TDS410A
0x560: TDS430A
0x700: hwProbeTvTrigPresent
</code></pre></div></div>

<p><code>hwAccountantQuery</code> calls <code>hwAccountantGetValue</code>. The first part of that function looks liks this:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwAccountantGetValue.png" alt="hwAccountantGetValue"></p>

<p>It‚Äôs a large <code>if-then-else</code> or <code>case</code> statement that calls a dedicated function for a particular
feature ID.</p>



<p>Did you see <code>_hwProbeTvTrigPresent()</code>? That‚Äôs the function that checks
if the video triggering feature should be enabled:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbeTvTrigPresent.png" alt="hwProbeTvTrigPresent"></p>

<p>And there we have it! To enable ‚ÄúOption 05 - Video Triggering‚Äù, all you need to do
is store a non-zero value in non-volatile RAM location 7!</p>

<p><em>This is not a shocking new discovery: plenty of online sources already mentioned this,
but it‚Äôs great to confirm it from first principles, by going to the source.</em></p>



<p>Internally, the Advanced Math DSP is called ‚ÄúMathPak‚Äù. Just like for video triggering, 
the <code>hwAccountGetValue</code> function issues a call to <code>hwProbeMathPakPresent()</code>:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbeMathPakPresent.png" alt="hwProbeMathPakPresent"></p>

<p>Option 2F simply relies on a non-zero value in NVRAM location 9!</p>



<p>It‚Äôs now just a matter of issuing the following 2 commands on the debug console:</p>

<div><div><pre><code>libManagerWordAtPut 0x50007, 1
libManagerWordAtPut 0x50009, 1
</code></pre></div></div>

<p>My scope booted up with this image:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/options_05_and_2f_enabled.jpg" alt="Options 05 and 2F enabled"></p>

<p>Success! I‚Äôm now the proud owner of a scope that supports an entirely obsolete video triggering
mode, and a FFT math option!</p>

<p>Video Triggering Menu:
<img src="https://tomverbeure.github.io/assets/tds420a/video_triggering_features.jpg" alt="Video triggering features"></p>

<p>Live FFT of a 1kHz square wave:
<img src="https://tomverbeure.github.io/assets/tds420a/fft.jpg" alt="FFT"></p>



<p>Unfortunately, the <code>case</code> statement is only a small part of the <code>hwAccountGetValue</code> function: most
feature checking functions are performed by looping through an array of structs that
have the feature ID and a function pointer to the checking function. It‚Äôs a bit harder to figure 
out in Ghidra, but we already know that the function names to enable options start with <code>hwProbe</code>.</p>

<p>With Ghidra, we can filter on this, and that gives the <code>hwProbe1MOption</code> and the 
<code>hwProbe1MPresent</code> functions.</p>

<p><code>hwProbe1MPresent</code> looks very familiar:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbe1MPresent.png" alt="hwProbe1MPresent"></p>

<p>Just like for the 05 and 2F options, we need to set a specific byte in the
NVRAM:</p>

<div><div><pre><code>libManagerWordAtPut 0x50006, 1
</code></pre></div></div>

<p><code>hwProbe1MOption</code> is a different story:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbe1MOption.png" alt="hwProbe1MOption"></p>

<p>When you run <code>hwProbe1MOption</code> on the command line, the function returns a 0.</p>

<p>Feature IDs 0x216 and 0x20f are also part of the array of structs. They call the functions
<code>hwProbeD2MemSize</code> and <code>hwProbeAcqMemSize</code> respectively.</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbeTable.png" alt="hwProbe table"></p>

<p><code>hwProbeD2MemSize</code> and <code>hwProbeAcqMemSize</code> both run a test to check the amount of RAM that 
is populated on the board.</p>

<p>When you run these query commands on the debug console, you get:</p>

<div><div><pre><code>hwAccountantQuery(0x216)    
262143
hwAccountantQuery(0x20f)    
131071
</code></pre></div></div>

<p>It‚Äôs now clear why option 1M doesn‚Äôt get enabled after changing the NVRAM value: 
feature ID 0x20f is fine (131071/0x1ffff is larger than 0x1fffe), but feature ID 0x216 is not 
(262143/0x3ffff is smaller than 0xffffe).</p>

<p>Whatever it is used for, the amount of ‚ÄúD2‚Äù memory in the scope is too small.</p>



<p>This finally gave me the crucial hint to start looking at other PCBs inside the scope and
try to find if there‚Äôs a place with empty footprints for RAM chips.</p>

<p>I call this the DSP PCB. Luckily, it‚Äôs a board that‚Äôs easy to remove from the chassis, without 
fragile flex cables or connectors.</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/dsp_pcb.jpg" alt="DSP PCB"></p>

<p>Look at those 6 beautiful, unused footprints!</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/ram_footprints_closeup.jpg" alt="RAM footprints closeup"></p>

<p>The RAM chips are M5M51008 with a 100ns speed rating, made by Mitsubishi LSI.</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/memory_datasheet.jpg" alt="Memory Datasheet"></p>

<p>Surprisingly, Digikey still carries these parts: they‚Äôre now made by Rochester
Electronics, and only available in 70ns or 55ns version, but faster is better,
so that shouldn‚Äôt be a problem.</p>

<p>They‚Äôre cheap too at just $2.56 a piece.</p>

<p>The only issue is a minimum order quantity of 100 parts. $256 for a feature
on a 25 years old $190 oscilloscope is a bit too much! Luckily, the parts
are available at various Chinese chip brokers: I was able to buy them at 
<a href="https://utsource.net/">UTSource</a> for just $1.81 a piece. Even when buying 10 
of them (for redundancy), shipping was the biggest part of the cost:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/memory_order.png" alt="Memory Order"></p>

<p><em>Once ordered, UTSource let me know that these parts were refurbished‚Ä¶</em></p>

<p>A few days later, the parts arrived at my front door, ready to be populated
on the DSP board:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/dsp_board_before_surgery.jpg" alt="DSP Board Before Surgery"></p>

<p>Note how I did not disconnect the battery that‚Äôs wired to the board: it‚Äôs used to
permanently provide power to those 4 RAMs chips on the left that are encased into 
some transparant polymer gu. Removing the battery will result in lost calibration
data (or so they say.)</p>

<p>I used a regular soldering iron instead of a hot air gun to attach the 6 RAMs:
there was enough solder on the pads and I‚Äôm most comfortable doing it that way.
Afterwards I Ohm‚Äôed out most of the pins, and I‚Äôm glad I did because
there were some open connections.</p>

<p>The end result isn‚Äôt perfect, but it‚Äôs good enough:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/rams_populated.jpg" alt="RAMs Populated"></p>



<p>With the RAM populated, it‚Äôs time to power on the scope and check the result
of the enhancement surgery!</p>

<p>The scope bootup screen looks good:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/option_1m_enabled.jpg" alt="Option 1M enabled"></p>

<p>And this formerly grayed out 12000 points menu option is now available:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/120k_points.jpg" alt="120K Points"></p>

<p>Victory at Last!</p>



<p>The TDS 420A is an old oscilloscope, and even with those 3 new options enabled, it‚Äôs
far inferior to my Siglent 2304X or even my HP 54825A (Windows 95!) loaner.</p>

<p>120K sample points is obviously better than 30K, but it still pales in comparison
to the 140M sample points of the Siglent.</p>

<p>So what then was the point of this whole exercise?</p>

<p>I got a close up view of oscilloscope internals, I learned Ghidra from scratch and
applied it on a real, non-trival project, I added RAM to a 25 year old oscilloscope 
and it worked, I spent tons of late night hours decoding firmware, and 
I had an unreasonable amount of fun doing so.</p>

<p>I even started to appreciate the Tektronix user interface a little bit!</p>

<p>It was time well spent.</p>

<p>For now, the scope will remain on my bench while I start adding Tektronix support 
in glscopeclient. That was the whole point of acquiring the scope to being with!</p>

<p>And if it turns out that it‚Äôs really too limited for my use, I can always
sell it back on eBay, this time with 3 additional features enabled.</p>



<ul>
  <li>
    <p><a href="https://www.eevblog.com/forum/testgear/hacking-my-tds460a-to-have-options-1m2f/">Hacking my TDS460A to have options 1M/2F?</a></p>
  </li>
  <li>
    <p><a href="https://forum.tek.com/viewtopic.php?t=140268">TDS420 Options Possible?</a></p>
  </li>
  <li>
    <p><a href="http://videohifi17.rssing.com/chan-62314146/all_p49.html">Upgrade Tektronix: FFT analyzer</a></p>

    <p>Story about upgrading the CPU board from 8MB to 16MB on a TDS420 (not the 420A?) and then FFT in the
  NVRAM.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=iJt2O5zaLRE">Enabling FFT option in Tektronix TDS 540A oscilloscope</a></p>

    <p>Not very useful for 420A owners: enables FFT by copying NVRAM EEPROM.</p>
  </li>
  <li>
    <p><a href="https://www.eevblog.com/forum/testgear/tds420-with-lost-options/msg2032465/?PHPSESSID=021nnvu02ca549sh5le7s9r8i5#msg2032465">TDS420 with lost options</a></p>

    <p>Specific comment about how to enable options on the 420A over GPIB. I wasn‚Äôt able to get this to 
  work for some reason.</p>
  </li>
  <li>
    <p><a href="http://www.ko4bb.com/getsimple/index.php?id=enable-tds754d-options">Enable TDS754D Options using GPIB</a></p>

    <p>Another one about using GPIB.</p>
  </li>
</ul>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://tomverbeure.github.io/2020/07/11/Option-Hacking-the-Tektronix-TDS-420A.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057162</guid>
            <pubDate>Wed, 11 Nov 2020 10:22:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Time Tracking]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057142">thread link</a>) | @hanspagel
<br/>
November 11, 2020 | https://blog.ueber.io/post/time-tracking/ | <a href="https://web.archive.org/web/*/https://blog.ueber.io/post/time-tracking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Our whole company is based on time tracking. While we can understand the love-hate relationship many people have with it, you shouldn‚Äôt overlook the benefits. Let‚Äôs go through a few things we learned about time tracking and how we make it less scary.</p>
<h2 id="the-benefits-of-tracking-time">The benefits of tracking time</h2>
<p>First of all, we think that time is the most precious thing we all have, so that‚Äôs what we sell. Clients trustfully hire us to work with them for a certain amount of days, giving the best we can during that time. We promise to focus entirely on our client‚Äôs projects and do the thing we can do best.</p>
<p>That also means no one is paying more hours than we work, and no one is paying fewer hours than we did. If we‚Äôre pretty fast together, that‚Äôs a win for both of us. If you‚Äôre adding more and more requirements to the feature, you‚Äôll get more, also pay more in the end, and it‚Äôs also a win for both sides. That‚Äôs the fairest it can get.</p>
<p>That makes writing offers and invoices easier, too. Why should we waste time negotiating a price with you? It‚Äôs not what we are good at, and it‚Äôs nothing anybody benefits from. <a href="https://blog.ueber.io/post/fixed-budgets">Our offers have a recommended amount of days we need to work together to help you the best.</a> Our invoices are a monthly sum of tracked hours, roughly the amount in our offers. Or it‚Äôs less if we didn‚Äôt work as much as we expected, or more if there was more to do a particular month.</p>
<p>Also, that‚Äôs fully transparent for everyone. We can warn our clients upfront if we‚Äôre going to need more time and leave the decision to them.</p>
<p>Most of our invoices only include the sum of hours and a list of things achieved in that time. If someone asks, we also attach a detailed time tracking report. From our experience, clients who ask for that level of transparency have trust issues anyway, and we can‚Äôt build up trust from that alone, so there‚Äôs probably some more serious issues behind that question.</p>
<p>Most people here work from their home office, and so a lot happens without everyone knowing it, but the sum of tracked hours per project gives a good glimpse over what happens in the company. Note that there is a big assumption in it, which probably doesn‚Äôt work for every team. We assume if people spend time on a project, they move it forward. If we want to move a project forward quicker, it‚Äôs often enough <a href="https://blog.ueber.io/post/the-schedule">to schedule more time of one or two project members for those projects for the upcoming months</a>.</p>
<h2 id="without-tracking-time">Without tracking time</h2>
<p>Sure, it‚Äôs great not having to press a button before and after work. But, that can be very dangerous in many regards, especially for creative work.</p>
<p>I don‚Äôt know about you, but we forget about time when we‚Äôre in a flow state and deeply concentrated. There is no chance I could tell you if I was working one or four hours on a problem at the end of a day, or I could know if I was working 50 or 100 hours on a specific project at the end of the month.</p>
<p>Though, I like to look up how much I worked over the week on a Friday evening. A lot of hours can be a sign of a lot of uninterrupted work, which‚Äôs a good thing.</p>
<p>We even feel it protects us from doing more or less than we get paid. Both could be bad for a calm working environment, where you don‚Äôt want to do extra hours (stress!) and don‚Äôt want to slack around too much in between projects (procrastination leads to stress).</p>
<h2 id="how-we-do-it">How we do it</h2>
<p><a href="https://blog.ueber.io/post/tools">We use Toggl Track for a few years now</a>, but you can use whatever you like. It‚Äôs a service that everyone in the team has access to, has a big start/stop button, and a description field. That‚Äôs it.</p>
<p>By the way, some tools offer automatic time tracking, which checks what app you‚Äôre running for how long. If you struggle to build the habit of tracking the time, that‚Äôs probably a better start.</p>
<p>When you‚Äôre ready to work on a project, start by clicking the start button. When you‚Äôre finished, hit stop. There is no need to stop the tracking if you‚Äôre away from the keyboard for a few minutes. Only pause the timer if you‚Äôre about to take your lunch break, any other kind of long pause, or to switch to a different project (which we try to avoid).</p>
<p>For most projects, it‚Äôs enough to attach the entry to that project and roughly describe in few words what you‚Äôre doing, for example, ‚ÄúDesigning wireframes‚Äù. There is no need to get too specific here and mention single tasks or anything like that.</p>
<h2 id="what-were-tracking">What we‚Äôre tracking</h2>
<p>Our whole billing bases on time tracking, so it‚Äôs essential to track clients‚Äô work, including everything you need to advance the project. For example, when you‚Äôre designing, developing, thinking, doing research, or experiments.</p>
<p>Besides that, we also expect people to track internal projects (I‚Äôm tracking time on ‚ÄúBlog‚Äù right now), and we have a lot of them. For example, our website, <a href="https://blog.ueber.io/post/list-of-side-projects">all of our self-initiated projects</a>, a sustainability project, social engagement projects, and many more.</p>
<p><a href="https://blog.ueber.io/post/keep-learning">Every team member needs time to learn</a>, so we schedule days to do just that. We ask people to track that too. Learning doesn‚Äôt produce a tangible outcome, so the tracked time can be a great indicator if there was enough time to learn over the year.</p>
<h2 id="dont-track-that">Don‚Äôt track that</h2>
<p>We don‚Äôt track other things, like socializing, watching a video between tasks, or other smaller breaks. We all need those, especially while doing creative work.</p>
<p>Also, we don‚Äôt expect anyone to get to the amount of time in their contract. There are probably many people sitting eight hours a day in front of their screen, but no one works eight hours straight‚Äîno need to get to that sum of hours for your working day.</p>
<h2 id="common-pitfalls">Common pitfalls</h2>
<p>We don‚Äôt want to sound too optimistic here. Yes, it can be unpleasant to press the start/stop before doing the actual work. All our projects are scheduled based on days, so people only have to press start and stop a few times in an ideal week. From our experience adding descriptions can feel tedious, too. For example, as I‚Äôve already said, ‚Äúdeveloping the backend‚Äù is eloquent enough in most cases.</p>
<p>If you expect to track your whole day, that‚Äôs going to be disappointing, too. We don‚Äôt get tired to repeat it:</p>
<p>No one works eight hours straight. A day with four to six hours of tracked time has probably been a great day with plenty of uninterrupted work. We consider that a huge success already. There is no need to get to eight hours per day (or whatever your contract says).</p>
<p>Oh, and yes, we don‚Äôt confuse the tracked time with ‚Äúperformance‚Äù or take it as a metric of success for a single team member or us as a company. Tracking more time doesn‚Äôt make you or us more productive per se. We try to keep it fair for everyone. For you, for the whole team, and our clients, that‚Äôs all.</p>
<h2 id="your-experience">Your experience</h2>
<p>What‚Äôs your experience with time tracking? Is there anything that annoys you? Do you have an idea of how it can get more comfortable? <a href="https://twitter.com/hanspagel/status/1326468288201826305" target="_blank" rel="nofollow noopener noreferrer">Share it with us on Twitter!</a></p>
</section></div>]]>
            </description>
            <link>https://blog.ueber.io/post/time-tracking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057142</guid>
            <pubDate>Wed, 11 Nov 2020 10:18:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Four Steps to Take After Your Unsuccessful Job Interview]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057115">thread link</a>) | @eisabai
<br/>
November 11, 2020 | https://code.likeagirl.io/four-steps-to-take-after-your-unsuccessful-job-interview-d4e5df344b1a?source=your_stories_page------------------------------------- | <a href="https://web.archive.org/web/*/https://code.likeagirl.io/four-steps-to-take-after-your-unsuccessful-job-interview-d4e5df344b1a?source=your_stories_page-------------------------------------">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="1182">What to do when you‚Äôve failed a job interview</h2><div><div><div><div><a href="https://medium.com/@eisabai?source=post_page-----d4e5df344b1a--------------------------------" rel="noopener"><div><p><img alt="Isabel Nyo" src="https://miro.medium.com/fit/c/96/96/1*BGXgVWhH-nqrX6VruxEvmA.jpeg" width="48" height="48"></p></div></a></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/12032/0*TadXdhbziKwvqTAg" width="6016" height="4016" srcset="https://miro.medium.com/max/552/0*TadXdhbziKwvqTAg 276w, https://miro.medium.com/max/1104/0*TadXdhbziKwvqTAg 552w, https://miro.medium.com/max/1280/0*TadXdhbziKwvqTAg 640w, https://miro.medium.com/max/1400/0*TadXdhbziKwvqTAg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*TadXdhbziKwvqTAg?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@benwhitephotography?utm_source=medium&amp;utm_medium=referral" rel="noopener">Ben White</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><blockquote><p id="b5c7">Dear {Name},</p><p id="03fa">We are sorry to inform you that the decision has been made not to progress with your application for the {role}. I‚Äôm sorry it isn‚Äôt better news.</p><p id="b9b8">Signed,<br>Recruiter/Hiring Manager</p></blockquote><p id="7790">We have all seen this kind of messages. Unfortunately though, it doesn‚Äôt get easier no matter how many times you have seen it.</p><p id="8f61">As someone who has been on the other side of the table many times as an interviewer and have had a good track record when it comes to nailing interviews as an interviewee, I still can‚Äôt completely escaped from such rejection messages.</p><p id="98d6">In this article, I‚Äôd like to share with you four steps that you can take to still walk away as a winner even after being rejected at an interview.</p></div></div></section><section><div><div><h2 id="f612">1. Obtain as much feedback as possible</h2><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/10368/0*l_fDsPC7ZWbZo-RG" width="5184" height="3456" srcset="https://miro.medium.com/max/552/0*l_fDsPC7ZWbZo-RG 276w, https://miro.medium.com/max/1104/0*l_fDsPC7ZWbZo-RG 552w, https://miro.medium.com/max/1280/0*l_fDsPC7ZWbZo-RG 640w, https://miro.medium.com/max/1400/0*l_fDsPC7ZWbZo-RG 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*l_fDsPC7ZWbZo-RG?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@nshuman1291?utm_source=medium&amp;utm_medium=referral" rel="noopener">Nathaniel Shuman</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="3d09">If you don‚Äôt hear from the company a few days or week after your interview or if you receive a generic rejection email, it‚Äôs on you to try and obtain as much feedback as possible. Be polite and professional and tell them that this will help you understand what you had done well and what you could do to improve next time. As long as you were honest in your ask, most companies will get back to you with some form of feedback. You will be using this feedback to adjust your game plan and strategy as needed, which is part of step 3.</p><p id="8408">What you should avoid doing though is to argue or counter their feedback. The decision is already made. Don‚Äôt waste your time. However, in rare occasions, if incorrect assumption was made regarding your take home exercise, or live presentation interview, you can provide more information to address the feedback. But do not expect to be considered for the role again ‚Äî in other words, do not keep your hopes up.</p></div></div></section><section><div><div><h2 id="48f7">2. Give yourself time to digest and process your emotion</h2><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/9216/0*yV4AO854GZ9Pm1u9" width="4608" height="3456" srcset="https://miro.medium.com/max/552/0*yV4AO854GZ9Pm1u9 276w, https://miro.medium.com/max/1104/0*yV4AO854GZ9Pm1u9 552w, https://miro.medium.com/max/1280/0*yV4AO854GZ9Pm1u9 640w, https://miro.medium.com/max/1400/0*yV4AO854GZ9Pm1u9 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*yV4AO854GZ9Pm1u9?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@blitzer?utm_source=medium&amp;utm_medium=referral" rel="noopener">Niklas Rh√∂se</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="925f">Being rejected and being unsuccessful at an interview is disappointing. There is no other way to put it. Even if you have got another offer from a different company or a different role, you would still want to get an offer for all the roles that you applied for. That‚Äôs human nature.</p><p id="b688">It‚Äôs completely ok to feel disappointed, upset, angry, defeated, or any other negative emotion for a while. Take the time to process your emotion. Personally for me, I go through a cycle of disappointment, sadness, anger, and then finally, acceptance. It usually takes me two hours, but every person is different, so it might just be 20 minutes for you, or 20 hours for another person. The key here is to allow yourself to feel that negative emotion instead of trying to push it aside. Once you‚Äôve felt all the emotions, you will find that you‚Äôre ready to move on and think clearly again.</p><p id="baf9">Maybe the interviewer made an error in judgement, maybe you said something that were taken on the face value, maybe your interview performance was not good enough, maybe there are more suitable candidates, it doesn‚Äôt matter what the reason is. What matter is for you to be able to move on without getting paralysed by what could have been.</p></div></div></section><section><div><div><h2 id="955e">3. Adjust your game plan and strategy if needed</h2><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/12000/0*AvjW-1p4Xhn6LC15" width="6000" height="4000" srcset="https://miro.medium.com/max/552/0*AvjW-1p4Xhn6LC15 276w, https://miro.medium.com/max/1104/0*AvjW-1p4Xhn6LC15 552w, https://miro.medium.com/max/1280/0*AvjW-1p4Xhn6LC15 640w, https://miro.medium.com/max/1400/0*AvjW-1p4Xhn6LC15 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*AvjW-1p4Xhn6LC15?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@felix_mittermeier?utm_source=medium&amp;utm_medium=referral" rel="noopener">Felix Mittermeier</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="06dc">Based on the feedback that you receive, you can do one of three things. First, you may want to change how you present yourself and how you communicate your skills to be more aligned with what interviewers are looking for. Second, you may decide to gain additional knowledge and skills in the areas that were identified as gaps. Third, you may accept that you are not going to change your tactics but apply for different roles that are more aligned with your skills and experiences.</p><p id="fed4">To give you my personal example, one of the feedback that I receive from those who do not know me or have worked with me in the industry is that I do not have a leadership presence. The perception comes from the fact that technology is a male-dominated industry and people are used to seeing assertive leaders who value hierarchy and command and control. To add to the fact that I am female, petite and soft-spoken, it‚Äôs hard for some to accept that I am an effective leader. While it‚Äôs sad to see gender and leader stereotypes in the 21st century, I have come to accept the fact. I am not willing to put on an act during an interview and display the masculine attributes commonly associated with effective leadership, such as assertiveness and competition, just to get the job.</p><p id="0ad5">This doesn‚Äôt mean I do not apply for leadership roles nor get leadership positions. I just have to understand myself well and know how to present myself in the best possible light without losing my integrity. And if I am unsuccessful because it was still not good enough in the interviewer‚Äôs opinion, then so be it.</p></div></div></section><section><div><div><h2 id="ed95">4. Remember the golden rule</h2><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/7744/0*bzx94k8FR8OiGrQr" width="3872" height="2592" srcset="https://miro.medium.com/max/552/0*bzx94k8FR8OiGrQr 276w, https://miro.medium.com/max/1104/0*bzx94k8FR8OiGrQr 552w, https://miro.medium.com/max/1280/0*bzx94k8FR8OiGrQr 640w, https://miro.medium.com/max/1400/0*bzx94k8FR8OiGrQr 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*bzx94k8FR8OiGrQr?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@quentinreyphoto?utm_source=medium&amp;utm_medium=referral" rel="noopener">Quentin Rey</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="f2ae">What‚Äôs the golden rule, I hear you ask. Dalai Lama once said, ‚ÄúRemember that sometimes not getting what you want is a wonderful stroke of luck.‚Äù Whether the reason for rejection was because you didn‚Äôt yet have the technical skills required for the role, personal traits that were deemed necessary by the interviewers and/or company, or purely a misjudgement from the interviewer‚Äôs part (yes, interviewers are humans too and they may make wrong decision), know that your worth is not tied to the performance of an interview.</p><p id="ecf7">I truly believe that everything in this world happens for you, not to you. Every time after I was rejected for a role, I got a better offer from another company. So my advice for you is to spend your time and energy on becoming a better person every day instead of dwelling on the rejection, and trust that a superior offer is just around the corner.</p></div></div></section><section><div><div><h2 id="a25c">Take the next step forward</h2><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/10368/0*QY53jEzOGv_1Qgl5" width="5184" height="3888" srcset="https://miro.medium.com/max/552/0*QY53jEzOGv_1Qgl5 276w, https://miro.medium.com/max/1104/0*QY53jEzOGv_1Qgl5 552w, https://miro.medium.com/max/1280/0*QY53jEzOGv_1Qgl5 640w, https://miro.medium.com/max/1400/0*QY53jEzOGv_1Qgl5 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*QY53jEzOGv_1Qgl5?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@brett_jordan?utm_source=medium&amp;utm_medium=referral" rel="noopener">Brett Jordan</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="e65d">So what you were rejected for a role. Your life isn‚Äôt over, your career isn‚Äôt over. It‚Äôs ok. The important thing is for you to pick yourself up again and take the next step forward. You win some, you lose some, but those who are the ultimate winners are those who have the courage to keep going until they get what they deserve, in this case, a role that is aligned with what you‚Äôre looking for and a company and colleagues who will appreciate you for what you bring to the table.</p><p id="c752">Good luck!</p></div></div></section></div></div>]]>
            </description>
            <link>https://code.likeagirl.io/four-steps-to-take-after-your-unsuccessful-job-interview-d4e5df344b1a?source=your_stories_page-------------------------------------</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057115</guid>
            <pubDate>Wed, 11 Nov 2020 10:12:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Forming Professional Dev Team Habits]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057078">thread link</a>) | @morchen
<br/>
November 11, 2020 | https://swimm.io/blog/2020-07-09-professionalism-by-forming-a-team-habit/ | <a href="https://web.archive.org/web/*/https://swimm.io/blog/2020-07-09-professionalism-by-forming-a-team-habit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-v-f94c7cca=""> <!----> <div data-v-0cf44990="" data-v-f94c7cca=""><div><p>How does your workplace cultivate an environment of team development? How do you make sure your engineers have time for creative ideas and professional development, all the while meeting sprints, deadlines and deliverables? While branded photogenic team building activities are common in many tech companies ‚Äî especially with rapidly growing teams, this strategy fails to help grow together as professionals and misses the aim in the long run.</p>
<p>For long, I‚Äôve been toying with such questions, asking myself ‚Äî how can companies keep ‚Äúthe fun bits‚Äù, but also cultivate purpose and a culture of self and team professional development. In this post you‚Äôll find the pilot we‚Äôre launching at Swimm: the main goals of such a pilot and why we believe in it, as well as the execution strategy. We will follow-up and share our experiences in future posts.</p>
<h3><strong>The Why: Delivering Code Excellence</strong></h3>
<p><strong>Professionalism</strong>. First, we want to create a culture where all of our team members learn new things, on an ongoing basis. To become professionals, we need to keep learning all the time. To stay happy and challenged at work we need access to resources, and need our managers to invest in our development.</p>
<p><strong>Innovation</strong>. Second, reviewing together new topics and brainstorming on how they can be integrated into our products will provide new ideas and make us constantly rethink our current approaches.</p>
<p>While thinking about a way to achieve these goals, I was looking for best practice, study cases and models that worked well or gloriously failed in other places in the tech industry. Specifically, I was inspired by <a href="https://medium.com/@Idan.Bassuk/a-proven-methodology-for-becoming-an-a-i-expert-32d43887cb1e">this post</a> by Idan Bassuk from <strong>Aidoc</strong>. I contacted Idan and he was very kind to answer all my questions. I learned that they‚Äôve been continuing their ‚ÄúDeep Snips‚Äù (where one of their team members learns a subject and presents it to the team) for the past 3 years, and that he still believes this method helps achieve its goals. I learned from their experience that many of their talks resulted in actual impact to their products. This gave me confidence that this method can indeed have a meaningful impact, and I was now more eager than before to put this to the test.</p>
<h3><strong>The How: Swimminars X 2 Weeks</strong></h3>
<p><strong>Swimminars.</strong> Every other week, one of our engineers will get to learn something new that they wish to dive deeper into and learn. It can be about anything at all, as long as it‚Äôs technological, and can be applied to our product(s), even if not in the foreseeable future. Then, the engineer will give a lecture, sharing their research and new knowledge with the team. After every session, we will also publish a blog post, summarising the lecture for our community or new hires to use if they wish.</p>
<p><strong>Technicalities</strong>. We plan to divide the session into two parts ‚Äî the first will be technical, an in-depth overview of the relevant subject (will be covered on our blog posts). The second part will include holding internal discussions on the possible utilisation, adoption and impacts of the topic on our product(s). Are we already relying on some of this knowledge? Can it help us tackle a current or future issue? Perhaps we need to consider implementing it now?</p>
<p>During the two weeks of the engineer‚Äôs turn, (s)he gets as much time as needed to learn the subject and prepare the lecture. This will be prioritised over other tasks, and we assume it will take between one and two days. This is a huge commitment ‚Äî with all the tasks that we have as a startup, every day is precious. Still, we decided that the impact we are hoping for is so valuable that it‚Äôs worth the price, and that we are willing to make the experiment.</p>
<h3><strong>Piloting: Managing Expectations</strong></h3>
<p><strong>Risks</strong>. Yet, as always, it‚Äôs easier said than done. Indeed this can go wrong in different ways ‚Äî time management vs efficiency, getting to a high level of interesting presentations and useful technological insight, or getting every one‚Äôs voice heard on the team in a manner that compliments them. It‚Äôs a learning on the go activity. So we‚Äôre up for a team challenge.</p>
<p><strong>Upsides</strong>. For the duration of our team pilot, every other week, the entire dev team will get to learn something new while taking turns deepening knowledge, improving writing and presentation skills and becoming experts within the team on their Swimminar topics. This team exercise will provide each engineer individually and the team as whole, positive experiences of success. We hope.</p>
<p>I will be the first to give a Swimminar ‚Äî specifically, on <strong>git internals</strong>. How it goes from there, only time will tell. We promise to report back on how this experiment is working for us. Stay tuned.</p>
<p><em>Swimm is a tool helping engineers contribute to any codebase faster and better with automatically generated hints and codebase insight.</em></p>
<p><em>Omer Rosenbaum, Swimm‚Äôs Chief Technology Officer. Cyber training expert and Founder of Checkpoint Security Academy. Author of <a href="https://data.cyber.org.il/networks/networks.pdf">Computer Networks (in Hebrew)</a>. Visit My <a href="https://www.youtube.com/watch?v=79jlgESHzKQ&amp;list=PL9lx0DXCC4BMS7dB7vsrKI5wzFyVIk2Kg">YouTube Channel</a>.</em></p>
</div></div> </section></div>]]>
            </description>
            <link>https://swimm.io/blog/2020-07-09-professionalism-by-forming-a-team-habit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057078</guid>
            <pubDate>Wed, 11 Nov 2020 10:04:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bdshemu: Bitdefender shellcode emulator]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 23 (<a href="https://news.ycombinator.com/item?id=25057062">thread link</a>) | @mdontu
<br/>
November 11, 2020 | https://hvmi.github.io/blog/2020/11/11/bdshemu.html | <a href="https://web.archive.org/web/*/https://hvmi.github.io/blog/2020/11/11/bdshemu.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <h2 id="introduction">Introduction</h2>

<p>Detecting exploits is one of the major strengths of Hypervisor Memory Introspection (HVMI). The ability to monitor guest physical memory pages against different kinds of accesses, such as write or execute, allows HVMI to impose restrictions on critical memory regions: for example, stack or heap pages can be marked as being non-executable at the EPT level, so when an exploit manages to gain arbitrary code execution, the introspection logic would step in and block the execution of the shellcode.</p>

<p>In theory, intercepting execution attempts from memory regions such as the stack or the heap should be enough to prevent most of the exploits. Real life is often more complicated, and there are many cases where legit software uses techniques that may resemble on attack - Just In Time compilation (JIT) in browsers is one good example. In addition, an attacker may store its payload in other memory regions, outside the stack or the heap, so a method of discerning good code from bad code is useful.</p>

<p>We will talk in this blog post about the Bitdefender Shellcode Emulator, or <a href="https://github.com/bitdefender/bddisasm">bdshemu</a> for short. bdshemu is a library capable of emulating basic x86  instructions (in all modes - 16, 32 and 64 bit), while observing shellcode-like behavior. Legitimate code, such as JIT code, will look different compared to a traditional shellcode, so this is what bdshemu is trying to determine: whether the emulated code behaves like a shellcode or not.</p>

<h2 id="bdshemu-overview">bdshemu Overview</h2>

<p>bdshemu is a library written in C, and is part of the bddisasm project (and of course, it makes use of bddisasm for instruction decoding). The bdshemu library is built to emulate x86 code only, so it has no support for API calls. In fact, the emulation environment is highly restricted and stripped down, and there are only two memory regions available:</p>

<ul>
  <li>The page(s) containing the emulated code;</li>
  <li>The stack;</li>
</ul>

<p>Both of these memory regions are virtualized, meaning that they are in fact copies of the actual memory being emulated, so modifications made to them don‚Äôt affect the actual system state. Any access made by the emulated code outside of these two areas (which we will call the shellcode and the stack, respectively) will trigger immediate emulation termination. For example, an API call will automatically cause a branch outside the shellcode region, thus terminating emulation. However, in bdshemu, all we care about is instruction-level behavior of the code, which is enough to tell us whether the code is malicious or not.</p>

<p>While bdshemu provides the main infrastructure for detecting shellcodes inside a guest operating-system, it is worth noting that this is not the only way HVMI determines that execution of a certain page is malicious - two other important indicators are used:</p>

<ul>
  <li>The executed page is located on the stack - this is common with stack-based vulnerabilities;</li>
  <li>The stack is pivoted - when a page is first executed and the <code>RSP</code> register points outside the normal stack allocated for the thread;</li>
</ul>

<p>These two indicators are enough on their own to trigger an exploit detection. If these are not triggered, bdshemu is used to take a good look at the executed code, and decide if it should be blocked or not.</p>

<h2 id="bdshemu-architecture">bdshemu Architecture</h2>

<p>bdshemu is created as a standalone C library, and it only depends on bddisasm. Working with bdshemu is fairly simple, as just like bddisasm, it is a single-API library:</p>
<div><div><pre><code><span>SHEMU_STATUS</span>
<span>ShemuEmulate</span><span>(</span>
    <span>SHEMU_CONTEXT</span> <span>*</span><span>Context</span>
    <span>);</span>
</code></pre></div></div>

<p>The emulator expects a single <code>SHEMU_CONTEXT</code> argument, containing all the needed information in order to emulate the suspicious code. This context is split in two sections - input parameters and output parameters. The input parameters must be supplied by the caller, and they contain information such as the code to be emulated, or initial register values. The output parameters contain information such as what shellcode indicators bdshemu detected. All these fields are well documented in the source-code.</p>

<p>Initially, the context is filled in with the following main information (please note that emulation outcome may change depending on the value of the provided registers and stack):</p>

<ul>
  <li>Input registers, such as segments, general purpose registers, MMX and SSE registers; they can be left 0, if they are not known, or if they are irrelevant;</li>
  <li>Input code, which is the actual code to be emulated;</li>
  <li>Input stack, which can contain actual stack contents, or can be left 0;</li>
  <li>Environment info, such as mode (32 or 64 bit), or ring (0, 1, 2 or 3);</li>
  <li>Control parameters, such as minimum stack-string length, minimum NOP sled length or the maximum number of instructions that should be emulated;</li>
</ul>

<p>The main output parameter is the <code>Flags</code> field, which contains a list of shellcode indicators detected during the emulation. Generally, a non-zero value of this field strongly suggests that the emulate code is, in fact, a shellcode.</p>

<p>bdshemu is built as a plain, quick and simple x86 instruction emulator: since it only works with the shellcode itself and a small virtual stack, it doesn‚Äôt have to emulate any architectural specifics - interrupts or exceptions, descriptor tables, page-tables, etc. In addition, since we only deal with the shellcode and stack memory, bdshemu does not do memory access checks, since it doesn‚Äôt even allow accesses to other addresses. The only state apart from the registers that can be accessed is the shellcode itself and the stack, and both are copies of the actual memory contents - the system state is never modified during the emulation, only the provided <code>SHEMU_CONTEXT</code> is. This makes bdshemu extremely fast, simple, and lets us focus on its main purpose: detecting shellcodes.</p>

<p>As far as instruction support goes, bdshemu supports all the basic x86 instructions, such as branches, arithmetic, logic, shift, bit manipulation, multiplication/divison, stack access and data transfer instructions. In addition, it also has support for other instructions, such as some basic MMX or AVX instructions - <code>PUNPCKLBW</code> or <code>VPBROADCAST</code> are two good examples.</p>

<h2 id="bdshemu-detection-techniques">bdshemu Detection Techniques</h2>

<p>In order to determine whether an emulated piece of code behaves like a shellcode, there are several indicators bdshemu uses.</p>

<h3 id="nop-sled">NOP Sled</h3>

<p>This is the classic presentation of shellcodes; since the exact entry point of the shellcode when gaining code execution may be unknown, attackers usually prepend a long sequence of <code>NOP</code> instructions, encoding <code>0x90</code>. The parameters for the NOP-sled length can be controlled when calling the emulator, via the <code>NopThreshold</code> context field. The default value is <code>SHEMU_DEFAULT_NOP_THRESHOLD</code>, which is <code>75</code>, meaning that minimum 75% of all the emulated instruction must be <code>NOP</code>.</p>

<h3 id="rip-load">RIP Load</h3>

<p>Shellcodes are designed to work correctly no matter what address they‚Äôre loaded at. This means that the shellcode has to determine, dynamically, during runtime, the address it was loaded at, so absolute addressing can be replaced with some form of relative addressing. This is typically achieved by retrieving the value of the instruction pointer using well-known techniques:</p>

<ul>
  <li><code>CALL $+5/POP ebp</code> - executing these two instructions will result in the value of the instruction pointer being stored in the <code>ebp</code> register; data can then be accessed inside the shellcode using offsets relative to the <code>ebp</code> value;</li>
  <li><code>FNOP/FNSTENV [esp-0xc]/POP edi</code> - the first instruction is any FPU instruction (not necessarily <code>FNOP</code>), and the second instruction, <code>FNSTENV</code> saves the FPU environment on the stack; the third instruction will retrieve the <code>FPU Instruction Pointer</code> from <code>esp-0xc</code>, which is part of the FPU environment, and contains the address of the last FPU executed - in our case, <code>FNOP</code>; from there on, addressing relative to the <code>edi</code> can be used to access shellcode data;</li>
</ul>

<p>Internally, bdshemu keeps track of all the instances of the instruction pointer being saved on the stack. Later loading that instruction pointer from the stack in any way will result in triggering this detection. Due to the way bdshemu keeps track of the saved instruction pointers, it doesn‚Äôt matter when, where or how the shellcode attempts to load the RIP in a register and use it, bdshemu will always trigger a detection.</p>

<p>In 64 bit, RIP-relative addressing can be used directly, since the instruction encoding allows it. However, surprisingly, a large number of shellcodes still use a classic method of retrieving the instruction pointer (generally the <code>CALL/POP</code> technique), which is somehow weird, but it probably indicated that 32 bit shellcodes were ported to 64 bit with minimal modifications.</p>

<h3 id="write-self">Write Self</h3>

<p>Most often, shellcodes come in encoded or encrypted forms, in order to avoid certain bad characters (for example, <code>0x00</code> in a shellcode that should resemble a string may break the exploit) or to avoid detection by security technologies (for example, AV scanners). This means that during runtime, the shellcode must decode itself (usually in-place), by modifying its own contents, and then executing the plain-text code. Typical methods of decoding involve <code>XOR</code> or <code>ADD</code> based decryption algorithms.</p>

<p>Certainly, bdshemu follows this kind of behavior, and keeps track internally of each modified byte inside the shellcode. Whenever the suspected shellcode writes any portion of itself, and then it executes it, the self-write detection will be triggered.</p>

<h3 id="tib-access">TIB Access</h3>

<p>Once a shellcode has gained code execution, it needs to locate several functions inside various modules, in order to carry its actual payload (for example, downloading a file, or creating a process). On Windows, the most common way of doing this is by parsing the user-mode loader structures, in order to locate the addresses where the required modules were loaded, and then locate the needed functions inside these modules. The sequence of structures the shellcode will access is:</p>

<ol>
  <li>The Thread Environment Block (<code>TEB</code>), which is located at <code>fs:[0]</code> (32 bit thread) or <code>gs:[0]</code> (64 bit thread);</li>
  <li>The Process Environment Block (<code>PEB</code>), which is located at <code>TEB+0x30</code> (32 bit) or <code>TEB+0x60</code> (64 bit)</li></ol></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hvmi.github.io/blog/2020/11/11/bdshemu.html">https://hvmi.github.io/blog/2020/11/11/bdshemu.html</a></em></p>]]>
            </description>
            <link>https://hvmi.github.io/blog/2020/11/11/bdshemu.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057062</guid>
            <pubDate>Wed, 11 Nov 2020 10:01:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Test your event-driven architecture with Microcks and AsyncAPI]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057022">thread link</a>) | @derberg
<br/>
November 11, 2020 | https://www.asyncapi.com/blog/microcks-asyncapi-part1 | <a href="https://web.archive.org/web/*/https://www.asyncapi.com/blog/microcks-asyncapi-part1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><img src="https://www.asyncapi.com/img/posts/microcks-asyncapi-part1/microcks-1.0.0-loves-asyncapi.webp" alt="Post cover image"><p>August 11th 2020 was the official announcement of <a href="https://microcks.io/blog/microcks-1.0.0-release/">Microcks 1.0.0</a> release and our first Microcks General Availability (GA) version to fully manage event-driven API through the support of <a href="https://www.asyncapi.com/">AsyncAPI</a> specification. <strong>This first post explains why we decided to start this project and provides more insights.</strong></p><p>For those who don't know <a href="https://microcks.io/">Microcks</a> yet: it is the ultimate Open source Kubernetes Native tool for Mocking and Testing all your APIs. With Microcks, you can turn your API contract, collection or SOAP UI projects into live mocks in a few seconds. For further information, please read <a href="https://microcks.io/blog/why-microcks/">"Why Microcks ?"</a>.</p><p>We are following the <a href="https://www.asyncapi.com/">AsyncAPI</a> specification initiative since day one and I clearly remember how the <a href="https://blog.hitchhq.com/introducing-the-asyncapi-specification-7feb57b460ae">first announcement back in 2017</a> resonated within our team ! We shared the same principles: Open source and community driven... and last but not least, 100% aligned with our vision that open specifications standards like <a href="https://www.openapis.org/">OpenAPI</a> is the ultimate way to move forward and perpetuate our mantra: unlock developers potential in an unpredictable and strongly innovative environment!</p><p>Since then, we have been in touch with our mutual communities and strategic users to see if we all embrace the idea of adding AsyncAPI testing and mocking support within Microcks.
Microcks community was very enthusiastic by the idea and problem this integration can solve. We have helped some users on their AsyncAPI use cases to grab valuable feedback on how to manage Microcks event-driven API integration. We learned a lot from different vertical industries, including tricky IoT &amp; Edge computing or fintech implementations.</p><p>Our communities clearly validate that it makes sense to have the same tool managing all their API whatever the type, open contract definition or design tool used. This is why, today Microcks supports open standards for contract definitions and mainstream open collaborative tools:</p><p><img src="https://www.asyncapi.com/img/posts/microcks-asyncapi-part1/microcks-supported-standards.webp" alt="microcks-supported-standards"></p><p>It took us a year to make, which explains why Microcks 1.0.0 release is already GA and the first tool on <a href="https://www.asyncapi.com/docs/tooling/#mocking">this topic</a><undefined> <span role="img" aria-label="winking face">üòâ</span> </undefined></p><p><img src="https://www.asyncapi.com/img/posts/microcks-asyncapi-part1/asyncapi-tool-tweet.webp" alt="asyncapi-tool-tweet"></p><p>This is a major step forward as we are convinced that the transition to cloud-native applications will strongly embrace event-based and reactive architecture. Thus the need to speed-up and govern event-based API like any other services mocking using Microcks will be crucial and a key success factor for any modern and agile software developments.</p><p>Microcks 1.0.0 provides a solid platform for simulating event-based API using message broker technologies like <a href="https://kafka.apache.org/">Apache Kafka</a> even before the publishing component has been developed. And once developed, it is then capable to validate that all the publisher sent events will be compliant with the defined specification, automatically from a CI/CD pipeline.</p><p>To demonstrate our commitment/vision and to <a href="https://www.asyncapi.com/blog/status-update-37-20/#proposal-for-more-formal-examples">improve AsyncAPI specifications</a> on our favorite topic: testing &amp; mocking, we have launched an upstream feature request in order to provide a formal type for message examples.</p><p><img src="https://www.asyncapi.com/img/posts/microcks-asyncapi-part1/call-to-action.webp" alt="call-to-action"></p><p>Please have a look at <a href="https://github.com/asyncapi/asyncapi/issues/329">this proposal #329</a> and share your opinion. At the moment, it is a part of <a href="https://github.com/asyncapi/asyncapi/milestone/17">AsyncAPI 2.1 milestone</a>.</p><p> <strong> In the next article, we will focus on Microcks + AsyncAPI use cases. Stay tuned.</strong></p><blockquote><p>And if you can't wait for text explanataions, do not hesitate having a look at the <a href="https://www.youtube.com/watch?v=pmRA4M-TWuE">AsyncAPI SIG Meeting #34 recording</a><undefined> for full illustrations of the capabilities. <span role="img" aria-label="winking face">üòâ</span></undefined></p></blockquote></article></div>]]>
            </description>
            <link>https://www.asyncapi.com/blog/microcks-asyncapi-part1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057022</guid>
            <pubDate>Wed, 11 Nov 2020 09:53:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Keyboardio Atreus: Yeah or Meh?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25056988">thread link</a>) | @liveweird
<br/>
November 11, 2020 | https://no-kill-switch.ghost.io/keyboardio-atreus-yeah-or-meh-review/ | <a href="https://web.archive.org/web/*/https://no-kill-switch.ghost.io/keyboardio-atreus-yeah-or-meh-review/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-post-id="5faba45f5480d10039a1a829">
	

	<section>
		<p>I've bought another mechanical keyboard (technically - I've backed <a href="https://www.kickstarter.com/projects/keyboardio/atreus">the Kickstarter campaign</a>). Feel free to call me an addict - I don't mind. It's my 4th and all three that I already have work well until now, so I have no valid reason to complain about them. Why waste money then (as they were not cheap - we're talking about an expenditure of 130+ USD per keyboard)?</p><p>The truth is, I use more than one computer (on a daily basis). Desktop PC powered by Windows 10, my private development machine (macOS), and the one provided by the company I currently cooperate with (Ubuntu 20). That means constant switching between very different keyboards and layouts. MacBook Pro's keyboard is pure rubbish (even the refined scissor 2020 model), Lenovo Thinkpad's one is a bit better but still very far from typing experience achievable only for mechanical keyboards, my desktop keyboard is fine but freakin' huge.</p><p>That's why I've decided that what I really need is a reliable mechanical keyboard <strong>I could carry with me easily</strong> and plug anywhere I want.</p><p>Sounds easy, but there are objective obstacles. Mechanical keyboards are generally large and heavy. Both Das Keyboards I own are 100% out of the question here. I have an 88 WASD keyboard as well, but even w/o a numerical keypad, it's too big to carry in the backpack.</p><p>Atreus to the rescue.</p><p>The brand "Atreus" is not new. If you're into mechanical keyboards, you've probably heard about <a href="https://atreus.technomancy.us/">Classic Atreus</a> - as it's available since 2014. The concept was very simple - to create a mechanical keyboard that is fully optimized for natural palms position, so you have all the keys within reach w/o making any move. That also means minimizing the number of keycaps by doing some crazy optimizations (more about that later).</p><p>The keyboard I've ordered is a product of cooperation of <strong>Atreus</strong> and <strong>Keyboardio</strong> - a refreshed, minimalistic version of Classic Atreus with few slight improvements aimed to make it even more compact and apply the lessons from previous models (e.g., adjust the keys in the very center area). You can read more about it (incl. specs and design decisions) <a href="https://shop.keyboard.io/products/keyboardio-atreus">here</a>.</p><figure><img src="https://no-kill-switch.ghost.io/content/images/2020/11/atreus_top.jpg" alt="" srcset="https://no-kill-switch.ghost.io/content/images/size/w600/2020/11/atreus_top.jpg 600w, https://no-kill-switch.ghost.io/content/images/2020/11/atreus_top.jpg 900w" sizes="(min-width: 720px) 720px"></figure><p>I've ordered a blank model (no symbols on the top of keycaps) with <strong>Kailh BOX White switches</strong> and the dedicated case. It's the first model with Kailh switches I've ever tried. The white ones are clicky and have very early tactile feedback. I'm not going to delay that message - the switches turned out to be <u>AWESOME</u>. The typing experience is extremely satisfying (IMHO better than Cherry MX Clear or Gamma Zulu ones). It does require some (reasonable) force, but in exchange, you get the subliminal certainty (the one that doesn't involve conscious thinking) of whether you pressed the button effectively (once) or not.</p><p>OK, good switches are important, but what about the layout? If you've used previous models of Atreus before, you won't be surprised - the changes are subtle but not revolutionary. If you had no prior experience with Atreus, it may be a real shocker.</p><p>First of all, the keyboard has only <strong>44 keycaps</strong> (yay). The space bar is of the size of any other keycap. There are three modes - black, blue, and red (officially named: default, fun, and upper). Default is ... well, default. Fun is active when you <u>hold</u> the 'Fun' button (3rd from the left in the bottom row of the right part of the keyboard) and upper is <u>switched on</u> by (pressing, you don't need to hold them) <strong>Fun</strong> &amp; <strong>Esc</strong> combo.</p><figure><img src="https://no-kill-switch.ghost.io/content/images/2020/11/atreus.png" alt="" srcset="https://no-kill-switch.ghost.io/content/images/size/w600/2020/11/atreus.png 600w, https://no-kill-switch.ghost.io/content/images/2020/11/atreus.png 680w"></figure><p>Some "standard" keys are entirely missing (e.g., <strong>Caps Lock</strong>), some have very un-intuitive positions (<strong>Escape</strong>, <strong>Tab</strong>, <strong>Backspace</strong>). You can read about the layout on the official page (linked above), so I'm not going to describe all the nuances - I'd like to focus on the impressions instead: how does it work? Is it easy to get used to? Convenient? How does it work for typical development keystrokes/routines?</p><p>It ... depends.</p><p>It didn't take me much time to get used to typing texts (articles, blog posts, e-mails) - the layout is a bit skewed, but still: it's QWERTY. The most mistakes I was making were in the 3rd row (<strong>'b'</strong>, <strong>'c'</strong> and <strong>'m'</strong>). However, getting accustomed to control/function keys is an entirely different kind of story:</p><ul><li><strong>Backspace</strong>/<strong>Space</strong> tandem is very different to what you know but once you try it, it gets very intuitive</li><li><strong>Ctrl</strong> and <strong>Alt</strong> are well within reach, but they force you to change your mechanical habits - that will take time</li><li><strong>Tab</strong>'s positioning is the most surprising - it's probably the least reachable keycap on the board</li><li>Having <strong>Delete</strong> in the red (upper) mode means that you're pretty much restricted to using <strong>Backspace</strong></li><li>All kinds of parenthesis (in the blue mode) require memorization from scratch</li><li>TBH I don't use red mode at all - it's just too much of a hassle (that means no <strong>PageUp</strong>, <strong>PageDown</strong>, <strong>F1 </strong>... <strong>F12 </strong>keys - but TBH I've used them very rarely anyway)</li></ul><hr><p><em>A side-note: I don't use Vim, I've also recently gave up on Spacemacs. Last months for codecrafting I've used mainly SublimeText + TabNine (80%) and Visual Studio Code (20%).</em></p><p>After two weeks of using Atreus, it feels like I'm still <u>terribly slow</u> - quite fluent, can manage without a cheatsheet, but still - just painfully slooow. The new automations (you don't need to think about) are not (yet) there, and the old ones got rusty already (when I try to use Das Keyboard occasionally). Ahh, yeah - I've mentioned the printed cheat sheet - it comes in the box with the keyboard, it's laminated, and it's a hell of help - especially in the first few days. A decent idea - kudos for that.</p><p>To be honest, I think that those few weeks are still too little to make a proper judgment, so let's consider it an early review and revisit in few months time.</p><p>IMHO, Atreus delivers what it promises. </p><p>It's compact and lightweight indeed. The quality (of manufacturing) is flawless - sharp, raw, minimalistic, yet beautiful.</p><p>Overall, it's my 2nd favorite of all mech keyboards I've ever used (runner up only to the <a href="https://www.wasdkeyboards.com/wasd-v3-88-key-iso-custom-mechanical-keyboard.html">Cherry MX Clear 88-key WASD</a>), and that says a lot. Yes, this position has been earned mainly by the outstanding switches and the unquestionable mobility, but it's not that I classify the layout as a con. It does require time to adjust your habits, but it's hard to name even a single, irrevocably bad design decision (in terms of positioning or spacing) - with <strong>Tab</strong> positioning being the most controversial one.</p><p>Btw. if you don't like any particular key position, there's a dedicated piece of software (Chrysalis: <a href="https://github.com/keyboardio/Chrysalis">https://github.com/keyboardio/Chrysalis</a>) you can use to conveniently remap it (in the end: I didn't remap any single key).</p><p>It should be stated very clearly - IMHO, this keyboard is <strong><u>much better suited for typists</u></strong> than e.g., developers (or gamers), but even for a typist, it will take several weeks to get used to it and regain a proper pace of typing. What does it mean 'proper pace'? Is it possible to get as effective as with a standard IBM Model M layout?</p><p>Opinions vary.</p><p>Personally, I don't think so, but please keep in mind that this is not a 105-cap but 44-cap keyboard - some efficiency is intended to be sacrificed for the compactness. Consider carefully the scenarios you'd like to use it for, before, not after buying.</p>
	</section>

	
</article></div>]]>
            </description>
            <link>https://no-kill-switch.ghost.io/keyboardio-atreus-yeah-or-meh-review/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25056988</guid>
            <pubDate>Wed, 11 Nov 2020 09:45:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benchmark a Decentralized Search System on 79 Past Releases]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25056863">thread link</a>) | @pepperwool
<br/>
November 11, 2020 | https://hanxiao.io/2020/11/10/Optimizing-the-Overhead-of-a-Decentralized-Search-System/ | <a href="https://web.archive.org/web/*/https://hanxiao.io/2020/11/10/Optimizing-the-Overhead-of-a-Decentralized-Search-System/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://get.jina.ai/" target="_blank" rel="noopener">Jina</a> is designed as a decentralized system from day one. Components are modularized as microservices, which we call <a href="https://github.com/jina-ai/jina/tree/master/docs/chapters/101#peas" target="_blank" rel="noopener">Pea/Pod</a> in Jina idioms. The data passing is done via <a href="https://zeromq.org/" target="_blank" rel="noopener">ZeroMQ</a> and <a href="https://grpc.io/" target="_blank" rel="noopener">gRPC</a>. Comparing to the traditional deep learning frameworks that follow a monolith architecture, latency and overhead are something the community and we care about a lot.<a id="more"></a></p><p>From the first release <code>v0.1</code> in May 2020 to <code>0.7.7</code> today, we have released 79 versions, including 2800+ new commits with 35K lines changes from 50+ contributors. How is the indexing and querying speed now comparing to May? Most importantly, how can we even benchmark fairly over different releases?</p><video width="90%" controls="" muted="" loop="" poster="https://hanxiao.io/2020/11/10/Optimizing-the-Overhead-of-a-Decentralized-Search-System/2fba5081.png"><br><source src="https://hanxiao.io/2020/11/10/Optimizing-the-Overhead-of-a-Decentralized-Search-System/index-speed.mp4" type="video/mp4"><br>Your browser does not support the HTML5 video tag. :(<br></video><p>This post will explain our containerized benchmark environment and highlight those changes made in the last few months that significantly improve/degrade the performance.</p><div><p><strong>Jina</strong> is an easier way for enterprises and developers to build cross- &amp; multi-modal neural search systems on the cloud. You can use Jina to bootstrap a text/image/video/audio search system in minutes. Give it a try:</p><p><a href="https://get.jina.ai/" target="_blank" rel="noopener"><img src="https://img.shields.io/github/stars/jina-ai/jina?label=Star%20Jina%20on%20Github&amp;style=for-the-badge&amp;logo=github&amp;color=3aa373" alt="GitHub Repo stars"></a></p></div><h4><span id="table-of-content">Table of Content</span></h4><ul><li><a href="#containerized-benchmark">Containerized Benchmark</a><ul><li><a href="#benchmark-task">Benchmark Task</a></li><li><a href="#reproducible-experiment-via-containerization">Reproducible Experiment via Containerization</a></li></ul></li><li><a href="#quick-analysis-on-the-speed">Quick Analysis on the Speed</a><ul><li><a href="#index-speed">Index Speed</a></li><li><a href="#query-speed">Query Speed</a></li></ul></li><li><a href="#summary">Summary</a></li></ul><h2><span id="containerized-benchmark">Containerized Benchmark</span></h2><h4><span id="benchmark-task">Benchmark Task</span></h4><p>If you are a Jina user, then you must know <code>jina hello-world</code>: an one-liner that showcases the entire index and query workflows on Fashion-MNIST dataset. It indexes 60,000 images via an index flow. The vectorized data is stored into multiple shards. It then randomly samples test set as queries, ask Jina to retrieve relevant results. Below is Jina√¢‚Ç¨‚Ñ¢s retrievals, where the left-most column is query image.</p><p><img src="https://hanxiao.io/2020/10/28/Mindspore-powered-Neural-Search-in-Jina/hello-world.gif"></p><p>This one-liner demo has been shipped in every Jina releases since <code>v0.1</code>, with a consistent high-level task across versions regardless the changes of the low-level API. This is perfect for serving as our benchmark task. The code snippet below shows the sketch of the benchmark function:</p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br></pre></td><td><pre><span><span><span>def</span> <span>benchmark</span><span>()</span>:</span></span><br><span>    <span>try</span>:</span><br><span>        <span>from</span> jina <span>import</span> __version__</span><br><span>        <span>from</span> jina.flow <span>import</span> Flow</span><br><span></span><br><span>        </span><br><span></span><br><span>        </span><br><span>        f = Flow.load_config(resource_filename(<span>'jina'</span>, <span>'/'</span>.join((<span>'resources'</span>, <span>'helloworld.flow.index.yml'</span>))))</span><br><span>        st = time.perf_counter()</span><br><span>        <span>with</span> f:</span><br><span>            f.index(input_numpy(load_mnist(<span>'original/index'</span>)), batch_size=<span>1024</span>)</span><br><span>        index_time = time.perf_counter() - st</span><br><span></span><br><span>        </span><br><span>        f = Flow.load_config(resource_filename(<span>'jina'</span>, <span>'/'</span>.join((<span>'resources'</span>, <span>'helloworld.flow.query.yml'</span>))))</span><br><span>        st = time.perf_counter()</span><br><span>        <span>with</span> f:</span><br><span>            f.search(input_numpy(load_mnist(<span>'original/query'</span>), size=query_size), batch_size=<span>1024</span>, top_k=<span>50</span>)</span><br><span>        query_time = time.perf_counter() - st</span><br><span></span><br><span>    <span>except</span> Exception:</span><br><span>        </span><br><span>        </span><br><span>        </span><br><span>    <span>return</span> {</span><br><span>        <span>'version'</span>: __version__,</span><br><span>        <span>'index_time'</span>: index_time,</span><br><span>        <span>'query_time'</span>: query_time,</span><br><span>        <span>'index_qps'</span>: index_size / index_time,</span><br><span>        <span>'query_qps'</span>: query_size / query_time,</span><br><span>    }</span><br></pre></td></tr></tbody></table></figure><p>Although Jina today provides many handy interfaces such as <code>Flow.index_ndarray()</code> and <code>TimeContext</code>, allowing you to write the same code more concisely; they are not necessarily available in the early versions. To maximize the compatibility, I use a very <strong>primitive style</strong> of Jina programming. I even put <code>from jina import ...</code> inside the try-except block, in case we don√¢‚Ç¨‚Ñ¢t have those interfaces (or in a different module structure) in the early version. Readers should not take it as the best practice.</p><h4><span id="reproducible-experiment-via-containerization">Reproducible Experiment via Containerization</span></h4><p>So we want to run <code>benchmark()</code> by looping over all releases. Of course no one want to <code>pip</code> install one by one and mess up the local environment. We want to conduct each experiment in a clean and immutable environment, and make sure the whole set is reproducible.</p><p>I use the Docker image tagged with <code>jinaai/jina:x.y.z</code> published on every patch release. It is a self-contained image based on <code>python:3.7.6-slim</code> with all dependencies installed. My benchmark function (<code>app.py</code>) has to be running inside these containers to get an accurate result. Here is how the <code>Dockerfile</code> of a benchmark container looks like:<br></p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br></pre></td><td><pre><span><span>ARG</span> JINA_VER</span><br><span></span><br><span><span>FROM</span> jinaai/jina:$JINA_VER</span><br><span></span><br><span><span>WORKDIR</span><span> workspace/</span></span><br><span></span><br><span><span>ADD</span><span> app.py ./  </span></span><br><span></span><br><span><span>ENTRYPOINT</span><span> [<span>"python"</span>, <span>"app.py"</span>]  </span></span><br></pre></td></tr></tbody></table></figure><p>Note, <code>ARG</code> is put in front of <code>FROM</code> to make version number as a parameter, so that one can choose a specific version for benchmarking. I then wrap <code>docker build</code> and <code>docker run</code> with a simple Bash script, which lists all releases and loops over them:<br></p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></pre></td><td><pre><span>JINA_VERS=$(git ls-remote --tags https://github.com/jina-ai/jina.git <span>"refs/tags/v*^{}"</span> | cut -d<span>'/'</span> -f3 | cut -d<span>'^'</span> -f1 | cut -d<span>'v'</span> -f2 | sort -Vr)</span><br><span></span><br><span><span>for</span> VER <span>in</span> <span>$JINA_VERS</span></span><br><span><span>do</span></span><br><span>  docker build --build-arg JINA_VER=<span>$VER</span> . -t latency-tracking</span><br><span>  docker run -v $(<span>pwd</span>)/output:/workspace/output -v $(<span>pwd</span>)/original:/workspace/original latency-tracking</span><br><span><span>done</span></span><br></pre></td></tr></tbody></table></figure><p>The figure below illustrates this procedure, where the results are aggregated to <code>benchmark.json</code>:</p><p><img src="https://hanxiao.io/2020/11/10/Optimizing-the-Overhead-of-a-Decentralized-Search-System/container-env.png"></p><p>The source code behind the benchmark environment <a href="https://github.com/jina-ai/latency-tracking" target="_blank" rel="noopener">can be found here</a>.</p><h2><span id="quick-analysis-on-the-speed">Quick Analysis on the Speed</span></h2><p>I run the benchmark on a 6-Core i7 machine with 32GB memory, with parallelization and sharding set to 4. In the end, the earliest version I can benchmark is <code>v0.0.8</code>. That was on Apr. 23, 2020, one week before first release.</p><h4><span id="index-speed">Index Speed</span></h4><p><img src="https://hanxiao.io/2020/11/10/Optimizing-the-Overhead-of-a-Decentralized-Search-System/51c3bf2e.png"></p><ul><li>The index speed has increased from 2000 docs/s to around 4000 docs/s over last few months.</li><li>The <code>hello-world</code> indexing time for 60,000 docs is reduced from 32 seconds at <code>0.0.8</code> to 14 seconds at <code>0.7.7</code>.</li><li>Besides continuous refactoring, the major improvements come from:<ul><li>Introducing <code>zmqstream</code> &amp; async IO around <code>0.3</code></li><li><a href="https://hanxiao.io/2020/08/28/What-s-New-in-Jina-v0-5/#hello-world-after-refactoring">Unifying <code>Document</code> structure and <code>Chunk</code> structure into one representation around <code>0.5</code></a></li><li>Removing <code>gzip</code> compression on <code>Document</code> and <a href="https://hanxiao.io/2020/09/21/Numpy-Tricks-and-A-Strong-Baseline-for-Vector-Index/#removing-gzip-compression">using <code>memmap</code> for <code>KVIndexer</code> &amp; <code>NumpyIndexer</code> around <code>0.6</code></a></li><li>Optimizing ZeroMQ binary protocol and <a href="https://github.com/jina-ai/jina/pull/1210" target="_blank" rel="noopener">introducing LazyRequest around 0.7</a></li></ul></li></ul><h4><span id="query-speed">Query Speed</span></h4><p><img src="https://hanxiao.io/2020/11/10/Optimizing-the-Overhead-of-a-Decentralized-Search-System/d3c56f81.png"></p><ul><li>The query speed has increased from 20 docs/s to around 70 docs/s over last few months.</li><li>The major improvement around <code>0.4</code> is due to unifying <code>Document</code> structure and <code>Chunk</code> structure.</li><li>The major setback around <code>0.6</code> is due to the use of <code>memmap</code> for <code>KVIndexer</code> &amp; <code>NumpyIndexer</code>. The search shifts away from <strong>in-memory search</strong> to <strong>on-disk search</strong>.</li><li>The slowly degraded query speed from <code>0.4</code> to <code>0.7</code> could be due to the refactoring on <code>Executor</code> and <code>Driver</code>, from then we have made <code>Executor</code> Protobuf-agnostic and algorithm-focus. Moreover, we have decoupled many huge all-in-one <code>Driver</code> into small pieces and then use them in a chain-style. <a href="https://hanxiao.io/2020/08/28/What-s-New-in-Jina-v0-5/#new-query-language-driver"><code>QueryLangDriver</code> introduced in <code>0.5</code> is a good example</a>. Though this effort is a sensible design decision and clarifies code structures, it may add extra dispatch overheads.</li><li>Need to keep an eye on the query speed in the future releases. More comprehensive analysis on the overhead is required. Avoid unnecessary work at the query time.</li></ul><h2><span id="summary">Summary</span></h2><p>Like traveling with a time machine, it is fun to look back on what we had back in May. Interestingly, the architecture and high-level user experience are consistent enough to benchmark all history versions. Four things made this benchmark possible:</p><ul><li>The <code>hello-world</code> demo defines a high-level task that is fixed across all releases.</li><li>Along with PyPI package on each release, we publish a Docker images with dependencies included, providing an immutable √¢‚Ç¨≈ìplayback√¢‚Ç¨ÔøΩ environment.</li><li><a href="https://hanxiao.io/2020/08/02/Layer-of-Abstraction-when-Building-Tensorflow-for-Search/" title="Jina's multi-abstraction-layer design">Jina's multi-abstraction-layer design</a> separates its high-level API from the intermediate and low-level API, allowing search developers to be agnostic on the lower-level changes.</li><li>Last but not least, <strong>high code quality</strong> and robust DevOps &amp; CICD infra from day one.</li></ul><p>If you√¢‚Ç¨‚Ñ¢d like to share some experiences and thoughts on latency issues, welcome to join <a href="https://hanxiao.io/2020/08/06/Engineering-All-Hands-in-Public/" title="our monthly Engineering All Hands via Zoom or Youtube live stream">our monthly Engineering All Hands via Zoom or Youtube live stream</a>. If you like Jina and want to join us as a full-time AI / Backend / Frontend developer, please submit your CV to <a href="https://career.jina.ai/" target="_blank" rel="noopener">our job portal</a>. Let√¢‚Ç¨‚Ñ¢s build the next neural search ecosystem together!</p></div></div>]]>
            </description>
            <link>https://hanxiao.io/2020/11/10/Optimizing-the-Overhead-of-a-Decentralized-Search-System/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25056863</guid>
            <pubDate>Wed, 11 Nov 2020 09:23:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A curious case of stacks and queues]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25056603">thread link</a>) | @oecumena
<br/>
November 11, 2020 | http://www.cofault.com/2020/11/a-curious-case-of-stacks-and-queues.html | <a href="https://web.archive.org/web/*/http://www.cofault.com/2020/11/a-curious-case-of-stacks-and-queues.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>When studying computing science we all learn how to convert an expression in the "normal" ("<a href="https://en.wikipedia.org/wiki/Infix_notation">infix</a>", "algebraic") notation to "<a href="https://en.wikipedia.org/wiki/Reverse_Polish_notation">reverse Polish</a>" notation. For example, an expression "<code>a*b + c*d</code>" is converted to "<code>a b * c d * +</code>". An expression in reverse Polish notation can be seen as a program for <a href="https://en.wikipedia.org/wiki/Pushdown_automaton">a stack automaton</a>:

</p><div><pre><code>PUSH A
PUSH B
MUL
PUSH C
PUSH D
MUL
ADD</code></pre></div>

<p>Where <code>PUSH</code> pushes its argument on the top of the (implicit) stack, while <code>ADD</code> and <code>MUL</code> pop 2 top elements from the stack, perform the respective operation and push the result back. 
</p><p>For reasons that will be clearer anon, let's re-write this program as
</p><div><pre><code>Container c;
c.put(A);
c.put(B);
c.put(c.get() * c.get())
c.put(C);
c.put(D);
c.put(c.get() * c.get())
c.put(c.get() + c.get())</code></pre></div>

<p>Where <code>Container</code> is the type of stacks, <code>c.put()</code> pushes the element on the top of the stack and <code>c.get()</code> pops and returns the top of the stack. <a href="https://en.wikipedia.org/wiki/LIFO">LIFO</a> discipline of stacks is so widely used (implemented natively on all modern processors, built in programming languages in the form of call-stack) that one never ask whether a different method of evaluating expressions is possible.
</p><p>Here is a problem: find a way to translate infix notation to a program for a queue automaton, that is, in a program like the one above, but where <code>Container</code> is the type of <a href="https://en.wikipedia.org/wiki/FIFO_(computing_and_electronics)">FIFO</a> <a href="https://en.wikipedia.org/wiki/Queue_(abstract_data_type)">queues</a> with <code>c.put()</code> enqueuing an element at the rear of the queue and <code>c.get()</code> dequeuing at the front. This problem was <a href="https://www.cs.utexas.edu/users/EWD/ewd08xx/EWD887.PDF">reportedly</a> solved by <a href="https://en.wikipedia.org/wiki/Jan_L._A._van_de_Snepscheut">Jan L.A. van de Snepscheut</a> sometime during spring 1984.

</p><p>While you are thinking about it, consider the following tree-traversal code (in some abstract imaginary language):
</p><div><pre><code>walk(Treenode root) {
        Container todo;
        todo.put(root);
        while (!todo.is_empty()) {
                next = todo.get();
                visit(next);
                for (child in next.children) {
                        todo.put(child);
                }
        }
}</code></pre></div>
<p>Where <code>node.children</code> is the list of node children suitable for iteration by <code>for</code> loop.
</p><p>Convince yourself that if <code>Container</code> is the type of stacks, tree-walk is depth-first. And if <code>Container</code> is the type of queues, tree-walk is breadth-first. Then, convince yourself that a depth-first walk of the parse tree of an infix expression produces the expression in Polish notation (unreversed) and its breadth-first walk produces the expression in "queue notation" (that is, the desired program for a queue automaton). Isn't it marvelous that traversing a parse tree with a stack container gives you the program for stack-based execution and traversing the same tree with a queue container gives you the program for queue-based execution?
</p><p>I feel that there is something deep behind this. <a href="https://en.wikipedia.org/wiki/Alexander_Stepanov">A. Stepanov</a> had an intuition (which cost him <a href="http://www.stlport.org/resources/StepanovUSA.html">dearly</a>) that <em>algorithms are defined on algebraic structures</em>. Elegant interconnection between queues and stacks on one hand and tree-walks and automaton programs on the other, tells us that the correspondence between algorithms and structures goes in both directions.

</p></div></div>]]>
            </description>
            <link>http://www.cofault.com/2020/11/a-curious-case-of-stacks-and-queues.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25056603</guid>
            <pubDate>Wed, 11 Nov 2020 08:36:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Container Queries are coming to Chromium]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25056551">thread link</a>) | @LorenzA
<br/>
November 11, 2020 | https://www.bram.us/2020/11/05/container-queries-are-coming-to-chromium/?ref=webdesignernews.com | <a href="https://web.archive.org/web/*/https://www.bram.us/2020/11/05/container-queries-are-coming-to-chromium/?ref=webdesignernews.com">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<div id="primary">
<main id="main">
<article id="post-25159">

<div>
<p><img loading="lazy" src="https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon.png" alt="" width="2024" height="880" srcset="https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon.png 2024w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-560x243.png 560w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1120x487.png 1120w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-768x334.png 768w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1536x668.png 1536w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1568x682.png 1568w" sizes="(max-width: 2024px) 100vw, 2024px" data-old-src="https://www.bram.us/wordpress/wp-content/plugins/native-lazyload/assets/images/placeholder.svg" data-src="https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon.png" data-srcset="https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon.png 2024w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-560x243.png 560w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1120x487.png 1120w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-768x334.png 768w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1536x668.png 1536w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1568x682.png 1568w"></p>
<p>Just <a href="https://groups.google.com/a/chromium.org/g/blink-dev/c/u1AKdrXhPGI/m/wrJb-unhAgAJ">announced</a> on the Chromium mailing list is an <a href="https://www.chromium.org/blink/launching-features">‚ÄúIntent to Prototype‚Äù</a> Container Queries, which is quite exciting news üéâ</p>
<details>
<summary>ü§î Container Queries?</summary>
<p>Container Queries allow authors to style elements according to the size of a container. This is similar to a @media query, except that it evaluates against a container instead of the viewport.</p>
</details>
<p>The experimental implementation will follow <a href="https://gist.github.com/mirisuzanne/748169312f110d6246e092945673b16e">Miriam Suzanne‚Äôs proposal</a>, which looks like this:</p>
<pre><code>main,
aside {
  contain: size; /* (1) Create an implicit "container root" or "containment context" */
}

.media-object {
  display: grid;
  gap: 1em;
}

@container (max-width: 45em) { /* (2) When the nearest `contain: size` ancestor has a max-width of 45em ‚Ä¶ */
  .media-object { /* ‚Ä¶ apply these rules onto .media-object */
    grid-template: 'img content' auto / auto 1fr;
  }
}</code></pre>
<p>Using <code>contain: size</code> <em>(1)</em> will create an implicit ‚Äúcontainer root‚Äù or ‚Äúcontainment context‚Äù on that element. Elements contained inside it can then have container queries applied onto them, by use of a new at-rule <code>@container (<em>&lt;container-media-query&gt;</em>)</code> <em>(2)</em>. The target selector and CSS rules to apply in that case are nested within the <code>@container</code> at-rule, just like we already do with other at-rules.</p>
<p>In the example above extra rules will be applied to <code>.media-object</code> whenever its nearest ancestor with size containment set ‚Äî such as <code>&lt;main&gt;</code> or <code>&lt;aside&gt;</code> ‚Äî has a <code>max-width</code> of <code>45em</code>.</p>
<p>~</p>
<p>A <a href="https://github.com/dbaron/container-queries-implementability#proposal">previous version of this proposal by L. David Baron</a> required a context selector to be set, but that has been dropped here. The <code>@container</code> rule from Miriam‚Äôs version will work in any containment context <em>(read: the nearest parent element that has <code>contain: size</code> set)</em>. The syntax might still change, but that‚Äôs irrelevant to the prototype which is to be implemented:</p>
<blockquote><p>This is not at all finalized, but the underlying problems we need to solve in Blink are (mostly) the same regardless of how the feature is accessed, so we‚Äôll for now use this proposal as the temporary syntax.</p></blockquote>
<p>~</p>
<p><a href="https://groups.google.com/a/chromium.org/g/blink-dev/c/u1AKdrXhPGI/m/wrJb-unhAgAJ">Intent to Prototype: Container Queries ‚Üí</a><br><a href="https://bugs.chromium.org/p/chromium/issues/detail?id=1145970">Chrome Tracking Bug ‚Üí</a></p>
<div>
<p><b>Did this help you out? Like what you see?<br>Thank me with a coffee.</b></p><p>I don't do this for profit but a small one-time donation would always put a smile on my face. Thanks!</p>
<p><a href="https://www.paypal.me/bramus/3EUR">‚òïÔ∏è Buy me a Coffee <em>(‚Ç¨3)</em></a></p>
</div>
</div>

<div>

<p>
Bramus is a Freelance Web Developer from Belgium. From the moment he discovered view-source at the age of 14 <em>(way back in 1997)</em>, he fell in love with the web and has been tinkering with it ever since <i><a href="https://www.bram.us/about">(more ‚Ä¶)</a></i> <a href="https://www.bram.us/author/bramus/" rel="author">
View more posts </a>
</p>
</div>
</article>
<nav role="navigation" aria-label="Posts">
<h2>Post navigation</h2>

</nav>

</main>
</div>
</div></div>]]>
            </description>
            <link>https://www.bram.us/2020/11/05/container-queries-are-coming-to-chromium/?ref=webdesignernews.com</link>
            <guid isPermaLink="false">hacker-news-small-sites-25056551</guid>
            <pubDate>Wed, 11 Nov 2020 08:28:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Being a minority in fancy coding land: a Windows user]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25056380">thread link</a>) | @flo_hu
<br/>
November 10, 2020 | https://blog.esciencecenter.nl/being-a-minority-in-fancy-coding-land-a-windows-user-d853d80a6ef9 | <a href="https://web.archive.org/web/*/https://blog.esciencecenter.nl/being-a-minority-in-fancy-coding-land-a-windows-user-d853d80a6ef9">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2 id="8c04">How I slowly went from my imposter-syndrome hiding to accepting what I am. A Windows user, at least most of the time. (Don‚Äôt worry, this is NOT one of those Linux vs. Windows posts!)</h2><div><div><div><div><a href="https://medium.com/@f.huber?source=post_page-----d853d80a6ef9--------------------------------" rel="noopener"><div><p><img alt="Florian Huber" src="https://miro.medium.com/fit/c/96/96/1*sv95w_DZibIhPBTosB6R2w.jpeg" width="48" height="48"></p></div></a></div></div></div></div><p id="c959">I work at the <a href="http://esciencecenter.nl/" rel="noopener">Netherlands eScience Center</a>, a wonderful organization with very nice colleagues. Hopefully nice enough to stay my colleagues after the following confession: I am a Windows user.</p><p id="a268">What‚Äôs so special about this? Most people use Windows, right? <br>Well, not in my small <em>coding bubble</em>. <br>In the world I work in (use all your clich√© imagination on nerds, hackers, computer scientists ‚Ä¶ but then remove those pictures of people wearing sun glasses indoors and desks full of pizza and caffeine-rich soft-drinks) coding from a Windows environment is often considered something between a no-go and a handicap. Breathing quickly, my fingers start to tremble as I write this, risking my career as a data scientist and machine learning practitioner. Or isn‚Äôt it all that bad?</p></div></div><div><div><h2 id="738b">How did I end up using Windows?</h2><p id="64d2"><em>(I see your shaking heads‚Ä¶ why the hell did he end up there?)</em><br>Let‚Äôs just say I have grown into it. All the way from <a href="https://en.wikipedia.org/wiki/MS-DOS" rel="noopener">MS DOS</a> through many painfully bad Windows versions and then I got so used to it that <strong>my skills to deal with it always felt better than my skills in handling the alternatives</strong>.</p><p id="4c26">In addition, I am not a software developer or computer scientist by training. For a long time I was a physicist, a scientist, an academic. And in the scientific fields where I was working, using Windows was ‚Äî believe it or not ‚Äîthe norm.</p><p id="061d">Sure, I had already installed VirtualBox on my computer to run Ubuntu. I had even done some stuff with Ubuntu, including training some machine learning models (for implementations for which the packages didn‚Äôt support Windows‚Ä¶). I knew the 10 most common shell commands and everything else I would simply look up when needed. No wonder working with Linux still feels like writing a long letter with my left hand (I am right handed): I am terribly slow and in the end it looks horrible.</p><h2 id="4cbb">But ‚Ä¶ why?</h2><p id="fb46">Ah, I see. That all sounds like lame excuses to you.<br>Well, it is not that I didn‚Äôt see all those golden merits of using Linux over Windows. Of course that‚Äôs the better system for many tasks, say setting up a server or handling access rights. And yes, it is much less wasteful in using hardware resources, it is considered less vulnerable, ‚Ä¶ and so on ‚Ä¶ , plus it is freely available without commercial interests. Still, I never wanted to pay the price of not having access to some of the high-end software that you would get on mac-OS or Windows (such as some MS office stuff or Adobe products). By the way: I am not trying to convince anybody that Windows is the best option. I am already happy if we can agree that it is<strong> <em>an</em></strong> option.</p><p id="5163">Time for another uncomfortable revelation: sometimes, being lazy simply pays off. For instance if you need to sort out a huge pile of stuff with some emotional value to you. Just put it in a box and hide it, take it out 10 years later and easily decide to dump nearly all of it. That‚Äôs a bit what I did with Linux. I survived with minimal use of VirtualBx and alike. Until recently, <em>finally!</em>, Linux became part of Windows. And that works pretty well for me. <a href="https://www.howtogeek.com/249966/how-to-install-and-use-the-linux-bash-shell-on-windows-10/" rel="noopener">See how simple it now is to run Linux from Windows 10.</a> And enjoy how easily you now can have the best of both worlds (not for nothing are more and more people arguing <a href="https://towardsdatascience.com/dual-boot-is-dead-windows-and-linux-are-now-one-27555902a128" rel="noopener">that the good old ‚Äúdual boot‚Äù is dead</a> for exactly this reason).</p></div></div><div><div><p id="617d">Enough all-united-hippie-talk. Let me share a few impressions of the actual life of an aspiring data scientist/research software engineer that happens to use Windows:</p><h2 id="5753">Starting a new job.</h2><p id="d098">I did a lot of programming as a researcher, but clearly I had never learned the proper software development basics such as testing, versioning etc. (in many academic fields those terms are often still unheard of!). No wonder I suffered a lot from imposter syndrome in the very beginning.</p><blockquote><p id="63c1"><em>I hope they won‚Äôt find out I can‚Äôt write proper code!</em></p></blockquote><p id="1c35">Naturally, that means that you might not immediately ask your colleagues for help, because that would reveal your amateur level, right?<br>But even worse, imagining you ask that colleague about how to get that Python package working and it turns out you are using Windows?</p><blockquote><p id="3038">Can you help me setting up that environment? ‚Ä¶ By the way ‚Ä¶ I use Windows for that.</p></blockquote><p id="9df6">The looks you get are suggesting that you have just asked how to import a 5GB .csv file into your Excel table (<em>*you don‚Äôt*</em>). So little surprise I did spend a fair amount of time in Forum-Land during my first months‚Ä¶</p><h2 id="e8ad">Being that Windows user in the room</h2><p id="0abd">You sit in that hands-on workshop on some fancy programming techniques, and the instructors asks:</p><blockquote><p id="6f37">Is there anybody using Windows? (chuckles)</p></blockquote><p id="a471">Or, actually worse, nobody asks. Of course the instructions are only given for Linux and mac-OS. Well, at least I can hide my Windows handicap for a little longer then‚Ä¶ but <strong>NO</strong>!, when the instructor walks around to inspect the progress of the participants she/he will of course shout out:</p><blockquote><p id="ec64">Wow ‚Ä¶ you are really using Windows for that!?</p></blockquote><p id="0f4b">Great. Now officially being tagged as <strong>the Windows user</strong> in the room. Better keep quiet and not ask any silly questions then‚Ä¶</p><h2 id="d5b7">Get used to rolled eyes ‚Äîthen secretly roll your eyes, too.</h2><p id="2553">As I grew more confident of what I was doing, the imposter syndrome started to disappear. It still occasionally comes back to say hello (for instance if people speak shell over coffee), but that‚Äôs OK.</p><p id="9f7e">In the end it‚Äôs luckily the results that matters most. I learned that you can write as good or bad code on Windows as on Linux. You can build great software on Windows that is then used by Linux people, and the other way around. Sure, for some things you better go the Linux way. But it turns out that in my projects this is less than 1% of my working time, which makes it OK to be a bit clumsy using it. And secretly (<em>don‚Äôt point at them, that‚Äôs mean!</em>), I can also enjoy those moments when another colloquium presentation doesn‚Äôt run properly because Ubuntu did not work well with the projector, or the microphone, or both.</p><h2 id="7d78">Do better than pointing at each other</h2><p id="7527">Windows is more convenient for running some very common software (e.g. MS office), Linux is more stable‚Ä¶ so go some cliches. But instead of fighting about what‚Äôs better (or hiding what feels inferior) it makes more sense to me to accept what‚Äôs there and simply go along with it. If somebody lives in a very geeky bubble it works fine to safely assume everyone runs their code on a certain operating systems and knows the in and outs of object oriented programming and containerization. But many of the more exciting projects involve people outside this bubble: researchers, users, future contributors, students. And they might as well ‚Äî lo and behold ‚Äî be using Windows (and by the way: containers are still primarily <strong>big steel boxes</strong> to most people).</p><p id="2b2a">So, even though in some IT-bubbles it can occasionally feel as if we are talking about a small unfortunate minority ‚Ä¶ in reality that‚Äôs really not true. Check out <a href="https://www.freecodecamp.org/news/stack-overflow-developer-survey-2020-programming-language-framework-salary-data/" rel="noopener">the 2020 Stack Overflow Developer Survey</a> to see that <strong>most developers actually use Windows</strong>.</p><h2 id="a2c4">What can you do to get more Windows users to adopt your package?</h2><p id="1114">Think of Windows what you want. I don‚Äôt work for Microsoft, and honestly, I don‚Äôt really care. But I assume that many coders out there working on great new software, methods, tools, tutorials, etc. actually want that people become happy users (paid by eternal gratitude). And that is a good enough reason to think about those Windows users as well.</p><ul><li id="10e8">Consider setting up your next continuous integration for your software package, so that it runs on all systems and will be used by more people.<br>For instance with <a href="https://docs.github.com/en/free-pro-team@latest/actions/guides/about-continuous-integration" rel="noopener">continuous integration using GitHub</a> actions it can be as simple as adding a <code>‚Äòwindows-latest‚Äô</code> to your matrix:<br><code>os: [‚Äòubuntu-latest‚Äô, ‚Äòmacos-latest‚Äô, ‚Äòwindows-latest‚Äô]<br></code>(small warning: adding different operating systems to such a continuous integration workflow is comparably easy, the later debugging sometimes is not. One option can be to work with <a href="https://developer.microsoft.com/en-us/windows/downloads/virtual-machines/" rel="noopener">Windows virtual machine</a>).</li><li id="906a">What about providing installation instructions for Windows users as well? Or did you just write a new tutorial? Great! But will it work for your fellow Windows users? You would be surprised how many packages and tutorials come with instructions that clearly won‚Äôt work for a Windows user. <br>Don‚Äôt know how to do that? No Problem! Just ask a Windows user to help you. Believe me, they will be very glad to assist.</li></ul><h2 id="3a14">Final symmetry</h2><p id="9879">Most of my arguments will hold when we just swap the named OS. So, obviously if you are (like me) primarily a Windows user: Think of all those Linux and mac-OS people out there. Either way, it will require learning a bit about the differences. But it will help to avoid a lot of frustration on all ends due to failing notebooks or hard to install packages.</p><h2 id="e34f">Get in touch</h2><p id="38ab">If you have comments or questions please get in touch! You can also find me on twitter: <a href="https://twitter.com/me_datapoint" rel="noopener"><strong>me_datapoint</strong></a></p></div></div></div>]]>
            </description>
            <link>https://blog.esciencecenter.nl/being-a-minority-in-fancy-coding-land-a-windows-user-d853d80a6ef9</link>
            <guid isPermaLink="false">hacker-news-small-sites-25056380</guid>
            <pubDate>Wed, 11 Nov 2020 07:56:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Back to C# basics: Difference between ‚Äú=‚Äù and ‚Äú{ get; } =‚Äù for properties]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25056344">thread link</a>) | @cincura_net
<br/>
November 10, 2020 | https://www.tabsoverspaces.com/id/233844 | <a href="https://web.archive.org/web/*/https://www.tabsoverspaces.com/id/233844">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	<h3>Back to C# basics: Difference between "=&gt;" and "{ get; } =" for properties <a href="https://www.tabsoverspaces.com/id/233844" rel="bookmark nofollow" title="Permalink"><span aria-label="Permalink"></span></a></h3>
	<p>
	<span aria-label="Published"></span> 11 Nov 2020
	<span></span>
	<span aria-label="Time to read"></span> 1 mins
	<span></span>
	<span aria-label="Tags"></span> .NET
</p>
<p>I recently realized, the difference between <code>=&gt;</code> and <code>{ get; } =</code> for properties might not be as known as everybody thinks, based on code I saw multiple times.</p>
<!-- excerpt --> 
<p>Here‚Äôs an example code.</p>
<pre><code>public class C
{
	public Foo A { get; } = new Foo();
	public Foo B =&gt; new Foo();
}
</code></pre>
<p>Is it the same or is it not? The answer is, it‚Äôs not the same. The <code>A</code> property is property with <em>getter</em> only (aka read only or immutable property). When <code>C</code> instance is created a new instance of <code>Foo</code> is assigned to the property and will be returned from now on. The <code>B</code> property defines also only <em>getter</em>, but this time the <em>getter</em> contains the <code>new Foo();</code> as it‚Äôs body, aka returning new instance of <code>Foo</code> every time you access <code>B</code>.</p>
<p>Putting it into barebone C#, it would look like this.</p>
<pre><code>public class C
{
	readonly Foo _a = new Foo();
	
	public Foo A
	{
		get { return _a; }
	}

	public Foo B
	{
		get { return new Foo(); }
	}
}
</code></pre>
<p>Makes sense?</p>

</article><article>
	<p>
		<a href="https://www.tabsoverspaces.com/about"><img src="https://www.tabsoverspaces.com/assets/bio_image.png" alt="Profile Picture"></a>
		Ji≈ô√≠ ƒåinƒçura is an independent developer focusing on data and business layers, language constructs, parallelism and databases. Specifically Entity Framework, asynchronous and parallel programming, cloud and Azure. He's Microsoft Most Valuable Professional and you can read his articles, guides, tips and tricks at www.tabsoverspaces.com.
	</p>
</article></div>]]>
            </description>
            <link>https://www.tabsoverspaces.com/id/233844</link>
            <guid isPermaLink="false">hacker-news-small-sites-25056344</guid>
            <pubDate>Wed, 11 Nov 2020 07:47:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cell Signaling Technologies ‚Äì Detailed 3D model of human cells]]>
            </title>
            <description>
<![CDATA[
Score 161 | Comments 50 (<a href="https://news.ycombinator.com/item?id=25055908">thread link</a>) | @ozten
<br/>
November 10, 2020 | http://www.digizyme.com/cst_landscapes.html | <a href="https://web.archive.org/web/*/http://www.digizyme.com/cst_landscapes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="u6389-bw">
     <div id="u6389"><!-- column -->
      <div id="u6389_align_to_page">
       <!-- m_editable region-id="editable-static-tag-U6264-BP_infinity" template="cst_landscapes.html" data-type="html" data-ice-options="disableImageResize,link,txtStyleTarget" -->
       <p><span id="u6264">Cell Signaling Technologies</span></p>
       <!-- /m_editable -->
       <!-- m_editable region-id="editable-static-tag-U6399-BP_infinity" template="cst_landscapes.html" data-type="html" data-ice-options="disableImageResize,link,txtStyleTarget" -->
       <p>Molecular Landscapes</p>
       <!-- /m_editable -->
       
       
       
      </div>
     </div>
    </div></div>]]>
            </description>
            <link>http://www.digizyme.com/cst_landscapes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055908</guid>
            <pubDate>Wed, 11 Nov 2020 06:02:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dive into BPF: a list of reading material]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25055866">thread link</a>) | @moks
<br/>
November 10, 2020 | https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/ | <a href="https://web.archive.org/web/*/https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<ul id="markdown-toc">
  <li><a href="#what-is-bpf" id="markdown-toc-what-is-bpf">What is BPF?</a></li>
  <li><a href="#dive-into-the-bytecode" id="markdown-toc-dive-into-the-bytecode">Dive into the bytecode</a></li>
  <li><a href="#resources" id="markdown-toc-resources">Resources</a>    <ul>
      <li><a href="#generic-presentations" id="markdown-toc-generic-presentations">Generic presentations</a>        <ul>
          <li><a href="#about-bpf" id="markdown-toc-about-bpf">About BPF</a></li>
          <li><a href="#about-xdp" id="markdown-toc-about-xdp">About XDP</a></li>
          <li><a href="#about-other-components-related-or-based-on-ebpf" id="markdown-toc-about-other-components-related-or-based-on-ebpf">About other components related or based on eBPF</a></li>
        </ul>
      </li>
      <li><a href="#documentation" id="markdown-toc-documentation">Documentation</a>        <ul>
          <li><a href="#about-bpf-1" id="markdown-toc-about-bpf-1">About BPF</a></li>
          <li><a href="#about-tc" id="markdown-toc-about-tc">About tc</a></li>
          <li><a href="#about-xdp-1" id="markdown-toc-about-xdp-1">About XDP</a></li>
          <li><a href="#about-flow-dissectors" id="markdown-toc-about-flow-dissectors">About flow dissectors</a></li>
          <li><a href="#about-p4-and-bpf" id="markdown-toc-about-p4-and-bpf">About P4 and BPF</a></li>
        </ul>
      </li>
      <li><a href="#tutorials" id="markdown-toc-tutorials">Tutorials</a></li>
      <li><a href="#examples" id="markdown-toc-examples">Examples</a>        <ul>
          <li><a href="#from-the-kernel" id="markdown-toc-from-the-kernel">From the kernel</a></li>
          <li><a href="#from-package-iproute2" id="markdown-toc-from-package-iproute2">From package iproute2</a></li>
          <li><a href="#from-bcc-set-of-tools" id="markdown-toc-from-bcc-set-of-tools">From bcc set of tools</a></li>
          <li><a href="#other-examples" id="markdown-toc-other-examples">Other examples</a></li>
          <li><a href="#manual-pages" id="markdown-toc-manual-pages">Manual pages</a></li>
        </ul>
      </li>
      <li><a href="#the-code" id="markdown-toc-the-code">The code</a>        <ul>
          <li><a href="#bpf-code-in-the-kernel" id="markdown-toc-bpf-code-in-the-kernel">BPF code in the kernel</a></li>
          <li><a href="#xdp-hooks-code" id="markdown-toc-xdp-hooks-code">XDP hooks code</a></li>
          <li><a href="#bpf-logic-in-bcc" id="markdown-toc-bpf-logic-in-bcc">BPF logic in bcc</a></li>
          <li><a href="#code-to-manage-bpf-with-tc" id="markdown-toc-code-to-manage-bpf-with-tc">Code to manage BPF with tc</a></li>
          <li><a href="#bpf-utilities" id="markdown-toc-bpf-utilities">BPF utilities</a></li>
          <li><a href="#other-interesting-chunks" id="markdown-toc-other-interesting-chunks">Other interesting chunks</a></li>
          <li><a href="#llvm-backend" id="markdown-toc-llvm-backend">LLVM backend</a></li>
          <li><a href="#running-in-userspace" id="markdown-toc-running-in-userspace">Running in userspace</a></li>
          <li><a href="#commit-logs" id="markdown-toc-commit-logs">Commit logs</a></li>
        </ul>
      </li>
      <li><a href="#troubleshooting" id="markdown-toc-troubleshooting">Troubleshooting</a>        <ul>
          <li><a href="#errors-at-compilation-time" id="markdown-toc-errors-at-compilation-time">Errors at compilation time</a></li>
          <li><a href="#errors-at-load-and-run-time" id="markdown-toc-errors-at-load-and-run-time">Errors at load and run time</a></li>
        </ul>
      </li>
      <li><a href="#and-still-more" id="markdown-toc-and-still-more">And still more!</a></li>
    </ul>
  </li>
</ul>

<p><em>~ <a href="https://github.com/qmonnet/whirl-offload/commits/gh-pages/_posts/2016-09-01-dive-into-bpf.md">Updated</a> 2019-01-10 ~</em></p>



<p>BPF, as in <strong>B</strong>erkeley <strong>P</strong>acket <strong>F</strong>ilter, was initially conceived in 1992
so as to provide a way to filter packets and to avoid useless packet copies
from kernel to userspace. It initially consisted in a simple bytecode that is
injected from userspace into the kernel, where it is checked by a verifier‚Äîto
prevent kernel crashes or security issues‚Äîand attached to a socket, then run on
each received packet. It was ported to Linux a couple of years later, and used
for a small number of applications (tcpdump for example). The simplicity of the
language as well as the existence of an in-kernel Just-In-Time (JIT) compiling
machine for BPF were factors for the excellent performances of this tool.</p>

<p>Then in 2013, Alexei Starovoitov completely reshaped it, started to add new
functionalities and to improve the performances of BPF. This new version is
designated as eBPF (for ‚Äúextended BPF‚Äù), while the former becomes cBPF
(‚Äúclassic‚Äù BPF). New features such as maps and tail calls appeared. The JIT
machines were rewritten. The new language is even closer to native machine
language than cBPF was. And also, new attach points in the kernel have been
created.</p>

<p>Thanks to those new hooks, eBPF programs can be designed for a variety of use
cases, that divide into two fields of applications. One of them is the domain
of kernel tracing and event monitoring. BPF programs can be attached to kprobes
and they compare with other tracing methods, with many advantages (and
sometimes some drawbacks).</p>

<p>The other application domain remains network programming. In addition to socket
filter, eBPF programs can be attached to tc (Linux traffic control tool)
ingress or egress interfaces and perform a variety of packet processing tasks,
in an efficient way. This opens new perspectives in the domain.</p>

<p>And eBPF performances are further leveraged through the technologies developed
for the IO Visor project: new hooks have also been added for XDP (‚ÄúeXpress Data
Path‚Äù), a new fast path recently added to the kernel. XDP works in conjunction
with the Linux stack, and relies on BPF to perform very fast packet processing.</p>

<p>Even some projects such as P4, Open vSwitch,
<a href="http://openvswitch.org/pipermail/ovs-dev/2014-October/047421.html">consider</a>
or started to approach BPF. Some others, such as CETH, Cilium, are entirely
based on it. BPF is buzzing, so we can expect a lot of tools and projects to
orbit around it soon‚Ä¶</p>



<p>As for me: some of my work (including for
<a href="https://qmonnet.github.io/whirl-offload/2016/07/15/beba-research-project/">BEBA</a>)
is closely related to eBPF, and several future articles on this site will focus
on this topic. Logically, I wanted to somehow introduce BPF on this blog before
going down to the details‚ÄîI mean, a real introduction, more developed on BPF
functionalities that the brief abstract provided in first section: What are BPF
maps? Tail calls? What do the internals look like? And so on. But there are a
lot of presentations on this topic available on the web already, and I do not
wish to create ‚Äúyet another BPF introduction‚Äù that would come as a duplicate of
existing documents.</p>

<p>So instead, here is what we will do. After all, I spent some time reading and
learning about BPF, and while doing so, I gathered a fair amount of material
about BPF: introductions, documentation, but also tutorials or examples. There
is a lot to read, but in order to read it, one has to <em>find</em> it first.
Therefore, as an attempt to help people who wish to learn and use BPF, the
present article introduces a list of resources. These are various kinds of
readings, that hopefully will help you dive into the mechanics of this kernel
bytecode.</p>



<figure>
  <img src="https://qmonnet.github.io/whirl-offload/img/icons/pic.svg">
</figure>

<h2 id="generic-presentations">Generic presentations</h2>

<p>The documents linked below provide a generic overview of BPF, or of some
closely related topics. If you are very new to BPF, you can try picking a
couple of presentation among the first ones and reading the ones you like most.
If you know eBPF already, you probably want to target specific topics instead,
lower down in the list.</p>

<h3 id="about-bpf">About BPF</h3>

<p>Generic presentations about eBPF:</p>

<ul>
  <li>
    <p><a href="https://blogs.igalia.com/dpino/2019/01/07/introduction-to-xdp-and-ebpf/"><em>A brief introduction to XDP and eBPF</em></a>
(Diego Pino Garc√≠a, January 2019): <br>
An excellent and accessible introduction providing context, history, and
details about the functioning of eBPF.</p>
  </li>
  <li>
    <p><a href="https://www.redhat.com/en/blog/introduction-ebpf-red-hat-enterprise-linux-7"><em>Introduction to eBPF in Red Hat Enterprise Linux 7</em></a>
(Stanislav Kozina, January 2019): <br>
Focusing on the eBPF features arriving in Red Hat.</p>
  </li>
  <li>
    <p><a href="http://fulvio.frisso.net/files/18HPSR%20-%20eBPF.pdf"><em>Toward Flexible and Efficient In-Kernel Network Function Chaining with IO Visor</em></a>
(Fulvio Risso, HPSR 2018, Bucharest, June 2018): <br>
A generic introduction to BPF, XDP, IO Visor, bcc and other components.</p>
  </li>
  <li>
    <p><a href="https://lwn.net/Articles/740157/"><em>A thorough introduction to eBPF</em></a>
(Matt Flemming, on LWN.net, December 2017): <br>
A well-written and accessible introduction providing an overview of eBPF
subsystem components.</p>
  </li>
  <li>
    <p><a href="http://schd.ws/hosted_files/ossna2017/da/BPFandXDP.pdf"><em>Making the Kernel‚Äôs Networking Data Path Programmable with BPF and XDP</em></a>
(Daniel Borkmann, OSSNA17, Los Angeles, September 2017):<br>
One of the best set of slides available to understand quickly all the basics about eBPF and XDP (mostly for network processing).</p>
  </li>
  <li>
    <p><a href="https://speakerdeck.com/tuxology/the-bsd-packet-filter">The BSD Packet Filter</a>
(Suchakra Sharma, June 2017): <br>
A very nice introduction, mostly about the tracing aspects.</p>
  </li>
  <li>
    <p><a href="http://www.slideshare.net/brendangregg/bpf-tracing-and-more"><em>BPF: tracing and more</em></a>
(Brendan Gregg, January 2017):<br>
Mostly about the tracing use cases.</p>
  </li>
  <li>
    <p><a href="http://www.slideshare.net/brendangregg/linux-bpf-superpowers"><em>Linux BPF Superpowers</em></a>
(Brendan Gregg, March 2016):<br>
With a first part on the use of <strong>flame graphs</strong>.</p>
  </li>
  <li>
    <p><a href="https://www.socallinuxexpo.org/sites/default/files/presentations/Room%20211%20-%20IOVisor%20-%20SCaLE%2014x.pdf"><em>IO Visor</em></a>
(Brenden Blanco, SCaLE 14x, January 2016):<br>
Also introduces <strong>IO Visor project</strong>.</p>
  </li>
  <li>
    <p><a href="https://events.linuxfoundation.org/sites/events/files/slides/ebpf_on_the_mainframe_lcon_2015.pdf"><em>eBPF on the Mainframe</em></a>
(Michael Holzheu, LinuxCon, Dublin, October 2015)</p>
  </li>
  <li>
    <p><a href="https://events.linuxfoundation.org/sites/events/files/slides/tracing-linux-ezannoni-linuxcon-ja-2015_0.pdf"><em>New (and Exciting!) Developments in Linux Tracing</em></a>
(Elena Zannoni, LinuxCon, Japan, 2015)</p>
  </li>
  <li>
    <p><a href="https://events.linuxfoundation.org/sites/events/files/slides/bpf_collabsummit_2015feb20.pdf"><em>BPF ‚Äî in-kernel virtual machine</em></a>
(Alexei Starovoitov, February 2015):<br>
Presentation by the author of eBPF.</p>
  </li>
  <li>
    <p><a href="https://lwn.net/Articles/603983/"><em>Extending extended BPF</em></a>
(Jonathan Corbet, July 2014)</p>
  </li>
</ul>

<p><strong>BPF internals</strong>:</p>

<ul>
  <li>Daniel Borkmann has been doing an amazing work to present <strong>the internals</strong> of eBPF, in particular about <strong>its use with tc</strong>, through several talks and papers.
    <ul>
      <li><a href="http://netdevconf.org/1.2/session.html?daniel-borkmann"><em>Advanced programmability and recent updates with tc‚Äôs cls_bpf</em></a>
(netdev 1.2, Tokyo, October 2016):<br>
Daniel provides details on eBPF, its use for tunneling and encapsulation,
direct packet access, and other features.</li>
      <li><a href="http://netdevconf.org/1.2/slides/oct5/07_tcws_daniel_borkmann_2016_tcws.pdf"><em>cls_bpf/eBPF updates since netdev 1.1</em></a>
(netdev 1.2, Tokyo, October 2016, part of
<a href="http://netdevconf.org/1.2/session.html?jamal-tc-workshop">this tc workshop</a>)</li>
      <li><a href="http://www.netdevconf.org/1.1/proceedings/slides/borkmann-tc-classifier-cls-bpf.pdf"><em>On getting tc classifier fully programmable with cls_bpf</em></a>
(netdev 1.1, Sevilla, February 2016):<br>
After introducing eBPF, this presentation provides insights on many
internal BPF mechanisms (map management, tail calls, verifier). A
must-read! For the most ambitious,
<a href="http://www.netdevconf.org/1.1/proceedings/papers/On-getting-tc-classifier-fully-programmable-with-cls-bpf.pdf">the full paper is available here</a>.</li>
      <li><a href="https://archive.fosdem.org/2016/schedule/event/ebpf/attachments/slides/1159/export/events/attachments/ebpf/slides/1159/ebpf.pdf"><em>Linux tc and eBPF</em></a>
(fosdem16, Brussels, Belgium, January 2016)</li>
      <li><a href="https://fosdem.org/2017/schedule/event/ebpf_xdp/"><em>eBPF and XDP walkthrough and recent updates</em></a>
(fosdem17, Brussels, Belgium, February 2017)</li>
    </ul>

    <p>These presentations are probably one of the best sources of documentation to
understand the design and implementation of internal mechanisms of eBPF.</p>
  </li>
</ul>

<p>The <a href="https://www.iovisor.org/resources/blog"><strong>IO Visor blog</strong></a> has some
interesting technical articles about BPF. Some of them contain a bit of
marketing talks.</p>

<p>As of early 2019, there are more and more presentations being done around
multiple aspects of BPF. One nice example is
<a href="http://vger.kernel.org/lpc-bpf.html">the BPF track</a> that was held in parallel
to the Linux Plumbers Conference in late 2018 (and should be held again on
coming years), where lots of topics related to eBPF development or use cases
were presented.</p>

<p><strong>Kernel tracing</strong>: summing up all existing methods, including BPF:</p>

<ul>
  <li>
    <p><a href="http://www.slideshare.net/vh21/meet-cutebetweenebpfandtracing"><em>Meet-cute between eBPF and Kerne Tracing</em></a>
(Viller Hsiao, July 2016):<br>
Kprobes, uprobes, ftrace</p>
  </li>
  <li>
    <p><a href="http://www.slideshare.net/vh21/linux-kernel-tracing"><em>Linux Kernel Tracing</em></a>
(Viller Hsiao, July 2016):<br>
Systemtap, Kernelshark, trace-cmd, LTTng, perf-tool, ftrace, hist-trigger,
perf, function tracer, tracepoint, kprobe/uprobe‚Ä¶</p>
  </li>
</ul>

<p>Regarding <strong>event tracing and monitoring</strong>, Brendan Gregg uses eBPF a lot and
does an excellent job at documenting some of his use cases. If you are in
kernel tracing, you should see his blog articles related to eBPF or to flame
graphs. Most of it are accessible
<a href="http://www.brendangregg.com/blog/2016-03-05/linux-bpf-superpowers.html">from this article</a>
or by browsing his blog.</p>

<p>Introducing BPF, but also presenting <strong>generic concepts of Linux networking</strong>:</p>

<ul>
  <li>
    <p><a href="http://www.slideshare.net/ThomasGraf5/linux-networking-explained"><em>Linux Networking Explained</em></a>
(Thomas Graf, LinuxCon, Toronto, August 2016)</p>
  </li>
  <li>
    <p><a href="http://www.slideshare.net/ThomasGraf5/linuxcon-2015-linux-kernel-networking-walkthrough"><em>Kernel Networking Walkthrough</em></a>
(Thomas Graf, LinuxCon, Seattle, August 2015)</p>
  </li>
</ul>

<p><strong>Hardware offload</strong>:</p>

<ul>
  <li>eBPF with tc or XDP supports hardware offload, starting with Linux kernel
version 4.9 and introduced by Netronome. Here is a presentation about this
feature:<br>
<a href="http://netdevconf.org/1.2/session.html?jakub-kicinski">eBPF/XDP hardware offload to SmartNICs</a>
(Jakub Kicinski and Nic Viljoen, netdev 1.2, Tokyo, October 2016)</li>
  <li>An updated version was presented on year later:<br>
<a href="https://www.netdevconf.org/2.2/session.html?viljoen-xdpoffload-talk">Comprehensive XDP offload‚ÄîHandling the edge cases</a>
(Jakub Kicinski and Nic Viljoen, netdev 2.2, Seoul, November 2017)</li>
  <li>I presented a shorter but updated version at FOSDEM 2018:<br>
<a href="https://fosdem.org/2018/schedule/event/xdp/">The Challenges of XDP Hardware Offload</a>
(Quentin Monnet, FOSDEM‚Äô18, Brussels, February 2018)</li>
</ul>

<p>About <strong>cBPF</strong>:</p>

<ul>
  <li>
    <p><a href="http://www.tcpdump.org/papers/bpf-usenix93.pdf"><em>The BSD Packet Filter: A New Architecture for User-level Packet Capture</em></a>
(Steven McCanne and Van Jacobson, 1992):<br>
The original paper about (classic) BPF.</p>
  </li>
  <li>
    <p><a href="http://www.gsp.com/cgi-bin/man.cgi?topic=bpf">The FreeBSD manual page about BPF</a>
is a useful resource to understand cBPF programs.</p>
  </li>
  <li>
    <p>Daniel Borkmann realized at least two presentations on cBPF,
<a href="http://borkmann.ch/talks/2013_devconf.pdf">one in 2013 on mmap, BPF and Netsniff-NG</a>, and
<a href="http://borkmann.ch/talks/2014_devconf.pdf">a very complete one in 2014 on tc and cls_bpf</a>.</p>
  </li>
  <li>
    <p>On Cloudflare‚Äôs blog, Marek Majkowski presented his
<a href="https://blog.cloudflare.com/introducing-the-bpf-tools/">use of BPF bytecode with the <code>xt_bpf</code> module for <strong>iptables</strong></a>.
It is worth mentioning that eBPF is also supported by this module, starting
with Linux kernel 4.10 (I do not know of ‚Ä¶</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/">https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/</a></em></p>]]>
            </description>
            <link>https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055866</guid>
            <pubDate>Wed, 11 Nov 2020 05:51:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Personal epistemology, free speech, and tech companies]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25055742">thread link</a>) | @jseliger
<br/>
November 10, 2020 | https://jakeseliger.com/2020/11/10/personal-epistemology-free-speech-and-tech-companies | <a href="https://web.archive.org/web/*/https://jakeseliger.com/2020/11/10/personal-epistemology-free-speech-and-tech-companies">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div>
						<p>The NYT describes ‚Äú<a href="https://www.nytimes.com/2020/10/13/magazine/free-speech.html">The Problem of Free Speech in an Age of Disinformation</a>, and in response Hacker News commenter <a href="https://news.ycombinator.com/item?id=24813749">throwaway13337</a> says, in part, ‚ÄúIt‚Äôs not unchecked free speech. Instead, it‚Äôs unchecked curation by media and social media companies with the goal of engagement.‚Äù There‚Äôs some truth to the idea that social media companies have evolved to seek engagement, rather than truth, but I think the social media companies are reflecting a deeper human tendency. I wrote back to throwaway13337: ‚ÄúTry teaching non-elite undergrads, and particularly assignments that require some sense of epistemology, and you‚Äôll discover that the vast majority of people have pretty poor personal epistemic hygiene‚Äîit‚Äôs not much required in most people, most of the time, in most jobs.‚Äù</p>
<p>From what I can tell, we evolved to form tribes, not to be ‚Äúright:‚Äù Jonathan‚Äôs Haidt‚Äôs <a href="https://jakeseliger.com/2012/03/25/jonathan-haidts-the-righteous-mind-and-what-were-really-arguing-about/"><em>The Righteous Mind: Why Good People Are Divided by Politics and Religion</em></a> deals with this topic well and at length, and I‚Äôve not seen any substantial rebuttals of it. We don‚Äôt naturally take to tracking the question, ‚ÄúHow do I know what I know?‚Äù Instead, we naturally seem to want to find ‚Äúfacts‚Äù or ideas that support our preexisting views. In the HN comment thread, someone asked for specific examples of poor undergrad epistemic hygiene, and while I‚Äôd prefer not to get super specific for reasons of privacy, I‚Äôve had many conversations that take the following form: ‚ÄúHow do you know article x is accurate?‚Äù ‚ÄúGoogle told me.‚Äù ‚ÄúHow does Google work?‚Äù ‚ÄúI don‚Äôt know.‚Äù ‚ÄúWhat does it take to make a claim on the Internet.‚Äù ‚ÄúUm. A phone, I guess?‚Äù A lot of people‚Äîmaybe most‚Äîwill uncritically take as fact whatever happens to be served up by Google (it‚Äôs always Google and never Duck Duck Go or Bing), and most undergrads whose work I‚Äôve read will, again uncritically, accept clickbait sites and similar as accurate. Part of the reason for this reasoning is that undergrads‚Äôs lives are minimally affected by being wrong or incomplete about some claim done in a short assignment that‚Äôs being imposed by some annoying professor toff standing between them and their degree.</p>
<p>The gap between elite information discourse and everyday information discourse, even among college students, who may be more sophisticated than their peer equivalents, is vast‚Äîso vast that I don‚Äôt think most journalists (who mostly talk to other journalists and to experts) and to other people who work with information, data, and ideas really truly understand it. We‚Äôre all living in bubbles. I don‚Äôt think I did, either, before I saw the epistemic hygiene most undergrads practice, or don‚Äôt practice. This is not a ‚Äúkids these days‚Äù rant, either: many of them have never really been taught to ask themselves, ‚ÄúHow do I know what I know?‚Äù Many have never really learned anything about the scientific method. It‚Äôs not happening much in most non-elite schools, so where are they going to get epistemic hygiene from?</p>
<p>The United States alone has 320 million people in it. Table DP02 in the Census at data.census.gov estimates that 20.3% of the population age 25 and older has a college bachelor‚Äôs degree, and 12.8% have a graduate or professional degree. Before someone objects, let me admit that a college degree is far from a perfect proxy for epistemic hygiene or general knowledge, and some high school dropouts perform much better at cognition, meta cognition, statistical reasoning, and so forth, than do some people with graduate degrees. With that said, though, a college degree is probably a decent approximation for baseline abstract reasoning skills and epistemic hygiene.</p>
<p>Almost anyone who wants a megaphone in the form of one of the many social media platforms available now has one. The number of people motivated by questions like ‚ÄúWhat is really true, and how do I discern what is really true? How do I enable myself to get countervailing data and information into my view, or worldview, or worldviews?‚Äù is not zero, again obviously, but it‚Äôs not a huge part of the population. And many very ‚Äúsmart‚Äù people in an IQ sense use their intelligence to build better rationalizations, rather than to seek truth (and I may be among the rationalizers: I‚Äôm not trying to exclude myself from that category).</p>
<p>Until relatively recently, almost everyone with a media megaphone had some kind of training or interest in epistemology, even they didn‚Äôt call it ‚Äúepistemology.‚Äù Editors would ask, ‚ÄúHow do you know that?‚Äù or ‚ÄúWho told you that?‚Äù or that sort of thing. Professors have systems that are supposed to encourage greater-than-average epistemic hygiene (again: these systems were not and are not perfect, and nothing I have written so far implies that they were or are).</p>
<p>Most people don‚Äôt care about the question, ‚ÄúHow do you know what you know?‚Äù and they‚Äôll be fairly surprised if it‚Äôs asked, implicitly or explicitly. Some people are intrigued by it but most aren‚Äôt, and view questions about sources and knowledge to be a hindrance. This is less likely to be true of people who aspire to be researchers or work in other knowledge-related professions, but that describes only a small percentage of undergraduates, particularly at non-elite schools. And the ‚Äúelite schools‚Äù thing drives a lot of the media discourse around education. One of the things I like about Professor X‚Äôs book <a href="https://jakeseliger.com/2011/06/10/summary-judgement-in-the-basement-of-the-ivory-tower-confessions-of-an-accidental-academic-professor-x/"><em>In the Basement of the Ivory Tower</em></a> is how it functions as a corrective to that discourse.</p>
<p>For most people, floating a factually incorrect conspiracy theory online isn‚Äôt going to negatively affect their lives. If someone is a nurse and gives a patient a wrong medication or incorrect medication, that person is not going to be a nurse for long. If the nurse states or repeats a factually incorrect political or social idea online, particularly but not exclusively under a pseudonym, that nurse‚Äôs life likely won‚Äôt be affected. There‚Äôs no truth feedback loop. The same is true for someone working in, say, construction, or engineering, or many other fields. The person is free to state things that are factually incorrect, or incomplete, or misleading, and doing so isn‚Äôt going to have many negative consequences. Maybe it will have some positive consequences: one way to show that you‚Äôre really on team x is to state or repeat falsehoods that show you‚Äôre on team x, rather than on team ‚ÄúWhat is really true?‚Äù</p>
<p>I don‚Äôt want to get into daily political discourse, since that tends to raise defenses and elicit anger, but the last eight months have demonstrated many people‚Äôs problems with epistemology, and in a way that can have immediate, negative personal consequences‚Äîbut not for everyone.</p>
<p><a href="https://www.pewresearch.org/fact-tank/2019/09/26/who-doesnt-read-books-in-america/">Pew Research data indicate that a quarter of US adults didn‚Äôt read a book in 2018</a>; this is consistent with <a href="https://www.newyorker.com/magazine/2007/12/24/twilight-of-the-books">other data</a> indicating that about half of US adults read zero or one books per year. Again, yes, there are surely many individuals who read other materials and have excellent epistemic hygiene, but this is a reasonable mass proxy, given the demands that reading makes on us.</p>
<p>Many people driving the (relatively) elite discourse don‚Äôt realize how many people are not only not like them, but wildly not like them, along numerous metrics. It may also be that <a href="http://www.arnoldkling.com/blog/gossip-at-scale/">we don‚Äôt know how to deal with gossip at scale</a>. Interpersonal gossip is all about personal stories, while many problems at scale are best understood through data‚Äîbut the number of people deeply interested in data and data‚Äôs veracity is small. And elite discourse has some of its own possible epistemic falsehoods, or at least uncertainties, embedded within it: some of the populist rhetoric against elites is rooted in truth.</p>
<p>We are all caught in our bubble, and the universe of people is almost unimaginably larger than the number of people in our bubble. If you got this far, you‚Äôre probably in a nerd bubble: usually, anything involving the word ‚Äúepistemology‚Äù sends people to sleep or, alternately, scurrying for something like ‚ÄúYou won‚Äôt believe what this celebrity wore/said/did‚Äù instead. Almost no one wants to consider epistemology; to do so as a hobby is rare. One person‚Äôs disinformation is another person‚Äôs teambuilding. If you think the preceding sentence is in favor of disinformation, by the way, it‚Äôs not.</p>
					</div><!-- .entry-content -->
	</div></div>]]>
            </description>
            <link>https://jakeseliger.com/2020/11/10/personal-epistemology-free-speech-and-tech-companies</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055742</guid>
            <pubDate>Wed, 11 Nov 2020 05:28:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Foundation for securing communications plane of CPS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25055601">thread link</a>) | @takko_the_boss
<br/>
November 10, 2020 | https://mikecurnow.com/csis_introduction/ | <a href="https://web.archive.org/web/*/https://mikecurnow.com/csis_introduction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://mikecurnow.com/csis_introduction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055601</guid>
            <pubDate>Wed, 11 Nov 2020 04:53:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Business ideas (from my first million podcast)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25055308">thread link</a>) | @micropoet
<br/>
November 10, 2020 | https://www.notion.so/50-Businesses-from-My-First-Million-306d9b5cbaef488ea8181e2d27e71553 | <a href="https://web.archive.org/web/*/https://www.notion.so/50-Businesses-from-My-First-Million-306d9b5cbaef488ea8181e2d27e71553">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/50-Businesses-from-My-First-Million-306d9b5cbaef488ea8181e2d27e71553</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055308</guid>
            <pubDate>Wed, 11 Nov 2020 03:46:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning a New Language While Browsing the Web]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25055257">thread link</a>) | @rahulchowdhury
<br/>
November 10, 2020 | https://hulry.com/toucan-learn-language/ | <a href="https://web.archive.org/web/*/https://hulry.com/toucan-learn-language/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
<p>Around 2015, I picked up a hobby of learning a new language ‚Äî Spanish.</p>



<p>However, after a few months of dedicated learning time, I couldn‚Äôt get myself to stick to the hobby.</p>



<p>I had other things to work on, and learning a language was not my priority.</p>



<p>But things have changed now.</p>



<p>In this post, I‚Äôll talk about how I‚Äôm learning a bit of Spanish every single day using a new language learning tool called <a href="https://jointoucan.com/" target="_blank" rel="noreferrer noopener">Toucan</a>.</p>



<p>Let‚Äôs get started with:</p>



<h2>My experience with various language-learning apps</h2>



<p>I started my Spanish learning journey with the most popular language-learning app ‚Äî <a href="https://www.duolingo.com/" target="_blank" rel="noreferrer noopener nofollow">Duolingo</a>.</p>



<p>While it was fun initially, I soon found myself missing practice days.</p>



<p>As time passed by, the gap widened. And soon enough, I stopped my Spanish sessions.</p>



<p>In the last few years, I‚Äôve tried to rekindle the Spanish spark in me and continue learning with Duolingo. Still, I never succeeded in sticking to the classes.</p>



<p>Then came <a href="https://www.babbel.com/" target="_blank" rel="noreferrer noopener nofollow">Babbel</a>.</p>



<p>While I must say that Babbel has a better course in terms of learning proper grammar and dialects, it had the same problem as Duolingo:</p>



<p>It was hard for me to dedicate time from my schedule for learning sessions.</p>



<p>My only motivation for learning Spanish was to expand my skill set.</p>



<p>Since I‚Äôm not moving to a Spanish speaking country anytime soon, I didn‚Äôt feel the need to prioritise this hobby.</p>



<p>But then:</p>



<p>A few months ago, I spotted a new <a href="https://chrome.google.com/webstore/detail/toucan/lokjgaehpcnlmkebpmjiofccpklbmoci" target="_blank" rel="noreferrer noopener nofollow">Chrome extension called Toucan</a>. Around the same time, a similar extension launched called <a href="https://www.usefluent.co/" target="_blank" rel="noreferrer noopener">Fluent</a>.</p>



<p>The key selling point of these new extensions was to learn a new language while browsing the web.</p>



<p>You don‚Äôt need to dedicate time for picking up a new language. Club the learning sessions, along with activities we do every day ‚Äî browsing the web and reading articles online.</p>



<p>After a quick test ride, here‚Äôs:</p>



<h2>Why I find language learning extensions interesting</h2>



<p>The first and most immense value ‚Äî habit bundling.</p>



<p>I had previously talked about how I <a href="https://hulry.com/building-podcasts-habit/" target="_blank" rel="noreferrer noopener">clubbed my habit</a> of making tea every morning with listening to podcasts.</p>



<p>I saw a similar opportunity with these browser extensions.</p>



<p>The biggest hurdle for me in learning Spanish was making time for classes.</p>



<p>Now:</p>



<p>I don‚Äôt need to dedicate time out of my daily routine to learn a new language.</p>



<p>I browse and read lots of articles online. With Toucan or Fluent, I can learn and practice Spanish every time I read stuff online.</p>



<p>Here‚Äôs:</p>



<h2>How Toucan and Fluent work</h2>



<p>Install Toucan or Fluent, and browse the web as you‚Äôd typically do.</p>



<p>These extensions will translate and highlight some words from the page content into the language you‚Äôve chosen.</p>



<p>Hovering over the highlighted word will bring up a popup card like this:</p>



<div><figure><img data-attachment-id="943" data-permalink="https://hulry.com/toucan-learn-language/toucan-translation-demo/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?fit=1646%2C742&amp;ssl=1" data-orig-size="1646,742" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-translation-demo" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?fit=300%2C135&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?fit=1024%2C462&amp;ssl=1" loading="lazy" width="1024" height="462" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1024%2C462&amp;ssl=1" alt="Toucan translating and showing up a word on Instapaper." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1024%2C462&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=300%2C135&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=768%2C346&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1536%2C692&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1200%2C541&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?w=1646&amp;ssl=1 1646w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1024%2C462&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=300%2C135&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=768%2C346&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1536%2C692&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1200%2C541&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?w=1646&amp;ssl=1 1646w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1024%2C462&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Toucan translating and showing up a word on Instapaper.</figcaption></figure></div>



<p>Pretty neat. Right?</p>



<p>Apart from the convenience, another thing I like is that the translations are beautifully blended into the content.</p>



<p>For example, from the above screenshot, you can see Toucan seamlessly translated and blended the English word ‚Äúevent‚Äù into its Spanish counterpart ‚Äî evento.</p>



<p>While reading an article, I can see a mixture of English and the language I want to learn.</p>



<p>To know more about the translated word, I can hover on it and Toucan will show me the word in English, with its definition.</p>



<p>I‚Äôve tried both Toucan and Fluent on multiple websites, and they seem to blend in translations flawlessly with the page‚Äôs design.</p>



<p>Here‚Äôs an article on Forbes with Toucan translations:</p>



<div><figure><img data-attachment-id="947" data-permalink="https://hulry.com/toucan-learn-language/toucan-translation-forbes/" data-orig-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?fit=1474%2C814&amp;ssl=1" data-orig-size="1474,814" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-translation-forbes" data-image-description="" data-medium-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?fit=300%2C166&amp;ssl=1" data-large-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?fit=1024%2C565&amp;ssl=1" loading="lazy" width="1024" height="565" src="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1024%2C565&amp;ssl=1" alt="Toucan translating words from an article on Forbes." srcset="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1024%2C565&amp;ssl=1 1024w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=300%2C166&amp;ssl=1 300w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=768%2C424&amp;ssl=1 768w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1200%2C663&amp;ssl=1 1200w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?w=1474&amp;ssl=1 1474w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1024%2C565&amp;ssl=1 1024w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=300%2C166&amp;ssl=1 300w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=768%2C424&amp;ssl=1 768w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1200%2C663&amp;ssl=1 1200w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?w=1474&amp;ssl=1 1474w" data-lazy-src="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1024%2C565&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Toucan translating words from an article on Forbes.</figcaption></figure></div>



<p>Now:</p>



<p>Fluent, however, has a more targeted highlighting than Toucan. </p>



<p>If you‚Äôre using Fluent, it‚Äôll highlight words with different colour based on gender.</p>



<div><figure><img data-attachment-id="983" data-permalink="https://hulry.com/toucan-learn-language/fluent-colour-highlights/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?fit=1596%2C508&amp;ssl=1" data-orig-size="1596,508" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fluent-colour-highlights" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?fit=300%2C95&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?fit=1024%2C326&amp;ssl=1" loading="lazy" width="1024" height="326" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1024%2C326&amp;ssl=1" alt="Fluent highlighting words with a different colour." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1024%2C326&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=300%2C95&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=768%2C244&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1536%2C489&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1200%2C382&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?w=1596&amp;ssl=1 1596w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1024%2C326&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=300%2C95&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=768%2C244&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1536%2C489&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1200%2C382&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?w=1596&amp;ssl=1 1596w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1024%2C326&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Fluent highlighting words with a different colour.</figcaption></figure></div>



<p>In the paragraph shown above, Fluent highlighted the word ‚Äúderrame‚Äù with a yellow tint (because it‚Äôs masculine), and ‚Äúincluso‚Äù with a neutral grey-ish colour (because it‚Äôs gender-neutral).</p>



<p>That said, here are:</p>



<h2>Some features in Toucan that caught my attention</h2>



<p>Trying out both extensions, I chose to stick with Toucan, mainly due to a couple of subtle features.</p>



<p>The first being:</p>



<h3>Word definitions</h3>



<p>Toucan shows up the definition of a translated word on the hovercard that shows up.</p>



<div><figure><img data-attachment-id="952" data-permalink="https://hulry.com/toucan-learn-language/toucan-word-definition/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?fit=1524%2C632&amp;ssl=1" data-orig-size="1524,632" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-word-definition" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?fit=300%2C124&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?fit=1024%2C425&amp;ssl=1" loading="lazy" width="1024" height="425" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1024%2C425&amp;ssl=1" alt="Toucan showing a word's definition." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1024%2C425&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=300%2C124&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=768%2C318&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1200%2C498&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?w=1524&amp;ssl=1 1524w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1024%2C425&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=300%2C124&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=768%2C318&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1200%2C498&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?w=1524&amp;ssl=1 1524w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1024%2C425&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Toucan showing a word‚Äôs definition.</figcaption></figure></div>



<p>As a non-native English speaker, this feature is helpful to me. </p>



<p>If I don‚Äôt know the meaning of the translated word, I can read the definition on the card.</p>



<p>There‚Äôs one caveat though:</p>



<p>Right now, not all words show up a definition. However, the number of words without a description is low.</p>



<p>Also, the team at Toucan promised they are continuously working on adding more words and definitions to the tool.</p>



<p>Therefore, this caveat should no longer exist pretty soon.</p>



<p>Another feature I found helpful is:</p>



<h3>The ability to mark a word as learnt</h3>



<p>The Toucan hovercard has a little checkmark which lets me mark a word as learnt, like this:</p>



<div><figure><img data-attachment-id="958" data-permalink="https://hulry.com/toucan-learn-language/touch-mark-word-done/" data-orig-file="https://i2.wp.com/hulry.com/wp-content/uploads/2020/11/touch-mark-word-done.gif?fit=840%2C526&amp;ssl=1" data-orig-size="840,526" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="touch-mark-word-done" data-image-description="" data-medium-file="https://i2.wp.com/hulry.com/wp-content/uploads/2020/11/touch-mark-word-done.gif?fit=300%2C188&amp;ssl=1" data-large-file="https://i2.wp.com/hulry.com/wp-content/uploads/2020/11/touch-mark-word-done.gif?fit=840%2C526&amp;ssl=1" loading="lazy" width="840" height="526" src="https://i2.wp.com/hulry.com/wp-content/uploads/2020/11/touch-mark-word-done.gif?resize=840%2C526&amp;ssl=1" alt="Marking a word as known in Toucan." data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Marking a word as known in Toucan.</figcaption></figure></div>



<p>What this does is it prevents the word from getting translated in future articles or content.</p>



<p>Since I had taken a couple of Spanish lessons in the past, I marked a handful of words as ‚ÄúI know this‚Äù and Toucan will leave those words in the source language ‚Äî English, for me.</p>



<p>Also:</p>



<p>The Toucan team is working on some recommendation magic for this feature.</p>



<p>For example:</p>



<p>Marking the word ‚Äúcoffee‚Äù as learnt will set Toucan to translate tricky words like ‚Äúhot coffee‚Äù or ‚Äúnice coffee‚Äù in your future reads.</p>



<p>This is how I‚Äôll be able to calibrate Toucan to show up more complicated words as I progress in my Spanish learning journey. </p>



<p>Now:</p>



<p>Everyone learns at a different pace.</p>



<p>To make it easy to progress comfortably, Toucan allows me to:</p>



<h3>Select language packs for translation</h3>



<p>Instead of being bombarded with a giant index of Spanish words, Toucan allows me to <a href="https://jointoucan.com/dashboard" target="_blank" rel="noreferrer noopener nofollow">select language packs</a> on the dashboard:</p>



<div><figure><img data-attachment-id="962" data-permalink="https://hulry.com/toucan-learn-language/toucan-language-packs/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?fit=1860%2C1182&amp;ssl=1" data-orig-size="1860,1182" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-language-packs" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?fit=300%2C191&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?fit=1024%2C651&amp;ssl=1" loading="lazy" width="1024" height="651" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1024%2C651&amp;ssl=1" alt="Selecting language packs in Toucan." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1024%2C651&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=300%2C191&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=768%2C488&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1536%2C976&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1200%2C763&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?w=1860&amp;ssl=1 1860w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1024%2C651&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=300%2C191&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=768%2C488&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1536%2C976&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1200%2C763&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?w=1860&amp;ssl=1 1860w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1024%2C651&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Selecting language packs in Toucan.</figcaption></figure></div>



<p>Each language pack has a set of words that Toucan will search for in an article or web page content and translate.</p>



<p>For example, choosing the language pack ‚ÄúGet Around the City‚Äù will set Toucan to translate the following English words in the collection to their Spanish counterparts:</p>



<div><figure><img data-attachment-id="964" data-permalink="https://hulry.com/toucan-learn-language/toucan-get-around-city-pack/" data-orig-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?fit=1420%2C834&amp;ssl=1" data-orig-size="1420,834" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-get-around-city-pack" data-image-description="" data-medium-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?fit=300%2C176&amp;ssl=1" data-large-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?fit=1024%2C601&amp;ssl=1" loading="lazy" width="1024" height="601" src="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1024%2C601&amp;ssl=1" alt="Toucan's &quot;Get Around the City&quot; language pack." srcset="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1024%2C601&amp;ssl=1 1024w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=300%2C176&amp;ssl=1 300w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=768%2C451&amp;ssl=1 768w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1200%2C705&amp;ssl=1 1200w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?w=1420&amp;ssl=1 1420w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1024%2C601&amp;ssl=1 1024w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=300%2C176&amp;ssl=1 300w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=768%2C451&amp;ssl=1 768w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1200%2C705&amp;ssl=1 1200w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?w=1420&amp;ssl=1 1420w" data-lazy-src="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1024%2C601&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Toucan‚Äôs ‚ÄúGet Around the City‚Äù language pack.</figcaption></figure></div>



<p>This feature is beneficial for beginners because we can choose a handful of language packs and start learning.</p>



<p>Once we have mastered the words in the selected packs, we can remove them from our list and move on to more advanced packs.</p>



<p>So, overall, Toucan seems to be a useful tool for learning a language.</p>



<p>But, here‚Äôs a burning question:</p>



<h2>Can language extensions be a distraction?</h2>



<p>It depends on the translation density set for the extension.</p>



<p>For example, in Toucan, we can control the number of translations on a page with the following setting:</p>



<div><figure><img data-attachment-id="967" data-permalink="https://hulry.com/toucan-learn-language/toucan-translation-frequency/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?fit=1600%2C1158&amp;ssl=1" data-orig-size="1600,1158" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-translation-frequency" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?fit=300%2C217&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?fit=1024%2C741&amp;ssl=1" loading="lazy" width="1024" height="741" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1024%2C741&amp;ssl=1" alt="Choosing a translation density in Toucan." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1024%2C741&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=300%2C217&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=768%2C556&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1536%2C1112&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1200%2C869&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1024%2C741&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=300%2C217&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=768%2C556&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1536%2C1112&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1200%2C869&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?w=1600&amp;ssl=1 1600w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1024%2C741&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Choosing a translation density in Toucan.</figcaption></figure></div>



<p>Choosing ‚ÄúMany‚Äù will set Toucan to replace and highlight a substantial number of words on the page with their translated counterparts.</p>



<p>I tried this setting for some time, and I found it somewhat distracting because there were a ton of words highlighted in the page fighting for my attention.</p>



<p>To take it easy and progress gradually, I started with the setting ‚ÄúLess‚Äù.</p>



<p>With ‚ÄúLess‚Äù, I get around 5‚Äì7 words translated in an article of 4‚Äì5 min read time.</p>



<p>Also:</p>



<p>With ‚ÄúLess‚Äù translations are distributed evenly in the article. Thus, the highlights don‚Äôt steal my attention from the content.</p>



<p>I can naturally spot a highlight as I read through the content, and hover on the translated word for the meaning.</p>



<p>Here‚Äôs what I recommend:</p>



<p>Start with ‚ÄúLess‚Äù ‚Üí As you become comfortable with the translations ‚Üí Move to ‚ÄúMore‚Äù.</p>



<p>With a gradual transition, it‚Äôll be easier to stick to this extension and interpret it as a tool instead of a distraction.</p>



<p>Similar to Toucan, Fluent also shows up an option to choose how many words you‚Äôd like to see translated:</p>



<div><figure><img data-attachment-id="992" data-permalink="https://hulry.com/toucan-learn-language/fluent-set-word-density/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?fit=1584%2C662&amp;ssl=1" data-orig-size="1584,662" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fluent-set-word-density" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?fit=300%2C125&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?fit=1024%2C428&amp;ssl=1" loading="lazy" width="1024" height="428" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1024%2C428&amp;ssl=1" alt="Setting a translation density on Fluent." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1024%2C428&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=300%2C125&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=768%2C321&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1536%2C642&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1200%2C502&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?w=1584&amp;ssl=1 1584w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1024%2C428&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=300%2C125&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=768%2C321&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1536%2C642&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1200%2C502&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?w=1584&amp;ssl=1 1584w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1024%2C428&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Setting a translation density on Fluent.</figcaption></figure></div>



<p>Establishing the fact that these extensions are a tool rather than a distraction, here‚Äôs another critical question:</p>



<h2>Are there any privacy concerns?</h2>



<p>Privacy is a significant factor in an extension like this since we‚Äôre giving the extension full access to whatever we browse.</p>



<p>Both <a href="https://jointoucan.com/privacy" target="_blank" rel="noreferrer noopener nofollow">Toucan</a> and <a href="https://www.usefluent.co/privacy" target="_blank" rel="noreferrer noopener nofollow">Fluent</a> have addressed this concern with a friendly privacy policy.</p>



<p>Here‚Äôs a gist:</p>



<ul><li>They don‚Äôt sell user data for ads.</li><li>The extensions don‚Äôt store any browsing history.</li><li>They only store the translated words in a browsing session to keep track of your learning progress.</li></ul>



<p>But:</p>



<p>With a free product, there will always be privacy concerns, no matter how clean it‚Äôs privacy policy might be. The business needs to make money.</p>



<p>Here‚Äôs how Toucan generates revenue right now:</p>



<ul><li><strong>Premium memberships.</strong> Toucan offers a premium membership which unlocks a couple of advanced learning packs.</li><li><strong>Own a word.</strong> With Toucan, you can <a href="https://jointoucan.com/own-the-word/claim" target="_blank" rel="noreferrer noopener nofollow">own a word</a> for <strong>$0.99/week</strong>. This means that if I own the word ‚Äúproductivity‚Äù, then every time someone hovers over the translated word for ‚Äúproductivity‚Äù, they‚Äôll see my name and website at the bottom of the card. Consider it a form of advertisement without the use of your browsing history.</li></ul>



<p>That said:</p>



<p>I would still recommend you turn off Toucan on sensitive websites like your email inbox, banking sites, etc.</p>



<p>Here‚Äôs how you can do it:</p>



<div><figure><img data-attachment-id="975" data-permalink="https://hulry.com/toucan-learn-language/turn-off-toucan/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/turn-off-toucan.gif?fit=840%2C526&amp;ssl=1" data-orig-size="840,526" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="turn-off-toucan" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/turn-off-toucan.gif?fit=300%2C188&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/turn-off-toucan.gif?fit=840%2C526&amp;ssl=1" loading="lazy" width="840" height="526" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/turn-off-toucan.gif?resize=840%2C526&amp;ssl=1" alt="Turning off Toucan translations on a specific website." data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Turning off Toucan translations on a specific website.</figcaption></figure></div>



<p>Once Toucan is turned off for a particular website, the extension will never read any data from any page of the website.</p>



<p>Here are some of the websites where I have disabled Toucan:</p>



<ul><li>HEY email</li><li>Dropbox</li><li>Gmail</li><li>Banking websites I use</li><li>WordPress</li><li>Notion</li></ul>



<p>It‚Äôs always wise to fine-tune privacy settings so that we don‚Äôt leak any of our data to a company who might use it to their advantage.</p>



<p>Now that we talked about Toucan‚Äôs premium subscription, let‚Äôs see:</p>



<h2>Whether premium is worth the money</h2>



<p>Right now, the only selling point of ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hulry.com/toucan-learn-language/">https://hulry.com/toucan-learn-language/</a></em></p>]]>
            </description>
            <link>https://hulry.com/toucan-learn-language/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055257</guid>
            <pubDate>Wed, 11 Nov 2020 03:39:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create Value for People]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25055070">thread link</a>) | @mooreds
<br/>
November 10, 2020 | https://letterstoanewdeveloper.com/2020/11/09/create-value-for-people/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2020/11/09/create-value-for-people/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><em>This is a guest post from Minh Pham. Enjoy.</em></p>



<p>Dear new developer,</p>



<p>I want to start off by saying Congrats and Good job. If you‚Äôre reading this, it‚Äôs likely you know how to code ‚Äì and even if you‚Äôre still working on getting that first job, that means you have one of the most desirable skill sets in the world today. I congratulate you because getting here took work. You weren‚Äôt born with this knowledge, and even if you felt like it came naturally, it was still a journey of discovery, learning, and practice that got you where you are today.</p>



<p>As you look towards your first job ‚Äì I want to offer you a single piece of advice that may act as your career‚Äôs guiding north star:</p>



<p><strong>Create Value for People.</strong></p>



<p>When you have the power to create anything, you begin to realize the importance isn‚Äôt on the code you‚Äôre writing but rather why you‚Äôre writing it in the first place. What value are you creating through your skill? This is why companies hire people like yourself. They are seeking out individuals who can ultimately deliver value to their customers, particularly through software. As you mature, you will realize that much of engineering has little to do with how fancy your solution is, and instead has everything to do with what problem it solves for the user. Once you accept this, you‚Äôll begin to see that discussions of tech choice and code structure rarely matters outside the context of what business value it represents.</p>



<p>This is where your focus should stay.</p>



<p>Obsessions with patterns and algorithms don‚Äôt serve anyone‚Äôs mission by themselves. Ignore the constant pressure to assert yourself through syntactic cleverness and obscure trivia. These things don‚Äôt matter. These things don‚Äôt drive value for anyone. No matter how many ‚Äúexperienced‚Äù engineers tell you these are important, I promise you no company hires people simply for them to recite principles and algorithms.</p>



<p>While coding might be your latest skill set, it is by no means an engineer‚Äôs only skillset. Remember that at the end of the day, it doesn‚Äôt matter if your code is ugly, fancy, verbose or concise ‚Äì the value you create matters. Strive to be an excellent communicator, a quality teammate, and an outstanding human. These attributes will guide your engineering efforts to ensure you bring value.</p>



<p>No matter where your career goes, if you focus on creating value for people, opportunities will never be in short supply. Desire for specific skills may rise and fall, but people will always look to those who can create value.</p>



<p>With that, I wish you the best of luck and may our journeys cross again,</p>



<p>Minh Pham</p>



<p><em><a href="https://www.linkedin.com/in/miniseagoat/">Minh Pham</a> believes you should lead how you want to be led. This has been the guiding principle of his career since he started. As an Engineer, he always wished he had someone who would guide him ‚Äì telling him what‚Äôs important, what he has to work on, and what he should ignore. Having gone through all that and then some, Minh now looks to be the positive influence he wishes he had.</em></p>



<p><em>As a manager, Minh‚Äôs greatest passion was teaching people the skills to create and drive the careers they want to have. Now as a career coach, he works to show people they have the power to build the life they want.</em></p>



<p><em>Minh believes anyone can do it ‚Äì and he promises it doesn‚Äôt involve linked lists or graph traversals.</em></p>
	</div><div>
			<!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2020-11-09T09:27:00-07:00">November 9, 2020</time><time datetime="2020-10-23T21:27:22-06:00">October 23, 2020</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2020/11/09/create-value-for-people/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055070</guid>
            <pubDate>Wed, 11 Nov 2020 03:00:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facial-Recognition Software for Bears]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25054992">thread link</a>) | @sandworm101
<br/>
November 10, 2020 | https://www.cbc.ca/news/canada/british-columbia/grizzly-bear-facial-recognition-software-1.5797525 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/british-columbia/grizzly-bear-facial-recognition-software-1.5797525">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Facial recognition technology previously used on humans has huge implications for managing bear-human interactions, says UVic ecologist who has developed software to identify grizzly bears.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5797547.1605049994!/fileImage/httpImage/image.JPG_gen/derivatives/16x9_780/bearid.JPG"></p></div><figcaption>BearID is grizzly bear facial recognition software developed 'from the ground up' with algorithms used to identify humans and primates. <!-- --> <!-- -->(Melanie Clapham)</figcaption></figure><p><span><p>Melanie Clapham has spent the last three years snapping images of grizzly bears at Knight Inlet, on the B.C. coast, using small camera traps housed in metal and strapped securely to the forest branches.</p>  <p>Three years and thousands of images later, the behavioural ecologist and postdoctoral student at the University of Victoria <a href="https://onlinelibrary.wiley.com/doi/10.1002/ece3.6840" target="_blank">has partnered with</a> two software developers living in Silicon Valley&nbsp;and a grizzly research centre in Alaska&nbsp;to develop facial recognition technology used to identify the bears.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5797551.1605050026!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/bearid-2.jpg 300w,https://i.cbc.ca/1.5797551.1605050026!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/bearid-2.jpg 460w,https://i.cbc.ca/1.5797551.1605050026!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/bearid-2.jpg 620w,https://i.cbc.ca/1.5797551.1605050026!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/bearid-2.jpg 780w,https://i.cbc.ca/1.5797551.1605050026!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/bearid-2.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5797551.1605050026!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/bearid-2.jpg"></p></div><figcaption>Melanie Clapham sets up a camera trap to capture images of grizzly bears for the BearID project.<!-- --> <!-- -->(Moira Le Patourel)</figcaption></figure></span></p>  <p>"They don't have distinctive markings on their bodies," said Clapham, whose&nbsp;interest in this technology stemmed from the need to "identify and recognize individual bears over time" as part of her behavioural research over the last 11 years.&nbsp;</p>  <p>Now, she says, the <a href="http://bearresearch.org/" target="_blank">open-source Bear ID software</a> can be used and adapted by anyone&nbsp;and could have huge implications for understanding the animals' behaviour and mitigating bear-human encounters.&nbsp;</p>  <h2>Technology based on human facial recognition</h2>  <p>Ed Miller and his partner Mary Nyugen are the software developers from California who connected with Clapham in an online forum for conservation technology in late 2017.&nbsp;</p>  <p>The pair were looking for photos of bears "for fun" as a way to learn more about recognition software, and so they connected with Clapham to offer their expertise in adapting artificial intelligence.</p>    <p>"The technology we're using is based on the same software [used] to recognize humans," said Miller, who added that human identification is far easier, as there are literally millions of images the software can learn from.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5797559.1605050036!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/bearid-3.JPG 300w,https://i.cbc.ca/1.5797559.1605050036!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/bearid-3.JPG 460w,https://i.cbc.ca/1.5797559.1605050036!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/bearid-3.JPG 620w,https://i.cbc.ca/1.5797559.1605050036!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/bearid-3.JPG 780w,https://i.cbc.ca/1.5797559.1605050036!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/bearid-3.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5797559.1605050036!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/bearid-3.JPG"></p></div><figcaption>Grizzly bears can be difficult to track, as many do not have distinctive markings on their bodies. <!-- --> <!-- -->(Melanie Clapham)</figcaption></figure></span></p>  <p>"We need (lots of) images of individual animals to tell the system which bear is which," said Clapham, who explained "deep learning" as the process where the software trains itself to recognize certain bears more accurately the more pictures it has.&nbsp;</p>    <p>This is especially important, given that a bear's appearance can change dramatically throughout the year as its fur moults and its weight fluctuates.&nbsp;</p>  <p>Claphams says BearID currently has an 84 per cent accuracy rate.</p>  <h2>Many practical applications</h2>  <p>Clapham said she hopes the technology will be adapted by municipalities, governments, non-profits ‚Äî as many groups as possible ‚Äî as it will allow people to understand animal behaviour, like how they move&nbsp;in and out of densely populated areas. It could also help researchers understand the movements of endangered species.</p>  <p>It can track bears as they move "in a similar way that a human is tracked through airports," she explained. From there, authorities could make better-informed land management and conservation decisions.&nbsp;</p>  <p>It could also help mitigate conflict encounters between bears and humans. </p>  <p>"If you have a bear digging through garbage cans, and you set cameras up ‚Ä¶ is this just one bear or is this five different bears coming into the area?" Clapham said.</p>  <p>Dallas Smith, president of the Nanwakolas Council, a group of five First Nations from Vancouver Island and the B.C. Coast&nbsp;formed to make land management decisions, said he's very excited for First Nations to use BearID, after connecting with Clapham.</p>  <p>"The grizzly bear is an icon in our cultural heritage. It's always been important to work in harmony with them," he explained. "It's really helping us gain a foothold in taking over the management of grizzly bear interactions in our territories."</p>  <p>He said the "collective territory" is working to gather more images for the system.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/british-columbia/grizzly-bear-facial-recognition-software-1.5797525</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054992</guid>
            <pubDate>Wed, 11 Nov 2020 02:44:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Series of blog posts about technology migrations]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25054689">thread link</a>) | @poros
<br/>
November 10, 2020 | http://poros.github.io/technology-migrations-series/ | <a href="https://web.archive.org/web/*/http://poros.github.io/technology-migrations-series/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <div> <nav> <ul> <li> <a href="http://poros.github.io/">Home</a> </li> <li> <a href="http://poros.github.io/pseudoblog">PseudoBlog</a> </li> <li> <a href="http://poros.github.io/projects">Projects</a> </li> <li> <a href="http://poros.github.io/works">Works</a> </li> <li> <a href="http://poros.github.io/about">About</a> </li> </ul> </nav>  <p><span> <time datetime="18-10-2020">Sunday. October 18, 2020</time> </span></p><div> <p><a href="http://poros.github.io/tags/#technology-migrations-series">technology-migrations-series</a> <a href="http://poros.github.io/tags/#tech-lead">tech-lead</a> </p></div>  <p><strong>Migrations are a messy business.</strong> They always run far behind schedule, and it is actually quite rare for them to end at all. They are hard to justify in terms of return on investment. They have a bad reputation among both users and management. They are emotionally draining. Yet they are the way things move forward, technologically speaking at least.</p> <p>Having been working for my entire career (so far) on internal teams focused on infrastructure or platforms, I end up thinking about migrations a lot. I have built my own little taxonomy of technology migrations, I have come up with my personal recipe to pull them off, and I have initiated engineers in the craft of running them. And those are the topics and the intent of this series of blog posts.</p> <p>The first post goes over the taxonomy of migrations and how to approach them based on the category they belong to. But you can start from the second one if you are only interested in how to run the most common type. In case you have read the entire thing already or you don‚Äôt have time for long reads, you can find a summary checklist to follow during your migration in the very last post.</p> <ol> <li><a href="http://poros.github.io/taxonomy-of-migrations/">A taxonomy of migrations</a></li> <li><a href="http://poros.github.io/mum-preparations/">Migrations under monopoly: Preparations</a></li> <li><a href="http://poros.github.io/mum-alpha/">Migrations under monopoly: Alpha</a></li> <li><a href="http://poros.github.io/mum-beta/">Migrations under monopoly: Beta</a></li> <li><a href="http://poros.github.io/mum-automation/">Migrations under monopoly: Automation</a></li> <li><a href="http://poros.github.io/mum-nudges/">Migrations under monopoly: Nudges</a></li> <li><a href="http://poros.github.io/mum-the-fat-tail/">Migrations under monopoly: The fat tail</a></li> <li><a href="http://poros.github.io/mum-deprecation/">Migrations under monopoly: Deprecation</a></li> <li><a href="http://poros.github.io/migration-checklist/">The migration checklist</a></li> </ol> <div> <a href="http://poros.github.io/taxonomy-of-migrations/"> <img src="http://poros.github.io/assets/images/next_arrow.png" alt="Next"> <b><figcaption>Next</figcaption></b> <figcaption>A taxonomy of migrations</figcaption> </a> </div> <div> <h4>Related Posts</h4> <ul> <li> <a href="http://poros.github.io/migration-checklist/">The migration checklist </a> </li> <li> <a href="http://poros.github.io/mum-deprecation/">Migrations under monopoly: Deprecation </a> </li> <li> <a href="http://poros.github.io/mum-the-fat-tail/">Migrations under monopoly: The fat tail </a> </li> <li> <a href="http://poros.github.io/mum-nudges/">Migrations under monopoly: Nudges </a> </li> <li> <a href="http://poros.github.io/mum-automation/">Migrations under monopoly: Automation </a> </li> </ul> </div> <section> <p><img src="http://poros.github.io/assets/images/profile.jpg" alt="Antonio Uccio Verardi"> </p> <div> <h4>Antonio Uccio Verardi</h4> <p>from <a href="http://www.yelp.com/" target="_blank">yelp</a> import engineering_manager</p>  </div> </section> <section>    <a href="http://disqus.com/">comments powered by <span>Disqus</span></a> </section>  </div> </div></div>]]>
            </description>
            <link>http://poros.github.io/technology-migrations-series/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054689</guid>
            <pubDate>Wed, 11 Nov 2020 01:49:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Great Code Reviews‚ÄìThe Superpower Your Team Needs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25054556">thread link</a>) | @saranshk
<br/>
November 10, 2020 | https://shopify.engineering/great-code-reviews | <a href="https://web.archive.org/web/*/https://shopify.engineering/great-code-reviews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p>There is a general consensus that code reviews are an important aspect of highly effective teams. <a href="https://sail.cs.queensu.ca/Downloads/EMSE_AnEmpiricalStudyOfTheImpactOfModernCodeReviewPracticesOnSoftwareQuality.pdf" target="_blank" title="An Empirical Study of the Impact of Modern Code Review Practices on Software Quality" rel="nofollow noopener noreferrer">This research paper</a> is one of many exploring this subject. Most organizations undergo code reviews of some form.</p>
<p>However, it‚Äôs all too common to see code reviews that barely scratch the surface, or that offer feedback that is unclear or hard to act upon. This robs the team the opportunity to speed up learning, share knowledge and context, and raise the quality bar on the resulting code.</p>
<p>At Shopify, we want to move fast while building for the long term. In our experience, having strong code review practices has a huge impact on the growth of our engineers and in the quality of the products we build.</p>

<p>Imagine you join a new team and you‚Äôre given a coding task to work on. Since you‚Äôre new on the team, you really want to show what you‚Äôre made of. You want to perform. So, this is what you do:</p>
<ol>
<li>You work frantically on your task for 3 weeks.</li>
<li>You submit a Pull Request for review with about 1000 new lines of code</li>
<li>You get a couple comments about code style and a question that shows the person has no clue what this work is about.</li>
<li>You get approval from both reviewers after fixing the code style and answering the question.</li>
<li>You merge your branch into master, eyes closed, shoulders tense, grinding your teeth. After a few minutes, CI completes. Master is not broken. Yet.</li>
<li>You live in fear for 6 months, not knowing when and how your code will break.</li>
</ol>
<p>You may have lived through some of the situations above, and hopefully you‚Äôve seen some of the red flags in that process.</p>
<p>Let‚Äôs talk about how we can make it much better.</p>

<p>At Shopify, we value the speed of shipping, learning, and building for the long term. These values - which sometimes conflict - lead us to experiment with many techniques and team dynamics. In this article, I have distilled a series of very practical techniques we use at Shopify to ship valuable code that can stand the test of time.</p>
<p>A Note about terminology: We refer to Pull Requests (PR) as one unit of work that's put forth for review before merging into the base branch. Github and Bitbucket users will be familiar with this term.</p>
<h2>1. Keep Your Pull Requests Small</h2>
<p>As simple as this sounds, this is easily the most impactful technique you can follow to level up your code review workflow. There are 2 fundamental reasons why this works:</p>
<ul>
<li>It‚Äôs mentally easier to <strong>start and complete a review</strong> for a small piece. Larger PRs will naturally make reviewers delay and procrastinate examining the work, and they are more likely to be interrupted mid-review.</li>
<li>As a reviewer, it‚Äôs exponentially <strong>harder to dive deep</strong> if the PR is long. The more code there is to examine, the bigger the mental map we need to build to understand the whole piece.</li>
</ul>
<p>Breaking up your work in smaller chunks increases your chances of getting faster and deeper reviews.</p>
<p>Now, it‚Äôs impossible to set one universal standard that applies to all programming languages and all types of work. Internally, for our data engineering work, the guideline is around 200-300 lines of code affected. If we go above this threshold, we almost always break up the work into smaller blocks.</p>
<p>Of course, we need to be careful about breaking up PRs into chunks that are <strong>too small</strong>, since this means reviewers may need to inspect several PRs to understand the overall picture.</p>
<h2>2. Use Draft PRs</h2>
<p>Have you heard the metaphor of building a car vs. drawing a car? It goes something like this:</p>
<ol>
<li>You‚Äôre asked to build a car.</li>
<li>You go away for 6 months and build a beautiful Porsche.</li>
<li>When you show it to your users, they ask about space for their 5 children and the surf boards.</li>
</ol>
<p>Clearly, the problem here is that the goal is poorly defined and the team jumped directly into the solution before gathering enough feedback.If after step 1 we created a drawing of the car and showed it to our users, they would have asked the same questions and we would have discovered their expectations and saved ourselves 6 months of work. Software is no different‚Äîwe can make the same mistake and work for a long time on a feature or module that isn't what our users need.</p>
<p>At Shopify, it‚Äôs common practice to use <strong>Work In Progress (WIP) PRs</strong> to elicit early feedback whose goal is validating direction (choice of algorithm, design, API, etc). Early changes mean less wasted effort on details, polish, documentation, etc.</p>
<p>As an author, this means you need to be open to changing the direction of your work. At Shopify, we try to embrace the principle of <a href="https://engineering.shopify.com/blogs/engineering/scaling-mobile-development-by-treating-apps-as-services" target="_blank" title="Scaling Mobile Development by Treating Apps as Services - Shopify Engineering" rel="noopener noreferrer"><strong>strong opinions, loosely held</strong></a>. We want people to make decisions confidently, but also be open to learning new and better alternatives, given sufficient evidence. In practice, we use Github‚Äôs <strong>Draft PRs</strong>‚Äîthey clearly signal the work is still in flow and Github prevents you from merging a Draft PR. Other tools may have similar functionality, but at the very least you can create normal PRs with a clear <strong>WIP</strong> label to indicate the work is early stage. This will help your reviewers focus on offering the right type of feedback.</p>
<h2>3. One PR Per Concern</h2>
<p>In addition to line count, another dimension to consider is how many <em>concerns</em> your unit of work is trying to address. A concern may be a feature, a bugfix, a dependency upgrade, an API change, etc. Are you introducing a new feature while refactoring at the same time? Fixing two bugs in one shot? Introducing a library upgrade and a new service?</p>
<p>Breaking down PRs into individual concerns has the following effects:</p>
<ul>
<li>
<strong>More independent review units</strong> and therefore <strong>better review quality</strong>
</li>
<li>
<strong>Fewer affected people</strong>, therefore less domains of expertise to gather</li>
<li>
<strong>Atomicity of rollbacks,</strong>&nbsp;the ability of rolling back a small commit or PR. This is valuable because if something goes wrong, it will be easier to identify where errors were introduced and what to roll back.</li>
<li>
<strong>Separating easy stuff from hard stuff</strong>. Imagine a new feature that requires refactoring a frequently used API. You change the API, update a dozen call-sites, and then implement your feature. 80% of your changes are obvious and skimmable with no functional changes, while 20% are new code that needs careful attention to test coverage, intended behaviour, error handling, etc. and will likely go through multiple revisions. With each revision, the reviewer will need to skim through <em>all</em> of the changes to find the relevant bits. By splitting this in two PRs, it becomes easy to quickly land the majority of the work and to optimize the review effort applied to the harder work.</li>
</ul>
<p>If you end up with a PR that includes more than one concern, you can break it down into individual chunks. Doing so will accelerate the iteration cycle on each individual review, giving a faster review overall. Often part of the work can land quickly, avoiding code rot and merge conflicts.</p>
<p><img alt="Breaking down PRs into individual concerns" data-src="//cdn.shopify.com/s/files/1/0779/4361/files/Code_Reviews_at_Shopify_-_blog_article.jpg?v=1581342642" src="https://cdn.shopify.com/s/files/1/0779/4361/files/Code_Reviews_at_Shopify_-_blog_article.jpg?v=1581342642"></p>
<meta charset="utf-8">
<p><em>Breaking down PRs into individual concerns</em></p>
<p>In the example above, we‚Äôve taken a PR that covered three different concerns and broke it up. You can see how each reviewer has strictly less context to go over. Best of all, as soon as <em>any</em> of the reviews is complete, the author can begin addressing feedback while continuing to wait for the rest of the work. In the most extreme cases, instead of completing a first draft, waiting several days (and shifting focus), and then eventually returning to address feedback, the author can work almost continuously on their family of PRs as they receive the different reviews asynchronously.</p>
<h2>4. Focus on the Code, Not the Person</h2>
<p>Focus on the code, not the person practice refers to communication styles and relationships between people. Fundamentally, it‚Äôs about trying to focus on making the product better, and avoiding the author perceiving a review as personal criticism.</p>
<p>Here are some tips you can follow:</p>
<ul>
<li>As a reviewer, think, ‚ÄúThis is <strong>our</strong> code, how can we improve on it?‚Äù</li>
<li>Offer positive remarks! If you see something done well, comment on it. This reinforces good work and helps the author balance suggestions for improvement.</li>
<li>As an author, assume best intention, and don‚Äôt take comments personally.</li>
</ul>
<p>Below are a few examples of not-so-great review comments, and a suggestion on how we can reword to emphasize the tips above.</p>
<table>
<tbody>
<tr>
<td>

<strong>Less of These</strong>
</td>
<td><strong>&nbsp;More of These</strong></td>
</tr>
<tr>
<td>

Move this to Markdown</td>
<td>

How about moving this documentation into our Markdown README file? That way we can more easily share with other users.<strong></strong>
</td>
</tr>
<tr>
<td>

Read the Google Python style guidelines</td>
<td>

We should avoid single-character variables. How about board_size or size instead?</td>
</tr>
<tr>
<td>

This feels too slow. Make it faster. Lightning fast.</td>
<td>&nbsp;This algorithm is very easy to read but I‚Äôm concerned about performance. Let‚Äôs test this with a large dataset to gauge its efficiency.</td>
</tr>
<tr>
<td>

Bool or int?</td>
<td>

Why did you choose a list of bool values instead of integers?</td>
</tr>
</tbody>
</table>
<p><br>Ultimately, a code review is a learning and teaching opportunity and should be celebrated as such.</p>
<h2>5. Pick the Right People to Review</h2>
<p>It‚Äôs often challenging to decide who should review your work. Here are some questions can use as guidance:</p>
<ul>
<li>Who has context on the feature or component you‚Äôre building?</li>
<li>Who has strong skills in the language, framework, or tool you‚Äôre using?</li>
<li>Who has strong opinions on the subject?</li>
<li>Who cares about the result of what you‚Äôre doing?</li>
<li>Who should learn this stuff? Or if you‚Äôre a junior reviewing someone more senior, use this as an opportunity to ask questions and learn. Ask all the silly questions, a strong team will find the time to share knowledge.</li>
</ul>
<p>Whatever rules your team might have, remember that it is your responsibility as an author to seek and receive a high-quality code review from a person or people with the right context.</p>
<h2>6. Give Your Reviewers a Map</h2>
<p>Last but definitely not least, the description on your PR is crucial. Depending on who you picked for review, different people will have different context. The onus is on the author to help reviewers by providing key information or links to more context so they can produce meaningful feedback.</p>
<p>Some questions you can include in <a href="https://help.github.com/en/github/building-a-strong-community/creating-a-pull-request-template-for-your-repository" target="_blank" title="Creating a pull request template for your repository - GitHub" rel="nofollow noopener noreferrer">your PR templates</a>:</p>
<ul>
<li>Why is this PR necessary?</li>
<li>Who benefits from this?</li>
<li>What could go wrong?</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shopify.engineering/great-code-reviews">https://shopify.engineering/great-code-reviews</a></em></p>]]>
            </description>
            <link>https://shopify.engineering/great-code-reviews</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054556</guid>
            <pubDate>Wed, 11 Nov 2020 01:31:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Helped me be more Productive as a Software Developer]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25054231">thread link</a>) | @strikingloo
<br/>
November 10, 2020 | https://www.datastuff.tech/programming/productivity-software-developer-student/ | <a href="https://web.archive.org/web/*/https://www.datastuff.tech/programming/productivity-software-developer-student/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-884" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">
<div>

<div itemprop="text">

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@strikingloo">
<meta name="twitter:title" content="How I Stay Productive as a Software Developer">
<meta name="twitter:description" content="Imagine getting more stuff done, more effectively, in less time.">
<meta name="twitter:image" content="https://cdn.pixabay.com/photo/2020/11/04/19/22/windmill-5713337_1280.jpg">
<p>Imagine getting more stuff done, more effectively, in less time. That is how I will define productivity for the rest of this piece.</p>
<p>I‚Äôve been reading a lot of productivity articles, tips, tricks and Twitter threads. In a way, doing so is the worst kind of procrastination, entropy for entropy‚Äôs sake. But every once in a while you‚Äôll glean some gold nugget among the rubble, and it will all be worth it.</p>
<p>This is my attempt at recollecting what nuggets I found. On each section I will:</p>
<ul><li>Cite sources I found interesting or relevant.</li><li>Mention whether the methods have worked for me and what exact impact they‚Äôve had.</li></ul>
<p>I will add a big caveat though: I think every person‚Äôs optimal productivity engine should be different. Thus, all of this advice should be taken, tested, and left to rot if it doesn‚Äôt work for you. And that pretty much applies to all other posts of this kind, in any blog ever, in my opinion.</p>
<p>Without further ado, here are the things I‚Äôve seen actually work to make me get more stuff done, or stay less stressed.</p>
<h2>Reduce cognitive load</h2>
<p>Cognitive load is a beautiful term. It roughly means ‚ÄúHow full is your mind‚Äôs RAM?‚Äù. </p>
<p>Whenever you‚Äôre thinking of the next 5 things you have to do, your groceries list, and whether you left the stove on, you‚Äôre carrying cognitive load.</p>
<p>It should be evident, but cognitive load stresses you out. Reducing it can help you better focus on your task.</p>
<p>Here‚Äôs what has worked for me on this account:</p>
<ul><li>Keep a clean room, office and desk<sup><a href="#fn1">1</a></sup>. You shouldn‚Äôt have trouble finding anything you use often, and the things you use the most often should be very easy to reach. This also applies to your filesystem, bookmarks system, etc. If you know you‚Äôll want to check a certain link again in the future, bookmark it under an intuitive path. Don‚Äôt find yourself looking for it through your twitter feed.</li><li>If something‚Äôs on your mind and it‚Äôs not useful to keep thinking of it, <strong>write it down and forget it</strong>. You can look it up later. </li></ul>
<p>Take this article, for instance: instead of pestering myself thinking ‚ÄòYou have to write that article!‚Äô I just added an item on my Trello backlog that said ‚Äòarticle on productivity‚Äô and forgot about it until I had free time again and checked.</p>
<p>My own setup for task tracking is a combination of Trello for daily/weekly tasks and a Google sheet for long term stuff -like a deferred backlog- but really, every person has their own perfect combination of tools and processes. Find your own. </p>
<p>I know many people who prefer physical post-its, or a board. I‚Äôd rather get the portability of a browser app and the tracking for future reference. This is especially good if you also practice journaling, because then it‚Äôs just ‚ÄúWhat did I do today? Oh ok I‚Äôll check today‚Äôs cards‚Äù. Still, your mileage will vary, so try many things and see what works best for you.</p>
<h2>Keep productive habits</h2>
<blockquote><p>‚Ä¶Watch your actions, they become your habits; watch your habits, they become your character; watch your character, it becomes your destiny.‚Äù</p><cite><em>‚Äï&nbsp;</em><strong>Lao Tzu</strong></cite></blockquote>
<p>Some people recommend this book called ‚ÄúAtomic Habits‚Äù. I won‚Äôt lie, I haven‚Äôt read it. But I read a good summary on reddit and agree with most of it, thought I was already kind of doing most of what it talks about.</p>
<p>The gist of it is: don‚Äôt try to build productivity on its own, build systems that incentivize you to be productive.</p>
<p>Some people use pomodoros, others prefer to put on noise-blocking headphones; I personally prefer to hide my cell phone until I have got enough stuff done. </p>
<p>My technique for this is simple: every month, (or use whatever time frame works for you), I decide which routines I will keep.</p>
<p>Right now for instance, my routines are:</p>
<ul><li>Exercise 4 times a week.</li><li>Do everything I have to for work and school, obviously.</li><li>Journal every night</li><li>2 hours of Japanese study every day</li></ul>
<p>The painful side of having a very clear set of goals and habits is: you‚Äôre extremely accountable to them. Is the day ending and you haven‚Äôt done your daily study session? You better get down to it right now. </p>
<p>In my case, my own conscience is a harsh enough mistress, but if you are not that hard on yourself when your to-do lists have uncrossed items, you may want to try something like </p>
<ul><li>Asking your SO to make passive aggressive remarks to you if you don‚Äôt finish your tasks.</li><li>Reward yourself with something sweet.</li><li>Going full monk-mode and forfeiting cell phone time until everything is done.</li></ul>
<p>Now for the flip side: you‚Äôre accountable for your tasks, yes, but you also set them. So whenever you define what your habits will be, don‚Äôt overestimate yourself. It‚Äôs better to have realistic, achievable goals that fall a bit short of your <em>maximum effort</em>, than it is to overstep, burn out or just not build the habits because you can‚Äôt keep up with them. </p>
<p>Did you underestimate your time management skills and now you‚Äôre doing everything you planned for <em>and</em> then get a lot of free time anyway? Cool! You get to feel productive <em>and</em> have free time. </p>
<p>You definitely don‚Äôt want to optimize for minimum free time. It sounds obvious, but I‚Äôve caught myself and others doing this without realizing it.</p>
<p>The devil doesn‚Äôt always make work with idle hands.</p>
<p>Another thing about incentives: this ties to the ‚Äúunclutter‚Äù rule I mentioned earlier, but do try to turn everything around you into a big <strong>habit-keeping engine</strong>. </p>
<p>For instance, if your goal is to read a book every week, have your book on sight and within arm‚Äôs reach at all times. Carry it on your suitcase/backpack, take it out instead of your cell phone when you want to procrastinate, etc. </p>
<p>You‚Äôll be surprised by how much stuff you get done when <strong>everything around you is making you do it</strong>.</p>
<p>For a small guide on creating habits that I found interesting (though maybe more complicated than necessary) see <a href="https://www.lesswrong.com/posts/vE7Z2JTDo5BHsCp4T/instrumental-rationality-4-2-creating-habits">creating habits</a>.</p>
<h2>Don‚Äôt use your head for things a PC was made for</h2>
<p>Really though, remember what I said about cognitive load? Defining daily goals is not cool if you end up spending 5 minutes every hour thinking ‚Äúok what comes next? I already crossed my Chinese practice and my Economics lecture, what was the next item?‚Äù. </p>
<p>You want whatever system you build to be maintainable in the long run, so you should make it as easy to consult as possible, and not depend on a very fallible piece of architecture (your head).</p>
<p>So keep everything written down, on a nice .txt file, a Google doc, a sheet, etc. Use whatever you like, but not your head. Really it‚Äôs that simple, and it works. </p>
<p>(Aside: I am not going into detail into different tools or task tracking systems because honestly? There are like 20 different articles on this topic posted on HackerNews every week, and they‚Äôre all the same).</p>
<h2>Effective Note Taking</h2>
<p>This is all I have to say about note taking.</p>
<p>I am not a very note taking inclined person. I started this particular habit this year, and even though it <em>feels</em> productive, I don‚Äôt feel like I can quite say it has actually made me perform better yet.</p>
<p>So my first tip on this will be: <strong>don‚Äôt take notes if you don‚Äôt think it will be worth it</strong>. Some people retain information better when they take notes, I am not one of those people but if you are, then that piece of advice doesn‚Äôt apply to you. Remember when I said systems needed to be custom?</p>
<p>I also say this because I see there‚Äôs this trend in the internet of ‚Äúwrite everything down, take all the notes!‚Äù and I think we‚Äôre tending towards an excessive ‚Äúpro-notes-taking‚Äù bias, which may be unwarranted.</p>
<p>Secondly: if you are not writing everything down, how do you decide what should be kept? Well, I‚Äôm open to better ideas, but in my case I optimize for (estimated) <strong>future searchability</strong>: is what I just read, heard or watched something I am <strong>likely to think of in the future</strong>? And maybe I will want to recall it exactly and won‚Äôt be able to? Well then, into the notes it goes.</p>
<p>Note that it doesn‚Äôt need to be a relevant piece of information per se. I take notes about interesting history facts, anime trivia and weird Japanese words, not because they‚Äôll come up in my final exams (fingers crossed) or, gods forbid, my job. I keep those quotes and facts around because they may come up in conversation.</p>
<p>Generally though, I think the category that makes the best notes is ‚Äúthings that I am likely to forget and look up again in the future, but I don‚Äôt care to learn by heart right now‚Äù. </p>
<p>This includes things like very specific facts about a domain, convoluted bash commands that you put into a script to not have to remember again (but want to persist somewhere else in case you want them on a different pc), or syntax details in a programming language.</p>
<p>I will be reading an article and think ‚Äúoh, $FRIEND_X surely would find this very funny‚Äù and just write it down. And then I may send it to them through IM, but let‚Äôs be honest I could forget‚Ä¶ until I reread my notes in the future.</p>
<p>Oh, the topic of rereading notes. This one is a tricky bit I haven‚Äôt mastered yet, and I am also open to suggestions in this area. Personally, I only reread notes on technical topics whenever they come up and I want to refresh my memory, and any other topic if I am thinking of it.</p>
<p>I know some people like to go through all of their notes every X time and they say it improves their creativity and gets the writing juices flowing. I am not super concerned about my creativity or writing right now (in case my one year posting-gap didn‚Äôt make that clear), but I will definitely experiment with that in the future (and write about it if I get any relevant results).</p>
<p>Lastly, I‚Äôve recently been using a <strong>personal wiki</strong> for some of my notes (only the polished, public-facing ones), and it‚Äôs really cool, but it just reinforces point one: I feel like part of why I use a personal wiki is just that it feels nice, and I haven‚Äôt yet seen a lot of improvement over a simple Evernote or Google Docs. Maybe it‚Äôs a matter of scale and the effects won‚Äôt be apparent until a few years in? We will see.</p>
<h2>Anki and SRS for studying and productivity.</h2>
<blockquote><p><strong>Anki makes memory a choice</strong>, rather than a haphazard event, to be left to chance.</p><cite>Michal ‚Ä¶</cite></blockquote></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.datastuff.tech/programming/productivity-software-developer-student/">https://www.datastuff.tech/programming/productivity-software-developer-student/</a></em></p>]]>
            </description>
            <link>https://www.datastuff.tech/programming/productivity-software-developer-student/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054231</guid>
            <pubDate>Wed, 11 Nov 2020 00:47:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PilferShush Jammer]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25054222">thread link</a>) | @karlzt
<br/>
November 10, 2020 | https://www.cityfreqs.com.au/pilfer.php | <a href="https://web.archive.org/web/*/https://www.cityfreqs.com.au/pilfer.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
            Basic information about how the SDKs code function. They start with a call to the Android/Java API that deals with audio recording and playback. From there with a buffer array full of some audio data, it can then be sent to a native code library that is also installed as part of the SDK. These libraries handle the more CPU intensive work such as sifting through the data using various common methods (Goertzel et al) to find audio signals of interest. 
            </p><p>
            This first section shows some of the Android/Java function calls and parameters used.
            </p><p>
							<strong>alphonso</strong>
              <br>
              ALPHONSO_VERSION = "2.0.46";
              </p><pre>    private static final int RECORDER_AUDIO_BYTES_PER_SEC = 16000;
    private static final int RECORDER_AUDIO_ENCODING = 2;
    private static final int RECORDER_BIG_BUFFER_MULTIPLIER = 16;
    private static final int RECORDER_CHANNELS = 16;
    private static final int RECORDER_SAMPLERATE_44100 = 44100;
    private static final int RECORDER_SAMPLERATE_8000 = 8000;
    private static final int RECORDER_SMALL_BUFFER_MULTIPLIER = 4;
    public static final byte ACR_SHIFT_186 = (byte) 0;
    public static final byte ACR_SHIFT_93 = (byte) 1;
    public static final int ACR_SPLIT = 2;</pre>

              <p><strong>bitsound</strong>
              <br>
              VERSION_NAME = "v4.2.2"
              </p><pre>    public void a(int i) {
      try {
        this.d = new AudioRecord(6, this.b, 16, 2, i);
        if (this.d.getState() == 1) {
          try {
            this.d.startRecording();
            if (this.d.getRecordingState() != 3) {
              b.c(a, "Audio recording startDetection fail");
              this.d.release();
              this.e = false;
              return;
            }
            a(this.d);
            this.e = true;
            return;</pre>
            
              <p><strong>cifrasoft</strong>
              <br>
              VERSION_NAME = "1.0.3"
              </p><pre>    public static final int AUDIO_BUFFER_SIZE_MULTIPLIER = 4;
    public static final int AUDIO_THREAD_STOP_TIMEOUT = 3000;
    public static final int MAX_EMPTY_AUDIO_BUFFER_SEQUENTIAL_READS = 10;
    this.SAMPLE_RATE = 44100;</pre>
    
              <pre>    private int readAudioData(int currentPcmOffset, byte[] pcm) {
      AudioRecordService.handler.sendEmptyMessageDelayed(1, 3000);
      int result = this.mAudioRecord.read(pcm, currentPcmOffset * 2, this.bufferLength * 2);
      AudioRecordService.handler.removeMessages(1);
      return result;
    }</pre>

              <p><strong>copsonic</strong>
              <br>
              CORE_VERSION = "SonicAuth_CORE_v1.2.2.1";
              </p><pre>    "signalType": "ULTRASONIC_TONES",
    "content" : {
        "frequencies" : [ [18000, 20000, "TwoTones"] ]

    "signalType": "ZADOFF_CHU",
    "content": {
      "config": {
        "samplingFreq": 44100,
        "minFreq": 18000,
        "maxFreq": 19850,
        "filterRolloff": 0.5,
        "totalSignalTime": 0.3,
        "nMsgSymbols": 2,
        "filterSpan": 8
      },
      "set": {
        "centralFreq": 18925,
        "nElemSamples": 36,
        "nSymbolElems": 181</pre>

              <p><strong>dv (dov-e)</strong>
              <br>
              VERSION_NAME = "1.1.7"
              </p><pre>    private void recorderWork() {
      if (this.recordingActive) {
        int bytesReadNumber = this.myRecorder.read(this.myBuffer, 0, this.myBuffer.length);
        if (this.recordingActive) {
          DVSDK.getInstance().DVCRxAudioSamplesProcessEvent(this.myBuffer, 0, bytesReadNumber / 2);
        }
      }
    }</pre>
    
              <p><strong>fanpictor</strong>
              <br>
              VERSION_NAME = "3.2.3"
              </p><pre>    enum FNPFrequencyBand {
      Default,
      Low,
      High
    }
              </pre>

              <p><strong>fidzup</strong></p><pre>    a. this.frequency = paramBasicAudioAnalyzerConfig.frequency;   // 19000.0f
    b. this.samplingFrequency = paramBasicAudioAnalyzerConfig.samplingRate;    // 44100.0f
    c. this.windowSize = paramBasicAudioAnalyzerConfig.windowSize;   // 0x200 (512)
    d. /* pulseDuration = 69.66f */
    e. this.pulseWidth = Math.round(paramBasicAudioAnalyzerConfig.pulseDuration * (this.samplingFrequency / 1000.0F));
    f. this.pulseRatio = paramBasicAudioAnalyzerConfig.pulseRatio;   // 32.0f
    /* signalSize = 0x20 (32)
    g. this.signalPeriodPulses = paramBasicAudioAnalyzerConfig.signalSize;
    h. this.bitCounts = paramBasicAudioAnalyzerConfig.bitcounts;   // 0xb (11)</pre>         
            <pre>    paramf.a = 19000.0F;            
    paramf.b = 44100.0F;            
    paramf.c = 512;                 
    paramf.d = 69.66F;              
    paramf.e = 0.33333334F;         
    paramf.f = ((int)(paramf.d * 32.0F * 3.2F)); // 7133.184
    paramf.g = 32;                 
    paramf.h = new int[] { 15, 17, 19, 13, 11, 21, 23, 9, 7, 25, 27 };</pre>             

              <p><strong>fluzo</strong>
              <br>
              VERSION = "1.3.001"</p><pre>    this.p = jSONObject.getInt("frame_length_milliseconds");
    this.q = jSONObject.getInt("frame_step_milliseconds");
    this.r = (float) jSONObject.getDouble("preemphasis_coefficient");
    this.s = jSONObject.getInt("num_filters");
    this.t = jSONObject.getInt("num_coefficients");
    this.u = jSONObject.getInt("derivative_window_size");</pre>
    
              <p><strong>instreamatic</strong>
              <br>
              VERSION_NAME = "7.16.0"</p><pre>    private static final int BUFFER_SECONDS = 5;
    private static int DESIRED_SAMPLE_RATE = 16000;</pre>
 
              <p><strong>lisnr</strong>
              <br>
              VERSION_NAME = "5.0.1.1";
              </p><pre>    // LisnrIDTone          
    public long calculateToneDuration() {
        return ((long) (((double) (this.lastIteration + 1)) * 2.72d)) * 1000;
    }
    // LisnrTextTone
    public long calculateToneDuration() {
        return (long) (((this.text.length() * 6) * 40) + 1280);
    }
    // LisnrDataTone
    public long calculateToneDuration() {
        return (long) (((this.data.length * 6) * 40) + 1280);
    }
    AudioRecord audioRecord = new AudioRecord(0, d, 16, 2, 131072);</pre>  

              <pre>    ArrayAudioPlayer.this.audioOutput = new AudioTrack(3, ArrayAudioPlayer.this.samplerate, 4, 2, 16000, 1);
    ArrayAudioPlayer.this.audioOutput.play();
    int written = 0;
    while (!ArrayAudioPlayer.this.threadShouldStop) {
      try {
        if (ArrayAudioPlayer.this.buffer.getBufferLeftToRead() &gt; 0) {
          int size = ArrayAudioPlayer.this.buffer.getBufferLeftToRead();
          written += size;
          ArrayAudioPlayer.this.audioOutput.write(ArrayAudioPlayer.this.buffer.readFromBuffer(size), 0, size);
          } else {
            ArrayAudioPlayer.this.threadShouldStop = true;
          }
        } catch (IOException e) {
          e.printStackTrace();
        }</pre>
        
              <p><strong>moodmedia</strong>
              <br>
              getVersion() = "1.2.1";
              </p><pre>    b = new AudioRecord(5, 44100, 16, 2, Math.max(AudioRecord.getMinBufferSize(44100, 16, 2) * 4, 32768));
    this.b = Type.SONIC;
    this.b = Type.ULTRASONIC;
    if (num.intValue() == 44100 || num.intValue() == 48000)
    this.j.setName("Demodulator");
    this.k.setName("Decoder");
    this.l.setName("HitCounter");
              </pre>
 
              <p><strong>prontoly (sonarax)</strong>
              <br>
              VERSION_NAME = "4.2.0";
             </p><pre>    contentValues.put("time", cVar.a);
    contentValues.put("type", cVar.b.name());
    contentValues.put(NotificationCompat.CATEGORY_EVENT, cVar.c);
    contentValues.put("communication_type", cVar.d);
    contentValues.put("sample_rate", cVar.e);
    contentValues.put("range_mode", cVar.f);
    contentValues.put("data", cVar.g);
    contentValues.put("duration", cVar.h);
    contentValues.put("count", cVar.i);
    contentValues.put("volume", cVar.j);</pre>
    
              <p><strong>realitymine</strong>
              <br>
              getSdkVersion = "5.1.6";
              </p><pre>    this.e = AudioRecord.getMinBufferSize(44100, 16, 2);
    int i = this.e;
    this.d = new byte[i];
    this.c = new AudioRecord(1, 44100, 16, 2, i);</pre>

              <p><strong>redbricklane (zapr)</strong>
              <br>
              SDK_VERSION = "3.3.0";
              </p><pre>    AudioRecord localAudioRecord = new AudioRecord(1, 8000, 16, 2, 122880);
    if (localAudioRecord.getState() == 1) {
      this.logger.write_log("Recorder initialized", "finger_print_manager");
      this.logger.write_log("Recording started", "finger_print_manager");
      localAudioRecord.startRecording();</pre>

              <p><strong>runacr</strong>
              <br>
              release = "1.0.4"
              </p><pre>    int minBufferSize = AudioRecord.getMinBufferSize(11025, 16, 2);
    this.K = new AudioRecord(6, 11025, 16, 2, minBufferSize * 10);</pre>

              <p><strong>shopkick</strong></p><pre>    .field bitDetectThreshold:Ljava/lang/Double;
    .field carrierThreshold:Ljava/lang/Double;
    .field detectThreshold:Ljava/lang/Double;
    .field frFactors:Ljava/lang/String;
    .field gapInSamplesBetweenLowFreqAndCalibration:Ljava/lang/Integer;
    .field maxFracOfAvgForOne:Ljava/lang/Double;
    .field maxIntermediates:Ljava/lang/Integer;
    .field minCarriers:Ljava/lang/Integer;
    .field noiseThreshold:Ljava/lang/Double;
    .field numPrefixBitsRequired:Ljava/lang/Integer;
    .field numSamplesToCalibrateWith:Ljava/lang/Integer;
    .field presenceDetectMinBits:Ljava/lang/Integer;
    .field presenceNarrowBandDetectThreshold:Ljava/lang/Double;
    .field presenceStrengthRatioThreshold:Ljava/lang/Double;
    .field presenceWideBandDetectThreshold:Ljava/lang/Double;
    .field useErrorCorrection:Ljava/lang/Boolean;
    .field wideBandPresenceDetectEnabled:Ljava/lang/Boolean;
    .field highPassFilterType:Ljava/lang/Integer;</pre>
              <pre>    Java_com_shopkick_app_presence_NativePresencePipeline_setDopplerCorrectionEnabledParam
    Java_com_shopkick_app_presence_NativePresencePipeline_setHighPassFilterEnabledParam
    Java_com_shopkick_app_presence_NativePresencePipeline_setWideBandDetectEnabledParam
    Java_com_shopkick_app_presence_NativePresencePipeline_setNumPrefixBitsRequiredParam
    Java_com_shopkick_app_presence_NativePresencePipeline_setPresenceDetectNarrowBandDetectThresholdFCParam
    ‚Ä¶</pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cityfreqs.com.au/pilfer.php">https://www.cityfreqs.com.au/pilfer.php</a></em></p>]]>
            </description>
            <link>https://www.cityfreqs.com.au/pilfer.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054222</guid>
            <pubDate>Wed, 11 Nov 2020 00:46:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eddie's Ink Chip Hack (2002)]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25054177">thread link</a>) | @userbinator
<br/>
November 10, 2020 | http://www.eddiem.com/photo/CIS/inkchip/chip.html | <a href="https://web.archive.org/web/*/http://www.eddiem.com/photo/CIS/inkchip/chip.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<tr>
<td>
<p lang="en-GB"><a href="http://www.eddiem.com/photo/CIS/cis.htm">My CIS page.</a></p></td>
<th>
<p lang="en-GB"><img alt="" src="http://www.eddiem.com/photo/CIS/inkchip/inkchip.JPG" name="Graphic2" width="401" height="400"></p></th>
<td>
<p lang="en-GB"><a href="http://www.eddiem.com/photo/printer/chipreset/resetchip.html">Part
				2 build your own reseter</a></p></td></tr>
<tr>
<td colspan="3">
<p lang="en-GB"><strong>What is a Intellidge ink chip.</strong><span size="5"><br>
</span>Epson fit
				small circuit boards to most of their ink cartridges. These
				record the amount of ink that is estimated to be in the
				cartridge. I read that the official epson line is that it is for
				the customers benefit and not an anti-refill device. Whether you
				believe this or not they are a bloody nuisance to anyone wanting
				to refill the cartridges or use bulk ink. It also stops people
				using old cartridges full of solvent for cleaning the heads.
				Another problem was early printer models didn't check if the
				cartridge had been changed while power was on. This was good if
				you wanted to trick the printer into copying a ‚Äúfull‚Äù
				chip to and empty one, however the reverse was also true and you
				could easily copy and ‚Äúempty‚Äù one into your full
				one.<br>
They are just a small memory device holds 32 bytes of
				data, they do not measure real ink level and nor does the
				printer. The printer reads the chips on startup, estimates
				(sometimes badly) how much ink should have been used and writes
				this back at shutdown. They hold other data as well.<br>
So epson
				go to the trouble of fitting chips to cartridges and building all
				the extra sockets, wiring, electronics and software into the
				printer so you can use the computer to see the predicted level
				and it can stop you printing if it think you've used enough ink.
				High-end Canon's on the other hand make the inks tank clear so
				you can see and have optical sensor to detect emptiness. This
				make a lot more sense ‚Äì unless you are making an
				anti-refill device that is. Canon almost got my business this
				time but nobody I could find has run pigment in them ‚Äì too
				risky.<br>
To get around the chip problems someone usually end up
				producing read-only chip which always read full (for use with
				CIS) and chip reseters for those who want to refill. These are
				not available for 2100p at the time of writing as far as I can
				tell.<br>
Before ordering my 2100p I did my homework and it seemed
				fairly likely a chip reseter would become available at some point
				and read-only chips as well. I was also cocky enough to think I
				could crack it myself and I have. It didn't go quite as expected
				though.<br>
<strong>What do I want to do?</strong><br>
I want the easiest way
				to fool the printer into believing it has full cartridges present
				so I can build my CIS.<br>
<strong>What did I expect?</strong><br>
A logical
				interface for Intellidge is i2c (i squared c) or TWI (two wire
				interface). Then the chip could just be some standard i2c eeprom.
				The Intellidge have too many pads for this but I was hopeful.
				After that would could SPI or microwire ‚Äì again this could
				use off the shelf parts. If the chips were micro-controllers then
				plain asynchronous serial would be my choice.<br>
<strong>I had a
				look.</strong><br>
To do this I use a AVR mega323 micro, I declined
				offers of logic analyzers being a homebrew type of guy. The 323
				has 2K of internal ram which is enough for some minimalist data
				logging. It was about $50AUS in parts ($30US) to make. I wired a
				cartridge to bring the signals out and took a quick look with a
				voltmeter.<br>
<strong>Nothing!</strong><br>
There was nothing there. I
				expected some power but no, the chips are only powered briefly
				when the are accessed. I used leds to get a rough idea what was
				what and hooked up the micro via resistors to give some degree of
				protection to the printer if I screwed up. The code in the micro
				was written is assembler and captured data sent via rs232 to my
				PC where I wrote a delphi program to display and process the
				data.</p></td></tr>
<tr>
<td colspan="3">
</td></tr>
<tr>
<td colspan="3">
<p lang="en-GB"><a href="http://www.eddiem.com/photo/CIS/inkchip/traces.html"><img alt="" src="http://www.eddiem.com/photo/CIS/inkchip/fastendsml.gif" name="Graphic5" width="615" height="213"></a><br>
<a href="http://www.eddiem.com/photo/CIS/inkchip/traces.html">Click
				here for more traces.</a></p>
<p lang="en-GB">This is the sort of thing I got. No
				protocol I ever seen. Obviously synchronous with bi-directional
				data, very short format. I was confused a little by how short it
				was - because I expect much better precision for the ink
				level.<br>
The traces seem to be.<br>
Top ‚Äì some sort of sync
				line, this always goes low before the start of transmission.<br>
Next
				‚Äì power this goes low (off) between chip reads at printer
				startup but stays high during the shutdown ‚Äì when data is
				written to the chip.<br>
Next ‚Äì the clock, data is read of
				the rising edge and changed on the falling.<br>
Bottom ‚Äì
				bi-directional data, the first 4 bits are always from printer to
				the chip, the rest depend on whether it is a read or write. LSB
				first (left).</p></td></tr>
<tr>
<td colspan="3">
<p lang="en-GB">Convert to binary and some patterns emerge.<br>
It
				was not real obvious how the chips were addressed or which bits
				encoded ink levels. Some more data when some ink had been used
				made it easier.</p>
<p lang="en-GB">Below is one chip being read at startup, there
				are 7 accesses one for each chip. Only 3 block have data ‚Äì
				the other chips must be hooked to different data lines.</p>
<div lang="en-GB"><p><img alt="" src="http://www.eddiem.com/photo/CIS/inkchip/strtbinary.gif" name="Graphic6" width="818" height="45"></p></div></td></tr>
<tr>
<td colspan="3">
<p lang="en-GB">Below is the complete shutdown stream. Again we
				can only see 3 chips from here.</p>
<p lang="en-GB"><img alt="" src="http://www.eddiem.com/photo/CIS/inkchip/endbinary.gif" name="Graphic7" width="297" height="199"><br clear="left">
After
				printing a few bits near the beginning of the bit stream did
				change. It looks to me like the first 3 bits are the chip address
				the next is a write bit then the ink level, I get the feeling
				there aren't many bits used to encode it (later looks like 6).<br>
So
				‚Äì the top one shows 252 bits of data being read out of the
				chip.<br>
The first part of the shutdown shows just the ink level
				being read out, this is to check the same chip is there.<br>
The
				second part is the ink-level and some other stuff (printer serial
				number maybe) being written into the chip. Seeing I didn't use
				any ink the bit-stream is identical to the read except for bit 3
				‚Äì presumably the write bit.</p></td></tr>
<tr>
<td colspan="3">
<p lang="en-GB"><span size="5"><br>
Tuesday
				24 Sept 2002. I fooled the printer.</span></p></td></tr>
<tr>
<td colspan="3">
<p lang="en-GB"><img alt="" src="http://www.eddiem.com/photo/CIS/inkchip/spoofed.gif" name="Graphic8" width="381" height="363"><span size="3">The
				interesting thing about this screen grab is the black cartridge
				is really only two thirds full. I spoofed the printer by pulling
				the serial data line low during the time the ink level bits are
				being clocked out of the ink chip.<br>
This is means 6 bits
				starting at the 5'th bit in the stream.</span></p>
<p lang="en-GB"><span size="3">The first 3 bits appear to be the
				chip address, I guess the next is a read/write select. I used a
				AVR mega323 to detect the start of the serial transmission look
				for the address of chip1+read (black apparently) then pull data
				low for 6 clock edges. </span></p>
<p lang="en-GB"><span size="3">I'm sure I can reset 3 of the chips
				by tapping into chip1 signal. Reseting the rest will mean tapping
				into at least one more. </span></p>
<p lang="en-GB"><span size="3">The current set up is for
				experimentation only ‚Äì it is not ‚Äúthe real thing‚Äù.</span></p>
<p lang="en-GB"><span size="3">Shorting the data to ground may be a
				bit drastic but it is only for a very brief time. I hoped the
				data line would be open collector but this doesn't seem to be the
				case.</span></p></td></tr></div></div>]]>
            </description>
            <link>http://www.eddiem.com/photo/CIS/inkchip/chip.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054177</guid>
            <pubDate>Wed, 11 Nov 2020 00:41:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nadia Eghbal on working (and writing) in public]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25053962">thread link</a>) | @jger15
<br/>
November 10, 2020 | https://www.thepullrequest.com/p/nadia-eghbal | <a href="https://web.archive.org/web/*/https://www.thepullrequest.com/p/nadia-eghbal">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3b69c75-0c5b-4746-b998-5b41a1064a8d_900x1200.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3b69c75-0c5b-4746-b998-5b41a1064a8d_900x1200.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/a3b69c75-0c5b-4746-b998-5b41a1064a8d_900x1200.jpeg&quot;,&quot;height&quot;:1200,&quot;width&quot;:900,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:399616,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p><em>                                                                                              Portrait by <a href="https://www.katiasobolski.com/">Katia Sobolski</a>.</em></p><p><strong>Nadia Eghbal is uniquely positioned to write about open source having spent almost two years in developer relations at the Alexandrian library of open source, GitHub. She then spent two years continuing her quasi-anthropological study of open source at Protocol Labs, and now works in writer relations at Substack (host of this publication). Her new book is <a href="https://www.amazon.com/Working-Public-Making-Maintenance-Software/dp/0578675862/">Working in Public: The Making and Maintenance of Open Source Software</a>, which like her career trajectory, starts in open source software but ends up grappling with larger issues of creators in an unbundled digital economy. </strong><em><strong><a href="https://pullrequest.substack.com/p/the-glory-of-achievement">The Pull Request</a></strong></em><strong><a href="https://pullrequest.substack.com/p/the-glory-of-achievement"> review is here</a>.</strong></p><p><em>AGM: My naive mental model of open-source was this almost communitarian kibbutz model. And yet, the big lesson from your book is that that‚Äôs not really how it works. </em></p><p>NE: Part of the reason why I wrote this book was because I feel like we've had this communitarian kibbutz kind of model, which you've identified, is the prevailing model that people understand in open source and that gets frequently talked about. And I think that narrative has kind of been owned by the likes of [Richard] Stallman or Eric Raymond or anyone who kind of remembers those early days of open source. And that model definitely still exists within the matrix of different community models. The ‚Äòclubs‚Äô are kind of like that, where everyone is rolling up their sleeves and there's lots of different active contributors. And then we also have  the ‚Äòfederations‚Äô that are kinda like the really big open source projects that we're used to thinking about like Linux, but then there‚Äôs the rise of the ‚Äòstadium‚Äô model that is, I think, much newer.</p><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8c16a1d6-74cc-4eab-9640-b6dd860b29cb_934x408.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8c16a1d6-74cc-4eab-9640-b6dd860b29cb_934x408.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/8c16a1d6-74cc-4eab-9640-b6dd860b29cb_934x408.png&quot;,&quot;height&quot;:408,&quot;width&quot;:934,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:57769,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></p><p><em>The Eghbal model of open-source communities (referenced copiously here), whose contours are readily applicable more broadly.</em></p><p>If you look at what's happened to open source for the past 20 years, at some point demand outpaced supply and the amount of context that anyone can really have around any one open source project‚Äîbecause every developer is relying on like hundreds of different projects‚Äîit's not really possible to become this roll-up-your-sleeves member of every single project. And so, yeah, I think the governance does look really different and it‚Äôs specifically something that I didn't want to bang people over the head about it in the book. But I think a stadium model lends itself a little bit more to that kind authoritarian model and there‚Äôs less the kind of governance issues that we see in like a federation where people are like <em>this is a democracy!</em> and everyone is gonna ask everyone for opinions and stuff even if you might only have one or a few contributors. The contributors [in a stadium] are kind of just making the decisions and I think they should feel comfortable leaning into that. Even though right now I think a lot of them feel uncomfortable doing that because they keep being told that open source is supposed to this super participatory thing.</p><p><em>AGM: And you think that it doesn't necessarily have to be.</em></p><p>NE: I think the tension in one of these stadium models is where you do have a lot of users. And then you have some of these casual contributors who are opening issues, making feature requests or just lost, and you are kind of sorting through all that volume from people that you don't know. In my view, it's kind of like, well, I don't understand why should that person have a say in your project, if they've never looked at it before, and they're just kind of coming in for the first time and you're the core developer of the project. </p><p>There is a set of rhetoric in open source that says every person is a contributor, and anyone who kind of comes in, you should treat them as a contributor and like invest in them and all this stuff, but I don't feel like we would do that for anything else. If you had a hobby meetup kind of group with you and your friends and someone came in once and then was like <em>I think we should runs a group like this</em>, you'd be like: W<em>ho are you?</em> <em>This is this is our thing. </em>I think I want people to feel more comfortable saying that. And there's obvious parallels between that and the Internet at large right now.</p><p><em>AGM: You took the words right out of my mouth. In the book, you‚Äôve got a long riff on the <a href="https://en.wikipedia.org/wiki/Tragedy_of_the_commons">tragedy of the commons</a>. Not that I want to turn this interview into a Facebook thing, because having worked there and spent part of my career on it, it's like the last thing I want to talk about‚Ä¶but I do think it's somewhat relevant in that, Twitter or Facebook, is it actually the public forum and a commons? Can Zuck or Jack run it as you suggest? Can they run it like [Guido] van Rossum does Python, as officially-titled Benevolent Dictator For Life? In some sense that‚Äôs actually better? </em></p><p>NE: Yeah. Well, I don't think Facebook is a commons anymore, just by sheer size that we‚Äôre dealing with. One of the things that I'm trying to do in the book is go back through Elinor Ostrom‚Äôs definition of a commons and saying, okay, she makes the argument that we can avoid this tragedy of the commons by having people self govern. But she has very specific rules that she's laid out around what actually qualifies something as a commons, so we can self govern in a healthy way, assuming these conditions hold and a lot of those conditions have to do with having clear membership boundaries and very high context for your interactions with each other. And so if you think just about Facebook being 2.6 billion people or however many people are on Facebook now, it's impossible that literally multiple billions of people all have that kind of context for each other. I think of Facebook as being this substrate that fosters a bunch of smaller communities. You might have Facebook Messenger which resembles more like the group chats or the ‚Äòclub‚Äô-style communities. You might have the ‚Äòstadium‚Äô type situations that are more like one person broadcasting out to a group of people and you might have Facebook groups which could be like either ‚Äòclubs‚Äô or ‚Äòfederations‚Äô depending how big they are. You actually have a permutation of lots of different types of communities that are across the entire platform. But I think having that kind of vocabulary can help us figure out, what does it actually mean to develop governance for any of these platforms? It's the same thing with Twitter also. I don't see a world where we have one policy or a certain set of guidelines. </p><p><em>AGM: That‚Äôs a somewhat shocking statement.</em></p><p>NE: Yeah, it's so it's funny that that‚Äôs controversial. Part of what I was trying to do in the book is saying like, okay, let's not like talk about social media, let's just talk about this other weird thing called open source. And let's look at the dynamics there and how that's evolved for 20 years. Can you depersonalize this a little bit and if you agree with me that these things seem to be happening in open source. And stacking this up against other economic frameworks we've had in the past, like the commons, and it doesn't seem to hold here, then can we take that conclusion and transfer it back over somewhere else‚Ä¶</p><p><em>AGM: Okay, that's the vibe I got from your book that you were trying to actually talk about the rest of it. So it's good to know that I wasn't over-reading into it. </em></p><p>NE: I was trying to be sensible about it. </p><p><em>AGM: Do you think the push on Facebook for content moderation, and Twitter, is a fool's errand? You know how Kevin Roose and Charles Warzel of </em>The Times<em> and that whole whiny mob that's constantly trying to get them to moderate everything. You think that's probably not the way forward?</em></p><p>NE: It seems beyond not just gonna happen, it seems actively wrong to me. It‚Äôs as though we're asking another country to govern the United States or something. I'm trying to look at where do those governance boundaries start and who should be moderating themselves or not, and just the thought that you would have a sort of widespread platform governance on some of these issues just seems, yeah, morally wrong to me.</p><p><em>AGM: Are you a free-speech absolutist, Nadia, that rarest of breeds?</em></p><p>NE: I'm not super public about my politics, but then I don‚Äôt mind poking my head out a little bit around it and publishing the book was kind of part of this for me because, to be totally frank, there are these democratic kind of ideals and these like communist-y ideals that we are holding about both the Internet and open source which are driving me crazy and, I'm trying to point out, you know, that's not always the case. And sometimes it's about one person who was doing a lot of things and we're just like couching it in a group cooperative. Yeah, I don't really know what my politics are, but I definitely err as far to that side as possible, as I think is reasonable. I do think this kind of moderation stuff, no one really has the answer to it. And so I'm not gonna sit here and be like, <em>I know how to fix it!</em> No one knows how to fix Facebook. Or any of these platforms. There's there's some humility that should be in place there, but I know what I stand for and what I'm aiming for.</p><p><em>AGM: I dislike looking always at the extreme example. But you know, Balaji [Srinivasan] had this whole dust-up with Taylor Lorenz and he's constantly getting into fights with these media people. And it's weird because he's often so right in so many ways, and he's good at getting attention. But somehow he hasn't parlayed into a mainstream following. </em></p><p>NE: I do feel like we need to have institutions a little bit in order to reinforce that. Well, I don't know if that's true or not, because people do follow like Elon Musk or Joe Rogan, or whatever. So that does exist. But I feel it would be so nice that if we had a publication that we could be proud of, that people would read outside of tech. There's no legible symbols for someone else to kind of follow. Like it's even weird that the most popular tech figures are not always the most popular figures actually in tech. Like Mark Cuban ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thepullrequest.com/p/nadia-eghbal">https://www.thepullrequest.com/p/nadia-eghbal</a></em></p>]]>
            </description>
            <link>https://www.thepullrequest.com/p/nadia-eghbal</link>
            <guid isPermaLink="false">hacker-news-small-sites-25053962</guid>
            <pubDate>Wed, 11 Nov 2020 00:16:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Analyzing Voting Systems]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25053892">thread link</a>) | @shihn
<br/>
November 10, 2020 | https://shihn.ca/posts/2020/voting-systems/ | <a href="https://web.archive.org/web/*/https://shihn.ca/posts/2020/voting-systems/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      
<h2>Introduction</h2>
<p>We encounter voting in some form around us all the time. We rate our Uber drivers, they rate us back. We up-vote and down-vote posts and trolls on Reddit. We give stars to movies and restaurants. We vote on who gets kicked out of our favorite reality television show. We vote for Presidents.</p>
<p>All these voting systems seem a bit different from one another, but one thing that's definitely common among them ‚Äî we will find ways to complain about them. The way a voting system is designed can make an <em>election</em> trivial or really complicated in nature. In fact, sometimes, the winner of an election may be determined by the rules of the voting system and not the intent of the voters (electoral college anyone?). In this post I try to explore the core of different voting systems and wonder if there is a perfect voting system.</p>
<p>Here I am going to use the word <em>election</em> to define an event or a goal that requires voting. An election doesn't have to be political in nature.</p>
<p><em>Note and Acknowledgement: This blog post is influenced by the chapter on voting systems in video games in the book Power-Up by Matthew Lane.</em></p>
<h2>Plurality Voting</h2>
<p>This is the simplest form of voting. Most political elections in the United States are done using this form of voting. It's quite simple ‚Äî every voter casts a vote for their favorite candidate. The candidate with the most number of votes wins.</p>
<p>Let's look at an example that we will continue to use in this post. We ask 100 people to vote for their favorite flavor of ice cream. The candidates are <em>Vanilla</em>, <em>Chocolate</em>, and <em>Strawberry</em>. Here's the result:</p>
<table>
<thead>
<tr>
<th>Flavor</th>
<th>Votes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla</td>
<td>45</td>
</tr>
<tr>
<td>Chocolate</td>
<td>40</td>
</tr>
<tr>
<td>Strawberry</td>
<td>15</td>
</tr>
</tbody>
</table>
<p><strong>Vanilla has won!</strong> Now if you stare at the numbers a bit, you will find some downsides in declaring Vanilla the winner in this election of the flavors.</p>
<p>An obvious one is that more votes were cast for a flavor that is not the winning flavor. You could also argue that no flavor should win because none of them reached a majority.</p>
<p>Here Strawberry is acting as a <strong>spoiler</strong> ‚Äî similar to how third-party candidates in US elections can be considered spoilers. Maybe we should have a <strong><em>run-off election</em></strong> where only Vanilla and Chocolate are considered. Perhaps more people favor Chocolate over Vanilla when Strawberry is out of the picture. (The US state of Georgia has rules akin to this. In the 2020 elections for the senate seats in Georgia, none of the candidates achieved a majority. So run-off elections will be held in January of 2021 with the top two candidates).</p>
<p>The essence of the Plurality voting system is that it does not capture the full spectrum of voters' preferences. If someone voted for Strawberry, it does not tell us how they feel about Vanilla or Chocolate.</p>
<p>This system does not truly determine the <em>'will of the people'</em>, unless.... there are only two candidates. One of the candidates is guaranteed to receive a majority, barring a tie. So if it were truly a <em>two-party system</em> some of the flaws of this system do not matter any more.</p>
<h2>Ranked Choice Voting</h2>
<p>Since the Plurality based system does not capture the full spectrum of the voter's preferences, we should probably ask for more information from the voters. What if we asked the voters to rank all the candidates, rather than cast a ballot for their favorite?</p>
<p>Let's look at the example we've been working with. We asked the 100 people to rank the candidate flavors. Here's the result:</p>
<table>
<thead>
<tr>
<th>1st</th>
<th>2nd</th>
<th>3rd</th>
<th>Votes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla</td>
<td>Strawberry</td>
<td>Chocolate</td>
<td>45</td>
</tr>
<tr>
<td>Strawberry</td>
<td>Chocolate</td>
<td>Vanilla</td>
<td>15</td>
</tr>
<tr>
<td>Chocolate</td>
<td>Strawberry</td>
<td>Vanilla</td>
<td>30</td>
</tr>
<tr>
<td>Chocolate</td>
<td>Vanilla</td>
<td>Strawberry</td>
<td>10</td>
</tr>
</tbody>
</table>
<p>All of the 45 people who voted for Vanilla had Strawberry as the second choice. All 15 people who voted for Strawberry, had Chocolate as their second choice. Of the 40 people who voted for Chocolate, 30 preferred Strawberry over Vanilla, and 10 preferred Vanilla. So, which flavor won? There are multiple ways to interpret this data. Let's look at a couple üëá</p>
<h2>Borda Count</h2>
<p>In this system for <code>n</code> candidates, each first-place vote receives <code>n</code> points. Second-place receives <code>n-1</code> points, and so on. The candidate with the most points wins.</p>
<p>Let's compute the points in our example. Vanilla received 45 first places, 10 second places, and 45 third places. So the score for Vanilla is <code>45n + 10(n-1) + 45(n-2)</code>. Here, <code>n</code> is <code>3</code>, giving Vanilla a score of <code>200</code>. Here's the final tally:</p>
<table>
<thead>
<tr>
<th>Flavor</th>
<th>Points</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla</td>
<td>200</td>
</tr>
<tr>
<td>Chocolate</td>
<td>195</td>
</tr>
<tr>
<td>Strawberry</td>
<td>205</td>
</tr>
</tbody>
</table>
<p><strong>Strawberry has won!</strong> Strawberry, which had the fewest votes in the Plurality voting system, has the most points in the Borda ranking system. Totally ridiculous, isn't it? Well maybe, but maybe not. Strawberry did receive the fewest third-place votes. And 75% of the people had Strawberry as their second choice.  Perhaps Strawberry does deserve to win!</p>
<h2>Instant Runoff Voting</h2>
<p>Let's take a look at a different model of interpreting the ranked voting data. In an Instant Runoff, the candidate with the fewest first-place votes is eliminated, and its votes are distributed to the second choice. This is then repeated until we have one candidate left standing.</p>
<p>Some consider this model of iterative elimination a bit confusing and thereby not practical. But it's getting wide adoption, including in political elections (San Francisco and Oakland city elections, for example). It is also used to decide the winner of the Best Picture Academy Award.</p>
<p>Let's apply this to our current example.</p>
<table>
<thead>
<tr>
<th>Flavor</th>
<th>Votes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla</td>
<td>45</td>
</tr>
<tr>
<td>Chocolate</td>
<td>40</td>
</tr>
<tr>
<td>Strawberry (eliminated)</td>
<td>15</td>
</tr>
</tbody>
</table>
<p>Strawberry is eliminated. Since all Strawberry voters preferred Chocolate over Vanilla, Chocolate gets Strawberry's 15 votes. Chocolate now has 55 votes, a majority. <strong>Chocolate has won!</strong></p>
<h2>Quick Recap</h2>
<p>We have discussed three systems so far, and in our example, we have had three different winners for the same election. You may decide subjectively that one of these systems may be better for the use case you have in mind, or you might think as I did at first: <strong>It's all pointless!</strong></p>
<h2>The Impossibility</h2>
<p>There is a concept in decision theory called the <strong><a href="https://en.wikipedia.org/wiki/Independence_of_irrelevant_alternatives">Independence of Irrelevant Alternatives (IIA)</a></strong> which states a voter's preference between two choices <code>x</code> and <code>y</code>, should not depend on any other choices.</p>
<p>This seems like a simple and a good rule to live by and our election systems should live by them as well. Sadly, all the systems we have looked at so far do not abide by this rule.</p>
<p>Let's look at the Plurality system - From the rankings we know that all of Strawberry voters prefer Chocolate over Vanilla. If the choice of Strawberry was not there, Chocolate would have won with 55 votes. But with Strawberry present, Vanilla wins with 45 votes.</p>
<p>For the Borda system, Chocolate is the spoiler. With Chocolate in the picture, Strawberry wins. Without Chocolate, Vanilla wins 55-45.</p>
<p>In the Instant Runoff, Chocolate wins when Vanilla is present but Strawberry wins 60-40 if Vanilla is not.</p>
<h3>Arrow's Impossibility Theorem</h3>
<p>In decision theory, here are some good things to have in an election or any voting system.</p>
<ul>
<li>Independence of Irrelevant Alternatives: which we have discussed and failed to account for so far.</li>
<li>Nondictatorship: Output should not be based on one individual, the wishes of multiple voters should be taken into consideration.</li>
<li>Pareto Efficiency (Unanimity): should have a notion of <a href="https://en.wikipedia.org/wiki/Pareto_efficiency">unanimity</a> ‚Äî If every voter prefers candidate A over candidate B, candidate A should win.</li>
<li>Unrestricted Domain: Voting must account for all individual preferences.</li>
<li>Ordering:  Each individual should be able to order the choices in any way.</li>
</ul>
<p>All good rules, don't you think? Let's create the ultimate voting system! But here comes <a href="https://en.wikipedia.org/wiki/Kenneth_Arrow">Kenneth Arrow</a> to shatter our hopes.</p>
<p><strong><a href="https://en.wikipedia.org/wiki/Arrow's_impossibility_theorem">Arrow's Impossibility Theorem</a> states that in all cases where preferences are ranked, it is impossible to formulate a social ordering without violating one of these rules.</strong></p>
<p>In other words, any democracy that satisfies Unanimity and the Independence of Irrelevant Alternatives, must be a dictatorship! *<em>insert dramatic sound effects</em>*</p>
<p>So yeah, we will always find things to argue about in an election. üòí</p>
<h2>Dodging the Impossibility</h2>
<p>Since every system is flawed, is it the end of this essay? Unfortunately for you, I, like many of you, noticed this one clause in Arrow's impossibility theorem which provides a way for us to escape this gravity well.</p>
<p>The theorem assumes that we are dealing with a ranked choice voting system. Let's just not rank our candidates. üí°</p>
<p>Here I would remind you, that we're trying to look at voting systems in general, not just political elections.</p>
<p>We have implemented non rank based systems in Software numerous times. Think Netflix, Yelp, Reddit, Tinder. The key as you may have guessed is rating, and not ranking (Tinder being a more specific type of rating - approval voting, which I'll discuss later). A voting system based on rating is usually called <strong>Score Voting</strong>.</p>
<h2>Score Voting</h2>
<p>The idea behind score voting is that you give each candidate a score in one or many categories. This score is independent of the score the other candidates receive. Think Diving and Gymnastics in the Olympics. The judges rate each athlete based on form, routine, landings. One with the highest total score wins.</p>
<p>But is this system better? That's subjective but we know it lets us escape the impossibility mathematically, and yet conform to independence, unanimity and nondictatorship rules.</p>
<h2>Approval Voting</h2>
<p>There's a simpler form or Score Voting - Approval Voting. Think of it as a binary version of the score voting. Each person can give a candidate a score of <code>0</code> or <code>1</code>. In other words one can approve or disapprove any number of candidates.</p>
<p>This is similar to how people vote on dating apps like Tinder. They give prospects a score of <code>1</code> by swiping right, and a score of <code>0</code> by swiping left.</p>
<h2>Strategizing the Ranked Vote</h2>
<p>One key advantage for Score Voting and Approval Voting is that it never hurts to vote for your favorite candidate. It may seem obvious and trivial but it's not always satisfied by voting systems. For example, it is common in political elections for people to not vote for the third-party candidate even though the third-party candidate may be the voter's first ‚Ä¶</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shihn.ca/posts/2020/voting-systems/">https://shihn.ca/posts/2020/voting-systems/</a></em></p>]]>
            </description>
            <link>https://shihn.ca/posts/2020/voting-systems/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25053892</guid>
            <pubDate>Wed, 11 Nov 2020 00:09:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React Frontload: Simple full-stack data loading for React]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25053845">thread link</a>) | @davnicwil
<br/>
November 10, 2020 | https://davnicwil.com/react-frontload/ | <a href="https://web.archive.org/web/*/https://davnicwil.com/react-frontload/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-reactroot="" data-reactid="1" data-react-checksum="1067123220"><div data-reactid="6"><div data-reactid="7"><p><img src="https://davnicwil.com/image/react-frontload-logo.png" width="100" height="100" data-reactid="8"></p></div><p data-reactid="10"><h2 data-reactid="11">Simple full-stack data loading for React</h2></p><p><a href="https://www.npmjs.com/package/react-frontload" data-reactid="13"><img src="https://img.shields.io/npm/v/react-frontload?style=social&amp;logo=npm" data-reactid="14"></a><a href="https://github.com/davnicwil/react-frontload" data-reactid="15"><img src="https://img.shields.io/github/stars/davnicwil/react-frontload?style=social" data-reactid="16"></a><a href="https://www.npmjs.com/package/react-frontload" data-reactid="17"><img src="https://img.shields.io/npm/dm/react-frontload?style=social" data-reactid="18"></a><a href="https://twitter.com/davnicwil" data-reactid="19"><img src="https://img.shields.io/twitter/url?label=made%20by%20%40davnicwil&amp;style=social&amp;url=https%3A%2F%2Fdavnicwil.com" data-reactid="20"></a></p></div><p data-reactid="21">React Frontload is a library to load and manage data inline in React components that works on both client and server.</p><div data-reactid="22"><ul data-reactid="23"><li data-reactid="24"><span data-reactid="25">Load data with a hook which works on client and server</span></li><li data-reactid="26"><span data-reactid="27">Data is managed in component state - no need for Redux / MobX</span></li><li data-reactid="28"><span data-reactid="29">Written in TypeScript, typing is easy as everything's inline</span></li><li data-reactid="30"><span data-reactid="31">Less than 3.5KB Gzipped, zero dependencies</span></li></ul></div><div data-reactid="32"><div data-reactid="33"><!-- react-text: 34 --><p>v2 has just shipped! </p><!-- /react-text --><p><a href="https://davnicwil.com/react-frontload/v2" data-reactid="35">See here</a></p><!-- react-text: 36 --><p> for the motivation for v2 and comparison with v1</p><!-- /react-text --></div></div><div data-reactid="37"><p>Install</p><p>npm install react-frontload</p></div><div id="problem" data-reactid="53"><h3 data-reactid="54">What problem does this solve?</h3><p><a href="#problem" data-reactid="55">#</a></p></div><p data-reactid="56">React provides no built-in way to do data loading - it's left for you to implement. Doing this is tricky in a React app that uses server side rendering (SSR) because client and server rendering work quite differently: Client render is async so data can be loaded inside components when they render, but server render is completely synchronous - the data must be loaded before render happens.</p><p data-reactid="57">Data loading is, of course, async. The client component-centric data loading pattern is nice, but it's incompatible with synchronous server render. React simply has no mechanism to wait for data to load when components render on SSR. There's a further problem too: React also provides no built-in way to hydrate data loaded during SSR into client state on first render. This is also up to you to implement.</p><p data-reactid="58">So, full stack data loading in React is a tricky problem. A couple of solutions have emerged:</p><ol data-reactid="59"><li data-reactid="60"><p data-reactid="61">Load data at the route level, instead of the component level, then pass data to all components under the route. Works on SSR since the route is known in the request, so data can be loaded before render begins. Can be implemented by piecing together router and state manager libraries.</p></li><li data-reactid="62"><p data-reactid="63">Use a framework that wraps React and abstracts the problem away, perhaps by providing a framework-specific async data loading function for components that works on SSR, and also takes care of hydrating state on the client.</p></li></ol><p data-reactid="64">React Frontload aims to provide a third way - the component-centric data loading pattern available full stack, but without having to buy into a whole framework just to get this feature. It's just a small library that solves this one problem, and can be used in any React stack.</p><p data-reactid="68">Here's an example of loading data into a component with React Frontload</p><p><span>const</span> <span>Component</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> <span>{</span> data<span>,</span> frontloadMeta <span>}</span> <span>=</span> <span>useFrontload</span><span>(</span><span>'my-component'</span><span>,</span> <span>async</span> <span>(</span><span><span>{</span> api <span>}</span></span><span>)</span> <span>=&gt;</span> <span>(</span><span>{</span>
    stuff<span>:</span> <span>await</span> api<span>.</span><span>getStuff</span><span>(</span><span>)</span>
  <span>}</span><span>)</span><span>)</span>

  <span>if</span> <span>(</span>frontloadMeta<span>.</span>pending<span>)</span> <span>return</span> <span>&lt;</span>div<span>&gt;</span>loading<span>&lt;</span><span>/</span>div<span>&gt;</span>
  <span>if</span> <span>(</span>frontloadMeta<span>.</span>error<span>)</span>   <span>return</span> <span>&lt;</span>div<span>&gt;</span>error<span>&lt;</span><span>/</span>div<span>&gt;</span>

  <span>return</span> <span>&lt;</span>div<span>&gt;</span><span>{</span>data<span>.</span>stuff<span>}</span><span>&lt;</span><span>/</span>div<span>&gt;</span>
<span>}</span>
</p><p data-reactid="70"><!-- react-text: 71 -->Here we have a <!-- /react-text --><span data-reactid="72">Component</span><!-- react-text: 73 --> that needs to load <!-- /react-text --><span data-reactid="74">stuff</span><!-- react-text: 75 --> from an API, with the usual loading state whilst it loads and some sort of error state if loading fails for some reason.<!-- /react-text --></p><p data-reactid="76"><!-- react-text: 77 -->With React Frontload, we do this by passing an async data loading function to the <!-- /react-text --><span data-reactid="78">useFrontload</span><!-- react-text: 79 --> hook. The hook loads the return value of the function into<!-- /react-text --><!-- react-text: 80 --> <!-- /react-text --><span data-reactid="81">data</span><!-- react-text: 82 -->, and gives us<!-- /react-text --><!-- react-text: 83 --> <!-- /react-text --><span data-reactid="84">frontloadMetadata</span><!-- react-text: 85 --> out the box so we can see when it's still <!-- /react-text --><span data-reactid="86">pending</span><!-- react-text: 87 --> or if an <!-- /react-text --><span data-reactid="88">error</span><!-- react-text: 89 --> is thrown when running the function.<!-- /react-text --></p><p data-reactid="90"><!-- react-text: 91 -->That's it - we're done in those few lines of code. That's the power of doing data loading inline in a component. And the best part here is that this just works on the server. If we render<!-- /react-text --><!-- react-text: 92 --> <!-- /react-text --><span data-reactid="93">Component</span><!-- react-text: 94 --> in a route, any route,<!-- /react-text --><!-- react-text: 95 --> <!-- /react-text --><span data-reactid="96">stuff</span><!-- react-text: 97 --> will load.<!-- /react-text --></p><p data-reactid="98"><!-- react-text: 99 -->To emphasise the ease and lack of plumbing involved in making changes, let's have <!-- /react-text --><span data-reactid="100">Component</span><!-- react-text: 101 --> load some more stuff:<!-- /react-text --></p><p><span>const</span> <span>Component</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> <span>{</span> data<span>,</span> frontloadMeta <span>}</span> <span>=</span> <span>useFrontload</span><span>(</span><span>'my-component'</span><span>,</span> <span>async</span> <span>(</span><span><span>{</span> api <span>}</span></span><span>)</span> <span>=&gt;</span> <span>(</span><span>{</span>
    stuff<span>:</span> <span>await</span> api<span>.</span><span>getStuff</span><span>(</span><span>)</span><span>,</span>
    moreStuff<span>:</span> <span>await</span> api<span>.</span><span>getMoreStuff</span><span>(</span><span>)</span> 
  <span>}</span><span>)</span><span>)</span>

  <span>if</span> <span>(</span>frontloadMeta<span>.</span>pending<span>)</span> <span>return</span> <span>&lt;</span>div<span>&gt;</span>loading<span>&lt;</span><span>/</span>div<span>&gt;</span>
  <span>if</span> <span>(</span>frontloadMeta<span>.</span>error<span>)</span>   <span>return</span> <span>&lt;</span>div<span>&gt;</span>error<span>&lt;</span><span>/</span>div<span>&gt;</span>

  <span>return</span> <span>&lt;</span>div<span>&gt;</span><span>{</span>data<span>.</span>stuff<span>}</span> and <span>{</span>data<span>.</span>moreStuff<span>}</span><span>&lt;</span><span>/</span>div<span>&gt;</span> 
<span>}</span>
</p><p data-reactid="103"><!-- react-text: 104 -->It's literally that simple - just add whatever you need to<!-- /react-text --><!-- react-text: 105 --> <!-- /react-text --><span data-reactid="106">useFrontload</span><!-- react-text: 107 --> and use it. Remember that this is all automatically typed. If the value returned by the<!-- /react-text --><!-- react-text: 108 --> <!-- /react-text --><span data-reactid="109">getMoreStuff</span><!-- react-text: 110 --> api call is a<!-- /react-text --><span data-reactid="111">string</span><!-- react-text: 112 -->,<!-- /react-text --><!-- react-text: 113 --> <!-- /react-text --><span data-reactid="114">data.moreStuff</span><!-- react-text: 115 --> has the string type, and you'll get errors if you try to use it as a number.<!-- /react-text --></p><p data-reactid="116"><!-- react-text: 117 -->You may have noticed that the above code loads data less efficiently than it could. <!-- /react-text --><span data-reactid="118">api.getStuff()</span><!-- react-text: 119 --> and<!-- /react-text --><!-- react-text: 120 --> <!-- /react-text --><span data-reactid="121">api.getMoreStuff()</span><!-- react-text: 122 --> are called in serial, when they could probably be called in parallel. Since it's just Javascript, though, we can change this:<!-- /react-text --></p><p><span>const</span> <span>{</span> data<span>,</span> frontloadMeta <span>}</span> <span>=</span> <span>useFrontload</span><span>(</span><span>'my-component'</span><span>,</span> <span>async</span> <span>(</span><span><span>{</span> api <span>}</span></span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> <span>[</span>stuff<span>,</span> moreStuff<span>]</span> <span>=</span> Promise<span>.</span><span>all</span><span>(</span><span>[</span>
    api<span>.</span><span>getStuff</span><span>(</span><span>)</span><span>,</span>
    api<span>.</span><span>getMoreStuff</span><span>(</span><span>)</span>
  <span>]</span><span>)</span>

  <span>return</span> <span>{</span> stuff<span>,</span> moreStuff <span>}</span>
<span>}</span><span>)</span>
</p><p data-reactid="124">In fact as data loaders get more complex, you can use any combination of serial and parallel that you need. It's just Javascript - you have the full power of the language without any abstractions or misdirection on top.</p><p data-reactid="125"><!-- react-text: 126 -->There is one more piece to this - what about updating data? Since React Frontload uses React component state to hold<!-- /react-text --><!-- react-text: 127 --> <!-- /react-text --><span data-reactid="128">data</span><!-- react-text: 129 -->, updating it is just a case of updating that state. React Frontload provides another function, called<!-- /react-text --><!-- react-text: 130 --> <!-- /react-text --><span data-reactid="131">setData</span><!-- react-text: 132 -->, for this:<!-- /react-text --></p><p><span>const</span> <span>Component</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> <span>{</span> data<span>,</span> setData<span>,</span> frontloadMeta <span>}</span> <span>=</span> <span>useFrontload</span><span>(</span><span>'my-component'</span><span>,</span> <span>async</span> <span>(</span><span><span>{</span> api <span>}</span></span><span>)</span> <span>=&gt;</span> <span>(</span><span>{</span>
    stuff<span>:</span> <span>await</span> api<span>.</span><span>getStuff</span><span>(</span><span>)</span>
  <span>}</span><span>)</span><span>)</span>

  <span>if</span> <span>(</span>frontloadMeta<span>.</span>pending<span>)</span> <span>return</span> <span>&lt;</span>div<span>&gt;</span>loading<span>&lt;</span><span>/</span>div<span>&gt;</span>
  <span>if</span> <span>(</span>frontloadMeta<span>.</span>error<span>)</span>   <span>return</span> <span>&lt;</span>div<span>&gt;</span>error<span>&lt;</span><span>/</span>div<span>&gt;</span>

  <span>const</span> <span>updateStuff</span> <span>=</span> <span>async</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>try</span> <span>{</span>
      <span>const</span> updatedStuff <span>=</span> <span>await</span> <span>updateStuff</span><span>(</span><span>'new value'</span><span>)</span> 
      <span>setData</span><span>(</span><span>data</span> <span>=&gt;</span> <span>(</span><span>{</span> <span>...</span>data<span>,</span> stuff<span>:</span> updatedStuff <span>}</span><span>)</span><span>)</span> 
    <span>}</span> <span>catch</span> <span>{</span>
      
    <span>}</span>
  <span>}</span>

  <span>return</span> <span>(</span>
    <span>&lt;</span><span>&gt;</span>
      <span>&lt;</span>div<span>&gt;</span><span>{</span>data<span>.</span>stuff<span>}</span><span>&lt;</span><span>/</span>div<span>&gt;</span>
      <span>&lt;</span>button onClick<span>=</span><span>{</span>updateStuff<span>}</span><span>&gt;</span>update<span>&lt;</span><span>/</span>button<span>&gt;</span>
    <span>&lt;</span><span>&gt;</span>
  <span>)</span>
</p><p data-reactid="134"><!-- react-text: 135 -->Again, this is all just inline in the component with zero plumbing. If you're coming from Redux, you can think of<!-- /react-text --><!-- react-text: 136 --> <!-- /react-text --><span data-reactid="137">setData</span><!-- react-text: 138 --> a little bit like a mini reducer. It takes the existing value of<!-- /react-text --><!-- react-text: 139 --> <!-- /react-text --><span data-reactid="140">data</span><!-- react-text: 141 --> as an argument, and you merge updates into it to return an updated value of<!-- /react-text --><!-- react-text: 142 --> <!-- /react-text --><span data-reactid="143">data</span><!-- react-text: 144 -->.<!-- /react-text --></p><p data-reactid="145">And that's it - full stack data loading and management inline in your React components.</p><p data-reactid="149"><!-- react-text: 150 -->The <!-- /react-text --><span data-reactid="151">useEffect</span><!-- react-text: 152 --> hook seen in the example above is the core of React Frontload - the code you'll actually work with in your components - but there is also a small amount of one-time setup code to write to get it to work.<!-- /react-text --></p><p data-reactid="153"><!-- react-text: 154 -->Essentially this is setting up wrappers around your server render logic, and your React application on both server and client, to make the<!-- /react-text --><span data-reactid="155">useFrontload</span><!-- react-text: 156 --> hook work, and also enable hydration of state loaded on server render to the client.<!-- /react-text --></p><p data-reactid="157">App Provider</p><p data-reactid="158">Wrap your app in the React Frontload provider</p><p><span>import</span> <span>{</span> FrontloadProvider <span>}</span> <span>from</span> <span>'react-frontload'</span>

<span>const</span> <span>App</span> <span>=</span> <span>(</span><span><span>{</span> frontloadState <span>}</span></span><span>)</span> <span>=&gt;</span> <span>(</span>
  <span>&lt;</span>FrontloadProvider initialState<span>=</span><span>{</span>frontloadState<span>}</span><span>&gt;</span>
    <span>&lt;</span>Content<span>&gt;</span><span>...</span><span>&lt;</span><span>/</span>Content<span>&gt;</span>
  <span>&lt;</span><span>/</span>FrontloadProvider<span>&gt;</span>
<span>)</span>
</p><p data-reactid="160">Server render</p><p data-reactid="161"><!-- react-text: 162 -->On server render, you need to wrap your existing synchronous server render code with<!-- /react-text --><!-- react-text: 163 --> <!-- /react-text --><span data-reactid="164">reactFrontloadServerRender</span><!-- react-text: 165 -->.<!-- /react-text --></p><p data-reactid="166"><!-- react-text: 167 -->You can think of this as the polyfill that allows React Frontload to load data asynchronously on server render. It just uses regular React server rendering under the hood, and its output is exactly the same. Read more about this <!-- /react-text --><a href="#how-it-works" data-reactid="168">here</a><!-- react-text: 169 -->.<!-- /react-text --></p><p><span>import</span> <span>{</span> renderToString <span>}</span> <span>from</span> <span>'react-dom/server'</span>
<span>import</span> <span>{</span> createFrontloadState<span>,</span> frontloadServerRender <span>}</span> <span>from</span> <span>'react-frontload'</span>
<span>import</span> serverApi <span>from</span> <span>'./serverApi'</span>

app<span>.</span><span>get</span><span>(</span><span>'*'</span><span>,</span> <span>async</span> <span>(</span><span>req<span>,</span> res</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>...</span>

  
  
  <span>const</span> frontloadState <span>=</span> createFrontloadState<span>.</span><span>server</span><span>(</span><span>{</span>
    
    
    
    context<span>:</span> <span>{</span> api<span>:</span> serverApi <span>}</span>
  <span>}</span><span>)</span>

  <span>try</span> <span>{</span>
    
    <span>const</span> <span>{</span> rendered<span>,</span> data <span>}</span> <span>=</span> <span>await</span> <span>frontloadServerRender</span><span>(</span><span>{</span>
      frontloadState<span>,</span>
      <span>render</span><span>:</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>renderToString</span><span>(</span><span>&lt;</span>App frontloadState<span>=</span><span>{</span>frontloadState<span>}</span> <span>/</span><span>&gt;</span><span>)</span>
    <span>}</span><span>)</span>

    res<span>.</span><span>send</span><span>(</span><span><span>`</span><span>
      &lt;html&gt;
        ...
        &lt;!-- server rendered markup --&gt;
        </span><span><span>${</span>rendered<span>}</span></span><span>

        &lt;!-- loaded data (to be hydrated on client) --&gt;
        &lt;script&gt;window._frontloadData=</span><span><span>${</span><span>toSanitizedJSON</span><span>(</span>data<span>)</span><span>}</span></span><span>&lt;/script&gt;
        ...
      &lt;/html&gt;
    </span><span>`</span></span><span>)</span>
  <span>}</span> <span>catch</span> <span>(</span>err<span>)</span> <span>{</span>
    
  <span>}</span>
<span>}</span><span>)</span>
</p><p data-reactid="171"><!-- react-text: 172 -->The output of<!-- /react-text --><!-- react-text: 173 --> <!-- /react-text --><span data-reactid="174">reactFrontloadServerRender</span><!-- react-text: 175 --> contains a <!-- /react-text --><span data-reactid="176">rendered</span><!-- react-text: 177 --> string, which is just the server render output to inject into your HTML template as usual.<!-- /react-text --></p><p data-reactid="178"><!-- react-text: 179 -->It also contains a <!-- /react-text --><span data-reactid="180">data</span><!-- react-text: 181 --> object, which you should serialize into your HTML as sanitised JSON.<!-- /react-text --><!-- react-text: 182 --> <!-- /react-text --><span data-reactid="183">data</span><!-- react-text: 184 --> contains all the data loaded for the current view across all components, and the purpose of this is to hydrate this data into React Frontload on the client (using<!-- /react-text --><!-- react-text: 185 --> <!-- /react-text --><span data-reactid="186">initialState</span><!-- react-text: 187 -->) so that it does not have to be reloaded on first render. This pattern is essentially the same as the one you see with other state managers such as Redux.<!-- /react-text --></p><p data-reactid="188">Client render</p><p data-reactid="189">The last remaining step is client integration, which is rather simpler. Just initialise a React Frontload state object on the client using your serialized data from server render, and pass it to the provider.</p><p><span>import</span> clientApi <span>from</span> <span>'./clientApi'</span>

<span>const</span> frontloadState <span>=</span> createFrontloadState<span>.</span><span>client</span><span>(</span><span>{</span>
  
  
  context<span>:</span> <span>{</span> api<span>:</span> clientApi <span>}</span><span>,</span>

  
  serverRenderedData<span>:</span> window<span>.</span>_frontloadData
<span>}</span><span>)</span>
<span>...</span>
ReactDOM<span>.</span><span>render</span><span>(</span><span>&lt;</span>App frontloadState<span>=</span><span>{</span>frontloadState<span>}</span> <span>/</span><span>&gt;</span><span>,</span> <span>...</span><span>)</span>
</p><p data-reactid="194">For most usecases, you don't need to care about this.</p><p data-reactid="195">That said, all abstractions are leaky at some point, and it's always useful to understand how things work under the hood so that when they behave unexpectedly, you can figure out why.</p><p data-reactid="196">The mechanism used to polyfill async on server render is deliberately very simple. As shown in the code above, React Frontload wraps ordinary synchronous server render code with an async function.</p><p data-reactid="197"><!-- react-text: 198 -->It works by running that synchronous function, and collecting the promises encountered on each render of a<!-- /react-text --><!-- react-text: 199 --> <!-- /react-text --><span data-reactid="200">useFrontload</span><!-- react-text: 201 --> hook. After the render, the collected promises are then awaited, which loads the data in those functions the same as it would be on the client. Now, React Frontload runs the server render again - this time injecting the data loaded from the previous run into each component ahead of the render. In this new render round, if no new<!-- /react-text --><!-- react-text: 202 --> <!-- /react-text --><span data-reactid="203">useFrontload</span><!-- react-text: 204 --> hooks are encountered (i.e. if there are no nested components with a<!-- /react-text --><!-- react-text: 205 --> <!-- /react-text --><span data-reactid="206">useFrontload</span><!-- react-text: 207 --> hook), then the output of this render is returned as the final output. If nested<!-- /react-text --><!-- react-text: 208 --> <!-- /react-text --><span data-reactid="209">useFrontload</span><!-- react-text: 210 --> hooks<!-- /react-text --><!-- react-text: 211 --> <!-- /react-text --><span data-reactid="212">are</span><!-- react-text: 213 --> found, the process repeats.<!-- /react-text --></p><ul id="api-useFrontload" data-reactid="225"><li data-reactid="226"><span data-reactid="227">useFrontload</span><a href="#api-useFrontload" data-reactid="228">#</a></li></ul><p data-reactid="229"><span data-reactid="230">useFrontload</span><!-- react-text: 231 --> is the React Frontload hook.<!-- /react-text --></p><p><span>import</span> <span>{</span> useFrontload <span>}</span> <span>from</span> <span>'react-frontload'</span>

<span>useFrontload</span><span>(</span>
  ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://davnicwil.com/react-frontload/">https://davnicwil.com/react-frontload/</a></em></p>]]>
            </description>
            <link>https://davnicwil.com/react-frontload/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25053845</guid>
            <pubDate>Wed, 11 Nov 2020 00:03:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Anonymous Donations to Universities Skyrocketing]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25053747">thread link</a>) | @SilentDonor
<br/>
November 10, 2020 | https://silentdonor.com/anonymous-donations-to-universities/ | <a href="https://web.archive.org/web/*/https://silentdonor.com/anonymous-donations-to-universities/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>		
		<div>
			
<p><span>We have been following a sustained trend that has hit higher-education institutions for a few years now: the rise of anonymous donations to universities. The desire among donors to remain private in their gifts to universities includes everything from millennials sending small sums, to wealthy donors giving gigantic</span><span> </span><a rel="noreferrer noopener" href="https://news.berkeley.edu/2020/02/29/largest-gift-in-berkeleys-history-will-create-a-hub-for-advancing-data-science/" target="_blank"><span><span>$252 million</span></span></a> <span>donations</span>. <span>Read more to <strong>see just how prevalent anonymous giving</strong> has become in donating to universities. </span></p>



<p><span>The choice to pursue anonymity as a donor is becoming more attractive for a variety of reasons (for more on the ‚Äòwhy‚Äô behind the choice to be anonymous, see our article</span> <a rel="noreferrer noopener" href="https://silentdonor.com/why-send-an-anonymous-donation/" target="_blank"><span><span>here</span></span></a>). <span>However, the traditional way of giving ‚Äúanonymously‚Äù to a university almost always means that the university actually knows who the donor is, but simply agrees to keep it confidential. Some institutions try to set up private foundations to help conceal the donors‚Äô identities, but, as this</span> <a rel="noreferrer noopener" href="https://www.chronicle.com/article/million-dollar-mystery-anonymous-donors-even-the-colleges-dont-know/" target="_blank"><span><span>Chronicle article</span></span></a> <span>reports,</span> ‚Äú<em>In college fund raising, anonymous donors typically aren‚Äôt truly anonymous. Someone on campus ‚Äî the president, or a top fund raiser who worked with the donor ‚Äî knows the identity of the person who gave the gift.</em>‚Äù </p>



<p><span>Many times this <strong>current system fails</strong> both the donors and the recipient universities, as the donor is not getting the actual anonymity they desire and now famously bureaucratic universities have to fight to keep their identity under wraps ‚Äì lest they risk angering and/or exposing their anonymous donor, which is exactly what happened to</span> <span><a rel="noreferrer noopener" href="https://www.bizjournals.com/portland/blog/health-care-inc/2014/08/the-news-pbj-readers-didnt-care-to-know-gert-boyle.html" target="_blank"><span>a $100 million anonymous donor</span></a> </span><span>to Oregon Health &amp; Science University. Or this $2 million </span><a rel="noreferrer noopener" href="https://www.ideastream.org/news/questions-over-myers-university" target="_blank"><span><span>anonymous donor to Myers University</span></span>, </a><span>who was outed by the&nbsp;Ohio Board of Regents Chancellor.</span></p>



<p><span>More people are turning to</span> <a rel="noreferrer noopener" href="http://silentdonor.com/" target="_blank"><span>Silent Donor</span></a> <span>to accomplish what they want ‚Äì <strong>to give back to their favorite schools, but to do so in a manner that is consistent with the level of privacy they are comfortable with</strong>. In line with this, anonymous gifts have exploded over the past few years and have in fact regularly become the largest donations that universities have ever seen. We have a few of them chronicled below, representing both large and small institutions from all across the United States:</span></p>



<ul><li><a rel="noreferrer noopener" href="https://houston.innovationmap.com/university-of-houston-50-million-donation-2639988486.html" target="_blank"><span><span>University of Houston</span></span></a> <span>$50 million <em>anonymous</em> donation in 2019 (largest in school history)</span></li><li><a rel="noreferrer noopener" href="https://news.berkeley.edu/2020/02/29/largest-gift-in-berkeleys-history-will-create-a-hub-for-advancing-data-science/" target="_blank"><span><span>UC Berkely</span></span></a> <span>$252 million <em>anonymous </em>donation in 2020 (largest in school history)</span></li><li><a rel="noreferrer noopener" href="https://www.insidehighered.com/news/2020/02/12/suny-binghamton-receives-largest-donation-its-history" target="_blank"><span><span>SUNY Binghampton</span></span></a> <span>$60 million <em>anonymous </em>donation in 2020 (largest in school history)</span></li><li><a rel="noreferrer noopener" href="https://www.wbrz.com/news/university-in-louisiana-gets-a-20m-anonymous-donation/" target="_blank"><span><span>Xavier University of Louisiana</span></span></a> <span>$20 million <em>anonymous </em>donation in 2020 (largest in school history)</span></li><li><a rel="noreferrer noopener" href="https://diverseeducation.com/article/178191/" target="_blank"><span><span>University of Arkansas Little Rock</span></span></a> <span>$25 million <em>anonymous </em>donation in 2020 (largest in school history)</span></li><li><a rel="noreferrer noopener" href="https://www.wmbfnews.com/2020/07/27/transformational-gift-anonymous-donor-commits-million-ccu/" target="_blank"><span><span>Coastal Carolina University</span></span></a> <span>$95 million <em>anonymous </em>donation in 2020 (largest in school history)</span></li><li><span>And there are <em>COUNTLESS </em>more examples</span></li></ul>



<p><span><strong>Silent Donor</strong> <strong>partners with universities (and nonprofits) to allow them to seamlessly accept anonymous gifts from their donors</strong> all over the country (and world) in order to help these institutions fundraise in a way that connects with their donor-base. As we can see, a look at the US donor-base reveals a predilection towards anonymous giving, rather than following tired ‚Äúask-and-give‚Äù patterns. While we have shown that wealthy donors are very interested in anonymous donations, we also decided to dive a little deeper into one very interesting set of donors that often go overlooked, but provide a massive amount of smaller-dollar donations: millennials.</span></p>



<p><strong>MILLENNIALS</strong></p>



<p><span>Millennials as a donor group are not to be discounted. The generation is infamous for helping to carry campaigns like Bernie Sanders‚Äô multimillion dollar fundraisers in which average donation amounts came in around $30. We wanted to find out more, so we conducted a small survey of college-graduate millennials who had donated to their alma mater and asked them a few questions about their experience.</span> </p>



<p><span>What we first heard <strong>overwhelmingly </strong>from respondents was that millennials were highly annoyed with the constant barrage of emails, calls, and physical mail that they receive from their university after they donated ‚Äì some saying they almost felt like their school was begging them to send another donation. One said she ‚Äúcouldn‚Äôt throw away the [university solicitation] mail fast enough.‚Äù Some respondents simply wanted to remain private with their small donation. The millennials understood the reason for the junk (e)mailing efforts, but almost all respondents answered that they would have preferred to not provide any of their contact information to their university in an attempt to avoid the subsequent mailing and calling barrage. One millennial hinted that it was enough to make him wish he did not send a donation at all.  </span></p>



<p><span>It is clear that millennials are interested in giving back to their schools, but they also want to do so on their terms. We are not here to tell universities to significantly alter their communications strategy, but rather urging universities <strong>to offer the donation path of least resistance</strong> ‚Äì one that offers an anonymous donation option (through Silent Donor!) to appeal to their career-climbing millennial audience, their wealthy audience, and millions of privacy-minded donors in between. </span></p>



<p><span>If you are in a fundraising role at a school or nonprofit, please reach out to us at <em>ContactUs@silentdonor.com</em> to learn more about how we can help your donations grow</span> for free!</p>
					</div><!-- .entry-content -->

		<!-- .entry-footer -->

				
			    
	    
	</div></div>]]>
            </description>
            <link>https://silentdonor.com/anonymous-donations-to-universities/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25053747</guid>
            <pubDate>Tue, 10 Nov 2020 23:54:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: You're paying too much for your superannuation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25053546">thread link</a>) | @truffle_pig
<br/>
November 10, 2020 | https://pennycott.com/super | <a href="https://web.archive.org/web/*/https://pennycott.com/super">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://pennycott.com/super</link>
            <guid isPermaLink="false">hacker-news-small-sites-25053546</guid>
            <pubDate>Tue, 10 Nov 2020 23:31:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Read Skew-T Charts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25053467">thread link</a>) | @sytelus
<br/>
November 10, 2020 | https://weathertogether.net/weather-101/how-to-read-skew-t-charts/ | <a href="https://web.archive.org/web/*/https://weathertogether.net/weather-101/how-to-read-skew-t-charts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="page-6586" class="page">
                                                
        
        <div>
          <p>If you haven‚Äôt seen a Skew-T chart before, to say they can look a little intimidating is a huge understatement. But with a little practice, you can become a Skew-T master and open up new doors to learn about a variety of meteorological subjects. Skew-T charts are incredibly useful for quickly and accurately viewing the structure of the atmosphere all the way from the surface to 100,000 feet, and they‚Äôve been around for a LONG time ‚Äì since 1947, to be exact<sup>1</sup>.</p>
<p>Skew-T charts are most commonly used to plot parameters measured by radiosondes as they rise throughout the atmosphere. They only plot three measurements: temperature, dew point, and wind velocity (the speed AND direction of the wind). Additionally, there are 5 lines on a Skew-T: isotherms, isobars, dry adiabats, moist adiabats, and saturation mixing ratio lines.</p>
<div id="attachment_6963"><p><a href="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/skewt_lines_q.jpg" rel="tc-fancybox-group6586"><img aria-describedby="caption-attachment-6963" src="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/skewt_lines_q.jpg" alt="" width="500" height="400"></a></p><p id="caption-attachment-6963">Isobars (A), dry adiabats (B), moist adiabats (C), isotherms (D), and saturation mixing ratio lines. <br>Credit: <a href="http://www.meted.ucar.edu/mesoprim/skewt/index.htm">UCAR MetEd module on reading Skew-T charts</a>. If you are looking for more information, I suggest you try the module! You will need to register to join, but registration is free,</p></div>
<p>Besides simply acting as a template to plot the temperature, dewpoint, and wind, Skew-Ts are useful for easily finding the locations and values of important levels and parameters of the atmosphere. CAPE, the LCL, and the LFC are just a few things that can easily be found with a Skew-T.</p>
<p>Let‚Äôs start our journey by learning about each line on a Skew-T.</p>
<p><span><strong>Isotherms</strong></span></p>
<div id="attachment_6965"><p><a href="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/isotherms.jpg" rel="tc-fancybox-group6586"><img aria-describedby="caption-attachment-6965" src="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/isotherms.jpg" alt="" width="500" height="400"></a></p><p id="caption-attachment-6965">Credit: UCAR Comet Program Skew-T module</p></div>
<p>Isotherms are lines of constant temperature. They are the namesake of the Skew-T chart because they are skewed 45 degrees to the right. Skewing the Ts may seem a little unintuitive, but a Skew-T allows us to easily calculate important atmospheric levels and parameters like the Lifting Condensation Level (LCL), Level of Free Convection (LFC), the Equilibrium Level, and CAPE. A <em>St√ºve</em> is like a Skew-T but without the skewed temperature lines. It is not as useful for most meteorological applications because the adiabats on it are not curved, meaning we can‚Äôt accurately calculate the things listed above.</p>
<p><span><strong>Isobars</strong></span></p>
<div id="attachment_6964"><p><a href="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/isobars.jpg" rel="tc-fancybox-group6586"><img aria-describedby="caption-attachment-6964" src="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/isobars.jpg" alt="" width="500" height="400"></a></p><p id="caption-attachment-6964">Credit: UCAR Comet Program Skew-T module</p></div>
<p>Isobars are defined as ‚Äúlines of constant pressure.‚Äù On a Skew-T chart, pressure, NOT height, is plotted on the y-axis, so isobars are simply parallel to the x-axis. Because pressure decreases more slowly with height the higher you go, pressure is plotted in a logarithmic fashion on Skew-T charts. For this reason, Skew-T charts are also commonly called Skew-T/Log-P charts. If we didn‚Äôt plot pressure in logarithms, the Skew-T charts would be as high as the weather balloons they plot traveled ‚Äì approximately 100,000 feet high!</p>
<p><span><strong>Dry Adiabats</strong></span></p>
<div id="attachment_6966"><p><a href="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/dry_adiabats.jpg" rel="tc-fancybox-group6586"><img aria-describedby="caption-attachment-6966" src="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/dry_adiabats.jpg" alt="" width="500" height="400"></a></p><p id="caption-attachment-6966">Credit: UCAR Comet Program Skew-T module</p></div>
<p>Adiabatic processes are processes in which no heat is exchanged with the outside system (in our case, the atmosphere), and dry adiabats show how much an <em>unsaturated</em> parcel cools when lifted through the atmosphere. You are probably thinking ‚Äúhow can a parcel cool and maintain the same heat content?‚Äù Well, keep in mind that as an air parcel rises, it expands due to the surrounding atmosphere exerting less pressure on it, so the total heat content remains the same.</p>
<p>Adiabatic processes are a consequence of the First Law of Thermodynamics, which states that the heat added to a certain mass of a gas is equal to its change in internal energy + the work done BY the gas ON the environment. My doing some nifty mathematical maneuvering and applying the ideal gas law, we find that the first law states that changes in temperature are positively correlated with changes in pressure. I‚Äôll discuss this and more in a tutorial in the future, but the important thing to know is that when an unsaturated air parcel rises and ANY air parcel sinks, it will travel parallel to these adiabats.</p>
<p>These adiabats follow the ‚ÄúDry Adiabatic Lapse Rate,‚Äù which is approximately 10 degrees Celsius per kilometer.</p>
<p><span><strong>Moist Adiabats</strong></span></p>
<div id="attachment_6967"><p><a href="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/sat_adiabats.jpg" rel="tc-fancybox-group6586"><img aria-describedby="caption-attachment-6967" src="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/sat_adiabats.jpg" alt="" width="500" height="400"></a></p><p id="caption-attachment-6967">Credit: UCAR Comet Program Skew-T module</p></div>
<p>When saturated air rises, it follows the ‚Äúsaturation‚Äù or ‚Äúmoist adiabats.‚Äù When air reaches saturation, gaseous water vapor condenses into liquid water droplets, and this phase change releases ‚Äúlatent heat‚Äù into the atmosphere. Because of this, the moist adiabatic lapse rate is ALWAYS less than the dry adiabatic lapse rate, but as you can see above, moist adiabats are NOT parallel and vary quite a bit with both temperature AND altitude.</p>
<p><strong>The most important thing to remember about moist adiabats is that a saturated air parcel will ONLY follow them if it is rising. If the parcel is sinking, it is warming away from saturation and will follow the dry adiabats.</strong></p>
<p><span><strong>Saturation Mixing Ratio Lines</strong></span></p>
<div id="attachment_6968"><p><a href="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/sat_mixing_ratio.jpg" rel="tc-fancybox-group6586"><img aria-describedby="caption-attachment-6968" src="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/sat_mixing_ratio.jpg" alt="" width="500" height="400"></a></p><p id="caption-attachment-6968">Credit: UCAR Comet Program Skew-T module</p></div>
<p>The saturation mixing ratio is the ratio, in grams of water vapor per kilogram of air, that an air parcel must have at a given pressure and temperature to be considered ‚Äúsaturated.‚Äù Once an air parcel is saturated, it generally cannot hold any more water vapor.</p>
<p>Now that you know the lines ‚Äì let‚Äôs find out how we can use them to calculate some particularly important levels of the atmosphere. We‚Äôll learn how to calculate the <strong>lifting condensation level (LCL)</strong>, the <strong>convective condensation level (CCL)</strong>, the<strong> level of free convection (LFC)</strong>, and the<strong> equilibrium level (EL)</strong>, as well as<strong> convective available potential energy (CAPE)</strong> and<strong> convective inhibition (CIN)</strong>.</p>
<p><span><strong>Lifting Condensation Level (LCL)</strong></span></p>
<div id="attachment_6970"><p><a href="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/lcl_proc.jpg" rel="tc-fancybox-group6586"><img aria-describedby="caption-attachment-6970" src="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/lcl_proc.jpg" alt="Lifting Condensation Level" width="350" height="290"></a></p><p id="caption-attachment-6970">Lifting Condensation Level<br>Credit: UCAR MetEd COMET Program</p></div>
<p>The LCL is the pressure level an air parcel would need to be raised (dry adiabatically) to to become saturated. To find the LCL, follow a dry adiabat from your surface environmental temperature and a saturation mixing ratio line from your surface dewpoint temperature. The intersection of these marks the location of the LCL. The LCL is important because it marks location where the air parcel stops rising at the dry adiabatic lapse rate and switches to the moist adiabatic lapse rate.</p>
<p><span><strong>Convective Condensation Level (CCL)</strong></span></p>
<div id="attachment_6971"><p><a href="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/ccl_proc.jpg" rel="tc-fancybox-group6586"><img aria-describedby="caption-attachment-6971" src="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/ccl_proc.jpg" alt="Convective Condensation Level" width="350" height="290"></a></p><p id="caption-attachment-6971">Convective Condensation Level. The Convective Temperature (Tc) can be found by taking a dry adiabat down from the CCL to the surface.</p></div>
<p>A closely related level is the <strong>Convective Condensation Level</strong>, or <strong>CCL</strong>. The CCL is the pressure level that a parcel, if heated to the ‚Äúconvective temperature,‚Äù would freely rise and form a cumulus cloud. The convective temperature is the temperature the surface must reach so that air can freely rise, and the CCL is at the intersection of the environmental temperature (NOT a dry adiabat from the surface‚Ä¶ that‚Äôs the LCL) and the saturation mixing ratio line from the surface dewpoint temperature.</p>
<p><strong>Notes: </strong>The LCL and CCL are useful for determining the height of cloud bases. For non-convective clouds that are forced to rise, the LCL is a good approximation. On the other hand, the CCL is a better estimate for clouds formed by convection, like cumulus clouds. In reality, cloud bases are generally somewhere between the LCL and CCL.</p>
<p>The reason why thunderstorms in the desert often have high bases is because surface dewpoints are low there, causing the LCL and CCL to be high in the atmosphere. Conversely, thunderstorms in humid locations generally have lower bases because the LCL is lower.</p>
<p><span><strong>Level of Free Convection (LFC)</strong></span></p>
<div id="attachment_6972"><p><a href="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/lfc_proc.jpg" rel="tc-fancybox-group6586"><img aria-describedby="caption-attachment-6972" src="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/lfc_proc.jpg" alt="" width="350" height="290"></a></p><p id="caption-attachment-6972">Level of free convection. It is calculated by taking a moist adiabat from the LCL until you intersect the environmental temperature.</p></div>
<p>The LFC is the pressure level an air parcel would need to be raised so that its temperature is equal with the environmental temperature. It is found by taking the moist adiabat from the LCL until it intersects the environmental temperature. After this, the air parcel is warmer than its environment and can freely rise (hence the name ‚Äì level of <em>free convection</em>).</p>
<p>There are a few isolated situations where this approach won‚Äôt work ‚Äì for example, if the surface has reached the ‚Äúconvective temperature‚Äù mentioned above, the LFC is at the surface. But for the vast majority of situations, this method works beautifully.</p>
<p><strong>Not all soundings have an LFC. </strong>If the moist adiabat never intersects the environmental temperature because the atmosphere is relatively stable and does not exhibit a sharp decrease in temperature with height, there is no LFC. Additionally, many places that have an LFC during the day may not have one at night, when the surface is cooler and the atmosphere is more stable.</p>
<p><strong><u>Equilibrium Level (EL)</u></strong></p>
<div id="attachment_6944"><p><a href="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/Skew-T-Diagram.png" rel="tc-fancybox-group6586"><img aria-describedby="caption-attachment-6944" src="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/Skew-T-Diagram.png" alt="" width="600" height="600"></a></p><p id="caption-attachment-6944">A Sample Skew-T Diagram. The slanted red lines are lines of constant temperature, the dotted purple lines are lines of constant mixing ratio, the solid curved green lines are dry adiabats, and the curved green lines are moist adiabats.<br>The Lifting Condensation Level (LCL), Level of Free Convection (LFC), and Equilibrium Level (EL) are labeled. The CAPE is bounded on the bottom by the LFC and the top by the EL and is the total area between the black line (path of the air parcel) and red line (environmental temperature).<br>Retrieved from <a href="http://wx4cast.blogspot.com/2014/04/the-basics-of-severe-weather-sounding.html">Rebecca Ladd‚Äôs Weather Blog</a></p></div>
<p>The equilibrium level only exists if there is an LFC, and it is defined as the level at which the moist adiabat denoting the parcel‚Äôs path recrosses the environmental temperature. At the EL, the air parcel is the same temperature as its environment, and above it, it is cooler and more dense. The EL can be found by looking at the ‚Äúanvils‚Äù on thunderstorms, as these mark the location where a rising air parcel is no longer positively buoyant. The ‚Äúovershooting top‚Äù of a thunderstorm exceeds the equilibrium level, but this is only because the momentum of the storm‚Äôs uber-powerful updraft is allowing it to reach a higher altitude, NOT because the air above the equilibrium level is positively buoyant.</p>
<p><span><strong>Convective Available Potential Energy (CAPE) and Convective Inhibition (CIN)</strong></span></p>
<div id="attachment_7034"><p><a href="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/cin_tephi.jpg" rel="tc-fancybox-group6586"><img aria-describedby="caption-attachment-7034" src="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/cin_tephi.jpg" alt="" width="500" height="550"></a></p><p id="caption-attachment-7034">Sounding showing CIN and CAPE<br>Credit: UCAR</p></div>
<p><b>CAPE</b> is the area bounded by the environmental temperature and the temperature of a ‚Ä¶</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://weathertogether.net/weather-101/how-to-read-skew-t-charts/">https://weathertogether.net/weather-101/how-to-read-skew-t-charts/</a></em></p>]]>
            </description>
            <link>https://weathertogether.net/weather-101/how-to-read-skew-t-charts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25053467</guid>
            <pubDate>Tue, 10 Nov 2020 23:22:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Priests upset by online 'mass-hoppers' rating performances, counting views]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25053433">thread link</a>) | @networked
<br/>
November 10, 2020 | https://www.independent.ie/irish-news/priests-upset-by-online-mass-hoppers-rating-performances-counting-views-39727993.html | <a href="https://web.archive.org/web/*/https://www.independent.ie/irish-news/priests-upset-by-online-mass-hoppers-rating-performances-counting-views-39727993.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            <p>Priests have said they are upset by the "very hurtful criticism" of "mass-hoppers" who go from one online mass to another passing comments over their "performances".</p>
            
            
    

                                <p>ccording to Fr Tim Hazelwood, a spokesman for the Association of Catholic Priests (ACP), which represents over 1,000 Irish priests, "mass-hoppers" are undermining many priests who are already self-conscious and are "not performers".</p>                                                                                    
                                <p>In a presentation to the ACP's AGM, the Co Cork priest said some of the comments were "very hurtful" and some priests had stopped doing online services because "they couldn't take it" anymore.</p>                                                                                                                    
                
        
                        
                                
                                
                
            
                        
                                                                                                                                                                                                            
        
        

                                            
            
    
              
        </div></div>]]>
            </description>
            <link>https://www.independent.ie/irish-news/priests-upset-by-online-mass-hoppers-rating-performances-counting-views-39727993.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25053433</guid>
            <pubDate>Tue, 10 Nov 2020 23:19:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Law of Large Numbers and the Central Limit Theorem (With Python)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25053341">thread link</a>) | @rbanffy
<br/>
November 10, 2020 | https://randomvariable.cc/law-of-large-numbers-central-limit-theorem-python/ | <a href="https://web.archive.org/web/*/https://randomvariable.cc/law-of-large-numbers-central-limit-theorem-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <section data-aos="fade">
            


              <span data-visibility="public"></span>
            <div>
                
              
                <p>Law of Large Numbers &amp; CLT: Explanation, mathematical proof &amp; illustration of theorems with Python</p>
            </div>
          </section>
        <section data-aos="fade-up">
          <div>
            <header>
              
              
                <p>Law of Large Numbers &amp; CLT: Explanation, mathematical proof &amp; illustration of theorems with Python</p>
            </header>
            
            <section>
                <!--kg-card-begin: html--><!--kg-card-end: html--><p>Statistics does not usually go with the word "famous," but a few theorems and concepts of statistics find such universal application, that they deserve that tag. The Central Limit Theorem and the Law of Large Numbers are two such concepts. Combined with hypothesis testing, they belong in the toolkit of every quantitative researcher. These are some of the most discussed theorems in quantitative analysis, and yet, scores of people still do not understand them well, or worse, misunderstand them. Moreover, these calculations are usually not done manually‚Äîthe datasets are too large, computations are time consuming‚Äîso it is equally important to understand the computation aspect of these theorems well.</p><p>A working knowledge of probability, random variables and their distributions is required to understand these concepts.</p><h2 id="sample-mean">Sample Mean</h2><p>A "sample" is a set of outcomes in an experiment or an event. A sample can sometimes also be replaced by "trials" or number of repetitions of the experiment. For example, tossing a coin with probability <em>p</em> of achieving a heads is <em><strong>n</strong></em> <em>Bernoulli (p)</em> trials. If the outcome is a random variable X, then <em>X~Binomial(n, p)</em> distribution (with <em>n</em> number of Bern(p) trials).</p><!--kg-card-begin: html--><p>
    The values in a sample, \(X_{1},X_{2},X_{3}, ..., X_{n}\), will all be random variables, all drawn from the same probabilistic distribution since they are outcomes of the same experiment. The \(X_{1},X_{2},X_{3}, ..., X_{n}\) here are not actual numbers but names of random variables. A realization of the random variable \(X_{1}\) will be \(x_{1}\), an actual number.
</p><!--kg-card-end: html--><p>A realization or an actual value of an experiment is one reading from the distribution. In a way, a probabilistic distribution is not a physical thing, and hence sometimes hard to relate to in everyday actions, even though highly applicable in everyday activities. It can be thought of as a tree. For example, a mango tree. We know the characteristics of the tree, what types of leaves it has, what types of fruits, their shape, size, color etc. We have a good idea of what a mango tree <em><strong>is</strong></em>, even if we don't physically see it &amp; know each and every value. That is similar to a probabilistic distribution of a random variable X. One specific leaf, x, plucked from a mango tree, is like a <em>realization</em> of the random variable X.</p><!--kg-card-begin: html--><p>
    <b>Sample Mean</b> is a random variable itself, as it is an average of other random variables. When referring to outcomes of the same experiment, all outcomes will belong to the same distribution, and hence will be identical in distribution. If each trial or sample is independent of the others, the random variables \(X_{1},X_{2},X_{3}, ..., X_{n}\), will also be independent. This is then a set of <b>I.I.D.</b> (Independent and Identically Distributed) random variables.</p>

<p>

For I.I.D. random variables \(X_{1},X_{2},X_{3}, ..., X_{n}\) the sample mean \({\overline{X_n}}\) is simply the arithmetic average of the set of random variables. (Note: the definition of sample mean applies to any set of random variables, but the fact that they are I.I.D. is going to be a special case scenario in common experiments, useful for deriving some important theorems.)
</p>

<p> \[{\bar{X_n}} =  \sum_{i=1}^{n}{X_i}/n\]<!--kg-card-end: html--></p><p>In a small lab experiment, like measuring the length of an instrument with Vernier Calipers, we normally observe and record 3-5 readings of a measurement, and take the average of the readings to report the final value, to cancel any errors. This is high-school level mathematics. In research experiments, this level of simplification is not possible. But the idea behind the averaging is the same. In real life, we draw samples, X<sub>i</sub>, and take the expectation of the samples to get the expectation of the sample mean. But the expectation of the sample mean is an average of all possible outcomes for each random variable X<sub>i</sub>, not just the realized values. So, in a sense, it is a <em><strong>theoretical average.</strong></em></p><!--kg-card-begin: html--><p>
\[E[{\overline{X_n}}] =  E[\sum_{i=1}^{n}{X_i}/n]\]
</p><!--kg-card-end: html--><p>When we take the expectation, the expectation of the errors becomes zero: E[e] = 0</p><h2 id="convergence-in-probability">Convergence in Probability</h2><p>A convergence in probability is defined as follows: a sequence of random variables X<sub>n</sub> is said to converge in probability to a number <em>a</em>, if for any given small number <em>œµ, </em>the probability of the difference between <em>X<sub>n</sub></em> and <em>a</em> being greater than <em>œµ</em> tends to zero as <em>n</em> approaches <em>‚àû</em>.</p><!--kg-card-begin: html--><p>
    For any \(\epsilon\) &gt; 0,
   \[\lim_{n \rightarrow  \infty } P(|X_n - a|   \geq  \epsilon ) = 0\]
    
</p><!--kg-card-end: html--><p>So, the distribution of X<sub>n</sub> bunches around the number<em> a</em> for a large enough number <em>n</em>. But it is <em>not always necessary</em> that the expectation E[X<sub>n</sub>] will converge to <em>a </em>too. This can be explained by the presence of outliers which might offset the expectation away from the number <em>a</em>, where the big proportion of the outcomes lie.</p><h2 id="law-of-large-numbers-lln-">Law of Large Numbers (LLN)</h2><p>As per the LLN, as the sample size <em>n</em> tends to ‚àû, the expectation of the sample mean tends to the true mean <em>Œº </em>of the population with probability 1. This is true for a set of I.I.D. random variables X<sub>i</sub> with mean <em>Œº</em> and variance <em>œÉ<sup>2</sup></em>. It is calculated as follows:</p><!--kg-card-begin: html--><p>
    \[E[{\overline{X_n}}] =  E[\sum_{i=1}^{n}{X_i}/n]  \longrightarrow  \mu \]
    
</p><!--kg-card-end: html--><p>This can be simulated and tested in Python by creating say 15 random variables, <em>X<sub>1</sub> </em>to <em>X<sub>15</sub></em> that are <em>X<sub>i</sub> ~Bin(n,p)</em> using the random generator of Numpy. The X<sub>i</sub> &nbsp;must be IID. We calculate the value of the sample mean by averaging the variables. The true mean ( <code>mu</code> in the code) is very close to the calculated value <code>mean</code> based on the randomly generated distributions.</p><p>Note that in Numpy, <code>np.random.binomial(n, p, size=None)</code> uses a slightly different notation for the Binomial distribution than what we have been using so far. Here <code>n</code><em> </em>refers to the number of trials in one variable, <code>p</code> is the probability of success, and <code>size</code> is the sample size (eg, number of coins tossed). It treats the Binomial distribution as a sum of indicator random variables; hence the output is the sum of number of successes for each sample (like each coin). So, if we take <code>size</code> as 5, and <code>n</code> (trials) as 100, the output will be a list of 5 numbers, with the sum of number of successes out of 100 for <em>each</em> sample (eg, for each coin).</p><p>For the sake of simplicity though, I have created 15 separate random variables, each with <code>size</code>= 1, for illustrative purposes. <code>XN</code> refers to the sample mean in the code.</p><pre><code>import numpy as np
import scipy.stats as sp

#Running the Simulation with 15 IID Binomial RV for size=1 each, with n=1000 trials, probability of success is p=0.5

X1 = np.random.binomial(1000, 0.5, 1)
X2 = np.random.binomial(1000, 0.5, 1)
X3 = np.random.binomial(1000, 0.5, 1)
X4 = np.random.binomial(1000, 0.5, 1)
X5 = np.random.binomial(1000, 0.5, 1)
X6 = np.random.binomial(1000, 0.5, 1)
X7 = np.random.binomial(1000, 0.5, 1)
X8 = np.random.binomial(1000, 0.5, 1)
X9 = np.random.binomial(1000, 0.5, 1)
X10 = np.random.binomial(1000, 0.5, 1)
X11 = np.random.binomial(1000, 0.5, 1)
X12 = np.random.binomial(1000, 0.5, 1)
X13 = np.random.binomial(1000, 0.5, 1)
X14 = np.random.binomial(1000, 0.5, 1)
X15 = np.random.binomial(1000, 0.5, 1)

XN = (X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8+ X9 + X10 + X11 + X12 + X13 + X14 + X15)/15        #Sample Mean
mean = np.mean(XN)   #Calculated mean of the sample
print("Sample Mean: "+ str(mean))

mu = sp.binom.mean(1000, 0.5)    #True Mean of the sample
print("True Mean: " + str(mu))</code></pre><pre><code>Output:

Sample Mean: 500.8666666666667
True Mean: 500.0</code></pre><p>This is the result for just 15 random variables. As the number increases, the sample mean gets closer to true mean. (Note: every time you run the code, it gives a new value for the sample mean because a new set of rv is generated every time. <a href="https://repl.it/@agarwalarti/LLN">You can check and run the code here.</a> )</p><!--kg-card-begin: html--><p>
    The variance of the Sample Mean \(\overline{X_n}\) is calculated as follows:
    
\[Var(\overline{X_n}) =\frac{Var(X_1 + X_2 + ... + X_n)}{n^2} = \frac{n \sigma^2}{n^2} = \frac{\sigma^2}{n} \]
    
    
</p><!--kg-card-end: html--><p>Since X<sub>i</sub> are independent, we can use the property of linearity of variances to find the variance of the sample mean. By using the variance calculated above, and the Chebyshev's inequality, we can prove the Weak Law of Large Numbers.</p><h3 id="weak-law-of-large-numbers">Weak Law of Large Numbers</h3><p>As per the Chebyshev's inequality, </p><!--kg-card-begin: html--><p>
    For any \(\epsilon\) &gt; 0,
   \[P(|Y_n - a|   \geq  \epsilon ) = \frac{Var(Y_n)}{ \epsilon ^2} \]
    
</p><!--kg-card-end: html--><p>Plugging in the values in this equation, we get:</p><!--kg-card-begin: html--><p>
    \[ P(|\overline{X_n} - \mu| \geq \epsilon ) = \frac{\sigma^2}{ n\epsilon ^2}  \underset{n  \longrightarrow \infty }{\overset{}{\longrightarrow}} 0
    \]
    
    
</p><!--kg-card-end: html--><p>As n approaches infinity, the probability of the difference between the sample mean and the true mean <em>Œº</em> tends to zero, taking <em>œµ </em>as a fixed small number.</p><h2 id="central-limit-theorem">Central Limit Theorem</h2><p>So far, we have not mentioned anything about which distribution the X<sub>i</sub> belong to and the distribution of the sample mean (which is a random variable too, remember?). Most of the times, knowing the mean is not enough; we would like to know more about the final distribution of the sample mean so we can understand its properties. The Central Limit Theorem describes exactly this.</p><p>The Central Limit Theorem (CLT) says:</p><!--kg-card-begin: html--><p>
    \[  \frac{\sqrt{n} (\overline{X_n} -  \mu )}{ \sigma }

\underset{n  \longrightarrow \infty }{\longrightarrow}N(0,1) \]
</p><!--kg-card-end: html--><pre><code>import numpy as np
import scipy.stats as sp
import matplotlib.pyplot as plt
import math

#Running the Simulation with 10 IID Binomial RV for 500 coins, with 1000 trials, probability of success is 0.5

X1 = np.random.binomial(1000, 0.5, 500)
X2 = np.random.binomial(1000, 0.5, 500)
X3 = np.random.binomial(1000, 0.5, 500)
X4 = np.random.binomial(1000, 0.5, 500)
X5 = ‚Ä¶</code></pre></section></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://randomvariable.cc/law-of-large-numbers-central-limit-theorem-python/">https://randomvariable.cc/law-of-large-numbers-central-limit-theorem-python/</a></em></p>]]>
            </description>
            <link>https://randomvariable.cc/law-of-large-numbers-central-limit-theorem-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25053341</guid>
            <pubDate>Tue, 10 Nov 2020 23:10:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Silicon: The Roads Not Taken]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25053236">thread link</a>) | @ingve
<br/>
November 10, 2020 | https://take.surf/2020/11/09/apple-silicon-the-roads-not-taken | <a href="https://web.archive.org/web/*/https://take.surf/2020/11/09/apple-silicon-the-roads-not-taken">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><section><p>[Please note: This was written ahead of <a href="https://www.apple.com/newsroom/2020/11/introducing-the-next-generation-of-mac/">today's announcements</a>.]</p><p>My track record on predicting things out of the blue is pretty spotty, so here are a few things I can imagine but that will probably not materialize.</p><ul><li><h3>"Apple Pi"</h3><p>Raspberry Pi-like, "tinkerer-friendly" Mac, for under $100.</p><p>Compare the prices of most single-board computers and the x86 models are steadily either significantly more expensive, or running four year old Intel Atom CPUs, or both. Not only do ARM processors not have the issue of having to keep Intel afloat, Apple has itself had experience putting out small SoCs <a href="https://panic.com/blog/the-lightning-digital-av-adapter-surprise/">in surprising places</a>.</p><p>If they would do this, chances are they'd make it all about hosting stuff on iCloud, writing code in Swift (maybe using a connected iPad). I don't quite see how it can both be what the Raspberry Pi crowd likes and what Apple likes at the same time. Apple's not interested in enabling tinkering. It's interested in making kids code, but on a high-margin iOS device and up. With the way macOS has moved recently, there's little making this a Mac as such, but it's more a Mac than iOS/iPadOS.</p></li><li><h3>"Mac nano"</h3><p>A Mac mini the size of the Apple TV, for $199, with 4GB RAM, 64/128 GB of iPhone-like storage, hardly any I/O, and probably an A12, A13 or A14. <a href="https://www.youtube.com/watch?v=GJpZGeihy0s">BYODKM</a> ‚Äì hook up the display with HDMI or USB-C, hook up keyboard and mouse wirelessly or with a USB-C hub/adapter.</p><p>The old Steve Jobs quote was "we don't know how to make a $500 computer that's not a piece of crap", and Apple can now comfortably pack in the computational power for an okay enough experience for what people are likely to plug into it. As long as it runs the software well enough, it's a candidate to bring people over from Windows, and they're about to lose the fallback "if all else fails you could use it as a Windows PC"; it needs to be cheaper.</p><p>("Mac SE" was already taken.)</p></li><li><h3>An affordable Mac mini</h3><p>Take the current Mac mini, make it a bit smaller and make it affordable. Again ‚Äì the Intel tax is gone, and Apple, if they want to, can churn out silicon in large scales by themselves already. The first Mac mini was $499 ‚Äì there's no reason the first ARM Mac mini can't be.</p></li></ul><p>All of these products essentially are based on this: there's an Apple that makes iPhones for $399 with industry-leading performance, and there's an Apple that sells wheels for almost twice that price. It's up to Apple to define what they want to sell and how they want to market it, and heading into a transition where you drop a hardware partner for your own designs is a perfect time to choose a new tack.</p><p>Say what you want about whether Apple wanted to offer lower-level products before, the price-to-performance ratio with Intel never made much sense. And if a Celeron or Atom didn't exactly scream high enough performance, neither did PowerPC chips that were lower-end than the ones they put in their low-end Macs back in those days. In a way, Apple's not had the opportunity to tackle this head-on at least for 20 years or so, so we don't really know that the idea has been rejected by Apple rather than by circumstance.</p></section></article></div>]]>
            </description>
            <link>https://take.surf/2020/11/09/apple-silicon-the-roads-not-taken</link>
            <guid isPermaLink="false">hacker-news-small-sites-25053236</guid>
            <pubDate>Tue, 10 Nov 2020 22:59:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My personal experience with Ethereum contract development]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25052857">thread link</a>) | @buzzert
<br/>
November 10, 2020 | https://buzzert.net/posts/2020-11-01-octahedron | <a href="https://web.archive.org/web/*/https://buzzert.net/posts/2020-11-01-octahedron">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="right-container">
            <div id="diary-page">
	
	<p>‚ÄúThe Blockchain‚Äù has become a real buzzword in computing these days, but often without a coherent justification. I think it‚Äôs because there are a lot of venture capitalists and entrepreneurs who are trying to remain really tuned in to the ‚Äúnext big thing‚Äù in technology. I personally cringe every time I hear business people talking about ‚Äúthe blockchain‚Äù, because it was never supposed to a tool to make money, or even be a part of business at all. It was <em>always</em> a hacker thing, meant to subvert businesses in many ways.</p>

<p>Distributed and trust-less computing was frequently discussed on the cipherpunks Usenet newsgroups in the 1990‚Äôs. Borne from the early excitement of the Internet, imagining newfound possibilities for an already established decentralized network of computers, our hacker grandparents envisioned a literal <a href="https://www.activism.net/cypherpunk/crypto-anarchy.html">‚Äúcrypto-anarchy‚Äù</a>. The Blockchain was never explicitly tied to currency in its inception. Currency, a thing that is controlled by governments, inhibits free market capitalism<sup id="fnref:1"><a href="#fn:1">1</a></sup>, and empowers individuals was simply the killer application for it, especially to the crypto-anarchists.</p>

<p>It‚Äôs interesting that the concept of a blockchain or even a cryptocurrency hadn‚Äôt even been conceived in Tim May‚Äôs original email (linked above), it was only the ideology. It wasn‚Äôt until <a href="http://www.weidai.com/bmoney.txt">Wei Dai‚Äôs textfile about b-money</a> did the idea of applying cryptography towards currency come about.</p>

<blockquote>
  <p>A community is defined by the cooperation of its participants, and efficient cooperation requires a medium of exchange (money) and a way to enforce contracts. Traditionally these services have been provided by the government or government sponsored institutions and only to legal entities. In this article I describe a protocol by which these services can be provided to and by untraceable entities.</p>
</blockquote>

<p>I think the most interesting thing about this textfile was the fact that Dai had also envisioned smart contracts. Smart contracts are the second killer application for the blockchain, in my opinion, but a far more difficult problem to solve.</p>

<p>Of course, all of this ultimately culminated in the anonymous hacker Satoshi Nakamoto‚Äôs paper about Bitcoin, and the rest is history. So why then did this idea‚Äìoriginating from hackers, some even anonymous to this day‚Äìgrow so many leeches promising a completely new wave of technology startups?</p>


<p>I was very excited by an opportunity to learn more about all of this stuff when coming up with an idea to track finances with my brother, who is also currently my roommate. Previously, my brother and I had shared various household expenses by sending each other money over Square Cash. While I still think Square Cash is a wonderful service<sup id="fnref:5"><a href="#fn:5">2</a></sup>, at some point we tallied up all of the transactions we had sent over the period of multiple years and discovered that our sums were nearly identical! This means that in the end, if we hadn‚Äôt sent each other money at all, we still would‚Äôve been mostly square. Since we try to share the burden of household expenses anyway, this was not entirely surprising.</p>

<p>After making this discovery, we thought it would be cool to develop a very simple piece of software that just <em>kept track</em> of these expenses rather than transfer any money. Although my brother and I trust each other (for the most part), we thought it would be far more interesting if we assumed we couldn‚Äôt trust each other at all, and developed an Ethereum Smart Contract built on the blockchain instead of running something on a server that one of us would have to own and operate.</p>

<p>In short, developing this application on the blockchain instead of using a centralized server was extraordinarily difficult, and at one point even became unaffordable. Before going into details with that, let me switch back to talking about some of the promises and myths of the blockchain in general.</p>


<p>There are a lot of hollow promises for blockchain technology, mostly from business people who don‚Äôt completely understand it themselves. If you‚Äôve ever heard of a company who promised a ‚Äúrevolution in e-commerce‚Äù using the blockchain, this would be one of those. I won‚Äôt even mention the myriad of ‚Äúget rich quick‚Äù schemes here.</p>

<p>However, there are a lot of actual features of the blockchain that <em>could</em> be appealing to application developers. Notably:</p>

<ul>
  <li><strong>A decentralized database.</strong> Centralized stores of data, particularly for data that would be perilous to lose, is a centralized point of failure. Application developers who would like to make guarantees about database integrity could count on the fact that their data is distributed among a large set of nodes across the globe.</li>
  <li><strong>Users have the ability to audit smart contract code.</strong> Although the developer is responsible for the development of the original code for a smart contract, if the source code of the contract was somehow published, users of the smart contract could actually guarantee that the contract they‚Äôre interacting with is the same as the one they personally audited by comparing the compiled bytecode stored in an actual blockchain transaction. Since the contract cannot be changed after the fact<sup id="fnref:2"><a href="#fn:2">3</a></sup>, users can also have confidence that as long as they interact with a contract at a particular address, that guarantee will also not suddenly change in the future.</li>
  <li><strong>The data stored on the blockchain is tamper-proof.</strong> Since the contents (inputs) of a transaction cannot be changed after it has been mined into the blockchain, the users of a contract can guarantee that rows in this decentralized database will not suddenly disappear or change without their authority.</li>
  <li><strong>Transactions are not forgeable.</strong> Thanks to the promises of asymmetric key cryptography.</li>
</ul>

<p>Taken at face value, all of these promises are pretty cool. What about some of the <em>myths</em>?</p>


<ul>
  <li><strong>Interactions with the Blockchain are anonymous.</strong> In order for a decentralized network like this to function, all interactions with smart contracts must be published and made widely available. Interactions with the blockchain can be anonymous if users are extremely careful with their keys, but this is not often practical or even feasible<sup id="fnref:3"><a href="#fn:3">4</a></sup>.</li>
  <li><strong>Applications on the Blockchain can be made easy to use by normal people.</strong> This, in my opinion, is also not practical or feasible for the same reason why PGP (email encryption) never took off. I will discuss more about this later in this post.</li>
  <li><strong>The blockchain is ‚Äúunhackable.‚Äù</strong> While certainly <em>nice to have</em> in a world where data breaches are becoming evermore common, this is also not guaranteed by the blockchain by itself. <a href="https://www.nytimes.com/2016/06/18/business/dealbook/hacker-may-have-removed-more-than-50-million-from-experimental-cybercurrency-project.html">The Ethereum DAO hack</a> is an excellent counterexample of this.</li>
  <li><strong>The blockchain is a major cost-saving technology.</strong> Quite the opposite, in fact. The cost to run a distributed database is significantly higher regardless of how it is done<sup id="fnref:4"><a href="#fn:4">5</a></sup>.</li>
</ul>

<p>With that summarized, let me now explain how I came to learn all of this from personal experience‚Ä¶</p>


<p>We called our application ‚ÄúOctahedron‚Äù, named after the shape of the <a href="https://upload.wikimedia.org/wikipedia/commons/6/6f/Ethereum-icon-purple.svg">Ethereum logo</a>. It is implemented in two separate parts. The first part is the client, which we decided would be an iOS application (but could be anything), and the second part is the smart contract itself. The smart contract can be considered the ‚Äúserver‚Äù in a typical client-server abstraction, but of course since it‚Äôs distributed, there is no code that runs on one particular server.</p>

<p>We drafted out some of the features that we wanted before writing either the client or the smart contract, mostly coming from what we‚Äôre used to from Square Cash:</p>
<ul>
  <li>The ability to ‚Äúrequest money‚Äù from another person</li>
  <li>The ability to either approve or deny that request</li>
  <li>An easy to access balance between each of us, represented as a positive number (I am owed money) or negative number (I owe money)</li>
  <li>A historical record of previous requests</li>
</ul>

<h2 id="the-smart-contract">The Smart Contract</h2>

<p>Implementing these features using a smart contract ended up being extremely interesting given the constraints. For example, smart contracts have very limited storage, and the more ‚Äúspace‚Äù you use in your contract the more you have to pay. Also, contracts can‚Äôt necessarily store arbitrary rows of data inside of them like you can with a SQL database, for example.</p>

<p>The design of the smart contract ended up being two separate code implementations. A request for money owed is a smart contract itself. The smart contract contains all the metadata about the request, such as the amount of money requested, the debtor and debtee‚Äôs wallet addresses, and a short description of the request. These are called ‚Äúdebt requests‚Äù, and they‚Äôre not created by the users themselves, but instead by the ‚Äúmain contract‚Äù.</p>

<p>The main contract is another contract implementation who effectively provides an API for creating debt requests, and keeps track of the balance between us. Therefore, the only storage the main contract has is a running balance, which is simply the amount of money ‚Äúsent‚Äù by me minus the amount of money ‚Äúsent‚Äù by my brother. Sent is in quotes here, because no money is actually sent (not even cryptocurrency), only <em>debt</em> is sent.</p>

<p>A typical use case might be as follows:</p>

<ol>
  <li>Brother A pays $20 for a new lamp for the living room.</li>
  <li>Brother A sends a debt request to Brother B for $10. A contract interaction transaction with the main contract is posted to the Ethereum blockchain with all of the metadata needed:
    <div><div><pre><code>Debtor: Brother A
Debtee: Brother B
Amount: 1000 (USD in cents)
Description: New Lamp
</code></pre></div>    </div>
  </li>
  <li>The main contract emits a <code>DebtRequested</code> event, containing the new debt request smart contract.</li>
  <li>Brother A sends a link to the debt request smart contract somehow, usually via the transaction hash or the address to the smart contract itself, to Brother B.</li>
  <li>Upon inspection of the metadata for the debt request contract, Brother B approves the debt request by ‚Äúfulfilling‚Äù it.</li>
  <li>When fulfilling the debt request, the balance is updated in the main contract and the state of the debt request moves from ‚Äúcreated‚Äù to ‚Äúfulfilled‚Äù.</li>
</ol>

<p>Notice that an important feature about the way this works is that the balance is not updated <em>until the debt ‚Ä¶</em></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://buzzert.net/posts/2020-11-01-octahedron">https://buzzert.net/posts/2020-11-01-octahedron</a></em></p>]]>
            </description>
            <link>https://buzzert.net/posts/2020-11-01-octahedron</link>
            <guid isPermaLink="false">hacker-news-small-sites-25052857</guid>
            <pubDate>Tue, 10 Nov 2020 22:21:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exodus of Silicon Valley]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 83 (<a href="https://news.ycombinator.com/item?id=25052818">thread link</a>) | @Reedx
<br/>
November 10, 2020 | https://breakingground.us/exodus/ | <a href="https://web.archive.org/web/*/https://breakingground.us/exodus/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4180">
					
					
					
					
					<div>
					<p>On the day the sun didn‚Äôt rise in San Francisco, the early warning signs came through the screen. The 6:30 a.m. Zoom always requires unnatural light, making the outlines of faces fuzzy. The natural morning light, combined with the ‚ÄúTouch Up My Appearance‚Äù feature on 2020‚Äôs preferred video conferencing system, hides the marks of age and sleeplessness that most of us seek to mask. But by 9:00, the fluorescent light was still dominating the screen, and the darkness outside our windows had turned to infernal orange.</p>
<p>The scientific explanation for our sunless day in September is pretty dull. The clouds of soot from the largest California wildfire in history intermixed with the Bay Area‚Äôs perennial fog, turning the usual sepia hue of dirty global cities into an apocalyptic blood-orange sky. Though Twitter blamed the hellscape on far more menacing forces, the direct cause of our Blade Runner Day was mostly carbon clinging to the blue-light hues while letting the red pierce through.</p>
<p>If we were more like ancient peoples, many joked, we would assume the gods were enraged. We‚Äôd be running for the hills to escape their wrath, or at least head straight for our prepper bunkers. That we are unlike ancient people is actually the only myth, as this is exactly the exodus that is happening in Silicon Valley right now‚Äîand will continue for the next few years as true believers deliver themselves from this promised land.</p>
<p><a href="https://breakingground.us/from-ashes/">It‚Äôs time to build</a>, yes. But it‚Äôs also time to leave.</p>
<p>The battle over tech‚Äôs supremacy has been waged and all of our premonitions came true: We wanted flying cars and got vertical take-off innovation hubs from every car maker in America. Software has not only eaten the world, but feasted on your screen-weary eyes. It has swallowed your children, your church, your bank, and your politics, and somehow it all feels inevitable. That these feats of human progress‚Äîof instant connectivity in a now homebound world‚Äîbecame the scapegoat of our time is another symptom of the era‚Äôs end, cueing the quiet exodus of builders who had bigger aspirations than the same-day shipping that keeps our households afloat.</p>
<p>Now, Silicon Valley is witnessing a reckoning, but it‚Äôs not the long-awaited one predicted by the New York press, or the antitrust bonanza that Washington longs for because too many people seem satisfied getting their news from Facebook. The reckoning is more of a realization that tech exceeded expectations and somehow squandered the fruit of its own garden, and that a city on a hill that could have supported so much innovation was not Florence in the Renaissance nor the Athenian Academy with MacBooks. Rather, it became a government-sponsored needle exchange, a haven for the homeless and forgotten that put government‚Äôs paralysis on display downtown on Market Street.</p>
<blockquote><p>2020 is not the great reckoning predicted in the book of Revelation, despite the fires, the plagues, and the wailing on Twitter. It is the resignation and determination of Exodus, of a dogged people packing up U-Hauls and fleeing this frontier state to seek an even newer, more eternal world.</p></blockquote>
<p>San Francisco had four times as many deaths from overdose this year as it did from the COVID-19 virus.</p>
<p>2020 is not the great reckoning predicted in the book of Revelation, despite the fires, the plagues, and the wailing on Twitter. It is the resignation and determination of Exodus, of a dogged people packing up U-Hauls and fleeing this frontier state to seek an even newer, more eternal world.</p>
<p>* * *</p>
<p>The computer revolution of the late twentieth century has yet to be named as an epoch, but we can assume that nomenclature will begin in the coming years, alongside the battle for what it all really meant.</p>
<p>What we now call our ‚Äútechnological age‚Äù was supposed to be a full-throated and enduring argument for the future, not unlike previous epochs in history that pushed art, science, philosophy, and religion forward in dizzying ways that run counter to ordinary time. The Enlightenment. The Renaissance. The French Revolution. These movements now sit as categories on our bookshelves with clear beginnings and ends, and more importantly, clear hubs and cities of frenetic building that drove the ethos forward. Many books assume that contemporary critics or philosophers were blissfully ignorant to the unraveling of their revolutions, but we should not assume that contemporaries did not feel the same twilight setting. The figurative orange skies always creep in before dawn.</p>


<p>Which brings us to the supposed death of Silicon Valley, a fate that has long been predicted but with data now finally catching up. San Francisco apartment rents in 2020 have deflated by 20 percent after an up-up-and-away decade that made the city truly unlivable. Home inventory has reached a fifteen-year high in a city blighted by restrictive housing policy that makes construction cranes as miraculous as stumbling upon a burning bush. The growth in online sales-tax collection, according to the <em>San Francisco Chronicle</em>, is the lowest of all counties in the state of California. And public tech companies, such as Pinterest, paid upwards of $90 million to break its lease in downtown San Francisco. Some would argue this is a clear end to Bay Area tech dominance, while others would point to the many new unicorns that popped up this year despite the once-in-a-century pandemic. No one‚Äôs living here, yet somehow the companies are still growing.</p>
<p>Silicon Valley doesn‚Äôt really have cultural critics to weigh in on whether this era is officially over, but we do have venture capitalists. And our Nostradomuses are telling us that change is afoot.</p>
<p><em>Do we really need this office? The founders all have left.</em></p>
<p><em>Their entire partnership is now living in Montana. It‚Äôs only a two-hour flight away!</em></p>
<p><em>Denver seems like a good option, but Reno has no state income tax.</em></p>
<p>The weirdness of this exodus is that it is not driven by fear. Technologists weren‚Äôt <em>really </em>driven out by plague or fire or San Francisco‚Äôs insatiable need for higher tax revenue. Those ills were always apparent, and yet people stayed to carry the torch.</p>
<p>The exodus of tech‚Äôs true believers may be that the covenant is finally fulfilled. That when America‚Äîalong with the rest of the world‚Äîmet their darkest hour and turned inward, the technology that was long ridiculed as frivolous or dangerous led us to relative normalcy. The Zooms. The Tiger Kings. The Signal chats. The Slack jokes. An election news cycle that plowed ruthlessly forward on Twitter. Though inconvenient, mothers and fathers set their children in front of screens to occupy them for <em>just</em> long enough to survive a terrible year. And maybe, just maybe, the same-day-shipping racket that made Jeff Bezos the richest man alive was actually a feat of human genius that held the country together when public infrastructure and the social fabric were fraying at the seams. Perhaps our lowly software revolution was actually the fruition of a long-held California dream, when the physical world forced us inside and virtual life prevailed.</p>
<blockquote><p>Silicon Valley is no longer a place, they‚Äôll say. It‚Äôs a way of being, of building, and the latest embodiment of belief in human progress. And it‚Äôs spreading faster than the viruses and the wildfires and the apocalyptic threats that mire our physical world.</p></blockquote>
<p>For that triumph, the nerds can now smell the impending scapegoating of their success. And like so many of history‚Äôs prophets and heretics, those who believe most fervently in the promise of technology are beginning their long march away from the Valley.</p>
<p>And they will substitute the virtual world for the physical space that once defined this movement. Silicon Valley is no longer a place, they‚Äôll say. It‚Äôs a way of being, of building, and the latest embodiment of belief in human progress. And it‚Äôs spreading faster than the viruses and the wildfires and the apocalyptic threats that mire our physical world.</p>
<p>Silicon Valley is over. The exodus is just beginning.</p>
					</div> <!-- .entry-content -->

				
				</article></div>]]>
            </description>
            <link>https://breakingground.us/exodus/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25052818</guid>
            <pubDate>Tue, 10 Nov 2020 22:19:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top 10 Most Important SQL Commands to Know]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25052742">thread link</a>) | @jackmcclelland
<br/>
November 10, 2020 | https://blog.arctype.com/sql-cheat-sheet-top-10-most-important-sql-commands-to-know/ | <a href="https://web.archive.org/web/*/https://blog.arctype.com/sql-cheat-sheet-top-10-most-important-sql-commands-to-know/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <figure><img src="https://blog.arctype.com/content/images/2020/11/SQL-Cheat-Sheet.png" alt="" srcset="https://blog.arctype.com/content/images/size/w600/2020/11/SQL-Cheat-Sheet.png 600w, https://blog.arctype.com/content/images/size/w1000/2020/11/SQL-Cheat-Sheet.png 1000w, https://blog.arctype.com/content/images/2020/11/SQL-Cheat-Sheet.png 1440w"></figure><p>As companies and organizations find themselves dealing with rapidly increasing amounts of data, there's a growing need for developers to effectively use databases to handle this data. SQL, which stands for Structured Query Language, is a programming language that helps manage data stored in relational databases (a popular type of database).</p><p>SQL commands can help a developer create tables, add and modify data in these tables, search the database, and more. This article will cover a list of ten basic SQL commands that are essential to know for developers working with SQL. You'll find for each SQL command a code snipped and brief description of what the code runs.</p><p>Whether you're a beginner or a pro at SQL, consider trying out <a href="http://arctype.com/"><strong>Arctype</strong></a>, a redesigned SQL client for PostgreSQL and MySQL developers and teams. It's free, fast, and easy-to-use: <a href="http://arctype.com/" rel="noopener noreferrer">http://arctype.com/</a></p><p>Let's get right into it! Here are ten basic building blocks of SQL programming.</p><hr><!--kg-card-begin: markdown--><h2 id="createtable">CREATE TABLE</h2>
<pre><code>CREATE TABLE table_name (
  column_1 datatype_1, 
  column_2 datatype_2, 
  column_3 datatype_3
);
</code></pre>
<!--kg-card-end: markdown--><p>This command allows you to create a new database or table; the example above adds a new table with a title and column names.</p><!--kg-card-begin: markdown--><h2 id="altertable">ALTER TABLE</h2>
<pre><code>ALTER TABLE table_name 
ADD column_name datatype;
</code></pre>
<!--kg-card-end: markdown--><p>Run this command to modify (add, drop, rename, etc) the structure (not the data) in your database; the example above adds a new column to a table with a specified datatype.</p><!--kg-card-begin: markdown--><h2 id="delete">DELETE</h2>
<pre><code>DELETE FROM table_name
WHERE some_condition = some_value;
</code></pre>
<!--kg-card-end: markdown--><p>This command can delete data from your table based on conditions specified with the WHERE keyword.</p><!--kg-card-begin: markdown--><h2 id="drop">DROP</h2>
<p><code>DROP TABLE table_name;</code></p>
<!--kg-card-end: markdown--><p>Similar to the create command, DROP deletes a database or table. Be careful when using this command ‚Äì the code above will delete your whole table, including all data, indexes, and more.</p><!--kg-card-begin: markdown--><p><code>ALTER TABLE table_name DROP COLUMN column_name;</code></p>
<!--kg-card-end: markdown--><p>The ALTER TABLE and DROP statement above will remove a specific column from a table.</p><!--kg-card-begin: markdown--><h2 id="insertinto">INSERT INTO</h2>
<pre><code>INSERT INTO table_name (column_1, column_2, column_3) 
VALUES (value_1, value_2, value_3);
</code></pre>
<!--kg-card-end: markdown--><p>To add new records to your table, use the INSERT INTO command. You can use this command on one or more rows.</p><!--kg-card-begin: markdown--><h2 id="select">SELECT</h2>
<pre><code>SELECT column_name 
FROM table_name;
</code></pre>
<!--kg-card-end: markdown--><p>Every query begins with SELECT; this is how you grab data from your database. It's the most fundamental SQL query. After the SELECT command, you can use the keyword FROM to specify a table, the keyword WHERE to select with conditions, and the keyword ORDER BY to sort your results.</p><!--kg-card-begin: markdown--><h2 id="update">UPDATE</h2>
<pre><code>UPDATE table_name
SET some_column = some_value
WHERE some_column = some_value;
</code></pre>
<!--kg-card-end: markdown--><p>This command lets you edit data in your table by updating data based on conditions specified after the WHERE keyword.</p><!--kg-card-begin: markdown--><h2 id="as">AS</h2>
<pre><code>SELECT column_name AS 'Alias'
FROM table_name;
</code></pre>
<!--kg-card-end: markdown--><p>The AS keyword allows you to use a temporary alias when referring to a column or table.</p><!--kg-card-begin: markdown--><h2 id="count">COUNT</h2>
<pre><code>SELECT COUNT(column_name)
FROM table_name;
</code></pre>
<!--kg-card-end: markdown--><p>Use the COUNT() function to add up the number of rows where the specified column is not NULL.</p><!--kg-card-begin: markdown--><h2 id="between">BETWEEN</h2>
<pre><code>SELECT column_name(s)
FROM table_name
WHERE column_name BETWEEN value_1 AND value_2;
</code></pre>
<!--kg-card-end: markdown--><p>This operator filters the results to be within a specified range (numbers, text, dates, etc).</p><hr><p>These building blocks will get you started programming with SQL, which is a great language useful and definitely worth learning in 2020. Check out the <a href="https://insights.stackoverflow.com/survey/2020">StackOverflow Developers Survey 2020</a>, where 65k developers answered questions about the programming languages and tools they run: SQL was top three in the most popular technologies question!</p><figure><img src="https://blog.arctype.com/content/images/2020/11/devdev.png" alt="" srcset="https://blog.arctype.com/content/images/size/w600/2020/11/devdev.png 600w, https://blog.arctype.com/content/images/2020/11/devdev.png 900w" sizes="(min-width: 720px) 720px"><figcaption>If you're curious you can check out the rest of the results of the survey here at the URL here: <a href="https://insights.stackoverflow.com/survey/2020" rel="noopener noreferrer">https://insights.stackoverflow.com/survey/2020</a></figcaption></figure><p>Database programming languages are popular and have active developer communities, and are becoming increasingly important as organizations seek to process the thousands of terabytes of data generated each day. If you're working with databases in SQL or are planning on doing so, check out the newly-designed <a href="http://arctype.com/"><strong>Arctype</strong></a> SQL client. It's faster and easier-to-use than many of the clients out there right now and is designed with your needs in mind as a modern developer.</p><p>Thanks for checking out my article covering these ten basic SQL commands! Let me know if you have any questions, or would like me to write a follow-up post with more intermediate SQL commands to check out. Happy coding!</p>
            </div></div>]]>
            </description>
            <link>https://blog.arctype.com/sql-cheat-sheet-top-10-most-important-sql-commands-to-know/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25052742</guid>
            <pubDate>Tue, 10 Nov 2020 22:12:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Borg, confidence in backups, GtkPod and software preservation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25052714">thread link</a>) | @edward
<br/>
November 10, 2020 | https://jmtd.net/log/gtkpod/ | <a href="https://web.archive.org/web/*/https://jmtd.net/log/gtkpod/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content">
<p>Over the summer I decided to migrate my backups from <em>rdiff-backup</em> to <em>borg</em>,
which offers some significant advantages, in particular de-duplication, but
comes at a cost of complexity, and a corresponding sense of unease about how
sound my backup strategy might be. I've now hit the Point Of No Return: my
second external backup drive is overdue being synced with my NAS, which will
delete the last copy of the older rdiff-backup backups.</p>

<p>Whilst I hesitate over this last action to commit to borg, something else
happened. My wife wanted to put a copy of her iTunes music library on her
new phone, and I couldn't find it: not only could I not find it on any of
our computers, I also couldn't find a copy on the NAS, or in backups, or even
in old DVD-Rs. This has further knocked my confidence in our family data
management, and makes me even more nervous to commit to borg. I'm now wondering
about stashing the contents of the second external backup disk on some cloud
service as a fail-safe.</p>

<p>There was one known-good copy of Sarah's music: on her ancient iPod Nano.
Apple have gone to varying lengths to prevent you from copying music <em>from</em> an
iPod. When Music is copied <em>to</em> an iPod, the files are stripped of all their
metadata (artist, title, album, etc.) and renamed to something non-identifying
(e.g. <code>F01/MNRL.m4a</code>), and the metadata (and correlation to the obscure file
name) is saved in separate database files. The partition of the flash drive
containing all this is also marked as "hidden" to prevent it appearing on macOS
and Windows systems. We are lucky that the iPod is so old, because Apple went
even further in more recent models, adding a layer of encryption.</p>

<p>To get the music off the iPod, one has to undo all of these steps.</p>

<p>Luckily, other fine folks have worked out reversing all these steps and
implemented it in software such as libgpod and its frontend, GtkPod, which
is still currently available as a Debian package. It mostly worked, and I got
back 95% of the tracks. (It would have been nice if GtkPod had reported the
tracks it <em>hadn't</em> recovered, it was aware they existed based on the errors
it did print. But you can't have everything.)</p>

<p>GtkPod is a quirky, erratic piece of software, that is only useful for old
Apple equipment
that is long out of production,
prior to the introduction of the encryption.
The upstream homepage is dead, and I suspect it is unmaintained.
The Debian package is orphaned. It's been removed from testing, because
it won't build with GCC 10. On the other hand, my experience shows that it
<em>worked</em>, and was <em>useful</em> for a real problem that someone had today.</p>

<p>I'm in two minds about GtkPod's fate. On the one hand, I think Debian has far
too many packages, with a corresponding burden of maintenance responsibility
(for the whole project, not just the individual package maintainers), and
there's a quality problem: once upon a time, if software had been packaged in
a distribution like Debian, that was a mark of quality, a vote of confidence,
and you could have some hope that the software would work and integrate well
with the rest of the system. That is no longer true, and hasn't been in my
experience for many years. If we were more discerning about what software we
included in the distribution, and what we kept, perhaps we could be a leaner
distribution, faster to adapt to the changing needs in the world, and of a
higher quality.</p>

<p>On the other hand, this story about GtkPod is just one of many similar stories.
Real problems have been solved in open source software, and computing
historians, vintage computer enthusiasts, researchers etc. can still benefit
from that software long into the future. Throwing out all this stuff in the
name of "progress", could be misguided. I'm especially sad when I see the glee
which people have expressed when ditching libraries like Qt4 from the archive.
Some software will not be ported on to Qt5 (or Gtk3, Qt6, Gtk4, Qt7, etc., in
perpetuity).  Such software might be all of: unmaintained, "finished", and
useful for some purpose (however niche), all at the same time.</p>

</section></div>]]>
            </description>
            <link>https://jmtd.net/log/gtkpod/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25052714</guid>
            <pubDate>Tue, 10 Nov 2020 22:10:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quantopian's open-source investment dream died]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25052699">thread link</a>) | @ugwigr
<br/>
November 10, 2020 | https://www.businessofbusiness.com/articles/how-quantopian-died-shut-down-quant-investment-robinhood/ | <a href="https://web.archive.org/web/*/https://www.businessofbusiness.com/articles/how-quantopian-died-shut-down-quant-investment-robinhood/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-section">
    <!-- .sidebar -->

    <section>
      
      

      <p>Back in 2011, John Fawcett and Jean Bredeche had the dream of democratizing investing. They envisioned a platform that would make quantitative analysis and investment accessible and understandable for anyone who was keen to give it a try, kicking down doors for the everyman that had mostly been open to hedge funds or super-rich angel investors until that point.</p>
<p>Quantopian was launched off the back of that dream. A platform that taught users about quant investment and gave them a platform to write and save their own code, Quantopian was supposed to be the first crowd-sourced hedge fund. For years, users iterated on each other‚Äôs code as a community developed on the platform, full of users with and without financial backgrounds. These users would pit their algorithms against one-another, and Quantopian would go on to use the winning equations to manage investor assets, giving the winners some returns.&nbsp;</p>
<p>Fawcett and Bredeche would go on to raise $48.8 million for Quantopian in the meantime. In 2016, Steven Cohen announced that he would be teaming up with Quantopian to the tune of $250 million, relying on some of the user models Quantopian managed and investing in Quantopian itself.</p>
<p><span>In February, the first cracks in the city wall took hold. For at least two years, Fawcett said in </span><a href="https://www.bizjournals.com/boston/news/2020/02/20/fintech-firm-quantopian-is-returning-investors.html"><span>an interview</span></a><span>, Quantopian‚Äôs low-risk, market-neutral strategy model hadn‚Äôt been yielding results. Fawcett and Bedeche announced that the company would be returning investor money and switching strategies in an attempt to keep things afloat, </span><a href="https://www.quantopian.com/posts/quantopian-strategic-pivot"><span>asking that users</span></a><span> now develop models beyond the market-neutral ones the company had relied on for years.</span></p>
<p>Now, the dream is dead.</p>
<p><span>This week, Quantopian </span><a href="https://www.quantopian.com/posts/quantopians-community-services-are-closing"><span>abruptly announced</span></a><span> that it would be shutting down its community services and that users would lose access to all their materials if not saved locally by November 14. No reason was given for the shutdown.&nbsp;</span><span>Quants across the finance community expressed equal parts shock and disappointment that Quantopian had </span><a href="https://www.linkedin.com/posts/dr-tom-starke-a0a9a3b3_tribute-to-quantopian-activity-6728150978325045248-Lrsf/"><span>come crashing down</span></a><span>.&nbsp;</span></p>
<p>‚ÄúOur mission was to break open quant finance and make it accessible to everyone,‚Äù Fawcett wrote in a blog post on Quantopian‚Äôs website. "You helped realize this mission and came together to form the biggest community of quants the world has ever seen. For that, I am extremely proud and grateful. I sincerely hope that Quantopian is just one milestone in your journey through quantitative finance.‚Äù</p>
<p>The announcement was met with mixed reception. Some users gave tearful goodbyes to the platform and expressed interest in crowdfunding the site, while others expressed outrage at the seemingly abrupt decision.&nbsp;</p>
<hr>
<blockquote>
<h2>"Was there a heads-up so we could retrieve our results? backtests? :("</h2>
</blockquote>

<blockquote>
<h2>"My god no. is there any way to save the quantopian community site ??? why is this site closing down???"</h2>
<h2>"0-day notice! Are you kidding me &gt; where is all the code ???"</h2>
</blockquote>
<hr>
<p>Fawcett gave no answers. Users wondered the extent to which Quantopian would disappear; would the lectures and learning resources be preserved online somewhere? Would they be able to recover assets of theirs which had already been taken down? Where would they go to chat and organize with other quants and finance junkies?&nbsp;</p>
<p>The name Quantopian gave itself proved to be an ominous foreshadowing of its eventual fate. All utopias must fall, and Quantopian‚Äôs democratic dream had turned to sand and fallen through users' fingers before they could come to grips with what was happening.&nbsp;</p>
<p><span>In 2020, Quantopian‚Äôs dream of ‚Äúdemocratizing finance‚Äù isn‚Äôt unique. Trading app Robinhood touts </span><a href="https://robinhood.com/us/en/support/articles/our-mission/#:~:text=Robinhood's%20mission%20is%20to%20democratize,for%20newcomers%20and%20experts%20alike."><span>the exact same mission</span></a><span>, and it‚Äôs trying to pick up where Quantopian left off. Yesterday, Fawcett announced that Quantopian and Robinhood would be </span><a href="https://www.quantopian.com/posts/were-joining-robinhood"><span>coming together</span></a><span> in what he described as a natural fit for the two companies.&nbsp;</span></p>
<p><span>‚Äú</span><span>Quantopian has always stood for greater access and deeper education, so we are fundamentally aligned with Robinhood‚Äôs mission to democratize finance for all,‚Äù Fawcett wrote. ‚ÄúOur merry band of Quantopians should fit right in as we work together to further expand access to financial information and education, and inspire greater participation in the financial markets.‚Äù</span></p>
<p>Fawcett offered little details as to how this deal would take form, but one thing was clear: the Quantopian of old would no longer exist.</p>
<p>These platforms are more than the sum of their parts, and Quantopian‚Äôs community structure ‚Äî the factor which most makes it unmistakably itself ‚Äî will not be preserved by Robinhood.&nbsp;</p>
<p>Robinhood has grown to considerable size and been downloaded by an ever-increasing number of users during the COVID-19 pandemic who are using it to invest and, hopefully, make a little extra money during trying times. Or, if they‚Äôre lucky enough, make it big.&nbsp;</p>
<p><span>But although Robinhood shares the same mission as Quantopian at first glance, it is propped up on something much uglier than Quantopian ever was. Robinhood lacks a community element, and what implementations it has tried have had </span><a href="https://fortune.com/2020/08/10/robinhood-popularity-data-robintrack-stock-market-trading-tracker/"><span>disastrous impacts</span></a><span>. A read through the replies to Quantopian‚Äôs shutdown announcement reveal the deep histories users had on the platform.</span></p>
<p>‚ÄúWithin a few months after joining in 2016, I'd learned Python, programmed all of my Excel-based strategies, entered and won Contest 22, [and] started live trading in IB,‚Äù user Roman Parker wrote. ‚ÄúWith no relevant degree or experience, I was interviewing at large NYC funds. Q was changing my life.‚Äù</p>
<hr>
<blockquote>
<h2>"Never in my life have i seen a place where so many smart people were willing to share so much information with me without expecting anything in return. I am and will forever be grateful for what you have done for me." ‚Äî Quantopian user Mattias Lamonte</h2>
</blockquote>

<hr>
<p>The communities that have sprouted up around Robinhood‚Äôs success are much darker. Communities like r/wallstreetbets and viral videos like the infamous ‚Äú<a href="https://www.youtube.com/watch?v=A-tNkuYV4_Q">wsb yolo</a>,‚Äù which shows a man losing tens of thousands of dollars on the app in real time, keep sincerity at an arm‚Äôs length and sustain themselves with desperate humor. Though the output of Quantopian‚Äôs community was ultimately gobbled up by Quantopian itself and its investors, what Quantopian provided to its users was collaboration and experience. Robinhood‚Äôs frenzy is about who can win big, and who can lose bigger.</p>
<p><span>Even if the business end couldn‚Äôt keep itself afloat, the utopia existed, for a time, for the site‚Äôs users, many of whom had their lives and careers changed by Quantopian‚Äôs open platform and its catalog of resources. Today, other services like Quantiacs and QuantConnect operate off similar models to Quantopian‚Äôs. The first to do something isn‚Äôt always the best to do it, and perhaps one of these companies will perfect what Quantopian initially set out to do.</span></p>
<p>These lives wouldn't have been impacted if Quantopian had not put out the rallying call, but ultimately, users didn't need Quantopian as much as Quantopian needed them.&nbsp;Quantopian gave them the first rocks and sticks, and the community used it to build cities. In the end, it was the failure of the company itself, not those who used its tools, to deliver on the promise that attracted such a large community to begin with.</p>
      

      

      



    </section><!-- .article-body -->

    
  </div></div>]]>
            </description>
            <link>https://www.businessofbusiness.com/articles/how-quantopian-died-shut-down-quant-investment-robinhood/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25052699</guid>
            <pubDate>Tue, 10 Nov 2020 22:09:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Birth of Unix with Brian Kernighan [audio]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25052605">thread link</a>) | @spinningslate
<br/>
November 10, 2020 | https://corecursive.com/brian-kernighan-unix-bell-labs1/ | <a href="https://web.archive.org/web/*/https://corecursive.com/brian-kernighan-unix-bell-labs1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>When you work on your computer, there are so many things you take for granted: operating systems, programming languages, they all have to come from somewhere. </span></p><p><span>In the late 1960s and 1970s, that somewhere was Bell Labs, and the operating system they were building was UNIX. </span></p><p><span>They were building more than just an operating system though. They were building a way to work with computers that had never existed before.&nbsp; </span></p><p><span>In today‚Äôs episode I talk to Brian Kernighan about the history of Unix.</span></p><p><span>‚ÄúIf you wanted, you could go sit in your office and think deep thoughts or program, or write on your own blackboard or whatever, but then come back to the common space when you wanted to.‚Äú ‚Äì Brian Kernighan </span></p><p><span>‚ÄúI found it easier to program when I was trying to figure out the logic for myself rather than trying to figure out where in the infinite stack of documentation was the function I needed. So for me, programming is more like creating something rather than looking it up, and too much of today‚Äôs programming is more like looking it up.‚Äù ‚Äì Brian Kernighan </span></p><p><span>‚ÄúIf what I find challenging or hard or whatever is also something that other people find hard or challenging or whatever, then if I do something that will improve my lot, I‚Äôm perhaps improving their lot at the same time.‚Äù ‚Äì Brian Kernighan</span></p><p><span><strong>Links:</strong></span></p><p><a href="https://www.cs.princeton.edu/people/profile/bwk" target="_blank" rel="noopener noreferrer">Brian‚Äôs Homepage</a></p><p><a href="https://www.amazon.com/dp/1695978552" target="_blank" rel="noopener noreferrer">Book: Unix: A History and a Memoir</a></p></div></div>]]>
            </description>
            <link>https://corecursive.com/brian-kernighan-unix-bell-labs1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25052605</guid>
            <pubDate>Tue, 10 Nov 2020 22:01:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Boring Tech Is More Fun]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25052491">thread link</a>) | @amzans
<br/>
November 10, 2020 | https://panelbear.com/blog/boring-tech/ | <a href="https://web.archive.org/web/*/https://panelbear.com/blog/boring-tech/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Over the years I have observed that many engineers tend to attribute much of the success or failure of a company to the technical choices made. I know I‚Äôm often guilty of this too. And while it is often justified, I would argue that for the vast majority of startups out there, the choice of programming language, framework, or even database doesn‚Äôt matter that much. This seems especially true during the early stages.</p><h2>Through the engineering lens</h2><p>This perception is understandable, we as engineers tend to look at the world from a specific lens, and are often biased by what we know best. Our daily activities may include things such as debugging CI pipelines, implementing new features, pairing with colleagues, or migrating the always present legacy codebase. The environment that surrounds us makes it easy to believe that it all boils down to those things that we see and understand. It‚Äôs an illusion that makes us feel like we‚Äôre fully in control of what makes or breaks the product.</p><p>Don‚Äôt get me wrong, it can be a huge advantage for many companies to make their product 3x more efficient than competitors, or to have elegant, composable code. But you might be focusing on the wrong problems if nobody cares about the product you‚Äôre actually building, and sooner or later your business will hit this wall.</p><p>I‚Äôm not saying that software doesn‚Äôt matter. A solid foundation for your startup goes a long way. If investing in this allows you to build better features faster than your competitors, more power to you. But finding the right balance is highly dependent on what you‚Äôre trying to solve and the resources you have at hand. There‚Äôs no right or wrong way to do it, and as usual, it mainly comes down to tradeoffs.</p><p><img src="https://panelbear.com/static/img/blog/lenses.png" alt="Different lenses"></p><h2>Boring makes me happy</h2><p>I believe aiming for a healthy balance of risk vs reward when it comes to your technical choices is something to strive for. In particular, if it decreases the chances you get stuck on the wrong problems down the road.</p><p>This is why I have come to appreciate ideas such as <a href="https://mcfunley.com/choose-boring-technology">Choose Boring Technology</a>. This is often interpreted as ‚Äúpicking old technologies over newer ones‚Äù, but it doesn‚Äôt necessarily mean that. For me, this comes down to using proven technologies in which the ways it can fail are mostly known, but occasionally experimenting with different, possibly newer tools that might suit me better.</p><p>Maybe you want to gain more experience by using the latest framework or programming language, or you just want to have some fun. You do what makes you happy. But if you‚Äôre trying to make a decision to increase the odds that your product or business will succeed, it‚Äôs worth stepping back and considering your options.</p><p>For me, mainly choosing software that has been around for longer is not about it being boring or older, it‚Äôs about the fact that the ways in which it fails are better known. There are fewer unknowns for you to deal with and this maximizes your chances of actually shipping the project.</p><p>For example the other day I had an issue with my Django app, and a quick search led me to tens of answers to this problem in various forums and websites. It took me at most 10 minutes to get back on track and that was the end of this issue.</p><p>I experienced the exact opposite a few years ago with a popular, but not so battle-tested Scala library my team had been using for a while. We were probably among the first to encounter the issues we were facing, and it seemed nobody had walked down this path before. Maybe it sounds like a fun challenge or a great chance to contribute back to OSS (which I‚Äôm happy to), but once you solve it, do your customers really care about it? How many days, weeks, or even months are you willing to invest in such issues? In my case, I‚Äôd rather use that time to ship new features or improve the existing ones.</p><h2>Proven tech vs new tools</h2><p>I try to follow an 80/20 distribution when it comes to my choice of tools. This means my stack consists of about 80% software I already know well, but I do allow myself 20% of the stack to explore tech I have less experience with. The exact ratio is not what‚Äôs important here, it‚Äôs more the fact that you should lean towards using proven technologies.</p><p>This also resonates with how <a href="https://en.wikipedia.org/wiki/Multi-armed_bandit">Multi-armed bandits</a> work. You try to maximize your expected gain by taking advantage of what worked well in the past, while sometimes exploring new things to avoid missing out on a possible goldmine.</p><p><img src="https://panelbear.com/static/img/blog/bandits.png" alt="Balance new vs proven"></p><p>A more recent example of mine is <a href="https://panelbear.com/">Panelbear</a>, it started as an embarrassingly simple Django app with no charts, all metrics were rendered on a plain HTML table, and all data was stored on a SQLite database. Took literally a weekend to get it up and running including manually deploying to a $5/mo VM. Low risk and high reward for my needs at the time.</p><p>Fast forward and as I added more features and began handling more page views for various websites, I started to notice that the codebase could use some refactoring. It also became increasingly repetitive to do things like deploying to new instances, issuing SSL certs, and keeping the DNS records up to date in case the IP address of my instances changed.</p><p>As a second iteration, I upgraded to a docker-compose setup plus lots of glue code. But soon enough I found myself reinventing what other tools already do well. There are multiple ways to solve each of these pain points, but in my case, it came down to using a tool I am very familiar with from my full-time job: Kubernetes.</p><p>Yes, I am well aware Kubernetes is an absolute overkill for a lot of projects out there, and I could have gotten away with a more traditional solution. But it allowed me to simplify the operational aspects tremendously, and I feel comfortable working with it after having the pleasure of putting down multiple production fires for my employer over the years. That‚Äôs why I wouldn‚Äôt bindly recommend it to everyone. Do what you know best.
As an added benefit, it also made it trivial when I migrated from DigitalOcean to Linode, and most recently to AWS (each migration took mostly an evening of changing my Terraform files and deploying them - I‚Äôm being serious). But that‚Äôs for another post.</p><p>Another case in which it paid off once again, was when I wanted to experiment with using Clickhouse for data ingestion and the aggregation queries. It took me less than 10 minutes to write a basic deployment manifest and have it up and running. This included automated SSL certs, in-cluster service discovery, and unified logging/monitoring out of the box. It was a huge win since it allowed me to try things out faster than before.</p><p>Even better, I can deploy any container and operate it the exact same way as I deploy anything else on my cluster. Need more volume storage with zero downtime? It‚Äôs a simple manifest change, commit and deploy. Same thing when I needed Redis for caching, I was up and running in minutes, without increasing my costs or adding operational complexity.</p><h2>Focus on shipping</h2><p>My point is, I moved into these technologies as the pain with the previous solution was higher than dealing with the new tech. But more importantly, it helped me ship features even faster to my customers while reducing the operational overhead for me.</p><p>If I had started with the more advanced setup from day one, I might have lost all motivation before I would have had the first version of Panelbear. The key is to solve the problems that are getting between you and your goals, not potential issues you believe one day will be yours.</p><p>Hope you enjoyed this blog post. I plan on writing more about Panelbear‚Äôs tech stack, and lessons learned along the way. So stay tuned!</p></div></div></div>]]>
            </description>
            <link>https://panelbear.com/blog/boring-tech/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25052491</guid>
            <pubDate>Tue, 10 Nov 2020 21:52:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I find 10x more content on Twitter in half the time]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25052286">thread link</a>) | @justanotherpm
<br/>
November 10, 2020 | https://blog.justanotherpm.com/discover-10x-more-content-on/ | <a href="https://web.archive.org/web/*/https://blog.justanotherpm.com/discover-10x-more-content-on/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<div>
    <main>
            <article>
    
    <div>
            <p>I am an avid Twitter user, and my Twitter goals are to consume meaningful content and share similarly interesting content with my followers. If in the process, I end up getting more followers, I welcome them with a smile.</p><p>I've always found that <em>discovering</em> good content is a more significant challenge than <em>sharing</em> useful content. Over the years, I've developed the following system to help me consume better content faster:</p><ol><li>Rather than following hundreds of accounts, I create Twitter lists and add relevant users to each list. For example, I have a list called "Product Tweeple", which includes those accounts which share relevant and interesting content on product management. Now, instead of aimlessly browsing my home feed, I scan the lists that I'm interested in at that time.</li><li>I like to know about certain content or events as soon as it's shared. For such accounts, I use the notification feature with the "all tweets" option. These are accounts that I like to engage with, and, secretly, want to be the first one to reply, like or RT their tweets.</li><li>Once a while, I find tweets that have long and engaging discussions. I use Tweetdeck for this. I search tweets with keywords of interest and then filter by the number of replies.</li><li>I bookmark Tweets, especially threads, that I want to have easy access to in the future.</li></ol><p>Let me know if you have any Twitter tricks that work for you.</p>
    </div>
        
</article>                            </main>
</div>
        </div></div>]]>
            </description>
            <link>https://blog.justanotherpm.com/discover-10x-more-content-on/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25052286</guid>
            <pubDate>Tue, 10 Nov 2020 21:35:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Get Rid of If-Else Ladder]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25052170">thread link</a>) | @maniish_jaiin
<br/>
November 10, 2020 | https://maniishjaiin.tech/how-to-get-rid-of-if-else-ladder | <a href="https://web.archive.org/web/*/https://maniishjaiin.tech/how-to-get-rid-of-if-else-ladder">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><h2 id="easy-way-to-write-clean-code-using-higher-order-functions-and-hashmaps">Easy way to write clean code using Higher-Order Functions and HashMaps</h2>
<p>In one of my previous articles, I talked about  <a target="_blank" href="https://maniishjaiin.tech/lets-talk-test-driven-development">Test-Driven Development</a>. There we ended up with a solution having a switch-case. In this one, we will see ways to avoid having a switch-case or an if-else ladder.</p>
<p>I will start with a problem known as Reverse Polish Notation. A lot of you might have heard of this problem, and it is a straightforward problem to solve. But our focus for this article is to understand how we can write <em>CLEAN CODE</em> by removing the <code>if-else</code> ladder by using Hashmaps and Higher-Order functions.</p>
<p>Before we start, the solution discussed here is in Java and Kotlin.</p>
<p>What is Reverse Polish Notation:</p>
<p><em>In reverse Polish notation, the operators follow their operands; for instance, to add 3 and 4, one would write</em> <code>_3 4 +_</code> <em>rather than</em> <code>_3 + 4_</code><em>. If there are multiple operations, operators are given immediately after their second operands; so the expression is written</em> <code>_3 ‚àí 4 + 5_</code> <em>in conventional notation would be written</em> <code>_3 4 ‚àí 5 +_</code> <em>in reverse Polish notation: 4 is first subtracted from 3, then 5 is added to it.</em></p>
<p>The solution to this problem is also pretty simple. We need to use a Stack and continuously push the elements until we find any operator <code>(+, ‚Äì, *, /)</code>. Once we find an operator we pop the two numbers from the stack and perform the operation (Addition, Division, etc.) on them.</p>
<p>So, for input <code>3 4 +</code> we will push 3, and then push 4 and then when we encounter a <code>+</code> we will pop <code>3</code> and <code>4</code> and add them.</p>

<p>A naive solution in Java would look like this. We have a method <code>evaluate</code> which takes in the input, splits it using <code>‚Äú ‚Äù</code> . And iterate over the char array pushing numbers to the stack and applying operations based on the operators encountered using the switch-case.</p>
<pre><code><span>import</span> java.util.Stack;

<span><span>class</span> <span>ReversePolishNotation</span> {</span>
    <span><span>public</span> <span>static</span> <span>void</span> <span>main</span><span>(String[] args)</span>
    </span>{
        System.out.println(evaluate(<span>"5 1 2 + 4 * + 3 -"</span>));
    }
    <span><span>public</span> <span>static</span> <span>double</span> <span>evaluate</span><span>(String expr)</span>
    </span>{
        String[] digitString = expr . split (<span>" "</span>);
        Stack&lt;Float&gt; <span>stack</span> = <span>new</span> Stack&lt;Float&gt;();
        <span>for</span> (String s : digitString) {
        <span>switch</span>(s) {
            <span>case</span> <span>"+"</span>: {
            <span>float</span> numberOne = <span>stack</span> . pop ();
            <span>float</span> numberTwo = <span>stack</span> . pop ();
            <span>stack</span>.push(numberOne + numberTwo);
            <span>break</span>;
        }
            <span>case</span> <span>"-"</span>: {
            <span>float</span> numberOne = <span>stack</span> . pop ();
            <span>float</span> numberTwo = <span>stack</span> . pop ();
            <span>stack</span>.push(numberTwo - numberOne);
            <span>break</span>;
        }
            <span>case</span> <span>"*"</span>: {
            <span>float</span> numberOne = <span>stack</span> . pop ();
            <span>float</span> numberTwo = <span>stack</span> . pop ();
            <span>stack</span>.push(numberOne * numberTwo);
            <span>break</span>;
        }
            <span>case</span> <span>"/"</span>: {
            <span>float</span> numberOne = <span>stack</span> . pop ();
            <span>float</span> numberTwo = <span>stack</span> . pop ();
            <span>stack</span>.push(numberTwo / numberOne);
            <span>break</span>;
        }
            <span>default</span>: {
            <span>stack</span>.push(Float.parseFloat(s));
            <span>break</span>;
        }
        }
    }
        <span>return</span> <span>stack</span>.pop();
    }
}
</code></pre><p>This is the first iteration of the solution that works as expected. Now, let's think of a better solution to this. If you look at each of the cases we see a lot of duplication.</p>
<pre><code><span>float</span> numberOne = <span>stack</span>.pop();
<span>float</span> numberTwo = <span>stack</span>.pop();
<span>stack</span>.push(numberOne + numberTwo);
</code></pre><p>The common part in the above code is the stack operation. The only change is the operation that we perform. If we could parameterize the operation to a function we should be able to reuse the code. Let‚Äôs see how we can do that.</p>

<p>The <code>[BiFunction](https://docs.oracle.com/javase/8/docs/api/java/util/function/BiFunction.html)</code> is a specialization of the <code>[Function](https://learnjava.co.in/java-8-function-interface-example/)</code> interface that accepts 2 arguments. Just like a <code>Function</code>, it provides a method called <code>apply</code>. This method accepts 2 arguments of any data type and returns a result. Exactly what we need to perform the operations. Our add function takes in two parameters and returns the result back!</p>
<p>So we can pass addition, subtraction, multiplication, and division functions as BiFunctions.</p>
<pre><code><span>import</span> java.util.Stack;
<span>import</span> java.util.function.BiFunction;

<span><span>class</span> <span>ReversePolishNotation</span> {</span>

    <span><span>public</span> <span>static</span> <span>void</span> <span>main</span><span>(String[] args)</span>
    </span>{
        System.out.println(evaluate(<span>"4 2 /"</span>));
    }

    <span><span>public</span> <span>static</span> <span>double</span> <span>evaluate</span><span>(String expr)</span>
    </span>{
        String[] digitString = expr . split (<span>" "</span>);
        Stack&lt;Float&gt; <span>stack</span> = <span>new</span> Stack&lt;Float&gt;();
        <span>for</span> (String s : digitString) {
        <span>switch</span>(s) {
            <span>case</span> <span>"+"</span>: {
            <span>stack</span>.push(operate((a, b) -&gt; a+b, <span>stack</span>));
            <span>break</span>;
        }
            <span>case</span> <span>"-"</span>: {
            <span>stack</span>.push(operate((a, b) -&gt; a-b, <span>stack</span>));
            <span>break</span>;
        }
            <span>case</span> <span>"*"</span>: {
            <span>stack</span>.push(operate((a, b) -&gt; a * b, <span>stack</span>));
            <span>break</span>;
        }
            <span>case</span> <span>"/"</span>: {
            <span>stack</span>.push(operate((a, b) -&gt; a / b, <span>stack</span>));
            <span>break</span>;
        }
            <span>default</span>: {
            <span>stack</span>.push(Float.parseFloat(s));
            <span>break</span>;
        }
        }
    }
        <span>return</span> <span>stack</span>.pop();
    }

    <span><span>public</span> <span>static</span> Float <span>operate</span><span>(BiFunction&lt;Float, Float, Float&gt; function, Stack&lt;Float&gt; <span>stack</span>)</span>
    </span>{
        <span>float</span> numberOne = <span>stack</span>.pop();
        <span>float</span> numberTwo = <span>stack</span>.pop();
        <span>return</span> function.apply(numberTwo, numberOne);
    }
}
</code></pre><p>In the above code the BiFunction is:</p>
<pre><code>(a, b) -&gt; a + b
</code></pre><p>And our method <code>operate</code> takes in the BiFunction as the input.</p>
<p>Now, we have removed the duplication by extracting a function from it and making it accept our operations as functions.</p>
<p>But there is still that switch-case ladder which is taking care of figuring out which operation we should use. What if we could get rid of that?</p>
<p>Let's think about that. Only if we could do a <code>operator</code> lookup, we would be able to remove this ladder.</p>
<p>And what can be used to do a lookup?</p>
<p>A HashMap indeed!</p>

<p>We map our operators with the functions and then when we iterate over the string, and fetch functions if we find an operator otherwise we just push that number to the stack.</p>
<pre><code>import java.util.HashMap;
import java.util.Stack;
import java.util.function.BiFunction;

<span><span>class</span> <span>ReversePolishNotation</span> </span>{

    <span>public</span> <span>static</span> <span>void</span> main(<span>String</span>[] args)
    {
        System.out.println(evaluate(<span>"4 2 /"</span>));
    }

    <span>public</span> <span>static</span> <span>double</span> evaluate(<span>String</span> expr)
    {
        <span>String</span>[] digitString = expr . split (<span>" "</span>);

        Stack&lt;<span>Float</span>&gt; stack = <span>new</span> Stack&lt;&gt;();
        HashMap&lt;<span>String</span>, BiFunction&lt;<span>Float</span>, <span>Float</span>, <span>Float</span>&gt;&gt; map = constructMapForOperator ();

        <span>for</span> (<span>String</span> s : digitString) {
        <span>if</span> (map.containsKey(s)) {
            stack.push(operate(map.get(s), stack));
        } <span>else</span> {
            stack.push(<span>Float</span>.parseFloat(s));
        }
    }
        <span>return</span> stack.pop();
    }

    <span>private</span> <span>static</span> HashMap&lt;<span>String</span>, BiFunction&lt;<span>Float</span>, <span>Float</span>, <span>Float</span>&gt;&gt; constructMapForOperator()
    {
        HashMap&lt;<span>String</span>, BiFunction&lt;<span>Float</span>, <span>Float</span>, <span>Float</span>&gt;&gt; map = <span>new</span> HashMap();
        map.put(<span>"+"</span>, (a, b) -&gt; a+b));
        map.put(<span>"-"</span>, (a, b) -&gt; a-b);
        map.put(<span>"*"</span>, (a, b) -&gt; a * b);
        map.put(<span>"/"</span>, (a, b) -&gt; a / b);
        <span>return</span> map;
    }

    <span>public</span> <span>static</span> <span>Float</span> operate(BiFunction&lt;<span>Float</span>, <span>Float</span>, <span>Float</span>&gt; <span><span>function</span>, <span>Stack</span>&lt;<span>Float</span>&gt; <span>stack</span>)
    </span>{
        <span>float</span> numberOne = stack.pop();
        <span>float</span> numberTwo = stack.pop();
        <span>return</span> function.apply(numberTwo, numberOne);
    }
}
</code></pre><p>This approach can be utilized in all those places where you see an if-else or a switch-case ladder. This works almost everywhere. You just have to carefully think about the Higher-Order function that you need to create.</p>
<p>For the Kotlin enthusiasts out there, here is the same solution in Kotlin.</p>
<pre><code><span>import</span> java.util.*

<span><span>fun</span> <span>main</span><span>()</span></span> {
    println(evaluate(<span>"4 2 /"</span>))
}

<span><span>fun</span> <span>evaluate</span><span>(expr: <span>String</span>)</span></span>: <span>Float</span> {
    <span>val</span> chars = expr.split(<span>" "</span>)
    <span>val</span> stack = Stack&lt;<span>Float</span>&gt;()
    <span>val</span> <span>operator</span> = operationForOperator()
    <span>for</span> (c <span>in</span> chars) {
        <span>operator</span>[c]?.let { stack.push(operate(it, stack)) } ?: stack.push(c.toFloat())
    }
    <span>return</span> stack.pop()
}

<span><span>fun</span> <span>operationForOperator</span><span>()</span></span>: Map&lt;String, (<span>Float</span>, <span>Float</span>) -&gt; <span>Float</span>&gt; {
    <span>return</span> mapOf(
        <span>"+"</span> to { a, b -&gt; a + b },
        <span>"-"</span> to { a, b -&gt; a - b },
        <span>"*"</span> to { a, b -&gt; a * b },
        <span>"/"</span> to { a, b -&gt; a / b }
    )
}

<span><span>fun</span> <span>operate</span><span>(function: (<span>a</span>: <span>Float</span>, <span>b</span>: <span>Float</span>) -&gt; <span>Float</span>, stack: <span>Stack</span>&lt;<span>Float</span>&gt;)</span></span>: <span>Float</span> {
    <span>val</span> numberOne = stack.pop()
    <span>val</span> numberTwo = stack.pop()
    <span>return</span> function(numberTwo, numberOne)
}
</code></pre><p>If you notice, we do not need an if-else here as in the for-loop at the top. We can utilize <strong>Kotlin‚Äôs Elvis Operator (?:)</strong> which will automatically execute the last part if there is no matching key in the map. We started with 50 lines of code and reached 30 lines of code using Kotlin.</p>
<p>You can follow me on <a target="_blank" href="https://twitter.com/manish_zainz1">Twitter</a> where I occasionally post from my learnings.</p>
<h2 id="you-might-be-interested-in-reading-these-as-well">You might be interested in reading these as well:</h2>
<p><a target="_blank" href="https://maniishjaiin.tech/3-habits-that-will-help-you-become-a-top-developer">3 Habits That Will Help You Become a Top Developer</a></p>
<p><a target="_blank" href="https://maniishjaiin.tech/5-mindsets-of-unsuccessful-developers">5 Mindsets of Unsuccessful Developers</a></p>
</div></div>]]>
            </description>
            <link>https://maniishjaiin.tech/how-to-get-rid-of-if-else-ladder</link>
            <guid isPermaLink="false">hacker-news-small-sites-25052170</guid>
            <pubDate>Tue, 10 Nov 2020 21:25:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The value of anonymous employee feedback]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25051908">thread link</a>) | @mirvise
<br/>
November 10, 2020 | https://inkrement.io/blog/diversity-inclusion-and-anonymous-feedback/ | <a href="https://web.archive.org/web/*/https://inkrement.io/blog/diversity-inclusion-and-anonymous-feedback/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	
	<div>
		<p>A few years ago, I witnessed a particular coworker get singled out and eventually forced out of a company where we worked. What happened? She shared constructive feedback to our leadership during an all-staff meeting about our company‚Äôs pay disparities by race. She made suggestions for improvement and transparency as a way to truly demonstrate the company‚Äôs values. The leaders acted like they appreciated her feedback and promised to commit to the necessary changes.</p><p>Many of us applauded her courage after the meeting because she was the voice we all needed. According to her, it felt like the right thing to do since the company claimed they had an open feedback culture, where anyone could share their honest opinions. Little did she know what awaited her afterwards‚Äîshe was treated differently and, in many overt ways, made to feel uncomfortable for an extended period. Eventually, she had to exit the company.</p><p>In recent times, we have seen a global reawakening around social issues relating to diversity and inclusion. Some of us would attest that conversations around diversity and inclusion have been ongoing for some time. Still, it feels like something is amiss.</p><p>According to a <a href="https://hbr.org/2018/12/to-retain-employees-focus-on-inclusion-not-just-diversity">Harvard Business Review</a> article, ‚Äúmost business leaders understand the diversity part of diversity and inclusion,‚Ä¶ [but] it‚Äôs the inclusion part that eludes them... [and] the key to inclusion is understanding who your employees really are.‚Äù As an organizational leader, can you say that you understand who your employees are? And how do you know that?</p><p>A meaningful way to understand your employees is by creating feedback channels that allow all employees to share their opinions or suggestions about workplace practices, without fear of retaliation.</p><h3 id="why-anonymous-feedback-is-important-for-diversity-and-inclusion">Why Anonymous Feedback Is Important For Diversity And Inclusion</h3><p>More than ever, many workplaces are adopting initiatives to improve their diversity, equity, and inclusion efforts.</p><p>While many business leaders describe their organizations as transparent, most of their employees do not agree‚Äîa <a href="https://slack.com/intl/en-ng/blog/transformation/trust-tools-and-teamwork-what-workers-want">study</a> of over 1,400 workers conducted by Slack, a popular workplace communication platform, proves this. In this study, ‚Äú55 percent of business owners described their organization as very transparent, but only 18 percent of their employees would agree.‚Äù Moreover, employees who complain about workplace issues have worse careers, mental health, and physical health than those who experience similar issues but do not complain, according to a recent <a href="https://www.umass.edu/employmentequity/sites/default/files/What_Works.pdf">report</a> titled, ‚ÄúWhat Works? Evidence-Based Ideas to Increase Diversity, Equity, and Inclusion in the Workplace.‚Äù</p><blockquote>55 percent of business owners described their organization as very transparent, but only <strong>18 percent</strong> of their employees would agree</blockquote><p>These findings tell me one thing: even though the mainstream opinion says that results from anonymous feedback can be <a href="https://hbr.org/2013/06/confidential-surveys-undermine">inaccurate, biased, or self-serving</a>, direct feedback isn‚Äôt proving to be sufficient for diversity, equity, and inclusion. Despite the open-door policies that many business leaders offer to make employees speak up, some employees may remain silent. Based on the experience I shared, employees may not speak up once they notice that they belong to a different race, gender, national origin, or other identities than most of their coworkers, to avoid being singled out.</p><p>As HR leaders and managers look to design diversity and inclusion programs, consider that some employees need a safe space to share honest feedback‚Äîespecially when giving upward feedback.</p><p>Therefore, I would like to explore the use of anonymous feedback in the workplace.</p><h3 id="what-is-anonymous-feedback">What Is Anonymous Feedback?</h3><p>Unlike <a href="https://pdf.sciencedirectassets.com/277811/1-s2.0-S1877042815X00334/1-s2.0-S1877042815038082/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEEkaCXVzLWVhc3QtMSJHMEUCIFeIdtU0SvQQBr4CrqqFLWudksr2TbdKlUa+kW9kbBLbAiEA0PhEPPRyZFZdm8dX2M+VU8N78EkRIF+qq/MrZma+LS4qtAMIYhADGgwwNTkwMDM1NDY4NjUiDI+mxJgSmfyoAzLf8CqRA5jk/e+vnwOhG6oNrVnYPNYUahkFedQiraRdEdWL8Y1/Mcp3n/78kmcuBNWNaKwttN7qCpKXUWHlyl/cHatFc9uO6ASzzZ3cWSk5PgRg/32/VpQwqknXaOOOQy/t38qzCSkl2Pxnb2LOtGS4HZApRetHTIVuUGWoGA9WIy/ua2HEiUB+Flk1anVw9VOIE/JkkS7Ta/jujPLSAplPHo8YZfjK0cQ6iivDHtPrUpnalGhVza1OmhEKeLNilDmG9DZP/W5KfEpx3znpTaj0pP1uppHpP3Q6R+ECURoweAEfgbV/E2z0lFWQL9tkJtW+HOCqcoPxeTpmHqowV48dbI9CSDpldhiJsya6bJ/Sr9F7tuR22ZQOCNcmDBPHFT5rCUMdTKt9Jv49Z/4m27+fd/a2fY4vWtFv7g9bzYXSungpDNJbVozNLZPwR+i7t30ZTamCTzRweYoWbGsDgoKAzjBqlDVzJqL4kcUdVH6FqWz0z3G8smuSQGbzTNoalMQSASAHI99FvhnOqwQ6T67c3Ah1STKRMKaInvsFOusB5KfCoxZHyf9g2eqdY4+yWmaMOkGvYSHajRXp6gARqmp4xZaQ+gOiAgz057HrJ0GvPHPebTXWg8j3BXdkyeuGyw+Nm5UxT7A6Tf6OMZWEvDA+9DFjNiPYDaIUFSPNEQbVmY9l99FCTOdBcMGORqtKdtCv8IXFZp1zLEpKqU4uyagLZ0w3GvGXgGPKsFD/oRxT6DNLyntSoBnTv4kOk/eH540ZNUAH/Hzr5GAC+jfE8c2YlKL0t0q/aO6eXiyT4ttmKiJsuqHZw24019KbH/QkS5al0B3UWqiuy9U9OQRchISovRaQpKQ0IltOMA==&amp;X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Date=20200920T175956Z&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Expires=300&amp;X-Amz-Credential=ASIAQ3PHCVTY5GNJTVNN/20200920/us-east-1/s3/aws4_request&amp;X-Amz-Signature=9d0ad3f8f3df53985edd301e94c6c9f150d539190c7511f1bca02dac896b528d&amp;hash=77222c7c6d6bafa8ea5f37880b047d82f5134bf75835597008a0ed7650bdcd0b&amp;host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&amp;pii=S1877042815038082&amp;tid=spdf-6bde122d-437c-4067-98d5-93f97e712e15&amp;sid=3344830398c1c441a209a100fe896d4ba43dgxrqb&amp;type=client">direct feedback</a>, where communication is open and in the form of emails, phone conversations, face-to-face meetings, or any medium that discloses people‚Äôs identity, anonymous feedback is simply the opposite. As the name implies, people share feedback to teammates or other organizational members while protecting their identities.</p><h3 id="pros-of-anonymous-feedback">Pros of Anonymous Feedback</h3><ul><li><strong>It provides the truth and protects the vulnerable:</strong> On topics that are considered sensitive, you‚Äôll often find employees who are afraid to share their opinions. But when employees have the option to use anonymous feedback, you will be offering a safe space for them to share their insights and truths about sensitive workplace issues, without fear of victimization. Also, employers benefit from anonymous feedback because they can receive honest and diverse perspectives on critical issues, and they can quickly address those issues before they escalate.‚Äå‚Äå</li><li><strong>It allows every voice to be heard and respected:</strong> In workplaces, where they practice direct or attributed feedback, leaders may give preference to some voices over others. Due to our unconscious biases, people of higher authority, backgrounds, or eloquence tend to command respect and attention. In such situations, the issues they raise are likely to get immediate attention than those raised by the rest of the group. However, when feedback is collected anonymously, it eliminates biases and allows leaders to focus entirely on the feedback.‚Äå‚Äå</li><li><strong>It encourages new employees to share their opinions:</strong> <a href="https://journals.sagepub.com/doi/pdf/10.1177/0893318905279191">Research</a> has shown that new employees, who happen to be less senior or influential, see anonymous feedback as more appropriate for formal and informal evaluations than their older colleagues. Typically, the last thing a new employee wants is to start on the wrong foot. During my check-in sessions with new employees to discuss their experiences, most of them often took a neutral stance. So, using anonymous feedback can make new employees feel more comfortable sharing their real opinions on workplace issues.‚Äå‚Äå</li></ul><h3 id="cons-of-anonymous-feedback">Cons of Anonymous Feedback</h3><ul><li><strong>It can breed hostility: </strong>Many people kick against anonymous feedback because it can create hostility. According to this Harvard Business Review<strong> </strong><a href="https://hbr.org/2016/01/can-your-employees-really-speak-freely">article</a>, anonymity often sets off a ‚Äúwitch hunt,‚Äù where leaders seek to know the source of a negative comment. On the one hand, employees can hide behind anonymity to say personal and hurtful things about their colleagues or leaders. On the other hand, leaders may take constructive feedback as a personal attack and become suspicious and hostile to all their employees.‚Äå‚Äå</li><li><strong>It can be less impactful than attributed feedback:</strong> When using attributed feedback where responses carry the employees‚Äô names, information can be analyzed for relevance and impact. However, with anonymous feedback, it can be difficult to analyze information accurately. It is not uncommon for companies who choose to practice anonymous feedback, to find <a href="https://www.forbes.com/sites/groupthink/2017/09/21/6-ways-anonymous-feedback-robs-your-team-blind-and-what-to-do-about-it/#7fc211a05ffd">less specific responses since details may reveal respondents‚Äô identities</a>. Vague feedback from employees would have less power to influence behaviors or drive change in the organization.‚Äå‚Äå</li><li><strong>It can be difficult to act on:</strong> Anonymity defeats the purpose of feedback, which is to <a href="https://www.forbes.com/sites/forbescommunicationscouncil/2018/08/01/the-importance-of-the-employee-feedback-loop/#564d64e02026">create a reciprocal relationship</a> and an opportunity to work toward improvement. Since anonymous feedback is often difficult to trace, it can be challenging for the organization to get context or follow up on important issues, especially when a problem is peculiar to an individual. ‚Äå‚Äå</li></ul><figure><img src="https://better-feedback-image-assets.storage.googleapis.com/2020/11/64627.jpg" alt=""></figure><h3 id="anonymous-feedback-training-wheels">Anonymous Feedback: Training Wheels</h3><p>Ideally, everyone in your company should be able to give feedback publicly and not anonymously. They should share constructive criticism and not shy away from direct feedback if they believe and trust that their opinions will be heard and addressed.</p><p>However, it takes time to build trust. It‚Äôs no different than trusting to balance yourself on two wheels‚Äîyou move slowly and incrementally. Anonymous feedback gives employees the training wheels to build that trust. They can use anonymous feedback to practice their feedback-giving skills, test the waters, and understand how people perceive their constructive (and sometimes critical) opinions. Is their feedback being ignored? Is management reacting emotionally to critical opinions?</p><p>Anonymous feedback allows people to develop trust and share their honest opinions and thoughts about company policies and processes, without fear of repercussions.</p><h3 id="how-to-request-for-anonymous-feedback">How to Request for Anonymous Feedback</h3><p>Traditionally, many organizations have collected anonymous feedback through suggestion boxes or ombudsmen. However, in recent times, technology platforms have created great channels for collecting feedback.</p><p>For example, <a href="http://inkrement.io/">Inkrement</a>, a feedback tool built for Slack, allows your team to request and deliver timely feedback effortlessly. Inkrement ensures that all voices are heard and empowers your team to give critical feedback directly or anonymously, without fear.</p><p>On a smaller scale, a manager can request anonymous feedback from peers or teammates in the form of feedback requests. You can ask thematic questions that ensure anonymity. The feedback you receive can inform your team‚Äôs discussions and determine training needs, team building, or performance improvement activities.</p><p>When requesting for anonymous feedback on an organizational level, it is necessary to:</p><ol><li><strong>Set expectations for employees:</strong> Let employees know how important their feedback is to the organization. Also, assure them that their responses will be non-identifiable (no identifiable names, titles, or other demographic details). According to a <a href="https://hbr.org/2002/02/getting-the-truth-into-workplace-surveys">Harvard Business Review</a> article, ‚Äúrespondents are much more likely to participate if they are confident that personal anonymity is guaranteed.‚Äù Set those expectations to increase the chances of response from employees. &nbsp;‚Äå‚Äå</li><li><strong><strong><strong>Provide Training: </strong></strong></strong>As referenced in our <a href="https://inkrement.io/blog/how-to-give-feedback/">Feedback Best Practices</a>, it‚Äôs important to train employees on how, when, where, and whom to give feedback. They need to keep their feedback objective and focused on the Situation, Behavior, Impact best practices. ‚Äå‚Äå</li><li><strong>Deploy a feedback platform: </strong>Use a trusted feedback platform to send feedback requests to employees. For example, when employees submit feedback requests through <a href="https://inkrement.io/">Inkrement</a>, the system protects and encrypts all personal information, both at rest and in transit, through secure connections to ensure anonymity. &nbsp;‚Äå‚Äå</li></ol><figure><img src="https://better-feedback-image-assets.storage.googleapis.com/2020/11/5236.jpg" alt=""><figcaption>Using feedback to grow incrementally</figcaption></figure><h3 id="how-to-act-on-anonymous-feedback">How to ‚Ä¶</h3></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://inkrement.io/blog/diversity-inclusion-and-anonymous-feedback/">https://inkrement.io/blog/diversity-inclusion-and-anonymous-feedback/</a></em></p>]]>
            </description>
            <link>https://inkrement.io/blog/diversity-inclusion-and-anonymous-feedback/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25051908</guid>
            <pubDate>Tue, 10 Nov 2020 21:06:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust as a productive high-level language]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25051897">thread link</a>) | @csomar
<br/>
November 10, 2020 | https://omarabid.com/rust-high-level-language | <a href="https://web.archive.org/web/*/https://omarabid.com/rust-high-level-language">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="container">
  <article id="wBiL7EUi4Kw16ahNjk6hmU">
	<time datetime="2020-11-10">November 10, 2020</time>
  
	<p>Rust is often critiqued as a <a href="https://news.ycombinator.com/item?id=24536645">not a very productive</a> programming language. It is true that there is a bit of a learning curve to be able to program in Rust; but beyond that, I think it pays off in productivity; and massively I must say.</p>

<p>I haven‚Äôt been using Rust for production much; maybe a bit more than a year. The static type checks means I‚Äôm getting much less bugs in my code, and spend considerably less time in debugging. I can safely say that, for me, Rust is more productive than JavaScript, PHP or Python and the margin keeps getting larger as I get more acquainted with the ecosystem.</p>

<hr>

<p>To entice your interest, here is a situation that I handled lately: I have a program that writes logs to <a href="https://en.wikipedia.org/wiki/Syslog">syslog</a> and the terminal. The program compiles and functions correctly on my development machine. However, it returned an error when I deployed it to an <a href="https://alpinelinux.org/">Alpine</a> Docker container. Turns out, Alpine doesn‚Äôt have a running syslog service by default.</p>

<p>Now that‚Äôs fine, the program functioned correctly. But I don‚Äôt care much for syslog on deployment since the program is running inside a container. One solution is to remove the syslog <a href="https://en.wikipedia.org/wiki/Sink_(computing)">drain</a> but I need that for development. I can use <a href="https://doc.rust-lang.org/reference/conditional-compilation.html">conditional compilation</a>; but there is a better option: If syslog fails, for whatever reason, just ignore that and move on.</p>

<p>So let‚Äôs take a look at the old code. </p>

<pre><code>    let syslog_drain = syslog_drain()?;
    let term_drain = term_drain()?;
</code></pre>

<p>This code creates two logging drains: one for syslog and one for the terminal. It uses the <a href="https://doc.rust-lang.org/edition-guide/rust-2018/error-handling-and-panics/the-question-mark-operator-for-easier-error-handling.html">? operator</a> to evaluate the result. If the function returns an error, execution will stop and the error bubbles back to the top of the program.</p>

<p>I have no idea how the syslog or any particular drain fails. And honestly, I don‚Äôt want to get into these details. What I want is to check if there is a failure; and if so ignore that particular drain. Or return a <a href="https://docs.rs/slog/2.5.2/slog/struct.Discard.html">Discard drain</a>.</p>

<p>The <a href="https://doc.rust-lang.org/std/result/">Result</a> type and <code>? operator</code> make this particularly easy. So here is the code that does that.</p>

<pre><code>    let syslog_drain = syslog_drain().unwrap_or(discard_drain()?);
    let term_drain = term_drain().unwrap_or(discard_drain()?);
</code></pre>

<p>And that‚Äôs it. This code now compiles and runs correctly. If syslog is running, it‚Äôll write logs to syslog and the terminal. Otherwise, it‚Äôll write logs to the terminal and syslog is skipped. There are no conditions, no complicated checks and it‚Äôs perfectly readable.</p>

<hr>

<p>There is more to Rust productivity than that. Macros, Iterators, Advanced Traits and Types, the new Async system. Once you are comfortable with all of these, you are now able to be productive, safe and fast.</p>

  <figure id="kudo_wBiL7EUi4Kw16ahNjk6hmU">
    <a href="#kudo">
      
    </a>
    <p>128</p>
    <p>Kudos</p>
  </figure>
  <figure id="kudo_side_wBiL7EUi4Kw16ahNjk6hmU">
    <a href="#kudo">
      
    </a>
    <p>128</p>
    <p>Kudos</p>
  </figure>
</article>

</section></div>]]>
            </description>
            <link>https://omarabid.com/rust-high-level-language</link>
            <guid isPermaLink="false">hacker-news-small-sites-25051897</guid>
            <pubDate>Tue, 10 Nov 2020 21:04:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Messenger App Tutorial with Phoenix LiveView]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25051678">thread link</a>) | @szsoppa
<br/>
November 10, 2020 | https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-1 | <a href="https://web.archive.org/web/*/https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>In a series of articles <strong>(don't forget to <a href="#c-newsletter" target="_blank">subscribe to our newsletter</a>!)</strong>, we'll convince you that Phoenix LiveView will revolutionize the way you create reactive UIs!</p>
<h2>Why Phoenix?</h2>
<p>The thing about Elixir, on top of Erlang/OTP, is that it offers a great mix of making life easy and being a scalable and reliable platform that will not let you down when your estimated traffic of 4000 users becomes 4,000,000 users.</p>
<p><strong>Phoenix Framework</strong> is Elixir's answer to the never-ending question of how to build rich web applications, and it's got a lot of tools that make the job easy - one of the latest being <strong>Phoenix LiveView</strong>.</p>
<p>Long story short, <strong>LiveView is a tool that lets an Elixir developer create reactive UIs without writing a single line of JS code</strong>. Which is great, given that many Elixir developers do not exactly consider themselves fluent at JS, or - just like myself - are not exactly in love with JS.</p>
<h2>Lessons learnt from reactive UI libraries</h2>
<p>Many JavaScript frameworks, both contemporary and not-so-contemporary ones, rely on manipulating the page's DOM for dynamic content updates.</p>
<p>Historically, for instance, developers using BackboneJS would define a <code>Backbone.View</code> to represent an <em>atomic chunk of user interface</em>, behind which there's a <code>Backbone.Model</code>, encapsulating the business logic of data.</p>
<p>Backbone remained unopinionated about how views were to be rendered, so it had no built-in tools to make the re-rendering of views on model changes efficient - the whole structure of a view had to be built from scratch and replaced, which tended to yield inefficient views.</p>
<p>In contrast, modern frameworks such as ReactJS or Vue.js don't care about how the data model layer works at all (loosely coupled data stores such as Redux are often used for this) - but they have a <strong>virtual DOM</strong> concept - long story short, a pattern of incrementally upgrading only those elements that need to be changed, based on changes in the state of particular components and their children.</p>
<p><strong>The challenge, though, is pretty much down to how to exchange data between the UI and the backend.</strong> You will usually need to implement a JSON API or a GraphQL service, or perhaps you could develop a WebSocket-based solution using Phoenix Channels.</p>
<p>Either way, the <a href="https://en.wikipedia.org/wiki/Pareto_principle" target="_blank">Pareto 80/20 principle</a> will imminently catch you, and when you get to the 20% of work needed to finish off your message-passing code, it'll soon become a <em>framework within a framework</em>.</p>
<h2>Why, where &amp; how LiveView excels</h2>
<p>Phoenix LiveView's concept is both groundbreaking and familiar, in different ways.</p>
<p>It is familiar in that it lets you define UI elements as nestable components composed of pure HTML markup, and it builds upon the experience of reactive UI frameworks in implementing mechanisms that calculate diffs between consecutive UI states to ensure efficient updates.</p>
<p>It is groundbreaking in the way it maintains the states of components and manages their updates - <strong>in Phoenix LiveView, components are stateful on the server, and their events and updates are communicated via a bidirectional WebSocket connection</strong>.</p>
<p><strong>Phoenix LiveView is built on top of Elixir processes and Phoenix Channels</strong> - every LiveView instance is a BEAM process, acting very much like a <a href="https://hexdocs.pm/elixir/GenServer.html" target="_blank">GenServer</a>, receiving messages and updating its state.</p>
<p>While modern JS frameworks such as React have server-side rendering capabilities, it is usually not convenient to do this in a non-NodeJS backend server. Rendering content via JavaScript often results in SEO issues, and some trickery is needed for search engines to index the page correctly. <strong>In Phoenix LiveView, the initial render is static as in the classic HTML request-response cycle</strong>, so you'll get good <a href="https://developers.google.com/web/tools/lighthouse" target="_blank">Lighthouse scores</a> and it won't hurt your SEO.</p>
<p>Erlang easily maintains thousands of processes concurrently, and Phoenix authors have even <a href="https://phoenixframework.org/blog/the-road-to-2-million-websocket-connections" target="_blank">managed to make it handle 2 million WebSocket connections</a> on a single (albeit pretty strong) machine. With the server using Elixir's strengths to manage LiveView states, <strong>the client-side logic can be thin and simple</strong>.</p>
<p>In fact, as stated in the introduction, <strong>in most LiveView-powered apps you won't write a single line of JS code</strong>. In many cases, when interacting with an element whose update is supposed to fetch data for a new UI state from the server, the workflow using a reactive JS framework would be:</p>
<ol>
<li>Handle the element's <code>change</code> event
</li>
<li>Send a request to the server containing the actual changes
</li>
<li>Receive response and update state store based on response data
</li>
<li>Let the view layer re-render the changed DOM elements
</li>
</ol>
<p>This involves annotating HTML elements so that they can be identified by JS code, writing browser-side scripts to handle the element's state change event, send a payload to the server, which processes the request as part of a Phoenix controller action.</p>
<p><strong>With Phoenix LiveView, you only write HTML and Elixir code, with the JS part being handled by a script bundled with the LiveView package.</strong></p>
<h2>Phoenix LiveView basic usage</h2>
<p>The basic idea behind Phoenix LiveView is very simple and straightforward. <strong>Be sure to <a href="#c-newsletter" target="_blank">subscribe to our newsletter</a> to learn more!</strong></p>
<p>LiveView is an Elixir behaviour, and your most basic LiveView definition will consist of two callback implementations:</p>
<ul>
<li>A <a href="https://hexdocs.pm/phoenix_live_view/Phoenix.LiveView.html#c:render/1" target="_blank"><code>render/1</code></a> function, containing the template of how your component is represented in HTML, with elements of the component's state interpolated. This is much like defining an ordinary view. The special <a href="https://hexdocs.pm/phoenix_live_view/Phoenix.LiveView.html#sigil_L/2" target="_blank"><code>~L</code> sigil</a> is used to interpolate <code>assigns</code> into your EEx syntax, and convert it into an HTML-safe structure.
</li>
<li>A <a href="https://hexdocs.pm/phoenix_live_view/Phoenix.LiveView.html#c:mount/2" target="_blank"><code>mount/2</code></a> function, wiring up socket assigns and establishing the LiveView's initial state.
</li>
</ul>
<pre><code>  <span><span>defmodule</span> <span>YourappWeb.CounterLive</span></span> <span>do</span>
    <span>use</span> Phoenix.LiveView

    <span><span>def</span> <span>render</span></span>(assigns) <span>do</span>
      ~L<span>""</span><span>"
      &lt;a href='#' phx-click='increment'&gt;
        I was clicked &lt;%= @counter %&gt; times!
      &lt;/a&gt;
      "</span><span>""</span>
    <span>end</span>

    <span><span>def</span> <span>mount</span></span>(params, socket) <span>do</span>
      {<span>:ok</span>, assign(socket, <span>:counter</span>, <span>0</span>)}
    <span>end</span>
  <span>end</span></code></pre>
<p>However, the whole fun of using LiveView is managing its state, and the next two callbacks will come in handy.</p>
<ul>
<li>A <a href="https://hexdocs.pm/phoenix_live_view/Phoenix.LiveView.html#c:handle_event/3" target="_blank"><code>handle_event/3</code></a> function, handling events coming <strong>from the browser</strong>. Noticed the <code>phx-click</code> attribute in our template's link? This is the name of an event that will be transported to the LiveView process via WebSockets. We'll define a function clause that will match to the event's name.
</li>
</ul>
<pre><code>  <span><span>def</span> <span>handle_event</span></span>(<span>"increment"</span>, params, %{<span>assigns:</span> %{<span>counter:</span> counter}} = socket) <span>do</span>
    {<span>:noreply</span>, assign(socket, <span>:counter</span>, counter + <span>1</span>)}
  <span>end</span></code></pre>
<p>  It will mutate the LiveView's state to have a new, incremented value of the counter, and the <code>render/1</code> function will be called with the new assigns.</p>
<p>  The second argument, here named <code>params</code>, is of special interest as well, because - in the case of a <code>phx-click</code> event - it contains the event's metadata:</p>
<pre><code>  %{
    <span>"altKey"</span> =&gt; <span>false</span>,
    <span>"ctrlKey"</span> =&gt; <span>false</span>,
    <span>"metaKey"</span> =&gt; <span>false</span>,
    <span>"pageX"</span> =&gt; <span>399</span>,
    <span>"pageY"</span> =&gt; <span>197</span>,
    <span>"screenX"</span> =&gt; <span>399</span>,
    <span>"screenY"</span> =&gt; <span>558</span>,
    <span>"shiftKey"</span> =&gt; <span>false</span>,
    <span>"x"</span> =&gt; <span>399</span>,
    <span>"y"</span> =&gt; <span>197</span>
  }</code></pre>
<p>  We trust that you won't now hesitate to try it out with a <code>&lt;form&gt;</code> tag and a <code>phx-change</code> attribute to see what event metadata are passed when a form element's value is changed. Either way, <strong>we'll explore this in more detail in later episodes of this tutorial - stay tuned and <a href="#c-newsletter" target="_blank">subscribe to our newsletter</a> so that you don't miss out</strong>!</p>
<ul>
<li>A <a href="https://hexdocs.pm/phoenix_live_view/Phoenix.LiveView.html#c:handle_info/2" target="_blank"><code>handle_info/2</code></a> callback, handling events coming from <strong>anywhere but the browser</strong>. This means events sent from external sources <em>(remember a LiveView is just an Elixir process, so you can do whatever's needed in order for it to receive messages!)</em>, or events sent from the LiveView to itself. For instance, it takes this to increment the counter every 5 seconds:
</li>
</ul>
<pre><code>  <span><span>def</span> <span>mount</span></span>(params, socket) <span>do</span>
    if connected?(socket), <span>do:</span> <span>:timer</span>.send_interval(<span>5000</span>, <span>self</span>(), <span>:increment</span>)

    {<span>:ok</span>, assign(socket, <span>:counter</span>, <span>0</span>)}
  <span>end</span>

  <span><span>def</span> <span>handle_info</span></span>(<span>:increment</span>, %{<span>assigns:</span> %{<span>counter:</span> counter}} = socket) <span>do</span>
    {<span>:noreply</span>, socket |&gt; assign(<span>:counter</span>, counter + <span>1</span>)}
  <span>end</span></code></pre>
<p>  To reduce code repetition, you could make <code>handle_event/3</code> send a message to <code>self()</code> that triggers the same <code>handle_info/2</code> routine.</p>
<p>You can now access your LiveView as a standalone route - to do this, put this in your <code>router.ex</code>:</p>
<pre><code><span>import</span> Phoenix.LiveView.Router

scope <span>"/"</span>, YourappWeb <span>do</span>
 live <span>"/counter"</span>, CounterLive
<span>end</span></code></pre>
<p>...or render the LiveView within any other template:</p>
<pre><code>&lt;%= Phoenix.LiveView.live_render(<span>@conn</span>, YourappWeb.CounterLive) %&gt;</code></pre>
<h2>The Curious Messenger Roadmap<a name="series" target="_blank"></a></h2>
<p>We'll make you familiar with how to wield the Phoenix LiveView sword, and you'll build a fully-fledged Messenger replacement, which will make you (almost) forget about any other instant messaging app you had ever used before...</p>
<p>Phoenix LiveView is obviously only part of the story, and there's a lot more ground that we'll cover. We'll do a few episodes, each of which touches a different set of concerns that we'll have to consider when designing the app.</p>
<ul>
<li><a href="https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-2" target="_blank">At the beginning, we'll bootstrap the app and install all needed dependencies, design the app's database and context structure, with all of the app's business logic in mind.</a>
</li>
<li><a href="https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-3" target="_blank">Then we'll implement the app's user authentication feature using Pow, a great library integrating all the tools you need to let users sign up and log into the application. Next, we'll go on to implement the actual awesome Curious Messenger features, and here's where most of the <strong>Phoenix LiveView</strong> magic will shine. We'll show you how to create a live-updated view of your contact list and of each of your conversations.</a>
</li>
<li><a href="https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-4" target="_blank">Obviously, we'll also elaborate on what can go wrong when using LiveView, because the worst assumption one can make is that people's network connections are perfect. We'll see for ourselves that Phoenix LiveView is not the Holy Grail of reactive UI building solutions and that this approach has several shortcomings that need to be kept in mind.</a>
</li>
<li>Finally, we'll fine-tune the Curious Messenger app, adding some customizable settings and push notifications <em>(did we actually say there'll be no JS? We lied.)</em> so that you never miss out on any message from ‚Ä¶</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-1">https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-1</a></em></p>]]>
            </description>
            <link>https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25051678</guid>
            <pubDate>Tue, 10 Nov 2020 20:46:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Anatomy of OpenSSH Key Revocation List (KRL) File]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25051381">thread link</a>) | @dbsentry
<br/>
November 10, 2020 | https://keyper.dbsentry.com/post/anatomy-of-openssh-krl/ | <a href="https://web.archive.org/web/*/https://keyper.dbsentry.com/post/anatomy-of-openssh-krl/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="introduction">Introduction</h2><p>When I started working on the SSH Certificate feature for Keyper, the question of certificate revocation and its verification came up. I searched but could not find a lightweight python library for this (aim is to keep the docker image smaller than 100MB). As a first iteration, I implemented this using Python subprocess and <code>ssh-keygen</code>. <code>ssh-keygen</code> is an awesome utility and considered a Swiss Army Knife for SSH Keys. The same utility helps you when you are either setting up a certificate authority (CA) or OpenSSH Key Revocation List (KRL) file.</p><h2 id="krl-basics">KRL Basics</h2><p>A KRL can be created using <code>ssh-keygen</code>:</p><pre><code>[manish@getafix sshca]$ ssh-keygen -k -f ca_krl

[manish@getafix sshca]$ ls -l
total 4
-rw-r--r-- 1 manish manish 44 Nov  5 11:09 ca_krl
[manish@getafix sshca]$
</code></pre><p>A Key or a Certificate is revoked by adding them to the KRL using <code>ssh-keygen</code>:</p><pre><code>[manish@getafix sshca]$ ls -l
total 12
-rw-r--r-- 1 manish manish   44 Nov  5 11:09 ca_krl
-rw-r--r-- 1 manish manish 2009 Nov  5 11:13 id_rsa-cert.pub
-rw-r--r-- 1 manish manish  568 Nov  5 11:13 id_rsa.pub

[manish@getafix sshca]$ ssh-keygen -k -u -f ca_krl id_rsa.pub
Revoking from id_rsa.pub

[manish@getafix sshca]$ ssh-keygen -k -u -f ca_krl id_rsa-cert.pub
Revoking from id_rsa-cert.pub
[manish@getafix sshca]$ 
</code></pre><p>A Key or a Certificate revocation can be checked using <code>ssh-keygen</code>. The output is as follows when the Key/Certificate is not in the KRL:</p><pre><code>[manish@getafix sshca]$ ssh-keygen -Q -f ca_krl id_rsa.pub
id_rsa.pub (manish@getafix): ok

[manish@getafix sshca]$ ssh-keygen -Q -f ca_krl id_rsa-cert.pub
id_rsa-cert.pub (manish@getafix): ok
[manish@getafix sshca]$ 
</code></pre><p>And, as follows when Key/Certificate is in the KRL:</p><pre><code>[manish@getafix sshca]$ ssh-keygen -Q -f ca_krl id_rsa.pub
id_rsa.pub (manish@getafix): REVOKED

[manish@getafix sshca]$ ssh-keygen -Q -f ca_krl id_rsa-cert.pub
id_rsa-cert.pub (manish@getafix): REVOKED
[manish@getafix sshca]$ 
</code></pre><h2 id="ssh-keygen-limitation">ssh-keygen limitation</h2><p>Although <code>ssh-keygen</code> can revoke keys or certificates using their fingerprint or serial number, it needs full Key or the Certificate for the KRL verification. As a result, when using Keyper, each SSH server needs to be configured to send Public Key or the Certificate (configured using <code>%k</code> and <code>%t</code> in the <code>sshd_config</code> file). There is always an option to periodically copy the KRL file to each SSH server so that it performs local KRL lookup. I was not happy with sending the full Key or the Certificate as part of the API call during each authentication. But could neither find a way to perform KRL lookup using fingerprint or serial number using <code>ssh-keygen</code> nor find a lightweight Python library for it. So, I decided to write a KRL lookup myself in python. This post is about what I learned while doing this.</p><p><code>man ssh-keygen</code> defines OpenSSH format Key Revocation Lists (KRLs) as ‚Äúbinary files specify keys or certificates to be revoked using a compact format, taking as little as one bit per certificate if they are being revoked by serial number.‚Äù</p><h2 id="krl-anatomy">KRL Anatomy</h2><p>To understand its internal structure I started with the OpenSSH source code. File <code>krl.c</code> has the following relevant definition:</p><pre><code>/*
 * Trees of revoked serial numbers, key IDs and keys. This allows
 * quick searching, querying and producing lists in canonical order.
 */

/* Tree of serial numbers. XXX make smarter: really need a real sparse bitmap */
struct revoked_serial {
        u_int64_t lo, hi;
        RB_ENTRY(revoked_serial) tree_entry;
};
static int serial_cmp(struct revoked_serial *a, struct revoked_serial *b);
RB_HEAD(revoked_serial_tree, revoked_serial);
RB_GENERATE_STATIC(revoked_serial_tree, revoked_serial, tree_entry, serial_cmp);

/* Tree of key IDs */
struct revoked_key_id {
        char *key_id;
        RB_ENTRY(revoked_key_id) tree_entry;
};
static int key_id_cmp(struct revoked_key_id *a, struct revoked_key_id *b);
RB_HEAD(revoked_key_id_tree, revoked_key_id);
RB_GENERATE_STATIC(revoked_key_id_tree, revoked_key_id, tree_entry, key_id_cmp);

/* Tree of blobs (used for keys and fingerprints) */
struct revoked_blob {
        u_char *blob;
        size_t len;
        RB_ENTRY(revoked_blob) tree_entry;
};
static int blob_cmp(struct revoked_blob *a, struct revoked_blob *b);
RB_HEAD(revoked_blob_tree, revoked_blob);
RB_GENERATE_STATIC(revoked_blob_tree, revoked_blob, tree_entry, blob_cmp);

/* Tracks revoked certs for a single CA */
struct revoked_certs {
        struct sshkey *ca_key;
        struct revoked_serial_tree revoked_serials;
        struct revoked_key_id_tree revoked_key_ids;
        TAILQ_ENTRY(revoked_certs) entry;
};
TAILQ_HEAD(revoked_certs_list, revoked_certs);

struct ssh_krl {
        u_int64_t krl_version;
        u_int64_t generated_date;
        u_int64_t flags;
        char *comment;
        struct revoked_blob_tree revoked_keys;
        struct revoked_blob_tree revoked_sha1s;
        struct revoked_blob_tree revoked_sha256s;
        struct revoked_certs_list revoked_certs;
};
</code></pre><p>I started with <code>struct ssh_krl</code> and after spending a couple of hours trying to read and understand the OpenSSH code, my eyes were glazing. So, I went back to the internet search to see if anyone has already figured this out. I found this
<a href="https://github.com/openssh/openssh-portable/blob/master/PROTOCOL.krl" target="_blank" rel="noopener">page</a>.</p><h2 id="krl-file-format">KRL File Format</h2><pre><code>This describes the key/certificate revocation list format for OpenSSH.

1. Overall format

The KRL consists of a header and zero or more sections. The header is:

#define KRL_MAGIC   0x5353484b524c0a00ULL  /* "SSHKRL\n\0" */
#define KRL_FORMAT_VERSION  1

  uint64  KRL_MAGIC
  uint32  KRL_FORMAT_VERSION
  uint64  krl_version
  uint64  generated_date
  uint64  flags
  string  reserved
  string  comment

Where "krl_version" is a version number that increases each time the KRL
is modified, "generated_date" is the time in seconds since 1970-01-01
00:00:00 UTC that the KRL was generated, "comment" is an optional comment
and "reserved" an extension field whose contents are currently ignored.
No "flags" are currently defined.

Following the header are zero or more sections, each consisting of:

  byte  section_type
  string  section_data

Where "section_type" indicates the type of the "section_data". An exception
to this is the KRL_SECTION_SIGNATURE section, that has a slightly different
format (see below).

The available section types are:

#define KRL_SECTION_CERTIFICATES    1
#define KRL_SECTION_EXPLICIT_KEY    2
#define KRL_SECTION_FINGERPRINT_SHA1    3
#define KRL_SECTION_SIGNATURE     4
#define KRL_SECTION_FINGERPRINT_SHA256    5

2. Certificate section

These sections use type KRL_SECTION_CERTIFICATES to revoke certificates by
serial number or key ID. The consist of the CA key that issued the
certificates to be revoked and a reserved field whose contents is currently
ignored.

  string ca_key
  string reserved

Where "ca_key" is the standard SSH wire serialisation of the CA's
public key. Alternately, "ca_key" may be an empty string to indicate
the certificate section applies to all CAs (this is most useful when
revoking key IDs).

Followed by one or more sections:

  byte  cert_section_type
  string  cert_section_data

The certificate section types are:

#define KRL_SECTION_CERT_SERIAL_LIST  0x20
#define KRL_SECTION_CERT_SERIAL_RANGE 0x21
#define KRL_SECTION_CERT_SERIAL_BITMAP  0x22
#define KRL_SECTION_CERT_KEY_ID   0x23

2.1 Certificate serial list section

This section is identified as KRL_SECTION_CERT_SERIAL_LIST. It revokes
certificates by listing their serial numbers. The cert_section_data in this
case contains:

  uint64  revoked_cert_serial
  uint64  ...

This section may appear multiple times.

2.2. Certificate serial range section

These sections use type KRL_SECTION_CERT_SERIAL_RANGE and hold
a range of serial numbers of certificates:

  uint64  serial_min
  uint64  serial_max

All certificates in the range serial_min &lt;= serial &lt;= serial_max are
revoked.

This section may appear multiple times.

2.3. Certificate serial bitmap section

Bitmap sections use type KRL_SECTION_CERT_SERIAL_BITMAP and revoke keys
by listing their serial number in a bitmap.

  uint64  serial_offset
  mpint revoked_keys_bitmap

A bit set at index N in the bitmap corresponds to revocation of a keys with
serial number (serial_offset + N).

This section may appear multiple times.

2.4. Revoked key ID sections

KRL_SECTION_CERT_KEY_ID sections revoke particular certificate "key
ID" strings. This may be useful in revoking all certificates
associated with a particular identity, e.g. a host or a user.

  string  key_id[0]
  ...

This section must contain at least one "key_id". This section may appear
multiple times.

3. Explicit key sections

These sections, identified as KRL_SECTION_EXPLICIT_KEY, revoke keys
(not certificates). They are less space efficient than serial numbers,
but are able to revoke plain keys.

  string  public_key_blob[0]
  ....

This section must contain at least one "public_key_blob". The blob
must be a raw key (i.e. not a certificate).

This section may appear multiple times.

4. SHA1/SHA256 fingerprint sections

These sections, identified as KRL_SECTION_FINGERPRINT_SHA1 and
KRL_SECTION_FINGERPRINT_SHA256, revoke plain keys (i.e. not
certificates) by listing their hashes:

  string  public_key_hash[0]
  ....

This section must contain at least one "public_key_hash". The hash blob
is obtained by taking the SHA1 or SHA256 hash of the public key blob.
Hashes in this section must appear in numeric order, treating each hash
as a big-endian integer.

This section may appear multiple times.
...
</code></pre><h2 id="krl-internals-in-action">KRL Internals in action</h2><p>The above clarified a lot. However, I still wasn‚Äôt clear about how would a parser figure the length of any string in the KRL file? (for e.g. <code>string section_data</code>) I decided to start looking into the KRL file itself. I started with a freshly generated KRL file.</p><pre><code>[manish@getafix sshca]$ ssh-keygen -k -f ca_krl

[manish@getafix sshca]$ hexdump -C ca_krl
00000000  53 53 48 4b 52 4c 0a 00  00 00 00 01 00 00 00 00  |SSHKRL..........|
00000010  00 00 00 00 00 00 00 00  5f a4 36 97 00 00 00 00  |........_.6.....|
00000020  00 00 00 00 00 00 00 ‚Ä¶</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://keyper.dbsentry.com/post/anatomy-of-openssh-krl/">https://keyper.dbsentry.com/post/anatomy-of-openssh-krl/</a></em></p>]]>
            </description>
            <link>https://keyper.dbsentry.com/post/anatomy-of-openssh-krl/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25051381</guid>
            <pubDate>Tue, 10 Nov 2020 20:23:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Flaws of ‚ÄúSubscription Fatigue‚Äù, ‚ÄúSVOD Fatigue‚Äù, and the ‚ÄúStreaming Wars‚Äù]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25051292">thread link</a>) | @bschne
<br/>
November 10, 2020 | https://www.matthewball.vc/all/misnomers | <a href="https://web.archive.org/web/*/https://www.matthewball.vc/all/misnomers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-96dbb3b03808a860d80e"><div><p>When we consider the state of tech-media in 2020, there are a few common narratives. The most inescapable is the ‚ÄúStreaming Wars‚Äù. In November, I argued that <a href="https://www.matthewball.vc/all/minedmedia">this term was a misnomer</a>. Digital/streaming/OTT video is really just <em>a</em> battle in a much larger war: the ‚Äúecosystem war‚Äù. And for the most part, this war is fought asymmetrically. Apple and Amazon both sell digital media devices, third-party media content, and their own original content, for example. However, Apple isn‚Äôt an e-retailer nor a diversified enterprise cloud services provider, and Amazon doesn‚Äôt even have a smartphone, personal computer, watch or non-video app store. I‚Äôll come back to this idea, but understanding the differences between these companies and their motivations is helpful when considering two other popular phases that are unhelpful at best and misleading at worst: ‚Äúsubscription fatigue‚Äù and ‚ÄúSVOD fatigue‚Äù.</p><p><strong>‚ÄúSubscription Fatigue‚Äù</strong></p><p>The ‚Äúsubscription economy‚Äù, by definition, presumes that the overall ‚Äúeconomy‚Äù ‚Äì from products, to services, content, transportation, labor and more ‚Äì is shifting over to ‚Äúsubscriptions‚Äù. Thus, to claim that consumers have ‚Äúsubscription fatigue‚Äù is to say that they have ‚Äúspending fatigue‚Äù.</p><p>As always, most consumers will say they wish they spent less money, bought fewer things, and enjoyed lower prices. However, it makes little sense to say that the decision to buy TV subscriptions, radio subscriptions, toothbrush subscriptions, video gaming subscriptions, dog food subscriptions, car subscriptions, or productivity software subscriptions should drive ‚Äúsubscription fatigue‚Äù or mean each subscription competes with one another. For decades, consumers have bought TV, music, toothbrushes, video games, dog food, cars and Microsoft Office. What‚Äôs new is that they all have similar models ‚Äì digitally-based, predominantly D2C subscriptions. This changes nothing about the individual value or baseline need for them.</p><p>Of course, the ‚Äúsubscription economy‚Äù does mean that step one of a recession will be to ‚Äúre-evaluate all subscriptions‚Äù. However, this does not mean subscription <em>fatigue</em> should be considered a real ‚Äúthing‚Äù, let alone a defining element of modern-day competition. Furthermore, payment model ‚Äì upfront v. recurring, subscription v. √° la carte, online v. offline ‚Äì is irrelevant to what‚Äôs ‚Äúre-evaluated‚Äù and not. Some subscriptions are ‚Äúnecessities‚Äù, like toilet paper, while others are concerned with discretionary spend, such as Office 365 or Netflix or Tinder. This latter group isn‚Äôt competitive because they‚Äôre ‚Äúsubscriptions‚Äù, but because there is, as always, finite spending money for non-essential items. </p><p>To this end, it‚Äôs important to highlight subscriptions are often a <em>preferred</em> buying path for consumers. Most would rather (or can only afford) $10 a month for a multi-year license to Microsoft Office for $300. Subscriptions also meaningfully reduce the cognitive burden of repeat decision making. No longer do you need to ‚Äútrack‚Äù your toothbrush for wear, risk ‚Äúrunning out‚Äù of toilet paper and then be forced to overpay for a small-volume purchase, or need to scan and hoard coupons to ensure a great deal. Similarly, many consumers would rather marginally overpay for an all-you-can-eat subscription than optimize for specific tiers of use. In fact, most of us have caustic responses to per unit pricing, often to the point of irrationality (e.g. $40 for 35 loads of laundry detergent v. $1.00 per load). Amazon Prime is based on the <em>need</em> to get shipping fees out of the way once, versus fight them over and over and over and over, even if the effective shipping cost went up for a consumer, or the lack of shipping costs led to unnecessary purchases.</p><p>The rise of fully flexible monthly commitments also means that consumers no longer have to worry about having made a bad decision and being stuck with it. In this sense, every subscription is still √° la carte, but unlike in the analog era, the default outcome of ‚Äúdoing nothing‚Äù is to keep getting value you enjoy rather than running out of a thing you need. </p><p><em>(Note that none of this means that a digital subscription business is a ‚Äúgood‚Äù one. Many sub-categories of CPGs and foodstuffs, not to mention music or fitness equipment, weren‚Äôt good business before the shift to subscription. The fact they shifted to subscriptions doesn‚Äôt inherently change this, just as it doesn‚Äôt mean they suddenly compete with all other subscriptions).</em></p><p><strong>‚ÄúSVOD Fatigue‚Äù</strong></p><p>Of course, the nuances of ‚Äúsubscription fatigue‚Äù is separate from the question of ‚ÄúSubscription <em>VOD</em> fatigue‚Äù. It is obvious consumers don‚Äôt need 20 Netflixes. However, they‚Äôre not being asked to buy 20 Netflixes. It‚Äôs wrong to treat Fox Nation, Netflix, ESPN, and Twitch as competitors, let alone interchangeable ‚Äúunits of SVOD‚Äù. They serve very different functions and offer very different content. Just as Spotify and the <em>New York Times</em> and Amazon Prime shipping each do.</p><p>Amazon and Apple TV+, meanwhile, aren‚Äôt Netflixes ‚Äì not in monetization, content volumes, or strategy. Now, if Amazon or Apple‚Äôs SVOD services can monetize so dramatically better through the Prime and iOS ecosystem than Netflix can via direct consumer spend and a singular focus, they can, in theory, ‚Äúkill‚Äù Netflix ‚Äì should they so choose ‚Äì but that has nothing to do with SVOD fatigue nor the number of viable SVODs.</p><p>The question of SVOD fatigue isn‚Äôt about ‚Äúhow many SVODs will the average household have‚Äù. It‚Äôs really about ‚Äúhow many different roles are there to be played in video‚Äù. And the answer here is mostly path dependent ‚Äì it depends on the innovation, risk taking, and discovery that happens in the marketplace, as well as timing. No one knew ‚Äúlive streaming video games‚Äù was an opportunity until Twitch, for example. And while Twitch likely steals <em>time</em> away from the video ecosystem, the viability of the Twitch subscription doesn‚Äôt mean that the number of viable OTT services has reduced.</p><p><strong>The Question</strong></p><p>All of which is to say what matters in SVOD is simple and not unique to SVOD: <span>A service will succeed if (1) it addresses a real, outstanding customer want/need; (2) at an appropriate price or value to the consumer; and (3) while generating sustainable economics</span>. </p><p>Quibi is a good example here. The company believes that there is an outstanding need for a new type of content, focused on a different time and place, under a different viewing behavior and focused on a specific audience. If it is right, and it can build up a defensible leadership position before other players replicate it, a new subscription will be possible and it doesn‚Äôt matter how many SVODs a customer already has (just as whether they have NYT or Spotify doesn‚Äôt matter). But of course, if you ask consumers ‚Äúdo you wish you had fewer subscriptions‚Äù or ‚Äúfewer SVODs‚Äù, they will say yes ‚Äì especially if they don‚Äôt really know what the new ‚Äúthing‚Äù is. Note, too, that Pay-TV studies have been promising that 10%‚Äì30% of subscribers will cancel each year. They never do‚Ä¶ because enough value remains. </p><p>More broadly, this three-point framework is well established (it actually has nothing to do with video). Over the past forty years, we have seen countless examples of ‚Äúnetworks‚Äù launching into hyper-saturated marketplaces with hyper-specific but unproven (and often openly derided) theses regarding outstanding consumer wants and needs. Almost all of these have succeeded. In fact, they usually spawned several direct competitors ‚Äì showing that the unmet want was even larger than originally anticipated. &nbsp;</p><p>For example‚Ä¶</p><ul data-rte-list="default"><li><p><em>1972: HBO launched a network focused on the most valuable TV time, Sunday night, with an unprecedented monetization model (√° la carte consumer spend and no advertising), and focused only on reruns of Hollywood movies. It was ultimately bought by 25% of TV homes, became the most profitable network in the world and the market leader in quality. And this was despite the launches of Showtime (1976), Starz (1994) and Epix (2009).</em></p></li><li><p><em>1977: Nickelodeon launched 24/7 content only for kids. No longer was kids content relegated just to afternoon and Sunday morning blocks. In the 2000s, Nickelodeon became the most watched cable network, despite having spun-off several other Nick-branded channels and seen the launch of The Disney Channel in 1983.</em></p></li><li><p><em>1979: ESPN launched a 24/7 sports channel, ultimately with the highest programming budget in the world. In 2019, it brought in more than $2.5B in profits, with an annual revenue of roughly $9B. In 2009, Fox launched its own suite of 24/7 Fox-branded sports networks.</em></p></li><li><p><em>1980: CNN launched a 24/7 news channel. Today, it generates an estimated $800MM a year in cash flow on $2B in revenue, and several other 24/7 networks exist.</em></p></li><li><p><em>1981: MTV launched a 24/7 music video and culture channel that focused only on young audiences. The result was the first new Hollywood film/TV conglomerate in decades. Within years, MTV had launched several other 24/7 networks, while competitors launched even more focused versions, such as CMT.</em></p></li><li><p><em>1983: BET launched a 24/7 network focused on black American audiences. In 2001, the company was sold to Viacom for $3B. Several other black-focused networks exist today. </em></p></li><li><p><em>1996: Fox News launched a 24/7 news channel‚Ä¶ only for half of news watchers. It now generates more than $1.5B in cash on $2.5B+ revenue</em></p></li></ul><p>Of course, this sort of logic can be used to justify faulty assumptions around what opportunity exists, where, how large it might be, how durable it is, etc. In addition, these specifics gaps were open because of technological limitations. A network like ABC could only air one thing at a time ‚Äì and therefore there were structural impediments to serving ‚Äúeveryone‚Äù. Netflix, meanwhile, can air anything, at any time, to every viewer, and on an individual basis.</p><p>But the crucial point here is that it‚Äôs wrong to think about the ‚Äúnumber‚Äù of subscription video services, just as it was wrong to think about how ‚Äúmany‚Äù networks were in the cable bundle in 1980, 1985, 1990, and so on. In fact, it‚Äôs incredibly close ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.matthewball.vc/all/misnomers">https://www.matthewball.vc/all/misnomers</a></em></p>]]>
            </description>
            <link>https://www.matthewball.vc/all/misnomers</link>
            <guid isPermaLink="false">hacker-news-small-sites-25051292</guid>
            <pubDate>Tue, 10 Nov 2020 20:18:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MCMC in JAX with benchmarks: 3 ways to write a sampler]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25051196">thread link</a>) | @jeremiecoullon
<br/>
November 10, 2020 | https://www.jeremiecoullon.com/2020/11/10/mcmcjax3ways/ | <a href="https://web.archive.org/web/*/https://www.jeremiecoullon.com/2020/11/10/mcmcjax3ways/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        
<article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>This post goes over 3 ways to write a sampler using JAX. I found that although there are a bunch of tutorials about learning the basics of JAX, it was not clear to me what was the best way to write a sampler in JAX. In particular, how much of the sampler should you write in JAX? Just the log-posterior (or the loss in the case of optimisation), or the entire loop? This blog post tries to answer this by going over 3 ways to write a sampler while focusing on the speed of each sampler.</p>

<p>I‚Äôll assume that you already know some JAX, in particular the functions <code>grad</code>, <code>vmap</code>, and <code>jit</code>, along with the random number generator. If not, you can check out how to use these in this <a href="https://colinraffel.com/blog/you-don-t-know-jax.html">blog post</a> or in the <a href="https://jax.readthedocs.io/en/latest/notebooks/quickstart.html">JAX documentation</a>! I will rather focus on the different ways of using JAX for sampling (using the ULA sampler) and the speed performance of each implementation. I‚Äôll then redo these benchmarks for 2 other samplers (MALA and SLGD) You can find the code to reproduce all these examples on <a href="https://github.com/jeremiecoullon/jax_MCMC_blog_post">Github</a>.</p>

<h2 id="sampler-and-model">Sampler and model</h2>

<p>To benchmark the samplers we‚Äôll Bayesian logistic regression throughout. As sampler we‚Äôll start with the unadjusted Langevin algorithm (ULA) with Euler dicretisation, as it is one of the simplest gradient-based samplers out there due to the lack of accept-reject step. Let  be the parameter at iteration ,   the gradient of the log-posterior,  the step size, and . Given a current position of the chain, the next sample is given by the equation:</p>



<p>The setup of the logistic regression model is the same as the one from this <a href="https://arxiv.org/abs/1907.06986">SG-MCMC review paper</a>:</p>

<ul>
  <li>Matrix of covariates , and vector responses: </li>
  <li>Parameters: </li>
</ul>

<p><strong>Model:</strong></p>

<ul>
  <li> with </li>
  <li>Prior:  with </li>
  <li>Likelihood: </li>
</ul>

<h2 id="version-1-python-loop-with-jax-for-the-log-posterior">Version 1: Python loop with JAX for the log-posterior</h2>

<p>In this version we only use JAX to write the log-posterior function (or the loss function in the case of optimisation). We use <code>vmap</code> to calculate the log-likelihood for each data point, <code>jit</code> to compile the function, and <code>grad</code> to get the gradient (see the code for the model on <a href="https://github.com/jeremiecoullon/jax_MCMC_blog_post/blob/master/logistic_regression_model.py">Github</a>). The rest of the sampler is a simple Python loop with NumPy to store the samples, as is shown below:</p>

<div><div><pre><code><span>def</span> <span>ula_sampler_python</span><span>(</span><span>grad_log_post</span><span>,</span> <span>num_samples</span><span>,</span> <span>dt</span><span>,</span> <span>x_0</span><span>,</span> <span>print_rate</span><span>=</span><span>500</span><span>):</span>
    <span>dim</span><span>,</span> <span>=</span> <span>x_0</span><span>.</span><span>shape</span>
    <span>samples</span> <span>=</span> <span>np</span><span>.</span><span>zeros</span><span>((</span><span>num_samples</span><span>,</span> <span>dim</span><span>))</span>
    <span>paramCurrent</span> <span>=</span> <span>x_0</span>

    <span>print</span><span>(</span><span>f</span><span>"Python sampler:"</span><span>)</span>
    <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>num_samples</span><span>):</span>
        <span>paramGradCurrent</span> <span>=</span> <span>grad_log_post</span><span>(</span><span>paramCurrent</span><span>)</span>
        <span>paramCurrent</span> <span>=</span> <span>paramCurrent</span> <span>+</span> <span>dt</span><span>*</span><span>paramGradCurrent</span> <span>+</span>
                        <span>np</span><span>.</span><span>sqrt</span><span>(</span><span>2</span><span>*</span><span>dt</span><span>)</span><span>*</span><span>np</span><span>.</span><span>random</span><span>.</span><span>normal</span><span>(</span><span>size</span><span>=</span><span>(</span><span>paramCurrent</span><span>.</span><span>shape</span><span>))</span>
        <span>samples</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>paramCurrent</span>
        <span>if</span> <span>i</span><span>%</span><span>print_rate</span><span>==</span><span>0</span><span>:</span>
            <span>print</span><span>(</span><span>f</span><span>"Iteration {i}/{num_samples}"</span><span>)</span>
    <span>return</span> <span>samples</span>
</code></pre></div></div>

<p>In this sampler we write the udpate equation using NumPy and store the samples in the array <code>samples</code>.</p>

<h2 id="version-2-jax-for-the-transition-kernel">Version 2: JAX for the transition kernel</h2>

<p>With JAX we can compile functions using <code>jit</code> which makes them run faster (we did this for the log-posterior function). Could we not put the bit inside the loop in a function and compile that? The issue is that for <code>jit</code> to work, you can‚Äôt have NumPy arrays or use the NumPy random number generator (<code>np.random.normal()</code>).</p>

<p>JAX does random numbers a bit differently to NumPy. I won‚Äôt explain how this bit works; you can read about them in the <a href="https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#JAX-PRNG">documentation</a>. The main idea is that jit-compiled JAX function don‚Äôt allow side effects, such as updating a global random state. As a result, you have to explicitly pass in a PRNG (called <code>key</code>) to every function that includes randomness, and split the key to get different pseudorandom numbers.</p>

<p>Below is a function for the transition kernel of the sampler rewritten to only include JAX functions and arrays (so it can be compiled). The point of the <code>partial</code> decorator and the <code>static_argnums</code> argument is to point to which arguments will not change once the function is compiled. Indeed, the function for the gradient of the log-posterior or the step size will not change throughout the sampler, but the PRNG key and the parameter definitely will! The means that the function will run faster as it can hardcode these static values/functions during compilation. Note that if the argument is a function (as is the case for <code>grad_log_post</code>) you don‚Äôt have a choice and must set it as static. See the <a href="https://jax.readthedocs.io/en/latest/jax.html#jax.jit">documentation</a> for info on this.</p>

<div><div><pre><code><span>@</span><span>partial</span><span>(</span><span>jit</span><span>,</span> <span>static_argnums</span><span>=</span><span>(</span><span>2</span><span>,</span><span>3</span><span>))</span>
<span>def</span> <span>ula_kernel</span><span>(</span><span>key</span><span>,</span> <span>param</span><span>,</span> <span>grad_log_post</span><span>,</span> <span>dt</span><span>):</span>
    <span>key</span><span>,</span> <span>subkey</span> <span>=</span> <span>random</span><span>.</span><span>split</span><span>(</span><span>key</span><span>)</span>
    <span>paramGrad</span> <span>=</span> <span>grad_log_post</span><span>(</span><span>param</span><span>)</span>
    <span>param</span> <span>=</span> <span>param</span> <span>+</span> <span>dt</span><span>*</span><span>paramGrad</span> <span>+</span> <span>jnp</span><span>.</span><span>sqrt</span><span>(</span><span>2</span><span>*</span><span>dt</span><span>)</span><span>*</span><span>random</span><span>.</span><span>normal</span><span>(</span><span>key</span><span>=</span><span>subkey</span><span>,</span> <span>shape</span><span>=</span><span>(</span><span>param</span><span>.</span><span>shape</span><span>))</span>
    <span>return</span> <span>key</span><span>,</span> <span>param</span>
</code></pre></div></div>

<p>The main loop in the previous function now becomes:</p>

<div><div><pre><code><span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>num_samples</span><span>):</span>
    <span>key</span><span>,</span> <span>param</span> <span>=</span> <span>ula_kernel</span><span>(</span><span>key</span><span>,</span> <span>param</span><span>,</span> <span>grad_log_post</span><span>,</span> <span>dt</span><span>)</span>
    <span>samples</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>param</span>
    <span>if</span> <span>i</span><span>%</span><span>print_rate</span><span>==</span><span>0</span><span>:</span>
        <span>print</span><span>(</span><span>f</span><span>"Iteration {i}/{num_samples}"</span><span>)</span>
</code></pre></div></div>
<p>Notice how we split the random key inside <code>ula_kernel()</code> function which means it gets compiled (JAX‚Äôs random number generator can be <a href="https://github.com/google/jax/issues/968">slow in some cases</a>). We still save the samples in the NumPy array <code>samples</code> as in the previous case. Running this function several times with the same starting PRNG key will now produce exactly the sample samples, which means that the sampler is completely reproducible.</p>

<h2 id="version-3-full-jax">Version 3: full JAX</h2>

<p>We‚Äôve written more of our function in JAX, but there is still some Python left. Could we rewrite the entire sampler in JAX? It turns out that we can! JAX does allow us write loops, but as it is designed to work on <a href="https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#%F0%9F%94%AA-Pure-functions">pure functions</a> you need to use the <a href="https://jax.readthedocs.io/en/latest/_autosummary/jax.lax.scan.html"><code>scan</code></a> function. This function which allows you to loop over an array (similar to doing <code>for elem in mylist</code> in Python).</p>

<p>The way to use <code>scan</code> is to pass in a function that is called at every iteration. This function takes in <code>carry</code> which contains all the information you use in each iteration (and which you update as you go along). It also takes in <code>x</code> which is the value of the array you‚Äôre iterating over. It should return an updated version of <code>carry</code> along with anything who‚Äôs progress you want to keep track of: in our case, we want to store all the samples as we iterate.</p>

<p>Note that JAX also has a similar <a href="https://jax.readthedocs.io/en/latest/_autosummary/jax.lax.fori_loop.html"><code>fori_loop</code></a> function which apparently you should only use if you can‚Äôt use scan (see the <a href="https://github.com/google/jax/discussions/3850">discussion on Github</a>). In the case of our sampler <code>scan</code> is easier to use as you don‚Äôt need to explicitly keep track of the entire chain of samples; <code>scan</code> does it for you. In contrast, when using <code>fori_loop</code> you have to pass an array of samples in <code>state</code> which you update yourself as you go along. In terms of performance I did quick benchmark for both and didn‚Äôt see a speed difference in this case, though the <a href="https://github.com/google/jax/discussions/3850">discussion on Github</a> says there can be speed benefits.</p>

<p>Here is the function that we‚Äôll pass in <code>scan</code>. Note that the first line unpacks <code>carry</code>. The <code>ula_kernel</code> function then generates the new key and parameter. We then return the new version of <code>carry</code> (ie: <code>(key, param)</code>) which includes the updated key and parameter, and return the current parameter (<code>param</code>) which <code>scan</code> will save in an array.</p>

<div><div><pre><code><span>def</span> <span>ula_step</span><span>(</span><span>carry</span><span>,</span> <span>x</span><span>):</span>
  <span>key</span><span>,</span> <span>param</span> <span>=</span> <span>carry</span>
  <span>key</span><span>,</span> <span>param</span> <span>=</span> <span>ula_kernel</span><span>(</span><span>key</span><span>,</span> <span>param</span><span>,</span> <span>grad_log_post</span><span>,</span> <span>dt</span><span>)</span>
  <span>return</span> <span>(</span><span>key</span><span>,</span> <span>param</span><span>),</span> <span>param</span>
</code></pre></div></div>

<p>You can then pass this function along with the initial state in <code>scan</code>, and recover the final <code>carry</code> along with all the samples. The last two arguments in the <code>scan</code> function below mean that we don‚Äôt care what we‚Äôre iterating over; we simply want to run the sampler for <code>num_samples</code> number of iterations (as always, see the <a href="https://jax.readthedocs.io/en/latest/_autosummary/jax.lax.scan.html">docs</a> for details).</p>

<div><div><pre><code><span>carry</span> <span>=</span> <span>(</span><span>key</span><span>,</span> <span>x_0</span><span>)</span>
<span>carry</span><span>,</span> <span>samples</span> <span>=</span> <span>lax</span><span>.</span><span>scan</span><span>(</span><span>ula_step</span><span>,</span> <span>carry</span><span>,</span> <span>None</span><span>,</span> <span>num_samples</span><span>)</span>
</code></pre></div></div>

<p>Putting it all together in a single function, we get the following. Notice that we compile the entire function with <code>grad_log_post</code>, <code>num_samples</code>, and <code>dt</code> kept as static. We allow the PRNG key and the starting point of the chain <code>x_0</code> to vary so we can get different realisations of our chain.</p>

<div><div><pre><code><span>@</span><span>partial</span><span>(</span><span>jit</span><span>,</span> <span>static_argnums</span><span>=</span><span>(</span><span>1</span><span>,</span><span>2</span><span>,</span><span>3</span><span>))</span>
<span>def</span> <span>ula_sampler_full_jax_jit</span><span>(</span><span>key</span><span>,</span> <span>grad_log_post</span><span>,</span> <span>num_samples</span><span>,</span> <span>dt</span><span>,</span> <span>x_0</span><span>):</span>

    <span>def</span> <span>ula_step</span><span>(</span><span>carry</span><span>,</span> <span>x</span><span>):</span>
        <span>key</span><span>,</span> <span>param</span> <span>=</span> <span>carry</span>
        <span>key</span><span>,</span> <span>param</span> <span>=</span> <span>ula_kernel</span><span>(</span><span>key</span><span>,</span> <span>param</span><span>,</span> <span>grad_log_post</span><span>,</span> <span>dt</span><span>)</span>
        <span>return</span> <span>(</span><span>key</span><span>,</span> <span>param</span><span>),</span> <span>param</span>

    <span>carry</span> <span>=</span> <span>(</span><span>key</span><span>,</span> <span>x_0</span><span>)</span>
    <span>_</span><span>,</span> <span>samples</span> <span>=</span> <span>lax</span><span>.</span><span>scan</span><span>(</span><span>ula_step</span><span>,</span> <span>carry</span><span>,</span> <span>None</span><span>,</span> <span>num_samples</span><span>)</span>
    <span>return</span> <span>samples</span>
</code></pre></div></div>

<p>Having the entire function written in JAX means that once the function is compiled it will usually be faster (see benchmarks below), and we can rerun it for different PRNG keys or different initial conditions to get different realisations of the chain. We can also run this function in <code>vmap</code> (mapping over the keys or inital conditions) to get several chains running in parallel. Check out this <a href="https://rlouf.github.io/post/jax-random-walk-metropolis/">blog post</a> for a benchmark of a Metropolis sampler in parallel using JAX and Tensorflow.</p>

<p>The only thing left to do this the full JAX version is to print the progress of the chain, which is especially useful for long runs. This is not as straightforwards to do with jitted functions as with standard Python functions, but this <a href="https://github.com/google/jax/discussions/4763">discussion on Github</a> goes over how to do this.</p>

<p>The final thing to point out is this JAX code ports directly to GPU without any modifications, so it might be possible to get an additional speedup in the full JAX version compared to those discussed below.</p>



<p>Now that we‚Äôve gone over 3 ways to write an MCMC sampler we‚Äôll show some speed benchmarks for ULA along with two other algorithms. We use the logistic regression model presented above and run <code>20 000</code> samples throughout.</p>

<h2 id="unadjusted-langevin-algorithm">Unadjusted Langevin algorithm</h2>

<h3 id="increase-amount-of-data">Increase amount of data:</h3>

<p>We run ULA for <code>20 000</code> samples for a 5 dimensional parameter. We vary the amount of data used and see how fast the algorithms are (time is in seconds).</p>

<table>
  <thead>
    <tr>
      <th>dataset size</th>
      <th>python</th>
      <th>JAX kernel</th>
      <th>full JAX (1st run)</th>
      <th>full JAX (2nd run)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td></td>
      <td>11</td>
      <td>3.4</td>
      <td>0.53</td>
      <td>0.18</td>
    </tr>
    <tr>
      <td></td>
      <td>11</td>
      <td>4.6</td>
      <td>2.0</td>
      <td>1.6</td>
    </tr>
    <tr>
      <td></td>
      <td>32</td>
      <td>32</td>
      <td>24</td>
      <td>24</td>
    </tr>
    <tr>
      <td></td>
      <td>280</td>
      <td>280</td>
      <td>250</td>
      <td>250</td>
    </tr>
  </tbody>
</table>

<p>We can see that for small amounts of data the full JAX sampler is much faster than the Python loop. In particular, for 1000 data points the full JAX sampler (once compiled) is almost 60 times faster than the Python loop version.</p>

<p>Note that all the samplers use JAX to get the gradient of the log-posterior ‚Ä¶</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.jeremiecoullon.com/2020/11/10/mcmcjax3ways/">https://www.jeremiecoullon.com/2020/11/10/mcmcjax3ways/</a></em></p>]]>
            </description>
            <link>https://www.jeremiecoullon.com/2020/11/10/mcmcjax3ways/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25051196</guid>
            <pubDate>Tue, 10 Nov 2020 20:11:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Large-Scale Geo-Replicated Conflict-Free Replicated Data Types [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25051115">thread link</a>) | @simonebrunozzi
<br/>
November 10, 2020 | https://www.gsd.inesc-id.pt/~ler/reports/carlosbartolomeu-midterm.pdf | <a href="https://web.archive.org/web/*/https://www.gsd.inesc-id.pt/~ler/reports/carlosbartolomeu-midterm.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.gsd.inesc-id.pt/~ler/reports/carlosbartolomeu-midterm.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25051115</guid>
            <pubDate>Tue, 10 Nov 2020 20:06:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Middle Management]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25050928">thread link</a>) | @duck
<br/>
November 10, 2020 | https://boz.com/articles/middle-management | <a href="https://web.archive.org/web/*/https://boz.com/articles/middle-management">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><p>There is an old saying in business that people don‚Äôt leave a job, they leave a
manager. I have found this to be generally accurate. But in my experience the
next most likely person to influence them isn‚Äôt their manager‚Äôs manager. It
is the CEO. </p>
<p>One reason I think middle managers so often feel like they are in no-man‚Äôs
land is because, well, they are. This is a chart I made up of how valuable a
connection is from each person to the various levels of management above
them.</p>
<p><img src="https://boz.com/middle-management.png" alt="horseshoe chart"></p>
<p>The ennui many middle managers feel at the trough of this diagram is
understandable. To the team you are the voice of management. But to
management you are the voice of the team. When I was at the nadir of this
chart in my own career it was the closest I came to leaving Facebook.</p>
<p>Eventually I managed to sort out a few strategies that helped me genuinely
enjoy middle management.</p>
<p>First, take pride in your job as the central link in the chain. Be an
efficient conduit of information in both directions. Don‚Äôt create any
friction in either direction unless you are sure you have unique value to
add. Too many middle managers create a layer for themselves when it isn‚Äôt
necessary which slows things down and is a form of value add disease.</p>
<p>Second, use this opportunity to sharpen your skills managing managers and
information flows. Those will be your core responsibilities for the rest of
your career from this point forward. </p>
<p>With those basic responsibilities sorted, you will find that this position in
the value chain allows you to identify opportunities nobody else sees. While
employees and senior leadership align on the work, you are effectively left to
operate the machinery by which work gets done. You have purview over the
processes that enable communication, escalation, and decision making. </p>
<p>As you advance in your career these things start to become obfuscated as
people push them below the surface to cater more to you. But they are always
there, as a hidden form of gravity that you will recognize if you invest the
time now. When teams slow down or drift from their mission, this is where the
problem is. When scope creeps or execution lags this is usually the first
place to look. I think this is one reason managers who were developed
internally often outperform those who arrived on top of an organization. It
helps if the machinery of progress isn‚Äôt entirely an abstraction.</p></section></div></div>]]>
            </description>
            <link>https://boz.com/articles/middle-management</link>
            <guid isPermaLink="false">hacker-news-small-sites-25050928</guid>
            <pubDate>Tue, 10 Nov 2020 19:55:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[8 questions for writing]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25050838">thread link</a>) | @flreln
<br/>
November 10, 2020 | https://vasilishynkarenka.com/8questions/ | <a href="https://web.archive.org/web/*/https://vasilishynkarenka.com/8questions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://vasilishynkarenka.com/content/images/size/w300/2020/11/angelina-litvin-K3uOmmlQmOo-unsplash.jpg 300w,
                            https://vasilishynkarenka.com/content/images/size/w600/2020/11/angelina-litvin-K3uOmmlQmOo-unsplash.jpg 600w,
                            https://vasilishynkarenka.com/content/images/size/w1000/2020/11/angelina-litvin-K3uOmmlQmOo-unsplash.jpg 1000w,
                            https://vasilishynkarenka.com/content/images/size/w2000/2020/11/angelina-litvin-K3uOmmlQmOo-unsplash.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://vasilishynkarenka.com/content/images/size/w2000/2020/11/angelina-litvin-K3uOmmlQmOo-unsplash.jpg" alt="8 questions for writing">
            </figure>

            <section>
                <div>
                    <p>You cannot write productively if you do not have a plan.</p><p>That‚Äôs why most people struggle with writing: they have an idea to communicate but no specific plan of action to express their thought. As a result, they either procrastinate and never begin writing in the first place, or they hit writer‚Äôs block and spend hours staring at a blinking cursor on the top of a blank page.</p><p>The reason why people don‚Äôt plan writing is counterintuitive. They <em>think</em> they know how to write because they know the alphabet. But just like learning how to drive Toyota Prius in the suburbs doesn‚Äôt make you Michael Schumacher on track, knowing how to write symbols doesn‚Äôt make you a professional writer. You need to learn the skill.</p><p>The secret to good writing, as to any kind of knowledge work, is deliberate planning. If you do not have a plan, writing becomes a mysterious process you do only when you‚Äôre inspired. But if you document what you‚Äôre going to do, writing turns into a professional act with less opportunity for sloth. And the best way to plan writing is to ask questions.</p><p>If you think about something proactively, you run two mental processes at once. First, you keep the subject of your thought in your working memory. And second, you actively search through your mind for the object of interest. That‚Äôs a problem, given how much effort it takes to stay focused on a task.</p><p>But if you present yourself with a question, you change that. When you write the question down and look at it, you stay focused for longer. You benefit from your sensory channels to stay engaged, and you also run one mental process instead of two.</p><p>That‚Äôs why I‚Äôve built a simple routine of asking myself a set of questions about what I‚Äôm planning to write. I apply it whenever I experience an itch like, ‚ÄúOh, I could write an article about this!‚Äù After running the process for two months, I‚Äôve empirically discovered how important it is to capture the idea right at the moment when it‚Äôs being formed. If I don‚Äôt turn my thought into an objective artifact that I can revisit later, I lose it.</p><p>Here are five reasons why questions work so well for writing:</p><ol><li>Good questions are like an advanced Google Search query to your mind. They have high suggestive value because the parameters that you pass to a question light up relevant areas of memory for you. If you do not have a question in mind and just roam through ideas, you‚Äôre like a first-time Google user who blindly presses ‚ÄúI‚Äôm Feeling Lucky‚Äù all the time.</li><li>Questions exist in the physical world. When you write a question down, you can get back to it later and think about it again. If you do not write your thought down, it will fly away from your unstable working memory, and you may never get into the same situation that triggered that thought in the first place. As it‚Äôs tough to trace back the system one thinking [1], you‚Äôre way better off writing things down.</li><li>Questions are discovery satellites for new knowledge. The best thing about questions is that you can ask yourself something you do not yet know. When you write down a problem with no answer, you may revisit it later and add new information as you develop more understanding. More interesting and less obvious is that asking yourself questions for which you have no answers triggers curiosity and programs your subconscious to think about it in the background.</li><li>Questions convince yourself that your work is important. This may sound trivial at first, but I‚Äôve discovered that if I don‚Äôt have a decent argument why what I‚Äôm writing is important, I produce bad writing or get stuck in writer‚Äôs block. And it‚Äôs way easier to stay convinced that what you‚Äôre doing matters if you documented the reasons on paper ‚Äì you can get back to your questions and get inspired when things get tough.</li><li>Questions help you avoid obvious mistakes. In many professions, checklists are a must. If you‚Äôre a pilot or a surgeon, you spend years mastering simple procedures because you don‚Äôt have time to do system two thinking when you have a problem in the field. You need to have already thought. I believe writers benefit from checklists even more because writing is considered to be a creative act, and most creative tasks usually benefit from systemic approaches and vice versa.</li></ol><p>Below are the questions I routinely ask myself when I‚Äôm profiling an idea.</p><h2 id="1-why-do-i-want-to-write-this-article">1. Why do I want to write this article?</h2><p>When you answer that question, you will discover the <em>actual</em> problem that you want to solve with the piece. Often, the problem will be different from the original idea of the article. If you have experience with the topic, you‚Äôll likely see a better solution, a different angle of attack you can use to solve a reader‚Äôs problem.</p><p>For example, when I started <a href="https://vasilishynkarenka.com/learning/">my work on learning</a>, the original idea was to produce a theoretical piece describing the research that I‚Äôve done. But when I answered the first question, I realized that my work aims to help a reader improve their learning process, and the best way to do that would be to write a description of my own process and embed principles into it of preaching theories.</p><p>The answer will often contradict the initial idea that you‚Äôve come up with. That‚Äôs fine ‚Äì just update the idea. What you must avoid doing is continuing with the initial plan if you‚Äôve clearly discovered a better one after answering the question. Even if you already have the draft done, you must rewrite the whole thing because your job as a writer is to not waste reader‚Äôs time.</p><p>Here‚Äôs how I defined the ‚Äúwhy‚Äù for this work:</p><blockquote>Q: Why do I want to write this article?<br>A: I want to help people improve their writing process by adding a simple routine of asking questions.</blockquote><p>The ‚Äúwhy‚Äù question is also a test for abstractions. If you do not have a concise answer, you will find yourself attempting to write an all-covering piece. Avoid that mistake and define the purpose of the work first.</p><p>If you cannot answer the question, do not write this article.</p><h2 id="2-what-do-i-want-to-write-about">2. What do I want to write about?</h2><p>The answer to the question determines the subject of your article. The subject is what the article is about, the broader topic of the work [2]. For example:</p><ul><li>‚ÄúI wanna write about productivity.‚Äù</li><li>‚ÄúI want to write about learning.‚Äù</li><li>‚ÄúI want to write a post about habits.‚Äù</li></ul><p>Here‚Äôs my subject for this post:</p><blockquote>Q: What do I want to write about?<br>A: I want to write about the writing process.</blockquote><p>When you answer the second question, you will grasp the category of knowledge you‚Äôre dealing with and enrich your writing.</p><p>Categories are a form of abstraction that we use to deal with complexity. Imagine a fridge. What I just did is I put some mental image in your head. But the refrigerator that you see is not some specific fridge, like the one you have in the kitchen, although it might be close. The fridge‚Äôs image in your head is an abstract fridge that combines details of fridges you have seen in the past. That‚Äôs what a category is.</p><p>The most value of categories comes from enrichment. When you see a new, tall, metallic rectangular object with two sections and a handle, you can‚Äôt help but guess it‚Äôs a fridge, because its properties match with the properties of fridges you have seen before. But you not only deduce the category of the unknown object based on how its features compare with the category representation that you know. You also <em>enrich</em> the concrete object with the features you expect an item of this category to have. In the fridge that you imagined, you‚Äôd expect to have some shelves inside, maybe a pack of eggs, or a cold bottle of Guiness. Without knowing it for sure, you pre-suppose to find this stuff in a new fridge that you see because of enrichment.</p><figure><img src="https://vasilishynkarenka.com/content/images/2020/11/alexandru-acea-cVTC0gEOx8E-unsplash.jpg" alt="" srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/11/alexandru-acea-cVTC0gEOx8E-unsplash.jpg 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/11/alexandru-acea-cVTC0gEOx8E-unsplash.jpg 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/11/alexandru-acea-cVTC0gEOx8E-unsplash.jpg 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/11/alexandru-acea-cVTC0gEOx8E-unsplash.jpg 2400w" sizes="(min-width: 720px) 720px"><figcaption>Photo by <a href="https://unsplash.com/@alexacea?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Alexandru Acea</a> on <a href="https://unsplash.com/s/photos/fridge?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</figcaption></figure><p>Once you understand the category of your work, you will be able to pull different ideas from the category level to enrich your article and better serve the reader. For example, suppose you‚Äôre writing a piece on fitness habits. In that case, you may jump to the category level and understand that fitness is about fitness habits <em>and</em> nutrition, <em>and</em> sleep. You could also level up to the habits category and see if there‚Äôs anything to pull from there ‚Äì any similarities between building a habit of jogging and learning to play the piano? And if you have something to say on those things and it fits the context of your work, you can enrich your work.</p><p>The process of jumping between categories may sound complicated. I‚Äôd recommend taking a piece of paper and a pen to draw things when you‚Äôre getting started. The paper will make it easier to see the category literally ‚Äúabove‚Äù the object because of spatial cognition [3], and you will discover other objects from that category (i.e., nutrition, sleep) because of the white space effect when your mind fills in the missing details for you.</p><p>With experience, the process of jumping across categories of knowledge, and looking at a thing from different angles becomes automatic. It integrates into your perception so well that you don‚Äôt even notice it happening. Like a chess grandmaster, you just <em>know</em> a good move.</p><h2 id="3-what-do-i-want-to-say-about-the-subject">3. What do I want to say about the subject?</h2><p>The third question determines your theme. The theme is what you have to say about the subject you‚Äôre writing about. For example, here‚Äôs a subject-theme pair for this work:</p><p>Subject:</p><blockquote>Q: What do I want to write about? <br>A: I want to write about the writing process.</blockquote><p>Theme:</p><blockquote>Q: What do I want to say about the subject?<br>A: I want to convince my reader that asking yourself simple questions about an article helps a) flesh out the idea better and b) notice more ideas for writing. To make the process easier, one could use shortcuts and think of an article as a set of blocks rather than one big monolithic piece.</blockquote><p>The purpose of selecting your theme is to limit what you‚Äôre writing about and outline a course of work. As you may have noticed, there are many things one can say about the writing process. If I attempted to write a piece on the ‚Äúwriting process‚Äù as ‚Ä¶</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vasilishynkarenka.com/8questions/">https://vasilishynkarenka.com/8questions/</a></em></p>]]>
            </description>
            <link>https://vasilishynkarenka.com/8questions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25050838</guid>
            <pubDate>Tue, 10 Nov 2020 19:50:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Draft Array API Standard Released for Public Comment]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25050558">thread link</a>) | @travisoliphant
<br/>
November 10, 2020 | https://data-apis.org/blog/array_api_standard_release/ | <a href="https://web.archive.org/web/*/https://data-apis.org/blog/array_api_standard_release/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post" itemprop="articleBody">
    
    <p>Array and tensor libraries - from NumPy, TensorFlow and PyTorch to Dask, JAX,
MXNet and beyond - could benefit greatly from a uniform API for creating and
working with multi-dimensional arrays (a.k.a tensors), as we discussed in
<a href="https://data-apis.org/blog/announcing_the_consortium/">our previous blog post</a>.
Today we‚Äôre pleased to announce a first version of our array API standard
(<a href="https://data-apis.github.io/array-api/latest">document</a>,
<a href="https://github.com/data-apis/array-api/">repo</a>) for review by the
wider community. Getting to this point took slightly longer than we had
initially announced because, well, it‚Äôs 2020 and hence nothing quite goes
according to plan.</p>
<p>The current status of the standard is that it is a coherent story (or at
least, we hope it is) that gives readers enough context about goals and scope
to understand and review the design decisions already taken and APIs it
contains. However, <em>it is not yet complete and we can still change direction
and make significant changes based on community feedback</em>. This is important
‚Äî no one likes a ‚Äútake it or leave it‚Äù approach, and more eyes can make the
final result better. There‚Äôs still a few TODOs in places, and a couple of key
sections to be finished. The most important of those are the API for device
support, and the Python API for the
<a href="https://data-apis.github.io/array-api/latest/design_topics/data_interchange.html">data interchange protocol</a>
(proposed to be based on <a href="https://github.com/dmlc/dlpack">DLPack</a>).</p>
<p>It is worth repeating the main goal of this standard: make it easier to
switch from one array library to another one, or to support multiple array
libraries as compute backends in downstream packages. We‚Äôd also like to
emphasize that if some functionality is <em>not</em> present in the API standard,
that does <em>not</em> mean it‚Äôs unimportant, or that we‚Äôre asking existing array
libraries to deprecate it. Instead it simply means that that functionality at
present isn‚Äôt supported - likely due to it not being present in all or most
current array libraries, or not being used widely enough to have been
included so far. The <a href="https://data-apis.github.io/array-api/latest/use_cases.html">use cases section</a>
of the standard may provide more insight into important goals.</p>
<h2 id="some-key-design-topics">Some key design topics</h2>
<p>Two topics stood out so far in terms of complexity and choices that were hard
to make in such a way that they‚Äôd work well for all existing libraries:
mutability &amp; copy/view behaviour, and dtype casting rules.</p>
<h5 id="the-standard-will-contain-common-mutable-operations-such-as-slice-assignment-but-will-generally-avoid-in-place-mutation-in-apis-like-the-out-keyword">The standard will contain common mutable operations such as slice assignment, but will generally avoid in-place mutation in APIs like the <code>out</code> keyword</h5>
<p>NumPy, PyTorch, CuPy and MXNet provide strided arrays, and rely heavily on
mutating values in existing arrays and on the concept of a ‚Äúview‚Äù for
performance. TensorFlow, JAX and Dask on the other hand have no or limited
support, given that they rely on an execution graph and/or JIT compiler which
provides constraints on how much mutability can be supported. The design
decisions described <a href="https://data-apis.github.io/array-api/latest/design_topics/copies_views_and_mutation.html">here</a>
will allow the most heavily used types of mutability - inplace operators,
item assignment and slice assignment - to be retained, while avoiding the use
of the <code>out=</code> keyword which is problematic to support for some libraries and
arguably a suboptimal API to begin with.</p>
<p>For libraries like SciPy and scikit-learn, the supported features are essential.
Code like this, from scikit-learn‚Äôs <code>ForestClassifier</code>:</p>
<div><pre><code data-lang="python"><span>for</span> <span>k</span> <span>in</span> <span>range</span><span>(</span><span>self</span><span>.</span><span>n_outputs_</span><span>):</span>
    <span>predictions</span><span>[</span><span>k</span><span>][</span><span>unsampled_indices</span><span>,</span> <span>:]</span> <span>+=</span> <span>p_estimator</span><span>[</span><span>k</span><span>]</span>
</code></pre></div><p>or this, from SciPy‚Äôs <code>optimize.linprog</code>:</p>
<div><pre><code data-lang="python"><span>r</span> <span>=</span> <span>b</span> <span>-</span> <span>A</span><span>@x</span>
<span>A</span><span>[</span><span>r</span> <span>&lt;</span> <span>0</span><span>]</span> <span>=</span> <span>-</span><span>A</span><span>[</span><span>r</span> <span>&lt;</span> <span>0</span><span>]</span>
<span>b</span><span>[</span><span>r</span> <span>&lt;</span> <span>0</span><span>]</span> <span>=</span> <span>-</span><span>b</span><span>[</span><span>r</span> <span>&lt;</span> <span>0</span><span>]</span>
<span>r</span><span>[</span><span>r</span> <span>&lt;</span> <span>0</span><span>]</span> <span>*=</span> <span>-</span><span>1</span>
</code></pre></div><p>is quite common and we see it as fundamental to how users work with array libraries.
<code>out=</code> is less essential though, and leaving it out is important for JAX,
TensorFlow, Dask, and future libraries designed on immutable data structures.</p>
<h5 id="casting-rules-for-mixed-type-families-will-not-be-specified-and-are-implementation-specific">Casting rules for mixed type families will not be specified and are implementation specific</h5>
<p>Casting rules are relatively straightforward when all involved dtypes are of
the same kind (e.g. all integer), but when mixing for example integers and
floats it quickly becomes clear that array libraries don‚Äôt agree with each
other. One may get exceptions, or dtypes with different precision. Therefore
we had to make the choice to leave the rules for ‚Äúmixed kind dtype casting‚Äù
undefined - when users want to write portable code, they should avoid this
situation or use explicit casts to obtain the same results from different
array libraries. An example as simple as this one:</p>
<div><pre><code data-lang="python"><span>x</span> <span>=</span> <span>np</span><span>.</span><span>arange</span><span>(</span><span>5</span><span>)</span>  <span># will be integer</span>
<span>y</span> <span>=</span> <span>np</span><span>.</span><span>ones</span><span>(</span><span>5</span><span>,</span> <span>dtype</span><span>=</span><span>float16</span><span>)</span>
<span>(</span><span>x</span> <span>*</span> <span>y</span><span>)</span><span>.</span><span>dtype</span>
</code></pre></div><p>will show the issue. NumPy will produce <code>float64</code> here, PyTorch will produce
<code>float16</code>, and TensorFlow will raise <code>InvalidArgumentError</code> because it does not
support mixing integer and float dtypes.</p>
<p>See <a href="https://data-apis.github.io/array-api/latest/API_specification/type_promotion.html">this section of the standard</a>
for more details on casting rules.</p>
<h2 id="a-portable-test-suite">A portable test suite</h2>
<p>With the array API standard document we are also working on a
<a href="https://github.com/data-apis/array-api-tests">test suite</a>. This test suite
will be implemented with Pytest and Hypothesis, and won‚Äôt rely on any
particular array implementation, and is meant to test compliance with the API
standard.</p>
<p>It is still very much a work-in-progress, but the aim is to complete it by
the time the community review of the API standard wraps up. However, the
community is encouraged to check out the current work on the test suite on
<a href="https://github.com/data-apis/array-api-tests">GitHub</a> and try it out and
comment on it. The
<a href="https://github.com/data-apis/array-api-tests/blob/master/README.md">README</a>
in the test suite repo contains more information on how to run it and
contribute to it.</p>
<p>The test suite will be runnable with any existing library. This can be done
by specifying the array implementation namespace to be tested via an
environment variable:</p>
<div><pre><code data-lang="bash">$ <span>ARRAY_API_TESTS_MODULE</span><span>=</span>jax.numpy pytest
</code></pre></div><p>The test suite will also support vendoring so that array libraries can easily
include it in their own test suites.</p>
<p>The result of running the test suite will be an overview of the level of
compliance with the standard. We expect it will take time for libraries to
get to 100%; anything less shouldn‚Äôt just mean ‚Äúfail‚Äù, 98% would be a major
step towards portable code compared to today.</p>
<h2 id="people--projects">People &amp; projects</h2>
<p>So who was involved in getting the API standard to this point, and which
libraries do we hope will adopt this standard? The answer to the latter is
‚Äúall existing and new array and tensor libraries with a Python API‚Äù. As for
who was involved, we were lucky to get contributions from creators and senior
maintainers of almost every project of interest - here‚Äôs a brief description:</p>
<ul>
<li>NumPy: Stephan Hoyer and Ralf Gommers are both long-time NumPy maintainers.
In addition we got to consult regularly with Travis Oliphant, creator of
NumPy, on the history behind some decisions made early on in NumPy‚Äôs life.</li>
<li>TensorFlow: Alexandre Passos was a technical lead on the TensorFlow team,
and has been heavily involved until a few weeks ago. Paige Bailey is the
product manager for TensorFlow APIs at Google Research. Edward Loper and
Ashish Agarwal, TensorFlow maintainers, replaced Alexandre recently as
Consortium members.</li>
<li>PyTorch: Adam Paszke is one of the co-creators of PyTorch. Ralf Gommers
leads a team of engineers contributing to PyTorch.</li>
<li>MXNet: Sheng Zha is a long-time MXNet maintainer. Markus Weimer is an
Apache PMC member and mentor for the MXNet incubation process into the
Apache Foundation.</li>
<li>JAX: Stephan Hoyer and Adam Paszke are two maintainers of JAX.</li>
<li>XArray: Stephan Hoyer is one of the co-creators, and still a maintainer, of Xarray.</li>
<li>Dask: Tom Augspurger is a senior Dask maintainer.</li>
<li>CuPy: we have no active participant from CuPy. However we have talked to
the CuPy team at Preferred Networks, who are supportive of the goals and
committed to following NumPy‚Äôs lead on APIs.</li>
<li>ONNX: Sheng Zha is an ONNX Steering Committee member.</li>
</ul>
<p>Many other people have made contributions so far, including the Consortium
members listed at <a href="https://github.com/data-apis/governance">https://github.com/data-apis/governance</a>.</p>
<h2 id="next-steps-to-a-first-complete-standard">Next steps to a first complete standard</h2>
<p>We are now looking for feedback from the wider community, and in particular
maintainers of array libraries. For each of those libraries, a Consortium
member involved in the library will be soliciting feedback from their own
project. We‚Äôd like to get to the point where it‚Äôs clear for each library that
there are no blockers to adoption and that the overall shape of the API
standard is considered valuable enough to support.</p>
<p>In addition, given that this API standard is completely new and drafting
something like it hasn‚Äôt been attempted before in this community, we‚Äôd love
to get meta feedback - is anything missing or in need of shaping in the
standard document, the goal and scope, ways to participate, or any other such
topic?</p>
<p>To provide feedback on the array API standard, please open issues or pull
requests on <a href="https://github.com/data-apis/array-api">https://github.com/data-apis/array-api</a>. For larger discussions
and meta-feedback, please open GitHub Discussion topics at
<a href="https://github.com/data-apis/consortium-feedback/discussions">https://github.com/data-apis/consortium-feedback/discussions</a>.</p>


</div></div>]]>
            </description>
            <link>https://data-apis.org/blog/array_api_standard_release/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25050558</guid>
            <pubDate>Tue, 10 Nov 2020 19:33:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons Learned Building an Open Source MLOps Platform]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25050500">thread link</a>) | @calebkaiser
<br/>
November 10, 2020 | https://www.cortex.dev/post/building-an-open-source-mlops-platform | <a href="https://web.archive.org/web/*/https://www.cortex.dev/post/building-an-open-source-mlops-platform">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div content-type="article"><p>For the last two years, we‚Äôve been working on Cortex, our open source machine learning deployment platform. Over that time, we‚Äôve been really fortunate to see it grow into what it is today, used in production by teams around the world, and supported by a fantastic community of contributors.</p><p>We‚Äôve also had to change our thinking several times along the way. The understanding of the ML ecosystem we had at the beginning has not always turned out to be accurate, and this is reflected in various changes we‚Äôve made to Cortex.</p><p>As interest in MLOps continues to increase, I thought it would be useful (for our sakes as much as anyone else‚Äôs) to document a few of the key lessons we‚Äôve learned that‚Äôve come to shape Cortex.</p><p>If you‚Äôre working on a production machine learning system, building machine learning infrastructure, or designing your own MLOps tool, hopefully the following lessons (listed in no particular order) are useful for you.</p><h3>1. Production machine learning runs in the cloud</h3><p>When Cortex was still in its idea stage, one of our most frequent discussions was whether or not it should support on-premise deployments. At the time, the worry was that a large portion of the machine learning ecosystem was going to remain on-premise indefinitely due to privacy and cost.</p><p>These worries were enflamed when we initially released Cortex. While we had some excited users, we also had plenty of people writing in requesting on-prem support. We worried that by going all-in on the public clouds, we‚Äôd cut off most of the machine learning ecosystem.</p><p>Over the last two years, things have changed. Production machine learning is almost entirely moving to the cloud, and there are a couple reasons why.</p><p>The first is the standard reason for moving to the cloud: scalability. As production machine learning systems become more powerful and responsible for more features, their workloads increase. If you need to autoscale to dozens of GPUs during peak hours, the cloud has obvious advantages.</p><p>The second is the investment by the major clouds into ML-specific offerings. Major clouds now offer both dedicated software and hardware for machine learning. For example, Google and AWS both offer ASICs (TPUs and Inferentia, respectively) that substantially improve machine learning performance, and both are only available on their respective clouds.</p><p>More and more, the cloud is becoming the only realistic way to deploy production machine learning systems.</p><h3>2. It‚Äôs too early for end-to-end MLOps tools</h3><p>Another misguided belief we held in Cortex‚Äôs early days was that Cortex needed to be an all-inclusive, end-to-end MLOps platform that automated your pipeline from raw data to deployed model.</p><figure id="w-node-a47abffb7609-258b12d0"><p><img src="https://uploads-ssl.webflow.com/5f6030edfd63364a668b1265/5fa9ad5cb4b8083a07ddc765_0*6z89yrFEvqkVBqIg.jpeg" alt=""></p></figure><p>We‚Äôve written a full <a href="https://towardsdatascience.com/we-tried-to-build-an-end-to-end-ml-platform-heres-why-it-failed-190c0f503536" target="_blank">breakdown of why that was the wrong decision,</a> but the short version is that it‚Äôs still way too early in the lifespan of MLOps to build that sort of platform.</p><p>Every page of the production machine learning playbook is constantly being rewritten. For example, in the last several years:</p><ul role="list"><li><strong>Our notion of ‚Äúbig‚Äù models has exploded.</strong> We thought models with hundreds of millions of parameters were flirting with boundaries of being ‚Äútoo large‚Äù to deploy. Then Transformer models like GPT-2 started weighing in the billions‚Äîand people still built applications out of them.</li><li><strong>The ways we train models have changed. </strong>Transfer learning, neural architecture search, knowledge distillation‚Äîwe have more techniques and tools than ever to design, train, and optimize models efficiently.</li><li><strong>The machine learning toolbox has grown rapidly</strong>. PyTorch was only released in 2016, shortly after TF Serving‚Äôs initial public release. ONNX came out in 2017. The frameworks, languages, and features that an end-to-end MLOps platform would need to support changes endlessly.</li></ul><p>We ran into all of these problems with our first release of Cortex. We provided a seamless experience‚Äî<em>if</em> <em>you used the narrow stack we supported.</em> Because everything (including language, pipeline, frameworks, and even team structure) can vary so wildly across ML orgs, we were almost always ‚Äúone feature away‚Äù from fitting any given team‚Äôs stack.</p><p>As a modular platform, focused on one discrete part of the machine learning lifecycle‚Äîdeployment‚Äîwithout opinions about the rest of the stack, Cortex has been adopted by many more teams at a much faster pace. We‚Äôve seen rapid growth in other MLOps tools with similar ‚Äúbest of breed‚Äù approaches at different parts of the stack, including <a href="https://dvc.org/" target="_blank">DVC (Data Version Control) </a>and <a href="https://www.comet.ml/site/" target="_blank">Comet</a>.</p><h3>3. Data science, ML engineering, and ML infrastructure are all different‚Ää‚Äî‚Ääin theory</h3><p>With Cortex, we use the following high-level model of an ML function and its constituent parts:</p><ul role="list"><li><strong>Data science</strong>. Concerned with the development of models, from exploring the data to conducting experiments to training and optimizing models.</li><li><strong>Machine learning engineering</strong>. Concerned with the deployment of models, from productionizing models to writing inference services to designing inference pipelines.</li><li><strong>Machine learning infrastructure</strong>. Concerned with the design and management of the ML platform, from resource allocation to cluster management to performance monitoring.</li></ul><p>And in theory, these are nicely delineated functions with clear handoff points. Data science creates models which are turned into inference pipelines by ML engineering and deployed to a platform maintained by ML infrastructure.</p><p>But, this is an overview of the theoretical functions in an ML org, not the <em>actual roles</em> people hold. Oftentimes, a data scientist will also do ML engineering work, or an ML engineer will be tasked with managing an inference cluster.</p><p>Building a tool for these different use-cases gets complex, as the optimal ergonomics of an interface for one role can vary drastically from another.</p><p>For example, <a href="https://towardsdatascience.com/why-we-do-machine-learning-engineering-with-yaml-not-notebooks-a2a97f5e04f8" target="_blank">for reasons we‚Äôve explained before</a>, Cortex APIs are written as Python scripts with YAML manifests, not notebooks, and are deployed via a CLI. </p><p>For MLEs, this is comfortable. For data scientists, however, it is often uncomfortable, as YAML and CLIs aren‚Äôt common tools in their ecosystem. Because of this, we needed to build a Python client for defining deployments in pure Python in order for some teams to use Cortex successfully.</p><p>Now, people who are more comfortable with CLIs can deploy like this:</p><figure id="w-node-b878c71bee4b-258b12d0"><p><img src="https://uploads-ssl.webflow.com/5f6030edfd63364a668b1265/5fa9ad5c272d5ce9d4c2dd28_0*yV51u9hxfGDvxtF3.png" alt=""></p></figure><p>And people more comfortable with pure Python can do this:</p><figure id="w-node-5864f8b2c1a4-258b12d0"><p><img src="https://uploads-ssl.webflow.com/5f6030edfd63364a668b1265/5fa9ad5c09e66f37c2c56cdf_1*1CO_-hPGhV9qNuH4c3Jxuw.png" alt=""></p></figure><p>The takeaway here is that if you‚Äôre building MLOps tooling, remember everyone who will be using it in practice, not just in theory.</p><h3>4. ML native companies have different needs</h3><p>Several years ago, the most common examples of production machine learning were popular products optimized by trained models. Payment processors would sprinkle in fraud detection models, streaming platforms would boost their engagement with recommendation engines, etc.</p><p>Now, however, there is a new wave of companies whose products aren‚Äôt enhanced by models‚Äîthey <em>are</em> models.</p><p>These companies, which we refer to as ML native, operate in different ways. Some sell access to an inference pipeline as an API, as in the case of <a href="https://www.glisten.ai/" target="_blank">Glisten</a>, whose API allows retailers to tag and categorize products instantly:</p><figure id="w-node-dc634e21281f-258b12d0"><p><img src="https://uploads-ssl.webflow.com/5f6030edfd63364a668b1265/5fa47e5ab8c60a850d3f4032_0*mw_tAL1CeDD1Q8e3.png" alt=""></p></figure><p>Others build applications whose core functionality is provided by a trained model. For example, <a href="https://postera.ai/" target="_blank">PostEra‚Äôs</a> medicinal chemistry platform uses models to predict the most likely chemical reactions for creating a specific drug, and <a href="https://play.aidungeon.io/main/home" target="_blank">AI Dungeon</a> uses a trained language model to create an endless choose-your-own-adventure:</p><p>These ML native applications have different infrastructure needs. For one, they typically rely on realtime inference, meaning their models need to be deployed and available at all times.</p><p>Ensuring this availability can get very expensive. <a href="https://medium.com/@aidungeon/how-we-scaled-ai-dungeon-2-to-support-over-1-000-000-users-d207d5623de9" target="_blank">AI Dungeon uses a 6 GB model</a> that can only handle a few concurrent requests and requires GPUs for inference. To scale to even a few thousand concurrent users, they need many large GPU instances running at once‚Äîsomething that is costly to sustain for long periods.</p><p>When we first built Cortex, we hadn‚Äôt worked with many ML native teams. After working with them, we wound up prioritizing a new set of features, many of which were at least in part aimed at helping control inference costs:</p><ul role="list"><li>Request-based autoscaling to optimally scale each model for spend</li><li>Spot instance support to allow for cheaper base instance prices</li><li>Multi-model caching, live reloading, and multi-model endpoints to increase efficiency</li><li>Inferentia support for more cost-effective and performant instance types</li></ul><p>As the number of ML native companies continues to rise quickly, MLOps tools and platforms are going to have to build for their needs.</p><h3>5. MLOps is production machine learning‚Äôs biggest bottleneck</h3><p>This is one of the few things we believed before building Cortex that we still find to be true today. It is the feasibility of building and deploying a production machine learning system prevents teams from using ML. </p><p>Training and retraining models is not cheap. Deploying models to production isn‚Äôt cheap either. Building a platform to support those deployments is a full-scale infrastructure project, one that has to be maintained moving forward.</p><p>These costs make machine learning unapproachable for most companies. and the frustrating part is that they aren‚Äôt intrinsic qualities of machine learning. We can solve them with better infrastructure‚Äîno ML research breakthroughs needed.</p><p>As the MLOps ecosystem matures, new tools will continue to abstract away these parts of infrastructure and nullify the costs that prohibit teams from using ML in production. If you want to accelerate the proliferation of machine learning, consider contributing to any of the many open source MLOps projects‚Äî<a href="https://github.com/cortexlabs/cortex" target="_blank">like this one</a>.</p><p>‚Äç</p></div></div>]]>
            </description>
            <link>https://www.cortex.dev/post/building-an-open-source-mlops-platform</link>
            <guid isPermaLink="false">hacker-news-small-sites-25050500</guid>
            <pubDate>Tue, 10 Nov 2020 19:30:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Benefits of Being a Stoic]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25050456">thread link</a>) | @davefreiburger
<br/>
November 10, 2020 | https://gradually.co/the-benefits-of-being-a-stoic/ | <a href="https://web.archive.org/web/*/https://gradually.co/the-benefits-of-being-a-stoic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			<article id="post-893">
				<!-- <a href="https://gradually.co/the-benefits-of-being-a-stoic/">-->
					<div>
						<div>
	              			<!-- category colored coded display and hide takeaways php -->
	              																			<p>								Wisdom								</p><!-- end cat-wrap -->
						<p><span>&nbsp; ‚Ä¢&nbsp; </span>
						<span>Benefits of Being a Stoic</span>
						<span> &nbsp;‚Ä¢&nbsp; </span>
						<span>
							November 10, 2020						</span>

						<img width="640" height="340" src="https://gradually.co/wp-content/uploads/2020/11/GD24-Wisdom.gif" alt="" loading="lazy"></p><div>

																					<div>
								<p><a href="https://linkmix.co/1611480" target="_blank">
									[Image source: Eric Gerlach/Giphy]								</a></p><h5>
									<a href="http://nautil.us/issue/92/frontiers/the-joys-of-being-a-stoic" target="_blank">
										The Joys of Being a Stoic									</a>
									 &nbsp;by Massimo Pigliucci									<br>
								</h5>
								
								<p>
									Takeaways
								</p>
								<div>
									<ul>
<li><span>‚ÄúIf there is nothing you can do about a particular situation, why beat yourself up about it?‚Äù ‚Äî Massimo Pigliucci</span></li>
<li><span>Stoicism shouldn‚Äôt be about suppressing your emotions. Moreso, Stoicism is about adjusting your unhealthy emotions (anger) to a more mindful embrace of healthier ones (joy).&nbsp;</span></li>
<li><span>Stoicism receives a great deal of pushback regarding the negative effects of not acknowledging pain and the silent endurance and lack of emotion.&nbsp;</span></li>
<li><span>Massimo quotes Epictetus (Greek Philosopher), ‚ÄúSome things are within our power, while others are not. Within our power are opinion, motivation, desire, aversion, and, in a word, whatever is of our own doing; not within our power are our body, our property, reputation, office, and, in a word, whatever is not of our own doing.‚Äù&nbsp;</span></li>
<li><span>Massimo adds, ‚Äú‚Ä¶the idea is to internalize our goals: Instead of focusing, as it comes natural, on outcomes, let‚Äôs pay attention to our intentions and efforts. The Stoics think that the only truly good thing for us is our own character, and that therefore the only truly bad things are whatever may undermine our character. Everything else (including health, wealth, reputation, etc.) has value, but does not define who we are.‚Äù</span></li>
<li><span>The four virtues:</span></li>
</ul>
<ol>
<li>
<ol>
<li><i><span>Practical wisdom</span></i><span> ‚Äî the knowledge of what is truly good or bad for me. Will this undermine my character or not?&nbsp;</span></li>
<li><i><span>Courage</span></i><span> ‚Äî doing something that frightens us.</span></li>
<li><i><span>Justice</span></i><span> ‚Äî as treating other people, like my coworker, fairly and with respect.</span></li>
<li><i><span>Temperance</span></i><span> ‚Äî we should do things in the right measure, neither too much nor too little.&nbsp;</span></li>
</ol>
</li>
</ol>
<ul>
<li><span>‚ÄúApply the dichotomy of control and the four virtues to everything you do and, as Epictetus promises, you will never be unhappy. You will be free, and you will live a life truly worth living.‚Äù ‚Äî Massimo Pigliucci</span></li>
</ul>
								</div>
								<p><img src="https://gradually.co/wp-content/themes/gradually/img/two-cents.png">
								</p><!-- end half sqaure arrow -->
								<p><span>Massimo mentions that the four virtues help us form a sort of moral compass. Allowing people to navigate the world and weather the storm of whatever that‚Äôs thrown at us. Moral compass or not, Stoicism or not, knowing your own virtues that help you navigate the world seems like an exercise worth doing. </span></p>
								<p>
								<span>Share</span> (if you're an OG)  &nbsp;  <span></span><span><span>
									</span><span>


							</span></span></p></div><!-- end newsletter wrap content -->
													
						</div><!-- end newsletter wrap content -->
					</div><!-- end newsletter wrap -->
				<!-- </a>-->
			</div></article><!-- #post-## -->
		</div></div>]]>
            </description>
            <link>https://gradually.co/the-benefits-of-being-a-stoic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25050456</guid>
            <pubDate>Tue, 10 Nov 2020 19:27:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Note to a Newly Liquid Entrepreneur]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25050332">thread link</a>) | @lconstable
<br/>
November 10, 2020 | https://lembascapital.com/library/note-to-a-newly-liquid-entrepreneur/ | <a href="https://web.archive.org/web/*/https://lembascapital.com/library/note-to-a-newly-liquid-entrepreneur/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Congratulations!</p><p>Whether your company has IPO‚Äôd, was acquired, or just gave you the chance to take some money off the table, you are now well off. You‚Äôre about to receive a lot of advice about how to do things correctly ‚Äì how to balance risk, how to earn exciting returns, how your friend‚Äôs startup is the next Facebook, etc.</p><p>I‚Äôm going to talk with you about how investments can go wrong.</p><p>I‚Äôve seen many situations where an entrepreneur makes money the hard way, brick by brick, and then loses it in a flash due to a bad investment decision or, worse, a scam. Just as bad as the money lost are the emotions that come with it ‚Äì embarrassment, shame, and a loss of trust that may keep you from working on your next project. Let‚Äôs take a few minutes to save you from years of anguish and millions of dollars lost.</p><p>Here are five lines of questioning that will help you avoid the worst mistakes:</p><p>1) Alignment ‚Äì <em>Is the manager invested alongside you? How is the manager compensated?</em></p><p>2) Strategy ‚Äì <em>Can you articulate why the investment strategy will work? How does it bring new information into the market?</em></p><p>3) Risk ‚Äì <em>What would cause your investment to fail? Is the manager intellectually honest about the risks and working to mitigate those downside scenarios?</em></p><p>4) Fraud ‚Äì <em>How can you tell if they‚Äôre a fraud? Are they offering Special Access or Risk-Free Returns?</em></p><p>5) Trust ‚Äì <em>Do you trust your manager?</em></p><h2>Alignment</h2><p><em>Is the manager invested alongside you? How is the manager compensated?</em></p><p>Finance is an odd business. It‚Äôs just like manufacturing, except every few years the manufacturers accidentally blow up the factory. Your goal should be to avoid getting caught in the blast. The reason this keeps happening is that people are driven by misaligned incentives.</p><p>There are three main incentive structures in finance: transactional (commission on initial sale), management (% of assets under management), and outcome (% of profits). Every financial institution has an ongoing internal struggle between these factions. When the transactional group wins out, the institution may focus too much on trading commissions and not enough on good investments. That‚Äôs when you get the potential for a spectacular blowup.</p><p>You can mitigate these misaligned incentives by having the manager invest alongside you.</p><p><strong>Incentive Structures in Finance</strong></p><figure><img width="936" height="390" src="https://lembascapital.com/library/wp-content/uploads/2020/10/Incentive-structures-in-finance-1.png" alt="" srcset="https://lembascapital.com/library/wp-content/uploads/2020/10/Incentive-structures-in-finance-1.png 936w, https://lembascapital.com/library/wp-content/uploads/2020/10/Incentive-structures-in-finance-1-300x125.png 300w, https://lembascapital.com/library/wp-content/uploads/2020/10/Incentive-structures-in-finance-1-768x320.png 768w" sizes="(max-width: 936px) 100vw, 936px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://lembascapital.com/library/wp-content/uploads/2020/10/Incentive-structures-in-finance-1.png" data-srcset="https://lembascapital.com/library/wp-content/uploads/2020/10/Incentive-structures-in-finance-1.png 936w, https://lembascapital.com/library/wp-content/uploads/2020/10/Incentive-structures-in-finance-1-300x125.png 300w, https://lembascapital.com/library/wp-content/uploads/2020/10/Incentive-structures-in-finance-1-768x320.png 768w"><figcaption><em>Source: </em>Lembas Capital</figcaption></figure><p>There is no silver bullet, and a GP co-investment with the LP does not prevent an aggressive strategy from failing (see LTCM). Still, if your manager is willing to sell you a product but isn‚Äôt willing to personally invest the same way, you should think very carefully about investing. Even if the manager has different financial goals or if there is a good reason why the manager can‚Äôt co-invest in the same fund, you may learn a great deal by asking why.</p><h2>Strategy</h2><p><em>Can you articulate why the investment strategy will work? How does it bring new information into the market?</em></p><p>As I wrote in&nbsp;<a href="https://lembascapital.com/credo" target="_blank" rel="noreferrer noopener">Lembas‚Äôs credo</a>, capital markets are information markets. I believe an asset‚Äôs price is comprised of (1) an asset‚Äôs cash flows and (2) the capital flows of other investors in and out of that asset. Successful investors bring new information to the market about an asset‚Äôs cash flows or capital flows. That‚Äôs what people mean when they say they are looking for investors with an edge.</p><p>Your advisor should be able to articulate why they think their strategy has worked in the past and why it should keep working in the future. How are they sourcing new information? You should be able to understand it sufficiently such that it‚Äôs not a black box to you. Or, if it is a black box and you still want to make the investment, just recognize what you‚Äôre doing and then size your investment appropriately.</p><h2>Risk</h2><p><em>What would cause your investment to fail? Is the manager intellectually honest about the risks and working to mitigate those downside scenarios?</em></p><p>There are many facets to risk management, but, simply put, a prudent investor tries to anticipate future risks and to stay resilient in the face of unforeseen catastrophes.</p><p>Understand what would cause the investment to collapse. As a basic heuristic, the main risks for long-term strategies are thesis (did they properly analyze the cash flows and capital flows?) and structure (can they get forced to sell too soon, even if they are right about the long-term thesis?). In contrast, the main risk for short-term strategies tends to be operational (what is their current speed and/or research edge, and why will that continue to hold 3+ years down the line?).</p><p>Your advisor should be forthright about these risks ‚Äì both for your sake and as a signal that they are vigilant in their own risk management. Part of being forthright is using an accurate measuring stick. An intellectually honest advisor won‚Äôt play games with portfolio marks that mask the underlying risk (e.g. make sure that no one convinces you that illiquid assets are less volatile just because there aren‚Äôt publicly available mark-to-market prices).</p><h2>Frauds</h2><p><em>How can you tell if they‚Äôre a fraud? Are they offering Special Access or Risk-Free Returns?</em></p><p>I‚Äôve seen frauds come in two main flavors: Special Access and Risk-Free Returns.</p><p>Special Access fraudsters claim that&nbsp;<em>only they</em>&nbsp;can get you into the best private deals. They tend to prey on people who don‚Äôt live in the region or don‚Äôt work in the industry where those opportunities originate (e.g. selling Chinese monopoly stories to South Americans or selling Silicon Valley stories to Europeans). The best private investors often do have access advantages, the difference being that those are legitimate. You can sort one from the other by doing reference checks and by looking to see if other smart people in the ecosystem are also investing. For instance, virtually none of the top SF investors were taken into Theranos or Nikola.</p><p>The Risk-Free Returns fraud is more insidious. It‚Äôs so hard to earn that initial capital that you will naturally be protective of it. Every wealth manager will tell you to keep a portion of your wealth in low-risk, low-return investments. Someone may approach you to tell you about a way to earn a little bit of a higher return with no added risk, month in and month out. It sounds too good to be true. It often is.</p><p>The soft version of the Risk-Free Returns fraud is a misrepresentation of an investment strategy. Many funds generate returns by selling insurance (aka short volatility). They collect premiums every month like clockwork. There‚Äôs nothing wrong with the insurance business, so long as you are amply compensated for the risk you are insuring. The problem is that, someday, the bill will come due. You shouldn‚Äôt evaluate that kind of fund without recognizing what kind of major risk is being insured and what the true downside scenario entails.</p><p>The hard version of the Risk-Free Returns fraud is simply made-up returns. Bernie Madoff is the prime example here. Many Jewish charities in the New York and Palm Beach communities were ruined by the promise of steady, low-risk returns that were just a bit better than the standard low-risk low-return options.</p><p>To give you a taste of what to watch out for, here‚Äôs a snapshot of how Madoff presented his Sentry fund to his clients. You can easily imagine how he sold the story ‚Äî <em>do a bit better than the market with none of the downside</em>, <em>long track record of steady returns</em>, <em>lets you sleep soundly</em>.</p><p><strong>Bernie Madoff‚Äôs ‚ÄúRisk-Free Returns‚Äù</strong></p><figure><img width="936" height="442" src="https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-graph-1.png" alt="" srcset="https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-graph-1.png 936w, https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-graph-1-300x142.png 300w, https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-graph-1-768x363.png 768w" sizes="(max-width: 936px) 100vw, 936px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-graph-1.png" data-srcset="https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-graph-1.png 936w, https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-graph-1-300x142.png 300w, https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-graph-1-768x363.png 768w"></figure><figure><img width="936" height="542" src="https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-table-1.png" alt="" srcset="https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-table-1.png 936w, https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-table-1-300x174.png 300w, https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-table-1-768x445.png 768w" sizes="(max-width: 936px) 100vw, 936px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-table-1.png" data-srcset="https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-table-1.png 936w, https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-table-1-300x174.png 300w, https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-table-1-768x445.png 768w"><figcaption><em>Source:</em> Bernie Madoff‚Äôs Sentry Fund</figcaption></figure><p>Unfortunately, even the most prestigious private banks have little to offer but an apology when you invest in a fraud through them. This is&nbsp;<a href="https://www.dropbox.com/s/ffovoxxuyi0bdfx/2008-12%20Union%20Bancaire%20Privee%20-%20%20Investing%20with%20Madoff.pdf?dl=0" target="_blank" rel="noreferrer noopener">Union Bancaire Priv√©e‚Äôs statement</a>&nbsp;to their clients after Madoff was uncovered. The good news is that an experienced fund manager could have spotted the problem immediately (as many did).</p><p>If you‚Äôre approached with any special access, structured product, or volatility selling strategy, make sure that you understand the true risk profile or that you speak with someone who does. Many of those structures are fine, but the dangerous ones are the ones that blow up the factory.</p><h2>Trust</h2><p><em>Do you trust your manager?</em></p><p>All of this comes down to trust.</p><p>The best advisors will want to build a lifelong relationship with you. They‚Äôll strive to earn your trust, and they‚Äôll be figuring out how much they can trust you too. Outcome-driven investors look for clients who will back them to deploy capital during market downturns, just at the exact moment when others are uncomfortable doing so too. Great clients really do help investors earn great returns.</p><p>I don‚Äôt think there‚Äôs any trick I can tell you about assessing who you can trust. I‚Äôm sure you‚Äôve had to figure this out in your own business, and I don‚Äôt think it will be any different here.</p><h2>What‚Äôs Next?</h2><p>It‚Äôs always exciting to see a project come to fruition, and it‚Äôs just as exciting to start the next one. I hope you can build on your success as a source of strength, not as a burden to be carried.</p><p>Wealth ownership can be a significant life transition. There are libraries of material to read. If you wanted to narrow it down to two selections, I would recommend&nbsp;<a href="https://www.amazon.com/Destructive-Power-Family-Wealth-Succession/dp/1119327520" target="_blank" rel="noreferrer noopener">The Destructive Power of Family Wealth</a>&nbsp;by Philip Marcovici (a book on wealth planning by the former chair of Baker McKenzie‚Äôs wealth management and tax practices) and&nbsp;<a href="https://grahamduncan.blog/letter-to-a-friend-who-just-made-a-lot-of-money/" target="_blank" rel="noreferrer noopener">Letter to a friend who just made a lot of money</a>&nbsp;by Graham Duncan (an essay on managing yourself and selecting a wealth manager by the head of a major family office).</p><p>Those should cover the basics, and I‚Äôm happy to go into more detail as specific questions come up. From there, you just have to pick and choose what works best for you.</p><p>Congrats again, and can‚Äôt wait to hear what you‚Äôre up to next,</p><p>Luke</p><p><em>Thanks to my friends in wealth management who helped me first learn these lessons, and credit to Benn Eifert for the factory analogy.</em></p><p><em>This essay was inspired by conversations I had with two friends who recently came into wealth ‚Äì one a young SF tech executive whose company was sold, one a middle age Middle East entrepreneur who took a dividend from his family business. ‚Ä¶</em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lembascapital.com/library/note-to-a-newly-liquid-entrepreneur/">https://lembascapital.com/library/note-to-a-newly-liquid-entrepreneur/</a></em></p>]]>
            </description>
            <link>https://lembascapital.com/library/note-to-a-newly-liquid-entrepreneur/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25050332</guid>
            <pubDate>Tue, 10 Nov 2020 19:20:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[.NET 5 Is Here]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25049738">thread link</a>) | @twords
<br/>
November 10, 2020 | https://twords.com/view-article/TLDR_Code-Net-5-is-Here | <a href="https://web.archive.org/web/*/https://twords.com/view-article/TLDR_Code-Net-5-is-Here">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="root"><div><div><div><div><div><header><div><p><a tag="[object Object]" href="https://twords.com/"><img src="https://twords.com/static/media/inverse_cropped.0601fa81.svg"></a></p><div><div><div></div></div></div><div><p><a tag="[object Object]" href="https://twords.com/authentication/login">Login</a></p></div></div></header></div><div class="page"><div><div><p><a href="https://twords.com/#" data-rb-event-key="/" role="button"></a><a href="https://twords.com/">Home</a></p></div><div><p><a href="https://twords.com/#" data-rb-event-key="/trending" role="button"></a><a href="https://twords.com/trending">Trending</a></p></div><div><p><a href="https://twords.com/#" data-rb-event-key="/my-feed" role="button"></a><a href="https://twords.com/my-feed">My Feed</a></p></div></div><div><nav><a href="https://twords.com/"></a></nav></div><div><div><a href="https://twords.com/view-article/null"><div><p>Continue reading...</p></div></a></div><div></div></div><div><div><p><h3>Latest Articles</h3></p><div><div><p><span>Loading..</span></p></div><p><span>Loading...</span></p></div></div></div></div><div><nav><div><p><a tag="[object Object]" href="https://twords.com/about-us">About Us</a></p></div><div><p><a tag="[object Object]" href="https://twords.com/contact-us">Contact Us</a></p></div><div><p><a tag="[object Object]" href="https://twords.com/faq">FAQ</a></p></div><div><div><p><a href="https://twitter.com/official_twords">Twitter</a></p></div></div></nav></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://twords.com/view-article/TLDR_Code-Net-5-is-Here</link>
            <guid isPermaLink="false">hacker-news-small-sites-25049738</guid>
            <pubDate>Tue, 10 Nov 2020 18:55:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Important Open Source projects should not use GitHub]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25049619">thread link</a>) | @rolph
<br/>
November 10, 2020 | https://www.unixsheikh.com/articles/important-open-source-projects-should-not-use-github.html | <a href="https://web.archive.org/web/*/https://www.unixsheikh.com/articles/important-open-source-projects-should-not-use-github.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>Published on <span id="pubdate">2020-10-23</span>. Modified on <span id="moddate">2020-10-25</span>.</p>
<p>Thousands of the worlds best Open Source projects are still hosting their code repositories on GitHub. Since Microsoft has purchased GitHub this has become a serious problem.</p>
<p><b>Update 2020-10-25:</b> This is not directly related as it could happen on other hosting platforms as well, but just a few hours after I wrote this the youtube-dl repository was taken down from GitHub by RIAA due to a <a href="https://github.com/ytdl-org/youtube-dl/">DMCA request</a>.</p>
<p>It is no news that <a href="https://en.wikipedia.org/wiki/GitHub#Acquisition_by_Microsoft">Microsoft purchased GitHub in 2018</a>, everyone knows that. Yet despite that fact thousands of the worlds most important Open Source projects continue to host their code on GitHub. People seem to have forgotten just how rotten Microsoft really is and how dangerous that situation is.</p>
<p>It is not so much the fact that many projects host their projects on GitHub, it is the fact that many projects haven't secured the code outside of GitHub! They rely fully on GitHub to maintain and protect the code.</p>
<p>Microsoft is very actively purchasing important projects related to Open Source and in April 2020 it was announced that they had now also acquired <a href="https://en.wikipedia.org/wiki/Npm_(software)">npm</a>, a JavaScript packaging vendor, for an undisclosed sum of money.</p>
<p>Perhaps the younger generation don't know anything about the past "evils" of Microsoft and naively believe that Microsoft is now the good friend to Open Source, but the truth is that all these acquisitions of Open Source projects is a business tactic that is put in place to improve Microsoft's loosing position to Open Source. It is a matter of control.</p>
<p>Just yesterday <a href="https://www.minecraft.net/en-us/article/java-edition-moving-house">Microsoft announced</a> that Minecraft will require a Microsoft account to play in 2021 and that owners of the classic version will be forced to migrate.</p>
<p>While this is not related to Open Source, it is a really good example of how bad it can get if Microsoft sometime in the future decides that projects on GitHub are required to do something which goes against these projects interests.</p>
<p>I will not name any names, because that is not important, but how in the world can any Open Source project that regards their code base as valuable not make sure that they have a completely up to date copy of every single line of code outside of GitHub!?</p>
<p>Some project developers only keep parts on the code in personal repositories, others haven't even got a backup but trust fully that GitHub will always have a working and current release of the latests commits.</p>
<p>For years people have warned about the position GitHub had in the world of Open Source because it concentrates too much of the power to make or break the community in a single entity. Having Microsoft behind the steering wheel makes the situation a thousand times worse.</p>
<p>Nobody in their right mind would ever have imagined uploading Open Source code to Microsoft servers just a decade ago. Microsoft where the archenemy of Open Source in the nineties and they deployed all kinds of dirty tactics to keep other operating systems out of the market, especially dirty tactics against Linux. In the early 2000s the then CEO Steve Ballmer said, <q>Linux is a cancer that attaches itself in an intellectual property sense to everything it touches.</q> And for many years they tried to gain control over Linux and manipulated the market in different ways in order to "crush the competition". When they realized they couldn't do that and that the battle was lost, they deployed a new tactic in which they instead try to make money of Linux, which is what that are doing now in a lot of areas, and which is why they seem "friendlier" to the Open Source community.</p>
<p>I myself do have some code residing on GitHub, but of course I also have multiple up-to-date clones and backups elsewhere. However, having the worlds largest repository of important Open Source code reside in the hands of Microsoft is just madness. Why haven't all the major projects migrated? Running a self-hosting Git server isn't that difficult and there even exists several solutions that are pretty solid.</p>
<p>More and more of all the good stuff about Open Source and community driven development and sharing of resources, code and experience is slowly getting either gobbled up or ruined and massacred by big corporations or economically based foundations. Why is it that as soon as money enters into the picture so many things are turned into "crap"? Of course, greed is the answer, but an even more important question than that is: Why is it that we have stopped caring?</p>
<p>Large projects should self-host their repositories in order to stay completely independent, but some alternative solutions to the more popular services such as GitHub, GitLab and BitBucket does exist (not an exhaustive list):</p>
<ul>
<li><a href="https://codeberg.org/">Codeberg</a><br>Codeberg is a registered German non-profit organization and I think it is the best alternative. Codeberg does not depend on external services. No third party cookies, no tracking. Hosted in the EU.<br>Relevant discussion on <a href="https://news.ycombinator.com/item?id=22795930">Hacker News</a>. Relevant <a href="https://codeberg.org/codeberg/org/src/branch/master/PrivacyPolicy.md">Privacy Policy</a></li>
<li><a href="https://notabug.org/">NotABug</a><br>NotABug.org is run by <a href="https://peers.community/">Peers</a>, a group of people interested in free software and free society. It is mostly for small projects though. Relevant <a href="https://notabug.org/tos">Privacy Policy</a>.</li>
<li><a href="https://sourcehut.org/">sourcehut</a><br>sourcehut is currently considered alpha and it is not going to stay free, but it does not have any tracking or advertising. All features work without JavaScript. Relevant <a href="https://man.sr.ht/privacy.md">Privacy Policy</a>. Relevant discussion on <a href="https://news.ycombinator.com/item?id=23030489">Hacker News</a>. After signing up you get the following message: <q>Payment is optional during the alpha, but be aware that it will become mandatory later. This service is funded by its users, not by investors.</q></li>
</ul>
<p>A few good solutions for self-hosting (not an exhaustive list):</p>
<ul>
<li><a href="https://gogs.io/">Gogs</a> - old discussion at <a href="https://news.ycombinator.com/item?id=11374003">Hacker News</a></li>
<li><a href="https://gitea.io/en-US/">Gitea</a> a community-managed fork of Gogs - discussed at <a href="https://news.ycombinator.com/item?id=17006503">Hacker News</a></li>
<li><a href="https://github.com/theonedev/onedev">OneDev</a> - discussed at <a href="https://news.ycombinator.com/item?id=22081419">Hacker News</a></li>
</ul>
<p>Other relevant reading: <a href="https://jacquesmattheij.com/what-is-wrong-with-microsoft-buying-github/">What is wrong with Microsoft buying GitHub</a></p>
</article></div>]]>
            </description>
            <link>https://www.unixsheikh.com/articles/important-open-source-projects-should-not-use-github.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25049619</guid>
            <pubDate>Tue, 10 Nov 2020 18:51:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Innocent badgers behind ‚Äúawful‚Äù and ‚Äúdisgusting‚Äù looting of Viking graves]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25049599">thread link</a>) | @Bologo
<br/>
November 10, 2020 | https://www.psychnewsdaily.com/innocent-badgers-behind-awful-and-disgusting-looting-of-viking-graves/ | <a href="https://web.archive.org/web/*/https://www.psychnewsdaily.com/innocent-badgers-behind-awful-and-disgusting-looting-of-viking-graves/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4973" role="main"><div><div><div><p>On November 4, various media reported on the looting of Viking graves in the Norwegian town of <a href="https://en.wikipedia.org/wiki/Oppdal">Oppdal</a>. <span data-ez-name="psychnewsdaily_com-medrectangle-3"></span></p><p>Malevolent grave robbers had allegedly ravaged a sacred Viking burial ground. Local newspapers attributed the misdeed to wanton vandals, greedy thieves, or both. The intruders had apparently drilled deep holes into 17 of the Viking graves.</p><p>‚ÄúIt‚Äôs awful!‚Äù <a href="https://www.adressa.no/nyheter/trondelag/2020/11/06/Anmeldte-vikinggrav-plyndring-i-Oppdal-n%C3%A5-har-saken-tatt-en-uventet-vending-22955618.ece">said Thora Nyborg</a>, a curator at the NTNU University Museum in Trondheim, according to local newspaper <em>OPP </em>(paywalled link <a href="https://opp.no/2020/11/nyheter/vikinggraver-plyndret-i-hostmorket/">here</a>). ‚ÄúMany organic objects have been lost, and more objects might be lost now that air has been allowed into the graves.‚Äù</p><p>Archaeology website AncientPages.com <a href="https://www.ancientpages.com/2020/11/06/disgusting-vandalism-and-looting-of-viking-graves-in-norway/">called the vandalism ‚Äúdisgusting.</a>‚Äù And commenters on the Facebook page The Heathen Underground <a href="https://www.facebook.com/heathenunderground/photos/pb.728159570530461.-2207520000../3763552250324496/?type=3&amp;eid=ARAk94RGYvhaVzFmr5C9yKMCmQ32q4-ZklASGYAnOI05bhST6Muv28ZWrAJzOp3mR3HLyVKKIZUIXIxy">said it was all ‚Äúvery sad.‚Äù</a></p><h2>Looting of Viking graves a blessedly rare event</h2><p>Their indignation was understandable. After all, the <a href="https://www.visitnorway.com/listings/the-burial-site-at-vang/204434/">Vang burial site</a>, and its more than 800 burial mounds, is Northern Europe‚Äôs largest remaining burial site from the Iron Age. As such, it is a site of major historical importance.<span data-ez-name="psychnewsdaily_com-medrectangle-4"></span></p><p>The local newspaper <em>OPP </em>even suggested that the holes, which were of varying depths, <a href="https://opp.no/2020/11/nyheter/vikinggraver-plyndret-i-hostmorket/">had been dug using a special drill</a> (paywalled link), indicating a wicked degree of cunning on the part of the graverobbers.</p><p>Furthermore, except for an isolated case in 2014, there had been no looting at this major Viking burial ground since the 19th century.</p><h2>Badgers behind the looting of Viking graves</h2><p>But on November 6, events took a different turn. The <a href="https://www.psychnewsdaily.com/300-cocaine-packages-wash-ashore-on-dutch-beach-drug-tourists-look-for-more/">police</a> had suddenly closed the case, said Sjur Vammervold, a cultural consultant for the municipality of Oppdal.</p><p>The reason was that the suspect turned out to be impossible to prosecute. ‚ÄúIt seems that a badger was behind it,‚Äù <a href="https://www.dagbladet.no/kultur/gravplyndrer-avslort/73037518">Vammervold told local newspaper <em>Dagbladet</em></a>.<span data-ez-name="psychnewsdaily_com-box-4"></span></p><p>‚ÄúAt least now we know that people weren‚Äôt responsible,‚Äù he said. ‚ÄúThe badger is quite innocent, and probably had no plans to rob any graves,‚Äù he added.</p><p>Vammervold said that while the badger hypothesis has not yet been proven, at this point it seems the most likely explanation.</p><p>‚ÄúBased on how badgers dig holes, they are probably behind this,‚Äù he said of the short legged <a href="https://www.psychnewsdaily.com/category/animal-psychology/" target="_blank" rel="noreferrer noopener">animals</a>.</p><p>Most of the burial sites at Vang date from the Late Iron Age (400 ‚Äì 1050 AD), which includes the <a href="https://en.wikipedia.org/wiki/Viking_Age">Viking Age</a> (793 ‚Äì 1066 AD). Archaeologists have made many important discoveries there.</p><hr><p><strong>Photo credit: </strong><a href="https://pixabay.com/users/andyballard-1141862/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2030975">andy ballard</a>&nbsp;via&nbsp;<a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2030975">Pixabay</a>&nbsp;</p><p>For a weekly summary of the latest psychology news, subscribe to our <a href="https://www.psychnewsdaily.com/the-psych-news-weekly-newsletter/" target="_blank" rel="noreferrer noopener">Psych News Weekly newsletter</a>.</p></div></div></div></article></div>]]>
            </description>
            <link>https://www.psychnewsdaily.com/innocent-badgers-behind-awful-and-disgusting-looting-of-viking-graves/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25049599</guid>
            <pubDate>Tue, 10 Nov 2020 18:50:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Platform APIs in Qt 6]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25049468">thread link</a>) | @Memosyne
<br/>
November 10, 2020 | https://www.qt.io/blog/platform-apis-in-qt-6 | <a href="https://web.archive.org/web/*/https://www.qt.io/blog/platform-apis-in-qt-6">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            

                            <p>
                                Tuesday November 10, 2020 by <a href="https://www.qt.io/blog/author/tor-arne-vestb%C3%B8">Tor Arne Vestb√∏</a> | <a href="#commento">Comments</a>
                            </p>
                            
                            <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p><span>While Qt solves many of the typical tasks of writing an application, there are always corner cases that Qt can not cover, or where it makes more sense to build a feature on top of the platform specific APIs, or another toolkit. One of the <a href="https://bugreports.qt.io/browse/QTBUG-80233" rel="noopener" target="_blank">tasks</a> we wanted to address for Qt 6 was to clean up and coordinate the various mechanisms we had for accessing platform-specific functionality. </span><span></span></p>
<!--more-->
<p><span>We'll now&nbsp; go through the result of this work in Qt 6. The full documentation is available in the documentation snapshots, as part of the new <a href="https://doc-snapshots.qt.io/qt6-dev/platform-integration.html" rel="noopener" target="_blank">Platform Integration </a></span><span>section.</span></p>
<h2 id="type-conversions">Type Conversions</h2>
<p>Many of Qt's basic data types, such as<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qstring.html">QString</a>,<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qpoint.html">QPoint</a>, or<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qimage.html">QImage</a>, provide conversions from and to the native equivalent types.</p>
<p>For example, to get the current user's username on Apple platforms:</p>
<div>
<pre><code>NSProcessInfo *processInfo = NSProcessInfo.processInfo;<br>QString userName = QString::fromNSString(processInfo.userName)</code></pre>
</div>
<p>For a complete list of all type conversions, see the<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/platform-type-conversions.html">Type Conversions</a><span>&nbsp;</span>overview.</p>
<h2>Window Embedding<a href="https://doc-snapshots.qt.io/qt6-dev/platform-integration.html#window-embedding" title="Direct link to this headline"></a></h2>
<p>Windows created by the underlying platform APIs may be used as both parent containers for Qt windows, or embedded into Qt windows as child windows.</p>
<p>The former is useful if the application is mainly written using the native platform APIs, but where parts of the application use Qt, for example to draw a specialized UI. To embed Qt into the window hierarchy of the native application, use<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qwindow.html#winId">QWindow::winId</a>() to get the native handle for the Qt window, and then use the native APIs to re-parent the window into the native UI.</p>
<a name="event-handling" id="event-handling" data-hs-anchor="true"></a>
<p>The latter is useful if the native platform, or another toolkit, exposes a specialized control as a native window. By using<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qwindow.html#fromWinId">QWindow::fromWinId</a>() to wrap the native window handle in a<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qwindow.html">QWindow</a>, the window can then be re-parented into the Qt window hierarchy as any other<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qwindow.html">QWindow</a>. To re-parent this<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qwindow.html">QWindow</a><span>&nbsp;</span>into a Qt Widget based UI, use the widgets-specific<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qwidget.html#createWindowContainer">QWidget::createWindowContainer</a>() function.</p>
<h2><span>Event Handling</span></h2>
<p><span>Most event handling use-cases in Qt are sufficiently covered by the cross platform event delivery, via</span><span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qwindow.html#event">QWindow::event</a><span>() and friends, or through</span><span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qobject.html#installEventFilter">QObject::installEventFilter</a><span>().</span></p>
<p>In cases where this is not enough, Qt provides access to the delivery of the native events. A global event filter that receives all native events can be installed by using<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qcoreapplication.html#installNativeEventFilter">QCoreApplication::installNativeEventFilter</a>(), while per-window native events can be handled in<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qwindow.html#nativeEvent">QWindow::nativeEvent</a>().</p>
<p><strong>Note:<span>&nbsp;</span></strong>Interfering with the native event flow may put Qt in an inconsistent state. These APIs should primarily be used to augment Qt's existing event handling, for example for events Qt doesn't handle yet.<span></span><span></span></p>
<h2 id="native-interfaces">Native Interfaces<a href="https://doc-snapshots.qt.io/qt6-dev/platform-integration.html#native-interfaces" title="Direct link to this headline"></a></h2>
<p>Platform specific functionality not covered by the APIs mentioned above are handled by the new generic<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/native-interfaces.html">native interface</a><span>&nbsp;</span>mechanism. This mechanism replaces the <a href="https://doc.qt.io/qt-5/qtplatformheaders-index.html" rel="noopener">platform headers</a> user-facing API, as well as the QPA-level <span><code>QPlatformNativeInterface</code></span> API. The interfaces provide access to native or platform specific APIs of the classes they extend.</p>
<p>The interfaces live in the<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qnativeinterface.html">QNativeInterface</a><span>&nbsp;</span>namespace, and cover use-cases such as accessing underlying native handles, adopting existing native handles, or providing platform specific APIs.</p>
<p>The majority of the old <a href="https://doc.qt.io/qt-5/qtplatformheaders-index.html" rel="noopener">platform header </a>APIs can be found in the <span><code>QNativeInterface::Private</code></span> namespace, since these were largely used by other internal code. Over time we'll expose more of these APIs based on feedback and use-cases.<span></span></p>
<h3 id="accessing-underlying-native-handles">Accessing underlying native handles<a href="https://doc-snapshots.qt.io/qt6-dev/native-interfaces.html#accessing-underlying-native-handles" title="Direct link to this headline"></a></h3>
<p>In situations where a feature of the native platform is not exposed in Qt, it can be helpful to access the native handles maintained by Qt, and use those to call the native APIs instead.</p>
<p>For example, to access the underlying NSOpenGLContext of an<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/native-interfaces.html#qopenglcontext">QOpenGLContext</a><span>&nbsp;</span>on macOS, via the<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qnativeinterface-qcocoaglcontext.html">QNativeInterface::QCocoaGLContext</a><span>&nbsp;</span>native interface:</p>
<div>
<pre><code><span>using</span><span> </span><span>namespace</span><span> </span><span><a href="https://doc-snapshots.qt.io/qt6-dev/qnativeinterface.html">QNativeInterface</a></span><span>;</span><span><br></span><span>if</span><span> </span><span>(</span><span>auto</span><span> </span><span>*</span><span>cocoaGLContext </span><span>=</span><span> glContext</span><span>-</span><span>&gt;</span><span>nativeInterface</span><span>&lt;</span><span>QCocoaGLContext</span><span>&gt;</span><span>())</span><span><br>    </span><span>[</span><span>cocoaGLContext</span><span>-</span><span>&gt;</span><span>nativeContext</span><span>()</span><span> makeCurrentContext</span><span>]</span><span>;</span></code></pre>
</div>
<p>The native interface is accessed through the<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qopenglcontext.html#nativeInterface">QOpenGLContext::nativeInterface</a>() accessor, which ensures that the requested interface is available, and otherwise returns<span>&nbsp;</span><code>nullptr</code>. The underlying NSOpenGLContext is then accessed through the<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qnativeinterface-qcocoaglcontext.html#nativeContext">nativeContext()</a><span>&nbsp;</span>accessor.<span></span></p>
<h3 id="adopting-existing-native-handles">Adopting existing native handles<a href="https://doc-snapshots.qt.io/qt6-dev/native-interfaces.html#adopting-existing-native-handles" title="Direct link to this headline"></a></h3>
<p>Similarly to the<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/platform-integration.html#window-embedding">window embedding</a><span>&nbsp;</span>use-case, there are situations where the native platform, or another toolkit, has created a native handle that you would like to pass on to Qt ‚Äî wrapping the existing handle instead of creating a new one.</p>
<p>For example, to adopt an existing NSOpenGLContext, and use that to share resources with a context created by Qt:</p>
<div>
<pre><code><span>using</span><span> </span><span>namespace</span><span> </span><span><a href="https://doc-snapshots.qt.io/qt6-dev/qnativeinterface.html">QNativeInterface</a></span><span>;</span><span><br></span><span><a href="https://doc-snapshots.qt.io/qt6-dev/qopenglcontext.html">QOpenGLContext</a></span><span> </span><span>*</span><span>adoptedContext </span><span>=</span><span> </span><span>QCocoaGLContext</span><span>::</span><span>fromNativeContext</span><span>(</span><span>nsOpenGLContext</span><span>);</span><span><br>anotherContext</span><span>-</span><span>&gt;</span><span>setShareContext</span><span>(</span><span>adoptedContext</span><span>);</span></code></pre>
</div>
<p>The adopted context is created by a platform specific factory function in the<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qnativeinterface-qcocoaglcontext.html">QNativeInterface::QCocoaGLContext</a><span>&nbsp;</span>native interface.<span></span></p>
<h3 id="accessing-platform-specific-apis">Accessing platform specific APIs<a href="https://doc-snapshots.qt.io/qt6-dev/native-interfaces.html#accessing-platform-specific-apis" title="Direct link to this headline"></a></h3>
<p>In some cases an API is too platform specific to be included in the cross platform Qt classes, but is still useful to include. These APIs are available either in the same way as when accessing the underlying native handles, through the<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qopenglcontext.html#nativeInterface">nativeInterface()</a><span>&nbsp;</span>accessor, or directly as static function in the native interface.</p>
<p>For example, to obtain the OpenGL module handle on Windows:</p>
<div>
<pre><code><span>using</span><span> </span><span>namespace</span><span> </span><span><a href="https://doc-snapshots.qt.io/qt6-dev/qnativeinterface.html">QNativeInterface</a></span><span>;</span><span><br>HMODULE moduleHandle </span><span>=</span><span> </span><span>QWGLContext</span><span>::</span><span>openGLModuleHandle</span><span>();<br></span></code></pre>
<p><span>Or to tweak the border behavior of a window on Windows, via its platform window handle:</span></p>
<div>
<pre><code><span>using</span><span> </span><span>namespace</span><span> </span><span>QNativeInterface::Private</span><span>;<br></span><span>if (auto *windowsWindow = dynamic_cast&lt;QWindowsWindow*&gt;(window-&gt;handle()))<br>    windowsWindow-&gt;setHasBorderInFullScreen(true);</span></code></pre>
</div>
</div>
<h3 id="source-and-binary-compatibility">Source and Binary Compatibility<a href="https://doc-snapshots.qt.io/qt6-dev/native-interfaces.html#source-and-binary-compatibility" title="Direct link to this headline"></a></h3>
<p>One important thing to note is that are no source or binary compatibility guarantees for the native interface APIs, meaning that an application using these interfaces is only guaranteed to work with the Qt version it was developed against. This allows us to adjust and add to these APIs as needed -- making them more flexible in tracking the underlying native functionality.</p>
<h2>Extras modules</h2>
<p>As some of you have noticed, the "extras" modules are not part of the initial Qt 6.0 release. This is related to the work described in this blog post, as we still need to go through these modules to survey:</p>
<ul>
<li>Whether any features are deprecated and can be removed</li>
<li>Whether any features have more modern replacements that we should advocate instead</li>
<li>Whether any features can be better solved by integrating directly with the native APIs</li>
<li>Whether any features fit better in the API paradigms described earlier, for example as native interfaces</li>
</ul>
<p>The end goal would ideally be that we don't need any standalone "extras" module, but rather that the functionality is available directly in the relevant modules, e.g. QtGui or QtDeclarative.&nbsp; If you want to track this work you can follow <a href="https://bugreports.qt.io/browse/QTBUG-83251" rel="noopener">QTBUG-83251</a>.</p></span></p>
                            
                            
                                <hr>
                          
                                <h6>Blog Topics:</h6>        
                                
                            


                        </div></div>]]>
            </description>
            <link>https://www.qt.io/blog/platform-apis-in-qt-6</link>
            <guid isPermaLink="false">hacker-news-small-sites-25049468</guid>
            <pubDate>Tue, 10 Nov 2020 18:42:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RIP Bill Morrow: Lead Developer Cinelerra-GG]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25049358">thread link</a>) | @constantinum
<br/>
November 10, 2020 | https://www.cinelerra-gg.org/news-updates/our-developer-good-guy-has-passed-away/ | <a href="https://web.archive.org/web/*/https://www.cinelerra-gg.org/news-updates/our-developer-good-guy-has-passed-away/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="et-boc">
<div>
<div><div>
<div>
<div>
<div>
<div><p>It is with dismay and sadness that I have to announce this devastating news that our highly esteemed developer W.P. Morrow aka Good Guy died in a traffic accident last Monday at the age of 66. Bill, as he also called in private, was as so often in his free time, out for sports riding his bicycle when he was hit by a truck. He was taken to hospital, but unfortunately he succumbed to his severe injuries.</p>
<p>This news is shocking and makes me speechless, although I find it extremely difficult to find words due to my sadness, I would like to remember him at this point.</p>
<p>A look back shows that, together with Phyllis, he has pushed this project forward with great passion, dedication and commitment. His ingenuity and creative solutions were always an enrichment for this project. He was never too comfortable to tackle even small problems and improvements to make the life of the users easier. You could tell that he enjoyed programming a lot. He enjoyed improving Cinelerra-GG and interacting with the community. He has acted selflessly and for the good of all, and through his commitment to free and open software, he has made this world a bit freer and better.</p>
<p>The gap he leaves behind is huge and filling it will be hard.</p>
<p>Thanks for everything dear Bill. It was a great honor and pleasure to work with you. You will be remembered. We will miss you. Rest in peace.</p>
<p>I express my condolences to Phyllis, his family and friends.</p>
<p>Sam</p>
<p>P.S.: Phyllis has expressed the wish to resume work on the project at a later date, currently she needs some time off, and to participate in the documentation and correspondence as usual. I will continue to support this project as before. The monthly releases cannot be offered in the same way at the moment. Minor changes and improvements will take place from time to time. We are open for new developers and hope for your support.</p></div>
</div> 
</div> 
</div> 
</div>  </div>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://www.cinelerra-gg.org/news-updates/our-developer-good-guy-has-passed-away/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25049358</guid>
            <pubDate>Tue, 10 Nov 2020 18:33:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Meet the world's first Kafka data catalog]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25049235">thread link</a>) | @lefterisdvr
<br/>
November 10, 2020 | https://lenses.io/blog/2020/07/data-dump-real-time-data-catalog-apache-kafka/ | <a href="https://web.archive.org/web/*/https://lenses.io/blog/2020/07/data-dump-real-time-data-catalog-apache-kafka/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>From data stagnating in warehouses to a growing number of real-time applications, in this article we explain why we need a new class of Data Catalogs: this time for real-time data.&nbsp;</p><p>The 2010s brought us organizations <i>‚Äúdoing big data‚Äù</i>. Teams were encouraged to dump it into a data lake and leave it for others to harvest.&nbsp;</p><p>But data lakes soon became data swamps. There were no best practices, no visibility into service levels or quality of data, no data contracts, no naming conventions or standardizations.&nbsp;</p><p>Just as quickly as data had arrived, it was impossible to find or trust.&nbsp;</p><p>If you were mature you might have deployed an enterprise Data Catalog that discovered data across your data stores. If you were less mature this would have been a manual process of documentation.&nbsp;</p><p>Either way, this wouldn‚Äôt prepare you for what was to come in the world of data and <a href="https://lenses.io/dataops/">DataOps</a>.&nbsp;</p><h3>

New streaming data, same problem, bigger stakes</h3><p>
As a developer or data engineer, you still have a problem finding data. Answering simple questions such as: Where do I have customer data? How about surnames and phone numbers or credit cards?&nbsp;</p><p>Why is this?&nbsp;</p><p>It‚Äôs because the challenge to catalog data got harder. Data isn‚Äôt sitting in data warehouses any longer. It‚Äôs streaming. And it is data generated by applications run within engineering, not business teams. </p><p>A lot of applications.</p><p>Engineering teams haven‚Äôt got time nor can they be expected to follow traditional data governance practices.</p><p>And yet, if there is no way to know what data there is across different teams and how to find it - it may as well not exist.</p><p>Much of DataOps is about self-service to remove friction from delivery. Pure luck in speaking to the right person at the right time or endless back-and-forths to understand what data exists, how it looks, etc isn't right. </p><p>This won‚Äôt work in 2020.&nbsp;</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/1tMpPZhid4mgL7MmbBaKiQ/e3b84596b166d1eba6bd5b303c891726/dataops-workspace.png" alt="DataOps container for your data platform"></p><p>For real-time data, there is no alternative but to automate the data management processes. This includes the discovery of data entities, data lineage, classification and quality.&nbsp;</p><p>Automation will mean teams are free to develop new data-intensive applications without centralized data governance or manual procedures.&nbsp; What data is generated can be immediately socialized across a business for other teams to benefit from.</p><h3>Commandments of Cataloguing data
</h3><p>Metadata is Queen. </p><p>If you can collect it from your different data infrastructure and applications you‚Äôre on the right path. Then to make it valuable you need to serve this information in the right measure, and you can start to answer the right questions:&nbsp;</p><ul><li><p> <!-- -->What data exists and its profile?</p></li><li><p> <!-- -->What is its quality?</p></li><li><p> <!-- -->What service levels can I expect?</p></li><li><p> <!-- -->What is its data provenance?</p></li><li><p> <!-- -->How might other services be impacted?</p></li><li><p> <!-- -->How compliant is it?</p></li></ul><p>Being able to answer these sorts of questions is fundamentally important to the success of real-time data projects.&nbsp;</p><p>Gartner agrees:<i> </i></p><p><i>‚ÄúBy 2021, organizations that offer a curated catalog of internal and external data to diverse users will realize twice the business value from their data and analytics investments than those that do not‚Äù</i></p><p><b><i>Source: Augmented Data Catalogs: Now an Enterprise Must-Have for Data and Analytics Leaders,‚Äù Ehtisham Zaidi &amp; Guido de Simoni, Sept.12, 2019</i></b>

</p><h3>Enter the Lenses real-time Data Catalog
</h3><p>Lenses.io delivers the first and only <a href="https://lenses.io/usecases/discover">Data Catalog for streaming data</a>.</p><p><img src="https://downloads.ctfassets.net/tnuaj0t7r912/3wE5igSRxlgeTTNk7Qy4zc/6cfe43a2e8a7d7ef49c29b02d4d462c0/lenses.io_4.0_real_time_data_catalog.gif" alt="Lenses.io - Real time data catalog for Apache Kafka"></p><p>
It's an easy, secure and intuitive way to identify your data:</p><ul><li><p> <!-- -->It works in real-time</p></li><li><p> <!-- -->It continuously and automatically identifies all your streaming data</p></li><li><p> <!-- -->It works across any data serialization format</p></li><li><p> <!-- -->It enables your team to mask and protect all <a href="https://help.lenses.io/using-lenses/data/data-policies/">sensitive data</a>.</p></li></ul><p><img src="https://images.ctfassets.net/tnuaj0t7r912/7BkMWioUDyPJTjE08BZ25P/f8bf542b6892bc0551133aeac7ae6a66/lenses.io_4.0_data_policies.gif" alt="lenses.io 4.0 data policies - data masking for Apache Kafka"></p><p>Lenses not only provides a Google Search experience over streaming data, but also a Google Maps experience. </p><p>In addition to monitoring your pipelines (Kafka Connect, Flink, Spark Streaming etc.) and your microservices<b>,</b> Lenses will highlight which applications are consuming or producing such ‚Äúsensitive‚Äù data.</p><p>Next, we‚Äôll explain the thought process and key principles behind our real-time Data Catalog.</p><h3>Like Google but for Apache Kafka metadata

</h3><p>Building a real-time Data Catalog was a natural progression for our team. We‚Äôve been giving visibility into Apache Kafka environments and applications that run on Kafka for years.&nbsp;&nbsp;</p><p>This was mainly developed to help engineers gain insight into their Kafka streams. Very useful when it came to debugging applications and inspecting message payload with SQL, partitioning information, overseeing infrastructure health or viewing consumer lag.</p><h3>It all starts with SQL
</h3><p>The SQL engine to explore topic data is particularly important. </p><p>To understand the data and its structure we connected to an AVRO schema registry or deserialized proprietary messages. This meant we had visibility into the metadata and payload of all data sitting in Kafka.</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/3H4HgRJRB2kIecDBxWrloU/be23f75b16a743698c0224577526af79/_Blog_-Data-Catalog---4.0-release---Alternative.jpg" alt="Lenses.io data catalog for Apache Kafka architecture"></p><p>
Last year we extended the capabilities to explore data in Elasticsearch with the same SQL engine and built a framework to connect to multiple different data stores in the future: Postgres, Redis, Cassandra.&nbsp;</p><p>We also register stream processing applications that run on our <a href="https://docs.lenses.io/4.0/sql/">streaming SQL engine</a> over Kubernetes.&nbsp;&nbsp;</p><p>We allow developers to register their external applications either as a REST endpoint or with a client for JVM-based applications.&nbsp;</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/VoX7OrBtso7pnE7dh66T5/d773f7955ba1d66ca978402f26ae8eb9/lenses-api-docs-external-apps.png" alt="Lenses API docs external apps"></p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/3iy2qCN9vTVzNpf5rDkwV6/6b1caba28603be4dc8680fc8f5670a01/topology-client-properties.png" alt="topology-client-properties"></p><p>This builds us an App Catalog and a Topology of all the dependencies between different flows and applications. Allowing us to build the data lineage of different data sets.&nbsp;</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/1tYvPfHqG2xHjfo7NfpVZ1/7394b4b2e3f409c1c12ff8c07b85fde6/_Blog_-Data-Catalog---4.0-release---Alternative_01.jpg" alt="Apache Kafka pipeline topology and data lineage lenses.io"></p><p>It also allows us to answer a few important questions:</p><ul><li><p> <!-- -->What applications generated this data?</p></li><li><p> <!-- -->How much can I trust the quality of the data and at what service levels?</p></li><li><p> <!-- -->What downstream applications consume this data to understand service disruption impact?</p></li></ul><p>The Topology, App Catalog and SQL Engine therefore give us the ability to maintain a metadata catalog of data flowing across a data platform.&nbsp;</p><p>Most importantly, this data is updated automatically and in real-time. </p><p>As engineering teams develop a new product, whether it be a consumer-facing microservice application or data processing pipeline, the data and topology will be discovered automatically, including payload and all metadata.&nbsp;&nbsp;</p><p>Or if an application writes to an Elasticsearch index, that too will automatically be picked up.</p><p>No need to manually maintain a catalog.&nbsp;</p><p>This information can then be presented and found in a free-text search fashion a la Google:&nbsp;</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/6xN1yqyFKhCyNTlik17Vb/caa0832fc2c1061daf9767bfd3823b73/image__25_.png" alt="Lenses.io - real time data catalog - searching metadata in Apache Kafka and Elasticsearch"></p><p>The catalog is protected with the same unified namespace-based security model that protects all data access in Lenses.&nbsp;</p><p>It opens up new use cases around how data can be accessed and drastically reduces the time or the duplicate effort compared to current methods of finding data.&nbsp;</p><p>Here are two examples.&nbsp;</p><h3>1. Scoping a new project
</h3><p>A business analyst is able to scope the feasibility of a new innovative stock management application by exploring what data can be used across multiple different lines of business, including service levels, quality and compliance requirements.</p><p>The analyst starts typing keywords such as <i>stock*</i> to find all metadata (indexes, documentation, field names, streamings) and generating applications that match.&nbsp;</p><p>They can drill down to the payload to explore the data or view in the context of a topology to understand upstream and downstream applications connected to the data. An analyst can only view data they have been granted access to, and/or may have certain sensitive fields masked in accordance with compliance requirements.&nbsp;</p><h3>2. Data access audit</h3><p>
An auditor needs to explore all data entities holding possible password information. </p><p>The auditor saves themselves weeks of data gathering and manual reporting by searching <i>pass*</i> to find all entities. They validate the Lenses user group namespaces for these entities to understand which users have access and understands the applications processing this information via a Topology.&nbsp;</p><p>This same process can help meet any number of compliance controls including GDPR, HIPPA, SOX, SEC and PCI.&nbsp;</p><p>You can try out these use cases (or your own) by exploring our real-time data catalog for free in a sandbox environment at <a href="https://portal.lenses.io/">portal.lenses.io</a> or see all deployment options at <a href="https://lenses.io/start">lenses.io/start</a></p></div></div>]]>
            </description>
            <link>https://lenses.io/blog/2020/07/data-dump-real-time-data-catalog-apache-kafka/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25049235</guid>
            <pubDate>Tue, 10 Nov 2020 18:25:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Upgrade WSL/WSL2 Ubuntu Version to 20.04 LTS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25049073">thread link</a>) | @flipchart
<br/>
November 10, 2020 | https://vivekdhami.com/learnings/upgrade-wslwsl2-ubuntu-version-to-20.04-lts/ | <a href="https://web.archive.org/web/*/https://vivekdhami.com/learnings/upgrade-wslwsl2-ubuntu-version-to-20.04-lts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
  
  <p><time datetime="2020-05-01T00:00:00Z">Fri, May 1, 2020</time></p><p>Its the time of the year again to upgrade Ubuntu version in WSL/WSL2 since the Ubuntu 20.04 LTS came out last week.</p>

<p>Please follow along the following steps in your WSL console to upgrade to the new version:</p>

<ul>
<li>Check installed Ubuntu version</li>
</ul>

<p>Take a note of your current Ubuntu version by running the following command:</p>
<div><pre><code data-lang="html">  No LSB modules are available.
  Distributor ID: Ubuntu
  Description:    Ubuntu 18.04.4 LTS
  Release:        18.04
  Codename:       bionic</code></pre></div>
<p>**<em>Upgrading to 20.04 should work seamlessly when upgrading from 18.04. However if you are on older versions then the suggested path should be upgrading first to 18.04 from 16.04 for example.</em></p>

<ul>
<li>Upgrade installed packages</li>
</ul>
<div><pre><code data-lang="bash">  sudo apt update
  sudo apt list --upgradable
  sudo apt upgrade</code></pre></div>
<ul>
<li>Remove unused packages</li>
</ul>
<div><pre><code data-lang="bash">  sudo apt --purge autoremove</code></pre></div>
<ul>
<li>Install update-manager-core package if not already installed</li>
</ul>
<div><pre><code data-lang="bash">  sudo apt install update-manager-core</code></pre></div>
<ul>
<li>Upgrade to 20.04</li>
</ul>

<p>If you receive the following message:</p>
<div><pre><code data-lang="html">  Checking for a new Ubuntu release
  There is no development version of an LTS available.
  To upgrade to the latest non-LTS develoment release 
  set Prompt=normal in /etc/update-manager/release-upgrades.</code></pre></div>
<p>Then do an upgrade forcefully using the following command:</p>
<div><pre><code data-lang="bash">  sudo <span>do</span>-release-upgrade -d</code></pre></div>
<ul>
<li>Finally check the version after upgrade is done:</li>
</ul>

<p>and you should receive the following similar output:</p>
<div><pre><code data-lang="html">  No LSB modules are available.
  Distributor ID: Ubuntu
  Description:    Ubuntu 20.04 LTS
  Release:        20.04
  Codename:       focal</code></pre></div>
</div>


    </div></div>]]>
            </description>
            <link>https://vivekdhami.com/learnings/upgrade-wslwsl2-ubuntu-version-to-20.04-lts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25049073</guid>
            <pubDate>Tue, 10 Nov 2020 18:13:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Six of JavaScript's Biggest Design Flaws]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25048950">thread link</a>) | @samwinter
<br/>
November 10, 2020 | https://thecarrots.io/blog/javascript-wtf-six-of-the-languages-gravest-design-flaws | <a href="https://web.archive.org/web/*/https://thecarrots.io/blog/javascript-wtf-six-of-the-languages-gravest-design-flaws">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>ü•ï Join the Carrots community</p><p>We‚Äôre a hiring platform for software engineers. Our algorithm shows where you rank among world class talent and surfaces you to top companies.</p></div></div>]]>
            </description>
            <link>https://thecarrots.io/blog/javascript-wtf-six-of-the-languages-gravest-design-flaws</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048950</guid>
            <pubDate>Tue, 10 Nov 2020 18:04:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Million Dollar Hackathon Winner: ‚ÄòVC Robot‚Äô]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25048932">thread link</a>) | @npguy
<br/>
November 10, 2020 | https://doublespend.io/2020/10/29/million-dollar-hackathon-winner-vc-robot/ | <a href="https://web.archive.org/web/*/https://doublespend.io/2020/10/29/million-dollar-hackathon-winner-vc-robot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

			
<article id="post-542">
	
				<p><a href="https://doublespend.io/wp-content/uploads/2020/10/robot.jpg"><img width="800" height="445" src="https://doublespend.io/wp-content/uploads/2020/10/robot-800x445.jpg" alt="" loading="lazy" srcset="https://doublespend.io/wp-content/uploads/2020/10/robot.jpg 800w, https://doublespend.io/wp-content/uploads/2020/10/robot-300x167.jpg 300w, https://doublespend.io/wp-content/uploads/2020/10/robot-768x427.jpg 768w" sizes="(max-width: 800px) 100vw, 800px"></a>
								</p>
			
	<div>

		
		

		
		<div>
			
<p>A team of Stanford students won the million dollar prize in the final round of the nationwide hackathon competition, for developing a stunning fully functional robot, called the ‚ÄòVC Robot‚Äô in just 48 hours.</p>



<p>The judges and audience were all stunned during the demo of the winning entry ‚Äì as the VC Robot made an entry on stage, with an iPad in hand and a smile that nobody could decrypt. The Stanford team had selected two scenes for the demo: a ‚ÄòMonday morning‚Äô VC pitch meeting and a board meeting.</p>



<p>In the Monday morning VC pitch meeting, the VC Robot stunned the judges with an impeccable performance ‚Äì never taking his eyes off his iPad for the whole duration of the pitch. Within 10 seconds of the pitch, the VC Robot suddenly blurted out ‚ÄúHow do you plan to get to product-market fit?‚Äù. It then walked out of the room during the pitch, taking a phone call. When the VC Robot entered the room after a good minute or so, it looked at the entrepreneur and asked him ‚ÄúWhy now, and Why you?‚Äù. As the entrepreneur ended the presentation, the VC Robot asked him ‚ÄúWho else is in? How many paying customers do you have?‚Äù and ended the meeting with ‚ÄúThis sounds exciting. We‚Äôll be in touch‚Äù. </p>



<p>The board meeting was a quick demo, with the VC Robot dialing into the call with coffee and bagels in hand. The Stanford team had kept this one very simple, with the VC Robot asking the following questions in five-minute intervals ‚Äì ‚Äúwhat is the ideal business model for our company?‚Äù, ‚Äúcan we be in two businesses at the same time?‚Äù, ‚Äúdo we need to build, own, and operate our payments system to be successful long term?‚Äù, and ‚Äúcan we build a sustainable business long term operating solely on Facebook?‚Äù. The VC Robot also won huge applause for the way it handled the iPad, the phone, coffee and bagels all at the same time.</p>



<p>The Stanford team plans to spend the million dollars on testing commercial viability of the VC Robot technology.</p>
		</div>

	</div>

	</article>

		</div></div>]]>
            </description>
            <link>https://doublespend.io/2020/10/29/million-dollar-hackathon-winner-vc-robot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048932</guid>
            <pubDate>Tue, 10 Nov 2020 18:03:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avoid Else, Return Early (2013)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25048842">thread link</a>) | @generichuman
<br/>
November 10, 2020 | https://blog.timoxley.com/post/47041269194/avoid-else-return-early | <a href="https://web.archive.org/web/*/https://blog.timoxley.com/post/47041269194/avoid-else-return-early">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
                        
                            
                        
        				
                        
                        <h3>tldr;</h3><ul><li>Return as soon as you know your method cannot do any more meaningful work</li><li>Reduce indentation by using <code>if/return</code> instead of a top-level <code>if/else</code></li><li>Try keep the ‚Äúmeat‚Äù of your method at the lowest indentation level.</li><li>Error handling is noise.</li></ul><hr><p>Programmers are often taught to have a ‚Äòsingle exit point‚Äô in their methods,
i.e. only return from a single location.</p><pre><code>
function () {
  var result;

  if () {
    result = x
  } else {
    if () {
      result = y
    } else {
      result = z
    }
  }

  return result // this return is single and lonely
}

</code></pre><p>This is a poor guideline in my opinion:</p><ul><li>‚Äúassign a result‚Äù doesn‚Äôt explain the intent: ‚Äúthis is the final value, processing stops here‚Äù</li><li>Leaves question open ‚Äúis the result object finished? can it be modified? by whom?‚Äù</li><li>Allows accidental modification of the result</li><li>Encourages ‚Äúhappy path‚Äù to be wrapped in one or more if/else statements</li></ul><h3>Example if/else refactoring</h3><p>Consider this typical node callback code:</p><pre><code>
function(err, results) {
  if (!err) {
    doOtherStuff()
    doMoreStuff()
    // ... etc
    // ... etc
  } else {
    handleError(err)
  }
}
</code></pre><p>There‚Äôs a few problems here. First, our error handling is dangling off the end of the method. If the ‚Äúhappy path‚Äù is many lines long, it can easily become unclear what the <code>else</code> even refers to.</p><p>Let‚Äôs try keep the ‚Äúmeat‚Äù of the code at the bottom of the method, and keep any special cases together at the top:</p><pre><code>
function(err, results) {
  if (err) {
    handleError(err)
  } else {
    doOtherStuff()
    doMoreStuff()
    // ... etc
    // ... etc
  
  }
}
</code></pre><p><a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fcallbackhell.com%2F&amp;t=MTQxODg3Njk0Yzc0MTI0MjlhYTk3NTdhMTU1NjMwZTg4NDU5ZDkxMyxQcjBHSTJVWg%3D%3D&amp;b=t%3AxntNe-nPZGsWC3-V_vsCGA&amp;p=https%3A%2F%2Fblog.timoxley.com%2Fpost%2F47041269194%2Favoid-else-return-early&amp;m=1&amp;ts=1605298808">It‚Äôs very easy to get unweildy levels of indentation in JavaScript</a>,
so we should strive to reduce any unnecessary
nesting.</p><p>In this case, we can remove the <code>else</code> indentation around
our ‚Äúhappy path‚Äù by replacing the <code>else</code> with a return:</p><pre><code>
function(err, results) {
  if (err) {
    handleError(err)
    return
  }

  doOtherStuff()
  doMoreStuff()
  // ... etc
  // ... etc
}
</code></pre><p>Not only does this unindent a bunch of code, it also moves the
method‚Äôs main purpose/intention/meat to indentation level 0.</p><p>We often don‚Äôt care about return values in non-promise-based async JS, so we can
futher compact the method vertically by putting the <code>return</code> first,
removing a whole line and more braces:</p><pre><code>
function(err, results) {
  if (err) return handleError(err)

  doOtherStuff()
  doMoreStuff()
  // ... etc
  // ... etc
}
</code></pre><p><em>2018 edit</em>: To more clearly signal that the return value is unimportant you can use the <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fdeveloper.mozilla.org%2Fen-US%2Fdocs%2FWeb%2FJavaScript%2FReference%2FOperators%2Fvoid&amp;t=ZmQ1MjAwNDI0NTBkZjhmZGJlOWUwN2Q5Y2NiOTJjZDdkNzIyOTM4OSxQcjBHSTJVWg%3D%3D&amp;b=t%3AxntNe-nPZGsWC3-V_vsCGA&amp;p=https%3A%2F%2Fblog.timoxley.com%2Fpost%2F47041269194%2Favoid-else-return-early&amp;m=1&amp;ts=1605298808">void operator</a>:</p><pre><code>
function(err, results) {
  if (err) return void handleError(err)
  // ...
}
</code></pre><p>It also obeys the ‚Äúone logical statement per line‚Äù guideline,
compacting the error detection and handling noise to a
single line.</p><p>Another benefit is that the <code>return</code> keyword is generally syntax highlighted, so all exit points become very clear, as opposed to hidden inside <code>result = something</code> assignments.</p><p>This final form has:</p><ul><li>Method at lowest indentation level</li><li>No unecessary indentation.</li><li>Many fewer lines</li></ul><p>Rebecca Murphey has also <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Frmurphey.com%2Fblog%2F2012%2F12%2F10%2Fjs-conditionals%2F&amp;t=M2Y4MzhmNWQ1ODQyZjNhOGEyZWM3ZjhlNDU2ODA0ZTcyOTQ1YzMwZixQcjBHSTJVWg%3D%3D&amp;b=t%3AxntNe-nPZGsWC3-V_vsCGA&amp;p=https%3A%2F%2Fblog.timoxley.com%2Fpost%2F47041269194%2Favoid-else-return-early&amp;m=1&amp;ts=1605298808">written about this</a></p><p>The end.</p><hr><p><em>2018 edit</em>: As with any programming practice, one shouldn‚Äôt see this as a hard rule that must be obeyed at all times. Early returns make little difference for small functions, and may even increase the cognitive load. However, I find the logic-flattening benefits of early returns become increasingly compelling as the size and complexity of a function increases.</p><p>Lots of discussion about this post:</p><ul><li><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fnews.ycombinator.com%2Fitem%3Fid%3D16678209&amp;t=MmVkZDIzYTA5MDYxYjQ5YjgzNTgyN2FmMzg0Zjk0MmViNmRmMDFmZSxQcjBHSTJVWg%3D%3D&amp;b=t%3AxntNe-nPZGsWC3-V_vsCGA&amp;p=https%3A%2F%2Fblog.timoxley.com%2Fpost%2F47041269194%2Favoid-else-return-early&amp;m=1&amp;ts=1605298808">HackerNews</a>.</li><li><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.reddit.com%2Fr%2Fprogramming%2Fcomments%2F878zi2%2Favoid_else_return_early%2F&amp;t=MDVmMGQxN2MzYjcyZWVkOTc4MjkwMjk1YjQxNmFjMDU0NmI2YTVlZCxQcjBHSTJVWg%3D%3D&amp;b=t%3AxntNe-nPZGsWC3-V_vsCGA&amp;p=https%3A%2F%2Fblog.timoxley.com%2Fpost%2F47041269194%2Favoid-else-return-early&amp;m=1&amp;ts=1605298808">Reddit</a></li></ul>
						
						
                </div></div>]]>
            </description>
            <link>https://blog.timoxley.com/post/47041269194/avoid-else-return-early</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048842</guid>
            <pubDate>Tue, 10 Nov 2020 17:56:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Corporate Private Jet Tracker]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25048723">thread link</a>) | @greatwave1
<br/>
November 10, 2020 | https://www.quiverquant.com/sources/corporateflights?hn= | <a href="https://web.archive.org/web/*/https://www.quiverquant.com/sources/corporateflights?hn=">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="myTable">
 <tbody>
    <tr>
	    <th>Company</th>
            <th onclick="">Departure time</th>
	    <th onclick="">Departure city</th>
	    <th onclick="">Arrival city</th>
          </tr>
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/AXP">AXP</a></td>
            <td>Nov. 11, 2020, 4:43 p.m.</td>
	    <td>Oshkosh</td>
	    <td>Appleton</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/HD">HD</a></td>
            <td>Nov. 11, 2020, 4:20 p.m.</td>
	    <td>Dallas-Fort Worth</td>
	    <td>Atlanta</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/AXP">AXP</a></td>
            <td>Nov. 11, 2020, 4:13 p.m.</td>
	    <td>Milwaukee</td>
	    <td>Oshkosh</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/SENEA">SENEA</a></td>
            <td>Nov. 11, 2020, 3:52 p.m.</td>
	    <td>Trenton</td>
	    <td>Penn Yan</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/AXP">AXP</a></td>
            <td>Nov. 11, 2020, 3:40 p.m.</td>
	    <td>Appleton</td>
	    <td>Milwaukee</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 11, 2020, 3:27 p.m.</td>
	    <td>Ontario</td>
	    <td>Seattle</td>
          </tr>
	  
          
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 11, 2020, 1:57 p.m.</td>
	    <td>Holt</td>
	    <td>Detroit</td>
          </tr>
	  
          
	  
          
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/HFC">HFC</a></td>
            <td>Nov. 11, 2020, 1:02 p.m.</td>
	    <td>Dallas</td>
	    <td>Dallas</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/CNI">CNI</a></td>
            <td>Nov. 11, 2020, 1 p.m.</td>
	    <td>Toronto</td>
	    <td>Montr√É¬©al</td>
          </tr>
	  
          
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/PFE">PFE</a></td>
            <td>Nov. 11, 2020, 12:21 p.m.</td>
	    <td>Teterboro</td>
	    <td>Trenton</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/VFC">VFC</a></td>
            <td>Nov. 11, 2020, 12:11 p.m.</td>
	    <td>Santa Ana</td>
	    <td>Pittsburgh</td>
          </tr>
	  
          
	  
          
	  
          
	  
          
	  
          
	  
          
	  
          
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/HUM">HUM</a></td>
            <td>Nov. 11, 2020, 9:31 a.m.</td>
	    <td>Tampa</td>
	    <td>Louisville</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/CNI">CNI</a></td>
            <td>Nov. 11, 2020, 9:23 a.m.</td>
	    <td>Calgary</td>
	    <td>Toronto</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/VFC">VFC</a></td>
            <td>Nov. 11, 2020, 9:17 a.m.</td>
	    <td>Denver</td>
	    <td>Santa Ana</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/PFE">PFE</a></td>
            <td>Nov. 11, 2020, 9:11 a.m.</td>
	    <td>Miami</td>
	    <td>Teterboro</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 11, 2020, 8:47 a.m.</td>
	    <td>San Diego</td>
	    <td>Riverside/Rubidoux/</td>
          </tr>
	  
          
	  
          
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/HD">HD</a></td>
            <td>Nov. 11, 2020, 7:28 a.m.</td>
	    <td>Atlanta</td>
	    <td>Dallas-Fort Worth</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/CP">CP</a></td>
            <td>Nov. 11, 2020, 7:09 a.m.</td>
	    <td>Minneapolis</td>
	    <td>Bloomington/Normal</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/SENEA">SENEA</a></td>
            <td>Nov. 11, 2020, 7:03 a.m.</td>
	    <td>Janesville</td>
	    <td>Penn Yan</td>
          </tr>
	  
          
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/HUM">HUM</a></td>
            <td>Nov. 11, 2020, 6:45 a.m.</td>
	    <td>Louisville</td>
	    <td>Los Angeles</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 11, 2020, 6:21 a.m.</td>
	    <td>Washington</td>
	    <td>Ottawa</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/PFE">PFE</a></td>
            <td>Nov. 11, 2020, 6:17 a.m.</td>
	    <td>Trenton</td>
	    <td>Miami</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 11, 2020, 2:42 a.m.</td>
	    <td>Manassas</td>
	    <td>Reading</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 11, 2020, 2:14 a.m.</td>
	    <td>Baltimore</td>
	    <td>Wernersville</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 11, 2020, 1:43 a.m.</td>
	    <td>Reading</td>
	    <td>Manassas</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 11, 2020, 1 a.m.</td>
	    <td>Teterboro</td>
	    <td>Reading</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 11, 2020, 12:58 a.m.</td>
	    <td>Manassas</td>
	    <td>Baltimore</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 11, 2020, 12:02 a.m.</td>
	    <td>Worcester</td>
	    <td>Teterboro</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 10, 2020, 11:55 p.m.</td>
	    <td>Pittsburgh</td>
	    <td>Manassas</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 10, 2020, 10:31 p.m.</td>
	    <td>Niagara Falls</td>
	    <td>Pittsburgh</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 10, 2020, 10:08 p.m.</td>
	    <td>Reading</td>
	    <td>Worcester</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 10, 2020, 9:50 p.m.</td>
	    <td>Rochester</td>
	    <td>Niagara Falls</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/UAA">UAA</a></td>
            <td>Nov. 10, 2020, 9:49 p.m.</td>
	    <td>Portsmouth</td>
	    <td>Baltimore</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 10, 2020, 9:18 p.m.</td>
	    <td>Syracuse</td>
	    <td>Rochester</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 10, 2020, 8:40 p.m.</td>
	    <td>Montour Falls</td>
	    <td>Syracuse</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 10, 2020, 7:47 p.m.</td>
	    <td>Reading</td>
	    <td>Troy</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/UAA">UAA</a></td>
            <td>Nov. 10, 2020, 7:42 p.m.</td>
	    <td>Madison</td>
	    <td>Portsmouth</td>
          </tr>
	  
          
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/UAA">UAA</a></td>
            <td>Nov. 10, 2020, 5:47 p.m.</td>
	    <td>Dallas</td>
	    <td>Madison</td>
          </tr>
	  
          
	  
          
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/CP">CP</a></td>
            <td>Nov. 10, 2020, 4:18 p.m.</td>
	    <td>Calgary</td>
	    <td>Minneapolis</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/NEE">NEE</a></td>
            <td>Nov. 10, 2020, 4:17 p.m.</td>
	    <td>Milton</td>
	    <td>Belle Glade</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/NEE">NEE</a></td>
            <td>Nov. 10, 2020, 4:17 p.m.</td>
	    <td>Milton</td>
	    <td>Belle Glade</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 10, 2020, 4:10 p.m.</td>
	    <td>Westhampton Beach</td>
	    <td>Centreville</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 10, 2020, 4:10 p.m.</td>
	    <td>Westhampton Beach</td>
	    <td>Centreville</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/TGT">TGT</a></td>
            <td>Nov. 10, 2020, 4:09 p.m.</td>
	    <td>Dallas-Fort Worth</td>
	    <td>Minneapolis</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/TGT">TGT</a></td>
            <td>Nov. 10, 2020, 4:09 p.m.</td>
	    <td>Dallas-Fort Worth</td>
	    <td>Minneapolis</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/CNI">CNI</a></td>
            <td>Nov. 10, 2020, 4:03 p.m.</td>
	    <td>Toronto</td>
	    <td>Calgary</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/TGT">TGT</a></td>
            <td>Nov. 10, 2020, 3:19 p.m.</td>
	    <td>Dallas</td>
	    <td>Panama City Beach</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/TGT">TGT</a></td>
            <td>Nov. 10, 2020, 3:19 p.m.</td>
	    <td>Dallas</td>
	    <td>Panama City Beach</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/HUM">HUM</a></td>
            <td>Nov. 10, 2020, 3:12 p.m.</td>
	    <td>Louisville</td>
	    <td>Lutz</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/HUM">HUM</a></td>
            <td>Nov. 10, 2020, 3:12 p.m.</td>
	    <td>Louisville</td>
	    <td>Lutz</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 10, 2020, 3 p.m.</td>
	    <td>Syracuse</td>
	    <td>Riverhead</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 10, 2020, 3 p.m.</td>
	    <td>Syracuse</td>
	    <td>Riverhead</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/CNI">CNI</a></td>
            <td>Nov. 10, 2020, 2:51 p.m.</td>
	    <td>Montr√É¬©al</td>
	    <td>Toronto</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/CNI">CNI</a></td>
            <td>Nov. 10, 2020, 2:51 p.m.</td>
	    <td>Montr√É¬©al</td>
	    <td>Toronto</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/CTAS">CTAS</a></td>
            <td>Nov. 10, 2020, 2:45 p.m.</td>
	    <td>Indianapolis</td>
	    <td>Cincinnati</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/CTAS">CTAS</a></td>
            <td>Nov. 10, 2020, 2:45 p.m.</td>
	    <td>Indianapolis</td>
	    <td>Cincinnati</td>
          </tr>
	  
          
	  
          
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/BNS">BNS</a></td>
            <td>Nov. 10, 2020, 1:57 p.m.</td>
	    <td>Montr√É¬©al</td>
	    <td>Toronto</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/BNS">BNS</a></td>
            <td>Nov. 10, 2020, 1:57 p.m.</td>
	    <td>Montr√É¬©al</td>
	    <td>Toronto</td>
          </tr>
	  
          
	  
          
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 10, 2020, 1:21 p.m.</td>
	    <td>Livermore</td>
	    <td>San Diego</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 10, 2020, 1:21 p.m.</td>
	    <td>Livermore</td>
	    <td>San Diego</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/D">D</a></td>
            <td>Nov. 10, 2020, 1:16 p.m.</td>
	    <td>Akron</td>
	    <td>Ashland</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/D">D</a></td>
            <td>Nov. 10, 2020, 1:16 p.m.</td>
	    <td>Akron</td>
	    <td>Ashland</td>
          </tr>
	  
          
	  
          
	  
          
	  
          
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/TGT">TGT</a></td>
            <td>Nov. 10, 2020, 11:51 a.m.</td>
	    <td>Minneapolis</td>
	    <td>Dallas-Fort Worth</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/TGT">TGT</a></td>
            <td>Nov. 10, 2020, 11:51 a.m.</td>
	    <td>Minneapolis</td>
	    <td>Dallas-Fort Worth</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 10, 2020, 10:37 a.m.</td>
	    <td>Rochester</td>
	    <td>Syracuse</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 10, 2020, 10:37 a.m.</td>
	    <td>Rochester</td>
	    <td>Syracuse</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 10, 2020, 10:12 a.m.</td>
	    <td>Manassas</td>
	    <td>Reading</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 10, 2020, 10:12 a.m.</td>
	    <td>Manassas</td>
	    <td>Reading</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 10, 2020, 10:03 a.m.</td>
	    <td>Seattle</td>
	    <td>Chicago/Romeoville</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 10, 2020, 10:03 a.m.</td>
	    <td>Seattle</td>
	    <td>Chicago/Romeoville</td>
          </tr>
	  
          
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/RF">RF</a></td>
            <td>Nov. 10, 2020, 9:25 a.m.</td>
	    <td>Baltimore</td>
	    <td>Pinson</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/RF">RF</a></td>
            <td>Nov. 10, 2020, 9:25 a.m.</td>
	    <td>Baltimore</td>
	    <td>Pinson</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 10, 2020, 8:59 a.m.</td>
	    <td>Pittsburgh</td>
	    <td>Manassas</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 10, 2020, 8:59 a.m.</td>
	    <td>Pittsburgh</td>
	    <td>Manassas</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 10, 2020, 8:10 a.m.</td>
	    <td>Seattle</td>
	    <td>Livermore</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 10, 2020, 8:10 a.m.</td>
	    <td>Seattle</td>
	    <td>Livermore</td>
          </tr>
	  
          
	  
          
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 10, 2020, 7:44 a.m.</td>
	    <td>Independence</td>
	    <td>Pittsburgh</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 10, 2020, 7:44 a.m.</td>
	    <td>Independence</td>
	    <td>Pittsburgh</td>
          </tr>
	  
          
	  
          
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/BNS">BNS</a></td>
            <td>Nov. 10, 2020, 7:23 a.m.</td>
	    <td>Toronto</td>
	    <td>Montr√É¬©al</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/BNS">BNS</a></td>
            <td>Nov. 10, 2020, 7:23 a.m.</td>
	    <td>Toronto</td>
	    <td>Montr√É¬©al</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 10, ‚Ä¶</td></tr></tbody></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.quiverquant.com/sources/corporateflights?hn=">https://www.quiverquant.com/sources/corporateflights?hn=</a></em></p>]]>
            </description>
            <link>https://www.quiverquant.com/sources/corporateflights?hn=</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048723</guid>
            <pubDate>Tue, 10 Nov 2020 17:47:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The rev.ng decompiler nightly builds have been released]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25048645">thread link</a>) | @agiantleap
<br/>
November 10, 2020 | https://rev.ng/blog/the-road-ahead/post.html | <a href="https://web.archive.org/web/*/https://rev.ng/blog/the-road-ahead/post.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          

<p>In this blog post we will briefly describe today's release, provide an overview of the components of rev.ng and introduce you the next steps the rev.ng project intends to take towards the 1.0 release.</p>
<p>We are inviting small groups of people to get access to nightly builds.
If you already registered, be patient and monitor our <a href="https://twitter.com/_revng">Twitter account</a>. Otherwise, <a href="https://rev.ng/register-for-nightly.html">register now</a>.</p>
<h2>Nightly builds release</h2>
<p>Today, we start releasing nightly builds of all the rev.ng components including <code>revng</code> (binary lifter and translator), <code>revng-c</code> (the decompiler) and <code>cold-revng</code> (the user interface).</p>
<p>rev.ng is an ambitious project which took the long route in several aspects.
We think this will prove to be a winning strategy to build an innovative product.</p>
<p>We're now starting to see the end of the tunnel that leads us to become a mature tool for binary analysis, but we're not there yet.
Nightly builds are our way to invite you to join us along the last mile of the journey.</p>
<h3>What to expect</h3>
<p>rev.ng can currently handle binaries compiled for Linux targeting x86-64, i386, ARM, AArch64, MIPS and SystemZ.
Here's a few things you can do with the current release.</p>
<h4>1. Try out the UI using test files</h4>
<p>The package we distribute includes a set of pre-lifted files.
You can open them in the UI right away.</p>
<div><pre><span></span><span>EXAMPLES</span><span>=</span>root/share/revng/qa/tests/runtime/x86_64/abi-enforced-for-decompilation
./revng ui <span>$EXAMPLES</span>/calc.bc
</pre></div>
<video controls="controls" width="945">
<source src="https://rev.ng/downloads/calc.mp4" type="video/mp4">
</video>
          
          
            <h4>2. Lift, translate and run ls</h4>
<p>You can also give a try to the binary translator.
For instance, you can lift <a href="https://rev.ng/downloads/ls-ubuntu-16.04"><code>ls</code></a> to LLVM IR, recompile it, and run it again:</p>
<div><pre><span></span>wget <span>'https://rev.ng/downloads/ls-ubuntu-16.04'</span>
chmod +x ls-ubuntu-16.04
./ls-ubuntu-16.04 --color<span>=</span>always -lhn
./revng translate ls-ubuntu-16.04
./ls-ubuntu-16.04.translated --color<span>=</span>always -lhn
</pre></div>

<p>Please note that translation support for non-x86-64 input architectures is working but has some limitations.</p>
<h4>3. Decompile ls</h4>
<p>The rev.ng UI also provides a wizard for decompilation.</p>
<video controls="controls" width="945">
<source src="https://rev.ng/downloads/ls.mp4" type="video/mp4">
</video><h3>What not to expect</h3>
<p>The builds are to be considered unstable and under heavy development, therefore keep in mind to:</p>
<ol>
<li>read the <code>README.md</code>
</li>
<li>perform frequent updates</li>
<li>expect suboptimal decompiled code and crashes</li>
<li>report anything unexpected/slow</li>
<li>expect rapid improvements</li>
</ol>
<p>For those, who have access to the nightly builds, the <a href="https://github.com/revng/help">revng/help</a> repository will contain a shortlist of known issues we're working on.</p>
<h2>Overview of the rev.ng components</h2>
<p>rev.ng is divided in several components, some of them are open source.</p>
<p>Let's start with the ones we forked from existing projects:</p>
<ul>
<li>
<code>qemu</code>: our fork provides a dynamic library able to produce tiny code instructions from a raw sequence of bytes.</li>
<li>
<code>llvm</code>: our LLVM 10 fork with minor changes.</li>
<li>
<code>qtcreator</code>: the base of our UI.</li>
</ul>
<p>The following projects are the open source parts of the rev.ng project:</p>
<ul>
<li>
<code>revng</code>. The core of rev.ng: the binary lifter and translator. Given a binary program, it lifts to tiny code instructions and then to LLVM IR. Produces an LLVM module, and, optionally recompiles it.</li>
<li>
<code>orchestra</code>. Our almighty meta-build system. It handles all the dependencies for you, fetches them from our binary archives or builds them from source. Don't try to build rev.ng by yourself, use <code>orchestra</code>.</li>
<li>
<code>revng-qa</code>. A repository for our test programs.</li>
</ul>
<p>The following projects will be released under a commercial license and are currently released as binaries only:</p>
<ul>
<li>
<code>revng-c</code>. Takes <code>revng</code> output and decompiles it to C.</li>
<li>
<code>caliban</code>. A project providing an API to perform high-level actions on binaries, on top of which the UI and, in the future, our scripting engine are built.</li>
<li>
<code>cold-revng</code>. The UI, a QtCreator plugin.</li>
</ul>
<h2>Roadmap towards the release</h2>
<p>In the following, we report a list of tasks to accomplish and components to develop/finalize in order to get to the final release.
You can expect one or more blog posts or some other form of publication for each item.</p>
<ul>
<li>
 Release the nightly builds</li>
<li>
 Create a <a href="https://github.com/revng/help">GitHub repository</a> to support nightly builds' users</li>
<li>
 Completely move the development of open source projects to GitHub</li>
<li>Requirements for tagging the beta:<ul>
<li>
 CFG combing</li>
<li>
 Improved ABI Analysis</li>
<li>
 Type Shrinking Analysis</li>
<li>
 Data Layout Analysis</li>
<li>
 Value Manipulation Analysis</li>
<li>
 Define a <em>data model</em> for the analyzed program and how to change it</li>
<li>
 Identify libraries using strings (BigMatch)</li>
<li>
 Full PE/COFF and Mach-O support</li>
</ul>
</li>
<li>Requirements for tagging the 1.0 release:<ul>
<li>
 Improve UI/UX</li>
<li>
 Python scripting engine</li>
<li>
 Windows and macOS port</li>
<li>
 Import C headers and debug information</li>
<li>
 Compatibility layer</li>
<li>
 Support for packers/self-modifying code</li>
<li>
 Support remote processing</li>
</ul>
</li>
</ul>
<h2>Conclusions</h2>
<p>We'd like to thank everyone who is participating in the nightly builds programme.
Your feedback will help us along the way towards the final release.</p>
<p>Releasing nightly builds, along with switching to a fully open air development of the open source components, is part of our effort to spread the word and collect feedback.
Our ultimate goal is to build a robust community to engage with and to grow a flourishing ecosystem of software based on rev.ng binary analysis framework.</p>
<p>Also, a shout-out to all those who put their hard work in order to make this first public release finally possible, in particular Pietro, <a href="https://twitter.com/carpikes">Alain</a>, <a href="https://twitter.com/fcremo">fcremo</a> and Andrea, but also all the others who contributed to spot bugs and share their opinions.</p>
<p>We hope you're excited as we are.
Enjoy!</p>
          
        </div></div>]]>
            </description>
            <link>https://rev.ng/blog/the-road-ahead/post.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048645</guid>
            <pubDate>Tue, 10 Nov 2020 17:42:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linus Torvalds' Home Office [YouTube]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25048457">thread link</a>) | @bojanvidanovic
<br/>
November 10, 2020 | https://devandgear.com/posts/linus-torvalds-home-office/ | <a href="https://web.archive.org/web/*/https://devandgear.com/posts/linus-torvalds-home-office/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p>When it comes to computer setups, there is one that always comes to my mind,
the setup of Linus Torvalds in the famous YouTube video <strong>‚ÄúLinus Torvalds Guided
Tour of His Home Office‚Äù</strong>. The video is from 2014 with almost 300k views, and
his home office probably changed until now, but interestingly it gives
a glimpse of how one of the most influential figures in the open-source
community works.</p>
<p>One would have imagined multiple <a href="http://localhost:1314/products/categories/monitors/">monitors</a> connected together, with a bunch of
computers, and everything perfectly organized. But that‚Äôs not a case here,
Linus getting done his work on a medium-sized Dell monitor set on a walking
desk. I wasn‚Äôt expecting to see a walking desk, they are very rare to be seen,
but in theory, they are healthier than a standing desk that keeps you in
a static position. If you already own a standing desk, you can add a walking
pad to it like this <a href="https://amzn.to/38t9Ll8">one</a>, and make it a walking desk. Aside from that everything
else seems pretty normal, a clean productive space.</p>
<p>That is one side of the office, the other side of his office is a bit messy
with a bunch of hardware stacked one on top of each other, which he admits it‚Äôs
probably best to burn.</p>
<p>I‚Äôd like to see the evolution of Linus‚Äôs office, but if you don‚Äôt know he is
a very reserved person, so it will be hard. Anyway, if you haven‚Äôt seen the
video, here is the link and enjoy it.</p>



        </div></div>]]>
            </description>
            <link>https://devandgear.com/posts/linus-torvalds-home-office/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048457</guid>
            <pubDate>Tue, 10 Nov 2020 17:26:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Burnout can exacerbate work stress, further promoting a vicious circle]]>
            </title>
            <description>
<![CDATA[
Score 300 | Comments 201 (<a href="https://news.ycombinator.com/item?id=25048455">thread link</a>) | @rustoo
<br/>
November 10, 2020 | https://www.uni-mainz.de/presse/aktuell/12451_ENG_HTML.php | <a href="https://web.archive.org/web/*/https://www.uni-mainz.de/presse/aktuell/12451_ENG_HTML.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
            <!-- Hier kommen Imagescroller und ZGN, sowie... -->
            <!-- Offene Universit√§t Scroller --><!-- Default Row -->
            <!-- Spaltenlayout gem√§√ü Einstellungen f√ºr option_schalter_linke_spalte, option_schalter_rechte_spalte -->
            <!-- Ende linke Spalte -->
            <article id="spaltemitte">
               <!-- Beginn Inhalt Spalte Mitte -->
               <!-- Index√ºberschrift:  -->
               <h3>
                  Work stress and burnout are mutually reinforcing / Surprisingly, the effect of work stress on burnout is much smaller than the effect of burnout on work stress
               </h3>
               <p>
                  10 November 2020
               </p>
               <p>
                  Stress and overload in the workplace are increasing worldwide and are often considered a cause of burnout. Indeed, a new study shows that work stress and burnout are mutually reinforcing. However, contrary to popular belief, burnout has a much greater impact on work stress than vice versa. "This means that the more severe a person's burnout becomes, the more stressed they will feel at work, such as being under time pressure, for example," said Professor Christian Dormann of Johannes Gutenberg University Mainz (JGU). Employees suffering from burnout should be timely provided with adequate support in order to break the vicious circle between work stress and burnout.
               </p>
               <p>
                  Symptoms of burnout include exhaustion, cynicism, and reduced performance. "The most important burnout symptom is the feeling of total exhaustion ‚Äì to the extent that it cannot be remedied by normal recovery phases of an evening, a weekend, or even a vacation," said Dormann. "To protect themselves from further exhaustion, some try to build a psychological distance to their work, that is, they alienate themselves from their work as well as the people associated with it and become more cynical," added Dr. Christina Guthier. She conducted the study as part of her doctoral thesis in Dormann's research group and was awarded with the dissertation prize of the Alfred Teves Foundation in 2020. The study has recently been published in <em>Psychological Bulletin</em>.
               </p>
               <p>
                  For the joint publication with Professor Christian Dormann and Professor Manuel V√∂lkle of Humboldt-Universit√§t zu Berlin, Christina Guthier evaluated 48 longitudinal studies of burnout and work stress comprising 26,319 participants. The average age in the initial survey was about 42 years, 44 percent of the respondents were men. The longitudinal studies from 1986 to 2019 came from various countries, including predominantly European countries as well as Israel, the USA, Canada, Mexico, South Africa, Australia, China, and Taiwan.
               </p>
               <h4>
                  Stopping the downward spiral and reducing the effect of burnout on work stress
               </h4>
               <p>
                  The results challenge, or at least relativize, the common perception that work stress is the driving force behind burnout. "Burnout can be triggered by a work situation, but that is not always the case," Dormann pointed out. Once burnout begins, it develops only very gradually, building up slowly over time. Ultimately it leads to work being increasingly perceived as stressful: The amount of work is too much, time is too short, and work stress is too great. "When exhausted, the ability to cope with stress usually decreases. As a result, even smaller tasks can be perceived as significantly more strenuous," explained Guthier, the first author of the article. "We expected an effect of burnout on work stress; the strength of the effect was very surprising," she noted. The effect of burnout on perceived work stress can be somewhat mitigated if employees have more control over their own work and receive support from colleagues or superiors.
               </p>
               <p>
                  According to Dormann, a new research area is emerging on the basis of this unique data because the strong boomerang effect of burnout on work stress has not yet been investigated. Key questions that need to be addressed are: how can the effects of burnout on perceived work stress be reduced and how can the development of this vicious circle be prevented? Dormann and Guthier suggest that the place to start is with management behavior. Employees should have the opportunity to give feedback on their work stress at any time and be appreciated. Last but not least, proper recovery could also help to stop the downward spiral.
               </p><!-- Ende Inhalt Spalte Mitte -->
            </article>            <!--Ende-->
                     </div></div>]]>
            </description>
            <link>https://www.uni-mainz.de/presse/aktuell/12451_ENG_HTML.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048455</guid>
            <pubDate>Tue, 10 Nov 2020 17:25:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is it time to modernize the PostgreSQL Core Team?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25048426">thread link</a>) | @MarkusWinand
<br/>
November 10, 2020 | https://postgresql.fund/blog/is-it-time-to-modernize-postgresql-core/ | <a href="https://web.archive.org/web/*/https://postgresql.fund/blog/is-it-time-to-modernize-postgresql-core/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        <div>
            <div>
                
                <div>
                    
<p>The PostgreSQL Community is large, diverse and global. There are users, enthusiasts, developers, contributors, advocates and commercial entities from around the world. All of them working in a loosely collaborative fashion to grow and make PostgreSQL succeed.</p>
<p>The Postgres Core Team is considered to be the steering committee for the Community. The definition of the group responsibilities can be <a href="https://www.postgresql.org/developer/core/">found here</a>. The core team members are listed on the <a href="https://www.postgresql.org/community/contributors/">Contributor Profiles</a> page.</p>
<p>On September 30th EnterpriseDB acquired 2ndQuadrant. At the time of the acquisition there were five members in Core; two of them were EnterpriseDB employees and another one a 2ndQuadrant employee. This meant that 60% of the Core members would be employed by EnterpriseDB. On October 20th, in an effort to diffuse concerns about a single commercial entity having majority control, the <a href="https://www.postgresql.org/about/news/statement-from-the-postgresql-core-team-on-the-edb-acquisition-of-2ndquadrant-2094/">Core Team announced</a> that this is an issue that they would be addressing:</p>
<p>‚Äú<em>There has long been an unwritten rule that there should be no more than 50% of the membership of the Core Team working for the same company</em>‚Äù</p>
<p>This rule was enacted back in the days of the <a href="https://www.postgresql.org/message-id/39181CCD.99531ADA@greatbridge.com">Great Bridge</a>. Core addressed the unwritten rule by appointing on November 2nd <a href="https://www.postgresql.org/about/news/new-postgresql-core-team-members-2103/">two new members: Andres Freund and Jonathan Katz</a>. This change in Core reduced the proportion of EnterpriseDB members to three out of seven. <strong>Fundaci√≥n PostgreSQL</strong> would like to extend a very warm welcome to Andres and Jonathan. They are both well known and long time community contributors.</p>
<p>The addition of the new members allowed Core to be compliant with the 50% rule. However: was this organizational change the best choice? Was it the only change that could have been implemented? Could we have looked at the culture of our global community and used this opportunity to strengthen our ties?</p>
<p>Here are some facts about Core‚Äôs structure and membership:</p>
<ul>
<li><strong>Company influence</strong>:
<ul>
<li>Core has switched from having 40% of its members from a single company to now having 43% from a single company and 71% from two companies.</li>
<li>100% of the members are from only 4 companies.</li>
</ul>
</li>
<li><strong>Diversity</strong>:
<ul>
<li>100% of the current Core team members are white men.</li>
<li>All of the Core members are either US or European. No other region is represented.</li>
<li>All but one Core member work for US companies.</li>
</ul>
</li>
<li><strong>Democracy:</strong>
<ul>
<li>Core members are only appointed by existing Core members. In contrast, the ‚Äú<a href="https://www.postgresql.org/community/recognition/#npos">Recognised Postgres Nonprofit Organisations</a>‚Äù (created and enforced by Core) has as a requirement that the ‚Äú<em>board of directors MUST be elected by the membership</em>‚Äù. These rules were, in turn, created by Core itself.</li>
<li>Core members serve for an <em>unlimited</em> term. In contrast, the same Community recognition rules above also require that ‚Äú<em>Lifetime directorships MUST NOT be allowed</em>‚Äù. Four of the current Core members <a href="https://web.archive.org/web/20051023004218/http://www.postgresql.org/developer/bios">have been serving in the Core team for more than 15 years</a>.</li>
</ul>
</li>
<li><strong>Transparency</strong>:
<ul>
<li>The election process, candidate selection, selection criteria, etc are all secret.</li>
<li>Core Team meeting minutes are secret.</li>
<li>Core team policies are enacted by declaration, without involvement of the global community.</li>
</ul>
</li>
</ul>
<p>Facts aside, there are some organizational concerns that may require some further analysis.</p>
<p>In the PostgreSQL distributed community, the <a href="https://www.postgresql.org/developer/core/">Core Team</a> acts as the <em>de facto</em> ‚Äúcentral authority‚Äù for the project. The <a href="https://www.postgres.ca/">Postgres Association of Canada</a> (‚ÄúCA‚Äù, in short), acts as its legal arm, holding assets (including intellectual property, like domain names and trademarks).</p>
<p>However, this presents an interesting dichotomy: Core makes decisions, but if these require a legal entity to be executed, they are executed by CA. Which has its own board of directors, that needs to approve them. What if they don‚Äôt? What if they don‚Äôt follow Core? Similarly, how is Core accountable, if it is not backed directly by a legal entity? Because of this, are there any potential liabilities faced directly by their members, as individuals? And what happens if CA‚Äôs Board goes haywire?</p>
<p>Other mature and successful open source projects, while distributed as Postgres and built from the contributions of people and organizations all around the world, are nowadays backed by clear and strong legal and organizational structure. Take for example the <a href="https://www.apache.org/foundation/">Apache Foundation</a>, or the <a href="https://www.fsf.org/working-together/fiscal-sponsorship">Free Software Foundation</a>. Or the <a href="https://www.cncf.io/">Cloud Native Computing Foundation (CNCF)</a>, which is a Charter of the Linux Foundation. Its structure <a href="https://www.cncf.io/blog/2019/12/06/cncf-toc-governance-structure-elections-2020/">has three main bodies</a>:</p>
<p>‚Äú<em>A <strong>Governing Board (GB)</strong> that is responsible for marketing, budget and other business oversight decisions for the CNCF, a <strong>Technical Oversight Committee (TOC)</strong> that is responsible for defining and maintaining the technical vision, and an <strong>End User Community (EUC)</strong> that is responsible for providing feedback from companies and startups to help improve the overall experience for the cloud native ecosystem</em>‚Äù</p>
<p>The <a href="https://www.cncf.io/people/governing-board/">Governing Board has currently 24 members</a>, and their <a href="https://www.cncf.io/about/governing-board-meeting-minutes/">meeting minutes are public</a> (they are not alone: MariaDB Foundation <a href="https://mariadb.org/bodminutes/2020-10-21/">is now publishing their board meetings too</a>); the <a href="https://www.cncf.io/people/technical-oversight-committee/">Technical Committee consists of 11 members and 77 contributors</a>; the <a href="https://docs.google.com/presentation/d/194SyKdHL7ws_DBOdbrXdowEJi54kIzDdDK_h-6Ag0uo/edit#slide=id.g9ffb40d42b_0_161">End User Community has more than 150 companies</a>; furthermore, there are dozens of <a href="https://www.cncf.io/people/ambassadors/">ambassadors</a>; and also dozens of <a href="https://www.cncf.io/people/staff/">staff</a> members. While possibly operating at a different scale than PostgreSQL, they all contribute, in different manners, to the steering, development and vision of the CNCF.</p>
<p>What do you think? <strong>Is PostgreSQL Core today what the PostgreSQL Community needs, or is it time to modernize its processes, structure and governance?</strong> If you think it is the latter, please leave your comments below. I hope this post serves as the starting point for a broader and constructive discussion that can serve as feedback to Core. Let‚Äôs ensure the best future for our beloved open source database!</p>

                </div>
                
                    
                
            </div>
        </div>
    </div>
</section></div>]]>
            </description>
            <link>https://postgresql.fund/blog/is-it-time-to-modernize-postgresql-core/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048426</guid>
            <pubDate>Tue, 10 Nov 2020 17:22:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avo's Ultimate Tracking Plan Template (With Downloadable Worksheet)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25048395">thread link</a>) | @kelseyfecho
<br/>
November 10, 2020 | https://www.avo.app/blog/avos-ultimate-tracking-plan-template-w-downloadable-worksheet | <a href="https://web.archive.org/web/*/https://www.avo.app/blog/avos-ultimate-tracking-plan-template-w-downloadable-worksheet">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>We talked in depth about <em>why</em> you need a tracking plan in our<a href="https://www.avo.app/blog/our-definitive-guide-to-tracking-plans"> definitive guide to tracking plans</a>; now, we‚Äôll break down the awesome tracking plan template we created for you, so you‚Äôre ready to implement better product analytics via your tool of choice (possibly Avo üòâ).</p><p>But before we dive in, here‚Äôs a quick refresher on what a tracking plan is (you may recognize this from our<a href="https://www.avo.app/blog/our-definitive-guide-to-tracking-plans"> definitive guide to tracking plans</a>):</p><p><em>A tracking plan is a document that defines the key stages of your customer life cycle and codifies a single source of truth for the data that supports it. It helps you standardize your data management and capture better and cleaner data.</em></p><p>As part of your tracking plan, you‚Äôll need to outline the events and properties relevant to your goals, explain where in your codebase tracking code should be placed, and provide context for why you‚Äôre tracking what you are.</p><p>While each of the elements of your tracking plan will be as unique to your business as your product is to your market, you can save admin time up front by using a tracking plan template. There are dozens floating around the internet, so we went ahead and created our üéâUltimate Tracking Plan Template üéâ that pulls together the 10 elements you absolutely must have. Use this template to spend less time researching how to make your tracking plan and more time using it.</p><h2><strong>What makes a good tracking plan?</strong></h2><p>Your tracking plan should include events and properties that help you understand your customers‚Äô behavior and measure progress through your sales funnel and customer journeys so you can see how well your features are meeting customer needs. It shouldn‚Äôt aim to measure every drop of data under the sun‚Äîjust those that are most important to you.</p><p><em>For the full breakdown of how to find the events and properties that mirror your customer journey, check out</em><a href="https://www.avo.app/blog/our-definitive-guide-to-tracking-plans"><em> our full guide on tracking plans</em></a><em>, and then meet us back here.</em></p><p>To get a full picture of your customers‚Äô behaviors and experiences, you‚Äôll need a mix of both <strong>qualitative metrics</strong> (the kind that reflect user sentiment) and <strong>quantitative metrics</strong> (the kind that reflect user actions).</p><p>Your tracking plan will focus on quantitative metrics. That's because it's possible to objectively measure whether an action happened. But it‚Äôs equally important that your sales and product teams reach out to customers and users via surveys, social media, and reviews to get qualitative data to complement your tracking plan.</p><h2><strong>The 10 key elements of your tracking plan</strong></h2><p>We have a lot of experience helping folks build killer tracking plans (and we‚Äôve seen a lot of great examples of tracking plans from other companies, too). When we sat down and pulled from our experience‚Äîand the experiences of others‚Äîwe noticed there were <strong>10 key elements</strong> that every great tracking plan included.</p><h3><strong>1. KPIs</strong></h3><figure id="w-node-530d128e532a-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8da57e1d363a3d9b0b_zFsYVY341ROFEJtzHTqKjGUl5B--qn1HOpQJveWLNR_qPh-UsdTVUqGCRatRYI8S9Y4z4ZM3U7bm__KHLqPCOEYSYsO-dvIwiyB57Y4sU1_D481F9IvaSCLtb9v687GfNMss5BvN.png" alt=""></p></figure><p>‚Äç</p><p>Each event you track should tie directly to a business-end key performance indicator (KPIs) that affects your success, so you can easily reference the tie-in between metrics tracked and their real-world value.</p><p>These KPIs will change depending on your company maturity, product, and business strategy, but here are some examples:</p><ul role="list"><li>Signup funnel&nbsp;</li><li>Retention from signup to playing game&nbsp;</li><li>Monthly new signups&nbsp;</li></ul><p>This first section is what will give any business-end stakeholders the context they need to understand how the tracking plan ties into a wider strategy.</p><h3><strong>2. Event categories</strong></h3><figure id="w-node-4acb0f34daaa-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8d25d6db8b075c10f4_DU2hKDTJVw5geaQSvCWdZyykuvO9nbgj3zRVCYZgG8Lv3eAKNBRShY9_R0XpxJ7hY0KcAPgHKukstUyxK-n7mC_UQxJ622J3GsS01LFzSXbnwPWfZHkuQzvcdYcsKibJImCc9_us.png" alt=""></p></figure><p>‚Äç</p><p>Your tracking plan should break down events tracked by macro category‚Äîtypically reflecting the different kinds of KPIs you‚Äôve set‚Äîso you can keep track of each segment of customer success.</p><p>Like all things on this list, the kinds of events you‚Äôll track will depend on your goals and use case, but here are a few examples:</p><ul role="list"><li>Authentication&nbsp;</li><li>Gameplay</li><li>Tournaments&nbsp;</li><li>Navigation</li></ul><p>Once you‚Äôve set the broad categories of events you care about, you can drill down and decide on the specific events and properties within each category.</p><h3><strong>3. Event names</strong></h3><figure id="w-node-187250f1dc30-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8fd082e416a91e7b79_TcJUo78HcU3SgDp2OEbWGP1kUdEwnKRCNvMBKYg3wctbFjMTcyr37VzBXFtiVQWmIzikz_XIAvHu1iL17HcPDyLiWG7H_R6DDMCDUPGrvJsQ1cShwvQ6qauCwydT-pFzwUMWaAKM.png" alt=""></p></figure><p>‚Äç</p><p>Your tracking plan should include one row for each event name (each of which will have rows for child properties). Additionally, each of your events should be <a href="https://www.avo.app/docs/best-practices/defining-descriptive-events-and-properties#a-namenaming-conventionsa-naming-conventions-for-events-and-properties">named in a consistent way</a> that‚Äôs in line with your agreed-on naming schema. This structure makes it easy for anyone to quickly scan and understand what events you‚Äôre tracking.</p><p>Your event names will depend on the kinds of events you‚Äôre tracking and on your naming schema. Within the categories we outlined above, some possible event names could include the following:</p><ul role="list"><li>Signup Started&nbsp;</li><li>Signup Completed&nbsp;</li><li>Login Completed&nbsp;</li><li>Game Started&nbsp;</li><li>Game Completed&nbsp;</li></ul><p>Note how each of these event names shares the same tense (past tense) and capitalization. This isn‚Äôt just to make your template look pretty; it makes everything easier to understand.</p><h3><strong>4. Event description</strong></h3><figure id="w-node-1dc7d6600a1b-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8e862fad531128fb1f_tHQLNeHbz4xZgGQ3UDyoKeIlRgTnEAInfIqB5SPwyCVGMzW8Is3gsevwEqNtDkAoBbEBFjggi_w5pBtynvHVoB1a16Hr9qE1EGK1uGG-zs0g3pTwRCeDDNhmWt_ZEK0yFUaBGhAk.png" alt=""></p></figure><p>‚Äç</p><p>Your tracking plan should include a clear description for each event, including the event source (where the action is taking place) and <a href="https://www.avo.app/docs/best-practices/defining-descriptive-events-and-properties#a-namedescriptionsa-descriptions-for-events-and-properties">any additional context of when and why the event happens</a>. That makes it easy for anyone looking at your template to quickly understand what the event is tracking.</p><p>Your event descriptions should be no longer than one or two sentences and should clearly and concisely explain what it is you‚Äôre measuring (and when). Let‚Äôs assume that we‚Äôre measuring the event ‚ÄúGame Completed.‚Äù Our description for this event might be:</p><p><em>Event sent when a user has successfully completed a game.&nbsp;</em></p><p>Creating consistent descriptions for each of your events will make it easy for anyone using your tracking plan to gain the context they need to interpret your data.</p><h3><strong>5. Properties</strong></h3><figure id="w-node-333264b27c1d-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8ee33289892753ad21_3EYStOV5VQlQYeGzMJPyMOp8QzHD8qKyZdFUxZp4ZAmQBmsKtm5gRQ-X1wUejDhl0AQRr2yjQ8F9uv4-0v-WDSn3lJJ5irFTq_c-S229dgHG8M9ts_0w0vdaSl4WAc4VMHbXMyIe.png" alt=""></p></figure><p>‚Äç</p><p>For each event, you should include a full breakdown of its attached properties, with one row per property‚Äîagain, all named consistently‚Äîso you can easily see which properties are being tracked for a given customer action.</p><p><em>Bonus: You should also define your property groups (these can be spaced across event groups) so you can easily see what kind of user behaviors you‚Äôre tracking.</em></p><p>It can be easy to let <a href="https://www.avo.app/docs/best-practices/defining-descriptive-events-and-properties#properties">naming conventions for properties</a> slide, but ensuring that each property follows your schema will prevent data collection and compilation errors down the road. Let‚Äôs say we‚Äôre measuring gameplay events, particularly the ‚ÄúGame Completed‚Äù event we identified above. We might track the following properties:</p><ul role="list"><li>Game Mode&nbsp;</li><li>Game Count&nbsp;</li></ul><p>Each of these properties will tell us whether or not a specific user action was completed (e.g., ‚ÄúGame Mode‚Äù tells us the mode of the game the user played and ‚ÄúGame Count‚Äù tells us how many games the user has completed).&nbsp;&nbsp;</p><h3><strong>6. Property description</strong></h3><figure id="w-node-7f23661ce86e-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8dda8f2787d81a87d7_SRKyGBFh80amOWqLYm4bzJbJVTRc8dPooGC5elZjp7LEHi4ATelWDMowhRa3Jx0RdpBp68K52pDCGMe6smASuB6iYRY0gTZ1klOETv6ue1imXwlaJkmpuLJyd_AYaq2jfgNAcKEd.png" alt=""></p></figure><p>‚Äç</p><p>Your tracking plan should include a clear description for each property so that any user can understand what the property is tracking and where the data is coming from.</p><p>Just like your event descriptions, your property descriptions should fill a column to the right of your property names and <a href="https://www.avo.app/docs/best-practices/defining-descriptive-events-and-properties#properties-1">clearly and concisely describe what each property measures</a>.</p><p>For example, if we‚Äôre tracking how many games players complete during their session, we may track a property called ‚ÄúGame Count‚Äù. Our description of this property might look something like this:</p><p><em>The number of games a player has completed when this event is sent. Including the game that was just completed on Game Completed.&nbsp;</em></p><p>This extra context will help anyone looking at your tracking plan make sense of all your properties.</p><h3><strong>7. Property value types</strong></h3><figure id="w-node-a7b247d39bb4-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8d4c3a92f224aa4e6d_P3Be8oQWJnz8WdmT5_PSPQpWy7JYNkUaweT8IWfUYFgC1Q7-zXGDT9kMMAKYc8Uo4g3K1E9F_4rhTIBRdSM_-wcGvRH2H_Sm7F3YhG-stRmHQU4jtRpScWITAVLZzg00buHIrHz8.png" alt=""></p></figure><p>‚Äç</p><p>Each property within your tracking plan will collect a different data type. These types should be explicitly laid out so developers implement across codepaths and platforms consistently. This also helps your data analysts know what to expect from the tracking analytics code output.&nbsp;</p><p>This is one of the few sections of your tracking plan that will not greatly vary. Instead, the data in this column should include these common data types:</p><ul role="list"><li>int</li><li>floating-point number</li><li>boolean</li><li>string</li><li>datetime</li><li>a list of any of the data types above&nbsp;</li></ul><p>When you formally identify these data types for each of your events and properties, you help your developers avoid coding errors that will impact data compilation down the line.</p><h3><strong>8. Platforms</strong></h3><figure id="w-node-27beb698434d-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8d3e80f7aef4929f6c_uE8HThZK-UHSz_XorkNrq5sj8lGQP5dYoD4Tr4jWi33Ky80JvVP_6wti3UGVtB1K4F2760jlQbO9zeYsK9CwjN94Yu-J93rG7TpLDpWKGWAy03pkK3tnB24ITLqB2vjPxz5-3u2W.png" alt=""></p></figure><p>‚Äç</p><p>For each property, you should note what platform the data is coming from so you can keep track of which applications contribute what information to your dataset.</p><p>This will depend on the development platforms you use and how your codebase is structured. But here‚Äôs a general outline of some of the platforms you may need to think about:</p><ul role="list"><li><strong>For web: </strong>JavaScript, TypeScript or Reason</li><li><strong>For mobile (generally): </strong>React Native or Expo or Flutter for iOS and Android apps</li><li><strong>For mobile (Android): </strong>Java or Kotlin&nbsp;</li><li><strong>For mobile (iOS):</strong>Swift or Objective C&nbsp;</li><li><strong>For backend: </strong>one or more backend sources (depending on number of programming languages and micro services)&nbsp;</li><li><strong>For game engines: </strong>Unity</li></ul><p>Including this breakdown of platforms that contribute data to your app will ensure that developers know where to implement tracking analytics across the board, and you won‚Äôt forget about any key components of your product.</p><h3><strong>9. Status</strong></h3><figure id="w-node-1697c41ba975-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8ee332892c4253ad22_Kjv8rek4cO-Y02kJmcgee0I4Wm5Qy2WxefQzbBeqQCf3nuMUA8hYuAKJUYL7Oi2Dpx-5VBZP88VKAWdwnxGdvugItvH_SoBxIOHrdTTofdp35s9GE_gqsGI-6qXl77A2pJn1Ahnh.png" alt=""></p></figure><p>‚Äç</p><p>This is a really important one: Your tracking plan must indicate the status of each step of tracking analytics implementation. This ensures that your team--and your tracking plan stakeholders--have a clear understanding of what work has been completed, what needs review, and what is in testing.&nbsp;</p><p>For example, let‚Äôs say you‚Äôre tracking events and properties related to your login authentication method. You‚Äôll need to note when that analytics code is ready for review and testing so your developers know that it‚Äôs not ready to ship, and don‚Äôt prematurely launch what could be a buggy bit of code.&nbsp;</p><h3><strong>10. Code snippet</strong></h3><figure id="w-node-9cafc5601453-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8ee3ef37d419b6f69b_sBOY_kvaTx5H_ds77RHPB7lR0xEDQ1MZL4SAWDVD5ICI4O8FvrD30dNhnEfq8Xv7_1B3HOclQUWqkXmuE6RquaNN3YLNxcOSTa4jNGV4gNcLxwEZz-cg_eYd9FNk_amDfkjxjR9N.png" alt=""></p></figure><p>‚Äç</p><p>Finally, your tracking plan should include your tracking code for each event and property that needs to be tracked so that your developers can easily place it into the correct spot without naming-convention or syntax errors.</p><p>If you‚Äôre doing this manually with a spreadsheet alone‚Äîinstead of using a tool, like Avo, that can house your implementation code and send it directly to developers‚Äîthis section can get a little lengthy.</p><p>By explicitly giving the code for each property, you reduce the likelihood of ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.avo.app/blog/avos-ultimate-tracking-plan-template-w-downloadable-worksheet">https://www.avo.app/blog/avos-ultimate-tracking-plan-template-w-downloadable-worksheet</a></em></p>]]>
            </description>
            <link>https://www.avo.app/blog/avos-ultimate-tracking-plan-template-w-downloadable-worksheet</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048395</guid>
            <pubDate>Tue, 10 Nov 2020 17:21:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The investor's approach to Machine Learning projects]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25048341">thread link</a>) | @louisdorard
<br/>
November 10, 2020 | https://www.louisdorard.com/blog/investors-approach-to-machine-learning-projects | <a href="https://web.archive.org/web/*/https://www.louisdorard.com/blog/investors-approach-to-machine-learning-projects">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-5f6cb338b8f7ec6492e30cbb" data-item-id="5f6cb338b8f7ec6492e30cbb">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1600960584781" id="item-5f6cb338b8f7ec6492e30cbb"><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1602690482673_47350"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5206b718e4b0bdc26006bae2/1602692107760-K7GPOSWKXO3UDNCKC6QQ/ke17ZwdGBToddI8pDm48kLkXF2pIyv_F2eUT9F60jBl7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iyqMbMesKd95J-X4EagrgU9L3Sa3U8cogeb0tjXbfawd0urKshkc5MgdBeJmALQKw/keenan-constance-VTLcvV6UVaI-unsplash.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5206b718e4b0bdc26006bae2/1602692107760-K7GPOSWKXO3UDNCKC6QQ/ke17ZwdGBToddI8pDm48kLkXF2pIyv_F2eUT9F60jBl7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iyqMbMesKd95J-X4EagrgU9L3Sa3U8cogeb0tjXbfawd0urKshkc5MgdBeJmALQKw/keenan-constance-VTLcvV6UVaI-unsplash.jpg" data-image-dimensions="2500x1667" data-image-focal-point="0.5,0.5" alt="Photo by  Keenan Constance  on  Unsplash" data-load="false" data-image-id="5f872409ba7a483b51f2165d" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5206b718e4b0bdc26006bae2/1602692107760-K7GPOSWKXO3UDNCKC6QQ/ke17ZwdGBToddI8pDm48kLkXF2pIyv_F2eUT9F60jBl7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iyqMbMesKd95J-X4EagrgU9L3Sa3U8cogeb0tjXbfawd0urKshkc5MgdBeJmALQKw/keenan-constance-VTLcvV6UVaI-unsplash.jpg">
          </p>
        
          
        

        
          
          <figcaption>
            
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1601637086178_13362"><div><p>How do you set Machine Learning projects for success?</p>
<p>There are many opportunities to create value with ML: increasing productivity, avoiding undesirable events, automating repetitive tasks... But there are also many sources of cost and uncertainty. ML projects can feel like games of poker: you need to pay to see if you've got a winning idea, and you should avoid going all-in without strong odds in your favor!</p>
<p>How can you <strong>figure out your odds</strong>, <strong>maximize chances of success</strong>, and <strong>minimize costs</strong>? By thinking like an investor! Here are 9 steps:</p>
<ol>
<li>Write the plan</li>
<li>Conduct customer/user studies</li>
<li>Set up Proof of Value with simulations and AutoML</li>
<li>Invest in data to increase performance</li>
<li>Shadow-deploy a Minimum Viable Product</li>
<li>Update model with new data</li>
<li>Canary-test and monitor</li>
<li>Invest in larger-scale deployment</li>
<li>Increase value / generate new value</li>
</ol>
</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1601637086178_34141"><div><p>When starting a new business, you‚Äôd use the business model canvas. For ML projects, use the <a href="https://www.louisdorard.com/machine-learning-canvas">ML Canvas</a>. It helps connect a value proposition to a prediction problem, identify bottlenecks, anticipate costs, and define the desired performance level.</p>
<p>Here are some questions you'll need to answer:</p>
<ul>
<li>Which value are you proposing, for which end-user?</li>
<li>Which prediction problem are you targeting?</li>
<li>How are you turning predictions into the proposed value? (Tip: ask yourself "what would I do if I already had a perfect model?")</li>
<li>How are you changing the end-user workflow?</li>
<li>How will you monitor the impact, quantify, and prove that value is created?</li>
</ul>
<p>The MLC helps formalize your plan, which you can use to better communicate with others, and convince them to join your efforts. Starting with the MLC is <a href="https://aws.amazon.com/blogs/apn/building-the-business-case-for-machine-learning-in-the-real-world/">recommended practice at AWS</a>. There are a few other frameworks with similar names, but what's unique with this one is that it helps anticipate running costs of the ML system you set out to build. For instance, you'll have to think about the volume of models and predictions to create, and this will determine infrastructure costs.</p>
</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1604599100593_119255"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5206b718e4b0bdc26006bae2/1604599451310-5XAR4DV2KR4718W9XS24/ke17ZwdGBToddI8pDm48kLl76CqolYQpYCK1tQUkpCVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzq3NVIIp6jYqnwxy-xF8aVXRy_AJKc5toB5m-gAPM7p7ivWsEabuWKGrHqsHOeNt4/wizardofoz.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5206b718e4b0bdc26006bae2/1604599451310-5XAR4DV2KR4718W9XS24/ke17ZwdGBToddI8pDm48kLl76CqolYQpYCK1tQUkpCVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzq3NVIIp6jYqnwxy-xF8aVXRy_AJKc5toB5m-gAPM7p7ivWsEabuWKGrHqsHOeNt4/wizardofoz.jpg" data-image-dimensions="640x360" data-image-focal-point="0.5,0.5" alt="wizardofoz.jpg" data-load="false" data-image-id="5fa43e9ba12889310b6a5ee8" data-type="image" src="https://www.louisdorard.com/blog/wizardofoz.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1604596910029_94157"><div><h2 id="2-conduct-customer-user-studies">2. Conduct customer/user studies</h2>
<p>Wouldn't it be great if you could make sure that end-users of your ML system will be able to use it ‚Äî and that they'll want to ‚Äî before you start building? For this, you can use mockups and run "wizard-of-oz" experiments, where you fake the ML system. It's been <a href="https://medium.com/google-design/human-centered-machine-learning-a770d10562cd">recommended practice at Google for years</a>.</p>
<p>Early UX research can also result in a better plan that factors in feedback loops (those could hurt in the long term) and new data collection opportunities.</p>
</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1601637086178_32786"><p><h2 id="3-set-up-proof-of-value-with-simulations-and-automl">3. Set up Proof of Value with simulations and AutoML</h2></p></div><div data-block-type="5" id="block-yui_3_17_2_1_1604599100593_18017"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          <a href="https://builtin.com/artificial-intelligence/artificial-intelligence-automotive-industry">
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5206b718e4b0bdc26006bae2/1604599130437-46NUJM5BU389WTHKPZ6D/ke17ZwdGBToddI8pDm48kEhRb-mGDiEi0xC18_AR20gUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcsUFtfQr2yxuOzlidL-fYvTwqjsYaERXA-DujV44Tnn4ay3UZP6GxYjP38VLon1Vj/image-asset.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5206b718e4b0bdc26006bae2/1604599130437-46NUJM5BU389WTHKPZ6D/ke17ZwdGBToddI8pDm48kEhRb-mGDiEi0xC18_AR20gUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcsUFtfQr2yxuOzlidL-fYvTwqjsYaERXA-DujV44Tnn4ay3UZP6GxYjP38VLon1Vj/image-asset.jpeg" data-image-dimensions="1200x630" data-image-focal-point="0.5,0.5" alt="If ML was a car, AutoML would be Tesla‚Äôs Autopilot! Actually, H2o.ai‚Äôs solution is even called  Driverless AI ‚Ä¶" data-load="false" data-image-id="5fa43d5afdc1165c0be072e5" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5206b718e4b0bdc26006bae2/1604599130437-46NUJM5BU389WTHKPZ6D/ke17ZwdGBToddI8pDm48kEhRb-mGDiEi0xC18_AR20gUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcsUFtfQr2yxuOzlidL-fYvTwqjsYaERXA-DujV44Tnn4ay3UZP6GxYjP38VLon1Vj/image-asset.jpeg">
          </p>
        
          </a>
        

        
          
          <figcaption>
            <p>If ML was a car, AutoML would be Tesla‚Äôs Autopilot! Actually, H2o.ai‚Äôs solution is even called <a href="https://www.h2o.ai/products/h2o-driverless-ai/">Driverless AI</a>‚Ä¶</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1604599100593_26838"><div><p>Before investing too much time/money/efforts, you'll want to create a baseline model with minimal costs, and in the quickest way possible. This means small data (e.g. 50 examples of each class, for a classification problem), automated ML, and no data scientist!</p>
<p>You will then proceed to proving that this baseline model can create value, by running it through a simulation (aka ‚Äúoffline evaluation‚Äù). The idea is to see how much value it would create, by making correct predictions on a "test" dataset. For this, you'll be using cost/gain values for the different types of incorrect/correct predictions.</p>
<p>One way to get a test dataset is to split your existing data into training and test sets, but there's a risk of "data leakage". The most secure option is to collect some more data, and to use it as test.</p>
<p>If you've reached your desired performance value, great! Go to step 5.</p>
</div></div><div data-aspect-ratio="59.354838709677416" data-block-type="5" id="block-yui_3_17_2_1_1601637086178_25762"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5206b718e4b0bdc26006bae2/1602522249592-8OG67A3QV5TCIWFNJWZ2/ke17ZwdGBToddI8pDm48kOJinPAM-bsCsrEW-EQQcxcUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcCYIMmt3J8eCP_1Xh0vGN4k6MSBhLjzgoEU9_RArInQXRklPxf4HZO9xZsY6xv2wj/Learning%2Bcurve%2B%252B%2Bdrawing%2B%252B%2Bplayer.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5206b718e4b0bdc26006bae2/1602522249592-8OG67A3QV5TCIWFNJWZ2/ke17ZwdGBToddI8pDm48kOJinPAM-bsCsrEW-EQQcxcUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcCYIMmt3J8eCP_1Xh0vGN4k6MSBhLjzgoEU9_RArInQXRklPxf4HZO9xZsY6xv2wj/Learning%2Bcurve%2B%252B%2Bdrawing%2B%252B%2Bplayer.jpg" data-image-dimensions="1058x684" data-image-focal-point="0.5,0.5" alt="Learning curve extrapolation" data-load="false" data-image-id="5f848c89fc98834485f02380" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5206b718e4b0bdc26006bae2/1602522249592-8OG67A3QV5TCIWFNJWZ2/ke17ZwdGBToddI8pDm48kOJinPAM-bsCsrEW-EQQcxcUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcCYIMmt3J8eCP_1Xh0vGN4k6MSBhLjzgoEU9_RArInQXRklPxf4HZO9xZsY6xv2wj/Learning%2Bcurve%2B%252B%2Bdrawing%2B%252B%2Bplayer.jpg">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Learning curve extrapolation</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1601637086178_31953"><div><h2 id="4-invest-in-data-to-increase-performance">4. Invest in data to increase performance</h2>
<p>Where should you invest, to increase performance? Common ideas are to: a) tune the ML algorithm, b) collect more data, c) improve data preparation.</p>
<p>One of the highlights of my survey results on <a href="https://www.linkedin.com/pulse/survey-results-what-managers-should-know-machine-learning-dorard/">what managers should know about ML</a> was S√©bastien Arnaud's "<em>invest in data, and activities around it: cleaning, analysis, processing pipeline, annotation, labelling, training/test set, validation</em>." Indeed, the most impactful improvements to your ML system will be coming from data collection and preparation. This means you should forget about a).</p>
<p>To choose between b) and c) you need to plot a <em>learning curve</em>. This consists in running the previous simulation again but with subsets of the training data that go from 10% to 100% in size (see illustration). You would look at how performance increases with the amount of training data that's available. Also consider how much time/money it took to acquire this training set (getting unbiased data can come at a cost, e.g. randomly approving transactions or loan applications). What happens if you extrapolate to more data?</p>
<p>How do you generate ideas to improve data preparation? The key is to inspect individual predictions among top errors, top predictions, and most uncertain ones. Prioritize ideas by grouping errors in different types, and counting occurrences of each type. Inspecting predictions also helps determine if you can trust the model: look at prediction explanations and check that they make sense.</p>
<p>Go through the implementation/inspection loop a few times, until performance is higher than the desired value. If you can't get there quickly enough, consider changing parameters of your prediction problem (e.g. reducing the time horizon).</p>
</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1601637086178_28201"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5206b718e4b0bdc26006bae2/1601637651959-NHYL1IQBA4PXJ3JJKJOM/ke17ZwdGBToddI8pDm48kFssEdhmOlK77ygr-KMi-Md7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UYJJAAZHaP_gTcZnuU_XDM1zyL6r9YsGRTiIw9e6RuDCFlq8oZZwhhoTbTOjCpwBwg/ML+system+architecture.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5206b718e4b0bdc26006bae2/1601637651959-NHYL1IQBA4PXJ3JJKJOM/ke17ZwdGBToddI8pDm48kFssEdhmOlK77ygr-KMi-Md7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UYJJAAZHaP_gTcZnuU_XDM1zyL6r9YsGRTiIw9e6RuDCFlq8oZZwhhoTbTOjCpwBwg/ML+system+architecture.jpg" data-image-dimensions="1811x2039" data-image-focal-point="0.5,0.5" alt="ML system architecture.jpg" data-load="false" data-image-id="5f770d1215e48c4fbd5b9576" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5206b718e4b0bdc26006bae2/1601637651959-NHYL1IQBA4PXJ3JJKJOM/ke17ZwdGBToddI8pDm48kFssEdhmOlK77ygr-KMi-Md7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UYJJAAZHaP_gTcZnuU_XDM1zyL6r9YsGRTiIw9e6RuDCFlq8oZZwhhoTbTOjCpwBwg/ML+system+architecture.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1601637086178_31096"><div><h2 id="5-shadow-deploy-a-minimum-viable-product">5. Shadow-deploy a Minimum Viable Product</h2>
<p>"Shadow-deployment" is the same as real deployment in production, except you don‚Äôt actually use predictions but you just log them. This allows to check whether model performance on production inputs is similar to what it was on test inputs. You'll also want to monitor performance through time, to see how fast it decreases, and thus to inform model refresh rate (i.e. updating with fresher data).</p>
<p>In the context of ML, a Minimum Viable Product (MVP) isn't just a model, but it's a <em>system</em> that's made of several components ‚Äî read more in <a href="https://www.linkedin.com/feed/update/urn:li:activity:6717822425423245313/">this post</a> and see how these components are interconnected in the diagram above. You should use an ML platform to get (and configure) a production-ready model builder and a server, and you should start with manual orchestration (this doesn't need to be a software component at first).</p>
<p>Finally, use shadow-deployment to check all running costs (ML platform / tools / infrastructure / compute), and see if there are any additional ones you hadn‚Äôt anticipated, when going from a lab environment to production.</p>
</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1602690482673_70558"><div><h2 id="6-update-model-with-new-data">6. Update model with new data</h2>
<p>As hinted above, you can expect performance to go down with time. This is because the dataset used to build your model becomes less and less representative of the reality, as time goes by. You'll need to periodically retrain your model with fresher data.</p>
<p>In the previous section, I advised to start with manual orchestration, which means manual (re)training and deployment. This should be fine in most cases, but you should test your ability to do this in a timely manner and without errors. This will also be an opportunity to collect new inputs and outputs and thus to confirm the cost of data collection.</p>
</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1602690482673_69097"><div><h2 id="7-canary-test-and-monitor">7. Canary-test and monitor</h2>
<p>I already mentioned monitoring in step 5, but this was about the model's performance. You'll also want to monitor the impact of your ML system, and make sure that you're system is creating value. But for this, you need to act on predictions and to integrate them into your end-users' app / workflow. You can start doing this for just a small subset of them (the "canary test"), to minimize the risk of "breaking" things with your new ML system.</p>
</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1602520515337_171287"><div><h2 id="8-invest-in-larger-scale-deployment">8. Invest in larger scale deployment</h2>
<p>Larger scale means increasing the subset of end-users who will be exposed to the new ML system / product. This means more predictions, higher running costs, changing the workflow of more people...</p>
<p>These costs have to be paid before getting gains, but you‚Äôve proved that your MVP creates value, so eventually it will pay off!</p>
</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1602690482673_149979"><div><h2 id="9-increase-value-or-generate-new-value-">9. Increase value or generate new value?</h2>
<p>If you're looking to invest more in ML, you have two options: 1) improve the current system and thus increase the value it creates, or 2) generate new value with a new ML use case.</p>
<h3 id="increase-value">Increase value</h3>
<p>Now's the right time to hire data scientists to <strong>tune modelling algorithms</strong>, or ML engineers to <strong>automate orchestration</strong>!</p>
<ul>
<li>Modelling improvements will result in higher performance, thus more value creation.</li>
<li>The idea with automation is to spend less time maintaining the system in production. You'll be setting up alerts (based on live performance, data drift detection...), triggers, and actions (train model, evaluate, deploy).</li>
</ul>
<h3 id="generate-new-value">Generate new value</h3>
<p>Targeting a new ML use case might provide a higher Return On Investment, if you <strong>make your ML assets reusable</strong>: reusing your previous data acquisition and preparation pipelines ‚Ä¶</p></div></div></div></div></div></article></section></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.louisdorard.com/blog/investors-approach-to-machine-learning-projects">https://www.louisdorard.com/blog/investors-approach-to-machine-learning-projects</a></em></p>]]>
            </description>
            <link>https://www.louisdorard.com/blog/investors-approach-to-machine-learning-projects</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048341</guid>
            <pubDate>Tue, 10 Nov 2020 17:16:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Detecting click outside a component using React hooks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25048169">thread link</a>) | @saranshk
<br/>
November 10, 2020 | https://www.wisdomgeek.com/development/web-development/react/detecting-click-outside-component-using-react-hooks/ | <a href="https://web.archive.org/web/*/https://www.wisdomgeek.com/development/web-development/react/detecting-click-outside-component-using-react-hooks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-td-block-uid="tdi_70_afa"><div><p>If you have tried developing your own dropdown, modal, or popover in React, you would have come across this. ‚ÄúHow do I detect a click outside my react component so that I can close it?‚Äù Detecting click outside component is luckily is not that difficult. This post will use react hooks to implement this functionality.</p><p>Before we get started with our process of detecting click outside component using React hooks, there is one hook in particular that we need to know about: useRef.</p><h2>The useRef hook</h2><p><span>- Advertisement -</span> <ins data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-1198872678846288" data-ad-slot="2989761355"></ins> </p><p>useRef is a react hook that can be used to access DOM elements. It returns a mutable object whose current property is initialized to the argument that gets passed as an argument.</p><p>The syntax for using the hooks looks like this:</p><pre><code>const refContainer = useRef(initialValue);</code></pre><p>And a sample implementation to focus the component on render would be:</p><pre><code>function TextInputWithFocusButton() {
  const inputEl = useRef(null);
  const onButtonClick = () =&gt; {
    // `current` points to the mounted text input element
    inputEl.current.focus();
  };
  return (
    &lt;&gt;
      &lt;input ref={inputEl} type="text" /&gt;
      &lt;button onClick={onButtonClick}&gt;Focus the input&lt;/button&gt;
    &lt;/&gt;
  );
}</code></pre><p>ref can be used in element tags or components too. It provides a way to access the corresponding DOM nodes. If you pass in a reference object using ref = {}, React sets the current property of the corresponding node. This property is updated whenever the node changes too.</p><p>There are other use cases for the useRef hook as well. But this post will be focused only on detecting click outside component.</p><h2>Setting up event listeners</h2><p>Now that you know of useRef, we will use it along with an event listener (for mouseDown or click). This listener will be attached to the document whenever the component is rendered. It will also be unmounted whenever the component is hidden. For obtaining this functionality, the useEffect react hook can be used. If you want a deeper insight into the <a href="https://www.wisdomgeek.com/development/web-development/react/learning-context-api-and-the-usecontext-react-hook/">useEffect react hook</a>, you can read the previous post about it.</p><p>For the component, there is a showOptionsList variable that is being used as a state variable to determine whether the component is visible or not. Thus, the useEffect will have it as a dependency, and according to its value, the event listener will be added/removed.</p><pre><code> useEffect(() =&gt; {
    if (showOptionsList) {
      document.addEventListener('mousedown', handleClickOutside);
    } else {
      document.removeEventListener('mousedown', handleClickOutside);
    }
    return () =&gt; {
      document.removeEventListener('mousedown', handleClickOutside);
    };
  }, [showOptionsList]);</code></pre><h2>Detecting click outside component</h2><p>Now that the handleClick will be triggered every time a click is registered on the document, all that remains is to check if the click is outside the component or not. For this, a reference to the component is needed. This can be obtained by making use of the useRef hook that was discussed earlier. Thus:</p><pre><code>const Select = () =&gt; {
  const node = useRef();
  return (
    &lt;div ref={node}&gt;
      // Remaining code
    &lt;/div&gt;
  );
};
</code></pre><p>And then, all that needs to be done in the handle click outside function would be to check if the user clicked outside the component or not. An implementation could be to check the target element of the click and if that equals the reference. But that only works for a single level node. In the case of multiple sub-nodes, the simple comparison would not work.</p><p>The .contains() method can be used to solve that problem. It tells if a node is a child of a given node or not. Thus, the implementation of the function becomes:</p><pre><code>const handleClickOutside = (e) =&gt; {
  if (node.current &amp;&amp; node.current.contains(e.target)) {
    // inside click
    return;
  }
  // outside click
  setShowOptionsList(false);
};</code></pre><p>The completed source code for the Select implementation can be found on <a aria-label="undefined (opens in a new tab)" href="https://github.com/saranshkataria/react-select/blob/main/src/components/Select/index.js" target="_blank" rel="noreferrer noopener">Github</a> if you want to go through it. If you want to make yourself familiar with other react hooks like <a aria-label="undefined (opens in a new tab)" href="https://www.wisdomgeek.com/development/web-development/react/learning-context-api-and-the-usecontext-react-hook/" target="_blank" rel="noreferrer noopener">useState and useEffect</a>, <a aria-label="undefined (opens in a new tab)" href="https://www.wisdomgeek.com/development/web-development/react/understanding-the-usereducer-hook-in-react/" target="_blank" rel="noreferrer noopener">useReducer</a>, or <a aria-label="undefined (opens in a new tab)" href="https://www.wisdomgeek.com/development/web-development/react/learning-context-api-and-the-usecontext-react-hook/" target="_blank" rel="noreferrer noopener">useContext</a>, check out the respective posts.</p><p>If there are any other <a aria-label="undefined (opens in a new tab)" href="https://www.wisdomgeek.com/tag/react-hooks/" target="_blank" rel="noreferrer noopener">react hooks</a> related things that you would want to cover, or if you have any queries, feel free to drop a comment below.</p></div></div></div>]]>
            </description>
            <link>https://www.wisdomgeek.com/development/web-development/react/detecting-click-outside-component-using-react-hooks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048169</guid>
            <pubDate>Tue, 10 Nov 2020 17:04:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Little Crony ‚Äì explore connections between Tories and contracted companies]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25048133">thread link</a>) | @davidbarker
<br/>
November 10, 2020 | https://sophieehill.shinyapps.io/my-little-crony/ | <a href="https://web.archive.org/web/*/https://sophieehill.shinyapps.io/my-little-crony/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>
          A visualization of the connections between
          <strong>Tory politicians</strong>
          and
          <strong>companies being awarded government contracts during the pandemic,</strong>
          based on reporting by
          <a href="https://www.opendemocracy.net/en/dark-money-investigations/">openDemocracy,</a>
          <a href="https://bylinetimes.com/">Byline Times,</a>
          and more.
        </p>
    </div></div>]]>
            </description>
            <link>https://sophieehill.shinyapps.io/my-little-crony/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048133</guid>
            <pubDate>Tue, 10 Nov 2020 17:00:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Predicting the Future of the Pandemic]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25048095">thread link</a>) | @gloriosoc
<br/>
November 10, 2020 | https://realscience.community/covid-projections/ | <a href="https://web.archive.org/web/*/https://realscience.community/covid-projections/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<div id="speakaboutWrapper"><p>US by State</p>



<figure><img loading="lazy" width="1024" height="443" src="https://realscience.community/wp-content/uploads/2020/11/image-2-1024x443.png" alt="" srcset="https://realscience.community/wp-content/uploads/2020/11/image-2-1024x443.png 1024w, https://realscience.community/wp-content/uploads/2020/11/image-2-300x130.png 300w, https://realscience.community/wp-content/uploads/2020/11/image-2-768x332.png 768w, https://realscience.community/wp-content/uploads/2020/11/image-2-1536x664.png 1536w, https://realscience.community/wp-content/uploads/2020/11/image-2-2048x885.png 2048w, https://realscience.community/wp-content/uploads/2020/11/image-2-1200x519.png 1200w, https://realscience.community/wp-content/uploads/2020/11/image-2-1388x600.png 1388w, https://realscience.community/wp-content/uploads/2020/11/image-2-960x415.png 960w, https://realscience.community/wp-content/uploads/2020/11/image-2-2000x865.png 2000w, https://realscience.community/wp-content/uploads/2020/11/image-2-1250x540.png 1250w, https://realscience.community/wp-content/uploads/2020/11/image-2-400x173.png 400w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<figure><img loading="lazy" width="1024" height="675" src="https://realscience.community/wp-content/uploads/2020/11/image-1-1024x675.png" alt="" srcset="https://realscience.community/wp-content/uploads/2020/11/image-1-1024x675.png 1024w, https://realscience.community/wp-content/uploads/2020/11/image-1-300x198.png 300w, https://realscience.community/wp-content/uploads/2020/11/image-1-768x507.png 768w, https://realscience.community/wp-content/uploads/2020/11/image-1-1536x1013.png 1536w, https://realscience.community/wp-content/uploads/2020/11/image-1-2048x1351.png 2048w, https://realscience.community/wp-content/uploads/2020/11/image-1-1200x792.png 1200w, https://realscience.community/wp-content/uploads/2020/11/image-1-910x600.png 910w, https://realscience.community/wp-content/uploads/2020/11/image-1-960x633.png 960w, https://realscience.community/wp-content/uploads/2020/11/image-1-1819x1200.png 1819w, https://realscience.community/wp-content/uploads/2020/11/image-1-1250x825.png 1250w, https://realscience.community/wp-content/uploads/2020/11/image-1-400x264.png 400w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>







<p><strong>About: </strong>Projections were created by the founder of Real <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical‚Ä¶">Science</a>, Dr. Christin Glorioso. I produced a separate SIR model for each county with an empirically derived beta from real data from that county. US and state level data are calculated from the sum of the county model results. The primary data are from the JHU COVID repository. Feel free to reach out to me for more details. You can <a href="https://realscience.community/register-2/">join the site</a> and message me or leave a comment below. </p>



<div>
<div><p><a href="https://realscience.community/register-2/" target="_blank" rel="noreferrer noopener">JOIN REal Science</a></p></div>
</div>




</div>					</div></div>]]>
            </description>
            <link>https://realscience.community/covid-projections/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048095</guid>
            <pubDate>Tue, 10 Nov 2020 16:57:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benchmarking Pulsar and Kafka a More Accurate Perspective on Pulsar Performance]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25048083">thread link</a>) | @addisonj
<br/>
November 10, 2020 | https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance | <a href="https://web.archive.org/web/*/https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048083</guid>
            <pubDate>Tue, 10 Nov 2020 16:56:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Walrus Operator in Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25047966">thread link</a>) | @renanmoura
<br/>
November 10, 2020 | https://renanmf.com/walrus-operator-python/ | <a href="https://web.archive.org/web/*/https://renanmf.com/walrus-operator-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The Walrus operator <code>:=</code> is an <a href="https://renanmf.com/assignment-operators-python/">assignment operator</a> and is available since Python 3.8.</p><p>It is called "walrus operator" due to its resemblance to the eyes and tusks of a walrus.</p><p>The walrus operator <strong>assigns and returns a value</strong> at the same time.</p><h2>Basic Example</h2><p>The regular way of asking for a piece of information in a terminal by using the <a href="https://renanmf.com/user-input-command-line-python/">input command</a> is as follows:</p><pre><code>&gt;&gt;&gt; age = input('How old are you? ')
How old are you? 30
&gt;&gt;&gt; print(f"You are {age} years old")
You are 30 years old
&gt;&gt;&gt; print(age)
30</code></pre><p>Using the walrus operator, you can make this code even shorter:</p><pre><code>&gt;&gt;&gt; print(f"You are {(age := input('How old are you? '))} years old")
How old are you? 30
You are 30 years old
&gt;&gt;&gt; print(age)
30</code></pre><h2>Example with a <code>while</code> loop</h2><p>Another example using <a href="https://renanmf.com/while-loops-python/">while loops</a> shows how you can simplify the code.</p><p>In this snippet, the loop will keep going until the user inputs the number 4.</p><pre><code>while True:
    number = int(input("Pick a number: "))
    if number == 4:
        break
    print(f'{number} squared is {number**2}')</code></pre><p>To have the same effect with the walrus operator, you do the following.</p><pre><code>while (number := int(input("Pick a number: "))) != 4:
    print(f'{number} squared is {number**2}')</code></pre><p>A simple test case for the while loop examples above is:</p><pre><code>Pick a number: 3
3 squared is 9
Pick a number: 5
5 squared is 25
Pick a number: 4</code></pre><h2>Example with a Regular Expression</h2><p>A simple example checking if the letter "Y" exists in "New York".</p><p>In the regular way to do it, we first get the result of the <code>search()</code> function, if there is no match, the function returns None which equals to <code>False</code> in the <code>if</code> statement.</p><p>If there is a match, the <code>res</code> variable will store a match object and pass the <code>if</code> statement.</p><pre><code>import re
text = "New York"
res = re.search("Y", text)
if res:
    print(res.group(0))</code></pre><p>To achieve the same result with the walrus operator, we can assign the result of the <code>search()</code> function directly to <code>res</code> in the <code>if</code> statement expression:</p><pre><code>import re
text = "New York"
if (res := re.search("Y", text)):
    print(res.group(0))</code></pre><h2>Example with a List Comprehension</h2><p>The use of the walrus operator with <a href="https://renanmf.com/list-comprehensions-in-python/">list comprehensions</a> enables the sharing of a subexpression.</p><p>In this case, without the walrus operator, we have to compute the operation <code>n**3</code> twice because we only want numbers whose cube is greater than 10.</p><pre><code>numbers = [1, 2, 3, 4, 5]
new_list = []
new_list = [n**3 for n in numbers if n**3 &gt; 10]
print(new_list)</code></pre><p>Using the walrus operator we can save this extra computation and reuse the value of <code>y</code> assigned in the <code>if</code> statement.</p><pre><code>numbers = [1, 2, 3, 4, 5]
new_list = []
new_list = [y for n in numbers if (y := n**3) &gt; 10]
print(new_list)</code></pre><p>Both will result in the same output, but the walrus operator allows a less expensive computation:</p><pre><code>[27, 64, 125]</code></pre><p>The code with the walrus operator might seem harder to read for some at first, use it only if it makes sense to you, and if it makes the code better overall.</p><h2>Controversy</h2><p>The Walrus Operator was controversial in the community and many people criticized it for some reasons:</p><ul><li>How will developers even use it?</li><li>Is this extra complexity needed?</li><li>This is confusing for new users of the language.</li></ul><p>These were the words that Guido van Rossum, the creator of Python,&nbsp;wrote after finishing PEP 572, which gave birth to the so-called Walrus Operator, saying he was resigning&nbsp;from his role.</p><blockquote><p>Now that PEP 572 is done, I don‚Äôt ever want to have to fight so hard for a PEP and find that so many people despise my decisions.</p><p>I would like to remove myself entirely from the decision process. I‚Äôll still be there for a while as an ordinary core dev, and I‚Äôll still be available to mentor people ‚Äî possibly more available. But I‚Äôm basically giving myself a permanent vacation from being BDFL, and you all will be on your own.</p><p>After all that‚Äôs eventually going to happen regardless ‚Äî there‚Äôs still that bus lurking around the corner, and I‚Äôm not getting younger‚Ä¶ (I‚Äôll spare you the list of medical issues.)</p><p>I am not going to appoint a successor.</p><p>So what are you all going to do? Create a democracy? Anarchy? A<br> dictatorship? A federation?</p><p>I‚Äôm not worried about the day to day decisions in the issue tracker or on GitHub. Very rarely I get asked for an opinion, and usually it‚Äôs not actually important. So this can just be dealt with as it has always been.</p><p>The decisions that most matter are probably</p><ul><li>How are PEPs decided</li><li>How are new core devs inducted</li></ul><p>We may be able to write up processes for these things as PEPs (maybe those PEPs will form a kind of constitution). But here‚Äôs the catch. I‚Äôm going to try and let you all (the current committers) figure it out for yourselves.</p><p>Note that there‚Äôs still the CoC ‚Äî if you don‚Äôt like that document your only option might be to leave this group voluntarily. Perhaps there are issues to decide like when should someone be kicked out (this could be banning people from python-dev or python-ideas too, since those are also covered by the CoC).</p><p>Finally. A reminder that the archives of this list are public (<a href="https://mail.python.org/pipermail/python-committers/">https://mail.python.org/pipermail/python-committers/</a>) although membership is closed (limited to core devs).</p><p>I‚Äôll still be here, but I‚Äôm trying to let you all figure something out for yourselves. I‚Äôm tired, and need a very long break.</p></blockquote><p>Personally speaking, as shown in the examples in this article, the walrus operator can be quite useful and help with some performant operations.</p><p>This is to show how even in the open source community, with highly smart people, there are disagreements that go beyond the professional level and get personal.</p><p>Projects are hard, designing programming languages is hard and we should thank those who take their time to build the tools we use every day to create awesome things.</p></div></div>]]>
            </description>
            <link>https://renanmf.com/walrus-operator-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25047966</guid>
            <pubDate>Tue, 10 Nov 2020 16:46:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Teach Testing First]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25047890">thread link</a>) | @kgashok
<br/>
November 10, 2020 | https://smalldata.tech/blog/2019/02/09/teach-testing-first | <a href="https://web.archive.org/web/*/https://smalldata.tech/blog/2019/02/09/teach-testing-first">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
The hallmark of an successful long term software project is its maintainablity. Maintainabity is a very loaded term in terms of software engineering and is usually dependent upon the software in question itself. In general however, decoupled code with a flexible overall system architecture is considered to be the best approach. Moreover, having comprehensive automated testing leads to highly resilient software. In recent years there has been a strong push towards Test Driven Development (TDD) which has become a rather polarising debate and this article does not focus on TDD but rather testing in general. 
</p>

<p>
Testing in this article can mean unit testing, integration testing as well as end-to-end integration testing interchangably. There is a well-know testing pyramid that visualizes the effort required for writing tests as one goes higher up. As the title suggests, the premise really is: <u><i>"Why isn't programming taught with a focus on testing first?"</i></u> and <u><i>"Will a focus on testing broaden the tip of the pyramid to make fully automated end-to-end integration testing easier?"</i></u>
</p>


<div>
  <p><a href="https://smalldata.tech/img/blog/testing-pyramid.png">
    <img alt="" src="https://smalldata.tech/img/blog/testing-pyramid.png">
  </a></p><p>
    The complexity and effort of writing and executing tests increases as one goes up the pyramid.
  </p>
</div>

<p>
When teaching programming, the general approach is to start with the basics such as setting up the environment, writing your first "Hello World" program, move on to programming concepts such as variables, loops, conditionals, etc. Towards the end, stuffed into advanced topics, is an introduction to unit testing. Some resources, such as the first hit on DDG for learning python (<a href="https://www.learnpython.org/">learnpython.org</a>) feature no testing at all! Recently however, testing has improved its position and can be found somewhere in the middle of the textbook in some instances, e.g <a href="https://www.learncpp.com/">learncpp.com</a>.
</p>

<blockquote>
  <p>If you're interested in learning a programming language or any other technical topic check out <a href="https://classpert.com/">classpert.com</a> for online courses!</p>
  
</blockquote>


<p>
Consider now that instead of jumping into variables and loops after "Hello World", we started with a test. It might be confusing at first as there are many concepts at play here, but assuming that "Hello World" was magic enough, a little bit more magic wouldn't harm given the long term benefits. In fact the hardest part here would be to actually enable a "Hello World" test to be written because we are not talking about a unit test, but rather a full integration test that runs the program which writes to <code>stdout</code> and then verifies that the output is correct.
</p>

<p>
Moving on, the teaching process itself could be simplified with excercises provided in the form of tests, e.g. write a program that makes this test pass. Of course, students will also need to learn that writing a program that makes a test pass does not necessarily mean that the program does what it is supposed to! The hardest part will likely be teaching UI testing. Currently, it is a lot of effort to setup end-to-end UI integration tests. There are many approaches and it might be enough to take a really simple approach to begin with, e.g. use an in-memory db with selenium for a web application, however, we should not let this deter us from coming up with better software that enable testing from the ground up.
</p>

<p>
The benefits of teaching testing first are rather clear, students will learn how to develop and test their software leading to better software being written. This will also force us to focus on making software testable, e.g. a desktop environment that can be programmatically queried regarding contents. There are of course, security concerns here but they could be mitigated by allowing a whitelist of software that can be interacted with on a per session basis but this is probably a post for a whole another article.
</p>

<!--
<div>
  <a class="image-popup-no-margins" href="/img/blog/016-automated-tests.jpg">
    <img class="img-responsive centered img-border" alt="" src="/img/blog/016-automated-tests.jpg">
  </a>
  <div class="img-desc">
    We need a goal to shoot for!
  </div>
</div>
-->

<p>
We can start small perhaps, teach unit testing for languages as early as possible and any new library or framework produced should also provide clear testing guidelines. Open source code should always have a section on testing along with project setup. The goal should be making testing a first class citizen!
</p>
<p><a href="https://news.ycombinator.com/submitlink?u=https%3A%2F%2Fsmalldata.tech%2Fblog%2F2019%2F02%2F09%2Fteach-testing-first&amp;t=Teach%20testing%20first">HackerNews submission / discussion</a></p></div></div>]]>
            </description>
            <link>https://smalldata.tech/blog/2019/02/09/teach-testing-first</link>
            <guid isPermaLink="false">hacker-news-small-sites-25047890</guid>
            <pubDate>Tue, 10 Nov 2020 16:39:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to beat the bank]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25047840">thread link</a>) | @venturegrit
<br/>
November 10, 2020 | https://andyjagoe.com/how-to-beat-the-bank/ | <a href="https://web.archive.org/web/*/https://andyjagoe.com/how-to-beat-the-bank/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://andyjagoe.com/content/images/size/w300/2020/11/felix-mittermeier-nAjil1z3eLk-unsplash.jpg 300w,
                            https://andyjagoe.com/content/images/size/w600/2020/11/felix-mittermeier-nAjil1z3eLk-unsplash.jpg 600w,
                            https://andyjagoe.com/content/images/size/w1000/2020/11/felix-mittermeier-nAjil1z3eLk-unsplash.jpg 1000w,
                            https://andyjagoe.com/content/images/size/w2000/2020/11/felix-mittermeier-nAjil1z3eLk-unsplash.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://andyjagoe.com/content/images/size/w2000/2020/11/felix-mittermeier-nAjil1z3eLk-unsplash.jpg" alt="How to beat the bank">
            </figure>

            <section>
                <div>
                    <!--kg-card-begin: markdown--><blockquote>
<p>Show me the incentive and I will show you the outcome.<br>
‚Äî Charlie Munger</p>
</blockquote>
<!--kg-card-end: markdown--><p>Have you ever thought about how much better some products are than the same version ten years ago?</p><p>My iPhone 12 is <a href="https://gadgetversus.com/processor/apple-a4-vs-apple-a14-bionic/">8,000% faster</a> than my iPhone 4. On 5G it can download at 4,000 Mbps versus my iPhone 4's top speed of 2 Mbps. <a href="https://www.in2013dollars.com/us/inflation/2010?amount=649">And it's the same price</a>. Meanwhile, countless physical products have become <a href="https://www.makeuseof.com/tag/apps-replacing-modern-devices/">just apps on the phone</a>.</p><p>In 2010, I had 7 Mbps Internet at home. Today I have 1,000 Mbps Internet. For the same price. And our children do live online video school while my wife and I run live Zoom meetings. Without even a hiccup.</p><p>Let's compare this to financial services.</p><p>If my Internet is 142 times better today than in 2010, how much better is my mortgage? Zero. My checking and savings accounts? Zero. My insurance? Zero. My investment services? OK, not zero. But not even a fraction of 142x.</p><p>Why?</p><p>One reason is that phone and Internet have exponential tailwinds from <a href="https://en.wikipedia.org/wiki/Moore%27s_law">Moore's Law</a> and digitalization. Digital is different, as we discussed in detail in <a href="https://andyjagoe.com/software-eats-money/">how software eats money</a>.</p><p>But that's not the only reason. Many financial services haven't improved in decades. How can that be?</p><h2 id="incentives">Incentives</h2><p>Charlie Munger, the vice-chairman of Berkshire Hathaway, wrote in the <a href="https://static1.squarespace.com/static/5ca3e714d74562b554c38604/t/5caa07a9971a182374badc19/1554646956708/Psychology+of+Human+Misjudgment.pdf">Psychology of Human Misjudgment</a>:</p><!--kg-card-begin: markdown--><blockquote>
<p>I think I‚Äôve been in the top five percent of my age cohorts almost all my adult life in understanding the power of incentives, and yet I‚Äôve always underestimated that power. Never a year passes but I get some surprise that pushes a little further my appreciation of incentive superpower.</p>
</blockquote>
<blockquote>
<p>One of my favorite cases about the power of incentives is the Federal Express case. The integrity of the Federal Express system requires that all packages be shifted rapidly among airplanes in one central airport each night. The system has no integrity for the customers if the night work shift can‚Äôt accomplish its assignment fast.</p>
</blockquote>
<blockquote>
<p>Federal Express had one hell of a time getting the night shift to do the right thing. They tried moral suasion. They tried everything in the world without luck. And, finally, somebody got the happy thought that it was foolish to pay the night shift by the hour when what the employer wanted was not maximized billable hours of employee service but fault-free, rapid performance of a particular task. Maybe, this person thought, if they paid the employees per shift and let all night shift employees go home when all the planes were loaded, the system would work better. And, lo and behold, that solution worked.</p>
</blockquote>
<!--kg-card-end: markdown--><p>Incentives matter. And if you know the incentive, you can know the outcome. The reason financial services have not improved in decades is a problem of incentives.</p><p>All good organizations pick metrics to measure success. But because measuring actual human behavior is difficult, we typically choose a <a href="https://kortina.nyc/essays/metrics-incrementalism-and-local-maxima/">proxy metric</a> to represent it. In education, we use test scores as a proxy for aptitude. In media, we use attention as a proxy for customer value. In consumer internet, we use clicks as a proxy for 'looked at this' and time spent as a proxy for 'enjoyed this.'</p><p>What do we use in financial services? </p><p>What metric is used to measure the amount of value being delivered to a customer? Is there one?</p><p>If a student has a higher test score, we can infer a higher aptitude. If someone spends more time watching a video, we can infer more entertainment or information value.</p><p>What is the equivalent in finance?</p><p>If a customer has more loans, are they getting more value? If a customer paid more fees, are they getting more value? If a customer trades more or has more insurance, are they getting more value?</p><p>The truth is most financial services companies do not think about customer value when measuring success. Assets under management, accounts opened, loans per loan officer and the <a href="https://www.staceybarr.com/measure-up/how-banks-should-change-their-kpis/">countless other current KPIs</a> are all inward facing. They measure bank value, not customer value.</p><p>If no one is measuring customer value, it's no surprise customer value isn't improving. There's no incentive.</p><p>Optimizing for the wrong metric is why Wells Fargo employees opened millions of fake customer accounts. Even after the <a href="https://www.federalreserve.gov/newsevents/pressreleases/files/enf20180202a1.pdf">consent order</a>, employees report the <a href="https://www.nytimes.com/2019/03/09/business/wells-fargo-sales-culture.html">culture still hasn't changed</a>. Have the metrics changed? Show me the incentive, and I will show you the outcome.</p><p>If optimizing for the wrong metric isn't bad enough, there's a second problem. Proxy metrics are imperfect measures of human behavior and often have second-order consequences that system designers didn't want or anticipate.</p><p>There are situations where using a product encourages more use of the product. This creates a feedback mechanism where not only the production side of the system is optimizing for the metric, but the consumption side is as well. This <a href="http://www.jimcollins.com/article_topics/articles/the-flywheel-effect.html">flywheel</a> effect can cause an epidemic, like when the media industry optimizes for content designed to trigger a dopamine response (like a newsfeed filled with <a href="https://www.newyorker.com/magazine/2017/02/27/why-facts-dont-change-our-minds">fake news</a> or <a href="https://www.pnas.org/content/106/22/9115.full">baby photos</a>) or when the food industry optimizes for empty calories (like <a href="https://www.npr.org/sections/thesalt/2014/01/08/260781785/is-sugar-addiction-why-so-many-january-diets-fail">sugar</a>).</p><p>How different are the feedback loops in media and food from the feedback loop in consumer loans? How many loans is too many loans?</p><p><a href="https://www.institutionalinvestor.com/article/b1nnpcj5q3l8wd/Charles-Schwab-Is-Quietly-One-of-the-Biggest-Banks-in-America-That-s-a-Problem">Charles Schwab has quietly become one of America's biggest banks</a> and plans to focus on loans since interest rates are so low and trading commissions have gone to zero. Increasingly, all financial services companies are in all lines of financial services. And competition is only going to increase as bank platform as a service offerings <a href="https://a16z.com/2020/01/21/every-company-will-be-a-fintech-company/">enable every company to be a fintech</a>. </p><p>What happens if loans are one of the few places left in financial services to make money, but now they're available from literally everyone? The same old product. A commodity. </p><p>And what if <a href="https://a16z.com/2020/10/01/fintech-for-gen-z/">Gen Z decides they don't want as many loans</a>, as the evidence suggests?</p><p>What do you do?</p><h2 id="build-something-no-one-else-can-measure">Build something no one else can measure</h2><p>The prevailing wisdom in media is to maximize engagement. This means you want people to spend as long as possible on your website. Google, by contrast, is optimized to <a href="https://www.google.com/about/philosophy.html">minimize the time you spend on their website</a>:</p><!--kg-card-begin: markdown--><blockquote>
<p>We know your time is valuable, so when you‚Äôre seeking an answer on the web you want it right away‚Äìand we aim to please. We may be the only people in the world who can say our goal is to have people leave our website as quickly as possible.</p>
</blockquote>
<!--kg-card-end: markdown--><p>Uber and Lyft <a href="https://www.uber.com/us/en/ride/transit/">show public transportation options</a> for users in their app even though they make no money if a user chooses them. Why? They are optimizing for the best way to get a user from point A to point B. They know that in many cases Uber or Lyft are the best option. Their goal is to be the starting point for <em>all</em> a user's trips, so they can measure and optimize them. Something public transit operators cannot do.</p><figure><img src="https://andyjagoe.com/content/images/2020/11/bostonjp1.png" alt="" srcset="https://andyjagoe.com/content/images/size/w600/2020/11/bostonjp1.png 600w, https://andyjagoe.com/content/images/2020/11/bostonjp1.png 720w" sizes="(min-width: 720px) 720px"></figure><p>In a world where most retailers want to minimize returns, Zappos has optimized to maximize them. They made returns a delight and part of shopping, noting that <a href="https://www.fastcompany.com/1614648/zappos-best-customers-are-also-ones-who-return-most-orders">the more goods their customers returned, the better they were for business</a>:</p><!--kg-card-begin: markdown--><blockquote>
<p>Our best customers have the highest returns rates, but they are also the ones that spend the most money with us and are our most profitable customers.<br>
-Craig Adkins, VP of services and operations, Zappos</p>
</blockquote>
<!--kg-card-end: markdown--><p><a href="https://sriramk.com/about">Sriram Krishnan</a>, who's worked on the product teams at Twitter, Snap and Facebook, said one of his theories on how to compete with major platform companies is to "<a href="https://sriramk.com/building-unmeasurable-things">build something that optimizes for a metric they can't measure.</a>"</p><p>This is also true in financial services.</p><p>It's not enough for financial services companies to evolve from sales organizations into software companies. You cannot win by optimizing for today's inward looking metrics. They result in <a href="https://kortina.nyc/essays/metrics-incrementalism-and-local-maxima/">incrementalism and local maxima</a>. </p><p>Tomorrow's winners will optimize for a metric that measures <strong>customer value</strong>.</p><p>Perhaps it's wealth generated per customer. Or percent of monthly income saved. Or even average improvement in credit score.</p><p>Whatever the metric is, it will reflect the fact that financial services will soon improve at the rate of phones or Internet service. Just like all digital products do.</p><p>This may sound unimaginable today. </p><p>So was iPhone upending the value chain in wireless and claiming the majority of profits. Or Craigslist taking every US telecom provider's yellow pages business from $10 billion to zero. The list goes on and on.</p><p>It won't be easy. And there will be many failures. But companies that win will optimize for a metric that makes customers feel awesome. Like they have a superpower. In the same way that using Google or iPhone feels like a superpower.</p><p>They'll be loved by customers. And bigger businesses than ever seen before.</p><p><em>Did you like this article? <a href="#subscribe">Subscribe now</a> to get content like this delivered free to your inbox. Learn more about what I do: <a href="https://andyjagoe.com/services/" rel="nofollow noopener">https://andyjagoe.com/services/</a></em></p><hr><!--kg-card-begin: html--><!--kg-card-end: html-->
                </div>
            </section>

                <section>
    <h3>Subscribe to Andy Jagoe</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://andyjagoe.com/how-to-beat-the-bank/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25047840</guid>
            <pubDate>Tue, 10 Nov 2020 16:35:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Gods on Hacker News]]>
            </title>
            <description>
<![CDATA[
Score 326 | Comments 161 (<a href="https://news.ycombinator.com/item?id=25047838">thread link</a>) | @ivm
<br/>
November 10, 2020 | https://www.riknieu.com/the-gods-on-hackernews/ | <a href="https://web.archive.org/web/*/https://www.riknieu.com/the-gods-on-hackernews/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>(Photo by <a href="https://unsplash.com/@tank_ghisletti?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Francisco Ghisletti</a> on <a href="https://unsplash.com/s/photos/greek-gods?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>)</p><p>(This post is mostly fun and tongue-in-cheek, please contain your indignation.)</p><p>Every so often I encounter a comment on HackerNews that involuntarily makes my jaw drop, head shake and eyes water. It's usually concerning what some on HackerNews consider a 'worthwhile' amount of money you can earn as an solopreneur or maker VS being an employee. </p><p>Obviously, it's probably a small minority of the silent masses who scroll through HN daily who have these views, but comments like the following, or a variant of it comes up so often I can't help but feel that a decent part of the community is <em>ridiculously</em> out of touch with the rest of humanity. </p><p>Behold.</p><!--kg-card-begin: html--><blockquote><p lang="und" dir="ltr">üòÇ <a href="https://t.co/mg1UFHxp08">https://t.co/mg1UFHxp08</a></p>‚Äî Pete from No CS Degree (@petecodes) <a href="https://twitter.com/petecodes/status/1326144308706209798?ref_src=twsrc%5Etfw">November 10, 2020</a></blockquote> <!--kg-card-end: html--><p>$1000 per month from a side project is considered meh. üò≥ üôÉ</p><p>And here's another from the same day,</p><figure><img src="https://www.riknieu.com/content/images/2020/11/soundslikealot.png"></figure><p>And from the same user a few scrolls later,</p><figure><img src="https://www.riknieu.com/content/images/2020/11/FANG.png"></figure><p>My god. Look, the commenter had the self awareness to bring up regional cost of living and that not everyone can work at the FAMANGs of the world, but really? Getting $3.7 million dollars for just 7 years of work is, like, a bad deal?</p><p>To consider making $500K pa as a doable, realistic salary to be taken into account when deciding between starting a company or just seeking a job... Like us millennials say, "I can't. Even." </p><p>That annual salary far outstrips what I can reasonably expect to earn in a decade, and I'm a developer working for a fintech startup with a good couple of years under my belt. For most people in the world, $500K pa is a <em><strong>preposterous</strong></em> amount of money. </p><p>I'm too lazy to go dig up more examples, but I'm sure you'll find some more gems like these if you go digging around on past threads.</p><p>This kind of poo-pooing of what most - and I'm talking 90% of the US population, never mind the rest of the world! - would consider rather large amounts of money is incredibly mind-blowing and makes my head spin.</p><p>Now I'm sure that in commenters like the above's worlds, that kind of money is indeed average and peanuts, but I wanted to write this article for myself and the rest of us to just try and deal. </p><p>I'm trying to make sense of the fact that I'm on this forum, interacting with people everyday, talking about current events and issues, that make more money per year than I can even imagine. In a way we're peers, but more realistically they're like the gods of Olympus who occasionally slum it with the rest of us.</p><p>So if you're like me, and you consider even a $1000 as lot of money, let's look at this as average mortals should.</p><h2 id="1-1000pm-is-a-flippen-lot">1) $1000pm is a flippen lot</h2><p>Let's go with the $1000 pm example, because figures like $3.6 million is, to be frank, in the realms of La-La land for me and almost everyone I know personally. </p><p>And let's - for the sake of simplicity - assume that you can take home 60% of that revenue as net earnings. And that the project doesn't take up more free time with maintenance and support issues than you can handle on your own. That's $600 per month. Extra. From a thing on the side. </p><p>I realise that I live in one of those cheap, unappealing parts of the world, but that kinda money would easily cover me and my family's rent every month, and then some. Do you realise how much of a mental weight that can take off a persons shoulders? To know rent is covered over and above your day-job earnings?</p><p>Away with your $1000-is-not-worth-it malarky!</p><h2 id="2-making-money-with-your-own-products-is-hard-">2) Making money with your own products is HARD.</h2><p>Take a look at <a href="https://www.indiehackers.com/post/holy-heck-this-is-hard-8ebe864174">this post</a> by <a href="https://twitter.com/mccrmx">Chris McCormick</a>, titled "<a href="https://www.indiehackers.com/post/holy-heck-this-is-hard-8ebe864174">Holy heck this is hard</a>". </p><p>When he last checked, 12 solo founders out of 17207 made more than $10K MRR. Only 54 products made more than $2000pm. I don't think I need to express that in ratios for you to see the probability of making a profitable project.</p><p>Starting a product and <em>actually earning money from it</em> is hard. Insanely hard. Hell, if you manage to make even $100pm from a side project you've got my respect. You've got me beat by a lot!</p><p>When I see makers on IndieHackers or Twitter celebrate $100 in sales I get genuinely excited for them. It's really an incredible feat. Bravo to them, I wish them luck and more success in the future.</p><h2 id="that-1000-per-month-can-grow">That $1000 per month can grow</h2><p>Another thing to consider is that earning a $1000 pm means your project is basically validated and ready to explode. With work, you could probably scale it to much higher multiples. </p><p>Sure, the money it makes is negligible to the higher beings in Silicon Valley, but for us regular plebs that's a <em>strong</em> signal that your project potentially has legs. It might even be a project you could sell for $3.7 million dollars in 7 years time, if you put the work in and get a little lucky.</p><h2 id="ya-but-rik-cost-of-living">Ya, but Rik, cost of living</h2><p>Sure, things cost more in the States. And more so in SanFran. But I can't just up and go live in the States. Nor pretty much anywhere else in the First World. A heck of a lot of the people frequenting HN, TW and IH on a daily basis could probably not either.</p><p>So for people like us, it's inspiring to read about some rando making a $1000 pm, on their own, independently. It gives us hope that some dude in Alabama could start a thing and sell it for more money than we could expect to earn in a lifetime as a salaried employee. Because maybe that means we could too.</p><p>Because they used the same tools we have access too(except for Stripe üòù). They had access to the same markets we could reach. </p><p>And they make the kinds of money with those tools that could buy people like us freedom. Freedom from being chained to a job, freedom from financial stress, and possibly even the freedom to move our families to better places in the world. Places that others just get born in.</p><p>So when you see smarmy comments on HackerNews new putting down the success of others, take a step back and realise, it's not meant for you. It's not personal. </p><p>These are merely the musings of a few lucky, privileged gods, reflecting on the toils of the mortals.</p><p>Thanks for reading. If you have any comments or suggestions, follow and contact me on Twitter <a href="https://twitter.com/riknieu">@RikNieu</a>.</p><p>If you want to read more of my rants, sign up below and I'll mail you when I post new stuff. üëá</p>
			</section></div>]]>
            </description>
            <link>https://www.riknieu.com/the-gods-on-hackernews/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25047838</guid>
            <pubDate>Tue, 10 Nov 2020 16:34:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Origins of the youtube-dl project]]>
            </title>
            <description>
<![CDATA[
Score 542 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25047818">thread link</a>) | @rg3
<br/>
November 10, 2020 | https://rg3.name/202011071352.html | <a href="https://web.archive.org/web/*/https://rg3.name/202011071352.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
<div>
<h3><a href="https://rg3.name/202011071352.html">Origins of the youtube-dl project</a></h3>
<p>Posted on <time>2020-11-07T13:52Z</time>. Updated on <time>2020-11-10T16:28Z</time>.</p>


<p>As you may know, as of the time this text is being written <a href="https://github.com/ytdl-org/youtube-dl">youtube-dl‚Äôs repository at GitHub</a> is blocked due to a <a href="https://github.com/github/dmca/blob/master/2020/10/2020-10-23-RIAA.md">DMCA takedown letter</a> received by GitHub on behalf of the RIAA. While I cannot comment on the current maintainers' plans or ongoing discussions, in light of the claims made in that letter I thought it would be valuable to put in writing the first years of youtube-dl as the project creator and initial maintainer.</p>
<div>
<h4 id="_copper_thieves">Copper thieves</h4>
<p>All good stories need at least a villain so I have arbitrarily chosen copper thieves as the villains of the story that set in motion what youtube-dl is today. Back in 2006 I was living in a town 5 to 10 kilometers away from <a href="https://en.wikipedia.org/wiki/Avil%C3%A9s">Avil√©s</a>, which is itself a small city or town in northern Spain. While people in Avil√©s enjoyed some nice infrastructures and services, including cable and ADSL Internet access, the area I lived in lacked those advantages. I was too far away from the telephone exchange to enjoy ADSL and copper thieves had been stealing copper wires along the way to it for years, causing telephone service outages from time to time and making the telephone company replace those wires with weaker and thinner wires, knowing they would likely be stolen again. This had been going on for several years at that point.</p>
<p>This meant my only choice for home Internet access so far had been a dial-up connection and a <a href="https://en.wikipedia.org/wiki/Modem#Standardized_56k_(V.90/V.92)">56k V.90 modem</a>. In fact, connection quality was so poor I had to limit the modem to 33.6 kbps mode so the connection would be at least stable. Actual download speeds rarely surpassed 4 KB/sec. <a href="https://en.wikipedia.org/wiki/YouTube">YouTube</a> was gaining popularity then to the point it was purchased by Google at the end of that year.</p>
</div>
<div>
<h4 id="_up_all_night_to_get_some_bits">Up all night to get some bits</h4>
<p>Watching any YouTube video on the kind of connection I described above was certainly painful, as you can imagine. Any video that was moderately big would take ages to download. For example, a short 10 MB video would take, if you do the math, 40 minutes to download, making streaming impossible. A longer and higher-quality video would take several hours and render the connection unusable for other purposes while you waited for it to be available, not to mention the possibility of the connection being interrupted and having to start the download process again. Now imagine liking a specific video a lot after watching it and wanting to watch it a second or third time. Going through that process again was almost an act of masochism.</p>
<p>This situation made me interested in the possibility of downloading the videos I was trying to watch: if the video was interesting, having a copy meant I could watch it several times easily. Also, if the downloader was any good, maybe the download process could be resumed if the connection was interrupted, as it frequently was.</p>
<p>At the time, there were other solutions to download videos from YouTube, including a quite popular <a href="https://addons.mozilla.org/en-US/firefox/addon/greasemonkey/">Greasemonkey</a> script. By pure chance, none of the few I tested were working when I did, so I decided to explore the possibility of creating my own tool. And that is, more or less, how youtube-dl was born. I made it a command-line program so it would be easy to use for me and wrote it in Python because it was easy thanks to its extensive standard library, with the nice side effect that it would be platform independent.</p>
</div>
<div>
<h4 id="_an_ethereal_start">An Ethereal start</h4>
<p>The initial version of the program only worked for YouTube videos. It had almost no internal design whatsoever because it was not needed. It did what it had to do as a simple script that proceeded straight to the point. Line count was merely 223, with only 143 being actual lines of code, 44 for comments and 36 of them blank. The name was chosen out of pure convenience: youtube-dl was an obvious name, hard to forget, and it could be intuitively typed as ‚ÄúY-O-U-TAB‚Äù in my terminal.</p>
<p>Having been using Linux for several years at that point, I decided to publish the program under a free software license (MIT for those first versions) just in case someone could find it useful. Back then, GitHub did not exist and we had to ‚Äúmake do‚Äù with <a href="https://en.wikipedia.org/wiki/SourceForge">SourceForge</a>, which had a bit of a tedious form that you needed to fill to create a new project. So, instead of going to SourceForge, I quickly published it under <a href="https://web.archive.org/web/20060812055952/http://www.arrakis.es/~rggi3/youtube-dl/">the web space that my Internet provider gave me</a>. While not usual today, it was common for ISPs to give you an email address and some web space you could upload stuff to using FTP. That way, you could have your own personal website on the net. The first ever version made public was 2006.08.08, although I probably had been using the program for a few weeks at that point.</p>
<p>To create the program, I studied what the web browser was doing when watching a YouTube video using Firefox. If I recall correctly, Firefox didn‚Äôt yet have the development tools it has today to analyze network activity. Connections were mostly HTTP and <a href="https://en.wikipedia.org/wiki/Wireshark">Wireshark</a>, known as ‚ÄúEthereal‚Äù up to that year, proved invaluable to inspect the network traffic coming in and out of my box when loading a YouTube video. I wrote youtube-dl with the specific goal of doing the same things the web browser was doing to retrieve the video. It even sent out a User-Agent string that was verbatim copied from Firefox for Linux, as a way to make sure the site would send the program the same version of video web pages that were used to study what the web browser was doing.</p>
<p>In addition, YouTube used <a href="https://en.wikipedia.org/wiki/Adobe_Flash">Adobe Flash</a> back then for the player. Videos were served as Flash Video files (FLV), and this all meant a proprietary plugin was required to watch them on the browser (many will remember the dreaded <code>libflashplayer.so</code> library), which would have made any browser development tools useless. This proprietary plugin was a constant source of security advisories and problems. I used a Firefox extension called <a href="https://en.wikipedia.org/wiki/Flashblock">Flashblock</a> that prevented the plugin from being loaded by default and replaced embedded content using the plugin, in web pages, with placeholder elements containing a clickable icon so content would be loaded only on demand and the plugin library was not used unless requested by the user.</p>
<p>Flashblock had two nice side effects apart from making the browsing experience more secure. On the one hand, it removed a lot of noisy and obnoxious ads from many web pages, which could also be a source of security problems when served by third parties. On the other hand, it eased analyzing how videos were being downloaded by the video player. I would wait until the video page had finished downloading completely and then start logging traffic with Wireshark just before clicking on the embedded video player placeholder icon, allowing it to load. This way, the only traffic to analyze was related to the plugin downloading the video player application and the application itself downloading the video.</p>
<p>It‚Äôs also worth noting the Flash Player plugin back then <a href="https://www.nirsoft.net/articles/copy_flash_flv_temp_file.html">was already downloading a copy of those videos to your hard drive</a> (they were stored in <code>/tmp</code> under Linux) and many users relied on that functionality to keep a copy of them without using additional tools. youtube-dl was simply more convenient because it could retrieve the video title and name the file more appropriately in an automated way, for example.</p>
</div>
<div>
<h4 id="_ahh_fresh_meat">Ahh, fresh meat!</h4>
<p>The Flash Player plugin was eventually <a href="https://www.omgubuntu.co.uk/2010/09/saving-flash-videos-in-linux-tmp-no-longer-works">modified so videos wouldn‚Äôt be so easily available to grab</a>. One of the first measures was to <a href="https://en.wikipedia.org/wiki/Unlink_(Unix)">unlink</a> the video file after creating it, so the i-node would still exist and be available to the process using it (until it was closed) while keeping the file invisible from the file system point of view. It was still possible to grab the file by using the <code>/proc</code> file system to examine file descriptors used by the browser process, but with every one of those small steps youtube-dl turned to be more and more convenient.</p>
<p>As many free and open source enthusiasts back then, I used <a href="https://en.wikipedia.org/wiki/Freecode">Freshmeat</a> to subscribe to new releases of projects I was interested in. When I created youtube-dl, I also created a project entry for it in that website so users could easily get notifications of new releases and a change log listing new features, fixes and improvements. Freshmeat could also be browsed to find new and interesting projects and its front page contained the latest updates, which usually amounted to only a few dozens a day. It‚Äôs only my guess that‚Äôs the way <a href="https://en.wikipedia.org/wiki/Joe_Barr">Joe Barr</a> (rest in peace), an editor for <a href="https://en.wikipedia.org/wiki/Linux.com">linux.com</a>, found out about the program and decided to write <a href="https://www.linux.com/news/cli-magic-enhance-your-youtube-viewing-pleasure/">an article about it</a> back in 2006. Linux.com was a bit different then and I think it was one of the frequently-visited sites for Linux enthusiasts together with other classics like <a href="https://en.wikipedia.org/wiki/Slashdot">Slashdot</a> or <a href="https://en.wikipedia.org/wiki/LWN.net">Linux Weekly News</a>. At least, it was for me.</p>
<p>From that point on, youtube-dl‚Äôs popularity started to grow and I started getting some emails from time to time to thank me for creating and maintaining the program.</p>
</div>
<div>
<h4 id="_measuring_buckets_of_bits">Measuring buckets of bits</h4>
<p>Fast forward to the year 2008. youtube-dl‚Äôs popularity had kept growing slowly and users frequently asked me to create similar programs to download from more sites, a request I had conceded a few times. It was at that point that I decided to rewrite the program from scratch and make it support multiple video sites natively. I had some simple ideas that would separate the program internals into several pieces. To simplify the most important parts: one would be the file downloader, common for every website, and another one would be the information extractors: objects (classes) that would contain code specific to a video site. When given a URL or pseudo-URL, the information extractors would be queried to know which one could handle that type of URL and then requested to extract information about that video or list of videos, with the primary goal of obtaining the video URL or a list of video URLs with available formats, together with some other metadata like the video titles, for example.</p>
<p>I also took the chance to switch version control systems and change where the project would be hosted. ‚Ä¶</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rg3.name/202011071352.html">https://rg3.name/202011071352.html</a></em></p>]]>
            </description>
            <link>https://rg3.name/202011071352.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25047818</guid>
            <pubDate>Tue, 10 Nov 2020 16:33:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jack Ma's Bund Finance Summit Speech]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 31 (<a href="https://news.ycombinator.com/item?id=25047544">thread link</a>) | @ceohockey60
<br/>
November 10, 2020 | https://interconnected.blog/jack-ma-bund-finance-summit-speech/ | <a href="https://web.archive.org/web/*/https://interconnected.blog/jack-ma-bund-finance-summit-speech/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <!-- social share icon -->
                    

                    <p><em>I don‚Äôt normally do any translation, because Interconnected is focused on original work and thinking. But I felt compelled to provide an English version of Jack Ma‚Äôs speech on October 24 at the Bund Finance Summit in Shanghai, because mainstream media coverage of the speech and the subsequent cancellation of Ant Group‚Äôs IPO has been lacking and simplistic. The speech is worth reading in its entirety to have a deeper understanding the full picture. Below is my unofficial translation of the speech </em><a href="https://sfl.global/news_post/mayunshanghaiwaitanjinrongluntanyanjiangquanwenwushanjian/"><em>based on a Chinese transcript</em></a><em>, with minor edits for clarity and speechifying. To read my deep dive analysis on the speech and its broader context, please check out: "<a href="https://interconnected.blog/jack-ma-p2p-lending-responsibility-legacy/">Jack Ma, P2P Lending, Responsibility, Legacy</a>"</em></p><p><em>ÊàëÈÄöÂ∏∏‰∏çÂÅö‰ªª‰ΩïÁøªËØëÂ∑•‰ΩúÔºåÂõ†‰∏∫„Ää‰∫íËÅî„Äã‰∏ìÊ≥®‰∫éÂéüÂàõ‰ΩúÂìÅÂíåÊÄùËÄÉ„ÄÇ‰ΩÜÊàëËßâÂæóÊúâÂøÖË¶ÅÊèê‰æõÈ©¨‰∫ë10Êúà24Êó•Âú®‰∏äÊµ∑Â§ñÊª©ÈáëËûçÂ≥∞‰ºö‰∏äÁöÑÊºîËÆ≤ÁöÑ‰∏Ä‰∏™Ëã±ÊñáÁâàÔºåÂ∞ΩÁÆ°Âè™ÊòØÊàë‰∏™‰∫∫ÈùûÂÆòÊñπÁöÑÁøªËØëÔºåÂõ†‰∏∫‰∏ªÊµÅÂ™í‰ΩìÂØπÊºîËÆ≤ÂíåÈöèÂêéËöÇËöÅÈõÜÂõ¢ÂèñÊ∂à‰∏äÂ∏ÇÁöÑÊä•ÈÅìÂ§™Ê¨†Áº∫ÔºåËøá‰∫éÁÆÄÂçïÂåñ„ÄÇÊï¥Â•óÊºîËÆ≤ÂÄºÂæó‰∏ÄËØªÊù•Êõ¥Ê∑±Â±ÇÁöÑ‰∫ÜËß£Êï¥‰∏™‰∫ãÊÉÖÔºåÂèØ‰ª•Âú®</em><a href="https://sfl.global/news_post/mayunshanghaiwaitanjinrongluntanyanjiangquanwenwushanjian/"><em>ËøôÈáåÁúãÂÖ®Êñá</em></a><em>ÔºåÂú®</em><a href="https://finance.sina.com.cn/chanjing/gsnews/2020-10-28/doc-iiznctkc8161643.shtml"><em>ËøôÈáåÁúãËßÜÈ¢ë</em></a><em>„ÄÇÊÉ≥ÁúãÊàëÂØπËøôÂ•óÊºîËÆ≤ÂíåÊúâÂÖ≥Â§ßËßÇÊôØÁöÑÊ∑±Â∫¶ÂàÜÊûêÔºåËØ∑ËØª„Ää<a href="https://interconnected.blog/jack-ma-p2p-lending-responsibility-legacy/">È©¨‰∫ëÔºåP2PÂÄüË¥∑ÔºåË¥£‰ªªÔºåÁïôÁªôÁ§æ‰ºöÁöÑÈÅó‰∫ß</a>„Äã</em></p><hr><p>Thank you for inviting me to this Summit. I am delighted to have this opportunity to learn, discuss, and exchange ideas together with you. In 2013, also in Shanghai, I came to the Lujiazui Finance Summit and shared some ‚Äúpie in the sky‚Äù views about Internet-powered finance. Seven years later, today I'm back in Shanghai as an unofficial non-professional person here at the Bund Finance Summit, hoping to share more ideas for you to ponder.</p><p>Actually, I was quite torn about whether to speak here today. But I think there is one thing that is incumbent upon this group of people, and that is the responsibility to think about the future, because although the world has left us many opportunities for development, there are really only one or two critical opportunities. This is a most critical moment.</p><p>So I come here to share some of my own thoughts and views, which are the result of our own practical experience in the last 16 years, plus discussions and research I have had with scholars, experts, and practitioners from all over the world, during the period when I was honored to be the co-chair of the UN High-Level Panel on Digital Cooperation and an advocate for the UN Sustainable Development Goals (SDGs).</p><p>I‚Äôm basically retired at this point, so I thought I'd speak freely at this unofficial forum and share the non-professional views of a non-professional person. Fortunately, I've discovered that many professionals no longer speak about their professions anymore.</p><p>I have three points of view for you to consider. They may be immature, incorrect, or laughable. Just give them a listen, if they make no sense, just forget about them.</p><p>The first point of view is we have some inertia in our thinking, like we always feel that in order to keep pace with international standards, we must do what developed countries like Europe and the United States have done. If we don‚Äôt have something they have, the so-called ‚Äúblank spot‚Äù, we must fill those blank spots domestically. Filling these spots has become the goal to pursue.</p><p>I have always felt that, given this year's situation, the phrase to ‚Äúfill the blank spot‚Äù is problematic. Just because Europe and the United States have something does not mean that thing is always advanced and worth having ourselves. In fact, today, we should not be concerned about what things to align with, which country's standard to adapt to, what blank spots to fill. Today, we have to think about how to align with the future, how to adapt to the future‚Äôs standard, how to fill the future‚Äôs blank spots. We have to figure out what the future will be, and what we really want to do, and then look at how others do it. If we always repeat the language of others, discuss topics defined by others, we will not only be lost in the present, but also miss the future.</p><p>After World War II, the world needed to restore economic prosperity. The establishment of the Bretton Woods system was an enormous catalyst to the global economy. Later, after the Asian financial crisis occurred, the Basel Accords talked about risk control, which has been gaining more and more attention, to the point that it became an operational standard for risk control. Now the trend is, the world is talking more and more just about risk control, not development. Very few people talk about where the opportunities are for young people, for developing countries.</p><p>This, in fact, is the root cause of many of the world's problems today. We also see today that the Basel Accords have put great limitations on Europe‚Äôs ability to innovate as a whole, for example, in digital finance.</p><p>Basel, more like a seniors club, is about solving the problem of an aging financial system that has been operating for decades, and Europe‚Äôs aging system is extremely complex. But the problem in China is the opposite: it is not a problem of systemic financial risk, because China's financial sector basically doesn‚Äôt have a system. Its risk is actually a "lack of financial system."</p><p>China's financial sector, like other developing countries that have just grown up, is a young industry that does not have a mature ecosystem and is not fully moving. China has many big banks. They are more like big rivers or arteries in our body‚Äôs circulatory system, but today we need more lakes, ponds, streams and tributaries, all kinds of swamps. Without these parts of the ecosystem, we will die when we are flooded, and die when we are in a drought. So, today we are a country that bears the risk of lacking a healthy financial system, and we need to build a healthy financial system, not worry about financial systemic risks.</p><p>They are like two completely different diseases, like Alzheimer's disease and polio. Both look similar at first glance but are two totally different illnesses. If a child takes Alzheimer's medication, he or she will not only get the old person‚Äôs disease, but a lot of other strange diseases as well.</p><p>The Basel Accords is designed to treat the diseases of the elderly with an aging system and over-complexity, and what we have to think about is what can we learn from the elderly? You must remember, older people and younger people care about different issues. Younger people care about whether there are schools, older people care about whether there are hospitals.</p><p>So, the way the world is changing this year is fascinating and very fast. Last night in Shanghai, we decided on the pricing of Ant‚Äôs IPO. This is the largest listing ever priced in the history of the entire human race, and the pricing happened in a place other than New York City. This was unthinkable five years ago, even three years ago, but miracles happen.</p><p>Second, innovation must come at a price, and our generation must take on that responsibility.</p><p>President Xi once said, "success does not have to come from me." I understand this phrase to be about a sense of responsibility. It‚Äôs about taking responsibility for the future, for tomorrow, for the next generation. Many of the world's problems today, including China's, can only be solved by innovation. However, for real innovation to happen, no one will show you the way, and someone must shoulder that responsibility, because innovation is bound to make mistakes. But the question is not how not to make mistakes, but whether we can perfect and correct them after making mistakes and persistently innovate. To make risk-free innovation is to stifle innovation, and there is no risk-free innovation in this world. There is no such thing as risk-free innovation. Oftentimes, managing risk down to zero is the biggest risk.</p><p>When the battle of Red Cliff was fought, I believe Cao Cao‚Äôs act of connecting all the ships together was the first instance of an aircraft carrier, in China and the world, but after a fire burned it all down, for a thousand years, the Chinese people didn't dare to think about it again. Once they thought about that fire, who still wanted to make a bigger ship, who could still have this kind of system-level thinking?</p><p>Seven or eight years ago, also in Shanghai, I mentioned this concept of Internet-powered finance. We have always emphasized that Internet-powered finance must have three core elements: first, it must have rich data; second, it must have risk control technology based on rich big data; and third, it must have a credit-based system built on big data.</p><p>Using these three criteria to evaluate, we can see that P2P is not Internet-powered finance at all, but today we cannot negate the innovation that the Internet has brought to finance just because of P2P. In fact, let's think about it, how can there be thousands of Internet-powered finance companies in China within a few years? Shouldn't we examine what gave birth to thousands of ‚ÄúInternet-powered finance‚Äù, the so-called P2P companies?</p><p>Today, it's really difficult to regulate ourselves; it's hard to conduct regulation everywhere around the globe. Innovation mainly comes from the marketplace, innovation comes from the grassroots, innovation comes from young people. Regulatory challenges are getting bigger and bigger. In fact, <em>jian </em>[editor's note: English word is ‚Äúsupervision‚Äù, the first character in the word for ‚Äúregulation‚Äù in Chinese] and <em>guan </em>[editor's note: English word is ‚Äúmanagement‚Äù, the second character in the word for ‚Äúregulation‚Äù in Chinese] are two different things. "Supervision" means watching you as you develop and paying attention to your development. ‚ÄúManagement‚Äù means intervening when there is a problem or when there is a foreseeable problem.</p><p>We are very good at ‚Äúmanagement‚Äù, but our ‚Äúsupervision‚Äù ability is sorely lacking.</p><p>Good innovation is not afraid of regulation, but is afraid of being subjected to yesterday's way to regulate. We cannot use the way to manage a railway station to manage an airport. We cannot use yesterday's way to manage the future.</p><p>"Supervision" and "management" are not the same, ‚Äúpolicies‚Äù and ‚Äúdocuments‚Äù are also not the same. This isn‚Äôt allowed, that isn‚Äôt allowed, those are all called ‚Äúdocuments‚Äù. Policy ‚Ä¶</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://interconnected.blog/jack-ma-bund-finance-summit-speech/">https://interconnected.blog/jack-ma-bund-finance-summit-speech/</a></em></p>]]>
            </description>
            <link>https://interconnected.blog/jack-ma-bund-finance-summit-speech/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25047544</guid>
            <pubDate>Tue, 10 Nov 2020 16:10:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C source-to-source compiler enhancement from within]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25047169">thread link</a>) | @ingve
<br/>
November 10, 2020 | https://hal.inria.fr/hal-02998412 | <a href="https://web.archive.org/web/*/https://hal.inria.fr/hal-02998412">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                    <p><strong>Abstract</strong> : We show how locally replaceable code snippets can be used to easily
  specify and prototype compiler and language enhancements for the
  C language that work by local source-to-source
  transformation.
  A toolbox implements the feature and provides many directives that
  can be used for compile time configuration and tuning, code
  unrolling, compile time expression evaluation and program
  modularization.
  The tool is also easily extensible by simple filters that can be
  programmed with any suitable text processing framework.                    </p>
                                </div><p><small>
                https://hal.inria.fr/hal-02998412<br>
                Contributeur : <a rel="nofollow" href="https://hal.inria.fr/search/index/q/*/contributorId_i/105206" target="_blank">Jens Gustedt</a>                        &lt;<a href="" id="link5faeea8dc50f2"></a>&gt;
                        <br>Soumis le : mardi 10 novembre 2020 - 15:02:12<br>Derni√É¬®re modification le : mercredi 11 novembre 2020 - 03:36:16</small>
        </p></div>]]>
            </description>
            <link>https://hal.inria.fr/hal-02998412</link>
            <guid isPermaLink="false">hacker-news-small-sites-25047169</guid>
            <pubDate>Tue, 10 Nov 2020 15:42:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Event: How Apple Silicon Changes Mac Forever]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25047142">thread link</a>) | @aasthembolt
<br/>
November 10, 2020 | https://heartbeat.fritz.ai/how-apple-silicon-changes-mac-forever-d2682a9722df | <a href="https://web.archive.org/web/*/https://heartbeat.fritz.ai/how-apple-silicon-changes-mac-forever-d2682a9722df">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="cb2b">WWDC20</h2><h2 id="087c">Learn more about Apple‚Äôs ARM-based silicon chips for Mac, announced at WWDC20</h2><div><div><div><p><a href="https://medium.com/@vhanagwal?source=post_page-----d2682a9722df--------------------------------" rel="noopener"><img alt="Vardhan Agrawal" src="https://miro.medium.com/fit/c/96/96/1*ORFRUf6O2Tk4XbG3kElncQ.jpeg" width="48" height="48"></a></p></div></div></div></div></div><div><figure><div role="button" tabindex="0"><div><p><img alt="Image for post" src="https://miro.medium.com/max/5000/1*3RTZkevqc5ZvJpivlnc1mg.jpeg" width="2500" height="1599" srcset="https://miro.medium.com/max/552/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 276w, https://miro.medium.com/max/1104/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 552w, https://miro.medium.com/max/1280/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 640w, https://miro.medium.com/max/1456/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 728w, https://miro.medium.com/max/1632/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 816w, https://miro.medium.com/max/1808/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 904w, https://miro.medium.com/max/1984/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 992w, https://miro.medium.com/max/2160/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 1080w, https://miro.medium.com/max/2700/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 1350w, https://miro.medium.com/max/3240/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 1620w, https://miro.medium.com/max/3780/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 1890w, https://miro.medium.com/max/4320/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 2160w, https://miro.medium.com/max/4800/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 2400w" sizes="100vw" data-old-src="https://miro.medium.com/max/60/1*3RTZkevqc5ZvJpivlnc1mg.jpeg?q=20"></p></div></div></figure></div><div><div><p id="93b7">At the end of the WWDC20 Keynote, Apple announced that it‚Äôs switching from Intel processors to its own: Apple Silicon. The release of custom Apple chips, powered by ARM, comes after a long history of using Intel-based chips, for the greater part of the 21st century.</p><p id="0fc0">Modeled after Apple‚Äôs use of its own chips on the iPhone, iPad, and Apple Watch, the company is switching to its own chips to give the Mac more performance per watt and better GPU performance.</p><p id="ecaf">Though we won‚Äôt go in-depth into the specific implications for machine learning, there‚Äôs a lot to be excited about when it comes to the future of ML development on Mac. Inevitably, the enhanced GPU performance will be a boon to machine learning developers, with benefits ranging from faster model training to reduced reliance on transfer learning. It will be interesting to see how ML engineers capitalize on Apple Silicon over time.</p></div></div></section><section><div><div><p id="10c8">The Mac, often considered Apple‚Äôs flagship lineup, has seen a couple changes in the past. Let‚Äôs look at what those changes were and how they‚Äôve contributed to the evolution of the Mac.</p><h2 id="114e">Motorola 68K to PowerPC</h2><p id="d699">One of the earliest transitions in chip architecture was the transition from Motorola 68K chips to IBM and Motorola PowerPC chips. This was an incredible transition, which significantly improved the Mac and played an important role in understanding future transitions.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1560/1*gf2Y6U112riltsrAmT6VaA.png" width="780" height="439" srcset="https://miro.medium.com/max/552/1*gf2Y6U112riltsrAmT6VaA.png 276w, https://miro.medium.com/max/1104/1*gf2Y6U112riltsrAmT6VaA.png 552w, https://miro.medium.com/max/1280/1*gf2Y6U112riltsrAmT6VaA.png 640w, https://miro.medium.com/max/1400/1*gf2Y6U112riltsrAmT6VaA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*gf2Y6U112riltsrAmT6VaA.png?q=20"></p></div></div></div><figcaption>The original iMac with a PowerPC processor.</figcaption></figure><h2 id="ed43">PowerPC to Intel x86</h2><p id="6ac1">The most notable transition was the move from PowerPC chips to Intel processors, which have been used for almost half of the Mac‚Äôs history so far. With this transition, Apple announced a developer kit to help with the transition, similar to what they announced in the switch to Apple Silicon.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2400/1*YIIun0yR2job_s0MRzSINg.png" width="1200" height="675" srcset="https://miro.medium.com/max/552/1*YIIun0yR2job_s0MRzSINg.png 276w, https://miro.medium.com/max/1104/1*YIIun0yR2job_s0MRzSINg.png 552w, https://miro.medium.com/max/1280/1*YIIun0yR2job_s0MRzSINg.png 640w, https://miro.medium.com/max/1400/1*YIIun0yR2job_s0MRzSINg.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*YIIun0yR2job_s0MRzSINg.png?q=20"></p></div></div></div><figcaption>A recent, Intel-based MacBook Pro.</figcaption></figure></div></div></section><section></section><section><div><div><p id="4c63">Undoubtedly, a switch to ARM-based Macs has a huge advantage for the performance and usability of Macs. Let‚Äôs look at how Apple Silicon will improve the Mac‚Äôs experience.</p><h2 id="71ef">Performance per Watt</h2><p id="e98c">Apple Silicon promises a stark improvement in performance per watt, meaning that the Mac could potentially promise desktop-level performance with the power consumption of a notebook computer, as exemplified by Apple‚Äôs diagram:</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3440/1*485W2PItyV9fz4UiWem0eQ.png" width="1720" height="953" srcset="https://miro.medium.com/max/552/1*485W2PItyV9fz4UiWem0eQ.png 276w, https://miro.medium.com/max/1104/1*485W2PItyV9fz4UiWem0eQ.png 552w, https://miro.medium.com/max/1280/1*485W2PItyV9fz4UiWem0eQ.png 640w, https://miro.medium.com/max/1400/1*485W2PItyV9fz4UiWem0eQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*485W2PItyV9fz4UiWem0eQ.png?q=20"></p></div></div></div><figcaption>Performance per watt for Apple Silicon</figcaption></figure><h2 id="95f4">Native Apps</h2><p id="b37d">Apps that support Apple Silicon natively will perform best on the new ARM-based Macs. Out-of-the-box, Apple‚Äôs own apps, including pro apps like Final Cut Pro and Logic Pro, will have native support for Apple Silicon. In addition, through their collaboration with Adobe, the Creative Cloud Suite will also have native support from the get-go. Eventually, Microsoft Office and other widely used programs will be able to take advantage of Apple Silicon‚Äôs performance.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2160/1*AkSiIGraS55x_sZV5vt6_A.png" width="1080" height="607" srcset="https://miro.medium.com/max/552/1*AkSiIGraS55x_sZV5vt6_A.png 276w, https://miro.medium.com/max/1104/1*AkSiIGraS55x_sZV5vt6_A.png 552w, https://miro.medium.com/max/1280/1*AkSiIGraS55x_sZV5vt6_A.png 640w, https://miro.medium.com/max/1400/1*AkSiIGraS55x_sZV5vt6_A.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*AkSiIGraS55x_sZV5vt6_A.png?q=20"></p></div></div></div><figcaption>Photoshop running natively on an ARM-based Mac.</figcaption></figure><h2 id="2e35">iOS Apps on Mac</h2><p id="3611">Another incredible benefit of using the ARM architecture across iOS, macOS, and watchOS is the ability to run iOS apps natively on Apple Silicon Macs. Without any additional work from the developer, most iOS apps can be installed from the Mac App Store.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/6718/1*SdaPx8Kn2Nw08JFB6XbDvw.png" width="3359" height="1891" srcset="https://miro.medium.com/max/552/1*SdaPx8Kn2Nw08JFB6XbDvw.png 276w, https://miro.medium.com/max/1104/1*SdaPx8Kn2Nw08JFB6XbDvw.png 552w, https://miro.medium.com/max/1280/1*SdaPx8Kn2Nw08JFB6XbDvw.png 640w, https://miro.medium.com/max/1400/1*SdaPx8Kn2Nw08JFB6XbDvw.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*SdaPx8Kn2Nw08JFB6XbDvw.png?q=20"></p></div></div></div><figcaption>Running Monument Valley and Fender Play, two popular iOS apps, on a Mac.</figcaption></figure><p id="4f66">To help developers transition their apps to support Apple Silicon, Apple has announced a whole host of tools to make native and simulated support for Apple Silicon as smooth as possible for users.</p><h2 id="0ebc">Universal 2</h2><p id="8277">As the name suggests, Universal 2 allows developers to quickly compile their apps for Apple Silicon while retaining support for Intel-based Macs. By using Universal 2 in Xcode, developers will be able to use the same binary for both Intel-based Macs, while providing a native experience for those who are using a Mac with Apple Silicon.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/6720/1*4Krp5sFt3beXnXbpuenl9Q.png" width="3360" height="2100" srcset="https://miro.medium.com/max/552/1*4Krp5sFt3beXnXbpuenl9Q.png 276w, https://miro.medium.com/max/1104/1*4Krp5sFt3beXnXbpuenl9Q.png 552w, https://miro.medium.com/max/1280/1*4Krp5sFt3beXnXbpuenl9Q.png 640w, https://miro.medium.com/max/1400/1*4Krp5sFt3beXnXbpuenl9Q.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*4Krp5sFt3beXnXbpuenl9Q.png?q=20"></p></div></div></div><figcaption>Universal 2 for the same binary for Intel and ARM-based Macs.</figcaption></figure><h2 id="38e9">Rosetta 2</h2><p id="49cb">An upgrade from their previous version of Rosetta (for the Intel transition), Rosetta 2 provides similar capabilities as its previous counterpart ‚Äî allowing Intel-based apps to run on Apple Silicon Macs. So if app developers haven‚Äôt yet recompiled their apps with Universal 2, their users can still access legacy versions of the app through Rosetta 2.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/6720/1*2qVtb8FXZoJARJJa-Pq0IQ.png" width="3360" height="2100" srcset="https://miro.medium.com/max/552/1*2qVtb8FXZoJARJJa-Pq0IQ.png 276w, https://miro.medium.com/max/1104/1*2qVtb8FXZoJARJJa-Pq0IQ.png 552w, https://miro.medium.com/max/1280/1*2qVtb8FXZoJARJJa-Pq0IQ.png 640w, https://miro.medium.com/max/1400/1*2qVtb8FXZoJARJJa-Pq0IQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*2qVtb8FXZoJARJJa-Pq0IQ.png?q=20"></p></div></div></div><figcaption>Rosetta 2 for install-time translation for Intel-based apps.</figcaption></figure><h2 id="b5ed">Virtualization</h2><p id="d298">For developers who need to use Linux, Docker, or similar tools, Apple has also announced virtualization tools for ARM Macs. These tools are expected to provide a seamless transition to Apple Silicon for developers who need server-side development tools.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/6718/1*z8L5KciHtXn7DOG5_HO8Ag.png" width="3359" height="1884" srcset="https://miro.medium.com/max/552/1*z8L5KciHtXn7DOG5_HO8Ag.png 276w, https://miro.medium.com/max/1104/1*z8L5KciHtXn7DOG5_HO8Ag.png 552w, https://miro.medium.com/max/1280/1*z8L5KciHtXn7DOG5_HO8Ag.png 640w, https://miro.medium.com/max/1400/1*z8L5KciHtXn7DOG5_HO8Ag.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*z8L5KciHtXn7DOG5_HO8Ag.png?q=20"></p></div></div></div><figcaption>Running an Apache server on an ARM-based Mac.</figcaption></figure><h2 id="f765">Developer Transition Kit</h2><p id="81af">Similar to the Intel transition, developers will be able to purchase a Developer Transition Kit, which comprises a Mac Mini enclosure fitted with the A12Z SoC ‚Äî used on the latest iPad lineup. The Mac Mini will have 16GB of memory and a 512GB SSD ‚Äî plenty for development needs. Also, macOS Big Sur and Xcode 12 will come pre-installed on the machine, which will be available for $500 (half the price of the Intel transition kit).</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2160/1*hpX5lvJahDiZXZxjGDDLMQ.png" width="1080" height="607" srcset="https://miro.medium.com/max/552/1*hpX5lvJahDiZXZxjGDDLMQ.png 276w, https://miro.medium.com/max/1104/1*hpX5lvJahDiZXZxjGDDLMQ.png 552w, https://miro.medium.com/max/1280/1*hpX5lvJahDiZXZxjGDDLMQ.png 640w, https://miro.medium.com/max/1400/1*hpX5lvJahDiZXZxjGDDLMQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*hpX5lvJahDiZXZxjGDDLMQ.png?q=20"></p></div></div></div><figcaption>Apple‚Äôs Mac Mini Based Developer Transition Kit</figcaption></figure><p id="de05">While Apple isn‚Äôt completely transitioning to Apple Silicon just yet, the announcement of their ARM-based chip for Mac is a huge step in a two year process to change Mac for the better.</p><p id="04c2">Stay tuned for some great new tutorials on the latest frameworks this week, and get ahead of the crowd by taking use of them before they‚Äôre released to the public in the fall.</p><p id="3993">In case you missed it, here‚Äôs the Keynote in all its glory:</p><figure><div></div></figure><p id="6139">Be sure to <strong>smash that ‚Äúclap‚Äù button</strong> as many times as you can, <strong>share this article</strong> on social media, and <strong>follow me on Twitter.</strong></p></div></div></section><section><div><div><p id="d325"><em>Editor‚Äôs Note:</em><a href="http://heartbeat.fritz.ai/" rel="noopener"><em> </em><strong><em>Heartbeat</em></strong></a><strong><em> </em></strong><em>is a contributor-driven online publication and community dedicated to exploring the emerging intersection of mobile app development and machine learning. We‚Äôre committed to supporting and inspiring developers and engineers from all walks of life.</em></p><p id="cfac"><em>Editorially independent, Heartbeat is sponsored and published by</em><a href="http://fritz.ai/" rel="noopener"><em> </em><strong><em>Fritz AI</em></strong></a><em>, the machine learning platform that helps developers teach devices to see, hear, sense, and think. We pay our contributors, and we don‚Äôt sell ads.</em></p><p id="5eba"><em>If you‚Äôd like to contribute, head on over to our</em><a rel="noopener" href="https://heartbeat.fritz.ai/call-for-contributors-october-2018-update-fee7f5b80f3e"><em> </em><strong><em>call for contributors</em></strong></a><em>. You can also sign up to receive our weekly newsletters (</em><a href="https://www.deeplearningweekly.com/" rel="noopener"><strong><em>Deep Learning Weekly</em></strong></a><em> and</em><a href="https://www.fritz.ai/newsletter" rel="noopener"><em> </em></a><em>the </em><a href="https://www.fritz.ai/newsletter/?utm_campaign=fritzai-newsletter&amp;utm_source=heartbeat-statement" rel="noopener"><strong><em>Fritz AI Newsletter</em></strong></a><em>), join us on</em><a href="https://join.slack.com/t/fritz-ai-community/shared_invite/enQtNTY5NDM2MTQwMTgwLWU4ZDEwNTAxYWE2YjIxZDllMTcxMWE4MGFhNDk5Y2QwNTcxYzEyNWZmZWEwMzE4NTFkOWY2NTM0OGQwYjM5Y2U" rel="noopener"><em> </em></a><a href="http://fritz.ai/slack" rel="noopener"><strong><em>Slack</em></strong></a><em>, and follow Fritz AI on</em><a href="https://twitter.com/fritzlabs" rel="noopener"><em> </em><strong><em>Twitter</em></strong></a><em> for all the latest in mobile machine learning.</em></p></div></div></section></div></div>]]>
            </description>
            <link>https://heartbeat.fritz.ai/how-apple-silicon-changes-mac-forever-d2682a9722df</link>
            <guid isPermaLink="false">hacker-news-small-sites-25047142</guid>
            <pubDate>Tue, 10 Nov 2020 15:40:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a weather station. Final post]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25047091">thread link</a>) | @kernelmode
<br/>
November 10, 2020 | https://blog.kdubovikov.ml/articles/rust/ui/weather-station-ui | <a href="https://web.archive.org/web/*/https://blog.kdubovikov.ml/articles/rust/ui/weather-station-ui">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
<p>November 4, 2020</p>

<p>In this last post of the series we are going to look at how to build a simple weather station UI dashboard.</p>

<!--more-->



<ol>
  <li><a href="https://blog.kdubovikov.ml/articles/hardware/build-yourself-a-weather-station">Build yourself a weather station. Part I</a></li>
  <li><a href="https://blog.kdubovikov.ml/articles/hardware/build-yourself-a-weathe-station-part-2">Building yourself a weather station. Part 2</a></li>
  <li><a href="https://blog.kdubovikov.ml/articles/rust/async-unicorns-love-rust">Async Unicorns love Rust</a></li>
  <li><a href="https://blog.kdubovikov.ml/articles/rust/building-a-weather-station-bot">Building a Weather Station Bot</a></li>
  <li>‚Üí Building a Weather Station UI</li>
</ol>


<p>In <a href="https://blog.kdubovikov.ml/articles/rust/building-a-weather-station-bot">the previous post</a> we have built a weather station bot that can notify us about new measurements made by our weather station. Today, we are going to build a simple REST API to fetch the data from our server and draw a chart on a simple dashboard.</p>


<p>Our web interface will need historical data that will be displayed in the charts. Before building an actual UI we will create a REST API that will return all sensor readings that are stored in our database. The code for the API is located in the <a href="https://github.com/kdubovikov/weather-station-bot/blob/master/src/bin/weather_station_api.rs"><code>weather_station_api.rs</code></a> file. We will use the <a href="https://docs.rs/tower-web/0.3.7/tower_web/">tower_web</a> crate to create a service that will return all sensor measurements along with their timestamps. We already have the database related code covered in the previous post. The entire service code is very concise:</p>

<div><div><pre><code><span>/// This type will be part of the web service as a resource.</span>
<span>#[derive(Clone,</span> <span>Debug)]</span>
<span>struct</span> <span>WeatherApi</span><span>;</span>

<span>/// This will be the JSON response</span>
<span>#[derive(Response)]</span>
<span>struct</span> <span>WeatherMessageResponse</span> <span>{</span>
    <span>messages</span><span>:</span> <span>Vec</span><span>&lt;</span><span>WeatherMessage</span><span>&gt;</span>
<span>}</span>

<span>impl_web!</span> <span>{</span>
    <span>impl</span> <span>WeatherApi</span> <span>{</span>
        <span>#[get(</span><span>"/"</span><span>)]</span>
        <span>#[content_type(</span><span>"json"</span><span>)]</span>
        <span>fn</span> <span>get_all_weather_messages</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>WeatherMessageResponse</span><span>,</span> <span>()</span><span>&gt;</span> <span>{</span>
            <span>let</span> <span>conn</span> <span>=</span> <span>establish_connection</span><span>(</span><span>"./db.sqlite"</span><span>);</span> <span>// this is a magic string better to be left in a config file, but I'll let it as it is for the sake of simplicity</span>
            <span>let</span> <span>weather_messages</span> <span>=</span> <span>get_all_weather_messages</span><span>(</span><span>&amp;</span><span>conn</span><span>);</span>
            <span>Ok</span><span>(</span>
               <span>WeatherMessageResponse</span> <span>{</span> <span>messages</span><span>:</span> <span>weather_messages</span> <span>}</span>
            <span>)</span>
        <span>}</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>After that all we need is to run the server somewhere inside our <code>main</code> function:</p>

<div><div><pre><code><span>let</span> <span>cors</span> <span>=</span> <span>CorsBuilder</span><span>::</span><span>new</span><span>()</span>
        <span>.allow_origins</span><span>(</span><span>AllowedOrigins</span><span>::</span><span>Any</span> <span>{</span> <span>allow_null</span><span>:</span> <span>true</span> <span>}</span> <span>)</span>
        <span>.build</span><span>();</span>

<span>ServiceBuilder</span><span>::</span><span>new</span><span>()</span>
    <span>.resource</span><span>(</span><span>WeatherApi</span><span>)</span>
    <span>.middleware</span><span>(</span><span>cors</span><span>)</span>
    <span>.run</span><span>(</span><span>&amp;</span><span>addr</span><span>)</span>
    <span>.unwrap</span><span>();</span>
</code></pre></div></div>

<p>You can check that the API works as intended by running the server and issuing an HTTP GET request with <code>curl</code> or <a href="https://www.postman.com/">Postman</a>.</p>


<p>Now, let‚Äôs create a simple UI Dashboard. The purpose of our interface will be to display a historical plot of temperature, humidity and pressure readings from our weather station. We won‚Äôt use any complex javascript frameworks and stick to vanilla javascript. This is how the final result will look like:</p>

<figure><img src="https://blog.kdubovikov.ml/assets/img/esp32-weather-station/post-1/weather-dashboard.gif"><figcaption></figcaption></figure>

<h2 id="markup">Markup</h2>
<p>For a start, let‚Äôs look at <code>index.html</code>:</p>

<div><div><pre><code><span>&lt;html&gt;</span>
<span>&lt;head&gt;</span>
	<span>&lt;link</span> <span>rel=</span><span>"stylesheet"</span> <span>href=</span><span>"styles/weather_station.css"</span> <span>/&gt;</span>
	
    <span>&lt;!-- load fonts --&gt;</span>
	<span>&lt;link</span> <span>href=</span><span>"https://fonts.googleapis.com/css2?family=Open+Sans:wght@300&amp;display=swap"</span> <span>rel=</span><span>"stylesheet"</span><span>&gt;</span>
    
    <span>&lt;!-- a few libraries that we will use --&gt;</span>
    <span>&lt;!-- a css framework for animations --&gt;</span>
	<span>&lt;link</span> <span>rel=</span><span>"stylesheet"</span> <span>href=</span><span>"https://cdnjs.cloudflare.com/ajax/libs/animate.css/4.0.0/animate.min.css"</span> <span>/&gt;</span>

    <span>&lt;!-- chart.js for plots --&gt;</span>
	<span>&lt;script </span><span>src=</span><span>"https://cdn.jsdelivr.net/npm/chart.js@2.9.3/dist/Chart.min.js"</span><span>&gt;&lt;/script&gt;</span>

    <span>&lt;!-- moment.js for working with dates --&gt;</span>
	<span>&lt;script </span><span>src=</span><span>"https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.26.0/moment.min.js"</span><span>&gt;&lt;/script&gt;</span>

    <span>&lt;!-- our main script, we will look into this later üòâ --&gt;</span>
	<span>&lt;script </span><span>src=</span><span>"index.js"</span><span>&gt;&lt;/script&gt;</span>
<span>&lt;/head&gt;</span>
<span>&lt;body&gt;</span>
    <span>&lt;!-- let's use HTML5 section tags to group --&gt;</span>
    <span>&lt;!-- related content together instead of using ambiguous div's --&gt;</span>
	<span>&lt;header&gt;</span>
		<span>&lt;div</span> <span>class=</span><span>"weatherIcon"</span><span>&gt;</span>
			<span>&lt;object</span> <span>data=</span><span>"img/weather_icon.svg"</span> <span>type=</span><span>"image/svg+xml"</span><span>&gt;&lt;/object&gt;</span>
		<span>&lt;/div&gt;</span>
		
		<span>&lt;h1&gt;</span>How's the <span>&lt;span</span> <span>class=</span><span>"accent"</span><span>&gt;</span>weather<span>&lt;/span&gt;</span>?<span>&lt;/h1&gt;</span>
	<span>&lt;/header&gt;</span>
	
	<span>&lt;section&gt;</span>
        <span>&lt;!-- this is a group of radio buttons --&gt;</span> s
        <span>&lt;!-- that user can click to switch between different metrics --&gt;</span>
		<span>&lt;div</span> <span>class=</span><span>"group"</span><span>&gt;</span>
			<span>&lt;input</span> <span>type=</span><span>"radio"</span> <span>name=</span><span>"rb"</span> <span>id=</span><span>"temp_radio"</span> <span>/&gt;</span>
		    <span>&lt;label</span> <span>for=</span><span>"temp_radio"</span><span>&gt;</span>Temperature<span>&lt;/label&gt;</span>
		    <span>&lt;input</span> <span>type=</span><span>"radio"</span> <span>name=</span><span>"rb"</span> <span>id=</span><span>"humidity_radio"</span> <span>/&gt;</span>
		    <span>&lt;label</span> <span>for=</span><span>"humidity_radio"</span><span>&gt;</span>Humidity<span>&lt;/label&gt;</span>
		    <span>&lt;input</span> <span>type=</span><span>"radio"</span> <span>name=</span><span>"rb"</span> <span>id=</span><span>"pressure_radio"</span> <span>/&gt;</span>
		    <span>&lt;label</span> <span>for=</span><span>"pressure_radio"</span><span>&gt;</span>Pressure<span>&lt;/label&gt;</span>
		<span>&lt;/div&gt;</span>
		
        <span>&lt;!-- a canvas that we will pass on to chart.js in our main script --&gt;</span>
		<span>&lt;div</span> <span>class=</span><span>"chartContainer"</span><span>&gt;</span>
			<span>&lt;canvas</span> <span>id=</span><span>"tempChart"</span> <span>width=</span><span>"50"</span> <span>height=</span><span>"50"</span><span>&gt;&lt;/canvas&gt;</span>
		<span>&lt;/div&gt;</span>
	<span>&lt;/section&gt;</span>
<span>&lt;/body&gt;</span>
<span>&lt;/html&gt;</span>
</code></pre></div></div>

<h2 id="ui-logic">UI logic</h2>
<p>Having finished with the markup we now can transition to making our dashboard to be useful by implementing some logic in the <code>index.js</code> script. As a headstart, let‚Äôs start from the top abstraction level and look what the code does in overall:</p>

<div><div><pre><code><span>const</span> <span>API_URL</span> <span>=</span> <span>"</span><span>http://localhost:8080</span><span>"</span><span>;</span>

<span>// this will be called by browser as soon as</span>
<span>// all necessary resources were loaded and the page</span>
<span>// is ready to render</span>
<span>window</span><span>.</span><span>onload</span> <span>=</span> <span>async</span> <span>()</span> <span>=&gt;</span> <span>{</span>
    <span>// fetch data from our API</span>
    <span>// we use asynchronous calls to block execution only when necessary</span>
    <span>const</span> <span>data</span> <span>=</span> <span>await</span> <span>(</span><span>await</span> <span>fetch</span><span>(</span><span>API_URL</span><span>)).</span><span>json</span><span>()</span>

    <span>// convert timestamps to the label format we want to use in our charts</span>
    <span>const</span> <span>labels</span> <span>=</span> <span>data</span><span>.</span><span>messages</span><span>.</span><span>map</span><span>(</span><span>item</span> <span>=&gt;</span> <span>moment</span><span>(</span><span>item</span><span>.</span><span>timestamp</span><span>).</span><span>format</span><span>(</span><span>'</span><span>ddd HH a</span><span>'</span><span>));</span>

    <span>// render chart</span>
    <span>let</span> <span>chart</span> <span>=</span> <span>createChart</span><span>(</span><span>labels</span><span>,</span> <span>data</span><span>);</span>

    <span>// create handlers for radio buttons that can be used to select different metrics</span>
    <span>// that will be displayed on the chart</span>
    <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>"</span><span>temp_radio</span><span>"</span><span>).</span><span>onclick</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>{</span>
        <span>// this call will prepare data to be used in a </span>
        <span>// format that chart.js expects as an input</span>
        <span>const</span> <span>tempData</span> <span>=</span> <span>createChartDataset</span><span>(</span><span>data</span><span>,</span> <span>'</span><span>temp</span><span>'</span><span>);</span>

        <span>// this function will update the initialized chart with</span>
        <span>// new data, along with its minimal and maximal bounds</span>
        <span>updateChart</span><span>(</span><span>chart</span><span>,</span> <span>tempData</span><span>,</span> <span>tempData</span><span>.</span><span>min</span> <span>-</span> <span>5</span><span>,</span> <span>tempData</span><span>.</span><span>max</span> <span>+</span> <span>5</span><span>);</span>
    <span>};</span>

    <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>"</span><span>pressure_radio</span><span>"</span><span>).</span><span>onclick</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>{</span>
        <span>const</span> <span>pressureData</span> <span>=</span> <span>createChartDataset</span><span>(</span><span>data</span><span>,</span> <span>'</span><span>pressure</span><span>'</span><span>);</span>
        <span>updateChart</span><span>(</span><span>chart</span><span>,</span> <span>pressureData</span><span>,</span> <span>700</span><span>,</span> <span>pressureData</span><span>.</span><span>max</span> <span>+</span> <span>10</span><span>);</span>
    <span>};</span>

    <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>"</span><span>humidity_radio</span><span>"</span><span>).</span><span>onclick</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>{</span>
        <span>const</span> <span>humidityData</span> <span>=</span> <span>createChartDataset</span><span>(</span><span>data</span><span>,</span> <span>'</span><span>humidity</span><span>'</span><span>);</span>
        <span>updateChart</span><span>(</span><span>chart</span><span>,</span> <span>humidityData</span><span>,</span> <span>0</span><span>,</span> <span>100</span><span>);</span>
    <span>};</span>

    <span>// set default metric to temperature</span>
    <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>'</span><span>temp_radio</span><span>'</span><span>).</span><span>click</span><span>();</span>
<span>};</span>
</code></pre></div></div>

<p>Now that we have seen the whole picture, let‚Äôs look at how the individual functions work. We will start with <code>createChart</code>, that uses our canvas to display a plot using chart.js library:</p>

<div><div><pre><code><span>/**
 * Creates a new chart
 * @param {Array.&lt;string&gt;} labels 
 * @param {Array} data 
 */</span>
<span>function</span> <span>createChart</span><span>(</span><span>labels</span><span>,</span> <span>data</span><span>)</span> <span>{</span>
    <span>let</span> <span>ctx</span> <span>=</span> <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>'</span><span>tempChart</span><span>'</span><span>).</span><span>getContext</span><span>(</span><span>'</span><span>2d</span><span>'</span><span>);</span>
    <span>// Set colors and fonts</span>
    <span>Chart</span><span>.</span><span>defaults</span><span>.</span><span>global</span><span>.</span><span>defaultFontColor</span> <span>=</span> <span>'</span><span>#636160ff</span><span>'</span><span>;</span>
    <span>Chart</span><span>.</span><span>defaults</span><span>.</span><span>global</span><span>.</span><span>defaultFontFamily</span> <span>=</span> <span>'</span><span>"Open Sans", sans-serif</span><span>'</span><span>;</span>
    <span>Chart</span><span>.</span><span>defaults</span><span>.</span><span>global</span><span>.</span><span>defaultFontSize</span> <span>=</span> <span>20</span><span>;</span>

    <span>// Create chart </span>
    <span>let</span> <span>chart</span> <span>=</span> <span>new</span> <span>Chart</span><span>(</span><span>ctx</span><span>,</span> <span>{</span>
        <span>"</span><span>type</span><span>"</span><span>:</span> <span>"</span><span>line</span><span>"</span><span>,</span>
        <span>"</span><span>data</span><span>"</span><span>:</span> <span>{</span>
            <span>"</span><span>labels</span><span>"</span><span>:</span> <span>labels</span><span>,</span>
            <span>"</span><span>datasets</span><span>"</span><span>:</span> <span>[{</span>
                <span>"</span><span>label</span><span>"</span><span>:</span> <span>""</span><span>,</span>
                <span>"</span><span>data</span><span>"</span><span>:</span> <span>data</span><span>,</span>
                <span>"</span><span>fill</span><span>"</span><span>:</span> <span>false</span><span>,</span>
                <span>"</span><span>borderColor</span><span>"</span><span>:</span> <span>"</span><span>#6e2594ff</span><span>"</span><span>,</span>
                <span>"</span><span>lineTension</span><span>"</span><span>:</span> <span>0.1</span>
            <span>}]</span>
        <span>},</span>
        <span>"</span><span>options</span><span>"</span><span>:</span> <span>{</span>
            <span>"</span><span>legend</span><span>"</span><span>:</span> <span>{</span>
                <span>"</span><span>display</span><span>"</span><span>:</span> <span>false</span>
            <span>},</span>
            <span>"</span><span>aspectRatio</span><span>"</span><span>:</span> <span>1</span><span>,</span>
            <span>"</span><span>maintainAspectRatio</span><span>"</span><span>:</span> <span>false</span><span>,</span>
            <span>"</span><span>scales</span><span>"</span><span>:</span> <span>{</span>
                <span>"</span><span>yAxes</span><span>"</span><span>:</span> <span>[{</span>
                    <span>"</span><span>offset</span><span>"</span><span>:</span> <span>true</span><span>,</span>
                    <span>"</span><span>gridLines</span><span>"</span><span>:</span> <span>{</span>
                        <span>"</span><span>display</span><span>"</span><span>:</span> <span>false</span>
                    <span>},</span>
                    <span>"</span><span>ticks</span><span>"</span><span>:</span> <span>{</span>
                        <span>"</span><span>suggestedMin</span><span>"</span><span>:</span> <span>0</span><span>,</span>
                        <span>"</span><span>suggestedMax</span><span>"</span><span>:</span> <span>35</span>
                    <span>}</span>
                <span>}],</span>
                <span>"</span><span>xAxes</span><span>"</span><span>:</span> <span>[{</span>
                    <span>"</span><span>offset</span><span>"</span><span>:</span> <span>true</span><span>,</span>
                    <span>"</span><span>gridLines</span><span>"</span><span>:</span> <span>{</span>
                        <span>"</span><span>display</span><span>"</span><span>:</span> <span>false</span>
                    <span>}</span>
                <span>}]</span>
            <span>}</span>
        <span>}</span>
    <span>});</span>

    <span>return</span> <span>chart</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Now, let‚Äôs look at how we can prepare data to be rendered by chart.js uring <code>createChartDataset</code> function:</p>

<div><div><pre><code><span>/**
 * Transforms API response into an object that can be used in the {@link updateChart} call. 
 * @param {Object} data 
 * @param {string} selector 
 */</span>
<span>function</span> <span>createChartDataset</span><span>(</span><span>data</span><span>,</span> <span>selector</span><span>)</span> <span>{</span>
    <span>let</span> <span>series</span> <span>=</span> <span>data</span><span>.</span><span>messages</span><span>.</span><span>map</span><span>(</span><span>item</span> <span>=&gt;</span> <span>item</span><span>[</span><span>selector</span><span>]);</span>
    <span>return</span> <span>{</span>
        <span>'</span><span>dates</span><span>'</span><span>:</span> <span>data</span><span>.</span><span>messages</span><span>.</span><span>map</span><span>(</span><span>item</span> <span>=&gt;</span> <span>item</span><span>.</span><span>timestamp</span><span>),</span>
        <span>'</span><span>data</span><span>'</span><span>:</span> <span>series</span><span>,</span>
        <span>'</span><span>min</span><span>'</span><span>:</span> <span>Math</span><span>.</span><span>min</span><span>.</span><span>apply</span><span>(</span><span>series</span><span>),</span>
        <span>'</span><span>max</span><span>'</span><span>:</span> <span>Math</span><span>.</span><span>max</span><span>.</span><span>apply</span><span>(</span><span>series</span><span>)</span>
    <span>};</span>
<span>}</span>
</code></pre></div></div>

<p>Finally, let‚Äôs look at how to update the existing chart‚Äôs data:</p>

<div><div><pre><code><span>/**
 * Updates given chart using data and sets y axis min and max values 
 * @param {ChartJS object} chart 
 * @param {Object} data 
 * @param {number} min 
 * @param {number} max 
 */</span>
<span>function</span> <span>updateChart</span><span>(</span><span>chart</span><span>,</span> <span>data</span><span>,</span> <span>min</span><span>,</span> <span>max</span><span>)</span> <span>{</span>
    <span>chart</span><span>.</span><span>data</span><span>.</span><span>datasets</span><span>[</span><span>0</span><span>].</span><span>data</span> <span>=</span> <span>data</span><span>.</span><span>data</span><span>;</span>
    <span>chart</span><span>.</span><span>data</span><span>.</span><span>datasets</span><span>[</span><span>0</span><span>].</span><span>labels</span> <span>=</span> <span>data</span><span>.</span><span>dates</span><span>.</span><span>map</span><span>(</span><span>item</span> <span>=&gt;</span> <span>moment</span><span>(</span><span>item</span><span>.</span><span>timestamp</span><span>).</span><span>format</span><span>(</span><span>'</span><span>ddd HH a</span><span>'</span><span>));</span>
    <span>chart</span><span>.</span><span>options</span><span>.</span><span>scales</span><span>.</span><span>yAxes</span><span>[</span><span>0</span><span>].</span><span>ticks</span><span>.</span><span>suggestedMin</span> <span>=</span> <span>min</span><span>;</span>
    <span>chart</span><span>.</span><span>options</span><span>.</span><span>scales</span><span>.</span><span>yAxes</span><span>[</span><span>0</span><span>].</span><span>ticks</span><span>.</span><span>suggestedMax</span> <span>=</span> <span>max</span><span>;</span>
    <span>chart</span><span>.</span><span>update</span><span>();</span>

<span>}</span>
</code></pre></div></div>

<p>That is everything that we neet to fetch and render our weather station measurements using an API. Now, let‚Äôs switch to the styling part and make things look a bit prettier.</p>

<h2 id="styling">Styling</h2>

<p>In this project, we will use <a href="https://sass-lang.com/">SASS</a> extension language as a handy abstraction upon regular CSS. It allows to write stylesheets in a more clean and readable manner. I won‚Äôt do a detailed walkthrough of the stylesheet and encourage you to clone the repository, open the <code>index.html</code> file in the browser and play with the styles yourself. Page styling and design are better to be learned in practice: install <code>sass</code>, read documentation and experiment.</p>



<p>By this post, we conclude the journey that led us from building ESP32 based weather station hardware, writing firmware, coding the backend service that tracks all measurements, building a Telegram notification bot and creating a simple web dashboard ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.kdubovikov.ml/articles/rust/ui/weather-station-ui">https://blog.kdubovikov.ml/articles/rust/ui/weather-station-ui</a></em></p>]]>
            </description>
            <link>https://blog.kdubovikov.ml/articles/rust/ui/weather-station-ui</link>
            <guid isPermaLink="false">hacker-news-small-sites-25047091</guid>
            <pubDate>Tue, 10 Nov 2020 15:35:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Use OpenAPI with API Gateway REST APIs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046983">thread link</a>) | @sashee
<br/>
November 10, 2020 | https://advancedweb.hu/how-to-use-openapi-with-api-gateway-rest-apis/ | <a href="https://web.archive.org/web/*/https://advancedweb.hu/how-to-use-openapi-with-api-gateway-rest-apis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <h2 id="rest-api-resources-with-openapi">REST API resources with OpenAPI</h2> <p>Similar to API Gateway HTTP APIs, REST APIs also support importing an OpenAPI document. This document is a standardized way to define APIs and various tools, such as validators and generators, can consume this format. API Gateway also supports it which gives a convenient way to set up the resources needed for the API.</p> <div> <p> Related </p> <div> <p><a href="https://advancedweb.hu/how-to-use-openapi-to-deploy-an-api-gateway-http-api/"> <img src="https://advancedweb.hu/assets/3a9d0c-e17731062a958aeb7b52b3dea994d2bde848598abc49aafcf6db5d3bd81a04ee.jpg" integrity="sha256-djc+uKXhNM0bvbpFhAC1V40PQoiICGzQZhsGj9dCR3A=" crossorigin="anonymous"> </a> </p> <div>  <p> Import and initialize an HTTP API using an OpenAPI document </p> </div> </div> </div> <p>To initialize a REST API using OpenAPI, choose import:</p> <p><img alt="Import REST API using OpenAPI" src="https://advancedweb.hu/assets/posts/openapi_rest_api/import-e34948d6e912777024b7508c863550bab1528fc5503c13cc2accf405867c2e19.png" integrity="sha256-40lI1ukSd3Akt1CMhjVQurFSj8VQPBPMKsz0BYZ8Lhk=" crossorigin="anonymous"></p> <p>The document defines the paths and operations:</p> <div><div><pre><code><span>paths</span><span>:</span>
  <span>/user</span><span>:</span>
    <span>post</span><span>:</span>
      <span>operationId</span><span>:</span> <span>createUser</span>
      <span>summary</span><span>:</span> <span>Create user</span>
      <span>requestBody</span><span>:</span>
        <span># ...</span>
      <span>responses</span><span>:</span>
        <span>default</span><span>:</span>
          <span>description</span><span>:</span> <span>Success</span>
</code></pre></div></div> <p>The import process then creates all the API Gateway resources that are needed for the API. For example, it creates a route for the path:</p> <p><img alt="Imported resources" src="https://advancedweb.hu/assets/posts/openapi_rest_api/resources-4ccd0930db5049b822010e535c6135622ee7776315ed2000b04287a3c3c91148.png" integrity="sha256-TM0JMNtQSbgiAQ5TXGE1Yi7nd2MV7SAAsEKHo8PJEUg=" crossorigin="anonymous"></p> <p>Apart from the routes, it creates data models. For example, the operation can define a request body using a JSON schema:</p> <div><div><pre><code><span>paths</span><span>:</span>
  <span>/user</span><span>:</span>
    <span>post</span><span>:</span>
      <span># ...</span>
      <span>requestBody</span><span>:</span>
        <span>content</span><span>:</span>
          <span>'</span><span>application/json'</span><span>:</span>
            <span>schema</span><span>:</span>
              <span>type</span><span>:</span> <span>object</span>
              <span>properties</span><span>:</span>
                <span>name</span><span>:</span>
                  <span>type</span><span>:</span> <span>string</span>
              <span>required</span><span>:</span>
                <span>-</span> <span>name</span>
              <span>additionalProperties</span><span>:</span> <span>false</span>
        <span>required</span><span>:</span> <span>true</span>
</code></pre></div></div> <p>The import process creates a model based on this schema:</p> <p><img alt="Imported models" src="https://advancedweb.hu/assets/posts/openapi_rest_api/model-48b9fad17584868429d9b6ac66d5a1f7ab4cafee7721353459505a0febcf4081.png" integrity="sha256-SLn60XWEhoQp2basZtWh96tMr+53ITU0WVBaD+vPQIE=" crossorigin="anonymous"></p> <p>And also associates the model with the method‚Äôs body:</p> <p><img alt="Imported models is associated with the request" src="https://advancedweb.hu/assets/posts/openapi_rest_api/request_model-a0471f965d11bdf9eb2b25463e0c85f3b88e5cae6020abda66bd4514077bb1c9.png" integrity="sha256-oEcfll0RvfnrKyVGPgyF87iOXK5gIKvaZr1FFAd7sck=" crossorigin="anonymous"></p> <p> Learn the services needed to build a serverless HTTP-based API on AWS from our <a href="#" data-toggle="modal" data-target="#contextual-promo-popup">free email course</a> . </p> <h3 id="vendor-extensions">Vendor extensions</h3> <p>OpenAPI supports vendor extensions which are properties starting with <code>x-</code>. These properties can define configurations that are not supported by the base OpenAPI specification. API Gateway <a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-swagger-extensions.html">supports many such extensions</a> for various purposes. Usually, anything that you can set using the Console can be configured embedded in the OpenAPI document.</p> <h4 id="integration">Integration</h4> <p>One of the most important is how to define an integration. It specifies where and how to send the request for a given operation. This uses the <code>x-amazon-apigateway-integration</code> property.</p> <p>Unlike HTTP APIs, REST APIs don‚Äôt support using <code>$ref</code>s for integrations, so you need to specify all its properties for every operation. Here is how to use a Lambda function to handle an operation:</p> <div><div><pre><code><span>paths</span><span>:</span>
  <span>/user</span><span>:</span>
    <span>post</span><span>:</span>
      <span>x-amazon-apigateway-integration</span><span>:</span>
        <span>type</span><span>:</span> <span>aws_proxy</span>
        <span>uri</span><span>:</span> <span>arn:${AWS::Partition}:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/&lt;lambda arn&gt;/invocations</span>
        <span>httpMethod</span><span>:</span> <span>POST</span>
      <span># ...</span>
</code></pre></div></div> <p>The <code>aws_proxy</code> defines the lambda proxy integration type. It forwards everything to the function and does not transform the response besides extracting the values from the JSON object.</p> <p>The <code>uri</code> has a specific format: <code>arn:&lt;partition&gt;:apigateway:&lt;region&gt;:lambda:path/2015-03-31/functions/&lt;lambda arn&gt;/invocations</code>. This seems complicated, but API Gateway <a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/import-api-aws-variables.html">supports variables</a> that make it easier to construct. By using the <code>${AWS::Partition}</code> and the <code>${AWS::Region}</code> placeholders the only moving part is the ARN of the Lambda function.</p> <p>The <code>httpMethod</code> is how API Gateway calls the Lambda, which is always POST.</p> <p>This integration makes this flow:</p> <p><img alt="Method execution flow" src="https://advancedweb.hu/assets/posts/openapi_rest_api/flow-f42333e998eec45e0981de12d31cfa9b5a7e6fca839c3566b78085e59fa5532b.png" integrity="sha256-9CMz6ZjuxF4Jgd4S0xz6m1p+b8qDnDVmt4CF5Z+lUys=" crossorigin="anonymous"></p> <h4 id="request-validation">Request validation</h4> <p>REST APIs support validation both for parameters and for the request body. This is especially useful as it makes the OpenAPI document the source of truth for which requests are accepted and which are not.</p> <p>You can enable validation for the whole API in one place, and all operations inherit from there. To do this, add a named validator under <code>x-amazon-apigateway-request-validators</code> and configure it to validate both the request body and the parameters.</p> <p>To select this validator for the whole API as the default, use the <code>x-amazon-apigateway-request-validator</code>:</p> <div><div><pre><code><span>x-amazon-apigateway-request-validators</span><span>:</span>
  <span>all</span><span>:</span>
    <span>validateRequestBody</span><span>:</span> <span>true</span>
    <span>validateRequestParameters</span><span>:</span> <span>true</span>
<span>x-amazon-apigateway-request-validator</span><span>:</span> <span>all</span>
</code></pre></div></div> <p>This setup adds the <code>all</code> validator to every method:</p> <p><img alt="Method validator" src="https://advancedweb.hu/assets/posts/openapi_rest_api/validator-bd53bffcaaea6ab6ff55109f15340d150f5d8c621b90a35c30de0640fc350230.png" integrity="sha256-vVO//Krqarb/VRCfFTQNFQ9djGIbkKNcMN4GQPw1AjA=" crossorigin="anonymous"></p> <p>Let‚Äôs see how it works!</p> <p>The API expects a request body with only a <code>name</code> property. When there is extra fields in the object, API Gateway returns an error without contacting the Lambda function:</p> <div><div><pre><code><span>---</span> ~ ¬ª curl <span>-X</span> POST <span>-i</span> <span>"</span><span>$API</span><span>/user"</span> <span>-H</span> <span>"Content-Type: application/json"</span> <span>-d</span> <span>"{</span><span>\"</span><span>name</span><span>\"</span><span>:</span><span>\"</span><span>testuser</span><span>\"</span><span>,</span><span>\"</span><span>userid</span><span>\"</span><span>:</span><span>\"</span><span>123</span><span>\"</span><span>}"</span>
HTTP/2 400
content-type: application/json
content-length: 35

<span>{</span><span>"message"</span>: <span>"Invalid request body"</span><span>}</span>
</code></pre></div></div> <h2 id="backend">Backend</h2> <p>On the backend, the <code>operationId</code> is available in the event object under the name <code>operationName</code>. This makes it easy to handle multiple operations in a single function.</p> <div><div><pre><code>	<span>const</span> <span>operationName</span> <span>=</span> <span>event</span><span>.</span><span>requestContext</span><span>.</span><span>operationName</span><span>;</span>
	<span>const</span> <span>method</span> <span>=</span> <span>event</span><span>.</span><span>httpMethod</span><span>;</span>
	<span>const</span> <span>body</span> <span>=</span> <span>event</span><span>.</span><span>body</span><span>;</span>

	<span>if</span> <span>(</span><span>operationName</span> <span>===</span> <span>"</span><span>getUser</span><span>"</span><span>)</span> <span>{</span>
		<span>// ...</span>
	<span>}</span><span>else</span> <span>if</span> <span>(</span><span>operationName</span> <span>===</span> <span>"</span><span>updateUser</span><span>"</span> <span>)</span> <span>{</span>
		<span>// ...</span>
	<span>}</span>
</code></pre></div></div> <p>The path parameters are also extracted from the request. For example, this path has a placeholder called <code>userid</code>:</p> <div><div><pre><code><span>paths</span><span>:</span>
  <span>'</span><span>/user/{userid}'</span><span>:</span>
    <span>parameters</span><span>:</span>
    <span>-</span> <span>name</span><span>:</span> <span>userid</span>
      <span>in</span><span>:</span> <span>path</span>
      <span>required</span><span>:</span> <span>true</span>
      <span>schema</span><span>:</span>
        <span>type</span><span>:</span> <span>string</span>
    <span>delete</span><span>:</span>
      <span>operationId</span><span>:</span> <span>deleteUser</span>
      <span>summary</span><span>:</span> <span>Delete user</span>
      <span>responses</span><span>:</span>
        <span>200</span><span>:</span>
          <span>description</span><span>:</span> <span>Success</span>
</code></pre></div></div> <p>The event object contains the extracted value:</p> <div><div><pre><code><span>const</span> <span>userid</span> <span>=</span> <span>event</span><span>.</span><span>pathParameters</span><span>.</span><span>userid</span><span>;</span>
</code></pre></div></div> <p>Unlike HTTP APIs, REST APIs only support the Lambda integration format 1.0. This means there is no shortcut return type, and every response must define the <code>statusCode</code> and stringify the <code>body</code>:</p> <div><div><pre><code><span>return</span> <span>{</span>
	<span>statusCode</span><span>:</span> <span>200</span><span>,</span>
	<span>headers</span><span>:</span> <span>{</span>
		<span>"</span><span>Content-Type</span><span>"</span><span>:</span> <span>"</span><span>application/json</span><span>"</span><span>,</span>
	<span>},</span>
	<span>body</span><span>:</span> <span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>items</span><span>.</span><span>Items</span><span>),</span>
<span>};</span>
</code></pre></div></div> <p>Also, it‚Äôs a bit slower than an HTTP API, as it does more things. And more importantly, it does not support the <code>$default</code> stage.</p> <div> <p> Related </p> <div> <p><a href="https://advancedweb.hu/how-to-use-the-aws-apigatewayv2-api-to-add-an-http-api-to-a-lambda-function/"> <img src="https://advancedweb.hu/assets/dbb39c-7051aa276e739bd77b8fe10336b4a9a16f9f322a381b4292dc009d1cfaf5d005.jpg" integrity="sha256-v8mShbwhEPRTMuMZRsSWSLLye+t+p9JZx1Q7LPlYQc0=" crossorigin="anonymous"> </a> </p> <div>  <p> Learn how to use AWS HTTP APIs to easily expose a Lambda-backed API </p> </div> </div> </div> <h2 id="terraform">Terraform</h2> <p>To specify a Lambda function that is managed by Terraform, the OpenAPI document needs to define placeholders for the functions‚Äô ARNs:</p> <div><div><pre><code><span>paths</span><span>:</span>
  <span>/user</span><span>:</span>
    <span>post</span><span>:</span>
      <span>x-amazon-apigateway-integration</span><span>:</span>
        <span>type</span><span>:</span> <span>aws_proxy</span>
        <span>uri</span><span>:</span> <span>arn:$${AWS::Partition}:apigateway:$${AWS::Region}:lambda:path/2015-03-31/functions/${users_lambda_arn}/invocations</span>
        <span>httpMethod</span><span>:</span> <span>POST</span>
</code></pre></div></div> <p>This construct defines the <code>users_lambda_arn</code> which will be substituted when Terraform deploys the stack. But since this interpolation uses the same <code>${...}</code> syntax as the AWS variables, the latter needs to be escaped using <code>$${...}</code>.</p> <p>In the <code>tf</code> file, the <code>templatefile</code> function provides a way to insert values for the placeholders:</p> <div><div><pre><code><span>resource</span> <span>"aws_api_gateway_rest_api"</span> <span>"rest_api"</span> <span>{</span>
	<span>name</span> <span>=</span> <span>"</span><span>${</span><span>random_id</span><span>.</span><span>id</span><span>.</span><span>hex</span><span>}</span><span>-rest-api"</span>
	<span>body</span> <span>=</span> <span>templatefile</span><span>(</span><span>"api.yml"</span><span>,</span> <span>{</span><span>users_lambda_arn</span> <span>=</span> <span>aws_lambda_function</span><span>.</span><span>users_lambda</span><span>.</span><span>arn</span><span>})</span>
<span>}</span>
</code></pre></div></div> <p>During <code>terraform apply</code> Terraform creates the function then initializes the API using an OpenAPI document that references the Lambda function. This wires the API to the backend.</p> <p>The other required resource is a deployment that creates a stage and deploys the API:</p> <div><div><pre><code><span>resource</span> <span>"aws_api_gateway_deployment"</span> <span>"deployment"</span> <span>{</span>
	<span>rest_api_id</span> <span>=</span> <span>aws_api_gateway_rest_api</span><span>.</span><span>rest_api</span><span>.</span><span>id</span>
	<span>stage_name</span>  <span>=</span> <span>"stage"</span>
<span>}</span>
</code></pre></div></div> <p>And finally, the permission to allow the API to call the Lambda function:</p> <div><div><pre><code><span>resource</span> <span>"aws_lambda_permission"</span> <span>"apigw"</span> <span>{</span>
	<span>action</span>        <span>=</span> <span>"lambda:InvokeFunction"</span>
	<span>function_name</span> <span>=</span> <span>aws_lambda_function</span><span>.</span><span>users_lambda</span><span>.</span><span>arn</span>
	<span>principal</span>     <span>=</span> <span>"apigateway.amazonaws.com"</span>

	<span>source_arn</span> <span>=</span> <span>"</span><span>${</span><span>aws_api_gateway_rest_api</span><span>.</span><span>rest_api</span><span>.</span><span>execution_arn</span><span>}</span><span>/*/*/*"</span>
<span>}</span>
</code></pre></div></div> <h2 id="conclusion">Conclusion</h2> <p>The OpenAPI document provides a central place to describe various aspects of an API. API Gateway REST API supports many parts of this specification and adds its own to it. As a result, you can define all aspects of the API in the document and deploy everything in this format, letting API Gateway create the resources.</p> </div></div>]]>
            </description>
            <link>https://advancedweb.hu/how-to-use-openapi-with-api-gateway-rest-apis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046983</guid>
            <pubDate>Tue, 10 Nov 2020 15:27:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benchmarking Pulsar and Kafka ‚Äì The Full Benchmark Report]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25046908">thread link</a>) | @tuhaihe
<br/>
November 10, 2020 | https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance-report | <a href="https://web.archive.org/web/*/https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance-report">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance-report</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046908</guid>
            <pubDate>Tue, 10 Nov 2020 15:22:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making Mass Effect not require admin rights, or how not to write a boolean check]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046894">thread link</a>) | @zdw
<br/>
November 10, 2020 | https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/ | <a href="https://web.archive.org/web/*/https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p>Hi all, it‚Äôs me again, your favorite modder who publishes a single research blog post a year. Welcome to my new blog, where I will also post maybe once a year! I got fed up with blogger‚Äôs endless unfixed bugs. I‚Äôm going to leave the content there though for historical sake.</p>
<p>I just finished a hardcore crunch to ship ALOT Installer V4, which is a complete rewrite of ALOT Installer. ALOT Installer is the Mass Effect modding scene‚Äôs main texture installation tool, built on top of aquadran‚Äôs MassEffectModder program, which can be used to install textures in a more advanced fashion. In V4 of ALOT Installer, I split the main ‚Äòcore‚Äô features into a cross-platform .NET Core library so I can also write a frontend that works on Linux. But that‚Äôs not why I‚Äôm here today ‚Äì I‚Äôm here to follow up on how I fixed Mass Effect on PC to not require elevation for good.</p>
<h2>Mass Effect on PC: About what you‚Äôd be expect from a mid 2000‚Äôs console port</h2>
<p>For those of you not in the know, Mass Effect came out on PC back in 2008, and was ported from the Xbox 360 by a studio named Demiurge, who also developed Pinnacle Station for Mass Effect. It‚Äôs‚Ä¶ a really meh port that has not aged very well. It‚Äôs passable as a game but it has a lot of problems, even when it came out. Particle LODs not working properly, texture LODs being read backwards, ini settings being randomly reset to their defaults, the problems are pretty numerous, just to name a few. But nothing completely game breaking.</p>
<p>Well, kind of. There is one, but it‚Äôs not specifically due to Mass Effect. The big issue is that Mass Effect requires administrator rights to run, because Demiurge seems to have assumed everyone would run the game as administrator ‚Äì which <em>might</em> have been OK if the game was only really developed when Windows XP existed, but Windows Vista had already been out for over a year by the time the game had released. Even back then though, Windows XP had a concept of LUA (Least User Access) with separated user accounts. For more information on this, you should check out the original post I wrote, <a href="https://www.me3tweaks.com/blog/modding/why-mass-effect-requires-administrator-rights-and-how-we-fixed-origin-not-running-it/">Why Mass Effect on PC requires administrator</a>. It describes a lot of backstory to this post.</p>
<h2>Oh boy, PhysX, my favorite physics library!</h2>
<figure id="attachment_67" aria-describedby="caption-attachment-67"><img loading="lazy" src="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/ageialogo1.gif" alt="" width="236" height="134"><figcaption id="caption-attachment-67">I may have a slight beef with this SDK.</figcaption></figure><p>
Mass Effect for PC runs on a lightly modified version of Unreal Engine 3, which appears to be dated around late 2006. According to some former BioWare developers, this version of Unreal Engine was not very mature yet, to put it lightly. According to some stories from these developers, it was really difficult to work with because Epic Games was focused on Gears of War and not dedicating much time to their partners who were also using the engine.</p>
<p>Unreal Engine 3 uses PhysX for physics interactions, so Epic Games built a dll that interfaces PhysX to Unreal Engine data formats through a file named PhysXLoader.dll, which loads the PhysX libraries from both parties. PhysX is a physics simulation library that was acquired by AGEIA Technologies in the mid 2000s before AGEIA was sold to Nvidia in early 2008. If you remember Physics Processing Unit cards, or PPU, they were using PhysX before Nvidia promptly killed that idea.</p>
<figure id="attachment_66" aria-describedby="caption-attachment-66"><img loading="lazy" src="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-07_19h50_25.png" alt="" width="360" height="136" srcset="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-07_19h50_25.png 360w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-07_19h50_25-300x113.png 300w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-07_19h50_25-250x94.png 250w" sizes="(max-width: 360px) 100vw, 360px"><figcaption id="caption-attachment-66">PhysXLoader.dll, PhysXCore.dll, and NxCooking.dll make up the PhysX dlls for Mass Effect.</figcaption></figure>
<p>All three Mass Effect games use PhysX, but Mass Effect 2 and Mass Effect 3 use the system‚Äôs install of PhysX, while Mass Effect uses the local game‚Äôs PhysX. Mass Effect 2 and Mass Effect 3 also use the ‚Äòmodern‚Äô version of PhysX, rather than the legacy one that was shipped by AGEIA. Nvidia changed some paths under the hood when it took over, which separates Legacy out from it‚Äôs ‚Äòmodern‚Äô versions. </p>
<p>But that doesn‚Äôt seem to stop Legacy PhysX‚Äôs uninstaller from deleting modern PhysX‚Äôs files/registry keys, so during the course of testing this fix, my other copies of Mass Effect 2/3 didn‚Äôt work, even after installing the ‚Äòmodern‚Äô PhysX redistributable. It‚Äôs really annoying how BioWare couldn‚Äôt just ship a 8MB library with the game ‚Äì they already shipped the installer for PhysX with the game, so it‚Äôs not like it saved space!</p>
<p>But anyways‚Ä¶</p>
<h2>The issue with Epic Games‚Äô PhysXLoader.dll is that it can load PhysXCore.dll locally, or from the system‚Äôs installed version</h2>
<p>Err‚Ä¶ wait, how is that an issue? Can‚Äôt you just load the local dll, and if that doesn‚Äôt exist, load the system one? How is that an issue exactly?</p>
<figure id="attachment_73" aria-describedby="caption-attachment-73"><img loading="lazy" src="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1.jpg" alt="OH BOY HERE WE GO" width="294" height="294" srcset="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1.jpg 294w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1-150x150.jpg 150w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1-48x48.jpg 48w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1-250x250.jpg 250w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1-180x180.jpg 180w" sizes="(max-width: 294px) 100vw, 294px"><figcaption id="caption-attachment-73">You won‚Äôt believe how many facepalms there were as I making this fix.</figcaption></figure><p>
On boot, Mass Effect writes two values to the Windows HKEY_LOCAL_MACHINE registry:</p>
<blockquote><p>REG_BINARY HKLM\SOFTWARE\AGEIA Technologies enableLocalPhysXCore [mac address, 6 bytes]<br>
REG_DWORD HKLM\SOFTWARE\AGEIA Technologies EpicLocalDllHack [1]</p></blockquote>
<p>*Mass Effect is a 32-bit program, so on 64-bit systems it goes into HKLM\SOFTWARE\WOW6432Node\AGEIA Technologies instead, if you‚Äôre looking for yourself.</p>
<p>Remember these registry values, they‚Äôre going to be important later!</p>
<p>These registry values are why Mass Effect requires administrative permissions. In my previous blog post linked above, we explored why these writings were enough to make Microsoft put Mass Effect into it‚Äôs compatibility database, which forces it to run as admin when matching on certain executable criteria, which we worked around by modifying the executable criteria to no longer match. </p>
<p>We have to modify the executable to enable Large Address Aware, so the game could load higher resolution textures without running out of memory, so there was no way to avoid breaking the signature. This in turn caused Origin to no longer run the game as it would not elevate games without a valid EA signature. But if the game cannot write these registry keys on boot, the game may crash‚Ä¶ </p>
<p>So it‚Äôs already a big fun chain of problems, but we worked around Mass Effect needing administrative rights by simply giving the user account permissions to that specific AGEIA Technologies registry key. This would let the game process write the values it needed, and would we could go on our merry way. I assumed the game crashed because it was denied write permissions and Demiurge couldn‚Äôt be bothered to write a try/catch around the registry writing code.</p>
<h2>You probably shouldn‚Äôt name your registry values as a hack if you want me to think this is a good idea</h2>
<p>Our solution to this problem did not change Mass Effect‚Äôs behavior ‚Äì the values it wanted to write to the registry were going to be written one way or another, so we were just letting it do the thing it‚Äôs always done, just without administrative rights. There wasn‚Äôt really any change in application behavior.</p>
<figure id="attachment_81" aria-describedby="caption-attachment-81"><img loading="lazy" src="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-01_12h55_59.png" alt="" width="362" height="154" srcset="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-01_12h55_59.png 362w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-01_12h55_59-300x128.png 300w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-01_12h55_59-250x106.png 250w" sizes="(max-width: 362px) 100vw, 362px"><figcaption id="caption-attachment-81">The two registry values that Mass Effect writes.</figcaption></figure>
<p>mirh, a moderator for <a href="https://www.pcgamingwiki.com/wiki/Home">PC Gaming Wiki</a>, sounded the alarm for years that somehow we were breaking other games in ALOT Installer ‚Äì even though our application didn‚Äôt actually change how Mass Effect was behaving writing these values, so there‚Äôs no way our change would break other games.</p>
<p>After many months, he wrote a fairly detailed reason why ALOT Installer (when, in reality, it was Mass Effect) is breaking other games: <b>enableLocalPhysXCore</b> being in the registry <em>is used by other games using Epic Game‚Äôs PhysXLoader.dll.</em> When I was writing V4 of ALOT Installer, I told mirh I would take a more serious look into his idea of a solution that would not break other games, even though at the time I did not really understand how a registry key with the system‚Äôs MAC address would break other games ‚Äì or why it even used a MAC address to begin with.</p>
<p>mirh seems to have determined this enableLocalPhysXCore lets Mass Effect use the local directory‚Äôs PhysXCore.dll/NxCooking.dll, instead of loading the one from the installed PhysX redistributable. Mass Effect doesn‚Äôt install the PhysX redistributable, so it could not rely on it existing, so it needed to use the local libraries.</p>
<p>Hope you‚Äôre strapped in because this is where it gets really dumb: </p>
<h4>The MAC address stored in in the registry by MassEffect.exe is read by PhysXLoader.dll and compared against your system‚Äôs MAC address to determine if it should load the local directory‚Äôs PhysX libraries or the system‚Äôs.</h4>
<p>Which MAC address? </p>
<h3>¬Ø\_(„ÉÑ)_/¬Ø</h3>
<p>So the way Mass Effect works:</p>
<ol>
<li>Very early in the boot process of MassEffect.exe, your MAC address is read and written to the registry as enableLocalPhysXCore (along with EpicLocalDllHack)</li>
<li>MassEffect.exe loads PhysXLoader.dll</li>
<li>PhysXLoader.dll reads the value of enableLocalPhysXCore and compares your system‚Äôs MAC address against it</li>
<li>If it matches, it uses the local folder‚Äôs PhysX, if not, it uses the system‚Äôs redistributable version of PhysX</li>
</ol>
<p>Yes, you read that right.</p>
<p>It turns out that other games, such as Mirror‚Äôs Edge, have a PhysXLoader.dll that also reads these values (as they‚Äôre based on the same code), <em>but they don‚Äôt include local PhysX libraries</em>. So those games boot up, see enableLocalPhysXCore, and try to load the local library, which fails, and the game doesn‚Äôt start. This information is second hand from mirh ‚Äì I have not tested other games broken by this registry value.</p>
<p>Normally that value wouldn‚Äôt exist, and it should use the system PhysX. This behavior can be tested in Mass Effect by denying it write permissions to the registry key, deleting the values, and having Legacy PhysX installed ‚Äì it will use the system libraries instead. If system PhysX is not installed, the application will not boot ‚Äì this is why we originally had to let Mass Effect write these keys, otherwise it could appear that the installer broke Mass Effect, when it actually was a terrible implementation by Epic Games.</p>
<figure id="attachment_157" aria-describedby="caption-attachment-157"><img loading="lazy" src="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1.png" alt="Facepalm" width="782" height="433" srcset="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1.png 782w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-300x166.png 300w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-768x425.png 768w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-250x138.png 250w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-550x305.png 550w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-325x180.png 325w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-542x300.png 542w" sizes="(max-width: 782px) 100vw, 782px"><figcaption id="caption-attachment-157">It‚Äôs hard to imagine any possible scenario where this was a good idea.</figcaption></figure><p>
If you‚Äôre interfacing with a library that has exports you can call to initialize/load the PhysX SDK‚Ä¶ couldn‚Äôt you just, you know, pass a boolean to tell it to locally load? Why does it not locally look to begin with? And what‚Äôs up with the MAC address? Why is this in the registry, where it behaves LIKE A GLOBAL SETTING??? </p>
<p>All of these seem like terrible design decisions ‚Äì and after disassembling the ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/">https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/</a></em></p>]]>
            </description>
            <link>https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046894</guid>
            <pubDate>Tue, 10 Nov 2020 15:21:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Homegrown KDP doubling crystal for Nd:YAG laser]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046806">thread link</a>) | @buescher
<br/>
November 10, 2020 | http://www.milankarakas.org/pub/KDP/HomegrownKDP.html | <a href="https://web.archive.org/web/*/http://www.milankarakas.org/pub/KDP/HomegrownKDP.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><span>

<p>
Long time ago I had idea to add a doubling crystal to my
Nd:YAG laser to get green output. But the problem is
that I have no idea which one to buy. There is many
choices, but no simple guide which one will be
appropriate for such Q-switched Nd:YAG laser. I have
another Nd:YAG laser without Q-switch, and this
complicates things a bit more if I want to get doubled
frequency from that laser too.

</p><p>
I heard of KDP (chemical formula
KH<sub>2</sub>PO<sub>4</sub>), and I have that chemical
for hydroponic use, but did not believe that it is
possible to grow decent crystal for SHG (Second Harmonic
Generation). Since my school days, I know how to grow
crystals with jar, chemical and just fiber. This type of
growing crystals give only heap of crystals bond
together, for which I not believe that it is possible to
use as a SHG.

</p><p>
Just by accident, I watched video on YouTube about
growing another type of crystal, so called
‚Äòalum‚Äô, and there is explanation how to get
single seeded crystal. Aside that, I saw another video
where they grow KDP crystal for NIF (National Ignition
Facility). Second video looks too complicated to me, so
I decided to follow procedure for growing alum crystal,
but with KH<sub>2</sub>PO<sub>4</sub> chemical. Result
was disappointing. I got many crystals aside from the
seeded one, and mostly bonded together. I tried re-seed
bigger one, but it lead to even worst situation.

</p><p>
After few attempts I gave up. What I get is hundreds of
small crystals, for what I believed that there is no
even smallest chance to get frequency doubling, or
making other harmonics (THG, FHG, etc.). I tried to find
information on the internet about whether someone got
homegrown KDP crystal and use it as SHG. There is no
results. Only result I got is about purchasing such
crystals, but price is... huh... &nbsp; :-p

</p><p> In private conversation with my friend
<a href="http://www.jarrodkinsey.com/">
Jarrod Kinsey</a>
he pushed me to try to put some small crystal at the
output beam from the Nd:YAG laser anyway. I argued that
this is not possible and that for such frequency
doubling it is required special cut of the crystal,
precision aligning, polarized laser, and so on.

</p><p>
Later on, I wanted to check what is necessary to get
proper angle, but all I got is many offers for buying
finished crystals with instructions how to use. At few
pages they mentioned some angles, but also many other
data, for what at this time I have no idea what they
means. Until today I am not sure about many of that, but
I am much more close to understanding it.

</p><p>
Laser is there, crystals are there, but also many
questions too. Finally, I got courage to try it. During
preparing for this test, I had all the time idea how to
tell him that it failed, and that he is wrong. Also, I
remember conversation with another friend,
<a href="http://www.jossresearch.org/">
Jon Singer,</a>
a long time ago about this subject, before my attempt to
grow crystals. He mentioned to me that this may be
difficult too, but not impossible. He also mentioned
that it is worth to try to grow crystals;
‚ÄúWhat‚Äôs to lose?‚Äù

</p><p>
With all of that on my mind, and with serious doubt, I
wear safety goggles and fire my laser with focusing lens
onto small KDP crystal. I had no idea where to point
that focus. I tried few times with different angles, and
WOW! Green light popped right out of the crystal. At
first very weak, but at that moment, my excitement
increased my perception of such intensity to the
extreme. By slightly changing angle, I got even more
green light out.

</p><p>
It took me a while until cool down my mind and realized
what I got. Then I reported to my friends on the
<a href="https://mail.neurotica.com/mailman/listinfo/lasers">
Lasers -- Laser and high-energy physics hacking </a>
mailing list, who congratulated me for this achievement.

<br>

</p>
<p>
At third picture from the left, there is glued crystal
at approximately 42¬∞ to the incoming beam. Note that
I am not sure of the exact angle, because incoming beam
is focused, which produce cone of light. Such cone is
not so good, and part of the incoming energy is wasted.
I tried to use binocular as a beam shrinker. Instead of
3 mm beam, my attempt is to narrow it to about 0.3 mm
(if binocular has magnification 8x, then reversed should
narrow or shrink beam to very narrow beam. Such narrow
beam has high divergence, but at short distance it is
okay. After beam pass crystal, it will be good to use
beam expander to back to the original beam diameter, or
to expand beam even more to achieve lower divergence.
But I forgot that in binocular are glued two lenses
together to correct chromatic aberration. Here is how it
looks after a few laser pulses:

<br>

</p>

<div><p>
There is glue, or optical cement between that two lenses.
It seems that some glues/cements don‚Äôt like IR (infra
red) radiation. I noticed that at first, there is only
burning spot, but as room temperature changes, one of
two lenses made different expansion rate and produce
crack.

</p></div>
<p>
I am mentioned birefringence which is visible on the
green spot. By slightly adjusting (rotating) angle, that
two groups of spots becomes one. When collimating to the
infinite, such phenomena is less visible, because both
spots make one small spot, slightly elliptic.

</p><p>
My both Nd:YAG lasers are non-polarized. For that reason
I use so called ‚ÄòType II‚Äô phase matching. Since I
am ‚Äònewbie‚Äô in that field, on the Internet you may
find some nice article(s) about phase matching. One of
them is:
</p>

<a href="http://ilphotonics.com/CD/Crystech-Crystals/Non_Linear_Crystals/nlo.pdf">
http://ilphotonics.com/CD/Crystech-Crystals/Non_Linear_Crystals/nlo.pdf</a>

<p>
And another document:

</p>
<a href="http://www.quantumtech.com/apps/916.pdf">http://www.quantumtech.com/apps/916.pdf</a>

<p> Citation from page 5:

</p><p>*4.

</p><p>
‚ÄúWhen the cell is mounted horizontally in an optical
mount, the screw (for filling the fluid) should face the
ceiling. The polarization for the input beam should make
and angle of 45¬∞ with respect to the horizontal or
vertical plane. Slight Rotation and/or angular
adjustment is required to obtain optimum efficiency.‚Äù

</p><p>
*5.

</p><p>
"Type II process is more efficient because the
acceptance angle is wider, making alignment and thermal
control less critical than Type I process, especially
for doubling 1060nm. For tripling two orthogonally
polarized beams, this process is attractive if the
crystal is cut at the proper angle for tripling. The
distance between the doubler and tripler should be as
small as possible for best efficiency. Two orthogonally
polarized beams should make an angle of 45¬∞ when the
cell is oriented as in instruction *4." [End of
citation]

</p><p>
I tried tripling Nd:YAG laser, but since my laser is not
polarized, and because there is huge amount of white
light from flashlamp, can‚Äôt be sure whether I got 355 nm
(THG) in UV range. For tripling frequency, there must be
actually two crystals. One after another, carefully
oriented, aligned and so on. Too much complicated for me
at this moment.

</p><p>
One of the beauty for such wide acceptance angle is for
beginners like me. Even when holding KDP crystal in
hand, one may be able to adjust close to the proper
angle, so that there is at least some green light.
Further adjusting is then easier, because it increase or
decrease intensity of doubled frequency very gently. Not
so sharp like Phase I matching. I tried that too, but it
works bad for non-polarized lasers.

</p><p>
Another good thing is that even completely fogged
crystal produce some green light. Not much, but crystal
glow green anyway. There is almost no output beam (no
visible spot), just diffuse green glowing. Even most
clear crystal produce some fluorescence which is
consequence of change in refraction indexes. I am not
completely sure how and why, because in relatively short
period read so much documents, and this matter is very
complex.

</p><p>
Such fluorescence can bee seen in clear crystals, so
that one may see the path of the laser beam.

</p><p>
In one document (can‚Äôt remember which one), they said
that fine powder can produce SHG too, but with helps of
PMT (Photo Multiplier Tube). This means that random
oriented small crystals, many of them will be
accidentally oriented close to the proper angle, so that
they can make frequency doubling. At that way, they get
very dim green light which can be seen only with aid of
PMT.

</p><div><p>
About conversion efficiency. I have no instruments for
measuring efficiency, and suppose that in my case,
efficiency of conversion is low. In one of my post to
the lasers mailing list, I mentioned that it is possible
to put KDP crystal intracavity for lasers which has not
Q-switch. On that way, one may get greater efficiency by
counting on standing waves inside laser resonator, But
this is very problematic if laser is not polarized.  My
friend Douglas Little tried it and got some green light
out too. But after few shots, one or both HR mirrors,
got optical damage. Standing wave become stronger and
stronger each time passes lasing media. Just one part is
‚Äòextracted‚Äô and converted into harmonic. It will be good
that conversion efficiency is high, so that both laser
mirrors are HR, but one of them with added high
reflectance for 532 nm. If both HR mirrors are for 1064
nm, then doubled frequency will exit at both end of the
Nd:YAG doubled laser.

</p></div><div><p>
About making seed crystals. You may use an old method of
growing crystals as a start for growing small KDP
crystals for seeds.

</p></div> 

<div><p>
An old method with string may give you bad result, so
consider alternative method, which is also simple.
</p></div> 
<p>
If you are lucky enough, and get big crystal, after
cutting to proper size and angle for SHG or THG use,
rest of the crystal may serve as seed crystal. Chose
part which is clear. Shape it and put it as a seed. Or,
if big crystal not met quality requirement, at least one
part of such crystal may serve as a seed crystal. Mostly
clear part is pyramidal part of the KDP crystal.
Prismatic part may be with inclusions, bubbles, water
pockets, and other defects.

</p><p>
I have no chance to get enough big crystal yet. For such
growing of near perfect crystals, it require more or
less sophisticated apparatus, ultra pure water, well
prepared solution etc. I use ‚Äôindustrial grade‚Äô
KH<sub>2</sub>PO<sub>4</sub>, which bought in hydroponic
store. It is marked as MKP 0-52-34. The problem with
that chemical is that there is small amount of</p></span></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.milankarakas.org/pub/KDP/HomegrownKDP.html">http://www.milankarakas.org/pub/KDP/HomegrownKDP.html</a></em></p>]]>
            </description>
            <link>http://www.milankarakas.org/pub/KDP/HomegrownKDP.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046806</guid>
            <pubDate>Tue, 10 Nov 2020 15:13:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reading, Wisely ‚Äì How I'm Using Readwise to Improve My Learning]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25046762">thread link</a>) | @ggnall
<br/>
November 10, 2020 | https://www.grahamgnall.com/blog/2020/11/9/reading-wisely | <a href="https://web.archive.org/web/*/https://www.grahamgnall.com/blog/2020/11/9/reading-wisely">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="44" id="block-9da5bc9359b1bdaa3cf4"><div><p>Readwise is a utility that‚Äôs changed the way I read. I'm thoroughly enjoying it and I recommend it to anyone looking to improve their learning. You can sign up for a trial here:</p>
<p><a href="https://readwise.io/">Readwise - plain link</a></p>
<p><a href="https://t.co/3y8bAXryW7?amp=1">Readwise - my referral link</a></p>
<h2 id="about">About</h2>
<p>Readwise is an app (browser extension, web app, mobile app) that organizes information from the books you read. The app relies on learning techniques like <a href="https://en.wikipedia.org/wiki/Spaced_repetition">spaced repetition</a> to train your memory on your reading highlights and annotations.</p>
<h2 id="benefits">Benefits</h2>
<p><strong>Retention</strong></p>
<p>Readwise makes it easy to retain information you‚Äôve read and deemed important in the past. I try to read constantly, but when I look at my <a href="https://www.grahamgnall.com/books">Books</a> list, there are plenty of subjects that are blurry or shockingly, missing altogether from my memory. I‚Äôve been a Kindle device/app enthusiast and previously built my own scripts to export and organize my highlights. It was fun, but I ended up spending more time writing the so-called automation than actually reviewing the highlights. Readwise handles all of the syncing automatically from all your ebooks and articles, and even supports input from physical books. Its Daily Readwise review feature is a daily, randomized feed of highlights that surfaces old and new content to train on.</p>
<p><strong>Making New Connections</strong></p>
<p>There is a thrilling feeling when your mind makes connections between two seemingly disparate topics. This is foundational in my belief in <a href="https://www.grahamgnall.com/blog/2014/7/9/learn-disciplines-not-skills-startups-for-liberal-arts-majors">liberal arts education</a> and it's applications. The simple act of viewing highlights from multiple, unrelated books in the Daily Readwise allows your brain to play with these concepts on the same plane. Readwise‚Äôs tagging feature allows you to group highlights about the same topic or theme, so you can build your knowledge base with more examples and perspectives. Both of these features aid in constructing, expanding, and applying mental models to the world, or what Charlie Munger called a <a href="https://fs.blog/great-talks/a-lesson-on-worldly-wisdom/">‚Äúlatticework‚Äù</a> of models from different disciplines.</p>
<h2 id="how-i-use-it">How I Use It</h2>
<p><strong>Set Up</strong></p>
<p>I mostly use the core Readwise syncing sources:</p>
<ol>
<li>Kindle - automated</li>
<li>Pocket - automated</li>
<li>Non-kindle ebooks - semi-automated, requires one manual step when I finish a book</li>
<li>Physical books - manual, but with highly reliable OCR.</li>
</ol>
<p>There are also other a growing number of non-traditional sources like Twitter threads and podcast annotations. I haven‚Äôt tried them out yet, but they look promising.</p>
<p>The default settings are thoughtfully done to maximize your learning right out of the box (e.g. 5 daily items, mix of old and new highlights). You can get really granular configuring these settings, down to the book/article level. So far, I‚Äôve only used this to filter out certain things, like definitions from a Javascript textbook I read in 2012. </p>
<p><strong>Developing a Review Habit</strong> </p>
<p>The best product experiences create new habits and rituals around them, for a positive result. Readwise has created a few distinct habits for me. I look forward to my Daily Readwise and it‚Äôs one of the few things I let myself do on my phone when waking up. This takes less than a minute and is easy to implement. I never have to schedule in time for this and I never miss it.</p>
<p>Readwise sits on my home screen and I‚Äôve started to open it whenever I need a ‚Äúfeed fix‚Äù. It takes my boredom trigger and offers something more valuable than a dopamine hit. Sometimes I‚Äôll do a few cycles of 5 items before calling it quits and going back to whatever I was supposed to be doing. </p>
</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1604955485534_44801"><div><p><strong>Developing Better Reading Habits</strong></p>
<p>Readwise has also changed the way I read. I now look for insights that I want to extract and return to later far more deliberately. I‚Äôve found that even for books I abandon, if I was able to pull a single interesting idea out of it, I got some value out of it. This has reduced the guilt of putting down a book that can‚Äôt hold my attention. Or in the case of many business books, lets me extract the primary bits in the beginning without slogging through the filler.</p>
<p>The same applies to how I approach articles. I now view all types of text as holding information I can extract for my own purposes. I'm excited to uncover items to clip and have been delighted by the easy inputs into Readwise, including: highlighting directly in my browser, copy/pasting text from a mobile app, or taking an image of a physical book or magazine. This lets me jot things down, like book recommendations, without having to leave the text and pick them up later. </p>
<p><strong>Organizing Information</strong></p>
<p>I‚Äôve always liked the idea of linking ideas together and this was lacking in my homegrown version of this tool. In addition to notes, you can also add freeform tags to your highlights. This makes it easy to view all your highlights that relate to theme like <code>writing</code> or <code>decision-making</code>. I use this feature to learn about a specific topic. I‚Äôm very interested in learning about the routines and processes of interesting creators, and I‚Äôve started to aggregate tags for <code>routine</code> and <code>process</code> for instance. </p>
<p>I use the Daily Review to tag anything that fits into my ongoing areas of interest.</p>
</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1604956577898_10298"><p>The free-form search is also a great way to pull in notes on a specific topic. Feeling homesick recently, I typed in ‚Äúnew york‚Äù and saw some highlights that made me smile:</p></div><div data-block-type="44" id="block-yui_3_17_2_1_1604955485534_70588"><div><h2 id="last-word">Last Word</h2>
<p>I was happy to drop my hacky version for a simple, easy, and well-designed product. It's helping me to create better habits and reinvigorating my reading pracitce.</p>
<p>I'm training myself to spend on well-designed software products so that such things can exist. Unfortunately paid apps are still a boundary for many - and hopefully the COVID trend of increased subscription spending will change that. For me, the $8.99 / month is well worth the increased utility from books I‚Äôve already purchased (usually for the low Amazon set price of $9.99). I‚Äôm sure this was intentional: get more out of your books for less than the already low price of a book a month. Better yet, it makes me <em>excited</em> to buy and read more books.</p>
<p>Of course, if you want to apply these lessons to a self-hosted system you can. You can scrape (pun intended) together your own version by parsing the Kindle Cloud Reader (and other reading apps) to a database (including no-code databases in Notion, Airtable, and even Google Sheets) and building out the necessary views. Or you can keep it lo-fi. I‚Äôve heard of several non-fiction authors using a index card based version of Readwise, where they group passages from different sources by them. I wouldn‚Äôt be surprised if this tradition influenced Readwise's card ui and tag features. </p>
<p>And then you <em>could</em> always take it further. While many in the <em>organized thinking</em> movement (or <a href="https://twitter.com/cultroam?lang=en">roamcult</a>) are using Readwise‚Äôs Notion and Roam exports to develop fully mapped information on <em>everything</em>, I find the Readwise experience to be fully satisfactory on its own.</p>
</div></div></div>]]>
            </description>
            <link>https://www.grahamgnall.com/blog/2020/11/9/reading-wisely</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046762</guid>
            <pubDate>Tue, 10 Nov 2020 15:08:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What to Care About in a Job]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046633">thread link</a>) | @StokoeKeagan
<br/>
November 10, 2020 | https://www.keaganstokoe.com/post/what-to-care-about-in-a-job | <a href="https://web.archive.org/web/*/https://www.keaganstokoe.com/post/what-to-care-about-in-a-job">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.3.0"><div dir="ltr"><div><p id="viewer-foo"><span><em>This post contains <strong>factors to underweight</strong> and <strong>factors to overweight</strong> when making career decisions. I've included the factors to underweight as </em>avoiding<em> bad decisions is often more impactful than making good ones.</em></span></p><h2 id="viewer-b83g7"><span><span><strong>Why It Pays To Know</strong></span></span></h2><p id="viewer-bcfas"><span><span>Entering the job market, and observing friends doing the same, I‚Äôve noticed that people get caught up in a mindset similar to teenage dating ‚Äî you get so excited that someone likes you, that you lose sight of whether or not you even like them back.  When taking a step in the wrong direction can be detrimental for years to come, knowing what you want in a job provides sure footing.</span></span></p><p id="viewer-cj7or"><span><span>It‚Äôs all too easy to view a job as a job, a day‚Äôs work as a day‚Äôs pay. I hate this approach to work. Your work is an opportunity to do something meaningful. It‚Äôs an opportunity to make art, create a gift, and to do something that matters. It‚Äôs an opportunity to invoke change. And it starts with the right job. </span></span></p><p id="viewer-c1m15"><span><span>Knowing what you want enables you to move backwards from that point. It makes it possible to identify the skills and traits that will help you land your dream role. My dream is to work at Shopify. Knowing what I value in a job, I've identified Shopify as the place that aligns most with those values, and I'm able to focus on developing skills that are relevant and beneficial to the application I'll be sending them in a few years time. I've identified specific technical skills that I need to develop. I've observed that they place a premium on being able to think and communicate with clarity. Instead of playing hit and miss with getting your dream job, work backwards to develop the magic needed to receive an offer letter. This is beneficial to you as an individual, but it's equally beneficial to future employers. Magic happens when values align.</span></span></p><p id="viewer-e9uov"><span><span>I‚Äôve written this post because I believe that your career plays a disproportionately large role in the way you experience life. The points below highlight what I seek, and value, in a job. They‚Äôre not the only things to value in a job. They‚Äôre more relevant to people in the early stages of their career, and particularly those interested in a career in technology.</span></span></p><p id="viewer-cbjf9"><span><span>I suspect that they‚Äôll differ from person to person, but the real benefit comes from taking the time to think about them. It can be difficult to start with a blank piece of paper, so use this as a framework if you‚Äôd like. I strongly encourage you to make a list of your own because it‚Äôll change how you approach your work and perceive opportunities.</span></span></p><h2 id="viewer-crnib"><span><span><strong>Factors to underweight in career decisions</strong></span></span></h2><h3 id="viewer-55ehc"><span><span><strong>1. Perks are multiplicative, not additive</strong></span></span></h3><p id="viewer-7bsd6"><span><span>Free lunch, beautiful office space, and Friday's off to work on your side projects are perks. They're great perks, and they'll make the job more enjoyable, but they're only perks. The perks are not the job.</span></span></p><p id="viewer-bg2gd"><span><span>Perks are multiplicative. To get a feel for what I mean by this, assign a value to each perk you get. The unlimited Nespresso and in-house chef are worth 5 points, the office with an ocean view </span>comes<span> in at a cool 3 points, and your company replicating Google's famous</span><a href="https://en.wikipedia.org/wiki/20%25_Project" target="_blank" rel="noopener"> <span><u>20% Project</u></span></a><span> is worth 5 points. Now take the work you'll be doing on a daily basis, and ask yourself how much you want to do it. Be brutally honest, because that's the work you're going to spend the majority of your time doing. </span></span></p><p id="viewer-bc748"><span><span>If the day-to-day work is enjoyable, the perks amplify that and make your dream position even better. But if you hate the day-to-day work, don‚Äôt fool yourself into thinking that the perks can make up for it. If you hate the day-to-day, it‚Äôll slowly seep into your life, mood and relationships. It‚Äôs difficult to be happy when you spend the majority of your time consumed by something you despise. It's impossible to win if you're multiplying by zero.</span></span></p><h3 id="viewer-5ieeb"><span><span><strong>2. Work-life balance isn't as important as it's made out to be</strong></span></span></h3><p id="viewer-f06u4"><span><span>Having a work-life balance doesn't concern me. Perhaps it's because I'm early in my career and don't have too many other responsibilities, or perhaps it's because I've found something that I like to do, but I don't feel the need to draw a distinct line between work and life. Provided I have enough time to maintain my relationship and look after my body, I'm happy to spend the rest of my time working. </span></span></p><p id="viewer-1ftip"><span><span>I imagine that in future - when I wish to have children - my views will change. I suspect that I'll work more than necessary in the early stages of my career, which will turn into </span><a href="https://www.forbes.com/sites/laurashin/2013/05/22/7-steps-to-developing-career-capital-and-achieving-success/?sh=79752ea57a9fhttps://www.forbes.com/sites/laurashin/2013/05/22/7-steps-to-developing-career-capital-and-achieving-success/?sh=79752ea57a9f" target="_blank" rel="noopener"><span><u>career capital</u></span></a><span> that I can trade in for more flexibility and autonomy when the time calls for it.</span></span></p><h3 id="viewer-4nlad"><span><span><strong>3. Compensation</strong></span></span></h3><p id="viewer-8btdr"><span><span>In light of the above, compensation is something to underweight. </span><a href="https://haseebq.com/about/" target="_blank" rel="noopener"><span><u>Haseeb Quresh</u></span><span><u>i</u></span></a><span> has an interesting initiative. He </span><a href="https://haseebq.com/how-to-break-into-tech-job-hunting-and-interviews/#information" target="_blank" rel="noopener"><span><u>donates 33%</u></span></a><span> of what he earns. I like that, and in that scenario, I can see how compensation plays an important role in your ability to make an impact. Interestingly, I suspect that his personal contributions are dwarfed by the contributions of people that have joined his cause. It supports the idea that your actions, not your wallet, carry the most potential to make a difference.</span></span></p><p id="viewer-85sfi"><span><span>I‚Äôm not saying that you shouldn‚Äôt be concerned with compensation. Ensure that you can pay your bills, have a decent quality of life, and build in some form of financial security for the future. Over and above that, income is far less important than the other factors on this list. This becomes even more applicable if you share my views on work-life balance, since the increased work hours results in decreased lifestyle hours, and decreased expenses. </span></span></p><p id="viewer-1689k"><span><span><em>(Note: This is, of course, irrelevant if your goal is to make as much money as possible.)</em></span></span></p><h2 id="viewer-8pm18"><span><span><strong>Factors to overweight in career decisions</strong></span></span></h2><h3 id="viewer-4fv24"><span><span><strong>1. Important work &gt; Difficult work</strong></span></span></h3><p id="viewer-92h86"><span><span>When I think about a job, the overarching purpose of having one is to make an impact. I find it easy to think more money means more impact: making more money means you're in a position to give more money. I'm currently making more, yet giving less. It leads me to believe that if I'm going to make an impact it will be through the work I do, not the money I give (or have available to give).</span></span></p><p id="viewer-a2qj6"><span><span>That's why I seek to do important work. Building, creating and developing things that make life better for others, particularly for those unable to make life better for themselves. </span></span></p><p id="viewer-d5qau"><span><span>For a long time, I was under the impression that difficult implies important. It must have been difficult for Cardi B to sell over </span><a href="https://v1019.com/2019/09/06/cardi-b-becomes-riaa-most-certified-woman-rapper-surpassing-nicki-minaj/#:~:text=Cardi%20B%20has%20recently%20hit,surpassing%20her%20nemesis%2C%20Nicki%20Minaj" target="_blank" rel="noopener"><span><u>31 million singles</u></span></a><span>, but I struggle to find one iota of importance in her work. Starting a charity is arguably less difficult, but far more important. </span></span></p><p id="viewer-29ru4"><span><span>There's plenty of grey area involved in this importance vs. difficulty point, but I find it helpful to be aware of when looking at jobs.</span></span></p><h3 id="viewer-82ip0"><span><span><strong>2. Prioritise people </strong></span></span></h3><p id="viewer-5haoo"><span><span>Working under the guidance of a good mentor takes care of most of the things on this list. When you're surrounded by great people who provide you with guidance and feedback, you get better really quickly.</span></span></p><p id="viewer-eoimb"><span><span>This is particularly important if your chosen profession is one in which you require deep expertise to be successful. Expertise is directly related to the people you spend time around. Cedric Chin, of the </span><a href="https://commoncog.com/blog/" target="_blank" rel="noopener"><span><u>Commonplace Blog</u></span></a><span>, has dealt extensively with what it requires to become an expert. </span></span></p><p id="viewer-2tchb"><span><span>Expertise comes from a pattern-matching </span><a href="https://www.amazon.com/Sources-Power-People-Make-Decisions/dp/0262611465" target="_blank" rel="noopener"><span><u>model</u></span></a><span> in which the expert pattern-matches the current situation against a bank of stored prototypes. It is part of implicit memory, meaning that it happens extremely quickly, like recognising a face. The level of expertise shown in a given situation is dependent upon the following four steps:</span></span></p><ul><li id="viewer-dr28t"><p><span><strong>Relevant cues:</strong> These tell the brain what to focus on. For example, when turning at an intersection you'll focus on the indicator and the oncoming traffic, but won't worry about the speedometer.</span></p></li><li id="viewer-1u819"><p><span><strong>Plausible goals:</strong> Given the current situation, what goals are plausible? These are ranked, with the ranking done in terms of prior experience.</span></p></li><li id="viewer-5bk4l"><p><span><strong>Expectancies:</strong> These are a list of things which should happen in the given situation. If something is amiss, the expert experiences what we would call a 'bad feeling' and returns to pattern matching mode.</span></p></li><li id="viewer-ebp2b"><p><span><strong>Action script:</strong> Based on the patterns that have emerged, these are the actions to take.</span></p></li></ul><p id="viewer-7bh29"><span><span>Surrounding yourself with the right people enables you to increase your bank of stored experiences. It trains you to select the most effective action script to follow when a pattern emerges. Prioritising people in your career decisions means prioritising time spent around experts. This fast tracks your path to expertise and puts you in a commanding position for the rest of your career. </span></span></p><p id="viewer-f22go"><span><span><em>(I strongly recommend reading the </em></span><a href="https://commoncog.com/blog/everything-you-need-to-know-about-human-learning-and-memory-retention/" target="_blank" rel="noopener"><em><span><u>entire piece</u></span></em></a><span><em> from Cedric, as well as his series on </em></span><a href="https://commoncog.com/blog/the-tacit-knowledge-series/" target="_blank" rel="noopener"><em><span><u>tacit knowledge</u></span></em></a><span><em>.) </em></span></span></p><h3 id="viewer-bsghe"><span><span><strong>3. Seeing eye-to-eye with coworkers</strong></span></span></h3><p id="viewer-c44h"><span><span>I have a </span><a href="https://www.zachwolpe.com/" target="_blank" rel="noopener"><span><u>friend</u></span></a><span> who I work on almost all </span><a href="https://www.keaganstokoe.com/entrepreneurship" target="_blank" rel="noopener"><span><u>projects</u></span></a><span> with. We're good friends - we chat most days, grab coffee whenever we can, and generally get along very well. We also work extraordinarily well with one another. The reason for that isn't because we're good friends. It's because we see eye-to-eye on the work we want to do. When working on something together, there‚Äôs complete freedom to criticise and disagree. We're brutally honest, and because of it, at the end of a meeting, we‚Äôre on the same page and ready to move ahead. We trust each other, and with that comes autonomy and freedom to get the work done.</span></span></p><p id="viewer-ek2ia"><span><span>When it comes to a job, seeing eye-to-eye with your co-workers isn't about feeling comfortable to go to lunch with them. It's about being on the same page when it comes to prioritising work, putting in the effort, and making decisions. It's about being in a job where you can be honest, transparent and straightforward. Great work is a byproduct of being aligned with the vision and values of the company. You‚Äôll do your best work when you‚Äôre surrounded by people who are invested in you doing your best work, regardless of the path required to get there. </span></span></p><h3 id="viewer-8607g"><span><span><strong>4. Company growth</strong></span></span></h3><p id="viewer-cfji1"><span><span>Working for a growing company takes care of almost everything mentioned above. In a growing company, growing pains present themselves in the form of problems to solve and customers to please. Learning to solve these problems makes your ‚Ä¶</span></span></p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.keaganstokoe.com/post/what-to-care-about-in-a-job">https://www.keaganstokoe.com/post/what-to-care-about-in-a-job</a></em></p>]]>
            </description>
            <link>https://www.keaganstokoe.com/post/what-to-care-about-in-a-job</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046633</guid>
            <pubDate>Tue, 10 Nov 2020 14:57:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Death to ‚ÄúJust-Add-Water Team Jelling‚Äù]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046561">thread link</a>) | @mcrittenden
<br/>
November 10, 2020 | https://critter.blog/2020/11/10/death-to-just-add-water-team-jelling/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/11/10/death-to-just-add-water-team-jelling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-3080">

	
<!-- .entry-header -->

	<div>

		<div>

			
<ul><li>‚ÄúTop 5 tips for jelling your team!‚Äù</li><li>‚ÄúUse this kickoff activity to jump start team jelling!‚Äù</li><li>‚ÄúOnboarding do‚Äôs and don‚Äôts to help your new employee jell!‚Äù</li></ul>



<p>No. <a href="https://critter.blog/2016/10/27/the-whys-and-hows-of-jelling-teams/">Team jelling</a> is not a series of steps. That‚Äôs trivializing. Replace ‚Äújelling‚Äù with ‚Äúsuccess‚Äù to understand how silly that sounds. We wouldn‚Äôt look for a ‚Äúkickoff activity to jump start <em>success</em>‚Äù because that doesn‚Äôt even make sense. </p>



<p>Jelling is <em>everything</em>. It serves everything. It comes from everywhere. It belongs to everyone. It deserves to be taken seriously. It‚Äôs not a bunch of checkboxes. </p>



<p>Bren√© Brown says this of earning trust:</p>



<blockquote><p>It turns out that trust is in fact earned in the smallest of moments. It is earned not through heroic deeds, or even highly visible actions, but through paying attention, listening, and gestures of genuine care and connection.</p><cite>Bren√© Brown, <em>Dare To Lead</em></cite></blockquote>



<p>And what is jelling but the result of trust? </p>



<p>Like trust, jelling is the long game. It‚Äôs difficult to build but <a href="https://critter.blog/2020/10/28/the-all-powerful-bad-apple/">easy to break</a>. It takes months of consistent <em>small moments</em> of listening, <a href="https://critter.blog/2020/11/05/respond-to-vulnerability-with-vulnerability/">vulnerability</a>, reliability, <a href="https://critter.blog/2020/10/30/the-i-suck-awards/">empathy</a>, silliness, authenticity. </p>



<p>Please treat it with the respect it deserves.</p>





		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/11/10/death-to-just-add-water-team-jelling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046561</guid>
            <pubDate>Tue, 10 Nov 2020 14:51:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everyone Talks About Insecure Randomness, but Nobody Does Anything About It]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046519">thread link</a>) | @airza
<br/>
November 10, 2020 | https://www.airza.net/2020/11/09/everyone-talks-about-insecure-randomness-but-nobody-does-anything-about-it.html | <a href="https://web.archive.org/web/*/https://www.airza.net/2020/11/09/everyone-talks-about-insecure-randomness-but-nobody-does-anything-about-it.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	<section>
		
		<p>In which I take a crack at pointing a neural network at random noise, and achieve 95+% predictive bitwise accuracy against my hated foe in this world, Xorshift128.</p>
		<blockquote><p>"Any one who considers arithmetical methods of producing random digits is, of course, in a state of sin."</p></blockquote>
	</section>
	<section>
		<h2>What exactly are you up to here?</h2>
		<p>The motivation for this blog was a secure code review a few years ago, when looking at a client's email token generation<label for="1"></label><span>I don't actually work as an RNN jockey for work- I'm a security consultant. </span>. Frankly, I don't remember what their code looked like at <i>all</i>, but it probably looked something like this:</p>
		<figure><pre><code data-lang="python"><span>"""gotta make a token and send it to the client!"""</span>
<span>very_random_number</span> <span>=</span> <span>get_random_number</span><span>()</span>
<span>two_factor_token</span> <span>=</span> <span>convert_representation</span><span>(</span><span>very_random_number</span><span>)</span>
<span>send_email</span><span>(</span><span>"Your two factor authentication token is:"</span>
	<span>+</span><span>two_factor_token</span><span>,</span><span>user_email</span><span>)</span>
<span>save_token_to_user</span><span>(</span><span>user_id</span><span>,</span><span>two_factor_token</span><span>)</span>
		</code></pre></figure>
		<p>Code like this undergirds the security of much of the internet. A user wants to reset their password, so they enter their email. We generate a secret code and send it to their email; opening the link in the email proves that the requestor is legitimate. Sometimes we text codes like this to users when they try to login to their banks; this type of association between a random number and a user is also the backbone of a huge chunk of cookie-based authentication.</p><p>Is this code secure?  Well, it depends. Naturally, we might attack the email component (as emails are sometimes sent unencrypted, whoops) or we might attack the association between the data (maybe the token and the email are derived from attacker controlled data or whatever). The quality of the random number generation here matters as well, at least in theory: some random number generators are predictable, while others are provably difficult to attack. If we could predict this, it would be super bad- we'd just trigger the email to the victim, somehow predict the RNG, and be on our way. On the other hand, even if we are able to 'predict' this, we are still in trouble: there is no obvious way to go about it without prior knowledge of what <i>convert_representation</i> is up to.</p>
		<p>I think machine learning provides the bridge here. The thought has hung in my mind for a few years, in fact; I've picked the brains of everyone I know remotely related to the field, and I've even hired some people to take a crack at it. So far, I haven't seen any prior literature suggesting that it's been possible or done, and nobody was really sure how to approach it. Finally, thanks to a generous grant from the Phil Brass Weird Ideas Foundation<label for="2"></label><span>AKA <a href="https://www.directdefense.com/">DirectDefense</a> who was happy to sponsor this research while I was not busy bug hunting for them! </span> I was able to take a few weeks to think about it methodically.</p>
		<p>The rest of this blog is structured in a pretty straightforward way: I talk about how numbers are generated at random in a computer, then talk about how to transform that notion of randomness into a learnable problem<label for="3"></label><span>A basic knowledge of machine learning, and especially gradient descent will be helpful for understanding some of my thought process through this blog. </span>. Not surprisingly, I will then solve that problem, and propose a roadmap for how to continue chipping away at the distance between my current progress and a usable attack.</p>
	</section>
	<section>
		<h2>Our Constant State of Sin</h2>
		<p>Computers, these fucked up little rocks we have forced to think, are gambling creatures. Despite the rigid constraints that we have imposed on them, we sometimes instead demand them to be fickle beyond our own capabilities, to choose a number more wildly than any human dare dream. For example, by invoking <code>Xorshift128</code>, a rather stylishly named fellow, you can choose a number between zero and about four billion (<code>2**32</code>, to be precise), which is a number that, while you do not often have a reason to choose at random, is at least a number whose neighbors you encounter at least occasionally. More excitingly, you can invoke this function a staggering <code>2**128</code> times<label for="4"></label><span>More or less the number of atoms in every living person on earth. </span> before you encounter a repetition in its pattern of randomness.</p>
		<p><i>But how?</i> I hear you cry. That is to say, A particular problem arises here, the one I think Von Neumann was referring to above: programming a computer is the art of telling it exactly what you want it to do, more or less in advance, and telling it exactly what random stuff to come up with, <i>in advance</i>, both defeats the purpose of the program in the first place and also poses fascinating logical challenges at the programming level. Certainly you do not have time to roll four billion of <i>anything</i>, and even if you did, writing each of those numbers down in some way would be a miserable use of time and hard disk space. On the other hand, cycling through just a few of the available numbers also sounds wrong; if you cycle through just a few hundred of the integers between 0 and 2**32, you're not really providing a lot of randomness.</p>
		<p>We will set aside the question of what randomness really <i>is</i> and think about it from a programming perspective. We can define a Random Number Generator (RNG) as something that outputs a sequence of numbers. In order to make sure that they are as random as possible, we're also going to introduce something new: <i>state</i>. The state gets passed into this RNG function, and in addition to outputting a random-ish number, it is going to output <i>new</i> state- this state will be as big or bigger (usually much bigger) than the output. Then we're just going to feed this output state <i>back</i> into the RNG to generate the next number in the sequence- and that's going to give us new state, which will let us continue this for quite a while. One point of confusion is that sometimes the output is <i>also</i> used as the state<label for="5"></label><span>Astute readers will wonder: where does the original state come from? Fascinatingly, movement of the mouse, entries into the keyboard, and other minutiae of computer operation are used to generate a very small amount of randomness- that is, at some level the start comes from the simple uncertainty of everyday computer use. There isn't a lot of randomness available here, so the RNG serves to <i>stretch</i> it out over a longer period of time. </span>.</p>
		<p>To take this into the concrete, we will consider an RNG, the <b>Middle-square method</b>. Relatively ancient by RNG standards, it was invented by Von Neumann sometime in the 1940s, when he was busy inventing almost everything else. A number of <code>N</code> digits is squared, and the <code>N/2</code> middle digits of the result are taken both as the <i>output</i> as well as the <i>state</i> to square for the next iteration. The simplest case, n=2, works as follows: we start with 43, square it to produce 1849, and then take the middle two digits to get our result, 84. This 84 is also our new state, so next time we're fiending for the results of a d100, we square it again, 7056, taking the middle to get 5, our output and our new state. Okay, so next is 25, which we'll call 0025, which gives us 2, which gives us 0004, translated as 0...</p>
		<p>Uh oh. We seem to have run into a dead end here. 0 squared is of course 0. These numbers are not looking so random anymore. In fact, the behavior is pretty bad no matter what number you begin with. The figure below lists all the states/outputs showing that the tendency to degrade towards cycles is pretty unavoidable.</p>
		<figure>
			<svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="100%" height="100%" viewBox="-307 -5 300 450">
 <title>Middle square method 2 digits</title>
 <desc></desc>
 
 <defs>
  <path id="arrow" d="M 9.5,0 H 14 m -2,-2 l 2,2 l -2,2"></path>
  <g id="loop1">
   <path d="M 9,0 V 10 H 0"></path>
   <use xlink:href="#arrow" transform="translate(0,19) rotate(-90)"></use>
  </g>
  <g id="loop2">
   <path d="M 9,0 V -10 H -20"></path>
   <use xlink:href="#arrow" transform="translate(-20,-19) rotate(90)"></use>
  </g>
 </defs>
 <g font-family="sans-serif" font-size="10" font-weight="bold" text-anchor="middle" stroke-linejoin="round" stroke-linecap="round" stroke="none" fill="none">
  <rect x="-4999" y="-4999" width="9999" height="9999"></rect>
  <g>
   <g transform="translate(-20 ,0)"><text x="0" y="0" dy="0.7ex" transform="scale(0.75,1)">00</text><path d="M 5,  0 H 9 V   0"></path><use xlink:href="#loop1" transform="translate(0,  0)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="0" dy="0.7ex" transform="scale(0.75,1)">01</text><path d="M 5,  0 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="0" dy="0.7ex" transform="scale(0.75,1)">04</text><path d="M 5,  0 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="0" dy="0.7ex" transform="scale(0.75,1)">07</text><path d="M 5,  0 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="10" dy="0.7ex" transform="scale(0.75,1)">71</text><path d="M 5, 10 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">02</text><path d="M 5, 20 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">05</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">84</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">29</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">36</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">19</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-160,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">14</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-180,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">12</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-200,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">11</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-220,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">46</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-240,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">92</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-260,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">77</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-280,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">76</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-300,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">42</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-300,0)"><text x="0" y="30" dy="0.7ex" transform="scale(0.75,1)">69</text><path d="M 5, 30 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-260,0)"><text x="0" y="40" dy="0.7ex" transform="scale(0.75,1)">89</text><path d="M 5, 40 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="50" dy="0.7ex" transform="scale(0.75,1)">37</text><path d="M 5, 50 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="60" dy="0.7ex" transform="scale(0.75,1)">58</text><path d="M 5, 60 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="70" dy="0.7ex" transform="scale(0.75,1)">43</text><path d="M 5, 70 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">62</text><path d="M 5, 80 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">25</text><path d="M 5, 80 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">16</text><path d="M 5, 80 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-160,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">13</text><path d="M 5, 80 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-180,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">56</text><path d="M 5, 80 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-200,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">81</text><path d="M 5, 80 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-200,0)"><text x="0" y="90" dy="0.7ex" transform="scale(0.75,1)">87</text><path d="M 5, 90 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="100" dy="0.7ex" transform="scale(0.75,1)">68</text><path d="M 5,100 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="100" dy="0.7ex" transform="scale(0.75,1)">41</text><path d="M 5,100 H 9 V 100"></path><use xlink:href="#arrow" transform="translate(0,100)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="110" dy="0.7ex" transform="scale(0.75,1)">75</text><path d="M 5,110 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="120" dy="0.7ex" transform="scale(0.75,1)">32</text><path d="M 5,120 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="120" dy="0.7ex" transform="scale(0.75,1)">18</text><path d="M 5,120 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="120" dy="0.7ex" transform="scale(0.75,1)">72</text><path d="M 5,120 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="120" dy="0.7ex" transform="scale(0.75,1)">27</text><path d="M 5,120 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="130" dy="0.7ex" transform="scale(0.75,1)">61</text><path d="M 5,130 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="140" dy="0.7ex" transform="scale(0.75,1)">82</text><path d="M 5,140 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="150" dy="0.7ex" transform="scale(0.75,1)">73</text><path d="M 5,150 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="160" dy="0.7ex" transform="scale(0.75,1)">45</text><path d="M 5,160 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="170" dy="0.7ex" transform="scale(0.75,1)">55</text><path d="M 5,170 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="180" dy="0.7ex" transform="scale(0.75,1)">95</text><path d="M 5,180 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">03</text><path d="M 5,190 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">06</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">08</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">09</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">64</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">93</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-160,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">44</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-180,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">21</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-200,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">96</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-220,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">31</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-220,0)"><text x="0" y="200" dy="0.7ex" transform="scale(0.75,1)">63</text><path d="M 5,200 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-180,0)"><text x="0" y="210" dy="0.7ex" transform="scale(0.75,1)">38</text><path d="M 5,210 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="220" dy="0.7ex" transform="scale(0.75,1)">33</text><path d="M 5,220 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="230" dy="0.7ex" transform="scale(0.75,1)">78</text><path d="M 5,230 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="230" dy="0.7ex" transform="scale(0.75,1)">28</text><path d="M 5,230 H 9 V 230"></path><use xlink:href="#arrow" transform="translate(0,230)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="230" dy="0.7ex" transform="scale(0.75,1)">17</text><path d="M 5,230 H 9 V 230"></path><use xlink:href="#arrow" transform="translate(0,230)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="240" dy="0.7ex" transform="scale(0.75,1)">91</text><path d="M 5,240 H 9 V 230"></path><use xlink:href="#arrow" transform="translate(0,230)"></use></g>
   <g transform="translate(-160,0)"><text x="0" y="240" dy="0.7ex" transform="scale(0.75,1)">54</text><path d="M 5,240 H 9 V 240"></path><use xlink:href="#arrow" transform="translate(0,240)"></use></g>
  </g>
  <g transform="translate(0,10)">
   <g transform="translate(-20 ,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">10</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#loop1" transform="translate(0,250)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">90</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">30</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">48</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">22</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">15</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">34</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="260" dy="0.7ex" transform="scale(0.75,1)">35</text><path d="M 5,260 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="260" dy="0.7ex" transform="scale(0.75,1)">66</text><path d="M 5,260 H 9 V 260"></path><use xlink:href="#arrow" transform="translate(0,260)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="270" dy="0.7ex" transform="scale(0.75,1)">65</text><path d="M 5,270 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="280" dy="0.7ex" transform="scale(0.75,1)">85</text><path d="M 5,280 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="290" dy="0.7ex" transform="scale(0.75,1)">59</text><path d="M 5,290 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="300" dy="0.7ex" transform="scale(0.75,1)">67</text><path d="M 5,300 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="300" dy="0.7ex" transform="scale(0.75,1)">26</text><path d="M 5,300 H 9 V 300"></path><use xlink:href="#arrow" transform="translate(0,300)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="310" dy="0.7ex" transform="scale(0.75,1)">70</text><path d="M 5,310 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="310" dy="0.7ex" transform="scale(0.75,1)">52</text><path d="M 5,310 H 9 V 310"></path><use xlink:href="#arrow" transform="translate(0,310)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="310" dy="0.7ex" transform="scale(0.75,1)">23</text><path d="M 5,310 H 9 V 310"></path><use xlink:href="#arrow" transform="translate(0,310)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="320" dy="0.7ex" transform="scale(0.75,1)">39</text><path d="M 5,320 H 9 V 310"></path><use xlink:href="#arrow" transform="translate(0,310)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="320" dy="0.7ex" transform="scale(0.75,1)">86</text><path d="M 5,320 H 9 V 320"></path><use xlink:href="#arrow" transform="translate(0,320)"></use></g>
  </g>
  <g>
   <g transform="translate(-20 ,0)"><text x="0" y="330" dy="0.7ex" transform="scale(0.75,1)">50</text><path d="M 5,330 H 9 V 330"></path><use xlink:href="#loop1" transform="translate(0,330)"></use></g>
  </g>
  <g transform="translate(0,10)">
   <g transform="translate(-20 ,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">60</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#loop1" transform="translate(0,340)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">40</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">20</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">47</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">74</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">88</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">83</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-160,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">94</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="350" dy="0.7ex" transform="scale(0.75,1)">49</text><path d="M 5,350 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="360" dy="0.7ex" transform="scale(0.75,1)">80</text><path d="M 5,360 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="360" dy="0.7ex" transform="scale(0.75,1)">53</text><path d="M 5,360 H 9 V 360"></path><use xlink:href="#arrow" transform="translate(0,360)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="370" dy="0.7ex" transform="scale(0.75,1)">99</text><path d="M 5,370 H 9 V 360"></path><use xlink:href="#arrow" transform="translate(0,360)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="380" dy="0.7ex" transform="scale(0.75,1)">97</text><path d="M 5,380 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="390" dy="0.7ex" transform="scale(0.75,1)">51</text><path d="M 5,390 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="400" dy="0.7ex" transform="scale(0.75,1)">98</text><path d="M 5,400 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
  </g>
  <g transform="translate(0,20)">
   <g transform="translate(-20 ,0)"><text x="0" y="410" dy="0.7ex" transform="scale(0.75,1)">24</text><path d="M 5,410 H 9 V 410"></path><use xlink:href="#loop2" transform="translate(0,410)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="410" dy="0.7ex" transform="scale(0.75,1)">57</text><path d="M 5,410 H 9 V 410"></path><use xlink:href="#arrow" transform="translate(0,410)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="420" dy="0.7ex" transform="scale(0.75,1)">79</text><path d="M 5,420 H 9 V 410"></path><use xlink:href="#arrow" transform="translate(0,410)"></use></g>
  </g>
 </g>
</svg>

			<label for="mn-demo">‚äï</label>
			
			<span>
				<i>Directed graph of all 100 2-digit pseudorandom numbers obtained using the middle-square method</i>, by CMG Lee.
			</span>
		</figure>
		<p>Performance for the version with 4 digits of state is better; the average length of time before being trapped in a cycle is after 43 outputs<label for="6"></label><span>Another useful property of these RNGs is that it is pretty obvious when they are starting to break down- among the 10000 numbers the 4-digit version can output, only <i><code>0, 9600, 1600, 5600, 8100, 100, 4100, 2916, 2500, 3009, 5030, 3600, 7600, 3792, 2100, 6100, 540</code></i> immediately lead to decay. </span>. That code looks something like this, just so you get the idea:</p>
		<figure><pre><code data-lang="python"><span>def</span> <span>von_neumann_generator</span><span>(</span><span>state</span><span>):</span>
	<span>"""The version with a 4 digit state/output
	not to be confused with the one above, that
	has two."""</span>

	<span>#e.g. 1234**2-&gt;1522756
</span>	<span>square</span> <span>=</span> <span>state</span><span>**</span><span>2</span> 

	<span>#1522756 -&gt; 01522756
</span>	<span>formattedSquare</span> <span>=</span> <span>"%08d"</span> <span>%</span> <span>square</span>

	<span>#01522756 -&gt; 5227
</span>	<span>next_state</span> <span>=</span> <span>output</span> <span>=</span> <span>int</span><span>(</span><span>formattedSquare</span><span>[</span><span>2</span><span>:</span><span>6</span><span>])</span>
	<span>return</span> <span>(</span><span>next_state</span><span>,</span><span>output</span><span>)</span>
<span>state</span> <span>=</span> <span>1234</span>
<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>20</span><span>):</span>
	<span>state</span><span>,</span><span>output</span> <span>=</span> <span>von_neumann_generator</span><span>(</span><span>state</span><span>)</span>
	<span>print</span><span>(</span><span>output</span><span>)</span>
		</code></pre></figure>
		<p>You can see in the above example that the state and the output are identical, but there is no particular reason this has to be the case. For example, we could have the state be the inner four numbers, with the output being the <i>outer</i> four numbers:</p>
		<figure><pre><code data-lang="python"><span>def</span> <span>much_better_von_neumann_generator</span><span>(</span><span>state</span><span>):</span>
	<span>square</span> <span>=</span> <span>state</span><span>**</span><span>2</span> <span># e.g. 1234**2-&gt;1522756
</span>	<span>formattedSquare</span> <span>=</span> <span>"%08d"</span><span>%</span><span>square</span>
	<span>output</span> <span>=</span> <span>int</span><span>(</span><span>formattedSquare</span><span>[</span><span>0</span><span>:</span><span>2</span><span>]</span><span>+</span><span>formattedSquare</span><span>[</span><span>6</span><span>:])</span>
	<span>next_state</span> <span>=</span> <span>int</span><span>(</span><span>formattedSquare</span><span>[</span><span>2</span><span>:</span><span>6</span><span>])</span>
	<span>return</span> <span>(</span><span>next_state</span><span>,</span><span>output</span><span>)</span>
<span>state</span> <span>=</span> <span>1234</span>
<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>40</span><span>):</span>
	<span>state</span><span>,</span><span>output</span> <span>=</span> <span>much_better_von_neumann_generator</span><span>(</span><span>state</span><span>)</span>
	<span>print</span><span>(</span><span>output</span><span>)</span>
		</code></pre></figure>
		<p>This RNG is also not quite ready for prime time, but the relationship between the output and state is already harder to guess. However, they are clearly <i>interconnected</i> in some causal sense, a fact we will return to in a bit. For now, we are starting to see a few important tensions in the design of RNGs already:</p>
		<ul>
			<li><b>Unpredictability</b> ‚Äì Increasing the number of digits in the output/state increases the unpredictability of the output. Sometimes less adroitly designed algorithms (like the one above) will eventually degenerate to some kind of undesirable low-randomness state, but most ones in use in computers simply will iterate through their entire state in some order before returning to the original one. Among the generators that look superficially okay, there are a lot of mathematically interesting ways to verify this intuition: we can count the number of bits to make sure it is evenly distributed; we can figure out if the runs of ones and zeros look OK, and a ‚Ä¶</li></ul></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.airza.net/2020/11/09/everyone-talks-about-insecure-randomness-but-nobody-does-anything-about-it.html">https://www.airza.net/2020/11/09/everyone-talks-about-insecure-randomness-but-nobody-does-anything-about-it.html</a></em></p>]]>
            </description>
            <link>https://www.airza.net/2020/11/09/everyone-talks-about-insecure-randomness-but-nobody-does-anything-about-it.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046519</guid>
            <pubDate>Tue, 10 Nov 2020 14:46:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Product-Led Growth Flywheel]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046415">thread link</a>) | @mooreds
<br/>
November 10, 2020 | https://www.productled.org/foundations/the-product-led-growth-flywheel | <a href="https://web.archive.org/web/*/https://www.productled.org/foundations/the-product-led-growth-flywheel">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><header><div><p><img src="https://assets.website-files.com/5c9ccce9e3044dd92e5814bc/5cc32a73a349764b789711fe_dot-circle-dark.svg" alt=""><img src="https://assets.website-files.com/5c9ccce9e3044dd92e5814bc/5cc32a73a349764b789711fe_dot-circle-dark.svg" alt=""></p><div data-ix="default-scroll-slide-in"><div><p>The funnel is dead. Long live the Flywheel!</p></div></div><p><a href="#go" data-w-id="1bd70af8-4f8d-6ed9-fe79-0d73491deb1a"><img src="https://assets.website-files.com/5c9ccce9e3044dd92e5814bc/5cab68d23be1929718823851_Down-Arrow.svg" alt=""></a></p><div><div><p>Product‚Äëled&nbsp;Growth&nbsp;cOLLECTIVE</p></div></div></div></header><section id="go" data-w-id="16913989-f06b-77b6-8eee-b10f7720c01c"><div><div><div id="Intro"><div><p>As product transitions from a supporting role to lead actor, companies are transforming the way they communicate with users, nurture relationships, and understand user behavior. <br>‚Äç<br>This product-led approach shifts the balance of power in favor of the user and upsets traditional ideas about what the customer lifecycle looks like. Leading with the product (versus sales or marketing) means that the product experience begins earlier and plays a much larger role in the user journey as a whole. &nbsp;<br>‚Äç<br>The way we understand and visualize this journey has been evolving for some time. SaaS businesses have been using Dave McClure‚Äôs pirate metrics framework for over a decade now. The pirate metrics‚Äîacquisition, activation, revenue, retention, and referral‚Äîhave been so widely adopted and remain so useful because they provide companies with a way to quantify the customer lifecycle and offer a framework for a more scientific approach to growth.<br>‚Äç<br>But the pirate metrics were developed in 2007. While the principles behind the framework are still sound, a lot has changed since then. User expectations have never been higher, and there‚Äôs more competition than ever. To stay ahead, innovative companies in every vertical have been transitioning away from traditional business methodologies and embracing the opportunities and challenges of <a href="https://www.productled.org/foundations/what-is-product-led-growth">product-led growth</a>.</p><p>Part of this transition involves rethinking the user journey and the strategies teams use to affect it at every stage. To this end, companies have been saying goodbye their siloed funnels and introducing variations of the flywheel model instead. <br>‚Äç<br>A flywheel model encourages companies to consider the user experience in its entirety and understand its potential for compounding growth. <br>‚Äç<br>We, the Product-Led Growth Collective, believe that making the transition from funnel to flywheel is critical to fully realizing product-led growth.</p></div></div><div id="Chap1"><p><h3>What is the Product-Led Growth Flywheel?</h3></p><p><img src="https://assets.website-files.com/5c9ccce9e3044dd92e5814bc/5d039b493011839d1761767f_gifofflywheel-2.gif" alt="This is a gif image of the Product-Led Growth Flywheel model that shows an animated infographic of the SaaS user journey. The inter circle of the flywheel shows 4 user segments‚Äîevaluators, beginners, regulars, champions‚Äîwhile the outer circle shows how companies can move users through the flywheel‚Äîactivate, adopt, adore, advocate. These sections all fill in with color gradients in a clockwise order."></p><p>The Product-Led Growth Flywheel is a framework for growing your business by investing in a product-led user experience. In this framework, the experience is designed to generate higher user satisfaction and increased advocacy, which in turn drives compounding growth of new user acquisition.<br>‚Äç<br>It depicts 4 sequential user segments that correlate with stages in the user journey from awareness to evangelism‚Äîevaluator, beginner, regular, and champion‚Äîand the key actions that users need to take to graduate to the next stage‚Äîactivate, adopt, adore, and advocate. <br>‚Äç<br>The goal is to focus company- and team-level strategies on optimizing the user experience to move users from one stage to the next. As the rate of users completing each action increases, the flywheel will spin faster, increasing the rate that users move from one segment to the next. This creates a positive feedback loop‚Äîas more users become advocates, they drive more acquisition, and growth increases exponentially.<br>‚Äç<br>We‚Äôll take a much deeper look at each part of the flywheel in the chapters below. But first, a bit about how we developed the Product-Led Growth Flywheel.<br></p></div><div id="Chap2"><p><h3>Methodology</h3></p><div><p>We interviewed over 50 companies covering a range of sizes and business models‚Äîfrom direct-to-consumer companies with over 500 employees to B2B SaaS businesses with fewer than 10. Some companies relied strictly on large enterprise contracts with low volume and long sales cycles, while others were dealing with high volume and a diverse customer composition.<br>‚Äç<br>Over the course of our interviews, we talked with people in marketing, sales, customer success, support, and product. We asked them how they think about users, how they leverage product experiences to drive behavior, and what they thought was the most important accelerant for their company‚Äôs growth in the near and long term. <br>‚Äç<br>What we found was a consistent pattern: Companies are beginning to refocus their efforts on improving the end-user experience through their products, and this change can be felt across every functional area of the business. The top performers are rethinking their approach to sales, marketing, and service in an effort to meet today‚Äôs user expectations and deliver high-quality, self-service touchpoint at scale‚Äîtypically through the product itself.<br>‚Äç<br>The companies we talked to are also becoming smarter about how they segment their users. They‚Äôre becoming more thoughtful and analytical about the goals their users are trying to achieve‚Äîand how they can support those goals‚Äîat different stages of their journey. </p><p>We used the insights from our conversations to inform the creation of the Product-Led Growth Flywheel. We shared working versions with the participants of our survey and iterated on new versions until we identified a model that best represented the way these forward-looking companies are thinking about their product users.</p><p>Now, let‚Äôs get to the flywheel.</p></div></div><div id="Chap3"><div><h3>The Product-Led Growth Flywheel</h3><p><img src="https://assets.website-files.com/5c9ccce9e3044dd92e5814bc/5d039b6d1c2fede3a7c27d84_found3.2-svgsFLYWHEEL%20FULL.svg" alt="This is an image of the Product-Led Growth Flywheel model that shows an illustration of the SaaS user journey. The inter circle of the flywheel shows 4 user segments‚Äîevaluators, beginners, regulars, champions‚Äîwhile the outer circle shows how companies can move users through the flywheel‚Äîactivate, adopt, adore, advocate. The flywheel replaces traditional business funnels."></p></div></div><div id="evaluators"><div><p><img src="https://assets.website-files.com/5c9ccce9e3044dd92e5814bc/5d039daa81e4f5cef0733ada_evaluators-icon-final.svg" width="20" alt=""></p><h3>Evaluators</h3></div><p><img src="https://assets.website-files.com/5c9ccce9e3044dd92e5814bc/5d039ba2dc6c677440a206b2_found3.2-svgsevaluators.svg" alt="This is an image of the Product-Led Growth Flywheel model that shows an illustration of the SaaS user journey. In this image, the focus is on the evaluator user segment. The flywheel replaces traditional business funnels."></p><div><p>Evaluators are just browsing right now, thanks. <br>‚Äç<br>These users are cautiously excited about your product as a solution to their problems. Whether they were compelled by your marketing or heard great things about your product from a current user, they‚Äôre here to realize the value they were promised. <br>‚Äç<br>If you have a free trial, freemium tier, or even a low-cost monthly plan, they‚Äôre probably evaluating a variety of solutions‚Äîincluding your competitors.</p><p><strong>Evaluators are typically:</strong></p></div><ul role="list"><li><p>In a trial or demo phase‚Äîthey‚Äôve just started playing around with your product</p></li><li><p>Not installed or using real data</p></li><li><p>Not using your product in their current workflows</p></li><li><p>Still searching for a solution to a problem they are trying to solve</p></li></ul><div><p><strong>What they want from your product<p>‚Äç</p></strong>Evaluators want to know that you understand their problem and can offer them a clear path to solving it. They don‚Äôt care about the nuances of your product or the wide range of use cases that you can address‚Äîthey are solely focused on how you relate to their most pressing needs. <br>‚Äç<br>They are gauging the tradeoffs between your product, those of your competitors, and possible internal solutions. Ease of use, core functionality, and unique features are at the forefront of these users‚Äô minds. Evaluators are searching for value but don‚Äôt want to work hard to find it. </p><p><strong>How to deliver value<br>‚Äç<br>‚Äç</strong>In short, guide evaluators to their <a href="https://www.appcues.com/blog/aha-moment-guide" target="_blank">aha moment</a>. <br>‚Äç<br>Let evaluators experience your product in action and get a basic understanding of its core functionality. Don‚Äôt drag them through an exhaustive tour of every single feature‚Äîassume they are starting with zero knowledge but firm goals in mind. Use your onboarding experience to gather information about these goals and then selectively guide users toward the features that will help them realize value. <br>‚Äç<br>Remember: Evaluators need a map to initial success, not an advanced user manual. If they want to dive deeper on a specific functionality, be ready to help them via in-product support, opt-in walkthroughs, or a user-friendly help center‚Äîbut don‚Äôt overwhelm them with this information all at once. Make sure they don‚Äôt get buried in the details of your product and that they stay focused on finding value and addressing the problem they came to you to solve. <br>‚Äç<br>The goal is to guide evaluators to value and get them to <strong>activate</strong>.</p></div></div><div id="activate"><h3>Activate</h3><p><img src="https://assets.website-files.com/5c9ccce9e3044dd92e5814bc/5d039bae81e4f53abb7333ee_found3.2-svgsactivate.svg" alt="This is an image of the Product-Led Growth Flywheel model that shows an illustration of the SaaS user journey. In this image, the activation phase is highlighted. The flywheel replaces traditional business funnels."></p><div><p>Activation looks different for every company. But at its core, activation is a feeling that the user experiences‚Äîit‚Äôs a moment of relief and excitement when a user discovers the solution to their problem. <br>‚Äç<br>Entering a credit card or signing a purchase order is not a prerequisite for activating‚Äîin fact, companies can have a lot of users who purchase but don‚Äôt activate. (You‚Äôll likely see them listed as churned accounts a few months later). <br>‚Äç<br>Instead, activation happens when a user sees your product‚Äôs value, has that critical aha moment, and experiences buy-in. Activated users <em>want</em> to learn more and are willing to invest time and energy into a product because they‚Äôve seen it can be an asset in their life. &nbsp;<br>‚Äç<br>To help your evaluators activate, you need to identify the in-product actions that users experience as aha moments and which trigger activation. Identifying your activation events can be done by analyzing product usage data, user testing, and interviewing customers.<br>‚Äç<br>Once you‚Äôve identified the activation events within your product, your goal should be to help your users get there quickly and minimize their <a href="https://www.appcues.com/blog/time-to-value" target="_blank">time-to-value</a>. </p><p><strong>Who is responsible for activation?<br></strong>‚Äç<br>Product-led growth requires coordination and collaboration across teams, and every department contributes to activation in one way or another. <br>‚Äç<br>That being said, sales and marketing typically own the evaluator stage, sometimes with the help of a dedicated growth, product, or customer success team member. Together, these teams will bear much of the responsibility for driving evaluators to activate. <br>‚Äç<br>To do this, they will need to focus on understanding users‚Äô needs and reducing friction on the path to activation.<br>‚Äç<br>Secondarily, your product managers, designers, and engineers should be working to optimize your product for new users and collaborating with marketing or growth on in-app messaging and user onboarding experiences. <br>‚Äç<br>And while much of their focus will be on customers further along in the flywheel, customer success and support teams should be communicating customer pain points and insights about their evaluator experience to improve your activation engine.<br>‚Äç<br>Once a user has activated through these combined efforts, they progress in their user journey and graduate to the <strong>beginner</strong> stage of the flywheel.</p></div></div><div id="beginners"><div><p><img src="https://assets.website-files.com/5c9ccce9e3044dd92e5814bc/5d039db9dc6c67acf3a221d2_beginners-icon-final.svg" width="20" alt=""></p><h3>Beginners</h3></div><p><img src="https://assets.website-files.com/5c9ccce9e3044dd92e5814bc/5d039bbe81e4f582a97333fd_found3.2-svgsbeginners.svg" alt="This is an image of the Product-Led Growth Flywheel model that shows an illustration of the SaaS user journey. In this image, the focus is on the beginner user segment. The flywheel replaces traditional business funnels."></p><div><p>Beginners understand how your product can meet their needs and deliver value‚Äîand they‚Äôre excited about it! <br>‚Äç<br>Due to this excitement, they‚Äôre spending more time with your product and exploring its features and functionality more deeply. These users may or may not be paying customers yet, but they‚Äôre mentally prepared to make that leap now that they‚Äôve experienced the value that your product provides.</p><p><strong>Beginners are typically:</strong></p></div><ul role="list"><li><p>Incorporatin‚Ä¶</p></li></ul></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.productled.org/foundations/the-product-led-growth-flywheel">https://www.productled.org/foundations/the-product-led-growth-flywheel</a></em></p>]]>
            </description>
            <link>https://www.productled.org/foundations/the-product-led-growth-flywheel</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046415</guid>
            <pubDate>Tue, 10 Nov 2020 14:38:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The state of JavaScript at the end of 2020]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25046293">thread link</a>) | @milo_im
<br/>
November 10, 2020 | https://www.ideamotive.co/javascript-business-guide | <a href="https://web.archive.org/web/*/https://www.ideamotive.co/javascript-business-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          
           <p><span id="hs_cos_wrapper_pillarPage_content" data-hs-cos-general-type="widget_container" data-hs-cos-type="widget_container"><p id="hs_cos_wrapper_widget_1603280203415" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    
      <h2>
        
          <span>00</span>
        
        
          <span>State of JavaScript in 2020 [INFOGRAPHIC]</span>
        
      </h2>
    
  </section>

</p>
<div id="hs_cos_wrapper_widget_1603200140243" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    <div>
      <p><img src="https://www.ideamotive.co/hs-fs/hubfs/Pillar%20JS/JavaScript%20in%202020%20C%20(4).png?width=1439&amp;quality=low" alt="JavaScript in 2020 C (4)"></p>

    </div>
  </section>

</div>
<div id="hs_cos_wrapper_widget_1603280336294" data-hs-cos-general-type="widget" data-hs-cos-type="module">









  <div>
    <p> Share the infographic in social media </p>
    
  </div>


</div>
<p id="hs_cos_wrapper_widget_1601646578122" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    
      <h2>
        
          <span>01</span>
        
        
          <span>What is JavaScript?</span>
        
      </h2>
    
  </section>

</p>
<div id="hs_cos_wrapper_widget_1601646616007" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    <div>
      <p>You might have heard that ‚ÄúJavaScript is everywhere.‚Äù Which is where exactly?&nbsp;&nbsp;</p>
<p>According to <a href="https://w3techs.com/technologies/details/cp-javascript" rel="noopener" target="_blank">Web3Techs</a> ‚Äî on over 96% of all websites. Google, LinkedIn, Yahoo, YouTube, eBay, Amazon, you name it. There‚Äôs JavaScript all over the place.&nbsp;</p>
<p>Created in 1995 by Brendan Eich, JavaScript is a scripting language used to build and manage dynamic web content, such as multimedia, interactive forms, animations, photo slideshows, calendars, autocomplete suggestions, and much more.</p>
<p>JS is one of the three core technologies of frontend web development, along with HTML and CSS. While HTML is a markup language responsible for giving the structure to a website, and CSS is a language used to apply styles to HTML content, JavaScript is responsible for creating and managing dynamic, interactive website elements.</p>
    </div>
  </section>

</div>
<div id="hs_cos_wrapper_widget_1602069795205" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <div id="">
    
      <h3>
        Who is the JavaScript creator?
      </h3>
    
    
      <div>
        <p>Born in 1961, <a href="https://www.linkedin.com/in/brendaneich/" rel="noopener" target="_blank"><span>Brendan Eich</span></a> is an American technologist, software engineer, and keynote speaker. After joining Netscape Communications in 1995, Eich created a language to support the browser. It was designed based on Java‚Äôs syntax and standard library, and with object names that corresponded to Java classes.&nbsp;</p>
<p>In 1998, Eich co-founded the Mozilla project, ultimately leading to the creation of the Mozilla Foundation, which later became <a href="https://www.mozilla.org/en-US/foundation/moco/" rel="noopener" target="_blank"><span>Mozilla Corporation</span></a>. After leaving Mozilla, Eich set up another company, <a href="https://brave.com/" rel="noopener" target="_blank"><span>Brave Software</span></a>, developing a privacy-oriented browser combined with a blockchain-based digital advertising platform.</p>
      </div>
    
  </div>

</div>
<div id="hs_cos_wrapper_widget_1601646749682" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    <div>
      <h3>Is JavaScript a programming language?</h3>
<p>Yes! As the name implies ‚Äî JavaScript is a <em>scripting language</em>. Traditionally, scripting languages are executed one line at a time by an interpreter, so a computer program that directly executes the written instructions. This stands in opposition to <em>compiled languages</em>, such as C++, for instance, which must run through a compiler before they can be translated into binary code.&nbsp;</p>
<p>Currently, it is possible to run JS with a just-in-time compiler, too. It compiles the code on the fly and caches the result to speed up the subsequent runs. Still, JavaScript remains a scripting language.</p>
<p>&nbsp;As a programming language, JavaScript is:</p>
<ul>
<li><strong>High-level</strong> ‚Äì high-level languages resemble natural languages or mathematical notation, which helps simplify programming, including code updates and extensions.</li>
<li><strong>Dynamic </strong>‚Äì as a dynamic language, JS uses dynamically-written code to quickly implement functionality to an application, in a way that enhances programming efficiency.</li>
<li><strong>Prototype-based </strong>‚Äì JavaScript‚Äôs structure is based on prototypical objects, which can be cloned and reused as templates to build new objects. Prototypes also enable building associations between objects in JS. Copying and modifying objects are more direct than in class-based languages such as Java, which simplifies coding and reduces the programmer‚Äôs cognitive load.</li>
<li><strong>Multi-paradigm </strong>‚Äì JS supports event-driven, functional, and imperative programming styles, which makes it a multi-paradigm language. This results in its flexibility and enables different approaches to development.&nbsp;</li>
</ul>
<h3>Is JavaScript open source?</h3>
<p>Open source applies to software, and JS is a programming language, so no, JS is not open source. However, it‚Äôs an open standard that conforms to <a href="https://www.ecma-international.org/ecma-262/" rel="noopener" target="_blank"><span>ECMAScript</span></a> specification. Anyone can use it to develop their own implementations.&nbsp;</p>
<p>For JS to produce any output, we need <a href="https://en.wikipedia.org/wiki/Interpreter_(computing)" rel="noopener" target="_blank"><span>interpreter engines</span></a>, each of which is subject to its own license agreement. For example, <a href="https://v8.dev/" rel="noopener" target="_blank"><span>Google‚Äôs V8</span></a>, <a href="https://github.com/facebook/hermes" rel="noopener" target="_blank"><span>Facebook‚Äôs Hermes</span></a>, or <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Projects/Rhino" rel="noopener" target="_blank"><span>Mozilla‚Äôs Rhino</span></a>, they are all open source. By contrast, <a href="https://jerryscript.net/" rel="noopener" target="_blank"><span>Jerryscript</span></a> is licensed under the Apache License.</p>
<h3>The difference between JavaScript library and framework</h3>
<p>While interpreters are essential to generate JS output, frameworks and libraries are optional but highly recommended. These are <strong>prewritten components that your JavaScript team can use to build robust, highly-performant code faster</strong>. They offer significant advantages to your business, too, from reducing code size and complexity to speeding up the deployment of your project.&nbsp;</p>
<p>Sometimes, e.g., in the case of React, it‚Äôs hard to categorically determine whether a given resource is a framework or a library. Nevertheless, in theory, the two notions are distinct.</p>
<p><strong><img src="https://www.ideamotive.co/hubfs/The%20difference%20between%20JavaScript%20library%20and%20framework%20(2).png" alt="The difference between JavaScript library and framework (2)"></strong></p>
<h4>Framework</h4>
<p>A <strong>framework </strong>is a software platform that lays the groundwork for programmers to develop applications. You can compare it to a house plan or blueprint that needs to be populated with input before the construction begins.&nbsp;</p>
<p>Same with a software framework; it is pre-equipped with code for predefined classes, workflows, and functions, but needs specific details to be supplied by the programmer before it can run a complete code.&nbsp;</p>
<p>Popular JS frameworks include Angular, Bootstrap, and Vue.js.</p>
<p><strong>Jump to </strong><a href="https://www.ideamotive.co/javascript-business-guide#the-most-popular-javascript-frameworks" rel="noopener"><strong><span>this section</span></strong></a><strong> to learn more about JS frameworks.&nbsp;</strong></p>
<h4>Library</h4>
<p>A <strong>library</strong>, like a framework, refers to a reusable piece of code; however, libraries are usually focused on delivering a specific functionality/component, and give developers greater freedom over the code structure than frameworks. Coming back to the house metaphor: libraries can be compared to ready-made pieces of furniture or appliances that we choose to make our home complete.&nbsp;</p>
<p>The main difference between a library and a framework is that a library contains snippets of ready-made code that needs to be still arranged by the developer into a workflow. Frameworks, on the other hand, are in charge of running workflows. Additionally, one framework can utilize multiple libraries.</p>
<p>There are dozens of JS libraries available, with DOJO, jQuery, and React topping popularity charts.&nbsp;</p>
    </div>
  </section>

</div>
<div id="hs_cos_wrapper_widget_1602069971226" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <div id="">
    
    
      <p>While most JavaScript developers rely on specific frameworks and libraries, some of them also build applications using the so-called ‚ÄúVanilla JavaScript,‚Äù i.e., pure JS code without any additional resources. However, this approach is infrequent.</p>
    
  </div>

</div>
<div id="hs_cos_wrapper_widget_1601647248048" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    <div>
      <h3>How does JavaScript work?</h3>
<p>JavaScript is primarily used in the form of<strong> client-side JavaScript</strong>. This means it is typically running on client devices (laptops, smartphones, PCs, and others) communicated with the network.&nbsp;</p>
<p>In the client-side context, scripts execute directly in the browser, which results in faster processing and immediate response to the user‚Äôs requests. Because of the speed and more lightweight script processing on the client side, this model is preferred to implement dynamic, interactive web content and handle user interactions.</p>
<p>An extended version of JS allows it to be run on the server side, with backend access to files, databases, and servers. In this context, JS code is created similarly to C, Java, or any other server-side language.</p>
<p><strong>Server-side JavaScript</strong> can be applied to handle logging in, manage personal information and preferences, and fetch specific files or data as requested by the user. <a href="https://nodejs.org/" rel="noopener" target="_blank"><span>NodeJS</span></a> is commonly used as a runtime environment to execute JavaScript code outside a web browser</p>
<p><strong>See also section <a href="https://www.ideamotive.co/javascript-business-guide#the-most-popular-javascript-frameworks" rel="noopener">The most popular JavaScript frameworks</a>.</strong></p>
<p>Currently, JS is the only commonly-recognized client-side language for browsers apart from WebAssembly, which is rather to be seen as a complementary technology. Alternative solutions like Java applets, Silverlight, or ActiveX, have all been discontinued by now.&nbsp;</p>
    </div>
  </section>

</div>
<div id="hs_cos_wrapper_widget_1603785890114" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <div id="">
    
      <h3>
        What is the difference between Java and JavaScript?
      </h3>
    
    
      <p>We‚Äôve seen it happen too many times... A job posting for JavaScript talent with a ‚ÄúJava Developer‚Äù header. A few years ago, the confusion between the two languages was so common it became anecdotal. Today, it seems to be a thing of the past.The two languages could not be further from the same thing. Still, just in case you (or your HR department) need a little recap, here are the core differences between Java and JS:</p>
    
  </div>

</div>

<div id="hs_cos_wrapper_widget_1601896662232" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    <div>
      <h3>What can you build with JavaScript?</h3>
<p>Originally, JavaScript was conceived to add interactivity into static browser pages. While today, it is still mostly used to enrich websites with animated, lively components, its capabilities also cover the creation of:</p>
<ul>
<li>Robust web and server applications</li>
<li>Stunning business presentations</li>
<li>Interactive gaming platforms</li>
<li>Multi-functional mobile apps</li>
<li>Smart device applications&nbsp;</li>
</ul>
<p><strong><br>For more details</strong><a href="https://www.ideamotive.co/javascript-business-guide#what-is-javascript-used-for" rel="noopener"><strong><span> jump to the next chapter</span></strong></a></p>
<h3><span>How is JavaScript different from TypeScript?</span></h3>
<p>If you already have some grasp of JavaScript, you might have stumbled upon <a href="https://www.typescriptlang.org/" rel="noopener" target="_blank"><span>TypeScript</span></a>. A superset of JS, TypeScript is a modern programming language developed and maintained by Microsoft. It was publicly released in 2012 as a tool for the development of large applications in JS (‚ÄúJavaScript that scales‚Äù ‚Äî states the official slogan). TypeScript simplifies JavaScript code, making it easier to read and debug, and at the same time, it expands on JS capabilities.</p>
<p><strong>See also: </strong><a href="https://www.ideamotive.co/javascript-business-guide#javascript-vs-typescript" rel="noopener"><strong><span>JavaScript vs. TypeScript</span></strong></a></p>
    </div>
  </section>

</div>
<p id="hs_cos_wrapper_widget_1601896842863" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="what-is-javascript-used-for">
    
      <h2>
        
          <span>02</span>
        
        
          <span>What is JavaScript used for?</span>
        
      </h2>
    
  </section>

</p>
<div id="hs_cos_wrapper_widget_1601896857056" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    <div>
      <p>In the introduction, we have already covered some of the key JavaScript applications. Here, we will add some more details about each use of the language.</p>
<h3>Adding interactive website components</h3>
<p>JavaScript was made to create and control dynamic website content, and this task remains its primary application. A vast majority of developers use JS to enhance Internet web pages with interactive features such as:</p>
<ul>
<li>dynamic forms</li>
<li>animated graphics</li>
<li>autocomplete suggestions</li>
<li>photo slideshows</li>
</ul>
<p>If we said that everyone uses JS on their website, this wouldn‚Äôt be much of an overstatement. JS powers over 90% of all global sites, including those of ‚Ä¶</p></div></section></div></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ideamotive.co/javascript-business-guide">https://www.ideamotive.co/javascript-business-guide</a></em></p>]]>
            </description>
            <link>https://www.ideamotive.co/javascript-business-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046293</guid>
            <pubDate>Tue, 10 Nov 2020 14:28:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Contempt Culture (2015)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046192">thread link</a>) | @riffraff
<br/>
November 10, 2020 | https://blog.aurynn.com/2015/12/16-contempt-culture | <a href="https://web.archive.org/web/*/https://blog.aurynn.com/2015/12/16-contempt-culture">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <article>
          <h2>
              <a href="https://blog.aurynn.com/2015/12/16-contempt-culture">Contempt Culture</a>
          </h2>
    
          
    
          <p>So when I started programming in 2001, it was <em>du jour</em> in the communities I participated in to be highly critical of other languages. Other languages <em>sucked</em>, the people using them were <em>losers</em> or <em>stupid</em>, if they would just use <em>a real language</em>, such as the one we used, everything would just be <em>better</em>.</p>
<p>Right?</p>
<p>This sort of culturally-encoded language was really prevalent around condemning <span>PHP</span> and Java. Developers in these languages were actively referred to as less competent than developers in the other, <em>more blessed</em> languages.</p>
<p>And at the time, as a new developer, I internalised this pretty heavily. The language I was in was blessed, obviously, not because I was using it but because it was <em>better designed</em> than a language like <span>PHP</span>, <em>less wordy and annoying</em> than Java, <em>more flexible</em> than many other options.</p>
<p>It didn‚Äôt matter that it was (and remains) difficult to read, it was that we were <em>better</em> for using it.</p>
<p>I repeated this pattern for a really long time, and as I learned new languages and patterns I‚Äôd repeat the same behaviour in those new environments. I was almost certainly not that fun to be around, a microcosm of the broader unpleasantness in tech.</p>
<p>At least, until I got called on it.</p>
<h4 id="have-you-thought-about..."><span>‚Äú</span>Have you thought about‚Ä¶‚Äù</h4>
<p>I‚Äôd been making critical comments about <span>PHP</span> the language, and <span>PHP</span> developers, nothing more than standard<span></span> <span>‚Äú</span><span>PHP</span> sucks‚Äù sort of language. The same thing I‚Äôd been doing, and supported in doing, for years.</p>
<p>Getting called out was hard, and I was asked to consider who and what I was criticising. I was able to access a very specific version of the self-taught narrative, where I used <em><span></span><span>‚Äú</span>real‚Äù</em> programming languages and had <em><span></span><span>‚Äú</span>real‚Äù</em> passion and drive, the result of which was that I fit the early hacker archetypes and was permitted status - as long as I participated in gate keeping. My self-taught narrative is not other peoples‚Äô self-taught narrative, and I was very firmly reminded of that. Other self-taught narratives, such as starting with Wordpress-based design backgrounds and moving from more simple themes to more complex themes where <span>PHP</span> knowledge is required, to plugin development is a completely valid narrative, but a path that is <em>predominately for women</em>.</p>
<p>This was a bombshell. I‚Äôd been <em>loudly</em> criticising the language and, through that criticism, implying that people using the language weren‚Äôt as good me, <em>weren‚Äôt good programmers</em>. And suddenly I was thinking about all the myriad ways that someone with that background would feel othered by me, like they didn‚Äôt belong and weren‚Äôt welcome in the communities I was a part of.</p>
<p>All of the ways in which I was actively participating in the exclusion of women from <span>STEM</span>.</p>
<h4 id="intent-is-not-magic1">Intent is Not Magic<a href="#footnote-1GRF" id="ref-1GRF"><sup>1</sup></a></h4>
<p>Of course, I hadn‚Äôt intended to do any of these things, but as I came to realise, it doesn‚Äôt matter what I intended to do, what matters is that I did it and that it had real repercussions.</p>
<p>I <em>intended</em> to make fun of a language, the repercussion is that people from minority backgrounds wouldn‚Äôt want to talk to me about the things they‚Äôd done in that language, they wouldn‚Äôt feel safe talking about their achievements and exploits.</p>
<p>And why would they feel safe? If they say what they use, we as a culture laugh at their choice. We tell them they should know better, tell them that it‚Äôs a horrible tool. Tell them that they are <em>wrong</em>. We ignore the achievement and focus exclusively on how it was reached, on how much <em>better we are</em> because we had access to narratives that the broader culture had already deemed <em>more real</em>.</p>
<p>Not better narratives or better tools, just more accepted, more permitted, more discriminatory.</p>
<h4 id="contempt-currency">Contempt Currency</h4>
<p>I was taught to be contemptuous of the non-blessed narratives, and I was taught to pay for my continued access to the technical communities through perpetuating that contempt. I was taught to have an elevated sense of self-worth, driven by the elitism baked into the <em>hacker ethos</em> as I learned to program. By adopting the same patterns that other, more knowledgable people expressed I could feel more credible, more like a real part of the community, more like I belonged.</p>
<p>I bought my sense of belonging, with contempt, and paid for it with contempt and exclusionary behaviour.</p>
<p>And now, I realise how much of it is an anxiety response. What if I chose the wrong thing? What if other people judge me for my choices and assert that my hard-earned skills actually aren‚Äôt worth anything?</p>
<p><em>What if people find out I‚Äôm a fraud?</em></p>
<p>By perpetuating a culture of contempt as the means of acquiring credibility, I was able to avoid these difficult, introspective questions. We don‚Äôt have to look at how we‚Äôre harming other people who want in, don‚Äôt have to acknowledge the niggling little voice in the back of our head asking <em>are you good enough</em>. It wasn‚Äôt me that was wrong, it was <em>them</em>.</p>
<p>Instead, I was taught to use emotional weaponry to silence and exclude others, resulting in the remaining voices being the most toxic and exclusionary, the most able to tolerate toxicity and exclusionary attitudes.</p>
<p>This pattern is <em>common</em> in tech, from extremely high-profile projects like the Linux kernel to the ongoing os/language/editor<span></span> <span>‚Äú</span>wars‚Äù to the vile reactionary attitudes towards the introduction of Codes of Conduct, to any developers making disparaging comments about other peoples‚Äô ability to code, and the growing contempt around people whose first or primary language is JavaScript.</p>
<h4 id="and-now">And now</h4>
<p>This culture has ramifications. <span>PHP</span> communities, for example, have lacked access to the development of DevOps tooling, the use of <span>PHP</span> is widely derided as being insecure by default, are they are widely mocked for being an<span></span> <span>‚Äú</span>objectively bad language.‚Äù</p>
<p>Yet people make their livings working with <span>PHP</span>, deploying <span>PHP</span>, trying to secure <span>PHP</span>. Don‚Äôt they deserve the help that we received, the help of good practises and security-first development? These people who can‚Äôt improve their work because we won‚Äôt work with them and drive them away from our communities with mockery and spite.</p>
<p>And then they engineer things on their own, because they still need these tools, and we have the gall to ask why they didn‚Äôt use these other tools.</p>
<p>Tools that we mocked them for asking about, telling them to get a real language, to rewrite their entire app, to rebuild from scratch because their particular path was <em>not blessed enough</em>.</p>
<p>Because <em>we</em> were the problematic elements.</p>
<h4 id="im-tired-of-this">I‚Äôm Tired of This</h4>
<p>It‚Äôs 2015, and I saw a presenter at a Python conference make fun of Java. How would that feel to people trying to move from Java into something else? I wouldn‚Äôt feel welcome, and I‚Äôd have learned that the idea that the Python community is welcoming wasn‚Äôt true.</p>
<p>I‚Äôm tired of calling people out again and again for dumping on <span>PHP</span>.</p>
<p>I‚Äôm tired of people dumping on Windows, that most popular operating system, because it‚Äôs not what we choose to use, tired of the fact that we don‚Äôt make it easy to use our tools and teach them how to move, when they‚Äôre ready.</p>
<p>Instead, we lecture and dismiss and heap scorn upon them. We don‚Äôt reinforce our communities with respect or a sense of achievement, but with shame and contempt and awfulness. We exclude people.</p>
<p>I‚Äôve excluded people. Directly, me. I have to own up to that and deal with it.</p>
<p><em>We</em> excluded people. Directly. All of us. Even if we didn‚Äôt intend to, <em>it does not matter</em>. We make fun of the things others care about, make them feel small, make them feel like their achievements didn‚Äôt matter. Make them feel like they‚Äôre not welcome.</p>
<h4 id="what-can-we-do">What can we Do?</h4>
<p><em><span>SHUT</span>.</em> <em><span>UP</span>.</em></p>
<p>No, really, <em>cut it out.</em> If you need to make fun of a language, do it with your own language, inside your own community. JavaScript is really good at this, because they‚Äôre trying to help people write better code <em>within JavaScript</em>.</p>
<p>Do it around friends only, and acknowledge that it‚Äôs extremely problematic that you‚Äôre doing it at all.</p>
<p>Find some amazing project to celebrate in a language you‚Äôre contemptuous of.</p>
<p>Go to meetups of what you despise. Say you don‚Äôt know anything, and see how welcoming they are to new people. See what they say, what they do, and ask if you‚Äôd be as welcoming to them when they come to your meetups.</p>
<p>Work to change your community. Ask people who try to pay for their membership in contempt to stop, or to leave. Make it unacceptable to use these behaviours as a means of obtaining social wealth.</p>
<p>The best advice we give programmers is to leave things better than how they started. We do it with code, why don‚Äôt we do it with communities? Why don‚Äôt we do it with people, colleagues, friends?</p>
<p>Ask why it‚Äôs okay to do these things in your community, and leave things better than when you started.</p>
<section>
<hr>
<ol>
<li id="footnote-1GRF"><p><a href="http://www.shakesville.com/2011/12/harmful-communication-part-one-intent.html">Intent is magic!</a><a href="#ref-1GRF">‚Ü©</a></p></li>
</ol>
</section>
    
          
      </article>
    </div></div>]]>
            </description>
            <link>https://blog.aurynn.com/2015/12/16-contempt-culture</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046192</guid>
            <pubDate>Tue, 10 Nov 2020 14:20:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vue 3.0 Components Library]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046142">thread link</a>) | @quatro444
<br/>
November 10, 2020 | https://quatrochan.github.io/Equal/ | <a href="https://web.archive.org/web/*/https://quatrochan.github.io/Equal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://quatrochan.github.io/Equal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046142</guid>
            <pubDate>Tue, 10 Nov 2020 14:17:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benefits of Infrastructure as Code]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046111">thread link</a>) | @FedericoRazzoli
<br/>
November 10, 2020 | https://vettabase.com/blog/benefits-of-infrastructure-as-code/ | <a href="https://web.archive.org/web/*/https://vettabase.com/blog/benefits-of-infrastructure-as-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p id="post-modified-info"><em>Last updated on 11 November 2020</em></p>
<p>Infrastructure As Code is a paradigm that consists of describing our infrastructure (servers and their configuration) as code that is understood by automation software like Ansible, Puppet, Terraform, and so on. Automation software can then be used to recreate the infrastructure we described or, more commonly, to fix differences between code current version and the way the infrastructure is now. Which means that, for example, we can upgrade our MariaDB version in the code, run Ansible, and have MariaDB upgraded in the relevant servers.</p>
<p>But what are the benefits of Infrastructure As Code? In this article I will list one of them.</p>
<figure><img src="https://vettabase.com/blog/wp-content/uploads/2020/11/inverness_castle-1.jpg" alt="Inverness Castle and Ness Bridge" srcset="https://vettabase.com/blog/wp-content/uploads/2020/11/inverness_castle-1.jpg 799w, https://vettabase.com/blog/wp-content/uploads/2020/11/inverness_castle-1-300x196.jpg 300w, https://vettabase.com/blog/wp-content/uploads/2020/11/inverness_castle-1-768x503.jpg 768w, https://vettabase.com/blog/wp-content/uploads/2020/11/inverness_castle-1-16x10.jpg 16w" sizes="(max-width: 799px) 100vw, 799px"><figcaption>Inverness Castle and Ness Bridge, Scotland</figcaption></figure>

<h2><span id="Deployment_speed">Deployment speed</span></h2>
<p>How much time do you need to setup a MariaDB replica? Hint: I bet that your first answer is too optimistic. Consider you need to feed the server, setup replication, maybe a job for backups, monitoring, let proxies know about the new server, find out what the hell you did wrong in a previous step, etc.</p>
<p><strong>Automation software will do it in no more than half minute</strong>, plus the time needed to import a backup (I never said it‚Äôs magic). When you have to setup or modify several servers, automation is precious. Even with 5-10 servers, it makes the difference between a reasonable activity and a miserable life. With 20 servers, it makes the difference between being able to deploy or not.</p>
<h2><span id="Avoiding_human_mistakes">Avoiding human mistakes</span></h2>
<p>Depending on which tools we use, the code could describe the configuration we want to have <strong>or</strong> the steps to reach the result we want. But whichever approach we use, deployments can be tested on staging before applying them to production. The software we use will always apply configuration in the same way. It will not forget a variable and will not mistype a command. <strong>Automation is much more reliable than humans</strong>, when it comes to repetitive tasks.</p>
<h2><span id="Testable_operations">Testable operations</span></h2>
<p>Applying a series of commands automatically instead of doing it manually is important, but it‚Äôs not all. <strong>The commands themselves can also be tested</strong>. We can run our automation against staging servers and see the results. We can also automate some tests. For example, an Ansible task can make the whole playbook fail if mysqld is not running when it should.</p>
<h2><span id="Think_declarative_think_idempotent">Think declarative, think idempotent</span></h2>
<p>Automation technologies are, in general, declarative. <strong>You describe what you want, you don‚Äôt write the steps to reach the goal</strong>. For example, you state that a certain directory should exist, and specify its owner, group, and mode, but you don‚Äôt write the system commands to make it happen. When you setup a new system, the two approaches are more or less equivalent. But when you modify an existing system, the declarative approach is incredibly simpler. You don‚Äôt have to check if the directory exists, who its owner is, and so on. Your code will be <strong>shorter, quicker to write, easier to understand</strong>.</p>
<p>Idempotent means that you can run the same code twice and obtain exactly the same result. This is very important. You can apply your code again to a production system to update something. You state that mysqld should be running? If it‚Äôs not, it will be started. If not, nothing will happen. This avoid a lot of problems.</p>
<h2><span id="Documenting_operations">Documenting operations</span></h2>
<p><strong>The code that describes your infrastructure also serves as a form of documentation</strong>. If you want to know the Xtrabackup version in your servers, Infrastructure As Code probably allows you to know it by just checking a variable. Even if it‚Äôs not so clear because your code is less than optimal, a tool like Ansible allows you to run <code>xtrabackup --version</code> against a group of servers with a simple command. Once you get used to this way of working, connecting to servers via SSH to check their configuration will appear as a waste of time.</p>
<h2><span id="Conclusions">Conclusions</span></h2>
<p>Vettabase highly recommends having proper automation in place for your database infrastructure. We discussed the reasons that seem to us most important reasons.</p>
<ul><li>Automation saves you plenty of time every day.</li><li>Automation is more reliable than humans.</li><li>Automation makes operations testable.</li><li>You describe your goal, not how to achieve it. You can safely apply your code twice.</li><li>The code serves as documentation.</li></ul>
<p>If you disagree with us, or on the contrary if you have more reason to recommend proper automation, <strong>please comment</strong>. We‚Äôll be happy to discuss.</p>
<p><em>Federico Razzoli</em></p>
<p><a href="https://www.flickr.com/photos/91779914@N00/3938586256">Photo credit</a></p>

			</div></div>]]>
            </description>
            <link>https://vettabase.com/blog/benefits-of-infrastructure-as-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046111</guid>
            <pubDate>Tue, 10 Nov 2020 14:14:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EU has plans for a European Internet with a firewall [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25046096">thread link</a>) | @MaKey
<br/>
November 10, 2020 | https://www.europarl.europa.eu/RegData/etudes/STUD/2020/648784/IPOL_STU(2020)648784_EN.pdf#page=39 | <a href="https://web.archive.org/web/*/https://www.europarl.europa.eu/RegData/etudes/STUD/2020/648784/IPOL_STU(2020)648784_EN.pdf#page=39">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>U√â√Ü}¬™√à≈æ√é6≈æ¬∑26√åk√æ√Æ√ßo√ô√õ¬©9¬∑-√¶¬∂√£s√≠√∞\;z√≤‚Äì√è√á‚Äì√Å√ä√õ2|√Æ¬∏√∫}√≤z‚Ä∫V√™¬¥√ó¬∞√ë√ö.}n√ù√æ√ö‚Ä°|√û√Ö_‚Äî¬≥HÔøΩ
endstream
endobj
2614 0 obj
&lt;&gt;stream
H‚Ä∞¬¥W√õr√ú√Ü}√ü¬ØÀúGL√äX√é¬∏\¬Æ≈†HI‚Äì-√ë¬§¬∏¬™T≈†N¬•jEo¬¢%%R≈†√ä√πz≈∏√Æ≈æ`‚Äî+^b‚Ñ¢h√¥√¥√µ√¥√©G‚Äπ√ô√û‚Äò√∫√Æ¬ª¬Ω√ª√è‚ÄùQ√ü√ø√®`_√ç√∂√∂O≈í:¬ªVf√Æ√É&nbsp;√î√µ√ô√Öloa√øi‚ÄùU‚Äπ¬∑3g√ßÔøΩj
√ÑÔøΩ‚Ä∫‚Ä¢√¨√ú¬©&lt;\¬¨gÔøΩ√í‚Äπ√è¬ø -¬£f[4√ëf√©V√Åw¬¢√Ç√ª√õT¬∏QEk√ß¬©‚Ä°√®‚Ä∫/ÀÜ√∫
√ë&gt;¬¶/‚Äπ‚Ä†√ª‚Äπ√Ü√ª√ê√ù_k¬∫¬øh‚Ä†√ªk¬µfC√ñ√ù¬¶√ñ√ö√àn&amp;√å√üj∆í‚Ç¨√û√∞√ô√∏√ô≈°47ÔøΩ√â√û-≈∏√Æ√∞√Ø1z√´√â√™√º√ì√ïr√º¬¶√¶√•√É√å¬∫4.¬™‚Ç¨√´‚Ç¨¬´ÔøΩ√à¬©√∑√ê5$dL]-gS√ú{≈†f&lt;¬ø≈æe√üwQq√ß¬∞≈ì1&amp;%√äB`¬∏√≥fn√êÔøΩ¬ßÔøΩ¬≠g{√è√ñF\√é≈ΩovT√ç√º1√ô√£4a√¨z√•]ÔøΩ¬™&nbsp;&amp;√è6<z"xa√°‚Äöq√∏√ü√π(√Ω≈í√á‚Ç¨‚Ä†3¬¥√¥√ú8¬ß≈∏‚Ä¢√èÔøΩ¬´ÔøΩ√î√òÔøΩ‚Ä¶~¬¥√∑is¬® √ï,?k√´√¶i5√™@√º√†¬ø√ö√ç-¬Æ√Ø="" us¬©="√∞¬•y/√¢√´√•‚Ä¶√∂‚Äì√§?√™‚Ä¶√ç¬µ√Ü?¬•√ø¬±√∏‚Äòb}|O3¬´ÔøΩ!n√õ‚Ñ¢" ≈Ω‚Äπ}*v¬Æ¬¥¬°s.¬¥¬•8¬™‚Ä¶o√ç√Ω‚Äû="√π√≠¬π¬∂ÔøΩ√û√¶≈∏uO&amp;¬æ√ñÔøΩ<y‚Ä°√†ÀÜ:a+¬ßQ¬≤t8">‚Ä°¬£pN‚Ä∫√•‚Ä¢¬¶859¬´3m=}¬º¬º.√à√é]G≈Ω‚Ä¶√ûe‚ÄîH¬°aOb√ÅT¬æ√∞¬®√∫‚Äô√ãrq¬≥√¨¬§"¬π√ø‚ÄîÀÜ√õ5P¬¶≈°ÔøΩOokD√≥√çg¬µ5lBQ¬π =A≈í√†√ë¬Ø¬∫¬µ9√Å¬≠√•T^√±ÔøΩ¬ß√∞√ït√æ_mÔøΩ√Æ≈ì‚Ñ¢√∑√•√º¬¶√çA√∏Z¬∫)¬∏E¬∑√∫c¬∫)¬ª]¬©ÔøΩ¬¥#≈Ω√î√ïa≈í√§/ÔøΩn;
Àú‚ÄúÔøΩ¬π8¬´}¬¢‚Ä∫_t~√øÔøΩ&amp;|A	¬Æ9√®¬∏[jG√¶4oj√°"√¥¬Ωj&gt;i√ü√ì¬ß√´¬Ø‚Ä∫√ü√µZ
|≈†R
√®√ÆF|√™√Ø‚Äú∆í≈ì‚ÄöÀÜ|√ïH√Ü√£7;Z√Äo√í√ñn‚Ä¢‚Ä∫:Zq¬®‚Äπ¬ª≈°6:√§,I√ô)√†≈í√ª√µB&lt;|¬∏&amp;&lt;|G√îsGJ~}.x5X@N√íO√á√∫jFd‚Ç¨kCWÔøΩ√∞¬£n√Åi √®6√¥&lt;√£∆íT1√éT√Ω√†%√º¬≠√Ø&amp;	√∞[¬ø¬©DR¬Ωg≈ì‚Ä∞E3n¬Æ¬Æq√ßd√å≈í√Ø≈æ√é√¥ ÔøΩN√¶p¬ß`8#}‚Ç¨√®√ñ[√ùtu]¬Ω&amp;W√µ‚Äù¬´√¢:ÀÜQv=√≤¬§l1√£@∆ín√ì x]L¬∏√ê√º≈°b√û√≤tP¬∞Q√∑‚Äö¬¢≈Ω√Å^7√∞ÀúY¬≠√π¬∂‚Äî‚Ñ¢h√æp¬∞0KZ*√ùQo√ï¬≤"√Æ√á¬£x¬Æb√∞¬§2ZwT√ãi√≥‚Äì¬¨qc√¶¬Ø√®√™¬≥ub≈ì√ôb√ª¬®M¬≥∆í*M≈†√ó√ü&amp;√≠
√®6rr√é0h	.√¶v¬Æ√é),0s%√°¬®√ä‚Äò¬£≈ì√î√®^q&nbsp;<g_rr√Éze8t‚Äù¬•¬ø√≤‚Äú≈Ωjhd4√ò¬∂q‚Ä°√áx√µ`¬ª√µ1‚Ä†>√ØUB√¢b√áji√∂A√©√õ&lt;√îWx¬∞√π;‚Äú√†¬≠EQ#‚Ä¶5=√ä‚Äòi}√ø‚Äî‚Ä∫VÀú¬§√à√¥√ä‚ÄòiÔøΩ¬Ω¬∞√Ü√è√≠0L¬º‚Ñ¢@Y√∂&gt;¬∫√≥L¬¨,√ü√ü‚Ä∞i¬æ‚Ä∫`≈°-√´¬©√ø¬£√ï
¬æ¬®pIX√ã%a√ã¬∂√©√†d7¬ßÀÜ)‚Ä†¬£√å)/¬µ 
1¬∂ √¨‚Äπ√¢7-√Ä≈Ω√™ÔøΩ`‚Äô!√π√∑√ö1√ã√£≈†¬∏√í¬Æb√™√π√•:]√®A√§¬πz¬´#√Ä¬ß¬•√±CPK√´¬π√©g‚Ä∞r~‚Äò,¬™√ä√Ø¬µX√à&gt;¬¶ÀúqÀú~¬∏√∫‚Äö
¬´bCuQ¬±!‚Äπ&amp;√Ç≈°N¬™X¬¨√Ç√ù¬±≈Ω√ú√ü≈∏t4‚Ñ¢√û¬≤≈†‚Äì√ß√æ√•5ZÀú≈íi4¬∂9¬∫√π≈ì√àF(√ñ	kW?√ú√àJ√è√ôv√Æz_\?¬º¬øÔøΩ/√ì*√™√´√ö`¬´√àa≈†√ën¬≤∆í1√çf(&gt;ÔøΩ√≠√ò√ØM‚Ä†¬∫ÔøΩ{√û	xk%√ª‚Äî√Ñ¬§√í(√≤≈°~S√Øo√É u√ãd R√Å¬∫Z¬∞V√¶¬°/~≈ì6O¬µ‚Ä¢‚Ä¶		√¢t`U‚Ä°‚Äú&lt;$√âP}¬•\5‚Ñ¢W‚Äπ≈ìz¬¶C√é¬∞‚Äîb:¬•¬¢¬®√ã/¬∂Ri√•√Ñ¬≤√ÇTB4√∏1√Ø(a√º¬Ω√úN∆í√©-√©u-¬´#¬Ø.¬ßCR!Q¬§ZC%(√Åd;‚Ñ¢∆í‚ÄîD√É9¬ªU√≥¬æK√ìi¬ºqDJ√ß¬∫}√Ω4DK¬¶√°‚Äù√¥2√ò¬Ω√ø0√†2√çÔøΩq¬¢√ô‚Ä†≈∏`√é√π≈°‚Ñ¢)√áf&nbsp;√ù√ô√º√∫¬æ√û|‚Äú√è}√éu√î√±√™¬§¬∏[√ó√ï√ã‚Äô¬≠√°5‚Äù:‚Äû√¥√∂√Ö√Ünb√£¬Ø√•s√π‚Ç¨s√ôF'(‚Äú¬ª√Ø‚Äû¬π¬ø≈æ√ê¬∏≈æ\_‚Äì=,[¬øO√§H5√¢NY√®^ GL√éF‚ÄùQ√∑¬Æ√è√•!‚Äò¬´6ÀÜ√ëY]I√òEv¬≠¬¶¬≤(¬∫√∏≈∏√û√¥Àú√ãm√´≈Ω¬∏B7√™X$?p‚Ä†‚Ä¶‚Ä∫√úYPyC√±O≈°√Ω√æY‚ÄπwG‚Ñ¢¬∏?√ë6√¶%‚Ä∞¬°√á¬™‚Ä°√¶G¬∏+&lt;√ê√ß¬•¬¥¬Øa√≤BE√®t#√∏(√å√¢i`¬¥eQn¬∞‚Äô\‚ÄòT√ô¬§‚Äî¬Ø√òy.%g%√¥√éLÔøΩ*ÀÜYOeUi¬¢¬™√äP&gt;√Ü√ßW√åe|1"M
‚ÄúÔøΩa|"√Ä{H¬∫¬¶¬°bk√†√≥√≥√ß√•√Æp¬ª√ç√º&lt;√û≈Ω¬π√ÅM0¬∑√¥≈∏ÔøΩB~Q	9∆íqÔøΩ¬¥√≠¬•∆í‚ÄöÔøΩ√äCk¬¨jR√î]P√™7m)'¬∂d¬©√•√≠¬≠/¬¥c&nbsp;√∂|√ío√∏√Ö√ß≈í3|√ê¬Æ√µi∆í√çf^Aw¬æ¬£¬™f∆í¬•z¬ª√Ö√ÄB√úb`√ë√Ä‚Äú¬®ÔøΩ√å√í=√°.¬ªXH#√£oA'‚Ä∞$s‚ÄûK{√•md¬©¬≠l¬©√Æbh √õQNÀú‚Ç¨√ë$√ê,^=&gt;√å√≠√∏L¬ªV√ß3√ç¬µ√Ñ"~‚Ä¶w;v¬±√é≈ícX√ö√ùj:√ósk‚Ä°ÔøΩY√Ø√çÀúE7ÔøΩ‚Äû√ßM&gt;√¨√ª√ù‚Äù‚Ä¢7≈í‚Äùdyh &amp;56√î√ú¬©'h¬¢-‚Ä∞√•	@H√πJ√∞√æ‚Ç¨VE√ï√º}J√ø√Ø&lt;;r√∂√§ !√â√ì‚ÄújÔøΩ≈Ω7¬£mP√êÔøΩ¬≤G-¬°√ã
'≈Ω;‚Ñ¢`LÀúx‚Äî¬Ω`"√Ü.¬º$‚ÄîI‚Ç¨√∞∆í√Æh‚Äö1√π&lt;√§;!1√Ø≈∏F6T≈æs√™_‚ÄûÔøΩ7S√§E≈ΩV√û,√ÅF√ê√∂≈Ω√∞J√ò√á¬æÀÜ:≈Ω√∑U‚Ç¨Q¬§≈°√ÉT+d√ß¬Æ√ó+√ùy¬Ø'√≥‚Ä¢P√¨√Ü≈æ‚Ä∞v√Æ‚Ä°
L√∫R1M6‚Ñ¢‚Ç¨
√≠-√≠Z√ñ¬°:‚Ä∞|¬≤8√ß√¶√Él√Ø)√ê√†√ºz√Ü¬Ø√ù√à‚Ä°bf√Ä¬¶"‚ÄùP≈†≈í√á¬¨Jp‚Ä∫‚Ä†
¬Ø¬≥√µl√Ø√ô√ö¬™∆íK$l¬∑)q¬¨k‚Ä∞¬ß√¶√†9≈æG√´	√¢Mk√∞¬≤¬£√É√ì√Ä√Ü¬∞	&gt;∆í√¨‚Ä†√ÅY‚Ä¶√Ö√ù≈°:√∞_¬±√ÑM,9≈æ√Ω.√Ä√Øk√é(
endstream
endobj
2615 0 obj
&lt;&gt;stream
H‚Ä∞b``≈ì√°√®√¢√§√ä$√Ä√ÄÔøΩ‚Ä∫WR√§√§¬•√Ä~≈æÔøΩÔøΩÔøΩ‚Ñ¢‚Äú‚Äπ|@√¨¬º√º¬ºT√∞√≠#ÀÜ¬æ¬¨2S/`M.(*√í‚Ç¨√ò(%¬µ8H√¢√å√≤‚Äô&nbsp;8cÔøΩ-‚Äô‚Äù
f∆í√î‚Ä∞d‚Ä°9√ô@6_IjH≈í√Å9¬ø&nbsp;¬≤(3=¬£D√Å√ê√í√íR√Å1%?)U!¬∏¬≤¬∏$5¬∑X√Å3/9¬ø¬® ¬ø(¬±$5¬®j√∞¬ª%V*¬∏'√¶√¶&amp;*√©‚Äò√®r"(,!¬¨√è!√†0b;ÔøΩC‚Ç¨√§√í¬¢2(‚Äú‚Äò√âÀúÔøΩ √ÄI√Ü8/
endstream
endobj
2616 0 obj
&lt;&gt;stream
H‚Ä∞|U{Tg≈∏aÀúI√§1√ÉHt&amp;ZÔøΩ¬´√µ‚Ä¶≈†‚Äö¬®‚Äù‚Ä°J"BWM‚Äû(!√®√©¬∂‚Ä†¬≠¬ßn¬∑√ù]QD@¬∞¬¢√ñ"A¬§ÔøΩWD@VYu√ï={√™ÔøΩ√∏√°√©¬∞√≠9√ª√è√æ√≥ÔøΩ√ª√∏√Æo√Æ√Ω√Æ√Ω√ç√Ö1{;√áqÔøΩ‚Ç¨&nbsp;5a√ë√™¬πtq‚Ä¢A?_¬≠ÔøΩOM≈í3≈í99~*√é¬ª√õ√≥√ì≈ì¬¥√•¬æ{√∑n	√ô‚Äú¬°v√ä¬≠¬©√ìb¬•ÔøΩ√£√§‚Ñ¢√í√ÄT∆í~¬≠&gt;IÀÜO0*{zz√é;¬Ω‚Äù¬´5√∫ÔøΩZe√Ñ√Å¬£v_≈†2x√ø.¬Ω!IoÀÜ3j5‚Äù¬´‚Ä¢√™¬±‚Ç¨¬•Z‚Ä∫¬¢5Àú√Ü≈í‚Äò"(U√Ç‚Ä¶√ΩFe‚Ç¨√óR¬ØyK}/Àú√àL¬©KQ√Ü)
√öxÔøΩ‚Ç¨f√êj‚ÄùFC≈ìF¬ª/√é¬∞W¬©√ü√Ω√ø¬æ¬¥p]√Ñ√¶∆íIZ¬•ÔøΩR¬£√ùÔøΩa¬∏PF√ôcN.‚ÄπaJ√¶¬Ø√Ä¬∂aX,‚Ä†%√†Àú√É√í0√¨‚Ä†¬µbX;‚Ä†=√Ä¬∞A?‚Äöa√õ‚Ä¶¬ß√Ç6b*√¨&gt;¬Ø√É√≠h¬ª@¬ª=vG√¨√≤√¨n√òu,¬±‚Ä†√à ^√ô/¬±√è!qr&amp;YF√ç¬§vR√á¬©¬¢¬π¬¢√á√¢√π√¢o√Ñ¬Ø&amp;LJ≈ì‚Äù=√©‚Ä¢∆í‚Ä∫√É|‚Ä°√≠_;\p√§‚Äú√Ø8¬π;e9¬Ωr√û√®≈ì√†|√Ü√πÔøΩ$H‚Äô'¬±J√êd¬ß√âs'≈∏rqt√ô√®rs≈†√ã‚Äù√∞)√Ω√í√í(i‚Ä∞tH
¬¥≈æ¬æN√õ\5¬Æ√≠≈í‚ÄöIf¬æe√û√ã¬ºe¬∏¬©√ù2√ú√≤√ù≈æ¬ª‚Äπ√úW¬π¬´√ú{¬∏{|&amp;'√•;√•ÔøΩ)ÔøΩG¬´√π‚Äî√ï¬∏p√é¬¨&amp;≈Ω√ö√≥6√ïh¬π¬®ÔøΩA~√∞	#R¬¢Z√Ü‚Äù√ë?‚ÄπF¬©√≠√£2√∏!A¬ß√∏fLBc≈°¬Ω‚Äú&nbsp;3¬∏√∞
i√ízp√∏]?√ùs`s‚Äö7‚Äôs¬©¬£F‚Äô¬º‚Äû√¢Àúr√ã√π¬≤rca¬º√éÔøΩ≈∏PÔøΩt‚Ä∞‚Äú‚Ç¨√°p√≠n≈ì¬Ø-¬®‚Ä¶√ÑZiI;¬¨lq¬¨j¬£√ã√çf‚Ä∫√É,
X∆íd‚Äôe¬∑√∑)u¬∂√Ç4p	k_√Ñ√ô√Ç√ºh	^¬π4yc√∏√¶√Ñ¬¶√æ¬Æ¬ø¬∏√πK√´√çU√Ø1‚Ä†¬ßm√ã√àjT√∫~I√óÀú√π√µ√º√¨q ¬∑q&nbsp;ÔøΩ&gt;√Ö√ÄÔøΩ√™ÔøΩ"√∑√û√à√¶√∫K I‚Ñ¢¬πEg¬≤‚ÄòÔøΩ√íÔøΩ&gt;√û=t%ÔøΩ√à¬ø‚Äô√≠¬∫‚Äìp9√ær√µÔøΩ√¢G√π?‚ÄπWP≈∏-3‚Ä¶$√æ~GUh‚Äî¬∫E≈ì+z[[Y√ü!R√ØÔøΩ√¨U√û√ã?&gt;S√ãfÀÜ√®J¬ø¬∏√ç√ägu/¬∑¬Æf√ã¬≠‚Äì6√™√≥≈ì&gt; ¬¶+Qf√£¬´¬æ√ì√ì√±√É¬µrw√©√Ω√•Wb√Ö	{c‚Äô√ï
¬∫4≈∏¬ø√á√îY¬∂√≠T√á√Ü¬Ø√óp√ª√ãS+¬™√§5√Ö7√™X‚Ä∞√ç/
¬ø#6?√ÜÔøΩ√ºAjx√Ω‚Äî√ÆE7¬ÆfK√ê¬∑√à√ôVÔøΩ7uea6x!√ó,-FQ¬≠√à√µ¬Æ√õF¬º√û¬Æ¬∞N√Å¬µ ¬≥√æ‚Äú√Ω5fY‚Ä∞'√à‚Ñ¢i¬º4l‚Ä¢Ct¬∏‚Ä†√∂¬≥√´¬©√é√ô¬∑ÔøΩ+Z/GA‚Ä∫‚Äò,`6+)<k‚Äö√¥fn7p≈° f√ê!d="" jo‚Äöt05"i√¶≈°√∞s¬∞ÀÜ√®e‚ÄúÀú¬¢√Ø¬Øa≈ì‚Äú√Æn^‚Äú¬§4¬©‚Äû4√≥√†ÔøΩ√çx="" %j¬†≈æ="" ÔøΩ¬£√ç"‚Ä∞¬§x="" 8@Àú‚Ñ¢="" √ã√π√≤≈†‚Äù√Ç‚Äûc√≤√Æ√∏√±‚Ä∞ai¬∂√ïix¬º&zv1pj√ì‚Äò√´)t√±¬Ω≈Ω‚Äù¬®√ç¬≠|i+^√æ√≤≈∏prÀú√§="">9¬°√Ω√ö‚Ä∫√≥w√§¬¥f√∂∆í‚Äôa√ó*ÔøΩ&nbsp;i√ú√´‚Ñ¢√°√ä√à√π√ÆÀú¬±hE√îXÔøΩ√µ√ø√®√°$√™¬≥&amp;¬æ¬π√øh≈°√å∆ítÀúe∆í6√ñ≈∏¬¢√õ√ê≈íÔøΩN√π#‚Ñ¢CI√îG¬≠√º√ü¬¨8√∞O~‚Ä°√å≈†¬æ√ã√ïT‚Äò√ÇT¬π?~	N√≤√ï¬§√¥√ïk¬∑¬≥E√âs%7K√Æ(^^√ú√åe√ç√±√∑F¬æh√±¬∫ √∑H‚ÄòÔøΩt|√ù≈°)&lt;
¬¶G¬Æ‚Äì2¬¶‚ÄπMF¬´&lt;√ª‚Ä†√ø=√í¬∏"ÔøΩ√ã√ëo_¬π}O√û√ûÔøΩ\∆í
k	%√èU[j}¬•√õ¬¢√º|√∑‚Äûr1√Å7)zd¬∞_√£‚Ñ¢√çEf'¬¨E¬§bS√∏¬π&lt;√Éx=√òÔøΩ∆í√∏√â!√ê
√ºL¬∑y√≤¬≥√ß‚Ä∞√ê¬µ√ë%d8√î¬°@√íA‚Äú#‚Äö%ÔøΩ≈ì_‚ÄôWt√¶¬≤G.‚Ä¢¬©√ã√í√©√§h√üD¬™‚Äî[√Å¬ª√õ√Å√öX5Qq¬®‚Ñ¢√å-(&gt;V¬°Y}Àúw6√ß√©¬£√ör&amp;/‚Ä∞M
"√ì.4¬¶u(`√∫‚Ä∫√ß@√∑√á√ïo-√¶
vE√ø5Z‚Äò√≤if√¶¬∏s¬∞B√ò√îX√ß&nbsp;¬°&lt;¬ª√±KÔøΩ√Å"`{√ôf3≈∏¬§fI√¶‚Äì¬ß¬Ø√ù¬πE¬∫mr‚Ä¢¬£U√É}`BC}ÔøΩhm¬§ng"‚Ä∫AÔøΩ|k}¬¨√•√ú1Kv~‚Äì√ç-b√Ü√¥¬æ√ç√§√≤≈Ω√ø√≤/√¨√∑7Kk}¬µl√ù√†?√ë√¢.+√é;&gt;#n‚Ä¢¬¨ÔøΩ≈ΩL*√≠$‚Ä°)(√ß‚Ä°√à‚Ä†¬±‚Äö‚Ä∫√∏¬´w¬•OC √•Q√àm_x√Ü√êC+t1√°√ã√•√≥√∫}a*¬∏¬º√¨¬≤7√∫¬∂√ØE6WD√∑&lt;¬º|√æNÔøΩ¬ºoC/‚Äô"√ä+p&amp;K[#.Dt√™√òg√®¬™√©√ù√ê‚Äô√ã√ΩTY√ù√Ω
√ª√ÑP¬ß])¬ß¬≠√Å[¬£W¬≤√ô¬º√†√Æ√©¬Ω¬•√ö¬±+√¢√ß&amp;¬¶¬¨Yp√ñ_¬©¬≤¬≤u√∫}√∞¬Ω7√Ø√°‚Ä¢ÔøΩ√°√Ñ√±"ÔøΩ9‚Ä∫U‚Äù}√±O√≠_¬µ‚Ä¢T√ü7√ΩT√µ&gt;ÔøΩ∆í√Ør√ÄÔøΩ√≤X≈í04√∑‚Äî√Ä¬§√¶≈°√Ç√´√•l.u√à/Q¬ΩC¬≥;√°c√ì√ñ√É√ª2R3√§ÀÜ√ÅK√†√¨¬≥√äeÀÜ√∏4#√Ω‚Äπ√è9ÔøΩq√õ~‚Ä¢√¢¬£Àú√õ}√èj[¬∫8ÔøΩÀÜS√†√Äod‚Äû√ßcl,√£*¬≤≈í√ß	‚Ä†¬§√ù√£¬ø√∞l√¥√≥o√∂√Ç1{√≤‚Äû]√†=+7‚Äö√±√†W√Æ~8√Å√ΩT‚Ä¢√∏_¬ºv|!T√è√°¬øh‚ÄôBÀú√ûS√±+√ºq‚Äö¬Ø‚Ä¶¬ßL√£√®√±0mÔøΩÔøΩ$√àGH‚Äπ√è√®‚Äù
√Ωw≈ì√≥¬∂√â≈í√Ω‚Äöy‚Ñ¢¬±¬ß√¥√ùz√ò√ådÔøΩ√ã√∏!√Ø¬ª√´5U√µ‚Äî¬´[√•√ùQH¬¥%√¢‚Äú‚Äù√øp]¬•QQdWX√Ñ*√ö√ë)#u‚Ä∫¬ÆXA&amp;≈†a√ê√≠¬£¬¢B@qDT√êQY¬ª7\XeqCA√ë@¬∞¬ª‚Ä¢Equ‚Äû‚Ä†Fd√ÄnQ√ú√£-√≤√∞$ÔøΩ≈ì√§√§√Ø¬´√∑n√ù{√ü√∑√ù√Ø{√Å√¨7√¢la√ô)√ìÔøΩZ√¨-√û¬∏i
¬ªne¬¨√áQ¬Ø√¥p√Ω√≤
√≤√ΩR√ã&amp;√é√Ø√•`r¬®√ö√µ?√É‚Ä∞√õ0¬©√ö√∞√ö√ù√Å&amp;√∞¬∏	3√Ø√í¬Ω√±√ºOp\ÀÜ%√¶¬Ø√±^N¬´√ü√®‚Äô√ä¬°√ñ_u¬πI√âY\√©¬®X¬µ√ôk≈∏'∆í√å‚Äò√û08‚Ç¨/F`√≥¬¥&amp;h‚Ä°ÔøΩ#ÔøΩ¬ß‚Äπw‚Äô¬∂O‚Ñ¢√ì¬°‚Ç¨√•¬¢S√°A'√º√ÑY √ΩÔøΩ√ÉÔøΩo√∏√î√ü¬Ø.¬∫¬ßd3I|√Ä=√πJX3√ò¬´∆í√Ø√ÄM‚Äû)√àE S√§‚Äö6¬£5√Ä¬°√â0√ø√ëÔøΩ‚ÄúEuUÔøΩ9/mu'c‚Ä¶√º¬∫‚Äúw¬©¬∞
I	¬¨√¨qXMH‚Äπ√µ√±¬©)‚Äò√ó,l‚Äö¬µ√Ω√≤t√π√â√≤¬¨2A:‚Ñ¢ÀúÔøΩ√£√õ‚Äû¬ºD√î√é‚Äûf√àn‚Äö√àG‚Ä†ZÀÜ√ñ-&nbsp;?v¬§‚Äú≈†¬™‚Äú√Æ30¬æ#√øZ
¬ß¬∏\PY/~¬∑√®¬∂√´ÔøΩ+¬æ√µ√¢¬µ¬ªÔøΩ√¢√õ¬≤2√©EV√°¬ø:√á‚Äìq√∑H8√ÑiW
3¬≤2√ä√ù√ΩP√ák6√å√£√â√•√öH√∫√£¬´¬Æ&nbsp;y√≥C¬¨B#√í2√¢8*+¬æÔøΩ¬Ø√ñl‚Äî¬™√®√æb¬ø0N¬∫&amp;√û‚ÄπA√≥√ß√º√Ä‚ÄôÔøΩ√Ø√Å√∫N√ç¬æ]‚Äî9√∫√ä¬πV‚Äön9√•‚Ä¢g√è&nbsp; √úS¬¥‚Ä¶∆í)√∫&lt;{√¶≈æ)√°¬®√ó	j√æZ‚Äπ^‚Ä°‚Äì≈∏√î¬ØÔøΩSO¬¨¬º‚Ä¢√º√ì‚Ä†

\√É/≈†0^z√í'ul√ùJ√´"4‚Ä¢Y√™‚Äìp√ê‚Äπ√ì¬∫
ÔøΩ(2¬´p{1√ô¬§rh√ÖlS√§¬º--3≈°¬•$‚Ä°5ÔøΩ√î√ÅX≈∏‚Äî√∞"!√äÔøΩ`(√ñ≈í≈Ω√ªl√áO√Å‚ÄôIÔøΩCR√≥√±M√î¬∑A√î‚Äî}FZ¬®‚Ä°√£m√®8DA‚Äò√Ω‚Äπ¬§:¬µ√ÅN5√ì‚Äû≈ΩU√ãO√Æ¬£‚Ä°√∏g√∞IÀÜ"‚Äì√Ät¬¥‚Äò√ú/&lt;ÀÜ1d5√≥=√º‚ÄôO`~s√ï√û]*≈Ω~:V√πP√∂√∑\	∆ídÀÜEfhc*g¬¢¬≤¬™_√ç¬∫5√µ‚Ä†`√∫;¬≤K9¬™g√ê√íJ9√é¬∫t√∫#v√Ç√èvZhÔøΩ.√î¬¢¬±¬≥AJ√îJ√å¬Æ√ûs¬≤;√π‚ÄîD¬ø√Æ¬±√É¬´&gt;√∏2@¬Æ!Z}ÔøΩ8,¬¨¬•‚Äô√°GÔøΩ√Ö¬≤{√é‚Äî*a@&nbsp;¬´≈Ω_kk@√≠√ºo\n√π¬∞"P/√±‚Ä∞√é√∞"H‚Ä†RÔøΩ#1bÔøΩ√ÜE√áF√Ü‚Ä†'√É[‚Äô¬≤√Ä≈†√∫√¶√∑S√º$
*√ß√ü√†U√ò‚Ä∫	√çd|¬Ø√ñ¬∞~d16ba√îG√∫c√º"}¬´{A_√ôn√©√ß"H&amp;√£√îQ√≠;¬±&amp;@‚Äî¬•√É|0¬æ%√≥&nbsp;√¢√®√ª#@¬§√∑¬ß‚Äúg.√ô‚Äì√å`U√óC√≠D‚Ä∞√áH¬∑b√†o}]X√¨R√≠ÔøΩ"√¢√à\¬•;¬§¬•≈í√∏	‚Äú¬ß¬£^√µ√ê&gt;`m√•t(LHy≈°√ò√áf¬§)≈ì¬´√ñ,2‚Ä†√¥≈†√Ä=\‚Ç¨‚Äù$ÔøΩk‚Äô¬æ√†¬∏‚Ä∫‚Äô¬∫¬≠%¬∞u]‚Äî1
‚Ä¶Ab√ég;\√Ü¬§√∏V√æf¬´≈æ√™%√ø√£‚Ç¨&gt;|q¬¢exV√ø	‚Ä¶ ?Àú≈†XX
‚Äπ`LÔøΩ√ù√†∆í√ç√ä√§√Ü%-√Ç,5√û"Fs%ÀÜ√Ü&lt;]BÀú	√¶m`39*√ük¬Æ≈†√Ü&nbsp;
	_¬ª]@&amp;√¶_H¬Ω√à√¥=.¬¨¬≠√¶√ä¬º√´√Ñ√∑¬£k¬∑‚Äù¬∞¬™¬∑√º√Ø‚Ñ¢%?%√≤√ß¬¥n√Ç√å≈ì¬¢≈í¬´√å√´?kKWo‚Äú‚Äò√©Gb¬∏√øKsdV¬∏√ê3√ã√π√å¬≤\A¬¶L(√≠√Ü2√†$‚Ä†
8?√§≈†V √¢P(√ö≈Ωa√∫
√ò&amp;¬∞¬ß¬≥¬≥¬π'a√è√É√∫#¬®l‚Äû√®ÔøΩ≈Ω8c√ì4f¬ß¬∂a¬π4c√ÄTÔøΩ1√àR‚Äö%‚Äô√•¬®m¬∏‚Ä†¬™&amp;8√∂√®j¬®√™!¬ª‚ÄôU√í|√ã¬≥√∂9≈æ'√•‚Äö√§≈æ‚Äπ¬ª¬£w¬©C¬Ø¬Ø√ç√ÉF¬ª√µ√ÇÔøΩ{√è√Ö¬∑b¬™∆í‚Äπ√ô¬´√æ¬π‚Äì≈í‚Ä°[√¢_N√´.√å√å.√é¬¨`R‚Äöl√ÖWz[¬≤√ñ$¬µ0^√É_o√Å¬ØlNwb‚Äú¬©j‚Ä¢72`√ì√ô?√ºvU"+9K√ï√¶¬ø7ÀÜ¬´‚Ä¢u¬™√§√ª√é¬≥t√ïL¬Ø√é√ú√≠√´√é,e√ê4[‚Ä∞√â≈ìfO√à√µKU[√ù√Ñ.k}¬¨=&lt;√≥/¬≤‚Äù3√∂C√ò√πa√ü√©g¬§√£‚Ä°`s√ªh‚Äô√∏‚ÄúT'n√ß?√•zÔøΩu√ê¬Æ√ì≈í)5:√É
;¬≥A¬ØX~¬∫√ç¬®¬©¬≤p]nf¬µ√¨!√º‚Ñ¢√•M
¬®}‚Ä°_,¬£ÔøΩa&amp;√ø3#H√ÄÀÜ¬∑$‚Ä∞≈æÔøΩ√ûf¬ß]≈íDÔøΩB√ÜvE√¥√¨√®7ÔøΩ&gt;√ë\√Ç0√ö)(:√º√ûA√Ü7√ø‚Ä†‚Äò‚Ä∫3√≤ÔøΩ√∂‚Ä†b¬£√ó0L√ê√íBmN√ì¬©Gx¬≤≈∏p√â^~√Æ√ª&gt;4,√Ç^g5≈ΩkMZ¬£‚Äî}Zf¬≥hÔøΩ¬ª¬ø5¬∂;¬¶{¬º√Ω‚Ä¶¬¥B/¬£le√±√ã≈íS√à}ÔøΩ¬±¬Ω√≤^√ç#√°‚Ä°¬±√ü¬•}ez!≈∏¬ß√è_3B[√†-√∏√ÉS√Ç≈í≈ì‚Ä°¬¨#√º√¢Bc≈í‚Äú√âXU≈í"¬¢√í¬¨E¬≥IXÔøΩ≈æa√¶√Ø√à¬ß`¬Æ¬ºwVu¬∂√ì√≤\√†√π-J√èg√àBD√≠√∏d¬∏‚Ä∫ÔøΩ≈í&nbsp;√åd√º4√Ç≈ì√º¬π‚Ä°{G√π√Ü√∏√¢Dd5√≤√≤√∞‚Ä∫s√Ä]dNB√∞¬®ÀÜ@¬•T≈æ‚Ä¶¬Ωb&gt;^¬ø√òÀÜÔøΩ√ó≈í~‚Ä∫A√≤¬æ‚Äö¬∏=¬∫√Å^%≈í~3ZIPK√êT√º√Æ√•‚Äú√µMX√á'√ü0&nbsp;F≈ì√•zJ¬∞√ê√á¬æb‚Äú√∞d√õ¬•√°s√µ¬´Da√Ω√ê¬∏({e√ü"∆í√É‚Ç¨j4T√™√Ä¬øÔøΩ¬Æ√•¬≠√†‚Ä†ph√´{d√Æ¬æ*.&lt;‚Ç¨√ç_E≈ìW√îdW1oO√æ√Ä√≠7@i¬¶¬Æh¬¢x√âÔøΩ¬•oZn)¬Æ^√Ç≈í√û}√åÔøΩ√®&amp;.¬ß‚ÄùWÀÜ√≠j‚Äût√≠ÔøΩ‚Äù√Ω√â√ò√ç{√úÀúMA‚Äî√Æ‚Äö^√Æ√´≈ΩJÔøΩW√âx‚Ä∞¬∂√â
5ZP√©√®Z
L√í¬ª√ΩR√ñ¬ß‚Äû¬∞$]‚Ä∫√ôMdÔøΩ¬Æ¬™;aj√ÜÔøΩ√û3p√¢√Ä,√ç√Æ≈°√åHVK√ó‚Äûr)p√ó‚Äì√î≈Ω:	¬≥3N¬•g√Ω‚Ä∫√¥¬≤
j√™J√£81√û¬∞;‚Ñ¢‚Ñ¢√´fr√õ{¬´T√Ä≈†√ö≈†¬¨¬Æ E√õ*(E!lPA√Ö"J‚Ä¶A√ñ"	ÔøΩ(¬≤ÀÜ√≤‚Äò√ü√Ñ‚Äö@¬©+¬¢"`_√öu√á¬©√èM√ªrB√´v¬ø√Ø‚Äî{f√é√å√π≈∏s≈æ√ß&gt;√ø√≥{Àú√ì‚Ä¢¬¶√∫I√á√™√∑√øs¬Ø√•‚Ä∫∆í≈°{SX√≠qmAÔøΩDÀÜ‚Äû√∏¬µ√¢√ïc√∞v¬ß4#S∆í√©%
√Ç√ú=√∑‚Ç¨√°≈ìF]√Ç≈æ¬ºI√®√£e‚Ä†√≠4Z¬±√É√•b√§√º√î	¬ø√≠4√™O¬±√Ç¬Ø4√É¬ª√•≈ì√ß&nbsp;√µ√Ä√µ¬°Àús¬≤H)√î¬¨4$√ó¬¨¬£√ë&lt;'g√§‚Äì√É"¬ß≈ì√Å√Æ√é¬µ¬¶K≈í‚Ä°$oq‚Ä°√å:‚Äî√ùn‚Äìp√∑¬Æ3y‚Äù*[ÔøΩ¬•fD√≠&gt;≈†√Ä√ù[i‚ÄîÔøΩ¬ª?¬æ¬∫4√∂¬®√ø‚Äö,√Ä√Ä√¶jr‚Äù‚Ä∞p∆íf&lt;√∫√Ä¬°ÔøΩW?√∏\√à¬©≈ì|]¬°I√≤pf&nbsp;hÔøΩ G√§√∏√ê√ü¬æh,¬¨b‚Äù}‚Äû*rÔøΩ√Ü‚Äîv√Ω¬∞√û√ê¬≤9}T√Ø¬±‚Ä†{√©≈∏√äVd√£¬∂¬≤
√ó¬∞√õ¬¨√¶√ù√ÉÔøΩ√ú√ö√π≈ì√ò
 ¬ª√ì‚Äö√ØO√¥√ü*7e|e`√¥7‚Ä∞c)¬±√á¬¢√©¬∞¬©Q‚Äòl√òn√•‚ÄìÔøΩ‚Äô‚ÄûÔøΩ√û7g√úp√ó≈†√∂√Ç√Ç¬∞jf∆íP&gt;‚Ä∞_√±xI‚Ä∞√Æ^√ì5√®jOR√¥<s=¬°%√•¬≤l*√ºw‚Äì¬°√ïh2¬±√æp¬´¬´¬∂¬µ‚Äö√ï‚Äôh√®√≥‚Äî√º‚Äöm'¬£¬¨√çs\√É u7√ù{¬≥¬∞¬•ÔøΩmk.¬Ω="" |√âjx‚Äπrjs2‚Äùl@¬≤√¥‚Äπ@≈∏;oan√è√∞√∏="" √≥¬Æ¬†b6oÔøΩ‚Äú¬™‚Äù‚Ä¢√∏.kfp6x#s¬†‚Ñ¢√¢ÔøΩ√å≈∏‚Äöv√íÀúc8¬™g.¬∑6^¬•√Øw√∫¬¨eq√ï~√ë√Ä√ù¬°qsd√¥!e¬´llt¬¥√ï√ÇewrÀÜb‚Ä¢√§¬§ÔøΩ√è√æ:√∞o‚Ä∞¬¶√Åm="">‚Äî√¨:‚Äú≈í¬ª√ë√ã***!&gt;zi|UMi√ô‚Ñ¢l¬∂J^√â√ë≈†¬¥ÔøΩ¬≥¬´F~]ÔøΩ"¬®¬∂√Ö

¬¨¬π¬•¬®√∑‚Ä∞‚Äû√õ√¢:¬≥D‚Ç¨l√Ø≈ΩÔøΩe√§	√ª4√°Y¬∂¬¢¬∞√û√íMEb√ÖÀú‚Äô∆í√ßjJ√ä+g¬£¬°√£√¨) √ü√ße%√æ¬´V√æS:	‚Ä∫√à√ñ√ÄJ√¢‚Ä∞¬ª√ñz√∞∆íb‚Ä∞"wUJ≈†\ÔøΩ‚Äö=BÀÜ&amp;¬±‚ÄúH¬≠A¬∞F√Ä"√Ö‚Äî#‚Äìs√ø¬ßhd√∂O@√¥‚Äû√®√Æ√à√º	ÔøΩ"]√ëQ√ìR√ò√òr‚Ñ¢¬®√∞d‚Äòy¬∫√Ö¬π√Öyz√Ü\√îP√óAW,cQ√Ö√î√Ä√É¬•y¬≥,JÔøΩ√É$)‚Äú√•√äXl≈°W√•√ÅÔøΩ&gt;¬¥{√®NY,‚Ä∫‚Ä¶k4s‚Äù√∞$s√És√Ç‚Äö_g√Ñ¬∫¬≠5!¬¢√õ√ñ≈í¬¥X√∑√å+`√ö‚ÄπZ‚Ä∫¬∫qF6√°≈í≈ìÔøΩ‚Äöf¬¨qh√¥v‚Ä¢√Ö3ZR√î≈°1F¬¨}¬≠#√ó√¥s√≥√∫q¬©B√õ|¬®√¢√í($Y√†‚Äö√æ‚Äû‚Äì¬æX;xs6‚Äö√≥√íÀÜe¬µ&gt;√î√ã&amp;‚Ä°?#≈æ¬Ø√á*¬∑O√á~~√ú√∫√¨%6√¥‚Ä∞√º9√æÔøΩ√¶¬µ¬ª&lt;ARj≈†udH√•‚Ä¢7h ≈æ‚Ç¨√µ√†√§√∫¬≤√≥√∞√ü¬∑5‚Äö√Ö√á¬∏‚Ä∫y≈∏√∞ u2]√∞√â¬§≈í√í√ßr√ë√≥~√£s=√ùi5‚Äì√Ä‚Äî√πnk√ÆU¬∞√ö¬≠√û ¬¶√èn5√Ñ√ç√í¬º√∂‚Ä¶√ß≈ì√ûk≈†;ÔøΩ;r≈°uM√åj\Y√ñ¬≤h‚Äπ¬Æ√≥¬¢!;w√§∆í≈ì/b√¥R√Ω‚Ä¶√ì¬¨≈Ω√°√ú√î¬¨‚ÄùL5√≥i‚Äôt≈∏?√Ω≈æl√º√∞.√ü~√î√ü&amp;≈ì5‚Ä¢¬ªX&amp;√±√ª√∑5I¬µ^K√î;‚Äö1¬¢G¬∏P¬ßg√∫√µ-m√ói}~¬∂6≈∏√ÆD¬Ω¬∫¬¥√¥≈ìC√¥√ñma‚Ä∫√ôLRT‚Ñ¢√µ√î≈°¬´√ê¬©?VZ√økÔøΩ/≈Ω∆í√§¬ø√°‚Ä¢T√ù¬Æ¬∫H∆í&nbsp;¬ø√∑√Åw;‚Ä∫WÔøΩe}√ãbLÔøΩ‚Äô√ö√ä3]¬≠5
√µ	¬¶√¥Q¬ª¬≥PJ;√∏n^√ªYS√àd4√ªm|y√Ç.I√∏√æ¬®√ç;d&amp;c¬Æ≈í4√ç√Äoz‚Äö?√ç
Q+¬º¬ºo!¬£√Ä?gy_rN√ïDWW|}√å√àf√∂‚Ñ¢¬©*m&lt;-M¬©√Æa¬°√¨ÔøΩ=√ò
‚Äû√â≈°‚Äò0k)√òMÔøΩrJ√î√ä√§‚Äô)W√îA*¬≤¬©√ånEX√òV√ö√Ω√Ä√µ√á,‚Äù¬∏¬¢Z√≤|¬¥√´oÔøΩÔøΩ
¬ß¬¨N‚Ä∫|√î∆í%¬≥√™¬≥[:$√ÇG¬¶¬ºg¬•\¬®(√ñ‚Ç¨u√Äw&amp;‚Ñ¢'√Å≈∏K&amp;‚Äì‚ÄúKQ9‚Ä†√ÖU¬∏&amp;S√µ¬°√Ü√îFE‚Äπ‚Äù‚Äπ‚Ä¶¬∞√¶√à8\{‚Äö√ô√Çd	√ï‚Ñ¢¬¨K√±√í1rRpf√¨*√™√êwc√Ü√ê√ª‚Ä†¬øG
√±	√Øc√ï‚Ä¢√§‚Äù¬©√∞O
J‚Äúb"√ê¬¥¬´:¬ø√¨√∂‚Äö√±:√íe+¬∂)¬∂k¬¨√≥‚Ä°;R;T‚Äî6C¬∂X√∏√¶√Ç#Ip&lt;‚Ä∞√∑
√ß√á/¬∂√Æ¬¥B^√®√±¬∑¬¨<s¬•¬±¬º√∏ fclq√¨‚Ä∞√ÉÀÜ'√æ;‚Ä∞<!¬∑‚Ä°¬©‚Äû¬π√±]e≈ì√¢¬†"¬´**‚Äù√•_vlx):#{¬π√•ÔøΩ$^="">√Ç√è¬∑Jn≈ì√±'√≤4¬∫√¥IFVz√¶a&amp;)t√ø√±√âq‚Ä∞1¬™√Ñ√¥√íu√¢√í<s‚Äò¬π¬æ¬ß√ã√º¬†√ñ‚Ç¨~ #‚Äî¬†:√µ¬æc{√á`ÔøΩi¬´t√ók√é.‚Ç¨¬±-<2√è‚Ä†y&√Æm¬æi="">√∑√∂¬™√ï‚Äò¬•√•'√ãNV@4T‚Äπs.3√Ñ√áP¬§%√£‚Äô√§q√®¬™√á¬´√ÜQ√Æ/J√û√Ñ√ÇrÀú√∫‚Äîr√†¬•@x√ÇJ√∫√≠√õ¬Øqo√∂ÀÜ√™¬∞9√ö√Ä^¬™GWZ^K√ó√ñ√â√öp√è5X¬´n¬§¬Øw7√Ä√ú√ñÔøΩ√º&lt;;%&amp;‚Äö√û¬ª√óT√Ñ≈†^≈ì√µ≈Ω2√¨¬¢79√•¬±√Ç{.√íy√ó√æm¬≥Ac√É√Ø¬¥xS√Ö(ÔøΩ¬∏D!ÔøΩ¬¢h+√ºTC√ßk√∏9√Ω¬≤√î
?~∆íH;√æ√ªd¬¨l¬≤I√ÑD√¥	$√¥`√å√≤√•≈∏ÔøΩ:√äÔøΩ√≥√≠X‚Ä¶&lt;¬≠B√ºi‚Äπ'¬•√π8√ñA√æ√ô‚Ä¢¬Ø√Ö√ß√ç`s√™¬æm√∑!&lt;√ßÔøΩ√∏¬øs√ÇWg≈°√Æ‚Ñ¢¬°√ö&lt;√ô√Ñ¬´√≠Àú√¨√¢√¶t√∞a√ö√≤‚Ä¶<q√É√É√†¬Ø√†<a-≈Ω<∆í¬ª#o‚Äûg√§√Åf‚Ä°q¬∏s≈°∆í√¶aqa√ñqf‚Äπws√ê¬∞‚Ä¶√ÖpÔøΩ90¬†i√©sc‚Äπ¬∂√ì≈Ω|‚Äûh√áw¬∞m>√ø√ç¬©V]O(√∂h√Ç√©√•√í¬æ√ë¬±√≥=O√ö√™√©√∂w¬∂¬∏¬ø√°\¬µ√∏√†Bs √∫¬∞ÔøΩ√ë;√±√ø√í√Üw√πÔøΩ¬Æ}√öx¬ø√Ø√Ω√Éw¬π‚Äû_
√ª√Æ√≤√£≈ì√®≈†√π‚Äπ‚Äî¬≠([Àú≈∏_R‚Äô_¬∞&nbsp;x‚Ä¶√ºw?1¬∏X)Pl&gt;PL√∏√•√á√üo(u¬§6√ªR¬°¬¥}¬™√¥√©¬∂¬£¬ØX{√ô≈Ω√™¬∞≈æg√ìz¬πXh‚ÄúZ√ë√Ä√ä¬´¬ØÔøΩ%V	√à‚ÄπÔøΩ‚Ä¶w
o√ª√ÆG¬¥w~g0%¬æ‚Äû¬´D.√°‚Äö.√ús|√Øw¬Ø‚ÄπB√ßY&gt;√æ√±¬£√∏¬•h]IlyÀú¬¥√∞‚Äî√ê√ày‚Ä∫√í√§V‚Äìok&gt;√ä√±}√Ω6√°¬ø¬∑¬±M√™≈æ0Qjf√è¬¨≈ær√ü¬∑√¨√Ω¬Ω≈°m√™ÔøΩ√π;V¬Æ√†X¬øv√ª¬º∆í√í;¬∂√ñ√ñ.‚Äò≈∏‚ÄìuV~√¨≈ìiK¬Ø√ú¬∞√π√§¬§√ú√ÄzW√è√àcl]¬µ]5√ïm√ùmmRAQ'√ô¬¶8/	√úÀú√à¬∏√∑r√é√©¬≥√ª,X%√è√ó0√≠¬ß√ô√¥√üq√ì¬æ√´O√õ3√≠O√â$¬∂^√ªL√º‚Äú?m√á√Ñ√ô√•$¬∏6√ç√º√è√Éy≈Ω√´1√∑√£~√û√Ø√â"√Ä&nbsp;0Eo¬©√°
endstream
endobj
2617 0 obj
&lt;&gt;stream
H‚Ä∞≈ì‚ÄìyTSw√áo√â≈æÔøΩ‚Ä¢¬∞√Éc
[‚Ç¨¬∞ÔøΩ5la‚ÄòQIBH√òADED‚Äû¬™‚Ä¢2√ñmtFOEÔøΩ.¬Æc¬≠√ñ}√™√í√µ0√™√®8¬¥√ó≈ΩÔøΩ8GÔøΩNg¬¶√ì√Ø√Ø√∑9√∑w√Ø√Ø√ù√ü¬Ω√∑ÔøΩ√≥&nbsp;'¬•¬™¬µ√ï0ÔøΩ√ñ&nbsp;√èJ≈í√Öb¬§	
 2y¬≠.-;!√†‚Äô√ÜK¬∞Z√ú	√º‚Äπ≈æ^ÔøΩi¬Ω"L√ä√Ä0√∞√ø‚Ä∞-√ó√©
@8(‚Äù¬µr≈ì;q¬Æ¬™7√®L√∂≈ìy¬•‚Ä¢&amp;‚Ä†Q√´√±q¬∂4¬±j≈æ¬Ω√ß|√¶9√ö√Ñ
ÔøΩVÔøΩ¬≥)gÔøΩB¬£0√±i≈ìW√ó‚Ä¢8#¬©8w√ï¬©‚Ä¢√µ8_√Ö√ô¬•√ä¬®Q√£√º√ú¬´Q√äj@√©&amp;¬ªA)/√á√ôg¬∫&gt;'K‚Äö√≥√àt√ï;\√∫‚Äù
√ì¬•$√ï¬∫F¬ΩZUn√Ä√ú√•Àú(4T≈í%)√´¬´‚Äù∆í0C&amp;¬Ø‚Äù√©Àú¬§Z¬£‚ÄúiÀú¬ø√≥≈ì8¬¶√öbx‚Äò∆íE¬°√Å√ÅB√ë;‚Ä¶√∫¬Ø‚Ä∫¬øP¬¶√û√é√ì‚Äú√å¬π≈æA√ºom?√ßW=
‚Ç¨x¬Ø√ç√∫¬∑¬∂√í-≈í¬Ø√Ä√≤√¶[‚Ä∫√ã√ª0√±¬æ¬æ√∏√é}√∏¬¶y)7ta¬æ¬æ√µ√µ√µ&gt;j¬•√ú√áT√ê7√∫≈∏¬ø@√Ø¬º√è√át√ú‚Ä∫√≤`q√ä2‚Ñ¢¬±√ä‚Ç¨‚Ñ¢√™&amp;¬Ø¬Æ¬™6√™¬±ZÔøΩL¬Æ√Ñ‚Äû?√¢_√∏√≥yxg)√ã‚Äùz¬•ÔøΩ√à√É¬ßL¬≠U√°√≠√ñ*√îu¬µSk√øSe√òO4?√ó¬∏¬∏c¬Ø¬Ø√ò¬∞.√≤√≤¬∑√•√íR¬¥
√üÔøΩ√û√¥-‚Ä¢‚Äô2√∞5√ü√°√û√º√ú√è	√∫√∑S√°&gt;√ì¬£V¬≠≈°‚Äπ‚Äúd√•`r¬£¬æn~√è√¥Y&nbsp;&amp;√†+`≈ìÔøΩ;√ÇA4ÀÜ√â √§‚Ç¨¬∞√àA9√ê=¬®-&nbsp;tÔøΩ¬∞l√É`;¬ª√Å~p≈í∆íÔøΩ√Å	√∞Gp|	¬ÆÔøΩ[`L∆í‚Ä°`&lt;¬Ø "AÀÜYAÔøΩ+√§√πCb(≈†‚Ä°R¬°,¬®*ÔøΩTÔøΩ2B-√ê
¬®√™‚Ä°‚Ä†¬°√ên√®√∑√êQ√®t¬∫}MA&nbsp;√Ø&nbsp;‚Äî0√ìal¬ª√Å¬æ¬∞≈ΩÔøΩS√†x	¬¨‚Äök√†&amp;¬∏^√Å¬£√∞&gt;√∏0|&gt;_∆í'√°‚Ä°√∞,√ÇG!"F$H:RÀÜ‚Äù!z¬§√©F‚ÄòQd?r9‚Äπ\A&amp;‚ÄòG√à‚ÄùÀÜrQ¬¢√°h≈°‚Äπ√ä√ë¬¥√≠E‚Ä°√ë]√®a√¥4zÔøΩBg√ê√ó√Å‚Äì√†E#H	‚Äπ*B=¬°‚Äπ0H√òI√∏ÀÜp‚Ä†pÔøΩ0MxJ$√πD1‚ÄûÀúD, V‚Ä∫‚Ä∞¬Ω√Ñ¬≠√Ñ√Ñ√£√ÑK√Ñ¬ª√ÑY‚Ä∞dE√≤"EÔøΩ√íI2‚ÄôÔøΩ√îE√öB√öG√∫≈ít‚Ñ¢4MzN¬¶‚Äò√à√æ√§r!YK√Æ ‚Äô√∑ÔøΩ?%_&amp;√ü#¬ø¬¢¬∞(¬Æ‚Äù0J:EAi¬§√¥Q√Ü(√á()√ì‚ÄùWT6U@ÔøΩ&nbsp;√¶P+¬®√≠√î!√™~√™√™m√™ÔøΩ√¶D¬•e√í√î¬¥√•¬¥!√ö√Øh≈∏√ì¬¶h/√®¬∫']B/¬¢√©√´√®√íÔøΩ√ì¬ø¬¢?a0n≈íhF!√É√ÄX√á√ò√ç8√Ö√∏≈°√±√ú≈ík√¶c&amp;5SÀú¬µ‚Ñ¢ÔøΩÀú6¬ªl√∂ÀúIa¬∫2cÀúK‚Ñ¢M√åA√¶!√¶E√¶#‚Ä¶√•√Ü‚Äô¬∞d¬¨V√ñ√´(√´k‚Äì√çe‚Äπ√ò√©l
¬ª‚Äî¬Ω‚Ä°}≈Ω}≈∏C√¢¬∏q√¢9
N'√ß√é)√é].√Çu√¶J¬∏r√Æ
√Æ√∑w≈°G√§	xR^¬Ø‚Ä°√∑[√ûo√Ü≈ìch≈æg√û`&gt;b√æ‚Ä∞√π$√°¬ª√±¬•√º*~√ø √ø:√ø¬•‚Ä¶ÔøΩE≈í‚Ä¶√íbÔøΩ√Ö~‚Äπ√ã√è,m,¬£-‚Ä¢‚Äì√ù‚Äì,¬ØY¬æ¬¥√Ç¬¨√¢¬≠*¬≠6XÔøΩ[√ù¬±F¬≠=¬≠3¬≠√´¬≠¬∑Y≈∏¬±~d√É¬≥	‚Ä¶</q√£√£√†¬Ø√†<a-≈æ<∆í¬ª#o‚Äûg√§√°f‚Ä°q¬∏s≈°∆í√¶aqa√∂qf‚Äπws√∞¬∞‚Ä¶√•pÔøΩ90¬†i√©sc‚Äπ¬∂√≥≈æ|‚Äûh√ßw¬∞m></s‚Äò¬π¬æ¬ß√´√º¬†√∂‚Ç¨~></s¬•¬±¬º√∏></s=¬°%√•¬≤l*√ºw‚Äì¬°√µh2¬±√æp¬´¬´¬∂¬µ‚Äö√µ‚Äôh√®√≥‚Äî√º‚Äöm'¬£¬¨√≠s\√£></k‚Äö√¥fn7p≈°></g_rr√£ze8t‚Äù¬•¬ø√≤‚Äú≈æjhd4√∏¬∂q‚Ä°√ßx√µ`¬ª√µ1‚Ä†></z"xa√°‚Äöq√∏√ü√π(√Ω≈ì√ß‚Ç¨‚Ä†3¬¥√¥√º8¬ß√ø‚Ä¢√ØÔøΩ¬´ÔøΩ√¥√∏ÔøΩ‚Ä¶~¬¥√∑is¬®></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.europarl.europa.eu/RegData/etudes/STUD/2020/648784/IPOL_STU(2020)648784_EN.pdf#page=39">https://www.europarl.europa.eu/RegData/etudes/STUD/2020/648784/IPOL_STU(2020)648784_EN.pdf#page=39</a></em></p>]]>
            </description>
            <link>https://www.europarl.europa.eu/RegData/etudes/STUD/2020/648784/IPOL_STU(2020)648784_EN.pdf#page=39</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046096</guid>
            <pubDate>Tue, 10 Nov 2020 14:12:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitdefender: UPX Unpacking Featuring Ten Memory Corruptions]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046084">thread link</a>) | @landave
<br/>
November 10, 2020 | https://landave.io/2020/11/bitdefender-upx-unpacking-featuring-ten-memory-corruptions/ | <a href="https://web.archive.org/web/*/https://landave.io/2020/11/bitdefender-upx-unpacking-featuring-ten-memory-corruptions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>This post breaks the two-year silence of this blog, showcasing a selection of memory corruption vulnerabilities in Bitdefender‚Äôs anti-virus engine.</p>
<h2 id="introduction">Introduction</h2>
<p>The goal of binary packing is to compress or obfuscate a binary, usually to save space/bandwidth or to evade malware analysis.
A packed binary typically contains a compressed/obfuscated data payload. When the binary is executed, a loader decompresses this payload and then jumps to the actual entry point of the (inner) binary.
Most anti-virus engines support binary unpacking at least for packers (such as <a href="https://upx.github.io/">UPX</a>) that are very popular and that are also used by non-malware software.</p>
<p>This blog post is about UPX unpacking of PE binaries in the Bitdefender core engine. The main steps in UPX unpacking of PE binary files are the following:</p>
<ol>
<li>Detect the loader from the entry point</li>
<li>Find the compressed data payload and extract it</li>
<li>Unfilter the extracted code</li>
<li>Rebuild various structures (such as the import table, the relocation table, the export table, and the resources)</li>
</ol>
<p>The following vulnerabilities are presented in the control-flow order of the UPX unpacker.</p>
<p><strong>Disclaimer</strong>: In the following, decompiled code from Bitdefender‚Äôs core engine is presented.
The naming of variables, fields, and macros is heavily inspired by the <a href="https://github.com/upx/">original UPX</a>. For some snippets, a reference to the original function is added for comparison. It is likely that some types are incorrect.</p>

<p>After the UPX loader has been detected, the Bitdefender engine tries to detect whether the loader applies a specific kind of deobfuscation to the compressed data payload before extracting it. The (de)obfuscation is very simple, making only use of the three operations ADD, XOR, and ROTATE_LEFT.
If this deobfuscation is detected, then the engine iterates through the corresponding instructions of the loader and parses them with their operands in order to be able to deobfuscate the data as well. This looks as follows:</p>
<div><pre><code data-lang="cpp"><span>int32_t</span> operation[<span>16</span>]; <span>// on the stack
</span><span></span><span>int32_t</span> operand[<span>16</span>]; <span>// on the stack
</span><span></span><span>int</span> i <span>=</span> <span>0</span>;
<span>int</span> pos <span>=</span> <span>0</span>;
<span>do</span> {
  <span>bool</span> op_XOR_or_ADD <span>=</span> <span>false</span>;
  <span>if</span> (loaderdata[pos] <span>==</span> <span>0x81u</span>
    <span>&amp;&amp;</span> (loaderdata[pos <span>+</span> <span>1</span>] <span>==</span> <span>0x34</span>  <span>||</span> loaderdata[pos <span>+</span> <span>1</span>] <span>==</span> <span>0x4</span>)) {
      operation[i] <span>=</span> (loaderdata[pos <span>+</span> <span>1</span>] <span>==</span> <span>0x34</span>) <span>?</span> <span>OP_XOR</span> : OP_ADD;
      operand[i] <span>=</span> <span>*</span>(<span>int32_t</span> <span>*</span>)<span>&amp;</span>loaderdata[pos <span>+</span> <span>3</span>];
<span>      <span>++</span>i;
</span>      pos <span>+=</span> <span>7</span>;
      op_XOR_or_ADD <span>=</span> <span>true</span>;
    }
  }
  <span>if</span> (loaderdata[pos] <span>==</span> <span>0xC1u</span> <span>&amp;&amp;</span> loaderdata[pos <span>+</span> <span>1</span>] <span>==</span> <span>4</span>) {
    operation[i] <span>=</span> OP_ROTATE_LEFT;
    operand[i] <span>=</span> loaderdata[pos <span>+</span> <span>3</span>];
<span>    <span>++</span>i;
</span>    pos <span>+=</span> <span>4</span>;
<span>    <span>if</span> (i <span>==</span> <span>16</span>) <span>break</span>;
</span>    <span>continue</span>;
  }
  <span>if</span> (op_XOR_or_ADD) {
<span>    <span>if</span> (i <span>==</span> <span>16</span>) <span>break</span>;
</span>    <span>continue</span>;
  }
  <span>if</span> (loaderdata[pos] <span>==</span> <span>0xE2u</span>) { <span>/* omitted: apply collected operations */</span> }
  pos <span>+=</span> <span>2</span>;
} <span>while</span> (pos <span>+</span> SOME_SLACK <span>&lt;</span> loaderdata_end);
</code></pre></div><p>Observe how the bound-check on the index variable <code>i</code> is performed. As the buffer <code>loaderdata</code> is fully attacker-controlled, it is easy to verify that we can increase the index variable <code>i</code> by two before running into one of the checks <code>i == 16</code>. In particular, we can increase <code>i</code> from 15 to 17, after which we can overwrite the stack with completely arbitrary data.</p>
<div><pre><code data-lang="python">(<span>10</span>ec<span>.</span><span>12</span>dc): Break instruction exception <span>-</span> code <span>80000003</span> (first chance)
<span>00000000</span><span>`</span><span>0601</span>fe42 cc              <span>int</span>     <span>3</span>
</code></pre></div><p>The debug break is due to the stack canary which we have overwritten. If we continue, we see that the return fails because the stack is corrupted.</p>
<div><pre><code data-lang="python"><span>0</span>:<span>000</span><span>&gt;</span> g
(<span>10</span>ec<span>.</span><span>12</span>dc): Access violation <span>-</span> code c0000005 (first chance)
First chance exceptions are reported before <span>any</span> exception handling<span>.</span>
This exception may be expected <span>and</span> handled<span>.</span>
<span>00000000</span><span>`</span><span>06006603</span> c3              ret

<span>0</span>:<span>000</span><span>&gt;</span> dd rsp
<span>00000000</span><span>`</span><span>0014</span>ed98  deadbeef deadbeef deadbeef deadbeef
<span>00000000</span><span>`</span><span>0014</span>eda8  deadbeef deadbeef deadbeef deadbeef
</code></pre></div>
<p>The collected operations (for the deobfuscation shown in //1//) are applied to the payload buffer at an attacker-controlled offset <code>write_offset</code>.
Obviously, this offsets needs to be checked before writing to it. There are two checks on <code>write_offset</code>. The first is</p>
<div><pre><code data-lang="cpp"><span>if</span> (write_offset <span>&lt;=</span> extractobj<span>-&gt;</span>dword10 <span>+</span> <span>3</span>) 
</code></pre></div><p>and the second one is</p>
<div><pre><code data-lang="cpp"><span>if</span> (loaderdata[pos] <span>==</span> <span>0xE2u</span>) {
  <span>if</span> (write_offset <span>&gt;=</span> extractobj<span>-&gt;</span>dword10 <span>-</span> <span>3</span>)
</code></pre></div><p>Both checks test against the field <code>dword10</code>. The field <code>dword10</code>, sitting on the calling functions‚Äôs stack frame, is never initialized. This makes the bound check useless and introduces a fully attacker-controlled heap buffer overflow.</p>

<p>After the extraction, the engine attempts to deobfuscate the extracted data with a static XOR key.</p>
<div><pre><code data-lang="cpp"><span>for</span>(<span>int</span> i<span>=</span><span>0</span>; i<span>&lt;</span><span>0x300</span>; i<span>++</span>) {
  <span>if</span> (<span>*</span>(<span>int32_t</span> <span>*</span>)<span>&amp;</span>entrypoint_data[i] <span>==</span> <span>0x4243484B</span>) {
    <span>int32_t</span> j <span>=</span> i <span>+</span> <span>0x4A</span>;
    <span>uint8_t</span> xor_key <span>=</span> entrypoint_data[j]; <span>// attacker-controlled
</span><span></span>    <span>int32_t</span> xor_len <span>=</span> <span>*</span>(<span>int32_t</span> <span>*</span>)<span>&amp;</span>entrypoint_data[j <span>-</span> <span>7</span>]; <span>// attacker-controlled
</span><span></span>    <span>if</span> (xor_len <span>&gt;</span> packer<span>-&gt;</span>set_to_size_of_rawdata) <span>return</span> j; <span>// &lt;-- wrong bound check
</span><span></span>    <span>for</span>(<span>int32_t</span> k<span>=</span><span>0</span>; k<span>&lt;</span>xor_len; k<span>++</span>) {
<span>      packer<span>-&gt;</span>extracted_data[k] <span>^=</span> xor_key; <span>// &lt;-- oob write
</span></span><span></span>    }
    <span>*</span>info_string <span>=</span> <span>"encrypted"</span>;
  }
}
</code></pre></div><p>The bound check is completely wrong. It should check against the size of the extracted data buffer. Instead, it checks against a value that is previously set to the raw data size of the section we extracted the data from. Those two sizes have nothing to do with each other. In particular, one can be much smaller than the other, or vice-versa.</p>
<p>As the function does not return after the first deobfuscation run, the memory corruption can be triggered up to 0x300 times in a row.
This allows us to bypass the limitation that in a single deobfuscation run we always XOR with the same byte. We would simply XOR as follows:</p>
<div><pre><code data-lang="cpp">First run (i<span>=</span><span>0</span>)<span>:</span>  XOR with B0 B0 B0 B0 B0 B0 B0
Second run (i<span>=</span><span>1</span>)<span>:</span> XOR with B1 B1 B1 B1 B1
Third run (i<span>=</span><span>2</span>)<span>:</span>  XOR with B2 B2
</code></pre></div><p>Overall, we then have XORed with C0 C0 C1 C1 C1 C2 C2 for completely arbitrary C0, C1, and C2. We can essentially XOR with such a pattern of almost arbitrary length, and switch the byte at most 0x300 times.</p>
<p>Needless to say, this vulnerability is a useful exploitation primitive as it enables very powerful memory corruptions: XORing allows us to modify selectively only certain parts of data, leaving other parts (for example heap metadata or critical objects) untouched.</p>
<h2 id="4-heap-buffer-overflow-in-the-filters">//4//: Heap Buffer Overflow in the Filters</h2>
<p>A filter is a simple transformation on binary code (say, x86-64 code) that is applied before compression, with the goal to make the code more compressible. After we have decompressed the data, we need to revert this filtering.
Bitdefender supports about 15 different filters. Here is one of them (filter 0x11):</p>
<div><pre><code data-lang="cpp"><span>int32_t</span> bytes_to_filter <span>=</span> <span>/* omitted. is guaranteed not to be oob. */</span>; 
<span>int</span> i <span>=</span> <span>0</span>;
<span>while</span> (<span>1</span>) {
  <span>do</span> {
    <span>if</span> (<span>--</span>bytes_to_filter <span>&lt;</span> <span>0</span>) <span>break</span>;
  } <span>while</span> (extracted_data[i<span>++</span>] <span>!=</span> <span>0xE8u</span>);
  <span>if</span> (bytes_to_filter <span>&lt;</span> <span>0</span>) <span>break</span>;
  <span>*</span>(<span>int32_t</span> <span>*</span>)<span>&amp;</span>extracted_data[i] <span>-=</span> i; <span>// &lt;-- oob write
</span><span></span>  i <span>+=</span> <span>4</span>;
}
</code></pre></div><p>The problem is that <code>bytes_to_filter</code> is only updated when <code>i</code> is incremented by one, but not when it is later incremented by four.</p>
<p>Of the 15 filters, about 8 seem to be affected by such a heap buffer overflow. I treated them all together as one bug (after all, it is not unlikely that they share code).</p>
<h2 id="5-heap-buffer-overflow-when-rebuilding-imports">//5//: Heap Buffer Overflow when Rebuilding Imports</h2>
<p>The following memory corruption occurs in a loop of the function PeFile::rebuildImports (cf. <a href="https://github.com/upx/upx/blob/d7ba31cab8ce8d95d2c10e88d2ec787ac52005ef/src/pefile.cpp#L2832">PeFile::rebuildImports</a>). It looks like this:</p>
<div><pre><code data-lang="cpp"><span>this</span><span>-&gt;</span>im<span>-&gt;</span>iat <span>=</span> <span>this</span><span>-&gt;</span>iatoffs;
<span>this</span><span>-&gt;</span>newiat <span>=</span> <span>&amp;</span>extract_obj<span>-&gt;</span>extracted_data[<span>this</span><span>-&gt;</span>iatoffs <span>-</span> (<span>uint64_t</span>)(<span>uint32_t</span>)pefile<span>-&gt;</span>rvamin];
<span>while</span> (<span>*</span>p) {
  <span>if</span> (<span>*</span>p <span>==</span> <span>1</span>) {
    ilen <span>=</span> strlen(<span>++</span>p) <span>+</span> <span>1</span>;
    <span>if</span> (<span>this</span><span>-&gt;</span>inamespos) {
      <span>if</span> (ptr_diff(<span>this</span><span>-&gt;</span>importednames,<span>this</span><span>-&gt;</span>importednames_start) <span>&amp;</span> <span>1</span>) <span>--</span><span>this</span><span>-&gt;</span>importednames;
<span>      memcpy(<span>this</span><span>-&gt;</span>importednames <span>+</span> <span>2</span>, p, ilen); <span>// &lt;-- memory corruption
</span></span><span></span>      <span>*</span><span>this</span><span>-&gt;</span>newiat <span>=</span> ptr_diff(<span>this</span><span>-&gt;</span>importednames,extract_obj<span>-&gt;</span>extracted_data <span>-</span> pefile<span>-&gt;</span>rvamin);
      <span>this</span><span>-&gt;</span>importednames <span>+=</span> ilen <span>+</span> <span>2</span>;
      p <span>+=</span> ilen;
    }
    <span>else</span> {
      <span>//omitted, see below //5//
</span><span></span>    }
  }
  <span>else</span> <span>if</span> (<span>*</span>p <span>==</span> <span>0xFFu</span>) {
    p <span>+=</span> <span>3</span>;
    <span>*</span><span>this</span><span>-&gt;</span>newiat <span>=</span> ord_mask <span>+</span> <span>*</span>(<span>uint16_t</span> <span>*</span>)(p <span>+</span> <span>1</span>);
  }
  <span>else</span> {
    <span>// omitted
</span><span></span>  }
  <span>++</span><span>this</span><span>-&gt;</span>newiat;
}
</code></pre></div><p>The length <code>ilen</code> that is passed to memcpy is completely attacker-controlled and thus needs to be checked. Observe that the <a href="https://github.com/upx/upx/blob/d7ba31cab8ce8d95d2c10e88d2ec787ac52005ef/src/pefile.cpp#L2847">original UPX</a> does a checked omemcpy at this place.</p>
<h2 id="6-another-heap-buffer-overflow-when-rebuilding-imports">//6//: Another Heap Buffer Overflow when Rebuilding Imports</h2>
<p>In the same loop of the function PeFile::rebuildImports (cf. <a href="https://github.com/upx/upx/blob/d7ba31cab8ce8d95d2c10e88d2ec787ac52005ef/src/pefile.cpp#L2832">PeFile::rebuildImports</a>), there is another memory corruption:</p>
<div><pre><code data-lang="cpp"><span>this</span><span>-&gt;</span>im<span>-&gt;</span>iat <span>=</span> <span>this</span><span>-&gt;</span>iatoffs;
<span>this</span><span>-&gt;</span>newiat <span>=</span> <span>&amp;</span>extract_obj<span>-&gt;</span>extracted_data[<span>this</span><span>-&gt;</span>iatoffs <span>-</span> (<span>uint64_t</span>)(<span>uint32_t</span>)pefile<span>-&gt;</span>rvamin];
<span>while</span> (<span>*</span>p) {
  <span>if</span> (<span>*</span>p <span>==</span> <span>1</span>) {
    ilen <span>=</span> strlen(<span>++</span>p) <span>+</span> <span>1</span>;
    <span>if</span> (<span>this</span><span>-&gt;</span>inamespos) {
      <span>//omitted, see above //5//
</span><span></span>    }
    <span>else</span> {
      extracted_data <span>=</span> extract_obj<span>-&gt;</span>extracted_data;
      dst_ptr <span>=</span> (extracted_data <span>-</span> pefile<span>-&gt;</span>rvamin) <span>+</span> (<span>*</span><span>this</span><span>-&gt;</span>newiat <span>+</span> <span>2</span>);
      <span>if</span> (dst_ptr <span>&lt;</span> extracted_data) <span>return</span> <span>0</span>;
      extracted_data_end <span>=</span> <span>&amp;</span>extracted_data[extract_obj<span>-&gt;</span>extractbuffer_bytes_written];
      <span>if</span> (dst_ptr <span>&gt;</span> extracted_data_end <span>||</span> <span>&amp;</span>dst_ptr[ilen <span>+</span> <span>1</span>] <span>&gt;</span> extracted_data_end) <span>return</span> <span>0</span>;
<span>      strcpy(dst_ptr,p); <span>// &lt;-- memory corruption
</span></span><span></span>      p <span>+=</span> ilen;
    }
  }
  <span>else</span> <span>if</span> (<span>*</span>p <span>==</span> <span>0xFFu</span>) {
    p <span>+=</span> <span>3</span>;
    <span>*</span><span>this</span><span>-&gt;</span>newiat <span>=</span> ord_mask <span>+</span> <span>*</span>(<span>uint16_t</span> <span>*</span>)(p <span>+</span> <span>1</span>);
  }
  <span>else</span> {
    <span>// omitted
</span><span></span>  }
  <span>++</span><span>this</span><span>-&gt;</span>newiat;
}
</code></pre></div><p>The problem is that the strings <code>dst_ptr</code> and <code>p</code> can overlap, so we overwrite the string that we called strlen() on earlier.
This can turn a terminating null-byte into a non-null byte and when strcpy() is called, the string is longer than expected, overflowing the buffer.</p>
<p>A possible fix is to replace the <code>strcpy(dst_ptr,p)</code> with <code>memmove(dst_ptr,p,ilen)</code>.</p>
<p>It looks like <a href="https://github.com/upx/upx/blob/d7ba31cab8ce8d95d2c10e88d2ec787ac52005ef/src/pefile.cpp#L2832">original UPX</a> is affected as well. The two commits <a href="https://github.com/upx/upx/commit/14992260c60b8d6677a677a9cdfae98b11353df7">14992260</a> and <a href="https://github.com/upx/upx/commit/1faaba8f4ce56eb5df8ce24bb4f04d665b87b4fa">1faaba8f</a> are an attempt to fix the problem in the devel branch of UPX.</p>
<h2 id="7-heap-buffer-overflow-when-unoptimizing-the-relocation-table">//7//: Heap Buffer Overflow when Unoptimizing the Relocation Table</h2>
<p>Another memory corruption is in the function Packer::unoptimizeReloc (cf. <a href="https://github.com/upx/upx/blob/d7ba31cab8ce8d95d2c10e88d2ec787ac52005ef/src/packer.cpp#L990">Packer::unoptimizeReloc</a>):</p>
<div><pre><code data-lang="cpp"><span>for</span> (<span>uint8_t</span> <span>*</span> p <span>=</span> <span>*</span>in; <span>*</span>p; p<span>++</span>, relocn<span>++</span>) {
  <span>if</span> (<span>*</span>p <span>&gt;=</span> <span>0xF0u</span>) {
    <span>if</span> (<span>*</span>p <span>==</span> <span>0xF0u</span> <span>&amp;&amp;</span> <span>!*</span>(<span>uint16_t</span> <span>*</span>)(‚Ä¶</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://landave.io/2020/11/bitdefender-upx-unpacking-featuring-ten-memory-corruptions/">https://landave.io/2020/11/bitdefender-upx-unpacking-featuring-ten-memory-corruptions/</a></em></p>]]>
            </description>
            <link>https://landave.io/2020/11/bitdefender-upx-unpacking-featuring-ten-memory-corruptions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046084</guid>
            <pubDate>Tue, 10 Nov 2020 14:11:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generating a random identifier grew my bundle size by 300kb]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25046036">thread link</a>) | @ThePadawan
<br/>
November 10, 2020 | https://blog.prat.ch/2020/11/10/randomstring-bundle-size | <a href="https://web.archive.org/web/*/https://blog.prat.ch/2020/11/10/randomstring-bundle-size">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div href="/2020/11/10/randomstring-bundle-size">
    <h2>How generating a random identifier grew my bundle size by 300kb</h2>
  </div><div>
    <p>Recently, I added a notification box to
<a href="https://github.com/ThePadawan/beevenue">Beevenue</a>, a small booru I am building
as a side project:</p>

<p><img src="https://blog.prat.ch/assets/img/2020-11-10-notification-box.png" alt="Notification box with two separate notifications"></p>

<p>Being the good developer that I am, I got annoyed the warning that every React
developer has probably seen at least once:</p>

<div><div><pre><code>Each child in an array should have a unique "key" prop.
</code></pre></div></div>

<p>I won‚Äôt repeat the reasoning behind this, since
<a href="https://reactjs.org/docs/lists-and-keys.html#keys">React‚Äôs documentation</a>
explains it very concisely.</p>

<h2 id="what-i-wanted">What I wanted</h2>

<p>Since notifications were not unique (they could have the same contents and timestamp),
I decided to add a randomly chosen identifier of the form ‚Äúnotification-abc123‚Äù.</p>

<p>Simple, right?</p>

<p>High on life, and eager to install NPM packages instead of building it myself,
the <a href="https://www.npmjs.com/package/randomstring">randomstring</a> package looked
like just what I needed.</p>

<p>It would allow me to generate an identifier of a great enough length to avoid
duplicates with a very high probability:</p>

<div><div><pre><code><span>randomstring</span><span>.</span><span>generate</span><span>({</span>
  <span>length</span><span>:</span> <span>12</span><span>,</span>
  <span>charset</span><span>:</span> <span>"</span><span>alphabetic</span><span>"</span><span>,</span>
<span>});</span>
<span>// &gt;&gt; "AqoTIzKurxJi"</span>
</code></pre></div></div>

<p>So I installed the package via npm, called <code>randomstring.generate</code>, tested the
functionality successfully, and moved on with my life.</p>

<h2 id="but-wait">‚Ä¶but wait</h2>

<p>Now, the notification box is a top-level component in Beevenue, meaning it is
visible on practically all pages. For that reason, it is reasonable to not lazy
load it, but eagerly package it in the bundle that is requested on initial load
of the application.</p>

<p>A while later (having implemented some other features and added more and more
npm packages), I wondered why my bundle size had at some point ballooned
significantly.</p>

<p>Since the project uses <a href="https://create-react-app.dev/">Create React App</a>, I
simply fired up the recommended
<a href="https://create-react-app.dev/docs/analyzing-the-bundle-size/">Source Map Explorer</a>:</p>

<p><img src="https://blog.prat.ch/assets/img/2020-11-10-sme-before.png" alt="Source Map Explorer output before (more than 700KB)"></p>

<p>Many of these dependencies make sense: React itself has the biggest impact at
&gt;100KB, fontawesome icons weigh in at &gt;30KB (both in blue).</p>

<p>But what‚Äôs <a href="https://www.npmjs.com/package/elliptic">elliptic</a> (in red)? A library for
<a href="https://en.wikipedia.org/wiki/Elliptic-curve_cryptography">elliptic-curve cryptography</a>?
I certainly have no need for that in my simple SPA to access a REST API.</p>

<p>It must have snuck in as a transitive runtime dependency of one of the packages
I <em>did</em> install.</p>

<p>The one thing that came to mind was that one library that I only used once, to
randomly generate a unique identifier. Could that be it?</p>

<p><img src="https://blog.prat.ch/assets/img/2020-11-10-sme-after.png" alt="Source Map Explorer output after (more than 400KB)"></p>

<p>Gotcha!</p>

<p>The bundle shrunk from 747KB to 448KB, by nearly a whopping 300KB.</p>

<h2 id="the-fix">The fix</h2>

<p>The fix is obvious:</p>

<p>Don‚Äôt try and be clever.</p>

<p>Implementing a simple version of the feature I <em>actually</em> needed took only
<a href="https://github.com/ThePadawan/beevenue-ui/commit/ef94e025adc5e3223ab63dc69b7885d2016986c3">four lines of code</a>:</p>

<div><div><pre><code><span>const</span> <span>getRandomInt</span> <span>=</span> <span>(</span><span>max</span><span>:</span> <span>number</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>return</span> <span>Math</span><span>.</span><span>floor</span><span>(</span><span>Math</span><span>.</span><span>random</span><span>()</span> <span>*</span> <span>Math</span><span>.</span><span>floor</span><span>(</span><span>max</span><span>));</span>
<span>};</span>

<span>const</span> <span>id</span> <span>=</span> <span>`</span><span>notification-</span><span>${</span><span>getRandomInt</span><span>(</span><span>1024</span> <span>*</span> <span>1024</span><span>)}</span><span>`</span><span>;</span>
</code></pre></div></div>

<p>This obviously is only pseudorandom, as opposed to <code>randomstring</code>‚Äôs possibly
cryptographically random - but that‚Äôs not what I needed in the first place.</p>

<p>And that‚Äôs certainly not what I would pay 300KB of bundle size for.</p>

  </div></div>]]>
            </description>
            <link>https://blog.prat.ch/2020/11/10/randomstring-bundle-size</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046036</guid>
            <pubDate>Tue, 10 Nov 2020 14:07:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hands on with: MeiliSearch ‚Äì A next generation search engine for modern web]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25045927">thread link</a>) | @piterrro
<br/>
November 10, 2020 | https://codefibershq.com/blog/hands-on-meilisearch-a-next-generation-search-engine-for-modern-web | <a href="https://web.archive.org/web/*/https://codefibershq.com/blog/hands-on-meilisearch-a-next-generation-search-engine-for-modern-web">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        <div>
                            <p><strong>In this post, I‚Äôm gonna review the Meilisearch repository which describes itself as a ‚ÄúLightning Fast, Ultra Relevant and Typo-Tolerant Search Engine‚Äù. There were couple of things that caught my eye with this project...</strong></p>

<h3>Quick intro: What is the ‚ÄúHands on with X‚Äù series?</h3>
<p>This is a series of blog posts in which we focus on open source technologies encountered in the course of our research for new development projects or while browsing latest news from a development environment which is close to our minds in our day to day work. One day I realized that my Github account is full of starred repositories containing interesting tools, databases, libraries and other cutting-edge technologies that seem to be very interesting for me. I was alway staring at them on Github for later review but never got a chance to really use them. That‚Äôs when the idea for this blog post series was born. I was having a feeling that a lot of users are in the same situation, they starred a repository because they might have used it in the future and was curious how it works, but never got a chance to do that. So for the next couple of posts I‚Äôm gonna focus on reviewing and using interesting and popular repositories I‚Äôve found on Github for the past couple of years.
</p>



<h3 id="h">Table of contents</h3>
<ul>
    <li><a href="#h2"> - Motivations for reviewing Meilisearch</a></li>
    <li><a href="#h3"> - Github repository and Readme</a></li>
    <li><a href="#h4"> - The data set for testing purposes</a></li>
    <li><a href="#h5"> - Kicking it off - Download binary and start the server</a></li>
    <li><a href="#h6"> - Prepare the data to be ingested</a></li>
    <li><a href="#h7"> - Indexing first collection</a></li>
    <li><a href="#h8"> - Indexing speed</a></li>
    <li><a href="#h9"> - Making search queries</a></li>
    <li><a href="#h10"> - Frontend integration</a></li>
    <li><a href="#h11"> - Would I recommend MeiliSearch?</a></li>
    <li><a href="#h12"> - Conclusions</a></li>
</ul>
<hr>

<h3 id="h2">Motivations for reviewing Meilisearch</h3>
<p><strong>Its search engine</strong>. I‚Äôm not a heavy user of search engines in my day-to-day projects. I know Elasticsearch and Spinx are among the most popular ones. I also have some experience with TSvector in Postgresql which allowed to create simple ‚Äúsearch engine features‚Äù within Postgresql database. But that's it, so I‚Äôm curious how that new Meilisearch project accommodates itself in this long-inhabited environment.</p>

<p><strong>Its written in Rust</strong> which is interesting so that Rust is very close to bare metal. It‚Äôs also a new technology and most of the search engines we have are written in C++ or Java. I feel that a new perspective from a totally new language might be worth a try.</p>

<p>Since it‚Äôs Rust, it compiles to a single binary and it's portable, so that means no more long hours of building a project which would make deploying along with any other project a breeze.</p>

<p><strong>It claims to have ‚Äúsearch as-you-type experience‚Äù</strong> which means that it is able to return results so fast that it returns results for EVERY keystroke. Interesting given the fact that the Readme file doesn‚Äôt contain information about reference dataset authors used to support that claim. Of course it is not possible for a dataset of any size and for smaller data sets it's trivial, so I wanted to learn how long Meilisearch is able to support that claim, given that I‚Äôll be using a bigger than usual dataset.
</p>

<h3 id="h3">Github repository and Readme</h3>
<p>The url address of Github repository is <a href="https://github.com/meilisearch/MeiliSearch">https://github.com/meilisearch/MeiliSearch</a>. As of the beggining of the September 2020, the repository has over 9k stars and over 30 contributors. The commits are pushed more or less weekly. The tool seem to have small community around it so its definitely not a dead project. In addition Meili raised 1,5M euros in their first funding round (<a href="https://blog.meilisearch.com/meili-fundraise/">https://blog.meilisearch.com/meili-fundraise/</a>) which shows that they are determined to develop the product and compete with big players, which is what they also claim on their website, they want to be an alternative to search engine APIs like Algolia.</p>
<p>What is more important for us - developers is the documentation and its clarity. The readme page is short and compact, with only relevant information which is a plus, because they also have a full blown documentation hosted as a separate website at <a href="https://docs.meilisearch.com/">https://docs.meilisearch.com/</a>.</p>
<p>The readme contains all of the basic informations need to start using the engine which means it has recipes for building from source as well as downloading a compiled binary or using a docker image. In addition there are examples how to index a first collection and make queries. All that is compact enough so that following it step by step should take no more than 10-15 minutes to complete.</p>
<p>The documentation contains description of the main concepts that were used when building the engine as well as advanced guides starting from installation and configuration up to the most advanced features of the engine. It is well written but after reading it I was left with a feeling that it is still immature project with a long road ahead of it.</p>




<h3 id="h4">The data set for testing purposes</h3>
<p>Of course testing the search engine with a small data set doesn‚Äôt make much sense since today‚Äôs hardware capabilities allows to easily keep in memory datasets weighing a couple hundreds of megabytes. So I took a different approach, I decided to find a data set that consists mostly of text and would be useful in real world examples. My choice went to Kaggle dataset: Cornell University arXiv index (<a href="https://www.kaggle.com/Cornell-University/arxiv">https://www.kaggle.com/Cornell-University/</a>). As per Wikipedia, arXiv is an open-access repository of electronic preprints (known as e-prints) approved for posting after moderation, but not full peer review. It consists of scientific papers in the fields of mathematics, physics, astronomy, electrical engineering, computer science, quantitative biology, statistics, mathematical finance and economics, which can be accessed online. The dataset hosted on Kaggle is just a friction of the whole arXiv and it contains an index of publications with information like: author, title, category and short excerpt. The dataset format is JSON and weights about 2.7gb all you need to do to download it and unzip.</p>

<h3 id="h5">Kicking it off - Download binary and start the server</h3>
<p>Now that I have a data set we can start testing MeiliSearch. The installation is pretty straightforward, I used a ready to use bash script (of course I reviewed the script in the first place as I know these bash installations are basically an attack vector).</p>
<pre><code>$ curl -L https://install.meilisearch.com | sh
$ ./meilisearch
Server is listening on: http://127.0.0.1:7700</code></pre>
<p>That was very smooth, it went well without any problems, point for Meilisearch.</p>


<h3 id="h6">Prepare the data to be ingested</h3>
<p>In order to search the data we have to create an index first (think of it as a database table) and ingest the data to it in a Meilisearch instance. For index creation I used:</p>
<pre><code>curl -i -X POST 'http://127.0.0.1:7700/indexes' --data '{ "name": "arxiv", "uid": "arxiv" }'</code></pre>
<p>After the command completed I tried to feed the index with raw data, but there are couple of constraints to the format. First thing is that the file must be less than 10 megabytes and second is that the JSON should actually be a JSON array where each element is a separate document identified by unique id field. I tried to use good old split, awk, sed unix tools in the first place, but after some time I gave up and switched to Node.js. </p>
<p>You can check the whole script below. Its not very sophisticated but it does the job.
</p>




<h3 id="h7">Indexing first collection</h3>
<p>The script above does basically two things. It first reads the file contents line by line and builds a payload containing about 1000 documents. It then sends the payload to MeiliSearch, in return we get an ‚ÄúupdateId‚Äù which is an identifier that we can later use to ask our MeiliSearch instance whether the indexation operation for that batch finished. If the indexation batch is finished, then we can resume the file consumption, assemble another data batch and send it to MeiliSearch. And here comes the first surprise, as the documentation doesn‚Äôt clearly lay that out and I had to figure it (how it works). It seems that MeiliSearch has an internal queue that is able to accept any number of data payloads for ingesting and it processes this queue at its own pace. Makes sense to me, but as it turned out later, it‚Äôs not so lovely.
</p>

<h3 id="h8">Indexing speed</h3>
<p>Buffering incoming data has a lot of advantages, having that buffer you are able to not overwhelm your processing units with work, while still maintaining the work pace. In addition you can scale your work capacity by adding more workers, that‚Äôs when the buffers shine, because you can quickly consume additional data by throwing more resources at it. Unfortunately MeiliSearch indexing queue is processed only by one worker even on a multi-core CPU. That means, you can throw a lot of data for indexing at it but it will basically take the same amount of time, if you would do it one payload at a time. </p>
<p>It actually gets worse as the indexation time increases as your data set size increases. That is not a bad thing as long as the growth is linear and it's not too significant. Unfortunately again with MeiliSearch it's exactly the opposite. The indexation time grows exponentially and even with small data sets it gets to a point where indexing 3gb of data would take unknown time (from my calculations). I was having high hopes downloading a 2.7gb data set and trying to index it with MeiliSearch, unfortunately I was only able to index 115mb (yes, megabytes) which is about 80 000 lines from the file. Just to give you the context, the first 20 000 items were indexed in less than 1 minute, another 20 000 items took about 4 minutes. Reaching 88 000 items took 10 minutes and arXiv data set has almost 1 800 000 items. </p>

<p>That being said, the indexation time is too long and I didn‚Äôt want to spend the next few days waiting for it to finish. I did spend some more time trying to find how to speed up the indexing process, I looked through the documentation and Issues on Github, unfortunately I was not the only one that had that problem. This issue: <a href="https://github.com/meilisearch/MeiliSearch/issues/876">https://github.com/meilisearch/MeiliSearch/issues/876</a> highlights it. Until the indexing process can be paralleled at least in ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://codefibershq.com/blog/hands-on-meilisearch-a-next-generation-search-engine-for-modern-web">https://codefibershq.com/blog/hands-on-meilisearch-a-next-generation-search-engine-for-modern-web</a></em></p>]]>
            </description>
            <link>https://codefibershq.com/blog/hands-on-meilisearch-a-next-generation-search-engine-for-modern-web</link>
            <guid isPermaLink="false">hacker-news-small-sites-25045927</guid>
            <pubDate>Tue, 10 Nov 2020 13:57:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kraftwerk song performed with 5 Arduinos]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25045818">thread link</a>) | @alanjay
<br/>
November 10, 2020 | https://marquisdegeek.com/music_kraftwerk01 | <a href="https://web.archive.org/web/*/https://marquisdegeek.com/music_kraftwerk01">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://marquisdegeek.com/music_kraftwerk01</link>
            <guid isPermaLink="false">hacker-news-small-sites-25045818</guid>
            <pubDate>Tue, 10 Nov 2020 13:46:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HTML Forms: How (and Why) to Prevent Double Form Submissions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25045789">thread link</a>) | @roosgit
<br/>
November 10, 2020 | https://www.bram.us/2020/11/04/preventing-double-form-submissions/ | <a href="https://web.archive.org/web/*/https://www.bram.us/2020/11/04/preventing-double-form-submissions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>When double clicking a submit button your form will be sent twice. Using JavaScript you can prevent this from happening, but wouldn‚Äôt it be nice if this behavior could be tweaked by use of an attribute on the <code>&lt;form&gt;</code>? If you think so, feel free to <a href="https://github.com/whatwg/html/issues/5312">give this issue a thumbs up</a>.</p>
<p><img loading="lazy" src="https://www.bram.us/wordpress/wp-content/uploads/2020/11/double-form-submit.gif" alt="" width="496" height="280" data-old-src="https://www.bram.us/wordpress/wp-content/plugins/native-lazyload/assets/images/placeholder.svg"></p>
<p>Today Sebastian wondered:</p>
<blockquote>
<p lang="en" dir="ltr">Disabling a form submit button while submitting: yay or nay?</p>
<p>(I thought I saw some research that discourages it, but can't remember where or why)</p>
<p>‚Äî Sebastian De Deyne (@sebdedeyne) <a href="https://twitter.com/sebdedeyne/status/1323921783729377280?ref_src=twsrc%5Etfw">November 4, 2020</a></p></blockquote>

<p>I quickly chimed in saying that I do tend to lock up forms when submitting them. Let me explain why ‚Ä¶</p>
<p>~</p>
<p>I started locking up submitted forms as users of the apps I‚Äôm building reported that sometimes the actions they had taken ‚Äî such as adding an entry ‚Äî were performed twice. I took me some time to figure out what exactly was going on, but eventually I found out <b>this was because they were double clicking the submit button of the forms</b>. As they double clicked the button, the form got sent over twice. By locking up forms after their first submission, all successive submissions ‚Äî such as those triggered by that second click of a double click ‚Äî are ignored.</p>
<p>~</p>
<p>To prevent these extra form submissions from being made I don‚Äôt hijack the form with Ajax nor do I perform any other complicated things. I let the inner workings of the web and forms in the browser be: when pressing the submit button the browser will still collect all form data, build a new HTTP request, and execute that request.</p>
<p>What I simply do is extend the form‚Äôs capabilities by adding a flag ‚Äî by means of a CSS class ‚Äî onto the form to indicate whether it‚Äôs being submitted or not. I can then use this flag‚Äôs presence to deny any successive submissions, and also hook some CSS styles on. ‚Äî <em>Progressive Enhancement, Yay! üéâ</em></p>
<p>The code looks as follows:</p>
<pre><code> // Prevent Double Submits
document.querySelectorAll('form').forEach(form =&gt; {
	form.addEventListener('submit', (e) =&gt; {
		// Prevent if already submitting
		if (form.classList.contains('is-submitting')) {
			e.preventDefault();
		}
		
		// Add class to hook our visual indicator on
		form.classList.add('is-submitting');
	});
});</code></pre>
<p>üí° Although the problem initially was a double click problem, we don‚Äôt listen for any clicks on the submit button but listen for the form‚Äôs <code>submit</code> event. This way our code not only works when clicking any of the submit buttons, but also when pressing enter to submit.</p>
<p>With that <code>.is-submitting</code> class in place, we can then attach some extra CSS onto the form to give the user visual feedback. Here‚Äôs a few examples:</p>
<p data-height="265" data-theme-id="light" data-default-tab="result" data-user="bramus" data-slug-hash="JjKZVPW" data-pen-title="Prevent Form Double Submits">
<span>See the Pen <a href="https://codepen.io/bramus/pen/JjKZVPW"><br>
Prevent Form Double Submits</a> by Bramus (<a href="https://codepen.io/bramus">@bramus</a>)<br>
on <a href="https://codepen.io/">CodePen</a>.</span>
</p>

<p data-height="265" data-theme-id="light" data-default-tab="result" data-user="bramus" data-slug-hash="NWrzmrV" data-pen-title="Prevent Form Double Submits (Alternative version)">
<span>See the Pen <a href="https://codepen.io/bramus/pen/NWrzmrV"><br>
Prevent Form Double Submits (Alternative version)</a> by Bramus (<a href="https://codepen.io/bramus">@bramus</a>)<br>
on <a href="https://codepen.io/">CodePen</a>.</span>
</p>

<p>Note that this solution might not cover 100% of all possible scenarios, as it doesn‚Äôt take failing networks and other things that might go wrong into account. However, as I‚Äôm relying on the basic mechanisms of the web I think I can also rely on the browser to show that typical ‚ÄúConfirm Form Resubmission‚Äù interstitial should a timeout occur. Additionally, if need be, one could always unlock the form after a fixed amount of time. That way the user will be able to re-submit it again.</p>
<p>~</p>
<p>Dealing with double form submissions isn‚Äôt a new issue at all. You‚Äôll find quite some results when running a few queries through Google ‚Äî something I only found out after stumbling over the issue myself.</p>
<p>Back in 2015 (!) Mattias Geniar <a href="https://ma.ttias.be/double-clicking-on-the-web/">also pondered about this</a>, after being pulled into the subject from a sysadmin view. Now, when even sysadmins are talking about an HTML/UX issue you know there‚Äôs something going on. This made me wonder why browsers behaved like that and how we could solve it:</p>
<blockquote>
<p lang="en" dir="ltr">ü§î Why is it that browsers don't prevent double form submissions by default? Some users (mistakingly) double click on submit buttons.</p>
<p>üí° An attribute on &lt;form&gt; to tweak this behavior ‚Äì instead of having to rely on JavaScript ‚Äì would come in handy ‚Ä¶</p>
<p>/cc <a href="https://twitter.com/WHATWG?ref_src=twsrc%5Etfw">@WHATWG</a> <a href="https://twitter.com/w3c?ref_src=twsrc%5Etfw">@w3c</a></p>
<p>‚Äî Bramus! (@bramus) <a href="https://twitter.com/bramus/status/1227925285041065986?ref_src=twsrc%5Etfw">February 13, 2020</a></p></blockquote>

<p>As a result I decided to open <a href="https://github.com/whatwg/html/issues/5312">an issue at the WHATWG HTML Standard repo</a>, suggesting for a way to fix this at spec level:</p>
<blockquote>
<p>An attribute on <code>&lt;form&gt;</code> to tweak this behavior ‚Äì instead of having to rely on JavaScript ‚Äì would come in handy and form a nice addition to the spec.</p>
<p>I see two options to go forward:</p>
<ol>
<li>Browsers/the standard keeps the current behavior and allow multiple submits. Developers must opt-in to prevent multiple submissions using a <code>preventmultiplesubmits</code> attribute.</li>
<li>Browsers/the standard adjust the current behavior to only submit forms once. Developers must opt-in to allow multiple submissions using a <code>allowmultiplesubmits</code> attribute.</li>
</ol>
</blockquote>
<p>Initial response on the issue was very low, and it looks like this isn‚Äôt that big of a priority.</p>
<p>Back then I was more in favor of the second solution, but now I‚Äôm quite undecided as changing the default behavior ‚Äî which has been around for ages ‚Äî is quite tricky.</p>
<p>~</p>
<p>Another way that this issue could be fixed is at the browser level: if they were to treat double clicks on form submit buttons as single clicks, then the double click problem ‚Äî but not the double submit problem ‚Äî could also be taken care of.</p>
<p>To then attach styles to forms being submitted a CSS Pseudo Class <code>:submitting</code> would come in handy. Come to think of it, this Pseudo Class would be a quite nice addition to CSS in itself, no matter whether this double click issue gets solved or not.</p>
<p>~</p>
<p>Winging back to <a href="https://github.com/whatwg/html/issues/5312">the addition to the HTML spec I suggested</a>: If you do think it could be something the HTML spec could benefit from, feel free to add a thumbs up to the issue to indicate that you want this, or add an extra comment to it if you have more input on the subject.</p>
<div>
<p><b>Did this help you out? Like what you see?<br>Thank me with a coffee.</b></p><p>I don't do this for profit but a small one-time donation would always put a smile on my face. Thanks!</p>
<p><a href="https://www.paypal.me/bramus/3EUR">‚òïÔ∏è Buy me a Coffee <em>(‚Ç¨3)</em></a></p>
</div>
</div></div>]]>
            </description>
            <link>https://www.bram.us/2020/11/04/preventing-double-form-submissions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25045789</guid>
            <pubDate>Tue, 10 Nov 2020 13:43:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[cyclog ‚Äì safely log standard input to status files and log directories]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25045778">thread link</a>) | @oftenwrong
<br/>
November 10, 2020 | https://jdebp.eu/Softwares/nosh/guide/cyclog.html | <a href="https://web.archive.org/web/*/https://jdebp.eu/Softwares/nosh/guide/cyclog.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div title="cyclog"><div><h2>Name</h2><p>cyclog ‚Äî safely log standard input to status files and log directories</p></div><div title="Synopsis"><h2>Synopsis</h2><p><code>cyclog</code>  [--max-file-size <em><code>max-file-size</code></em>] [--max-total-size <em><code>max-total-size</code></em>] [--margin <em><code>margin</code></em>] {<em><code>directories</code></em>...}</p></div><div title="Description"><h2>Description</h2><p>
<span><strong>cyclog</strong></span> is a simple logging utility that logs everything that it receives on its standard input to a set of log file directories named as its command arguments.
It automatically timestamps logs, produces time-sortable log file names, rotates log files, and caps log directory sizes.
</p><p>
At startup, <span><strong>cyclog</strong></span> attempts to open all of the <em><code>directories</code></em>.
If they are directories (or symbolic links to the same), it treats them as log directories.
Otherwise, if they don't exist or are other types of file such as regular files, device files, or FIFOs, it aborts startup without reading from standard input.
</p><p>
It keeps a file descriptor open to each log directory for its lifetime, and accesses files relative to that open file descriptor.
Log directories can thus be renamed as it is running, and it will continue to use the original directory, wherever it is renamed to.
</p><div title="Log directory"><h3>Log directory</h3><p>
A log directory is compatible with the log directories employed by daemontools' and daemontools-encore's <span><span>multilog</span>(1)</span>, s6's <span><span>s6-log</span>(1)</span>, and runit's <span><span>svlog</span>(1)</span>.
It contains:
</p><div><ul type="disc"><li><p>
a <code>lock</code> file (compatible with <span><span>setlock</span>(1)</span>) that prevents two logging processes from sharing an active log directory;
</p></li><li><p>
a set of old log files, named as <code>@</code> followed by a TAI64N timestamp in external form (16 hexadecimal digits of seconds and 8 hexadecimal digits of nanoseconds) and either <code>.s</code> (safely written to disc) or <code>.u</code> (aborted whilst writing to disc and possibly incomplete);
and
</p></li><li><p>
a <code>current</code> file where incoming log data are currently being appended.
</p></li></ul></div><p>
An active <code>current</code> file, or an old log file or a <code>current</code> file that was not written to disc by <span><strong>cyclog</strong></span> properly shutting down, has permissions 0644.
A <code>current</code> file or an old log file where <span><strong>cyclog</strong></span> properly shut down has permissions 0744.
(See the <a href="#COMPATIBILITY" title="Compatibility">Compatibility</a> section.)
</p><p>
<span><strong>cyclog</strong></span> shuts down when either it sees EOF on its standard input, or it receives one of the "good" termination signals (<code>SIGTERM</code>, <code>SIGPIPE</code>, <code>SIGINT</code>, or <code>SIGHUP</code>).
At shut down, <span><strong>cyclog</strong></span> writes all pending data that it has already read from standard input, flushes <code>current</code> to disc, and changes <code>current</code>'s permissions.
At start up, it checks <code>current</code>'s permissions, creating the file with permissions 0744 if it does not already exist.
If they indicate proper shutdown, as they will also do if the file was created because it did not exist, it carries on.
If they indicate that the file was not properly written at shutdown, it performs <a href="#ROTATION" title="Automatic log rotation">automatic log rotation</a> to prevent appending to a potentially corrupt file (that may be sparse or contain ranges of zeroed blocks).
</p></div><div title="Reliable piped input"><h3>Reliable piped input</h3><p>
In the normal case, the standard input of <span><strong>cyclog</strong></span> will be a pipe; and both ends of the the pipe will be open in a long-lived supervisor process such as <span><span>service-manager</span>(1)</span>.
<span><strong>cyclog</strong></span>, as aforementioned, ensures that it writes all data read from its standard input, even if it is terminated by a (good) signal.
</p><p>
Thus no log data are lost, even if <span><strong>cyclog</strong></span> is shut down and restarted.
</p></div><div title="Automatic log rotation"><h3>Automatic log rotation</h3><p>
<span><strong>cyclog</strong></span> performs automatic log rotation when it writes a linefeed within <em><code>margin</code></em> bytes of the maximum size (<em><code>max-file-size</code></em>) of the <code>current</code> file, when it is about to exceed that size, when it receives a <code>SIGALRM</code>, or when it finds an improperly written to disc <code>current</code> file at startup.  
When recovering from an improperly finalized <code>current</code>, it simply renames it to a timestamped <code>.u</code> name.
Otherwise, it renames it to a timestamped <code>.u</code> name, flushes it to disc, changes its permissions, and then renames it to a timestamped <code>.s</code> name.
In both cases, it then creates a new <code>current</code> file.
The TAI64N timestamp of an old log file is the timestamp of when <span><strong>cyclog</strong></span> rotated <code>current</code> to that file.
</p><p>
At log rotation, and also at startup, it checks to ensure that the total size of all log files in the directory does not exceed the maximum total size (<em><code>max-total-size</code></em>).
(It only totals the sizes of <code>current</code> and old log files.  
Other files, not managed or created by <span><strong>cyclog</strong></span>, are ignored.)
If the total exceeds that maximum, it deletes each old log file with the numerically lowest name until either the total is less than the maximum or there is only the <code>current</code> file left.
</p><p>
Thus the maximum size of all log files at any time is <em><code>max-total-size</code></em> (the total size after the last rotation) plus <em><code>max-file-size</code></em> (the data written since that rotation).
The default <em><code>max-file-size</code></em> is 16MiB and the default <em><code>max-total-size</code></em> is 1GiB.
</p><p>
<span><strong>cyclog</strong></span> totals file sizes rather than space allocated on disc.
The amount of space allocated to all files may be, depending from the filesystem type and the maxima chosen, higher or lower than the space usage calculated by <span><strong>cyclog</strong></span>.
</p></div><div title="Timestamps"><h3>Timestamps</h3><p>
<span><strong>cyclog</strong></span> writes a timestamp at the beginning of every line written to <code>current</code>, which is the time when it processes the beginning of a line.  
This is slightly after it has read the beginning of that line.
The timestamp is in TAI64N external form (16 hexadecimal digits of seconds and 8 hexadecimal digits of nanoseconds), which can be converted to human-readable form using <span><span>tai64nlocal</span>(1)</span>.
</p><p>
<span><strong>cyclog</strong></span> uses the <code>CLOCK_REALTIME</code> clock of the <span><span>clock_gettime</span>(2)</span> system call.
On many systems this has nanosecond resolution.
</p><p>
<span><strong>cyclog</strong></span> attempts to generate real TAI timestamps.
On a Linux system where it detects an Olson "right" timezone currently in use, it knows that the system clock is TAI seconds since the Epoch and performs a simple conversion.
On other Linux systems, and on BSDs, it assumes that the system clock is UTC seconds since the Epoch and attempts to correct for (known) UTC leap seconds in order to determine TAI.
</p></div></div><div title="Compatibility"><h2>Compatibility</h2><p>
A <span><span>cyclog</span>(1)</span> utility was part of daemontools version 0.53.
This utility is a workalike, with some minor additions to automatic log rotation and changes to log directory semantics.
</p><p>
daemontools later replaced <span><span>cyclog</span>(1)</span> with <span><span>multilog</span>(1)</span>, which treats its command arguments as a script and has the abilities to do pattern matching and run external commands.
<span><strong>cyclog</strong></span> is intended for the commonest, simple, use cases of logging services where there is just one plain logging directory with no bells and whistles.
As such, it does not implement a script syntax, does not have pattern matching, and does not invoke other programs at all.
</p><p>
The daemontools version 0.53 <span><span>cyclog</span>(1)</span> used permissions 0644 and 0444 to flag files that had not been written to disc.
<span><strong>cyclog</strong></span> adopts the convention employed by the later <span><span>multilog</span>(1)</span>, and thence <span><span>s6-log</span>(1)</span> and <span><span>svlog</span>(1)</span>.
This convention changed to using the owner execute permission bit rather than the owner write permission bit as the flag.
<span><strong>cyclog</strong></span> sets and clears the execution bit as appropriate for interoperability with those tools, and <a href="#LOGDIRECTORY" title="Log directory">uses it itself for the same purpose</a>.
<span><span>multilog</span>(1)</span> altered the convention in order to cope with scenarios where it would end up trying to open a read-only file for writing.
</p><p>
The daemontools version 0.53 <span><span>cyclog</span>(1)</span> used the TAI64 timestamp of when a log file was started as its timestamp.
Again <span><strong>cyclog</strong></span> adopts the convention employed by later tools.
</p><p>
daemontools' and daemontools-encore's <span><span>multilog</span>(1)</span> uses a timer with only microsecond resolution, and for the same events will thus produce different timestamps to <span><strong>cyclog</strong></span>.
</p><p>
See <a href="https://jdebp.eu/Softwares/nosh/guide/timestamps.html" target="_top">the timestamps section of the <em>nosh Guide</em></a> for detailed information on the differences from daemontools, daemontools-encore, and other toolsets in how <span><strong>cyclog</strong></span> handles TAI.
</p></div></div></div>]]>
            </description>
            <link>https://jdebp.eu/Softwares/nosh/guide/cyclog.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25045778</guid>
            <pubDate>Tue, 10 Nov 2020 13:41:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sven Yrvind on provisioning for a sea voyage]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25045749">thread link</a>) | @oftenwrong
<br/>
November 10, 2020 | https://www.yrvind.com/provisioning/ | <a href="https://web.archive.org/web/*/https://www.yrvind.com/provisioning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div id="content">

<div>
	<div id="primary">
		<main id="main" role="main">

			
<article id="post-7486">
		<!-- .entry-header -->

	
	<div>
		<p>I will eat twice a day, breakfast and lunch four hours later.<br>
Me, I am afraid of insulin. Alzheimer is diabetes type 3. After four hours of no eating there be no insulin in the blood and my mitocondrias switches over to use stored fat for fuel. That‚Äôs the food strategy.<br>
Some people say, ‚ÄúThats not much of a variation‚Äù<br>
I say, ‚ÄúCows only eat grass and wolfs only eat meat‚Äù<br>
Modern society is so boring and there is so much food that we have to be stimulated by spices and chefs and different foods to eat. At sea in a small boat its different. Life itself out there is so interesting that I do not need stimulants.<br>
My breakfast consists of one can of sardines, one slice of dense dark rye bread and muesli.<br>
One meal of muesli contains:<br>
Almond flour 25 grams<br>
Dried grinded blueberries 15 grams<br>
Whole milk powder 30 grams<br>
Oats flakes 60 grams<br>
Raisins 20 grams<br>
Walnuts 20 grams<br>
Total 170 grams of muesli for each meal<br>
My lunch is the same as breakfast but no sardines.<br>
I hope to make the voyage in about 300 days, but 2018 may turn out to be a bad year weather vise. To have a margin I will load Exlex with food for 400 days. The weight of that food is 240 kilos. It breaks down into:<br>
136 kilos muesli, 64 kilos sardines and 40 kilos bread.<br>
My water capacity is 56 liters. There are two rain catchers. Hopefully there will be some rain otherwise I have to beg.<br>
A big job is to vacuum pack the muesli and the bread and store it safely in Exlex.<br>
I will also have plenty of multivitamin/mineral supplements.<br>
I look forward to be out on the deep, wet, endless, eternal ocean eating muesli and sardines.<br>
To be continued‚Ä¶<br>
Regards Yrvind.</p>
	</div><!-- .entry-content -->

	 <!-- .entry-footer -->
</article><!-- #post-## -->

		</main><!-- #main -->
	</div><!-- #primary -->
	
<!-- #secondary -->
</div><!-- .wrap -->


		</div><!-- #content -->

		<!-- #colophon -->
	</div></div>]]>
            </description>
            <link>https://www.yrvind.com/provisioning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25045749</guid>
            <pubDate>Tue, 10 Nov 2020 13:38:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating a Web Performance Team]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25045594">thread link</a>) | @mostlystatic
<br/>
November 10, 2020 | https://www.debugbear.com/blog/web-performance-team | <a href="https://web.archive.org/web/*/https://www.debugbear.com/blog/web-performance-team">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <div>
    <div>
    
      
      

      

      <div>
        
        

        <p>Creating a web performance team is essential for many online businesses. Improving web performance for the long term requires a culture that understands the value of performance and treats it as a priority.</p>
<p>Setting up a team comes with a variety of challenges, many of them depending on your company and its culture. This post guides you through some of these difficulties.</p>
<h2 id="get-support-from-someone-higher-up-in-your-organization">Get support from someone higher up in your organization</h2>
<p>Creating a performance team is a lot of work. There are many things to prepare before the team starts making its first performance optimizations.</p>
<p>Starting is much easier if you have someone higher up in your organization supporting your efforts. Ideally, this is someone in management with budgetary responsibility. But if that's not the case, your team lead can also take on this role.</p>
<p>This person pushes web performance inside your company. They could promote your successes, organize budget, or help you to handle internal politics. They should understand the importance of performance and invest in your team.</p>
<p>To find someone, you need to promote your initiative. For example, you can speak at internal or public conferences. Company events like hackathons are a good way to start working on performance topics and form a group of co-workers that's interested in web performance.</p>
<h2 id="speaking-the-right-language">Speaking the right language</h2>
<p>Website performance means different things to different people. For a front-end developer, performance means site speed or load time. For a marketer, website performance relates to engagement, conversion rates, or page views. SEO experts talk about the ranking of key pages.</p>
<p>Managers look at the business value the website generates.</p>
<p>Planning for the long term requires these people to understand why web performance matters. They need to know the correlation between speed and measurable outcomes. You need to speak their language to convince these different disciplines.</p>
<p>You can find many performance case-studies on <a href="https://wpostats.com/">WPO stats</a> (WPO stands for Web Performance Optimization). These case studies show how performance impacts business results. You can filter the case studies by category, to find ones discussing metrics that are relevant to the person in your organization you're targeting.</p>
<h2 id="building-the-team">Building the team</h2>
<p>No matter how big your company, start by finding like-minded people. People that are passionate about web performance and who recognize its value.</p>
<p>Use your company meetings, hackathons, or any other events that your company already organizes. Pick a web performance topic and start forming a team around it. The advantage of finding like-minded people is that you don't need to convince them of the value web performance brings.</p>
<p>A good size to start with is 3 to 5 team members. Not all of them need to be performance engineers. Depending on your company's tech stack, the team could consist of many disciplines, including front-end developers, back-end developers, data analysts, marketers, and managers. A cross-functional or mixed performance team approach is a good option, but usually the team will lean toward technical roles.</p>
<p>Each development team could have a performance ambassador who's also a member of the performance team.</p>
<p><img src="https://www.debugbear.com/public/blog/web-performance-team/team-members.png" alt="Performance team and performance ambassadors"></p>
<h2 id="setting-up-a-performance-plan">Setting up a performance plan</h2>
<p>After you've found a group of people who care about performance, start creating a performance plan that captures what your team will do.</p>
<p>It describes <a href="https://www.debugbear.com/docs/web-performance-metrics">performance metrics</a>, monitoring, infrastructure, and accountability for performance issues. Additionally, it defines the tools you use and how you'll educate and incentivize the people in your organization.</p>
<h3 id="goals-and-engagement">Goals and Engagement</h3>
<p>To decide what goals to put into your performance plan, you need to identify what's most important for your users. What keeps them engaging with your website?</p>
<p>The resulting goal might be time on site or custom metrics like clicking on a link. You need to start measuring these metrics as they will form your baseline data for any changes you make in the future.</p>
<h3 id="mapping-performance-metrics-to-business-and-or-marketing-metrics">Mapping performance metrics to business and or marketing metrics</h3>
<p>Once you've gathered enough data, make sure that your team understands each metric. This knowledge is essential, as it forms the basis of all your future work.</p>
<p>In the next step, tie your performance metrics to business or marketing outcomes. For example, you could take the time it takes until the product page is interactive and compare that to the number of product purchases.</p>
<p><img src="https://www.debugbear.com/public/blog/web-performance-team/page-views-vs-bounce-rate.png" alt="Page views versus bounce rate"></p>
<p>Mapping business or marketing metrics to performance metrics is necessary for any performance team. The results will be the most potent arguments to push your work within the organization. And the results will help you estimate the impact of any optimizations you plan to make.</p>
<h3 id="accountability-education-and-empowerment">Accountability, education, and empowerment</h3>
<p>Accountability is a core part of your performance plan. One goal of the performance team is to educate, incentivize, and empower people to care about performance.</p>
<p>Depending on the size of your company, you can't be accountable for every issue. You should teach people how they can care about performance. They should know how to use your performance tools.</p>
<p>Everybody who touches your website (developer, content manager, marketing consultant) is responsible for its performance. Make people accountable by giving them ownership, and help them identify performance issues on their own.</p>
<p><a href="https://www.debugbear.com/docs/performance-budgets">Performance budgets</a> are a reliable way to monitor a page. You can specify a threshold for a metric, and you'll need to take action when this is exceeded. How you define your budget depends on your goals and user engagement metrics. For example, you could pick a certain Lighthouse score, or set a threshold for the download size of your images.</p>
<p>A quick tip for performance budgets: you can motivate your employees by choosing the status quo as your first performance budget. Whenever you've optimized your website, reduce the budget to the new values.</p>
<p><img src="https://www.debugbear.com/public/blog/web-performance-team/performance-budget.png" alt="Example of a JavaScript size performance budget chart"></p>
<p>Suppose your company is too big to educate everyone about web performance. Your performance team will be busy and you don't don't want them to be gatekeepers who are blocking the work of other teams.</p>
<p>In that case, you can create performance ambassadors inside each team who can take charge without being reliant on the performance team.</p>
<p><img src="https://www.debugbear.com/public/blog/web-performance-team/performance-team-relationships.png" alt="Performance ambassadors in each team together form a performance team"></p>
<h3 id="use-performance-tools-and-infrastructure">Use performance tools and infrastructure</h3>
<p>Web performance tools vary a lot. Some tools collect real user data, while others test site performance <a href="https://www.debugbear.com/blog/web-performance-metrics-lab-vs-rum">in a lab environment</a>. Some are very good at monitoring your key pages, while others give you a better overview of your entire site. Which tool you should use depends on your website or project. In most cases, it will be a combination of multiple tools.</p>
<p>A developer could use Lighthouse to check if the code has a performance issue. After a commit, continuous integration can spin up some test servers, and you can test if any performance budgets have been breached.</p>
<p>Another milestone could be a performance test after each new release. You have to decide which of these approaches fits your needs. Testing on each commit could be pricey, but testing only releases makes it challenging to identify the cause of a performance regression.</p>
<h3 id="celebrate-your-wins">Celebrate your wins</h3>
<p>Celebrating wins is an essential part of building a performance team. Actively celebrate successes periodically.</p>
<p>You could write a tweet or a blog post. Appoint a web performance employee of the month. Award a performance hero price. The hero doesn't need to be a developer or a performance engineer. A performance hero could also be your marketing manager.</p>
<h3 id="internal-or-public-pr">Internal or public PR</h3>
<p>No matter where you work, it is vital to communicate your wins within the organization. You show your successes to your boss or team lead to get a promotion someday. The same goes for your web performance wins. Modestly show them around your company, create simple graphs, or write internal blog posts. The people in your company shouldn't take it for granted that your website is fast.</p>
<h3 id="optimization">Optimization</h3>
<p>Optimization is one core job of your performance team. The performance team identifies and prioritizes opportunities for improvement. What aspects of your website you can optimize depends on your site and your users. Before you start, you need to analyze and monitor the performance of your website.</p>
<p>First, identify performance issues on your site and can create a list of potential improvements.</p>
<p>Next, estimate the impact of each issue and how much effort would be required to address it.</p>
<p>In the beginning, this might be a little tricky as you won't have any past optimizations to compare to. You could start by creating a sample issue that everybody can estimate, and then compare other issues to the sample issue. It's simpler to compare a new issue to an existing one rather than speculate about the impact.</p>
<p>For example, let's say reducing all your images to under 100 KB takes two days and speeds up your site by 500 ms. One of your current issues could be to hide some pictures on mobile. In our case, removing images on mobile devices could influence load times, but it won't take much time to finish.</p>
<h3 id="regressions">Regressions</h3>
<p>One of your biggest enemies as a web performance team are regressions. Regressions happens more often than you think, as it's easier to make a website fast once than keeping it fast long-term. Sometimes preventing regressions can be more impactful than shipping optimizations.</p>
<p>Depending on your infrastructure, you could use your tools to prevent regression. Put in place continuous integration for performance testing. If an issue happens, send daily, weekly or monthly reports. Besides that, you should send performance alerts to an accountable person in real-time.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Building a dedicated web performance team depends on web performance culture. This team's primary goal is to promote and encourage this culture. The members are doing this by sharing knowledge and educating all other employees.</p>
<p>Becoming and staying fast can not be done without a group of people who care about web performance. The ‚Ä¶</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.debugbear.com/blog/web-performance-team">https://www.debugbear.com/blog/web-performance-team</a></em></p>]]>
            </description>
            <link>https://www.debugbear.com/blog/web-performance-team</link>
            <guid isPermaLink="false">hacker-news-small-sites-25045594</guid>
            <pubDate>Tue, 10 Nov 2020 13:18:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Aesthetics over Usability ‚Äì Google's New App Icons]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25045441">thread link</a>) | @moeminm
<br/>
November 10, 2020 | https://blog.moeminmamdouh.com/aesthetics-over-usability-googles-new-app-icons | <a href="https://web.archive.org/web/*/https://blog.moeminmamdouh.com/aesthetics-over-usability-googles-new-app-icons">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1605012940954/mO5AoN3Ie.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text"><p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605011290156/BFSvCYtdr.png?auto=format&amp;q=60" alt="Google-Workspace-Icons-bad.png"></p>
<p>Google's new app icons are, well, a massive disappointment. They are so bad, there's a <a target="_blank" href="https://restoreoldicons.xyz/">Chrome extension</a> that you can download to restore the old icons. Design changes are always met with some sort of backlash, that's understandable, people don't like change. Facebook's desktop redesign, Instagram's icon redesign, Macbook's touchbar, etc. The problem here; however, revolves around usability, and that's when user feedback should be seriously taken into consideration.</p>
<p>Aside from the icon's shapes, there is nothing else distinguishable about them. They are all made from a palette of four colors; blue, green, yellow, and red. There's a reason why people hate them, and it's not colors, it's usability. </p>
<p>Browsing through the internet, here are some common complaints:</p>
<blockquote>
<p>I had to manually change every Google app icon on my Android phone. I had trouble finding the Maps icon even though it is in the same place. All the new icons look similar to Google drive icon.</p>
</blockquote>
<p>The complaints all revolve around not being to <em>find</em> the apps they want to launch.</p>
<blockquote>
<p>Bring back the old version. Like the new icons aren't even close. They're so unrecognizable that when I go search for them, I forget what I'm looking for before I get to them. It takes me 3 tries to create new events in my calendar or check my email lol</p>
</blockquote>
<p>I believe this comment summarizes why this change rolled out and is live</p>
<blockquote>
<p>To me, this is a symptom of a large company with lots of internal politics and friction, where it is not safe for a designer to push back and say "no, this is not a good idea" to their manager.</p>
<p>Or, even more likely, someone did, and were forced to execute anyway.</p>
</blockquote>
<p>Unfortunately, this is the current state of UX and Design in a lot of companies. Stakeholders are ultimately the one making decisions despite being met with proven statistics from designers. </p>
<p>I also feel like this is a great lesson to any aspiring designer that working for FANG companies isn't always rainbows and sunshine. I can't be sure why these icons rolled out, if it actually was internal politics or not, but it <strong>does</strong> happen. It isn't always about working for FANG companies, but working for a company that aligns with your values. </p>
<p>See you in another Google rebrand. </p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.moeminmamdouh.com/aesthetics-over-usability-googles-new-app-icons</link>
            <guid isPermaLink="false">hacker-news-small-sites-25045441</guid>
            <pubDate>Tue, 10 Nov 2020 12:59:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bidirectional Scrolling: Why Not Both?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25045390">thread link</a>) | @bradley_taunt
<br/>
November 10, 2020 | https://uglyduck.ca/bidirectional-scrolling/ | <a href="https://web.archive.org/web/*/https://uglyduck.ca/bidirectional-scrolling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
      <section>
        
          <p><time datetime="2020-11-09T00:00:00+00:00">November 9, 2020</time></p>
        
        
        
          <p><em>Discussing the design decisions of bidirectional scrolling in regards to performance</em></p>
        
        <p>I recently came across Adam Silver‚Äôs post <a href="https://adamsilver.io/articles/bidirectional-scrolling-whats-not-to-like/">about the merits and pitfalls of bidirectional scrolling</a> and found myself conflicted with the design arguments put forth in the article. It‚Äôs a very good article overall, and I suggest giving it a read before digging deeper into my post here.</p>

<h2 id="the-premise">The Premise</h2>

<p>The original article argues that displaying page content via horizontal scrolling (and therefore slightly hiding interactive content) creates a few major issues:</p>

<ul>
  <li>it increases the chance users won‚Äôt see it</li>
  <li>there‚Äôs a greater reliance on digital literacy</li>
  <li>it‚Äôs generally more labour intensive for users</li>
</ul>

<p>Adam also makes a solid statement here:</p>

<blockquote>
  <p>Having to scroll down and across in a zig zag fashion can be tiresome, especially for people with motor impairments.</p>
</blockquote>

<p>But I don‚Äôt believe these issues create a need to completely remove the horizontal ‚Äúscrolling‚Äù design altogether. You can still implement the <code>See All Items</code> category link, while allowing the horizontal content to load in <em>dynamically</em>. Balance is always key.</p>

<h2 id="not-all-at-once-please">Not All At Once, Please!</h2>

<p>So what exactly do I mean by <em>dynamically</em> loading in horizontal content?</p>

<ul>
  <li>The user is shown the top 4 items in a given category</li>
  <li>From there, the user can use the <code>See All Items</code> link to jump into a full category page</li>
  <li>If they so desire, they can begin scroll horizontally in a given category row
    <ul>
      <li>Once they reach the end of the row, 4 more items will load in automatically to expand the list</li>
      <li>To avoid a never-ending list, it might be best to limit total row items to ~20 items. At this point the UI could prompt the user to <code>View All Items</code> in that category.</li>
    </ul>
  </li>
</ul>

<p>By loading the row content in piece-by-piece, initial loads for users will be faster and subsequent list items will load quickly as well (since they would limit to a set default - in this case only 4).</p>

<h2 id="final-improvements">Final Improvements</h2>

<p>Below you can find a quick, static version of this concept. Here you can see the horizontal list items, along with their corresponding <code>See All Items</code> links. You‚Äôll have to use your imagination for how new items would load once you each the end of a horizontal row. (I‚Äôm too lazy to spend extra time building out that functionality for a hypothetical blog post)</p>

<p data-height="844" data-theme-id="dark" data-default-tab="result" data-user="bradleytaunt" data-slug-hash="pobxpXz" data-pen-title="Bidirectional Scrolling CSS">
  <span>See the Pen <a href="https://codepen.io/bradleytaunt/pen/pobxpXz">
  Bidirectional Scrolling CSS</a> by Bradley Taunt (<a href="https://codepen.io/bradleytaunt">@bradleytaunt</a>)
  on <a href="https://codepen.io/">CodePen</a>.</span>
</p>



        
<br>

      </section>
    </div></div>]]>
            </description>
            <link>https://uglyduck.ca/bidirectional-scrolling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25045390</guid>
            <pubDate>Tue, 10 Nov 2020 12:52:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is a Single Source of Truth and why do you need it]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25045127">thread link</a>) | @gabeadami
<br/>
November 10, 2020 | https://www.infolio.co/post/what-is-a-single-source-of-truth-and-why-do-you-need-it | <a href="https://web.archive.org/web/*/https://www.infolio.co/post/what-is-a-single-source-of-truth-and-why-do-you-need-it">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.3.0"><div dir="ltr"><div><p id="viewer-foo"><span>Nowadays, too many companies struggle with difficulties organizing multiple data sources, low data accuracy or poor data accessibility. Most organizations have their company information scattered across several sources, databases, email threads. Thus, many teams end up having multiple conflicting versions of the same information, which may lead to severe errors. According to&nbsp;<a href="https://assets.kpmg/content/dam/kpmg/xx/pdf/2016/10/building-trust-in-analytics.pdf" target="_blank" rel="noopener"><u>KPMG and Forrester's survey</u></a>,&nbsp;only 34% of decision-makers report that they feel confident in the accuracy of the information they use.</span></p><div id="viewer-fbd7q"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img" aria-label="Single source of truth anyone?"><p><img data-pin-url="https://www.infolio.co/post/what-is-a-single-source-of-truth-and-why-do-you-need-it" data-pin-media="https://static.wixstatic.com/media/78f01e_5ff465f2e4e74c5aac029c4c8c76ef2f~mv2.jpg/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/78f01e_5ff465f2e4e74c5aac029c4c8c76ef2f~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg" alt="Single source of truth anyone?"></p></div><p><span dir="auto">Our take on SSOT visual representation</span></p></div></div></div><p id="viewer-f0t8v"><span>Just imagine the following scenario: you have three teams that work independently but within the same project's frames. Everything's going smooth: each week you are updated by your teams ‚Äì you know that they all are on track, and the project is finally moving to its final milestone. But in the end, it turns out that the product cannot be delivered as expected: the teams have worked each with a different goal in mind, supported by entirely different sources of information.&nbsp;</span></p><p id="viewer-cf90a"><span>For example:</span></p><ul><li id="viewer-fhjll"><p>Team A relied on your email guidance;</p></li><li id="viewer-ca2eq"><p>Team B followed specific client requirements without sharing them;</p></li><li id="viewer-ep6c9"><p>Team C followed the notes they made during the check-up meetings.</p></li></ul><p id="viewer-6hh0r"><span>So, what Is the main problem? We all have too many information channels, and instead of investing time into the right organization, we waste it on information search and verification. Besides, many employees search for the necessary information only when they need it, but they don't have it always at hand and don't follow the updates regularly.</span></p><p id="viewer-d6ekj"><span>Afterwards, we get what we deserve¬≠ ‚Äî dozens of communication channels, each carrying its own version of the information. Solution? A concept called Single Source of Truth (SSOT). This article will uncover what SSOT is, its characteristics and benefits, how it is organized, and why you clearly need it.</span></p><h2 id="viewer-6bo5l"><span>What is a Single Source of Truth (SSOT)?</span></h2><p id="viewer-ajjgd"><span>Here's one more example. Imagine that you're watching a football match with your friend, enjoying popcorn on the couch. And then your friend suddenly declares that Ronaldo is the best football player in the world, but you insist that it's Neymar, and the situation is getting tense. To settle this, you have to agree on the source with trusted stats, such as the number of played matches, wins, goals, etc. In other words, you agree upon your Single Source of Truth, to check who really is the best of these two talented guys, based on the trustful information.</span></p><p id="viewer-o8ll"><span>SSOT is a concept used to ensure that everyone in an organization bases business decisions on the same data. It is a platform where all company knowledge and information are stored and managed centrally to avoid overlaps and duplication. This platform might include decisions, processes, and operations of various company departments, e.g., Management, Human Resources, Sales, Marketing, etc.</span></p><p id="viewer-2va09"><span>A single source of truth provides employees, employers, and stakeholders with a clearer picture of information they possess, which in turn makes the decision-making process much simpler. SSOT ensures that the provided information is most recent and accurate; the reports are up-to-date so that you can rely on this data.</span></p><h2 id="viewer-b5js8"><span>Why have a Single Source of Truth?</span></h2><p id="viewer-csc4b"><span>SSOT is important for the times when an employee needs only one right answer. Organizations must ensure that their personnel is provided with one source that stores the information they need.&nbsp;You don't want your projects to fail. And you clearly don't need those dozens of tools in use, numerous apps to get the job done, and not a single one integrated with another. That doesn't sound good, right? The main idea is to put away the useless discussions and argues on which numbers/sources/stats and other data you should primarily rely on.</span></p><p id="viewer-d8cru"><span>Here are the primary and inarguable benefits of having SSOT:</span></p><ul><li id="viewer-9ojf9"><p>Decision-makers are provided with the right data;</p></li><li id="viewer-5oorj"><p>Reduction of the time spent on identifying the source with the correct and updated information;</p></li><li id="viewer-9erl8"><p>Eliminate duplicates and overlaps;</p></li><li id="viewer-7b7eh"><p>Increased clarity, transparency; and productivity;</p></li><li id="viewer-d1dag"><p>Reduction of tools and communication channels and associated costs;&nbsp;</p></li><li id="viewer-8a36v"><p>Reduction of error chances.</p></li></ul><h2 id="viewer-9mir1"><span>How organizations put an SSOT in place?</span></h2><p id="viewer-3m9v8"><span>For organizations, the best way to establish a Single Source of Truth is to connect and organize all the company information in one integrated software toolkit/suite. Creating SSOT isn't as complicated as it may seem from the first sight, especially if you already use a centralized task and project management tool. The project management tool that fits your team's needs has everything to become a single source of truth for your team.</span></p><div id="viewer-1mbnb"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img" aria-label="Many ideas, single place to keep them "><p><img data-pin-url="https://www.infolio.co/post/what-is-a-single-source-of-truth-and-why-do-you-need-it" data-pin-media="https://static.wixstatic.com/media/78f01e_879787ef1ad04e5b9e98ce8bf8dde07f~mv2.jpg/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/78f01e_879787ef1ad04e5b9e98ce8bf8dde07f~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg" alt="Many ideas, single place to keep them "></p></div><p><span dir="auto">Many ideas, single place to keep them </span></p></div></div></div><p id="viewer-5uptg"><span>An SSOT should be agreed upon and declared so that everyone knows where is the right information stored, when/how often it should be updated. If this works for your team, you're almost here. But wait, you still need to choose the right tool that will serve you as an SSOT.</span></p><p id="viewer-530g7"><span>Here are some ways how task and project management tools, used as a single source of truth might help your team to deliver better results:</span></p><h3 id="viewer-fntmo"><span>Reduced number of meetings and emails</span></h3><p id="viewer-1feth"><span>You simply wouldn't need so many. Suppose your team has a central place to store important information, project progress, and updates. In that case, many status/sync meetings can be transformed into project chat messages or short comments/descriptions in task cards. The number of delayed projects due to miscommunications will decrease as well. So, it is highly recommended to choose a task management tool that has chat functionality.</span></p><h3 id="viewer-83nqs"><span>Greater team accountability</span></h3><p id="viewer-2lk02"><span>Task management tools ensure clarity and transparency, which leads to increased employee accountability. The past projects are stored, the future projects are planned, and everyone is on the same page. Each team member can track the team‚Äôs progress, always in the know of who is working on what and by when. An extra layer of clarity/personalization can be added with custom fields: priority, notes, comments, progress, or any other additional information. When everyone has up-to-date information on the project progress and is informed about the deadlines, it is more likely to be delivered in time. By updating Statuses in real-time, you provide more visibility for everyone in your team on their accomplishments.</span></p><div id="viewer-3dgdd"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img" aria-label="Greater team accountability"><p><img data-pin-url="https://www.infolio.co/post/what-is-a-single-source-of-truth-and-why-do-you-need-it" data-pin-media="https://static.wixstatic.com/media/78f01e_c8965819ce9a4f5d9c19f65dc48186e5~mv2.png/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/78f01e_c8965819ce9a4f5d9c19f65dc48186e5~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png" alt="Greater team accountability"></p></div><p><span dir="auto">With great team comes great accountability?</span></p></div></div></div><h3 id="viewer-dafal"><span>One task ‚Äì many details</span></h3><p id="viewer-9il29"><span>Emails and meetings are a part of our lives for some time now, and we got used to them. But aren't they getting a little outdated? With a task management tool, you don't have to send long emails with task descriptions and many attachments, which might later get lost in your inbox. Create a task, add subtasks or checklists (if needed), attach any documents you need, set due dates and responsible assignees, add tags, and any other details you wish in custom fields. You can be very specific, writing a task description, and avoid a lot of questions. Knowing that you have everything about the task in one place makes everyone more confident in doing their jobs. And you always know where to look for the updates.</span></p><div id="viewer-8sb4v"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img" aria-label="One task ‚Äî many details"><p><img data-pin-url="https://www.infolio.co/post/what-is-a-single-source-of-truth-and-why-do-you-need-it" data-pin-media="https://static.wixstatic.com/media/78f01e_75ef8487eb5a45bca47c5888c553187c~mv2.png/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/78f01e_75ef8487eb5a45bca47c5888c553187c~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png" alt="One task ‚Äî many details"></p></div><p><span dir="auto">Looks like this one is already overdue</span></p></div></div></div><h3 id="viewer-6m04o"><span>One place for everything</span></h3><p id="viewer-c872n"><span>The most crucial benefit of any task management tool is that it is an all-in-one place to manage people, projects, and everything in between. You control the team's and projects' process; you share files, communicate, brainstorm, provide comments in one place, and collaborate in real-time. You can store all your reports, tables, presentations, lists, and links in spaces and update when needed. The only important rule to adhere to: this is the only source of truth for your team, and it contains the most accurate and up-to-date information. As a Manager or a Team Lead, you should be responsible for keeping this source updated or for selecting responsible employees to delegate this important task.</span></p><div id="viewer-3g5sl"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img" aria-label="One place for everything task and project related"><p><img data-pin-url="https://www.infolio.co/post/what-is-a-single-source-of-truth-and-why-do-you-need-it" data-pin-media="https://static.wixstatic.com/media/78f01e_93c82284c88945ab8ebac8a6bbec6262~mv2.png/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/78f01e_93c82284c88945ab8ebac8a6bbec6262~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png" alt="One place for everything task and project related"></p></div><p><span dir="auto">Nobody said you can't keep tasty recipes in you task management tool!</span></p></div></div></div><h2 id="viewer-bouro"><span>How to choose the right project management tool for your team?</span></h2><p id="viewer-12uah"><span>Everyone knows there are tons of project and task management tools available right now. And many of them are really great. But how to choose the best one? We would say that the "best "is very subjective and unfair evaluation. When choosing your project management software, you need to consider many factors, such as team size and particular features needed, functionality, security, budget, and more. It's obvious that a small start-up team will need a completely different tool compared to the needs of a vast organization with many departments and hundreds of employees. Thus, we have prepared some recommendations that you can take into consideration:</span></p><p id="viewer-5822p"><span><strong>Freelancers/ individuals:</strong></span></p><ul><li id="viewer-6k06r"><p><a href="https://www.infolio.co/" target="_blank" rel="noopener"><u><span>Infolio</span></u></a></p></li><li id="viewer-8ak3i"><p><a href="https://trello.com/" target="_blank" rel="noopener"><u><span>Trello</span></u></a></p></li><li id="viewer-acgm7"><p><a href="https://todoist.com/" target="_blank" rel="noopener"><u><span>Todoist</span></u></a></p></li><li id="viewer-6s6go"><p><a href="https://www.taskpigeon.co/" target="_blank" rel="noopener"><u><span>Task Pigeon</span></u></a></p></li></ul><p id="viewer-bbff8"><span><strong>Small to mid-size teams:</strong></span></p><ul><li id="viewer-ev7dd"><p><a href="https://asana.com/" target="_blank" rel="noopener"><u><span>Asana</span></u></a></p></li><li id="viewer-ubks"><p><a href="https://airtable.com/" target="_blank" rel="noopener"><u><span>Airtable</span></u></a></p></li><li id="viewer-57khb"><p><a href="https://clickup.com/" target="_blank" rel="noopener"><u><span>ClickUp</span></u></a></p></li><li id="viewer-98jr0"><p><a href="https://www.infolio.co/" target="_blank" rel="noopener"><u><span>Infolio</span></u></a> (yes, we are mentioned twice here because it's our list!)</p></li><li id="viewer-ak3mf"><p><a href="https://toggl.com/" target="_blank" rel="noopener"><u><span>Toggl</span></u></a></p></li><li id="viewer-10mbf"><p><a href="https://www.wrike.com/" target="_blank" rel="noopener"><u><span>Wrike</span></u></a></p></li></ul><p id="viewer-836h4"><span><strong>Bigger teams:</strong></span></p><ul><li id="viewer-ek0ka"><p><a href="https://monday.com/" target="_blank" rel="noopener"><u><span>Monday.com</span></u></a></p></li><li id="viewer-a8upa"><p><a href="https://www.atlassian.com/software/jira" target="_blank" rel="noopener"><u><span>Jira</span></u></a></p></li><li id="viewer-mp9j"><p><a href="https://asana.com/" target="_blank" rel="noopener"><u><span>Asana</span></u></a></p></li><li id="viewer-irit"><p><a href="https://www.teamwork.com/" target="_blank" rel="noopener"><u><span>Teamwork</span></u></a></p></li><li id="viewer-dmp08"><p><a href="https://www.hubspot.com/" target="_blank" rel="noopener"><u><span>Hubspot</span></u></a></p></li></ul></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.infolio.co/post/what-is-a-single-source-of-truth-and-why-do-you-need-it</link>
            <guid isPermaLink="false">hacker-news-small-sites-25045127</guid>
            <pubDate>Tue, 10 Nov 2020 12:18:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Does Pwd Operate?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25045067">thread link</a>) | @gclv
<br/>
November 10, 2020 | https://www.gclv.es/how-does-pwd-operate | <a href="https://web.archive.org/web/*/https://www.gclv.es/how-does-pwd-operate">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>After re-reading some of the papers from Bell Labs, something clicked in my mind, and I'm hooked. I'm now reading <a href="https://en.wikipedia.org/wiki/The_Unix_Programming_Environment" rel="nofollow">‚ÄúThe UNIX Programming Environment‚Äù</a>, by Kernighan and Pike. It's got that fun style you're probably familiar with, if you've read K&amp;R or the <a href="https://gopl.io/" rel="nofollow">blue book</a>. One of the first exercise questions, on the chapter on file systems:</p>

<blockquote><p>(harder) How does the <code>pwd</code> command operate?</p></blockquote>

<p>Seems like a fun one. My first guess is that it used <code>$PWD</code> from the environment. Let's test that.</p>

<pre><code>~ % PWD=/usr/local pwd
/home/gg
</code></pre>

<p>There's a non-standard <code>-L</code> flag that seems to use <code>$PWD</code>. Maybe that one would do?</p>

<pre><code>~ % PWD=/usr/local pwd -L
/home/gg
</code></pre>

<p>Not that either. Wait a second, what's <code>pwd</code> again?</p>

<pre><code>~ % type pwd
pwd is a shell builtin
</code></pre>

<p>Hah, so I was calling the wrong one. So I replace <code>pwd</code> with <code>/bin/pwd</code> in my queries above, but the results are the same.</p>

<p>My next hypothesis is that it would somehow expand <code>.</code> to absolute. I'm not aware of a UNIX command that performs such an expansion, so I <code>man -k</code> some keywords. Nothing.</p>

<p>Maybe <code>pwd(1)</code>? It's not terribly descriptive (it's such a simple utility after all.) It doesn't explain the implementation at all, but links me to <code>getcwd(3)</code>. Alright, let's just look at the source.</p>

<h2 id="openbsd-implementation">OpenBSD implementation</h2>

<pre><code>int
main(int argc, char *argv[])
{
	int ch, lFlag = 0;
	const char *p;

	/* pledge(), parse flags... */

	if (lFlag)
		p = getcwd_logical();
	else
		p = NULL;
	if (p == NULL)
		p = getcwd(NULL, 0);

	if (p == NULL)
		err(EXIT_FAILURE, NULL);

	puts(p);

	exit(EXIT_SUCCESS);
}
</code></pre>

<p>Unless <code>-P</code> is passed, it just calls <code>getcwd</code>. Let's see what that ‚Äúlogical‚Äù
function does:</p>

<pre><code>static char *
getcwd_logical(void)
{
	char *pwd, *p;
	struct stat s_pwd, s_dot;

	/* Check $PWD -- if it's right, it's fast. */
	pwd = getenv("PWD");
	puts("PWD found in the ENV");
	puts(pwd);
	if (pwd == NULL)
		return NULL;
	if (pwd[0] != '/')
		return NULL;

	/* check for . or .. components, including trailing ones */
	for (p = pwd; *p != '\0'; p++)
		if (p[0] == '/' &amp;&amp; p[1] == '.') {
			if (p[2] == '.')
				p++;
			if (p[2] == '\0' || p[2] == '/')
				return NULL;
		}

	if (stat(pwd, &amp;s_pwd) == -1 || stat(".", &amp;s_dot) == -1)
		return NULL;
	if (s_pwd.st_dev != s_dot.st_dev || s_pwd.st_ino != s_dot.st_ino)
		return NULL;
	return pwd;
}
</code></pre>

<p>So <code>-L</code> <em>does</em> check for <code>$PWD</code>, but only returns it if it's pointing to the same inode, on the same device. You can't just manually override it to be anything you want. In that case, it falls back to the libc call to <code>getcwd</code>.</p>

<p>Makes me wonder what use this <code>-L</code> flag is in the first place. Maybe it has to do with symlinks?</p>

<pre><code>/tmp % mkdir one
/tmp % ln -s one two
/tmp % cd one
/tmp/one % /bin/pwd
/tmp/one
/tmp/one % cd ../two
/tmp/two % /bin/pwd
/tmp/one
/tmp/two % /bin/pwd -L
/tmp/two
</code></pre>

<p>Makes sense. Anyway, that's not a very satisfying answer. I doubt the authors' intended answer would have been ‚Äúdefer to the libc‚Äù.</p>

<h2 id="plan9">Plan9</h2>

<p>Ok, OpenBSD source didn't help. But Plan9 is <em>Unicibus ipsis Unicior</em>, so maybe we can find the answer there. Let's inspect <code>pwd(1)</code>:</p>

<pre><code>     DESCRIPTION
          Pwd prints the path name of the working (current) directory.
          Pwd is guaranteed to return the same path that was used to
          enter the directory.  If, however, the name space has
          changed, or directory names have been changed, this path
          name may no longer be valid.  (See fd2path(2) for a descrip-
          tion of pwd's mechanism.)
</code></pre>

<p>Hah, that was helpful! Now, from <code>fd2path(2)</code>:</p>

<pre><code>          As an example, getwd(2) is implemented by opening . and exe-
          cuting fd2path on the resulting file descriptor.
</code></pre>

<p>So my hypothesis above was correct, at least when it comes to Plan9. Also, another cool thing about Plan9 is that it lets me inspect a folder (‚Äúeverything is a file‚Äù, right?)</p>

<pre><code>% cat . &gt; foo
% cat foo
</code></pre>

<p>I can then run <code>foo</code> through <code>hexdump</code> and see what's in there.</p>

<h2 id="gnu">GNU</h2>

<p>Let's see <a href="https://github.com/coreutils/coreutils/blob/master/src/pwd.c" rel="nofollow">how coreutils implements it</a>... nope. Just nope.</p>

<h2 id="wrapping-up">Wrapping up</h2>

<p>So that was it, a brief excursion into different implementations of a simple command in UNIX. The difference in complexity is palpable. The Plan9 documentation is fun to read, and so is the code.</p>
</div></div>]]>
            </description>
            <link>https://www.gclv.es/how-does-pwd-operate</link>
            <guid isPermaLink="false">hacker-news-small-sites-25045067</guid>
            <pubDate>Tue, 10 Nov 2020 12:10:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Micro 3.0 is a platform for cloud native development]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25044604">thread link</a>) | @asim
<br/>
November 10, 2020 | https://micro.mu/blog/2020/11/05/micro-v3-aka-m3o.html | <a href="https://web.archive.org/web/*/https://micro.mu/blog/2020/11/05/micro-v3-aka-m3o.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      

      
      
      

      <p>This is the official announcement for the release of Micro 3.0 better known as M3O - a platform for cloud native development. 
Our 3.0 release is a major refactor and consolidation of the existing tooling into something that addresses the entire workflow 
of build, run, manage and consume all from the developers perspective.</p>

<p>Read on to learn more or go straight to the <a href="https://github.com/micro/micro/releases/latest">latest release</a>. 
Head to <a href="https://m3o.com/">m3o.com</a> for the hosted offering.</p>

<h2 id="overview">Overview</h2>

<p>Micro focuses on developer productivity for the backend. It‚Äôs clear that the Cloud has become infinitely more complex 
over the past few years. Micro attempts to create order out of that chaos by distilling it all down to a handful of 
primitives for distributed systems development.</p>

<p>Why should you care? If you‚Äôre reading this you‚Äôve no doubt encountered the tedious nature of infrastructure management, 
wrangling a kubernetes cluster on AWS or the thousands of things you need to do to cobble together a platform before 
starting to build a product. We think we‚Äôve nailed the solution for that just as Android did for Mobile. Keep reading 
if you want to find out more.</p>

<h2 id="quick-flashback">Quick Flashback</h2>

<p>Micro started out as a <a href="https://micro.mu/blog/2016/03/20/micro.html">toolkit for microservices</a> development, 
incorporating an api gateway, web dashboard and cli to interact with services built using a Go RPC framework. 
Back then it felt like getting anyone to buy into PaaS again was going to be a losing battle. So we chose 
to write single purpose tools around an RPC framework thinking it might allow people to adopt it piece by piece 
until they saw the need for a platform. It was really straight forward right until it wasn‚Äôt.</p>

<p>There was a simple Go framework plus some surrounding 
components to query and interact with them, but like any long lived project, the complexity grew as we 
tried to solve for that platform experience that just couldn‚Äôt be done with a swiss army knife. The repo 
exploded with a number of independent libraries. To the creator its obvious what these are all for but to 
the user there is nothing but cognitive overload.</p>

<p>In 2019 we went through a <a href="https://micro.mu/blog/2019/06/10/the-great-consolidation.html">consolidation</a> of all those libraries 
which helped tremendously but there was still always one outstanding question. What‚Äôs the difference between 
<a href="https://github.com/micro/micro">micro</a> and <a href="https://github.com/micro/go-micro">go-micro</a>? It‚Äôs a good 
question and one we‚Äôve covered before. We saw go-micro as a framework and micro as a toolkit but these 
words were basically empty and meaningless because multiple projects working in coordination really need a 
crisp story that makes sense and we didn‚Äôt have one.</p>

<p>In 2020 we‚Äôre looking to rectify that but let‚Äôs first let‚Äôs talk about platforms.</p>

<h2 id="paas-in-2020">PaaS in 2020</h2>

<p>5 years ago the world exploded with a proliferation of ‚Äúcloud native‚Äù tooling as containers and 
container orchestration took centre stage. More specifically, Docker and Kubernetes redefined the 
technology landscape along with a more conscious move towards building software in the cloud.</p>

<p>Micro took a forward looking view even as far back as 2015. It was clear distributed systems and cloud native 
was going to become the dominant model for backend services development over the coming years but, what wasn‚Äôt clear 
is just how long we‚Äôd spend wrangling all sorts tools like docker, kubernetes, grpc, istio and everything else. 
It felt like we were rebuilding the stack and weren‚Äôt really ready to talk about development aspects of it all.</p>

<p>In fact at that time, people mostly wanted to kick the tyres on all these tools and piece something together. 
Running kubernetes yourself became all the rage and even using service mesh as the holy grail for solving 
all your distributed systems problems. Many of us have come to realise while all of this tech is fun 
it‚Äôs not actually solving development problems.</p>

<p>We‚Äôve gotten to the point of managed kubernetes and even things like Google Cloud Run or DigitalOcean App 
Platform, but none of these things are helping with a development model for a cloud native era. Our 
frustrations with the existing developer experience have grown and Micro felt like something that 
could solve for all that, but only if we took a drastic step to overhaul it.</p>

<p>We think PaaS 3.0 is not just about running your container or even your source code but something that 
encapsulates the entire developer experience including a model for writing code for the cloud. Based on that 
Micro 3.0 aka M3O is a platform for cloud native development.</p>

<h2 id="what-even-is-cloud-native">What even is Cloud Native?</h2>

<p>What is cloud native? What does it mean to build for the cloud? What is a cloud service?</p>

<p>Cloud native is basically a descriptive term for something that was built to run in the cloud. That‚Äôs it. It‚Äôs not 
magic, it might sound like a buzzword, but the reality is it simply means, that piece of software was built 
to run in the cloud. How does that differ from the way we used to build before? Well the idea behind the cloud 
is that its ephemeral, scalable and everything can be accessed via an API.</p>

<p>Our expectation for services running in the cloud is that they‚Äôre mostly stateless, leveraging external services 
for the persistence, that they are identified by name rather than IP address and they themselves provide an 
API that can be consumed by multiple clients such as web, mobile and cli or other services.</p>

<p>Cloud native applications are horizontally scalable and operate within domain boundaries that divide them as 
separate apps which communicate over the network via their APIs rather than as one monolithic entity. 
We think cloud services require a fundamentally different approach to software creation and why Micro 3.0 
was designed with this in mind.</p>

<h2 id="micro-30-aka-m3o">Micro 3.0 aka M3O</h2>

<p>Micro 3.0 (M3O) reimagines Micro as a platform for cloud native development. What does that mean? Well we think of 
it as PaaS 3.0, a complete solution for source to running and beyond. Micro has moved from just being a Go 
framework to incorporating a standalone server and hosted platform. Our hosted offering is called 
<a href="https://m3o.com/">M3O</a>, a hat tip to Micro 3.0 or M[icr]o, whichever way you want to see it.</p>

<p>Another way to think about it. What Git is to GitHub, Micro is to the M3O platform. Let‚Äôs dig into it.</p>

<p>Micro 3.0 includes the following.</p>

<h3 id="server">Server</h3>

<p>The server is our abstraction for cloud infrastructure and underlying systems you might need for writing 
distributed systems. The server encapsulates all of these concerns as gRPC services which you can 
query via any language. The goal here is to say developers don‚Äôt really need to be thinking about infrastructure 
but what they do need is design patterns and primitives for building distributed systems.</p>

<p><img src="https://micro.mu/images/micro-3.0.png"></p>

<p>The server includes the following:</p>

<ul>
  <li>
    <p><strong>Authentication</strong>: Auth whether its authentication or authorization is part of the system. Create JWT tokens, define access rules, use one system to govern everything in a simple and straight forward manner. Whether it‚Äôs for a user or a service.</p>
  </li>
  <li>
    <p><strong>Configuration</strong>: Dynamic config management allows you to store relevant config that needs to be updated without having to restart services. Throw API keys and business logic related configuration into the secure config service and let your services pick up the changes.</p>
  </li>
  <li>
    <p><strong>Key-Value Storage</strong>: We‚Äôre focused on best practices for microservices development which means keeping services mostly stateless. To do this we‚Äôre providing persistent storage on the platform. Key-Value allows you to rapidly write code and store data in the format you care about.</p>
  </li>
  <li>
    <p><strong>Event Streaming</strong>: Distributed systems are fundamentally in need of an event driven architecture to breakdown the tight dependencies between them. Using event streaming and pubsub allows you to publish and subscribe to relevant events async.</p>
  </li>
  <li>
    <p><strong>Service Registry</strong>: Micro and M3O bake in service discovery so you can browse a directory of services to explore your service APIs and enable you to query services by name. Micro is all about microservices and multi-service development.</p>
  </li>
  <li>
    <p><strong>Service Network</strong>: Because you don‚Äôt want to have to resolve those service names to addresses and deal with the load balancing aspect, the server bakes in a ‚Äúservice mesh‚Äù which will handle your inter-service requests (as gRPC) and route to the 
appropriate instance.</p>
  </li>
  <li>
    <p><strong>Identity Proxy</strong>: We include a separate identity proxy for external requests using gRPC via the CLI and other means. This enables you to query from your local machine or anywhere else using valid auth credentials and have it seamlessly work as if 
you were in the platform itself.</p>
  </li>
  <li>
    <p><strong>API Gateway</strong>: Finally there‚Äôs an API gateway that automatically exposes your services to the outside world over HTTP. Internally writing service to service using gRPC makes sense, but at the end of the day we want to build APIs consumed from clients via HTTP.</p>
  </li>
</ul>

<h3 id="clients">Clients</h3>

<p>The server provides inter-service communication and two means of external communication with a HTTP API and gRPC proxy but that 
experience is made much better when there‚Äôs user experience on the client side that works. Right now we‚Äôve got two ways of doing this.</p>

<ul>
  <li>
    <p><strong>Command Line</strong>: The CLI provides a convenient and simple way to talk to the server via gRPC requests through the proxy. 
The most convenient commands are builtin but every service you write also gets beautiful dynamic generated commands 
for each endpoint.</p>
  </li>
  <li>
    <p><strong>gRPC SDKs</strong>: Every service in the server is accessible via gRPC. We‚Äôre code generating clients for the server itself 
so you can access them from any language. What this enables is a wide array of experiences on the client side without 
having to handcraft libraries for each language.</p>
  </li>
  <li>
    <p><strong>Web Interface</strong>: Coming soon is a dynamically generated web interface that creates a simple query mechanism through a 
browser for any of your services. We‚Äôve got a http api, gRPC proxy and command line interface but feel like the browser 
could use some love too.</p>
  </li>
</ul>

<h3 id="framework">Framework</h3>

<p>One thing we really understood from our time working on go-micro was that the developer experience ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://micro.mu/blog/2020/11/05/micro-v3-aka-m3o.html">https://micro.mu/blog/2020/11/05/micro-v3-aka-m3o.html</a></em></p>]]>
            </description>
            <link>https://micro.mu/blog/2020/11/05/micro-v3-aka-m3o.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044604</guid>
            <pubDate>Tue, 10 Nov 2020 11:00:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to revert HP printer‚Äôs ban on 3rd-party ink cartridges]]>
            </title>
            <description>
<![CDATA[
Score 411 | Comments 253 (<a href="https://news.ycombinator.com/item?id=25044597">thread link</a>) | @kdeldycke
<br/>
November 10, 2020 | https://kevin.deldycke.com/2020/11/revert-hp-printer-ban-on-third-party-ink-cartridges/ | <a href="https://web.archive.org/web/*/https://kevin.deldycke.com/2020/11/revert-hp-printer-ban-on-third-party-ink-cartridges/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" role="main">
     <p>
      Hewlett
      <span>
       &amp;
      </span>
      Packard, the founders, had great lessons to teach us (managers in high-tech) about culture. I even
      <a href="https://github.com/kdeldycke/awesome-engineering-team-management/commit/de3e64647c911f78a37b3e54c7e46197acb061e1">
       quoted them
      </a>
      in my
      <a href="https://github.com/kdeldycke/awesome-engineering-team-management#readme">
       awesome list on engineering team management
      </a>
      .&nbsp;üë®‚Äçüíº
     </p>
     <p>
      <span>
       HP
      </span>
      Inc., the company, sucks. At least their
      <a href="https://news.ycombinator.com/item?id=25045024">
       printer division‚Äôs business model
      </a>
      . They recently pushed a
      <strong>
       firmware update to ban third-party compatible toner cartridges
      </strong>
      .&nbsp;üíî
     </p>
     <p>
      The timeline is&nbsp;straightforward:
     </p>
     <ul>
      <li>
       <p>
        2020, March: general lockdown. ü¶† I need a home office.
        <span>
         SO
        </span>
        is a scientist and spend her time printing papers for review. Got her an
        <a href="https://amzn.com/B073R2WVKB/?tag=kevideld-20">
         <span>
          HP
         </span>
         Color LaserJet M254dw
        </a>
        to keep her productive workflow (
        <a href="https://en.wikipedia.org/wiki/Publish_or_perish">
         publish or perish!
        </a>
        ).
       </p>
      </li>
      <li>
       <p>
        2020, October:
        <span>
         HP
        </span>
        release a new firmware (versioned
        <code>
         20201021
        </code>
        ).
       </p>
      </li>
     </ul>
     <p>
      <img alt="" src="https://kevin.deldycke.com/uploads/2020/hp-laserjet-printer-20201021-firmware.jpg">
     </p>
     <ul>
      <li>
       2020, November: my printer auto-upgrade. I‚Äôm welcomed with this
       <em>
        Supply Problem
        <a href="https://en.wikipedia.org/wiki/Screen_of_death">
         Screen of Death
        </a>
       </em>
       :
      </li>
     </ul>
     <p>
      <img alt="" src="https://kevin.deldycke.com/uploads/2020/hp-laserjet-printer-supply-problem-screen-of-death.jpg">
     </p>
     <p>
      I can‚Äôt print anymore.&nbsp;ü§Ø
     </p>
     <p>
      Eight months. My printer worked for only 8 months.&nbsp;üò§
     </p>
     <p>
      <span>
       OK
      </span>
      . It‚Äôs my fault. I should have spent more money buying certified‚Ñ¢ gear.&nbsp;üòë
     </p>
     <p>
      <img alt="" src="https://comdoc.com/wp-content/uploads/2019/01/copier-printer-meme-03.jpg">
     </p>
     <p>
      The solution is to travel back in time when things were working just great, and downgrade to the previous&nbsp;firmware.
     </p>
     <h2 id="disable-auto-upgrade">
      Disable Auto-Upgrade
      <a href="#disable-auto-upgrade" title="Permanent link">
       ¬∂
      </a>
     </h2>
     <p>
      We will start by stopping this madness for good, and prevent the printer from downloading a firmware behind our&nbsp;back.
     </p>
     <p>
      In the control panel, go to
      <code>
       Setup
      </code>
      &gt;
      <code>
       Service
      </code>
      &gt;
      <code>
       LaserJet Update
      </code>
      &gt;
      <code>
       Manage Updates
      </code>
      :
     </p>
     <p>
      <img alt="" src="https://kevin.deldycke.com/uploads/2020/hp-laserjet-printer-manage-updates-menu.jpg">
     </p>
     <p>
      Then set these&nbsp;options:
     </p>
     <ul>
      <li>
       Allow Downgrade:
       <code>
        Yes
       </code>
      </li>
      <li>
       Check Automatically:
       <code>
        Off
       </code>
      </li>
      <li>
       Prompt Before Install:
       <code>
        Always Prompt
       </code>
      </li>
      <li>
       Allow Updates:
       <code>
        No
       </code>
      </li>
     </ul>
     <p>
      I‚Äôm quite surprised downgrades are allowed. ü§î It seems out of character. Therefor, with my
      <em>
       Evil Product Manager
      </em>
      hat, I advise
      <span>
       HP
      </span>
      to monetize this feature under a monthly Enterprise Subscription of sort.&nbsp;üòà
     </p>
     <h2 id="download-old-firmware">
      Download Old Firmware
      <a href="#download-old-firmware" title="Permanent link">
       ¬∂
      </a>
     </h2>
     <p>
      I got lucky and found the previous
      <code>
       20200612
      </code>
      firmware referenced in
      <a href="https://ftp.hp.com/pub/networking/software/pfirmware/pfirmware.glf">
       <code>
        https://ftp.hp.com/pub/networking/software/pfirmware/pfirmware.glf
       </code>
      </a>
      .
     </p>
     <p>
      There you‚Äôll get a direct link to the
      <code>
       .rfu
      </code>
      file (Remote Firmware Update):
      <a href="http://ftp.hp.com/pub/networking/software/pfirmware/HP_Color_LaserJet_Pro_M254_dw_Printer_series_20200612.rfu">
       <code>
        http://ftp.hp.com/pub/networking/software/pfirmware/HP_Color_LaserJet_Pro_M254_dw_Printer_series_20200612.rfu
       </code>
      </a>
      .
     </p>
     <p>
      And just in case it disappear from its original location, here is a
      <a href="https://kevin.deldycke.com/uploads/2020/HP_Color_LaserJet_Pro_M254_dw_Printer_series_20200612.rfu">
       copy of
       <code>
        HP_Color_LaserJet_Pro_M254_dw_Printer_series_20200612.rfu
       </code>
      </a>
      .
     </p>
     <p>
      The checksum of that file&nbsp;is:
     </p>
     <div>
      <pre><span></span><code><span data-linenos="1 "></span><span>$</span> sha256sum ./HP_Color_LaserJet_Pro_M254_dw_Printer_series_20200612.rfu
<span data-linenos="2 "></span><span>91c7f51ceba2386f3b94dcb9da20c669ab10b1ee3a9b1e1f742c40091920188e</span>
</code></pre>
     </div>
     <h2 id="downgrade-firmware">
      Downgrade Firmware
      <a href="#downgrade-firmware" title="Permanent link">
       ¬∂
      </a>
     </h2>
     <p>
      Once you get the
      <code>
       .rfu
      </code>
      file, list all your printers from a macOS&nbsp;terminal:
     </p>
     <div>
      <pre><span></span><code><span data-linenos="1 "></span><span>$</span> lpstat -p -d
<span data-linenos="2 "></span><span>printer HP_Color_LaserJet_M254dw_0 is idle.  enabled since Fri Nov  6 17:47:06 2020</span>
<span data-linenos="3 "></span><span>system default destination: HP_Color_LaserJet_M254dw_0</span>
</code></pre>
     </div>
     <p>
      And run the firmware downgrade
      <span>
       CLI
      </span>
      :
     </p>
     <div>
      <pre><span></span><code><span data-linenos="1 "></span><span>$</span> lpr -P HP_Color_LaserJet_M254dw_0 /Users/kde/Downloads/HP_Color_LaserJet_Pro_M254_dw_Printer_series_20200612.rfu
</code></pre>
     </div>
     <p>
      Nothing gets printed to the&nbsp;console.
     </p>
     <p>
      I don‚Äôt know what happens here but it seems the
      <code>
       .rfu
      </code>
      file is pushed to the printer‚Äôs queue and then gets consumed as any other printable document. See,
      <a href="https://www.jsof-tech.com/unpacking-hp-firmware-updates-part-1/">
       the
       <span>
        RFU
       </span>
       file format is a matryoshka doll
      </a>
      embedding printing commands, encoded data and raw
      <span>
       NAND
      </span>
      code.
     </p>
     <p>
      After a minute  or two, the printers reboots and upgrades&nbsp;itself:
     </p>
     <p>
      <img alt="" src="https://kevin.deldycke.com/uploads/2020/hp-laserjet-printer-firmware-updating.jpg">
     </p>
     <p>
      And we‚Äôre back in business!&nbsp;ü•≥
     </p>
     <p>
      A detour via
      <code>
       Setup
      </code>
      &gt;
      <code>
       Service
      </code>
      &gt;
      <code>
       Firmware Datecode
      </code>
      menu confirm we‚Äôre running the the previous&nbsp;firmware:
     </p>
     <p>
      <img alt="" src="https://kevin.deldycke.com/uploads/2020/hp-laserjet-printer-20200612-firmware.jpg">
     </p>
     <h2 id="printer-security">
      Printer Security
      <a href="#printer-security" title="Permanent link">
       ¬∂
      </a>
     </h2>
     <p>
      In my research for this article, I found out about
      <a href="https://github.com/RUB-NDS/PRET">
       <span>
        PRET
       </span>
       , a printer exploitation toolkit
      </a>
      . It‚Äôs a brilliant tool, in a malignant way. It allows for pen-testing and hacking, using the same vectors as the firmware update.&nbsp;ü§´
     </p>
     <p>
      I‚Äôll probably play with it in the future. For fun, but also to try enhance the security of the printer. In the mean time, I guess a password is the bare minimum. And if my printer get kidnapped by a cyber gang, I now have a way to restore my printer‚Äôs firmware!&nbsp;üò¨
     </p>
     <h3>
      Related content
     </h3>
     
     
    </div></div>]]>
            </description>
            <link>https://kevin.deldycke.com/2020/11/revert-hp-printer-ban-on-third-party-ink-cartridges/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044597</guid>
            <pubDate>Tue, 10 Nov 2020 10:59:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Plant Tweets]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25044512">thread link</a>) | @luu
<br/>
November 10, 2020 | http://sarabee.github.io/2020/04/19/plant-tweets-part-1/ | <a href="https://web.archive.org/web/*/http://sarabee.github.io/2020/04/19/plant-tweets-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="http://sarabee.github.io/images/monstera.jpg" width="180">
This past week my monstera deliciosa, a lovely tropical houseplant, <a href="https://twitter.com/monsterasays">started to
tweet</a>. This is the first of two posts on this here skeleton of a blog showing
how I helped it get its voice out into the internet. First, we‚Äôll take a look at the hardware and code
needed to read my plant‚Äôs mind; Part 2 will look at how those thoughts are
broadcast to the world. These posts should make sense even if you‚Äôve never
played with hardware before, so please @ me
(<a href="https://twitter.com/SaraBee">@SaraBee</a>) if you have questions!</p>

<p>A month ago, I was shopping for a cheap soil moisture meter to help me care
for my growing army of plants. In my search results were hits for the simple
mechanical sensors I was looking for, but also inexpensive hardware sensors for use in
projects with, for example, Arduinos. Of course, my first thought was: ‚ÄúMy
plant needs to connect to the internet.‚Äù</p>

<p><img src="http://sarabee.github.io/images/tweets.jpg" width="500"></p>

<p>In researching which sensors to buy, I saw that there were two types
available: resistive and capacitive. Resistive sensors work by measuring the
conductivity of the soil in which it is placed by running electricity through
it, and if you remember back to
high school science class you may remember something something electrolysis
something something ionization (that‚Äôs about where I‚Äôm at) ‚Äì basically the
electricty creates a chemical reaction with the water and metal that removes copper from the sensor
over time, eventually causing it to stop working. Capacitive sensors, on the other hand, do not have exposed
electrodes, and so should not fail due to electrolysis over time. I really
enjoyed <a href="https://www.youtube.com/watch?v=udmJyncDvw0">this video</a>, which gets into how each sensor type works and
demonstrates this particular failure mode of resistive sensors. Needless to
say, I went capacitive, since I was planning to leave my sensor in-place over
long periods of time.</p>

<p><img src="http://sarabee.github.io/images/sensor.jpg" width="500"></p>

<p>The sensor on its own wouldn‚Äôt really get me anywhere, all it does is output
an analog value (like 273, or 418, or 550) for something else to read. I had
already set up a <a href="https://www.raspberrypi.org/products/raspberry-pi-3-model-b/">Raspberry
Pi</a> as an always-on linux server that I use as my
dev box, so initially I was interested in connecting the sensor straight to
the rpi‚Äôs GPIO pins (general-purpose input/output pins, for use with sensors
and other stuff). One small problem: rpi‚Äôs GPIO pins only work with digital
input and output, not analog like my sensor‚Äôs output. If I plugged the sensor directly into my rpi, it wouldn‚Äôt
be able to make sense of the signal.</p>

<p><img src="http://sarabee.github.io/images/adc.jpg" width="180">
My first thought was to use a small, inexpensive component in between the two
called an ADC - analog-to-digital converter - which would convert the sensor‚Äôs
signal into something that my rpi could use. I bought two of these when
I bought my sensor, and got as far as soldering header pins on them so that
I could seat them on a breadboard before realising that they were both
duds. Bummer!</p>

<p>All was not lost, however. In my bin of hardware toys was an <a href="https://store.arduino.cc/usa/arduino-uno-rev3">Arduino
Uno</a>,
which was a good fit for this project for a number of reasons. First, Arduinos
do have analog connections built right in, meaning I wouldn‚Äôt need any extra
components, I could plug the sensor straight into the Arduino. Second, while
the Arduino Uno doesn‚Äôt have a way to connect to the internet itself, it does have
a USB port (more on this later).</p>

<p>Arduinos run small snippets of code called Sketches, which are flashed into
their onboard memory by the tinkerer (that‚Äôs me) and can run continuously as long
as the board is receiving power. I plugged my sensor into my Arduino‚Äôs first analog pin (number 0), and so the sketch to read its output once every 100ms and write it
out to the serial port looks like
this:</p>

<pre><code>void setup() {
        Serial.begin(9600); // open serial port, set the baud rate as 9600 bps
}
void loop() {
        int val;
        val = analogRead(0); //connect sensor to Analog 0
        Serial.println(val); //print the value to serial port
        delay(100);
}
</code></pre>

<p>Something that might not make sense yet is this serial business. What‚Äôs
a serial port, and why is the sketch writing to it? Serial communciation is
a simple way for two computers (or components, or circuits) to talk to
each other, one bit at a time. The baud rate is how many bits are sent per
second, and both sides need to agree so they each know how to receive bits from the other. I found <a href="https://learn.sparkfun.com/tutorials/serial-communication/all">this article over on SparkFun</a> to
be a really great deep-dive on how all of this works. In the case of my Arduino, the serial
input and output can be done via pins (like how the sensor is hooked up) or,
handily, over USB (which, remember, is short for universal <em>serial</em> bus).</p>

<p>Plugging the Arduino into my Raspberry Pi via USB gets the signal from my
plant into Linux land, which opens up all kinds of possibilities for using the
data in code. In <a href="http://sarabee.github.io/2020/05/10/plant-tweets-part-2/">Part 2</a>, I‚Äôll talk through how I explored just one of those
possibilities, hooking this mess up to Twitter.</p>

</div></div>]]>
            </description>
            <link>http://sarabee.github.io/2020/04/19/plant-tweets-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044512</guid>
            <pubDate>Tue, 10 Nov 2020 10:43:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Revisit Your First GitHub Commit Ever]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25044482">thread link</a>) | @amitmerchant
<br/>
November 10, 2020 | https://www.amitmerchant.com/your-first-commit-ever/ | <a href="https://web.archive.org/web/*/https://www.amitmerchant.com/your-first-commit-ever/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>
              <h3>Revisit Your First GitHub Commit Ever!</h3>
            </p>
          </div></div>]]>
            </description>
            <link>https://www.amitmerchant.com/your-first-commit-ever/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044482</guid>
            <pubDate>Tue, 10 Nov 2020 10:37:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The myriad meanings of pwd in Unix systems]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 63 (<a href="https://news.ycombinator.com/item?id=25044131">thread link</a>) | @quyleanh
<br/>
November 10, 2020 | https://qmacro.org/2020/11/08/the-meaning-of-pwd-in-unix-systems/ | <a href="https://web.archive.org/web/*/https://qmacro.org/2020/11/08/the-meaning-of-pwd-in-unix-systems/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>Last week I ran a poll on Twitter to see what people considered with respect to the meaning of ‚Äòpwd‚Äô in Unix and Linux systems. The results were varied, for perhaps good reason.</em></p>

<p>At the end of Oct 2020 I ran a <a href="https://twitter.com/qmacro/status/1322567992551624705">brief poll on Twitter</a>, on which 82 people voted. Here‚Äôs that poll, and the results. They‚Äôre quite mixed, which at first might seem surprising. But there are reasons for that, as we‚Äôll find out.</p>

<p><img src="https://qmacro.org/content/images/2020/11/twitter-poll-pwd.png" alt="Poll on Twitter: &quot;Fun Saturday afternoon shell poll. In Unix (and Linux), what do you think the P in $PWD (or pwd) stand for?&quot;"></p>

<p><strong>Print working directory</strong></p>

<p>The most popular option was ‚Äúprint working directory‚Äù. At first sight it seems logical: ‚Äúprint out the current working directory, i.e. where I am right now‚Äù. Moreover, the description in various versions of the manual for <code>pwd</code> help to drive home that notion. Typically we see sentences like ‚Äú<a href="https://linux.die.net/man/1/pwd">print name of current/working directory</a>‚Äù or ‚Äú<a href="https://www.mankier.com/1/pwd">print the current directory</a>‚Äù.</p>

<p>But there are lots of commands that print stuff, and are described in that way too. Take the <code>id</code> command. Here‚Äôs what one man page says: ‚Äú<a href="https://man7.org/linux/man-pages/man1/id.1.html">print real and effective user and group IDs</a>‚Äù. There‚Äôs ‚Äúprint‚Äù again. But the command isn‚Äôt <code>pid</code>, it‚Äôs <code>id</code>. When you think about it, many, many commands in Unix send information to STDOUT, i.e. to the terminal. That‚Äôs sort of the point of many of them.</p>

<p>This time arguably only superficially definitive, it would seem, the Wikipedia entry states, on the <a href="https://en.wikipedia.org/wiki/Pwd">page for <code>pwd</code></a>: ‚Äúthe pwd command (print working directory) writes the full pathname of the current working directory to the standard output‚Äù. As if to underline the hopeful authority of this statement, there are five (!) footnotes that supposedly link to resources that back this up.</p>

<p>Unfortunately, the first footnote points to a Wayback Machine copy of the <a href="https://web.archive.org/web/20050520231659/http://cm.bell-labs.com/7thEdMan/v7vol1.pdf">UNIX PROGRAMMERS MANUAL - Seventh Edition, Volume 1 - January, 1979</a>, wherein there are actually zero references to <code>pwd</code> being short for ‚Äúprint working directory‚Äù:</p>

<p><img src="https://qmacro.org/content/images/2020/11/programmers-manual-pwd.png" alt="excerpt from UNIX PROGRAMMERS MANUAL on pwd"></p>

<p>I don‚Äôt know about you, but this historic document carries more weight for me than other sources I‚Äôve come across, and it only serves here to undermine the credibility of the Wikipedia entry.</p>

<p>The rest of the footnote links seem dubious at best, except for the one pointing to the <a href="https://www.gnu.org/software/coreutils/manual/coreutils.html#pwd-invocation">GNU Coreutils manual on pwd</a> which has it as ‚Äúprint working directory‚Äù. But everything else I‚Äôve seen so far makes me think that this is a misunderstanding that has spread for obvious and innocent reasons. In addition, the one footnote in the Wikipedia page that is not used to back this claim up is a pointer to <a href="https://pubs.opengroup.org/onlinepubs/9699919799/utilities/pwd.html">The Open Group Base Specifications Issue 7, 2018 edition‚Äôs information on pwd</a>, which almost seems like it‚Äôs actually avoiding using the word ‚Äúprint‚Äù at all: ‚Äúreturn working directory name‚Äù ‚Ä¶ ‚ÄúThe pwd utility shall write to standard output an absolute pathname of the current working directory, which does not contain the filenames dot or dot-dot.‚Äù. Very specific, very not-print.</p>

<p>So I‚Äôm thinking that ‚Äúprint working directory‚Äù isn‚Äôt what <code>pwd</code> stands for. In fact, ‚Äúprint working directory‚Äù may be common to some man pages, but on this macOS machine, with its <a href="https://en.wikipedia.org/wiki/Berkeley_Software_Distribution">BSD</a> heritage, we have, instead: ‚Äúpwd ‚Äì return working directory name‚Äù. Moreover, it goes on to say ‚ÄúThe pwd utility writes the absolute pathname of the current working directory to the standard output‚Äù.</p>

<p><strong>Pathname of working directory</strong></p>

<p>So perhaps it really is ‚Äúpathname of working directory‚Äù. That would, at least to me, make more sense. Not only does it eschew the redundancy of ‚Äúprint‚Äù, it also is more specific about the output - if I‚Äôm in <code>/home/dja/</code> for example, then invoking pwd will tell me that, i.e. where I am, including the whole path, and not just <code>dja</code>:</p>



<p><strong>Process working directory</strong></p>

<p>As for the other options, I do favour ‚Äúprocess working directory‚Äù, mostly because it makes a lot of sense to me; every process in Unix has the concept of a current working directory, and that‚Äôs exactly what I‚Äôm asking for when I‚Äôm in my shell process and enter <code>pwd</code> - there‚Äôs a part in the video <a href="https://youtu.be/hgFBRZmwpSM?t=165">Unix terminals and shells</a> that explains this very well.</p>

<p>I‚Äôd love to be able to point to some old Unix sources that definitively explain the answer, but unfortunately that search has come up with very little - the <code>pwd</code> source in both the <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V5/usr/source/s2/pwd.c">5th</a> and <a href="https://github.com/yisooan/unix-v6/blob/master/source/s2/pwd.c">6th</a> Editions of Unix shed no light on this whatsoever.</p>

<p><strong>Present working directory</strong></p>

<p>What about ‚Äúpresent working directory‚Äù? Well, that option seems to have legs, in the form of the Korn shell. While <a href="https://northstar-www.dartmouth.edu/doc/solaris-forte/ipe-help/dbx/dbx88cc.html">one source</a> implies that the answer might well be ‚Äúpathname of current working directory‚Äù, in that <code>pwd</code> just emits the value of the <code>$PWD</code> environment variable (and a variable called ‚Äúprint working directory‚Äù makes no sense at all) ‚Ä¶ it would seem that in ksh-land, at least, ‚Äúpresent working directory‚Äù is what <code>pwd</code> represents. Take, for example, the <a href="https://osr507doc.xinuos.com/en/man/html.C/ksh.C.html">ksh man page</a> which states ‚ÄúPWD - The present working directory set by the cd command‚Äù.</p>

<p>There‚Äôs a ton of discussion, both direct and indirect, on this very question. Take for example these two entries in the Unix &amp; Linux Stack Exchange forum: <a href="https://unix.stackexchange.com/questions/399026/etymology-of-pwd">Etymology of $PWD</a> and <a href="https://unix.stackexchange.com/questions/174990/what-is-pwd-vs-current-working-directory">What is $PWD? (vs current working directory)</a>. Of course, perhaps the definitive answer will never be found, as computing history is nothing if not varied and prone to forking.</p>

<p><strong>Multics and print_wdir</strong></p>

<p>Talking of history, we could go further back to pre-Unix roots, in the form of Multics, which indirectly gave rise to Unix (originally ‚ÄúUnics‚Äù). In the <a href="https://multicians.org/multics-commands.html">list of Multics Commands</a>, we see, nestled amongst other similarly named commands, something that jumps out at us:</p>

<div><div><pre><code>print_mail (pm)	display mail in a mailbox
print_messages (pm)	display interactive messages in a mailbox
print_motd (pmotd)	display message of the day (source)
print_proc_auth (ppa)	display process's sensitivity level and compartments
print_request_types (prt)	display list of I/O daemon request types
print_search_paths (psp)	display search paths
print_search_rules (psr)	display ready messages
print_wdir (pwd)	display working directory
</code></pre></div></div>

<p>There‚Äôs <code>pwd</code>, and in fact, just like its sibling <code>pmotd</code>, for example, which is short for <code>print_motd</code>, it‚Äôs short for <code>print_wdir</code>. Now, given the context of the original poll being set to Unix and Linux, perhaps we must discount this information. But as someone who is fascinated with Unix history in general - how can I?</p>

<p>I guess there are few things to conclude. The history is rich and diverse, and maybe we‚Äôll never know for sure. Perhaps, in fact, the answer will depend on whom we ask. In the grand scheme of things, it doesn‚Äôt really matter ‚Ä¶ but to those who delight in minutiae, it‚Äôs a fun topic worth exploring.</p>

  </div>

</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://qmacro.org/2020/11/08/the-meaning-of-pwd-in-unix-systems/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044131</guid>
            <pubDate>Tue, 10 Nov 2020 09:30:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Automation Part 4: Who made it, why, and in what context?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25044097">thread link</a>) | @nonoesp
<br/>
November 10, 2020 | https://sketch.nono.ma/who-made-it-why-and-in-what-context | <a href="https://web.archive.org/web/*/https://sketch.nono.ma/who-made-it-why-and-in-what-context">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    <div>

    
          <svg data-name="sketch.nono.ma" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 600 153"><defs></defs><title>Sketch.Nono.MA</title><path d="M182.51,57.42v1.29a8.6,8.6,0,0,0,.48,3.47,1.85,1.85,0,0,0,1.82,1c1.34,0,2-1.05,2-3.14a8,8,0,0,0-.12-1.42,6.27,6.27,0,0,0-.44-1.38,11.32,11.32,0,0,0-.84-1.52c-.36-.54-.81-1.17-1.36-1.9l-2.22-3.23c-.71-1-1.3-1.92-1.77-2.72a18.44,18.44,0,0,1-1.13-2.28,10,10,0,0,1-.61-2,11.93,11.93,0,0,1-.17-2,6.9,6.9,0,0,1,1.79-5,6.43,6.43,0,0,1,4.84-1.85,6,6,0,0,1,3.86,1.23,5.77,5.77,0,0,1,2,3.43c.06.28.11.53.14.74a6.16,6.16,0,0,1,.07.69c0,.25,0,.57,0,1v1.57l-4.4.43c0-.83,0-1.42,0-1.79a6.37,6.37,0,0,0-.12-1.07c-.16-1.33-.78-2-1.86-2-1.24,0-1.86,1-1.86,3a9.55,9.55,0,0,0,.07,1.26,4.32,4.32,0,0,0,.39,1.21,16.05,16.05,0,0,0,1,1.66l1.77,2.66,2.27,3.23a21.45,21.45,0,0,1,2.4,4.58,12.66,12.66,0,0,1,.84,4.34,6.61,6.61,0,0,1-1.7,4.89,6.53,6.53,0,0,1-4.85,1.71,6.34,6.34,0,0,1-6.55-4.73,14.33,14.33,0,0,1-.29-3.26v-.83a8.51,8.51,0,0,1,.05-.88Z"></path><path d="M211.28,66.84h-4.69l-3.33-15L201.32,57v9.8h-4.54V35.11h4.54V47.05l4.4-11.94h4.6l-4.07,10.71Z"></path><path d="M226.51,35.11V39.3h-6.38v8.8h4.45v4.18h-4.45V62.65h6.77v4.19H215.59V35.11Z"></path><path d="M234.59,39.3h-4.21V35.11h13.15V39.3h-4.4V66.84h-4.54Z"></path><path d="M259.92,55.52c0,.85.06,1.51.08,2s0,.91,0,1.36q0,8.46-6.53,8.46-6.33,0-6.33-7.61V42.25q0-7.61,6.33-7.61Q260,34.64,260,43V44a13.8,13.8,0,0,1-.1,1.45h-4.54a12,12,0,0,0,.09-1.21v-1a10.26,10.26,0,0,0-.4-3.54,1.54,1.54,0,0,0-1.58-.93,1.44,1.44,0,0,0-1.43.69,6.93,6.93,0,0,0-.36,2.77V59.67a6.93,6.93,0,0,0,.36,2.77,1.44,1.44,0,0,0,1.43.69,1.56,1.56,0,0,0,1.56-.88,9,9,0,0,0,.42-3.36c0-.53,0-1,0-1.49s0-1.09-.07-1.88Z"></path><path d="M270.13,52.28V66.84h-4.55V35.07h4.55v13h3.57v-13h4.55V66.84H273.7V52.28Z"></path><path d="M283.91,62.08h4.54v4.76h-4.54Z"></path><path d="M309.34,66.84h-4.55l-5.22-16.65V66.84H295V35.11h3.85l5.91,18.7V35.11h4.55Z"></path><path d="M328.34,58.75c0,1,0,1.73,0,2.33s-.08,1.12-.14,1.55a4.63,4.63,0,0,1-.29,1.09,7.46,7.46,0,0,1-.53,1,5.56,5.56,0,0,1-2.25,1.92,7.4,7.4,0,0,1-6.24,0,5.56,5.56,0,0,1-2.25-1.92,7.46,7.46,0,0,1-.53-1,5.11,5.11,0,0,1-.31-1.09,10.43,10.43,0,0,1-.15-1.55c0-.6,0-1.38,0-2.33V43.15c0-.95,0-1.73,0-2.33a10.28,10.28,0,0,1,.15-1.54,5.21,5.21,0,0,1,.31-1.1,7.39,7.39,0,0,1,.53-1,5.63,5.63,0,0,1,2.25-1.88,7.4,7.4,0,0,1,6.24,0,5.63,5.63,0,0,1,2.25,1.88,7.39,7.39,0,0,1,.53,1,4.72,4.72,0,0,1,.29,1.1c.06.42.11.94.14,1.54s0,1.38,0,2.33ZM323.8,41.38a3.47,3.47,0,0,0-.43-2,1.6,1.6,0,0,0-1.41-.6,1.62,1.62,0,0,0-1.39.6,3.29,3.29,0,0,0-.45,2V60.57a3.51,3.51,0,0,0,.42,2,2,2,0,0,0,2.81,0,3.33,3.33,0,0,0,.45-2Z"></path><path d="M348.84,66.84H344.3l-5.23-16.65V66.84h-4.54V35.11h3.85l5.92,18.7V35.11h4.54Z"></path><path d="M367.84,58.75c0,1,0,1.73,0,2.33s-.08,1.12-.14,1.55a4.63,4.63,0,0,1-.29,1.09,7.46,7.46,0,0,1-.53,1,5.56,5.56,0,0,1-2.25,1.92,7.4,7.4,0,0,1-6.24,0,5.56,5.56,0,0,1-2.25-1.92,7.46,7.46,0,0,1-.53-1,5.11,5.11,0,0,1-.31-1.09,10.43,10.43,0,0,1-.15-1.55c0-.6,0-1.38,0-2.33V43.15c0-.95,0-1.73,0-2.33a10.28,10.28,0,0,1,.15-1.54,5.21,5.21,0,0,1,.31-1.1,7.39,7.39,0,0,1,.53-1,5.63,5.63,0,0,1,2.25-1.88,7.4,7.4,0,0,1,6.24,0,5.63,5.63,0,0,1,2.25,1.88,7.39,7.39,0,0,1,.53,1,4.72,4.72,0,0,1,.29,1.1c.06.42.11.94.14,1.54s0,1.38,0,2.33ZM363.3,41.38a3.38,3.38,0,0,0-.43-2,1.6,1.6,0,0,0-1.41-.6,1.62,1.62,0,0,0-1.39.6,3.29,3.29,0,0,0-.45,2V60.57a3.42,3.42,0,0,0,.43,2,1.62,1.62,0,0,0,1.41.59,1.64,1.64,0,0,0,1.39-.59,3.33,3.33,0,0,0,.45-2Z"></path><path d="M374.37,62.08h4.55v4.76h-4.55Z"></path><path d="M397.19,35.11h5.42V66.84h-3.87V44.44L395,66.84H393l-3.77-22.4v22.4h-3.77V35.11h5.32L394,50.9Z"></path><path d="M412.62,66.84h-4.36l4.4-31.73h5.81l4.2,31.73h-4.4l-.82-7.14h-4.06Zm2.8-26-1.55,14.7H417Z"></path><path d="M96.84,97.69c-1.56,0-2.5.76-2.5,1.8s1.21,1.63,2.34,1.9l1.3.32c2.08.5,4,1.59,4.06,4s-1.93,4.09-5.24,4.09-5.26-1.54-5.36-4.29H93.9c.1,1.45,1.31,2.15,2.88,2.15s2.75-.79,2.76-2-1-1.53-2.48-1.91l-1.58-.41c-2.27-.58-3.68-1.72-3.68-3.71,0-2.44,2.17-4.07,5.07-4.07s4.93,1.65,5,4H99.44C99.32,98.38,98.33,97.69,96.84,97.69Z"></path><path d="M103.78,95.76h2.44v7.61h.17l3.73-4.16H113l-4,4.47,4.25,5.89h-2.93l-3.16-4.43-.9,1v3.48h-2.44Z"></path><path d="M113.33,104.45c0-3.19,1.94-5.37,4.91-5.37,2.55,0,4.73,1.6,4.73,5.23v.75h-7.21a2.55,2.55,0,0,0,2.64,2.81,2.16,2.16,0,0,0,2.19-1.33l2.28.25c-.43,1.8-2.09,3-4.5,3C115.24,109.77,113.33,107.7,113.33,104.45Zm7.3-1a2.3,2.3,0,0,0-2.36-2.43,2.5,2.5,0,0,0-2.51,2.43Z"></path><path d="M129.83,101.1h-2v5.36c0,1,.49,1.2,1.11,1.2a3.12,3.12,0,0,0,.71-.1l.41,1.91a4.8,4.8,0,0,1-1.43.24c-1.84.06-3.26-.9-3.24-2.85V101.1h-1.47V99.21h1.47V96.73h2.44v2.48h2Z"></path><path d="M131,104.43c0-3.16,1.91-5.35,5-5.35,2.53,0,4.28,1.47,4.45,3.72H138a2,2,0,0,0-2.09-1.75c-1.5,0-2.51,1.25-2.51,3.34s1,3.39,2.51,3.39A2,2,0,0,0,138,106h2.33c-.18,2.2-1.84,3.74-4.44,3.74C132.82,109.77,131,107.57,131,104.43Z"></path><path d="M144.42,109.57H142V95.76h2.39V101h.12a3,3,0,0,1,3.09-1.89c2.15,0,3.56,1.39,3.56,3.9v6.59H148.7v-6.22a2,2,0,0,0-2-2.21,2.15,2.15,0,0,0-2.24,2.36Z"></path><path d="M152.8,104.45c0-3.19,1.94-5.37,4.91-5.37,2.55,0,4.73,1.6,4.73,5.23v.75h-7.21a2.55,2.55,0,0,0,2.64,2.81,2.16,2.16,0,0,0,2.19-1.33l2.28.25c-.43,1.8-2.09,3-4.5,3C154.71,109.77,152.8,107.7,152.8,104.45Zm7.3-1a2.3,2.3,0,0,0-2.36-2.43,2.49,2.49,0,0,0-2.51,2.43Z"></path><path d="M170.09,102.19a1.81,1.81,0,0,0-1.91-1.29c-1,0-1.79.48-1.78,1.18s.41,1,1.46,1.21l1.77.37c2,.43,2.9,1.33,2.91,2.81,0,2-1.83,3.3-4.42,3.3s-4.15-1.12-4.45-3l2.38-.23a1.86,1.86,0,0,0,2.06,1.41c1.16,0,1.93-.53,1.93-1.24s-.45-1-1.4-1.18l-1.76-.37c-2-.41-2.92-1.41-2.92-2.92,0-1.92,1.69-3.14,4.19-3.14s3.83,1.12,4.17,2.87Z"></path><path d="M178,106.66c0-2.33,1.92-2.93,3.93-3.15,1.83-.19,2.57-.22,2.57-.93v0c0-1-.62-1.59-1.76-1.59a2.06,2.06,0,0,0-2.12,1.31l-2.28-.32c.54-1.89,2.21-2.86,4.39-2.86,2,0,4.21.82,4.21,3.56v6.93h-2.35v-1.42h-.08a3.21,3.21,0,0,1-3,1.63C179.52,109.78,178,108.7,178,106.66Zm6.5-.8v-1.23a7.34,7.34,0,0,1-2.24.51c-1.09.15-1.9.55-1.9,1.48s.72,1.37,1.74,1.37A2.21,2.21,0,0,0,184.53,105.86Z"></path><path d="M191.5,109.57h-2.45V99.21h2.34V101h.12a3.11,3.11,0,0,1,3.09-1.89c2.14,0,3.55,1.41,3.55,3.9v6.59H195.7v-6.22a2,2,0,0,0-2-2.21,2.12,2.12,0,0,0-2.19,2.36Z"></path><path d="M199.83,104.41c0-3.46,1.89-5.33,4.28-5.33a3.08,3.08,0,0,1,3,1.84h.1V95.76h2.45v13.81h-2.4v-1.63h-.15a3.13,3.13,0,0,1-3,1.81C201.66,109.75,199.83,107.82,199.83,104.41Zm7.39,0c0-2-.86-3.31-2.44-3.31s-2.46,1.38-2.46,3.31.85,3.36,2.46,3.36S207.22,106.4,207.22,104.39Z"></path><path d="M222.15,102.19a1.81,1.81,0,0,0-1.91-1.29c-1,0-1.79.48-1.78,1.18s.41,1,1.46,1.21l1.77.37c1.95.43,2.9,1.33,2.91,2.81,0,2-1.83,3.3-4.42,3.3s-4.14-1.12-4.45-3l2.38-.23a1.86,1.86,0,0,0,2.06,1.41c1.16,0,1.93-.53,1.93-1.24s-.45-1-1.4-1.18l-1.76-.37c-2-.41-2.92-1.41-2.92-2.92,0-1.92,1.7-3.14,4.19-3.14s3.83,1.12,4.17,2.87Z"></path><path d="M231.42,101.1h-2v5.36c0,1,.49,1.2,1.11,1.2a3.12,3.12,0,0,0,.71-.1l.41,1.91a4.8,4.8,0,0,1-1.43.24c-1.84.06-3.25-.9-3.24-2.85V101.1h-1.47V99.21h1.47V96.73h2.44v2.48h2Z"></path><path d="M232.53,104.43c0-3.21,1.93-5.35,5-5.35s5,2.14,5,5.35-1.93,5.34-5,5.34S232.53,107.64,232.53,104.43Zm7.45,0c0-1.9-.82-3.42-2.47-3.42s-2.51,1.52-2.51,3.42.83,3.39,2.51,3.39S240,106.32,240,104.43Z"></path><path d="M244.15,99.21h2.36v1.73h.11a2.6,2.6,0,0,1,2.56-1.88,5.79,5.79,0,0,1,.87.07v2.25a4.54,4.54,0,0,0-1.13-.14,2.21,2.21,0,0,0-2.33,2.24v6.09h-2.44Z"></path><path d="M251.11,96.42a1.42,1.42,0,1,1,1.42,1.32A1.38,1.38,0,0,1,251.11,96.42Zm.19,2.79h2.44v10.36H251.3Z"></path><path d="M255.43,104.45c0-3.19,1.94-5.37,4.9-5.37,2.55,0,4.74,1.6,4.74,5.23v.75h-7.22a2.55,2.55,0,0,0,2.64,2.81,2.17,2.17,0,0,0,2.2-1.33l2.28.25c-.44,1.8-2.09,3-4.51,3C257.34,109.77,255.43,107.7,255.43,104.45Zm7.3-1a2.31,2.31,0,0,0-2.36-2.43,2.48,2.48,0,0,0-2.51,2.43Z"></path><path d="M272.72,102.19a1.82,1.82,0,0,0-1.91-1.29c-1,0-1.8.48-1.79,1.18s.41,1,1.46,1.21l1.77.37c2,.43,2.91,1.33,2.92,2.81,0,2-1.84,3.3-4.43,3.3s-4.14-1.12-4.44-3l2.38-.23a1.85,1.85,0,0,0,2.05,1.41c1.16,0,1.93-.53,1.93-1.24s-.44-1-1.39-1.18l-1.77-.37c-2-.41-2.92-1.41-2.91-2.92,0-1.92,1.69-3.14,4.18-3.14s3.84,1.12,4.17,2.87Z"></path><path d="M281.25,95.76h2.44v5.16h.1a3.09,3.09,0,0,1,3-1.84c2.4,0,4.28,1.87,4.28,5.33s-1.83,5.34-4.27,5.34a3.14,3.14,0,0,1-3-1.81h-.14v1.63h-2.4Zm4.83,12c1.61,0,2.46-1.42,2.46-3.36s-.83-3.31-2.46-3.31-2.44,1.3-2.44,3.31S284.52,107.75,286.08,107.75Z"></path><path d="M292.27,113.33l.57-2c1.07.31,1.77.22,2.23-.92l.25-.66-3.76-10.58h2.59l2.39,7.83h.1l2.4-7.83h2.59l-4.18,11.71a3.65,3.65,0,0,1-3.64,2.68A4.33,4.33,0,0,1,292.27,113.33Z"></path><path d="M318.74,109.57h-2.23l-6.5-9.41h-.12v9.41h-2.5V95.76h2.24l6.5,9.41h.12V95.76h2.49Z"></path><path d="M320.53,104.43c0-3.21,1.93-5.35,5-5.35s5,2.14,5,5.35-1.93,5.34-5,5.34S320.53,107.64,320.53,104.43Zm7.45,0c0-1.9-.82-3.42-2.47-3.42s-2.5,1.52-2.5,3.42.82,3.39,2.5,3.39S328,106.32,328,104.43Z"></path><path d="M334.59,109.57h-2.44V99.21h2.33V101h.12a3.11,3.11,0,0,1,3.09-1.89c2.14,0,3.56,1.41,3.55,3.9v6.59H338.8v-6.22a2,2,0,0,0-2-2.21,2.12,2.12,0,0,0-2.19,2.36Z"></path><path d="M342.91,104.43c0-3.21,1.93-5.35,5-5.35s5,2.14,5,5.35-1.92,5.34-5,5.34S342.91,107.64,342.91,104.43Zm7.45,0c0-1.9-.82-3.42-2.48-3.42s-2.5,1.52-2.5,3.42.83,3.39,2.5,3.39S350.36,106.32,350.36,104.43Z"></path><path d="M362,95.76l4.1,10h.16l4.1-10h3.06v13.81h-2.4v-9.49h-.13l-3.81,9.45h-1.8l-3.81-9.47h-.13v9.51H359V95.76Z"></path><path d="M375.47,106.66c0-2.33,1.92-2.93,3.93-3.15,1.83-.19,2.56-.22,2.56-.93v0c0-1-.62-1.59-1.75-1.59a2.06,2.06,0,0,0-2.12,1.31l-2.28-.32c.54-1.89,2.21-2.86,4.39-2.86,2,0,4.21.82,4.21,3.56v6.93h-2.35v-1.42H382a3.21,3.21,0,0,1-3,1.63C377,109.78,375.47,108.7,375.47,106.66Zm6.5-.8v-1.23a7.41,7.41,0,0,1-2.24.51c-1.09.15-1.91.55-1.91,1.48s.73,1.37,1.75,1.37A2.21,2.21,0,0,0,382,105.86Z"></path><path d="M386.49,99.21h2.37v1.73H389a2.58,2.58,0,0,1,2.55-1.88,5.92,5.92,0,0,1,.88.07v2.25a4.54,4.54,0,0,0-1.13-.14,2.21,2.21,0,0,0-2.34,2.24v6.09h-2.44Z"></path><path d="M399.47,101.1h-2.05v5.36c0,1,.5,1.2,1.11,1.2a3.33,3.33,0,0,0,.72-.1l.41,1.91a4.88,4.88,0,0,1-1.44.24c-1.83.06-3.25-.9-3.24-2.85V101.1h-1.47V99.21H395V96.73h2.44v2.48h2.05Z"></path><path d="M401.13,99.21h2.45v10.36h-2.45Zm1.8-4.44h2.39l-2.07,3.08h-1.83Z"></path><path d="M408.15,109.57h-2.44V99.21H408V101h.12a3.11,3.11,0,0,1,3.09-1.89c2.14,0,3.55,1.41,3.55,3.9v6.59h-2.44v-6.22a2,2,0,0,0-2-2.21,2.12,2.12,0,0,0-2.19,2.36Z"></path><path d="M416.47,104.45c0-3.19,1.93-5.37,4.9-5.37,2.55,0,4.73,1.6,4.73,5.23v.75h-7.21a2.55,2.55,0,0,0,2.64,2.81,2.16,2.16,0,0,0,2.19-1.33l2.28.25c-.43,1.8-2.09,3-4.5,3C418.38,109.77,416.47,107.7,416.47,104.45Zm7.29-1A2.3,2.3,0,0,0,421.4,101a2.5,2.5,0,0,0-2.51,2.43Z"></path><path d="M427.66,108l5.34-6.7v-.08h-5.17v-2H436v1.67l-5.09,6.58v.09h5.26v2h-8.5Z"></path><path d="M441.63,109.57l4.87-13.81h3.08l4.87,13.81h-2.67l-1.14-3.4h-5.2l-1.14,3.4Zm8.33-5.41-1.87-5.57H448l-1.87,5.57Z"></path><path d="M458.24,109.57h-2.45V95.76h2.45Z"></path><path d="M459.92,104.43c0-3.21,1.93-5.35,5-5.35s5,2.14,5,5.35-1.93,5.34-5,5.34S459.92,107.64,459.92,104.43Zm7.45,0c0-1.9-.82-3.42-2.47-3.42s-2.5,1.52-2.5,3.42.82,3.39,2.5,3.39S467.37,106.32,467.37,104.43Z"></path><path d="M474,109.57h-2.44V99.21h2.33V101H474a3.11,3.11,0,0,1,3.09-1.89c2.14,0,3.55,1.41,3.55,3.9v6.59h-2.44v-6.22a2,2,0,0,0-2-2.21A2.12,2.12,0,0,0,474,103.5Z"></path><path d="M488.7,102.19a1.81,1.81,0,0,0-1.91-1.29c-1,0-1.79.48-1.78,1.18s.41,1,1.46,1.21l1.77.37c1.95.43,2.91,1.33,2.91,2.81,0,2-1.83,3.3-4.42,3.3s-4.14-1.12-4.45-3l2.38-.23a1.86,1.86,0,0,0,2.06,1.41c1.16,0,1.93-.53,1.93-1.24s-.44-1-1.4-1.18l-1.76-.37c-2-.41-2.92-1.41-2.92-2.92,0-1.92,1.7-3.14,4.19-3.14s3.83,1.12,4.17,2.87Z"></path><path d="M492.35,104.43c0-3.21,1.93-5.35,5-5.35s5,2.14,5,5.35-1.93,5.34-5,5.34S492.35,107.64,492.35,104.43Zm7.45,0c0-1.9-.82-3.42-2.47-3.42s-2.51,1.52-2.51,3.42.83,3.39,2.51,3.39S499.8,106.32,499.8,104.43Z"></path></svg>
    
    

            <p><img src="https://nono.imgix.net/img/u/sketch-191102-cordoba-las-ramblas-alfar-torres-ferreras-ceramic-artisan.jpg?auto=format%2Ccompress&amp;ixlib=php-3.3.0&amp;w=2500"></p>

    <p>Andy Warhol's artworks have sold for millions of dollars. His most famous works‚Äîthink of Campbell's Soup Cans (1962) and Marylin Diptych (1962)‚Äîare limited edition paintings. Campbell's Soup Cans' piece consists of 32 images produced over five months<sup id="fnref:wikipedia-warhol-andy"><a href="#fn:wikipedia-warhol-andy" role="doc-noteref">1</a></sup>, and Marilyn Monroe's artwork consists of 50 portraits.<sup id="fnref:wikipedia-warhol-marilyn"><a href="#fn:wikipedia-warhol-marilyn" role="doc-noteref">2</a></sup></p>
<p>After hand-painting thirty-two soup cans by hand, Warhol moved to photo-silkscreen, a printmaking technique originally invented for commercial use that allowed Warhol and other artists to create reproductions of the same artwork using a silkscreen.<sup id="fnref:warhol-moma-learning"><a href="#fn:warhol-moma-learning" role="doc-noteref">3</a></sup></p>
<p>Warhol painted the soup cans with acrylic paint. Each canvas corresponded to a soup variety sold by Campbell's back in the 1960s.</p>
<p>Screen printing speeds up the reproduction of an artwork. Once the silkscreen is ready, colors are applied, one by one, using a squeegee to push the ink through the mesh screen<sup id="fnref:dickblick-screen-printing"><a href="#fn:dickblick-screen-printing" role="doc-noteref">4</a></sup>, either by hand or automatically with a machine, a process being used at the time to mass-produce advertisements.<sup id="fnref:warhol-moma-learning__2"><a href="#fn:warhol-moma-learning" role="doc-noteref">3</a></sup></p>
<p>"I don't think art should be only for the select few," Warhol claimed, "I think it should be for the mass of the American people."</p>
<p>Nowadays, we could argue this vision is a reality. Large corporations and artisans deploy a wide range of mediums to automate what used to be done by hand, producing goods en masse, lessening their price and uniqueness while improving its quality and availability. You can buy a ready-to-hang print of Vang Goh's&nbsp;<em>The Starry Night</em>&nbsp;at IKEA for $49.99 while the Museum of Modern Art in Midtown Manhattan shields and exhibits the original painting.</p>
<p>Contrary to his statement, Warhol created artwork for the selected few that could pay for it. In 2007, a 1964&nbsp;<em>Large Campbell's Soup Can</em>&nbsp;sold for $7.4 million, and&nbsp;<em>Silver Car Crash</em>&nbsp;sold for $105.4 million in 2013.</p>
<p>Aesthetics and taste aside, it's all about the story behind each piece.</p>
<p>Who made it, why, and in what context?</p>
<!-- References -->



  </div>



  </div><div>
      <p><img src="https://nono.imgix.net/folio/images/veil.gif" data-src="https://nono.imgix.net/img/u/sketch-nono-ma-logo.svg"></p>
<hr>
<p>
My sketches and stories, in&nbsp;your&nbsp;inbox.
</p>

<p><span>One email per week. No spam ever.</span></p>

<p><img src="https://sketch.nono.ma/img/u/profile-nono-ma-sketch.jpg" alt="Pencil sketch of Nono Mart√≠nez Alonso.">
</p>


      </div></div>]]>
            </description>
            <link>https://sketch.nono.ma/who-made-it-why-and-in-what-context</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044097</guid>
            <pubDate>Tue, 10 Nov 2020 09:24:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Low Hanging Fruits in Front End Performance Optimization]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25044079">thread link</a>) | @pawurb
<br/>
November 10, 2020 | https://pawelurbanek.com/frontend-performance-optimization | <a href="https://web.archive.org/web/*/https://pawelurbanek.com/frontend-performance-optimization">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
    <p><img title="Web apps frontend performance is represented by grapes Photo by Amos Bar-Zeev on Unsplash" alt="Web apps frontend performance is represented by grapes Photo by Amos Bar-Zeev on Unsplash" data-src="https://pawelurbanek.com/assets/frontend-optimization-fruits-6ff2f8bc957fe4e1142ab67c3a460ce9dc962eba5b1dc2f10c5125292c558b37.jpg" src="https://pawelurbanek.com/assets/frontend-optimization-fruits-thumb-90ff9c113ed86f833b4e2fa0bbe34e130f2ee5871d3b08aa033fe1e1cbc0e7ad.jpg">
    </p>
  

  

  

  <p>I conduct Rails performance audits for a living. Clients usually approach me with a request to speed up the backend, i.e., optimize the bottleneck API endpoint or tune the database queries. After the initial research, it often turns out that tweaking the frontend will make a better impact on the perceivable performance than fine-tuning the backend.</p>

<p>In this blog post, I describe the often-overlooked techniques that can significantly improve your web app‚Äôs overall performance.</p>

<p>These tips apply to all the web technologies like Ruby on Rails, NodeJS, Python Django, or Elixir Phoenix. It does not matter if you render an HTML or serve an API consumed by the JavaScript SPA framework. It all comes down to transferring bytes over the HTTP protocol. Frontend performance optimization is all about making this process as efficient as possible.</p>

<h2 id="why-is-frontend-performance-critical-for-your-websites-success">Why is frontend performance critical for your website‚Äôs success?</h2>

<p>I guess that developers often disregard the frontend performance because it doesn‚Äôt directly affect the infrastructure costs. Rendering the unoptimized website is offloaded to the visitor‚Äôs desktop or mobile device and cannot be measured using backend monitoring tools.</p>

<p>Developers usually work on top-notch desktop computers with a high-speed internet connection. They do not experience poor performance themselves. The UX of visiting your landing page on a 15 inch Mac Book Pro with a fiber connection cannot be compared to an old Android device on a shaky 3G network.</p>

<p>A typical web app issues dozens of requests on initial load. Only a few are backend-related, i.e., website HTML, API calls, etc. The majority of requests are static assets, JavaScript libraries, images. Fine-tuning the frontend-related requests will give a much greater return than shaving a couple of hundered milliseconds off a database query.</p>

<p>Google Bot measures the performance of your website, and it directly affects the SEO rating. Since <a href="https://developers.google.com/search/mobile-sites/mobile-first-indexing" target="_blank" rel="noopener noreferrer">July 2019</a>, Google Bot is using a <em>‚ÄúMobile first‚Äù</em> approach to assessing your website.</p>

<p>You might not care about frying the CPU and wasting the bandwidth of your mobile users. Maybe landing a sweet spot in Google search results should convince you to focus on your frontend performance?</p>

<h2 id="test-in-your-clients-shoes">Test in your client‚Äôs shoes</h2>

<p><em>‚ÄúIf you want to write fast websites, use slow internet.‚Äù</em>.</p>

<p>You should regularly throttle the internet speed during the development process to experience first-hand how your app will behave for most users.</p>

<p>On macOS, you can use the <a href="https://nshipster.com/network-link-conditioner/" target="_blank" rel="noopener noreferrer">Network Link Conditioner</a> to do it:</p>

<p><img alt="Simulate mobile network on a desktop computer" title="Simulate mobile network on a desktop computer" loading="lazy" src="https://pawelurbanek.com/assets/3g-network-performance-4273c3bd62edbdaddfdc36d7dad126747f3d69804a7ce8c1227cd8f96ff0a1ed.png"></p>

<p>Also, both Firefox and Chrome developer tools offer the option to throttle the internet speed in the <strong>Network</strong> tab:</p>

<p><img alt="Chrome network throttle setting" title="Chrome network throttle setting" loading="lazy" src="https://pawelurbanek.com/assets/chrome-network-throttle-ed2b0e3cb5163dbf3d6fe89601bd32c072af9a2b7146e82d8004f8e536ca208d.png"></p>

<p>Chrome network throttle</p>

<p><img alt="Firefox network throttle setting" title="Firefox network throttle setting" loading="lazy" src="https://pawelurbanek.com/assets/firefox-network-throttle-d11d6b54034fff903c4cc721f05a66747904fd72d3d9760ab7f1141491875434.png"></p>

<p>Firefox network throttle</p>


<p>Maybe the internal demos of the new features should also be done on the throttled network? Everyone in the company should have the chance to see how the app really works for most users.</p>

<h2 id="reconnaissance">Reconnaissance</h2>

<p>Discovering frontend issues is usually more straightforward than backend ones. You don‚Äôt even need admin access to the website. By definition, the frontend issues are in the <em>frontend</em>. You can scan and diagnose every website out there. I use the following tools to perform the initial scan:</p>

<p><a href="https://www.fastorslow.com/" target="_blank" rel="noopener noreferrer">FastOrSlow</a></p>

<p><a href="https://www.webpagetest.org/" target="_blank" rel="noopener noreferrer">WebPageTest</a></p>

<p><a href="https://developers.google.com/speed/pagespeed/insights/" target="_blank" rel="noopener noreferrer">Google PageSpeed Insights</a></p>

<p><a href="https://github.com/GoogleChrome/lighthouse" target="_blank" rel="noopener noreferrer">GoogleChrome lighthouse</a></p>

<p>There‚Äôs no reason why ANY website shouldn‚Äôt score top on each of those tools. Read on if your score is anywhere below 90%.</p>

<p><img alt="Abot for Slack FastOrSlow score" title="Abot for Slack FastOrSlow score" loading="lazy" src="https://pawelurbanek.com/assets/abot-fastorslow-28336ad9b7b74849a6a1d85a1ad269be81dd6288a960ee3b3ecbe69e6cf6b6a7.png"></p>

<p><img alt="Abot for Slack WebPageTest score" title="Abot for Slack WebPageTest score" loading="lazy" src="https://pawelurbanek.com/assets/abot-webpagetest-e33807bf28e738ced4aa16f48cdf17e44836a986b283aca9d673c8504ff045fa.png"></p>

<p><img alt="Abot for Slack Google speed score" title="Abot for Slack FastOrSlow score" loading="lazy" src="https://pawelurbanek.com/assets/abot-googlespeed-03d18ebbc637cce72357f44e3ed65e1cf60062e633df52bafc2eb178e0cca7ac.png"></p>

<p>The <a href="https://abot.app/" target="_blank">Abot landing page</a> is a dynamic Rails website getting top performance rating</p>





<h2 id="client-side-caching">Client-side caching</h2>

<p>Correctly configuring client-side caching is the most critical frontend optimization. I‚Äôve seen it misconfigured in multiple production apps so far. <a href="https://github.com/webpack/webpack" target="_blank" rel="noopener noreferrer">Webpack</a> comes with a great mechanism to easily leverage client-side caching, i.e., <em>MD5 digest</em>. The production assets generation process must be configured to append the <em>MD5 digest</em> tag to the filename.</p>

<p>It means that in the production environment, the <code>application.js</code> file becomes <code>application-5bf4f97...95c2147.js</code>. The random suffix is generated based on the file contents, so it is guaranteed to change if the file changes. You must add the correct <code>cache-control</code> header to make sure that once downloaded, the file will persist in the browser cache:</p>

<figure><pre><code data-lang="bash">cache-control: public, max-age<span>=</span>31536000, immutable</code></pre></figure>

<p>The <code>immutable</code> parameter ensures that cache is not cleared when the user explicitly refreshes the website on the Chrome browser.</p>

<p>If you‚Äôre using NGINX as reverse proxy you can use the following directive:</p>

<figure><pre><code data-lang="nginx"><span>location</span> <span>~</span><span>*</span> <span>\</span><span>.(?:ico|css|js|gif|jpe?g|png|woff2)</span>$ <span>{</span>
  <span>add_header</span> <span>Cache-Control</span> <span>"public,</span> <span>max-age=31536000,</span> <span>immutable"</span><span>;</span>
  <span>try_files</span> <span>$uri</span> <span>=</span><span>404</span><span>;</span>
<span>}</span></code></pre></figure>

<p>I‚Äôve seen many apps using <code>Etag</code> and <code>Last-Modified</code> headers instead of <code>Cache-Control</code>. <code>Etag</code> is also generated based on the file contents, but the client has to talk to the server to confirm that the cached version is still correct. It means that on every page visit, the browser has to issue a request to validate its cache contents and wait for <code>304 Not Modified</code> response. This  completely unnecessary network roundtrip can be avoided if you add a <code>Cache-Control</code> header.</p>

<h2 id="limit-bandwidth-usage">Limit bandwidth usage</h2>

<p>Nowadays, websites are just MASSIVE. It often takes multiple MBs to render a static landing page. Let me point out the most common mistakes that affect it and how they can be resolved.</p>

<h3 id="compress-and-resize-images">Compress and resize images</h3>

<p>There‚Äôs no excuse for serving uncompressed images on your website. You must make sure to process all your images with tools like <a href="https://compressor.io/" target="_blank" rel="noopener noreferrer">Compressor.io</a>. There‚Äôs often no perceivable difference for images processed with <strong>Lossy</strong> compression, and it usually means ~70% size reduction.</p>

<p>Resizing an image to the size that it actually needs is often overlooked. To check it, visit your website using Firefox on a large desktop screen, right-click the image, and select <strong>View image info</strong>. You‚Äôll see what dimensions the image needs vs. how large it is now:</p>

<p><img alt="Checking real image" title="Checking real image" loading="lazy" src="https://pawelurbanek.com/assets/real-image-size-524abe8437774180a233461deb8ada35092fda22cee4b3dfe85c0d0ad2e757b8.png"></p>

<p>Make sure first to resize the image and only then compress it. Otherwise, you might lose quality.</p>

<h3 id="defer-images-loading">Defer images loading</h3>

<p>You should defer the loading of the images that are not visible in the initial viewport. During the initial load, dozens of requests are competing for network throughput. Delaying the transfer of unnecessary images will leave more resources for necessary assets like CSS stylesheets etc.</p>

<p>There‚Äôs <a href="https://github.com/aFarkas/lazysizes" target="_blank" rel="noopener noreferrer">plenty</a> of <a href="https://github.com/tuupola/lazyload" target="_blank" rel="noopener noreferrer">different</a> <a href="https://github.com/vvo/lazyload" target="_blank" rel="noopener noreferrer">JavaScript libraries</a> that offer this feature. Including them means additional bandwidth usage, so I prefer to keep things simple and use a native <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/img#attr-loading" target="_blank" rel="noopener noreferrer"><code>loading='lazy'</code></a> HTML attribute.</p>

<p>It has decent <a href="https://caniuse.com/loading-lazy-attr" target="_blank" rel="noopener noreferrer">browser support</a>. Have a look at how it affected one of my blog posts:</p>

<p><img alt="Checking real image " title="Checking real image " loading="lazy" src="https://pawelurbanek.com/assets/before-lazy-images-a0e8cdb9099f3d5a348f853f4f222b67149aa058e59ecd29d2d5338be81cd8c0.png"></p>

<p>Without lazy loaded images</p>

<p><img alt="Checking real image " title="Checking real image " loading="lazy" src="https://pawelurbanek.com/assets/after-lazy-images-836f1781a9b7bf56cd8883a0ad0d252f52223f74b856e7e994ecef1d52efd029.png"></p>

<p>Lazy loading for images enabled</p>



<p>As you can see, adding <code>loading='lazy'</code> to all the images reduced ten requests and over <em>250kb</em> of transfer on the initial load. That‚Äôs a massive deal for slower internet connections!</p>

<h3 id="enough-with-the-gifs-already">Enough with the GIFs already‚Ä¶</h3>

<p>GIFs are HUGE! I understand you want to showcase a fancy UI on your landing page, but maybe you could use a lazy-loaded movie clip instead? <em>10MB</em> GIF can be converted to <em>250kb</em> mp4 file‚Ä¶ Twitter automatically changes <em>GIF</em> images to <em>mp4</em> files, so I‚Äôd trust them on this one.</p>

<h3 id="cherry-pick-and-measure-dependencies-size">Cherry-pick and measure dependencies size</h3>

<p>Many frontend libraries offer a modular approach to including them in your application. For example, <a href="https://getbootstrap.com/docs/3.4/customize/" target="_blank" rel="noopener noreferrer">Bootstrap</a> allows you to customize the build to include only the components you need.</p>

<p>Some popular libraries have lightweight alternatives. Since recently, <a href="https://twitter.com/addyosmani/status/1304676118822174721" target="_blank" rel="noopener noreferrer">ChromeDevTools suggests them</a>, so make sure to use it for your application.</p>

<h3 id="reconsider-3rd-party-dependencies">Reconsider 3rd party dependencies</h3>

<p>Overusing externally hosted 3rd party JavaScript libraries is the simplest way to kill the performance of your website.</p>

<p>Dropping in yet another <code>&lt;script src="..."&gt;</code> tag might not seem like a big deal. It‚Äôs easy to forget that one script can result in a cascade of requests, each including more resources. Here‚Äôs the cost of embedding sample 3rd party JavaScript libraries:</p>

<table>
  <tbody><tr>
    <th></th>
    <th>Requests</th>
    <th>Bandwidth (total/gzipped)</th>
  </tr>
  <tr>
    <td><a href="https://www.google.com/analytics/" target="_blank" rel="noopener noreferrer">Google Analytics</a></td>
    <td>4</td>
    <td>104.09 KB / 40.37 KB</td>
  </tr>
  <tr>
    <td><a href="https://simpleanalytics.com/" target="_blank" rel="noopener noreferrer">Simple Analytics</a></td>
    <td>2</td>
    <td>5.29 KB / 3.12 KB</td>
  </tr>
  <tr>
    <td><a href="https://developer.twitter.com/en/docs/twitter-for-websites/follow-button/overview.html" target="_blank" rel="noopener noreferrer">Twitter button</a></td>
    <td>8</td>
    <td>173.68 KB / 59.30 KB</td>
  </tr>
  <tr>
    <td><a href="https://disqus.com/" target="_blank" rel="noopener noreferrer">Disqus</a></td>
    <td>26</td>
    <td>862.55 KB / 271.48 KB</td>
  </tr>
  <tr>
    <td><a href="https://commento.io/" target="_blank" rel="noopener noreferrer">Commento.io</a></td>
    <td>5</td>
    <td>64.73 KB / 19.25 KB</td>
  </tr>
</tbody></table>



<p>The only 3rd party JavaScript dependency I use for this blog is <a href="https://commento.io/" target="_blank" rel="noopener noreferrer">Commento.io</a> for comments. It‚Äôs over <strong>10x</strong> lighter than its alternative Disqus.</p>

<p>I‚Äôve switched from using Google Analytics to SimpleAnalytics long ago. Recently I‚Äôve decided I don‚Äôt need to track the visitors of this blog at all. Summary visit stats from Cloudflare are enough for me.</p>

<p><img alt="CloudFlare visits stats" title="CloudFlare visits stats" loading="lazy" src="https://pawelurbanek.com/assets/cloudflare-total-stats-2af208b0332a799e70e0aaa5495ef01c05c12ccc24514110accd3a4005817863.png"></p>

<p>All the tracking I need. No JavaScript dependencies required</p>


<p>Including 3rd party libraries from external sources often reduces your ability to set correct caching headers, thus hurting your performance score.</p>

<p>You should always look for the most straightforward tool that meets your requirements and only resort to using 3rd party if you cannot develop the lightweight solution yourself.</p>

<h2 id="http-2">HTTP 2</h2>

<p><em>HTTP 2</em> offers massive performance improvement over <em>HTTP 1.1</em> for loading static assets. Headers are compressed to reduce bandwidth. Even more important is that multiple assets can be loaded in parallel over a single HTTP connection.</p>

<p>It might not be critical for API calls, but for static assets, you should enable <em>HTTP 2</em> and expect serious performance gains.</p>

<p>How to do it depends on your infrastructure. If you‚Äôre using custom infrastructure with NGINX reverse proxy, you can check out <a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-nginx-with-http-2-support-on-ubuntu-18-04" target="_blank" rel="noopener noreferrer">this tutorial</a>.</p>

<p>If you‚Äôre using Heroku, you‚Äôre out of luck because currently, it <a href="https://help.heroku.com/JAOCNZ25/does-heroku-have-plans-to-support-http-2" target="_blank" rel="noopener noreferrer">does not support HTTP 2</a>. The simplest way to add HTTP 2 support for Heroku is to proxy your traffic through <a href="https://pawelurbanek.com/cloudflare.com/" target="_blank" rel="noopener noreferrer">Cloudflare</a>.</p>

<p>If you don‚Äôt want to move your application to Cloudflare‚Äôs DNS, you can always use a custom domain just for serving assets from their CDN.</p>

<h2 id="physical-server-location-and-cdn">Physical server location and CDN</h2>

<p>The usage of CDN (<em>Content Delivery Network</em>) is critical if your user base is spread across the globe. Correctly configured CDN will cache static assets on the edge locations, significantly reducing the request‚Äôs duration. We‚Äôre talking like <em>50ms</em> vs. <em>800ms</em> (<strong>16x</strong> ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pawelurbanek.com/frontend-performance-optimization">https://pawelurbanek.com/frontend-performance-optimization</a></em></p>]]>
            </description>
            <link>https://pawelurbanek.com/frontend-performance-optimization</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044079</guid>
            <pubDate>Tue, 10 Nov 2020 09:20:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software development: should we stop? Maybe we should]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25044031">thread link</a>) | @enz
<br/>
November 10, 2020 | http://blog.spencermounta.in/2020/should-we-stop/index.html | <a href="https://web.archive.org/web/*/http://blog.spencermounta.in/2020/should-we-stop/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://blog.spencermounta.in/2020/should-we-stop/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044031</guid>
            <pubDate>Tue, 10 Nov 2020 09:09:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Awful Edge Case in Bash's Set -e]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25044030">thread link</a>) | @jbrot
<br/>
November 10, 2020 | http://jbrot.com/blog/dash_e_problems.html | <a href="https://web.archive.org/web/*/http://jbrot.com/blog/dash_e_problems.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
            <header>
                
                
            </header>

            <p>
            The last six months, I've been building out the automated testing infrastructure at a start up.
            Our infrastructure is mostly in Python, but writing Bash scripts is inevitable.
            At the end of the day, automated testing is all about running commands in a row‚Äîand Bash is the right tool for the job.
            </p>

            <p>
            There are a <a href="https://mywiki.wooledge.org/BashPitfalls">whole</a> <a href="https://github.com/anordal/shellharden/blob/master/how_to_do_things_safely_in_bash.md">bunch</a> <a href="https://sipb.mit.edu/doc/safe-shell/">of</a> <a href="https://wizardzines.com/comics/bash-errors/">articles</a> about how to write safe Bash scripts, and the standard advice is to add <code>set -euo pipefail</code> to make your scripts "safe."
            In this article, I'm going to describe one edge case where <code>set -e</code> completely fails to work.
            </p>

            <h2> Background </h2>

            <p>
            Suppose we have two projects in a git repo, say MyLibrary and MyApplication, where MyApplication depends on MyLibrary. And suppose each project provides a script <code>test.sh</code> that looks something like this:
            </p>

<pre><code>#!/bin/bash

set -e

./configure
make

python fancy_test_driver.py tests/first_tests
python fancy_test_driver.py --option-1 tests/second_tests
python fancy_test_driver.py --option-2 tests/third_tests
</code></pre>

            <p>
            This is a pretty reasonable script.
            We can now require that all changes pass both <code>my_library/test.sh</code> and <code>my_application/test.sh</code> before being merged.
            </p>

            <p>
            As time goes on, the amount of tests (and projects!) can spiral out of control.
            Eventually, someone (me) gets tasked with trying to optimize things.
            One obvious thing to do is to abort early.
            If MyLibrary fails testing, we don't need to bother with testing MyApplication.
            </p>

            <p>
            Of course, the developers who used to get errors from both projects aren't very happy about this change.
            Now passing the <code>test.sh</code> scripts is like peeling an onion: you resolve the first layer of errors only to find more errors lurking underneath‚Äîhidden by the early abort.
            However, there's a middle ground.
            We can test MyApplication only if MyLibrary fails while running test cases.
            If MyLibrary fails during compilation, continuing on is pointless since MyApplication depends on MyLibrary.
            </p>

            <p>
            So how do we distinguish when <code>test.sh</code> fails during compilation from when it fails during testing?
            Exit codes, naturally:
            </p>

<pre><code>#!/bin/bash

set -e

COMPILE_FAILURE_CODE=79

./configure || exit $COMPILE_FAILURE_CODE
make || exit $COMPILE_FAILURE_CODE

python fancy_test_driver.py tests/first_tests
python fancy_test_driver.py --option-1 tests/second_tests
python fancy_test_driver.py --option-2 tests/third_tests
</code></pre>

            <p>
            And we're done!
            An exit code of 0 means we passed the tests, an exit code of 79 means compilation failure (no need to test further projects), and any other exit code means we failed in testing‚Äîso we can continue testing the other projects.
            </p>

            <h2> Finding the Problem </h2>

            <p>
            The above solution works fine when we only have two lines that need the special exit code.
            However, it quickly becomes unwieldly when it needs to be applied to more lines:
            </p>

<pre><code>#!/bin/bash

set -e

COMPILE_FAILURE_CODE=79

pushd codegen_tool1 || exit $COMPILE_FAILURE_CODE
./configure || exit $COMPILE_FAILURE_CODE
make || exit $COMPILE_FAILURE_CODE
./codegen_tool1 || exit $COMPILE_FAILURE_CODE
popd || exit $COMPILE_FAILURE_CODE

pushd codegen_tool2 || exit $COMPILE_FAILURE_CODE
./configure || exit $COMPILE_FAILURE_CODE
make || exit $COMPILE_FAILURE_CODE
./codegen_tool2 || exit $COMPILE_FAILURE_CODE
popd || exit $COMPILE_FAILURE_CODE

./configure || exit $COMPILE_FAILURE_CODE
make || exit $COMPILE_FAILURE_CODE

# Run some tests...
</code></pre>

            <p>
            Gross!
            Clearly, we should factor out the <code>|| exit $COMPILE_FAILURE_CODE</code> line and have it apply to all of our lines at once.
            We can easily do this by creating a separate <code>build.sh</code> script:
            </p>

<pre><code>#!/bin/bash

set -e

pushd codegen_tool1
./configure
make
./codegen_tool1
popd

# snip

./configure
make
</code></pre>

            <p>
            And then adjusting <code>test.sh</code> to just have:
            </p>

<pre><code>#!/bin/bash

set -e

COMPILE_FAILURE_CODE=79

./build.sh || exit $COMPILE_FAILURE_CODE

# Run some tests...
</code></pre>

            <p>
            And this, too, works great!
            But wait!
            Why even use a second script?
            Can't we do the exact same thing with a subshell?
            </p>

<pre><code>#!/bin/bash

set -e

COMPILE_FAILURE_CODE=79

(
    pushd codegen_tool1
    ./configure
    make
    ./codegen_tool1
    popd

    # snip

    ./configure
    make
) || exit $COMPILE_FAILURE_CODE

# Run some tests...
</code></pre>

            <p>
            <strong>No!</strong>
            This subshell implementation is dangerously broken.
            The rest of this article will explore how and why the subshell code does not function as expected.
            </p>

            <h2> There's a Problem? </h2>

            <p>
            Let's run some simple bash programs and see what happens.
            First, we'll confirm <code>set -e</code> works as expected.
            </p>

<pre><samp>$ cat script1.sh
#!/bin/bash
echo "Statement 1"
(exit 3)
echo "Statement 2"

$ echo "$?"
0

#!/bin/bash
set -e
echo "Statement 1"
(exit 3)
echo "Statement 2"

$ ./script2.sh
Statement 1

$ echo "$?"
3
</samp></pre>

            <p>
            Yep, that's what we expected.
            Without <code>set -e</code> Bash ran every statement, and with <code>set -e</code> Bash stopped after the first non-zero exit code.
            What if we put our statements in a subshell?
            </p>

<pre><samp>$ cat script3.sh
#!/bin/bash
(
    echo "Statement 1"
    (exit 3)
    echo "Statement 2"
)

$ ./script3.sh
Statement 1
Statement 2

$ echo "$?"
0

$ cat ./script4.sh
#!/bin/bash
set -e
(
    echo "Statement 1"
    (exit 3)
    echo "Statement 2"
)

$ ./script4.sh
Statement 1

$ echo "$?"
3
</samp></pre>

        <p>
        And again, that's what we expected.
        The subshell made no difference.
        Note that <code>set -e</code> does propagate into the subshell.
        Alright. What if we mask the subshell's exit code?
        </p>

<pre><samp>$ cat script5.sh
#!/bin/bash
set -e
(
    echo "Statement 1"
    (exit 3)
    echo "Statement 2"
) || exit 9

$ ./script5.sh
Statement 1
Statement 2

$ echo "$?"
0
</samp></pre>

        <p>And again everything works as...</p>

        <h2> Wait, what? </h2>

        <p>Okay. Maybe <code>set -e</code> doesn't propagate?</p>

<pre><samp>$ cat script6.sh
#!/bin/bash
set -e
(
    set -e
    echo "Statement 1"
    (exit 3)
    echo "Statement 2"
) || exit 9

$ ./script6.sh
Statement 1
Statement 2

$ echo "$?"
0

$ cat script7.sh
#!/bin/bash
(
    set -e
    echo "Statement 1"
    (exit 3)
    echo "Statement 2"
) || exit 9

$ ./script7.sh
Statement 1
Statement 2

$ echo "$?"
0
</samp></pre>

        <p>
        Nope. Still doesn't work.
        Even if we just have <code>set -e</code> in the subshell and not in the outer script, it doesn't work.
        </p>

        <h2>So what's going on?</h2>

        <p>
        Well, if we dig into the Bash man page, we find this excerpt about <code>set -e</code>:
        </p>

        <blockquote>
              Exit  immediately  if a pipeline (which may consist of a single simple command), a list, or a compound command (see SHELL GRAMMAR above), exits with a non-zero status.
              The shell does not exit if the  command  that  fails  is part  of  the command list immediately following a while or until keyword, part of the test following the if or elif reserved  words, <em>part of any command executed in a &amp;&amp; or || list except the command following the final &amp;&amp; or ||,</em> any command in a pipeline but the last, or if the command's return value is being inverted with !.
        </blockquote>

        <p>
        So, the spec says that if you're using <code>&amp;&amp;</code> or <code>||</code>, only the last command's exit code can cause the shell to exit.
        This makes sense, because you expect  <code>command_1 || command_2</code> to execute <code>command_2</code> if <code>command_1</code> fails.
        Without this exception, it would be very hard to have any logical statements when <code>-e</code> is set.
        </p>

        <p>
        The behavior we just witnessed is, therefore, Working as Intended‚Ñ¢.
        When we try to mask the subshell's exit code, we put the subshell at the start of an <code>||</code> list.
        So, the subshell's exit code will not cause an exit despite <code>-e</code> being set.
        But, every single command inside the subshell is <em>also</em> considered part of the <code>||</code> list, and thus no exit code anywhere in the subshell can cause the subshell to exit.
        It's as if <code>set +e</code> is being run implicitly in the subshell‚Äîonly, as we've seen, we can't override it with an explicit <code>set -e</code> in the subshell.
        </p>

        <p>
        Is there anything we can do to fix this?
        Well, you're probably better off with one of the approaches I presented earlier.
        If you need to stay inside the same shell script, the solution with <code>trap</code> below is probably what you want.
        And if you truly need to use a subshell, I was able to come up with this mess:
        </p>

<pre><samp>$ cat script8.sh
#!/bin/bash
set -e
echo "Some stuff with -e set"

set +e
(
    set -e
    echo "Statement 1"
    (exit 3)
    echo "Statement 2"
)
[[ $? -ne 0 ]] &amp;&amp; exit 9
set -e

echo "More code with -e set (unreachable)"

$ ./script8.sh
Some stuff with -e set
Statement 1

$ echo "$?"
9
</samp></pre>

        <h3>Bonus Solution</h3>

        <p>
        I ended up using <code>trap</code> for error masking:
        </p>

<pre><samp>$ cat script9.sh
#!/bin/bash

set -e

trap 'exit 9' ERR

echo "Statement 1"
(exit 3)
echo "Statement 2"

trap - ERR

$ ./script9.sh
Statement 1

$ echo "$?"
9
</samp></pre>

        <p>
        The nice part about this solution is it allows you to stick with just one script (useful if you need to use functions), and the logic is straightforward.
        This option can be harder to make work if you're already using <code>trap ERR</code> for cleanup, though.
        </p>

        </article></div>]]>
            </description>
            <link>http://jbrot.com/blog/dash_e_problems.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044030</guid>
            <pubDate>Tue, 10 Nov 2020 09:09:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Become Covid Savvy in 10 Steps]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25044022">thread link</a>) | @datashrimp
<br/>
November 10, 2020 | https://adsp.ai/articles/how-to-become-covid-savvy-in-10-steps/ | <a href="https://web.archive.org/web/*/https://adsp.ai/articles/how-to-become-covid-savvy-in-10-steps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://adsp.ai/articles/how-to-become-covid-savvy-in-10-steps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044022</guid>
            <pubDate>Tue, 10 Nov 2020 09:06:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[iOS 14 IDFA changes. Research on change in mobile ad market]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25044000">thread link</a>) | @iwitaly
<br/>
November 10, 2020 | https://blog.adapty.io/ios-14-idfa-attribution-a-global-change-in-the-mobile-advertising-market/ | <a href="https://web.archive.org/web/*/https://blog.adapty.io/ios-14-idfa-attribution-a-global-change-in-the-mobile-advertising-market/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>The mobile industry is undergoing one of the most fundamental changes of recent years. Apple has decided that early 2021, app developers will no longer have access to IDFA by default.</p><p>IDFA is a unique device identifier used for ad attribution, retargeting, alike audiences, analytics and other tasks. After the change, in order to receive the IDFA, an app developer must explicitly request the user‚Äôs permission (which is similar to allowing push notifications in an app). According to various estimates, the share of users who will provide access to their IDFA doesn‚Äôt exceed 10%.</p><p>Apple has provided privacy-friendly alternatives for attribution, but they fail to cover even a small fraction of the tasks that teams working on developing and promoting mobile apps currently have.</p><p>This shift means that mobile marketing (estimated at $80 billion), and by extension the mobile industry, are about to change drastically. In this essay, we will discuss in detail what will change, how it will affect the main players in the mobile advertising market such as developers, ad systems, attribution service providers, and advertisers.</p><figure><img src="https://blog.gopractice.io/wp-content/uploads/2020/09/for-post.jpg"></figure><h2 id="a-short-summary-of-the-key-changes-and-implications-of-ios-14-release-and-limiting-default-access-to-idfa"><strong><strong>A short summary of the key changes and implications of iOS 14 release and limiting default access to IDFA</strong></strong></h2><p><strong><strong># 1 Access restrictions: In iOS 14, IDFA will only be accessible upon user permission.</strong></strong></p><p>IDFA (Identifier for Advertisers) is a unique identifier of an iOS device. It is used in mobile apps for user attribution and tells advertisers where a user came from.</p><p>With iOS 14, to be released in early 2021, every app that wants to use an advertising user ID (IDFA) will have to explicitly ask permission from the user.</p><p>This will work in the same way as requesting permission to send push notifications.</p><figure><img src="https://lh4.googleusercontent.com/ary-L0VrnuIGlsebGQyVjv9IvP--cr9L0G2gMnSXBsP399mw2VnRal5OGOr7u9oqR9oVOOdOuWovqElUe8XyDaPb4gSYrOTRhlSnOqprRQRCEDoDQESdrFvOiMM_GEHTr-3_YMdR"></figure><p>Request to use IDFA will look like this ‚Äì the text on the popup will ask: ‚ÄúWould you like to give permission to track you across apps and websites owned by other companies?‚Äù</p><p>The text is very straightforward, and the button to refuse is located below, making it more convenient to deny access to the IDFA. <a href="https://mobiledevmemo.com/mobile-advertising-without-the-idfa-a-comprehensive-overview/" rel="noopener noreferrer">Most experts</a> agree that 9 out of 10 people will most probably not opt in. After the initial declaration, Apple suggested a milder design for the popup, yet the idea remains largely the same and won‚Äôt bring fundamental changes.</p><p>Thus Apple is breaking the existing ad traffic attribution infrastructure under the pretext of privacy concerns. And this will affect everyone: ad networks systems, mobile developers, advertisers, and users.</p><p><strong><strong># 2. Lack of access to IDFA will lead to a decrease in the quality of mobile traffic attribution and an increase in the cost of user acquisition.</strong></strong></p><p>Previously, mobile developers and ad networks could use the IDFA without the explicit consent of the user. But now, the situation is radically changing:</p><p>1. Without access to IDFA, mobile ad attribution services (Appsflyer, Adjust and others) will no longer be able to trace back a significant portion of mobile traffic. It is important to understand that IDFA is now the primary accurate attribution tool. Appsflyer, Adjust and others will be forced to switch to less accurate and less efficient methods of determining the source of installs (e.g., device fingerprinting).</p><p>2. This will reduce the accuracy of traffic attribution, which will complicate things for companies developing and promoting mobile apps. In the future, it could lead to an increase in the cost of attribution.</p><p>3. We can expect a rise in acquisition costs as accurate targeting will become much more limited. Such popular and effective tools as lookalike audiences and retargeting will now be available only for a small portion of users who agreed to honor a request to provide access to the IDFA or used a relevant email or phone number while signing up.</p><p><strong><strong># 3. Apple presented its own attribution system, but it still doesn‚Äôt cover all mobile developers‚Äô needs.</strong></strong></p><p>Apple offered the market an alternative, privacy-friendly traffic attribution system. This system makes it possible to send information about installs to advertising networks without explicitly revealing information about the user. But, unfortunately, the capabilities of this system are severely limited and don‚Äôt cover basic marketing needs.</p><p>One of the biggest problems is that developers and ad systems will no longer have access to user-level data. They will only see aggregated data in the account.</p><p>Developers will no longer be able to calculate and segment ROI or link attribution data to product events.</p><p><strong><strong>#4. Impact of IOS 14 Changes: rising user acquisition costs, accelerating mobile market consolidation, difficulties for large advertising networks and ad-attribution services</strong></strong></p><p>It‚Äôs hard to predict the results of this change. But here are some possible scenarios:</p><ul><li>As iOS 14 takes over (users will be gradually updating their devices to a newer iOS version with a IDFA), the cost of user acquisition will increase. The key factors here will be a lower quality of attribution and limited access to ad-targeting tools like lookalike audiences and retargeting.</li><li>Companies that provide attribution services will find themselves in a difficult position. Prior to iOS 14, they held a central position in the mobile advertising market. Without these companies developers wouldn‚Äôt be able to run mobile marketing efficiently. Apple‚Äôs decision will shatter their positions in the market. And there‚Äôs a possibility that Google will follow suit.</li><li>Large ad networks will also suffer. In its <a href="https://www.facebook.com/audiencenetwork/news-and-insights/preparing-audience-network-for-ios14/" rel="noopener noreferrer">latest report</a>, Facebook has already declared that it sees the changes in iOS 14 as a risk to its advertising business. Google, Twitter, Snapchat, Tiktok, and other big players have voiced <a href="https://www.facebook.com/audiencenetwork/news-and-insights/preparing-audience-network-for-ios14/" rel="noopener noreferrer">similar concerns.</a></li><li>It will become even more difficult for small players to compete with large publishers on the mobile market. They will lose the ability to accurately calculate ROI for ad campaigns. Without the ability to precisely link users‚Äô payments to ad campaigns, it will be impossible to calculate the profit from acquired users. For small players, ineffective marketing can be a disaster, and many will have to be much more careful or even abandon paid channels. Big players have greater error tolerance and more tools to solve the emerging problems, although the problem will be no less relevant to them. Due to this asymmetry, it makes sense to expect an acceleration of the consolidation process on the mobile market.</li></ul><p><strong><strong>If you want to understand in more details what and why will happen, then here is what we will discuss further on:</strong></strong></p><ul><li>How traffic attribution currently works for mobile apps and why IDFA is so important?</li><li>What exactly will change in iOS 14?</li><li>What is the alternative Apple is offering to replace IDFA and existing mobile traffic attribution mechanisms?</li><li>Why do we expect an increase in user acquisition costs?</li><li>What do the leaders of the mobile market say?</li><li>When can we expect this change to take place?</li><li>How to prepare your app for iOS 14?</li><li>What will be the broader implications for mobile advertising and attribution?</li><li>How traffic attribution currently works for mobile apps, and why IDFA is so important?</li></ul><h2 id="how-traffic-attribution-works-for-mobile-apps"><strong><strong>How traffic attribution works for mobile apps</strong></strong></h2><p>Traffic attribution helps find out where a particular user came from. This is a critical task for performance marketing, as without high-quality attribution, it is impossible to determine which advertising campaigns are profitable (i.e., are making money) and which are not.</p><p>On the web, attribution is tackled in a simple way ‚Äì we just need to add special parameters (usually utm-parameters) to the ad links leading to the site.</p><p>This scheme doesn‚Äôt work with mobile apps largely because mobile app stores add an intermediate step to the process and do not provide information about where the user came from.</p><p>Another reason is the policy of a number of leading advertising systems on the market. For example, Facebook doesn‚Äôt allow you to add any parameters when promoting mobile apps through its ad network.</p><p>Therefore, there are other methods for traffic attribution for mobile apps out there. Say you have a mobile app or a mobile game. To acquire users to your app, you purchase ad traffic. This is what happens in order to link ad clicks to an app‚Äôs install:</p><ul><li>The app developer has to integrate the SDK of a mobile attribution service into the app to track the traffic source of new users. Examples include AppsFlyer, Adjust, and Kochava.</li><li>The developer purchases ads in the advertising network, while using special links from the traffic-tracking service (Appsflyer, Adjust, etc.).</li><li>After clicking on the ad, the user is redirected to a special page, where various information is collected about him, including IDFA and his traffic source (it is transmitted from the advertising network, while access to IDFA is limited on the web). The user is then redirected to the app‚Äôs page in App Store or Google Play. Users will see none of this happen.</li><li>When a new user launches the app for the first time, the information about this action is sent to the mobile attribution service (AppsFlyer, Adjust, Kochava), which tries to find a match between the data received and the data collected at the previous step. If there is a match, then this user is attributed to the corresponding ad campaign. Absent a match, the traffic is considered organic.</li><li>The developer must set up a postback from a partner to the ad network, so that the ad system understands which campaigns are working well and which are not, and can optimize the display of ads on its side.</li><li>In some ad networks, the logic differs slightly. For example, the logic is different for Facebook, which is directly integrated with Appsflyer, Adjust and other providers.</li></ul><p>If you are not familiar with this topic, then here is a good <a href="https://www.appagent.co/blog/2019/01/09/the-principles-of-mobile-ad-attribution-analytics-and-tracking/" rel="noopener noreferrer">essay</a>.</p><figure><img src="https://lh4.googleusercontent.com/UfaVT2cgGlrEBil86RyIVr4tzeJi-pS3YLNVluew3DvgRDJ0lYjWotReEUaOZdVs8j8B_2RO09oNWdcplvBLW6agdeLEqyrSiZOMb7BFaHZZlAw-DxeYpbC9niIoi22u5hH8x0NM"></figure><h2 id="why-idfa-is-a-central-element-of-mobile-traffic-attribution">Why IDFA is a central element of mobile traffic attribution</h2><p>As is evident in the process described above, data about users who click on ads is key to the logic behind mobile traffic attribution systems. The IDFA is the central element of the data collected, and if IDFA is missing, the accuracy of this attribution method will drop <a href="https://medium.com/@gsimmons/your-attribution-may-be-more-wrong-than-right-903cde0ce4ca#:~:text=Fingerprinting%20accuracy%3A,result%20as%20a%20deterministic%20match)." rel="noopener noreferrer">dramatically.</a></p><p>Without IDFA, ‚Ä¶</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.adapty.io/ios-14-idfa-attribution-a-global-change-in-the-mobile-advertising-market/">https://blog.adapty.io/ios-14-idfa-attribution-a-global-change-in-the-mobile-advertising-market/</a></em></p>]]>
            </description>
            <link>https://blog.adapty.io/ios-14-idfa-attribution-a-global-change-in-the-mobile-advertising-market/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044000</guid>
            <pubDate>Tue, 10 Nov 2020 09:02:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Five Keys to create a killer CLI in Go]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25043979">thread link</a>) | @alexellisuk
<br/>
November 10, 2020 | https://blog.alexellis.io/5-keys-to-a-killer-go-cli/ | <a href="https://web.archive.org/web/*/https://blog.alexellis.io/5-keys-to-a-killer-go-cli/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

        

        <section>
            <div><p>We're having a renaissance of CLIs - every programming language from Node.js to Go to less fashionable ones like .NET all have CLIs and developers love them. You should love them too and make sure your next CLI is a killer.</p>
<blockquote>
<p>CLIs (command-line interfaces) are text-based interfaces for your applications which are easily automated, fast to work with and can be combined with other CLIs to create workflows.</p>
</blockquote>
<h3 id="1pickgo">1. Pick Go</h3>
<p>Here's why I prefer the OpenFaaS CLI in Go over the Serverless Framework Inc Node.js CLI:</p>
<ul>
<li>Compiles to a single static binary</li>
</ul>
<p>With Go you can easily provide a single static binary that contains your whole application or CLI for your chosen platform. To target a different CPU or OS you just pass in an environmental override when building.</p>
<p>Here's a binary for Windows, 64-bit Linux and Raspberry Pi:</p>
<pre><code>GOOS=windows go build -o cli.exe
GOOS=linux go build -o cli
GOARCH=armv7 GOOS=linux go build -o cli-rpi
</code></pre>
<p>That's it - and there are more platforms available too - like FreeBSD. You won't need to install any dependencies and the final output binary can be tiny.</p>
<ul>
<li>Consistent style</li>
</ul>
<p>Go is an opinionated language and while there may be some differences between which editors a project prefers - you will encounter a consistent standard for styling, formatting and build tools. Something like Node.js could involve any number of "task runners" or "transpilers" - or a more esoteric flavour of the language like TypeScript or CoffeeScript.</p>
<p>Go has a consistent style and was deliberately designed to be unambiguous. This makes it attractive to contributors and easy for on-boarding.</p>
<ul>
<li>Fast on every platform</li>
</ul>
<p>A statically compiled Go binary is super fast to load - compared to Node.js. For instance: Node.js on a single-core Raspberry Pi can take 1.5-3.0 seconds to load before executing any code.</p>
<ul>
<li>Easy to create a REST client</li>
</ul>
<p>Go includes a no-nonsense <code>http</code> client and has built-in support for working with <code>xml</code>, <code>json</code> and binary formats. There's also a very good library for working with YAML which is used in OpenFaaS here: <a href="https://github.com/openfaas/faas-cli/blob/master/stack/stack.go">stack.go</a></p>
<p>There may be reasons why Node.js or another language is more suitable for your use-case. If you've already decided to build a CLI in Go - then you can reap the benefits of a fast binary that's small and easy to distribute.</p>
<h3 id="2parseflagsarguments">2. Parse flags &amp; arguments</h3>
<p>The standard Go library includes a <code>flags</code> package that can be used to parse flags or arguments in a couple of lines of code.</p>
<pre><code>package main

import (
	"flag"
	"fmt"
	"os"
)

func main() {
	var image string
	flag.StringVar(&amp;image, "image", "", "Docker image")
    flag.Parse()
    
	if len(image) == 0 {
		fmt.Fprintf(os.Stderr, "You must specify a Docker image name")
	}

	fmt.Printf("Your Docker image was: %s", image)
}
</code></pre>
<blockquote>
<p>From my experiences in the world of enterprise development - the average C# developer would have written his own string parser and then created a ConsoleApp as an entry-point then a DLL Library for the parsing and one more for the application code. Contrast that to the snippet above.</p>
</blockquote>
<p>Go is unpretentious - you can have a single file that compiles to a tiny binary and be done with that.</p>
<p>I suggest you start here and then once you've stretched <code>flags</code> to the limit you can look at something more modular like <a href="https://github.com/spf13/cobra">Cobra</a>.</p>
<p>Cobra is used by Docker, Kubernetes and the OpenFaaS projects and means that handlers/commands can live in separate files or modules. It also makes documenting each command really simple. <a href="https://github.com/openfaas/faas-cli/blob/master/commands/list.go">Checkout the code here for our 'list functions' command</a>.</p>
<p>Another advantage of using "cobra" is that it has a verb noun syntax. This helped us when designing our user experience. We went from a somewhat jarring experience to something more fluid:</p>
<pre><code>faas-cli -deploy -image=functions/alpine -name=cat -fprocess=/bin/cat
</code></pre>
<p>To:</p>
<pre><code>faas-cli deploy --image=functions/alpine --name=cat --fprocess=/bin/cat
</code></pre>
<p>We also took feedback about managing multiple functions and created a YAML format which meant the CLI command could be as simple as:</p>
<pre><code>faas deploy -f stack.yml
</code></pre>
<p>Or</p>
<pre><code>faas deploy -f https://git.raw/stack.yml
</code></pre>
<blockquote>
<p>Tip: pick verbs / commands carefully and ask other people if they make sense. If something jars with you then it's probably wrong. It can take several iterations but what you're aiming for is an intuitive experience.</p>
</blockquote>
<h3 id="3automateeverything">3. Automate everything</h3>
<p>Create an automated build using a free and public CI platform like Travis so that contributors or collaborators know whether their changes can be integrated.</p>
<p>Use GitHub releases to track changes in the project and milestones. You can set up a post-build action in Travis to publish binary artifacts automatically for every platform you target.</p>
<p>If you have a Docker image - publish that on the Docker store at the same time as pushing a new release artifact. Tools like Travis can obfuscate credentials and keys so that they do not show up in logs.</p>
<p>Go projects are very easy to build in Docker. Here's an example from one of our projects:</p>
<ul>
<li><a href="https://github.com/openfaas/faas/blob/master/gateway/Dockerfile">Dockerfile for API Gateway</a></li>
</ul>
<p>Make sure you use <a href="https://docs.docker.com/engine/userguide/eng-image/multistage-build/">multi-stage builds</a> so you ship a lean image.</p>
<ul>
<li><a href="https://github.com/openfaas/faas/blob/master/.travis.yml">OpenFaaS main project CI .travis.yml file</a></li>
</ul>
<p>While it's easy to start with - you do not want to be building 3-5 binary files on your own machine for every release then uploading them to a web-form every time you need an update.</p>
<h3 id="4integratewithpackagemanagers">4. Integrate with package managers</h3>
<p>If you want to make it easy for your target audience to be able get hold of your CLI then you need to make that as easy as possible. This means integrating with package managers.</p>
<ul>
<li><code>brew</code> - if your target audience is the developer - then a large percentage of them may have a Mac. brew is a package manage which means most CLIs are only one command away <code>brew install faas</code> for instance</li>
<li>Linux - for Linux there are many package managers so I've chosen to build a download utility which can be run as root or as a regular user. To get the OpenFaaS CLI: <code>curl -sL https://cli.openfaas.com | sh</code> - or to get hold of Docker: <code>curl -sL https://get.docker.com | sh</code>.</li>
<li>Windows - Windows users have good options available for shells including Git Bash (my preferred option) and the Windows Subsystem for Linux. WSL can use the Linux <code>curl</code> utility, but if you are targeting "point and click" developers you may want to create a "double-click" installer.</li>
</ul>
<p>Whatever you do - make sure it's automated and evaluate each package manager you support. Will you have time to maintain the integration? Is it provided by the project or by the community? What if it breaks? For instance - we maintain a guide on how to <a href="https://github.com/openfaas/faas-cli/blob/master/CONTRIBUTING.md#how-to-update-the-brew-formula">upgrade our brew formula</a>.</p>
<blockquote>
<p>Tip: Make sure the update/release cycle of chosen packages can match the cadence of your project. How many times have you had to install Ubuntu packages from a third-party PPA due to them being out of date?</p>
</blockquote>
<h3 id="5acceptcontributionsandgatherfeedback">5. Accept contributions and gather feedback</h3>
<p>Provide an easy way for people to provide feedback and contributions. A CLI should be designed for its operators - so make it easy for them to submit code changes or suggestions.</p>
<p>User feedback is essential, but when running an Open Source Software project I often hear people struggle to understand how or if their software is being used.</p>
<p>Basic feedback can be gathered from the download statistics on GitHub or <code>brew</code>. Several key projects have started gathering usage data automatically using an analytics platform - examples include: <code>brew</code>, Visual Studio Code, Atom and Docker for Mac/Windows. If you go down this route make sure you provide a privacy policy and comply with any potential data-protection regulations.</p>
<p>Here's some things we're looking at collecting for <a href="https://github.com/openfaas/faas-cli/issues/108">OpenFaaS in issue #108</a>:</p>
<ul>
<li>which commands were used</li>
<li>what programming languages functions are being scaffolded for</li>
<li>operating system / CLI version / location in the world etc</li>
</ul>
<blockquote>
<p>OpenFaaS contributor John McCabe has been leading this initiative for the project.</p>
</blockquote>
<h3 id="wrappingup">Wrapping up</h3>
<p>There are many reasons to use Go to build your next killer CLI - from the speed of compilation and execution, the availability of built-in or high-quality packages, to the ease of automation. It may not be right for everyone and other languages and platforms do have different pros and cons.</p>
<p>If you're starting out wanting to take your CLI to the next level then take inspiration from this post and the experience we've built up over the last 8 months building the <a href="https://github.com/openfaas/faas-cli">OpenFaaS CLI</a>. <em>If you would like to contribute to the code-base we're always looking for help and have an thriving community.</em></p>
<p><strong>Follow and share on Twitter</strong></p>
<p>Do you have questions, comments and suggestions? Follow me on <a href="https://twitter.com/alexellisuk">Twitter</a> and never miss a post again.</p>
<blockquote data-lang="en"><p lang="en" dir="ltr">5 keys to create a killer CLI in Go - <a href="https://t.co/AoHfHgv5w3">https://t.co/AoHfHgv5w3</a> <a href="https://twitter.com/golang?ref_src=twsrc%5Etfw">@golang</a> <a href="https://twitter.com/Docker?ref_src=twsrc%5Etfw">@docker</a> <a href="https://twitter.com/kubernetesio?ref_src=twsrc%5Etfw">@kubernetesio</a> <a href="https://twitter.com/openfaas?ref_src=twsrc%5Etfw">@openfaas</a></p>‚Äî Alex Ellis (@alexellisuk) <a href="https://twitter.com/alexellisuk/status/947487509533085696?ref_src=twsrc%5Etfw">December 31, 2017</a></blockquote> 
<h4 id="seealso">See also:</h4>
<p><a href="https://www.openfaas.com/">OpenFaaS.com</a> - Serverless Functions Made Simple</p>
<p><img src="https://raw.githubusercontent.com/openfaas/media/master/OpenFaaS_logo_stacked_opaque.png" width="450px" height="450px"></p>
<p>With OpenFaaS you can build serverless functions in any language in seconds and run them anywhere at scale.</p>
<blockquote>
<p>Serverless functions are small, discrete, reusable chunks of code that can be built once and deployed the same way everywhere. They do one thing and do it really well - the best uses for functions are integrating event driven systems or building integrations between existing microservices.</p>
</blockquote>
<p>Find out more on the <a href="https://www.openfaas.com/">project website</a> or read <a href="https://github.com/openfaas/faas">the code on GitHub</a>.</p>
<blockquote>
<p>Acknowledgements - thanks to John McCabe and Richard Gee for reviewing the post and for all their <a href="https://github.com/openfaas/faas-cli/graphs/contributors">contributions to the OpenFaaS CLI</a> through code, testing and feedback.</p>
</blockquote>
</div>
        </section>

        

    </article>
</div></div>]]>
            </description>
            <link>https://blog.alexellis.io/5-keys-to-a-killer-go-cli/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043979</guid>
            <pubDate>Tue, 10 Nov 2020 08:56:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Messaging via SEPAtransfercomments [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25043965">thread link</a>) | @zanfr
<br/>
November 10, 2020 | https://franzkruhm.com/SEPA2020.pdf | <a href="https://web.archive.org/web/*/https://franzkruhm.com/SEPA2020.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://franzkruhm.com/SEPA2020.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043965</guid>
            <pubDate>Tue, 10 Nov 2020 08:54:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Productivity Guide: All You Need to Know to Be Efficient]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25043892">thread link</a>) | @iuliangulea
<br/>
November 10, 2020 | https://iuliangulea.com/productivity/ | <a href="https://web.archive.org/web/*/https://iuliangulea.com/productivity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://iuliangulea.com/images/productivity.png" alt="Productivity"></p><h2 id="productivity-definition">Productivity Definition</h2><blockquote><p>Productivity is a measure of the efficiency of a person to perform a specific task.</p></blockquote><p>We often think it is a state of constant efficiency that allows us to do everything faster and better, but this is wrong. <em>Productivity is a measurement per individual task.</em></p><p>If you try to measure productivity as the number of tasks you accomplish daily, you still have to count in each individual assignment, which endorses the idea that productivity is a measurement per task.</p><h2 id="productivity-from-within-and-without">Productivity From Within And Without</h2><p>There are different strategies for productivity, and all those strategies can be classified into two main categories: <strong>external productivity</strong> and <strong>internal productivity.</strong></p><p><strong>External productivity</strong> is what usually people put their emphasis on. Also, it is what all those products, apps, and services promise to deliver. External productivity is all about automation, better tools, frameworks, software, and anything that allows you to perform your work better and faster. It has a significant potential to improve your performance by taking advantage of technology and advanced tools.</p><p><strong>Internal productivity,</strong> on the other hand, is often overlooked. Unlike the external one, internal productivity is all about your cognitive and physical performance, about your ability to focus, sustain your attention on the task at hand, manage your energy, and, generally speaking, understand how your body and mind works.</p><h2 id="gaining-productivity-expertise--the-pyramid-of-mastery">Gaining Productivity Expertise ‚Äî The Pyramid Of Mastery</h2><p><img src="https://iuliangulea.com/images/the-pyramid-of-mastery/the-pyramid-of-mastery-1.png" alt="Pyramid of Mastery"></p><p><a href="https://iuliangulea.com/pyramid-of-mastery/">The Pyramid of Mastery</a> is a model that defines any domain in terms of 4 categories:</p><p><strong>Elements</strong> are the fundamental building blocks that make up a domain. In productivity, elements are abstract: focus, attention, working memory, sensory channels, etc.</p><p><strong>Rules</strong> are the laws by which the elements interact with each other and general principles that govern a domain. Some rules are: goal-directed attention is easily distracted, senses have a different throughput, working memory cannot perform two tasks simultaneously (hence multitasking is a myth), etc.</p><p><strong>Tools</strong> are the instruments that help you operate with the Elements and Rules. The majority of productivity tools nowadays are software apps. One of the best productivity tools is pen and paper.</p><p><strong>Frameworks</strong> are a combination of the previous layers. A Framework is a layer of abstraction that hides the underlying fundamentals behind a friendly facade that is easy to use to achieve a specific goal. Some frameworks in productivity are office suites and various productivity methods (e.g., <a href="https://en.wikipedia.org/wiki/Pareto_principle">80/20 Rule</a>, <a href="https://en.wikipedia.org/wiki/Time_management#The_Eisenhower_Method">The Eisenhower Method</a>, and others).</p><p>All four layers together allow you to be an expert in your field. Leave one out, and there will always be something you do not fully understand. And when you don‚Äôt understand something, you cannot be fully efficient at it.</p><p>If you would like to find out more about how the Pyramid of Mastery applies to the field of productivity, I wrote a separate <a href="https://iuliangulea.com/pyramid-of-mastery/productivity/">article</a> on that topic.</p><h2 id="productivity-approaches">Productivity Approaches</h2><p>Generally speaking, you can be more productive by taking one or several of the following approaches:</p><p><strong>1. Delegate/Outsource the task.</strong> This approach is the most efficient from the time standpoint as it frees all your time and allows you to focus on other tasks. Although it is limited in how much you can delegate/outsource, it is crucial to keep in mind that you can and need to delegate.</p><p><strong>2. Automate the task.</strong> If you cannot delegate/outsource, think about whether your work on a task can be either fully or partially automated. There are lots of services, products, and programs that can do the work for you in a broad range of areas. If their cost is smaller than the value of the time you can save using them, then do it.</p><p><strong>3. Use better tools and learn them well.</strong> If automation is also not an option, then it means <em>you</em> need to do it. Having good tools is crucial if you want to be productive. A thorough understanding of their functions can make a big difference. In the case of software, learn its features and the shortcuts of the most frequently used functionality by you.</p><p><strong>4. Understand cognitive processes and learn what works best for you.</strong> Whenever we need to perform mental work, understanding <em>how</em> our <a href="https://iuliangulea.com/human-senses/">senses</a>, <a href="https://iuliangulea.com/attention/">attention</a>, <a href="https://iuliangulea.com/working-memory/">working memory</a>, and other relevant processes work can make a huge difference. As a plant flourishes, when the conditions are right, our brains can be incredibly performant whenever we offer them the right environment in which they can function.</p><h2 id="my-top-productivity-strategies">My Top Productivity Strategies</h2><p><strong>The Rule Of Threes.</strong> This is a meta strategy I came up with some time ago that help me make the right decisions when it comes to taking on new opportunities. No matter how productive you are, if you have too much on your plate, your attention and energy will split into too many places, and that will affect your productivity. The rule is simple: at any one point in time, I should have no more than three ongoing projects, and by an ongoing project, I mean any work that spans for longer than one week. Having more than that will scatter your energy and attention to the detriment of effectiveness.</p><p><strong>Plan Your Day In Advance.</strong> It is much easier to follow a predefined list of steps rather than having only the destination in mind and think about your next course of action after each task. The 10‚Äì15 minutes spent in the evening to decide and prioritize what you will work on will save you plenty of energy and time the following day.</p><h2 id="more-productivity-tips-for-every-day">More Productivity Tips For Every Day</h2><p><strong>1. Reduce Distractions As Much As Possible.</strong> If there is something that can distract you, sooner or later, it will distract you. Therefore, if you want to keep focused for a longer time, remove as many distractions as you can. This includes visual distractions on your table and screen (yes, those Facebook and Twitter tabs are hooking your attention pretty easy, aren‚Äôt they?), audial distractions (buy yourself a good pair of noise-canceling headphones), and other types of disturbances that distract you regularly.</p><p><strong>2. Put Your Phone Away.</strong> Although it is also a distraction, this tip deserves a separate mention. Put your phone on silent mode and away from your sight (not in your pocket). All those sounds (including notifications, calls, etc.) and flashes are nothing else than stimuli that have their primary goal to grab your attention and distract you from the thing you are focused on. It is also essential to put the phone away, as having it in your area of sight will also urge you to grab it when you see it on the table.</p><p><strong>3. Split Your Tasks Into Manageable Chunks.</strong> If an assignment is too big for you to comprehend, consider splitting it into several smaller subtasks until you get them of a size that you can easily accomplish. A positive side-effect of this is that smaller tasks provide a sense of progress, positively affecting your overall state and mood.</p><p><strong>4. Use Good Tools And Learn Them Properly.</strong> If you use software tools, learn the shortcuts of the programs you work in as it will save you dozens of hours within a year. If you use physical tools, buy high-quality tools, as they will pay off multiple times.</p><p><strong>5. Your Energy Is More Important Than The Allocated Time.</strong> Time Management is overrated. It‚Äôs not that timing your tasks is not essential, but <em>time is absolute.</em> It is independent of anything. Consider your energy levels when planning your tasks. Your energy is what matters when working on a job. You can spend 2 hours banging your head against something in the evening when you are tired and then complete that task in 30 minutes the next morning. Know when you are more productive and work on the most important tasks then.</p><p><strong>6. Use Visual Aids.</strong> A pen and a piece of paper are sometimes the best, simple, and most efficient productivity tools you can use. If the task you are working on relies on manipulating multiple pieces of information at a time, write them on paper or draw a diagram. That will free up resources necessary to store them in your working memory so that you can focus on processing and manipulating them instead. This will also involve your visual sense, allowing you to make more potentially relevant connections between ideas.</p><h2 id="all-productivity-articles">All Productivity Articles</h2><p>These are all articles I have written on productivity. Enjoy!</p><ul><li><a href="https://iuliangulea.com/keyboard-shortcuts/">6 Shortcuts That Save Me 62 Hours Each Year</a></li><li><a href="https://iuliangulea.com/pyramid-of-mastery/productivity/">The Ultimate Productivity Guide ‚Äî Scientifically Proven Techniques To Get Things Done</a></li><li><a href="https://iuliangulea.com/attention/">The Dual Nature Of Attention ‚Äî 5 Ways To Stay Less Distracted And Be More Productive</a></li><li><a href="https://iuliangulea.com/working-memory/">How People Learn ‚Äî Working Memory And The 3 Basic Rules Of Productivity</a></li><li><a href="https://iuliangulea.com/the-most-substantial-word/">Your Name ‚Äî The Most Substantial Word</a></li><li><a href="https://iuliangulea.com/how-i-automated-things/">How I Saved 14 Hours Of Working Time Each Month</a></li><li><a href="https://iuliangulea.com/one-percent-rule/">The One Percent Rule - How Tiny Changes Can Bring Big Results</a></li><li><a href="https://iuliangulea.com/team-processes-what/">Increase Your Team‚Äôs Productivity by Establishing Processes - Part III</a></li><li><a href="https://iuliangulea.com/team-processes-how/">Increase Your Team‚Äôs Productivity by Establishing Processes - Part II</a></li><li><a href="https://iuliangulea.com/team-processes-why/">Increase Your Team‚Äôs Productivity by Establishing Processes - Part I</a></li></ul><hr></div></div>]]>
            </description>
            <link>https://iuliangulea.com/productivity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043892</guid>
            <pubDate>Tue, 10 Nov 2020 08:38:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Smartphone Upgrades Are Impacting the Environment]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25043889">thread link</a>) | @scottbucks
<br/>
November 10, 2020 | https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades | <a href="https://web.archive.org/web/*/https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.3.0"><div dir="ltr"><div><div id="viewer-16t2j"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" data-pin-media="https://static.wixstatic.com/media/f361a8_da6af0458bd5469fb370e704386f86a3~mv2.jpeg/v1/fit/w_1000%2Ch_635%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/f361a8_da6af0458bd5469fb370e704386f86a3~mv2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg"></p></div><p><span dir="auto">Photo by Daniel Romero on Unsplash</span></p></div></div></div><p id="viewer-7arqh"><span>Smartphone technology is evolving rapidly. Every year there are better cameras, performance, refresh rates, screens and batteries. Tempted by a host of new features, people can't help but upgrade to the latest model, but what happens to all the smartphones we go through?

</span></p><p id="viewer-5o3kt"><span>The average lifespan of a smartphone is 3 to 4 years, perhaps even 5, but by that time the battery's capacity is likely to have decreased significantly. After an average lifespan has been reached, most people will throw away their smartphone and upgrade to a more recent model.</span></p><blockquote id="viewer-cmiam"><span><em>On average only 12,5% of electronic waste is recycled, with approximately 20 to 50 million metric tons of e-waste disposed of worldwide every year.</em></span></blockquote><p id="viewer-74ml0"><span>This is a huge problem for the environment due to the chemicals in these devices leaching into the groundwater system from landfills, polluting the land, water and air.</span></p><div id="viewer-bm1b6"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" data-pin-media="https://static.wixstatic.com/media/f361a8_e577402e314d40939016a7c158736c28~mv2.jpeg/v1/fit/w_794%2Ch_528%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/f361a8_e577402e314d40939016a7c158736c28~mv2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg"></p></div></div></div></div><p id="viewer-87pmv"><span>With companies constantly encouraging people to upgrade by stopping updates for older models, it renders them obsolete.

</span></p><p id="viewer-31crc"><span>Not only is this a problem for the environment, but by throwing away these devices, we are wasting precious metals such as copper, silver, gold, palladium and other raw materials, that would require significant resources to mine and manufacture.</span></p><div id="viewer-d1tql"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" data-pin-media="https://static.wixstatic.com/media/nsplsh_6a58643246537663527238~mv2.jpg/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/nsplsh_6a58643246537663527238~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-bqd9o"><span>
This is why it is important to recycle old cell phones and preserve these increasingly scarce materials where possible.


</span></p><p id="viewer-c1me1"><span>Here are some suggestions on how to alleviate these problems:

</span></p><ol><li id="viewer-4p3cu"><p>Instead of buying a new phone, why not change the battery? Often the smartphone is still in good condition.</p></li><li id="viewer-bqu6i"><p>Once you have had your smartphone for several years and have already changed the battery, you could recycle it and buy a new one. Some companies offer trade-ins fo credit to use on your next phone.</p></li><li id="viewer-16hl3"><p>You could buy a refurbished product; they are often as good as brand new with the added benefit it helps the environment and saves you money.</p></li><li id="viewer-1aql"><p>Instead of throwing the phone away you could sell it, or give it to a friend/family member.</p></li></ol><p id="viewer-26bo7"><span>The bottom line is currently we change smartphones too often. There is no specific amount of time that you should keep the same phone but when changing, think about where your phone may end up if you don't recycle it, sell it or pass it on to someone else.</span></p><p id="viewer-5oobg"><span>If you enjoyed this article, why not consider subscribing to our newsletter, or check out some of our <a href="http://thedetechtor.com/all-news" target="_blank" rel="noopener"><u>other posts</u></a><u>.</u> </span></p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043889</guid>
            <pubDate>Tue, 10 Nov 2020 08:37:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[YSFlight HQ: ‚ÄúSTART HERE ‚Äì What you need to know‚Äù]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25043835">thread link</a>) | @app4soft
<br/>
November 10, 2020 | https://forum.ysfhq.com/viewtopic.php?f=306&t=10520&p=116962#p116962 | <a href="https://web.archive.org/web/*/https://forum.ysfhq.com/viewtopic.php?f=306&t=10520&p=116962#p116962">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://forum.ysfhq.com/viewtopic.php?f=306&amp;t=10520&amp;p=116962#p116962</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043835</guid>
            <pubDate>Tue, 10 Nov 2020 08:26:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[This is how I git]]>
            </title>
            <description>
<![CDATA[
Score 228 | Comments 135 (<a href="https://news.ycombinator.com/item?id=25043731">thread link</a>) | @ingve
<br/>
November 10, 2020 | https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Every now and then I get questions on how to work with git in a smooth way when developing, bug-fixing or extending curl ‚Äì or how I do it. After all, I <a href="https://daniel.haxx.se/blog/2020/10/26/working-open-source/" data-type="post" data-id="14901">work on open source full time</a> which means I have very frequent interactions with git (and GitHub). Simply put, I work with git all day long. Ordinary days, I issue git commands several hundred times.</p>



<p>I have a very simple approach and way of working with git in curl. This is how it works.</p>



<h2>command line</h2>



<p>I use git almost exclusively from the command line in a terminal. To help me see which branch I‚Äôm working in, I have this little bash helper script.</p>



<pre>brname () {
  a=$(<code>git rev-parse --abbrev-ref HEAD 2&gt;/dev/null</code>)
  if [ -n "$a" ]; then
    echo " [$a]"
  else
    echo ""
  fi
}
PS1="\u@\h:\w\$(brname)$ "</pre>



<p>That gives me a prompt that shows username, host name, the current working directory and the current checked out git branch.</p>



<p>In addition: I use Debian‚Äôs <a href="https://salsa.debian.org/debian/bash-completion/-/blob/master/README.md">bash command line completion</a> for git which is also really handy. It allows me to use tab to complete things like git commands and branch names. </p>



<h2>git config</h2>



<p>I of course also have my customized <code>~/.gitconfig</code> file to provide me with some convenient aliases and settings. My most commonly used git aliases are:</p>


<pre title="">st = status --short -uno
ci = commit
ca = commit --amend
caa = commit -a --amend
br = branch
co = checkout
df = diff
lg = log -p --pretty=fuller --abbrev-commit
lgg = log --pretty=fuller --abbrev-commit --stat
up = pull --rebase
latest = log @^{/RELEASE-NOTES:.synced}..
</pre>


<p>The ‚Äòlatest‚Äô one is for listing all changes done to curl since the most recent RELEASE-NOTES ‚Äúsync‚Äù. The others should hopefully be rather self-explanatory.</p>



<p>The config also sets <code>gpgsign = true</code>, enables mailmap and a few other things.</p>



<h2>master is clean and working</h2>



<p>The main curl development is done in the single <a href="https://github.com/curl/curl">curl/curl</a> git repository (primarily hosted on GitHub). We keep the master branch the bleeding edge development tree and we work hard to always keep that working and functional. We do our releases off the master branch when that day comes (every eight weeks) and we provide ‚Äú<a href="https://curl.haxx.se/snapshots/">daily snapshots</a>‚Äù from that branch, put together ‚Äì yeah ‚Äì daily.</p>



<p>When merging fixes and features into master, we avoid merge commits and use rebases and fast-forward as much as possible. This makes the branch very easy to browse, understand and work with ‚Äì as it is 100% linear.</p>



<h2>Work on a fix or feature</h2>



<p>When I start something new, like work on a bug or trying out someone‚Äôs patch or similar, I first create a local branch off master and work in that. That is, I don‚Äôt work directly in the master branch. Branches are easy and quick to do and there‚Äôs no reason to shy away from having loads of them!</p>



<p>I typically name the branch prefixed with my GitHub user name, so that when I push them to the server it is noticeable who is the creator (and I can use the same branch name locally as I do remotely).</p>



<pre>$ git checkout -b bagder/my-new-stuff-or-bugfix</pre>



<p>Once I‚Äôve reached somewhere, I commit to the branch. It can then end up one or more commits before I consider myself ‚Äúdone for now‚Äù with what I was set out to do.</p>



<p>I try not to leave the tree with any uncommitted changes ‚Äì like if I take off for the day or even just leave for food or an extended break. This puts the repository in a state that allows me to easily switch over to another branch  when I get back ‚Äì should I feel the need to. Plus, it‚Äôs better to commit and explain the change <em>before</em> the break rather than having to recall the details again when coming back.</p>



<h2>Never stash</h2>



<p>‚Äúgit stash‚Äù is therefore not a command I ever use. I rather create a new branch and commit the (temporary?) work in there as a potential new line of work.</p>



<h2>Show it off and get reviews</h2>



<p>Yes I am the lead developer of the project but I still maintain the same work flow as everyone else. All changes, except the most minuscule ones, are done as pull requests on GitHub.</p>



<p>When I‚Äôm happy with the functionality in my local branch. When the bug seems to be fixed or the feature seems to be doing what it‚Äôs supposed to do and the test suite runs fine locally.</p>



<p>I then clean up the commit series with ‚Äú<code>git rebase -i</code>‚Äù (or if it is a single commit I can instead use just ‚Äú<code>git commit --amend</code>‚Äú).</p>



<p>The commit series should be a set of logical changes that are related to this change and not any more than necessary, but kept separate if they are separate. Each commit also gets its own proper commit message. Unrelated changes should be split out into its own separate branch and subsequent separate pull request.</p>



<pre>git push origin bagder/my-new-stuff-or-bugfix</pre>



<h2>Make the push a pull request</h2>



<p>On GitHub, I then make the newly pushed branch into a <a href="https://github.com/curl/curl/pulls">pull request</a> (aka ‚Äúa PR‚Äù). It will then become visible in the list of pull requests on the site for the curl source repository, it will be announced in the #curl IRC channel and everyone who follows the repository on GitHub will be notified accordingly.</p>



<p>Perhaps most importantly, a pull request kicks of a flood of CI jobs that will build and test the code in numerous different combinations and on several platforms, and the results of those tests will trickle in over the coming hours. When I write this, we have around 90 different CI jobs ‚Äì per pull request ‚Äì and something like 8 different code analyzers will scrutinize the change to see if there‚Äôs any obvious flaws in there.</p>



<figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-05-curl-Project-status-dashboard.png"><img loading="lazy" width="2686" height="1510" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-05-curl-Project-status-dashboard.png" alt=""></a><figcaption>CI jobs per platform over time. Graph snapped on November 5, 2020</figcaption></figure>



<h2>A branch in the actual curl/curl repo</h2>



<p>Most contributors who would work on curl would not do like me and make the branch in the curl repository itself, but would rather do them in their own forked version instead. The difference isn‚Äôt that big and I <em>could</em> of course also do it that way.</p>



<h2>After push, switch branch</h2>



<p>As it will take some time to get the full CI results from the PR to come in (generally a few hours), I switch over to the next branch with work on my agenda. On a normal work-day I can easily move over ten different branches, polish them and submit updates in their respective pull-requests.</p>



<p>I can go back to the&nbsp;master branch again with ‚Äò<code>git checkout master</code>‚Äò and there I can ‚Äú<code>git pull</code>‚Äù to get everything from upstream ‚Äì like when my fellow developers have pushed stuff in the mean time.</p>



<h2>PR comments or CI alerts</h2>



<p>If a reviewer or a CI job find a mistake in one of my PRs, that becomes visible on GitHub and I get to work to handle it. To either fix the bug or discuss with the reviewer what the better approach might be.</p>



<p>Unfortunately, flaky CI jobs is a part of life so very often there ends up one or two red markers in the list of CI jobs that can be ignored as the test failures in them are there due to problems in the setup and not because of actual mistakes in the PR‚Ä¶</p>



<p>To get back to my branch for that PR again, I ‚Äú<code>git checkout bagder/my-new-stuff-or-bugfix</code>‚Äú, and fix the issues.</p>



<p>I normally start out by doing follow-up commits that repair the immediate mistake and push them on the branch:</p>



<pre>git push origin <code>bagder/my-new-stuff-or-bugfix</code></pre>



<p>If the number of fixup commits gets large, or if the follow-up fixes aren‚Äôt small, I usually end up doing a squash to reduce the number of commits into a smaller, simpler set, and then force-push them to the branch.</p>



<p>The reason for that is to make the patch series easy to review, read and understand. When a commit series has too many commits that changes the previous commits, it becomes hard to review.</p>



<h2>Ripe to merge?</h2>



<p>When the pull request is ripe for merging (independently of who authored it), I switch over to the master branch again and I merge the pull request‚Äôs commits into it. In special cases I cherry-pick specific commits from the branch instead. When all the stuff has been yanked into master properly that should be there, I push the changes to the remote.</p>



<p>Usually, and especially if the pull request wasn‚Äôt done by me, I also go over the commit messages and polish them somewhat before I push everything. Commit messages should follow our style and mention not only which PR that it closes but also which issue it fixes and properly give credit to the bug reporter and all the helpers ‚Äì using the right syntax so that our automatic tools can pick them up correctly!</p>



<p>As already mentioned above, I merge fast-forward or rebased into master. No merge commits.</p>



<h2>Never merge with GitHub!</h2>



<p>There‚Äôs a button GitHub that says ‚Äúrebase and merge‚Äù that could theoretically be used for merging pull requests. I <em>never</em> use that (and if I could, I‚Äôd disable/hide it). The reasons are simply:</p>



<ol><li>I don‚Äôt feel that I have the proper control of the commit message(s)</li><li>I can‚Äôt select to squash a subset of the commits, only all or nothing</li><li>I often want to cleanup the author parts too before push, which the UI doesn‚Äôt allow</li></ol>



<p>The downside with not using the merge button is that the message in the  PR says ‚Äúclosed by [hash]‚Äù instead of ‚Äúmerged in‚Ä¶‚Äù which causes confusion to a fair amount of users who don‚Äôt realize it means that it actually means the same thing! I consider this is a (long-standing) GitHub UX flaw.</p>



<h2>Post merge</h2>



<p>If the branch has nothing to be kept around more, I delete the local branch again with ‚Äú<code>git branch -d [name]</code>‚Äù and I remove it remotely too since it was completely merged there‚Äôs no reason to keep the work version left.</p>



<p>At any given point in time, I have some 20-30 different local branches alive using this approach so things I work on over time all live in their own branches and also submissions from various people that haven‚Äôt been merged into master yet exist in branches of various maturity levels. Out of those local branches, the number of concurrent pull requests I have in progress can be somewhere between just a few up to ten, twelve something.</p>



<h2>RELEASE-NOTES</h2>



<p>Not strictly related, but in order to keep interested people informed about what‚Äôs happening in the tree, we sync the <a href="https://github.com/curl/curl/blob/master/RELEASE-NOTES">RELEASE-NOTES</a> file every once in a while. Maybe every 5-7 days or so. It ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/">https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/</a></em></p>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043731</guid>
            <pubDate>Tue, 10 Nov 2020 08:08:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Event, 18th Nov: Building a Notion Website Live]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25043693">thread link</a>) | @saviorand
<br/>
November 9, 2020 | http://optemization.com/how-to-build-notion-website | <a href="https://web.archive.org/web/*/http://optemization.com/how-to-build-notion-website">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article id="block-how-to-build-notion-website"><div id="block-128d927961c546d8870b1a51a5579a93"><picture><source srcset="https://api.super.so/asset/optemization.com/67b219ac-6de7-482c-b615-91d148315e54.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/67b219ac-6de7-482c-b615-91d148315e54.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/67b219ac-6de7-482c-b615-91d148315e54.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/67b219ac-6de7-482c-b615-91d148315e54.png?w=1500" alt="image" loading="lazy"></picture></div><h2 id="block-d2269dc812f14b90932490290a797437"><span id="d2269dc812f14b90932490290a797437"></span><span><span>üñ•Ô∏è You can do websites on Notion?</span></span></h2><blockquote id="block-2d6de681f9a04563af1656151a4a72ac"><span><span>If you spend anytime on #productivity Twitter or r/Notion you know that building websites on Notion, is the new normal :)  Thanks to projects like Super and Fruition, Notion pages can turn into real websites, with custom domains, analytics, and styling!

My new teammate Valentine, just shared a </span><span><a target="_blank" rel="noopener noreferrer" href="https://optemization.com/notion-landing-page-guide">comprehensive guide</a></span><span> on how to build your own Notion website. 

However, this stuff is really visual, so we thought it'd be super fun to host an </span><span><strong>event where we conceptualize, design and ship a Notion website LIVE</strong></span><span>! 

So two things: RSVP below and tell us what kind of website do you want to build!</span></span></blockquote><h2 id="block-1b34e201f6484d4680c97fe88b965d4c"><span id="1b34e201f6484d4680c97fe88b965d4c"></span><span><span>üñãÔ∏è Sign Up</span></span></h2><h2 id="block-b67496c5fc8b4bdcb04d5891dc6baf0b"><span id="b67496c5fc8b4bdcb04d5891dc6baf0b"></span><span><span>üòÉ Are you excited?</span></span></h2><div id="block-c91d2a953127494f86a21d77c34339ea"><div id="block-f2134537e8d04052915c6399871b09eb"><blockquote id="block-7d5a84aa13624e43ba7e69fbac453dea"><span><span>Share the event on the ze twitter üôè</span></span></blockquote></div></div></article></div></div></div>]]>
            </description>
            <link>http://optemization.com/how-to-build-notion-website</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043693</guid>
            <pubDate>Tue, 10 Nov 2020 07:56:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[2020 Haskell Is Ready for Prime Time]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25043675">thread link</a>) | @_query
<br/>
November 9, 2020 | https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55 | <a href="https://web.archive.org/web/*/https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>by Marc Scholten, 29.10.2020</em></p>

<p>
There‚Äôs been a recent blog post <a href="https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1" target="_blank"><q>Haskell: The Bad Parts</q></a> in the haskell community. To keep things in balance and to spread some positive vibes we should also talk about the good parts of the haskell programming language and it‚Äôs ecosystem.
</p>

<p>
Here are some of the best parts we encountered while using Haskell at digitally induced. We focus on the advantages in the web dev space because that is what we are currently working on.
</p>

<h2>Type Safety</h2>
<p>
Haskell has one of the most impressive type systems of any programming language in practical use. If you have used TypeScript or other type safe languages in the past, you should be aware of the great advantages of having a type-checked codebase. Now think TypeScript - but 10x better. That‚Äôs how Haskell feels like.
</p>

<p>
You save a lot of time debugging runtime errors. Once the compiler approved your code, you can be pretty sure that it is working. This kind of development process is usually a lot more fun than debugging why something is <code>null</code> or <code>undefined</code>.
</p>

<p>
Once your system has hit a certain size and when new feature requests are rolling in you will want to make changes and refactor some parts of your code base. With Haskell you feel empowered to make changes to any part of your codebase.
</p>

<p>
Compare this to the ruby ecosystem: When working with rails you usually need to have lots of tests or otherwise you cannot confidently refactor code after things are running in production. And even then things will break. With the power of the type safety provided by Haskell, we can make refactorings whenever we want.
</p>

<p>
It‚Äôs really a blessing.
</p>

<h2>Managed Side Effects</h2>
<p>The way you deal with the file system, external APIs and user input is way different in Haskell than in other less functional programming languages. Your program consists of a main routine that handles the side effects and calls all your pure functions that do the real business logic.</p>

<p>
Systems build this way scale really well because there are less moving parts. Additionally pure functions can be easily tested and changed later on.
</p>

<p>
Most other languages encourage you to do side effects in an unrestricted way. For example when working in Java, a call to an object method might indirectly change the state of many related objects. This means you cannot easily reason about what a method calls does. In Haskell most functions are pure and thus don't trigger side effects like this. And when they do you can see this already by the function's type signature.
</p>

<p>
Haskell forces you to manage your side effects in a more careful way. You can still do IO and have mutable state, you just need to make this explicit inside the type signature. This leads to a far more robust system in overall.
</p>

<h2>Performance</h2>
<p>
Out of the box the performance of Haskell based web applications is great. It just feels faster than your typical Rails or PHP application. Thanks to it‚Äôs highly optimized runtime system it can also <a href="https://www.yesodweb.com/blog/2011/03/preliminary-warp-cross-language-benchmarks" target="_blank">handle way more requests than a nodejs application</a>.
</p>

<p>
And you get all that without ever thinking about performance at all. 
</p>

<h2>Tooling</h2>
<p>In 2020 it‚Äôs finally good. Thanks to <a href="https://github.com/haskell/haskell-language-server" target="_blank">Haskell Language Server</a> there‚Äôs now an easy way to have type information, documentation on hover and smart refactorings inside your text editor.</p>

<p>
With nix, cabal and stack we have the best tools for managing Haskell dependencies. Cabal hell is a thing of the past.
</p>

<p>
Great things are also happening to the Haskell compiler itself. <a href="https://github.com/ghc-proposals/ghc-proposals/pull/282" target="_blank">We soon can write dot expressions as you know from most other programming languages:</a> <code>project.name</code> instead of <code>name project</code>.
</p>

<h2>Hiring Haskell Developers</h2>
<p>
Haskell is a secret super power in that regard. The Haskell community consists of many very smart and talented software engineers. Haskell developers usually learn about Haskell because they care about their craft and about building high quality software products instead of learning about it to get a high paying job. Exactly the kind of people you want in your team.
</p>

<h2>2020 Haskell is Ready for Prime Time</h2>
<p>
For years there has been this trend of growing use of type safety as well as the growing use of functional programming techniques. What language could fill this space better than Haskell. Haskell has really matured in the last years and in 2020 it feels like it‚Äôs finally ready to conquer the world.
</p>

<p>
If this post made you interested, <a href="https://ihp.digitallyinduced.com/" target="_blank">check out IHP, our batteries-included haskell web framework.</a>
</p></div></div>]]>
            </description>
            <link>https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043675</guid>
            <pubDate>Tue, 10 Nov 2020 07:50:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why's (Poignant) Guide to Ruby (2004)]]>
            </title>
            <description>
<![CDATA[
Score 339 | Comments 143 (<a href="https://news.ycombinator.com/item?id=25043544">thread link</a>) | @creolabs
<br/>
November 9, 2020 | https://poignant.guide/book/chapter-2.html | <a href="https://web.archive.org/web/*/https://poignant.guide/book/chapter-2.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<h2>1. Opening This Book</h2>

<p>Pretend that you‚Äôve opened this book (although you probably <em>have</em> opened this
book), just to find a huge onion right in the middle crease of the book. (The
manufacturer of the book has included the onion at my request.)</p>

<p>So you‚Äôre like, ‚ÄúWow, this book comes with an onion!‚Äù (Even if you don‚Äôt
particularly like onions, I‚Äôm sure you can appreciate the logistics of shipping
any sort of produce discreetly inside of an alleged programming manual.)</p>

<p>Then you ask yourself, ‚ÄúWait a minute. I thought this was a book on Ruby, the
incredible new programming language from Japan. And although I can appreciate
the logistics of shipping any sort of produce discreetly inside of an alleged
programming manual: Why an onion? What am I supposed to do with it?‚Äù</p>

<p>No. Please don‚Äôt puzzle over it. You don‚Äôt need to do anything with the onion.
Set the onion aside and let <em>it</em> do something with <em>you</em>.</p>

<p>I‚Äôll be straight with you. I want you to cry. To weep. To whimper sweetly. This
book is a <strong>poignant</strong> guide to Ruby. That means code so beautiful that tears
are shed. That means gallant tales and somber truths that have you waking up the
next morning in the arms of this book. Hugging it tightly to you all the day
long. If necessary, fashion a makeshift hip holster for <em>Why‚Äôs (Poignant) Guide
to Ruby</em>, so you can always have this book‚Äôs tender companionship.</p>

<p>You really must sob once. Or at least sniffle. And if not, then the onion will
make it all happen for you.</p>





<h2>2. The Dog Story</h2>

<p>So try this first bit of poignancy on for size:</p>

<p>One day I was walking down one of those busy roads covered with car dealerships
(this was shortly after my wedding was called off) and I found an orphaned dog
on the road. A woolly, black dog with greenish red eyes. I was kind of feeling
like an orphan myself, so I took a couple balloons that were tied to a pole at
the dealership and I relocated them to the dog‚Äôs collar. Then, I decided he
would be my dog. I named him Bigelow.</p>

<p>We set off to get some Milkbones for Bigelow and, afterwards, head over to my
place, where we could sit in recliners and listen to Gorky‚Äôs Zygotic Mynci. Oh,
and we‚Äôd also need to stop by a thrift store and get Bigelow his own recliner.</p>

<p>But Bigelow hadn‚Äôt accepted me as his master. So five minutes later, the stupid
dog took a different crosswalk than I did and I never caught up. So whereas he
had previously only been lost once, he was now lost twice. I slowed my pace
towards the life of Milkbones and an extra recliner. I had a dog for five
minutes.</p>

<p>Stupid Benedict Arnold of a dog. I sat on a city bench and threw pine cones at a
statue of three sheep crossing a bridge. After that, I wept for hours. The tears
just came. Now there‚Äôs a little something poignant to get you started.</p>

<p>I wonder where he went with all those balloons. That crazy dog must have looked
like a party with legs.</p>

<p>It wasn‚Äôt much later that I pulled my own Bigelow. I printed out a bunch of
pages on Ruby. Articles found around the Web. I scanned through them on a train
ride home one day. I flipped through them for five minutes and then gave up. Not
impressed.</p>

<p>I sat, staring out the window at the world, a life-sized blender mixing graffiti
and iron smelts before my eyes. <em>This world‚Äôs too big for such a a little
language</em>, I thought. <em>Poor little thing doesn‚Äôt stand a chance. Doesn‚Äôt have
legs to stand on. Doesn‚Äôt have arms to swim.</em></p>

<p>And yet, there I was. One little man on a flimsy little train (and I even still
had a baby tooth to lose at the time) out of billions of people living on a
floating blue rock. How can I knock Ruby? Who‚Äôs to say that I‚Äôm not going to
happen to choke on my cell phone and die later that evening. Why‚Äôs dead, Ruby
lives on.</p>

<p>The gravestone:</p>

<blockquote>
  <p>What‚Äôs in his trachea? Oh, look, a Nokia!</p>
</blockquote>

<p>Just my luck. Finally get to have a good, long sleep underground, only to be
constantly disturbed by <em>Pachelbel‚Äôs Canon</em> going off in my stomach.</p>



<h2>3. The Red Sun Rises</h2>

<p>So, now you‚Äôre wondering why I changed my mind about Ruby. The quick answer is:
we clicked.</p>

<p>Like when you meet Somebody in college and they look like somebody who used to
hit you in the face with paintbrushes when you were a kid. And so, impulsively,
you conclude that this new Somebody is likely a non-friend. You wince at their
hair. You hang up phones loudly during crucial moments in their anecdotes. You
use your pogo stick right there where they are trying to walk!</p>

<p>Six months later, somehow, you and Somebody are sitting at a fountain having a
perfectly good chat. Their face doesn‚Äôt look so much like that childhood
nemesis. You‚Äôve met the Good Twin. You clicked.</p>

<p>So whereas I should probably be pounding your teeth in with hype about Ruby and
the tightly-knit cadre of pertinent acronyms that accompany it everywhere
(whetting the collective whistles of your bosses and their bosses‚Äô bosses),
instead I will just let you coast. I‚Äôll let you free-fall through some code,
interjecting occasionally with my own heartfelt experiences. It‚Äôll be quite
easy, quite natural.</p>

<p>I should offer you some sort of motivation, though. So, Smotchkkiss, I‚Äôm going
to give my three best reasons to learn Ruby and be done with it.</p>

<ol>
  <li>
    <p><strong>Brain health.</strong></p>

    <p>Vitamin R. Goes straight to the head. Ruby will teach you to <em>express</em> your
ideas through a computer. You will be writing stories for a machine.</p>

    <p>Creative skills, people. Deduction. Reason. Nodding intelligently. The
language will become a tool for you to better connect your mind to the world.
I‚Äôve noticed that many experienced users of Ruby seem to be clear thinkers and
objective. (In contrast to: heavily biased and coarse.)</p>
  </li>
  <li>
    <p><strong>One man on one island.</strong></p>

    <p>Ruby was born in Japan. Which is freaky. Japan is not known for its
software. And since programming languages are largely written in English, who
would suspect a language to come from Japan?</p>

    <p>And yet, here we have Ruby. Against the odds, Yukihiro Matsumoto created
Ruby on February 24, 1993. For the past ten years, he has steadily brought Ruby
to a global audience. It‚Äôs triumphant and noble and all that. Support diversity.
Help us tilt the earth just a bit.</p>
  </li>
  <li>
    <p><strong>Free.</strong></p>

    <p>Using Ruby costs nothing. The code to Ruby itself is open for all of the
world to inhale/exhale. Heck, this book is free. It‚Äôs all part of a great, big
giveaway that should have some big hitch to it.</p>

    <p>You‚Äôd think we‚Äôd make you buy vacuums or timeshare or fake Monets. You‚Äôd
think there‚Äôd be a 90 minute presentation where the owner of the company comes
out at the end and knuckles you into sealing the deal.</p>

    <p>Nope, free.</p>
  </li>
</ol>

<p>With that, it‚Äôs time for the book to begin. You can now get out your highlighter
and start dragging it along each captivating word from this sentence on. I think
I have enough hairspray and funny money on my person to keep me sustained until
the final page.</p>



<h2>4. How Books Start</h2>

<p>Now, if you ever have read a book, you know that no book can properly start
without an exorbitant amount of synergy. Yes, synergy. Maybe you didn‚Äôt know
this. Synergy means that you and I are supposed to cooperate to make this a
great reading experience.</p>

<p>We start off the book by getting along well in the Introduction. This
togetherness, this <strong>synergy</strong>, propels us through the book, with me guiding you
on your way. You give me a reassuring nod or snicker to indicate your progress.</p>

<p>I‚Äôm Peter Pan holding your hand. Come on, Wendy! Second star to the right and on
till morning.</p>

<p>One problem here. I don‚Äôt get along well with people. I don‚Äôt hold hands very
well.</p>

<p>Any of my staff will tell you. At the Opening Ceremonies of This Book (a catered
event with stadium seating), I discovered that the cucumber sandwiches weren‚Äôt
served in tea towels. As a result, the butter hadn‚Äôt set with the cucumbers
right‚Ä¶ Anyways, I made a big scene and set fire to some of the advertising
trucks outside. I smashed this spotlight to pieces and so on. I had this loud
maniacal laughing thing going on deep into that night. It was a real mess.</p>

<p>But, since I don‚Äôt get along well with people, I hadn‚Äôt invited anyone but
myself to the Opening Ceremonies of This Book. So it wasn‚Äôt really that
embarrassing. I kept it under wraps and no one found out about the whole ordeal.</p>

<p>So you‚Äôve got to know that <strong>synergy</strong> doesn‚Äôt actually mean <strong>synergy</strong> in this
book. I can‚Äôt do normal <strong>synergy</strong>. No, in this book, <strong>synergy</strong> means
<strong>cartoon foxes</strong>. What I‚Äôm saying is: this book will be starting off with an
exorbitant amount of <strong>cartoon foxes</strong>.</p>

<p>And I will be counting on you to turn them into <strong>synergy</strong>.</p>


      <p>
      <a href="https://poignant.guide/book/chapter-3.html">Turn page.</a>
      </p>
    </div></div>]]>
            </description>
            <link>https://poignant.guide/book/chapter-2.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043544</guid>
            <pubDate>Tue, 10 Nov 2020 07:26:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My new GoBlog-Blog is finally alive]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25043497">thread link</a>) | @jlelse
<br/>
November 9, 2020 | https://jlelse.blog/posts/new-blog-goblog | <a href="https://web.archive.org/web/*/https://jlelse.blog/posts/new-blog-goblog">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I spent months coding and it‚Äôs finally time to say ‚ÄúHello World‚Äù!</p><p>Until a few hours ago I used a complicated setup of Hugo, Drone, Webmentiond, Caddy and some self-programmed tools for my blog to have an IndieWeb compatible blog with support for MicroPub, Webmentions, ActivityPub, IndieAuth, Telegram notifications and more. A use case that actually calls for a dynamic backend.</p><p>The dynamic backend is finally here. Finally no more workarounds!</p><p>I decided to develop my own CMS because it gives me the opportunity to know my code inside and out and in case of problems I know directly where to look for it. I developed the code to the best of my conscience so that everything is done as efficiently as possible. And I will be able to add more features to my blog much easier in the future!</p><p>I am especially happy about the function that I can now finally edit or delete posts. Far too often it happened to me that I had mistakes in the text or made stupid mistakes while creating the post itself. These can now be corrected directly.</p><p>To the technology behind the blog: The CMS is written in Go (my current favorite programming language!) and SQLite is used for database purposes.</p><p>The code is available <a href="https://jlel.se/goblog" target="_blank" rel="noopener">on my Gitea instance</a>. In the next days I will fix bugs I find and add a documentation and license.</p><p>P.S.: Sorry for the name of this project, ‚ÄúGoBlog‚Äù is a pretty lame name, feel free to send me better suggestions!</p></div></div>]]>
            </description>
            <link>https://jlelse.blog/posts/new-blog-goblog</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043497</guid>
            <pubDate>Tue, 10 Nov 2020 07:15:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hottest FinTech Accelerators in London]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25043490">thread link</a>) | @cpepper
<br/>
November 9, 2020 | https://codeandpepper.com/fintech-accelerators-in-london/ | <a href="https://web.archive.org/web/*/https://codeandpepper.com/fintech-accelerators-in-london/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://codeandpepper.com/fintech-accelerators-in-london/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043490</guid>
            <pubDate>Tue, 10 Nov 2020 07:13:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kotlin for Interviews ‚Äì Part 5: Frequently Used Code Snippets]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25043477">thread link</a>) | @joannawyka
<br/>
November 9, 2020 | https://blog.kotlin-academy.com/kotlin-for-interviews-part-5-frequently-used-code-snippets-444ad4d137f5 | <a href="https://web.archive.org/web/*/https://blog.kotlin-academy.com/kotlin-for-interviews-part-5-frequently-used-code-snippets-444ad4d137f5">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><div><div><div><p><a href="https://medium.com/@sherryyuan?source=post_page-----444ad4d137f5--------------------------------" rel="noopener"><img alt="Sherry Yuan" src="https://miro.medium.com/fit/c/96/96/1*vPHsbna8rWXF2trnsf3w3Q.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/9792/0*_88Jukrh3Lx8aLKV" width="4896" height="3264" srcset="https://miro.medium.com/max/552/0*_88Jukrh3Lx8aLKV 276w, https://miro.medium.com/max/1104/0*_88Jukrh3Lx8aLKV 552w, https://miro.medium.com/max/1280/0*_88Jukrh3Lx8aLKV 640w, https://miro.medium.com/max/1400/0*_88Jukrh3Lx8aLKV 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*_88Jukrh3Lx8aLKV?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@fabulu75?utm_source=medium&amp;utm_medium=referral" rel="noopener">Fabrice Villard</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="26ee">This is Part 5 of Kotlin for Interviews, a series where I go over Kotlin functions and code snippets that came up often during my Android interview prep. I also compiled a cheatsheet that covers all 5 parts of this series, which you can find <a rel="noopener" href="https://blog.kotlin-academy.com/kotlin-for-interviews-cheatsheet-88a9831e9d55">here</a>.</p><p id="01a2">You can find Part 1: Common Data Types <a rel="noopener" href="https://blog.kotlin-academy.com/kotlin-for-interviews-part-1-common-data-types-886ea1e40645">here,</a> Part 2: Collection Functions <a rel="noopener" href="https://blog.kotlin-academy.com/kotlin-for-interviews-part-2-collection-functions-a4a488fa0a14">here</a>, Part 3: Numbers and Math <a rel="noopener" href="https://blog.kotlin-academy.com/kotlin-for-interviews-part-3-numbers-and-math-786660295cea">here</a>, and Part 4: Iteration <a rel="noopener" href="https://blog.kotlin-academy.com/kotlin-for-interviews-part-4-iteration-b176dee4f1ae">here</a>.</p><p id="b016">This part covers:</p><ul><li id="54c0"><a href="#7ff6" rel="noopener">Creating graphs in adjacency list form</a></li><li id="7140"><a href="#41f6" rel="noopener">Breadth first search</a></li><li id="59ac"><a href="#04fe" rel="noopener">Depth first search</a></li><li id="c993"><a href="#de2a" rel="noopener">Tree traversal</a></li><li id="1f74"><a href="#a810" rel="noopener">Dynamic programming/memoization</a></li></ul><p id="f75e">We‚Äôll go over blocks of code that I found myself using frequently for many different problems. For example, a lot of interview problems boil down to depth-first search, and I used variations of the basic depth-first search code snippet to solve them.</p><p id="44f7">For many graph problems, you‚Äôll be given a list of pairs of nodes, where the second node depends on the first node (or vice versa depending on your interviewer). For example, a pair that looks like [0, 1] means in to visit node 1 you have to first visit 0. However, most graph algorithms require an <a href="https://www.geeksforgeeks.org/graph-and-its-representations/" rel="noopener">adjacency list representation</a>, so here‚Äôs an algorithm that takes in a list of pairs of nodes and transforms it into an adjacency list.</p><p id="8a38">Given this sample input:</p><p id="5c2b">[[1, 2], [1, 3], [1, 4], [2, 4], [2, 5], [3, 6], [4,6], [4, 7], [5, 4], [5, 7]]</p><p id="534e">Which represents this graph:</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/678/0*rgGD2S73ez7BXF3p.gif" width="339" height="196" srcset="https://miro.medium.com/max/552/0*rgGD2S73ez7BXF3p.gif 276w, https://miro.medium.com/max/678/0*rgGD2S73ez7BXF3p.gif 339w" sizes="339px" data-old-src="https://miro.medium.com/freeze/max/60/0*rgGD2S73ez7BXF3p.gif?q=20"></p></div></div></div></figure><p id="ed37">We want to create the following adjacency list:</p><p id="4281">[[1: [2, 4, 3]], [2: [4, 5]], [3: [6]], [4: [6, 7, 3]], [5: [4, 7]], [7: [6]]]</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/822/0*5sXb9IqIdUnslrrg.gif" width="411" height="339" srcset="https://miro.medium.com/max/552/0*5sXb9IqIdUnslrrg.gif 276w, https://miro.medium.com/max/822/0*5sXb9IqIdUnslrrg.gif 411w" sizes="411px" data-old-src="https://miro.medium.com/freeze/max/60/0*5sXb9IqIdUnslrrg.gif?q=20"></p></div></div></figure><pre><span id="d234"><strong>fun createAdjacencyList(pairs: Array&lt;IntArray&gt;) {<br>    val graph: HashMap&lt;Int, MutableList&lt;Int&gt;&gt; = <em>hashMapOf</em>()<br>    pairs.<em>forEach </em>{ pair -&gt;<br>        if (!graph.containsKey(pair[0])) {</strong><br><em>            // If the current node isn't in the adjacency list yet, <br>            // add it and create its dependency list starting with <br>            // pair[1]</em><br>            <strong>graph[pair[0]] = <em>mutableListOf</em>(pair[1])</strong><br>        <strong>} else {</strong><br><em>            // Otherwise, append pair[1] to its existing dependency  <br>            // list.<br>            </em><strong>val dependencies = graph[pair[0]]                 <br>            dependencies.add(pair[1])<br>            graph[pair[0]] = dependencies<br>        }<br>    }<br>}</strong></span></pre><p id="85d8">Note that this algorithm is for directed graphs. If you‚Äôre told the graph is undirected ‚Äî meaning the pair [0, 1] just means 0 and 1 have an edge between them ‚Äî just repeat the code in the <code>forEach()</code> loop with <code>pair[0]</code> and <code>pair[1]</code> swapped, so that the <code>MutableList</code>s in the graph represent all adjacent nodes rather than directed dependencies only.</p><p id="f882">Many interview problems require traversing graphs ‚Äî from finding a node to checking for cycles to finding the length of a path between two nodes. Breadth-first search is one way to do it. The algorithm starts at some node of the graph and, with the help of a queue, explores all of the neighbor nodes at the present depth before moving on to the nodes at the next depth level.</p><p id="f276">Here‚Äôs a basic version that traverses through all nodes reachable from the first one. You can modify it depending on the graph problem you‚Äôre solving.</p><pre><span id="3d8a"><strong>fun bfs(nodes: List&lt;List&lt;Int&gt;&gt;) {<br>    val visited = BooleanArray(nodes.size) { false }<br>    </strong><em>// Create a queue and add 0 to represent the index of the <br>    // first node</em><strong><br>    val queue: MutableList&lt;Int&gt; = mutableListOf(0)<br>    while (queue.isNotEmpty()) {<br>        </strong><em>// Dequeue a node from queue</em><br><strong>        val node = queue.removeAt(0)<br>        </strong><em>// Add all of the node's unvisited neighbors to the queue</em><br><strong>        if (!visited[node]) {<br>            nodes[node].forEach {<br>                queue.add(it)<br>            }<br>            </strong><em>// Mark the dequeued node as visited</em><strong><br>            visited[node] = true<br>        }<br>    }<br>}</strong></span></pre><p id="b5d9">Depth first search can also be used for graph traversal problems. The algorithm uses a stack instead of a queue, and explores the current node branch as far as possible before being forced to backtrack and expand to other nodes.</p><p id="1695">Here‚Äôs a recursive version that relies on a function call stack rather than an explicit stack variable. You could write an iterative version of the algorithm using a stack variable, as well.</p><pre><span id="6674"><strong>fun dfs(nodes: List&lt;List&lt;Int&gt;&gt;) {<br>    val visited = BooleanArray(nodes.size) { false }<br>    helper(nodes, 0, visited)<br>}<p> fun helper(nodes: List&lt;List&lt;Int&gt;&gt;, node: Int, visited: BooleanArray){<br>    visited[node] = true<br>    nodes[node].forEach { <br>        if (!visited[it]) {<br>            helper(nodes, it, visited)<br>        }<br>    }<br>}</p></strong></span></pre><p id="fe20">Tree problems are very common in interviews. Some examples are finding the lowest common ancestor of two nodes, summing values of all nodes in a tree, etc.</p><h2 id="af17">Binary tree</h2><p id="210a">Binary trees are the most common tree you‚Äôll encounter in interviews. A node for a binary tree will look something like this:</p><pre><span id="799f"><strong>class Node(<br>    var key: Int, <br>    var left: Node? = null, <br>    var right: Node? = null<br>)</strong></span></pre><p id="f740">Note that not all binary trees are binary search trees, and you shouldn‚Äôt assume you‚Äôre given a BST unless your interviewer confirms it. A binary tree is only a BST if it also fulfills the following criteria:</p><ul><li id="3333">The left subtree of a node contains only nodes with keys lesser than the node‚Äôs key.</li><li id="ac35">The right subtree of a node contains only nodes with keys greater than the node‚Äôs key.</li><li id="cc9a">The left and right subtree each must also be a binary search tree.</li></ul><p id="404d">Let‚Äôs use this tree (which isn‚Äôt a BST!) as an example:</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/692/1*h1NH-OTJ8cfHdoHa2eyRSQ.png" width="346" height="258" srcset="https://miro.medium.com/max/552/1*h1NH-OTJ8cfHdoHa2eyRSQ.png 276w, https://miro.medium.com/max/692/1*h1NH-OTJ8cfHdoHa2eyRSQ.png 346w" sizes="346px" data-old-src="https://miro.medium.com/max/60/1*h1NH-OTJ8cfHdoHa2eyRSQ.png?q=20"></p></div></div></figure><p id="e216">You can construct it using the following code:</p><pre><span id="4e2f"><strong>val node4 = Node(4)<br>val node7 = Node(7)<br>val node6 = Node(6, node4, node7)<br>val node11 = Node(11)<br>val node9 = Node(9, node6, node11)<br>val node2 = Node(2)<br>val node5 = Node(5)<br>val node12 = Node(12, node2, node5)<br>val node3 = Node(3, node12)<br>val node1 = Node(1, node9, node3)</strong></span></pre><p id="1981">Here‚Äôs what a pre-order traversal would look like:</p><pre><span id="c617"><strong>fun preOrder(n: Node?) {<br>    n?.let { node -&gt;<br>        print(node.key)<br>        preOrder(node.left)<br>        preOrder(node.right)<br>    }<br>}</strong></span><span id="1af2"><strong>preOrder(node1)</strong> <em>// prints 1 9 6 4 7 11 3 12 2 5</em></span></pre><p id="1b19">Here‚Äôs what an in-order traversal would look like:</p><pre><span id="fdff"><strong>fun inOrder(n: Node?) {<br>    n?.let { node -&gt;<br>        inOrder(node.left)<br>        print(node.key)<br>        inOrder(node.right)<br>    }<br>}</strong></span><span id="d60d"><strong>inOrder(node1</strong>) <em>// prints 4 6 7 9 11 1 2 12 5 3</em></span></pre><p id="9ac2">Here‚Äôs what a post-order traversal would look like:</p><pre><span id="f525"><strong>fun postOrder(n: Node?) {<br>    n?.let { node -&gt;<br>        postOrder(node.left)<br>        postOrder(node.right)<br>        print(node.key)<br>    }<br>}</strong></span><span id="6e90"><strong>postOrder(node1)</strong> <em>// prints 4 7 6 11 9 2 5 12 3 1</em></span></pre><h2 id="e208">Tree with multiple children</h2><p id="21d6">You may also encounter trees that have an array of children rather than left and right nodes. An example of this data structure would be the Android view hierarchy, where each view may have multiple children.</p><pre><span id="c915"><strong>class Node(var value: Int) {<br>  val children: List&lt;Node&gt;<br>}</strong></span></pre><p id="12a8">In this case, you‚Äôd have to recursively call your function on all the children and the code would look something like this:</p><pre><span id="646a"><strong>fun traverse(node: Node) {<br>    print(node.key)<br>    node.children.forEach {<br>        traverse(it)<br>    }<br>}</strong></span></pre><p id="a239">Whenever you end up with a recursive algorithm that has repeated calls with same inputs, you can likely optimize it using dynamic programming. The idea is to store the results of subproblems in a table so that we don‚Äôt have to re-compute them when needed later. This reduces time complexities from exponential to polynomial. It can be implemented using either iteration or recursion.</p><h2 id="9498">Iteration</h2><p id="edbd">We start from the smallest <code>i</code> and fill the results table from there. Every subproblem we need for the current iteration should be solved already. In the final iteration, we solve for <code>i=n</code> and return that result.</p><pre><span id="df7b"><strong>fun fibonacci(n: Int): Int {</strong><br>    <em>// Initialize an array to keep track of results of subproblems<br>    // We'll use 0 as the placeholder initial value</em><br>    <strong>val results = Array(n + 1) { 0 }<br></strong><em>    // Set the base cases</em><strong><br>    results[1] = 1<br>    results[2] = 1<br>    for (i in 3..n) {<br>        results[i] = results[i-1] + results[i-2]<br>    }<br>    return results[n]</strong><br><strong>}</strong></span></pre><h2 id="093e">Recursion</h2><p id="4d62">We start from <code>i = n</code>. If the results of the subproblems we need for the current iteration already exist in the results table, we can use them. If not, we‚Äôll call the function recursively to solve them and store the results.</p><pre><span id="e752"><strong>fun fibonacci(n: Int): Int {<br></strong><em>    // Initialize an array to keep track of results of subproblems<br>    // We'll use 0 as the placeholder initial value</em><strong><br>    val results = Array(n + 1) { 0 } <br>    </strong><em>// Set the base cases</em><strong><br>    results[1] = 1<br>    results[2] = 1<br>    return helper(n, results)<br>}</strong></span><span id="cb7e"><em>// Write a helper function that takes in the results array as an <br>// argument</em><strong><br>fun helper(n: Int, results: Array&lt;Int&gt;): Int {<br></strong><em>    // Check for the result of the subproblem you need in the <br>    // results table first</em><strong><br>    val nMinusOne: Int = if (results[n-1] != 0) {<br>        results[n-1]<br>    } else {<br></strong><em>        // Only make the recursive call to the subproblem if it's <br>        // not in the results table yet</em><strong><br>        helper(n-1, results)<br>    }<br>    val nMinusTwo: Int = if (results[n-2] != 0) {<br>        results[n-2]<br>    } else {<br>        helper(n-2, results)<br>    }<br></strong><em>    // Fill in the results table with the current results</em><strong><br>    results[n] = nMinusOne + nMinusTwo<br>    return nMinusOne + nMinusTwo<br>}</strong></span></pre><p id="8fec">And that‚Äôs the end of the Kotlin for Interview series. Here‚Äôs the <a rel="noopener" href="https://blog.kotlin-academy.com/kotlin-for-interviews-cheatsheet-88a9831e9d55">link to the cheatsheet</a> covering all 5 parts again. Good luck on your interviews!</p></div></div></section></div>]]>
            </description>
            <link>https://blog.kotlin-academy.com/kotlin-for-interviews-part-5-frequently-used-code-snippets-444ad4d137f5</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043477</guid>
            <pubDate>Tue, 10 Nov 2020 07:10:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making Mass Effect not require admin rights, or how to not write a boolean check]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25042910">thread link</a>) | @__david__
<br/>
November 9, 2020 | https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/ | <a href="https://web.archive.org/web/*/https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p>Hi all, it‚Äôs me again, your favorite modder who publishes a single research blog post a year. Welcome to my new blog, where I will also post maybe once a year! I got fed up with blogger‚Äôs endless unfixed bugs. I‚Äôm going to leave the content there though for historical sake.</p>
<p>I just finished a hardcore crunch to ship ALOT Installer V4, which is a complete rewrite of ALOT Installer. ALOT Installer is the Mass Effect modding scene‚Äôs main texture installation tool, built on top of aquadran‚Äôs MassEffectModder program, which can be used to install textures in a more advanced fashion. In V4 of ALOT Installer, I split the main ‚Äòcore‚Äô features into a cross-platform .NET Core library so I can also write a frontend that works on Linux. But that‚Äôs not why I‚Äôm here today ‚Äì I‚Äôm here to follow up on how I fixed Mass Effect on PC to not require elevation for good.</p>
<h2>Mass Effect on PC: About what you‚Äôd be expect from a mid 2000‚Äôs console port</h2>
<p>For those of you not in the know, Mass Effect came out on PC back in 2008, and was ported from the Xbox 360 by a studio named Demiurge, who also developed Pinnacle Station for Mass Effect. It‚Äôs‚Ä¶ a really meh port that has not aged very well. It‚Äôs passable as a game but it has a lot of problems, even when it came out. Particle LODs not working properly, texture LODs being read backwards, ini settings being randomly reset to their defaults, the problems are pretty numerous, just to name a few. But nothing completely game breaking.</p>
<p>Well, kind of. There is one, but it‚Äôs not specifically due to Mass Effect. The big issue is that Mass Effect requires administrator rights to run, because Demiurge seems to have assumed everyone would run the game as administrator ‚Äì which <em>might</em> have been OK if the game was only really developed when Windows XP existed, but Windows Vista had already been out for over a year by the time the game had released. Even back then though, Windows XP had a concept of LUA (Least User Access) with separated user accounts. For more information on this, you should check out the original post I wrote, <a href="https://www.me3tweaks.com/blog/modding/why-mass-effect-requires-administrator-rights-and-how-we-fixed-origin-not-running-it/">Why Mass Effect on PC requires administrator</a>. It describes a lot of backstory to this post.</p>
<h2>Oh boy, PhysX, my favorite physics library!</h2>
<figure id="attachment_67" aria-describedby="caption-attachment-67"><img loading="lazy" src="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/ageialogo1.gif" alt="" width="236" height="134"><figcaption id="caption-attachment-67">I may have a slight beef with this SDK.</figcaption></figure><p>
Mass Effect for PC runs on a lightly modified version of Unreal Engine 3, which appears to be dated around late 2006. According to some former BioWare developers, this version of Unreal Engine was not very mature yet, to put it lightly. According to some stories from these developers, it was really difficult to work with because Epic Games was focused on Gears of War and not dedicating much time to their partners who were also using the engine.</p>
<p>Unreal Engine 3 uses PhysX for physics interactions, so Epic Games built a dll that interfaces PhysX to Unreal Engine data formats through a file named PhysXLoader.dll, which loads the PhysX libraries from both parties. PhysX is a physics simulation library that was acquired by AGEIA Technologies in the mid 2000s before AGEIA was sold to Nvidia in early 2008. If you remember Physics Processing Unit cards, or PPU, they were using PhysX before Nvidia promptly killed that idea.</p>
<figure id="attachment_66" aria-describedby="caption-attachment-66"><img loading="lazy" src="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-07_19h50_25.png" alt="" width="360" height="136" srcset="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-07_19h50_25.png 360w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-07_19h50_25-300x113.png 300w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-07_19h50_25-250x94.png 250w" sizes="(max-width: 360px) 100vw, 360px"><figcaption id="caption-attachment-66">PhysXLoader.dll, PhysXCore.dll, and NxCooking.dll make up the PhysX dlls for Mass Effect.</figcaption></figure>
<p>All three Mass Effect games use PhysX, but Mass Effect 2 and Mass Effect 3 use the system‚Äôs install of PhysX, while Mass Effect uses the local game‚Äôs PhysX. Mass Effect 2 and Mass Effect 3 also use the ‚Äòmodern‚Äô version of PhysX, rather than the legacy one that was shipped by AGEIA. Nvidia changed some paths under the hood when it took over, which separates Legacy out from it‚Äôs ‚Äòmodern‚Äô versions. </p>
<p>But that doesn‚Äôt seem to stop Legacy PhysX‚Äôs uninstaller from deleting modern PhysX‚Äôs files/registry keys, so during the course of testing this fix, my other copies of Mass Effect 2/3 didn‚Äôt work, even after installing the ‚Äòmodern‚Äô PhysX redistributable. It‚Äôs really annoying how BioWare couldn‚Äôt just ship a 8MB library with the game ‚Äì they already shipped the installer for PhysX with the game, so it‚Äôs not like it saved space!</p>
<p>But anyways‚Ä¶</p>
<h2>The issue with Epic Games‚Äô PhysXLoader.dll is that it can load PhysXCore.dll locally, or from the system‚Äôs installed version</h2>
<p>Err‚Ä¶ wait, how is that an issue? Can‚Äôt you just load the local dll, and if that doesn‚Äôt exist, load the system one? How is that an issue exactly?</p>
<figure id="attachment_73" aria-describedby="caption-attachment-73"><img loading="lazy" src="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1.jpg" alt="OH BOY HERE WE GO" width="294" height="294" srcset="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1.jpg 294w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1-150x150.jpg 150w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1-48x48.jpg 48w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1-250x250.jpg 250w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1-180x180.jpg 180w" sizes="(max-width: 294px) 100vw, 294px"><figcaption id="caption-attachment-73">You won‚Äôt believe how many facepalms there were as I making this fix.</figcaption></figure><p>
On boot, Mass Effect writes two values to the Windows HKEY_LOCAL_MACHINE registry:</p>
<blockquote><p>REG_BINARY HKLM\SOFTWARE\AGEIA Technologies enableLocalPhysXCore [mac address, 6 bytes]<br>
REG_DWORD HKLM\SOFTWARE\AGEIA Technologies EpicLocalDllHack [1]</p></blockquote>
<p>*Mass Effect is a 32-bit program, so on 64-bit systems it goes into HKLM\SOFTWARE\WOW6432Node\AGEIA Technologies instead, if you‚Äôre looking for yourself.</p>
<p>Remember these registry values, they‚Äôre going to be important later!</p>
<p>These registry values are why Mass Effect requires administrative permissions. In my previous blog post linked above, we explored why these writings were enough to make Microsoft put Mass Effect into it‚Äôs compatibility database, which forces it to run as admin when matching on certain executable criteria, which we worked around by modifying the executable criteria to no longer match. </p>
<p>We have to modify the executable to enable Large Address Aware, so the game could load higher resolution textures without running out of memory, so there was no way to avoid breaking the signature. This in turn caused Origin to no longer run the game as it would not elevate games without a valid EA signature. But if the game cannot write these registry keys on boot, the game may crash‚Ä¶ </p>
<p>So it‚Äôs already a big fun chain of problems, but we worked around Mass Effect needing administrative rights by simply giving the user account permissions to that specific AGEIA Technologies registry key. This would let the game process write the values it needed, and would we could go on our merry way. I assumed the game crashed because it was denied write permissions and Demiurge couldn‚Äôt be bothered to write a try/catch around the registry writing code.</p>
<h2>You probably shouldn‚Äôt name your registry values as a hack if you want me to think this is a good idea</h2>
<p>Our solution to this problem did not change Mass Effect‚Äôs behavior ‚Äì the values it wanted to write to the registry were going to be written one way or another, so we were just letting it do the thing it‚Äôs always done, just without administrative rights. There wasn‚Äôt really any change in application behavior.</p>
<figure id="attachment_81" aria-describedby="caption-attachment-81"><img loading="lazy" src="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-01_12h55_59.png" alt="" width="362" height="154" srcset="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-01_12h55_59.png 362w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-01_12h55_59-300x128.png 300w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-01_12h55_59-250x106.png 250w" sizes="(max-width: 362px) 100vw, 362px"><figcaption id="caption-attachment-81">The two registry values that Mass Effect writes.</figcaption></figure>
<p>mirh, a moderator for <a href="https://www.pcgamingwiki.com/wiki/Home">PC Gaming Wiki</a>, sounded the alarm for years that somehow we were breaking other games in ALOT Installer ‚Äì even though our application didn‚Äôt actually change how Mass Effect was behaving writing these values, so there‚Äôs no way our change would break other games.</p>
<p>After many months, he wrote a fairly detailed reason why ALOT Installer (when, in reality, it was Mass Effect) is breaking other games: <b>enableLocalPhysXCore</b> being in the registry <em>is used by other games using Epic Game‚Äôs PhysXLoader.dll.</em> When I was writing V4 of ALOT Installer, I told mirh I would take a more serious look into his idea of a solution that would not break other games, even though at the time I did not really understand how a registry key with the system‚Äôs MAC address would break other games ‚Äì or why it even used a MAC address to begin with.</p>
<p>mirh seems to have determined this enableLocalPhysXCore lets Mass Effect use the local directory‚Äôs PhysXCore.dll/NxCooking.dll, instead of loading the one from the installed PhysX redistributable. Mass Effect doesn‚Äôt install the PhysX redistributable, so it could not rely on it existing, so it needed to use the local libraries.</p>
<p>Hope you‚Äôre strapped in because this is where it gets really dumb: </p>
<h4>The MAC address stored in in the registry by MassEffect.exe is read by PhysXLoader.dll and compared against your system‚Äôs MAC address to determine if it should load the local directory‚Äôs PhysX libraries or the system‚Äôs.</h4>
<p>Which MAC address? </p>
<h3>¬Ø\_(„ÉÑ)_/¬Ø</h3>
<p>So the way Mass Effect works:</p>
<ol>
<li>Very early in the boot process of MassEffect.exe, your MAC address is read and written to the registry as enableLocalPhysXCore (along with EpicLocalDllHack)</li>
<li>MassEffect.exe loads PhysXLoader.dll</li>
<li>PhysXLoader.dll reads the value of enableLocalPhysXCore and compares your system‚Äôs MAC address against it</li>
<li>If it matches, it uses the local folder‚Äôs PhysX, if not, it uses the system‚Äôs redistributable version of PhysX</li>
</ol>
<p>Yes, you read that right.</p>
<p>It turns out that other games, such as Mirror‚Äôs Edge, have a PhysXLoader.dll that also reads these values (as they‚Äôre based on the same code), <em>but they don‚Äôt include local PhysX libraries</em>. So those games boot up, see enableLocalPhysXCore, and try to load the local library, which fails, and the game doesn‚Äôt start. This information is second hand from mirh ‚Äì I have not tested other games broken by this registry value.</p>
<p>Normally that value wouldn‚Äôt exist, and it should use the system PhysX. This behavior can be tested in Mass Effect by denying it write permissions to the registry key, deleting the values, and having Legacy PhysX installed ‚Äì it will use the system libraries instead. If system PhysX is not installed, the application will not boot ‚Äì this is why we originally had to let Mass Effect write these keys, otherwise it could appear that the installer broke Mass Effect, when it actually was a terrible implementation by Epic Games.</p>
<figure id="attachment_157" aria-describedby="caption-attachment-157"><img loading="lazy" src="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1.png" alt="Facepalm" width="782" height="433" srcset="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1.png 782w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-300x166.png 300w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-768x425.png 768w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-250x138.png 250w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-550x305.png 550w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-325x180.png 325w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-542x300.png 542w" sizes="(max-width: 782px) 100vw, 782px"><figcaption id="caption-attachment-157">It‚Äôs hard to imagine any possible scenario where this was a good idea.</figcaption></figure><p>
If you‚Äôre interfacing with a library that has exports you can call to initialize/load the PhysX SDK‚Ä¶ couldn‚Äôt you just, you know, pass a boolean to tell it to locally load? Why does it not locally look to begin with? And what‚Äôs up with the MAC address? Why is this in the registry, where it behaves LIKE A GLOBAL SETTING??? </p>
<p>All of these seem like terrible design decisions ‚Äì and after disassembling the ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/">https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/</a></em></p>]]>
            </description>
            <link>https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25042910</guid>
            <pubDate>Tue, 10 Nov 2020 04:53:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AppleCrate II: A New Apple II-Based Parallel Computer (2015)]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25042551">thread link</a>) | @aresant
<br/>
November 9, 2020 | http://michaeljmahon.com/AppleCrateII.html | <a href="https://web.archive.org/web/*/http://michaeljmahon.com/AppleCrateII.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<b><span face="Arial, helvetica" size="4"><p>AppleCrate II:  A New Apple II-Based Parallel Computer</p>
</span><span face="Arial, helvetica" size="2"><p>
Michael J. Mahon ‚Äì July 26, 2008<br>
Revised ‚Äì September 23, 2015</p>

<p><img src="http://michaeljmahon.com/CrateII.jpg" width="500" height="612"></p>

</span><span face="Arial, helvetica"><p>Introduction</p>
</span></b><span face="Arial, helvetica" size="2"><p>
In 2004 I built the first <a href="http://michaeljmahon.com/Applecrate.html">AppleCrate</a>, an 8-board system, as an inexpensive, easy to program
vehicle for experiments in parallel programming‚Äîa kind of "blade server" for the Apple II, if
you will!  AppleCrate I (at the time I didn't realize that it was number "I" ;-) was great fun, and it
enabled some very interesting experiments, but over time I discovered some of its shortcomings.</p>

<p>First and foremost, since the boards were supported by only two edges and not clamped in place, it
was relatively fragile and hard to transport.  Second, I had come across situations in which more
than 8 slave processors would have been useful.  Third, my arrangement for collecting audio signals
synthesized by the slaves was quite makeshift and delivered sound with lots of digital "hash"
as background noise.  And finally, the original AppleCrate made no provision for plugging I/O cards
into any of its boards, so it had to be hosted by a separate Apple II, adding to the problem of
transporting it for demonstrations.</p>

<p>The AppleCrate II is designed to be significantly improved in all of the areas that were
problems for the AppleCrate I.</p>

<b></b></span><b><span face="Arial, helvetica"><p>Description</p>
</span></b><span face="Arial, helvetica" size="2">

<p>The AppleCrate II is made from 17 Enhanced Apple //e main boards.  (Fifteen of these boards were
obtained in the same eBay auction that netted the eight unenhanced boards for the original AppleCrate.)
Because they are enhanced ROMs, the original NadaNet boot ROM code would not fit and a new
boot protocol had to be developed, as described below.</p>

<p>Instead of mounting the cards vertically in a frame, as in the original, I decided to mount them
horizontally in a stack secured with standoffs‚Äî3/4" long hexagonal rods, each with a screw protruding from
one end and a tapped hole in the other.  The AppleCrate II has nine "columns" of these standoffs‚Äîsix
metal columns at the back and corners of the boards and three nylon columns interior to the boards
to add stiffness, as shown in the photo below at the 2-board construction stage:</p>

<p><img src="http://michaeljmahon.com/TwoBoards.jpg" width="800" height="554"></p>

<p>This "hi-rise" construction makes the "stack" quite rigid and sturdy, while eliminating the need
for a space-consuming exoskeleton.  It also has the advantage of leaving the top board unobstructed
so that I/O cards can be plugged in, allowing it to serve as the host machine for the AppleCrate.  (In fact,
I used 17 boards so that the top board can serve as master and leave 16 slave machines for parallel
programs.)</p>

<p>The Pushbutton 1 input and Annunciator 1 output bus wires and the AN2-to-PB2 GETID daisy chain wires are connected to
machined-pin sockets inserted into the 16-pin game port connector.  These connections support <a href="http://michaeljmahon.com/NadaNet.html">NadaNet</a>,
which is the only signal connection between the boards.  The network adapter (described below) is shown
with its mounting bracket under what will be the third board.  The power bus card is supported by a
similar angle bracket, and the standoffs immediately beneath them are filed down to accomodate the
bracket thickness.</p>

<p>The boards are powered by a PC AT power supply.  The average power consumed by an Apple //e
board is about 4.2 watts, so the whole 17-board crate consumes only about 70 watts in total,
and both the AppleCrate and the power supply run only a few degrees above ambient temperature.</p>

<p>I decided to use #12 copper bus wires
to distribute power to all boards (visible on the right side of the first photo).  I would have preferred
a connectorized approach, but I could not come up with a connector scheme with a
reasonable mating/unmating force.  As a result, I decided to go with soldered power connections.
(It's a good thing that Apple //e's are so reliable, since replacing one in the middle of the
stack would be relatively difficult!)</p>

<p>The top board is used as the "master" machine with I/O cards and an external keyboard plugged into it.
The Master boots the 16 slave Apples in the AppleCrate II and uses them to run parallel programs.
Once they have been booted and started, they can run independently of the master‚Äîthough they are clearly
I/O-constrained!</p>

<b></b></span><b><span face="Arial, helvetica"><p>Indicators</p>
</span></b><span face="Arial, helvetica" size="2">

<p>It has proven useful to have some real-time indication of each board's activity.  The stock board contains a
red "power" LED (at the right) and a red "speaker" LED at the left.  Both are easily visible from the back of the
boards (the "front" of the AppleCrate).  The function of the power LED is fixed, but the speaker LED is usable
as an indicator that software running on the board can operate, just by toggling the speaker.  For example,
printing a "beep"‚ÄîCHR$(07)‚Äîcauses the speaker LED to flash for 0.1 second, and can be used to indicate some
condition in the software.  (The speaker LED will not light when a speaker is installed, but AppleCrate
boards have no speakers attached.)</p>

<p>Although the Applecrate network interface described below incorporates an LED to show global network activity,
it is very useful to be able to see when any particular board is sending on the network.  This need is met by
using the PDL 3 timer to "stretch" each packet send operation into a visible flash of a green rectangular LED.</p>

<p><img src="http://michaeljmahon.com/SendLED.jpg" width="762" height="263"></p>

<p>These photos show the modification made to the 558 timer chip, in which a 267-ohm resistor (just what I
had handy‚Äîany value between 220 and 560 ohms is fine) is connected
between pins 5 and 8, and the "send" signalling LED is connected between pin 8 and ground, with pin 8 going to the
anode.  The rectangular LED is carefully pressed between the cassette input and output jacks.  On some boards,
the jacks were so close together that it was necessary to "shave" the upper plastic swage on the side of the input
jack with an Exacto knife to make room for the LED to press fit between them.  (Note that in these photos the red
wire connected to the anode of the LED has not yet been soldered.)</p>

</span><b><span face="Arial, helvetica"><p>Network Boot in NadaNet 3.x</p>
</span></b><span face="Arial, helvetica" size="2">

<p>Since AppleCrate machines have no I/O capabilities other than
the network, they must be booted from the network.  This requires that the ROMs on the boards be replaced with
EPROMs containing modified RESET code to perform the network boot.</p>

<p>As with the AppleCrate I, replacement of the self-test code was the easiest path, since it is self-contained,
contiguous, and is executed upon power-on reset if no keyboard is connected.  However, the Enhanced //e ROM contains
only $200 bytes of self-test code, just half the size of the unenhanced //e self-test, requiring a new
design for the network boot.</p>

<p>The AppleCrate I used an "active" boot protocol, in which each board enabled by the "GETID daisy chain" (connected from
AN2 of the previous machine to PB2 of the current machine) continuously sent GETID requests to ID 1, until it was assigned
a permanent ID and received a NadaNet boot image.  The complexity of this protocol, requiring both sending and receiving
packets over the network, resulted in a boot ROM requirement of almost $400 bytes‚Äîwhich fit in an <b>Unenhanced</b> //e ROM.</p>

<p>Since the <b>Enhanced</b> //e ROM has only $200 bytes available, a new "passive" boot protocol had to be devised.
The <a href="http://michaeljmahon.com/PASSIVEBOOT.ROM.pdf">new ROM code</a> continuously monitors the network for a broadcast BOOTREQ control packet
containing  the load address and length of the immediately following boot code data.  When the boot image has been correctly
read from the network, control is passed to its starting address.  This passive boot code only needs to <b>read</b> packets from the
net, and so occupies just $190 bytes, which comfortably fits in place of the Enhanced //e ROM self-test code at $C600.</p>

<p>The new boot protocol capitalizes on the fact that boot code is sent as a broadcast transaction, so the
machines being booted do not need IDs to receive boot code.  A page of "second-stage boot" code is added at the
front of the slave machine boot image.  This code is given control immediately after the boot image is received, and,
when enabled by the "GETID daisy chain", it sends a GETID request to the machine that &amp;BOOTed it, making use of the
code in the full NadaNet boot image to do so (see the BOOT2 code in the <a href="http://michaeljmahon.com/NADA.CRATE.pdf">NADA.CRATE</a>
listing for details).</p>

<p>The GETID daisy chain functions just as it did in the AppleCrate I.  The "first" machine is permanently enabled
by connecting its PB2 to ground.  AN2 of each machine is connected
to PB2 of the "next" machine.  The second-stage boot code running in each machine initially sets its AN2.
Then it waits until it sees its PB2 go low, enabling it to send its GETID request.  When its GETID is successful
it drops its AN2, enabling the next machine.  Then it clears its video display, writes a banner showing the
machine ID, and enters its server loop.</p>

<p>This results in permanent
IDs being assigned in the fixed order of the physical daisy chain, while allowing all ROMs to be identical.
An LED on the AppleCrate II NadaNet adapter board is wired to the last machine's AN2, so that when the last
machine drops its AN2, the red LED extinguishes, signalling that all machines have booted successfully.</p>

<p>When a network-booting machine is reset, it first checks the network state.  If the network is low (ZERO),
it performs a cold start.  If the network is being held high (ONE), it checks page 3 to see if it is being cold started or warm reset.  If it is
a warm reset, it re-enters its Server loop.  If it is a cold start, it initializes and enters the ROM boot code, again waiting
for a BOOTREQ packet.  (This approach has the advantage of reliably forcing a reboot on a power cycle, while
still permitting boards to be warm reset while holding the network high.)</p>

<p>As of NadaNet 3.1, all AppleCrate boot ROMs must be <a href="http://michaeljmahon.com/PASSIVEBOOT.ROM.pdf">NadaNet 3.x capable</a>.</p>

</span><b><span face="Arial, helvetica"><p>AppleCrate II NadaNet Interface</p>
</span></b><span face="Arial, helvetica" size="2">
<p><a href="http://michaeljmahon.com/NadaNet.html">NadaNet</a> is a TTL-level serial network in which logic high is represented by a voltage greater than +2 volts
and logic low is represented by a voltage less than +0.7 volts.  The fanout capability of a TTL annunciator output
is sufficient to  drive a dozen or so TTL pushbutton inputs if they are not otherwise ‚Ä¶</p></span></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://michaeljmahon.com/AppleCrateII.html">http://michaeljmahon.com/AppleCrateII.html</a></em></p>]]>
            </description>
            <link>http://michaeljmahon.com/AppleCrateII.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25042551</guid>
            <pubDate>Tue, 10 Nov 2020 03:23:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stakes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25042480">thread link</a>) | @exolymph
<br/>
November 9, 2020 | https://www.sonyasupposedly.com/stakes/ | <a href="https://web.archive.org/web/*/https://www.sonyasupposedly.com/stakes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.sonyasupposedly.com/stakes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25042480</guid>
            <pubDate>Tue, 10 Nov 2020 03:06:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Kills Cname Cloaking on iOS/iPadOS]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25042374">thread link</a>) | @fenier
<br/>
November 9, 2020 | https://cunderwood.dev/2020/11/06/using-cnames-to-bypass-itp-has-been-put-to-torch/ | <a href="https://web.archive.org/web/*/https://cunderwood.dev/2020/11/06/using-cnames-to-bypass-itp-has-been-put-to-torch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://cunderwood.dev/2020/11/06/using-cnames-to-bypass-itp-has-been-put-to-torch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25042374</guid>
            <pubDate>Tue, 10 Nov 2020 02:46:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Networking for Introverts]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25042288">thread link</a>) | @davefreiburger
<br/>
November 9, 2020 | https://gradually.co/how-to-network-as-an-introvert/ | <a href="https://web.archive.org/web/*/https://gradually.co/how-to-network-as-an-introvert/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://gradually.co/how-to-network-as-an-introvert/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25042288</guid>
            <pubDate>Tue, 10 Nov 2020 02:26:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[1984 by George Orwell [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25042280">thread link</a>) | @bra-ket
<br/>
November 9, 2020 | https://snewd.com/wp-content/uploads/2020/01/1984-George-Orwell.pdf | <a href="https://web.archive.org/web/*/https://snewd.com/wp-content/uploads/2020/01/1984-George-Orwell.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://snewd.com/wp-content/uploads/2020/01/1984-George-Orwell.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25042280</guid>
            <pubDate>Tue, 10 Nov 2020 02:24:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Best Practices for Writing Clean Interfaces in Go]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25042085">thread link</a>) | @lanecwagner
<br/>
November 9, 2020 | https://qvault.io/2020/03/15/best-practices-for-writing-clean-interfaces-in-go/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/03/15/best-practices-for-writing-clean-interfaces-in-go/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://qvault.io/2020/03/15/best-practices-for-writing-clean-interfaces-in-go/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25042085</guid>
            <pubDate>Tue, 10 Nov 2020 01:53:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debunking an election fraud claim using open data and Dolt]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25041998">thread link</a>) | @proverbialbunny
<br/>
November 9, 2020 | https://www.dolthub.com/blog/2020-11-09-debunking-election-fraud/ | <a href="https://web.archive.org/web/*/https://www.dolthub.com/blog/2020-11-09-debunking-election-fraud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.dolthub.com/blog/2020-11-09-debunking-election-fraud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25041998</guid>
            <pubDate>Tue, 10 Nov 2020 01:34:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Try Design Thinking]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25041961">thread link</a>) | @gbasin
<br/>
November 9, 2020 | https://garybasin.com/try-design-thinking/ | <a href="https://web.archive.org/web/*/https://garybasin.com/try-design-thinking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2081">
	<img width="362" height="410" src="https://i1.wp.com/garybasin.com/wp-content/uploads/2020/11/remote-1.png?resize=362%2C410&amp;ssl=1&amp;is-pending-load=1" alt="" loading="lazy" data-lazy-src="https://i1.wp.com/garybasin.com/wp-content/uploads/2020/11/remote-1.png?resize=362%2C410&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">	<div>
		<!-- .entry-header -->

		<div>
			
<p>It‚Äôs 9pm, you‚Äôre at your friend‚Äôs house, and the show you‚Äôre watching ends. You scramble to change the channel but you can‚Äôt figure out the remote. You stare at dozens of buttons with no clue where to start. <strong>Doesn‚Äôt it make you feel stupid?</strong> Some experimentation might get you somewhere, but it‚Äôs not easy. Why can‚Äôt you figure it out?</p>



<p>In these situations, we often blame ourselves. We‚Äôre not smart, patient, or capable enough. This conclusion is incorrect ‚è§ <strong>product design is the direct cause of the stress</strong>.</p>



<p>This realization won‚Äôt help you with your frustrating remote experience. However, it does emphasize the importance of user experience design. <strong>We can redesign experiences to create new feelings</strong>.</p>



<p>Next time you‚Äôre confronted with a bad user experience, <a href="https://twitter.com/garybasin/status/1324908038524899329">spend some time brainstorming better designs</a>. You never know where your experiments will take you.</p>



<div><figure><img loading="lazy" width="362" height="950" src="https://i1.wp.com/garybasin.com/wp-content/uploads/2020/11/remote-1.png?resize=362%2C950&amp;ssl=1" alt="" srcset="https://i1.wp.com/garybasin.com/wp-content/uploads/2020/11/remote-1.png?w=362&amp;ssl=1 362w, https://i1.wp.com/garybasin.com/wp-content/uploads/2020/11/remote-1.png?resize=114%2C300&amp;ssl=1 114w" sizes="(max-width: 362px) 100vw, 362px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/garybasin.com/wp-content/uploads/2020/11/remote-1.png?w=362&amp;ssl=1 362w, https://i1.wp.com/garybasin.com/wp-content/uploads/2020/11/remote-1.png?resize=114%2C300&amp;ssl=1 114w" data-lazy-src="https://i1.wp.com/garybasin.com/wp-content/uploads/2020/11/remote-1.png?resize=362%2C950&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>




					</div><!-- .entry-content -->

		<!-- .entry-meta -->
	</div>

	
</article></div>]]>
            </description>
            <link>https://garybasin.com/try-design-thinking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25041961</guid>
            <pubDate>Tue, 10 Nov 2020 01:27:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Replacing my phone battery with a cheap AliExpress knock-off]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25041894">thread link</a>) | @flotwig
<br/>
November 9, 2020 | https://zach.bloomqu.ist/blog/2020/11/aftermarket-cell-phone-battery.html | <a href="https://web.archive.org/web/*/https://zach.bloomqu.ist/blog/2020/11/aftermarket-cell-phone-battery.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>This is a story of one man√¢‚Ç¨‚Ñ¢s quest for power.</p> <p>I purchased my current phone, a OnePlus 5T, in 2017. This summer, after about two and a half years of ownership, I noticed that it was no longer holding a charge all day. Frequently, the phone would reach 0% and shut off, right in the middle of tracking an evening bike ride or watching Netflix while cooking dinner. Although cell phone battery wear is a well-known issue, I got tired of it pretty quickly.</p> <p>I used the <a href="https://play.google.com/store/apps/details?id=com.digibites.accubattery&amp;hl=en_US&amp;gl=US">AccuBattery</a> app for about two months to try and get a handle on my battery health. It measured my phone√¢‚Ç¨‚Ñ¢s amperage draw during the day and used that to estimate that of the 3300 milliamp-hour (mAh) capacity that my battery originally offered, only about 2400 mAh of capacity remained - only about 75% of the battery√¢‚Ç¨‚Ñ¢s original health:</p> <p><img src="https://zach.bloomqu.ist/assets/battery/oem-capacity.png" alt="Screenshot of AccuBattery app for OEM battery capacity"></p> <p>This answered the question of √¢‚Ç¨≈ìwhy does it feel like my phone is shutting off so quickly?√¢‚Ç¨ÔøΩ pretty clearly. Now, it was up to me to get a replacement battery.</p> <h3 id="attempting-to-get-a-genuine-battery">Attempting to get a genuine battery</h3> <p>My first thought was that I could simply order the OEM OnePlus 5T battery somewhere online. Why not? I found a page on the OnePlus website where prices are listed for replacement parts. The USA page was down at the time of this writing, but the <a href="https://www.oneplus.in/support/pricing/detail?code=7">India support page</a> lists a OnePlus 5T OEM battery replacement as being about $15.</p> <p>This seemed acceptable to me. My first thought was to email OnePlus support asking how to purchase the battery. Unfortunately, according to the service rep, they do not ship or sell OEM batteries without service:</p> <blockquote> <p>We would like to inform you that we do not ship or sell the accessories in any parts of the world, and all the repairs are carried out by our Authorized service centers only. So if you wish to get the device repaired, you can send it to the OnePlus authorized service center and get the same repaired.</p> </blockquote> <p>This is in line with what other OnePlus customers have reported - nobody, as far as I can tell, has ever been able to source OEM batteries from OnePlus, leaving DIY customers like myself to try and find knock-offs elsewhere.</p> <p>I would√¢‚Ç¨‚Ñ¢ve sent my phone in for repairs, but after I received the above email, I had such a long and terrible customer support experience trying to arrange the repair that by the end of it, I no longer trusted OnePlus to reliably service and return my phone. This lack of trust was reinforced by horror stories from other OnePlus customers - one customer√¢‚Ç¨‚Ñ¢s phone was <a href="https://www.reddit.com/r/oneplus/comments/eleckw/sent_my_oneplus_5_to_fort_worth_tx_for_repair_no/">lost by the Fort Worth, TX service center</a>, another√¢‚Ç¨‚Ñ¢s was <a href="https://www.reddit.com/r/oneplus/comments/depgkg/oneplus_lost_my_coworkers_phone_during_repair_at/">lost and took 4 weeks before being returned</a>, and yet another customer had <a href="https://www.reddit.com/r/oneplus/comments/jke2kd/sent_my_op3t_for_a_battery_replacement_oneplus/">their phone held hostage unless they agreed to repairing EVERYTHING instead of just getting the battery replaced</a>. These stories, combined with my awful customer support experience, convinced me that sending my phone in would be a truly bad idea.</p> <h3 id="buying-an-aftermarket-battery">Buying an aftermarket battery</h3> <p>Many people on the /r/oneplus5t subreddit have recommended purchasing a <a href="https://www.ifixit.com/Store/Android/OnePlus-5-5T-Replacement-Battery/IF330-018?o=2">replacement battery from iFixit</a>, but I felt like iFixit was simply selling cheap Chinese batteries with a nice label on them. I mean, if OnePlus can fix it for $15, why does the iFixit battery cost $30, if not for marketing?</p> <p>So, I hit up eBay and AliExpress, and eventually found the [sic] √¢‚Ç¨≈ìSpecail Mobilephone Parts Store√¢‚Ç¨ÔøΩ, where they offer a <a href="https://web.archive.org/web/20201109223630/https://www.aliexpress.com/item/4000438352423.html">√¢‚Ç¨≈ì4650 mAh√¢‚Ç¨ÔøΩ √¢‚Ç¨≈ìPerfect business battery√¢‚Ç¨ÔøΩ</a> for the OnePlus 5T. With slogans like <a href="https://zach.bloomqu.ist/assets/battery/giant-energy-huge-capacity.webp">√¢‚Ç¨≈ìGiant energy; huge capacity√¢‚Ç¨ÔøΩ</a>, <a href="https://zach.bloomqu.ist/assets/battery/safety-does-not-explode.webp">√¢‚Ç¨≈ìSafety does not explode√¢‚Ç¨ÔøΩ</a>, and <a href="https://zach.bloomqu.ist/assets/battery/ensure-qualified-and-safe-to-use.webp">√¢‚Ç¨≈ìEnsure qualified and safe to use√¢‚Ç¨ÔøΩ</a>, I felt confident that my $11.87 was going to a good place. I placed the order and, about 3 weeks later, I received the battery in my mailbox.</p> <h3 id="battery-physics-101">Battery Physics 101</h3> <p><img src="https://zach.bloomqu.ist/assets/battery/oem-and-aftermarket.jpg" alt="Photo of the OEM battery and the aftermarket battery side-by-side"> <small>The OEM battery (left) and the aftermarket battery installed (right).</small></p> <p>The first thing I noticed about the replacement battery was that the capacity was even HIGHER than what I ordered. The OnePlus 5T OEM battery is rated at 3300 mAh capacity, the AliExpress product page advertised a battery with 4650 mAh capacity, and the label on the battery I received claimed an astounding <em>5350 mAh</em> capacity - 162% of the OEM capacity. Clearly, I had gotten a great deal!</p> <p>The second thing I noticed was that the aftermarket battery was significantly lighter than the OEM battery. So much lighter that I weighed the batteries out of curiosity. The OEM OnePlus 5T battery weighed 47.0g. The aftermarket OnePlus 5T battery weighed 38.7g, or about 17% less.</p> <p>It√¢‚Ç¨‚Ñ¢s amazing that Da Da Xiong was able to achieve 162% capacity with 17% less weight. Too amazing to be true, in fact.</p> <p>Via Wikipedia, I learned that the <a href="https://en.wikipedia.org/wiki/Specific_energy">specific energy</a> of a lithium-ion polymer battery can be up to <a href="https://en.wikipedia.org/wiki/Lithium-ion_battery">265 watt-hours per kilogram (Wh/kg)</a>. The nominal voltage of the lithium-ion polymer batteries here is about 3.8V. We can use <a href="https://en.wikipedia.org/wiki/Ohm%27s_law">Ohm√¢‚Ç¨‚Ñ¢s law</a> to calculate the maximum possible capacity of each battery based on weight, assuming that each battery is always supplying the nominal 3.8V.</p> <p>Let√¢‚Ç¨‚Ñ¢s start by calculating the maximum possible Amp-hours (Ah) per kilogram (kg) for a Li-ion poly battery at 3.8V, using Ohm√¢‚Ç¨‚Ñ¢s law:</p> <div><div><pre><code>265 Wh/kg / 3.8 V = 69 Ah/kg
</code></pre></div></div> <p>Now, we can calculate the maximum physically possible capacity for each battery by multiplying this number by the weights of each battery:</p> <div><div><pre><code>OEM battery:          .047 kg * 69 Ah/kg = 3.2 Ah = 3200 mAh
Aftermarket battery: .0387 kg * 69 Ah/kg = 2.6 Ah = 2600 mAh
</code></pre></div></div> <p>The astute reader might be wondering why this estimate for the maximum capacity of the OEM battery (3200 mAh) is less than the capacity OnePlus advertises (3300 mAh). Why is this? Well, it√¢‚Ç¨‚Ñ¢s because the assumption we made - that each battery is always supplying the nominal 3.8V - is false. The voltage output of a Li-ion poly battery <a href="https://learn.adafruit.com/li-ion-and-lipoly-batteries/voltages">drops over time</a>, so the calculation shown is only a lower bound approximation of each battery√¢‚Ç¨‚Ñ¢s maximum capacity.</p> <p>I don√¢‚Ç¨‚Ñ¢t have information about the exact chemical composition of these batteries, nor the voltage charts, nor do I know what the upper and lower voltage limits are on the OnePlus 5T charging circuit. However, if we estimate that the voltage drops from 3.8V to 3.0V in a linear fashion (<code>V = 3.8 - .8t, 0 &lt;= t &lt;= 1</code>), we can use integration to arrive at approximately 3600 mAh maximum capacity for the OEM battery and 2900 mAh maximum capacity for the aftermarket battery.</p> <p>Even without exact numbers, these calculations demonstrate that <em>something</em> is fishy about the Da Da Xiong battery√¢‚Ç¨‚Ñ¢s mAh claims.</p> <h3 id="real-world-usage">Real-world usage</h3> <p>Anyways, I didn√¢‚Ç¨‚Ñ¢t buy this shady AliExpress battery just so that I could do a bunch of math. I purchased it to restore my phone√¢‚Ç¨‚Ñ¢s ability to last all day, and it has definitely succeeded at that. From a qualitative perspective, I now have enough juice to keep my phone√¢‚Ç¨‚Ñ¢s battery fueled all day until I can recharge it at night.</p> <p>From a quantitative perspective, AccuBattery reports that the aftermarket battery has an estimated 3360 mAh capacity, which about matches the capacity of the OEM battery:</p> <p><img src="https://zach.bloomqu.ist/assets/battery/aftermarket-capacity.png" alt="Screenshot of AccuBattery app for aftermarket battery capacity"></p> <p>However, what AccuBattery fails to account for is the fact that once the aftermarket battery reaches 15%, the battery percentage begins to free-fall until it reaches 0% and shuts off. It seems like 15% on the aftermarket battery is equivalent to 1% on the OEM battery. I think this is because the Android OS cannot correctly estimate the battery√¢‚Ç¨‚Ñ¢s remaining charge because it has different voltage characteristics than the OEM battery, but it doesn√¢‚Ç¨‚Ñ¢t really bother me, I just have to make sure that to charge the phone at 15% instead of 1%. This seems to be an extremely common experience with DIY battery replacements - even folks using the iFixit battery run in to this issue.</p> <p>If we take 15% off of AccuBattery√¢‚Ç¨‚Ñ¢s estimated capacity, we get 2856 mAh, which is really really close to what a brand new OnePlus 5T reports - AccuBattery estimates the OEM battery as having ~3000 mAh capacity when it is brand new. That about matches my experience - with the Da Da Xiong battery, the phone is staying alive longer, almost like when it was new.</p> <h3 id="conclusions">Conclusions</h3> <ul> <li>Random Chinese batteries do not work as advertised - they will not magically double your phone√¢‚Ç¨‚Ñ¢s battery capacity.</li> <li>However, random Chinese batteries work <em>almost as well</em> as brand new OEM batteries, but your battery percentage will forever be miscalibrated.</li> <li>Never trust OnePlus customer service.</li> </ul> </div></div>]]>
            </description>
            <link>https://zach.bloomqu.ist/blog/2020/11/aftermarket-cell-phone-battery.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25041894</guid>
            <pubDate>Tue, 10 Nov 2020 01:14:15 GMT</pubDate>
        </item>
    </channel>
</rss>
